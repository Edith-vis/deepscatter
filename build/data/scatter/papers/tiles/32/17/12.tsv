id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
f81f28876dc3b4185d4bcae68cf6c894b96ca5b2	understanding and forecasting atmospheric quality parameters with the aid of anns	neural nets;spatial scale;neural nets data mining decision making forecasting theory geophysics computing;data mining;artificial intelligent;geophysics computing;forecasting theory;decision making process;artificial neural nets atmospheric quality parameters forecasting artificial intelligence knowledge discovery urban air quality pollutant concentration criteria operational forecasting knowledge domain environmental decision making process;artificial neural networks conferences joints;urban air quality;ozone;problem solving;knowledge discovery	A problem solving domain for the application of artificial intelligence (AI) methods towards knowledge discovery for the purposes of modelling and forecasting is urban air quality. This domain has the specific characteristic that the key parameters of interest (pollutant concentration criteria) have multiple temporal (and spatial) scales. The present paper applies ANNs for the operational forecasting of the 8-hour running average for Ozone, 24 hours in advance, for two locations in Athens, Greece. Results verify the ability of the methods to analyze and model this knowledge domain and to forecast the levels of key parameters that provide direct input to the environmental decision making process.	applications of artificial intelligence;problem solving	Kostas D. Karatzas;George Papadourakis;Ioannis Kyriakidis	2008	2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)	10.1109/IJCNN.2008.4634159	ozone;decision-making;marketing and artificial intelligence;spatial ecology;computer science;artificial intelligence;machine learning;data mining;knowledge extraction;operations research;artificial neural network	Vision	9.648059706475971	-19.073119123634385	160669
74c5207a322669a20d6c2b37a064a0bc3efadf60	probabilistic prediction of chaotic time series using similarity of attractors and loocv predictable horizons for obtaining plausible predictions		This paper presents a method for probabilistic prediction of chaotic time series. So far, we have developed several model selection methods for chaotic time series prediction, but the methods cannot estimate the predictable horizon of predicted time series. Instead of using model selection methods employing the estimation of mean square prediction error (MSE), we present a method to obtain a probabilistic prediction which provides a prediction of time series and the estimation of predictable horizon. The method obtains a set of plausible predictions by means of using the similarity of attractors of training time series and the time series predicted by a number of learning machines with different parameter values, and then obtains a smaller set of more plausible predictions with longer predictable horizons estimated by LOOCV (leave-one-out cross-validation) method. The effectiveness and the properties of the present method are shown by means of analyzing the result of numerical experiments.	cross-validation (statistics);time series	Shuichi Kurogi;Mitsuki Toidani;Ryosuke Shigematsu;Kazuya Matsuo	2015		10.1007/978-3-319-26555-1_9	artificial intelligence;machine learning;mathematics;statistics	ML	8.971161581696622	-21.73082824310804	161113
e640ff99245347efd46cd11b54aebf1059752b77	a study of deep learning networks on mobile traffic forecasting		With evolution toward the fifth generation (5G) cellular technologies, forecasting and understanding of mobile Internet traffic based on big data is the foundation to enable intelligent management features. To take full advantage of machine learning, a more comprehensive investigation on a mobile traffic dataset with the latest deep learning models is desired. Therefore, a multitask learning architecture using deep learning networks for mobile traffic forecasting is presented in this work. State-of-the-art deep learning models are studied, including 1) recurrent neural network (RNN), 2) three-dimensional convolutional neural network (3D cNn), and 3) combination of CNN and RNN (CNN-RNN). The experiments reveal that CNN and RNN can extract geographical and temporal traffic features respectively. Comparing with either deep or non-deep learning approaches, CNN-RNN is a reliable model leading in all tasks with 70 to 80% forecasting accuracy.	artificial neural network;big data;computer multitasking;convolutional neural network;deep learning;experiment;fifth generation computer;machine learning;random neural network;recurrent neural network	Chih-Wei Huang;Chiu-Ti Chiang;Qiuhui Li	2017	2017 IEEE 28th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)	10.1109/PIMRC.2017.8292737	internet traffic;architecture;convolutional neural network;real-time computing;big data;deep learning;recurrent neural network;multi-task learning;computer science;machine learning;artificial intelligence	Metrics	8.219790382449373	-23.049650433723066	161203
2045be228f6391f5f74a77f1bd0328501e590011	dynamics of predictability and variable influences identified in financial data using sliding window machine learning		In this paper we analyze the dynamics of the predictability and variable interactions in financial data of the years 2007–2014. Using a sliding window approach, we have generated mathematical prediction models for various financial parameters using other available parameters in this data set. For each variable we identify the relevance of other variables with respect to prediction modeling. By applying sliding window machine learning we observe that changes of the predictability of financial variables as well as of influence factors can be identified by comparing modeling results generated for different periods of the last 8 years. We see changes of relationships and the predictability of financial variables over the last years, which corresponds to the fact that relationships and dynamics in the financial sector have changed significantly over the last decade. Still, our results show that the predictability has not decreased for all financial variables, indeed in numerous cases the prediction quality has even improved.		Stephan M. Winkler;Gabriel Kronberger;Michael Kommenda;Stefan Fink;Michael Affenzeller	2015		10.1007/978-3-319-27340-2_41	real-time computing;simulation;computer science;machine learning	ML	6.737165773084205	-18.5873652482911	161798
3e3bf31f3d32ef81cd31ad5d3647b8adf09521cd	a methodology for improving complex sales success in crm systems		In this paper we propose a methodology for extracting complex sales expert rules by analyzing the data from the past lost/won deals stored in Customer Relationship Management Systems.	customer relationship management;email;fax;management system;random forest;rule induction;time series	Doru Rotovei;Viorel Negru	2017	2017 IEEE International Conference on INnovations in Intelligent SysTems and Applications (INISTA)	10.1109/INISTA.2017.8001179	customer intelligence;data mining;data modeling;feature extraction;business;customer relationship management;marketing	Robotics	4.9667340990532685	-19.44867957228901	163145
0b1742462ab6b228a148375e482beb492ea3a925	analyzing stock market tick data using piecewise nonlinear model	stock market;backpropagation neural network;chaotic analysis;stock price;indexation;time lag;financial market;profitability;stock trading;change point detection;change point;nonlinear model	Trading in stock market indices has gained unprecedented popularity in major ®nancial markets around the world. However, the prediction of stock price index is a very dif®cult problem because of the complexity of the stock market data. This study proposes stock trading model based on chaotic analysis and piecewise nonlinear model. The core component of the model is composed of four phases: The ®rst phase determines time-lag size in input variables using chaotic analysis. The second phase detects successive change-points in the stock market data and the third phase forecasts the change-point group with backpropagation neural networks (BPNs). The ®nal phase forecasts the output with BPN. The experimental results are encouraging and show the usefulness of the proposed model with respect to pro®tability. q 2002 Elsevier Science Ltd. All rights reserved.	artificial neural network;backpropagation;business process network;chaos theory;darknet market;nonlinear system	Kyong Joo Oh;Kyoung-jae Kim	2002	Expert Syst. Appl.	10.1016/S0957-4174(01)00058-6	change detection;financial market;profitability index	ML	5.41101476251679	-17.415958156916123	163484
48b4f05bf82dbe4c24acab6c62c02e94a8f23db9	a study on the universal method of eeg and ecg prediction		As one of the most important attribute of nonlinear dynamic system, chaotic time series include electroencephalogram (EEG) and electrocardiogram (ECG) have been widely studied for decades. However, the universal prediction method of them is still unexplored due to their inherent random feature and complexity. Considering the high-layer information of images and time-correlation of time series data, traditional support vector machine (SVM), convolution neural network (CNN) and bi-directional recurrent neural network (BRNN) are the main models being used. In this work, by combining CNN with BRNN, we developed a universal model (BRCNN) for high accurate prediction of two of chaotic time series problems (CTSPs), EEG and ECG. For comparison, three models include SVM, CNN, and BRCNN are simultaneously performed on a dataset of EEG signal and a dataset of ECG signal, results demonstrated a superior classification quality of BRCNN (i.e., ∼0.90 and ∼0.85 AUC, respectively). Such a high prediction accuracy of BRCNN provides the possibility of applying a universal model for high accurate prediction of EEG and ECG.	artificial neural network;convolution;dynamical system;electroencephalography;nonlinear system;recurrent neural network;support vector machine;time series	Chenxuan Wei;Chuang Zhang;Ming Wu	2017	2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)	10.1109/CISP-BMEI.2017.8302096	convolutional neural network;support vector machine;time series;artificial intelligence;pattern recognition;nonlinear system;electroencephalography;computer science;recurrent neural network	ML	8.967459747071056	-22.093737961293968	164096
80ea94e27b7ee19a811e888d8cf022f3478e93a3	application of generalized chebyshev neural network in air quality prediction	chebyshev polynomial;air quality prediction;artificial neural network	Air pollution time series is often characterized as chaotic in nature. The prediction using traditional statistical techniques and artificial neural network with back-propagation (BP) algorithm, which is most widely applied, do not give reliable prediction results. The new algorithm is therefore proposed to predict the chaotic time series based on the generalized Chebyshev neural network technique. In addition, the new algorithm has no problems such as local minima, slow convergence arising from the steepest descent-like algorithm. Finally, to illustrate the power of the Chebyshev Neural Network (CNN), a simulation example is presented to show good performance that extracts useful information from the weight functions for understanding relations inherent in the given patterns, and the trained CNN has good performance both on generalization and calculating precision.	artificial neural network	Fengjun Li	2011		10.1007/978-3-642-21515-5_56	chebyshev polynomials;mathematical optimization;computer science;artificial intelligence;machine learning;artificial neural network	ML	8.845390758411956	-22.082877619598055	164296
db6279de9856cc5890fb4a37f2571b56e0455d32	design of specific-to-problem kernels and use of kernel weighted k-nearest neighbours for time series modelling	kernel methods;parallelization of kernel methods;large data sets;specific to problem kernels;input output;large scale;function approximation;time series modelling;gaussian kernel;least squares support vector machines;time series data;kernel method;feature selection;k nearest neighbour;time series prediction;kernel weighted k nearest neighbours;least squares support vector machine;generalization capability	Least squares support vector machines (LSSVM) with Gaussian kernel represent the most used of the kernel methods existing in the literature for regression and time series prediction. These models have a good behaviour for these types of problems due to their generalization capabilities and their smooth interpolation, but they are very dependent on the feature selection performed and their computational cost notably increases with the number of training samples. Time series prediction can be tackled as a regression problem by constructing a set of input/output data from the series; this traditional approach and the use of typical recursive or direct strategies present serious drawbacks in long-term prediction. This paper presents an alternative based on the settings of specific-to-problem kernels to be applied to time series prediction focusing on large scale prediction. A simple methodology for kernel creation based on the periodicities in time series data is proposed. An alternative to LSSVM models with lower computational cost, the Kernel Weighted K-Nearest Neighbours (KWKNN) is described for function approximation. A parallel version of KWKNN is also presented to deal with large data sets. & 2010 Elsevier B.V. All rights reserved.	algorithmic efficiency;approximation;computation;computational complexity theory;epcc;experiment;feature selection;granada;input/output;interpolation;k-nearest neighbors algorithm;kernel (operating system);kernel method;least squares support vector machine;parallel computing;recursion;time series	Ginés Rubio;Luis Javier Herrera;Héctor Pomares;Ignacio Rojas;Alberto Guillén	2010	Neurocomputing	10.1016/j.neucom.2009.11.029	kernel method;mathematical optimization;kernel embedding of distributions;computer science;machine learning;time series;pattern recognition;mathematics;tree kernel;feature selection;variable kernel density estimation;polynomial kernel	AI	8.095235269041542	-20.872048602574665	165157
fee48f5120beba459db01ec1478f0f288d6a27b3	a short-term spatio-temporal approach for photovoltaic power forecasting	forecasting;solar irradiance;time series;forecasting algorithm performances short term spatiotemporal approach photovoltaic power forecasting pv power conversion model spatial variable dependency temporal information pv plant weather variables irradiance tilted plane ambient temperature wind speed correlation sparsity time series data meteorological stations;time series load forecasting photovoltaic power systems spatiotemporal phenomena sunlight;time series forecasting solar irradiance distributed generation correlated data;distributed generation;forecasting wind forecasting predictive models correlation time series analysis data models;correlated data	This paper presents a Photovoltaic (PV) power conversion model and a forecasting approach which uses spatial dependency of variables along with their temporal information. The power produced by a PV plant is forecasted by a PV conversion model using the predictions of three weather variables, namely, irradiance on the tilted plane, ambient temperature, and wind speed. The predictions are accomplished using a spatio-temporal algorithm that exploits the sparsity of correlations between time series data of different meteorological stations in the same region. The performances of the forecasting algorithm as well as the PV conversion model are investigated using real data recorded at various locations in Italy. The comparisons with various benchmark methods show the effectiveness of the proposed approaches over short-term forecasts.	algorithm;benchmark (computing);electric power conversion;page view;performance;sparse matrix;time series	Akin Tascikaraoglu;Borhan Molazem Sanandaji;Gianfranco Chicco;Valeria Cocina;Filippo Spertino;Ozan Erdinc;Nikolaos G. Paterakis;João P. S. Catalão	2016	2016 Power Systems Computation Conference (PSCC)	10.1109/PSCC.2016.7540958	meteorology;geography;climatology;remote sensing	AI	9.44342613997309	-18.208249011776783	167194
1afb689d29bf19dc07fa8c5b125a81ce69443fb9	a comparative study on forecasting polyester chips prices for 15 days, using different hybrid intelligent systems	chemical industry;chemicals;financial forecasting;raw materials;efficient market hypothesis;economic forecasting;hybrid neuro fuzzy model;pricing;stock markets;locally linear model tree;artificial neural networks;decision support system;polymer blends;decision support systems;artificial intelligence;fuzzy systems;knowledge based systems;textile industry	Forecasting in a risky situation is a very important function for managers to assist them in decision-making. One of the fluctuated markets in stock exchange market is chemical market. In this research the target item for prediction is PET (Poly Ethylene Terephthalate) which is the raw material for textile industries and it's very sensitive on oil prices and the demand and supply ratio. The main idea is coming through NORN model which was presented by Lee and Liu [1]. In this article after modifying the NORN model, a model has been proposed and real data are applied to this new model (we named it AHIS which stands for Adaptive Hybrid Intelligent System). Finally, three different types of simulation have been conducted and compared with each other. They show that hybrid model which is supporting both Fuzzy Systems and Neural Networks concepts, satisfied the research question considerably. In normal situation the model forecasts a relevant trend and can be used as a DSS for a manager.	artificial neural network;fuzzy control system;hybrid intelligent system;neural network software;payment card industry data security standard;polyethylene terephthalate;simulation	Mojtaba Sedigh Fazli;Jean-Fabrice Lebraty	2013	The 2013 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2013.6706967	chemical industry;decision support system;computer science;artificial intelligence;machine learning;operations research	Robotics	6.683558048641854	-19.374110388047203	167281
852fc18190a83025deb4de8f1725ce00b864cece	engineering item risk evaluating based on evolutionary algorithm and bp neural network	convergence;evolutionary computation;neural nets;engineering item risk evaluation;training;risk evaluation;risk management;quality improvement;construction industry;building industry;backpropagation;data mining;structural engineering backpropagation construction industry evolutionary computation neural nets quality control risk management;evolutionary computation neural networks network topology quality management risk management engineering management convergence buildings construction industry conference management;engineering item evolutionary algorithm neural network;indexes;artificial neural networks;engineering item;building industry engineering item risk evaluation evolutionary algorithm bp neural network quality improvement;complex system;structural engineering;bp neural network;indexation;optimization;evolutionary algorithm;quality control;neural network	The purpose of this paper is to improve the risk evaluating quality of engineering item. The topology structure of evolutionary algorithm based BP (EABP) neural network is described, the principle of EABP neural network is introduced,and the implement step of EABP neural network is given. The combination algorithm is applied to risk evaluating for the engineering item, and its result is compared with that of conventional BP neural network. The comparing result shows that EABP neural network fits to complex system such as risk evaluating for engineering item, it improves in a certain extension training speed and precision, it can improve the quality of engineering item risk evaluating, and it fits to solve some problems in which evaluating indexes weights are difficult to be determined or there exists complex non-linear relation among them.	artificial neural network;evolutionary algorithm	Wanhua Zhao	2009		10.1109/SSME.2009.137	quality control;convergence;construction;computer science;engineering;artificial intelligence;backpropagation;machine learning;data mining;artificial neural network	ML	5.71730192758092	-21.203550731785928	168395
c3f5b21ee666dd87fbf1d7de32202e5e5092898e	aplicación de modelos auto regresivos para la predicción de generación de energía eléctrica a partir de datos eólicos		We discuss the classic auto regressive statistical models Box and Jenkins used in prediction problems, and their application is analyzed in the energy sector. Subsequently, we propose a methodology based on the application of these models for the prediction of electric power generation, from data obtained at a wind farm in Ventosa, Oaxaca. Finally, the model and the preliminary results obtained shows an R2 = 0.974 and an RMSE = 18.862.	jenkins;linear algebra;statistical model	Sara Edith Pinzón Pineda;José Alberto Hernández Aguilar;Gustavo Arroyo-Figueroa	2017	Research in Computing Science			ML	8.592805820280963	-19.446659063870012	168993
1eda56fe14625b5d80e8452c26ecf43f4ea2dc33	modified diffusion model with multiple products using a hybrid ga approach	life cycle;linear least square;non linear least square;parameter estimation;diffusion model;hybrid genetic algorithm;new products;demand forecasting	As technology advances, the speed in which new products are developed also increases. Due to such increases, product forecasting has become much more vital for a company. The Bass diffusion model is a demand-forecast model that explores the phases of a product's life cycle that have been successful in the diffusion of forecasting innovation in new products. Recognizing the need for an efficient parameter estimation method for multi-product forecasting, we have conducted research using the hybrid genetic algorithm (HGA). The research conducted will provide an alternate approach to explore the forecasting capability of the diffusion models without having as many limitations as the original method. We used both published data and LCD-monitor global sales data to test and verify our method. Results show that the proposed model using a hybrid GA approach can improve the forecasting efficiency.	software release life cycle	Fu-Kwun Wang;Ku-Kuang Chang	2009	Expert Syst. Appl.	10.1016/j.eswa.2009.05.018	biological life cycle;econometrics;demand forecasting;artificial intelligence;machine learning;diffusion;estimation theory;operations research	Vision	6.530903744191547	-17.627295734091756	170768
fcb8c54d361a6a30ac61d66e21a3d4beb63d30c9	customer recognition of network finance based on mkl algorithm	preface;network finance;customer recognition;mkl algorithm	Given Bayes neural network method, the direct marketing customer repurchase behavior shall be built to analyze how different customer groups have different expectations on ATM services. Also, application of GMKL algorithm in customer recognition of network finance is proposed, training with the use of 20, 000 customer records extracted from RESSET/DB financial research database. First, transform the numerical characteristics of sample for collected customer record and normalize the data. Next, try to obtain multi-kernel function with different array modes of kernel function and compare the results, and the results show that accuracy of MKL in customer recognition of network finance can be up to 86. 4%, which is obvious higher than that of support vector machine.	atm turbo;algorithm;artificial neural network;database;math kernel library;numerical analysis;support vector machine	Lixin Wang;Lianggang Wu;Kelly Wang	2013	JNW	10.4304/jnw.8.10.2452-2458	voice of the customer;data science;machine learning;data mining;customer intelligence;world wide web;computer security	ML	5.052023716096139	-20.828486805589566	172117
cf37ac4fea384cf796b3c8920afb9adfb7d1ef43	neural networks and statistical techniques: a review of applications	feed forward neural network;statistical method;logistic regression;discriminant analysis;model building;regression analysis;statistical techniques;neural network;neural network regression	Neural networks are being used in areas of prediction and classification, the areas where statistical methods have traditionally been used. Both the traditional statistical methods and neural networks are looked upon as competing model-building techniques in literature. This paper carries out a comprehensive review of articles that involve a comparative study of feed forward neural networks and statistical techniques used for prediction and classification problems in various areas of applications. Tabular presentations highlighting the important features of these articles are also provided. This study aims to give useful insight into the capabilities of neural networks and statistical methods used in different kinds of applications.	neural networks	Mukta Paliwal;Usha A. Kumar	2009	Expert Syst. Appl.	10.1016/j.eswa.2007.10.005	feedforward neural network;probabilistic neural network;model building;computer science;artificial intelligence;machine learning;data mining;logistic regression;linear discriminant analysis;artificial neural network;regression analysis	DB	6.8399879368602186	-23.710214553389335	172316
612d8d8bca80d5b73e03cae612adbfb4abbf3673	fuzzy modeling in stock-market analysis	takagi sugeno fuzzy models;takagi sugeno model;takagi sugeno fuzzy model;scenario model;general nonlinear systems fuzzy modeling stock market analysis takagi sugeno fuzzy models model structures case study dutch aex price index scenario model what if scenarios prediction model predictive components macro economic variables ts models;what if scenarios;finance;stock market;neural networks;economic forecasting;economic forecasting environmental economics takagi sugeno model predictive models finance fuzzy sets fuzzy systems fuzzy neural networks neural networks linear regression;predictive components;linear regression;uncertainty handling;modelling stock markets fuzzy set theory uncertainty handling economic cybernetics;fuzzy set theory;fuzzy sets;financial engineering;stock markets;ts models;fuzzy modeling;stock market analysis;model structures;price index;environmental economics;predictive models;macro economic variables;prediction model;nonlinear system;fuzzy neural networks;dutch aex price index;economic cybernetics;fuzzy systems;fuzzy model;general nonlinear systems	This article examines the application of Takagi-Sugeno fuzzy models to the problem of stock-market analysis. Different model structures are evaluated in a case study on the modeling of the Dutch AEX-price index. A scenario-model is used for examining “what if ’-scenario’s and a prediction model searches for predictive components in relevant (macro) economic variables. It is found that TS-models can be applied successfully in these areas, due to their capability of approximating general non-linear systems and to their transparency. Further research is recommended.	approximation algorithm;fuzzy concept;linear system;nonlinear system;what if	Magne Setnes;O. J. H. van Drempt	1999		10.1109/CIFER.1999.771124	financial economics;economics;artificial intelligence;data mining	ML	5.763154298743679	-21.032226466047117	172523
2a34753c8e7686539b01bf63d5abdb48e8e7b5a4	an application of enhanced knowledge models to fuzzy time series		Knowledge is usually employed by domain experts to solve domain-specific problems. Huarng was the first to embed knowledge into forecasting fuzzy time series (2001). His model involved simple calculations and offers better prediction results once more supporting information has been supplied. On the other hand, Chen first proposed a high-order fuzzy time series model to overcome the drawback of existing fuzzy first-order forecasting models. Chen’s model involved limited computing and came with higher accuracy than some other models. For this reason, the study is focused on these two types of models. The first model proposed here, which is referred to as a weighted model, aims to overcome the deficiency of the Huarng’s model. Second, we propose another fuzzy time series model, called knowledge based high-order time series model, to deal with forecasting problems. This model aims to overcome the deficiency of the Chen’s model, which depends strongly on highest-order fuzzy time series to eliminate ambiguities at forecasting and requires a vast memory for data storage. Experimental study of enrollment of University Alabama and the forecasting of a future’s index show that the proposed models reflect fluctuations in fuzzy time series and provide forecast results that are more accurate than the ones obtained when using the to two referenced models.	knowledge representation and reasoning;time series	Chung-Ming Own	2013		10.1007/978-3-642-33439-9_7	artificial intelligence;machine learning;data mining	AI	6.407139119225777	-20.889640238953504	173367
19cbc70299adfcd73e8a8dc8237d7e7aa2779d15	real-time prediction of water stage with artificial neural network approach	water level;learning rate;activation function;real time;data collection;lead time;sensitivity analysis;rainfall runoff models;cost effectiveness;statistical techniques;water resource management;artificial neural network;neural network	An accurate water stage prediction allows the pertinent authority to issue a forewarning of the impending flood and to implement early evacuation measures when required. Existing methods including rainfall-runoff modeling or statistical techniques entail exogenous input together with a number of assumptions. In this paper, neural networks are used to predict real-time water levels in Shing Mun River of Hong Kong with different lead times on the basis of the upstream gauging stations or stage/time history at the specific station. The network is trained by using two different algorithms. It is demonstrated that the artificial neural network approach, which is able to provide model-free estimates in deducing the output from the input, is an appropriate forewarning tool. It is shown from the training and verification simulation that the water stage prediction results are highly accurate and are obtained in very short computational time. Both these two factors are important in water resources management. Besides, sensitivity analysis is carried out to evaluate the most suitable network characteristics including number of input neurons, number of hidden layers, number of neurons in hidden layer, number of output neurons, learning rate, momentum factor, activation function, number of training epoch, termination criterion, etc. under this specific circumstance. The findings lead to the reduction of any redundant data collection as well as the accomplishment of cost-effectiveness.	artificial neural network;real-time transcription	Kwok-wing Chau;Chuntian Cheng	2002		10.1007/3-540-36187-1_64	simulation;cost-effectiveness analysis;water level;computer science;artificial intelligence;machine learning;activation function;operations research;sensitivity analysis;artificial neural network;statistics;data collection	ML	9.236011243247704	-18.69520540060282	174164
abe842d9dc851b927994a730660d4db792dc8d47	health products sales forecasting using computational intelligence and adaptive neuro fuzzy inference systems		In our days the importance of reducing the inventory level in a healthcare organization is increasing fast. As a result, the value of an accurate supply forecast is becoming more relevant. The main objective of this paper is to analyze and compare some of the most popular and widely applied techniques available based on computational intelligence. In addition, it aims to demonstrate the competitiveness of the aforementioned using real-world data. The methods that are employed include neural networks (feed forward, radial basis, generalized regression, and recurrent networks) and the hybrid neural fuzzy system (ANFIS). The experimental part of this study is conducted with the use of sales’ data extracted from the database of a major Greek medical supplier. A two-year period was employed in order to gather the appropriate sales figures about some of the most popular medicines and subsequently each technique’s forecasting ability was tested against a third year. The parameters of each technique are then fine-tuned in order to minimize the performance functions. Finally, a brief statistical analysis of the techniques used is performed to facilitate the comparison between them and define the most appropriate method for this particular issue.	adaptive neuro fuzzy inference system;artificial neural network;computation;computational intelligence;fuzzy control system;fuzzy logic;radial (radio)	Dimitris E. Koulouriotis;Georgios Mantas	2012	Operational Research	10.1007/s12351-010-0094-y	artificial intelligence;marketing;operations management;machine learning;data mining;management;operations research;statistics	ML	6.4908519605182216	-20.03516376708137	174717
c52c3c62819f6ec7245f90c2d686c6bd7f9a3288	obst-based segmentation approach to financial time series	optimal binary search tree;segmentation;financial time series;turning points;trends	Financial time series data are large in size and dynamic and non-linear in nature. Segmentation is often performed as a pre-processing step for locating technical patterns in financial time series. In this paper, we propose a segmentation method based on Turning Points (TPs). The proposed method selects TPs from the financial time series in question based on their degree of importance. A TP's degree of importance is calculated on the basis of its contribution to the preservation of the trends and shape of the time series. Algorithms are also devised to store the selected TPs in an Optimal Binary Search Tree (OBST) and to reconstruct the reduced sample time series. Comparison with existing approaches show that the time series reconstructed by the proposed method is able to maintain the shape of the original time series very well and preserve more trends. Our approach also ensures that the average retrieval cost is kept at a minimum. & 2013 Elsevier Ltd. All rights reserved.	algorithm;approximation algorithm;approximation error;artificial neural network;benchmark (computing);bottom-up parsing;data mining;data point;for loop;logic programming;network model;nonlinear system;optimal binary search tree;pattern matching;pattern recognition;preprocessor;programmable logic array;quantum fluctuation;real-time locating system;sampling (signal processing);time series;top-down and bottom-up design;while loop	Yain-Whar Si;Jiangling Yin	2013	Eng. Appl. of AI	10.1016/j.engappai.2013.08.015	optimal binary search tree;mathematical optimization;computer science;artificial intelligence;machine learning;data mining;segmentation	AI	9.428656849114976	-22.616733750948715	175377
96f0cd56b6d9a9f57e244263db6daaa36b45c237	kalman filters and neural networks in forecasting and trading		The motivation of this paper is to investigate the use of a Neural Network (NN) architecture, the Psi Sigma Neural Network, when applied to the task of forecasting and trading the Euro/Dollar exchange rate and to explore the utility of Kalman Filters in combining NN forecasts. This is done by benchmarking the statistical and trading performance of PSN with a Naive Strategy and two different NN architectures, a Multi-Layer Perceptron and a Recurrent Network. We combine our NN forecasts with Kalman Filter, a traditional Simple Average and the Granger- Ramanathan’s Regression Approach. The statistical and trading performance of our models is estimated throughout the period of 2002-2010, using the last two years for out-of-sample testing. The PSN outperforms all models’ individual performances in terms of statistical accuracy and trading performance. The forecast combinations also present improved empirical evidence, with Kalman Filters outperforming by far its benchmarks.	kalman filter;neural networks	Georgios Sermpinis;Christian L. Dunis;Jason Laws;Charalampos Stasinakis	2012		10.1007/978-3-642-32909-8_44	econometrics;engineering;machine learning;data mining	ML	7.345845282548733	-19.929799995313537	175564
a28048d621b59b17e79224835255fc9d4d735f92	a novel model for stock market forecasting	forecasting;complex networks;stock markets;indexes;time series analysis;predictive models;adaptation models	To promote the forecasting performance of Fuzzy time-series models, based on complex network, a novel fuzzy time series model for stock price forecasting was pressented, this pressented model includes the concept of the complex network and weighted adaptive expectation method. By comparing the fuzzy time series model of based on complex network and weighted adaptive expectation fuzzy time series model, we conclude that the pressented model surpasses weighted adaptive expectation model in accuracy.	complex network;network model;time series	Yanlong Li;Fang Wang;Renbing Sun;Rui Li	2016	2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)	10.1109/CISP-BMEI.2016.7853046	financial economics;database index;econometrics;economics;forecasting;computer science;machine learning;time series;mathematics;predictive modelling;complex network;statistics	DB	7.160876298056588	-19.464309320658835	176092
aabe7225f51585e6d713e3677a2eccae91992a3e	intelligent control of robotic systems with application in industrial processes	control autoajustable;selftuning control;generic model;control inteligente;fabrica pescado;aproximacion;production system;atelier flexible;logique floue;base connaissance;automatisation;logica difusa;robotics;prise decision;automatizacion;intelligent control;fish processing plant;approximation;robot manipulator;fuzzy logic;usine poisson;intelligent robot;approximate reasoning;robot control;flexible manufacturing system;robotica;base conocimiento;sistema flexible produccion;commande intelligente;robotique;robot inteligente;toma decision;commande autoajustable;robot intelligent;knowledge base;automation	Intelligent control can significantly improve the performance of a robotic manipulator. The paper will review some ways of incorporating intelligence into a robotic control system. Specific attention will be given to techniques of approximate reasoning, particularly fuzzy-logic-based control. First, several concepts of approximation will be explored and their application in approximate reasoning will be discussed. A general model for knowledge-based decision making will be presented, and the special cases as applicable to some common concepts of approximation will be studied. Practical example considered will include sensor-based manipulation in fish processing tasks, which employs on-line measurement of task impedance; tuning of parameters of a robotic motion controller; and intelligent restructuring of a flexible production system that consists of multiple, robotic workcells. Other trends and possibilities will be indicated.	intelligent control;robot	Clarence W. de Silva	1997	Robotics and Autonomous Systems	10.1016/S0921-8890(97)00076-6	fuzzy logic;knowledge base;simulation;computer science;artificial intelligence;automation;approximation;robot control;production system;robotics;intelligent control	Robotics	5.193181817381765	-23.765081817184782	177014
ba5f669590e3d75bb2e321aa785ec4b8d36d15ef	forecasting container throughputs at ports using genetic programming	forecasting;genetic program;optimal method;forecasting model;genetic programming;container throughput;seasonality;optimal prediction;auto regressive integrated moving average;historical data	To accurately forecast container throughput is crucial to the success of any port operation policy. This study attempts to create an optimal predictive model of volumes of container throughput at ports by using genetic programming (GP), decomposition approach (X-11), and seasonal auto regression integrated moving average (SARIMA). Twenty-nine years of historical data from Taiwan's major ports were collected to establish and validate a forecasting model. The Mean Absolute Percent Error levels between forecast and actual data were within 4% for all three approaches. The GP model predictions were about 32-36% better than those of X-11 and SARIMA. These results suggest that GP is the optimal method for this case. GP predicted that container throughputs at Taiwan's major ports would slowly increase in the year 2008. Since Taiwan's government opened direct transportation with China in July 2008, the issue of container throughput in Taiwan has become even more worthy of discussion.	genetic programming	Shih-Huang Chen;Jun-Nan Chen	2010	Expert Syst. Appl.	10.1016/j.eswa.2009.06.054	genetic programming;simulation;forecasting;computer science;operations research;seasonality;statistics	Robotics	8.74460697377754	-18.975918955784543	177066
a10597ecb698b4d271ed30483df33ae08be5a168	time series forecasting in turning processes using arima model		A prediction model which is able to predict the tool life and the cutting edge replacement is tackled. The study is based on the spindle load during a turning process in order to optimize productivity and the cost of the turning processes. The methodology proposed to address the problem encompasses several steps. The main ones include filtering the signal, modeling of the normal behavior and forecasting. The forecasting approach is carried out by an Autoregressive Integrated Moving Average (ARIMA) model. Results are compared with a robust ARIMA model and show that the previous preprocessing steps are necessary to obtain greater accuracy in predicting future values of this specific process.	autoregressive integrated moving average;time series	Alberto Jimenez Cortadi;Fernando Boto;Itziar Irigoien;Basilio Sierra;Germán Rodríguez	2018		10.1007/978-3-319-99626-4_14	time series;econometrics;filter (signal processing);autoregressive integrated moving average;robust statistics;computer science	NLP	7.0498875393951534	-18.261391249700516	177220
b3dd5a1778e647a63efcca8cf04e3404b2a090af	the prediction of the medium term power load based on combined model of the bayes theory and ls-svm	bayesian theory;time series forecasting;least squares approximations;kernel;ls svm;support vector machines;bayes methods;bayesian least squares support vector machines;biological system modeling;bayesian methods;bayes theory;time series forecasting methods;load forecasting;regression;regression bayes theory time series forecasting methods bayesian least squares support vector machines;predictive models load modeling bayesian methods support vector machines kernel load forecasting biological system modeling;predictive models;support vector machines bayes methods least squares approximations load forecasting;powerload;load modeling;prediction bayesian theory ls svm powerload;prediction;least squares support vector machine	This paper presents a new time-series forecasting methods-Bayesian least squares support vector machines which applies the Bayesian evidence flamework to infer automatically model parameters of LS-SVM regression. using the mixed Bayesian least squares support vector machines algorithm. Comparing with other models,we can see that this method has favorably high predicting precision and can achieve better results.	algorithm;least squares;support vector machine;time series	Qiang Song;Aimin Wang	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5583842	least squares support vector machine;econometrics;computer science;machine learning;pattern recognition	Robotics	8.428320007896524	-20.17039717315632	177404
22330729ca77873c217a0a012529f02550dba25e	an evolutionary morphological-rank-linear approach for time series prediction	time series forecasting;mathematical morphology;least mean square;genetic operator;mathematics computing;lms algorithm;least mean squares methods;finite impulse response filter nonlinear filters predictive models genetic algorithms mathematical model acceleration convergence least squares approximation measurement multilayer perceptrons;convergence of numerical methods;multilayer perceptron;time series;mathematical operators;performance metric;arima model;finite impulse response;forecasting theory;fir filter;time lag;genetic algorithm;genetic algorithms;search problems;least mean squares algorithm morphological rank linear approach time series prediction time series forecasting intelligent hybrid evolutionary mrl model mrl filter genetic algorithm optimal genetic operators search convergence ga population training;learning artificial intelligence;time series convergence of numerical methods forecasting theory genetic algorithms learning artificial intelligence least mean squares methods mathematical morphology mathematical operators mathematics computing search problems;time series prediction	In this paper, a hybrid evolutionary Morphological-Rank-Linear (MRL) approach is proposed for time series forecasting. The proposed method consists of an Intelligent Hybrid Evolutionary MRL (IHEMRL) model composed of an MRL filter and a modified Genetic Algorithm (GA) that employs optimal genetic operators that accelerate its search convergence. The modified GA searches for the particular time lags capable of a fine tuned characterization of the time series and estimates the initial (sub-optimal) parameters of the MRL filter (mixing parameter (lambda), rank (r), linear Finite Impulse Response (FIR) filter (6) and the Morphological-Rank (MR) filter (a) coefficients). Thus, each individual of the GA population is trained by the averaged Least Mean Squares (LMS) algorithm to further improve the MRL filter parameters supplied by the GA. Experiments are conducted with the proposed approach using three real world time series according to a group of relevant performance metrics and the results are compared both to ARIMA models and MultiLayer Perceptrons (MLP).	autoregressive integrated moving average;coefficient;computational complexity theory;emoticon;experiment;finite impulse response;genetic algorithm;genetic operator;ieee congress on evolutionary computation;jones calculus;least mean squares filter;mean squared error;media resource locator;multilayer perceptron;quad flat no-leads package;software release life cycle;statistical model;time series;xm1219 armed robotic vehicle	Ricardo de A. Araújo;Germano C. Vasconcelos;Tiago Alessandro Espínola Ferreira	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4425035	econometrics;mathematical optimization;computer science;artificial intelligence;machine learning;time series;mathematics;statistics	ML	8.078211934414831	-20.37144602839639	177411
3bf0533eee6172fa07fe9aaf7e757bb36e8ff406	estimation of cyclostationary codebooks for kernel adaptive filtering		A methodology based on kernel adaptive filtering termed DCKAF to support prediction tasks over one-dimensional time-series is proposed. DCKAF uses a linear combination of multiple codebooks to obtain the estimation from an input-output nonlinear mapping. This methodology employs a vector quantization based on statistic measures to check whether is necessary create a new codebook, then the nearest codebook to the current input sample is found. After that, codebooks are used to obtain the signal prediction at every instant, and evaluates if the current sample is added as a codeword or not as in traditional quantized kernel least mean square (QKLMS). Hence, DCKAF takes advantage of information learned on previous iterations to improve the system accuracy. The proposed methodology is tested on two one-dimensional time series and compared against QKLMS in terms of prediction accuracy. Obtained results show that DCKAF provides an effective way to predict time series improving prediction tasks.	adaptive filter;codebook;cyclostationary process;kernel (operating system)	Sergio García-Vega;Andrés Marino Álvarez-Meza;Germán Castellanos-Domínguez	2014		10.1007/978-3-319-12568-8_43	mathematical optimization;pattern recognition;statistics	Vision	9.418798454458758	-22.125752864435675	177498
5b587ad7e6f42b373805f831f6bc82276dd78f5a	application of the fuzzy artmap neural network architecture to bank failure predicitons	puzzy sets theory;fuzzy artmap neural network;supervised neural network;bank failure predicitons;bank failure predictions;adaptive resonance theory	This paper describes an application of a neural nertwork architecture for bank failure predictions. The experiences of financial instability has motivated a great interest in the question of bank solvency. Although several prediction models have been developed, their reliability is not enough. The paper presents a supervised neural networt model, based on the Adaptive Resonance Theory (ART), which was introduced by Stephen Grossberg in 1976. Also Fuzzy Sets Theory is used as processing scheme. The data sample have been taken from the Spanish bank crisis during 1978–1983. The model obtained is able to predict the complete learning data set in two different cases, data one year prior the failure and data two years prior the failure. The obtained results, using a set of test data, reach a high level of performance, with a low number of training cycles.		Luis J. de Miguel;Elena Revilla;J. Miguel Rodríguez;J. Manuel Cano	1993		10.1007/3-540-56798-4_227	artificial intelligence;machine learning	ML	6.9167943950085835	-22.011023422704124	178019
b56de57d07748e677df76af3e89c2b7c100300f5	implementation of hybrid short-term load forecasting system with analysis of temperature sensitivities	temperature sensitivities;fuzzy support vector regression;hybrid load forecasting;support vector regression;system security;load forecasting;short term load forecasting;temperature sensitive;linear extrapolation;similar day;unit commitment	Load forecasting is necessary for economic generation of power, economic allocation between plants (unit commitment scheduling), maintenance scheduling, and for system security such as peak load shaving by power interchange with interconnected utilities. A novel hybrid load forecasting algorithm, which combines the fuzzy support vector regression method and the linear extrapolation based on similar days method with the analysis of temperature sensitivities is presented in this paper. The fuzzy support vector regression method is used to consider the lower loaddemands in weekends and Monday than on other weekdays. The normal load in weekdays is forecasted by the linear extrapolation based on similar days method. Moreover, the temperature sensitivities are used to improve the accuracy of the load forecasting in relation to the daily load and temperature. The result demonstrated the accuracy of the proposed load forecasting scheme.	algorithm;extrapolation;load profile;scheduling (computing);support vector machine	Changyin Sun;Jinya Song;Linfeng Li;Ping Ju	2008	Soft Comput.	10.1007/s00500-007-0252-1	support vector machine;econometrics;real-time computing;computer science;machine learning;power system simulation;extrapolation	HPC	8.912467866334987	-17.542396978398354	178101
094032937f8f36301c3118f147b2b097c2fff3bb	a hybrid fmm-cart model for human activity recognition	rule extraction classification and regression tree fuzzy min max neural network human activity recognition;classification and regression tree;legged locomotion accuracy training decision trees complexity theory accelerometers computational modeling;rule extraction;decision tree hybrid fmm cart model human activity recognition fuzzy min max neural network classification and regression tree cart;regression analysis decision trees fuzzy set theory minimax techniques neural nets pattern classification;human activity recognition;fuzzy min max neural network	In this paper, the application of a hybrid model combining the fuzzy min-max (FMM) neural network and the classification and regression tree (CART) to human activity recognition is presented. The hybrid FMM-CART model capitalizes the merits of both FMM and CART in data classification and rule extraction. To evaluate the effectiveness of FMM-CART, two data sets related to human activity recognition problems are conducted. The results obtained are higher than those reported in the literature. More importantly, practical rules in the form of a decision tree are extracted to provide explanation and justification for the predictions from FMM-CART. This outcome positively indicates the potential of FMM-CART in undertaking human activity recognition tasks.	activity recognition;algorithm;artificial neural network;benchmark (computing);decision tree learning;embedded system;fast multipole method;maxima and minima;microprocessor;mobile app;rom cartridge;real-time clock;real-time transcription;rule induction;smartphone;wearable technology	Manjeevan Seera;Chu Kiong Loo;Chee Peng Lim	2014	2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2014.6973904	computer science;artificial intelligence;machine learning;pattern recognition	Robotics	8.042043437791957	-23.566347965130102	178931
8240a7f1b643959c6d59d78c9c9f206a5f6057ef	factors that impact the accuracy of clustering-based load forecasting	forecasting;cluster approximation load forecasting least squares methods load modeling predictive models support vector machines;support vector machines;least squares support vector machines clustering based load forecasting electric power industry k means clustering load predictions mean absolute percent error mape relative mean square error rmse;companies;load forecasting;estimation;least squares support vector machine ls svm load forecasting k means clustering;predictive models;load modeling;k means clustering;least squares support vector machine ls svm;support vector machines electricity supply industry least squares approximations load forecasting	Due to the deregulation of the power system, the electric power industry is undergoing a transformation in terms of its planning and operation strategies. Because of the importance in reducing financial and operational risk, improving load forecasting accuracy is paramount. In some load forecasting applications, K-means clustering is used to group customers prior to forecasting. This method has been shown to improve the accuracy of load predictions. However, there are situations where K-means clustering reduces load forecasting accuracy. This paper studies the factors that affect the performance of K-means clustering. Additionally, several strategies have been proposed to tackle the lower estimation accuracy problems for this clustering algorithm. The data used for validating the proposed strategies associated with the factors is from the Consolidated Edison Company of New York, Inc. (Con Edison). The mean absolute percent error and relative mean square error are utilized to evaluate the forecasting results of K-means-based least squares support vector machines (LS-SVM) and preprocessed K-means-based LS-SVM. Additionally, the outperformance of preprocessed K-means-based LS-SVM is demonstrated via the data results.	algorithm;alien;approximation error;cluster analysis;intel edison;k-means clustering;least squares;load testing;mean squared error;preprocessor;scheduling (computing);support vector machine	Xin Wang;Wei-Jen Lee;Heng Huang;Robert L. Szabados;David Yanshi Wang;Peter Van Olinda	2015	IEEE Transactions on Industry Applications	10.1109/IAS.2015.7356794	least squares support vector machine;probabilistic forecasting;computer science;machine learning;pattern recognition;data mining	ML	9.092806261112823	-17.945573461784416	180403
bcb3bf17039f1c2993dbde1a80b236dba9cb9896	dynamic building energy consumption forecast using weather forecast interpolations	gaussian processes;weather forecasting;vbdd model dynamic building energy consumption forecast weather forecast interpolations united states buildings sector transportation sector industrial sector variable base degree day model;computational modeling;energy consumption;load forecasting building management systems energy consumption interpolation;predictive models;buildings;weather forecasting buildings predictive models energy consumption computational modeling gaussian processes	In the United States, the buildings sector accounted for about 41% of primary energy consumption in 2010, which was around 44% more than the transportation sector and 36% more than the industrial sector. Real time forecasts for building energy consumption using weather forecasts are crucial for effective building energy management. And the Variable Base Degree Day (VBDD) model has been proven effective in this field. In the VBDD model, two factors mainly determine the accuracy of the energy forecasts, where the first is the computation of optimal base values in the dynamic building energy consumption forecasts model and the second is the accuracy of weather forecasts. In this paper, we are motivated by the field study of forecasting the energy consumption of commercial buildings using local weather forecasts. We advance the state-of-the-arts by correcting biases in the weather forecasts and interpolating the daily weather forecasts into higher frequency to synchronize with the frequency of the energy consumption forecasts. Based on this framework, we propose an optimal efficient algorithm to compute base values in the VBDD model through the coordinate gradient descent method. Experiment results on multiple real datasets demonstrate the effectiveness of the proposed method through achieving more than 90% accuracy.	algorithm;computation;computational complexity theory;computer simulation;field research;gaussian process;gradient descent;iteration;linear interpolation;test set	Rui Zhang;Hongxia Yang	2015	2015 IEEE International Conference on Smart Grid Communications (SmartGridComm)	10.1109/SmartGridComm.2015.7436378	meteorology;simulation;geography;operations management;global forecast system;consensus forecast	Robotics	9.368353087643403	-17.700041952287354	180651
037c99808d0e4e881078cbbc249e97c930172596	stock price prediction using neural networks: a project report	stock price;neural network	We analyzed the possibility of predicting stock prices on a short-term, day-to-day basis with the help of aeural networks by studying three important German stocks chosen at random (BASF, COMMERZBANK, MERCEDES). We examined the use of PERCEPTRON, ADALINE, MADALINE and BACK-PROPAGATION networks. The results were encouraging. Within short prediction time spans (10 days), we achieved a very hight degree of accuracy of up to 90%. With a BACK-PROPAGATION network we carried out an absolute-value prediction. The network was thereby able to recognize on its own an obvious heuristic and showed a behaviour similar to the exponential smoothing algorithm. The results we achieved led us to expect that neural networks could considerably improve the prognosis of stock prices (and more generally, the prognosis of semi-chaotic time series) in the future. Nevertheless considerable improvements are needed in the theory of neural networks, as practicable methods to support the design of neural networks for specific applications are not available yet.	adaline;algorithm;artificial neural network;heuristic;perceptron;semantic network;semiconductor industry;smoothing;time complexity;time series	Eberhard Schöneburg	1990	Neurocomputing	10.1016/0925-2312(90)90013-H	computer science;artificial intelligence;machine learning;operations research;artificial neural network	ML	6.8753165278727435	-20.1861897629428	180881
80b432badcb4ab067c7da14ac7c3f69ee78fe5cb	mining association rules from time series to explain failures in a hot-dip galvanizing steel line	continuous hot dip galvanized line;cause failures;multiple time series;association rules;time series;association rule;knowledge discovery	This paper presents an experience based on the use of association rules from multiple time series captured from industrial processes. The main goal is to seek useful knowledge for explaining failures in these processes. An overall method is developed to obtain association rules that represent the repeated relationships between pre-defined episodes in multiple time series, using a time window and a time lag. First, the process involves working in an iterative and interactive manner with several pre-processing and segmentation algorithms for each kind of time series in order to obtain significant events. In the next step, a search is made for sequences of events called episodes that are repeated among the various time series according to a pre-set consequent, a pre-established time window and a time lag. Extraction is then made of the association rules for those episodes that appear many times and have a high rate of hits. Finally, a case study is described regarding the application of this methodology to a historical database of 150 variables from an industrial process for galvanizing steel coils. 2012 Elsevier Ltd. All rights reserved.	algorithm;association rule learning;extrapolation;fuzzy logic;human factors and ergonomics;intrusion detection system;iteration;iterative method;linear algebra;maxima and minima;preprocessor;r language;remote file sharing;rule induction;time series	Francisco J. Martínez de Pisón Ascacibar;Andrés Sanz-García;Eduardo Martínez-de-Pisón;Emilio Jiménez Macías;Dante Conti	2012	Computers & Industrial Engineering	10.1016/j.cie.2012.01.013	association rule learning;computer science;engineering;artificial intelligence;operations management;machine learning;data mining;knowledge extraction;statistics	AI	5.454900684295402	-22.128310314716135	181085
4be6b558885f48b4edb4007da83a33dffa390400	a comparison of neural network and multiple regression analysis in modeling capital structure	multiple linear regression;empirical study;capital structure;multiple regression analysis;regression model;non linear model;statistical model;multiple regression model;prediction model;article;artificial neural network model;artificial neural network;neural network	Empirical studies of the variation in debt ratios across firms have used statistical models singularly to analyze the important determinants of capital structure. Researchers, however, rarely employ non-linear models to examine the determinants and make little effort to identify a superior prediction model. This study adopts multiple linear regressions and artificial neural networks (ANN) models with seven explanatory variables of corporation’s feature and three external macro-economic control variables to analyze the important determinants of capital structures of the high-tech and traditional industries in Taiwan, respectively. Results of this study show that the determinants of capital structure are different in both industries. The major different determinants are business-risk and growth opportunities. Based on the values of RMSE, the ANN models achieve a better fit and forecast than the regression models for debt ratio, and ANNs are cable of catching sophisticated non-linear integrating effects in both industries. It seems that the relationships between debt ratio and independent variables are not linear. Managers can apply these results for their dynamic adjustment of capital structure in achieving optimality and maximizing firm’s value. 2007 Elsevier Ltd. All rights reserved.		Hsiao-Tien Pao	2008	Expert Syst. Appl.	10.1016/j.eswa.2007.07.018	econometrics;proper linear model;computer science;linear regression;machine learning;linear model;data mining;regression diagnostic;artificial neural network;regression analysis;statistics	AI	6.707196735856506	-18.341392100149264	181340
32c9b47d0320d03b938ce2b04ba053f586abc1c2	a hybrid forecasting methodology using feature selection and support vector regression	feature extraction time series forecasting theory support vector machines regression analysis;support vector machines;non linear regression;support vector regression;regression model;time series;model construction time series forecasting feature selection support vector regression regression based forecasting regression model;real world application;forecasting theory;feature extraction;predictive models regression tree analysis neural networks support vector machines nonlinear filters industrial engineering smoothing methods diversity reception data mining computational modeling;hybrid system;feature selection;regression analysis;support vector machine;neural network;time series model	Various techniques have been proposed to forecast a given time series. Models from the ARIMA family have been successfully used as well as regression approaches based on e.g. linear, non-linear regression, neural networks, and support vector machines. What makes the difference in many real-world applications, however, is not the technique but an appropriated forecasting methodology. Here we present such a methodology for the regression-based forecasting approach. A hybrid system is presented that iteratively selects the most relevant features and constructs the best regression model given certain criteria. We present a particular technique for feature selection as well as for model construction. The methodology, however, is a generic one providing the opportunity to employ alternative approaches within our framework.	artificial neural network;autoregressive integrated moving average;feature selection;hybrid system;nonlinear system;support vector machine;time series	Jose Guajardo;Jaime Miranda;Richard Weber	2005	Fifth International Conference on Hybrid Intelligent Systems (HIS'05)	10.1109/ICHIS.2005.9	proper linear model;engineering;machine learning;pattern recognition;data mining	ML	8.159722816073817	-20.575423640314913	181438
d4b0b3f7efa1e9e66de9f176f328f40f504bec4f	improving return using risk-return adjustment and incremental training in technical trading rules with gaps	stock market;technical trading rule;soft computing;gaps;trading system;technical analisys;indexation;automatic trading systems;genetic algorithm;trading rule;low risk	The principle objective of this paper is to obtain trading rules with a low risk level which are also capable of obtaining high returns. To that purpose a methodology has been defined, based on the design of a genetic algorithm GAP and an incremental training technique adapted to the learning of series of stock market values. The GAP technique consists in a fusion of GP and GA. In GAP a chromosome is composed of a tree with language operators and a vector with numeric values. The GAP algorithm implements the automatic search for trading rules taking as objectives of the training both the optimization of the return obtained and the minimization of the assumed risk. In order to diminish high over-fitting, a technique of incremental training has been used. Applying the proposed methodology, rules have been obtained for a period of eight years of the S&P500 index. The achieved adjustment of the relation return-risk has generated rules with returns very superior in the testing period to those obtained applying habitual methodologies and even clearly superior to Buy&Hold. Insert your abstract here. Include keywords, PACS and mathematical subject classification numbers as needed.	brute-force search;financial times;fitness function;futures and promises;genetic algorithm;genetic programming;heuristic;mathematical optimization;metaheuristic;olami–feder–christensen model;overfitting;physics and astronomy classification scheme;software release life cycle;tree (data structure);vector graphics	Manuel E. Fernandez Garcia;Enrique A. de la Cal Marín;Raquel Quiroga Garcia	2008	Applied Intelligence	10.1007/s10489-008-0151-x	genetic algorithm;computer science;artificial intelligence;trading strategy;machine learning;data mining;soft computing	SE	7.088224585589822	-21.473987914731147	182362
de2d48348b165d3bce4f4e4913ebbabf795ea2ff	a modified regression model for forecasting the volumes of taiwan's import containers	forecast;calcul scientifique;computer aided analysis;matematicas aplicadas;analyse assistee;modele mathematique;mathematiques appliquees;linear regression;regression model;modelo matematico;empirical evidence;modelo regresion;computacion cientifica;modele regression;prediction accuracy;mathematical model;analisis asistido;scientific computation;applied mathematics;containerization;economic growth;international trade	The available empirical evidence on the relationship between international trade container volume and the economic growth in Taiwan is not conclusive. The purpose of this paper is to propose a modified regression model for forecasting the volumes of Taiwan's import containers. This article first identifies the contributions and shortcomings of previous empirical works. Then, a new modified regression model is proposed and built using data for the period 1989-2001. Finally, this paper compares the accuracy of the traditional regression model and this modified regression model for forecasting the volumes of Taiwan's import containers. The results show that this modified regression model proposed in this paper exhibits higher prediction accuracy.		Chien-Chang Chou;Ching-Wu Chu;Gin-Shuh Liang	2008	Mathematical and Computer Modelling	10.1016/j.mcm.2007.05.005	econometrics;empirical evidence;linear regression;mathematical model;mathematics;operations research;regression analysis;statistics	Vision	6.04366851657788	-17.315423930103204	182514
84eee8191cc14186af01e9e68a05c72eb77039ac	hierarchical clustering of ensemble prediction using loocv predictable horizon for chaotic time series		Recently, we have presented a method of ensemble prediction of chaotic time series. The method employs strong learners capable of making predictions with small error, where usual ensemble mean does not work well owing to the long term unpredictability of chaotic time series. Thus, we have developed a method to select a representative prediction from a set of plausible predictions by means of using LOOCV (leave-one-out cross-validation) measure to estimate predictable horizon. Although we have shown the effectiveness of the method, it sometimes fails to select the representative prediction with long predictable horizon. In order to cope with this problem, this paper presents a method to select multiple candidates of representative prediction by means of employing hierarchical K-means clustering with K = 2. From numerical experiments, we show the effectiveness of the method and an analysis of the property of LOOCV predictable horizon.	cluster analysis;cross-validation (statistics);experiment;hierarchical clustering;k-means clustering;numerical analysis;time series	Shuichi Kurogi;Naoto Shimoda;Kazuya Matsuo	2017	2017 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2017.8285285	ensemble average;horizon;cluster analysis;chaotic;hierarchical clustering;artificial intelligence;mathematics;pattern recognition	AI	8.934918110129257	-21.74405485384462	182798
362aef280fb27fba83d1417748e52cc4d1941756	a hybrid cost estimation framework based on feature-oriented data mining approach	feature modeling;data mining;welding feature;erp;cost estimation	This paper presents an informatics framework to apply feature-based engineering concept for cost estimation supported with data mining algorithms. The purpose of this research work is to provide a practical procedure for more accurate cost estimation by using the commonly available manufacturing process data associated with ERP systems. The proposed method combines linear regression and data-mining techniques, leverages the unique strengths of the both, and creates a mechanism to discover cost features. The final estimation function takes the user’s confidence level over each member technique into consideration such that the application of the method can phase in gradually in reality by building up the data mining capability. A case study demonstrates the proposed framework and compares the results from empirical cost prediction and data mining. The case study results indicate that the combined method is flexible and promising for determining the costs of the example welding features. With the result comparison between the empirical prediction and five different data mining algorithms, the ANN algorithm shows to be the most accurate for welding operations. 2015 Elsevier Ltd. All rights reserved.	algorithm;data mining;erp;enterprise resource planning;informatics;robot welding	Narges Sajadfar;Yongsheng Ma	2015	Advanced Engineering Informatics	10.1016/j.aei.2015.06.001	computer science;engineering;data science;machine learning;data mining;cost estimate	ML	4.705516282087668	-20.030059856783755	182843
b521a77b56b7a9aaf47b897098f17fcac2aa17d2	multiple linear regression and artificial neural networks based on principal components to predict ozone concentrations	multiple linear regression;human health;principal component regression;early warning;artificial neural networks;tropospheric ozone;principal components;trophospheric ozone;ozone;artificial neural network;principal component	The prediction of tropospheric ozone concentrations is very important due to the negative impacts of ozone on human health, climate and vegetation. The development of models to predict ozone concentrations is thus very useful because it can provide early warnings to the population and also reduce the number of measuring sites. The aim of this study was to predict next day hourly ozone concentrations through a new methodology based on feedforward artificial neural networks using principal components as inputs. The developed model was compared with multiple linear regression, feedforward artificial neural networks based on the original data and also with principal component regression. Results showed that the use of principal components as inputs improved both models prediction by reducing their complexity and eliminating data collinearity. 2005 Elsevier Ltd. All rights reserved.	artificial neural network;coefficient;feedforward neural network;kerrison predictor;learning to rank;linear model;pc²;personal computer;principal component analysis;principal component regression;test set	S. I. V. Sousa;F. G. Martins;M. C. M. Alvim-Ferraz;M. C. Pereira	2007	Environmental Modelling and Software	10.1016/j.envsoft.2005.12.002	meteorology;econometrics;computer science;machine learning;artificial neural network;principal component analysis	AI	9.823719275978139	-19.436670302611684	183075
1e7cfc35db4b1fe2a882ee9b51fe926e81b8d2a5	fuzzy automata with epsilon-moves compute fuzzy measures between strings	engineering;approximate string matching;fuzzy system models;fuzzy set;procesamiento informacion;fuzzy measure;51e24;conjunto difuso;ensemble flou;automaton;ingenierie;automata;estimation erreur;error estimation;automate;information processing;estimacion error;pattern recognition;ingenieria;sistema difuso;reconnaissance forme;fuzzy measures;systeme flou;reconocimiento patron;traitement information;fuzzy system;fuzzy automata	This paper introduces fuzzy automata with transitions by empty string (ε-moves), and shows their relationship with other classes of classical fuzzy automata. The ε-move represents a state change of the automaton without consuming any symbol of the input string. In approximate string matching, ε-moves allow to model the effect of the insertion of a symbol (one of the possible edit operations). We provide a fuzzy measure between strings based on the concepts of string alignments and fuzzy edit operations. The main contribution of this paper is to prove that a particular class of fuzzy automata with ε-moves computes those fuzzy measures without restricting the number of errors between the strings. Given a fuzzy measure, a building method for constructing the fuzzy automaton with ε-moves that computes it, is also proposed. © 2006 Elsevier B.V. All rights reserved.	approximate string matching;automaton;empty string;fuzzy measure theory;string searching algorithm	José Javier Astrain;José Ramón González de Mendívil;José Ramón Garitagoitia	2006	Fuzzy Sets and Systems	10.1016/j.fss.2006.01.006	fuzzy logic;membership function;defuzzification;information processing;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy subalgebra;fuzzy number;machine learning;fuzzy measure theory;mathematics;automaton;fuzzy associative matrix;string-to-string correction problem;string metric;fuzzy set operations;algorithm;fuzzy control system;string searching algorithm	Logic	3.0873089713584054	-23.560920160299748	183276
ba3e60eb6d9c7da6450dfa615ecab04326dcd402	pre-ignition detection using deep neural networks: a step towards data-driven automotive diagnostics		Fault detection in vehicles is currently carried out using model-based or rule-based approaches. Due to advances in automotive technology such as autonomous driving and further connectivity, the complexity of vehicles and their subsystems increases continuously. As a consequence, models and rule-based systems for fault detection become more complex and require more extensive implementation effort and expert knowledge not only within but also across several domains. Besides, vehicles produce rich amounts of data including valuable information for fault detection. These amounts cannot fully be considered by current fault detection approaches. Deep neural networks offer promising capabilities to address these challenges by allowing automated model generation for fault detection without extensive domain knowledge using vast amounts of in-vehicle data. Hence, in this work a data-driven automotive diagnostics approach to fault detection with deep neural networks is proposed in two steps. First, a novel data-driven diagnostics process to learn data-driven algorithms on in-vehicle data is presented. Second, as a key element of this process, a novel fault detection model is proposed using a combination of convolutional and long short-term memory neural networks. To demonstrate the suitability for fault detection, the model is evaluated on internal engine control unit signals for pre-ignition detection in high-pressure turbocharged petrol engines. A classical machine learning processing pipeline and each neural network type separately are used as baselines for a performance comparison. Results show that the proposed model is a promising approach to data-driven automotive diagnostics outperforming all implemented baselines.		Peter Wolf;Artur Mrowca;Tam Thanh Nguyen;Bernard Baker;Stephan Günnemann	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569908		Robotics	8.633457901548518	-23.888467341047175	183379
b8f58d50e710f970776a2bc51560aa00591d299e	a 'world' model of integrated financial markets using artificial neural networks	non linear analysis;capital market;market model;fundamental market models;economectric methods;comparison of neural networks with econometric methods;exchange rate forecasting;artificial neural networks;recurrent network;technical intermarket models;international finance;model integration;financial market;financial analysis;exchange rate;integrated financial markets;developing country;bond forecasting;stock forecasting;artificial neural network;neural network	Over the last two decades, many important changes took place in the area of international finance. The liberalisation of financial markets and the development of powerful communication and trading facilities have enlarged the scope of selection for investors. Most financial markets of major developed countries must be regarded as highly integrated now. Traditional capital market theory has also changed and methods of financial analysis have been improved considerably. The existence of non-linearities in financial market movements has been emphasized by various researchers and financial analysts over the last years. Taking both aspects into account, a new kind of financial analysis seems to be necessary: the non-linear analysis of integrated financial markets. Recent developments in the theory of neural computation provide interesting mathematical tools for such a new kind of financial analysis.#R##N##R##N#This paper presents both the economic approach to an analysis of highly integrated financial markets and the econometric methods, especially artificial neural networks (ANN), to realize it. Forecasting of any asset class, e.g. stock, bond or exchange rate prediction, now becomes an integrated part within such a wider global capital market equilibrium. ANN, especially recurrent networks, are used to model integrated financial markets. This approach tries to develop a ‘world’ model of integrated financial markets. The ‘world’ consists of the stock, bond and currency markets of the United States, Japan and Germany. Traditional econometric methods as well as ANN are used to develop various kinds of models, which in turn are rated by their ability to provide accurate forecasts for these financial markets in an out-of-sample test.	artificial neural network	Thorsten Poddig;Heinz Rehkugler	1996	Neurocomputing	10.1016/0925-2312(96)00049-5	indirect finance;market data;financial modeling;financial econometrics;market microstructure;geography of finance;actuarial science;financial analysis;developing country;financial capital;computer science;market depth;machine learning;finance;financial intermediary;capital market;financial system;statistical finance;mark to model;artificial neural network;financial market;financial market participants	AI	5.975127673706651	-17.70215775528865	183412
df51772b0b9731d085341bd267f9171e15d4ed19	nonstationary regression with support vector machines	info eu repo semantics article;nonstationary problems;regression;support vector machine;info ar repo semantics articulo;info eu repo semantics publishedversion	In this work, we introduce a method for data analysis in nonstationary environments: time-adaptive support vector regression (TA-SVR). The proposed approach extends a previous development that was limited to classification problems. Focusing our study on time series applications, we show that TA-SVR can improve the accuracy of several aspects of nonstationary data analysis, namely the tasks of modelling and prediction, input relevance estimation, and reconstruction of a hidden forcing profile.	relevance;support vector machine;time series	Guillermo L. Grinblat;Lucas C. Uzal;Pablo F. Verdes;Pablo M. Granitto	2014	Neural Computing and Applications	10.1007/s00521-014-1742-6	support vector machine;econometrics;regression;computer science;artificial intelligence;machine learning;data mining	ML	8.34642225076311	-21.304588272226454	184589
5d7485da334dd417dbf16eb4b15dbb6cf4021ba3	rule induction for forecasting method selection: meta-learning the characteristics of univariate time series	serial correlation;empirical study;rule induction;meta learning;univariate time series;time series;data mining;statistical model;clustering;seasonality;time series data;data characteristics;forecast accuracy;forecasting method	For univariate forecasting, there are various statistical models and computational algorithms available. In real-world exercises, too many choices can create difficulties in selecting the most appropriate technique, especially for users lacking sufficient knowledge of forecasting. This study focuses on rule induction for forecasting method selection by understanding the nature of historical forecasting data. characteristics is presented that combines elements of data mining, meta-learning, clustering, classification and statistical measurement. We conducted a large-scale empirical study of over 300 time series using four of the most popular forecasting methods. To provide a rich portrait of the global characteristics of univariate time series, we extracted measures from a comprehensive set of features such as trend, seasonality, periodicity, serial correlation, skewness, kurtosis, nonlinearity, self-similarity, and chaos. Both supervised and unsupervised learning methods are used to learn the relationship between the characteristics of the time series and the forecasting method suitability, providing both recommendation rules, as well as visualizations in the feature space. A derived weighting schema based on the rule induction is also used to improve forecasting accuracy based on combined	algorithm;autocorrelation;cluster analysis;computation;data mining;feature vector;nonlinear system;quasiperiodicity;rule induction;seasonality;self-similarity;statistical classification;statistical model;supervised learning;time series;unsupervised learning	Xiaozhe Wang;Kate Smith-Miles;Rob J. Hyndman	2009	Neurocomputing	10.1016/j.neucom.2008.10.017	probabilistic forecasting;econometrics;forecasting;computer science;machine learning;time series;data mining;statistics	ML	7.242320200125496	-20.33988107341398	184648
1c9ac4fc27a146c839584abfa5f84d9ba3f3e15c	wavelet neural network prediction method of stock price trend based on rough set attribute reduction		Abstract To improve the prediction capacity of stock price trend, an integrated prediction method is proposed based on Rough Set (RS) and Wavelet Neural Network (WNN). RS is firstly introduced to reduce the feature dimensions of stock price trend. On this basis, RS is used again to determine the structure of WNN, and to obtain the prediction model of stock price trend. Finally, the model is applied to prediction of stock price trend. The simulation results indicate that, through RS attribute reduction, the structure of WNN prediction model can be simplified significantly with the improvement of model performance. The directional symmetry values of prediction, corresponding to SSE Composite Index, CSI 300 Index, All Ordinaries Index, Nikkei 225 Index and Dow Jones Index, are 65.75%, 66.37%, 65.97%, 65.52% and 66.75%, respectively. The prediction results are better than those obtained by other neural networks, SVM, WNN and RS-WNN, which verifies the feasibility and effectiveness of the proposed method of predicting stock price trend.	artificial neural network;rough set;wavelet	Lei Lei	2018	Appl. Soft Comput.	10.1016/j.asoc.2017.09.029	support vector machine;composite index;wavelet;machine learning;artificial intelligence;artificial neural network;mathematics;rough set	ML	8.278618167781415	-19.91485298106718	185290
a103cc1e3fe7664079189b28c64a500143c663d5	spatial pattern assessment of tropical forest fire danger at thuan chau area (vietnam) using gis-based advanced machine learning algorithms: a comparative study		Abstract Thuan Chau is a serious district affected by forest fire in Vietnam, especially in 2016; however, no forest fire prediction research has been conducted for this region. Thus, knowledge of spatial patterns of fire danger of the district plays a key role in forest succession and ecological implications. This studyu0027s aim was to analyze the spatial pattern of fire danger for the tropical forest of Thuan Chau district using advanced machine learning algorithms, Support Vector Machine classifier (SVMC), Random Forests (RF), and Multilayer Perceptron Neural Network (MLP-Net). For this purpose, a GIS database for the study area was established with 564 forest fire locations and ten forest fire variables. Then, Pearson correlation method was used to assess the correlation of the variables with the forest fire. In the next step, three forest fire danger models, SVMC, RF, and MLP-Net, were trained and validated. Finally, global performance of these models was assessed using the classification accuracy (ACC), Kappa statistics (KS), Area under the curve (AUC). In addition, Wilcoxon signed-rank test was employed to check the prediction performance of these models. The result shows the three models performed well; however, the MLP-Net model has the highest prediction performance (ACC = 81.7, KS = 0.633, and AUC = 0.894), followed by the RF model (ACC = 81.1, KS = 0.621, and AUC = 0.883), and the SVMC model (ACC = 80.2, KS = 0.604, and AUC = 0.867). The result in this study is useful for the local authority and forest manager in forest management and fire suppression.	algorithm;geographic information system;machine learning	Nguyen Ngoc Thach;Dang Bao-Toan Ngo;Pham Xuan-Canh;Nguyen Hong-Thi;Bui Hang Thi;Hoang Nhat-Duc;Tien Bui Dieu	2018	Ecological Informatics	10.1016/j.ecoinf.2018.05.009	data mining;fire protection;ecological succession;support vector machine;forest management;spatial ecology;artificial neural network;algorithm;random forest;computer science;multilayer perceptron;machine learning;artificial intelligence	AI	6.282112916714453	-22.454649777277456	185777
e8c437ba3e5ad4531d34d6c226583a2be9a13523	integrating fuzzy ahp and gis to prioritize sites for the solar plant installation	rajasthan fuzzy ahp gis solar plant installation solar power plant site selection process thematic map multicriteria decision making fuzzy analytical hierarchy process bikaner;fuzzy ahp iso cluster classification geographic information system gis;fuzzy ahp;geographic information system gis;iso cluster classification;solar power stations analytic hierarchy process fuzzy set theory geographic information systems power engineering computing;power generation analytic hierarchy process sociology statistics solar radiation production data mining	Selection of site is the most fundamental and crucial decision, in the process of setting up a solar power plant. Since several factors influence the site selection process, multi criteria analysis is used to resolve this problem. In this study, seven districts of Rajasthan in India are considered as different alternatives for the installation of solar power plant. They are evaluated over few crucial criteria's such as solar radiation, land availability, water availability, cost of land, population benefitted, transmission losses and number of rainy days, which have a great impact on power generation. As the data corresponding to the criteria's considered is not available, thematic map is used as the raw data, with Arc GIS as interface, baseline data, corresponding to the criteria's for all study areas is extracted. A multi-criteria decision making technique, is used to choose the best suitable site for installation of solar power plant. Based on the literature, Fuzzy Analytical Hierarchy Process (Fuzzy AHP), which is advanced and a simple method, is used in this study for the location allocation of solar plant. Results dictate that Bikaner, which is one among the alternatives considered, is the optimal site for the installation for the solar plant in Rajasthan.	analytical hierarchy;arcgis;baseline (configuration management);common criteria;geographic information system;location-allocation;thematic map	Rajiv Guptha;Harish Puppala;Shalini Kanuganti	2015	2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2015.7381987	analytic hierarchy process;site selection;raw data;fuzzy logic;electricity generation;machine learning;operations research;computer science;artificial intelligence;location-allocation;solar power;population	DB	9.103658410626661	-17.193607086259433	187753
39f4d86cb132a285c680f6090d3905cdb4e45286	a kpca rnn based model for the area flowing of graduate employment forecasting	kernel principal component analysis kpca rnn area flowing graduate employment forecasting time series recurrent neural network;time series employment forecasting theory human resource management principal component analysis recurrent neural nets;forecasting;employment;kernel principal component analysis;area flowing;empirical study;kernel;kpca;graduate employment forecasting;time series;recurrent neural networks predictive models employment principal component analysis kernel feature extraction humans technology forecasting neural networks remuneration;artificial neural networks;graduate employment;forecasting theory;high school;forecasting kpca area flowing graduate employment;feature extraction;principal component analysis;kpca rnn;recurrent neural nets;recurrent neural networks;recurrent neural network;neural network model;human resource management;neural network	Searching influence variables as well as forecasting the flowing of graduate employment is an ongoing activity of considerable significance. But the forecasting is complex due to the time series and complex factor inputs. The neural network method has been successfully employed to solve the multi factors problem. However the forecasting result is not ideal due to the nonlinearity and noise. In this work, a neural network model is presented by combining Recurrent Neural Network (RNN) with Kernel Principal Component Analysis (KPCA). And then try to forecast the area flowing of graduate employment using this model. In the model, RNN with Kernel Principal Component Analysis (KPCA) and Principal Component Analysis (PCA) as the feature extraction is introduced in as comparison. And then by an empirical study with actual data from some high school of China, it is shown that the proposed methods can both achieve good forecasting performance comparing with NN method. And the KPCA method performs better than the PCA method.	artificial neural network;feature extraction;kernel principal component analysis;network model;nonlinear system;random neural network;recurrent neural network;time series	Cheng-Song Qing;Xiang Sun	2008	2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2008.162	computer science;recurrent neural network;machine learning;pattern recognition;data mining;artificial neural network	ML	8.817118919956096	-20.26326677215616	187903
4b0628f8c98c6c08721dc9794e5835b01c9abeab	rbf neural network modeling based on pca clustering analysis	clinker strength principal components analysis pca clustering analysis ca rbf neural network;radial basis function networks data analysis learning artificial intelligence pattern clustering principal component analysis;prediction accuracy pca clustering analysis pretreatment data principal component analysis spss software data correlation analysis data samples rbf neural network prediction model data center network structure neural network training matlab;neural networks principal component analysis mathematical model predictive models analytical models training correlation	Aiming at the problem of lower forecast accuracy of traditional RBF neural network model, we suggest a new modeling method. First, pretreatment data are sampled using SPSS software. Principal component analysis (PCA) was applied to original data correlation analysis to remove the correlations between attributes and find the main influencing indicator to reduce the number of input layer nodes. The following step is to apply the clustering analysis on data samples to choose the training data samples for neural network modeling and reduce the number of data samples. Then, after preprocessing, the data samples can be used to construct RBF neural network prediction model. The core problem solving at this stage is to determine the number of hidden layer nodes and the corresponding data center, so that design the network which its target error meet the requirement. We use cement clinker strength prediction as the research example to determine the network structure is 5-89-2. Finally, we implemented the neural network training and simulation work using the neural network toolbox provided in MATLAB. This modeling method can filter the raw data sample to fully reflect the characteristics of the problem in its field, effectively reduce RBF network structure and meanwhile improve the forecast precision of the model. The simulation results show that our model had higher prediction accuracy. The method of construction of prediction model provides a new idea and method for the study of prediction problems, and expands the thought for the research of other field modeling1.	artificial neural network;certificate authority;cluster analysis;complexity;data center;matlab;network model;preprocessor;principal component analysis;problem solving;radial basis function network;spss;simulation	Lifang Chen;Xiao Lu;Zhidian Du	2014	2014 IEEE International Conference on Granular Computing (GrC)	10.1109/GRC.2014.6982803	probabilistic neural network;machine learning;pattern recognition;data mining	ML	9.567317552510865	-20.485359008081733	188023
3eca0c979d35ab70206d643eeeca7a757567ea7a	a ga-based support vector machine diagnosis model for business crisis	intellectual capital;business crisis;diagnosis model;prediction accuracy;genetic algorithm;support vector machine	This research proposes a diagnosis model for business crisis integrated a real-valued genetic algorithm and support vector machine. A series of learning and testing processes with real business data show that the diagnosis model has a crisis prediction accuracy of up to 95.56%, demonstrating the applicability of the proposed method. Six features, including five financial and one intellectual capital indices, are used for the diagnosis. These features are common and easily accessible from publicly available information. The proposed GA-SVM diagnosis model can be used by firms for self-diagnosis and evaluation.	software release life cycle;support vector machine	Ming-Fen Yang;Huey-Der Hsiao	2010		10.1007/978-3-642-16693-8_29	support vector machine;genetic algorithm;computer science;machine learning;data mining	ML	5.350911374966439	-19.667339667419142	188120
3fd45191d9c559788919a80ce1cce68e047f9d55	analysis of wind energy time series with kernel methods and neural networks	forecasting;forecasting techniques;information structure;modeling and forecasting;kernel;high dimensionality;neural networks;support vector machines;renewable energy sources;kernel density estimation;wind power;nrel western wind resource dataset;support vector regression;energy production;time series;wind forecasting;wind energy;power engineering computing;smart power grids;time series analysis;self organising feature maps;self organizing feature maps;wind forecasting time series analysis kernel wind energy forecasting support vector machines;self organized feature map;monitoring techniques;statistic sound modeling;kernel density estimate;wind data modeling;wind energy time series;error detection wind energy time series neural networks renewable energy resource monitoring techniques forecasting techniques smart energy grids kernel density estimation wind data modeling statistic sound modeling nrel western wind resource dataset support vector regression self organizing feature maps;time series data;wind power power engineering computing regression analysis self organising feature maps smart power grids support vector machines time series;system development;energy system;kernel method;regression analysis;support vector machine;error detection;renewable energy resource;smart energy grids;neural network	Wind energy has an important part to play as renewable energy resource in a sustainable world. For a reliable integration of wind energy the volatile nature of wind has to be understood. This article shows how kernel methods and neural networks can serve as modeling, forecasting and monitoring techniques, and, how they contribute to a successful integration of wind into smart energy grids. First, we will employ kernel density estimation for modeling of wind data. Kernel density estimation allows a statistically sound modeling of time series data. The corresponding experiments are based on real data of wind energy time series from the NREL western wind resource dataset. Second, we will show how prediction of wind energy can be accomplished with the help of support vector regression. Last, we will use self-organizing feature maps to map high-dimensional wind time series to colored sequences that can be used for error detection.	artificial neural network;dynamical system;error detection and correction;experiment;kernel (operating system);kernel density estimation;kernel method;map;organizing (structure);real-time computing;real-time transcription;self-organization;smart tv;support vector machine;time series;volatile memory	Oliver Kramer;Fabian Gieseke	2011	2011 Seventh International Conference on Natural Computation	10.1109/ICNC.2011.6022597	simulation;engineering;machine learning;data mining	ML	9.147975441080836	-18.69718169162124	188337
ac37cdbd18bb344f739dea8007e8949f36f3f957	tournament searching method for optimization of the forecasting model based on the nadaraya-watson estimator		In the article the tournament searching method is used for optimization of the forecasting model based on the Nadaraya-Watson estimator. This is a nonparametric regression model useful for forecasting the nonstationary in mean and variance time series with multiple seasonal cycles and trend. The tournament searching is a stochastic global optimization algorithm which is easy to use and competitive to other stochastic methods such as evolutionary algorithms. Three types of tournament searching algorithms are proposed: for estimation of the forecasting model parameters (continuous optimization), for the predictor selection (binary optimization) and for both predictor selection and parameter estimation (mixed binary-continuous optimization). The effectiveness of the proposed approach is illustrated through applications to electrical load forecasting and compared with other optimization methods: grid search method, genetic and evolutionary algorithms, and sequential methods of feature selection. Application examples confirm good properties of tournament searching.		Grzegorz Dudek	2014		10.1007/978-3-319-07176-3_30	econometrics;mathematical optimization;machine learning	Vision	8.119628513879315	-19.922160178070136	188362
1c5f6145c426d05c4166a95cd74baca233f4c684	time series forecasting by a seasonal support vector regression model	forecast;time series forecasting;seasonal time series;support vector regression;forecasting model;time series;seasonal autoregressive integrated moving average;moving average;seasonality;time series data;tabu search;forecast accuracy;hybrid genetic algorithm	The support vector regression (SVR) model is a novel forecasting approach and has been successfully used to solve time series problems. However, the applications of SVR models in a seasonal time series forecasting has not been widely investigated. This study aims at developing a seasonal support vector regression (SSVR) model to forecast seasonal time series data. Seasonal factors and trends are utilized in the SSVR model to perform forecasts. Furthermore, hybrid genetic algorithms and tabu search (GA/TS) algorithms are applied in order to select three parameters of SSVR models. In this study, two other forecasting models, autoregressive integrated moving average (SARIMA) and SVR are employed for forecasting the same data sets. Empirical results indicate that the SSVR outperforms both SVR and SARIMA models in terms of forecasting accuracy. Thus, the SSVR model is an effective method for seasonal time series forecasting.	support vector machine;time series	Ping-Feng Pai;Kuo-Ping Lin;Chi-Shen Lin;Ping-Teng Chang	2010	Expert Syst. Appl.	10.1016/j.eswa.2009.11.076	econometrics;autoregressive integrated moving average;machine learning;time series;statistics	ML	8.228954557851063	-19.74298745105782	189552
54caa4672b205b051750338f033560414a8d114f	"""application of neural networks to stock prediction in """"pool"""" companies"""	artificial intelligent;quality of service;artificial neural network;neural network	"""Nowadays, carrying out precise stock predictions is essential for many companies in order to reduce material in storage. It allows these companies to decrease their investment in material. In the particular case of """" Pool """" companies, this need becomes greater since they have to maintain the quality of service as well as to minimize the investment in fixed assets. In order to make an accurate prediction, we have used artificial intelligence techniques, specifically artificial neural networks. Introduction Nowadays, many companies require the use of predictions to adjust material stocks stored in their warehouses."""	artificial intelligence;neural networks;quality of service	Oscar Sapena;Vicent J. Botti;Estefania Argente	2003	Applied Artificial Intelligence	10.1080/713827208	quality of service;computer science;machine learning;data mining;artificial neural network	AI	4.72248003751164	-17.70936887085676	190417
8c218beaabb10066ecc9dd98fa0f6e196dfb8b0f	construction of benchmarking models using fuzzy linear regression techniques	benchmarking;fuzzy regression;linear regression;fuzzy set theory;data envelopment analysis benchmarking models fuzzy linear regression techniques standardized input data;benchmark testing data models buildings linear regression energy efficiency mathematical model analytical models;data envelopment analysis;regression analysis benchmark testing data envelopment analysis fuzzy set theory;regression analysis;benchmarking fuzzy regression;benchmark testing	By applying fuzzy linear regression analysis with standardized input data, benchmarking model and the corresponding table can be built with normalized the center component. End users can use the benchmarking table to check their performance. An illustrative example is given.		William Chung	2012	2012 9th International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2012.6233784	benchmark;econometrics;proper linear model;multivariate adaptive regression splines;computer science;linear regression;machine learning;data mining;data envelopment analysis;fuzzy set;regression analysis;statistics;benchmarking	DB	4.13667451141777	-22.65212199290899	190444
6100f8cdb85fc8d1ac22bf19bd7fc0b67ca10781	fault diagnosis of car assembly line based on fuzzy wavelet kernel support vector classifier machine and modified genetic algorithm	wavelet analysis;fuzzy theory;fuzzy number;support vector classifier;journal;multi dimensional;triangular fuzzy number;genetic algorithm;support vector classifier machine;uncertain data;fault diagnosis	This paper presents a new version of fuzzy wavelet support vector classifier machine to diagnosing the nonlinear fuzzy fault system with multi-dimensional input variables. Since there exist problems of finite samples and uncertain data in complex fuzzy fault system, the input and output variables are described as fuzzy numbers. Then by integrating the fuzzy theory, wavelet analysis theory and v-support vector classifier machine, fuzzy wavelet v-support vector classifier machine (FWv-SVCM) is proposed. To seek the optimal parameters of FWv-SVCM, genetic algorithm (GA) is also applied to optimize unknown parameters of FWv-SVCM. A diagnosing method based on FWv-SVCM and GA is put forward. The results of the application in car assembly line diagnosis confirm the feasibility and the validity of the diagnosing method. Compared with the traditional model and other SVCM methods, FWv-SVCM method requires fewer samples and has better diagnosing precision.	genetic algorithm;kernel (operating system);support vector machine;wavelet	Qi Wu;Rob Law;Shuyan Wu	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.12.109	wavelet;margin classifier;genetic algorithm;defuzzification;quadratic classifier;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;data mining;mathematics;fuzzy associative matrix;fuzzy set operations;structured support vector machine	AI	5.056786056285462	-22.632612610010163	191336
748d59f1d610a727e14729ea43476b8f18ce1aef	study on interval data envelopment analysis model with preference restraint cone based on unascertained rational number	analytical models;reliability;preference restraint cone model;multiple input and multiple output;unascertained theory;biological system modeling;decision making data envelopment analysis;interval number;unascertained math;interval data;preference restraint cone;interval data envelopment analysis;indexes;data envelopment analysis data models indexes analytical models decision making reliability biological system modeling;data envelopment analysis;indexation;interval number unascertained rational number data envelopment analysis preference restraint cone;relative efficiency;non parametric method;rational number;unascertained rational number;decision making units;decision making unit;data envelope analysis;data models;unascertained theory interval data envelopment analysis preference restraint cone model unascertained rational number decision making units unascertained math	Data envelopment analysis (DEA) is a non-parametric method for evaluating the relative efficiency of decision-making units (DMUs) with multiple inputs and multiple outputs. Unascertained math is a useful tool for dealing with unascertained information. The unascertained theory was introduced to data envelopment analysis in this paper. A new model, which is called interval data envelopment analysis with preference restraint cone model, was constructed to make approval of the decision making units. In this model, the input data and output data could be disposed by unascertained rational number method in advance and the weight of index should be dominated by evaluator through preference restraint cone. Therefore, interval data envelopment analysis with preference restraint cone model is convenient for integrating decision-maker's preferences and precision of imprecise data. At the end of the text, a case was applied to qualify scientific and feasibility of the method.	data envelopment analysis;interpreter (computing)	Xinzheng Wang;Jingyan Liu;Xiaochen Duan	2010	2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2010.5569399	econometrics;computer science;data envelopment analysis;mathematics;statistics	DB	3.822367644986238	-22.596890226947085	191905
f41bfa97cd03a63f8c50d28a5c2905567bf25adb	granular-based dimension reduction for solar radiation prediction using adaptive memory programming	granular computing;dimension reduction;adaptive memory programming;solar radiation prediction	Estimation of the solar radiation level reaching a specific zone on the surface of earth is a crucial step in the design and planning of solar energy systems. The large number of parameters affecting the estimation and prediction processes mandates dimension reduction of the input feature space. In this paper, we address this problem for a prediction system in which uncertainties play a major role. We propose an adaptive memory programming-based approach to optimize the input feature space of a solar radiation predictor. The fitness values of reducts are calculated using granular computing. The attribute reduction concept in the rough set theory is invoked and the dependency degree is used as a fitness function. The proposed methodology is evaluated using a large environmental temporal dataset collected for regions that exhibit diverse climate conditions.	dimensionality reduction;feature vector;fitness function;granular computing;kerrison predictor;rough set;set theory	Abdel-Rahman Hedar;Alaa E. Abdel-Hakim;Majid Almaraashi	2016		10.1145/2908961.2931648	mathematical optimization;simulation;granular computing;computer science;artificial intelligence;machine learning;mathematics;dimensionality reduction	AI	9.650612591962137	-17.29243794269324	191929
b11c324357bb279694c98a1dd6a1f6bd165bfdf5	combination of time series forecasts using neural network	nonparametric combination schema;forecasting;time series forecasting;combination;kernel;nn5 competition;validation performance;neural nets;weighted averaging;hidden markov model;nonlinear combination method;training;weighted average schema time series forecasting neural network forecast combination nonlinear combination method nn5 competition predictor ensemble validation performance nonparametric combination schema simple averaging schema;time series;predictor ensemble;ensemble;artificial neural networks;simple averaging schema;hidden markov models;time series forecasting theory neural nets;forecasting theory;weighted average schema;time series analysis;ordinary least square;time series data;predictive models;prediction model;dimensional reduction;prediction;forecast combination;artificial neural network;neural network;artificial neural networks time series analysis hidden markov models forecasting predictive models kernel training;neural network time series forecasting prediction combination ensemble	Forecast combination, which is a method to combine the result of several predictors, offers a way to improve the forecast result. Several methods have been proposed to combine the forecasting results into single forecast, namely the simple averaging, weighted average on validation performance, or non-parametric combination schemas. Recent literature uses dimensional reduction method for individual prediction and employs ordinary least squares for forecast combination. Other literature combines prediction results from neural networks using dimensional reduction techniques. Thus, those previous combination schemas can be categorized into linear combination methods. This paper aims to explore the use of non-linear combination method to perform the ensemble of individual predictors. We believe that the non-linear combination method may capture the non linear relationship among predictors, thus, may enhance the result of final prediction. The Neural Network (NN), which is widely used in literature for time series tasks, is used to perform such combination. The dataset used in the experiment is the time series data designated for NN5 Competition. The experimental result shows that forecast combination using NN performs better than the best individual predictors, provided that the predictors selected for combination have fairly good performance.	akaike information criterion;artificial neural network;bayesian information criterion;categorization;feature selection;kerrison predictor;model selection;nonlinear system;ordinary least squares;time series	Agus Widodo;Indra Budi	2011	Proceedings of the 2011 International Conference on Electrical Engineering and Informatics	10.1109/ICEEI.2011.6021770	computer science;machine learning;time series;pattern recognition;data mining;artificial neural network;statistics	HPC	8.035132366363122	-20.406950776055023	192594
f8631c3359fd11c7e76cbc6f8d73e79417bac21a	analysis and prediction of cranberry growth with dynamical neural network models	neural nets;one month ahead prediction cranberry growth prediction dynamical neural network models pca principle component analysis minimum cranberry spectral match measurement data;principal component analysis agriculture neural nets forecasting theory;forecasting theory;principal component analysis;dynamic neural network;agriculture;principle component analysis;neural networks predictive models computer networks wavelength measurement weather forecasting principal component analysis monitoring pest control vectors absorption;neural network model;growth process;high performance;monitoring and control;neural network	Cranberry plants are very sensitive to weather and other conditions. In this paper, the condition of cranberry growth is analyzed through PCA (principle component analysis) of the minimum cranberry spectral match measurement data. Three neural network models are applied to the one-month ahead prediction. The simulation results show the high performance modeling ability of these neural networks. The reliable prediction provided by the dynamic neural networks will be useful for the farmers to monitor and control the cranberry growth process.		C. H. Chen;Bichuan Shen	1999		10.1109/IJCNN.1999.836208	computer science;artificial intelligence;machine learning;data mining;artificial neural network;principal component analysis	ML	9.464205584231467	-19.125602606855963	192934
2d2f6a43c783541a9c1ba34abdde6ff4892d2dfa	a novel composition forecasting model based on choquet integral with respect to q-measure	linear regression composition forecasting model;q measure;fuzzy measure;l e measure;integral equations;queueing theory;linear weighted composition forecasting model;lambda measure;fuzzy set theory;o density;forecasting theory;regression analysis forecasting theory fuzzy set theory integral equations mean square error methods queueing theory;abstracts predictive models;choquet integral;abstracts;mean square error;mean square error methods;multivalent fuzzy measure;exponential smoothing model;composition forecasting model;predictive models;linear weighted composition forecasting model composition forecasting model choquet integral q measure p measure lambda measure multivalent fuzzy measure fuzzy density o density exponential smoothing model gm 1 1 forecasting model mean square error l e measure ridge regression composition forecasting model linear regression composition forecasting model;regression analysis;fuzzy density;p measure;gm 1 1 forecasting model;q measure composition forecasting model fuzzy measure choquet integral;ridge regression composition forecasting model	In our previous works, all of the multivalent fuzzy measures which based on the p-measure and additive measure always do not contain the well-known fuzzy measure, lambda-measure. In this paper, based on p-measure and lambda-measure, an improved multivalent fuzzy measure which contains lambda-measure, called Q-measure, is proposed. Based on a new fuzzy density, O- density, and the Choquet integral respect to Q-measure, a novel composition forecasting model composed of the time series model, the exponential smoothing model and the GM (1,1) forecasting model is proposed as well. An experiment with real data by using the 5 fold cross validation mean square error is conducted. The performances of the Choquet integral composition forecasting model with the Q-measure, LE-measure, the L-measure, the Lambda-measure and the P-measure, respectively, are compared with the ones of the ridge regression composition forecasting model, the multiple linear regression composition forecasting model and the traditional linear weighted composition forecasting model. The experimental results show that the Choquet integral composition forecasting model with the proposed Q-measure and the O-density has the best performance.	cross-validation (statistics);fuzzy measure theory;mean squared error;performance;smoothing;time complexity;time series;utility functions on indivisible goods;whole earth 'lectronic link	Hsiang-Chuan Liu;Shih-Neng Wu;Chih-Hswng Su;Yen-Kuei Yu	2012	2012 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2012.6359658	exponential smoothing;econometrics;mathematical optimization;computer science;machine learning;fuzzy measure theory;mathematics;mean squared error;predictive modelling;fuzzy set;choquet integral;queueing theory;integral equation;regression analysis;statistics	Robotics	6.8421839321422535	-21.798610805007524	193683
3769eaa0a0a265faa10265cba5882e85f65ca629	flood pattern detection using sliding window technique	art;rivers;neural networks;floods data mining educational institutions art rivers predictive models mathematical model hazards hydrologic measurements neural networks;rivers data mining disasters floods geophysics computing hydrological techniques rain regression analysis;temporal data;hazards;prior knowledge;data mining;hydrologic measurements;river water level;river water;pattern discovery;rainfall measurement;pattern detection;geophysics computing;sliding window technique;mathematical flood prediction model;temporal data flood occurrence pattern detection sliding window technique pattern discovery hydrological data river water level rainfall measurement mathematical flood prediction model regression technique;regression technique;mathematical model;rain;hydrological data;predictive models;sliding window pattern detection;regression analysis;prediction model;floods;data consistency;hydrological techniques;sliding window;flood occurrence pattern detection;historical data;disasters;qa76 computer software	Patterns could be discovered from historical data and can be used to recommend decisions suitable for a typical situation in the past. In this study, the sliding window technique was used to discover flood patterns that relate hydrological data consisting of river water levels and rainfall measurements. Unique flood occurrence patterns were obtained at each location. Based on the discovered flood occurrence patterns, mathematical flood prediction models were formulated by employing the regression technique. Experimental results showed that the mathematical flood prediction models were able to produce good prediction on the flood occurrences. Results from this study proved that sliding window technique was able to detect patterns from temporal data. It is also considered a sound approach to adopt in predicting the flood occurrence patterns as it requires no prior knowledge as compared to other approaches when dealing with temporal data.	flood;mathematical model;notification system;simulation	Ku Ruhana Ku-Mahamud;Norharyani Zakaria;Norliza Katuk;Mohamad Shbier	2009	2009 Third Asia International Conference on Modelling & Simulation	10.1109/AMS.2009.15	geography;hydrology;data mining;remote sensing	SE	9.886574643235766	-19.477031323486923	193782
24926658236f3c4b4b07868618f84deb5a8eda4a	knowledge extraction from web-based consumer surveys: bayesian networks with feature selection		Large-scale internet surveys have become very popular during the last two decades because of the internetu0027s evolution. Such surveys often contain multiple objective variables, and the relationship between these variables is unknown beforehand. Although various statistical methods are used for marketing analyses, conventional statistical methods are not designed to handle multiple objective variables. This paper proposes a method of extracting useful knowledge from a multi-objective survey dataset by performing Bayesian network modelling, accompanied by feature selection in which Crameru0027s coefficient of association (Crameru0027s V) is used as the information index. A marketer as a do-main expert subjectively decides what features to use in Bayesian networks, by firstly referring to the Cramer V ranking of explanatory variables, and by supplementarily referring to the Cramer V values of some combinations of variables. This method aims at not only finding a feature subset that accurately classifies objective var...	bayesian network;feature selection;web application	Yoko Ishino	2017	Int. J. Web Eng. Technol.	10.1504/IJWET.2017.089696	knowledge extraction;data mining;computer science;bayesian network;the internet;web application;feature selection;ranking;objective variables	AI	4.418869596109023	-18.999971647460587	194691
cd540783d51071818707ac5bef0d01b98c19a996	short-term load forecasting in smart grid: a combined cnn and k-means clustering approach	forecasting;training;testing;load forecasting;predictive models;load modeling;data models	Although many methods are available to forecast short-term electricity load based on small scale data sets, they may not be able to accommodate large data sets as electricity load data becomes bigger and more complex in recent years. In this paper, a novel machine learning model combining convolutional neural network with K-means clustering is proposed for short-term load forecasting with improved scalability. The large data set is clustered into subsets using K-means algorithm, then the obtained subsets are used to train the convolutional neural network. A real-world power industry data set containing more than 1.4 million of load records is used in this study and the experimental results demonstrate the effectiveness of the proposed method.	algorithm;artificial neural network;baseline (configuration management);cluster analysis;computation;convolutional neural network;evaluation function;experience;iteration;k-means clustering;machine learning;scalability	Xishuang Dong;Lijun Qian;Lei Huang	2017	2017 IEEE International Conference on Big Data and Smart Computing (BigComp)	10.1109/BIGCOMP.2017.7881726	real-time computing;computer science;machine learning;data mining	Robotics	7.892929025735691	-22.1013257058198	194799
3d28248f85efc978b8684e430fcbd214cc0f9a55	a novel artificial neural network ensemble model based on k--nearest neighbor nonparametric estimation of regression function and its application for rainfall forecasting	least square regression;forecasting;least squares approximations;nonparametric estimation;neural nets;artificial neural network ensemble model;bagging;training;artificial neural networks predictive models neural networks weather forecasting meteorology wind forecasting computer networks mathematical model disaster management statistical analysis;nonparametric;partial least square regression;biological system modeling;neural network ensemble;weather forecasting;forecasting model;anne rainfall forecasting method;ensemble;artificial neural networks;k nearest neighbor nonparametric estimation;geophysics computing;estimation;evaluation measure;meteorology application;weather forecasting atmospheric techniques bagging geophysics computing least squares approximations neural nets rain;bagging technology;rain;rainfall forecasting;nonparametric regression;k nearest neighbor;predictive models;network architecture;atmospheric techniques;k nearest neighbor artificial neural network ensemble nonparametric;china;guangxi;forecast accuracy;artificial neural network;data models;china artificial neural network ensemble model anne rainfall forecasting method k nearest neighbor nonparametric estimation rainfall forecasting meteorology application bagging technology least square regression guangxi	In this paper, a novel artificial neural network ensemble rainfall forecasting model is proposed for rainfall forecasting based on K--nearest neighbor nonparametric estimation of regression. In this model, original data set are partitioned into some different training subsets via Bagging technology. Then different ANN algorithms and different network architecture generate diverse individual neural network ensemble by training subsets. Thirdly, the partial least square regression is adopted to extract ensemble members. Finally, the K--nn nonparametric regression is used for ensemble model. Empirical results obtained reveal that the prediction by using the nonparametric ensemble model is generally better than those obtained using other models presented in this study in terms of the same evaluation measurements. Our findings reveal that the K--nn nonparametric regression ensemble model proposed here can be used as an alternative forecasting tool for a Meteorological application in achieving greater forecasting accuracy and improving prediction quality further.	algorithm;artificial neural network;bootstrap aggregating;ensemble forecasting;ensemble learning;ising model;kernel density estimation;nearest neighbor search;network architecture;nonlinear system;relevance;smoothing;theory	Jiansheng Wu	2009	2009 International Joint Conference on Computational Sciences and Optimization	10.1109/CSO.2009.307	econometrics;estimation;network architecture;bootstrap aggregating;weather forecasting;forecasting;computer science;machine learning;ensemble forecasting;data mining;ensemble learning;nonparametric regression;china;artificial neural network	ML	9.247247952216679	-20.40689167001886	195462
7dec312296a09c9fa9d85066fee37beb7ed041bd	competitive local linear modeling	ar model;piecewise linear;predictive value;linear model;nonlinear model	This paper describes a novel approach for nonlinear signal modeling and prediction. We propose a nonlinear extension of the conventional AR model by using several linear models, each covering a subset of the whole signal data. Considering that AR modeling is conducted by associating a delay vector with the future value to be predicted, we interpret the signal as a codebook of patterns having the desired predicted value as the associated output. The pattern groups associated with each AR model are obtained by competition among the linear models as they are trained: the competition gives us the AR models as well as a classification of the data patterns. The obtained data groups are the basis for estimating a segmentation model, i.e., a classifier that, given a new data pattern, indicates what linear model should be used. The combination of the classifier and the linear models constitutes the final system. Several practical applications show the advantages of our approach.		Carlos Pantaleón;Ignacio Santamaría;Aníbal R. Figueiras-Vidal	1996	Signal Processing	10.1016/0165-1684(95)00147-6	econometrics;generalized linear mixed model;proper linear model;piecewise linear function;computer science;machine learning;linear model;mathematics;autoregressive model;linear system;statistics;log-linear model	ML	8.11514139084745	-20.948914262382186	196320
4654a60f9b3bc5c5b6b7d4d32acfccdd1f5a69ce	enhanced accuracy of fuzzy time series predictor using genetic algorithm	forecasting;rate of change;time series computational complexity data analysis forecasting theory fuzzy logic fuzzy set theory genetic algorithms;time series analysis biological cells genetic algorithms forecasting accuracy predictive models data models;predictive value;time series;fuzzy set theory;average forecasting error rate fuzzy time series predictor genetic algorithm forecasting domain large historical value dominant factor optimization prediction accuracy membership function fitness checking ga complexity chromosome bit size;data model;fuzzy logic;accuracy;data analysis;biological cells;forecasting theory;time series analysis;computational complexity;mean square error;comparative study;prediction accuracy;membership function;accuracy genetic algorithm ga fuzzy logic time series analysis;error rate;time series data;genetic algorithm;predictive models;genetic algorithms;prediction model;forecast accuracy;data models;genetic algorithm ga	Accuracy is one of the most important aspects in the domain of forecasting. It is very difficult to improve accuracy of prediction system where prediction is based only on large historical values and accuracy is important for each predicted value along with the whole system. The main objective of this research is to optimize dominant factors of fuzzy time series predictor (FTSP) using genetic algorithm (GA) and further to improve prediction accuracy for each time series variable along with whole system. This is obtained by (a) generating wide range of parameters for membership function at time t on the basis of their base value (b) subset of population generated at time t is used for fitness checking. Additionally, GA complexity is also reduced by utilizing rate of change of time series data to cut down the bit size of chromosome. It can be observed from comparative study that use of GA considerably reduced mean square error (MSE) and average forecasting error rate (AFER).	c date and time functions;emoticon;genetic algorithm;kerrison predictor;mean squared error;software release life cycle;time series	Bindu Garg;M. M. Sufyan Beg;Abdul Quaiyum Ansari	2011	2011 Third World Congress on Nature and Biologically Inspired Computing	10.1109/NaBIC.2011.6089464	econometrics;computer science;machine learning;time series;data mining;mathematics;statistics	HCI	7.575067646629501	-19.95093785538481	196409
472bca4d52fbb4c61835226c04c724755c053185	valid predictions with confidence estimation in an air pollution problem		The present study is aimed to evaluate levels of air pollution for the Barcelona Metropolitan Region. For this purpose, a newly developed approach called conformal predictors is considered, and, in particular, use is made of the ridge regression confidence machine (RRCM). The hallmark of this method is that it gives valid estimates, i.e. for a given level of significance of prediction, the probability of error does not exceed this level. Moreover, the chosen specification of the RRCM predictor does not place any requirements on data distribution, apart from being independent and identically distributed. A linear ridge regression conformal predictor has been applied to the data. It has allowed to obtain valid interval estimates of annual nitrogen dioxide concentrations with 95 % confidence. The model has provided good results, but to further increase the efficiency of prediction, the RBF kernel has been used. The data for this study have been provided by the XVPCA (Network for Monitoring and Forecasting of Air Pollution) of the Generalitat of Catalonia. The pollutant considered in this paper is nitrogen dioxide. Its values are represented by annual average concentrations within the period from 1998 to 2009. This paper also describes an application of ordinary kriging, and its results have been compared to those of ridge regression conformal predictor.	conformal dimension;kerrison predictor;kriging;predictor–corrector method;radial basis function kernel;requirement;vertical blanking interval	Olga Ivina;Ilia Nouretdinov;Alexander Gammerman	2012	Progress in Artificial Intelligence	10.1007/s13748-012-0018-6	data mining	SE	9.364584059968973	-19.798495637570124	196413
bbb5bd26bae7c7da4e4e9aba2623716c2710551d	ensemble learning of rule-based evolutionary algorithm using multi layer perceptron for stock trading models	rule pools ensemble learning rule based evolutionary algorithm multilayer perceptron stock trading models pattern recognition classification generalization ability classifiers decision making market trend stock buying stock selling trading rules mlp;learning artificial intelligence barium training indexes;stock markets decision making evolutionary computation knowledge based systems learning artificial intelligence multilayer perceptrons pattern classification	Classification is a major research field in pattern recognition and many methods have been proposed to enhance the generalization ability of classification. Ensemble learning is one of the methods which enhance the classification ability by creating several classifiers and making decisions by combining their classification results. On the other hand, when we consider stock trading problems, trends of the markets are very important to decide to buy and sell stocks. In this case, the combinations of trading rules that can adapt to various kinds of trends are effective to judge the good timing of buying and selling. Therefore, in this paper, to enhance the performance of the stock trading system, ensemble learning mechanism of rule-based evolutionary algorithm using multi layer perceptron (MLP) is proposed, where several rule pools for stock trading are created by rule-based evolutionary algorithm, and effective rule pools are adaptively selected by MLP and the selected rule pools cooperatively make decisions of stock trading. In the simulations, it is clarified that the proposed method shows higher profits or reduces losses than the method without ensemble learning and buy &hold.	algorithmic trading;electronic trading;ensemble learning;evolutionary algorithm;logic programming;memory-level parallelism;pattern recognition;perceptron;rule 184;simulation	Shingo Mabu;Masanao Obayashi;Takashi Kuremoto	2014	2014 Joint 7th International Conference on Soft Computing and Intelligent Systems (SCIS) and 15th International Symposium on Advanced Intelligent Systems (ISIS)	10.1109/SCIS-ISIS.2014.7044647	artificial intelligence;machine learning;data mining	Robotics	5.88894153286006	-19.48026185053779	197508
d0c6c58aec2ccdfb88043279b6a063822f40910b	a hybrid ga-bp model for bankruptcy prediction	economic globalization;finance;neural networks;neural nets;economic forecasting;information technology;indexing terms;backpropagation;accuracy;artificial neural networks;backpropagation bankruptcy prediction economic globalization information technology accounting information decision making genetic algorithm neural networks;neural nets accounts data processing backpropagation decision making genetic algorithms;accounting information;performance analysis;prediction accuracy;accounts data processing;genetic algorithm;predictive models;genetic algorithms;bankruptcy prediction;neurons;predictive models artificial neural networks neurons finance neural networks power generation economics economic forecasting genetic algorithms accuracy performance analysis;back propagation;power generation economics;neural network	With the increase of economic globalization and evolution of information technology, accounting information are being generated and accumulated at an unprecedented pace. As a result, there has been a critical need for automated approaches to effective and efficient utilization of massive amount of accounting information to support companies' decision making. In this paper, we describe a hybrid GA-BP model in bankruptcy prediction. Optimization based on the genetic algorithm was executed on the neural networks thresholds and weights values. In addition, an example is given to validate the model; the results show our model has a high prediction accuracy in bankruptcy prediction	artificial neural network;genetic algorithm;information theory;kiva;software release life cycle	Ying Sai;Chenjian Zhong;Le-Hong Qu	2007	Eighth International Symposium on Autonomous Decentralized Systems (ISADS'07)	10.1109/ISADS.2007.3	genetic algorithm;computer science;artificial intelligence;backpropagation;machine learning;data mining;artificial neural network	Arch	7.487265405669703	-19.197275325611276	198851
0264aed57d6a2c110b00c310fb7a0d070d07fd5e	application of the rfid data mining to an apparel field	sales management;support vector machines;predication of sales volume;data collection;training;data mining rfid sales predication apparel shop customer action;data mining;companies;rfid tags;apparel shop;rfid;consumer behaviour;sales predication;predictive models;clothing;svm;prediction model;numerical experiment;training marketing and sales predictive models companies support vector machines rfid tags;sales management clothing consumer behaviour data mining radiofrequency identification;customer action;radiofrequency identification;predication of sales volume rfid apparel shop svm;marketing and sales	This paper proposes a new method that efficiently uses the RFID data collected from apparel shops. This method learns prediction models from the data by using data mining techniques. The models represent relationships between the number of sales in the next term and the actions of customers, such as the number of pick-up, the number of fitting, the number of customers, and so on. It is possible to predict sales volume by applying the present RFID data to the models. This paper verifies the efficiency of the method through numerical experiments based on the RFID data collected from two branches of an apparel company.	bootstrap aggregating;data mining;ensemble learning;experiment;numerical analysis;radio-frequency identification	Shigeaki Sakurai;Masanori Sanbe;Katsutoshi Watanabe	2010	2010 13th International Conference on Network-Based Information Systems	10.1109/NBiS.2010.17	radio-frequency identification;support vector machine;computer science;sales management;data mining;predictive modelling	DB	5.186497866855604	-20.205822072057956	198959
6e9ca32e4eac74b781636e78b9ebe76588f0b33f	urban traffic congestion evaluation based on kernel the semi-supervised extreme learning machine	asymmetric data;cooperative learning;traffic congestion evaluation;kernel sselm	There is always an asymmetric phenomenon between traffic data quantity and unit information content. Labeled data is more effective but scarce, while unlabeled data is large but weaker in sample information. In an urban transportation assessment system, semi-supervised extreme learning machine (SSELM) can unite manual observed data and extensively collected data cooperatively to build connection between congestion condition and road information. In our method, semi-supervised learning can integrate both small-scale labeled data and large-scale unlabeled data, so that they can play their respective advantages, while the ELM can process large scale data at high speed. Optimized by kernel function, Kernel-SSELM can achieve higher classification accuracy and robustness than original SSELM. Both the experiment and the real-time application show that the evaluation system can precisely reflect the traffic condition.	geographic information system;kernel (operating system);linux;mathematical optimization;network congestion;real-time clock;real-time computing;self-information;semi-supervised learning;semiconductor industry;supervised learning	Qing Shen;Xiaojuan Ban;Chong Guo	2017	Symmetry	10.3390/sym9050070	semi-supervised learning;cooperative learning;simulation;computer science;machine learning;data mining	AI	8.474736659940094	-23.66457576512597	199228
dbd565f2e78ee18c3d9a77b868b494d24c83aad7	prediction of exchange rates using averaging intrinsic mode function and multiclass support vector regression		Prediction of nonlinear and nonstationary time series datasets can be achieved by using support vector regression. To improve the accuracy, we propose a new model ‘averaging intrinsic mode function’ which is a derivative of empirical mode decomposition to filter datasets of an exchange rate, followed by using a new algorithm of multiclass Support Vector Regression (SVR) for prediction. Simulation results show that the proposed model significantly improves prediction yields of the exchange rates, compared to simulation of SVR model without filtering and multiclass.	64-bit computing;akaike information criterion;algorithm;bayesian information criterion;bloomberg terminal;computation;cryptographic hash function;digital signal processing;eur-lex;electronic engineering;hilbert–huang transform;machine learning;mean squared error;microsoft windows;multiclass classification;nonlinear system;operating system;random-access memory;server (computing);simulation;support vector machine;test data;time series	Bhusana Premanode;Jumlong Vongprasert;Christofer Toumazou	2013	Artif. Intell. Research	10.5430/air.v2n2p47	computer science;machine learning;pattern recognition;data mining	ML	8.500983349909685	-20.818536650266754	199993
