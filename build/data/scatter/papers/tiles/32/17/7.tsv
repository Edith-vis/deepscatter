id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
e05066d617f605df4e3a52f9fbd218d7c2576d12	assessment of cluster overlaps to improve accuracy of module detection from ppi networks	biology computing;cluster algorithm;protein protein interaction network;pattern clustering;proteins biology computing merging molecular biophysics pattern clustering;protein complex;computational techniques;proteins clustering algorithms accuracy algorithm design and analysis merging bioinformatics protein engineering;graph clustering;functional modules protein protein interactions protein interaction networks clustering protein complexes;protein protein interactions;functional modules;cluster merging algorithm yeast ppi network genome wide protein protein interaction graph clustering algorithm protein complex identification protein functional module identification seed refinement algorithm overlapping cluster overlap coverage metric overlapping consistency metric;proteins;clustering;molecular biophysics;protein protein interaction;protein complexes;merging;protein interaction networks;protein interaction network	Recent computational techniques have facilitated analyzing genome-wide protein-protein interactions. Various graph-clustering algorithms have been applied to the protein interaction networks for identifying protein complexes and functional modules. Since each protein performs multiple functions, a clustering algorithm should be able to produce overlapping clusters. In this paper, we use the seed-refinement algorithm to generate a set of preliminary overlapping clusters. Next, for further refining the preliminary clusters, we carry out a systematic analysis of their overlaps by novel metrics: overlap coverage and overlapping consistency. We propose the cluster-merging algorithm to yield final clusters by parameterizing the metrics. In the test with the yeast protein-protein interaction network, we demonstrate the proposed approach improves accuracy on detecting protein complexes and functional modules by optimizing the parameter values.	algorithm;cluster analysis;complex systems;computation;computer cluster;data mining;interaction network;machine learning;pixel density;refinement (computing);sensor	Nicholas Soltau;Young-Rae Cho	2011	2011 IEEE International Conference on Bioinformatics and Biomedicine	10.1109/BIBM.2011.25	protein–protein interaction;biology;biochemistry;computer science;bioinformatics;machine learning;data mining;multiprotein complex;molecular biophysics	Comp.	4.50555092390327	-55.65823946241942	117970
e858dc6e5494c12bcc5cb52123e80ae8bfa4f5b1	predicting functional sites in biological sequences using canonical correlation analysis	pearson correlation;novel method;protein function;protein engineering;existing method;canonical correlation analysis;biological sequence;key role;protein ligand binding site;protein functional site prediction;well-known benchmark dataset;vectors;correlation;noise measurement;metals;bioinformatics;proteins;ions;ligand binding	Protein functional site prediction plays a key role in understanding protein function and in protein engineering. In this work we developed a novel method using canonical correlation analysis to predict protein ligand binding sites. The method was tested with a well-known benchmark dataset and consistently outperformed the existing method Xdet, which is based on Pearson correlation, by improving the lowest and highest ranked positives for more than 18% and 22% respectively.	benchmark (computing);conserved sequence;sensitivity and specificity	Alvaro J. González;Li Liao;Cathy H. Wu	2009	2009 IEEE International Conference on Bioinformatics and Biomedicine Workshop		pearson product-moment correlation coefficient;biology;canonical correlation;bioinformatics;noise measurement;machine learning;protein engineering;ligand;correlation;statistics;ion	Visualization	9.776824989286537	-57.48592845847313	118065
235c778ec5fafd2702101bbbec9b752c0e938e85	bayesian variable selection for the analysis of microarray data with censored outcomes	microarray data;data augmentation;sample size;high dimensionality;linear regression;search method;microarray data analysis;accelerated failure time;decision theoretic;cox model;bayesian variable selection;simulation study	MOTIVATION A common task in microarray data analysis consists of identifying genes associated with a phenotype. When the outcomes of interest are censored time-to-event data, standard approaches assess the effect of genes by fitting univariate survival models. In this paper, we propose a Bayesian variable selection approach, which allows the identification of relevant markers by jointly assessing sets of genes. We consider accelerated failure time (AFT) models with log-normal and log-t distributional assumptions. A data augmentation approach is used to impute the failure times of censored observations and mixture priors are used for the regression coefficients to identify promising subsets of variables. The proposed method provides a unified procedure for the selection of relevant genes and the prediction of survivor functions.   RESULTS We demonstrate the performance of the method on simulated examples and on several microarray datasets. For the simulation study, we consider scenarios with large number of noisy variables and different degrees of correlation between the relevant and non-relevant (noisy) variables. We are able to identify the correct covariates and obtain good prediction of the survivor functions. For the microarray applications, some of our selected genes are known to be related to the diseases under study and a few are in agreement with findings from other researchers.   AVAILABILITY The Matlab code for implementing the Bayesian variable selection method may be obtained from the corresponding author.   CONTACT mvannucci@stat.tamu.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	automatic frequency control;bioinformatics;censor;clinical trial censoring;coefficient;convolutional neural network;distributional semantics;feature selection;matlab;microarray;simulation;statistical imputation;survivors	Naijun Sha;Mahlet G. Tadesse;Marina Vannucci	2006	Bioinformatics	10.1093/bioinformatics/btl362	microarray analysis techniques;econometrics;computer science;data mining;statistics	Comp.	6.138419467346342	-52.38504424837006	118327
64388565c67335aa1beef9cde6166b45ab9e148e	svm-balsa: remote homology detection based on bayesian sequence alignment	dynamic programming;sequence comparison;protein family;learning;receiver operator characteristic;implementation;vectors support vector machine;remote homology;dynamic program;detection;profiles methods;bayesian;sensitivity;proteins;statistical learning theory;homology;roc curve;sequence analysis;sequence alignment;support vector machine;basic biological sciences;construction;alignment	Biopolymer sequence comparison to identify evolutionarily related proteins, or homologs, is one of the most common tasks in bioinformatics. Support vector machines (SVMs) represent a new approach to the problem in which statistical learning theory is employed to classify proteins into families, thus identifying homologous relationships. Current SVM approaches have been shown to outperform iterative profile methods, such as PSI-BLAST, for protein homology classification. In this study, we demonstrate that the utilization of a Bayesian alignment score, which accounts for the uncertainty of all possible alignments, in the SVM construction improves sensitivity compared to the traditional dynamic programming implementation over a benchmark dataset consisting of 54 unique protein families. The SVM-BALSA algorithms returns a higher area under the receiver operating characteristic (ROC) curves for 37 of the 54 families and achieves an improved overall performance curve at a significance level of 0.07.		Bobbie-Jo M. Webb-Robertson;Christopher S. Oehmen;Melissa M. Matzke	2005	Computational biology and chemistry	10.1016/j.compbiolchem.2005.09.006	biology;computer science;bioinformatics;machine learning;pattern recognition;mathematics;receiver operating characteristic	ML	9.896163047818545	-55.82059696522985	118355
0958e43dcda254a44ebb8c2c3c84918791c2009b	machine learning from concept to clinic: reliable detection of braf v600e dna mutations in thyroid nodules using high-dimensional rna expression data		The promise of personalized medicine will require rigorously validated molecular diagnostics developed on minimally invasive, clinically relevant samples. Measurement of DNA mutations is increasingly common in clinical settings but only higher-prevalence mutations are cost-effective. Patients with rare variants are at best ignored or, at worst, misdiagnosed. Mutations result in downstream impacts on transcription, offering the possibility of broader diagnosis for patients with rare variants causing similar downstream changes. Use of such signatures in clinical settings is rare as these algorithms are difficult to validate for commercial use. Validation on a test set (against a clinical gold standard) is necessary but not sufficient: accuracy must be maintained amidst interfering substances, across reagent lots and across operators. Here we report the development, clinical validation, and diagnostic accuracy of a pre-operative molecular test (Afirma BRAF) to identify BRAF V600E mutations using mRNA expression in thyroid fine needle aspirate biopsies (FNABs). FNABs were obtained prospectively from 716 nodules and more than 3,000 features measured using microarrays. BRAF V600E labels for training (n=181) and independent test (n=535) sets were established using a sensitive quantitative PCR (qPCR) assay. The resulting 128-gene linear support vector machine was compared to qPCR in the independent test set. Clinical sensitivity and specificity for malignancy were evaluated in a subset of test set samples (n=213) with expert-derived histopathology. We observed high positive- (PPA, 90.4%) and negative (NPA, 99.0%) percent agreement with qPCR on the test set. Clinical sensitivity for malignancy was 43.8% (consistent with published prevalence of BRAF V600E in this neoplasm) and specificity was 100%, identical to qPCR on the same samples. Classification was accurate in up to 60% blood. A double-mutant still resulting in the V600E amino acid change was negative by qPCR but correctly positive by Afirma BRAF. Non-diagnostic rates were lower (7.6%) for Afirma BRAF than for qPCR (24.5%), a further advantage of using RNA in small sample biopsies. Afirma BRAF accurately determined the presence or absence of the BRAF V600E DNA mutation in FNABs, a collection method directly relevant to solid tumor assessment, with performance equal to that of an established, highly sensitive DNA-based assay and with a lower non-diagnostic rate. This is the first such test in thyroid cancer to undergo sufficient analytical and clinical validation for real-world use in a personalized medicine context to frame individual patient risk and inform surgical choice.	amino acid metabolism, inborn errors;amino acids;anaplastic thyroid carcinoma;antivirus software;aspirate substance;braf np_004324.2:p.v600e;biopsy;downstream (software development);histopathology;machine learning;microarray;mutation;neoplasms;patients;personalization;phenylpropanolamine;precision medicine;printer working group;rna;reagents;real-time polymerase chain reaction;reverse transcriptase polymerase chain reaction;scientific publication;sensitivity and specificity;subgroup;support vector machine;test set;transcription (software);algorithm;solid tumor	James Diggans;Su Yeon Kim;Zhanzhi Hu;Daniel Pankratz;Mei G. Wong;Jessica Reynolds;Ed Y. Tom;Moraima Pagan;Robert J. Monroe;Juan Rosai;Virginia A. Livolsi;Richard B. Lanman;Richard T. Kloos;P. Sean Walsh;Giulia C. Kennedy	2015	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		bioinformatics;thyroid nodules;dna microarray;genetics;thyroid cancer;personalized medicine;molecular diagnostics;real-time polymerase chain reaction;malignancy;v600e;biology	Comp.	7.921331520277239	-53.30986838047768	118358
1fd3e6cf699ee3ff5f095803beb3ead6d33e8b2e	sensitivity analysis of biological boolean networks using information fusion based on nonadditive set functions	simulation and modeling;node attributes;systems biology;signal transduction;physiological cellular and medical topics;models biological;computational biology bioinformatics;sensitivity;choquet integral;nonadditive set functions;algorithms;information fusion;protein interaction maps;computer simulation;bioinformatics	An algebraic method for information fusion based on nonadditive set functions is used to assess the joint contribution of Boolean network attributes to the sensitivity of the network to individual node mutations. The node attributes or characteristics under consideration are: in-degree, out-degree, minimum and average path lengths, bias, average sensitivity of Boolean functions, and canalizing degrees. The impact of node mutations is assessed using as target measure the average Hamming distance between a non-mutated/wild-type network and a mutated network. We find that for a biochemical signal transduction network consisting of several main signaling pathways whose nodes represent signaling molecules (mainly proteins), the algebraic method provides a robust classification of attribute contributions. This method indicates that for the biochemical network, the most significant impact is generated mainly by the combined effects of two attributes: out-degree, and average sensitivity of nodes. The results support the idea that both topological and dynamical properties of the nodes need to be under consideration. The algebraic method is robust against the choice of initial conditions and partition of data sets in training and testing sets for estimation of the nonadditive set functions of the information fusion procedure.	anatomic node;boolean network;cell signaling;directed graph;dynamical system;hamming distance;initial condition;mutation;node - plant part;signal transduction;transduction (machine learning)	Naomi Kochi;Tomás Helikar;Laura Allen;Jim A. Rogers;Zhenyuan Wang;Mihaela Teodora Matache	2014		10.1186/s12918-014-0092-4	computer simulation;biology;sensitivity;computer science;bioinformatics;theoretical computer science;machine learning;choquet integral;systems biology;signal transduction	ML	7.013541988375301	-58.24562322968418	118436
fefee69007bffcf976a34e1940d02854ec22a8a1	homosar: bridging comparative protein modeling with quantitative structural activity relationship to design new peptides	ace inhibitory peptides;hamphiphysin 1 sh3 domain binding peptides;homosar;peptide quantitative structural activity relationship;homology modeling;multiple sequence alignment;camel s antibiotic peptides	Peptides play significant roles in the biological world. To optimize activity for a specific therapeutic target, peptide library synthesis is inevitable; which is a time consuming and expensive. Computational approaches provide a promising way to simply elucidate the structural basis in the design of new peptides. Earlier, we proposed a novel methodology termed HomoSAR to gain insight into the structure activity relationships underlying peptides. Based on an integrated approach, HomoSAR uses the principles of homology modeling in conjunction with the quantitative structural activity relationship formalism to predict and design new peptide sequences with the optimum activity. In the present study, we establish that the HomoSAR methodology can be universally applied to all classes of peptides irrespective of sequence length by studying HomoSAR on three peptide datasets viz., angiotensin-converting enzyme inhibitory peptides, CAMEL-s antibiotic peptides, and hAmphiphysin-1 SH3 domain binding peptides, using a set of descriptors related to the hydrophobic, steric, and electronic properties of the 20 natural amino acids. Models generated for all three datasets have statistically significant correlation coefficients (r(2)) and predictive r2 (r(pred)2) and cross validated coefficient ( q(LOO)2). The daintiness of this technique lies in its simplicity and ability to extract all the information contained in the peptides to elucidate the underlying structure activity relationships. The difficulties of correlating both sequence diversity and variation in length of the peptides with their biological activity can be addressed. The study has been able to identify the preferred or detrimental nature of amino acids at specific positions in the peptide sequences.	amino acids;angiotensin-converting enzyme inhibitors;angiotensins;bridging (networking);ctag2 gene;class;coefficient;computation;contain (action);homology (biology);homology modeling;peptide library;peptide sequence;semantics (computer science);therapeutic targets database;viz: the computer game	Mahesh R. Borkar;Raghuvir R. S. Pissurlenkar;Evans C. Coutinho	2013	Journal of computational chemistry	10.1002/jcc.23436	molecular biology;homology modeling;multiple sequence alignment;combinatorial chemistry	Comp.	9.441242591909985	-58.7683072511804	118641
f438cb97dd3daf6c5066a6fa9c56644767d7add7	influence relevance voting: an accurate and interpretable virtual high throughput screening method	high throughput screening;models molecular;structure activity relationship;reproducibility of results;drug evaluation preclinical;artificial intelligence;algorithms;informatics;databases factual;neural networks computer;tetrahydrofolate dehydrogenase;computer simulation;anti hiv agents	Given activity training data from high-throughput screening (HTS) experiments, virtual high-throughput screening (vHTS) methods aim to predict in silico the activity of untested chemicals. We present a novel method, the Influence Relevance Voter (IRV), specifically tailored for the vHTS task. The IRV is a low-parameter neural network which refines a k-nearest neighbor classifier by nonlinearly combining the influences of a chemical's neighbors in the training set. Influences are decomposed, also nonlinearly, into a relevance component and a vote component. The IRV is benchmarked using the data and rules of two large, open, competitions, and its performance compared to the performance of other participating methods, as well as of an in-house support vector machine (SVM) method. On these benchmark data sets, IRV achieves state-of-the-art results, comparable to the SVM in one case, and significantly better than the SVM in the other, retrieving three times as many actives in the top 1% of its prediction-sorted list. The IRV presents several other important advantages over SVMs and other methods: (1) the output predictions have a probabilistic semantic; (2) the underlying inferences are interpretable; (3) the training time is very short, on the order of minutes even for very large data sets; (4) the risk of overfitting is minimal, due to the small number of free parameters; and (5) additional information can easily be incorporated into the IRV architecture. Combined with its performance, these qualities make the IRV particularly well suited for vHTS.	artificial neural network;benchmark (computing);biological neural networks;experiment;high-throughput computing;high-throughput satellite;k-nearest neighbors algorithm;nearest neighbour algorithm;nonlinear system;overfitting;population parameter;relevance;rule (guideline);single linkage cluster analysis;sorting algorithm;support vector machine;test set;throughput;virtual screening	Sanjay Joshua Swamidass;Chloé-Agathe Azencott;Ting-Wan Lin;Hugo Gramajo;Shiou-Chuan Tsai;Pierre Baldi	2009	Journal of chemical information and modeling	10.1021/ci8004379	computer simulation;high-throughput screening;structure–activity relationship;chemistry;computer science;bioinformatics;artificial intelligence;machine learning;data mining;informatics;statistics	ML	9.973624976059565	-56.237997832923824	119165
0a84864197c1703394e9cb093063d87eb436b33b	fasttagger: an efficient algorithm for genome-wide tag snp selection using multi-marker linkage disequilibrium	software;human disease;efficient algorithm;chromosome mapping;genetic variation;association study;computational biology bioinformatics;dna mutational analysis;statistical power;human genome;prediction accuracy;algorithms;combinatorial libraries;computer appl in life sciences;linkage disequilibrium;genetic markers;polymorphism single nucleotide;single nucleotide polymorphism;microarrays;bioinformatics	Human genome contains millions of common single nucleotide polymorphisms (SNPs) and these SNPs play an important role in understanding the association between genetic variations and human diseases. Many SNPs show correlated genotypes, or linkage disequilibrium (LD), thus it is not necessary to genotype all SNPs for association study. Many algorithms have been developed to find a small subset of SNPs called tag SNPs that are sufficient to infer all the other SNPs. Algorithms based on the r2 LD statistic have gained popularity because r2 is directly related to statistical power to detect disease associations. Most of existing r2 based algorithms use pairwise LD. Recent studies show that multi-marker LD can help further reduce the number of tag SNPs. However, existing tag SNP selection algorithms based on multi-marker LD are both time-consuming and memory-consuming. They cannot work on chromosomes containing more than 100 k SNPs using length-3 tagging rules. We propose an efficient algorithm called FastTagger to calculate multi-marker tagging rules and select tag SNPs based on multi-marker LD. FastTagger uses several techniques to reduce running time and memory consumption. Our experiment results show that FastTagger is several times faster than existing multi-marker based tag SNP selection algorithms, and it consumes much less memory at the same time. As a result, FastTagger can work on chromosomes containing more than 100 k SNPs using length-3 tagging rules. FastTagger also produces smaller sets of tag SNPs than existing multi-marker based algorithms, and the reduction ratio ranges from 3%-9% when length-3 tagging rules are used. The generated tagging rules can also be used for genotype imputation. We studied the prediction accuracy of individual rules, and the average accuracy is above 96% when r2 ≥ 0.9. Generating multi-marker tagging rules is a computation intensive task, and it is the bottleneck of existing multi-marker based tag SNP selection methods. FastTagger is a practical and scalable algorithm to solve this problem.	chromosomes;computation;gain;genetic polymorphism;genotype;geo-imputation;inference;linkage disequilibrium;mental association;nitroprusside;numerous;rule (guideline);snp array;scalability;single nucleotide polymorphism;small;statistical imputation;subgroup;time complexity;variation (genetics);algorithm	Guimei Liu;Yue Wang;Limsoon Wong	2009		10.1186/1471-2105-11-66	single-nucleotide polymorphism;tag snp;linkage disequilibrium;biology;human genome;dna microarray;bioinformatics;genetic variation;genetic marker;statistical power;snp genotyping;genetics	Comp.	2.810345589045196	-52.65615880227565	119630
9ad6a9e6dc59a9b30f18cf4b49c7def97d132ce8	an algebra-based method for inferring gene regulatory networks	rna interference;simulation and modeling;gene knockout techniques;systems biology;gene regulatory networks;physiological cellular and medical topics;computational biology bioinformatics;models genetic;reproducibility of results;algorithms;bioinformatics	The inference of gene regulatory networks (GRNs) from experimental observations is at the heart of systems biology. This includes the inference of both the network topology and its dynamics. While there are many algorithms available to infer the network topology from experimental data, less emphasis has been placed on methods that infer network dynamics. Furthermore, since the network inference problem is typically underdetermined, it is essential to have the option of incorporating into the inference process, prior knowledge about the network, along with an effective description of the search space of dynamic models. Finally, it is also important to have an understanding of how a given inference method is affected by experimental and other noise in the data used. This paper contains a novel inference algorithm using the algebraic framework of Boolean polynomial dynamical systems (BPDS), meeting all these requirements. The algorithm takes as input time series data, including those from network perturbations, such as knock-out mutant strains and RNAi experiments. It allows for the incorporation of prior biological knowledge while being robust to significant levels of noise in the data used for inference. It uses an evolutionary algorithm for local optimization with an encoding of the mathematical models as BPDS. The BPDS framework allows an effective representation of the search space for algebraic dynamic models that improves computational performance. The algorithm is validated with both simulated and experimental microarray expression profile data. Robustness to noise is tested using a published mathematical model of the segment polarity gene network in Drosophila melanogaster. Benchmarking of the algorithm is done by comparison with a spectrum of state-of-the-art network inference methods on data from the synthetic IRMA network to demonstrate that our method has good precision and recall for the network reconstruction task, while also predicting several of the dynamic patterns present in the network. Boolean polynomial dynamical systems provide a powerful modeling framework for the reverse engineering of gene regulatory networks, that enables a rich mathematical structure on the model search space. A C++ implementation of the method, distributed under LPGL license, is available, together with the source code, at http://www.paola-vera-licona.net/Software/EARevEng/REACT.html .	anatomy, regional;boolean;c++;computation;dynamical system;ephrin type-b receptor 1, human;evolutionary algorithm;experiment;gene regulatory networks;gene expression profiling;gene regulatory network;immunoradiometric assays;inference;irma board;mathematical model;mathematical optimization;mathematical structure;mathematics;microarray;network topology;polynomial;precision and recall;rna interference;requirement;reverse engineering;scientific publication;source code;synthetic intelligence;systems biology;time series	Paola Vera-Licona;Abdul Salam Jarrah;Luis David García-Puente;John McGee;Reinhard C. Laubenbacher	2013		10.1186/1752-0509-8-37	biological network inference;biology;gene regulatory network;biological network;computer science;bioinformatics;rna interference;theoretical computer science;machine learning;systems biology	Comp.	6.573930410241272	-58.703017681933176	119631
534b5a57b705889f44d0c3506200bbf2510e1973	pandora, a pathway and network discovery approach based on common biological evidence	semantic similarity;software;integrated approach;systems biology;signal transduction;reseau;genetics;red;network topology;functional genomics;functional redundancy;positive predictive value;protein protein interaction;system biology;algorithms;databases factual;high throughput;computational biology;network;gene ontology	MOTIVATION Many biological phenomena involve extensive interactions between many of the biological pathways present in cells. However, extraction of all the inherent biological pathways remains a major challenge in systems biology. With the advent of high-throughput functional genomic techniques, it is now possible to infer biological pathways and pathway organization in a systematic way by integrating disparate biological information.   RESULTS Here, we propose a novel integrated approach that uses network topology to predict biological pathways. We integrated four types of biological evidence (protein-protein interaction, genetic interaction, domain-domain interaction and semantic similarity of Gene Ontology terms) to generate a functionally associated network. This network was then used to develop a new pathway finding algorithm to predict biological pathways in yeast. Our approach discovered 195 biological pathways and 31 functionally redundant pathway pairs in yeast. By comparing our identified pathways to three public pathway databases (KEGG, BioCyc and Reactome), we observed that our approach achieves a maximum positive predictive value of 12.8% and improves on other predictive approaches. This study allows us to reconstruct biological pathways and delineates cellular machinery in a systematic view.	algorithm;anatomy, regional;bio-informatics;biocyc database collection;bioinformatics;biological phenomena;databases;elfacos ow 100;fundamental interaction;gene ontology;gene regulatory network;high-throughput computing;inference;interactome;kegg;lithium;mandibular right second molar tooth;manuscripts;neoplasms;network topology;phenotype;positive predictive value of diagnostic test;reactome: a database of reactions, pathways and biological processes.;score;semantic similarity;synthetic intelligence;systems biology;throughput;web page;wu-ling-san;protein protein interaction	Kelvin Xi Zhang;B. F. Francis Ouellette	2010		10.1093/bioinformatics/btp701	protein–protein interaction;functional genomics;high-throughput screening;biopax : biological pathways exchange;biology;semantic similarity;computer science;bioinformatics;data mining;systems biology;network topology;signal transduction	Comp.	4.90577732519076	-57.081708078823716	119712
09e13104131758a3cd4f0b04c7e7952f327c0947	improving the efms quality by augmenting their representativeness in lp methods	flux modes;linear programming;metabolic networks;pathways and efms;representativeness and quality;systems biology	Although cellular metabolism has been widely studied, its fully comprehension is still a challenge. A main tool for this study is the analysis of meaningful pieces of knowledge called modes and, in particular, specially interesting classes of modes such as pathways and Elementary Flux Modes (EFMs). Its study often has to deal with issues such as the appearance of infeasibilities or the difficulty of finding representative enough sets of modes that are free of repetitions. Mode extraction methods usually incorporate strategies devoted to mitigate this phenomena but they still get a high ratio of repetitions in the set of solutions. This paper presents a proposal to improve the representativeness of the full set of metabolic reactions in the set of computed modes by penalizing the eventual high frequency of occurrence of some reactions during the extraction. This strategy can be applied to any linear programming based extraction existent method. Our strategy enhances the quality of a set of extracted EFMs favouring the presence of every reaction in it and improving the efficiency by mitigating the occurrence of repeated solutions. The new proposed strategy can complement other EFMs extraction methods based on linear programming. The obtained solutions are more likely to be diverse using less computing effort and improving the efficiency of the extraction.	class;complement system proteins;computation (action);extraction;linear programming;metabolic process, cellular;perseveration;solutions	José F. Hidalgo;Jose A. Egea;Francisco De Asís Guil Asensio;José M. García	2018		10.1186/s12918-018-0619-1		AI	3.191503434538076	-55.94815837499057	119917
a8cb980eaee18a92bcbf3c3edd676fea6c0cdf85	bayesian inference of protein–protein interactions from biological literature	bayes estimation;bayesian network;proteine;interaction moleculaire;molecular interaction;bayesian inference;bayes theorem;binding sites;estimacion bayes;interaccion molecular;proteins;inferencia;protein protein interaction;proteina;cross validation;protein interaction;protein interaction mapping;computational biology;protein;information storage and retrieval;inference;estimation bayes;biological process;databases protein	MOTIVATION Protein-protein interaction (PPI) extraction from published biological articles has attracted much attention because of the importance of protein interactions in biological processes. Despite significant progress, mining PPIs from literatures still rely heavily on time- and resource-consuming manual annotations.   RESULTS In this study, we developed a novel methodology based on Bayesian networks (BNs) for extracting PPI triplets (a PPI triplet consists of two protein names and the corresponding interaction word) from unstructured text. The method achieved an overall accuracy of 87% on a cross-validation test using manually annotated dataset. We also showed, through extracting PPI triplets from a large number of PubMed abstracts, that our method was able to complement human annotations to extract large number of new PPIs from literature.   AVAILABILITY Programs/scripts we developed/used in the study are available at http://stat.fsu.edu/~jinfeng/datasets/Bio-SI-programs-Bayesian-chowdhary-zhang-liu.zip.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	abstract summary;acceptance testing;bayesian network;bioinformatics;complement system proteins;cross-validation (statistics);inference;literature;name;pixel density;proton pump inhibitors;pubmed;scientific publication;silo (dataset);triplet state;protein protein interaction;triangulation	Rajesh Chowdhary;Jinfeng Zhang;Jun S. Liu	2009	Bioinformatics	10.1093/bioinformatics/btp245	protein–protein interaction;biology;computer science;bioinformatics;binding site;machine learning;bayesian network;data mining;bayes' theorem;bayesian inference;biological process;cross-validation;statistics	Comp.	5.452487139209479	-55.33682950793436	119986
52d5c22abadf1878d3df71ae912fc5af5d6022c2	funfold: an improved automated method for the prediction of ligand binding residues using 3d models of proteins	software;fold recognition;functional annotation;automated visual inspection;amino acid sequence;web interface;statistical significance;ligand binding;binding site;binding sites;endnotes;computational biology bioinformatics;models molecular;3d model;cluster analysis;internet;proteins;protein conformation;structural homology protein;sequence homology amino acid;protein binding;algorithms;pubications;matthews correlation coefficient;function prediction;combinatorial libraries;computer appl in life sciences;group testing;microarrays;bioinformatics	The accurate prediction of ligand binding residues from amino acid sequences is important for the automated functional annotation of novel proteins. In the previous two CASP experiments, the most successful methods in the function prediction category were those which used structural superpositions of 3D models and related templates with bound ligands in order to identify putative contacting residues. However, whilst most of this prediction process can be automated, visual inspection and manual adjustments of parameters, such as the distance thresholds used for each target, have often been required to prevent over prediction. Here we describe a novel method FunFOLD, which uses an automatic approach for cluster identification and residue selection. The software provided can easily be integrated into existing fold recognition servers, requiring only a 3D model and list of templates as inputs. A simple web interface is also provided allowing access to non-expert users. The method has been benchmarked against the top servers and manual prediction groups tested at both CASP8 and CASP9. The FunFOLD method shows a significant improvement over the best available servers and is shown to be competitive with the top manual prediction groups that were tested at CASP8. The FunFOLD method is also competitive with both the top server and manual methods tested at CASP9. When tested using common subsets of targets, the predictions from FunFOLD are shown to achieve a significantly higher mean Matthews Correlation Coefficient (MCC) scores and Binding-site Distance Test (BDT) scores than all server methods that were tested at CASP8. Testing on the CASP9 set showed no statistically significant separation in performance between FunFOLD and the other top server groups tested. The FunFOLD software is freely available as both a standalone package and a prediction server, providing competitive ligand binding site residue predictions for expert and non-expert users alike. The software provides a new fully automated approach for structure based function prediction using 3D models of proteins.	3d modeling;amino acid sequence;amino acids;annotation;benchmark (computing);black–derman–toy model;boolean algebra;casp;clinical use template;experiment;ligand binding;ligands;matthews correlation coefficient;server (computer);server (computing);threading (protein sequence);user interface;visual inspection;while;caspase-8;caspase-9	Daniel B. Roche;Stuart J. Tetchner;Liam James McGuffin	2011		10.1186/1471-2105-12-160	biology;computer science;bioinformatics;binding site;machine learning;data mining	Comp.	9.155480931492523	-56.32561542421391	120009
31188a27a3a9fc0839deb00d5f8b5e38725b8c2d	constraint network analysis (cna): a python software package for efficiently linking biomacromolecular structure, flexibility, (thermo-)stability, and function		"""For deriving maximal advantage from information on biomacromolecular flexibility and rigidity, results from rigidity analyses must be linked to biologically relevant characteristics of a structure. Here, we describe the Python-based software package Constraint Network Analysis (CNA) developed for this task. CNA functions as a front- and backend to the graph-based rigidity analysis software FIRST. CNA goes beyond the mere identification of flexible and rigid regions in a biomacromolecule in that it (I) provides a refined modeling of thermal unfolding simulations that also considers the temperature-dependence of hydrophobic tethers, (II) allows performing rigidity analyses on ensembles of network topologies, either generated from structural ensembles or by using the concept of fuzzy noncovalent constraints, and (III) computes a set of global and local indices for quantifying biomacromolecular stability. This leads to more robust results from rigidity analyses and extends the application domain of rigidity analyses in that phase transition points (""""melting points"""") and unfolding nuclei (""""structural weak spots"""") are determined automatically. Furthermore, CNA robustly handles small-molecule ligands in general. Such advancements are important for applying rigidity analysis to data-driven protein engineering and for estimating the influence of ligand molecules on biomacromolecular stability. CNA maintains the efficiency of FIRST such that the analysis of a single protein structure takes a few seconds for systems of several hundred residues on a single core. These features make CNA an interesting tool for linking biomacromolecular structure, flexibility, (thermo-)stability, and function. CNA is available from http://cpclab.uni-duesseldorf.de/software for nonprofit organizations."""	application domain;certified nurse assistant;estimated;exanthema;ligands;maximal set;muscle rigidity;netware;network topology;protein engineering;python;simulation;unfolding (dsp implementation)	Christopher Pfleger;Prakash Chandra Rathi;Doris L. Klein;Sebastian Radestock;Holger Gohlke	2013	Journal of chemical information and modeling	10.1021/ci400044m	computational science;computer science;bioinformatics;operating system	Comp.	3.971861686432258	-57.85778306937417	120131
35ba589e292044bfe9e41598749cd0a76c9cbf13	high dimensional latent gaussian copula model for mixed data in imaging genetics		Recent advances in imaging genetics combine different types of data including medical images like functional MRI images and genetic data like single nucleotide polymorphisms (SNPs). Many studies have proved that several mental diseases such as autism, ADHD, schizophrenia are affected by gene mutations. Understanding the complex interactions among these heterogeneous datasets may give rise to a new perspective for diseases diagnosis and prevention. In statistics, various graphical models have been proposed for the study of association networks with continuous data, binary data, and count data as well as the mixture of them. However, limited efforts have been made for the multinomial case, which has a direct application for SNP data. Therefore, in this paper, we propose a latent Gaussian copula model for mixed data containing multinomial components, which fills a vacancy of graphical models in imaging genetics. The performance of the proposed methods is first numerically assessed through simulation studies. Then it is validated with fMRI and SNP data collected by the Mind Clinical Imaging Consortium (MCIC) for a schizophrenia study.	binary data;consortium;count data;graphical model;graphical user interface;interaction;multinomial logistic regression;numerical analysis;simulation	Aiying Zhang;Jian Fang;Vince D. Calhoun;Yu-Ping Wang	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363533	count data;single-nucleotide polymorphism;data type;copula (probability theory);artificial intelligence;imaging genetics;pattern recognition;computer science;multinomial distribution;graphical model;binary data	ML	7.14827588131416	-52.601484799753734	120246
ca46972de4d8655da4cc3cf8dd27a0a07e6975f3	predicting dna recognition by cys2his2 zinc finger proteins	dna;zinc fingers;cysteine;structural model;zinc finger protein;dna binding proteins;databases nucleic acid;early growth response protein 1;nucleotides;amino acid;amino acid sequence;histidine;dna binding;models biological;binding site;zinc finger;transcription factor;reproducibility of results;protein dna interaction;binding affinity;support vector machine;base sequence;computational biology;oligonucleotide array sequence analysis	MOTIVATION Cys(2)His(2) zinc finger (ZF) proteins represent the largest class of eukaryotic transcription factors. Their modular structure and well-conserved protein-DNA interface allow the development of computational approaches for predicting their DNA-binding preferences even when no binding sites are known for a particular protein. The 'canonical model' for ZF protein-DNA interaction consists of only four amino acid nucleotide contacts per zinc finger domain.   RESULTS We present an approach for predicting ZF binding based on support vector machines (SVMs). While most previous computational approaches have been based solely on examples of known ZF protein-DNA interactions, ours additionally incorporates information about protein-DNA pairs known to bind weakly or not at all. Moreover, SVMs with a linear kernel can naturally incorporate constraints about the relative binding affinities of protein-DNA pairs; this type of information has not been used previously in predicting ZF protein-DNA binding. Here, we build a high-quality literature-derived experimental database of ZF-DNA binding examples and utilize it to test both linear and polynomial kernels for predicting ZF protein-DNA binding on the basis of the canonical binding model. The polynomial SVM outperforms previously published prediction procedures as well as the linear SVM. This may indicate the presence of dependencies between contacts in the canonical binding model and suggests that modification of the underlying structural model may result in further improved performance in predicting ZF protein-DNA binding. Overall, this work demonstrates that methods incorporating information about non-binding and relative binding of protein-DNA pairs have great potential for effective prediction of protein-DNA interactions.   AVAILABILITY An online tool for predicting ZF DNA binding is available at http://compbio.cs.princeton.edu/zf/.	amino acids;binding sites;canonical model;computation;dna binding site;largest;polynomial;protein–dna interaction;scientific publication;support vector machine;transcription factor;transcription (software);zermelo–fraenkel set theory	Anton V. Persikov;Robert Osada;M T Singh	2009	Bioinformatics	10.1093/bioinformatics/btn580	biology;biochemistry;zinc finger;bioinformatics;genetics	Comp.	9.587268267507197	-58.002471586077476	120280
ecb74d0c351570185ffa2e740be1d8cce0f15163	a haplotype-based framework for group-wise transmission/disequilibrium tests for rare variant association analysis		MOTIVATION A major focus of current sequencing studies for human genetics is to identify rare variants associated with complex diseases. Aside from reduced power of detecting associated rare variants, controlling for population stratification is particularly challenging for rare variants. Transmission/disequilibrium tests (TDT) based on family designs are robust to population stratification and admixture, and therefore provide an effective approach to rare variant association studies to eliminate spurious associations. To increase power of rare variant association analysis, gene-based collapsing methods become standard approaches for analyzing rare variants. Existing methods that extend this strategy to rare variants in families usually combine TDT statistics at individual variants and therefore lack the flexibility of incorporating other genetic models.   RESULTS In this study, we describe a haplotype-based framework for group-wise TDT (gTDT) that is flexible to encompass a variety of genetic models such as additive, dominant and compound heterozygous (CH) (i.e. recessive) models as well as other complex interactions. Unlike existing methods, gTDT constructs haplotypes by transmission when possible and inherently takes into account the linkage disequilibrium among variants. Through extensive simulations we showed that type I error was correctly controlled for rare variants under all models investigated, and this remained true in the presence of population stratification. Under a variety of genetic models, gTDT showed increased power compared with the single marker TDT. Application of gTDT to an autism exome sequencing data of 118 trios identified potentially interesting candidate genes with CH rare variants.   AVAILABILITY AND IMPLEMENTATION We implemented gTDT in C++ and the source code and the detailed usage are available on the authors' website (https://medschool.vanderbilt.edu/cgg).   CONTACT bingshan.li@vanderbilt.edu or wei.chen@chp.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	autistic disorder;bioinformatics;biopolymer sequencing;c++;candidate disease gene;genetic algorithm;haplotypes;interaction;linkage (software);linkage disequilibrium;mental association;sensor;simulation;source code;stratification;time-domain reflectometry;utility functions on indivisible goods;whole exome sequencing	Rui Chen;Qiang Wei;Xiaowei Zhan;Xue Zhong;James S. Sutcliffe;Nancy J. Cox;Edwin H. Cook;Chun Li;Wei Chen;Bingshan Li	2015	Bioinformatics	10.1093/bioinformatics/btu860	biology;bioinformatics;genetics	Comp.	3.1487557317345516	-53.3551762049271	120345
e99e8595756c6ce343b18074d3ff166357e2883d	data mining in genome wide association studies	genome wide association study;data mining	The genetic basis for some human diseases, in which one or a few genome regions increase the probability of acquiring the disease, is fairly well understood. For example, the risk for cystic fibrosis is linked to particular genomic regions. Identifying the genetic basis of more common diseases such as diabetes has proven to be more difficult, because many genome regions apparently are involved, and genetic effects are thought to depend in unknown ways on other factors, called covariates, such as diet and other environmental factors (Goldstein and Cavalleri, 2005). Genome-wide association studies (GWAS) aim to discover the genetic basis for a given disease. The main goal in a GWAS is to identify genetic variants, single nucleotide polymorphisms (SNPs) in particular, that show association with the phenotype, such as “disease present” or “disease absent” either because they are causal, or more likely, because they are statistically correlated with an unobserved causal variant (Goldstein and Cavalleri, 2005). A GWAS can analyze “by DNA site” or “by multiple DNA sites. ” In either case, data mining tools (Tachmazidou, Verzilli, and De Lorio, 2007) are proving to be quite useful for understanding the genetic causes for common diseases.	causal filter;data mining	Tom Burr	2009			phylogenetic tree;phenotype;haplotype;genome-wide association study;genetics;pearson's chi-squared test;biology;bioinformatics;allele	ML	3.2954715569562194	-55.58851356275261	121145
43bd6462a76beedee97cb0a3adf2d59e868638bc	a high-order representation and classification method for transcription factor binding sites recognition in escherichia coli	transcription factor binding sites;classification;partial least squares;tensor;machine learning;computational biology	BACKGROUND Identifying transcription factors binding sites (TFBSs) plays an important role in understanding gene regulatory processes. The underlying mechanism of the specific binding for transcription factors (TFs) is still poorly understood. Previous machine learning-based approaches to identifying TFBSs commonly map a known TFBS to a one-dimensional vector using its physicochemical properties. However, when the dimension-sample rate is large (i.e., number of dimensions/number of samples), concatenating different physicochemical properties to a one-dimensional vector not only is likely to lose some structural information, but also poses significant challenges to recognition methods.   MATERIALS AND METHOD In this paper, we introduce a purely geometric representation method, tensor (also called multidimensional array), to represent TFs using their physicochemical properties. Accompanying the multidimensional array representation, we also develop a tensor-based recognition method, tensor partial least squares classifier (abbreviated as TPLSC). Intuitively, multidimensional arrays enable borrowing more information than one-dimensional arrays. The performance of each method is evaluated by average F-measure on 51 Escherichia coli TFs from RegulonDB database.   RESULTS In our first experiment, the results show that multiple nucleotide properties can obtain more power than dinucleotide properties. In the second experiment, the results demonstrate that our method can gain increased prediction power, roughly 33% improvements more than the best result from existing methods.   CONCLUSION The representation method for TFs is an important step in TFBSs recognition. We illustrate the benefits of this representation on real data application via a series of experiments. This method can gain further insights into the mechanism of TF binding and be of great use for metabolic engineering applications.	binding sites;classification;concatenation;dna binding site;dimensions;dinucleoside phosphates;experiment;feature selection;feature vector;futures studies;gper protein, human;gene regulatory network;geodetic datum;image processing;machine learning;metabolic engineering;molecular dynamics;motif;nucleotides;overfitting;partial least squares regression;protein domain;regulondb;sampling (signal processing);transcription (software);benefit;transcription factor binding	Shiquan Sun;Xiongpan Zhang;Qinke Peng	2017	Artificial intelligence in medicine	10.1016/j.artmed.2016.11.004	tensor;biological classification;computer science;bioinformatics;artificial intelligence;machine learning;data mining;partial least squares regression;dna binding site;statistics	AI	9.708872931913914	-54.09041641102216	121189
fef7fe6e52f30d677d6ef54c398c8d1df2610e7b	improving the analysis of designed studies by combining statistical modelling with study design information	apolipoproteins;animals;study design;liver;metabolomics;partial least square regression;statistical method;statistical modelling;biology;intervention study;universiteitsbibliotheek;statistical model;metabolites;computational biology bioinformatics;transgenic mice;serum amyloid a;statistical analysis;selection combining;relational model;life sciences;amyloid;biological systems;models statistical;blood chemistry;algorithms;design;humans;databases factual;combinatorial libraries;computer appl in life sciences;models;biomedical research;anova analysis of variance;microarrays;bioinformatics	In the fields of life sciences, so-called designed studies are used for studying complex biological systems. The data derived from these studies comply with a study design aimed at generating relevant information while diminishing unwanted variation (noise). Knowledge about the study design can be used to decompose the total data into data blocks that are associated with specific effects. Subsequent statistical analysis can be improved by this decomposition if these are applied on selected combinations of effects. The benefit of this approach was demonstrated with an analysis that combines multivariate PLS (Partial Least Squares) regression with data decomposition from ANOVA (Analysis of Variance): ANOVA-PLS. As a case, a nutritional intervention study is used on Apoliprotein E3-Leiden (APOE3Leiden) transgenic mice to study the relation between liver lipidomics and a plasma inflammation marker, Serum Amyloid A. The ANOVA-PLS performance was compared to PLS regression on the non-decomposed data with respect to the quality of the modelled relation, model reliability, and interpretability. It was shown that ANOVA-PLS leads to a better statistical model that is more reliable and better interpretable compared to standard PLS analysis. From a following biological interpretation, more relevant metabolites were derived from the model. The concept of combining data composition with a subsequent statistical analysis, as in ANOVA-PLS, is however not limited to PLS regression in metabolomics but can be applied for many statistical methods and many different types of data.	analysis of variance;biological science disciplines;biological system;liver diseases;metabolite;metabolomics;papillon-lefevre disease;partial least squares regression;plasma active;statistical model	Uwe Thissen;Suzan Wopereis;Sjoerd A. A. van den Berg;Ivana Bobeldijk;Robert Kleemann;Teake Kooistra;Ko Willems van Dijk;Ben van Ommen;Age K. Smilde	2008	BMC Bioinformatics	10.1186/1471-2105-10-52	statistical model;biology;computer science;bioinformatics;data science;metabolomics	HCI	6.984393994507363	-55.1631361784234	121436
a03df265d798db196fe161f4b68cc2d2cd995df0	a network-based meta-analysis strategy for the selection of potential gene modules in type 2 diabetes	meta analysis;candidate gene markers;system biology;type 2 diabetes;gene co expression network analysis	We propose an integrative network-based meta-analysis strategy to enable the selection of potential gene markers for one of the most prevalent diseases worldwide, Type 2 diabetes (T2D), formally known as the non-insulin dependent diabetes mellitus. Comprehensive elucidation of the genes regulated through this disorder and their wiring will provide a more complete understanding of the overall gene network topology and their role in disease progression and treatment. The proposed strategy was able to find conservative gene modules which play interesting role in T2D, pointing to gene markers such as NR3C1, ADIPOR1 and CDC123. Network-based meta-analysis by enumerating conserved gene modules pave a practical approach to the identification of candidate gene markers across several related transcriptomic studies. The NEMESIS R pipeline for network-based meta-analysis is also provided.	nsa product types	Ronnie Alves;Marcus Mendes;Diego Bonnato	2013		10.1007/978-3-319-02624-4_15	biology;meta-analysis;computer science;bioinformatics;genetics;systems biology	NLP	5.639158195402298	-58.15047977020346	121439
c55724cd30e7a99aa16e325dc47a1aab76756f17	a global structural em algorithm for a model of cancer progression	bioinformatics and systems biology;bioinformatik och systembiologi;datavetenskap datalogi;medical biotechnology;computer science;medicinsk bioteknologi	Cancer has complex patterns of progression that include converging as well as diverging progressional pathways. Vogelstein’s path model of colon cancer was a pioneering contribution to cancer research. Since then, several attempts have been made at obtaining mathematical models of cancer progression, devising learning algorithms, and applying these to cross-sectional data. Beerenwinkel et al. provided, what they coined, EM-like algorithms for Oncogenetic Trees (OTs) and mixtures of such. Given the small size of current and future data sets, it is important to minimize the number of parameters of a model. For this reason, we too focus on tree-based models and introduce Hidden-variable Oncogenetic Trees (HOTs). In contrast to OTs, HOTs allow for errors in the data and thereby provide more realistic modeling. We also design global structural EM algorithms for learning HOTs and mixtures of HOTs (HOT-mixtures). The algorithms are global in the sense that, during the M-step, they find a structure that yields a global maximum of the expected complete log-likelihood rather than merely one that improves it. The algorithm for single HOTs performs very well on reasonable-sized data sets, while that for HOT-mixtures requires data sets of sizes obtainable only with tomorrow’s more cost-efficient technologies.	colon classification;color gradient;cost efficiency;cross-sectional data;expectation–maximization algorithm;hidden variable theory;machine learning;mathematical model;maxima and minima	Ali Tofigh;Erik Sjölund;Mattias Höglund;Jens Lagergren	2011			computer science;bioinformatics;machine learning;data mining;mathematics;statistics	ML	5.149974257911203	-55.303281481909956	122331
9e30fa6ee9f50afa0f68b531bf5b20050901f84f	fine classification of human gut microbiota by using hierarchical clustering approach	hierarchical clustering;enterotype;gut micobiome	Human microbiota account for 1-3 % total human body mass. The gastro-intestinal tract, especially the gut, is rich in different microorganisms, which play important role in our health and diseases. Understanding our gut microbiome may help us to increase the precision of disease prediction and treatment. Traditional culture-based methods are time-consuming, expensive and incomplete. The 16S rRNA metagenomic approach provided a simple and culture-independent way to get more information of gut microbiota. In this study, we analyzed 30 human stool microbiome samples. The hierarchical clustering method was applied to classify the enterotypes. The results showed that: (1) There is a positive correlation between the original NGS data volume, rRNA read number and microbiota diversity. (2) Some bacterial genera presented dominantly in human gut, so that a sufficient sequencing depth is important to identify the minor microbiota component. (3) Bacteroides, Lachnospiracea_incertae_sedis and Ruminococcus2 are the most frequently presented genera. Bacteroides, Prevotella and Alistipes are the most abundant genera. (4) Clustering result showed that there are four main enterotypes: Parabacteroides, Prevotella, Ruminococcus, and Bacterioides. We can still divide Parabacteroides into 3 subclasses according to the composition of bacteria.	cluster analysis;communications satellite;genera;hierarchical clustering;human body weight;metagenomics;tract (literature)	Tzu-Fan Chen;Rong-Ming Chen;Jeffrey J. P. Tsai;Rouh-Mei Hu	2016	2016 IEEE 16th International Conference on Bioinformatics and Bioengineering (BIBE)	10.1109/BIBE.2016.33	biology;computer science;bioinformatics;machine learning;hierarchical clustering;microbiology;enterotype;statistics	Visualization	6.542250550862631	-54.412944812032976	122467
62dcfb6a4da2ac6c69c89449252ad100bce27328	abduction based drug target discovery using boolean control network		A major challenge in cancer research is to determine the genetic mutations causing the cancerous phenotype of cells and conversely, the actions of drugs initiating programmed cell death in cancer cells. However, such a challenge is compounded by the complexity of the genotype-phenotype relationship and therefore, requires to relate the molecular effects of mutations and drugs to their consequences on cellular phenotypes. Discovering these complex relationships is at the root of new molecular drug targets discovery and cancer etiology investigation. In their elucidation, computational methods play a major role for the inference of the molecular causal actions from molecular and biological networks data analysis. In this article, we propose a theoretical framework where mutations and drug actions are seen as topological perturbations/actions on molecular networks inducing cell phenotype reprogramming. The framework is based on Boolean control networks where the topological network actions are modelled by control parameters. We present a new algorithm using abductive reasoning principles inferring the minimal causal topological actions leading to an expected behavior at stable state. The framework is validated on a model of network regulating the proliferation/apoptosis switch in breast cancer by automatically discovering driver genes and finding drug targets.		Célia Biane;Franck Delaplace	2017		10.1007/978-3-319-67471-1_4	cancer cell;reprogramming;computational biology;theoretical computer science;drug;computer science;phenotype;abductive reasoning;biological network;inference;cancer etiology;artificial intelligence	ML	6.372018010179744	-58.81693078048067	122768
5813b17ac830d2e02d2638758dc472fa1e25eee5	a comparative study of survival models for breast cancer prognostication based on microarray data: does a single gene beat them all?	gene expression profile;microarray data;prediction method;breast neoplasms;female;seno;cancer;tumor maligno;estudio comparativo;sobrevivencia;gen;bioinformatique;models biological;data mining;breast;microreseau;etude comparative;modelo;microarreglo;survival analysis;comparative study;gene;sein;clinical outcome;survie;algorithms;tumeur maligne;modele;microarray;humans;cross validation;bioinformatica;survival;data analysis techniques;phenotype;breast cancer;models;gene expression profiling;oligonucleotide array sequence analysis;malignant tumor;biological process;bioinformatics	MOTIVATION Survival prediction of breast cancer (BC) patients independently of treatment, also known as prognostication, is a complex task since clinically similar breast tumors, in addition to be molecularly heterogeneous, may exhibit different clinical outcomes. In recent years, the analysis of gene expression profiles by means of sophisticated data mining tools emerged as a promising technology to bring additional insights into BC biology and to improve the quality of prognostication. The aim of this work is to assess quantitatively the accuracy of prediction obtained with state-of-the-art data analysis techniques for BC microarray data through an independent and thorough framework.   RESULTS Due to the large number of variables, the reduced amount of samples and the high degree of noise, complex prediction methods are highly exposed to performance degradation despite the use of cross-validation techniques. Our analysis shows that the most complex methods are not significantly better than the simplest one, a univariate model relying on a single proliferation gene. This result suggests that proliferation might be the most relevant biological process for BC prognostication and that the loss of interpretability deriving from the use of overcomplex methods may be not sufficiently counterbalanced by an improvement of the quality of prediction.   AVAILABILITY The comparison study is implemented in an R package called survcomp and is available from http://www.ulb.ac.be/di/map/bhaibeka/software/survcomp/.	biological processes;cross reactions;cross-validation (statistics);data mining;elegant degradation;genetic heterogeneity;mammary neoplasms;microarray;patients;r language	Benjamin Haibe-Kains;Christine Desmedt;Christos Sotiriou;Gianluca Bontempi	2008	Bioinformatics	10.1093/bioinformatics/btn374	biology;bioinformatics;data mining;cancer	Comp.	6.725053151430813	-52.64494259570671	122787
a14bba637434b0f3cbdcf82ae2ebb65659bb3dd5	integrating diverse biological and computational sources for reliable protein-protein interactions	software;saccharomyces cerevisiae;saccharomyces cerevisiae proteins;false negative;computational biology bioinformatics;high throughput screening;reproducibility of results;protein protein interaction;algorithms;combinatorial libraries;protein interaction;false positive;protein interaction mapping;computational biology;computer appl in life sciences;microarrays;bioinformatics	Protein-protein interactions (PPIs) play important roles in various cellular processes. However, the low quality of current PPI data detected from high-throughput screening techniques has diminished the potential usefulness of the data. We need to develop a method to address the high data noise and incompleteness of PPI data, namely, to filter out inaccurate protein interactions (false positives) and predict putative protein interactions (false negatives). In this paper, we proposed a novel two-step method to integrate diverse biological and computational sources of supporting evidence for reliable PPIs. The first step, interaction binning or InterBIN, groups PPIs together to more accurately estimate the likelihood (Bin-Confidence score) that the protein pairs interact for each biological or computational evidence source. The second step, interaction classification or InterCLASS, integrates the collected Bin-Confidence scores to build classifiers and identify reliable interactions. We performed comprehensive experiments on two benchmark yeast PPI datasets. The experimental results showed that our proposed method can effectively eliminate false positives in detected PPIs and identify false negatives by predicting novel yet reliable PPIs. Our proposed method also performed significantly better than merely using each of individual evidence sources, illustrating the importance of integrating various biological and computational sources of data and evidence.	benchmark (computing);chamaecyparis lawsoniana;computation (action);experiment;high-throughput computing;pixel density;product binning;proton pump inhibitors;throughput;protein protein interaction	Min Wu;Xiaoli Li;Hon Nian Chua;Chee Keong Kwoh;See-Kiong Ng	2010		10.1186/1471-2105-11-S7-S8	protein–protein interaction;high-throughput screening;biology;dna microarray;type i and type ii errors;computer science;bioinformatics;data science;data mining	Comp.	4.8849946368328245	-55.499248110866716	122807
2d7f3037eea1cdf954e1237b484c2529006e2d01	tilemap: create chromosomal map of tiling array hybridizations	false discovery rate;empirical bayes;high resolution;hidden markov model;complex multiplication;moving average;spatial pattern;protein binding;variance estimation	MOTIVATION Tiling array is a new type of microarray that can be used to survey genomic transcriptional activities and transcription factor binding sites at high resolution. The goal of this paper is to develop effective statistical tools to identify genomic loci that show transcriptional or protein binding patterns of interest.   RESULTS A two-step approach is proposed and is implemented in TileMap. In the first step, a test-statistic is computed for each probe based on a hierarchical empirical Bayes model. In the second step, the test-statistics of probes within a genomic region are used to infer whether the region is of interest or not. Hierarchical empirical Bayes model shrinks variance estimates and increases sensitivity of the analysis. It allows complex multiple sample comparisons that are essential for the study of temporal and spatial patterns of hybridization across different experimental conditions. Neighboring probes are combined through a moving average method (MA) or a hidden Markov model (HMM). Unbalanced mixture subtraction is proposed to provide approximate estimates of false discovery rate for MA and model parameters for HMM.   AVAILABILITY TileMap is freely available at http://biogibbs.stanford.edu/~jihk/TileMap/index.htm.   SUPPLEMENTARY INFORMATION http://biogibbs.stanford.edu/~jihk/TileMap/index.htm (includes coloured versions of all figures).	approximation algorithm;binding sites;crossbreeding;estimated;hidden markov model;inference;markov chain;microarray;new type;nucleic acid hybridization;sample variance;transcription factor;tiling array;tiling window manager;transcription (software);transcription, genetic;version	Hongkai Ji;Wing Hung Wong	2005	Bioinformatics	10.1093/bioinformatics/bti593	econometrics;plasma protein binding;false discovery rate;common spatial pattern;image resolution;complex multiplication;computer science;bioinformatics;mathematics;moving average;hidden markov model;statistics	Comp.	3.367833995242229	-53.12060926278735	122881
be4b185d77ab1fd22c9d16e69fa33eeee2bd8776	protquant: a tool for the label-free quantification of mudpit proteomics data	software;data interpretation statistical;user interface;amino acid sequence;mass spectrometry;data management;ease of use;computational biology bioinformatics;stable isotope;proteins;differential expression;quantitative analysis;graphic user interface;artificial intelligence;algorithms;pattern recognition automated;protein expression;molecular sequence data;missing data;missing values;combinatorial libraries;false positive;high throughput;computer appl in life sciences;sequence analysis protein;databases protein;microarrays;bioinformatics;peptide mapping	"""Effective and economical methods for quantitative analysis of high throughput mass spectrometry data are essential to meet the goals of directly identifying, characterizing, and quantifying proteins from a particular cell state. Multidimensional Protein Identification Technology (MudPIT) is a common approach used in protein identification. Two types of methods are used to detect differential protein expression in MudPIT experiments: those involving stable isotope labelling and the so-called label-free methods. Label-free methods are based on the relationship between protein abundance and sampling statistics such as peptide count, spectral count, probabilistic peptide identification scores, and sum of peptide Sequest XCorr scores (ΣXCorr). Although a number of label-free methods for protein quantification have been described in the literature, there are few publicly available tools that implement these methods. We describe ProtQuant, a Java-based tool for label-free protein quantification that uses the previously published ΣXCorr method for quantification and includes an improved method for handling missing data. ProtQuant was designed for ease of use and portability for the bench scientist. It implements the ΣXCorr method for label free protein quantification from MudPIT datasets. ProtQuant has a graphical user interface, accepts multiple file formats, is not limited by the size of the input files, and can process any number of replicates and any number of treatments. In addition,ProtQuant implements a new method for dealing with missing values for peptide scores used for quantification. The new algorithm, called ΣXCorr*, uses """"below threshold"""" peptide scores to provide meaningful non-zero values for missing data points. We demonstrate that ΣXCorr* produces an average reduction in false positive identifications of differential expression of 25% compared to ΣXCorr. ProtQuant is a tool for protein quantification built for multi-platform use with an intuitive user interface. ProtQuant efficiently and uniquely performs label-free quantification of protein datasets produced with Sequest and provides the user with facilities for data management and analysis. Importantly, ProtQuant is available as a self-installing executable for the Windows environment used by many bench scientists."""	accepting of extremity;arabic numeral 0;data point;executable;experiment;graphical user interface;handling (psychology);isotopes;java programming language;microsoft windows;missing data;newton's method;numerous;proteomics;quantitation;sampling (signal processing);sampling - surgical action;scientific publication;sequest scoring engine;spectrometry;throughput;usability;user interface device component;algorithm;format;protein expression;stable isotope	Susan M. Bridges;G. Bryce Magee;Nan Wang;W. Paul Williams;Shane C. Burgess;Bindu Nanduri	2007	BMC Bioinformatics	10.1186/1471-2105-8-S7-S24	biology;mass spectrometry;missing data;data management;computer science;bioinformatics;data science;data mining;genetics	Comp.	3.989375245388448	-53.39410816740655	123235
f9ab6aa1089bbf95e22db7bb1c69f387af3b8cd7	community detection from genomic datasets across human cancers	genomics;cancer;lungs;colon;tumors;bioinformatics	Cancers originating from different organs can show similar genomic alterations whereas cancers originating from the same organ can vary across patients. Therefore cancer stratification that does not depend on the tissue of origin can play an important role to better understand cancers having similar genomic patterns irrespective of their origins. In this work, we formulated the problem as a weighted graph and communities were found using a modularity maximization based graph clustering method. We classified 3,199 subjects from twelve different cancer types into five clusters. The five communities show significantly different survival rate curves. The distribution of tumor types against communities shows that lung, colon and rectum adenocarcinoma cluster together, whereas breast and ovarian cancers form another cluster.	cluster analysis;colon classification;computer cluster;expectation–maximization algorithm	Nandinee Fariah Haq;Z. Jane Wang	2016	2016 IEEE Global Conference on Signal and Information Processing (GlobalSIP)	10.1109/GlobalSIP.2016.7906021	biology;pathology;bioinformatics;oncology	Visualization	5.959946712435225	-56.53936556023948	123454
394d0ed4eaa1d2409cba3b479106ed9d96c9aaea	finding patterns in biochemical reaction networks	systems biology;graph database;pattern detection;subgraph mining;biochemical reaction networks;knowledge discovery	Computational models in biology encode molecular and cell biological processes. Many of them can be represented as biochemical reaction networks. Studying such networks, one is often interested in systems that share similar reactions and mechanisms. Typical goals are to understand the parts of a model, to identify reoccurring patterns, and to find biologically relevant motifs. The large number of models are available for such a search, but also the large size of models require automated methods. Specifically the generic problem of finding patterns in large networks is computationally hard. As a consequence, only partial solutions for a structural analysis of models exist. Here we introduce a tool chain that identifies reoccurring patterns in biochemical reaction networks. We started this work with an evaluation of algorithms for the identification of frequent subgraphs. Then, we created graph representations of existing SBML models and ran the most suitable algorithm on the data. The result was a list of reaction patterns together with statistics about the occurrence of each pattern in the data set. The approach was validated with 575 SBML models from the curated branch of BioModels. We analysed how the resulting patterns confirm with expectations from the literature and from previous model statistics. In the future, the identified patterns can serve as a tool to measure the similarity of models.	algorithm;biomodels database;computation;computational model;encode;sbml;structural analysis;toolchain	Ron Henkel;Fabienne Lambusch;Olaf Wolkenhauer;Kurt Sandkuhl;Christian Rosenke;Dagmar Waltemath	2016	PeerJ PrePrints	10.7287/peerj.preprints.1479v2	computer science;bioinformatics;machine learning;data mining;systems biology;graph database	ML	2.9968471372122556	-57.72210706774207	123609
a5e29b65380bed34361945ecdfad4fab9e4d5fb8	disease-specific integration of omics data to guide functional validation of genetic associations		Unbiased genetic association studies, including genome-wide association and whole-genome sequencing studies, have uncovered many novel disease-associated variants. Relatively few of these associated regions, however, have led to insights that are biologically mechanistic or clinically actionable due in part to the difficulty in designing appropriate functional validation studies to understand how variants contribute to disease. Asthma is a complex inflammatory lung disease for which many genetic associations have been identified. Using asthma as a disease model, we designed Reducing Associations by Linking Genes And transcriptomic Results (REALGAR), an app that facilitates the design of functional validation studies by integrating cell- and tissue-specific results of diseaserelevant gene expression and other omics studies. Via specific examples, we demonstrate how integrated gene- centric and disease-specific information leads to asthma insights, and more broadly, can help understand complex diseases.	gene expression;genetic association studies;lung diseases;mental association;omics;whole genome sequencing	Maya Shumyatcher;Rui Hong;Jessica Levin;Blanca E. Himes	2017	AMIA ... Annual Symposium proceedings. AMIA Symposium		disease;omics;bioinformatics;biology	Comp.	5.315616839043497	-57.472892067915716	123766
8fa373c8687ec313af80ac359b903abe97231d39	sana netgo: a combinatorial approach to using gene ontology (go) terms to score network alignments		Motivation Gene Ontology (GO) terms are frequently used to score alignments between protein-protein interaction (PPI) networks. Methods exist to measure GO similarity between proteins in isolation, but proteins in a network alignment are not isolated: each pairing is dependent on every other via the alignment itself. Existing measures fail to take into account the frequency of GO terms across networks, instead imposing arbitrary rules on when to allow GO terms.   Results Here we develop NetGO, a new measure that naturally weighs infrequent, informative GO terms more heavily than frequent, less informative GO terms, without arbitrary cutoffs, instead downweighting GO terms according to their frequency in the networks being aligned. This is a global measure applicable only to alignments, independent of pairwise GO measures, in the same sense that the edge-based EC or S3 scores are global measures of topological similarity independent of pairwise topological similarities. We demonstrate the superiority of NetGO in alignments of predetermined quality and show that NetGO correlates with alignment quality better than any existing GO-based alignment measures. We also demonstrate that NetGO provides a measure of taxonomic similarity between species, consistent with existing taxonomic measuresa feature not shared with existing GObased network alignment measures. Finally, we re-score alignments produced by almost a dozen aligners from a previous study and show that NetGO does a better job at separating good alignments from bad ones.   Availability and implementation Available as part of SANA.   Contact whayes@uci.edu.   Supplementary information Supplementary data are available at Bioinformatics online.	alignment;bioinformatics;gene ontology;geographic information systems;pixel density;proton pump inhibitors;rule (guideline);sana protein, e coli;protein protein interaction;succinyl-trialanine-4-nitroanilide	Wayne B. Hayes;Nil Mamano	2018	Bioinformatics	10.1093/bioinformatics/btx716	bioinformatics;machine learning;data mining;mathematics	Comp.	4.407155046474361	-55.076677324039444	124046
91788f04547a946dea025a0ee56dc400973b4ee2	multi level clustering of phylogenetic profiles	databases;genomics;pattern clustering;intra genome gene clusters;inter genome gene cluster;phylogeny;genome sequences;proteomics biochemistry bioinformatics genetics genomics pattern clustering proteins;genetics;algorithm;phylogenetic profiles algorithm clustering;multi level clustering algorithm;proteins;clustering;image color analysis;phylogenetic profiles;clustering algorithms;metabolic pathway;structural complex;proteomics;gene function;gene function phylogenetic profiles proteins structural complex metabolic pathway multi level clustering algorithm intra genome gene clusters inter genome gene cluster bioinformatics genome sequences;biochemistry;phylogeny bioinformatics genomics clustering algorithms databases proteins biomedical engineering intelligent systems computational intelligence software engineering;bioinformatics	The prediction of gene function from genome sequences is one of the main issues in Bioinformatics. Most computational approaches are based on the similarity between sequences to infer gene function. However, the availability of several fully sequenced genomes has enabled alternative approaches, such as phylogenetic profiles. Phylogenetic profiles are vectors which indicate the presence or absence of a gene in other genomes. The main concept of phylogenetic profiles is that proteins participating in a common structural complex or metabolic pathway are likely to evolve in a correlated fashion. In this paper, a multi level clustering algorithm of phylogenetic profiles is presented, which aims to detect inter- and intra-genome gene clusters.	algorithm;bioinformatics;cluster analysis;gene regulatory network;multi-storey car park;phylogenesis;phylogenetics;whole genome sequencing	Fotis E. Psomopoulos;Pericles A. Mitkas	2010	2010 IEEE International Conference on BioInformatics and BioEngineering	10.1109/BIBE.2010.67	biology;genomics;computer science;bioinformatics;cluster analysis;proteomics;phylogenetic network;genetics	Comp.	6.987009659244617	-56.5867174256403	124681
bfa677db66669c57d5ca2eb72f77fd49e096701c	prediction of micrornas involved in immune system diseases through network based features	classification;mirna;svm;immune diseases;topological features;network	MicroRNAs are a class of small non-coding regulatory RNA molecules that modulate the expression of several genes at post-transcriptional level and play a vital role in disease pathogenesis. Recent research shows that a range of miRNAs are involved in the regulation of immunity and its deregulation results in immune mediated diseases such as cancer, inflammation and autoimmune diseases. Computational discovery of these immune miRNAs using a set of specific features is highly desirable. In the current investigation, we present a SVM based classification system which uses a set of novel network based topological and motif features in addition to the baseline sequential and structural features to predict immune specific miRNAs from other non-immune miRNAs. The classifier was trained and tested on a balanced set of equal number of positive and negative examples to show the discriminative power of our network features. Experimental results show that our approach achieves an accuracy of 90.2% and outperforms the classification accuracy of 63.2% reported using the traditional miRNA sequential and structural features. The proposed classifier was further validated with two immune disease sub-class datasets related to multiple sclerosis microarray data and psoriasis RNA-seq data with higher accuracy. These results indicate that our classifier which uses network and motif features along with sequential and structural features will lead to significant improvement in classifying immune miRNAs and hence can be applied to identify other specific classes of miRNAs as an extensible miRNA classification system.	autoimmune diseases;baseline (configuration management);class;classification;computation;deregulation;immune system diseases;micrornas;microarray;motif;multiple sclerosis;neoplasms;psoriasis;rna;support vector machine;transcription, genetic	Archana Prabahar;Jeyakumar Natarajan	2017	Journal of biomedical informatics	10.1016/j.jbi.2016.11.003	support vector machine;pathology;biological classification;computer science;bioinformatics;machine learning;data mining;genetics;microrna	Comp.	8.951393622527773	-55.6058960807195	125273
02c7b40b6e6c93bd744c6f30b78b9cc384757128	protein complexes discovery based on protein-protein interaction data via a regularized sparse generative network model	peripheral protein protein complex protein protein interaction network generative network model regularization method overlapping complex;peripheral proteins;competing algorithms protein complexes discovery protein protein interaction data regularized sparse generative network model detecting protein complexes postgenome era computational algorithms traditional algorithms protein protein interaction networks density based methods peripheral proteins generative network model generation processing laplacian regularizer protein complexes identification exponential distribution;biology computing;genomics;protein protein interaction network;postgenome era;proteins communities biological system modeling rna polymers exponential distribution;computational algorithms;exponential distribution;protein complex;protein complexes identification;regularization method;biological system modeling;generative network model;interaction network;algorithms databases protein models theoretical protein interaction mapping proteins;density based methods;traditional algorithms;peripheral protein;protein complexes discovery;social network;detecting protein complexes;graph partitioning;regularized sparse generative network model;rna;proteins;network model;laplacian regularizer;molecular biophysics;protein protein interaction;protein protein interaction networks;generation processing;proteins biochemistry biology computing exponential distribution genomics molecular biophysics physiological models;communities;polymers;competing algorithms;physiological models;protein protein interaction data;biochemistry;overlapping complex;protein interaction network	Detecting protein complexes from protein interaction networks is one major task in the postgenome era. Previous developed computational algorithms identifying complexes mainly focus on graph partition or dense region finding. Most of these traditional algorithms cannot discover overlapping complexes which really exist in the protein-protein interaction (PPI) networks. Even if some density-based methods have been developed to identify overlapping complexes, they are not able to discover complexes that include peripheral proteins. In this study, motivated by recent successful application of generative network model to describe the generation process of PPI networks and to detect communities from social networks, we develop a regularized sparse generative network model (RSGNM), by adding another process that generates propensities using exponential distribution and incorporating Laplacian regularizer into an existing generative network model, for protein complexes identification. By assuming that the propensities are generated using exponential distribution, the estimators of propensities will be sparse, which not only has good biological interpretation but also helps to control the overlapping rate among detected complexes. And the Laplacian regularizer will lead to the estimators of propensities more smooth on interaction networks. Experimental results on three yeast PPI networks show that RSGNM outperforms six previous competing algorithms in terms of the quality of detected complexes. In addition, RSGNM is able to detect overlapping complexes and complexes including peripheral proteins simultaneously. These results give new insights about the importance of generative network models in protein complexes identification.	algorithm;community;graph partition;interaction network;laplacian matrix;network model;peripheral;pixel density;proton pump inhibitors;social network;sparse matrix;exponential;protein protein interaction	Xiao-Fei Zhang;Dao-Qing Dai;Xiao Li	2012	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2012.20	biology;biochemistry;peripheral membrane protein;genomics;bioinformatics;data science;machine learning;molecular biophysics	Comp.	4.856681430472177	-55.99549376576143	125470
741b3e86bf738bde14d952196cb20c613ab58877	optimization of gene set annotations via entropy minimization over variable clusters (emvc)	molecular sequence annotation;leukemia;algorithms;humans;tumor suppressor protein p53;gene expression profiling;oligonucleotide array sequence analysis	MOTIVATION Gene set enrichment has become a critical tool for interpreting the results of high-throughput genomic experiments. Inconsistent annotation quality and lack of annotation specificity, however, limit the statistical power of enrichment methods and make it difficult to replicate enrichment results across biologically similar datasets.   RESULTS We propose a novel algorithm for optimizing gene set annotations to best match the structure of specific empirical data sources. Our proposed method, entropy minimization over variable clusters (EMVC), filters the annotations for each gene set to minimize a measure of entropy across disjoint gene clusters computed for a range of cluster sizes over multiple bootstrap resampled datasets. As shown using simulated gene sets with simulated data and Molecular Signatures Database collections with microarray gene expression data, the EMVC algorithm accurately filters annotations unrelated to the experimental outcome resulting in increased gene set enrichment power and better replication of enrichment results.   AVAILABILITY AND IMPLEMENTATION http://cran.r-project.org/web/packages/EMVC/index.html.	algorithm;annotation;cns disorder;collections (publication);common variable immunodeficiency;data sources;elfacos ow 100;experiment;gene expression;gene ontology term enrichment;high-throughput computing;manuscripts;mathematical optimization;microarray;r language;refinement (computing);self-replication;sensitivity and specificity;throughput;funding grant	H. Robert Frost;Jason H. Moore	2014		10.1093/bioinformatics/btu110	biology;bioinformatics;theoretical computer science;data mining;gene expression profiling	Comp.	4.043741150131782	-54.18008790729718	125679
28ca80bcafa16910fc3e5e625ff5d23e9cde42be	prediction of interactions between hiv-1 and human proteins by information integration	information integration;interaction network;protein binding;supervised learning;random forest;life cycle;vitamin d receptor;ligands;mean average precision;biometry;transcription regulation;immune system;artificial intelligence	Human immunodeficiency virus-1 (HIV-1) in acquired immune deficiency syndrome (AIDS) relies on human host cell proteins in virtually every aspect of its life cycle. Knowledge of the set of interacting human and viral proteins would greatly contribute to our understanding of the mechanisms of infection and subsequently to the design of new therapeutic approaches. This work is the first attempt to predict the global set of interactions between HIV-1 and human host cellular proteins. We propose a supervised learning framework, where multiple information data sources are utilized, including co-occurrence of functional motifs and their interaction domains and protein classes, gene ontology annotations, posttranslational modifications, tissue distributions and gene expression profiles, topological properties of the human protein in the interaction network and the similarity of HIV-1 proteins to human proteins' known binding partners. We trained and tested a Random Forest (RF) classifier with this extensive feature set. The model's predictions achieved an average Mean Average Precision (MAP) score of 23%. Among the predicted interactions was for example the pair, HIV-1 protein tat and human vitamin D receptor. This interaction had recently been independently validated experimentally. The rank-ordered lists of predicted interacting pairs are a rich source for generating biological hypotheses. Amongst the novel predictions, transcription regulator activity, immune system process and macromolecular complex were the top most significant molecular function, process and cellular compartments, respectively. Supplementary material is available at URL www.cs.cmu.edu/õznur/hiv/hivPPI.html	acquired immunodeficiency syndrome;anatomical compartments;angular defect;cellular material:mcnt:pt:calculus:qn:estimated;class;computation;computational science;drug or chemical tissue distribution;experiment;gene ontology;hiv infections;hiv-1;immune system processes;immunologic deficiency syndromes;information retrieval;interaction network;interactome;mean squared error;post-translational protein processing;radio frequency;random forest;supervised learning;transcription (software);uniform resource locator;vitamin d;system process	Oznur Tastan;Yanjun Qi;Jaime G. Carbonell;Judith Klein-Seetharaman	2009	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		interaction network;random forest;biology;biological life cycle;plasma protein binding;immune system;computer science;bioinformatics;information integration;machine learning;supervised learning;calcitriol receptor;ligand;genetics;transcriptional regulation	Comp.	8.518869578525958	-57.95946263649136	125693
b3257005e2c51e8ff456b58f48e1af085ca66098	supporting precision medicine by data mining across multi-disciplines: an integrative approach for generating comprehensive linkages between single nucleotide variants (snvs) and drug-binding sites		Motivation Genetic variants in drug targets and metabolizing enzymes often have important functional implications, including altering the efficacy and toxicity of drugs. Identifying single nucleotide variants (SNVs) that contribute to differences in drug response and understanding their underlying mechanisms are fundamental to successful implementation of the precision medicine model. This work reports an effort to collect, classify and analyze SNVs that may affect the optimal response to currently approved drugs.   Results An integrated approach was taken involving data mining across multiple information resources including databases containing drugs, drug targets, chemical structures, protein-ligand structure complexes, genetic and clinical variations as well as protein sequence alignment tools. We obtained 2640 SNVs of interest, most of which occur rarely in populations (minor allele frequency < 0.01). Clinical significance of only 9.56% of the SNVs is known in ClinVar, although 79.02% are predicted as deleterious. The examples here demonstrate that even if the mapped SNVs predicted as deleterious may not result in significant structural modifications, they can plausibly modify the protein-drug interactions, affecting selectivity and drug-binding affinity. Our analysis identifies potentially deleterious SNVs present on drug-binding residues that are relevant for further studies in the context of precision medicine.   Availability and Implementation Data are available from Supplementary information file.   Contact yanli.wang@nih.gov.   Supplementary information Supplementary Tables S1-S5 are available at Bioinformatics online.		Amrita Roy Choudhury;Tiejun Cheng;Lon Phan;Stephen H. Bryant;Yanli Wang	2017	Bioinformatics	10.1093/bioinformatics/btx031	biology;molecular biology;bioinformatics;genetics	Comp.	3.860959028358445	-56.44531125845369	125714
c41fbb0c6965fcdc34d938bb2ecf2c70741b949e	inferring regulations in a genomic network from gene expression profiles		With many revolutionary advancements in technology, biological researchers are now attempting to accumulate the fragments of knowledge to make up the whole living system, or at least to a larger fragment that gives a better understanding of the system implicit in a living organism. Reconstructing genetic networks from expression profiles is an important challenge in systems biology. This chapter presents an improved evolutionary algorithm for inferring the underlying gene network from gene expression data. We used the decoupled S-system formalism for representing genetic interactions and proposed a more effective fitness function for attaining the sparse network architecture in biological systems. The performance of the method was evaluated using artificial genetic networks by varying network size and expression profile characteristics (noise-free and noisy). The results showed the superiority of the method in constructing the network structure and predicting the regulatory parameters. The method was also used to analyze real gene expression data for predicting the interactions among the genes in SOS DNA repair network in Escherichia coli.	biological system;effective fitness;embedded system;evolutionary algorithm;fitness function;formal system;gary kimura;gene co-expression network;gene expression profiling;gene regulatory network;genetic algorithm;image noise;information source;input/output;interaction;living systems;local optimum;local search (optimization);mathematical optimization;microarray;nl (complexity);network architecture;network topology;numerical aperture;semantics (computer science);simulation;sparse matrix;systems biology	Nasimul Noman;Hitoshi Iba	2007		10.1142/9789812708892_0009	mathematical optimization;printed circuit board;pressing;electronic circuit;computer science;bent molecular geometry;flexible electronics;mechanical engineering	Comp.	5.42495801979989	-58.5348139980118	125829
ca795faf1899771e44004013b43b03c30c6725b1	use of biplots and partial least squares regression in microarray data analysis for assessing association between genes involved in different biological pathways	polarity gene;squares regression;cell polarity;emt gene;visualization technique;pls regression;pca-based biplot;passive projection;different biological pathway;microarray data analysis;pls regression result;pls path modeling;epithelial-mesenchymal transition	Microarrays are widely used to study expression profiles for thousand of transcripts simultaneously and to explore interrelationships between sets of genes.#R##N##R##N#Visualization techniques and Partial Least Squares (PLS) regression have thus gained relevance in genomic. Biplots provide an aid to understand relationships between genes and samples and among genes, whereas passive projections of variables are helpful for understanding conditional relationships between sets of genes to be quantitatively evaluated via PLS regression.#R##N##R##N#62 genes involved in loss of cell polarity and 8 involved in Epithelial-Mesenchymal Transition (EMT), were selected from a study on 49 mesothelioma samples, and analysis considered EMT genes as conditioning and polarity genes as conditioned variables. PLS regression results are consistent with the PCA-based biplot of EMT genes and with passive projections of polarity genes.#R##N##R##N#Future work will address sparsity in PCA and PLS regression. PLS path modeling will be considered after specification of a detailed dependency network.	microarray;partial least squares regression	Niccoló Bassani;Federico Ambrogi;Danila Coradini;Elia Biganzoli	2010		10.1007/978-3-642-21946-7_10	econometrics;data mining;statistics	ML	7.296789551448448	-52.608457122112405	126530
f206d269d7f15f1eac0e03477db2876362e3248c	length-dependent prediction of protein intrinsic disorder	software;protein structure secondary;amino acid sequence;models chemical;amino acid composition;computational biology bioinformatics;models molecular;proteins;protein structure prediction;prediction accuracy;algorithms;molecular sequence data;sequence alignment;cross validation;combinatorial libraries;computer appl in life sciences;computer simulation;sequence analysis protein;microarrays;bioinformatics	Due to the functional importance of intrinsically disordered proteins or protein regions, prediction of intrinsic protein disorder from amino acid sequence has become an area of active research as witnessed in the 6th experiment on Critical Assessment of Techniques for Protein Structure Prediction (CASP6). Since the initial work by Romero et al. (Identifying disordered regions in proteins from amino acid sequences, IEEE Int. Conf. Neural Netw., 1997), our group has developed several predictors optimized for long disordered regions (>30 residues) with prediction accuracy exceeding 85%. However, these predictors are less successful on short disordered regions (≤30 residues). A probable cause is a length-dependent amino acid compositions and sequence properties of disordered regions. We proposed two new predictor models, VSL2-M1 and VSL2-M2, to address this length-dependency problem in prediction of intrinsic protein disorder. These two predictors are similar to the original VSL1 predictor used in the CASP6 experiment. In both models, two specialized predictors were first built and optimized for short (≤30 residues) and long disordered regions (>30 residues), respectively. A meta predictor was then trained to integrate the specialized predictors into the final predictor model. As the 10-fold cross-validation results showed, the VSL2 predictors achieved well-balanced prediction accuracies of 81% on both short and long disordered regions. Comparisons over the VSL2 training dataset via 10-fold cross-validation and a blind-test set of unrelated recent PDB chains indicated that VSL2 predictors were significantly more accurate than several existing predictors of intrinsic protein disorder. The VSL2 predictors are applicable to disordered regions of any length and can accurately identify the short disordered regions that are often misclassified by our previous disorder predictors. The success of the VSL2 predictors further confirmed the previously observed differences in amino acid compositions and sequence properties between short and long disordered regions, and justified our approaches for modelling short and long disordered regions separately. The VSL2 predictors are freely accessible for non-commercial use at http://www.ist.temple.edu/disprot/predictorVSL2.php	amino acid sequence;amino acids;artificial neural network;branch predictor;casp;composition;cross reactions;cross-validation (statistics);intrinsically disordered proteins;kerrison predictor;markov chain;probability;protein data bank;protein structure prediction;silo (dataset);test set;caspase-6;emotional dependency	Kang Peng;Predrag Radivojac;Slobodan Vucetic;A. Keith Dunker;Zoran Obradovic	2005	BMC Bioinformatics	10.1186/1471-2105-7-208	computer simulation;biology;biochemistry;dna microarray;computer science;bioinformatics;sequence alignment;protein structure prediction;peptide sequence;cross-validation	Comp.	9.857357817791488	-56.04361993570124	126747
ab2114a43dd1e13fa0f2b7aea519edeb88a59f9b	the ability of different imputation methods to preserve the significant genes and pathways in cancer	gene expression;imputation method;missing data;pathway enrichment;significant genes	Deciphering important genes and pathways from incomplete gene expression data could facilitate a better understanding of cancer. Different imputation methods can be applied to estimate the missing values. In our study, we evaluated various imputation methods for their performance in preserving significant genes and pathways. In the first step, 5% genes are considered in random for two types of ignorable and non-ignorable missingness mechanisms with various missing rates. Next, 10 well-known imputation methods were applied to the complete datasets. The significance analysis of microarrays (SAM) method was applied to detect the significant genes in rectal and lung cancers to showcase the utility of imputation approaches in preserving significant genes. To determine the impact of different imputation methods on the identification of important genes, the chi-squared test was used to compare the proportions of overlaps between significant genes detected from original data and those detected from the imputed datasets. Additionally, the significant genes are tested for their enrichment in important pathways, using the ConsensusPathDB. Our results showed that almost all the significant genes and pathways of the original dataset can be detected in all imputed datasets, indicating that there is no significant difference in the performance of various imputation methods tested. The source code and selected datasets are available on http://profiles.bs.ipm.ir/softwares/imputation_methods/.	chi-squared target models;consensuspathdb;gene expression;gene ontology term enrichment;geo-imputation;malignant neoplasm of lung;microarray;missing data;neoplasms;partial;significance analysis of microarrays;silo (dataset);source code;statistical imputation;tube,rectal,24fr,plastic b#6510	Rosa Aghdam;Taban Baghfalaki;Pegah Khosravi;Elnaz Saberi Ansari	2017		10.1016/j.gpb.2017.08.003	cancer;gene;missing data;bioinformatics;imputation (statistics);consensuspathdb;significance analysis of microarrays;biology	Comp.	6.172254869441727	-53.002449003654554	127257
2b4692be639e0810f3e98f36c1fded983222fb9b	measure transcript integrity using rna-seq data	rna seq quality control;computational biology bioinformatics;gene expression;algorithms;combinatorial libraries;tin;computer appl in life sciences;transcript integrity number;microarrays;bioinformatics	Stored biological samples with pathology information and medical records are invaluable resources for translational medical research. However, RNAs extracted from the archived clinical tissues are often substantially degraded. RNA degradation distorts the RNA-seq read coverage in a gene-specific manner, and has profound influences on whole-genome gene expression profiling. We developed the transcript integrity number (TIN) to measure RNA degradation. When applied to 3 independent RNA-seq datasets, we demonstrated TIN is a reliable and sensitive measure of the RNA degradation at both transcript and sample level. Through comparing 10 prostate cancer clinical samples with lower RNA integrity to 10 samples with higher RNA quality, we demonstrated that calibrating gene expression counts with TIN scores could effectively neutralize RNA degradation effects by reducing false positives and recovering biologically meaningful pathways. When further evaluating the performance of TIN correction using spike-in transcripts in RNA-seq data generated from the Sequencing Quality Control consortium, we found TIN adjustment had better control of false positives and false negatives (sensitivity = 0.89, specificity = 0.91, accuracy = 0.90), as compared to gene expression analysis results without TIN correction (sensitivity = 0.98, specificity = 0.50, accuracy = 0.86). TIN is a reliable measurement of RNA integrity and a valuable approach used to neutralize in vitro RNA degradation effect and improve differential gene expression analysis.	archive;body tissue;can - object;chamaecyparis lawsoniana;distortion;elegant degradation;extraction;gene expression profiling;gene expression programming;genes, vif;medical privacy;prostatic neoplasms;rna degradation;sensitivity and specificity;sequence number;tissue-specific gene expression;transcript	Liguo Wang;Jinfu J. Nie;Hugues Sicotte;Ying Li;Jeanette E. Eckel-Passow;Surendra Dasari;Peter T. Vedell;Poulami Barman;Liewei Wang;Richard Weinshiboum;Jin Jen;Haojie Huang;Manish Kohli;Jean-Pierre A. Kocher	2016		10.1186/s12859-016-0922-z	biology;molecular biology;gene expression;dna microarray;tin;bioinformatics;genetics	Comp.	3.693925299535667	-53.87624837294442	127307
bdb74b004291ecf8d6244f6e0a801cbb85d04df3	hidden markov models and the viterbi algorithm applied to integrated bioinformatics analyses of putative flagellar actin-interacting proteins in leishmania spp	hmms;aip;hidden markov model;leishmania genomes;hidden markov models;viterbi algorithm;cofilin;flagellar proteins;pattern recognition;actin interacting proteins;twinfilin;bioinformatics	For performing vital cellular processes, such as motility, eukaryotic cells rely on the actin cytoskeleton, whose structure and dynamics are tightly controlled by a large number of actin-interacting proteins (AIPs). Actin can determine cell stiffness and transmit force during mechanotransduction, cytokinesis, cell motility and other cellular shape changes, while the identification and analyses of AIPs can help to improve understanding of their mechanical properties on physiological/pathological architectures. In this work we employ bioinformatics tools in some refined pattern recognition techniques (such as hidden Markov models (HMMs) through the Viterbi algorithm/path) in order to improve the recognition of actin-binding/interacting activity through identification of AIPs in genomes, transcriptomes and proteomes of the flagellated protozoan Leishmania. We report our in silico analyses on cofilin and twinfilin, here predicted as flagellar proteins, a direct bioinformatics contribution in the secondary ann...	bioinformatics;hidden markov model;interaction;markov chain;viterbi algorithm	Ana Carolina L. Pacheco;Fabiana Freire Araújo;Michel T. Kamimura;Samara C. Silva-Santiago;Michely C. Diniz;Fátima De Cassia E. Oliveira;Raimundo Araujo-Filho;Marcilia P. Costa;Diana Magalhaes de Oliveira	2009	IJCAET	10.1504/IJCAET.2009.028550	viterbi algorithm;computer science;bioinformatics;machine learning;hidden markov model	Comp.	8.454763918646128	-58.75538758401896	127351
ea08161cec2efa526a0b0c9c05d7296b43e7c0a6	epistatic analysis of clarkson disease		Genome Wide Association Studies (GWAS) have predominantly focused on the association between single SNPs and disease. It is probable, however, that complex diseases are due to combined effects of multiple genetic variations, as opposed to single variations. Multi-SNP interactions, known as epistatic interactions, can potentially provide information about causes of complex diseases, and build on previous GWAS looking at associations between single SNPs and phenotypes. By applying epistatic analysis methods to GWAS datasets, it is possible to identify significant epistatic interactions, and map SNPs identified to genes allowing the construction of a gene network. A large number of studies have applied graph theory techniques to analyse gene networks from microarray data sets, using graph theory metrics to identify important hub genes in these networks. In this work, we present a graph theory study of SNP and gene interaction networks constructed for a Clarkson disease GWAS, as a result of applying epistatic interaction methods to identify significant epistatic interactions. This study identifies a number of genes and SNPs with potential roles for Clarkson disease that could not be found using traditional single SNP analysis, including a number located on chromosome 5q previously identified as being of interest for capillary malformation.	gene regulatory network;genetic algorithm;graph theory;interaction;microarray;usb hub	Alex Upton;Oswaldo Trelles;James Richard Perkins	2015		10.1016/j.procs.2015.05.191	bioinformatics	Comp.	5.198390222328032	-56.58895612075824	127539
1d0bba4e140808e7bfafe4af2b47549385e929d3	identifying the biologically relevant gene categories based on gene expression and biological data: an example on prostate cancer	selection model;gene expression;source code;biological data;gene function;biological process;prostate cancer	MOTIVATION Most gene-expression based studies aim to identify genes with the capability of distinguishing different phenotypes. Although analysis at the genomic level is important, results of the molecular/cellular level are essential for understanding biological mechanisms. To deliver molecular/cellular-level results, a two-stage scheme is widely employed. This scheme just evaluates biological processes/molecular activities individually, totally overlooking the relationship between processes/activities. This treatment conflicts with the fact that most biological processes/molecular activities do not work alone. In order to deliver improved results, this shortcoming should be addressed.   RESULTS We design a selection model from a novel perspective to directly detect important gene functional categories (each category represents a cellular process or a molecular activity). More importantly, the correlations between gene categories are considered. Contributed by this capability, the proposed method shows its advantages over others.   AVAILABILITY the source code in Matlab is accessible via http://www.ee.cityu.edu.hk/~twschow/category_selection/category_selection.htm	biological factors;categories;category theory;cell physiology;conflict (psychology);gene expression;gene co-expression network;matlab;phenotype;prostatic neoplasms;source code	Di Huang;Tommy W. S. Chow	2007	Bioinformatics	10.1093/bioinformatics/btm141	biology;gene expression;biological data;bioinformatics;artificial intelligence;data mining;biological process;genetics;source code	Comp.	6.880872888579151	-55.1561913206302	127785
3637181f05a49e2f2fc87740deff011b1ac59105	a statistically representative atlas for mapping neuronal circuits in the drosophila adult brain	drosophila adult brain;anatomical atlas;atlas-based image segmentation;average brain template;brain mapping;confocal microscopy;diffeomorphic image registration	Imaging the expression patterns of reporter constructs is a powerful tool to dissect the neuronal circuits of perception and behavior in the adult brain of Drosophila, one of the major models for studying brain functions. To date, several Drosophila brain templates and digital atlases have been built to automatically analyze and compare collections of expression pattern images. However, there has been no systematic comparison of performances between alternative atlasing strategies and registration algorithms. Here, we objectively evaluated the performance of different strategies for building adult Drosophila brain templates and atlases. In addition, we used state-of-the-art registration algorithms to generate a new group-wise inter-sex atlas. Our results highlight the benefit of statistical atlases over individual ones and show that the newly proposed inter-sex atlas outperformed existing solutions for automated registration and annotation of expression patterns. Over 3,000 images from the Janelia Farm FlyLight collection were registered using the proposed strategy. These registered expression patterns can be searched and compared with a new version of the BrainBaseWeb system and BrainGazer software. We illustrate the validity of our methodology and brain atlas with registration-based predictions of expression patterns in a subset of clock neurons. The described registration framework should benefit to brain studies in Drosophila and other insect species.	atlases;brain atlas;cervical atlas;clinical use template;collections (publication);performance;search - action;server farm;solutions;subgroup;algorithm;registration - actclass	Ignacio Arganda-Carreras;Tudor Manoliu;Nicolas Mazuras;Florian Schulze;Juan E. Iglesias;Katja Bühler;Arnim Jenett;François Rouyer;Philippe Andrey	2018		10.3389/fninf.2018.00013	brain atlas;machine learning;software;computer science;artificial intelligence;annotation;bioinformatics;brain mapping	ML	3.0712884155461015	-55.73809455906838	127879
12cfaa247f473af2060ed136c249c77958293e3e	phylogenomic inference of protein molecular function: advances and challenges	protein family;phylogenomic analysis;phylogenomic inference;protein functional classification;functional classification;experimental data;protein function prediction;structural phylogenomics;protein molecular function;explicit integration;structure prediction;protein superfamily evolution	MOTIVATION Protein families evolve a multiplicity of functions through gene duplication, speciation and other processes. As a number of studies have shown, standard methods of protein function prediction produce systematic errors on these data. Phylogenomic analysis--combining phylogenetic tree construction, integration of experimental data and differentiation of orthologs and paralogs--has been proposed to address these errors and improve the accuracy of functional classification. The explicit integration of structure prediction and analysis in this framework, which we call structural phylogenomics, provides additional insights into protein superfamily evolution.   RESULTS Results of protein functional classification using phylogenomic analysis show fewer expected false positives overall than when pairwise methods of functional classification are employed. We present an overview of the motivations and fundamental principles of phylogenomic analysis, new methods developed for the key tasks, benchmark datasets for these tasks (when available) and suggest procedures to increase accuracy. We also discuss some of the methods used in the Celera Genomics high-throughput phylogenomic classification of the human genome.   AVAILABILITY Software tools from the Berkeley Phylogenomics Group are available at http://phylogenomics.berkeley.edu	benchmark (computing);functional genomics;gene duplication abnormality;high-throughput computing;homology (biology);inference;motivation;phylogenetic tree;phylogenetics;protein family;protein function prediction;superfamily;throughput;molecular_function;multiplicity	Kimmen Sjölander	2004	Bioinformatics	10.1093/bioinformatics/bth021	biology;bioinformatics;data mining	Comp.	3.5689543234738736	-55.97021036824697	128046
34cb7a62032d7b4de8761d3c2d57fdbc843c4776	computing power of quantitative trait locus association mapping for haploid loci	quantitative trait loci;study design;quantitative trait locus;qtl mapping;male;chromosome mapping;association mapping;gene mapping;computational biology bioinformatics;statistical power;haploidy;algorithms;humans;human genetics;combinatorial libraries;computer appl in life sciences;computer simulation;microarrays;bioinformatics	Statistical power calculations are a critical part of any study design for gene mapping. Most calculations assume that the locus of interest is biallelic. However, there are common situations in human genetics such as X-linked loci in males where the locus is haploid. The purpose of this work is to mathematically derive the biometric model for haploid loci, and to compute power for QTL mapping when the loci are haploid. We have derived the biometric model for power calculations for haploid loci and have developed software to perform these calculations. We have verified our calculations with independent mathematical methods. Our results fill a need in power calculations for QTL mapping studies. Furthermore, failure to appropriately model haploid loci may cause underestimation of power.	biometrics;chromosome mapping;haploidy;locus;mathematics;norm (social);quantitative trait loci;x-linked lymphoproliferative disorder	Derek Gordon;Andrew R. Zinn	2009	BMC Bioinformatics	10.1186/1471-2105-10-261	computer simulation;biology;association mapping;family-based qtl mapping;bioinformatics;locus;genetics;quantitative trait locus;evolutionary biology	HPC	5.518300764294011	-53.878415391647636	128661
505346ddf85ac5db3686cc2fab3669264d073db0	how networks change with time	software;animals;mitochondria;saccharomyces cerevisiae;bayes theorem;drosophila;cluster analysis;stochastic processes;likelihood functions;algorithms;protein interaction mapping;computational biology;protein interaction maps;gene expression profiling;ribosomes;nuclear pore	MOTIVATION Biological networks change in response to genetic and environmental cues. Changes are reflected in the abundances of biomolecules, the composition of protein complexes and other descriptors of the biological state. Methods to infer the dynamic state of a cell would have great value for understanding how cells change over time to accomplish biological goals.   RESULTS A new method predicts the dynamic state of protein complexes in a cell, with protein expression inferred from transcription profile time courses and protein complexes inferred by joint analysis of protein co-expression and protein-protein interaction maps. Two algorithmic advances are presented: a new method, DHAC (Dynamical Hierarchical Agglomerative Clustering), for clustering time-evolving networks; and a companion method, MATCH-EM, for matching corresponding clusters across time points. With link prediction as an objective assessment metric, DHAC provides a substantial advance over existing clustering methods. An application to the yeast metabolic cycle demonstrates how waves of gene expression correspond to individual protein complexes. Our results suggest regulatory mechanisms for assembling the mitochondrial ribosome and illustrate dynamic changes in the components of the nuclear pore.   AVAILABILITY All source code and data are available under the Boost Software License as supplementary material, at www.baderzone.org, and at sourceforge.net/projects/dhacdist.	5,6-dihydro-5-azacytidine;biological network;boost;cluster analysis;dynamical system;electronic supplementary materials;ephrin type-b receptor 1, human;evolving networks;expectation–maximization algorithm;gene expression profiling;hierarchical clustering;inference;matching;map;metabolic process, cellular;mitochondrial ribosomes;nuclear pore;software license;source code;sourceforge;transcription (software);protein expression;protein protein interaction;statistical cluster	Yongjin Park;Joel S. Bader	2012		10.1093/bioinformatics/bts211	stochastic process;biology;nuclear pore;mitochondrion;bioinformatics;ribosome;data mining;gene expression profiling;cluster analysis;bayes' theorem;genetics;statistics	Comp.	4.716744405727938	-57.81336514699947	129179
1c6b9962d1bdb208e176eac7a7ce6ece2881a54a	mining hiv protease cleavage data using genetic programming with a sum-product function	genetique;production function;genetic program;p16ink4a;score function;programmation;hydrolases;genetica;virus;enzyme;bioinformatique;human immunodeficiency virus;peptidases;enzima;data mining;virus immunodeficience humaine;genetics;programacion;5 fluorouracil;degeneration;fouille donnee;adjuvant chemotherapy;prediction accuracy;software package;colorectal cancer;bioinformatica;retroviridae;thymidylate synthase;lentivirus;programming;busca dato;bioinformatics	MOTIVATION In order to design effective HIV inhibitors, studying and understanding the mechanism of HIV protease cleavage specification is critical. Various methods have been developed to explore the specificity of HIV protease cleavage activity. However, success in both extracting discriminant rules and maintaining high prediction accuracy is still challenging. The earlier study had employed genetic programming with a min-max scoring function to extract discriminant rules with success. However, the decision will finally be degenerated to one residue making further improvement of the prediction accuracy difficult. The challenge of revising the min-max scoring function so as to improve the prediction accuracy motivated this study.   RESULTS This paper has designed a new scoring function called a sum-product function for extracting HIV protease cleavage discriminant rules using genetic programming methods. The experiments show that the new scoring function is superior to the min-max scoring function.   AVAILABILITY The software package can be obtained by request to Dr Zheng Rong Yang.	abnormal degeneration;endopeptidases;experiment;genetic programming;hiv infections;hla-dr ag:type:pt:tiss:nom;linear discriminant analysis;maxima and minima;rule (guideline);score;scoring functions for docking;sensitivity and specificity;specification;yang	Zheng Rong Yang;Andrew R. Dalby;Jing Qiu	2004	Bioinformatics	10.1093/bioinformatics/bth414	biology;programming;enzyme;virus;thymidylate synthase;bioinformatics;colorectal cancer;virology;production function;immunology;score;genetics	AI	8.289355342110758	-53.520338283803724	129788
4fdf527b1370755e118728d0c21fe715aa7ff112	hierarchical analysis of rna-seq reads improves the accuracy of allele-specific expression		Motivation Allele-specific expression (ASE) refers to the differential abundance of the allelic copies of a transcript. RNA sequencing (RNA-seq) can provide quantitative estimates of ASE for genes with transcribed polymorphisms. When short-read sequences are aligned to a diploid transcriptome, read-mapping ambiguities confound our ability to directly count reads. Multi-mapping reads aligning equally well to multiple genomic locations, isoforms or alleles can comprise the majority (>85%) of reads. Discarding them can result in biases and substantial loss of information. Methods have been developed that use weighted allocation of read counts but these methods treat the different types of multi-reads equivalently. We propose a hierarchical approach to allocation of read counts that first resolves ambiguities among genes, then among isoforms, and lastly between alleles. We have implemented our model in EMASE software (Expectation-Maximization for Allele Specific Expression) to estimate total gene expression, isoform usage and ASE based on this hierarchical allocation.   Results Methods that align RNA-seq reads to a diploid transcriptome incorporating known genetic variants improve estimates of ASE and total gene expression compared to methods that use reference genome alignments. Weighted allocation methods outperform methods that discard multi-reads. Hierarchical allocation of reads improves estimation of ASE even when data are simulated from a non-hierarchical model. Analysis of RNA-seq data from F1 hybrid mice using EMASE reveals widespread ASE associated with cis-acting polymorphisms and a small number of parent-of-origin effects.   Availability and implementation EMASE software is available at https://github.com/churchill-lab/emase.   Supplementary information Supplementary data are available at Bioinformatics online.		Narayanan Raghupathy;Kwangbom Choi;Matthew J. Vincent;Glen L. Beane;Keith S. Sheppard;Steven C. Munger;Ron Korstanje;Fernando Pardo-Manual de Villena;Gary A. Churchill	2018	Bioinformatics	10.1093/bioinformatics/bty078	computer science;rna-seq;bioinformatics;allele	Comp.	3.7787200683141164	-53.61956818818893	130390
83f20459a1f11132002df6a6d17d54ceb18b93f5	random forest and gene networks for association of snps to alzheimer's disease	genome wide association study;random forest;alzheimer s disease;snp	Machine learning methods, such as Random Forest (RF), have been used to predict disease risk and select a set of single nucleotide polymorphisms (SNPs) associated to the disease on Genome-Wide Association Studies (GWAS). In this study, we extracted information from biological networks for selecting candidate SNPs to be used by RF, for predicting and ranking SNPs by importance measures. From an initial set of genes already related to a disease, we used the tool GeneMANIA for constructing gene interaction networks to find novel genes that might be associated with Alzheimer's Disease (AD). Therefore, it is possible to extract a small number of SNPs making the application of RF feasible. The experiments conducted in this study focus on investigating which SNPs may influence the susceptibility to AD.	gene regulatory network;random forest	Gilderlanio S. Araújo;Manuela R. B. Souza;João Ricardo M. Oliveira;Ivan G. Costa	2013		10.1007/978-3-319-02624-4_10	genome-wide association study;random forest;biology;biotechnology;computer science;bioinformatics;snp;machine learning;genetics	Vision	6.118521412221311	-55.7824191720448	130473
ecae1fac403e08c28f3153597646af2c9acb3475	survey on modelling methods applicable to gene regulatory network		Gene Regulatory Network (GRN) plays an important role in knowing insight of cellular life cycle. It gives information about at which different environmental conditions genes of particular interest get over expressed or under expressed. Modelling of GRN is nothing but finding interactive relationships between genes. Interaction can be positive or negative. For inference of GRN, time series data provided by Microarray technology is used. Key factors to be considered while constructing GRN are scalability, robustness, reliability and maximum detection of true positive interactions between genes. This paper gives detailed technical review of existing methods applied for building of GRN along with scope for future work.	bioinformatics;computer engineering;computer science;curse of dimensionality;data mining;gene regulatory network;interaction;partial template specialization;robustness (computer science);scalability;software technical review;time series	Chanda Panse;Manali Kshirsagar	2013	CoRR		bioinformatics;artificial intelligence;data mining	Comp.	4.827840146472514	-58.35554800220117	130502
608a4dc9f2464942030cb860a84ddcb215691188	assessing gene significance from cdna microarray expression data via mixed models	statistical approach;experimental design;false negative;statistical significance;mixed models;anova;gene expression;mixed model;statistical power;linear model;cdna microarray;differentially expressed gene;false positive;article	The determination of a list of differentially expressed genes is a basic objective in many cDNA microarray experiments. We present a statistical approach that allows direct control over the percentage of false positives in such a list and, under certain reasonable assumptions, improves on existing methods with respect to the percentage of false negatives. The method accommodates a wide variety of experimental designs and can simultaneously assess significant differences between multiple types of biological samples. Two interconnected mixed linear models are central to the method and provide a flexible means to properly account for variability both across and within genes. The mixed model also provides a convenient framework for evaluating the statistical power of any particular experimental design and thus enables a researcher to a priori select an appropriate number of replicates. We also suggest some basic graphics for visualizing lists of significant genes. Analyses of published experiments studying human cancer and yeast cells illustrate the results.	dna microarray;dna, complementary;experiment;experimental design;graphics;linear model;mixed model;scientific publication;spatial variability	Russell D. Wolfinger;Greg Gibson;Elizabeth D. Wolfinger;Lee Bennett;Hisham Hamadeh;Pierre R. Bushel;Cynthia A. Afshari;Richard S. Paules	2001	Journal of computational biology : a journal of computational molecular cell biology	10.1089/106652701753307520	mixed model;computer science;bioinformatics;data science;mathematics;statistics	Comp.	4.614220278148614	-53.16322132803409	130715
49ca6c2e05b0e8587855424391fd312bd7314307	tac-elm: metagenomic taxonomic classification with extreme learning machines		Next-generation technologies have allowed researchers to determine the collective genomes of all organisms within specific environments or communities. Varying species abundance, length and complexities within different communities, coupled with discovery of new species makes the problem of taxonomic assignment to short DNA sequence reads extremely challenging. We have developed a new sequence compositionbased taxonomic classifier, TAC-ELM for metagenomic analysis. TAC-ELM uses the framework of extreme learning machines to quickly and accurately learn the weights for a neural network model, with input features consisting of GC content and oligonucleotides. TAC-ELM is evaluated on two standard metagenomic benchmarks with sequence read lengths reflecting the traditional and current technologies. Our empirical results indicate the strength of the developed approach, which outperforms state-of-the-art taxonomic classifiers in terms of accuracy, training time and implementation complexity. We also perform experiments that evaluate the pervasive case within metagenome analysis, where a species may not have been previously sequenced or discovered and will not exist in the reference genome databases.	artificial neural network;blast;benchmark (computing);clade;database;elm;experiment;feedforward neural network;learning classifier system;linear classifier;metagenomics;network model;pervasive informatics	Zeehasham Rasheed;Huzefa Rangwala	2011			oligonucleotide;artificial neural network;genome;gc-content;reference genome;relative species abundance;dna sequencing;metagenomics;biology;bioinformatics	ML	8.988668709084392	-55.16534905465534	130769
ac2a085cce61f69ed4e89f203203ebc86935f1da	convolutional neural networks in classifying cancer through dna methylation		DNA Methylation has been the most extensively studied epigenetic mark. Usually a change in the genotype, DNA sequence, leads to a change in the phenotype, observable characteristics of the individual. But DNA methylation, which happens in the context of CpG (cytosine and guanine bases linked by phosphate backbone) dinucleotides, does not lead to a change in the original DNA sequence, but has the potential to change the phenotype. DNA methylation is implicated in various biological processes and diseases including cancer. Hence there is a strong interest in understanding the DNA methylation patterns across various epigenetic related ailments in order to distinguish and diagnose the type of disease in its early stages. In this work, the relationship between methylated versus unmethylated CpG regions and cancer types is explored using Convolutional Neural Networks (CNNs). A CNN based Deep Learning model that can classify the cancer of a new DNA methylation profile based on the learning from publicly available DNA methylation datasets is then proposed.	convolutional neural network;deep learning;internet backbone;observable	Soham Chatterjee;Archana Iyer;Satya Avva;Abhai Kollara;Malaikannan Sankarasubbu	2018	CoRR		dna methylation;guanine;genetics;cytosine;cpg site;biology;phenotype;genotype;dna sequencing;epigenetics	Comp.	8.229109812850123	-56.661068849016694	130943
8fa5c60dbd39271f57306cdb24538c7d405fd2ff	efficient sampling of protein folding pathways using hmmstr and efficient sampling of protein folding pathways using hmmstr and	hidden markov model;amino acid sequence;folding pathway;hidden markov models;proteins;protein conformation;secondary structure;molecular biophysics;protein folding;folding funnel model compact protein conformations folding pathways fragment assembly methods probabilistic roadmap amino acid sequence conformational sampling hidden markov model sequence structure correlation energy landscape secondary structure content;sampling methods proteins hidden markov models amino acids windows joining processes assembly buildings road transportation monte carlo methods;hidden markov models proteins molecular biophysics;energy landscape	We present a method for constructing thousands of compact protein conformations from fragments and then connecting these structures to form a network of physically plausible folding pathways. This is the first attempt to merge the previous successes in fragment assembly methods with probabilistic roadmap (PRM) methods. Previous PRM methods have used the knowledge of the true structure to sample conformational space. Our method uses only the amino acid sequence to bias the conformational sampling. Conformational sampling is done using HMMSTR, a hidden Markov model for local sequence-structure correlations. We then build a PRM graph and find paths that have the the lowest energy climb. We find that favored folding pathways exist, corresponding to deep valleys in the energy landscape. We describe the pathways for three small proteins with different secondary structure content in the context of a folding funnel model.	gibbs sampling	Yogesh A. Girdhar;Christopher Bystroff;Srinivas Akella	2005		10.1109/CSBW.2005.59	crystallography;protein folding;biology;biochemistry;protein structure;computer science;bioinformatics;energy landscape;machine learning;mathematics;peptide sequence;hidden markov model;protein secondary structure	Comp.	8.987061661651325	-58.62530194993855	131158
f21fa1fc296717519353fc6aae105e370b6710c5	genes related to differentiation are correlated with the gene regulatory network structure		MOTIVATION Many secondary messengers, receptors and transcription factors are related to cell differentiation. Their role in cell differentiation can be affected by their position in the gene regulatory network. Here, we test whether the properties of the gene regulatory network can highlight which genes and proteins are associated with cell differentiation. We use a previously developed purely theoretical algorithm built to detect nodes that can induce a state change in Boolean gene regulatory networks, and show that most genes predicted to participate in differentiation in the theoretical framework are also experimentally known to be associated with such differentiation. These results show that genes related to differentiation are associated with specific features of the genetic regulatory network. The proposed algorithm produces a better classification than simple network measures such as the nodes degree or centrality. Boolean networks were used in many previous theoretical models. Here, we show a direct application of such networks to the detection of genes and subnetworks related to differentiation. The subnetwork emerging from the genes and edges that are predicted to be associated with differentiation are the most active molecular pathways experimentally described to be involved in cell differentiation.   AVAILABILITY AND IMPLEMENTATION http://peptibase.cs.biu.ac.il/homepage/Boolean_network_conversion_code.zip.	algorithm;cell (microprocessor);cell differentiation process;centrality;experiment;gene regulatory network;second messenger systems;subnetwork;transcription factor;transcription (software)	Matan Bodaker;Eran Meshorer;Eduardo Mitrani;Yoram Louzoun	2014	Bioinformatics	10.1093/bioinformatics/btt685	biology;gene regulatory network;bioinformatics;genetics	Comp.	5.902361406524557	-58.861592778449506	131322
130f3f99a12a393c9e610f1f453766c4a1e254e4	a comparative study of machine-learning methods to predict the effects of single nucleotide polymorphisms on protein function	metodo analisis;protein function;decision tree;proteine;development;robust estimator;learning;nucleotides;estudio comparativo;biological effect;volume;desarrollo;polimorfismo mononucleotido;arbol decision;aprendizaje;etude comparative;protein structure;polymorphisme mononucleotide;methode analyse;apprentissage;volumen;learning methods;machine learning;analysis method;developpement;comparative study;proteina;cross validation;support vector machine;protein;arbre decision;single nucleotide polymorphism	MOTIVATION The large volume of single nucleotide polymorphism data now available motivates the development of methods for distinguishing neutral changes from those which have real biological effects. Here, two different machine-learning methods, decision trees and support vector machines (SVMs), are applied for the first time to this problem. In common with most other methods, only non-synonymous changes in protein coding regions of the genome are considered.   RESULTS In detailed cross-validation analysis, both learning methods are shown to compete well with existing methods, and to out-perform them in some key tests. SVMs show better generalization performance, but decision trees have the advantage of generating interpretable rules with robust estimates of prediction confidence. It is shown that the inclusion of protein structure information produces more accurate methods, in agreement with other recent studies, and the effect of using predicted rather than actual structure is evaluated.   AVAILABILITY Software is available on request from the authors.	cross reactions;cross-validation (statistics);decision trees;decision tree;estimated;function (biology);generalization (psychology);genetic polymorphism;machine learning;open reading frames;rule (guideline);support vector machine;tomography, emission-computed, single-photon;trees (plant)	Vidhya Gomathi Krishnan;David R. Westhead	2003	Bioinformatics	10.1093/bioinformatics/btg297	single-nucleotide polymorphism;biology;robust statistics;support vector machine;protein structure;nucleotide;computer science;bioinformatics;artificial intelligence;decision tree;comparative research;volume;algorithm;cross-validation	Comp.	8.067880439057225	-53.629374822104836	131427
afe35f0a871e68f3bf72cf366d4cc013323dfe00	improving phylogenetic analyses by incorporating additional information from genetic sequence databases	genetique;phylogeny;genetica;phylogenese;database;base dato;databases genetic;genetics;filogenesis;base de donnees;algorithms;analyse information;sequence alignment;computational biology;markov chains	MOTIVATION Statistical analyses of phylogenetic data culminate in uncertain estimates of underlying model parameters. Lack of additional data hinders the ability to reduce this uncertainty, as the original phylogenetic dataset is often complete, containing the entire gene or genome information available for the given set of taxa. Informative priors in a Bayesian analysis can reduce posterior uncertainty; however, publicly available phylogenetic software specifies vague priors for model parameters by default. We build objective and informative priors using hierarchical random effect models that combine additional datasets whose parameters are not of direct interest but are similar to the analysis of interest.   RESULTS We propose principled statistical methods that permit more precise parameter estimates in phylogenetic analyses by creating informative priors for parameters of interest. Using additional sequence datasets from our lab or public databases, we construct a fully Bayesian semiparametric hierarchical model to combine datasets. A dynamic iteratively reweighted Markov chain Monte Carlo algorithm conveniently recycles posterior samples from the individual analyses. We demonstrate the value of our approach by examining the insertion-deletion (indel) process in the enolase gene across the Tree of Life using the phylogenetic software BALI-PHY; we incorporate prior information about indels from 82 curated alignments downloaded from the BAliBASE database.	bayesian network;databases;default;deletion mutation;enolase;estimated;hierarchical database model;indel mutation;information;insertion mutation;list of phylogenetics software;markov chain monte carlo;monte carlo algorithm;monte carlo method;phy (chip);population parameter;random effects model;semiparametric model;silo (dataset);vagueness	Li-Jung Liang;Robert E. Weiss;Benjamin D. Redelings;Marc A. Suchard	2009	Bioinformatics	10.1093/bioinformatics/btp473	biology;markov chain;computer science;bioinformatics;sequence alignment;data mining;genetics;statistics;phylogenetics	Comp.	3.7021895622049565	-52.389033579927485	131763
25f58e6490e965520552fe2e4da9fcf72b5f54ac	chromatin structure fully determines replication timing program in human cells	chromatin;acm proceedings;replication timing	"""DNA replication is a tightly regulated process that follows a strict, yet poorly understood, temporal program [12, 9]. This timing program is intricately linked to many aspects of cell biology [1], it is cell type specific [11, 6] and altered in cancer cells [4, 5]. Although on the genome scale DNA replication appears as a highly orchestrated process, at the level of individual initiation events it is found to be stochastic [3, 8]. The mechanisms controlling global DNA replication timing remain largely unknown. Recently, stochastic DNA replication models, where global timing emerges from the collective action of unregulated initiation events, have been proposed [7, 2] yet there is still no quantitative model that can explain complex timing patterns observed in metazoan genomes. Contributing to the dearth of such models is the incomplete characterization of replication initiation sites in these genomes. We show that this issue does not prevent building a successful DNA replication timing model because we find that (a) the replication timing program is so robust that knowledge of exact firing probabilities is unnecessary and (b) high efficiency replicators are sufficiently localized by a specific chromatin mark.  We arrive at these conclusions based on simulations generated by a simple mechanistic model and comparisons to experimental timing data [6]. The input to our model is an """"Initiation Probability Landscape"""" (IPLS), a mathematical construct representing the location of proposed initiation sites. We find that even a simplistic IPLS, based on positions of transcription start sites, produces a remarkably accurate replication timing prediction (r=0.75 prediction vs. experiment). In principle, any genomic dataset can be used to define an IPLS and we systematically tried all ENCODE datasets [10], performed simulations and ranked the resulting predictions according to their agreement with empirical data. A number of chromatin marks dominate the top of this ranking, but only a single mark remains fully predictive after reducing the mutual interdependence between the top contenders."""	encode;emoticon;interdependence;replicator (stargate);simulation;transcription (software)	Sven Bilke;Yevgeniy Gindin;Paul S. Meltzer	2013		10.1145/2506583.2506700	biology;chromatin;bioinformatics;genetics	Metrics	4.3005120251170625	-56.109629857277355	132116
f77622389ecd894d936b5a26673205702bb3bf58	computational analysis of kinase inhibitor selectivity using structural knowledge		Motivation Kinases play a significant role in diverse disease signaling pathways and understanding kinase inhibitor selectivity, the tendency of drugs to bind to off-targets, remains a top priority for kinase inhibitor design and clinical safety assessment. Traditional approaches for kinase selectivity analysis using biochemical activity and binding assays are useful but can be costly and are often limited by the kinases that are available. On the other hand, current computational kinase selectivity prediction methods are computational intensive and can rarely achieve sufficient accuracy for large-scale kinome wide inhibitor selectivity profiling.   Results Here, we present a KinomeFEATURE database for kinase binding site similarity search by comparing protein microenvironments characterized using diverse physiochemical descriptors. Initial selectivity prediction of 15 known kinase inhibitors achieved an > 90% accuracy and demonstrated improved performance in comparison to commonly used kinase inhibitor selectivity prediction methods. Additional kinase ATP binding site similarity assessment (120 binding sites) identified 55 kinases with significant promiscuity and revealed unexpected inhibitor cross-activities between PKR and FGFR2 kinases. Kinome-wide selectivity profiling of 11 kinase drug candidates predicted novel as well as experimentally validated off-targets and suggested structural mechanisms of kinase cross-activities. Our study demonstrated potential utilities of our approach for large-scale kinase inhibitor selectivity profiling that could contribute to kinase drug development and safety assessment.   Availability The KinomeFEATURE database are available at https://simtk.org/projects/kdb.   Supplementary information Supplementary data are available at Bioinformatics online.		Yu-Chen Lo;Tianyun Liu;Kari M. Morrissey;Satoko Kakiuchi-Kiyota;Adam R Johnson;Fabio Broccatelli;Yu Zhong;Amita Joshi;Russ B. Altman	2018	Bioinformatics	10.1093/bioinformatics/bty582	computer science;kinase;selectivity;bioinformatics	Comp.	8.77989922340693	-57.95878532764079	132282
2e045239d9e4b0dc2ca34a6cd5e3951d123221ba	a novel approach for protein subcellular location prediction using amino acid exposure	nucleocytoplasmic transport proteins;support vector machines;amino acid sequence;computational biology bioinformatics;proteins;principal component analysis;predictive value of tests;algorithms;humans;neural networks computer;combinatorial libraries;computational biology;computer appl in life sciences;amino acid motifs;subcellular fractions;databases protein;microarrays;bioinformatics	Proteins perform their functions in associated cellular locations. Therefore, the study of protein function can be facilitated by predictions of protein location. Protein location can be predicted either from the sequence of a protein alone by identification of targeting peptide sequences and motifs, or by homology to proteins of known location. A third approach, which is complementary, exploits the differences in amino acid composition of proteins associated to different cellular locations, and can be useful if motif and homology information are missing. Here we expand this approach taking into account amino acid composition at different levels of amino acid exposure. Our method has two stages. For stage one, we trained multiple Support Vector Machines (SVMs) to score eukaryotic protein sequences for membership to each of three categories: nuclear, cytoplasmic and extracellular, plus extra category nucleocytoplasmic, accounting for the fact that a large number of proteins shuttles between those two locations. In stage two we use an artificial neural network (ANN) to propose a category from the scores given to the four locations in stage one. The method reaches an accuracy of 68% when using as input 3D-derived values of amino acid exposure. Calibration of the method using predicted values of amino acid exposure allows classifying proteins without 3D-information with an accuracy of 62% and discerning proteins in different locations even if they shared high levels of identity. In this study we explored the relationship between residue exposure and protein subcellular location. We developed a new algorithm for subcellular location prediction that uses residue exposure signatures. Our algorithm uses a novel approach to address the multiclass classification problem. The algorithm is implemented as web server 'NYCE’ and can be accessed at http://cbdm.mdc-berlin.de/~amer/nyce .	algorithm;amino acids;antivirus software;artificial neural network;categories;homologous gene;homology (biology);information;motif;multiclass classification;peptide sequence;proteins;server (computer);server (computing);staphylococcal protein a;support vector machine;web server;cellular targeting;protein location	Arvind Mer;Miguel A. Andrade-Navarro	2013		10.1186/1471-2105-14-342	biology;support vector machine;biochemistry;dna microarray;computer science;bioinformatics;machine learning;predictive value of tests;peptide sequence;principal component analysis	Comp.	9.533715919351241	-56.26863850546536	132416
2e6b9e040aacfdec22a18de086e8686a883f0e12	algorithms for pseudoknot classification	classification algorithm;rna secondary structure;efficient algorithm;non coding rna;pseudoknot classification;structure alignment	The structures of non-coding RNAs are found to be critical in many biological functions. In particular, pseudoknotted structures play an important role in some of these functions. Different pseudoknotted structures may have different functionalities. Algorithms developed to handle pseudoknotted ncRNAs are usually designed for specific pseudoknot structures (e.g. structural alignment algorithms). It is desirable to have a tool to classify a given RNA secondary structure into different types. In this paper, we solve this problem by providing a set of efficient algorithms to perform the classification. We implemented the algorithms and used them in the web-based tool RNASAlign (http://www.bio8.cs.hku.hk/RNASAlign) which can automatically classify the input structure into the correct type, then perform the structural alignment according to the identified type. The classification algorithms proposed in the paper are found to be effective.	algorithm;web application	Thomas K. F. Wong;Hui-Ting Yu;Bay-Yuan Hsu;Tak Wah Lam;Wing-Kai Hon;Siu-Ming Yiu	2011		10.1145/2147805.2147877	computer science;bioinformatics;machine learning;data mining	Comp.	9.107446808486255	-52.69667367544374	132666
6cca32f860c3cb6bb856a1651b8a00c76ecc7f39	integrating gene expression and go classification for pca by preclustering	gene expression profile;expression profile;saccharomyces cerevisiae;cell differentiation;mesenchymal stromal cells;human mesenchymal stem cells;databases genetic;gene expression data;computational biology bioinformatics;gene expression;article letter to editor;cluster analysis;principal component analysis;algorithms;cell cycle;cell wall;humans;combinatorial libraries;computer appl in life sciences;gene expression profiling;microarrays;bioinformatics	"""Gene expression data can be analyzed by summarizing groups of individual gene expression profiles based on GO annotation information. The mean expression profile per group can then be used to identify interesting GO categories in relation to the experimental settings. However, the expression profiles present in GO classes are often heterogeneous, i.e., there are several different expression profiles within one class. As a result, important experimental findings can be obscured because the summarizing profile does not seem to be of interest. We propose to tackle this problem by finding homogeneous subclasses within GO categories: preclustering. Two microarray datasets are analyzed. First, a selection of genes from a well-known Saccharomyces cerevisiae dataset is used. The GO class """"cell wall organization and biogenesis"""" is shown as a specific example. After preclustering, this term can be associated with different phases in the cell cycle, where it could not be associated with a specific phase previously. Second, a dataset of differentiation of human Mesenchymal Stem Cells (MSC) into osteoblasts is used. For this dataset results are shown in which the GO term """"skeletal development"""" is a specific example of a heterogeneous GO class for which better associations can be made after preclustering. The Intra Cluster Correlation (ICC), a measure of cluster tightness, is applied to identify relevant clusters. We show that this method leads to an improved interpretability of results in Principal Component Analysis."""	annotation;categories;cellular phone;class;cluster headache;computer cluster;gene expression profiling;genetic heterogeneity;mental association;mesenchymal stem cells;microarray;osteoblasts;principal component analysis;silo (dataset);cell wall organization;skeletal development;subclass	Jorn R. de Haan;Ester Piek;René C. van Schaik;Jacob de Vlieg;Susanne Bauerschmidt;Lutgarde M. C. Buydens;Ron Wehrens	2009		10.1186/1471-2105-11-158	biology;gene expression;dna microarray;bioinformatics;cell cycle;data mining;mesenchymal stem cell;gene expression profiling;cluster analysis;genetics;cellular differentiation;cell wall;principal component analysis	Comp.	5.684658757903292	-54.752970473958364	132742
1c9a6c71a2f990f992c23713bd2ef9bbbe65db44	network enhancement as a general method to denoise weighted biological networks		Networks are ubiquitous in biology where they encode connectivity patterns at all scales of organization, from molecular to the biome. However, biological networks are noisy due to the limitations of measurement technology and inherent natural variation, which can hamper discovery of network patterns and dynamics. We propose Network Enhancement (NE), a method for improving the signal-to-noise ratio of undirected, weighted networks. NE uses a doubly stochastic matrix operator that induces sparsity and provides a closed-form solution that increases spectral eigengap of the input network. As a result, NE removes weak edges, enhances real connections, and leads to better downstream performance. Experiments show that NE improves gene–function prediction by denoising tissue-specific interaction networks, alleviates interpretation of noisy Hi-C contact maps from the human genome, and boosts fine-grained identification accuracy of species. Our results indicate that NE is widely applicable for denoising biological networks. Technical noise in experiments is unavoidable, but it introduces inaccuracies into the biological networks we infer from the data. Here, the authors introduce a diffusion-based method for denoising undirected, weighted networks, and show that it improves the performances of downstream analyses.	biological network;doubly stochastic model;downstream (software development);encode;experiment;graph (discrete mathematics);inference;map;noise reduction;performance;signal-to-noise ratio;sparse matrix;stochastic matrix;weighted network	Bo Wang;Armin Pourshafeie;Marinka Zitnik;Junjie Zhu;Carlos Daniel Bustamante;Serafim Batzoglou;Jure Leskovec	2018		10.1038/s41467-018-05469-x	genetics;operator (computer programming);artificial intelligence;biological network;doubly stochastic matrix;eigengap;biology;pattern recognition	ML	5.408667711031426	-55.86488324627413	132871
3e8049dc995e576c423a7cf806ab5f4357f4fd1f	cavities tell more than sequences: exploring functional relationships of proteases via binding pockets		Computational approaches play an increasingly important role for the analysis and prediction of selectivity profiles. As most of the successfully administered small molecule drugs bind in depressions on the surface of proteins, physicochemical properties of the pocket-exposed amino acids play a central role in ligand recognition during the binding event. Cavbase is an approach to describe binding sites in terms of the exposed physicochemical properties and to compare them independent of their sequence and fold homology. Classification of proteins by means of their binding-site properties is a promising approach to obtain information necessary for selectivity modeling. For this purpose, the workflow clusterScore has been developed to explore the important parameters of a clustering procedure, which will allow an accurate classification of proteins. It has been successfully applied on two diverse and challenging data sets. The predicted number of clusters, as suggested by clusterScore and the subsequent clustering of proteins are in agreement with the EC and Merops classifications. Furthermore, putative cross-reactivity mapped between calpain-1 and cysteine cathepsins on structural level has so far only been described based on ligand data. In a benchmark study using ligand topology, binding site, and sequence information of eleven serine proteases, the emerging clusters indicate a pronounced correlation between the cavity and ligand data. These results emphasize the importance of binding-site information which should be considered for ligand design during lead optimization cycles. The program clusterScore is freely available and can be downloaded from our Web site www.agklebe.de.	amino acids;anatomy, regional;benchmark (computing);binding sites;cathepsins;classification;cluster analysis;computation;dental caries;depressive disorder;homologous gene;homology (biology);ligands;merops;mathematical optimization;non-small cell lung carcinoma;selectivity (electronic);statistical cluster	Serghei Glinca;Gerhard Klebe	2013	Journal of chemical information and modeling	10.1021/ci300550a	small molecule;bioinformatics;combinatorial chemistry;proteases;binding site;amino acid;cluster analysis;structural classification of proteins database;chemistry;ligand	Comp.	8.91380852687016	-58.35367878308745	133149
8547773e78ca01b7b06a0574c04c94274801d3e0	comparison of three preprocessing filters efficiency in virtual screening: identification of new putative lxrβ regulators as a test case	virtual screening	In silico screening methodologies are widely recognized as efficient approaches in early steps of drug discovery. However, in the virtual high-throughput screening (VHTS) context, where hit compounds are searched among millions of candidates, three-dimensional comparison techniques and knowledge discovery from databases should offer a better efficiency to finding novel drug leads than those of computationally expensive molecular dockings. Therefore, the present study aims at developing a filtering methodology to efficiently eliminate unsuitable compounds in VHTS process. Several filters are evaluated in this paper. The first two are structure-based and rely on either geometrical docking or pharmacophore depiction. The third filter is ligand-based and uses knowledge-based and fingerprint similarity techniques. These filtering methods were tested with the Liver X Receptor (LXR) as a target of therapeutic interest, as LXR is a key regulator in maintaining cholesterol homeostasis. The results show that the three considered filters are complementary so that their combination should generate consistent compound lists of potential hits.	analysis of algorithms;boat dock;cholesterol homeostasis;database;docking (molecular);drug discovery;fingerprint;high-throughput computing;knowledge-based systems;lxr_xref;ligands;liver x receptor-like family;liver x receptors;liver diseases;pharmacophore;preprocessor;test case;thrombocytopenia;throughput;virtual screening	Leo Ghemtio;Marie-Dominique Devignes;Malika Smaïl-Tabbone;Michel Souchet;Vincent Leroux;Bernard Maigret	2010	Journal of chemical information and modeling	10.1021/ci900356m	simulation;chemistry;virtual screening;bioinformatics;computational chemistry;data mining	Comp.	9.84668388997445	-58.2989221641748	133316
3c119609bbb6ae0308c627a48ee45b91f0251f0c	sima: simultaneous multiple alignment of lc/ms peak lists	multiple;multiple alignment	MOTIVATION Alignment of multiple liquid chromatography/mass spectrometry (LC/MS) experiments is a necessity today, which arises from the need for biological and technical repeats. Due to limits in sampling frequency and poor reproducibility of retention times, current LC systems suffer from missing observations and non-linear distortions of the retention times across runs. Existing approaches for peak correspondence estimation focus almost exclusively on solving the pairwise alignment problem, yielding straightforward but suboptimal results for multiple alignment problems.   RESULTS We propose SIMA, a novel automated procedure for alignment of peak lists from multiple LC/MS runs. SIMA combines hierarchical pairwise correspondence estimation with simultaneous alignment and global retention time correction. It employs a tailored multidimensional kernel function and a procedure based on maximum likelihood estimation to find the retention time distortion function that best fits the observed data. SIMA does not require a dedicated reference spectrum, is robust with regard to outliers, needs only two intuitive parameters and naturally incorporates incomplete correspondence information. In a comparison with seven alternative methods on four different datasets, we show that SIMA yields competitive and superior performance on real-world data.   AVAILABILITY A C++ implementation of the SIMA algorithm is available from http://hci.iwr.uni-heidelberg.de/MIP/Software.	algorithm;amyotrophic lateral sclerosis;bernhard schölkopf;bioinformatics;c++;dfg peptide;distortion;experiment;f1 score;fits;inference;kernel;liquid chromatography mass spectrometry;maximum likelihood estimation;metabolomics;midazolam;multiple sequence alignment;nonlinear system;partial;proteomics;random sample consensus;sebastian syndrome;sampling (signal processing);sampling - surgical action;sharp mz;time series;weight;word lists by frequency;algorithm	Björn Voß;Michael Hanselmann;Bernhard Y. Renard;Martin S. Lindner;Ullrich Köthe;Marc Kirchner;Fred A. Hamprecht	2011	Bioinformatics	10.1093/bioinformatics/btr051	biology;multiple sequence alignment;bioinformatics;artificial intelligence;multiple;statistics	Comp.	3.6796384744797006	-52.54798934278105	133719
1ce0432c594b6abb660c66a980fae05553ce10de	the role of hepatitis c virus in the dynamic protein interaction networks of hepatocellular cirrhosis and carcinoma	dynamic network;hcv;hcc;hepatocellular cirrhosis;hepatocellular carcinoma;hepatitis c virus;protein interaction network	As an important risk factor for Hepatocellular Carcinoma (HCC), Hepatitis C Virus (HCV) infection can induce cirrhosis and HCC. But, the molecular mechanisms of HCV-induced transformation remain largely unknown. In this study, first, we identified the dysfunctional protein interaction networks in cirrhosis and HCC based on the gene expression profiles of 19 normal, 58 cirrhotic and 47 HCC liver tissues. Then, the relationship between dysfunctional networks and HCV infection was analysed. Our results may help understand the mechanisms of HCV-induced malignant transformation and provide clues to cirrhosis and HCC therapy or prevention.		Tao Huang;Lei Liu;Qi Liu;Guohui Ding;Yejun Tan;Zhidong Tu;Yixue Li;Hongyue Dai;Lu Xie	2011	International journal of computational biology and drug design	10.1504/IJCBDD.2011.038654	dynamic network analysis	Comp.	6.307051524556637	-58.528873820740564	134214
84edacc60bb65c2631fa1c1bce9ef21beaa48de7	learning biological network using mutual information and conditional independence	structure learning;conditional independence;low dose;bayesian network;protein array analysis;signaling network;dna binding proteins;signal transduction;gene regulatory networks;reversed phase;bayes theorem;quantum dots;computational biology bioinformatics;dose response relationship radiation;reproducibility of results;protein protein interaction;biological systems;mutual information;algorithms;signaling pathway;ionizing radiation;tumor suppressor proteins;combinatorial libraries;proteomics;protein serine threonine kinases;computer appl in life sciences;biological network;microarrays;bioinformatics;cell cycle proteins;cell line	Biological networks offer us a new way to investigate the interactions among different components and address the biological system as a whole. In this paper, a reverse-phase protein microarray (RPPM) is used for the quantitative measurement of proteomic responses. To discover the signaling pathway responsive to RPPM, a new structure learning algorithm of Bayesian networks is developed based on mutual Information, conditional independence, and graph immorality. Trusted biology networks are thus predicted by the new approach. As an application example, we investigate signaling networks of ataxia telangiectasis mutation (ATM). The study was carried out at different time points under different dosages for cell lines with and without gene transfection. To validate the performance ofthe proposed algorithm, comparison experiments were also implemented using three well-known networks. From the experiment results, our approach produces more reliable networks with a relatively small number of wrong connection especially in mid-size networks. By using the proposed method, we predicted different networks for ATM under different doses of radiation treatment, and those networks were compared with results from eight different protein protein interaction (PPI) databases. By using a new protein microarray technology in combination with a new computational framework, we demonstrate an application of the methodology to the study of biological networks of ATM cell lines under low dose ionization radiation.	atm turbo;algorithm;bayesian network;biological network;biological system;cultured cell line;database;dosage;episodic ataxia type 2 (disorder);experiment;friedreich ataxia;gene regulatory network;graph - visual representation;microarray analysis;mutation testing;mutual information;pixel density;protein microarrays;proteomics;proton pump inhibitors;reverse phase protein lysate microarray;signal transduction pathways;telangiectasis;protein protein interaction	Dong-Chul Kim;Xiaoyu Wang;Chin-Rang Yang;Jean Gao	2010		10.1186/1471-2105-11-S3-S9	biology;cell biology;bioinformatics;proteomics;genetics;signal transduction	Comp.	6.5548162526875675	-57.12843070290986	134701
3ce11af57c8ab50c96b7a00d814a39c0dc3dc7f2	poisson factor models with applications to non-normalized microrna profiling	software;high throughput nucleotide sequencing;cluster analysis;models statistical;algorithms;humans;micrornas;article;gene expression profiling;poisson distribution	MOTIVATION Next-generation (NextGen) sequencing is becoming increasingly popular as an alternative for transcriptional profiling, as is the case for micro RNAs (miRNA) profiling and classification. miRNAs are a new class of molecules that are regulated in response to differentiation, tumorigenesis or infection. Our primary motivating application is to identify different viral infections based on the induced change in the host miRNA profile. Statistical challenges are encountered because of special features of NextGen sequencing data: the data are read counts that are extremely skewed and non-negative; the total number of reads varies dramatically across samples that require appropriate normalization. Statistical tools developed for microarray expression data, such as principal component analysis, are sub-optimal for analyzing NextGen sequencing data.   RESULTS We propose a family of Poisson factor models that explicitly takes into account the count nature of sequencing data and automatically incorporates sample normalization through the use of offsets. We develop an efficient algorithm for estimating the Poisson factor model, entitled Poisson Singular Value Decomposition with Offset (PSVDOS). The method is shown to outperform several other normalization and dimension reduction methods in a simulation study. Through analysis of an miRNA profiling experiment, we further illustrate that our model achieves insightful dimension reduction of the miRNA profiles of 18 samples: the extracted factors lead to more accurate and meaningful clustering of the cell lines.   AVAILABILITY The PSVDOS software is available on request.	biopolymer sequencing;carcinogenesis;cluster analysis;cultured cell line;dimensionality reduction;estimated;extraction;infection;micrornas;microarray;nextgen healthcare record system;principal component analysis;simulation;singular value decomposition;transcription, genetic;virus diseases;x-ray microtomography;algorithm;statistical cluster	Seonjoo Lee;Pauline E. Chugh;Haipeng Shen;Rebekka Eberle;Dirk P. Dittmer	2013	Bioinformatics	10.1093/bioinformatics/btt091	biology;computer science;bioinformatics;data science;data mining;gene expression profiling;poisson distribution;cluster analysis;genetics;statistics;microrna	Comp.	4.445216989092551	-52.950352709190945	134857
e54b216a9c2869b5d8b421db63add2fedf294295	a novel logic-based approach for quantitative toxicology prediction		There is a pressing need for accurate in silico methods to predict the toxicity of molecules that are being introduced into the environment or are being developed into new pharmaceuticals. Predictive toxicology is in the realm of structure activity relationships (SAR), and many approaches have been used to derive such SAR. Previous work has shown that inductive logic programming (ILP) is a powerful approach that circumvents several major difficulties, such as molecular superposition, faced by some other SAR methods. The ILP approach reasons with chemical substructures within a relational framework and yields chemically understandable rules. Here, we report a general new approach, support vector inductive logic programming (SVILP), which extends the essentially qualitative ILP-based SAR to quantitative modeling. First, ILP is used to learn rules, the predictions of which are then used within a novel kernel to derive a support-vector generalization model. For a highly heterogeneous dataset of 576 molecules with known fathead minnow fish toxicity, the cross-validated correlation coefficients (R2CV) from a chemical descriptor method (CHEM) and SVILP are 0.52 and 0.66, respectively. The ILP, CHEM, and SVILP approaches correctly predict 55, 58, and 73%, respectively, of toxic molecules. In a set of 165 unseen molecules, the R2 values from the commercial software TOPKAT and SVILP are 0.26 and 0.57, respectively. In all calculations, SVILP showed significant improvements in comparison with the other methods. The SVILP approach has a major advantage in that it uses ILP automatically and consistently to derive rules, mostly novel, describing fragments that are toxicity alerts. The SVILP is a general machine-learning approach and has the potential of tackling many problems relevant to chemoinformatics including in silico drug design.	adverse reaction to drug;chemical procedure;cheminformatics;coefficient;commercial software;diagnostic service section id - toxicology;dosage forms;drug design;generalization (psychology);genetic heterogeneity;inductive logic programming;inductive reasoning;machine learning;pseudobarbus quathlambae;rule (guideline);silo (dataset);xiap gene	Ata Amini;Stephen Muggleton;Huma Lodhi;Michael J. E. Sternberg	2007	Journal of chemical information and modeling	10.1021/ci600223d	chemistry;computer science;bioinformatics;machine learning;data mining	ML	8.07297640088188	-54.9570561700451	135065
3e2ed1065abaaee3c368a65b30704746b85e386d	cascade_scan: mining signal transduction network from high-throughput data based on steepest descent method	pheromones;yeasts;signal transduction;steepest descent method;intracellular signaling;computational method;computational biology bioinformatics;signal transduction networks;feedback;proteins;transcription factor;protein protein interaction;algorithms;signaling pathway;combinatorial libraries;high throughput;proteomics;computational biology;computer appl in life sciences;biological process;microarrays;bioinformatics	Signal transduction is an essential biological process involved in cell response to environment changes, by which extracellular signaling initiates intracellular signaling. Many computational methods have been generated in mining signal transduction networks with the increasing of high-throughput genomic and proteomic data. However, more effective means are still needed to understand the complex mechanisms of signaling pathways. We propose a new approach, namely CASCADE_SCAN, for mining signal transduction networks from high-throughput data based on the steepest descent method using indirect protein-protein interactions (PPIs). This method is useful for actual biological application since the given proteins utilized are no longer confined to membrane receptors or transcription factors as in existing methods. The precision and recall values of CASCADE_SCAN are comparable with those of other existing methods. Moreover, functional enrichment analysis of the network components supported the reliability of the results. CASCADE_SCAN is a more suitable method than existing methods for detecting underlying signaling pathways where the membrane receptors or transcription factors are unknown, providing significant insight into the mechanism of cellular signaling in growth, development and cancer. A new tool based on this method is freely available at http://www.genomescience.com.cn/CASCADE_SCAN/ .	biological processes;cell signaling;computation;gene ontology term enrichment;gradient descent;high-throughput computing;interaction;precision and recall;proteomics;sensor;signal transduction;transcription factor;throughput;transcription (software);transduction (machine learning)	Kai Wang;Fuyan Hu;Kejia Xu;Hua Cheng;Meng Jiang;Ruili Feng;Jing Li;Tieqiao Wen	2010		10.1186/1471-2105-12-164	biology;molecular biology;cell biology;bioinformatics;proteomics;signal transduction	Comp.	2.906856038647614	-58.15479318874629	135080
02c8d7b1216bd6b4d9d35e82a79f2ebb509edaf4	identifying frequent patterns in biochemical reaction networks: a workflow		Computational models in biology encode molecular and cell biological processes. Many of these models can be represented as biochemical reaction networks. Studying such networks, one is mostly interested in systems that share similar reactions and mechanisms. Typical goals of an investigation thus include understanding of model parts, identification of reoccurring patterns and recognition of biologically relevant motifs. The large number and size of available models, however, require automated methods to support researchers in achieving their goals. Specifically for the problem of finding patterns in large networks only partial solutions exist. We propose a workflow that identifies frequent structural patterns in biochemical reaction networks encoded in the Systems Biology Markup Language. The workflow utilizes a subgraph mining algorithm to detect the network patterns. Once patterns are identified, the textual pattern description can automatically be converted into a graphical representation. Furthermore, information about the distribution of patterns among a selected set of models can be retrieved. The workflow was validated with 575 models from the curated branch of BioModels. In this paper, we highlight interesting and frequent structural patterns. Furthermore, we provide exemplary patterns that incorporate terms from the Systems Biology Ontology. Our workflow can be applied to a custom set of models or to models already existing in our graph database MaSyMoS. The occurrences of frequent patterns may give insight into the encoding of central biological processes, evaluate postulated biological motifs or serve as a similarity measure for models that share common structures.Database URL: https://github.com/FabienneL/BioNet-Mining.	algorithm;biomodels database;biochemical reaction;computation;encode (action);graph database;graphical user interface;markup language;sbml;similarity measure;solutions;structural pattern;systems biology ontology;uniform resource locator	Fabienne Lambusch;Dagmar Waltemath;Olaf Wolkenhauer;Kurt Sandkuhl;Christian Rosenke;Ron Henkel	2018	Database : the journal of biological databases and curation	10.1093/database/bay051	data mining;knowledge extraction;graph database;computer science;workflow;pattern detection;systems biology;bioinformatics	ML	3.000523269568178	-57.85410448245386	135133
ed91fd4a516569bbcac7df537075cd8e8f470ebf	probe rank approaches for gene selection in oligonucleotide arrays with a small number of replicates	use;treatment effect;pulga de dna;puce a dna;interaction;selection;gen;area of interest;chip;gene expression;variations;utilisation;expression genique;statistical analysis;uso;dna chip;gene;number;interaccion;differentially expressed gene;variacion;variation;seleccion;nombre;gene selection;expresion genetica;numero;perfect match	MOTIVATION One major area of interest in analyzing oligonucleotide gene array data is identifying differentially expressed genes. A challenge to biostatisticians is to develop an approach to summarizing probe-level information that adequately reflects the true expression level while accounting for probe variation, chip variation and interaction effects. Various statistical tools, such as MAS and RMA, have been developed to address this issue. In these approaches, the probe level expression data are summarized into gene level data, which are then used for downstream statistical analysis. Since probe variation is often larger than chip variation and there is also a potential interaction effect between probe affinity and treatment effect, strategies such as a gene level analysis, may not be optimal. In this study, we propose a procedure to analyze probe level data for selecting differentially expressed genes under two treatment conditions (groups) with a small number of replicates. The probe level discrepancy between two groups can be measured by a difference of the percentiles of probe perfect-match (PM) ranks or of probe PM weighted ranks. The difference is then compared with a pre-specified threshold to determine differentially expressed genes. The probe level approach takes into account non-homogenous treatment effects and reduces possible cross-hybridization effects across a set of probes.   RESULTS The proposed approach is compared with MAS and RMA using two benchmark gene array datasets. Positive predictivity and sensitivity are used for evaluation. Results show the proposed approach has higher positive predictivity and higher sensitivity.   AVAILABILITY Available on request from the authors.   CONTACT dtchen@uab.edu.	benchmark (computing);dna microarray;discrepancy function;downstream (software development);large;nucleic acid hybridization;processor affinity;registered medical assistant (occupation);revolution in military affairs;percentile	Dung-Tsa Chen;James J. Chen;Seng-jaw Soong	2005	Bioinformatics	10.1093/bioinformatics/bti413	chip;gene-centered view of evolution;biology;selection;interaction;gene expression;dna microarray;numero sign;bioinformatics;gene;average treatment effect;theme and variations;genetics;grammatical number	Comp.	4.87152351586544	-53.26213315966617	135190
33e8ac50f9154b82cbd7ec5f409d815f3a874d0a	social network analysis of gene expression data		To investigate the structure of genomic interaction network, social affiliation network analysis was performed for the yeast gene expression compendium dataset of hundreds of systematic perturbations. Network density and centrality indices of genes and groups of genes revealed the core-peripheral and the significant intermediary players that may be critical for the control of the biological system.	biological system;centrality;compendium;gene expression;interaction network;peripheral;silo (dataset);social network analysis	Jung Hun Ohn;Jihoon Kim;Ju Han Kim	2003	AMIA ... Annual Symposium proceedings. AMIA Symposium		network analysis;regulation of gene expression;gene;gene expression;social network analysis;gene expression profiling;centrality;genetics;interaction network;bioinformatics;biology	Theory	5.053211542256917	-57.32552402835122	135372
013875267a5e0517b6d0c77f285a642821778241	generation of gene ontology benchmark datasets with various types of positive signal	databases genetic;a1 refereed journal article;computational biology bioinformatics;clustering method;algorithms;differentially expressed gene;user computer interface;combinatorial libraries;computational biology;computer appl in life sciences;information storage and retrieval;microarrays;bioinformatics;gene ontology	The analysis of over-represented functional classes in a list of genes is one of the most essential bioinformatics research topics. Typical examples of such lists are the differentially expressed genes from transcriptional analysis which need to be linked to functional information represented in the Gene Ontology (GO). Despite the importance of this procedure, there is a little work on consistent evaluation of various GO analysis methods. Especially, there is no literature on creating benchmark datasets for GO analysis tools. We propose a methodology for the evaluation of GO analysis tools, which consists of creating gene lists with a selected signal level and a selected number of independent over-represented classes. The methodology starts with a real life GO data matrix, and therefore the generated datasets have similar features to real positive datasets. The user can select the signal level for over-representation, the number of independent positive classes in the dataset, and the size of the final gene list. We present the use of the effective number and various normalizations while embedding the signal to a selected class or classes and the use of binary correlation to ensure that the selected signal classes are independent with each other. The usefulness of generated datasets is demonstrated by comparing different GO class ranking and GO clustering methods. The presented methods aid the development and evaluation of GO analysis methods as they enable thorough testing with different signal types and different signal levels. As an example, our comparisons reveal clear differences between compared GO clustering and GO de-correlation methods. The implementation is coded in Matlab and is freely available at the dedicated website http://ekhidna.biocenter.helsinki.fi/users/petri/public/POSGODA/POSGODA.html .	benchmark (computing);bioinformatics;class;cluster analysis;embedding;gene ontology;matlab;real life;signal-to-noise ratio;silo (dataset);transcription, genetic;web site;statistical cluster	Petri Törönen;Petri Pehkonen;Liisa Holm	2008	BMC Bioinformatics	10.1186/1471-2105-10-319	biology;dna microarray;computer science;bioinformatics;data mining;information retrieval	Comp.	5.106312221469769	-54.13641795305638	135437
f315fd1a7af2c4e261edeebaf94b95ee05ca14f8	system-wide peripheral biomarker discovery using information theory	information theory	The identification of reliable peripheral biomarkers for clinical diagnosis, patient prognosis, and biological functional studies would allow for access to biological information currently available only through invasive methods. Traditional approaches have so far considered aspects of tissues and biofluid markers independently. Here we introduce an information theoretic framework for biomarker discovery, integrating biofluid and tissue information. This allows us to identify tissue information in peripheral biofluids. We treat tissue-biofluid interactions as an information channel through functional space using 26 proteomes from 45 different sources to determine quantitatively the correspondence of each biofluid for specific tissues via relative entropy calculation of proteomes mapped onto phenotype, function, and drug space. Next, we identify candidate biofluids and biomarkers responsible for functional information transfer (p < 0.01). A total of 851 unique candidate biomarkers proxies were identified. The biomarkers were found to be significant functional tissue proxies compared to random proteins (p < 0.001). This proxy link is found to be further enhanced by filtering the biofluid proteins to include only significant tissue-biofluid information channels and is further validated by gene expression. Furthermore, many of the candidate biomarkers are novel and have yet to be explored. In addition to characterizing proteins and their interactions with a systemic perspective, our work can be used as a roadmap to guide biomedical investigation, from suggesting biofluids for study to constraining the search for biomarkers. This work has applications in disease screening, diagnosis, and protein function studies.	biological markers;body tissue;disease screening;gene expression;information theory;interaction;kullback–leibler divergence;nih roadmap initiative tag;patients;peripheral neuropathy;peripheral vascular diseases;proteome;proxy;mapped	Gil Alterovitz;Michael Xiang;Jonathan Liu;Amelia Chang;Marco Ramoni	2008	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing			Comp.	5.439629259763635	-57.760992903824615	135817
070faf409d97b8b84076f87aeda45f9d2efc8835	recognition of microrna-binding sites in proteins from sequences using laplacian support vector machines with a hybrid feature	sequences;support vector machines biochemistry bioinformatics bonds chemical evolution biological genetics internet learning artificial intelligence molecular biophysics molecular configurations proteins rna sequences;support vector machines;molecular configurations;evolution biological;proteins amino acids predictive models support vector machines prediction algorithms reliability training;mbindr web server microrna binding site recognition protein sequences laplacian support vector machines mirna binding residue recognition gene silencing semisupervised learning method lapsvm hybrid feature data labelling evolutionary information amino acid sequence mutual interaction propensities protein mirna complex structures lapsvm model performance f1 score auc value area under the roc curve value;会议论文;genetics;internet;rna;proteins;molecular biophysics;mutual interaction propensities laplacian support vector machine mirna binding residues evolutionary information;learning artificial intelligence;bonds chemical;biochemistry;bioinformatics	The recognition of microRNA (miRNA)-binding residues in proteins would further enhance our understanding of how miRNAs silence their target genes and some relevant biological processes. Due to the insufficient labeled examples, traditional methods such as SVMs could not work well on such problems. Thus, we propose a semi-supervised learning method, i.e., Laplacian Support Vector Machine (LapSVM) for recognizing miRNA-binding residues in proteins from sequences by making use of both labeled and unlabeled data in this article. A hybrid feature is put forward for coding instances which incorporates evolutionary information of the amino acid sequence and mutual interaction propensities in protein-miRNA complex structures. The results indicate that the LapSVM model receives good performance with a F1 score of 22.06±0.28% and an AUC (area under the ROC curve) value of 0.760±0.043. A web server called MBindR is built and freely available at http:// cbi.njupt.edu.cn/MBindR/MBindR.htm for academic usage.	f1 score;machine learning;peptide sequence;receiver operating characteristic;semi-supervised learning;semiconductor industry;server (computing);supervised learning;support vector machine;web server	Jiansheng Wu;Wei Han;Dong Hu;Xin Xu;Shancheng Yan;Lihua Tang	2013	2013 6th International Conference on Biomedical Engineering and Informatics	10.1109/BMEI.2013.6746990	biology;support vector machine;the internet;rna;computer science;bioinformatics;machine learning;pattern recognition;sequence;genetics;molecular biophysics	ML	9.609819670818721	-55.70700586412658	136713
6dd86900568ab05dca3f55e162194686c3c5af1e	penndiff: detecting differential alternative splicing and transcription by rna sequencing		Motivation Alternative splicing and alternative transcription are a major mechanism for generating transcriptome diversity. Differential alternative splicing and transcription (DAST), which describe different usage of transcript isoforms across different conditions, can complement differential expression in characterizing gene regulation. However, the analysis of DAST is challenging because only a small fraction of RNA-seq reads is informative for isoforms. Several methods have been developed to detect exon-based and gene-based DAST, but they suffer from power loss for genes with many isoforms.   Results We present PennDiff, a novel statistical method that makes use of information on gene structures and pre-estimated isoform relative abundances, to detect DAST from RNA-seq data. PennDiff has several advantages. First, grouping exons avoids multiple testing for 'exons' originated from the same isoform(s). Second, it utilizes all available reads in exon-inclusion level estimation, which is different from methods that only use junction reads. Third, collapsing isoforms sharing the same alternative exons reduces the impact of isoform expression estimation uncertainty. PennDiff is able to detect DAST at both exon and gene levels, thus offering more flexibility than existing methods. Simulations and analysis of a real RNA-seq dataset indicate that PennDiff has well-controlled type I error rate, and is more powerful than existing methods including DEXSeq, rMATS, Cuffdiff, IUTA and SplicingCompass. As the popularity of RNA-seq continues to grow, we expect PennDiff to be useful for diverse transcriptomics studies.   Availability and implementation PennDiff source code and user guide is freely available for download at https://github.com/tigerhu15/PennDiff.   Supplementary information Supplementary data are available at Bioinformatics online.		Yu Hu;Jennie Lin;Jian Hu;Gang Hu;Kui Wang;Hanrui Zhang;Muredach P. Reilly;Mingyao Li	2018	Bioinformatics	10.1093/bioinformatics/bty097	computer science;rna;alternative splicing;transcription (biology);bioinformatics	Comp.	3.348230940522702	-54.35126723218273	136908
cb3b4c5a30b2527c39cb0d11eead7864010a87a3	pcm-sabre: a platform for benchmarking and comparing outcome prediction methods in precision cancer medicine	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	Numerous publications attempt to predict cancer survival outcome from gene expression data using machine-learning methods. A direct comparison of these works is challenging for the following reasons: (1) inconsistent measures used to evaluate the performance of different models, and (2) incomplete specification of critical stages in the process of knowledge discovery. There is a need for a platform that would allow researchers to replicate previous works and to test the impact of changes in the knowledge discovery process on the accuracy of the induced models. We developed the PCM-SABRE platform, which supports the entire knowledge discovery process for cancer outcome analysis. PCM-SABRE was developed using KNIME. By using PCM-SABRE to reproduce the results of previously published works on breast cancer survival, we define a baseline for evaluating future attempts to predict cancer outcome with machine learning. We used PCM-SABRE to replicate previous work that describe predictive models of breast cancer recurrence, and tested the performance of all possible combinations of feature selection methods and data mining algorithms that was used in either of the works. We reconstructed the work of Chou et al. observing similar trends – superior performance of Probabilistic Neural Network (PNN) and logistic regression (LR) algorithms and inconclusive impact of feature pre-selection with the decision tree algorithm on subsequent analysis. PCM-SABRE is a software tool that provides an intuitive environment for rapid development of predictive models in cancer precision medicine.	algorithm;baseline (configuration management);data mining;decision tree;feature selection;forecast of outcome;gene expression;knime - the open analytics platform;lr parser;list of algorithms;logistic regression;machine learning;mammary neoplasms;partial;patient-centered medicine;precision medicine;predictive modelling;probabilistic neural network;programming tool;protein-energy malnutrition;sabre (computer system);scientific publication;self-replicating machine;self-replication;specification;perineuronal net (cell component)	Noah Eyal-Altman;Mark Last;Eitan Rubin	2016		10.1186/s12859-016-1435-5	biology;dna microarray;computer science;bioinformatics;data science;data mining	ML	7.2093872238215635	-53.489546276720404	136948
32be293a15cf5f3766dae1cea1cc4e2876c50675	positive sample only learning (psol) for predicting rna genes in e. coli	biology computing;genetics;learning (artificial intelligence);macromolecules;molecular biophysics;proteins;e. coli k12 genome;discriminative methods;functional rna gene prediction;noncoding genomic sequences;positive sample only learning;protein gene identification	"""RNA genes lack most of the signals used for protein gene identification. A major shortcoming of previous discriminative methods to distinguish functional RNA (fRNA) genes from other non-coding genomic sequences is that only positive examples of fRNAs are known; there are no confirmed negatives - only intergenic sequences that may be positive or negative. To address this problem we developed the """"positive sample only learning"""" (PSOL) method. This method can identify the most likely negative examples from an unlabeled set and is therefore able to distinguish putative functional RNA genes from other non-coding sequence. We compare RNA gene predictions using the PSOL method with previous large-scale analyses of the E. coli K12 genome."""	bioinformatics;computational resource;homology (biology);microarray;statistical classification	Richard F. Meraz;Xiaofeng He;Chris H. Q. Ding;Stephen R. Holbrook	2004	Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.	10.1109/CSB.2004.1332488	macromolecule;biology;molecular biology;whole genome sequencing;bioinformatics;genetics;gene prediction;molecular biophysics	Comp.	9.057532585917407	-54.88139945009403	136977
08077245dcd4b5aa2e1c1407e69c2269a7b28c0d	a multiple network learning approach to capture system-wide condition-specific responses	saccharomyces cerevisiae;learning;systeme apprentissage;reseau;proceso adquisicion;acquisition process;red;aprendizaje;apprentissage;artificial intelligence;computational biology;multiple;computer simulation;processus acquisition;network	MOTIVATION Condition-specific networks capture system-wide behavior under varying conditions such as environmental stresses, cell types or tissues. These networks frequently comprise parts that are unique to each condition, and parts that are shared among related conditions. Existing approaches for learning condition-specific networks typically identify either only differences or only similarities across conditions. Most of these approaches first learn networks per condition independently, and then identify similarities and differences in a post-learning step. Such approaches do not exploit the shared information across conditions during network learning.   RESULTS We describe an approach for learning condition-specific networks that identifies the shared and unique subgraphs during network learning simultaneously, rather than as a post-processing step. Our approach learns networks across condition sets, shares data from different conditions and produces high-quality networks that capture biologically meaningful information. On simulated data, our approach outperformed an existing approach that learns networks independently for each condition, especially for small training datasets. On microarray data of hundreds of deletion mutants in two, yeast stationary-phase cell populations, the inferred network structure identified several common and population-specific effects of these deletion mutants and several high-confidence cases of double-deletion pairs, which can be experimentally tested. Our results are consistent with and extend the existing knowledge base of differentiated cell populations in yeast stationary phase.   AVAILABILITY AND IMPLEMENTATION C++ code can be accessed from http://www.broadinstitute.org/~sroy/condspec/ .	body tissue;c++;deletion mutation;experiment;g1 to g0 transition;inference;knowledge base;microarray;population;stationary process;video post-processing;mutant	Sushmita Roy;Margaret Werner-Washburne;Terran Lane	2011	Bioinformatics	10.1093/bioinformatics/btr270	computer simulation;biology;computer science;bioinformatics;artificial intelligence;machine learning;multiple;statistics	Comp.	4.00742836982997	-59.109969806041654	137187
06813b07d7dc402e99912a972a843b591b3c6c24	using protein-protein interactions for refining gene networks estimated from microarray data by bayesian networks	gene network;bayesian network;microarray data;protein protein interaction	We propose a statistical method to estimate gene networks from DNA microarray data and protein-protein interactions. Because physical interactions between proteins or multiprotein complexes are likely to regulate biological processes, using only mRNA expression data is not sufficient for estimating a gene network accurately. Our method adds knowledge about protein-protein interactions to the estimation method of gene networks under a Bayesian statistical framework. In the estimated gene network, a protein complex is modeled as a virtual node based on principal component analysis. We show the effectiveness of the proposed method through the analysis of Saccharomyces cerevisiae cell cycle data. The proposed method improves the accuracy of the estimated gene networks, and successfully identifies some biological facts.	bayesian network;dna microarray format;estimated;fundamental interaction;gene regulatory network;mitotic cell cycle;multiprotein complexes;node - plant part;principal component analysis;staphylococcal protein a;statistical technique;protein protein interaction	Naoki Nariai;SunYong Kim;Seiya Imoto;Satoru Miyano	2004	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		dna microarray;bioinformatics;protein–protein interaction;gene regulatory network;genetics;principal component analysis;gene;microarray analysis techniques;biology;messenger rna;bayesian network	Comp.	5.547719184145368	-56.08037557466152	137333
8a5eda1399c8e7371e92c4ffc1e9a08ebf8b76c5	new statistical methods for estimation of recombination fractions in f2 population	codominant marker;dominant marker;els algorithm;em algorithm;gamete frequency	Dominant markers in an F2 population or a hybrid population have much less linkage information in repulsion phase than in coupling phase. Linkage analysis produces two separate complementary marker linkage maps that have little use in disease association analysis and breeding. There is a need to develop efficient statistical methods and computational algorithms to construct or merge a complete linkage dominant marker maps. The key for doing so is to efficiently estimate recombination fractions between dominant markers in repulsion phases. We proposed an expectation least square (ELS) algorithm and binomial analysis of three-point gametes (BAT) for estimating gamete frequencies from F2 dominant and codominant marker data, respectively. The results obtained from simulated and real genotype datasets showed that the ELS algorithm was able to accurately estimate frequencies of gametes and outperformed the EM algorithm in estimating recombination fractions between dominant loci and recovering true linkage maps of 6 dominant loci in coupling and unknown linkage phases. Our BAT method also had smaller variances in estimation of two-point recombination fractions than the EM algorithm. ELS is a powerful method for accurate estimation of gamete frequencies in dominant three-locus system in an F2 population and BAT is a computationally efficient and fast method for estimating frequencies of three-point codominant gametes.	algorithmic efficiency;batch file;complete linkage cluster analysis;cooperative breeding;estimated;expectation–maximization algorithm;extreme loading for structures;f2 gene;germ cells;locus;least-squares analysis;linkage (software);map;recombination, genetic;genetic linkage	Yuan-De Tan;Xiang H. F. Zhang;Qianxing Mo	2017		10.1186/s12859-017-1804-8	biology;genetic linkage;genetics;dna microarray;complete linkage;merge (version control);bioinformatics;expectation–maximization algorithm;disease association;population;recombination	Comp.	2.842722515231065	-52.57981089072406	137423
4902995b6d752e1fbddcfbffbca19fbf286b0f92	m6avar: a database of functional variants involved in m6a modification		Identifying disease-causing variants among a large number of single nucleotide variants (SNVs) is still a major challenge. Recently, N6-methyladenosine (m6A) has become a research hotspot because of its critical roles in many fundamental biological processes and a variety of diseases. Therefore, it is important to evaluate the effect of variants on m6A modification, in order to gain a better understanding of them. Here, we report m6AVar (http://m6avar.renlab.org), a comprehensive database of m6A-associated variants that potentially influence m6A modification, which will help to interpret variants by m6A function. The m6A-associated variants were derived from three different m6A sources including miCLIP/PA-m6A-seq experiments (high confidence), MeRIP-Seq experiments (medium confidence) and transcriptome-wide predictions (low confidence). Currently, m6AVar contains 16 132 high, 71 321 medium and 326 915 low confidence level m6A-associated variants. We also integrated the RBP-binding regions, miRNA-targets and splicing sites associated with variants to help users investigate the effect of m6A-associated variants on post-transcriptional regulation. Because it integrates the data from genome-wide association studies (GWAS) and ClinVar, m6AVar is also a useful resource for investigating the relationship between the m6A-associated variants and disease. Overall, m6AVar will serve as a useful resource for annotating variants and identifying disease-causing variants.	acute erythroblastic leukemia;dna binding site;experiment;genome-wide association study;mettl3 gene;micrornas;nucleotides;rna splicing;sequence number;transcription, genetic;transcriptional regulation;transcriptome	Yueyuan Zheng;Peng Nie;Di Peng;Zhihao He;Mengni Liu;Yubin Xie;Yanyan Miao;Zhixiang Zuo;Jian Ren	2018		10.1093/nar/gkx895	genetics;microrna;gene;biology	ML	2.8453512394495624	-56.780957917078396	138009
0bc23f5f7fef6b8b4634d1133f0891dbbc78b3e0	using gostats to test gene lists for go term association	gene ontology	MOTIVATION Functional analyses based on the association of Gene Ontology (GO) terms to genes in a selected gene list are useful bioinformatic tools and the GOstats package has been widely used to perform such computations. In this paper we report significant improvements and extensions such as support for conditional testing.   RESULTS We discuss the capabilities of GOstats, a Bioconductor package written in R, that allows users to test GO terms for over or under-representation using either a classical hypergeometric test or a conditional hypergeometric that uses the relationships among GO terms to decorrelate the results.   AVAILABILITY GOstats is available as an R package from the Bioconductor project: http://bioconductor.org	bio-informatics;bioconductor;bioinformatics;computation;gene ontology;r language	Seth Falcon;Robert Gentleman	2007	Bioinformatics	10.1093/bioinformatics/btl567	biology;computer science;bioinformatics;data mining;database	Comp.	4.902390328304174	-53.13204031464621	138793
f06581f7e35909f0d18862e1c765eae3113f540c	association between bivariate expression of key oncogenes and metabolic phenotypes of patients with prostate cancer	akt;myc;metabolite set;oncogene;prostate cancer	"""BACKGROUND AKT and MYC are two of the most prevalent oncogenes associated with prostate cancer. The precise effects of overexpression of these two key oncogenes on the regulation of metabolic pathways in prostate cancer are under active investigation; however, few studies have investigated their bivariate oncogene-pair expressions in metabolic prostate cancer phenotypes. This is primarily due to the lack of a suitable statistical method to analyze the data in the presence of oncogene interactions and within-metabolite-set correlations.   METHODS We analyzed data on the expressions of phosphorylated AKT1 and MYC and the concentrations of 228 metabolites from 60 human prostate tumor samples and 16 normal tissue samples. The metabolomic data allowed us to study not only the measurement of individual metabolites, which can exhibit a dynamic range, but the enriched phenotypes in terms of """"metabolite sets"""" that come from known metabolic pathways. We studied 71 metabolite sets defined by KEGG annotation. We used a modification of linear combination test (LCT) for multiple continuous outcomes to find associations between metabolite sets and oncogenic expressions, after accounting for the correlation between AKT1 and MYC expressions and the correlation between metabolites in a metabolite set. The LCT performance was evaluated using a simulation study.   RESULTS Through a comprehensive analytical method, our study linked oncogenomics and metabolomics data from patients to improve our understanding of the interconnected mechanisms underlying prostate cancer. This study showed that dysregulations of AKT1 and MYC significantly alter the metabolic pathways activated by nonglucose nutrient sources and their downstream targets. Our findings highlighted the role of MYC as the leading, but not the only, oncogene in prostate oncogenesis. In our simulation study, the LCT performed better than the known alternative method, gene-set enrichment analysis (GSEA).   CONCLUSIONS Our study offers a solution for linking genomics and metabolomics, working directly with multiple continuous and correlated measurements."""		Elham Khodayari Moez;Saumyadipta Pyne;Irina A. Dinu	2018	Computers in biology and medicine	10.1016/j.compbiomed.2018.09.017	metabolomics;oncogene;carcinogenesis;metabolite;protein kinase b;cancer research;kegg;artificial intelligence;pattern recognition;prostate cancer;oncogenomics;computer science	Comp.	5.487739010131218	-57.29555796275896	138998
08d33edfcc96160901b982a38b7e2e531ba1c835	predicting protective linear b-cell epitopes using evolutionary information	immunodiagnostic tests;epitope prediction;antigenic sequence evolutionary profiles;computational methods;evolutionary computation;position specific scoring matrix;evolutionary information;selected works;perforation;amino acid;bayes methods;linear b cell epitope;computational method;epitope mapping;vaccine design;naive bayes classifier;antibody production;pattern classification bayes methods bioinformatics cellular biophysics evolutionary computation learning artificial intelligence macromolecules;classifier input representations;b cell epitope mapping;machine learning;b cell;pssm profile;linear b cell epitope epitope mapping epitope prediction;dipeptide composition protective linear b cell epitope prediction evolutionary information b cell epitope mapping vaccine design immunodiagnostic tests antibody production computational methods antigenic sequence evolutionary profiles machine learning methods propensity scale based methods naive bayes classifier classifier input representations amino acid identities position specific scoring matrix profile pssm profile;pattern classification;macromolecules;position specific scoring matrix profile;bepress;protection sequences amino acids databases vaccines proteins bioinformatics immune system testing production;learning artificial intelligence;machine learning methods;propensity scale based methods;protective linear b cell epitope prediction;amino acid identities;dipeptide composition;cellular biophysics;bioinformatics	Mapping B-cell epitopes plays an important role in vaccine design, immunodiagnostic tests, and antibody production. Because the experimental determination of B-cell epitopes is time-consuming and expensive, there is an urgent need for computational methods for reliable identification of putative B-cell epitopes from antigenic sequences. In this study, we explore the utility of evolutionary profiles derived from antigenic sequences in improving the performance of machine learning methods for protective linear B-cell epitope prediction. Specifically, we compare propensity scale based methods with a Naive Bayes classifier using three different representations of the classifier input: amino acid identities, position specific scoring matrix (PSSM) profiles, and dipeptide composition. We find that in predicting protective linear B-cell epitopes, a Naive Bayes classifier trained using PSSM profiles significantly outperforms the propensity scale based methods as well as the Naive Bayes classifiers trained using the amino acid identity or dipeptide composition representations of input data.	computation;machine learning;naive bayes classifier;position weight matrix;protein structure prediction	Yasser El-Manzalawy;Drena Dobbs;Vasant Honavar	2008	2008 IEEE International Conference on Bioinformatics and Biomedicine	10.1109/BIBM.2008.80	macromolecule;biology;naive bayes classifier;amino acid;computer science;bioinformatics;machine learning;pattern recognition;evolutionary computation	Robotics	9.800036904475045	-56.23239433533183	139100
ba191c35dde62056f271652ad564000213054e25	inclusion of textual documentation in the analysis of multidimensional data sets: application to gene expression data	gene annotation;text analysis;multidimensional data;gene expression data;objective function;gene expression;gene expression analysis;indexation;functional genomics;gene expression pattern;natural language processing;bioinformatics	Recently, biology has been confronted with large multidimensional gene expression data sets where the expression of thousands of genes is measured over dozens of conditions. The patterns in gene expression are frequently explained retrospectively by underlying biological principles. Here we present a method that uses text analysis to help find meaningful gene expression patterns that correlate with the underlying biology described in scientific literature. The main challenge is that the literature about an individual gene is not homogenous and may addresses many unrelated aspects of the gene. In the first part of the paper we present and evaluate the neighbor divergence per gene (NDPG) method that assigns a score to a given subgroup of genes indicating the likelihood that the genes share a biological property or function. To do this, it uses only a reference index that connects genes to documents, and a corpus including those documents. In the second part of the paper we present an approach, optimizing separating projections (OSP), to search for linear projections in gene expression data that separate functionally related groups of genes from the rest of the genes; the objective function in our search is the NDPG score of the positively projected genes. A successful search, therefore, should identify patterns in gene expression data that correlate with meaningful biology. We apply OSP to a published gene expression data set; it discovers many biologically relevant projections. Since the method requires only numerical measurements (in this case expression) about entities (genes) with textual documentation (literature), we conjecture that this method could be transferred easily to other domains. The method should be able to identify relevant patterns even if the documentation for each entity pertains to many disparate subjects that are unrelated to each other.	documentation;entity;gene expression profiling;loss function;numerical analysis;optimization problem;scientific literature;text corpus	Soumya Raychaudhuri;Hinrich Schütze;Russ B. Altman	2003	Machine Learning	10.1023/A:1023901610396	text mining;gene expression;computer science;bioinformatics;data mining;information retrieval	Comp.	4.566835488974432	-55.05843172652563	139544
495f7e15a587296cba746a7da8437bbf05cad5c8	detecting protein complexes in protein interaction networks using a ranking algorithm with a refined merging procedure	computational biology bioinformatics;cluster analysis;internet;proteins;algorithms;humans;combinatorial libraries;protein interaction mapping;protein interaction maps;computer appl in life sciences;microarrays;bioinformatics	Developing suitable methods for the identification of protein complexes remains an active research area. It is important since it allows better understanding of cellular functions as well as malfunctions and it consequently leads to producing more effective cures for diseases. In this context, various computational approaches were introduced to complement high-throughput experimental methods which typically involve large datasets, are expensive in terms of time and cost, and are usually subject to spurious interactions. In this paper, we propose ProRank+, a method which detects protein complexes in protein interaction networks. The presented approach is mainly based on a ranking algorithm which sorts proteins according to their importance in the interaction network, and a merging procedure which refines the detected complexes in terms of their protein members. ProRank + was compared to several state-of-the-art approaches in order to show its effectiveness. It was able to detect more protein complexes with higher quality scores. The experimental results achieved by ProRank + show its ability to detect protein complexes in protein interaction networks. Eventually, the method could potentially identify previously-undiscovered protein complexes. The datasets and source codes are freely available for academic purposes at http://faculty.uaeu.ac.ae/nzaki/Research.htm .	algorithm;code;complement system proteins;high-throughput computing;interaction network;throughput;protein protein interaction	Eileen Marie Hanna;Nazar Zaki	2014		10.1186/1471-2105-15-204	the internet;dna microarray;computer science;bioinformatics;data science;data mining;cluster analysis	Comp.	3.917496414232382	-56.06797075518896	139550
ca0fc5a2b65ec373ef7a24f3d4e120e941dbd5a6	identifying disease associated mirnas based on protein domains	databases;disease;network disease microrna protein domain;diseases proteins databases gene expression breast cancer biological processes;gene expression;protein structural blocks disease associated microrna small endogenous noncoding genes post transcriptional processes;proteins;rna diseases molecular biophysics proteins;diseases;microrna;breast cancer;biological processes;network;protein domain	MicroRNAs miRNAs are a class of small endogenous non-coding genes, acting as regulators in the post-transcriptional processes. Recently, the miRNAs are found to be widely involved in different types of diseases. Therefore, the identification of disease associated miRNAs can help understand the mechanisms that underlie the disease and identify new biomarkers. However, it is not easy to identify the miRNAs related to diseases due to its extensive involvements in various biological processes. In this work, we present a new approach to identify disease associated miRNAs based on domains, the functional and structural blocks of proteins. The results on real datasets demonstrate that our method can effectively identify disease related miRNAs with high precision.	biological markers;endogeneity (econometrics);micrornas;transcription, genetic	Gui-Min Qin;Rui-Yi Li;Xing-Ming Zhao	2016	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2016.2515608	biology;molecular biology;gene expression;gene silencing;bioinformatics;breast cancer;protein domain;biological process;genetics;microrna	Comp.	5.7658505103821085	-57.83334192678615	140031
17096b7a1950900f1da73cf89ece3550ed92d9f9	gene interaction enrichment and network analysis to identify dysregulated pathways and their interactions in complex diseases	breast neoplasms;simulation and modeling;dysregulated pathways;epistasis genetic;enrichment analysis;pancreatic neoplasms;bad pathway;disease;systems biology;gene regulatory networks;gene gene interaction;physiological cellular and medical topics;bcl associated death protein;computational biology bioinformatics;cell line tumor;algorithms;humans;computational biology;tumor suppressor protein p53;prognosis;mutation;bioinformatics	The molecular behavior of biological systems can be described in terms of three fundamental components: (i) the physical entities, (ii) the interactions among these entities, and (iii) the dynamics of these entities and interactions. The mechanisms that drive complex disease can be productively viewed in the context of the perturbations of these components. One challenge in this regard is to identify the pathways altered in specific diseases. To address this challenge, Gene Set Enrichment Analysis (GSEA) and others have been developed, which focus on alterations of individual properties of the entities (such as gene expression). However, the dynamics of the interactions with respect to disease have been less well studied (i.e., properties of components ii and iii). Here, we present a novel method called Gene Interaction Enrichment and Network Analysis (GIENA) to identify dysregulated gene interactions, i.e., pairs of genes whose relationships differ between disease and control. Four functions are defined to model the biologically relevant gene interactions of cooperation (sum of mRNA expression), competition (difference between mRNA expression), redundancy (maximum of expression), or dependency (minimum of expression) among the expression levels. The proposed framework identifies dysregulated interactions and pathways enriched in dysregulated interactions; points out interactions that are perturbed across pathways; and moreover, based on the biological annotation of each type of dysregulated interaction gives clues about the regulatory logic governing the systems level perturbation. We demonstrated the potential of GIENA using published datasets related to cancer. We showed that GIENA identifies dysregulated pathways that are missed by traditional enrichment methods based on the individual gene properties and that use of traditional methods combined with GIENA provides coverage of the largest number of relevant pathways. In addition, using the interactions detected by GIENA, specific gene networks both within and across pathways associated with the relevant phenotypes are constructed and analyzed.	annotation;biological system;entity;gene expression;gene ontology term enrichment;gene regulatory network;interaction;neoplasms;perturbation theory;phenotype;redundancy (engineering);scientific publication;emotional dependency	Yu Liu;Mehmet Koyutürk;Jill S. Barnholtz-Sloan;Mark R. Chance	2012		10.1186/1752-0509-6-65	mutation;biology;gene regulatory network;cell biology;bioinformatics;genetics;systems biology	Comp.	5.302300950801518	-58.26189517009394	140064
51b67aa640e334372602c4bc4c43c4849c336662	cnvscan: detecting borderline copy number variations in ngs data via scan statistics	next generation sequencing;computational biology;copy number variation	Background. Next Generation Sequencing (NGS) data has been extensively exploited in the last decade to analyse genome variations and to understand the role of genome variations in complex diseases. Copy number variations (CNVs) are genomic structural variants estimated to account for about 1.2% of the total variation in humans. CNVs in coding or regulatory regions may have an impact on the gene expression, often also at a functional level, and contribute to cause different diseases like cancer, autism and cardiovascular diseases. Computational methods developed for detection of CNVs from NGS data and based on the depth of coverage are limited to the identification of medium/large events and heavily influenced by the level of coverage.  Result. In this paper we propose, CNVScan a CNV detection method based on scan statistics that overcomes limitations of previous read count (RC) based approaches mainly by being a window-less approach. The scans statistics have been used before mainly in epidemiology and ecology studies, but never before was applied to the CNV detection problem to the best of our knowledge. Since we avoid windowing we do not have to choose an optimal window-size which is a key step in many previous approaches. Extensive simulated experiments with single read data in extreme situations (low coverage, short reads, homo/heterozygoticity) show that this approach is very effective for a range of small CNV (200-500 bp) for which previous state-of-the-art methods are not suitable.  Conclusion. The scan statistics technique is applied and adapted in this paper for the first time to the CNV detection problem. Comparison with state-of-the art methods shows the approach is quite effective in discovering short CNV in rather extreme situations in which previous methods fail or have degraded performance. CNVScan thus extends the range of CNV sizes and types that can be detected via read count with single read data.	ct scan;communications satellite;computation;ecology;experiment;sensor;simulation	Elisabetta Bergamini;Romina D'Aurizio;Mauro Leoncini;Marco O O Pellegrini	2015		10.1145/2808719.2808754	biology;dna sequencing;bioinformatics;copy-number variation;genetics	Comp.	2.7692066435494005	-53.96067065989034	140474
2b10dc2effaac336cdf498c7cc8897ce3313220c	a classification and characterization of two-locus, pure, strict, epistatic models for simulation and detection	biological patents;biomedical journals;text mining;europe pubmed central;citation search;data mining and knowledge discovery;citation networks;computational biology bioinformatics;research articles;abstracts;open access;life sciences;clinical guidelines;algorithms;full text;computer appl in life sciences;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	The statistical genetics phenomenon of epistasis is widely acknowledged to confound disease etiology. In order to evaluate strategies for detecting these complex multi-locus disease associations, simulation studies are required. The development of the GAMETES software for the generation of complex genetic models, has provided the means to randomly generate an architecturally diverse population of epistatic models that are both pure and strict, i.e. all n loci, but no fewer, are predictive of phenotype. Previous theoretical work characterizing complex genetic models has yet to examine pure, strict, epistasis which should be the most challenging to detect. This study addresses three goals: (1) Classify and characterize pure, strict, two-locus epistatic models, (2) Investigate the effect of model ‘architecture’ on detection difficulty, and (3) Explore how adjusting GAMETES constraints influences diversity in the generated models. In this study we utilized a geometric approach to classify pure, strict, two-locus epistatic models by “shape”. In total, 33 unique shape symmetry classes were identified. Using a detection difficulty metric, we found that model shape was consistently a significant predictor of model detection difficulty. Additionally, after categorizing shape classes by the number of edges in their shape projections, we found that this edge number was also significantly predictive of detection difficulty. Analysis of constraints within GAMETES indicated that increasing model population size can expand model class coverage but does little to change the range of observed difficulty metric scores. A variable population prevalence significantly increased the range of observed difficulty metric scores and, for certain constraints, also improved model class coverage. These analyses further our theoretical understanding of epistatic relationships and uncover guidelines for the effective generation of complex models using GAMETES. Specifically, (1) we have characterized 33 shape classes by edge number, detection difficulty, and observed frequency (2) our results support the claim that model architecture directly influences detection difficulty, and (3) we found that GAMETES will generate a maximally diverse set of models with a variable population prevalence and a larger model population size. However, a model population size as small as 1,000 is likely to be sufficient.	addresses (publication format);categorization;class;genetic algorithm;germ cells;kerrison predictor;locus;large;mental association;numerous;projections and predictions;randomness;science of genetics;sensor;shape context;simulation	Ryan J. Urbanowicz;Ambrose Granizo-Mackenzie;Jeff Kiralis;Jason H. Moore	2013		10.1186/1756-0381-7-8	biology;text mining;medical research;computer science;bioinformatics;data science;data mining;genetics;algorithm	ML	5.108489903882735	-56.38874457841044	140651
4ed53268c016ad803f870e12204093efb1a18440	boolean analysis reveals systematic interactions among low-abundance species in the human gut microbiome		The analysis of microbiome compositions in the human gut has gained increasing interest due to the broader availability of data and functional databases and substantial progress in data analysis methods, but also due to the high relevance of the microbiome in human health and disease. While most analyses infer interactions among highly abundant species, the large number of low-abundance species has received less attention. Here we present a novel analysis method based on Boolean operations applied to microbial co-occurrence patterns. We calibrate our approach with simulated data based on a dynamical Boolean network model from which we interpret the statistics of attractor states as a theoretical proxy for microbiome composition. We show that for given fractions of synergistic and competitive interactions in the model our Boolean abundance analysis can reliably detect these interactions. Analyzing a novel data set of 822 microbiome compositions of the human gut, we find a large number of highly significant synergistic interactions among these low-abundance species, forming a connected network, and a few isolated competitive interactions.	advance directive - proxy;boolean network;composition;database;databases;gain;hl7publishingsubsection <operations>;inference;interaction;microbiome;network model;relevance;synergy;negative regulation of gut granule assembly	Jens Christian Claussen;Jurgita Skieceviciene;Philipp Rausch;Tom H. Karlsen;Wolfgang Lieb;John F. Baines;Andre Franke;Marc-Thorsten Hütt	2017		10.1371/journal.pcbi.1005361	bioinformatics;boolean analysis;biology;boolean network;microbiome;boolean operations in computer-aided design;data analysis	ML	5.231793926120229	-58.45526312815851	140903
9e7aebad80bf90d6e9cdc4493fb56fd360b91b22	a network partition algorithm for mining gene functional modules of colon cancer from dna microarray data	gn algorithm;xiao gang ruan jin lian wang jian geng li dna微阵列数据 大肠癌 基因功能模块 gn算法 网络分割算法 a network partition algorithm for mining gene functional modules of colon cancer from dna microarray data;colon cancer;gene functional module;dna microarray data;gene function	Computational analysis is essential for transforming the masses of microarray data into a mechanistic understanding of cancer. Here we present a method for finding gene functional modules of cancer from microarray data and have applied it to colon cancer. First, a colon cancer gene network and a normal colon tissue gene network were constructed using correlations between the genes. Then the modules that tended to have a homogeneous functional composition were identified by splitting up the network. Analysis of both networks revealed that they are scale-free. Comparison of the gene functional modules for colon cancer and normal tissues showed that the modules' functions changed with their structures.	biological network;body tissue;colon carcinoma;colon classification;computation;dna microarray;gene regulatory networks;gene regulatory network;genes, regulator;manuscripts;natural science disciplines;neoplasms;network partition;silo (dataset);small;xgr gene;algorithm;interest	Xiao-Gang Ruan;Jinlian Wang;Jian-Geng Li	2006		10.1016/S1672-0229(07)60005-9	biology;bioinformatics;colorectal cancer;data mining;genetics	Comp.	5.980534102397899	-55.86899227430951	141318
89bbe42996198605e59edd8e706c85944174e03d	interpol: an r package for preprocessing of protein sequences	health research;uk clinical guidelines;biological patents;europe pubmed central;amino acid;protein sequence;amino acid sequence;citation search;data mining and knowledge discovery;spectrum;computational biology bioinformatics;machine learning;uk phd theses thesis;linear interpolation;life sciences;algorithms;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;open source;bioinformatics	"""Most machine learning techniques currently applied in the literature need a fixed dimensionality of input data. However, this requirement is frequently violated by real input data, such as DNA and protein sequences, that often differ in length due to insertions and deletions. It is also notable that performance in classification and regression is often improved by numerical encoding of amino acids, compared to the commonly used sparse encoding. The software """"Interpol"""" encodes amino acid sequences as numerical descriptor vectors using a database of currently 532 descriptors (mainly from AAindex), and normalizes sequences to uniform length with one of five linear or non-linear interpolation algorithms. Interpol is distributed with open source as platform independent R-package. It is typically used for preprocessing of amino acid sequences for classification or regression. The functionality of Interpol widens the spectrum of machine learning methods that can be applied to biological sequences, and it will in many cases improve their performance in classification and regression."""	algorithm;amino acid sequence;amino acids;clinical act of insertion;interpolation imputation technique;linear interpolation;machine learning;neural coding;nonlinear system;numerical analysis;open-source software;preprocessor;sparse matrix	Dominik Heider;Daniel Hoffmann	2011		10.1186/1756-0381-4-16	biology;spectrum;amino acid;computer science;bioinformatics;data science;protein sequencing;data mining;peptide sequence;linear interpolation;algorithm	Comp.	6.15661248678796	-52.30231468399745	141581
fd7662aa95aa23d4317806321ceef631b8745507	one-class detection of cell states in tumor subtypes		The cellular composition of a tumor greatly influences the growth, spread, immune activity, drug response, and other aspects of the disease. Tumor cells are usually comprised of a heterogeneous mixture of subclones, each of which could contain their own distinct character. The presence of minor subclones poses a serious health risk for patients as any one of them could harbor a fitness advantage with respect to the current treatment regimen, fueling resistance. It is therefore vital to accurately assess the make-up of cell states within a tumor biopsy. Transcriptome-wide assays from RNA sequencing provide key data from which cell state signatures can be detected. However, the challenge is to find them within samples containing mixtures of cell types of unknown proportions. We propose a novel one-class method based on logistic regression and show that its performance is competitive to two established SVM-based methods for this detection task. We demonstrate that one-class models are able to identify specific cell types in heterogeneous cell populations better than their binary predictor counterparts. We derive one-class predictors for the major breast and bladder subtypes and reaffirm the connection between these two tissues. In addition, we use a one-class predictor to quantitatively associate an embryonic stem cell signature with an aggressive breast cancer subtype that reveals shared stemness pathways potentially important for treatment.	antivirus software;binary classification;bladder tissue;body tissue;embryonic stem cells;genetic heterogeneity;kerrison predictor;logistic regression;mammary neoplasms;method (computer programming);patients;population;subtype (attribute);urinary bladder;cell type;drug response;mixture	Artem Sokolov;Evan O. Paull;Joshua M. Stuart	2016	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		biology;text mining;medical research;computer science;bioinformatics;data mining;genetics	Comp.	8.51261848306934	-55.98766466215566	141866
74139ce904bd9ccbab87b07bb22038911f48de64	reconstructing mutational pathways from serial evolutionary trees	hiv;drugs;mutational pathway reconstruction;hiv infection;mutational pathways phylogenetics evolution of drug resistant mutations evolutionary trees;antiretroviral drug;evolution of drug resistant mutations;organic compounds;rna virus;evolution biological;reverse transcriptase inhibitors;efavirenz;genetics;medical computing;efavirenz mutational pathway reconstruction serial evolutionary tree rna virus hiv hcv evolutionary potential drug resistant strain bioinformatics drug resistant mutation serially sampled viral sequence data antiretroviral drug phylogenetics reverse transcriptase inhibitor;reverse transcriptase inhibitor;serial evolutionary tree;hcv;statistical analysis;evolutionary trees;drug therapy;drug resistant mutation;drugs immune system human immunodeficiency virus rna viruses medical medical treatment capacitive sensors bioinformatics genetic mutations phylogeny;serially sampled viral sequence data;molecular biophysics;clinical study;mutational pathways;macromolecules;diseases;statistical analysis diseases drugs evolution biological genetics macromolecules medical computing microorganisms molecular biophysics organic compounds;drug resistance;microorganisms;evolutionary potential;phylogenetics;drug resistant strain;bioinformatics	RNA viruses like HIV and HCV have an extraordinary evolutionary potential to escape from both immune pressures and targeted drug therapies. In HIV infections, the emergence of drug resistant strains is of particular interest, as it complicates the choice of an optimal follow-up regimen. A series of bioinformatics tools for predicting drug resistance were previously developed to support physicians in this task. A new method is proposed that captures the order of occurrence of drug-resistant mutations and can be applied to serially-sampled viral sequence data from patients taking antiretroviral drugs. The new phylogenetic approach reduces a serial evolutionary tree inferred by the Sliding MinPD program [12] to a set of mutational pathways of drug resistance. The method is applied to data from an HIV-1 clinical study of the reverse transcriptase inhibitor, Efavirenz. This approach can effectively identify mutational pathways by considering all available information and the statistical support for each prediction.	bioinformatics;emergence;phylogenetic tree;phylogenetics	Patricia Buendia	2007	2007 IEEE 7th International Symposium on BioInformatics and BioEngineering	10.1109/BIBE.2007.4375654	macromolecule;biology;biochemistry;phylogenetic tree;drug resistance;bioinformatics;virology;microorganism;genetics;phylogenetics;molecular biophysics	Comp.	3.225469038919242	-54.85677463914762	141945
e975ff96fab47b8cdfe5045132282475d7e363cc	prediction of disulfide connectivity in proteins with machine-learning methods and correlated mutations	cysteine;amino acid sequence;disulfides;computational biology bioinformatics;proteins;artificial intelligence;algorithms;sequence alignment;combinatorial libraries;computer appl in life sciences;mutation;microarrays;bioinformatics	Recently, information derived by correlated mutations in proteins has regained relevance for predicting protein contacts. This is due to new forms of mutual information analysis that have been proven to be more suitable to highlight direct coupling between pairs of residues in protein structures and to the large number of protein chains that are currently available for statistical validation. It was previously discussed that disulfide bond topology in proteins is also constrained by correlated mutations. In this paper we exploit information derived from a corrected mutual information analysis and from the inverse of the covariance matrix to address the problem of the prediction of the topology of disulfide bonds in Eukaryotes. Recently, we have shown that Support Vector Regression (SVR) can improve the prediction for the disulfide connectivity patterns. Here we show that the inclusion of the correlated mutation information increases of 5 percentage points the SVR performance (from 54% to 59%). When this approach is used in combination with a method previously developed by us and scoring at the state of art in predicting both location and topology of disulfide bonds in Eukaryotes (DisLocate), the per-protein accuracy is 38%, 2 percentage points higher than that previously obtained. In this paper we show that the inclusion of information derived from correlated mutations can improve the performance of the state of the art methods for predicting disulfide connectivity patterns in Eukaryotic proteins. Our analysis also provides support to the notion that improving methods to extract evolutionary information from multiple sequence alignments greatly contributes to the scoring performance of predictors suited to detect relevant features from protein chains.	anatomy, regional;direct coupling;disulfide linkage;fifty nine;machine learning;mutation;mutual information;relevance;score;sequence alignment;support vector machine;total peripheral resistance	Castrense Savojardo;Piero Fariselli;Pier Luigi Martelli;Rita Casadio	2013		10.1186/1471-2105-14-S1-S10	mutation;biology;dna microarray;bioinformatics;sequence alignment;peptide sequence;genetics	Comp.	9.504937224344957	-57.8244015161896	142603
f070cf984053efb45216e0b3294327c18135051b	accurate and scalable techniques for the complex/pathway membership problem in protein networks	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;protein network;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	A protein network shows physical interactions as well as functional associations. An important usage of such networks is to discover unknown members of partially known complexes and pathways. A number of methods exist for such analyses, and they can be divided into two main categories based on their treatment of highly connected proteins. In this paper, we show that methods that are not affected by the degree (number of linkages) of a protein give more accurate predictions for certain complexes and pathways. We propose a network flow-based technique to compute the association probability of a pair of proteins. We extend the proposed technique using hierarchical clustering in order to scale well with the size of proteome. We also show that top-k queries are not suitable for a large number of cases, and threshold queries are more meaningful in these cases. Network flow technique with clustering is able to optimize meaningful threshold queries and answer them with high efficiency compared to a similar method that uses Monte Carlo simulation.	categories;cluster analysis;degree (graph theory);flow network;fundamental interaction;gene regulatory network;hierarchical clustering;mental association;monte carlo method;simulation;statistical cluster	Orhan Çamoglu;Tolga Can;Ambuj K. Singh	2009		10.1155/2009/787128	biology;medical research;medicine;computer science;bioinformatics;data science;data mining	Comp.	5.335057509718064	-56.20773934392335	142631
e6e8fe5040fa195e0b43c77b62c3beaacd505b3d	how to improve the statistical power of the 10-fold cross validation scheme in recommender systems	experimental design;folding;paired testing;evaluation;recommender systems	At this stage development of recommender systems (RS), an evaluation of competing approaches (methods) yielding similar performances in terms of experiment reproduction is of crucial importance in order to direct the further development toward the most promising direction. These comparisons are usually based on the 10-fold cross validation scheme. Since the compared performances are often similar to each other, the application of statistical significance testing is inevitable in order to not to get misled by randomly caused differences of achieved performances. For the same reason, to reproduce experiments on a different set of experimental data, the most powerful significance testing should be applied. In this work we provide guidelines on how to achieve the highest power in the comparison of RS and we demonstrate them on a comparison of RS performances when different variables are contextualized.	data validation;experiment;performance;randomness;recommender system	Andrej Kosir;Ante Odic;Marko Tkalcic	2013		10.1145/2532508.2532510	econometrics;simulation;engineering;statistics	AI	5.944516364231705	-52.5201956497965	142653
1afc1f3308e90e77d50bedd7e6185ea49c7c5e3f	shallow sparsely-connected autoencoders for gene set projection		When analyzing biological data, it can be helpful to consider gene sets, or predefined groups of biologically related genes. Methods exist for identifying gene sets that are differential between conditions, but large public datasets from consortium projects and single-cell RNA-Sequencing have opened the door for gene set analysis using more sophisticated machine learning techniques, such as autoencoders and variational autoencoders. We present shallow sparsely-connected autoencoders (SSCAs) and variational autoencoders (SSCVAs) as tools for projecting gene-level data onto gene sets. We tested these approaches on single-cell RNA-Sequencing data from blood cells and on RNASequencing data from breast cancer patients. Both SSCA and SSCVA can recover known biological features from these datasets and the SSCVA method often outperforms SSCA (and six existing gene set scoring algorithms) on classification and prediction tasks.	algorithm;autoencoder;biopolymer sequencing;calculus of variations;machine learning;mammary neoplasms;patients;score;variational principle	Maxwell P. Gold;Alexander LeNail;Ernest Fraenkel	2019				Comp.	7.518437868052877	-52.2809332273857	142686
4983538563af7b7f2a4c9545a9367cd48de85f76	recent advances in the computational discovery of transcription factor binding sites	context specific;transcription factor binding site;regulatory element;transcription factor binding sites;promoter analysis;prior knowledge;binding site;computational method;transcriptional regulatory networks;gene expression;phylogenetic footprinting;transcription factor;high throughput;genome sequence;binding site representation;transcriptional regulatory network	The discovery of gene regulatory elements requires the synergism between computational and experimental techniques in order to reveal the underlying regulatory mechanisms that drive gene expression in response to external cues and signals. Utilizing the large amount of high-throughput experimental data, constantly growing in recent years, researchers have attempted to decipher the patterns which are hidden in the genomic sequences. These patterns, called motifs, are potential binding sites to transcription factors which are hypothesized to be the main regulators of the transcription process. Consequently, precise detection of these elements is required and thus a large number of computational approaches have been developed to support the de novo identification of TFBSs. Even though novel approaches are continuously proposed and almost all have reported some success in yeast and other lower organisms, in higher organisms the problem still remains a challenge. In this paper, we therefore review the recent developments in computational methods for transcription factor binding site prediction. We start with a brief review of the basic approaches for binding site representation and promoter identification, then discuss the techniques to locate physical TFBSs, identify functional binding sites using orthologous information, and infer functional TFBSs within some context defined by additional prior knowledge. Finally, we briefly explore the opportunities for expanding these approaches towards the computational identification of transcriptional regulatory networks.	computation;dna binding site;de novo transcriptome assembly;de-identification;design of experiments;gene regulatory network;high-throughput computing;homology (biology);medical transcription;sequence homology;throughput;transcription (software)	Tung T. Nguyen;Ioannis P. Androulakis	2009	Algorithms	10.3390/a2010582	bioinformatics;dna binding site	Comp.	3.0819568084613675	-58.20584993941351	142782
7e9c8caa9229a661d926cfd30d25ea543c776bf6	enhancements to the admixture algorithm for individual ancestry estimation	software;genetics population;supervised learning;large dataset;allele frequency;genetics;computational biology bioinformatics;gene frequency;likelihood functions;genome human;population groups;artificial intelligence;algorithms;humans;genetic epidemiology;cross validation;combinatorial libraries;computer appl in life sciences;high performance;polymorphism single nucleotide;arsenic;single nucleotide polymorphism;microarrays;bioinformatics;population genetics	The estimation of individual ancestry from genetic data has become essential to applied population genetics and genetic epidemiology. Software programs for calculating ancestry estimates have become essential tools in the geneticist's analytic arsenal. Here we describe four enhancements to ADMIXTURE, a high-performance tool for estimating individual ancestries and population allele frequencies from SNP (single nucleotide polymorphism) data. First, ADMIXTURE can be used to estimate the number of underlying populations through cross-validation. Second, individuals of known ancestry can be exploited in supervised learning to yield more precise ancestry estimates. Third, by penalizing small admixture coefficients for each individual, one can encourage model parsimony, often yielding more interpretable results for small datasets or datasets with large numbers of ancestral populations. Finally, by exploiting multiple processors, large datasets can be analyzed even more rapidly. The enhancements we have described make ADMIXTURE a more accurate, efficient, and versatile tool for ancestry estimation.	central processing unit;coefficient;cross reactions;cross-validation (statistics);estimated;gene frequency;genetic epidemiology;genetics, population;maximum parsimony (phylogenetics);nitroprusside;occam's razor;single nucleotide polymorphism;supervised learning	David H. Alexander;Kenneth Lange	2011		10.1186/1471-2105-12-246	biology;genetic epidemiology;bioinformatics;allele frequency;supervised learning;genetics;evolutionary biology	ML	3.423589447306566	-52.75756971975457	142846
fa91087108d4a9e5c0783bf3f549b90acf436650	bayesian selection of graphical regulatory models	bayesian inference;clustering;time course microarray experiments;article;causality	Definition of a new class of coloured graphical models for regulatory models.Direct representation of typical qualitative hypotheses about regulatory processes.Edge colours directly distinguish important features of the mechanism. We define a new class of coloured graphical models, called regulatory graphs. These graphs have their own distinctive formal semantics and can directly represent typical qualitative hypotheses about regulatory processes like those described by various biological mechanisms. They admit an embellishment into classes of probabilistic statistical models and so standard Bayesian methods of model selection can be used to choose promising candidate explanations of regulation. Regulation is modelled by the existence of a deterministic relationship between the longitudinal series of observations labelled by the receiving vertex and the donating one. This class contains longitudinal cluster models as a degenerate graph. Edge colours directly distinguish important features of the mechanism like inhibition and excitation and graphs are often cyclic. With appropriate distributional assumptions, because the regulatory relationships map onto each other through a group structure, it is possible to define a conditional conjugate analysis. This means that even when the model space is huge it is nevertheless feasible, using a Bayesian MAP search, to a discover regulatory network with a high Bayes Factor score. We also show that, like the class of Bayesian Networks, regulatory graphs also admit a formal but distinctive causal algebra. The topology of the graph then represents collections of hypotheses about the predicted effect of controlling the process by tearing out message passers or forcing them to transmit certain signals. We illustrate our methods on a microarray experiment measuring the expression of thousands of genes as a longitudinal series where the scientific interest lies in the circadian regulation of these plants.	graphical user interface	Silvia Liverani;Jim Q. Smith	2016	Int. J. Approx. Reasoning	10.1016/j.ijar.2016.05.007	econometrics;causality;computer science;artificial intelligence;machine learning;mathematics;graphical model;cluster analysis;bayesian inference;statistics	Logic	5.790922361375147	-55.342951147797976	143099
01f54ce61711191542dc1d1c20360b476ee68d16	predicting subcellular localization of proteins using machine-learned classifiers	anotacion;prediction method;prediccion;metodo analisis;purificacion;base donnee;gram negative bacteria;proteine;thallophyta;localization;database;base dato;annotation;localizacion;web service;accuracy;methode analyse;fungi;precision;localisation;machine learning;analysis method;purification;subcellular localization;proteina;sequence analysis;protein;prediction;proteome analyst;gram positive	MOTIVATION Identifying the destination or localization of proteins is key to understanding their function and facilitating their purification. A number of existing computational prediction methods are based on sequence analysis. However, these methods are limited in scope, accuracy and most particularly breadth of coverage. Rather than using sequence information alone, we have explored the use of database text annotations from homologs and machine learning to substantially improve the prediction of subcellular location.   RESULTS We have constructed five machine-learning classifiers for predicting subcellular localization of proteins from animals, plants, fungi, Gram-negative bacteria and Gram-positive bacteria, which are 81% accurate for fungi and 92-94% accurate for the other four categories. These are the most accurate subcellular predictors across the widest set of organisms ever published. Our predictors are part of the Proteome Analyst web-service.	categories;code coverage;gram-negative bacteria;gram-positive bacteria;homology (biology);learning to rank;machine learning;proteome analyst;purification of quantum state;scientific publication;sequence analysis;web service;gram	Zhiyong Lu;Duane Szafron;Russell Greiner;Paul Lu;David S. Wishart;Brett Poulin;John Anvik;Cam Macdonell;Roman Eisner	2004	Bioinformatics	10.1093/bioinformatics/btg447	biology;computer science;bioinformatics;machine learning;data mining;accuracy and precision;statistics	Comp.	8.662747946220602	-56.74872777783952	143230
0752b2dcc4dcefbabe35119d86a2a1b5dc2fb4de	retraction note: predicting new molecular targets for rhein using network pharmacology	biological patents;simulation and modeling;biomedical journals;text mining;europe pubmed central;systems biology;citation search;physiological cellular and medical topics;citation networks;computational biology bioinformatics;research articles;abstracts;open access;life sciences;clinical guidelines;algorithms;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Background: Drugs can influence the whole biological system by targeting interaction reactions. The existence of interactions between drugs and network reactions suggests a potential way to discover targets. The in silico prediction of potential interactions between drugs and target proteins is of core importance for the identification of new drugs or novel targets for existing drugs. However, only a tiny portion of drug-targets in current datasets are validated interactions. This motivates the need for developing computational methods that predict true interaction pairs with high accuracy. Currently, network pharmacology has used in identifying potential drug targets to predicting the spread of drug activity and greatly contributed toward the analysis of biological systems on a much larger scale than ever before. Methods: In this article, we present a computational method to predict targets for rhein by exploring drugreaction interactions. We have implemented a computational platform that integrates pathway, protein-protein interaction, differentially expressed genome and literature mining data to result in comprehensive networks for drug-target interaction. We used Cytoscape software for prediction rhein-target interactions, to facilitate the drug discovery pipeline. Results: Results showed that 3 differentially expressed genes confirmed by Cytoscape as the central nodes of the complicated interaction network (99 nodes, 153 edges). Of note, we further observed that the identified targets were found to encompass a variety of biological processes related to immunity, cellular apoptosis, transport, signal transduction, cell growth and proliferation and metabolism. Conclusions: Our findings demonstrate that network pharmacology can not only speed the wide identification of drug targets but also find new applications for the existing drugs. It also implies the significant contribution of network pharmacology to predict drug targets.	pharmacology	Aihua Zhang;Hui Sun;Bo Yang;Xijun Wang	2012		10.1186/s12918-014-0105-3	biology;text mining;medical research;computer science;bioinformatics;data science;data mining;systems biology	Logic	5.811914345804672	-58.097545817481326	143549
6431409b6436e187f6eff6adfd62d33d057bed4b	computational techniques for identifying networks of interrelated diseases	bipartite network;diseases proteins diabetes bipartite graph databases crosstalk;hub;biological pathway;biological pathway bipartite network hub protein;proteins diseases genetics graph theory network theory graphs;biological ontology computational techniques interrelated diseases protein to protein interactions gene networks metabolic reactions graph based structures graph network analysis crosstalk human related diseases graph theory genetic modules online databases;protein;pharmacy and pharmacology	Recently there has been a lot of interest in using computational techniques to build networks of protein-to-protein interactions, interacting gene networks and metabolic reactions. Many interesting and novel discoveries have been made using graph based structures using links and nodes to represent the relationships between proteins and genes. Analysis of graph networks has revealed that genes and proteins cooperate in modules performing specific functions and that there is crosstalk or overlap between modules. In this paper we take these ideas further and build upon current knowledge to build up a network of human related diseases based on graph theory and the concept of overlap or shared function. We explore the hypothesis that many human diseases are linked by common genetic modules, therefore a defect in one of any of the cooperating genes in a module may lead to a specific disease or related symptom. We build our networks using data and information extracted from several online databases along with supporting knowledge in the form of biological ontologies.	cluster analysis;computation;crosstalk;database;diagram;drugbank;gene regulatory network;graph (discrete mathematics);graph theory;interaction;ontology (information science);string;snapshot (computer storage);software bug	Ken McGarry;Ukeme Daniel	2014	2014 14th UK Workshop on Computational Intelligence (UKCI)	10.1109/UKCI.2014.6930179	computer science;bioinformatics;theoretical computer science;machine learning	ML	4.634287793068116	-56.92239258786204	143550
b5bb46f013277183ff1e93902a8bb499e70ce39c	identifying dynamic protein complexes based on gene expression profiles and ppi networks	gene expression profile;information science;protein protein interactions;genetics;gene expression profile protein complexes protein protein interactions;gene expression;mechanical engineering;proteins;proteins heuristic algorithms educational institutions gene expression information science mechanical engineering computer science;heuristic algorithms;molecular biophysics;protein complexes;scaccharomves cerevisiae gene expression profiles protein protein interaction network dpc algorithm core attachment assumption molecular cycle protein complex cores attachment protein;computer science;proteins bioinformatics genetics microorganisms molecular biophysics;microorganisms;bioinformatics	Summary form only given. Identification of protein complexes from protein-protein interaction network has become a key problem for understanding cellular life in post-genomic era. Many computational methods have been proposed for identifying protein complexes. Up to now, the existing computational methods are mostly applied on static PPI networks. However, proteins and their interactions are dynamic in reality. Identifying dynamic protein complexes is more meaningful and challenging. In this paper, a novel algorithm, named DPC, is proposed to identify dynamic protein complexes by integrating PPI data and gene expression profiles. Not only is the topological characters but also dynamic meaning considered in DPC. The protein complexes produced by our algorithm DPC contain two parts: static core expressed in all the molecular cycle and dynamic attachments short-lived. According to core-attachment assumption, these proteins which are always active in the molecular cycle are regarded as core proteins. The protein-complex cores are identified from these always active proteins by detecting dense sub-graphs. All possible protein complexes are extended from the protein-complex cores by adding attachments based on a topological character of “closeness”. Others which not belong to always active proteins are considered as potential attachments. On a certain time course, an attachment protein can only participate in one protein complex. Based on this idea, we first find a best protein-complex core for each potential attachment. It means that if a protein would be active at the some time, it would be added into the best protein-complex core for forming protein complexes. According to the formation and function of a protein complex, it should be active in two or more continual time courses. Based on the above analysis, we use the following rules to filter false positive complexes: 1) A protein complex should include at least two proteins; 2) The attachment proteins should be active in the same time course or in different but adjacent time courses; 3) If the attachments of a possible protein complex do not satisfy the second rule and the protein-complex core involves at least two proteins, the core will be kept as a final protein complex. So final protein complexes are extended from the protein-complex cores by adding attachments based on a topological character of “closeness” and dynamic meaning. The protein complexes produced by our algorithm DPC contain two parts: static core expressed in all the molecular cycle and dynamic attachments short-lived. The proposed algorithm DPC was applied on the data of Scaccharomves cerevisiae and the experimental results show that DPC outperforms CMC, MCL, SPICi, HC-PIN, COACH and Core-Attachment based on the validation of matching with known complexes and hF-measures.	gene co-expression network;pixel density	Min Li;Weijie Chen;Jianxing Wang;Fang-Xiang Wu;Yi Pan	2013		10.1109/BIBM.2013.6732610	protein–protein interaction;biology;molecular biology;gene expression;information science;bioinformatics;multiprotein complex;microorganism;genetics;molecular biophysics	Comp.	6.959713318495839	-56.8320122676205	143573
c2912c27ab7668d78cf2a97a752494f1388bd838	impres: integrative multiomics pathway resolution algorithm and tool	integrative multiomics pathway	A central goal of systems biology is to uncover the underlying functional architecture of the cell and study its mechanisms. To this end, large amounts of omics data are being rapidly generated, and a focus of bioinformatics research has been towards integrating these data to identify active pathways or modules under certain conditions. Many bioinformatics algorithms include optimization methods, statistical methods, and methods using interaction network topology attributes have been applied for this. Although biologically significant modules can often be detected globally by these methods, it is hard to interpret or make use of the results towards in silico hypothesis generation and testing. We propose a step-wise active pathway detection method (IMPRes) using a dynamic programming approach. First, we take advantage of the existing pathway interaction knowledge in KEGG to build a background network, and then starting from one or multiple receptors of a certain perturbation, we use transcriptomics data collected under these conditions to detect paths that best explain the variations of genes downstream. More other omics data will be integrated in the future. Since dynamic programming enables the detection one step a time, it is easy for biomedical researchers to trace the pathway and finally lead to more accurate drug design and more effective treatment strategies. Additionally, by adding protein-protein interactions in our method, the hypotheses that we generate do not merely utilize existing knowledge, but have potential to discover new knowledge. We have evaluated our method on a dataset of cell wall stress in yeast. The path we found highly agrees with the Cell Wall Integrity (CWI) pathway, which is the main signaling pathway involved in the regulation of cell wall stress responses. We have also compared with other methods on a yeast high osmolality stress dataset and achieved an overall better performance than some other methods. More experiments have been done on human cancer datasets and mouse datasets. Finally, the IMPRes web server is established to offer a simple interface for applying IMPRes. Users can upload their own data and obtain an interactive visualization of the resulting pathway map. Users can further filter or highlight interactions according to pathway information or relation types. All genes in the pathway map are listed with detailed annotations. The IMPRes web server is available at http://gene.rnet.missouri.edu/soykb_dev/IMPRes/.	algorithm;bioinformatics;cell (microprocessor);downstream (software development);dynamic programming;experiment;gene regulatory network;integrative level;interaction network;interactive visualization;kegg;mathematical optimization;network topology;omics;server (computing);systems biology;upload;web server	Yuexu Jiang;Yanchun Liang;Duolin Wang;Dong Xu;Trupti Joshi	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8218016	computer science;machine learning;bioinformatics;artificial intelligence;web server;kegg;in silico;systems biology;interaction network;algorithm;dynamic programming;omics;upload	Visualization	5.718610479556956	-58.22440337744363	143688
ae155b843dca371b2e6e7fba8ddef034611d3042	an integrated approach to identify protein complex based on best neighbour and modularity increment	global modularity;ppi networks;data mining;proteins;local modularity;modularity increment;protein complexes;protein protein interaction networks;algorithms;protein interaction mapping;proteomics;best neighbour node;bioinformatics	In order to overcome the limitations of global modularity and the deficiency of local modularity, we propose a hybrid modularity measure Local-Global Quantification (LGQ) which considers global modularity and local modularity together. LGQ adopts a suitable module feature adjustable parameter to control the balance of global detecting capability and local search capability in Protein-Protein Interactions (PPI) Network. Furthermore, we develop a new protein complex mining algorithm called Best Neighbour and Local-Global Quantification (BN-LGQ) which integrates the best neighbour node and modularity increment. BN-LGQ expands the protein complex by fast searching the best neighbour node of the current cluster and by calculating the modularity increment as a metric to determine whether the best neighbour node can join the current cluster. The experimental results show BN-LGQ performs a better accuracy on predicting protein complexes and has a higher match with the reference protein complexes than MCL and MCODE algorithms. Moreover, BN-LGQ can effectively discover protein complexes with better biological significance in the PPI network.	anatomic node;angular defect;gene ontology term enrichment;increment;interaction;largest;letter-quality printer;local search (optimization);moe;medial collateral ligament;monte carlo localization;natural science disciplines;node - plant part;pixel density;population parameter;proton pump inhibitors;quantitation;rats, inbred bn;semantic similarity;sensor;staphylococcal protein a;universities;algorithm;establishment and maintenance of localization;protein complex location	Xianjun Shen;Yanli Zhao;Yanan Li;Yang Yi;Tingting He;Jincai Yang	2015	International journal of data mining and bioinformatics	10.1504/IJDMB.2015.067973	biology;computer science;bioinformatics;modularity;machine learning;data mining;multiprotein complex;proteomics	Comp.	6.153149205610322	-55.73852168346456	143695
b89c7f5421f8057668e7c2666363ae407d57f6f6	scfeaturefilter: correlation-based feature filtering for single-cell rnaseq		Single cell RNA sequencing is becoming increasingly popular due to rapidly evolving technology, decreasing costs and its wide applicability. However, the technology suffers from high drop-out rate and high technical noise, mainly due to the low starting material. This hinders the extraction of biological variability, or signal, from the data. One of the first steps in the single cell analysis pipelines is, therefore, to filter the data to keep the most informative features only. This filtering step is often done by arbitrarily selecting a threshold.		Angeles Arzalluz-Luque;Guillaume Devailly;Anagha Joshi	2018		10.1007/978-3-319-78723-7_31	engineering;computer vision;filter (signal processing);feature selection;cell;artificial intelligence;single-cell analysis;pattern recognition	ML	3.215721015249937	-54.22545250283668	144306
a291ebffcb551a28f8e7ae2e95c0fb1bc4b2c7d9	crystallographic threading	crystallographic threading	"""Crystallographic studies play a major role in current efforts towards protein structure determination. Despite recent advances in computational tools for molecular modeling and graphics, the construction of a three-dimensional protein backbone model from crystallographic data remains complex and time-consuming. This paper describes a unique contribution to an automated approach to protein model construction and evaluation, where a model is represented as an annotated trace (or partial trace) of a structure. Candidate models are derived through a topological analysis of the electron density map of a protein. Using sequence alignment techniques, we determine an optimal threading of the known sequence onto the candidate protein structure models. In this threading, connected nodes on the model are associated with adjacent amino acids in the sequence and a fitness score is assigned based on features extracted from the electron density map for the protein. Experimental results demonstrate that crystallographic threading provides an effective means for evaluating the """"goodness"""" of experimentally derived protein models."""	amino acids;experiment;extraction;graphics;internet backbone;personnameuse - assigned;protein, organized by structure;scanning electron microscopy;sequence alignment;staphylococcal protein a;thread (computing);vertebral column;electron density;molecular modeling	Alan Ableson;Janice I. Glasgow	1999	Proceedings. International Conference on Intelligent Systems for Molecular Biology			Comp.	9.35495958527295	-58.64663750169371	144441
9c2bc971bb4f2ec3e952d92875d37d976b033651	data-driven ontologies		"""Gene networks are important tools in studying gene-gene relationships and gene function. Understanding the relationships within these networks is an important challenge. Ontologies are a critical tool in helping deal with these data. The use of the Gene Ontology, for example, has become routine in methods for validation, discovery, etc. Here we present a novel algorithm that synthesizes an ontology by considering both extant annotation terms and also the connections between genes in gene networks. The process is efficient and produces easily inspectable ontologies. Because the relationships drawn between terms are heavily influenced by data, we call these """"Data-Driven"""" Ontologies. We apply this algorithm to both discover new relationships between biological processes and as a tool to compare sets of genes across microrarray experiments. Supplemental data and source code are available at: http://www.ddont.org"""	algorithm;annotation;experiment;gene ontology;gene regulatory network;ontology (information science);source code	James C. Costello;Daniel R. Schrider;Jeff Gehlhausen;Mehmet M. Dalkilic	2009	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		bioinformatics;ontology (information science);biology;data-driven	Comp.	3.2213664653201572	-57.29523663456752	144946
17909ecb6d2a31d112d38c1206227dd9a585f38e	evaluation of six methods for estimating synonymous and nonsynonymous substitution rates	zhang zhang jun yu 基因序列 基因突变 蛋白 生物 evaluation of six methods for estimating synonymous and nonsynonymous substitution rates;synonymous substitution;approximation method;approximate method;substitution rate;ka ks ratio;maximum likelihood method;nonsynonymous substitution	Methods for estimating synonymous and nonsynonymous substitution rates among protein-coding sequences adopt different mutation (substitution) models with subtle yet significant differences, which lead to different estimates of evolutionary information. Little attention has been devoted to the comparison of methods for obtaining reliable estimates since the amount of sequence variations within targeted datasets is always unpredictable. To our knowledge, there is little information available in literature about evaluation of these different methods. In this study, we compared six widely used methods and provided with evaluation results using simulated sequences. The results indicate that incorporating sequence features (such as transition/transversion bias and nucleotide/codon frequency bias) into methods could yield better performance. We recommend that conclusions related to or derived from Ka and Ks analyses should not be readily drawn only according to results from one method.	estimated;ka band;low-discrepancy sequence;nucleotides;substitution (logic);transversion mutation	Zhang Zhang;Jun Yu	2006		10.1016/S1672-0229(06)60030-2	biology;synonymous substitution;nonsynonymous substitution;bioinformatics;ka/ks ratio;maximum likelihood;genetics	HPC	4.140413613009939	-53.284136495156304	145243
0ce3dc04da911078a7e3ebd56cb84836f732a8e7	functional alignment of metabolic networks		Network alignment has become a standard tool in comparative biology, allowing the inference of protein function, interaction and orthology. However, current alignment techniques are based on topological properties of networks and do not take into account their functional implications. Here we propose, for the first time, an algorithm to align two metabolic networks by taking advantage of their coupled metabolic models. These models allow us to assess the functional implications of genes or reactions, captured by the metabolic fluxes that are altered following their deletion from the network. Such implications may spread far beyond the region of the network where the gene or reaction lies. We apply our algorithm to align metabolic networks from various organisms, ranging from bacteria to humans, showing that our alignment can reveal functional orthology relations that are missed by conventional topological alignments.	algorithm;align (company);greedy algorithm;html element;isolation (database systems);iteration;maxima and minima;observable;randomness;sequence alignment;topological derivative	Arnon Mazza;Allon Wagner;Eytan Ruppin;Roded Sharan	2015		10.1007/978-3-319-16706-0_24	biology;bioinformatics;genetics	Comp.	4.052172419648154	-58.51273075154988	145504
65325c60b2877917d1154d47b491a63dc3d75e99	comparing imperfect measurements with the bland-altman technique: application in gene expression analysis	computational biology;gene expression	Several problems in medicine and biology involve the comparison of two measurements made on the same set of cases. The problem differs from a calibration problem because no gold standard can be identified. Testing the null hypothesis of no relationship using measures of association is not optimal since the measurements are made on the same cases, and therefore correlation coefficients will tend to be significant. The descriptive Bland-Altman method can be used in exploratory analysis of this problem, allowing the visualization of gross systematic differences between the two sets of measurements. We utilize the method on three sets of matched observations and demonstrate its usefulness in detecting systematic variations between two measurement technologies to assess gene expression.	calibration;coefficient;description;gene expression;imagery;sensor	Lucila Ohno-Machado;Staal A. Vinterbo;Stephan Dreiseitl;Tor-Kristian Jenssen;Winston Patrick Kuo	2002	Proceedings. AMIA Symposium		calibration;bland–altman plot;data mining;statistics;bias (epidemiology);null hypothesis;visualization;correlation and dependence;biology;imperfect;correlation	Comp.	5.031486124667427	-52.70053845516306	145627
3010ddd6d7efb09ed1689d2fbcc8975b01583402	identification of functionally related genes using data mining and data integration: a breast cancer case study	genes;gene expression profile;breast neoplasms;female;expression profile;data integrity;large dataset;gene regulation;databases genetic;pyruvate kinase;data mining;computational biology bioinformatics;chip;transcription factor;protein protein interaction;algorithms;humans;combinatorial libraries;computational biology;computer appl in life sciences;breast cancer;oligonucleotide array sequence analysis;biological process;microarrays;bioinformatics;gene ontology	The identification of the organisation and dynamics of molecular pathways is crucial for the understanding of cell function. In order to reconstruct the molecular pathways in which a gene of interest is involved in regulating a cell, it is important to identify the set of genes to which it interacts with to determine cell function. In this context, the mining and the integration of a large amount of publicly available data, regarding the transcriptome and the proteome states of a cell, are a useful resource to complement biological research. We describe an approach for the identification of genes that interact with each other to regulate cell function. The strategy relies on the analysis of gene expression profile similarity, considering large datasets of expression data. During the similarity evaluation, the methodology determines the most significant subset of samples in which the evaluated genes are highly correlated. Hence, the strategy enables the exclusion of samples that are not relevant for each gene pair analysed. This feature is important when considering a large set of samples characterised by heterogeneous experimental conditions where different pools of biological processes can be active across the samples. The putative partners of the studied gene are then further characterised, analysing the distribution of the Gene Ontology terms and integrating the protein-protein interaction (PPI) data. The strategy was applied for the analysis of the functional relationships of a gene of known function, Pyruvate Kinase, and for the prediction of functional partners of the human transcription factor TBX3. In both cases the analysis was done on a dataset composed by breast primary tumour expression data derived from the literature. Integration and analysis of PPI data confirmed the prediction of the methodology, since the genes identified to be functionally related were associated to proteins close in the PPI network. Two genes among the predicted putative partners of TBX3 (GLI3 and GATA3) were confirmed by in vivo binding assays (crosslinking immunoprecipitation, X-ChIP) in which the putative DNA enhancer sequence sites of GATA3 and GLI3 were found to be bound by the Tbx3 protein. The presented strategy is demonstrated to be an effective approach to identify genes that establish functional relationships. The methodology identifies and characterises genes with a similar expression profile, through data mining and integrating data from publicly available resources, to contribute to a better understanding of gene regulation and cell function. The prediction of the TBX3 target genes GLI3 and GATA3 was experimentally confirmed.	cell physiology;complement system proteins;cross link;dna integration;data mining;enhancer elements, genetic;enhancer of transcription;exclusion;experiment;gata3 gene;gata3 protein, human;gene expression profiling;gene ontology;genetic heterogeneity;mammary neoplasms;pixel density;proton pump inhibitors;pyruvate;silo (dataset);subgroup;tbx3 gene;transcription factor;transcription (software);video-in video-out	Ettore Mosca;Gloria Bertoli;Eleonora Piscitelli;Laura Vilardo;Rolland A. Reinbold;Ileana Zucchi;Luciano Milanesi	2009	BMC Bioinformatics	10.1186/1471-2105-10-S12-S8	protein–protein interaction;chip;biology;molecular biology;regulation of gene expression;dna microarray;computer science;bioinformatics;breast cancer;gene;data integrity;biological process;genetics;transcription factor	Comp.	5.799943726108086	-57.31294222145104	146402
dc5b482e5f14095d816440937eed09a2008e9bb4	evaluation of fecal mrna reproducibility via a marginal transformed mixture modeling approach	microarray data;new technology;intraclass correlation coefficient;rna messenger;databases genetic;computational biology bioinformatics;colon cancer;gene expression;density estimation;normal mixture;mixture model;reproducibility of results;goodness of fit test;feces;models statistical;algorithms;pattern recognition automated;combinatorial libraries;monte carlo;mixture distribution;computer appl in life sciences;early detection;gene expression profiling;oligonucleotide array sequence analysis;microarrays;bioinformatics	Developing and evaluating new technology that enables researchers to recover gene-expression levels of colonic cells from fecal samples could be key to a non-invasive screening tool for early detection of colon cancer. The current study, to the best of our knowledge, is the first to investigate and report the reproducibility of fecal microarray data. Using the intraclass correlation coefficient (ICC) as a measure of reproducibility and the preliminary analysis of fecal and mucosal data, we assessed the reliability of mixture density estimation and the reproducibility of fecal microarray data. Using Monte Carlo-based methods, we explored whether ICC values should be modeled as a beta-mixture or transformed first and fitted with a normal-mixture. We used outcomes from bootstrapped goodness-of-fit tests to determine which approach is less sensitive toward potential violation of distributional assumptions. The graphical examination of both the distributions of ICC and probit-transformed ICC (PT-ICC) clearly shows that there are two components in the distributions. For ICC measurements, which are between 0 and 1, the practice in literature has been to assume that the data points are from a beta-mixture distribution. Nevertheless, in our study we show that the use of a normal-mixture modeling approach on PT-ICC could provide superior performance. When modeling ICC values of gene expression levels, using mixture of normals in the probit-transformed (PT) scale is less sensitive toward model mis-specification than using mixture of betas. We show that a biased conclusion could be made if we follow the traditional approach and model the two sets of ICC values using the mixture of betas directly. The problematic estimation arises from the sensitivity of beta-mixtures toward model mis-specification, particularly when there are observations in the neighborhood of the the boundary points, 0 or 1. Since beta-mixture modeling is commonly used in approximating the distribution of measurements between 0 and 1, our findings have important implications beyond the findings of the current study. By using the normal-mixture approach on PT-ICC, we observed the quality of reproducible genes in fecal array data to be comparable to those in mucosal arrays.	colon carcinoma;colon classification;data point;early diagnosis;gene expression;marginal model;microarray databases;mixture model;monte carlo method;mucous membrane;pearson correlation coefficient;seizures;specification	Nysia I. George;Joanne R. Lupton;Nancy D. Turner;Robert S. Chapkin;Laurie A. Davidson;Naisyin Wang	2009		10.1186/1471-2105-11-13	biology;microarray analysis techniques;gene expression;density estimation;dna microarray;mixture distribution;computer science;bioinformatics;mixture model;intraclass correlation;gene expression profiling;feces;goodness of fit;monte carlo method	ML	5.675907099134826	-52.590657294345554	146468
01bba25aee9028686a0e797c0fbb6ac3f13ae548	bayesian normalization model for label-free quantitative analysis by lc-ms	analytical models;bayesian hierarchical model;bayes methods;mass spectrometry;biological system modeling;bayes theorem;shape bayes methods data models bioinformatics biological system modeling analytical models noise;liquid chromatography;shape;statistical analysis bayes methods biology computing chromatography data acquisition intensity measurement mass spectroscopy;linear mixed effects model bayesian normalization model label free quantitative analysis data acquired normalization liquid chromatography coupled mass spectrometry label free differential expression analysis lc ms data normalization subsequent statistical analysis sample storage sample collection experimental design noise intensity measurements scan level information;chromatography liquid;normalization;models statistical;algorithms;bayesian hierarchical model liquid chromatography mass spectrometry normalization;signal to noise ratio;computational biology;noise;data models;bioinformatics	We introduce a new method for normalization of data acquired by liquid chromatography coupled with mass spectrometry (LC-MS) in label-free differential expression analysis. Normalization of LC-MS data is desired prior to subsequent statistical analysis to adjust variabilities in ion intensities that are not caused by biological differences but experimental bias. There are different sources of bias including variabilities during sample collection and sample storage, poor experimental design, noise, etc. In addition, instrument variability in experiments involving a large number of LC-MS runs leads to a significant drift in intensity measurements. Although various methods have been proposed for normalization of LC-MS data, there is no universally applicable approach. In this paper, we propose a Bayesian normalization model (BNM) that utilizes scan-level information from LC-MS data. Specifically, the proposed method uses peak shapes to model the scan-level data acquired from extracted ion chromatograms (EIC) with parameters considered as a linear mixed effects model. We extended the model into BNM with drift (BNMD) to compensate for the variability in intensity measurements due to long LC-MS runs. We evaluated the performance of our method using synthetic and experimental data. In comparison with several existing methods, the proposed BNM and BNMD yielded significant improvement.	design of experiments;earth inductor compass;experiment;extraction;heart rate variability;ions;iontophoresis;liquid chromatography;serous endometrial intraepithelial carcinoma;spatial variability;specimen collection;spectrometry;synthetic intelligence	Mohammad R. Nezami Ranjbar;Mahlet G. Tadesse;Yue Joseph Wang;Habtom W. Ressom	2015	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2014.2377723	data modeling;econometrics;mass spectrometry;shape;computer science;noise;normalization;mathematics;bayesian hierarchical modeling;bayes' theorem;signal-to-noise ratio;statistics	Comp.	4.583966287355367	-53.648133128575545	147318
16aff53ac0061dd00017abab28e3e9cc9bda53b3	robustness can evolve gradually in complex regulatory gene networks with varying topology	transcription genetic;evolution molecular;signal transduction;transcription factors;gene network;models genetic;adaptation physiological;gene expression regulation;science artificial life evolvability;computer simulation	The topology of cellular circuits (the who-interacts-with-whom) is key to understand their robustness to both mutations and noise. The reason is that many biochemical parameters driving circuit behavior vary extensively and are thus not fine-tuned. Existing work in this area asks to what extent the function of any one given circuit is robust. But is high robustness truly remarkable, or would it be expected for many circuits of similar topology? And how can high robustness come about through gradual Darwinian evolution that changes circuit topology gradually, one interaction at a time? We here ask these questions for a model of transcriptional regulation networks, in which we explore millions of different network topologies. Robustness to mutations and noise are correlated in these networks. They show a skewed distribution, with a very small number of networks being vastly more robust than the rest. All networks that attain a given gene expression state can be organized into a graph whose nodes are networks that differ in their topology. Remarkably, this graph is connected and can be easily traversed by gradual changes of network topologies. Thus, robustness is an evolvable property. This connectedness and evolvability of robust networks may be a general organizational principle of biological networks. In addition, it exists also for RNA and protein structures, and may thus be a general organizational principle of all biological systems.	anatomy, regional;biological network;biological system;circuit topology;gene expression;graph (discrete mathematics);graph - visual representation;mutation;network topology;robustness (computer science);transcriptional regulation	Stefano Ciliberti;Olivier C. Martin;Andreas Wagner	2007	PLoS Computational Biology	10.1371/journal.pcbi.0030015	computer simulation;biology;gene regulatory network;regulation of gene expression;bioinformatics;machine learning;genetics;signal transduction;transcription factor	Comp.	5.8033583877953445	-59.10519885857281	147510
256c373ed23069031b145ae4d40e39445b5a9b54	phenotype prediction based on genome-wide dna methylation data	female;computational biology bioinformatics;uterine cervical neoplasms;genome human;principal component analysis;algorithms;dna methylation;papillomavirus infections;papillomaviridae;humans;combinatorial libraries;phenotype;computer appl in life sciences;cpg islands;microarrays;bioinformatics	DNA methylation (DNAm) has important regulatory roles in many biological processes and diseases. It is the only epigenetic mark with a clear mechanism of mitotic inheritance and the only one easily available on a genome scale. Aberrant cytosine-phosphate-guanine (CpG) methylation has been discussed in the context of disease aetiology, especially cancer. CpG hypermethylation of promoter regions is often associated with silencing of tumour suppressor genes and hypomethylation with activation of oncogenes. Supervised principal component analysis (SPCA) is a popular machine learning method. However, in a recent application to phenotype prediction from DNAm data SPCA was inferior to the specific method EVORA. We present Model-Selection-SPCA (MS-SPCA), an enhanced version of SPCA. MS-SPCA applies several models that perform well in the training data to the test data and selects the very best models for final prediction based on parameters of the test data. We have applied MS-SPCA for phenotype prediction from genome-wide DNAm data. CpGs used for prediction are selected based on the quantification of three features of their methylation (average methylation difference, methylation variation difference and methylation-age-correlation). We analysed four independent case–control datasets that correspond to different stages of cervical cancer: (i) cases currently cytologically normal, but will later develop neoplastic transformations, (ii, iii) cases showing neoplastic transformations and (iv) cases with confirmed cancer. The first dataset was split into several smaller case–control datasets (samples either Human Papilloma Virus (HPV) positive or negative). We demonstrate that cytology normal HPV+ and HPV- samples contain DNAm patterns which are associated with later neoplastic transformations. We present evidence that DNAm patterns exist in cytology normal HPV- samples that (i) predispose to neoplastic transformations after HPV infection and (ii) predispose to HPV infection itself. MS-SPCA performs significantly better than EVORA. MS-SPCA can be applied to many classification problems. Additional improvements could include usage of more than one principal component (PC), with automatic selection of the optimal number of PCs. We expect that MS-SPCA will be useful for analysing recent larger DNAm data to predict future neoplastic transformations.	carbamoyl-phosphate synthase i deficiency disease;cervix carcinoma;cytosine;dna microarray;f7 wt allele;genes, suppressor;genetic selection;guanine;hiv;hypermethylation;hypomethylation;large;ms-dos;machine learning;methylation;model selection;neck;neoplasms;neoplastic cell transformation;oncogenes;photon correlation spectroscopy;principal component analysis;promoter regions, genetic;quantitation;silo (dataset);small;test data;cytidylyl-3'-5'-guanosine;inorganic phosphate;study of epigenetics	Thomas Wilhelm-Stein	2014		10.1186/1471-2105-15-193	biology;molecular biology;dna microarray;epigenetics of physical exercise;bioinformatics;phenotype;dna methylation;cpg site;genetics;principal component analysis	Comp.	8.050556041261233	-53.75482910372512	147961
bdbb0517c1c4cf263a2ca526c45551f619b07170	the power of linkage analysis of a disease-related endophenotype using asymmetrically ascertained sib pairs	genetique;health research;uk clinical guidelines;biological patents;metodo estadistico;biomedical journals;analisis datos;text mining;genetica;fonction repartition;europe pubmed central;estadistica test;fonction monotone;statistique test;monotone function;citation search;linkage analysis;allele frequency;statistical method;citation networks;funcion monotona;genetics;schizophrenia;funcion distribucion;data analysis;test power;distribution function;general population;research articles;uk phd theses thesis;methode statistique;abstracts;esquizofrenia;open access;statistical computation;calculo estadistico;life sciences;monotonic function;clinical guidelines;schizophrenie;analyse donnee;calcul statistique;26a48;full text;potencia test;uk research reports;puissance test;60e05;medical journals;genetic parameter;rest apis;test statistic;orcids;europe pmc;biomedical research;bioinformatics;literature search	A linkage study of a qualitative disease endophenotype in a sample of sib pairs, consisting of one disease affected proband and one sibling is considered. The linkage statistic compares marker allele sharing with the proband in siblings with an abnormal endophenotype to siblings with the normal endophenotype. Expressions for the distribution of this linkage statistic, in terms of the recombination fraction are derived and (1) the genetic parameter values (allele frequency and endophenotype and disease penetrance) and (2) the abnormal endophenotype rates in the population and in classes of relatives of disease affected probands. It is then shown that when either the disease or the abnormal endophenotype has additive penetrance, the expressions simplify to a monotonic function of the difference between abnormal endophenotype rates in siblings and in the population. Thought disorder is considered as a putative schizophrenia endophenotype. Forty sets of genetic parameter values that correspond to the known prevalence values for thought disorder in schizophrenic patients, siblings of schizophrenics and the general population are evaluated. For these genetic parameter values, numerical results show that the test statistic has>70% power (α = 0.0001) in general with a sample of 200 or more proband-sibling pairs to detect the linkage between a marker (θ = 0.01), and a locus pleiotropic for schizophrenia and thought disorder.		Heejong Sung;Fei Ji;Deborah L. Levy;Steven Matthysse;Nancy Role Mendell	2009	Computational statistics & data analysis	10.1016/j.csda.2008.08.030	text mining;monotonic function;mathematics;statistics	Comp.	5.0344591400396	-53.29062712654002	148643
1a26407ab226dcc754dcd339bb441553eec7fe90	accurate multiple network alignment through context-sensitive random walk	biological patents;simulation and modeling;biomedical journals;text mining;europe pubmed central;systems biology;citation search;physiological cellular and medical topics;citation networks;computational biology bioinformatics;research articles;abstracts;open access;life sciences;clinical guidelines;algorithms;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Comparative network analysis can provide an effective means of analyzing large-scale biological networks and gaining novel insights into their structure and organization. Global network alignment aims to predict the best overall mapping between a given set of biological networks, thereby identifying important similarities as well as differences among the networks. It has been shown that network alignment methods can be used to detect pathways or network modules that are conserved across different networks. Until now, a number of network alignment algorithms have been proposed based on different formulations and approaches, many of them focusing on pairwise alignment. In this work, we propose a novel multiple network alignment algorithm based on a context-sensitive random walk model. The random walker employed in the proposed algorithm switches between two different modes, namely, an individual walk on a single network and a simultaneous walk on two networks. The switching decision is made in a context-sensitive manner by examining the current neighborhood, which is effective for quantitatively estimating the degree of correspondence between nodes that belong to different networks, in a manner that sensibly integrates node similarity and topological similarity. The resulting node correspondence scores are then used to predict the maximum expected accuracy (MEA) alignment of the given networks. Performance evaluation based on synthetic networks as well as real protein-protein interaction networks shows that the proposed algorithm can construct more accurate multiple network alignments compared to other leading methods.	amiga walker;anatomic node;biological network;context-sensitive grammar;context-sensitive language;estimated;global network;network switch;node - plant part;performance evaluation;random walker algorithm;sequence alignment;social network analysis;switch device component;synthetic intelligence;walkers;protein protein interaction	Hyundoo Jeong;Byung-Jun Yoon	2015		10.1186/1752-0509-9-S1-S7	biology;text mining;medical research;computer science;bioinformatics;dynamic network analysis;data science;data mining;network simulation;systems biology;algorithm	ML	5.19462511214625	-56.98259827448045	148745
e2576359dad2fe61f03919666292b235238e5f7c	classification of dna sequences basing on the dinucleotide compositions	dna;biology computing;genomics;pattern classification backpropagation biology computing biotechnology data analysis dna microorganisms neural nets;neural nets;backpropagation;data mining;accuracy;data analysis;artificial neural networks;dinucleotide composition;dna sequences artificial neural networks microorganisms genomics bioinformatics statistical analysis computational intelligence computer errors predictive models;pattern classification;bacteria;backpropagation artificial neural network;leave one out method dna sequence classification dinucleotide composition bacteria backpropagation artificial neural network;dna sequence classification;dna sequence;biotechnology;back propagation;microorganisms;leave one out method;leave one out;artificial neural network;bioinformatics	DNA sequences of several bacteria were classified using artificial neural network model. The “dinucleotides compositions” method was used to characterize the DNA sequences which transform every DNA sequence to a 16-dimension vector. Back-propagation artificial neural network was developed and trained using “leave-one-out” method. Results showed that the accuracy of classification was 84.3%, which proved that the model was satisfactory in summary. However, the author stated that the applicability of the characterization strategy needs to be improved.	artificial neural network;backpropagation;network model;software propagation	Wei You;Kun Wang;Huixiao Li;Yang Jia;Xiaoqin Wu;Yaning Du	2009	2009 Second International Symposium on Computational Intelligence and Design	10.1109/ISCID.2009.244	computer science;bioinformatics;artificial intelligence;backpropagation;machine learning;artificial neural network	Arch	10.011516665619308	-55.126230336583404	148801
abdf7c58914f1cae499ce8624f184062cb038e02	answer to the comments of k. dobbin, j. shih and r. simon on the paper 'evaluation of the gene-specific dye-bias in cdna microarray experiments'	cdna microarray	We would like to thank K. Dobbin, J. Shih and R. Simon for their comments about Martin-Magniette et al. (2005). Their remarks relate to the design of microarray experiments and notably about the use of dye-swaps. We, however, want to make it clear that our manuscript primarily focuses on the detection, quantification and correction of the gene-specific dye-bias introduced in dual-color microarray experiments. The most important point in Martin-Magniette et al. (2005) is the following: by dint of studying technical errors, we will be able to identify and then to remove most of them. For the first time, in Martin-Magniette et al. (2005), we were able to quantify the genespecific dye bias by calculating the Labelling Bias Index, (LBI). The LBI measured on different array types shows that this artifact seems to be very low in some cases and could be thus neglected. However, it is high in other cases and it cannot thus be neglected for data issued from these array types. This measure is of crucial importance as it allows users to evaluate the impact of this bias on their data. Moreover, we think that each platform should at least know in what class it belongs for each array types. Although this artifact is not lowered nor understood, it is simply dangerous to underestimate it. The gene-specific dye bias is not an inevitability and can be well controlled, as we point out in our paper. Recently, in another paper, Dobbin et al. (2005) studied the genespecific dye bias. Although they reached the same conclusions, some of their remarks are explained in Martin-Magniette et al. (2005): e.g. Dobbin et al. (2005) have found that ‘(the gene-specific) dye bias appears to have masked the true differential expression’. This is explained in Martin-Magniette et al. (2005): the variance associated to a gene is overestimated by the dye bias effect in model (2) of Martin-Magniette et al. Dye-swaps constitute a simple and effective design to remove gene-specific dye bias when it is high. Nevertheless, we agree with Dobbin et al. (2005), that a balanced block design may be better than dye-swaps in some situations. As the former designs allow the use of more biological samples, the estimation of the biological variability will be more precise. Even if balanced block designs are statistically more efficient, the following considerations should be taken into account before choosing the experimental design:	dna microarray;dna, complementary;design of experiments;dual;dyes;experiment;exponent bias;manuscripts;martin-probst deafness-mental retardation syndrome;neuritis, autoimmune, experimental;published comment;quantitation;sample variance;spatial variability;technical standard;word lists by frequency	Marie-Laure Martin-Magniette;Julie Aubert;Eric Cabannes;Jean-Jacques Daudin	2005	Bioinformatics	10.1093/bioinformatics/bti479	biology;molecular biology;bioinformatics;genetics	NLP	5.162832875188709	-52.305188761111445	148866
053bda3307a36adec7d6050b5ccb97fe0ddabd17	integrated genomic analysis of biological gene sets with applications in lung cancer prognosis	data integration;epigenetics;gene expression;gene set analysis;integrative genomics;pathway analysis	Burgeoning interest in integrative analyses has produced a rise in studies which incorporate data from multiple genomic platforms. Literature for conducting formal hypothesis testing on an integrative gene set level is considerably sparse. This paper is biologically motivated by our interest in the joint effects of epigenetic methylation loci and their associated mRNA gene expressions on lung cancer survival status. We provide an efficient screening approach across multiplatform genomic data on the level of biologically related sets of genes, and our methods are applicable to various disease models regardless whether the underlying true model is known (iTEGS) or unknown (iNOTE). Our proposed testing procedure dominated two competing methods. Using our methods, we identified a total of 28 gene sets with significant joint epigenomic and transcriptomic effects on one-year lung cancer survival. We propose efficient variance component-based testing procedures to facilitate the joint testing of multiplatform genomic data across an entire gene set. The testing procedure for the gene set is self-contained, and can easily be extended to include more or different genetic platforms. iTEGS and iNOTE implemented in R are freely available through the inote package at https://cran.r-project.org// .	behavior;carcinoma of lung;component-based software engineering;contain (action);epigenomics;forecast of outcome;gene expression;non-small cell lung carcinoma;random effects model;sample variance;sparse matrix;study of epigenetics	Su Hee Chu;Yen-Tsung Huang	2017		10.1186/s12859-017-1737-2	computational biology;lung cancer;gene;genetics;gene expression;dna microarray;bioinformatics;locus (genetics);biology;survival status;methylation;epigenetics	Comp.	5.728294953472245	-52.95021255213757	149316
a2194d077efa1f18d85c25a0dbbb97b931dabc3a	brane clust: cluster-assisted gene regulatory network inference refinement		Discovering meaningful gene interactions is crucial for the identification of novel regulatory processes in cells. Building accurately the related graphs remains challenging due to the large number of possible solutions from available data. Nonetheless, enforcing a priori on the graph structure, such as modularity, may reduce network indeterminacy issues. BRANE Clust (Biologically-Related A priori Network Enhancement with Clustering) refines gene regulatory network (GRN) inference thanks to cluster information. It works as a post-processing tool for inference methods (i.e., CLR, GENIE3). In BRANE Clust, the clustering is based on the inversion of a system of linear equations involving a graph-Laplacian matrix promoting a modular structure. Our approach is validated on DREAM4 and DREAM5 datasets with objective measures, showing significant comparative improvements. We provide additional insights on the discovery of novel regulatory or co-expressed links in the inferred Escherichia coli network evaluated using the STRING database. The comparative pertinence of clustering is discussed computationally (SIMoNe, WGCNA, X-means) and biologically (RegulonDB). BRANE Clust software is available at: http://www-syscom.univ-mlv.fr/~pirayre/Codes-GRN-BRANE-clust.html .	algorithm;brane;cluster analysis;computer cluster;dclk3 gene;gene regulatory network;graph - visual representation;indeterminacy in concurrent computation;inference;interaction;laplacian matrix;linear equation;mathematical optimization;playstation 3 cluster;precision and recall;promotion (action);refinement (computing);regulondb;relevance;string;synthetic intelligence;system of linear equations;thresholding (image processing);video post-processing;weight;weighted network;statistical cluster	Aur&#x00E9;lie Pirayre;Camille Couprie;Laurent Duval;Jean-Christophe Pesquet	2018	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2017.2688355	artificial intelligence;machine learning;gene regulatory network;cluster analysis;modularity;computer science;probabilistic logic;data mining;inference;brane;clustering coefficient;bioinformatics;graphical model	Comp.	4.8275115730062135	-55.663540330830514	149382
443d8417eb4653951478e222f7b89b0b666656d5	prediction of protein binding sites in protein structures using hidden markov support vector machine	protein sequence;accessible surface area;binding site;binding sites;journal;cutting plane algorithm;computational biology bioinformatics;protein structure;proteins;machine learning;comparative method;conditional random field;protein binding;artificial intelligence;algorithms;support vector machine;combinatorial libraries;computational biology;computational efficiency;computer appl in life sciences;artificial neural network;markov chains;databases protein;microarrays;bioinformatics	Predicting the binding sites between two interacting proteins provides important clues to the function of a protein. Recent research on protein binding site prediction has been mainly based on widely known machine learning techniques, such as artificial neural networks, support vector machines, conditional random field, etc. However, the prediction performance is still too low to be used in practice. It is necessary to explore new algorithms, theories and features to further improve the performance. In this study, we introduce a novel machine learning model hidden Markov support vector machine for protein binding site prediction. The model treats the protein binding site prediction as a sequential labelling task based on the maximum margin criterion. Common features derived from protein sequences and structures, including protein sequence profile and residue accessible surface area, are used to train hidden Markov support vector machine. When tested on six data sets, the method based on hidden Markov support vector machine shows better performance than some state-of-the-art methods, including artificial neural networks, support vector machines and conditional random field. Furthermore, its running time is several orders of magnitude shorter than that of the compared methods. The improved prediction performance and computational efficiency of the method based on hidden Markov support vector machine can be attributed to the following three factors. Firstly, the relation between labels of neighbouring residues is useful for protein binding site prediction. Secondly, the kernel trick is very advantageous to this field. Thirdly, the complexity of the training step for hidden Markov support vector machine is linear with the number of training samples by using the cutting-plane algorithm.	accessible surface area;algorithm;amino acid sequence;artificial neural network;binding sites;computation;conditional random field;cutting-plane method;integer programming;interaction;kernel method;ligand binding domain;machine learning;markov chain;peptide sequence;protein binding;protein structure prediction;staphylococcal protein a;support vector machine;theory;time complexity;orders - hl7publishingdomain	Bin Liu;Xiaolong Wang;Lei Lin;Buzhou Tang;Qiwen Dong;Xuan Wang	2009		10.1186/1471-2105-10-381	computer science;bioinformatics;binding site;data science;machine learning;artificial neural network	ML	9.970254029031103	-54.1617857194412	149713
8f69c11f7ae762227f3fcd333d9c5b7aa5aa962c	constructing a gene semantic similarity network for the inference of disease genes	simulation and modeling;models theoretical;systems biology;gene regulatory networks;physiological cellular and medical topics;databases genetic;journal;computational biology bioinformatics;proteins;genome human;reproducibility of results;algorithms;humans;protein interaction mapping;computational biology;phenotype;protein interaction maps;bioinformatics	The inference of genes that are truly associated with inherited human diseases from a set of candidates resulting from genetic linkage studies has been one of the most challenging tasks in human genetics. Although several computational approaches have been proposed to prioritize candidate genes relying on protein-protein interaction (PPI) networks, these methods can usually cover less than half of known human genes. We propose to rely on the biological process domain of the gene ontology to construct a gene semantic similarity network and then use the network to infer disease genes. We show that the constructed network covers about 50% more genes than a typical PPI network. By analyzing the gene semantic similarity network with the PPI network, we show that gene pairs tend to have higher semantic similarity scores if the corresponding proteins are closer to each other in the PPI network. By analyzing the gene semantic similarity network with a phenotype similarity network, we show that semantic similarity scores of genes associated with similar diseases are significantly different from those of genes selected at random, and that genes with higher semantic similarity scores tend to be associated with diseases with higher phenotype similarity scores. We further use the gene semantic similarity network with a random walk with restart model to infer disease genes. Through a series of large-scale leave-one-out cross-validation experiments, we show that the gene semantic similarity network can achieve not only higher coverage but also higher accuracy than the PPI network in the inference of disease genes. ruijiang@tsinghua.edu.cn	biological processes;candidate disease gene;cross reactions;cross-validation (statistics);experiment;gene ontology;genes, vif;genetic algorithm;hereditary diseases;inference;linkage (software);pixel density;proton pump inhibitors;semantic similarity	Rui Jiang;Mingxin Gan;Peng He	2011		10.1186/1752-0509-5-S2-S2	computational biology;biology;gene regulatory network;bioinformatics;phenotype;genetics;systems biology	Comp.	5.667464384990886	-56.131342841396624	149875
5d85003182fab144f856c94cb64d5d2294b8be9b	mining low-variance biclusters to discover coregulation modules in sequencing datasets	coregulation module;high-throughput sequencing chip-seq data;ideal biclusters;desirable biclusters;existing biclustering algorithm;low variance;chip-seq peak;variance value;mining low-variance biclusters;sequencing datasets;overlapping biclusters;use variance;pre-defined variance bound	High-throughput sequencing CHIP-Seq data exhibit binding events with possible binding locations and their strengths, followed by interpretation of the locations of peaks. Recent methods tend to summarize all CHIP-Seq peaks detected within a limited up and down region of each gene into one real-valued score in order to quantify the probability of regulation in a region. Applying subspace clustering techniques on these scores can help discover important knowledge such as the potential co-regulation or co-factor mechanisms. The ideal biclusters generated would contain subsets of genes and transcription factors TF such that the cell-values in biclusters are distributed around a mean value with very low variance. Such biclusters would indicate TF sets regulating gene sets with very similar probability values. However, most existing biclustering algorithms neither enforce low variance as the desired property of a bicluster, nor use variance as a guiding metric while searching for the desirable biclusters. In this paper we present an algorithm that searches a space of all overlapping biclusters organized in a lattice, and uses an upper bound on variance values of biclusters as the guiding metric. We show the algorithm to be an efficient and effective method for discovering the possibly overlapping biclusters under pre-defined variance bounds. We present in this paper our algorithm, its results with synthetic, CHIP-Seq and motif datasets, and compare them with the results obtained by other algorithms to demonstrate the power and effectiveness of our algorithm.		Zhen Hu;Raj Bhatnagar	2012	Scientific Programming	10.3233/SPR-2012-0336	biological classification;computer science;bioinformatics;machine learning;data mining;cluster analysis	HPC	5.092524848033444	-54.70272853686796	150284
94cb87d0fee9818236253a434dcb8b02b907cb07	prediction of potential drug targets based on simple sequence properties	physicochemical properties;prediction method;drug discovery;drug targeting;protein sequence;pharmaceutical preparations;computational biology bioinformatics;research and development;proteins;algorithms;humans;support vector machine;combinatorial libraries;pharmaceutical industry;computational biology;computer appl in life sciences;3d structure;microarrays;bioinformatics	During the past decades, research and development in drug discovery have attracted much attention and efforts. However, only 324 drug targets are known for clinical drugs up to now. Identifying potential drug targets is the first step in the process of modern drug discovery for developing novel therapeutic agents. Therefore, the identification and validation of new and effective drug targets are of great value for drug discovery in both academia and pharmaceutical industry. If a protein can be predicted in advance for its potential application as a drug target, the drug discovery process targeting this protein will be greatly speeded up. In the current study, based on the properties of known drug targets, we have developed a sequence-based drug target prediction method for fast identification of novel drug targets. Based on simple physicochemical properties extracted from protein sequences of known drug targets, several support vector machine models have been constructed in this study. The best model can distinguish currently known drug targets from non drug targets at an accuracy of 84%. Using this model, potential protein drug targets of human origin from Swiss-Prot were predicted, some of which have already attracted much attention as potential drug targets in pharmaceutical research. We have developed a drug target prediction method based solely on protein sequence information without the knowledge of family/domain annotation, or the protein 3D structure. This method can be applied in novel drug target identification and validation, as well as genome scale drug target predictions.	academia (organization);amino acid sequence;annotation;best practice;dosage forms;drug delivery systems;drug discovery;extraction;gene prediction;peptide sequence;pharmacy (field);swiss-model;staphylococcal protein a;support vector machine;switzerland;cellular targeting	Qingliang Li;Luhua Lai	2007	BMC Bioinformatics	10.1186/1471-2105-8-353	reverse pharmacology;pharmacology;biology;support vector machine;targeted drug delivery;dna microarray;computer science;bioinformatics;protein sequencing;druggability;drug discovery;hit to lead	Comp.	9.167230609846028	-56.787360147215075	150399
3b7e236110cb11e16a617c6d5c3fcac1ecdf1fc7	identification of microrna precursors based on random forest with network-level representation method of stem-loop structure	animals;rna messenger;receiver operator curve;computational biology bioinformatics;rna precursors;stem loop;feature extraction;secondary structure;random forest;nucleic acid conformation;models statistical;artificial intelligence;algorithms;humans;prediction model;combinatorial libraries;computational efficiency;micrornas;computer appl in life sciences;microrna;structure analysis;biological process;microarrays;bioinformatics	MicroRNAs (miRNAs) play a key role in regulating various biological processes such as participating in the post-transcriptional pathway and affecting the stability and/or the translation of mRNA. Current methods have extracted feature information at different levels, among which the characteristic stem-loop structure makes the greatest contribution to the prediction of putative miRNA precursor (pre-miRNA). We find that none of these features alone is capable of identifying new pre-miRNA accurately. In the present work, a pre-miRNA stem-loop secondary structure is translated to a network, which provides a novel perspective for its structural analysis. Network parameters are used to construct prediction model, achieving an area under the receiver operating curves (AUC) value of 0.956. Moreover, by repeating the same method on two independent datasets, accuracies of 0.976 and 0.913 are achieved, respectively. Network parameters effectively characterize pre-miRNA secondary structure, which improves our prediction model in both prediction ability and computation efficiency. Additionally, as a complement to feature extraction methods in previous studies, these multifaceted features can reflect natural properties of miRNAs and be used for comprehensive and systematic analysis on miRNA.	area under curve;complement system proteins;computation (action);feature extraction;gene regulatory network;hypothalamic area, lateral;micrornas;random forest;structural analysis;transcription, genetic	Jiamin Xiao;Xiaojing Tang;Yizhou Li;Zheng Fang;Daichuan Ma;Yangzhige He;Menglong Li	2010		10.1186/1471-2105-12-165	biology;computer science;bioinformatics;genetics;microrna	ML	8.091560137598572	-57.58513642725626	150602
4fe83a025f66b9fd67e720a1561e5542fdbaf990	efficient stratified testing procedure for a false discovery rate	microarray data;multiple testing;stratified testing;gene expression;secondary 62f03;primary 62	The false discovery rate (FDR) has become a popular error measure in the large-scale simultaneous testing. When data are collected from heterogenous sources and form grouped hypotheses testing, it may be beneficial to use the distinct feature of groups to conduct the multiple hypotheses testing. We propose a stratified testing procedure that uses different FDR levels according to the stratification features based on p-values. Our proposed method is easy to implement in practice. Simulations studies show that the proposed method produces more efficient testing results. The stratified testing procedure minimizes the overall false negative rate (FNR) level, while controlling the overall FDR. An example from a type II diabetes mice study further illustrates the practical advantages of this new approach.		Seungbong Han;Adin-Cristian Andrei;Kam-Wah Tsui	2015	Communications in Statistics - Simulation and Computation	10.1080/03610918.2013.809097	microarray analysis techniques;econometrics;gene expression;mathematics;multiple comparisons problem;statistics	Theory	5.8123561045852945	-52.13985522984001	150774
447879978ec1e5fabe91c96061a0f2320674d561	a mathematical model in the study of genes for identifying transcription factor binding sites	regulation of gene expression;transcription factor binding site;regulatory element;transcription factor;gene expression regulation;mathematical model;regression analysis	This paper deals with the analysis of a mathematical model for a study of genomics concerned with the differential regulation of gene expression. The approach being studied here pioneers the motif-based regression analysis of a single transcriptome. Implemented as the algorithm REDUCE-an acronym that stands for regulatory element detection using correlation with expression-the method naturally takes into account the combinatorial nature of gene expression regulation and provides context-specific information about transcription factor activities.	mathematical model;transcription (software)	J. C. Misra;B. Dravid	2006	Computers & Mathematics with Applications	10.1016/j.camwa.2005.06.013	cis-regulatory element;regulation of gene expression;bioinformatics;cis-regulatory module;sp3 transcription factor;response element;promoter	Metrics	4.260480761495004	-59.01846301293765	150920
275c7e070c3b981ee2e1e63d7a3c598bc34caed2	inferring the conservative causal core of gene regulatory networks	escherichia coli;simulation and modeling;estimation method;systems biology;gene regulatory networks;physiological cellular and medical topics;gene network;computational biology bioinformatics;large scale;computational complexity;system biology;mutual information;algorithms;point of view;high throughput;computational biology;gene regulatory network;molecular interactions;biological process;bioinformatics	Inferring gene regulatory networks from large-scale expression data is an important problem that received much attention in recent years. These networks have the potential to gain insights into causal molecular interactions of biological processes. Hence, from a methodological point of view, reliable estimation methods based on observational data are needed to approach this problem practically. In this paper, we introduce a novel gene regulatory network inference (GRNI) algorithm, called C3NET. We compare C3NET with four well known methods, ARACNE, CLR, MRNET and RN, conducting in-depth numerical ensemble simulations and demonstrate also for biological expression data from E. coli that C3NET performs consistently better than the best known GRNI methods in the literature. In addition, it has also a low computational complexity. Since C3NET is based on estimates of mutual information values in conjunction with a maximization step, our numerical investigations demonstrate that our inference algorithm exploits causal structural information in the data efficiently. For systems biology to succeed in the long run, it is of crucial importance to establish methods that extract large-scale gene networks from high-throughput data that reflect the underlying causal interactions among genes or gene products. Our method can contribute to this endeavor by demonstrating that an inference algorithm with a neat design permits not only a more intuitive and possibly biological interpretation of its working mechanism but can also result in superior results.	behavior;causal filter;computational complexity theory;dclk3 gene;estimated;expectation–maximization algorithm;gene regulatory network;high-throughput computing;inference;interaction;license;mutual information;numerical analysis;simulation;systems biology;throughput	Gökmen Altay;Frank Emmert-Streib	2010		10.1186/1752-0509-4-132	computational biology;biology;gene regulatory network;bioinformatics;genetics;systems biology	Comp.	4.518413568945865	-55.79215579937969	151583
2a05102d23ea511e58863baeef281bfd769c80d4	modeling and visualizing cell type switching	software;animals;imaging three dimensional;cell differentiation;gene regulatory networks;transcription factors;models biological;drosophila;cell transdifferentiation;cell lineage;myeloid cells;algorithms;humans;neoplasms;computational biology;mutation	Understanding cellular differentiation is critical in explaining development and for taming diseases such as cancer. Differentiation is conventionally represented using bifurcating lineage trees. However, these lineage trees cannot readily capture or quantify all the types of transitions now known to occur between cell types, including transdifferentiation or differentiation off standard paths. This work introduces a new analysis and visualization technique that is capable of representing all possible transitions between cell states compactly, quantitatively, and intuitively. This method considers the regulatory network of transcription factors that control cell type determination and then performs an analysis of network dynamics to identify stable expression profiles and the potential cell types that they represent. A visualization tool called CellDiff3D creates an intuitive three-dimensional graph that shows the overall direction and probability of transitions between all pairs of cell types within a lineage. In this study, the influence of gene expression noise and mutational changes during myeloid cell differentiation are presented as a demonstration of the CellDiff3D technique, a new approach to quantify and envision all possible cell state transitions in any lineage network.	cell differentiation process;gene expression;gene regulatory network;graph - visual representation;histopathologic grade differentiation;imagery;lineage (evolution);myeloid cell differentiation;transcription factor;transcription (software);tree (data structure);trees (plant);transdifferentiation	Ahmadreza Ghaffarizadeh;Gregory J. Podgorski;Nicholas S. Flann	2014		10.1155/2014/293980	mutation;biology;gene regulatory network;bioinformatics;genetics;cellular differentiation;transcription factor	Comp.	3.9633411064612223	-57.680322852187054	151703
6a74f1c6d041ceb073af81f3de49ecc3768f8183	prediction of drugs having opposite effects on disease genes in a directed network	simulation and modeling;systems biology;physiological cellular and medical topics;computational biology bioinformatics;algorithms;bioinformatics	Developing novel uses of approved drugs, called drug repositioning, can reduce costs and times in traditional drug development. Network-based approaches have presented promising results in this field. However, even though various types of interactions such as activation or inhibition exist in drug-target interactions and molecular pathways, most of previous network-based studies disregarded this information. We developed a novel computational method, Prediction of Drugs having Opposite effects on Disease genes (PDOD), for identifying drugs having opposite effects on altered states of disease genes. PDOD utilized drug-drug target interactions with ‘effect type’, an integrated directed molecular network with ‘effect type’ and ‘effect direction’, and disease genes with regulated states in disease patients. With this information, we proposed a scoring function to discover drugs likely to restore altered states of disease genes using the path from a drug to a disease through the drug-drug target interactions, shortest paths from drug targets to disease genes in molecular pathways, and disease gene-disease associations. We collected drug-drug target interactions, molecular pathways, and disease genes with their regulated states in the diseases. PDOD is applied to 898 drugs with known drug-drug target interactions and nine diseases. We compared performance of PDOD for predicting known therapeutic drug-disease associations with the previous methods. PDOD outperformed other previous approaches which do not exploit directional information in molecular network. In addition, we provide a simple web service that researchers can submit genes of interest with their altered states and will obtain drugs seeming to have opposite effects on altered states of input genes at http://gto.kaist.ac.kr/pdod/index.php/main . Our results showed that ‘effect type’ and ‘effect direction’ information in the network based approaches can be utilized to identify drugs having opposite effects on diseases. Our study can offer a novel insight into the field of network-based drug repositioning.	adverse reaction to drug;computation;drug delivery systems;drug repositioning;interaction;mental association;patients;repositioning (procedure);score;short;shortest path problem;web service;drug development	Hasun Yu;Sungji Choo;Junseok Park;Jinmyung Jung;Yeeok Kang;Doheon Lee	2015		10.1186/s12918-015-0243-2	computational biology;biology;toxicology;computer science;bioinformatics;systems biology	Comp.	7.819889942286518	-59.024126267245286	152610
48a67f24e48ab37ee34486a038d9a2750856ab0b	tandem machine learning for the identification of genes regulated by transcription factors	cluster algorithm;bayesian classification;decision tree;receptors steroid;gene regulation;nucleic acids;chromosome mapping;dna binding;transcription factors;binding site;binding sites;information content;journal article;computational biology bioinformatics;cluster analysis;machine learning;transcription factor;human genome;gene targeting;target gene;artificial intelligence;algorithms;pattern recognition automated;cross validation;combinatorial libraries;nuclear receptor;tandem machine learning;receptors cytoplasmic and nuclear;computer appl in life sciences;gene expression profiling;leave one out;information theory;oligonucleotide array sequence analysis;candidate gene;neural network;microarrays;bioinformatics	The identification of promoter regions that are regulated by a given transcription factor has traditionally relied upon the identification and distributions of binding sites recognized by the factor. In this study, we have developed a tandem machine learning approach for the identification of regulatory target genes based on these parameters and on the corresponding binding site information contents that measure the affinities of the factor for these cognate elements. This method has been validated using models of DNA binding sites recognized by the xenobiotic-sensitive nuclear receptor, PXR/RXRα, for target genes within the human genome. An information theory-based weight matrix was first derived and refined from known PXR/RXRα binding sites. The promoter region of candidate genes was scanned with the weight matrix. A novel information density-based clustering algorithm was then used to identify clusters of information rich sites. Finally, transformed data representing metrics of location, strength and clustering of binding sites were used for classification of promoter regions using an ensemble approach involving neural networks, decision trees and Naïve Bayesian classification. The method was evaluated on a set of 24 known target genes and 288 genes known not to be regulated by PXR/RXRα. We report an average accuracy (proportion of correctly classified promoter regions) of 71%, sensitivity of 73%, and specificity of 70%, based on multiple cross-validation and the leave-one-out strategy. The performance on a test set of 13 genes showed that 10 were correctly classified. We have developed a machine learning approach for the successful detection of gene targets for transcription factors with high accuracy. The method has been validated for the transcription factor PXR/RXRα and has the potential to be extended to other transcription factors.	artificial neural network;bayesian network;binding sites;candidate disease gene;classification;cluster analysis;cross reactions;cross-validation (statistics);dna binding site;decision tree;information theory;information design;machine learning;nr1i2 gene;nr1i2 wt allele;naive bayes classifier;neural network simulation;promoter regions, genetic;receptors, nuclear;scanning;sensitivity and specificity;transcription factor;test set;transcription (software);trees (plant);algorithm;contents - htmllinktype;statistical cluster	Deendayal Dinakarpandian;Venetia Raheja;Saumil Mehta;Erin G. Schuetz;Peter K. Rogan	2005	BMC Bioinformatics	10.1186/1471-2105-6-204	biology;molecular biology;information theory;bioinformatics;binding site;genetics;transcription factor	Comp.	4.285584157080728	-57.71009508902357	153074
3b323b1fb4f59bbed380f2cf15e9d888f658d846	development of a system for the inference of large scale genetic networks	wild type;steady state;system modeling;top down;network architecture;boolean network;gene expression	We propose a system named AIGNET (Algorithms for Inference of Genetic Networks), and introduce two top-down approaches for the inference of interrelated mechanism among genes in genetic network that is based on the steady state and temporal analyses of gene expression patterns against some kinds of gene perturbations such as disruption or overexpression. The former analysis is performed by a static Boolean network model based on multi-level digraph, and the latter one is by S-system model. By integrating these two analyses, we show our strategy is flexible and rich in structure to treat gene expression patterns; we applied our strategy to the inference of a genetic network that is composed of 30 genes as a case study. Given the gene expression time-course data set under the conditions of wild-type and the deletion of one gene, our system enabled us to reconstruct the same network architecture as original one.	algorithm;boolean network;deletion mutation;denial-of-service attack;directed graph;gene expression;gene co-expression network;gene regulatory network;inference;name;network architecture;network model;numerous;steady state;top-down and bottom-up design	Yukihiro Maki;Daisuke Tominaga;Masahiro Okamoto;Shoji Watanabe;Yukihiro Eguchi	2001	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		biological network inference;biology;boolean network;gene expression;systems modeling;network architecture;bioinformatics;machine learning;top-down and bottom-up design;data mining;steady state;genetics;wild type	Comp.	5.531955719944005	-56.90625718709175	153591
eea66fc53c762607ad3d3119d21ae8af32113192	prediction by support vector machines and analysis by z-score of poly-l-proline type ii conformation based on local sequence	prediction method;poly l;local sequence;poly l proline type ii;z score;kernel function;protein structure;secondary structure;pattern classification;pattern recognition;support vector machine;correlation coefficient;biological process	In recent years, the poly-L-proline type II (PPII) conformation has gained more and more importance. This structure plays vital roles in many biological processes. But few studies have been made to predict PPII secondary structures computationally. The support vector machine (SVM) represents a new approach to supervised pattern classification and has been successfully applied to a wide range of pattern recognition problems. In this paper, we present a SVM prediction method of PPII conformation based on local sequence. The overall accuracy for both the independent testing set and estimate of jackknife testing reached approximately 70%. Matthew's correlation coefficient (MCC) could reach 0.4. By comparing the results of training and testing datasets with different sequence identities, we suggest that the performance of this method correlates with the sequence identity of dataset. The parameter of SVM kernel function was an important factor to the performance of this method. The propensities of residues located at different positions were also analyzed. By computing Z-scores, we found that P and G were the two most important residues to PPII structure conformation.	coefficient;computation (action);correlation study;gain;jackknife resampling;kernel;pattern recognition;poly a;poly i-c;population parameter;proline;sense of identity (observable entity);sequence alignment;silo (dataset);support vector machine	Minglei Wang;Hui Yao;Wenbo Xu	2005	Computational biology and chemistry	10.1016/j.compbiolchem.2005.02.002	kernel;biology;support vector machine;biochemistry;protein structure;standard score;chemistry;computer science;bioinformatics;machine learning;pattern recognition;biological process;protein secondary structure	ML	9.67564178984594	-55.529267067168966	153883
3065838ff61b68a853d154ba63e0c0936ae28b57	gaussian graphical modeling reconstructs pathway reactions from high-throughput metabolomics data	simulation and modeling;metabolomics;metabolic networks and pathways;normal distribution;department biologie i;systems biology;physiological cellular and medical topics;models biological;fatty acids;computational biology bioinformatics;algorithms;humans;gaussian graphical model;ddc 570;high throughput;biologie;bioinformatics	With the advent of high-throughput targeted metabolic profiling techniques, the question of how to interpret and analyze the resulting vast amount of data becomes more and more important. In this work we address the reconstruction of metabolic reactions from cross-sectional metabolomics data, that is without the requirement for time-resolved measurements or specific system perturbations. Previous studies in this area mainly focused on Pearson correlation coefficients, which however are generally incapable of distinguishing between direct and indirect metabolic interactions. In our new approach we propose the application of a Gaussian graphical model (GGM), an undirected probabilistic graphical model estimating the conditional dependence between variables. GGMs are based on partial correlation coefficients, that is pairwise Pearson correlation coefficients conditioned against the correlation with all other metabolites. We first demonstrate the general validity of the method and its advantages over regular correlation networks with computer-simulated reaction systems. Then we estimate a GGM on data from a large human population cohort, covering 1020 fasting blood serum samples with 151 quantified metabolites. The GGM is much sparser than the correlation network, shows a modular structure with respect to metabolite classes, and is stable to the choice of samples in the data set. On the example of human fatty acid metabolism, we demonstrate for the first time that high partial correlation coefficients generally correspond to known metabolic reactions. This feature is evaluated both manually by investigating specific pairs of high-scoring metabolites, and then systematically on a literature-curated model of fatty acid synthesis and degradation. Our method detects many known reactions along with possibly novel pathway interactions, representing candidates for further experimental examination. In summary, we demonstrate strong signatures of intracellular pathways in blood serum data, and provide a valuable tool for the unbiased reconstruction of metabolic reactions from large-scale metabolomics data sets.	antivirus software;class;coefficient;computer simulation;cross-sectional data;dividend discount model;elegant degradation;estimated;fatty acids;fatty acid biosynthetic process;gene regulatory network;graph (discrete mathematics);graphical model;high-throughput computing;interaction;metabolic process, cellular;metabolite;metabolomics;normal statistical distribution;other toxicity studies: metabolites;score;serum;throughput;fatty acid metabolism	Jan Krumsiek;Karsten Suhre;Thomas Illig;Jerzy Adamski;Fabian J. Theis	2010		10.1186/1752-0509-5-21	normal distribution;high-throughput screening;biology;computer science;bioinformatics;data science;metabolomics;data mining;systems biology	ML	5.940638945023142	-55.19017191192222	153980
4d0480f1d4399fc84769cb30276a5e7beb3165dd	a comparative study on sequence feature extraction for type iii secreted effector prediction	biology computing;protein sequence feature;t3ss study;delivery system;sequence feature extraction method;bacterial survival;amino acid;protein sequence;the type iii secretion system;accessibility information;type iii secreted effector prediction;proteins biology computing feature extraction learning artificial intelligence molecular biophysics;solvents;pseudomonas syringae data set;accuracy;proteins;machine learning;feature extraction;secondary structure;protein delivery system;molecular biophysics;comparative study;proteins amino acids feature extraction bioinformatics accuracy solvents microorganisms;pseudomonas syringae;secretion mechanism;amino acids;machine learning method;solvent accessibility;learning artificial intelligence;pseudomonas syringae data set sequence feature extraction method type iii secreted effector prediction protein secretion bacterial survival protein delivery system pathogens secretion mechanism t3ss study machine learning method secreted effector identification protein sequence feature secondary structure accessibility information;secreted effector identification;protein secretion;microorganisms;bioinformatics;pathogens	Protein secretion is an essential mechanism for bacterial survival in their surrounding environment. The type III secretion system (T3SS) is a specialized protein delivery system that plays a key role in pathogens. Since the secretion mechanism has not been fully understood yet, T3SS has attracted a great deal of research interests. Especially, the identification of novel effectors (secreted proteins) is an important and challenging task for the T3SS study. This paper adopts machine learning methods to predict type III secreted effectors (T3SE). We conduct a comparative study on the feature extraction methods for protein sequence of T3SEs, and propose new methods involving sequence features, secondary structure and solvent accessibility information. The experimental results on Pseudomonas syringae data set demonstrate the effectiveness of our methods.	accessibility;bioinformatics;computation;cross-validation (statistics);experiment;feature extraction;k-mer;machine learning;mer;support vector machine	Yang Yang	2011	2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2011.6019870	amino acid;computer science;bioinformatics;molecular biophysics	DB	9.353503833500797	-56.203675124024784	154011
cbb7e9d639591cae3383a06b2f9f0c6607be8bdd	lncanet: pan-cancer co-expression network for human lncrna and cancer genes		UNLABELLED Thousands of human long non-coding RNAs (lncRNAs) have been identified in cancers and played important roles in a wide range of tumorigenesis. However, the functions of vast majority of human lncRNAs are still elusive. Emerging studies revealed that the expression level of majority lncRNAs shows discordant expression pattern with their protein-coding gene neighbors in various model organisms. Therefore, it may be useful to infer lncRNAs' potential biological function in cancer development by more comprehensive functional views of co-expressed cancer genes beyond mere physical proximity of genes. To this aim, we performed thorough searches and analyses of the interactions between lncRNA and non-neighboring cancer genes and provide a comprehensive co-expression data resource, LnCaNet. In current version, LnCaNet contains the pre-computed 8 494 907 significant co-expression pairs of 9641 lncRNAs and 2544 well-classified cancer genes in 2922 matched TCGA samples. In detail, we integrated 10 cancer gene lists from public database and calculate the co-expression with all the lncRNAs in 11 TCGA cancer types separately. Based on the resulted 110 co-expression networks, we identified 17 common regulatory pairs related to extracellular space shared in 11 cancers. We expect LnCaNet will enable researcher to explore lncRNA expression pattern, their affected cancer genes and pathways, biological significance in the context of specific cancer types and other useful annotation related to particular kind of lncRNA-cancer gene interaction.   AVAILABILITY AND IMPLEMENTATION http://lncanet.bioinfo-minzhao.org/   CONTACT : m.zhao@uq.edu.au   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.		Yining Liu;Min Zhao	2016	Bioinformatics	10.1093/bioinformatics/btw017	biology;bioinformatics;genetics	Comp.	3.8117907779368636	-57.6567713263033	154983
57eb9d763d51d6bc5eddd9f26782be973b1e914c	searching for closely related ligands with different mechanisms of action using machine learning and mapping algorithms.		Supervised machine learning approaches, including support vector machines, random forests, Bayesian classifiers, nearest-neighbor similarity searching, and a conceptually distinct mapping algorithm termed DynaMAD, have been investigated for their ability to detect structurally related ligands of a given receptor with different mechanisms of action. For this purpose, a large number of simulated virtual screening trials were carried out with models trained on mechanistic subsets of different classes of receptor ligands. The results revealed that ligands with the desired mechanism of action were frequently contained in database selection sets of limited size. All machine learning approaches successfully detected mechanistic subsets of ligands in a large background database of druglike compounds. However, the early enrichment characteristics considerably differed. Overall, random forests of relatively simple design and support vector machines with Gaussian kernels (Gaussian SVMs) displayed the highest search performance. In addition, DynaMAD was found to yield very small selection sets comprising only ~10 compounds that also contained ligands with the desired mechanism of action. Random forest, Gaussian SVM, and DynaMAD calculations revealed an enrichment of compounds with the desired mechanism over other mechanistic subsets.		Jenny Balfer;Martin Vogt;Jürgen Bajorath	2013	Journal of chemical information and modeling	10.1021/ci400359n	computer science;bioinformatics;machine learning;data mining	AI	9.821136887344187	-56.517559999936495	155047
74e72710c829d2e30076765ad5ec5d0919dcda6b	sample phenotype clusters in high-density oligonucleotide microarray data sets are revealed using isomap, a nonlinear algorithm	microarray data;hl 60 cells;animals;high resolution;environmental variables;spinal cord injuries;high density;rats;oligonucleotide microarray;bias epidemiology;chromosome mapping;exploratory analysis;genetics;computational biology bioinformatics;data display;models genetic;cluster analysis;spinal cord injury;nonlinear dynamics;drug evaluation preclinical;algorithms;humans;neurons;combinatorial libraries;high throughput;computational biology;computer appl in life sciences;drug screening;dimensional reduction;cell death;oligonucleotide array sequence analysis;environmental factor;microarrays;bioinformatics	Life processes are determined by the organism's genetic profile and multiple environmental variables. However the interaction between these factors is inherently non-linear [1]. Microarray data is one representation of the nonlinear interactions among genes and genes and environmental factors. Still most microarray studies use linear methods for the interpretation of nonlinear data. In this study, we apply Isomap, a nonlinear method of dimensionality reduction, to analyze three independent large Affymetrix high-density oligonucleotide microarray data sets. Isomap discovered low-dimensional structures embedded in the Affymetrix microarray data sets. These structures correspond to and help to interpret biological phenomena present in the data. This analysis provides examples of temporal, spatial, and functional processes revealed by the Isomap algorithm. In a spinal cord injury data set, Isomap discovers the three main modalities of the experiment – location and severity of the injury and the time elapsed after the injury. In a multiple tissue data set, Isomap discovers a low-dimensional structure that corresponds to anatomical locations of the source tissues. This model is capable of describing low- and high-resolution differences in the same model, such as kidney-vs.-brain and differences between the nuclei of the amygdala, respectively. In a high-throughput drug screening data set, Isomap discovers the monocytic and granulocytic differentiation of myeloid cells and maps several chemical compounds on the two-dimensional model. Visualization of Isomap models provides useful tools for exploratory analysis of microarray data sets. In most instances, Isomap models explain more of the variance present in the microarray data than PCA or MDS. Finally, Isomap is a promising new algorithm for class discovery and class prediction in high-density oligonucleotide data sets.	affymetrix;algorithm;amygdaloid structure;body tissue;chemicals;dna microarray;dimensionality reduction;embedded system;embedding;high-throughput computing;image resolution;interaction;isomap;map;monocytes;nonlinear system;principal component analysis;renal tissue;sample variance;spinal cord injuries;throughput;granulocyte	Kevin Dawson;Raymond L. Rodriguez;Wasyl Malyj	2004	BMC Bioinformatics	10.1186/1471-2105-6-195	programmed cell death;high-throughput screening;biology;microarray analysis techniques;molecular biology;gene chip analysis;dna microarray;image resolution;nonlinear system;computer science;bioinformatics;cluster analysis;genetics	ML	5.8282347613770344	-56.37459343098539	155102
5a1e00e2385a2b489085e6bd01492cffabf9673f	high-confidence predictions in systems biology dynamic models		Obtaining reliable predictions from large-scale dynamic models is a challenging task due to frequent lack of identifiability. This work presents a methodology for obtaining high-confidence predictions in biotechnological applications using metabolite time-series data. To preserve the complex behaviour of the network while reducing the number of estimated parameters, model parameters are combined in sets of meta-parameters, obtained from correlations between metabolite concentrations and between biochemical reaction rates. Next, an ensemble of models with different parameterizations is constructed and calibrated. Convergence of model outputs (consensus) is used as an indicator of confidence. Computational tests were carried out on a metabolic model of Chinese Hamster Ovary (CHO) cells. Using noisy simulated data, averaged ensemble predictions with high consensus were found to be more accurate than either predictions of individual ensemble models or averaged ensemble predictions with large variance. The procedure provides quantitative estimates of the confidence in model predictions and enables the analysis of sufficiently complex networks as required for practical applications in biotechnology.	systems biology	Alejandro Fernández Villaverde;Sophia Bongard;Klaus Mauch;Dirk Müller;Eva Balsa-Canto;Joachim Schmid;Julio R. Banga	2014		10.1007/978-3-319-07581-5_20	econometrics;computer science;machine learning;statistics	Logic	7.651894725609416	-58.480327931831745	155181
44199125e8789ce29a0b54dcfb26357f15364dfe	a comprehensive study of a svm-based mirna target prediction algorithm	microarray data;sensitivity and specificity;biology computing;svm based mirna target prediction algorithm;support vector machines;svmicro;disease;training;non coding rna;prediction algorithms;two stage svm algorithm;data mining;multiple microarray data set;single stranded noncoding rna;sensitivity;single stranded;training data set;feature extraction;molecular biophysics;macromolecules;support vector machines svm based mirna target prediction algorithm microrna single stranded noncoding rna mirna regulatory target identification training data set multiple microarray data set two stage svm algorithm biological process disease svmicro;support vector machines biology computing macromolecules molecular biophysics;mirna regulatory target identification;microrna;prediction algorithms support vector machines feature extraction testing rna spatial databases genomics bioinformatics pediatrics cancer;biological process;bioinformatics	MicroRNAs are single-stranded non-coding RNAs that play important regulatory roles in many biological processes and diseases. Identifying miRNA regulatory targets is paramount in elucidating its function. We carried out a comprehensive study of a new SVM-based target prediction algorithm called SVMicrO in this paper. The training data set is carefully derived from the most up-to-date collection of verified targets and multiple microarray data sets. Several varieties of feature design and selection schemes are investigated. The prediction results are compared with most of the existing algorithms, which show improved sensitivity and specificity of this two-stage SVM algorithm.	algorithm;microarray;sensitivity and specificity;test set	Hui Liu;Dong Yue;Yidong Chen;Yufei Huang	2009	2009 IEEE International Workshop on Genomic Signal Processing and Statistics	10.1109/GENSIPS.2009.5174346	macromolecule;biology;support vector machine;microarray analysis techniques;prediction;sensitivity;feature extraction;computer science;bioinformatics;machine learning;data mining;non-coding rna;biological process;genetics;microrna;molecular biophysics	Visualization	8.84025286040007	-55.53405476549695	155251
73a0e0195486cf347701d8f7e0cc47ac86a5c1e5	an algorithm for modularization of mapk and calcium signaling pathways: comparative analysis among different species	comparative analysis;systems biology;signal transduction;signal transduction pathway;graphs;community structure;system biology;biochemical network;calcium signaling;signaling pathway;biological networks;modules;biological network;community finding algorithm	Signaling pathways are large complex biochemical networks. It is difficult to analyze the underlying mechanism of such networks as a whole. In the present article, we have proposed an algorithm for modularization of signal transduction pathways. Unlike studying a signaling pathway as a whole, this enables one to study the individual modules (less complex smaller units) easily and hence to study the entire pathway better. A comparative study of modules belonging to different species (for the same signaling pathway) has been made, which gives an overall idea about development of the signaling pathways over the taken set of species of calcium and MAPK signaling pathways. The superior performance, in terms of biological significance, of the proposed algorithm over an existing community finding algorithm of Newman [Newman MEJ. Modularity and community structure in networks. Proc Natl Acad Sci USA 2006;103(23):8577-82] has been demonstrated using the aforesaid pathways of H. sapiens.	aspartate transaminase;calcium signaling;cell signaling;experiment;gene regulatory network;mapk signaling pathway;modularity (networks);muscle;musculus <invertebrate>;newman's lemma;optimization problem;samuel newman;signal transduction pathways;small;transduction (machine learning);activated t cell autonomous cell death;algorithm	Losiana Nayak;Rajat K. De	2007	Journal of biomedical informatics	10.1016/j.jbi.2007.05.007	computer science;bioinformatics;systems biology;signal transduction	ML	4.596179547796646	-58.16075543771624	155317
359662a7e8a9fba2e36e40fae5d6624f9ea4afed	a powerful score-based statistical test for group difference in weighted biological networks	computational biology bioinformatics;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	Complex disease is largely determined by a number of biomolecules interwoven into networks, rather than a single biomolecule. A key but inadequately addressed issue is how to test possible differences of the networks between two groups. Group-level comparison of network properties may shed light on underlying disease mechanisms and benefit the design of drug targets for complex diseases. We therefore proposed a powerful score-based statistic to detect group difference in weighted networks, which simultaneously capture the vertex changes and edge changes. Simulation studies indicated that the proposed network difference measure (NetDifM) was stable and outperformed other methods existed, under various sample sizes and network topology structure. One application to real data about GWAS of leprosy successfully identified the specific gene interaction network contributing to leprosy. For additional gene expression data of ovarian cancer, two candidate subnetworks, PI3K-AKT and Notch signaling pathways, were considered and identified respectively. The proposed method, accounting for the vertex changes and edge changes simultaneously, is valid and powerful to capture the group difference of biological networks.	anatomy, regional;biological network;contribution;drug delivery systems;gene expression;genome-wide association study;interaction network;malignant neoplasm of ovary;network topology;proto-oncogene proteins c-akt;sample size;simulation;statistic (data);statistical test;vertex;weighted network;leprosy vaccine;ovarian neoplasm	Jiadong Ji;Zhongshang Yuan;Xiaoshuai Zhang;Fuzhong Xue	2016	BMC Bioinformatics	10.1186/s12859-016-0916-x	biology;dna microarray;computer science;bioinformatics;data science	Comp.	5.361876797168108	-56.69033556578353	155395
50dfd5c8374074cc3c00d39c6b9b4ea193f43dce	on combining recursive partitioning and simulated annealing to detect groups of biologically active compounds	recursive partitioning;simulated annealing;biological activity	Statistical data mining methods have proven to be powerful tools for investigating correlations between molecular structure and biological activity. Recursive partitioning (RP), in particular, offers several advantages in mining large, diverse data sets resulting from high throughput screening. When used with binary molecular descriptors, the standard implementation of RP splits on single descriptors. We use simulated annealing (SA) to find combinations of molecular descriptors whose simultaneous presence best separates off the most active, chemically similar group of compounds. The search is incorporated into a recursive partitioning design to produce a regression tree for biological activity on the space of structural fingerprints. Each node is characterized by a specific combination of structural features, and the terminal nodes with high average activities correspond, roughly, to different classes of compounds. Using LeadScope structural features as descriptors to mine a database from the National Cancer Institute, the merging of RP and SA consistently identifies structurally homogeneous classes of highly potent anticancer agents.		Paul E. Blower;Michael Fligner;Joseph S. Verducci;Jeffrey Bjoraker	2002	Journal of chemical information and computer sciences	10.1021/ci0101049	mathematical optimization;chemistry;simulated annealing;computer science;bioinformatics;machine learning;biological activity;mathematics;recursive partitioning	Comp.	9.51652412372646	-57.825629695551626	155462
24e9f3e8eb7fceda2fb69e35e1e40ab00eb0208b	erratum to: integrating mean and variance heterogeneities to identify differentially expressed genes	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	In functional genomics studies, tests on mean heterogeneity have been widely employed to identify differentially expressed genes with distinct mean expression levels under different experimental conditions. Variance heterogeneity (aka, the difference between condition-specific variances) of gene expression levels is simply neglected or calibrated for as an impediment. The mean heterogeneity in the expression level of a gene reflects one aspect of its distribution alteration; and variance heterogeneity induced by condition change may reflect another aspect. Change in condition may alter both mean and some higher-order characteristics of the distributions of expression levels of susceptible genes. In this report, we put forth a conception of mean-variance differentially expressed (MVDE) genes, whose expression means and variances are sensitive to the change in experimental condition. We mathematically proved the null independence of existent mean heterogeneity tests and variance heterogeneity tests. Based on the independence, we proposed an integrative mean-variance test (IMVT) to combine gene-wise mean heterogeneity and variance heterogeneity induced by condition change. The IMVT outperformed its competitors under comprehensive simulations of normality and Laplace settings. For moderate samples, the IMVT well controlled type I error rates, and so did existent mean heterogeneity test (i.e., the Welch t test (WT), the moderated Welch t test (MWT)) and the procedure of separate tests on mean and variance heterogeneities (SMVT), but the likelihood ratio test (LRT) severely inflated type I error rates. In presence of variance heterogeneity, the IMVT appeared noticeably more powerful than all the valid mean heterogeneity tests. Application to the gene profiles of peripheral circulating B raised solid evidence of informative variance heterogeneity. After adjusting for background data structure, the IMVT replicated previous discoveries and identified novel experiment-wide significant MVDE genes. Our results indicate tremendous potential gain of integrating informative variance heterogeneity after adjusting for global confounders and background data structure. The proposed informative integration test better summarizes the impacts of condition change on expression distributions of susceptible genes than do the existent competitors. Therefore, particular attention should be paid to explicitly exploit the variance heterogeneity induced by condition change in functional genomics analysis.	bias–variance tradeoff;data structure;functional genomics;gene expression;genetic heterogeneity;information;integration testing;long-running transaction;normality unit;null value;peripheral;sample variance;semantic heterogeneity;simulation;welch's method;likelihood ratio;t test	Weiwei Ouyang;Qiang An;Jinying Zhao;Huaizhen Qin	2016		10.1186/s12859-017-1507-1	computational biology;biology;dna microarray;computer science;bioinformatics;data science	ML	5.138413244159032	-53.16047061546264	155788
c919e33478e9a5cf4c18ff146e7bfe2a758c5158	effective pre-processing strategies for functional clustering of a protein-protein interactions network	biology computing;protein protein interaction network;protein function;process network;graphs;scale free;graph partitioning;proteins;statistical analysis;side effect;clustering algorithms protein engineering partitioning algorithms databases biological processes bioinformatics ontologies chaos computer science information resources;molecular biophysics;protein protein interaction;protein functionality preprocessing strategies functional clustering protein protein interactions network scale free property false positive interactions hierarchical graph partitioning multilevel graph partitioning;biology computing proteins molecular biophysics graphs statistical analysis;weight function;false positive	In this article we present novel preprocessing techniques, based on typological measures of the network, to identify clusters of proteins from protein-protein interaction (PPI) networks wherein each cluster corresponds to a group of functionally similar proteins. The two main problems with analyzing protein-protein interaction networks are their scale-free property and the large number of false positive interactions that they contain. Our preprocessing techniques use a key transformation and separate weighting functions to effectively eliminate suspect edges, potential false positives, from the graph. A useful side-effect of this transformation is that the resulting graph is no longer scale free. We then examine the application of two well-known clustering techniques, namely hierarchical and multilevel graph partitioning on the reduced network. We define suitable statistical metrics to evaluate our clusters meaningfully. From our study, we discover that the application of clustering on the pre-processed network results in significantly improved, biologically relevant and balanced clusters when compared with clusters derived from the original network. We strongly believe that our strategies would prove invaluable to future studies on prediction of protein functionality from PPI networks.	cluster analysis;futures studies;graph partition;interaction;pixel density;preprocessor;semantic network;side effect (computer science)	Duygu Ucar;Srinivasan Parthasarathy;Sitaram Asur;Chao Wang	2005	Fifth IEEE Symposium on Bioinformatics and Bioengineering (BIBE'05)	10.1109/BIBE.2005.25	protein–protein interaction;weight function;type i and type ii errors;computer science;bioinformatics;graph partition;theoretical computer science;scale-free network;machine learning;graph;side effect;statistics;molecular biophysics	Comp.	4.805480311445033	-56.43283073220386	155937
7bab07bf0bf2fbe1565c47ad202cd52e685c914c	a novel and efficient method for differential pathway identification	genomics;cancer gene expression gene set analysis gsa pathway analysis;liver;cancer;genetics;medical information systems;cancer liver dna gene expression pathology;medical information systems cancer cellular biophysics genetics genomics liver;leukemia differential pathway identification phenotype specific cellular mechanism deciphering gene chain decomposition multiple gene set test methods public available gene expression data sets liver cancer;cellular biophysics	Identifying differential pathways plays important roles in deciphering phenotype-specific cellular mechanisms. In this paper, we propose to decompose pathways into gene chains for detecting pathway expression changes. The decomposition into gene chains allows capturing local information on differential expression of pathways. To avoid biases of single gene set test methods, we collectively used multiple gene set tests to test whether a gene chain is significantly differentially expressed between two phenotypes. Focusing on p53 signal pathway that is well-recognized to be cancer-related, we evaluated the proposed method on two public available gene expression data sets, Liver cancer and Leukemia. Experimental results show the effectiveness and efficiency of the proposed method in identifying differentially expressed pathways.	gene regulatory network;sensor	Hong-Qiang Wang;Rui Li	2013	2013 6th International Conference on Biomedical Engineering and Informatics	10.1109/BMEI.2013.6746985	biology;genomics;molecular biology;bioinformatics;gene expression profiling;genetics;cancer	Comp.	6.489365458646826	-56.47374179979272	155953
a5a5d6e185525063197953aa388372fccd23a422	semiparametric prognosis models in genomic studies	genomique;genomics;pronostic;models theoretical;genomic studies;semiparametric prognosis models;genomica;model comparison;modelo;pronostico;modele;humans;prognosis;models	Development of high-throughput technologies makes it possible to survey the whole genome. Genomic studies have been extensively conducted, searching for markers with predictive power for prognosis of complex diseases such as cancer, diabetes and obesity. Most existing statistical analyses are focused on developing marker selection techniques, while little attention is paid to the underlying prognosis models. In this article, we review three commonly used prognosis models, namely the Cox, additive risk and accelerated failure time models. We conduct simulation and show that gene identification can be unsatisfactory under model misspecification. We analyze three cancer prognosis studies under the three models, and show that the gene identification results, prediction performance of all identified genes combined, and reproducibility of each identified gene are model-dependent. We suggest that in practical data analysis, more attention should be paid to the model assumption, and multiple models may need to be considered.	diabetes mellitus;forecast of outcome;high-throughput computing;neoplasms;semiparametric model;simulation;throughput;utility functions on indivisible goods	Shuangge Ma;Jian Huang;Mingyu Shi;Yang Li;Ben-Chang Shia	2010	Briefings in bioinformatics	10.1093/bib/bbp070	biology;genomics;bioinformatics;statistics	Comp.	6.709835783842356	-52.916722809214725	156503
b4519cb0d53264e405d30c11b5f2c63335773bca	sequence-based prediction of protein-binding sites in dna: comparative study of two svm models	dna protein interactions;binding sites;protein binding nucleotides;prediction model	As many structures of protein-DNA complexes have been known in the past years, several computational methods have been developed to predict DNA-binding sites in proteins. However, its inverse problem (i.e., predicting protein-binding sites in DNA) has received much less attention. One of the reasons is that the differences between the interaction propensities of nucleotides are much smaller than those between amino acids. Another reason is that DNA exhibits less diverse sequence patterns than protein. Therefore, predicting protein-binding DNA nucleotides is much harder than predicting DNA-binding amino acids. We computed the interaction propensity (IP) of nucleotide triplets with amino acids using an extensive dataset of protein-DNA complexes, and developed two support vector machine (SVM) models that predict protein-binding nucleotides from sequence data alone. One SVM model predicts protein-binding nucleotides using DNA sequence data alone, and the other SVM model predicts protein-binding nucleotides using both DNA and protein sequences. In a 10-fold cross-validation with 1519 DNA sequences, the SVM model that uses DNA sequence data only predicted protein-binding nucleotides with an accuracy of 67.0%, an F-measure of 67.1%, and a Matthews correlation coefficient (MCC) of 0.340. With an independent dataset of 181 DNAs that were not used in training, it achieved an accuracy of 66.2%, an F-measure 66.3% and a MCC of 0.324. Another SVM model that uses both DNA and protein sequences achieved an accuracy of 69.6%, an F-measure of 69.6%, and a MCC of 0.383 in a 10-fold cross-validation with 1519 DNA sequences and 859 protein sequences. With an independent dataset of 181 DNAs and 143 proteins, it showed an accuracy of 67.3%, an F-measure of 66.5% and a MCC of 0.329. Both in cross-validation and independent testing, the second SVM model that used both DNA and protein sequence data showed better performance than the first model that used DNA sequence data. To the best of our knowledge, this is the first attempt to predict protein-binding nucleotides in a given DNA sequence from the sequence data alone.	amino acid sequence;amino acids;binding sites;cross reactions;cross-validation (statistics);dna sequence;dna binding site;exhibits as topic;f1 score;matthews correlation coefficient;nucleotides;peptide sequence;silo (dataset);small;support vector machine	Byungkyu Brian Park;Jinyong Im;Narankhuu Tuvshinjargal;Wook Lee;Kyungsook Han	2014	Computer methods and programs in biomedicine	10.1016/j.cmpb.2014.07.009	computer science;bioinformatics;binding site;machine learning;predictive modelling	Comp.	9.797306001455132	-55.77196911590573	156748
7cb7f5bf995a52fab655ee66a7c1d3fc636ec643	guest editorial: pattern recognition in bioinformatics	genomics;protein complex;special issues and sections;semantics;uncertain graph model;proteins;feature extraction;pattern recognition;meetings;relative degree;expected density;special issues and sections meetings bioinformatics genomics pattern recognition feature extraction semantics proteins;bioinformatics	Ç DEVELOPMENT and application of pattern recognition techniques in the field of bioinformatics is of utmost importance for gaining new insights about phenomena in life sciences through the analysis of biological data. In this special section, three research manuscripts in their significantly extended form were selected from the papers presented at the Eighth IAPR International Conference on Pattern Recognition in Bioinformatics (PRIB 2013), which was held in Nice, France. These papers tackle three core problems in bioinformatics using different pattern recognition techniques. In “Fast Entropic Profiler. An Information Theoretic Approach for the Discovery of Patterns in Genomes”, Comin et al. introduce a fast algorithm for pattern discovery in genomes, named Fast Entropic Profiler (FastEP). This algorithm is based on a local entropy function that captures the importance of a region with respect to the whole genome. FastEP has a linear time and linear space complexity. Additionally, the authors also propose an efficient alternative to data normalization leading to a simpler implementation as well as a faster execution of FastEP. Computational experiments and results show that FastEP is suitable for large genomes and for the discovery of patterns with unbounded length. In “A Segmentation-based Method to Extract Structural and Evolutionary Features for Protein Fold Recognition”, Dehzangi et al. introduce a segmentation-based feature extraction technique providing local evolutionary information embedded within a position specific scoring matrix (PSSM) and structural information embedded within a predicted secondary structure of proteins using SPINE-X. By applying a support vector machine (SVM) on the extracted features, the authors enhance the protein fold prediction accuracy by 7.4 percent over the best results reported in the literature. They report 73.8 percent prediction accuracy for a data set consisting of proteins with less than 25 percent sequence similarity rates and 80.7 percent prediction accuracy for a data set with proteins belonging to 110 folds with less than 40 percent sequence similarity rates. The authors investigate the relation between the number of folds and the number of features being used and show that the number of features should be increased to get better protein fold prediction results when the number of folds is relatively large. In “Outlier Analysis and Top Scoring Pairs for Integrated Data Analysis and Biomarker Discovery”, Ochs et al. investigate pathway deregulation, a key driver of carcinogenesis, with proteins in signaling pathways serving as primary targets for drug development. They introduce a novel approach that identifies pathways of interest by integrating outlier analysis within and across molecular data types with gene set analysis. The authors use the results to seed the top-scoring pair algorithm to identify robust biomarkers associated with pathway deregulation. Application of this methodology to pediatric acute myeloid leukemia (AML) data results in the identification of biomarkers in primary AML tumors. The authors demonstrate the robustness of their approach with an independent primary tumor data set, and show that the identified biomarkers also function well in relapsed pediatric AML tumors.	bioinformatics;biological markers;biological science disciplines;carcinogenesis;computation;dspace;deregulation;embedded system;embedding;experiment;feature extraction;gene regulatory network;genome;homology (biology);international association for pattern recognition;leukemia, myelocytic, acute;myeloid leukemia;name;neoplasms;neoplasms, unknown primary;outlier;paper;pierre robin syndrome;position weight matrix;position-specific scoring matrices;score;support vector machine;threading (protein sequence);time complexity;algorithm;drug development;pediatric acute myeloblastic leukemia;primary tumor;recurrent childhood brain stem glioma	Elena Marchiori;Alioune Ngom;Raj Acharya	2014	IEEE/ACM transactions on computational biology and bioinformatics	10.1109/TCBB.2014.2315668	biology;genomics;feature extraction;computer science;bioinformatics;data science;data mining;multiprotein complex;semantics	Comp.	9.838720931406552	-53.42275766274416	157470
f2cee03e983fe9820b6462e284bad0c87e882540	tsapa: identification of tissue-specific alternative polyadenylation sites in plants		Summary Alternative polyadenylation (APA) is now emerging as a widespread mechanism modulated tissue-specifically, which highlights the need to define tissue-specific poly(A) sites for profiling APA dynamics across tissues. We have developed an R package called TSAPA based on the machine learning model for identifying tissue-specific poly(A) sites in plants. A feature space including more than 200 features was assembled to specifically characterize poly(A) sites in plants. The classification model in TSAPA can be customized by selecting desirable features or classifiers. TSAPA is also capable of predicting tissue-specific poly(A) sites in unannotated intergenic regions. TSAPA will be a valuable addition to the community for studying dynamics of APA in plants.   Availability and implementation https://github.com/BMILAB/TSAPA.   Supplementary information Supplementary data are available at Bioinformatics online.		Guoli Ji;Moliang Chen;Wenbin Ye;Sheng Zhu;Congting Ye;Yaru Su;Haonan Peng;Xiaohui Wu	2018	Bioinformatics	10.1093/bioinformatics/bty044	computer science;polyadenylation;bioinformatics	Comp.	8.59893110149948	-56.20969263277294	157561
cb02a44a601b2ad8b6412e3935a98c0bd784025a	gene expression patterns combined with bioinformatics analysis identify genes associated with cholangiocarcinoma	regulatory network;differentially coexpressed gene;cholangiocarcinoma;bioinformatics analysis	To explore the molecular mechanisms of cholangiocarcinoma (CC), microarray technology was used to find biomarkers for early detection and diagnosis. The gene expression profiles from 6 patients with CC and 5 normal controls were downloaded from Gene Expression Omnibus and compared. As a result, 204 differentially co-expressed genes (DCGs) in CC patients compared to normal controls were identified using a computational bioinformatics analysis. These genes were mainly involved in coenzyme metabolic process, peptidase activity and oxidation reduction. A regulatory network was constructed by mapping the DCGs to known regulation data. Four transcription factors, FOXC1, ZIC2, NKX2-2 and GCGR, were hub nodes in the network. In conclusion, this study provides a set of targets useful for future investigations into molecular biomarker studies.	bioinformatics;biological markers;cholangiocarcinoma;coenzymes;early diagnosis;gene co-expression network;gene expression profiling;gene regulatory network;metabolism;microarray analysis;patients;proteolytic enzyme;transcription factor;transcription (software);usb hub;zic2 gene;coenzyme metabolic process;peptidase activity	Chen Li;Weixing Shen;Sheng Shen;Zhilong Ai	2013	Computational biology and chemistry	10.1016/j.compbiolchem.2013.08.010	biology;molecular biology;bioinformatics;genetics	Comp.	5.9066128810947305	-58.13579497570569	157659
1aa50b25c0e7858f483ea2417199066c9f93c5af	genome-wide prediction and analysis of function-specific transcription factor binding sites	transcription factor binding site	DNA-binding transcription factors play a central role in transcription regulation, and the annotation of transcription-factor binding sites in upstream regions of human genes is essential for building a genome-wide regulatory network. We describe methodology to accurately predict the transcription-factor binding sites in the proximal-promoter region of function-specific genes. In order to increase the accuracy of transcription factor binding-site prediction, we rely on recent genome sequence data, known transcription factor binding-site matrices, and Gene Ontology biological-function-based gene classification. Using TRANSFAC position-frequency matrices, we detected individual and cooperating transcription-factor binding sites in proximal promoters of ENSEMBL annotated human genes. We used the over representation of detected binding sites in the proximal promoters as compared to the second exons to control specificity. We confirmed the majority of transcription-factor binding sites predicted in proximal promoters of immune-response genes with evidence from existing literature. We validated the predicted cooperation between transcription factors NF-kappa B and IRF in the regulation of gene expression with microarray transcript profiling data and literature-derived protein-protein interaction network. We also identified over-represented individual and pairs of transcription-factor binding sites in the proximal promoters of each Gene Ontology biological-process gene group. Our tools and analysis provide a new resource for deciphering transcription regulation in different biological paradigms.	annotation;binding sites;dna binding site;exons;gene expression regulation;gene ontology;information retrieval facility;interaction network;microarray;promoter regions, genetic;sensitivity and specificity;transcript;transcription (software);transcriptional regulation;lyt-10 protein;protein protein interaction;transcription factor binding	Fan Long;Hong Liu;Chang S. Hahn;Pavel Sumazin;Michael Q. Zhang;Asher Zilberstein	2004	In silico biology		transcription factor ii d;sigma factor;biology;cis-regulatory element;taf2;gata transcription factor;transcription factor ii a;transcription factor ii f;sp1 transcription factor;sp3 transcription factor;response element;transcription factor ii b;genetics;general transcription factor;transfac;promoter;dna binding site;transcription factor ii e;transcription factor	Comp.	4.433655307753142	-58.52534250635554	158302
c4da91296f9e389c7a0e3256dcaaa38063f89535	2d similarity kernels for biological sequence classification	amino acid;protein sequence;amino acid sequence;kernel methods;feature vector;data analysis;sequence classification;string kernel;machine learning;kernel method;string kernels	String kernel-based machine learning methods have yielded great success in practical tasks of structured/sequential data analysis. They often exhibit state-of-the-art performance on tasks such as document topic elucidation, biological sequence classification, or protein superfamily and fold prediction. However, typical string kernel methods rely on analysis of discrete 1D string data (e.g., DNA or amino acid sequences). This work introduces new 2D kernel methods for sequence data in the form of sequences of feature vectors (as in biological sequence profiles, or sequences of individual amino acid physico-chemical descriptors). On three protein sequence classification tasks proposed 2D kernels show significant 15-20% improvements compared to state-of-the-art sequence classification methods.	feature vector;kernel method;machine learning;peptide sequence;superfamily;string kernel	Pavel P. Kuksa	2012		10.1145/2350176.2350179	kernel method;string kernel;radial basis function kernel;bioinformatics;machine learning;pattern recognition;graph kernel;mathematics	ML	9.865939178058108	-54.19169489297322	158445
678ca5b747a740fd29703559eb36b1d99d402210	identification of melanoma (skin cancer) proteins through support vector machine	rna interference;amino acid;spectrum;skin cancer;genetics;support vector machine;correlation coefficient	Melanoma is a form of cancer that begins in melanocytes. The occur- rence of melanoma continues to rise across the world and current therapeutic options are of limited benefit. Researchers are studying the genetic changes in skin tissue linked to a life-threatening melanoma through SNP genotyping, Ex- pression microarrays, RNA interference etc. In the spectrum of disease, identi- fication and characterization of melanoma proteins is also very important task. In the present study, effort has been made to identify the melanoma protein through Support Vector Machine. A positive dataset has been prepared through databases and literature whereas negative dataset consist of core metabolic pro- teins. Total 420 compositional properties of amino acid dipeptide and multiplet frequencies have been used to develop SVM model classifier. Average perfor- mance of models varies from 0.65-0.80 Mathew's correlation coefficient values and 91.56% accuracy has been achieved through random data set.		Babita Rathore;Sandeep Kumar Kushwaha;Madhvi Shakya	2010		10.1007/978-3-642-15766-0_97	spectrum;support vector machine;amino acid;computer science;bioinformatics;rna interference	ML	9.523438479988592	-57.19340317109421	158579
b077b4a97ee634378c9faeec3d3c8247c85c58cc	a self-directed method for cell-type identification and separation of gene expression microarrays	myocardium;animals;brain;heart;liver;rats;monocytes;databases genetic;gene expression;cluster analysis;algorithms;prostate gland;humans;computational biology;b cells;gene expression profiling;oligonucleotide array sequence analysis;organ specificity;prostate cancer;microarrays	Gene expression analysis is generally performed on heterogeneous tissue samples consisting of multiple cell types. Current methods developed to separate heterogeneous gene expression rely on prior knowledge of the cell-type composition and/or signatures--these are not available in most public datasets. We present a novel method to identify the cell-type composition, signatures and proportions per sample without need for a-priori information. The method was successfully tested on controlled and semi-controlled datasets and performed as accurately as current methods that do require additional information. As such, this method enables the analysis of cell-type specific gene expression using existing large pools of publically available microarray datasets.	dna microarray;electronic signature;gene expression profiling;gene expression programming;genetic heterogeneity;semiconductor industry;type signature;cell type	Neta S. Zuckerman;Yair Noam;Andrea J. Goldsmith;Peter P. Lee	2013		10.1371/journal.pcbi.1003189	biology;molecular biology;gene expression;dna microarray;bioinformatics;gene expression profiling;cluster analysis;genetics;heart	Comp.	6.522959263653406	-54.50354387104766	158763
18a612297f81a6d454fedfcbb37c3de6ddb04545	genotype correlation analysis reveals pathway-based functional disequilibrium and potential epistasis in the human interactome		Epistasis is thought to be a pervasive part of complex phenotypes due to the dynamics and complexity of biological systems, and a further understanding of epistasis in the context of biological pathways may provide insight into the etiology of complex disease. In this study, we use genotype data from the International HapMap Project to characterize the functional dependencies between alleles in the human interactome as defined by KEGG pathways. We performed chi-square tests to identify non-independence between functionally-related SNP pairs within parental Caucasian and Yoruba samples. We further refine this list by testing for skewed transmission of pseudo-haplotypes to offspring using a haplotype-based TDT test. From these analyses, we identify pathways enriched for functional disequilibrium, and a set of 863 SNP pairs (representing 453 gene pairs) showing consistent non-independence and transmission distortion. These results represent gene pairs with strong evidence of epistasis within the context of a biological function.	alleles;biological system;distortion;function (biology);functional dependency;gene regulatory network;haplotypes;human interactome;international hapmap project;kegg;nitroprusside;pervasive informatics;phenotype;pseudo brand of pseudoephedrine;snp annotation;time-domain reflectometry	William S. Bush;Jonathan L. Haines	2014	Applications of Evolutionary Computation : 17th European Conference, EvoApplications 2014, Granada, Spain, April 23-25, 2014 : revised selected papers. EvoApplications (Conference)	10.1007/978-3-662-45523-4_72	bioinformatics;genetics	Comp.	4.143640725620767	-57.162901182365005	158866
87ef9905ce81444d62106d7be32650b1d146d46c	detecting overlapping protein complexes in weighted protein-protein interaction networks using pseudo-clique extension based on fuzzy relation	human ppi network overlapping protein complexes detection weighted protein protein interaction networks pseudo clique extension fuzzy relation cellular functional organization gene expression profile;proteins transforms clustering algorithms symmetric matrices gene expression prediction algorithms;proteins fuzzy set theory	Detecting overlapping protein complexes in protein-protein interaction (PPI) networks can provide insight into cellular functional organization and thus elucidate underlying cellular mechanisms. Recently, various algorithms for protein complex detection have been developed for PPI networks. However, the majority of algorithms primarily depend on network topological features and/or gene expression profile, failing to consider the inherent biological meanings between protein pairs. In this paper, we propose a method of pseudo-clique extension based on fuzzy relation (PCE-FR) that detects protein complexes from PPI networks weighted with the biological significance hidden in protein pairs. The proposed algorithm operates in three stages: it first forms the non-overlapping protein sub-structure based on fuzzy relation and then expands each sub-structure by adding neighbor proteins to maximize the cohesive score. Finally, highly overlapped candidate protein complexes are merged to form the final protein complex set. We apply PCE-FR to two yeast PPI networks and a human PPI network and validate our results by using CYC2008 and CHPC2012, respectively. Experimental results show that our method outperforms classical algorithms such as CFinder, ClusterONE, CMC, RRW, HC-PIN and ProRank+, and that it achieves ideal overall performance in terms of Precision, Accuracy, and Separation.	algorithm;centrality;computer-mediated communication;failure;gene co-expression network;gene expression profiling;greedy algorithm;iteration;pixel density;seeds (cellular automaton);sensor	Buwen Cao;Jiawei Luo;Cheng Liang;Shulin Wang	2016	2016 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2016.7727340	combinatorics;bioinformatics;machine learning;mathematics	Comp.	4.777819819129451	-55.55939248877985	159878
fc1dab65989b02e250951d59f56fd04577b26f39	expatgen: generating dynamic expression patterns for the systematic evaluation of analytical methods	expression pattern;analytical method	MOTIVATION Experimental gene expression data sets, such as those generated by microarray or gene chip experiments, typically have significant noise and complicated interconnectivities that make understanding even simple regulatory patterns difficult. Given these complications, characterizing the effectiveness of different analysis techniques to uncover network groups and structures remains a challenge. Generating simulated expression patterns with known biological features of expression complexity, diversity and interconnectivities provides a more controlled means of investigating the appropriateness of different analysis methods. A simulation-based approach can systematically evaluate different gene expression analysis techniques and provide a basis for improved methods in dynamic metabolic network reconstruction.   RESULTS We have developed an on-line simulator, called eXPatGen, to generate dynamic gene expression patterns typical of microarray experiments. eXPatGen provides a quantitative network structure to represent key biological features, including the induction, repression, and cascade regulation of messenger RNA (mRNA). The simulation is modular such that the expression model can be replaced with other representations, depending on the level of biological detail required by the user. Two example gene networks, of 25 and 100 genes respectively, were simulated. Two standard analysis techniques, clustering and PCA analysis, were performed on the resulting expression patterns in order to demonstrate how the simulator might be used to evaluate different analysis methods and provide experimental guidance for biological studies of gene expression.   AVAILABILITY http://www.che.udel.edu/eXPatGen/	approximation algorithm;behavior;cascade device component;cluster analysis;computer cluster;dna microarray;delaware language;electronic circuit simulation;experiment;fluorescent dyes;gene co-expression network;gene expression programming;gene regulatory network;interaction;mathematical induction;metrorrhagia;norm (social);online and offline;organism;principal component analysis;principal component analysis;rna;rna, messenger;repression, psychology;research support as topic;sample variance;sampling (signal processing);sampling - surgical action;spatial variability;format;statistical cluster	Dennis J. Michaud;Adam G. Marsh;Prasad S. Dhurjati	2003	Bioinformatics	10.1093/bioinformatics/btg132	biology;computer science;bioinformatics;machine learning;data mining	Comp.	6.090010621786515	-58.60959074249309	159988
618530dad37123b7581495b15b9dcadb2a82222d	eresponsenet: a package prioritizing candidate disease genes through cellular pathways	human disease;cn supplementary information;associated variant;bioinformatics online;prioritizing candidate disease gene;available approach;eresponsenet package;cellular pathway;disease-associated genetic variation;common genetic variant	MOTIVATION Although genome-wide association studies (GWAS) have found many common genetic variants associated with human diseases, it remains a challenge to elucidate the functional links between associated variants and complex traits.   RESULTS We developed a package called eResponseNet by implementing and extending the existing ResponseNet algorithm for prioritizing candidate disease genes through cellular pathways. Using type II diabetes (T2D) as a study case, we demonstrate that eResponseNet outperforms currently available approaches in prioritizing candidate disease genes. More importantly, the package is instrumental in revealing cellular pathways underlying disease-associated genetic variations.   AVAILABILITY The eResponseNet package is freely downloadable at http://hanlab.genetics.ac.cn/eResponseNet.   CONTACT jdhan@picb.ac.cn   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;diabetes mellitus, non-insulin-dependent;eaf2 gene;genome-wide association study;hereditary diseases;algorithm	Jialiang Huang;Yi Liu;Wei Zhang;Hong Yu;Jing-Dong Jackie Han	2011	Bioinformatics	10.1093/bioinformatics/btr380	biology;bioinformatics;data mining	Comp.	3.82622832796487	-56.48274973071821	161024
5cda0e663c249cd45499a92c4aea960ecc053036	gwasinlps: non-local prior based iterative snp selection tool for genome-wide association studies		Motivation Multiple marker analysis of the genome-wide association study (GWAS) data has gained ample attention in recent years. However, because of the ultra high-dimensionality of GWAS data, such analysis is challenging. Frequently used penalized regression methods often lead to large number of false positives, whereas Bayesian methods are computationally very expensive. Motivated to ameliorate these issues simultaneously, we consider the novel approach of using nonlocal priors in an iterative variable selection framework.   Results We develop a variable selection method, named, iterative nonlocal prior based selection for GWAS, or GWASinlps, that combines, in an iterative variable selection framework, the computational efficiency of the screen-and-select approach based on some association learning and the parsimonious uncertainty quantification provided by the use of nonlocal priors. The hallmark of our method is the introduction of 'structured screen-and-select' strategy, that considers hierarchical screening, which is not only based on response-predictor associations, but also based on response-response associations, and concatenates variable selection within that hierarchy. Extensive simulation studies with SNPs having realistic linkage disequilibrium structures demonstrate the advantages of our computationally efficient method compared to several frequentist and Bayesian variable selection methods, in terms of true positive rate, false discovery rate, mean squared error, and effect size estimation error. Further, we provide empirical power analysis useful for study design. Finally, a real GWAS data application was considered with human height as phenotype.   Availability and implementation An R-package for implementing the GWASinlps method is available at https://cran.r-project.org/web/packages/GWASinlps/index.html.   Supplementary information Supplementary data are available at Bioinformatics online.		Nilotpal Sanyal;M. Lo;Karolina Kauppi;Srdjan Djurovic;Ole A. Andreassen;Valen E. Johnson;C Chen	2018	Bioinformatics	10.1093/bioinformatics/bty472	snp;bioinformatics;computer science;genome-wide association study	Comp.	3.7688340505546076	-52.63091811335809	161643
3f280a396547552ed01f23ec482b559b20c343d9	detecting purely epistatic multi-locus interactions by an omnibus permutation test on ensembles of two-locus analyses	autosomal recessive;epistasis genetic;complex disease;genotype;case control study;genome wide association study;computational biology bioinformatics;type 2 diabetes mellitus;large scale;multifactor dimensionality reduction;genetic predisposition to disease;transcription factor;case control studies;algorithms;feature selection;humans;genetic epidemiology;interaction model;parkinson disease;combinatorial libraries;false positive;computational biology;glycogen synthase;computer appl in life sciences;polymorphism single nucleotide;candidate gene;single nucleotide polymorphism;microarrays;bioinformatics;permutation test	Purely epistatic multi-locus interactions cannot generally be detected via single-locus analysis in case-control studies of complex diseases. Recently, many two-locus and multi-locus analysis techniques have been shown to be promising for the epistasis detection. However, exhaustive multi-locus analysis requires prohibitively large computational efforts when problems involve large-scale or genome-wide data. Furthermore, there is no explicit proof that a combination of multiple two-locus analyses can lead to the correct identification of multi-locus interactions. The proposed 2LOmb algorithm performs an omnibus permutation test on ensembles of two-locus analyses. The algorithm consists of four main steps: two-locus analysis, a permutation test, global p-value determination and a progressive search for the best ensemble. 2LOmb is benchmarked against an exhaustive two-locus analysis technique, a set association approach, a correlation-based feature selection (CFS) technique and a tuned ReliefF (TuRF) technique. The simulation results indicate that 2LOmb produces a low false-positive error. Moreover, 2LOmb has the best performance in terms of an ability to identify all causative single nucleotide polymorphisms (SNPs) and a low number of output SNPs in purely epistatic two-, three- and four-locus interaction problems. The interaction models constructed from the 2LOmb outputs via a multifactor dimensionality reduction (MDR) method are also included for the confirmation of epistasis detection. 2LOmb is subsequently applied to a type 2 diabetes mellitus (T2D) data set, which is obtained as a part of the UK genome-wide genetic epidemiology study by the Wellcome Trust Case Control Consortium (WTCCC). After primarily screening for SNPs that locate within or near 372 candidate genes and exhibit no marginal single-locus effects, the T2D data set is reduced to 7,065 SNPs from 370 genes. The 2LOmb search in the reduced T2D data reveals that four intronic SNPs in PGM1 (phosphoglucomutase 1), two intronic SNPs in LMX1A (LIM homeobox transcription factor 1, alpha), two intronic SNPs in PARK2 (Parkinson disease (autosomal recessive, juvenile) 2, parkin) and three intronic SNPs in GYS2 (glycogen synthase 2 (liver)) are associated with the disease. The 2LOmb result suggests that there is no interaction between each pair of the identified genes that can be described by purely epistatic two-locus interaction models. Moreover, there are no interactions between these four genes that can be described by purely epistatic multi-locus interaction models with marginal two-locus effects. The findings provide an alternative explanation for the aetiology of T2D in a UK population. An omnibus permutation test on ensembles of two-locus analyses can detect purely epistatic multi-locus interactions with marginal two-locus effects. The study also reveals that SNPs from large-scale or genome-wide case-control data which are discarded after single-locus analysis detects no association can still be useful for genetic epidemiology studies.	autosomal recessive inheritance;candidate disease gene;chronic fatigue syndrome;climate forecast system;consortium;diabetes mellitus;diabetes mellitus, non-insulin-dependent;feature selection;genetic epidemiology;genetic polymorphism;glycogen (starch) synthase;hnf1a gene;hereditary diseases;interaction;introns;locus;marginal model;memory data register;multifactor dimensionality reduction;nsa product types;nucleotides;numerous;p-value;park2 gene;parkinson disease 2, autosomal recessive juvenile;pgm1 gene;phosphoglucomutase;resampling (statistics);sensor;simulation;single nucleotide polymorphism;single-chain antibodies;transcription factor;transcription (software);tuned amplifier;algorithm;confirmation - responselevel	Waranyu Wongseree;Anunchai Assawamakin;Theera Piroonratana;Saravudh Sinsomros;Chanin Limwongse;Nachol Chaiyaratana	2009	BMC Bioinformatics	10.1186/1471-2105-10-294	biology;case-control study;genetic epidemiology;biotechnology;bioinformatics;feature selection;genetics	Comp.	6.159364606548697	-53.87784246268593	162002
09f332878d1e58e0d7ae40e1a3592860542a7bf2	mixture models reveal multiple positional bias types in rna-seq data and lead to accurate transcript concentration estimates	statistical data;statistical models;complementary dna;rna sequencing;probability distribution;rna hybridization;quality control;microarrays	"""Accuracy of transcript quantification with RNA-Seq is negatively affected by positional fragment bias. This article introduces Mix2 (rd. """"mixquare""""), a transcript quantification method which uses a mixture of probability distributions to model and thereby neutralize the effects of positional fragment bias. The parameters of Mix2 are trained by Expectation Maximization resulting in simultaneous transcript abundance and bias estimates. We compare Mix2 to Cufflinks, RSEM, eXpress and PennSeq; state-of-the-art quantification methods implementing some form of bias correction. On four synthetic biases we show that the accuracy of Mix2 overall exceeds the accuracy of the other methods and that its bias estimates converge to the correct solution. We further evaluate Mix2 on real RNA-Seq data from the Microarray and Sequencing Quality Control (MAQC, SEQC) Consortia. On MAQC data, Mix2 achieves improved correlation to qPCR measurements with a relative increase in R2 between 4% and 50%. Mix2 also yields repeatable concentration estimates across technical replicates with a relative increase in R2 between 8% and 47% and reduced standard deviation across the full concentration range. We further observe more accurate detection of differential expression with a relative increase in true positives between 74% and 378% for 5% false positives. In addition, Mix2 reveals 5 dominant biases in MAQC data deviating from the common assumption of a uniform fragment distribution. On SEQC data, Mix2 yields higher consistency between measured and predicted concentration ratios. A relative error of 20% or less is obtained for 51% of transcripts by Mix2, 40% of transcripts by Cufflinks and RSEM and 30% by eXpress. Titration order consistency is correct for 47% of transcripts for Mix2, 41% for Cufflinks and RSEM and 34% for eXpress. We, further, observe improved repeatability across laboratory sites with a relative increase in R2 between 8% and 44% and reduced standard deviation."""	approximation error;biopolymer sequencing;chamaecyparis lawsoniana;converge;dhrystone;estimated;expectation–maximization algorithm;microarray;mixture model;quantitation;rna;repeatability;sequence number;standard deviation;titration method;transcript	Andreas Tuerk;Gregor Wiktorin;Serhat Güler	2017		10.1371/journal.pcbi.1005515	probability distribution;statistical model;biology;quality control;dna microarray;rna-seq;bioinformatics;complementary dna;statistics	ML	4.091465720588599	-53.53175426776174	162155
2295d83c0252d279ad7dfeefb1bc1dd940baa3bb	prognostic transcriptional association networks: a new supervised approach based on regression trees	regression tree;gene regulatory networks;myocardial infarction;gene expression;algorithms;humans;linear models;prognosis	MOTIVATION The application of information encoded in molecular networks for prognostic purposes is a crucial objective of systems biomedicine. This approach has not been widely investigated in the cardiovascular research area. Within this area, the prediction of clinical outcomes after suffering a heart attack would represent a significant step forward. We developed a new quantitative prediction-based method for this prognostic problem based on the discovery of clinically relevant transcriptional association networks. This method integrates regression trees and clinical class-specific networks, and can be applied to other clinical domains.   RESULTS Before analyzing our cardiovascular disease dataset, we tested the usefulness of our approach on a benchmark dataset with control and disease patients. We also compared it to several algorithms to infer transcriptional association networks and classification models. Comparative results provided evidence of the prediction power of our approach. Next, we discovered new models for predicting good and bad outcomes after myocardial infarction. Using blood-derived gene expression data, our models reported areas under the receiver operating characteristic curve above 0.70. Our model could also outperform different techniques based on co-expressed gene modules. We also predicted processes that may represent novel therapeutic targets for heart disease, such as the synthesis of leucine and isoleucine.   AVAILABILITY The SATuRNo software is freely available at http://www.lsi.us.es/isanepo/toolsSaturno/.	benchmark (computing);bioinformatics;cardiovascular diseases;categories;decision tree;distributed computing;expert system;gene expression;heart diseases;inference;interaction;isoleucine;large;leucine;linear algebra;microarray;myocardial infarction;patients;proteomics;receiver operating characteristic;scientific publication;silo (dataset);systems biomedicine;technical support;transcription, genetic;trees (plant);ventricular dysfunction;version;algorithm	Isabel A. Nepomuceno-Chamorro;Francisco Azuaje;Yvan Devaux;Petr V. Nazarov;Arnaud Muller;Jesús S. Aguilar-Ruiz;Daniel R. Wagner	2011		10.1093/bioinformatics/btq645	myocardial infarction;biology;gene regulatory network;gene expression;bioinformatics;data science;decision tree;linear model;data mining;genetics	Comp.	7.1547393204625385	-53.807269524147436	162250
addc892571ef40e0a25d47bfc9c0c1187bbc2df0	noxclass: prediction of protein-protein interaction types	software;structural model;x ray crystallography;binding sites;models chemical;protein structure quaternary;computational biology bioinformatics;protein structure;models molecular;proteins;protein conformation;online systems;protein protein interaction;protein binding;artificial intelligence;algorithms;pattern recognition automated;support vector machine;combinatorial libraries;protein interaction;protein interaction mapping;automatic classification;crystallography;computer appl in life sciences;computer simulation;leave one out cross validation;sequence analysis protein;microarrays;bioinformatics	Structural models determined by X-ray crystallography play a central role in understanding protein-protein interactions at the molecular level. Interpretation of these models requires the distinction between non-specific crystal packing contacts and biologically relevant interactions. This has been investigated previously and classification approaches have been proposed. However, less attention has been devoted to distinguishing different types of biological interactions. These interactions are classified as obligate and non-obligate according to the effect of the complex formation on the stability of the protomers. So far no automatic classification methods for distinguishing obligate, non-obligate and crystal packing interactions have been made available. Six interface properties have been investigated on a dataset of 243 protein interactions. The six properties have been combined using a support vector machine algorithm, resulting in NOXclass, a classifier for distinguishing obligate, non-obligate and crystal packing interactions. We achieve an accuracy of 91.8% for the classification of these three types of interactions using a leave-one-out cross-validation procedure. NOXclass allows the interpretation and analysis of protein quaternary structures. In particular, it generates testable hypotheses regarding the nature of protein-protein interactions, when experimental results are not available. We expect this server will benefit the users of protein structural models, as well as protein crystallographers and NMR spectroscopists. A web server based on the method and the datasets used in this study are available at http://noxclass.bioinf.mpi-inf.mpg.de/ .	algorithm;classification;cross reactions;cross-validation (statistics);crystal oscillator;crystal structure;crystallography;slpi protein, human;server (computer);server (computing);set packing;support vector machine;web server;protein protein interaction	Hongbo Zhu;Francisco S. Domingues;Ingolf Sommer;Thomas Lengauer	2005	BMC Bioinformatics	10.1186/1471-2105-7-27	computer simulation;biology;protein structure;computer science;bioinformatics;machine learning	Comp.	9.639275236654452	-57.66376460681023	162585
7670eb98e6f8844aa01e03bd82811bba67298928	a monte carlo approach to measure the robustness of boolean networks	network robustness;boolean network	Emergence of robustness in biological networks is a paramount feature of evolving organisms, but a study of this property in vivo, for any level of representation such as Genetic, Metabolic, or Neuronal Networks, is a very hard challenge. In the case of Genetic Networks, mathematical models have been used in this context to provide insights on their robustness, but even in relatively simple formulations, such as Boolean Networks (BN), it might not be feasible to compute some measures for large system sizes. We describe in this work a Monte Carlo approach to calculate the size of the largest basin of attraction of a BN, which is intrinsically associated with its robustness, that can be used regardless the network size. We show the stability of our method through finite-size analysis and validate it with a full search on small networks.	biological network;boolean network;emergence;mathematical model;mental representation;monte carlo method;video-in video-out	Vitor H. P. Louzada;Fabrício Martins Lopes;Ronaldo Fumio Hashimoto	2012		10.1145/2382936.2383062	theoretical computer science;machine learning;mathematics;statistics;robustness	ML	6.917340703088647	-58.609901769741825	162654
14446392a9ab64fdd293730317608f95aa0a060d	mixture-model based estimation of gene expression variance from public database improves identification of differentially expressed genes in small sized microarray data	bayesian framework;microarray data;estimacion;pulga de dna;dato;small sample size;puce a dna;large dataset;data;database;bayes theorem;gen;base dato;databases genetic;gold standard;microreseau;gene expression;expression genique;modelo;microarray data analysis;gaussian mixture model;estimation;mixture model;donnee;identification;microarreglo;snu;base de donnees;dna chip;gene;identificacion;pattern recognition automated;teoria mezcla;modele;microarray;differentially expressed gene;mixture theory;theorie melange;models;expresion genetica;gene expression profiling;oligonucleotide array sequence analysis;variance;variancia	MOTIVATION The small number of samples in many microarray experiments is a challenge for the correct identification of differentially expressed gens (DEGs) by conventional statistical means. Information from public microarray databases can help more efficient identification of DEGs. To model various experimental conditions of a public microarray database, we applied Gaussian mixture model and extracted bi- or tri-modal distributions of gene expression. Prior variance of Baldi's Bayesian framework was estimate for the analysis of the small sample-sized datasets.   RESULTS First, we estimated the prior variance of a gene expression by pooling variances obtained from mixture modeling of large samples in the public microarray database. Then, using the prior variance, we identified DEGs in small sample-sized test datasets using the Baldi's framework. For benchmark study, we generated test datasets having several samples from relatively large datasets. Our proposed method outperformed other benchmark methods in terms of detecting gold-standard DEGs from the test datasets. The results may be a challenging evidence for usage of public microarray databases in microarray data analysis.	benchmark (computing);experiment;extraction;gene expression;microarray databases;mixture model;modal logic;normal statistical distribution;published database;sample variance;sensor;triangular function;trimipramine	Mingoo Kim;Sung-Bum Cho;Ju Han Kim	2010		10.1093/bioinformatics/btp685	biology;microarray analysis techniques;gene chip analysis;computer science;bioinformatics;mixture model;data mining;microarray databases;statistics	ML	4.800961208458786	-52.111379187458475	163030
bf1cec1eb82e54ca5387527bcd3487d170e4022b	feature selection with interactions in logistic regression models using multivariate synergies for a gwas application	genotype-phenotype association;feature selection;genome-wide association study;synergistic interaction;mutual information	"""Identifying """"synergistic"""" interactions with respect to the outcome of interest can help accurate phenotypic prediction and understand the underlying mechanism of system behavior. Many statistical measures for estimating synergistic interactions have been proposed in the literature for such a purpose. However, except for empirical performances, there is still no theoretical analysis on the power and limitation of these synergistic interaction measures. In this paper, we provide a rigorous theoretical analysis on how the information-theoretic multivariate synergy helps with identifying genetic risk factors via synergistic interactions. When genotype-phenotype relationships can be modeled with logistic regression, it is shown that the multivariate synergy depends on a small subset of the interaction parameters in the model, sometimes on only one interaction parameter. We further conduct the experiments over both a simulated data set and a real-world Genome-Wide Association Study (GWAS) data set to show the effectiveness."""	experiment;feature selection;information theory;interaction;logistic regression;performance;synergy	Easton Li Xu;Xiaoning Qian;Qilian Yu;Han Zhang;Shuguang Cui	2017		10.1145/3107411.3110406	machine learning;data mining;mutual information;feature selection;genome-wide association study;bioinformatics;genotype-phenotype association;logistic regression;artificial intelligence;multivariate statistics;computer science	AI	6.958021862871266	-53.18396600716344	163049
9f66ebf7db1b1a51f90530055b8138f7496a9e4d	the role of endogenous and exogenous mechanisms in the formation of r&d networks	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	We develop an agent-based model of strategic link formation in Research and Development (R&D) networks. Empirical evidence has shown that the growth of these networks is driven by mechanisms which are both endogenous to the system (that is, depending on existing alliances patterns) and exogenous (that is, driven by an exploratory search for newcomer firms). Extant research to date has not investigated both mechanisms simultaneously in a comparative manner. To overcome this limitation, we develop a general modeling framework to shed light on the relative importance of these two mechanisms. We test our model against a comprehensive dataset, listing cross-country and cross-sectoral R&D alliances from 1984 to 2009. Our results show that by fitting only three macroscopic properties of the network topology, this framework is able to reproduce a number of micro-level measures, including the distributions of degree, local clustering, path length and component size, and the emergence of network clusters. Furthermore, by estimating the link probabilities towards newcomers and established firms from the data, we find that endogenous mechanisms are predominant over the exogenous ones in the network formation, thus quantifying the importance of existing structures in selecting partner firms.	agent-based model;anatomy, regional;cluster analysis;clustering coefficient;emergence;estimated;exploratory search;network formation;network topology;probability;research and development;silo (dataset);statistical cluster	Mario Vincenzo Tomasello;Nicola Perra;Claudio J. Tessone;Márton Karsai;Frank Schweitzer	2014		10.1038/srep05679	text mining;medical research;medicine;computer science;bioinformatics;data science;data mining	AI	5.139931722625069	-57.15382606277666	163447
6eeca2ac051694437f146fa700bd41a970496aa7	combining multidimensional genomic measurements for predicting cancer prognosis: observations from tcga	cancer prognosis;multidimensional genomic study;prediction;the cancer genome atlas tcga	With accumulating research on the interconnections among different types of genomic regulations, researchers have found that multidimensional genomic studies outperform one-dimensional studies in multiple aspects. Among many sources of multidimensional genomic data, The Cancer Genome Atlas (TCGA) provides the public with comprehensive profiling data on >30 cancer types, making it an ideal test bed for conducting and comparing different analyses. In this article, the analysis goal is to apply several existing methods and associate multidimensional genomic measurements with cancer outcomes in particular prognosis, with special focus on the predictive power of genomic signatures. We exploit clinical data and four types of genomic measurement including mRNA gene expression, DNA methylation, microRNA and copy number alterations for breast invasive carcinoma, glioblastoma multiforme, acute myeloid leukemia and lung squamous cell carcinoma collected by TCGA. To accommodate the high dimensionality, we extract important features using Principal Component Analysis, Partial Least Squares and Least Absolute Shrinkage and Selection Operator (Lasso), which are representative of dimension reduction and variable selection techniques and have been extensively adopted, and fit Cox survival models with combined important features. We calibrate the predictive power of each type of genomic measurement for the prognosis of four cancer types and find that the results vary across cancers. Our analysis also suggests that for most of the cancers in our study and the adopted methods, there is no substantial improvement in prediction when adding other genomic measurement after gene expression and clinical covariates have been included in the model. This is consistent with the findings that molecular features measured at the transcription level affect clinical outcomes more directly than those measured at the DNA/epigenetic level.	antivirus software;behavior;cancer prognosis;clinical decision support system;copy number;dimensionality reduction;entity name part qualifier - adopted;feature selection;forecast of outcome;gene expression;genetic selection;glioblastoma multiforme;invasive carcinoma;lasso;leukemia, myelocytic, acute;myeloid leukemia;neoplasms;partial least squares regression;principal component analysis;regulation;squamous epithelial cells;squamous cell carcinoma;squamous cell lung carcinoma;testbed;the cancer genome atlas;transcription (software);study of epigenetics	Qing Zhao;Xingjie Shi;Yang Xie;Jian Huang;Ben-Chang Shia;Shuangge Ma	2015	Briefings in bioinformatics	10.1093/bib/bbu003	biology;prediction;bioinformatics;genetics	Comp.	6.977602407386267	-53.15334723083277	163603
a36b3913de449a350d4c928c28f15a1b65c40c77	the microarray quality control (maqc) project and cross-platform analysis of microarray data		As a powerful tool for genome-wide gene expression analysis, DNA microarray technology is widely used in biomedical research. One important application of microarrays is to identify differentially expressed genes (DEGs) between two distinct biological conditions, e.g. disease versus normal or treatment versus control, so that the underlying molecular mechanism differentiating the two conditions maybe revealed. Mechanistic interpretation of microarray results requires the identification of reproducible and reliable lists of DEGs, because irreproducible lists of DEGs may lead to different biological conclusions. Many vendors are providing microarray platforms of different characteristics for gene expression analysis, and the widely publicized apparent lack of intraand cross-platform concordance in DEGs from microarray analysis of the same sets of study samples has been of great concerns to the scientific community and regulatory agencies like the US Food and Drug Administration (FDA). In this chapter, we describe the study design of and the main findings from the FDA-led MicroArray Quality Control (MAQC) project that aims to objectively assess the performance of different microarray platforms and the advantages and limitations of various competing statistical methods in identifying DEGs from microarray data. Using large data sets generated on two human reference RNA samples established by the MAQC project, we show that the levels of concordance in inter-laboratory and cross-platform comparisons are generally high. Furthermore, the levels of concordance largely depend on the statistical criteria used for ranking and selecting DEGs, irrespective of the chosen platforms or test sites. Importantly, a straightforward method combining fold-change ranking with a nonstringent P-value cutoff produces more reproducible lists of DEGs than those by t-test P-value ranking. Similar conclusions are reached when microarray data sets The views presented in this article do not necessarily reflect those of the US Food and Drug Administration. L. Shi (B) National Center for Toxicological Research, US Food and Drug Administration, 3900 NCTR Road, Jefferson, AR 72079, USA e-mail: leming.shi@fda.hhs.gov H. Horng-Shing Lu et al. (eds.), Handbook of Statistical Bioinformatics, Springer Handbooks of Computational Statistics, DOI 10.1007/978-3-642-16345-6 9, c Springer-Verlag Berlin Heidelberg 2011 171	bioinformatics;computation;computational statistics;concordance (publishing);dna microarray;email;lu decomposition;springer (tank)	Zhining Wen;Zhenqiang Su;Jie Liu;Baitang Ning;Lei Guo;Weida Tong;Leming Shi	2011		10.1007/978-3-642-16345-6_9	dna microarray;toxicogenomics;computational biology;concordance;microarray analysis techniques;personalized medicine;drug development;microarray;ranking;computer science	Comp.	4.804331362903531	-52.6895062059776	163987
136b469ca619bf17758724dd9b7af8b9f876243e	sampling designs via a multivariate hypergeometric-dirichlet process model for a multi-species assemblage with unknown heterogeneity	multinomial distribution;dirichlet process prior;sample size;dirichlet process;sample design;multivariate hypergeometric distribution;cluster analysis;clustering method;sequence tags;sampling methods;monte carlo simulation;species abundance	In a sample of mRNA species counts, sequences without duplicates or with small numbers of copies are likely to carry information related tomutations or diseases and can be of great interest. However, in some situations, sequence abundance is unknown and sequencing the whole sample to find the rare sequences is not practically possible. To collect mRNA sequences of interest, or more generally, species of interest, we propose a two-phase Bayesian sampling method that addresses these concerns. The first phase of the design is used to infer sequence (species) abundance levels through a cluster analysis applied to a pilot data set. The clustering method is built upon a multivariate hypergeometric model with a Dirichlet process prior for species relative frequencies. The second phase, through Monte Carlo simulations, infers the sample size necessary to collect a certain number of species of particular interest. Efficient posterior computing schemes are proposed. The developed approach is demonstrated and evaluated via simulations. An mRNA segment data set is used to illustrate and motivate the proposed sampling method. © 2012 Elsevier B.V. All rights reserved.	cluster analysis;monte carlo method;process modeling;sampling (signal processing);simulation;two-phase locking	Hongmei Zhang;Kaushik Ghosh;Pulak Ghosh	2012	Computational Statistics & Data Analysis	10.1016/j.csda.2012.02.013	sample size determination;sampling;econometrics;relative species abundance;sampling design;bioinformatics;mathematics;cluster analysis;multinomial distribution;statistics;monte carlo method	Comp.	4.252654697316304	-52.4166930506043	163992
dd83daca944392cd581d2aad96d3795040801543	global sequence properties for superfamily prediction: a machine learning approach	functional annotation;protein sequence;profiles methods;machine learning	Functional annotation of a protein sequence in the absence of experimental data or clear similarity to a sequence of known function is difficult. In this study, a simple set of sequence attributes based on physicochemical and predicted structural characteristics were used as input to machine learning methods. In order to improve performance through increasing the data available for training, a technique of sequence enrichment was explored. These methods were used to predict membership to 24 and 49 large and diverse protein superfamiles from the SCOP database. We found the best performance was obtained using an enriched training dataset. Accuracies of 66.3% and 55.6% were achieved on datasets comprising 24 and 49 superfamilies with LibSVM and AdaBoostM1 respectively. The methods used here confirm that domains within superfamilies share global sequence properties. We show machine learning models used to predict categories within the SCOP database can be significantly improved via a simple sequence enrichment step. These approaches can be used to complement profile methods for detecting distant relationships where function is difficult to infer.	a library for support vector machines;amino acid sequence;annotation;categories;class;complement system proteins;database;forty nine;gene ontology term enrichment;inference;machine learning;superfamily;scop;sensor;silo (dataset);simple set;staphylococcal protein a;while	Richard J. B. Dobson;Patricia B. Munroe;Mark J. Caulfield;Mansoor A. S. Saqi	2009	Journal of integrative bioinformatics	10.2390/biecoll-jib-2009-109	biology;computer science;bioinformatics;machine learning;protein sequencing;data mining;alignment-free sequence analysis	Comp.	9.847481503244419	-55.761574379601164	164010
104a34edc3c5b1cf51144ba317f8b38a999f0948	fuzzy clustering of cpp family in plants with evolution and interaction analyses	cysteine;phylogeny;transcription factors;computational biology bioinformatics;fuzzy logic;cluster analysis;algorithms;arabidopsis proteins;molecular sequence data;combinatorial libraries;protein interaction mapping;computer appl in life sciences;gene expression profiling;plant proteins;microarrays;bioinformatics	Transcription factors have been studied intensively because they play an important role in gene expression regulation. However, the transcription factors in the CPP family (cystein-rich polycomb-like protein), compared with other transcription factor families, have not received sufficient attention, despite their wide prevalence in a broad spectrum of species, from plants to animals. The total number of known CPP transcription factors in plants is 111 from 16 plants, but only 2 of them have been studied so far, namely TSO1 and CPP1 in Arabidopsis thaliana and soybean, respectively. In this work, to study their functions, we applied the fuzzy clustering method to all plant CPP transcription factors. The feature vector of each protein sequence for the fuzzy clustering method is encoded by the short length peptides and the combination of functional domain models. With the fuzzy clustering method, all plant CPP transcription factors are grouped into two subfamilies. A systems approach, including Expressed Sequence Tag analysis, evolutionary analysis, protein-protein interaction network analysis and co-expression analysis, is employed to validate the clustering results, the results of which also indicates that the transcription factors from different subfamilies show uncorrelated responses.	amino acid sequence;cluster analysis;feature vector;fuzzy clustering;gene expression regulation;gene expression profiling;interaction network;medical transcription;pathway analysis;pierre robin syndrome;route inspection problem;transcription factor;transcription (software);protein protein interaction;statistical cluster	Tao Lu;Yongchao Dou;Chi Zhang	2013		10.1186/1471-2105-14-S13-S10	fuzzy logic;biology;molecular biology;dna microarray;computer science;bioinformatics;gene expression profiling;cluster analysis;genetics;phylogenetics;transcription factor	Comp.	4.381056074223309	-58.54575263696109	164030
dab95ac00a411519efcf27d7ffc972d97def8f5b	a methodology for the analysis of differential coexpression across the human lifespan	semantic similarity;computers;ordered group;databases genetic;investigative techniques and equipment;genomics and proteomics;computational biology bioinformatics;statistical properties;ubc;genome human;multiple time scale;differential expression;human;test methods;algorithms;humans;computer software;combinatorial libraries;computational biology;computer appl in life sciences;gene expression profiling;oligonucleotide array sequence analysis;microarrays;bioinformatics;gene ontology	Differential coexpression is a change in coexpression between genes that may reflect 'rewiring' of transcriptional networks. It has previously been hypothesized that such changes might be occurring over time in the lifespan of an organism. While both coexpression and differential expression of genes have been previously studied in life stage change or aging, differential coexpression has not. Generalizing differential coexpression analysis to many time points presents a methodological challenge. Here we introduce a method for analyzing changes in coexpression across multiple ordered groups (e.g., over time) and extensively test its validity and usefulness. Our method is based on the use of the Haar basis set to efficiently represent changes in coexpression at multiple time scales, and thus represents a principled and generalizable extension of the idea of differential coexpression to life stage data. We used published microarray studies categorized by age to test the methodology. We validated the methodology by testing our ability to reconstruct Gene Ontology (GO) categories using our measure of differential coexpression and compared this result to using coexpression alone. Our method allows significant improvement in characterizing these groups of genes. Further, we examine the statistical properties of our measure of differential coexpression and establish that the results are significant both statistically and by an improvement in semantic similarity. In addition, we found that our method finds more significant changes in gene relationships compared to several other methods of expressing temporal relationships between genes, such as coexpression over time. Differential coexpression over age generates significant and biologically relevant information about the genes producing it. Our Haar basis methodology for determining age-related differential coexpression performs better than other tested methods. The Haar basis set also lends itself to ready interpretation in terms of both evolutionary and physiological mechanisms of aging and can be seen as a natural generalization of two-category differential coexpression. Contact: paul@bioinformatics.ubc.ca	basis set (chemistry);categories;categorization;differential signaling;expanded memory;experiment;gene regulatory networks;gene ontology;generalization (psychology);haar wavelet;manuscripts;microarray;pp (complexity);scientific publication;semantic similarity;signal processing;technical support;united states national institutes of health;citation	Jesse A. Gillis;Paul Pavlidis	2009	BMC Bioinformatics	10.1186/1471-2105-10-306	biology;semantic similarity;dna microarray;computer science;bioinformatics;data mining;gene expression profiling;test method;genetics	Comp.	4.272195969928149	-56.89137832893029	164623
c7ca322b37a1961a25a90775a4ea3732d0d14e7c	a neural networks algorithm for inferring drug gene regulatory networks from microarray time-series with missing transcription factors information	drugs;biology computing;neural network application;genetic program;algebraic equations drug gene regulatory networks neural networks algorithm microarray time series missing transcription factors information mathematical modeling ordinary differential equations reverse engineering algorithm feedback linearization genetic programming;neural nets;ordinary differential equation;neural networks algorithm;biological system modeling;differential equation;gene network;time series;genetic programming;data mining;missing transcription factors information;neural networks drugs differential equations genetic programming reverse engineering bioinformatics artificial intelligence mathematical model neurofeedback differential algebraic equations;artificial neural networks;a priori knowledge;ordinary differential equations;algebra;transcription factor;microarray time series;mathematical model;time series data;algebraic equations;feedback linearization;genetic algorithms;differential equations;mathematical modeling;data handling;drug gene regulatory networks;reverse engineering algorithm;time series algebra biology computing data handling differential equations genetic algorithms neural nets reverse engineering;high throughput;gene regulatory network;reverse engineering;data models;neural network	Mathematical modeling gene regulatory networks is important for understanding and controlling them, with various drugs and their dosage regimens. The ordinary differential equations approach is sensible but also very difficult. Our reverse engineering algorithm (RODES), based on neural networks feedback linearization and genetic programming, takes as inputs high-throughput (e.g., microarray) time series data and automatically infer an accurate ordinary differential equations model. The algorithm decouples the systems of differential equations, reducing the problem to that of revere engineering individual algebraic equations, and is able to deal with missing information, reconstructing the temporal series of the transcription factors or drug related compounds which are usually missing in microarray experiments. It is also able to incorporate common a priori knowledge. To our knowledge, this is the first realistic reverse engineering algorithm, based on genetic programming and neural networks, applicable to large gene networks.	algebraic equation;algorithm;artificial neural network;experiment;gene regulatory network;genetic programming;high-throughput computing;linear algebra;microarray;reverse engineering;throughput;time series;transcription (software)	Alexandru G. Floares	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5179081	ordinary differential equation;gene regulatory network;computer science;bioinformatics;theoretical computer science;machine learning;time series;mathematical model;differential equation;artificial neural network	Comp.	4.233050341947122	-57.614982750361044	165047
6844b7000aa1783c673a864cbe29b4e6baf8965c	features-based deisotoping method for tandem mass spectra	health research;dynamic programming;uk clinical guidelines;biological patents;overlapping;europe pubmed central;citation search;deisotoping;tandem mass spectra;features;uk phd theses thesis;life sciences;isotopic cluster graphs;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	For high-resolution tandem mass spectra, the determination of monoisotopic masses of fragment ions plays a key role in the subsequent peptide and protein identification. In this paper, we present a new algorithm for deisotoping the bottom-up spectra. Isotopic-cluster graphs are constructed to describe the relationship between all possible isotopic clusters. Based on the relationship in isotopic-cluster graphs, each possible isotopic cluster is assessed with a score function, which is built by combining nonintensity and intensity features of fragment ions. The non-intensity features are used to prevent fragment ions with low intensity from being removed. Dynamic programming is adopted to find the highest score path with the most reliable isotopic clusters. The experimental results have shown that the average Mascot scores and F-scores of identified peptides from spectra processed by our deisotoping method are greater than those by YADA and MS-Deconv software.	algorithm;assumed;bottom-up parsing;dynamic programming;entity name part qualifier - adopted;graph - visual representation;image resolution;ions;large;ms-dos;mascot scoring engine;rca spectra 70;silo (dataset);stellar classification	Zheng Yuan;Jin-Hong Shi;Wenjun Lin;Bolin Chen;Fang-Xiang Wu	2011		10.1155/2011/210805	computer science;bioinformatics;data science;dynamic programming;data mining	ML	3.410901114682521	-55.11160923412301	165172
d3771d1f5d2374a73aee64245afbf228e2d10430	qpath: a method for querying pathways in a protein-protein interaction network	sequence comparison;protein protein interaction network;homology search;sequence similarity;signal transduction;transcription factors;models biological;protein network;computational biology bioinformatics;gene expression regulation;algorithms;sequence analysis;combinatorial libraries;protein interaction;protein interaction mapping;high throughput;gene function;computer appl in life sciences;computer simulation;information storage and retrieval;microarrays;bioinformatics	Sequence comparison is one of the most prominent tools in biological research, and is instrumental in studying gene function and evolution. The rapid development of high-throughput technologies for measuring protein interactions calls for extending this fundamental operation to the level of pathways in protein networks. We present a comprehensive framework for protein network searches using pathway queries. Given a linear query pathway and a network of interest, our algorithm, QPath, efficiently searches the network for homologous pathways, allowing both insertions and deletions of proteins in the identified pathways. Matched pathways are automatically scored according to their variation from the query pathway in terms of the protein insertions and deletions they employ, the sequence similarity of their constituent proteins to the query proteins, and the reliability of their constituent interactions. We applied QPath to systematically infer protein pathways in fly using an extensive collection of 271 putative pathways from yeast. QPath identified 69 conserved pathways whose members were both functionally enriched and coherently expressed. The resulting pathways tended to preserve the function of the original query pathways, allowing us to derive a first annotated map of conserved protein pathways in fly. Pathway homology searches using QPath provide a powerful approach for identifying biologically significant pathways and inferring their function. The growing amounts of protein interactions in public databases underscore the importance of our network querying framework for mining protein network data.	algorithm;clinical act of insertion;database;databases;functional genomics;gene regulatory network;high-throughput computing;homologous gene;homology (biology);inference;interaction network;pierre robin syndrome;question (inquiry);score;sequence alignment;staphylococcal protein a;throughput;protein protein interaction	Tomer Shlomi;Daniel Segal;Eytan Ruppin;Roded Sharan	2005	BMC Bioinformatics	10.1186/1471-2105-7-199	computer simulation;high-throughput screening;biology;molecular biology;regulation of gene expression;dna microarray;bioinformatics;sequence analysis;genetics;signal transduction;transcription factor	Comp.	2.9875517263844333	-58.108686024872426	165282
a1ffc85ad2187e2d791a154329e40397ff6629d1	individualized analysis of differentially expressed mirnas with application to the identification of mirnas deregulated commonly in lung cancer tissues		Identifying differentially expressed microRNAs (DE miRNAs) between cancer samples and normal controls is a common way to investigate carcinogenesis mechanisms. However, for a DE miRNA detected at the population-level, we do not know whether it is DE in a particular cancer sample. Here, based on the finding that the within-sample relative expression orderings of miRNA pairs are highly stable in a particular type of normal tissues but widely disrupted in the corresponding cancer tissues, we proposed a method, called RankMiRNA, to identify DE miRNAs in each cancer tissue compared with its own normal state. Evaluated with pair-matched miRNA expression profiles of cancer tissues and adjacent normal tissues for lung and liver cancers, RankMiRNA exhibited excellent performance. Finally, we exemplified an application of the individual-level differential expression analysis by finding miRNAs DE in at least 90% lung cancer tissues, defined as common DE miRNAs of lung cancer. After identifying DE miRNAs for each of 991 lung cancer samples from The Cancer Genome Atlas with RankMiRNA, we found that hsa-mir-210 was upregulated, while hsa-mir-490 and hsa-mir-486 were downregulated in > 90% of the 991 lung cancer samples. These common DE miRNAs were validated in independent pair-matched samples of cancer tissues and adjacent normal tissues measured with different platforms. In conclusion, RankMiRNA provides us a novel tool to find common and subtype-specific miRNAs for a type of cancer, allowing us to study cancer mechanisms in a novel way.		Haidan Yan;Hao Cai;Qingzhou Guan;Jun He;Juan Zhang;You Guo;Haiyan Huang;Xiangyu Li;Yawei Li;Yunyan Gu;Lishuang Qi;Zheng Guo	2018	Briefings in bioinformatics	10.1093/bib/bbx015	lung cancer;bioinformatics;microrna;biology	Comp.	6.546203588019717	-55.97986246923893	165524
43cf37ffb101dad590563ffc53e6bdb1a19907ba	towards prediction and prioritization of disease genes by the modularity of human phenome-genome assembled network		Empirical clinical studies on the human interactome and phenome not only illustrates prevalent phenotypic overlap and genetic overlap between diseases, but also reveals a modular organization of the genetic landscape of human disease, providing new opportunities to reduce the complexity in dissecting the phenotype-genotype association. We here introduce a network-module based method towards phenotype-genotype association inference and disease gene identification. This approach incorporates protein-protein interaction network, phenotype similarity network and known phenotype-genotype associations into an assembled network. We then decomposes the resulted network into modules (or communities) wherein we identified and prioritized the disease genes from the candidates within the loci associated with the query disease using a linear regression model and concordance score. For the known phenotype-gene associations in the OMIM database, we used the leave-one-out validation to evaluate the feasibility of our method, and successfully ranked known disease genes at top 1 in 887 out of 1807 cases. Moreover, applying this approach on 850 OMIM loci characterized by an unknown molecular basis, we propose high-probability candidates for 81 genetic diseases.	community;concordance (publishing);disease gene identification;hereditary diseases;human interactome;inference;interaction network;linear iga bullous dermatosis;mental association;online mendelian inheritance in man;phenome;question (inquiry);protein protein interaction	Jeffrey Q. Jiang;Andreas W. M. Dress;Ming Chen	2010	Journal of integrative bioinformatics	10.2390/biecoll-jib-2010-149	biology;bioinformatics;data mining;genetics	Comp.	4.67203571001402	-57.102508209953726	165639
9998e1d50250a01497aaab00e9592c651995769e	predicting protein-ligand binding site using support vector machine with protein properties	drugs;support vector machine svm bioinformatics protein ligand binding sites binding sites predication structure based drug design;support vector machines;support vector machine svm;proteins support vector machines bioinformatics drugs computational biology diseases three dimensional displays;journal article;proteins;machine learning;biology and genetics;three dimensional displays;molecular biophysics;support vector machines biochemistry bioinformatics drugs molecular biophysics proteins;structure based drug design;protein ligand binding sites;diseases;binding sites predication;protein ligand binding site drug target protein complexes data set ligasite meta pocket q site finder pocket finder f pocket surfnet ligsite geometric characteristics svm sequence based methods energetic methods geometric methods docking algorithms structure based drug design support vector machine;computational biology;biochemistry;bioinformatics	Identification of protein-ligand binding site is an important task in structure-based drug design and docking algorithms. In the past two decades, different approaches have been developed to predict the binding site, such as the geometric, energetic, and sequence-based methods. When scores are calculated from these methods, the algorithm for doing classification becomes very important and can affect the prediction results greatly. In this paper, the support vector machine (SVM) is used to cluster the pockets that are most likely to bind ligands with the attributes of geometric characteristics, interaction potential, offset from protein, conservation score, and properties surrounding the pockets. Our approach is compared to LIGSITE, $({\rm LIGSITE}^{{\rm csc}})$, SURFNET, Fpocket, PocketFinder, Q-SiteFinder, ConCavity, and MetaPocket on the data set LigASite and 198 drug-target protein complexes. The results show that our approach improves the success rate from 60 to 80 percent at AUC measure and from 61 to 66 percent at top 1 prediction. Our method also provides more comprehensive results than the others.	area under curve;binding sites;boat dock;concave function;docking (molecular);drug design;eighty;ligand binding domain;ligands;support vector machine;algorithm	Ginny Y. Wong;F. H. Frank Leung;Sai-Ho Ling	2013	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2013.126	support vector machine;biochemistry;computer science;bioinformatics;machine learning;data mining;molecular biophysics	Comp.	9.89691809794342	-56.51424126665327	165660
28fa3c4c980132085bb134e9996b1344699806ad	algorithms for modeling global and context-specific functional relationship networks	predictions;functional relationship network;inference	Functional genomics has enormous potential to facilitate our understanding of normal and disease-specific physiology. In the past decade, intensive research efforts have been focused on modeling functional relationship networks, which summarize the probability of gene co-functionality relationships. Such modeling can be based on either expression data only or heterogeneous data integration. Numerous methods have been deployed to infer the functional relationship networks, while most of them target the global (non-context-specific) functional relationship networks. However, it is expected that functional relationships consistently reprogram under different tissues or biological processes. Thus, advanced methods have been developed targeting tissue-specific or developmental stage-specific networks. This article brings together the state-of-the-art functional relationship network modeling methods, emphasizes the need for heterogeneous genomic data integration and context-specific network modeling and outlines future directions for functional relationship networks.		Fan Zhu;Bharat Panwar;Yuanfang Guan	2016	Briefings in bioinformatics	10.1093/bib/bbv065	biological network inference;prediction;machine learning	Comp.	5.278164200637029	-57.50538730563721	165755
21a96f3d68ee58d60c0eb038a9de216a567a7cd1	affymetrix genechip microarray preprocessing for multivariate analyses	multivariate analysis;gene regulatory networks;gene expression;cluster analysis;gene expression profiling;oligonucleotide array sequence analysis	Affymetrix GeneChip microarrays are the most widely used high-throughput technology to measure gene expression, and a wide variety of preprocessing methods have been developed to transform probe intensities reported by a microarray scanner into gene expression estimates. There have been numerous comparisons of these preprocessing methods, focusing on the most common analyses-detection of differential expression and gene or sample clustering. Recently, more complex multivariate analyses, such as gene co-expression, differential co-expression, gene set analysis and network modeling, are becoming more common; however, the same preprocessing methods are typically applied. In this article, we examine the effect of preprocessing methods on some of these multivariate analyses and provide guidance to the user as to which methods are most appropriate.	affymetrix;cluster analysis;estimated;gene expression;gene co-expression network;high-throughput computing;microarray;preprocessor;runge–kutta methods;scanning systems;throughput;statistical cluster	Matthew N. McCall;Anthony Almudevar	2012	Briefings in bioinformatics	10.1093/bib/bbr072	biology;gene regulatory network;molecular biology;gene expression;bioinformatics;gene expression profiling;multivariate analysis;cluster analysis;genetics	Comp.	5.131459094407744	-52.72990676635483	166125
9a3b3a7579a3f98eb5063aff74a59e4837e5bfb7	using multiple levels of learning and diverse evidence to uncover coordinately controlled genes	complete genome;data type;computational method;computational molecular biology;level of detail;machine learning;number of factors	Now that the complete genomes of numerous organisms have been determined, a key problem in computational molecular biology is uncovering the relationships that exist among the genes in each organism and the regulatory mechanisms that control their operation. We are developing computational methods for discovering such regulatory mechanisms and relationships. Toward this end, we have developed a machine learning approach to identifying sets of genes that are coordinately controlled in the E. coli genome. A number of factors make this an interesting application for machine learning: (i) there is a rich variety of data types that provide useful evidence for this task, (ii) the overall problem of uncovering regulatory mechanisms can be decomposed in multiple machine learning subtasks operating at dieren t levels of detail, (iii) there are not any known negative training examples, and (iv) some of the features are misleading in their predictiveness.		Mark Craven;David Page;Jude W. Shavlik;Joseph Bockhorst;Jeremy D. Glasner	2000			data type;computer science;bioinformatics;machine learning;level of detail;data mining	ML	3.2689663562786553	-58.06181071662082	166295
094ceb9c803d9a42b529793b3794ac471c89d017	prophnet: a generic prioritization method through propagation of information	genes;interaction networks;breast neoplasms;prophnet;database;diabetes mellitus;info eu repo semantics article;computational biology bioinformatics;alzheimer;genetic predisposition to disease;diabetes mellitus type 2;algorithms;humans;combinatorial libraries;software design;computational biology;computer appl in life sciences;breast cancer;microarrays;bioinformatics	Prioritization methods have become an useful tool for mining large amounts of data to suggest promising hypotheses in early research stages. Particularly, network-based prioritization tools use a network representation for the interactions between different biological entities to identify novel indirect relationships. However, current network-based prioritization tools are strongly tailored to specific domains of interest (e.g. gene-disease prioritization) and they do not allow to consider networks with more than two types of entities (e.g. genes and diseases). Therefore, the direct application of these methods to accomplish new prioritization tasks is limited. This work presents ProphNet, a generic network-based prioritization tool that allows to integrate an arbitrary number of interrelated biological entities to accomplish any prioritization task. We tested the performance of ProphNet in comparison with leading network-based prioritization methods, namely rcNet and DomainRBF, for gene-disease and domain-disease prioritization, respectively. The results obtained by ProphNet show a significant improvement in terms of sensitivity and specificity for both tasks. We also applied ProphNet to disease-gene prioritization on Alzheimer, Diabetes Mellitus Type 2 and Breast Cancer to validate the results and identify putative candidate genes involved in these diseases. ProphNet works on top of any heterogeneous network by integrating information of different types of biological entities to rank entities of a specific type according to their degree of relationship with a query set of entities of another type. Our method works by propagating information across data networks and measuring the correlation between the propagated values for a query and a target sets of entities. ProphNet is available at: http://genome2.ugr.es/prophnet . A Matlab implementation of the algorithm is also available at the website.	breast carcinoma;data mining;diabetes mellitus;entity;generic drugs;genetic heterogeneity;interaction;matlab;parkinson disease;question (inquiry);sensitivity and specificity;software propagation;web site;algorithm	Víctor Martínez;Carlos Cano;Armando Blanco	2014		10.1186/1471-2105-15-S1-S5	biology;dna microarray;computer science;bioinformatics;software design;theoretical computer science;breast cancer;gene;data mining	ML	6.623582515012168	-56.826331473618765	166720
7e7086f3523ac016fee835963672cd9984bfd28b	effectiveness of applying codon usage bias for translational initiation sites prediction	dna;genomics;proteins bioinformatics sequences computer science genomics context modeling predictive models biomedical computing organisms signal synthesis;molecular configurations;translation initiation site;codon usage bias;computational method;protein primary structure identification;proteomics bioinformatics dna genomics molecular configurations proteins;cdna sequences;proteins;genomics translation initiation site codon usage;tis recognition;codon preference usage translational initiation site prediction tis recognition genomic sequences cdna sequences mrna sequences protein primary structure identification codon usage bias agent;codon usage;codon preference usage;proteomics;genomic sequences;translational initiation site prediction;codon usage bias agent;bioinformatics;mrna sequences	The accurate recognition of translational initiation sites (TISs) in genomic, cDNA and mRNA sequences is crucial to identifying the primary structure of the functional gene products - proteins. Many computational methods have been proposed in the literature which apply one or more complicated models that examine a variety of sequence features. In this paper, we propose a novel TIS prediction approach, called codon usage bias agent, which operates solely based on the usage of codon preference; the algorithm only requires O(n) for execution time. The results of the experiments conducted on three benchmark data sets have shown that the proposed approach is very effective and well applicable to solving the problem of TIS recognition.	algorithm;apply;benchmark (computing);computation;experiment;run time (program lifecycle phase)	Jia Zeng;Reda Alhajj;Douglas J. Demetrick	2008	2008 IEEE International Conference on Bioinformatics and Biomedicine	10.1109/BIBM.2008.30	biology;genomics;molecular biology;codon usage bias;bioinformatics;proteomics;genetics	Robotics	8.155254844033761	-56.45444192193941	166882
b1f7542ef625773ca0faf50430755409fd82ec27	stochastic models inspired by hybridization theory for short oligonucleotide arrays	affymetrix probe level data;background adjustment;measurement error;high density;physical models;statistical model;gene expression;large scale;stochastic model;physical model;microarrays;stochastic models	High density oligonucleotide expression arrays are a widely used tool for the measurement of gene expression on a large scale. Affymetrix GeneChip arrays appear to dominate this market. These arrays use short oligonucleotides to probe for genes in an RNA sample. Due to optical noise, non-specific hybridization, probe-specific effects, and measurement error, ad-hoc measures of expression, that summarize probe intensities, can lead to imprecise and inaccurate results. Various researchers have demonstrated that expression measures based on simple statistical models can provide great improvements over the ad-hoc procedure offered by Affymetrix. Recently, physical models based on molecular hybridization theory, have been proposed as useful tools for prediction of, for example, non-specific hybridization. These physical models show great potential in terms of improving existing expression measures. In this paper we suggest that the system producing the measured intensities is too complex to be fully described with these relatively simple physical models and we propose empirically motivated stochastic models that compliment the above mentioned molecular hybridization theory to provide a comprehensive description of the data. We discuss how the proposed model can be used to obtain improved measures of expression useful for the data analysts.	affymetrix;crossbreeding;dna microarray;gene expression;hoc (programming language);inspiration function;nucleic acid hybridization;oligonucleotides;rna;statistical model;stochastic process;tiling array	Zhijin Wu;Rafael A. Irizarry	2004	Journal of computational biology : a journal of computational molecular cell biology	10.1145/974614.974628	biology;physical model;computer science;bioinformatics;stochastic modelling;data mining;mathematics;genetics;statistics	Comp.	4.344309223824724	-53.69489022918337	167593
255781ed1691d8ee4c560619b24251cf78810c6d	algpred: prediction of allergenic proteins and mapping of ige epitopes	epitopes;software;immunoglobulin e;amino acid;epitope mapping;hybrid approach;internet;proteins;allergens;amino acids;artificial intelligence;algorithms;support vector machine;amino acid motifs	In this study a systematic attempt has been made to integrate various approaches in order to predict allergenic proteins with high accuracy. The dataset used for testing and training consists of 578 allergens and 700 non-allergens obtained from A. K. Bjorklund, D. Soeria-Atmadja, A. Zorzet, U. Hammerling and M. G. Gustafsson (2005) Bioinformatics, 21, 39-50. First, we developed methods based on support vector machine using amino acid and dipeptide composition and achieved an accuracy of 85.02 and 84.00%, respectively. Second, a motif-based method has been developed using MEME/MAST software that achieved sensitivity of 93.94 with 33.34% specificity. Third, a database of known IgE epitopes was searched and this predicted allergenic proteins with 17.47% sensitivity at specificity of 98.14%. Fourth, we predicted allergenic proteins by performing BLAST search against allergen representative peptides. Finally hybrid approaches have been developed, which combine two or more than two approaches. The performance of all these algorithms has been evaluated on an independent dataset of 323 allergens and on 101 725 non-allergens obtained from Swiss-Prot. A web server AlgPred has been developed for the predicting allergenic proteins and for mapping IgE epitopes on allergenic proteins (http://www.imtech.res.in/raghava/algpred/). AlgPred is available at www.imtech.res.in/raghava/algpred/.	101 mouse;algorithm;allergens;amino acids;blast;bioinformatics;clinical trial protocol document;dipeptides;epitopes;greater than;ige;meme;motif;swiss-model;sensitivity and specificity;server (computing);silo (dataset);support vector machine;switzerland;web server	Sudipto Saha;Gajendra P. S. Raghava	2006	Nucleic Acids Research	10.1093/nar/gkl343	biology;amino acid;biotechnology;bioinformatics;immunology	Comp.	9.548206352379786	-56.4236168982564	167627
0a4a2ffb59bebcfe95befff02acb77d39df30b75	unified cox model based multifactor dimensionality reduction method for gene-gene interaction analysis of the survival phenotype	cox model;gene-gene interaction;multifactor dimensionality reduction method;survival time;unified model based method	One strategy for addressing missing heritability in genome-wide association study is gene-gene interaction analysis, which, unlike a single gene approach, involves high-dimensionality. The multifactor dimensionality reduction method (MDR) has been widely applied to reduce multi-levels of genotypes into high or low risk groups. The Cox-MDR method has been proposed to detect gene-gene interactions associated with the survival phenotype by using the martingale residuals from a Cox model. However, this method requires a cross-validation procedure to find the best SNP pair among all possible pairs and the permutation procedure should be followed for the significance of gene-gene interactions. Recently, the unified model based multifactor dimensionality reduction method (UM-MDR) has been proposed to unify the significance testing with the MDR algorithm within the regression model framework, in which neither cross-validation nor permutation testing are needed. In this paper, we proposed a simple approach, called Cox UM-MDR, which combines Cox-MDR with the key procedure of UM-MDR to identify gene-gene interactions associated with the survival phenotype. The simulation study was performed to compare Cox UM-MDR with Cox-MDR with and without the marginal effects of SNPs. We found that Cox UM-MDR has similar power to Cox-MDR without marginal effects, whereas it outperforms Cox-MDR with marginal effects and more robust to heavy censoring. We also applied Cox UM-MDR to a dataset of leukemia patients and detected gene-gene interactions with regard to the survival time. Cox UM-MDR is easily implemented by combining Cox-MDR with UM-MDR to detect the significant gene-gene interactions associated with the survival time without cross-validation and permutation testing. The simulation results are shown to demonstrate the utility of the proposed method, which achieves at least the same power as Cox-MDR in most scenarios, and outperforms Cox-MDR when some SNPs having only marginal effects might mask the detection of the causal epistasis.		Seungyeoun Lee;Donghee Son;Yongkang Kim;Wenbao Yu;Taesung Park	2018		10.1186/s13040-018-0189-1	data mining;permutation;proportional hazards model;computational biology;snp;regression analysis;missing heritability problem;computer science;multifactor dimensionality reduction;unified model;martingale (probability theory)	Comp.	6.795693206662493	-52.62105534792531	168229
2465b0676d82d1e9102da9429d3e91c02224e536	manifold learning visualization of metabotropic glutamate receptors	g protein coupled receptors;conference report;generative topographic mapping;data visualization;metabotropic glutamate receptors	G-Protein-Coupled Receptors (GPCRs) are cell membrane proteins with a key role in biological processes. GPCRs of class C, in particular, are of great interest in pharmacology. The lack of knowledge about their 3-D structures means they must be investigated through their primary amino acid sequences. Sequence visualization can help to explore the existing receptor sub-groupings at different partition levels. In this paper, we focus on Metabotropic Glutamate Receptors (mGluR), a subtype of class C GPCRs. Different versions of a probabilistic manifold learning model are employed to comparatively sub-group and visualize them through different transformations of their sequences.	nonlinear dimensionality reduction	Martha Ivón Cárdenas;Alfredo Vellido;Jesús Giraldo	2014		10.3233/978-1-61499-452-7-269	biology;neuroscience;bioinformatics;class c gpcr;communication	ML	5.0987750001606695	-57.48267705745672	168375
51e24e5f9f3a639a2daae7ea5c40916efc8fe772	ensemble graphs to reveal post-transcriptional regulatory networks in alzheimer's disease	bayesian network classifier;alzheimer’s disease;post-transcriptional regulation;ensemble graph;feature sta- bility	Integration of multiple datasets grants in-silico investigations with higher statistical and reasoning power to elucidate secondary discoveries hidden to the initial data producers. Here we introduce a novel method for the network analysis of messenger RNA regulation. Post-translational regulation of gene activity by microRNA molecules is investigated, combining expression data and sequence binding predictions. A set of sounding machine learning techniques allows the integration of these structural and functional results, conveying them into an ensemble graph of regulations. Ensemble graphs are embedded in Bayesian network classifiers following an ascending order of complexity and finally evaluated by their goodness-of-fit and classification performances. The new proposal is put to the test in the integration of four Alzheimeru0027s disease datasets, reaching optimal values of 94.39% ± 2.34 accuracy and 0.9794 ± 0.01 for the area under the ROC curve. Detected regulations within the optimal network structure match the state-of-the-art literature. Additional dependences suggest previously unreported regulations in Alzheimeru0027s disease research.		Rubén Armañanzas	2017		10.1109/BIBM.2017.8217667	network analysis;artificial intelligence;machine learning;gene;computer science;bayesian network;messenger rna;graph	Theory	7.484431020008614	-57.235709956801394	168566
5d617b19b5b3f9c8c99a9ae1230155ae6a57ee2e	new algorithm for analysis of off-target effects in sirna screens		The occurrence of RNAi side effects called “off-target effects” is still a challenging aspect in the interpretation of data from large-scale RNA interference screens. To reduce off-target effects, improved algorithms have been developed for small interfering RNA (siRNA) design, but also chemical modifications of double stranded RNA molecules were introduced by the various commercial providers. To aid the analysis of large-scale screens, we present a new algorithm and tool for the prediction of potential off-target effects that can be applied to RNAi experimental data. Our approach provides different possibilities to search for homologies between individual siRNAs of cellular mRNAs. We demonstrate our approach on a ribosomal RNAi screening dataset.	algorithm;computation;computational model;homology (biology);interference (communication)	Karol Kozak;Sandra Kaestner;Thomas Wild;Andreas Vonderheit;Benjamin Misselwitz;Ulrike Kutay;Gabor Csucs	2013			machine learning;artificial intelligence;bioinformatics;computer science	Comp.	7.652738158687093	-58.12657955310604	168880
2b14982f5408059c25139131b4248d2d303e9b09	methodological study of affine transformations of gene expression data with proposed robust non-parametric multi-dimensional normalization method	microarray data;software;empirical distribution;data interpretation statistical;bioinformatik och systembiologi;models theoretical;gene expression data;image processing computer assisted;computational biology bioinformatics;multi dimensional;microarray analysis;likelihood functions;affine transformation;comparative study;cdna microarray;models statistical;algorithms;regression analysis;humans;differentially expressed gene;curve fitting;combinatorial libraries;computational biology;computer appl in life sciences;gene expression profiling;oligonucleotide array sequence analysis;microarrays;bioinformatics	"""Low-level processing and normalization of microarray data are most important steps in microarray analysis, which have profound impact on downstream analysis. Multiple methods have been suggested to date, but it is not clear which is the best. It is therefore important to further study the different normalization methods in detail and the nature of microarray data in general. A methodological study of affine models for gene expression data is carried out. Focus is on two-channel comparative studies, but the findings generalize also to single- and multi-channel data. The discussion applies to spotted as well as in-situ synthesized microarray data. Existing normalization methods such as curve-fit (""""lowess"""") normalization, parallel and perpendicular translation normalization, and quantile normalization, but also dye-swap normalization are revisited in the light of the affine model and their strengths and weaknesses are investigated in this context. As a direct result from this study, we propose a robust non-parametric multi-dimensional affine normalization method, which can be applied to any number of microarrays with any number of channels either individually or all at once. A high-quality cDNA microarray data set with spike-in controls is used to demonstrate the power of the affine model and the proposed normalization method. We find that an affine model can explain non-linear intensity-dependent systematic effects in observed log-ratios. Affine normalization removes such artifacts for non-differentially expressed genes and assures that symmetry between negative and positive log-ratios is obtained, which is fundamental when identifying differentially expressed genes. In addition, affine normalization makes the empirical distributions in different channels more equal, which is the purpose of quantile normalization, and may also explain why dye-swap normalization works or fails. All methods are made available in the aroma package, which is a platform-independent package for R."""	2',5'-oligoadenylate;academy;alien;bsd;biorobotics;calibration;corn of toe;dna microarray format;database normalization;downstream (software development);dyes;eliza;estimated;exanthema;exposure to humidity;feedback;forty nine;gene expression;high- and low-level;image analysis;image scanner;instrument - device;manuscripts;microgrid;mj ab:acnc:pt:ser:qn:ia;morphologic artifacts;nonlinear system;normalize;nucleic acid hybridization;numerous;oligo primer analysis software;oligonucleotides;paging;pixel;premenstrual tension;printing;quantum gate;rna;radionuclide imaging;scanner device component;scanning systems;science;seizures;slide (glass microscope);statistical test;steam;system software 6;tracer;uc browser;weakness;cell transformation	Henrik Bengtsson;Ola Hössjer	2005	BMC Bioinformatics	10.1186/1471-2105-7-100	biology;microarray analysis techniques;computer science;bioinformatics;data science;data mining	Comp.	4.4130496247780675	-53.0484286573085	169206
22e2f237fad55ff40a1722f32ba9b460db623d9b	an integrative modular approach to systematically predict gene-phenotype associations	human disease;drug targeting;databases genetic;computational biology bioinformatics;chip;transcription regulation;gene ontology annotation;specific activity;genome;random forest;protein protein interaction;algorithms;combinatorial libraries;computational biology;phenotype;computer appl in life sciences;gene expression profiling;microarrays;bioinformatics;global analysis	Complex human diseases are often caused by multiple mutations, each of which contributes only a minor effect to the disease phenotype. To study the basis for these complex phenotypes, we developed a network-based approach to identify coexpression modules specifically activated in particular phenotypes. We integrated these modules, protein-protein interaction data, Gene Ontology annotations, and our database of gene-phenotype associations derived from literature to predict novel human gene-phenotype associations. Our systematic predictions provide us with the opportunity to perform a global analysis of human gene pleiotropy and its underlying regulatory mechanisms. We applied this method to 338 microarray datasets, covering 178 phenotype classes, and identified 193,145 phenotype-specific coexpression modules. We trained random forest classifiers for each phenotype and predicted a total of 6,558 gene-phenotype associations. We showed that 40.9% genes are pleiotropic, highlighting that pleiotropy is more prevalent than previously expected. We collected 77 ChIP-chip datasets studying 69 transcription factors binding over 16,000 targets under various phenotypic conditions. Utilizing this unique data source, we confirmed that dynamic transcriptional regulation is an important force driving the formation of phenotype specific gene modules. We created a genome-wide gene to phenotype mapping that has many potential implications, including providing potential new drug targets and uncovering the basis for human disease phenotypes. Our analysis of these phenotype-specific coexpression modules reveals a high prevalence of gene pleiotropy, and suggests that phenotype-specific transcription factor binding may contribute to phenotypic diversity. All resources from our study are made freely available on our online Phenotype Prediction Database [1].	aquaporin 1;chip-on-chip;class;disease phenotype;drug delivery systems;gene ontology;mental association;microarray;mutation;random forest;transcription factor;transcription (software);transcriptional regulation;protein protein interaction	Michael R. Mehan;Juan Nunez-Iglesias;Chao Dai;Michael S. Waterman;Xianghong Jasmine Zhou	2010		10.1186/1471-2105-11-S1-S62	protein–protein interaction;computational biology;chip;random forest;biology;targeted drug delivery;dna microarray;bioinformatics;phenotype;specific activity;global analysis;gene expression profiling;genetics;transcriptional regulation;genome	Comp.	5.227138735456387	-57.928287619443886	169266
d2bf041ca523dcde7b9f49356f3935d34fc5f105	compadre: an r and web resource for pathway activity analysis by component decompositions	mx supplementary information;biological network;compadre pipeline;supplementary information;activity index;supplementary data;gene expression sub-matrix;biological networks analysis;gene set;complete biological picture	UNLABELLED The analysis of biological networks has become essential to study functional genomic data. Compadre is a tool to estimate pathway/gene sets activity indexes using sub-matrix decompositions for biological networks analyses. The Compadre pipeline also includes one of the direct uses of activity indexes to detect altered gene sets. For this, the gene expression sub-matrix of a gene set is decomposed into components, which are used to test differences between groups of samples. This procedure is performed with and without differentially expressed genes to decrease false calls. During this process, Compadre also performs an over-representation test. Compadre already implements four decomposition methods [principal component analysis (PCA), Isomaps, independent component analysis (ICA) and non-negative matrix factorization (NMF)], six statistical tests (t- and f-test, SAM, Kruskal-Wallis, Welch and Brown-Forsythe), several gene sets (KEGG, BioCarta, Reactome, GO and MsigDB) and can be easily expanded. Our simulation results shown in Supplementary Information suggest that Compadre detects more pathways than over-representation tools like David, Babelomics and Webgestalt and less false positives than PLAGE. The output is composed of results from decomposition and over-representation analyses providing a more complete biological picture. Examples provided in Supplementary Information show the utility, versatility and simplicity of Compadre for analyses of biological networks.   AVAILABILITY AND IMPLEMENTATION Compadre is freely available at http://bioinformatica.mty.itesm.mx:8080/compadre. The R package is also available at https://sourceforge.net/p/compadre.	biological network;chamaecyparis lawsoniana;ephrin type-b receptor 1, human;gene expression;gene regulatory network;immunodeficiency, common variable, 10;independent component analysis;index;kegg;kruskal's algorithm;non-negative matrix factorization;principal component analysis;radiology information systems;s-adenosylmethionine;simulation;sourceforge;statistical test;web resource;welch's method;f test	Roberto-Rafael Ramos-Rodriguez;Raquel Cuevas-Diaz-Duran;Francesco Falciani;José G. Tamez-Peña;Victor Treviño	2012	Bioinformatics	10.1093/bioinformatics/bts513	computer science;bioinformatics;machine learning;data mining;statistics	Comp.	4.372293858401414	-53.88512218211698	169475
ae8659a55e4d221f39c6e2a5ba571c870867bb67	effect of microarray data heterogeneity on regulatory gene module discovery	microarray data;simulation and modeling;systems biology;physiological cellular and medical topics;computational biology bioinformatics;algorithms;bioinformatics	Introduction An integrative genomics approach, in which data from different micro-array experiments are merged together to study regulatory networks [1], has been adopted in several recent research studies. However, we propose that blind use of this approach can be misleading. Our hypothesis is that as micro-array data from different experiments are merged, local patterns of activity, for example the cell cycle, can be masked by more global and dominant patterns such as stress reactions. We have carried out a systematic study in which data with increasing heterogeneity is clustered to determine groups of functionally related genes. These clusters are then tested for similarity to each other.	cell (microprocessor);experiment;functional genomics;microarray	Alok Mishra;Duncan Fyfe Gillies	2007	BMC Systems Biology	10.1186/1752-0509-1-S1-S2	computational biology;biology;microarray analysis techniques;computer science;bioinformatics;data science;microarray databases;systems biology	ML	4.7698295330333345	-56.1358205220391	169556
e778c68a11939b1f7fd566c5707ed19900e90f41	predicting patterns of gene expression during drosophila embryogenesis	systems biology;gene regulatory networks;pattern recognition and classification;gene expression;machine learning;local search;prediction;bioinformatics	Understanding how organisms develop from a single cell into a functioning multicellular organism is one of the key questions in developmental biology. Research in this area goes back decades ago, but only recently have improvements in technology allowed biologists to achieve experimental results that are more quantitative and precise. Here, we show how large biological datasets can be used to learn a model for predicting the patterns of gene expression in Drosophila melanogaster (fruit fly) throughout embryogenesis. We also explore the possibility of considering spatial information in order to achieve unique patterns of gene expression in different regions along the anterior-posterior (head-tail) axis of the egg. We then demonstrate how the resulting model can be used to (1) classify these regions into the various segments of the fly, and (2) to conduct a virtual gene knockout experiment. Our learning algorithm is based on a model that has biological meaning, which indicates that its structure and parameters have their correspondence in biology.	algorithm;apache axis;artificial gene synthesis;knockout	Rotem Golan;Christian Jacob;Savraj S Grewal;Jörg Denzinger	2014		10.1145/2576768.2598250	gene regulatory network;gene expression;prediction;computer science;bioinformatics;local search;systems biology	Comp.	4.632156058510942	-58.986202310432155	169657
530ba245122d8b47732ddbb7ffaa70cec90010ac	an integrative scoring approach to identify transcriptional regulations controlling lung surfactant homeostasis	transcriptional regulatory networks semi supervised learning lung surfactant homeostasis integrative scoring transcriptional regulation identification;semi supervised learning based integrative scoring transcriptional regulation lung surfactant homeostasis transcriptional regulatory network identification systems biology data mining machine learning;lung surfactant homeostasis;transcriptional regulation;systems biology;lungs;lungs data mining mathematical model proteins bioinformatics lipidomics differential equations;lipidomics;biology;transcriptional regulatory networks;data mining;semi supervised learning;learning artificial intelligence biology data mining;transcription regulation;semi supervised learning based integrative scoring;proteins;machine learning;integrative scoring;system biology;mathematical model;transcriptional regulation identification;differential equations;learning artificial intelligence;transcriptional regulatory network identification;bioinformatics;transcriptional regulatory network	Transcriptional regulatory network identification is both a fundamental challenge in systems biology and an important practical application of data mining and machine learning. In this study, we propose a semi-supervised learning-based integrative scoring approach to tackle this challenge and predict transcriptional regulations. Our approach out-performs a state-of-the-art label propagation method and reaches AUC scores above 0.96 for three datasets from microarray experiments in the validation. A map of the transcriptional regulatory network controlling lung surfactant homeostasis was constructed. The predicted and prioritized transcriptional regulations were further validated through experimental verifications. Many other predicted novel regulations may serve as candidates for future experimental investigations.	data mining;experiment;homeostasis;machine learning;microarray;semi-supervised learning;semiconductor industry;software propagation;supervised learning;systems biology	Minlu Zhang;Chunsheng Fang;Yan Xu;Raj Bhatnagar;Long J. Lu	2010	2010 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2010.110	computer science;bioinformatics;machine learning;data mining;systems biology;transcriptional regulation	Robotics	7.382137779298574	-56.51320303297724	171334
fa374b4119f816aac149af7c5ac859d4d1bdadc9	using stochastic causal trees to augment bayesian networks for modeling eqtl datasets	structure learning;quantitative trait loci;bayesian network;sample size;genotype;probabilistic method;gene regulatory networks;bayes theorem;gene network;causal ordering;expression quantitative trait loci;learning networks;genetic variation;computational biology bioinformatics;models genetic;stochastic processes;algorithms;genotypic variation;gene expression programming;combinatorial libraries;computer appl in life sciences;computer simulation;microarrays;bioinformatics	The combination of genotypic and genome-wide expression data arising from segregating populations offers an unprecedented opportunity to model and dissect complex phenotypes. The immense potential offered by these data derives from the fact that genotypic variation is the sole source of perturbation and can therefore be used to reconcile changes in gene expression programs with the parental genotypes. To date, several methodologies have been developed for modeling eQTL data. These methods generally leverage genotypic data to resolve causal relationships among gene pairs implicated as associates in the expression data. In particular, leading studies have augmented Bayesian networks with genotypic data, providing a powerful framework for learning and modeling causal relationships. While these initial efforts have provided promising results, one major drawback associated with these methods is that they are generally limited to resolving causal orderings for transcripts most proximal to the genomic loci. In this manuscript, we present a probabilistic method capable of learning the causal relationships between transcripts at all levels in the network. We use the information provided by our method as a prior for Bayesian network structure learning, resulting in enhanced performance for gene network reconstruction. Using established protocols to synthesize eQTL networks and corresponding data, we show that our method achieves improved performance over existing leading methods. For the goal of gene network reconstruction, our method achieves improvements in recall ranging from 20% to 90% across a broad range of precision levels and for datasets of varying sample sizes. Additionally, we show that the learned networks can be utilized for expression quantitative trait loci mapping, resulting in upwards of 10-fold increases in recall over traditional univariate mapping. Using the information from our method as a prior for Bayesian network structure learning yields large improvements in accuracy for the tasks of gene network reconstruction and expression quantitative trait loci mapping. In particular, our method is effective for establishing causal relationships between transcripts located both proximally and distally from genomic loci.	bayesian network;causal filter;causality;expression quantitative trait locus;gene expression;gene regulatory network;genotype;manuscripts;phenotype;population;protocols documentation;quantitative real-time polymerase chain reaction;sample size;transcript	Kyle C. Chipman;Ambuj K. Singh	2010		10.1186/1471-2105-12-7	computer simulation;biology;gene regulatory network;bioinformatics;machine learning;gene expression programming;genetics	Comp.	2.8295238517195296	-53.052522627105716	171582
eb81e8e9bf695d82dd5ce5f5f38ecede33e76af7	identification of viral protein genotypic determinants using combinatorial filtering and active learning	silicon;genotype phenotype mapping;convergence;viral phenotype;active learning;viruses medical;fusogenicity;feline immunodeficiency virus envelope proteins viral protein genotypic determinants combinatorial filtering active learning rna viruses viral phenotype genotype phenotype mapping fusogenicity;rna viruses;feline immunodeficiency virus envelope proteins;genetics;key residues identification combinatorial filtering active learning;proteins;feline immunodeficiency virus;proteins bioinformatics genetics learning artificial intelligence macromolecules microorganisms;immune system;macromolecules;key residues identification;combinatorial filtering;viral protein genotypic determinants;learning artificial intelligence;strain;proteins active filters rna viruses medical human immunodeficiency virus influenza diseases filtering algorithms capacitive sensors laboratories;microorganisms;bioinformatics	RNA viruses such as HIV, Influenza, impose very significant disease burden throughout the world. Identifying key protein residue determinants that affect a given viral phenotype is an important step in learning the genotype-phenotype mapping and making clinic decisions. This identification is currently done through a laborious experimental process which is arguably inefficient, incomplete, and unreliable. We describe a supervised combinatorial filtering algorithm that systematically and efficiently infers the correct set of key residue positions from all available labeled data. We demonstrate its consistency, validate it on a variety of datasets, show the superior power to conventional identification methods, and describe its use under incremental relaxation of constraints. For cases where more data is needed to fully converge to an answer, we introduce an active learning algorithm to help choose the most informative experiment from a set of unlabeled candidate strains or mutagenesis experiments, so as to minimize the expected total laboratory time or financial cost. As an example, we demonstrate the savings afforded by this algorithm in identifying the molecular determinants of fusogenicity from a previously published dataset of Feline Immunodeficiency Virus Envelope proteins.	active learning (machine learning);algorithm;converge;experiment;information;linear programming relaxation;supervised learning	Chuang Wu;Andrew S. Walsh;Ronald Rosenfeld	2010	2010 IEEE International Conference on BioInformatics and BioEngineering	10.1109/BIBE.2010.25	macromolecule;biology;immune system;convergence;computer science;bioinformatics;virology;active learning;strain;microorganism;silicon;genetics	ML	9.07983906647246	-53.21987577492086	171828
d46eee2dba4154e3a9a823dc9a7c1c835e63345f	identifying biologically active compound classes using phenotypic screening data and sampling statistics	measurement error;false negative;recovery rate;biological activity;time use;false positive;high throughput;structural similarity	Scoring the activity of compounds in phenotypic high-throughput assays presents a unique challenge because of the limited resolution and inherent measurement error of these assays. Techniques that leverage the structural similarity of compounds within an assay can be used to improve the hit-recovery rate from screening data. A technique is presented that uses clustering and sampling statistics to predict likely compound activity by scoring entire structural classes. A set of phenotypic assays performed against a commercially available compound library was used as a test set. Using the class-scoring technique, the resultant activity prediction scores were more reproducible than individual assay measurements, and class scoring recovered known active compounds more efficiently than individual assay measurements because class scoring had fewer false positives. Known biologically active compounds were recovered 87% of the time using class scores, suggesting a low false-negative rate that compared well to individual assay measurements. In addition, many weak and potentially novel classes of active compounds, overlooked by individual assay measurements, were suggested.	activity recognition;chamaecyparis lawsoniana;chemical library;class;cluster analysis;high-throughput computing;resultant;sampling (signal processing);sampling - surgical action;score;structural similarity;test set;thrombocytopenia;throughput;statistical cluster	Justin Klekota;Erik Brauner;Stuart L. Schreiber	2005	Journal of chemical information and modeling	10.1021/ci050087d	high-throughput screening;chemistry;type i and type ii errors;toxicology;computer science;bioinformatics;structural similarity;biological activity;statistics;observational error	Metrics	3.6391896075125296	-54.19904760107437	172246
234bd358ab1ac9e6db6e170ed097079bbb8d7bc3	a new statistical approach to detecting differentially methylated loci for case control illumina array methylation data	female;ovarian neoplasms;middle aged;case control studies;models statistical;dna methylation;humans;computer simulation;oligonucleotide array sequence analysis;aged;aged 80 and over	MOTIVATION As an epigenetic alteration, DNA methylation plays an important role in epigenetic controls of gene transcription. Recent advances in genome-wide scan of DNA methylation provide great opportunities in studying the impact of DNA methylation on many human diseases including various types of cancer. Due to the unique feature of this type of data, applicable statistical methods are limited and new sophisticated approaches are desirable.   RESULTS In this article, we propose a new statistical test to detect differentially methylated loci for case control methylation data generated by Illumina arrays. This new method utilizes the important finding that DNA methylation is highly correlated with age. The proposed method estimates the overall P-value by combining the P-values from independent individual tests each for one age group. Through real data application and simulation study, we show that the proposed test is robust and usually more powerful than other methods.	estimated;protein methylation;sensor;simulation;transcription (software);transcription, genetic;value (computer science);study of epigenetics	Zhongxue Chen;Qingzhong Liu;Saralees Nadarajah	2012	Bioinformatics	10.1093/bioinformatics/bts093	computer simulation;biology;molecular biology;case-control study;bioinformatics;dna methylation;genetics	Comp.	3.629672153868317	-53.36539145033546	172290
4ba0967ffd16303e18aa52f3254ea57afba480cd	genetic algorithm for analysis of mutations in parkinson's disease	mitochondrial dna;parkinson s disease;pattern recognition;genetic algorithm	OBJECTIVE Mitochondrial genetics has unique features that impede analysis of the biological significance of mitochondrial mutations. Simple searches for differences in total mutational load between normal and pathological samples have been frequently unrewarding, raising the possibility that more complex patterns of mutations may be responsible for some conditions. We explore this possibility in the context of Parkinson's disease (PD).   METHODS AND MATERIALS We report the development of a modified genetic algorithm suited for detection of biologically meaningful patterns of mitochondrial mutations. The algorithm is applied to a database of mutations derived from biological samples, and verified by the use of shuffled data, and repeated leave-one-out testing.   RESULTS It is possible to derive, from a very small sample, multiple accurate classifier functions that correlate with biological features. The methodology is validated statistically through experiments with fabricated data.   CONCLUSION This algorithm might be generally applicable to conditions where interactions among multiple mitochondrial DNA mutations are important. The patterns embodied in the classifier functions obtained should be the subject of further experimental study.	database;experiment;genetic algorithm;interaction;mutation;parkinson disease;parkinsonian disorders	Rafal Smigrodzki;Ben Goertzel;Cassio Pennachin;Lúcio de Souza Coelho;Francisco Prosdocimi;W. Davis Parker	2005	Artificial intelligence in medicine	10.1016/j.artmed.2004.11.006	mitochondrial dna;genetic algorithm;computer science;bioinformatics	Comp.	8.394896967613365	-54.66414113293281	172741
b1303da3a8ac086402a651d3ef5200fdb5cdf670	ensemble of rankers for efficient gene signature extraction in smoke exposure classification	feature selection;gene signature;smoking;supervised learning;toxicology	System toxicology aims at understanding the mechanisms used by biological systems to respond to toxicants. Such understanding can be leveraged to assess the risk of chemicals, drugs, and consumer products in living organisms. In system toxicology, machine learning techniques and methodologies are applied to develop prediction models for classification of toxicant exposure of biological systems. Gene expression data (RNA/DNA microarray) are often used to develop such prediction models. The outcome of the present work is an experimental methodology to develop prediction models, based on robust gene signatures, for the classification of cigarette smoke exposure and cessation in humans. It is a result of the participation in the recent sbv IMPROVER SysTox Computational Challenge. By merging different gene selection techniques, we obtain robust gene signatures and we investigate prediction capabilities of different off-the-shelf machine learning techniques, such as artificial neural networks, linear models and support vector machines. We also predict six novel genes in our signature, and firmly believe these genes have to be further investigated as biomarkers for tobacco smoking exposure. The proposed methodology provides gene signatures with top-ranked performances in the prediction of the investigated classification methods, as well as new discoveries in genetic signatures for bio-markers of the smoke exposure of humans.	antivirus software;artificial neural network;biological markers;biological system;british informatics olympiad;computation;dna microarray format;gene expression;linear model;machine learning;organism;performance;rna;support vector machine;tobacco smoke;tobacco smoking behavior;type signature	Maurizio Giordano;Kumar Parijat Tripathi;Mario Rosario Guarracino	2018		10.1186/s12859-018-2035-3	supervised learning;linear model;gene;artificial neural network;feature selection;support vector machine;bioinformatics;toxicant;biology;gene signature	ML	8.733377089232686	-55.68828131745606	172777
53a8f0f9cf433c459baa0b4cd2c4c481446114ae	enriching targeted sequencing experiments for rare disease alleles	rare diseases;rare allele;software;sequencage;alleles;probability;genotype;enfermedad;disease;genome wide association study;sequence analysis dna;alelo raro;target;sequencing;allele rare;genome;blanco;cible;algorithms;humans;base sequence;computational biology;computer simulation;polymorphism single nucleotide;maladie	MOTIVATION Next-generation targeted resequencing of genome-wide association study (GWAS)-associated genomic regions is a common approach for follow-up of indirect association of common alleles. However, it is prohibitively expensive to sequence all the samples from a well-powered GWAS study with sufficient depth of coverage to accurately call rare genotypes. As a result, many studies may use next-generation sequencing for single nucleotide polymorphism (SNP) discovery in a smaller number of samples, with the intent to genotype candidate SNPs with rare alleles captured by resequencing. This approach is reasonable, but may be inefficient for rare alleles if samples are not carefully selected for the resequencing experiment.   RESULTS We have developed a probability-based approach, SampleSeq, to select samples for a targeted resequencing experiment that increases the yield of rare disease alleles substantially over random sampling of cases or controls or sampling based on genotypes at associated SNPs from GWAS data. This technique allows for smaller sample sizes for resequencing experiments, or allows the capture of rarer risk alleles. When following up multiple regions, SampleSeq selects subjects with an even representation of all the regions. SampleSeq also can be used to calculate the sample size needed for the resequencing to increase the chance of successful capture of rare alleles of desired frequencies.   SOFTWARE http://biostat.mc.vanderbilt.edu/SampleSeq	alleles;biopolymer sequencing;dna resequencing;experiment;genome-wide association study;genotype;massively-parallel sequencing;nitroprusside;nucleotides;power (psychology);rare diseases;sample size;sampling (signal processing);sampling - surgical action;single nucleotide polymorphism;single-chain antibodies;small	Todd L. Edwards;Zhuo Song;Chun Li	2011	Bioinformatics	10.1093/bioinformatics/btr324	computer simulation;allele;genome-wide association study;biology;molecular biology;bioinformatics;sequencing;genotype;probability;genetics;genome	Comp.	3.095789187863098	-53.20528705759289	173172
abe4d60801167bbb9614b3a313a564981aa05898	natural similarity measures between position frequency matrices with an application to clustering	gene regulation;frequence;bioinformatique;binding site;similitude;frecuencia;transcription factor;clustering method;similarity;null model;source code;bioinformatica;similitud;frequency;computational biology;similarity measure;bioinformatics;in silico	MOTIVATION Transcription factors (TFs) play a key role in gene regulation by binding to target sequences. In silico prediction of potential binding of a TF to a binding site is a well-studied problem in computational biology. The binding sites for one TF are represented by a position frequency matrix (PFM). The discovery of new PFMs requires the comparison to known PFMs to avoid redundancies. In general, two PFMs are similar if they occur at overlapping positions under a null model. Still, most existing methods compute similarity according to probabilistic distances of the PFMs. Here we propose a natural similarity measure based on the asymptotic covariance between the number of PFM hits incorporating both strands. Furthermore, we introduce a second measure based on the same idea to cluster a set of the Jaspar PFMs.   RESULTS We show that the asymptotic covariance can be efficiently computed by a two dimensional convolution of the score distributions. The asymptotic covariance approach shows strong correlation with simulated data. It outperforms three alternative methods. The Jaspar clustering yields distinct groups of TFs of the same class. Furthermore, a representative PFM is given for each class. In contrast to most other clustering methods, PFMs with low similarity automatically remain singletons.   AVAILABILITY A website to compute the similarity and to perform clustering, the source code and Supplementary Material are available at http://mosta.molgen.mpg.de.	binding sites;cluster analysis;computational biology;convolution;distance;gene expression regulation;hearing loss, high-frequency;matrix metalloproteinases, membrane-associated;medical transcription;null value;null model;similarity measure;source code;transcription factor;web site;statistical cluster	Utz J. Pape;Sven Rahmann;Martin Vingron	2008	Bioinformatics	10.1093/bioinformatics/btm610	biology;regulation of gene expression;null model;similarity;bioinformatics;binding site;similitude;machine learning;frequency;data mining;mathematics;genetics;statistics;source code;transcription factor	Comp.	2.794111688171494	-55.739909101783766	173329
ca67b2f38aefc77af772efeda26098c9deaf7aef	identification of regulatory binding sites on mrna using in vivo derived informations and svms		Proteins able to interact with ribonucleic acids (RNA) are involved in many cellular processes. A detailed knowledge about the binding pairs is necessary to construct computational models which can avoid time consuming biological experiments. This paper addresses the creation of a model based on support vector machines and trained on experimentally validated data. The goal is the identification of RNA molecules binding specifically to a regulatory protein, called CELF1.	gene regulatory network;video-in video-out	Carmen Maria Livi;Luc Paillard;Enrico Blanzieri;Yann Audic	2012		10.1007/978-3-642-28839-5_4	biology;bioinformatics;machine learning;pattern recognition	EDA	8.794285362194271	-58.274903917372015	173640
5eda2e361a18597eefd9899d0c36f03ffffa9e3c	are scale-free networks robust to measurement errors?	least squares analysis;software;measurement error;saccharomyces cerevisiae;robust estimator;proteome;saccharomyces cerevisiae proteins;false negative;mean square;models biological;gold standard;scale free network;random networks;network analysis;computational biology bioinformatics;scale free;false positive rate;yeast two hybrid;reproducibility of results;simulation study;algorithms;neural networks computer;combinatorial libraries;protein interaction;false positive;protein interaction mapping;high throughput;proteomics;computational biology;computer appl in life sciences;computer simulation;biological network;databases protein;microarrays;protein interaction network;bioinformatics;fungal proteins	Many complex random networks have been found to be scale-free. Existing literature on scale-free networks has rarely considered potential false positive and false negative links in the observed networks, especially in biological networks inferred from high-throughput experiments. Therefore, it is important to study the impact of these measurement errors on the topology of the observed networks. This article addresses the impact of erroneous links on network topological inference and explores possible error mechanisms for scale-free networks with an emphasis on Saccharomyces cerevisiae protein interaction networks. We study this issue by both theoretical derivations and simulations. We show that the ignorance of erroneous links in network analysis may lead to biased estimates of the scale parameter and recommend robust estimators in such scenarios. Possible error mechanisms of yeast protein interaction networks are explored by comparisons between real data and simulated data. Our studies show that, in the presence of erroneous links, the connectivity distribution of scale-free networks is still scale-free for the middle range connectivities, but can be greatly distorted for low and high connecitivities. It is more appropriate to use robust estimators such as the least trimmed mean squares estimator to estimate the scale parameter γ under such circumstances. Moreover, we show by simulation studies that the scale-free property is robust to some error mechanisms but untenable to others. The simulation results also suggest that different error mechanisms may be operating in the yeast protein interaction networks produced from different data sources. In the MIPS gold standard protein interaction data, there appears to be a high rate of false negative links, and the false negative and false positive rates are more or less constant across proteins with different connectivities. However, the error mechanism of yeast two-hybrid data may be very different, where the overall false negative rate is low and the false negative rates tend to be higher for links involving proteins with more interacting partners.	addresses (publication format);anatomy, regional;biological network;estimated;experiment;flow network;high-throughput computing;hyperlink;inference;population parameter;simulation;social network analysis;throughput;two-hybrid screening;yeast proteins;protein protein interaction	Nan Lin;Hongyu Zhao	2004	BMC Bioinformatics	10.1186/1471-2105-6-119	computer simulation;biology;computer science;bioinformatics;theoretical computer science;scale-free network;machine learning;proteomics	Metrics	5.435011747672635	-56.56040944711032	174677
3452a9b7f544d213dfef5058d0d7dfecfd8f989d	finite set dsp, with applications to dna sequences	dna;diseases;medical signal processing;tumours;dna sequences;biological problems;finite set dsp;fragile-x mental retardation;promoter analysis;regular substructures;signal processing problems;tumor cells	Regular substructures in DNA sequences are important in a number of biological problems including promoter analysis, the detection of recurring anomalies in tumor cells, and the study of certain genetic diseases like fragile-X mental retardation. This paper considers signal processing problems relevant to the analysis of regular or semi-regular structure in DNA sequences that must address the fundamental issue of working with unordered, finite value sets.	semiconductor industry;signal processing	Ronald K. Pearson;Gregory E. Gonye;Moncef Gabbouj	2004	2004 12th European Signal Processing Conference		biology;bioinformatics;genetics;algorithm	HPC	6.202729499813755	-55.07029738892971	174775
3e00a7c9c1555a07cfbfa04f74c95426bac4a0cd	comparability of gene expression in human blood, immune and carcinoma cells	tissue specificity;computational diagnostics;analisis numerico;expression pattern;matematicas aplicadas;high density;mathematiques appliquees;analisis datos;hombre;clinical diagnosis;gene co regulation;journal;analyse numerique;leukemia;gene expression;data analysis;numerical analysis;immune cell;co expression;human;analyse donnee;microarray;transcriptional profiling;applied mathematics;puce a adn;mrna expression;peripheral blood;central nervous system;lymphoma;homme;microarrays;bioinformatics	The tissue-specific pattern of gene expression can provide important clues for clinical diagnosis and prognosis. Though high-density microarray technology offers the opportunity to examine patterns of mRNA expression on a genomic scale, accessible tissue is still a problem. We conducted secondary data analysis on transcriptional profiles of 79 human tissues using Affymetrix U133a microarrays. We found that expression among tissues belonging to the central nervous system shows distinctly similar patterns. The organ-free immune cells in peripheral blood are more comparable with leukemia/lymphoma at the transcriptome level, and differential co-expression patterns appear between tissue groups of organ-free immune and leukemia/lymphoma cells.		Xinan Yang;Xiao Sun;Jianming Xie;Zuhong Lu	2008	Applied Mathematics and Computation	10.1016/j.amc.2008.05.023	gene expression;dna microarray;numerical analysis;bioinformatics;central nervous system;microarray;mathematics;data analysis	Comp.	5.187986508731712	-53.7231803441311	175261
09764c8aa286c4a7164bce0b8d789eef6624b0f5	multiple network algorithm for epigenetic modules via the integration of genome-wide dna methylation and gene expression data	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	With the increase in the amount of DNA methylation and gene expression data, the epigenetic mechanisms of cancers can be extensively investigate. Available methods integrate the DNA methylation and gene expression data into a network by specifying the anti-correlation between them. However, the correlation between methylation and expression is usually unknown and difficult to determine. To address this issue, we present a novel multiple network framework for epigenetic modules, namely, Epigenetic Module based on Differential Networks (EMDN) algorithm, by simultaneously analyzing DNA methylation and gene expression data. The EMDN algorithm prevents the specification of the correlation between methylation and expression. The accuracy of EMDN algorithm is more efficient than that of modern approaches. On the basis of The Cancer Genome Atlas (TCGA) breast cancer data, we observe that the EMDN algorithm can recognize positively and negatively correlated modules and these modules are significantly more enriched in the known pathways than those obtained by other algorithms. These modules can serve as bio-markers to predict breast cancer subtypes by using methylation profiles, where positively and negatively correlated modules are of equal importance in the classification of cancer subtypes. Epigenetic modules also estimate the survival time of patients, and this factor is critical for cancer therapy. The proposed model and algorithm provide an effective method for the integrative analysis of DNA methylation and gene expression. The algorithm is freely available as an R-package at https://github.com/william0701/EMDN .	british informatics olympiad;dna integration;dna methylation [pe];effective method;gene expression;malignant neoplasms;mammary neoplasms;patients;specification;subtype (attribute);the cancer genome atlas;algorithm;cancer therapy;study of epigenetics	Xiaoke Ma;Zaiyi Liu;Zhongyuan Zhang;Xiao-Tai Huang;Wanxin Tang	2017		10.1186/s12859-017-1490-6	biology;molecular biology;dna microarray;computer science;bioinformatics;genetics	Comp.	6.353253901037213	-56.073783737450334	175623
ce08b380f20fff905193e8d2c0569c09652b42e3	detection of network structure changes by graphical chain modeling: a case study of hepatitis c virus-related hepatocellular carcinoma	graph theory;expression profile;probability;cancer;gene cluster;probability model network structure change detection graphical chain modeling hepatitis c virus hepatocellular carcinoma biological molecular networks cellular environment gene gene relationships path consistency algorithm liver cancer progression gene cluster relationships cell stage progression;resource management;liver diseases gene expression biological system modeling cellular networks clustering algorithms cancer organisms stress genomics bioinformatics;gene expression data;data mining;essential gene;genetics;gene expression;molecular biophysics;liver cancer;model development;clustering algorithms;inference algorithms;network structure;correlation;hepatocellular carcinoma;cellular biophysics;algorithm design and analysis;probability cancer cellular biophysics genetics graph theory molecular biophysics;hepatitis c virus	One of the most characteristic features of biological molecular networks is that the network structure itself changes, depending on the cellular environment. Indeed, activated molecules show a variety of responses to distinctive cell conditions, and subsequently the network structures of active molecules also change. Here we present an approach to trace the network structure changes by using the graphical chain model developed from the gene expression data. The previous procedure for applying the graphical chain model to the expression profiles of a limited number of genes has been improved to analyze the entire set of genes. Furthermore, the chain model has been rearranged according to the association strength, and was scrutinized to identify the candidates of essential gene-gene relationships for the network changes, by using the path consistency algorithm. The improved procedure was applied to the expression profiles of 8,427 genes, which were measured in two distinctive stages of liver cancer progression. As a result, the chain model of the 18 gene cluster relationships with strong associations was inferred, in which the coordination of clusters was described in the cell stage progression, and the gene-gene relationships between known cancer-related genes causing the progression were further refined. Thus, the present procedure is a useful method to model the network structure changes in the cell stage progression, and to clarify the gene candidates for the progression.	algorithm;artificial neural network;color gradient;graphical user interface;local consistency	Shigeru Saito;Masao Honda;Shuichi Kaneko;Katsuhisa Horimoto	2009	Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference	10.1109/CDC.2009.5400061	algorithm design;gene expression;gene cluster;bioinformatics;graph theory;resource management;probability;mathematics;cluster analysis;correlation;cancer;molecular biophysics	Comp.	6.5336967733219105	-57.077964712672156	176055
c3f1a07cb96420416392b429241913ce41df4de2	message-passing algorithms for the prediction of protein domain interactions from protein-protein interaction data	prediccion;proteine;interaction moleculaire;molecular interaction;protein domains;message passing algorithms;bioinformatique;qa 76 software;algorithme;computer programming;algorithm;interaccion molecular;protein protein interaction;proteina;bioinformatica;protein;prediction;bioinformatics;algoritmo	MOTIVATION Cellular processes often hinge upon specific interactions among proteins, and knowledge of these processes at a system level constitutes a major goal of proteomics. In particular, a greater understanding of protein-protein interactions can be gained via a more detailed investigation of the protein domain interactions that mediate the interactions of proteins. Existing high-throughput experimental techniques assay protein-protein interactions, yet they do not provide any direct information on the interactions among domains. Inferences concerning the latter can be made by analysis of the domain composition of a set of proteins and their interaction map. This inference problem is non-trivial, however, due to the high level of noise generally present in experimental data concerning protein-protein interactions. This noise leads to contradictions, i.e. the impossibility of having a pattern of domain interactions compatible with the protein-protein interaction map.   RESULTS We formulate the problem of prediction of protein domain interactions in a form that lends itself to the application of belief propagation, a powerful algorithm for such inference problems, which is based on message passing. The input to our algorithm is an interaction map among a set of proteins, and a set of domain assignments to the relevant proteins. The output is a list of probabilities of interaction between each pair of domains. Our method is able to effectively cope with errors in the protein-protein interaction dataset and systematically resolve contradictions. We applied the method to a dataset concerning the budding yeast Saccharomyces cerevisiae and tested the quality of our predictions by cross-validation on this dataset, by comparison with existing computational predictions, and finally with experimentally available domain interactions. Results compare favourably to those by existing algorithms.   AVAILABILITY A C language implementation of the algorithm is available upon request.	algorithm;belief propagation;cross reactions;cross-validation (statistics);design of experiments;experiment;gain;high-level programming language;high-throughput computing;hinge (physical object);inference;message passing;probability;protein domain;proteomics;saccharomyces cerevisiae;saccharomycetales;silo (dataset);software propagation;throughput;protein protein interaction	Mudassar Iqbal;Alex Alves Freitas;Colin G. Johnson;Massimo Vergassola	2008	Bioinformatics	10.1093/bioinformatics/btn366	prediction;computer science;bioinformatics;artificial intelligence;theoretical computer science;computer programming	Comp.	9.203915393692748	-58.84664005176116	176115
e972129af76371a2b2d63417134cd4b8a3e7242e	improving the performance of an svm-based method for predicting protein-protein interactions		Predicting the interactions between all the possible pairs of proteins in a given organism (making a protein-protein interaction map) is a crucial subject in bioinformatics. Most of the previous methods based on supervised machine learning use datasets containing approximately the same number of interacting pairs of proteins (positives) and non-interacting pairs of proteins (negatives) for training a classifier and are estimated to yield a large number of false positives. Thinking that the negatives used in previous studies cannot adequately represent all the negatives that need to be taken into account, we have developed a method based on multiple Support Vector Machines (SVMs) that uses more negatives than positives for predicting interactions between pairs of yeast proteins and pairs of human proteins. We show that the performance of a single SVM improved as we increased the number of negatives used for training and that, if more than one CPU is available, an approach using multiple SVMs is useful not only for improving the performance of classifiers but also for reducing the time required for training them. Our approach can also be applied to assessing the reliability of high-throughput interactions.		Shinsuke Dohkan;Asako Koike;Toshihisa Takagi	2006	In silico biology		support vector machine;yeast proteins;human proteins;protein–protein interaction;protein-protein interaction map;false positive paradox;machine learning;classifier (linguistics);computer science;pattern recognition;artificial intelligence	Comp.	9.237799897892387	-54.62958294470479	176431
2cfe0efe6940608069797944bad45792de5d7b9e	assessing how multiple mutations affect protein stability using rigid cluster size distributions		Predicting how amino acid substitutions affect the stability of a protein has relevance to drug design and may help elucidate the mechanisms of disease-causing protein variants. Unfortunately, wet-lab experiments are time intensive, and to the best of our knowledge there are no efficient computational techniques to asses the effect of multiple mutations. In this work we present a new approach for inferring the effects of single and multiple mutations on a protein's structure. Our rMutant algorithm generates in silico mutants with single or multiple amino acid substitutions. We use a graph-theoretic rigidity analysis approach to compute the distributions of rigid cluster sizes of the wild type and mutant structures which we then analyze to infer the effect of the amino acid substitutions. We successfully predict the effects of multiple mutations for which our previous methods were unsuccessful. We validate the predictions of our computational approach against experimental ΔΔG data. To demonstrate the utility of using rigid cluster size distributions to infer the effects of mutations, we also present a Random Forest Machine Learning approach that relies on rigidity data to predict which residues are critical to the stability of a protein. We predict the destabilizing effects of a single or multiple mutations with over 86% accuracy.	algorithm;artificial neural network;experiment;graph theory;machine learning;radio frequency;random forest;relevance	Erik Andersson;Rebecca Hsieh;Howard Szeto;Roshanak Farhoodi;Nurit Haspel;Filip Jagodzinski	2016	2016 IEEE 6th International Conference on Computational Advances in Bio and Medical Sciences (ICCABS)	10.1109/ICCABS.2016.7802777	biology;bioinformatics;machine learning;genetics	Comp.	6.412672622188766	-56.806255659161394	176470
6d108cd69d8dcf35933bc2779a9c90e93cf3d784	ab initio tertiary structure prediction of proteins	immunoglobulin;amino acid sequence;first principle;power method;tertiary structure prediction;secondary structure;structure prediction;mathematical model;protein folding;global optimization;three dimensional structure;computational biology;bovine pancreatic trypsin inhibitor	A daunting challenge in the area of computational biology has been to develop a method to theoretically predict the correct three-dimensional structure of a protein given its linear amino acid sequence. The ability to surmount this challenge, which is known as the protein folding problem, has tremendous implications. We introduce a novel ab initio approach for the protein folding problem. The accurate prediction of the three-dimensional structure of a protein relies on both the mathematical model used to mimic the protein system and the technique used to identify the correct structure. The models employed are based solely on first principles, as opposed to the myriad of techniques relying on information from statistical databases. The framework integrates our recently proposed methods for the prediction of secondary structural features including helices and strands, as well as β-sheet and disulfide bridge formation. The final stage of the approach, which culminates in the tertiary structure prediction of a protein, utilizes search techniques grounded on the foundations of deterministic global optimization, powerful methods which can potentially guarantee the correct identification of a protein’s structure. The performance of the approach is illustrated with bovine pancreatic trypsin inhibitor protein and the immunoglobulin binding domain of protein G.	computational biology;deterministic global optimization;mathematical model;mathematical optimization;peptide sequence;protein structure prediction;search algorithm;statistical database	John L. Klepeis;Christodoulos A. Floudas	2003	J. Global Optimization	10.1023/A:1021331514642	protein folding;first principle;power iteration;bioinformatics;loop modeling;protein structure prediction;mathematical model;mathematics;antibody;peptide sequence;protein design;protein secondary structure;global optimization	Comp.	9.127207206467926	-58.71884702206734	176606
4602dc7cf367138ff78b90a2e8467e0955b6e016	prediction of regulatory elements in mammalian genomes using chromatin signatures	animals;ucsd;supervised learning;hidden markov model;regulatory element;computational method;simulated annealing;computational biology bioinformatics;histones;chip;chromatin;promoter regions genetic;human genome;genome;positive predictive value;algorithms;histone modification;humans;cross validation;combinatorial libraries;computational biology;computer appl in life sciences;regulatory sequences nucleic acid;markov chains;microarrays;bioinformatics;cell line	Recent genomic scale survey of epigenetic states in the mammalian genomes has shown that promoters and enhancers are correlated with distinct chromatin signatures, providing a pragmatic way for systematic mapping of these regulatory elements in the genome. With rapid accumulation of chromatin modification profiles in the genome of various organisms and cell types, this chromatin based approach promises to uncover many new regulatory elements, but computational methods to effectively extract information from these datasets are still limited. We present here a supervised learning method to predict promoters and enhancers based on their unique chromatin modification signatures. We trained Hidden Markov models (HMMs) on the histone modification data for known promoters and enhancers, and then used the trained HMMs to identify promoter or enhancer like sequences in the human genome. Using a simulated annealing (SA) procedure, we searched for the most informative combination and the optimal window size of histone marks. Compared with the previous methods, the HMM method can capture the complex patterns of histone modifications particularly from the weak signals. Cross validation and scanning the ENCODE regions showed that our method outperforms the previous profile-based method in mapping promoters and enhancers. We also showed that including more histone marks can further boost the performance of our method. This observation suggests that the HMM is robust and is capable of integrating information from multiple histone marks. To further demonstrate the usefulness of our method, we applied it to analyzing genome wide ChIP-Seq data in three mouse cell lines and correctly predicted active and inactive promoters with positive predictive values of more than 80%. The software is available at http://http:/nash.ucsd.edu/chromatin.tar.gz .	antivirus software;cross reactions;encode;eighty;enhancer of transcription;genome;hidden markov model;histone code;histones;information;mammals;markov chain;physical inactivity;simulated annealing;supervised learning;tree accumulation;type signature;promoter;study of epigenetics	Kyoung-Jae Won;Iouri Chepelev;Bing Ren;Wei Wang	2008	BMC Bioinformatics	10.1186/1471-2105-9-547	biology;chia-pet;molecular biology;computer science;bioinformatics;histone;supervised learning;genetics;hidden markov model	Comp.	3.3153982759013734	-58.92461924610356	176716
587054f4e61724e7d4e4370112aeb7832d5700fc	evaluating clustering algorithms for genetic regulatory network structural inference	gene expression profile;cluster algorithm;structural model;genetic regulatory network;quality measures;gene regulatory network	Modern biological research increasingly recognises the importance of genome-wide gene regulatory network inference; however, a range of statistical, technological and biological factors make it a difficult and intractable problem. One approach that some research has used is to cluster the data and then infer a structural model of the clusters. When using this kind of approach it is very important to choose the clustering algorithm carefully. In this paper we explicitly analyse the attributes that make a clustering algorithm appropriate, and we also consider how to measure the quality of the identified clusters. Our analysis leads us to develop three novel cluster quality measures that are based on regulatory overlap. Using these measures we evaluate two modern candidate algorithms: FLAME, and KMART. Although FLAME was specifically developed for clustering gene expression profile data, we find that KMART is probably a better algorithm to use if the goal is to infer a structural model of the clusters.	gene regulatory network	Christopher Fogelberg;Vasile Palade	2009		10.1007/978-1-84882-983-1_10	bioinformatics;machine learning;data mining	AI	4.2775797962451785	-56.083594432998865	177155
7be7ebd54af20fb46d31e31f0e08dd3bbf164273	a new method of finding groups of coexpressed genes and conditions of coexpression	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	To study a biological phenomenon such as finding mechanism of disease, common methodology is to generate the microarray data in different relevant conditions and find groups of genes co-expressed across conditions from such data. These groups might enable us to find biological processes involved in a disease condition. However, more detailed understanding can be made when information of a biological process associated with a particular condition is obtained from the data. Many algorithms are available which finds groups of co-expressed genes and associated conditions of co-expression that can help finding processes associated with particular condition. However, these algorithms depend on different input parameters for generating groups. For real datasets, it is difficult to use these algorithms due to unknown values of these parameters. We present here an algorithm, clustered groups, which finds groups of co-expressed genes and conditions of co-expression with minimal input from user. We used random datasets to derive a cutoff on the basis of which we filtered the resultant groups and showed that this can improve the relevance of obtained groups. We showed that the proposed algorithm performs better than other known algorithms on both real and synthetic datasets. We have also shown its application on a temporal microarray dataset by extracting biclusters and biological information hidden in those biclusters. Clustered groups is an algorithm which finds groups of co-expressed genes and conditions of co-expression using only a single parameter. We have shown that it works better than other existing algorithms. It can be used to find these groups in different data types such as microarray, proteomics, metabolomics etc.	algorithm;biological processes;metabolomics;microarray;population parameter;proteomics;raynaud phenomenon;relevance;resultant;silo (dataset);synthetic intelligence	Rajat Anand;Srikanth Ravichandran;Samrat Chatterjee	2016		10.1186/s12859-016-1356-3	biology;dna microarray;computer science;bioinformatics;data science;data mining	ML	5.138334987124563	-54.79958209835931	177299
16b753a9fac367e0d1422fe88df50e6b9a309f75	concomitant prediction of function and fold at the domain level with go-based profiles	vocabulary controlled;position specific scoring matrices;molecular sequence annotation;computational biology bioinformatics;proteins;protein structure tertiary;algorithms;protein folding;combinatorial libraries;computational biology;computer appl in life sciences;sequence analysis protein;microarrays;bioinformatics	Predicting the function of newly sequenced proteins is crucial due to the pace at which these raw sequences are being obtained. Almost all resources for predicting protein function assign functional terms to whole chains, and do not distinguish which particular domain is responsible for the allocated function. This is not a limitation of the methodologies themselves but it is due to the fact that in the databases of functional annotations these methods use for transferring functional terms to new proteins, these annotations are done on a whole-chain basis. Nevertheless, domains are the basic evolutionary and often functional units of proteins. In many cases, the domains of a protein chain have distinct molecular functions, independent from each other. For that reason resources with functional annotations at the domain level, as well as methodologies for predicting function for individual domains adapted to these resources are required. We present a methodology for predicting the molecular function of individual domains, based on a previously developed database of functional annotations at the domain level. The approach, which we show outperforms a standard method based on sequence searches in assigning function, concomitantly predicts the structural fold of the domains and can give hints on the functionally important residues associated to the predicted function.	database;protein function prediction;staphylococcal protein a;molecular_function	Daniel Lopez;Florencio Pazos	2013		10.1186/1471-2105-14-S3-S12	protein folding;biology;dna microarray;computer science;bioinformatics;data science;protein function prediction	Comp.	8.556816222894447	-56.49736251234945	177506
b3d6775c7ef576f1f45307c4b565147ef4631443	genome-wide genetic heterogeneity discovery with categorical covariates		Motivation Genetic heterogeneity is the phenomenon that distinct genetic variants may give rise to the same phenotype. The recently introduced algorithm Fast Automatic Interval Search ( FAIS ) enables the genome-wide search of candidate regions for genetic heterogeneity in the form of any contiguous sequence of variants, and achieves high computational efficiency and statistical power. Although FAIS can test all possible genomic regions for association with a phenotype, a key limitation is its inability to correct for confounders such as gender or population structure, which may lead to numerous false-positive associations.   Results We propose FastCMH , a method that overcomes this problem by properly accounting for categorical confounders, while still retaining statistical power and computational efficiency. Experiments comparing FastCMH with FAIS and multiple kinds of burden tests on simulated data, as well as on human and Arabidopsis samples, demonstrate that FastCMH can drastically reduce genomic inflation and discover associations that are missed by standard burden tests.   Availability and Implementation An R package fastcmh is available on CRAN and the source code can be found at: https://www.bsse.ethz.ch/mlcb/research/bioinformatics-and-computational-biology/fastcmh.html.   Contact felipe.llinares@bsse.ethz.ch.   Supplementary information Supplementary data are available at Bioinformatics online.	algorithmic efficiency;bioinformatics;categorical variable;computation;curie;data mining;estimated;exhibits as topic;experiment;genetic heterogeneity;geographic information systems;importal;mental association;microsoft outlook for mac;qt interval feature (observable entity);r language;region of interest;smithkline beecham;source code;structure of parenchyma of lung;benefit	Felipe Llinares-López;Laetitia Papaxanthos;Dean A. Bodenham;Damian Roqueiro;COPDGene Investigators;Karsten M. Borgwardt	2017		10.1093/bioinformatics/btx071	genetic heterogeneity;computer science;genome;categorical variable;bioinformatics;covariate	Comp.	3.5859193039982586	-53.25341328732286	177603
bb38dce6bff8a732d9bf199a106d4280d808c63d	headliners: reproduction: oocyte generation in adult mice	gene expression profile;prognostic marker;lung cancer;common factor;hazard ratio;diagnostic accuracy;meta analysis;tumor markers biological;computational biology bioinformatics;diagnosis computer assisted;microarray analysis;neoplasm proteins;solid tumor;clinical study;algorithms;pattern recognition automated;humans;statistical techniques;support vector machine;meta analysis as topic;neoplasms;combinatorial libraries;computer appl in life sciences;prognosis;information storage and retrieval;gene therapy;databases protein;microarrays;bioinformatics	Although prognostic biomarkers specific for particular cancers have been discovered, microarray analysis of gene expression profiles, supported by integrative analysis algorithms, helps to identify common factors in molecular oncology. Similarities of Ordered Gene Lists (SOGL) is a recently proposed approach to meta-analysis suitable for identifying features shared by two data sets. Here we extend the idea of SOGL to the detection of significant prognostic marker genes from microarrays of multiple data sets. Three data sets for leukemia and the other six for different solid tumors are used to demonstrate our method, using established statistical techniques. We describe a set of significantly similar ordered gene lists, representing outcome comparisons for distinct types of cancer. This kind of similarity could improve the diagnostic accuracies of individual studies when SOGL is incorporated into the support vector machine algorithm. In particular, we investigate the similarities among three ordered gene lists pertaining to mesothelioma survival, prostate recurrence and glioma survival. The similarity-driving genes are related to the outcomes of patients with lung cancer with a hazard ratio of 4.47 (p = 0.035). Many of these genes are involved in breakdown of EMC proteins regulating angiogenesis, and may be used for further research on prognostic markers and molecular targets of gene therapy for cancers. The proposed method and its application show the potential of such meta-analyses in clinical studies of gene expression profiles.		Xinan Yang;Xiao Sun	2005		10.1186/1471-2105-8-118	biology;support vector machine;microarray analysis techniques;meta-analysis;dna microarray;computer science;bioinformatics;data mining;hazard ratio	ML	6.924292091292823	-55.20380484256172	177619
0d8c20e2c6695ce80704eb6a403ae830a5c33a0f	alignment and prediction of cis-regulatory modules based on a probabilistic model of evolution	dna;evolution molecular;prediction method;blastoderm;sequence evolution;cis regulatory module;evolutionary model;transcription factor binding site;invertebrate genomics;transcription factors;sequence analysis dna;binding site;binding sites;gene expression;probabilistic model;models genetic;transcription factor;drosophila melanogaster;evolutionary genetics;sequence motif analysis;protein binding;models statistical;regulatory elements transcriptional;sequence alignment;transcription start site;dna sequence;multiple alignment calculation;evolutionary constraint	Cross-species comparison has emerged as a powerful paradigm for predicting cis-regulatory modules (CRMs) and understanding their evolution. The comparison requires reliable sequence alignment, which remains a challenging task for less conserved noncoding sequences. Furthermore, the existing models of DNA sequence evolution generally do not explicitly treat the special properties of CRM sequences. To address these limitations, we propose a model of CRM evolution that captures different modes of evolution of functional transcription factor binding sites (TFBSs) and the background sequences. A particularly novel aspect of our work is a probabilistic model of gains and losses of TFBSs, a process being recognized as an important part of regulatory sequence evolution. We present a computational framework that uses this model to solve the problems of CRM alignment and prediction. Our alignment method is similar to existing methods of statistical alignment but uses the conserved binding sites to improve alignment. Our CRM prediction method deals with the inherent uncertainties of binding site annotations and sequence alignment in a probabilistic framework. In simulated as well as real data, we demonstrate that our program is able to improve both alignment and prediction of CRM sequences over several state-of-the-art methods. Finally, we used alignments produced by our program to study binding site conservation in genome-wide binding data of key transcription factors in the Drosophila blastoderm, with two intriguing results: (i) the factor-bound sequences are under strong evolutionary constraints even if their neighboring genes are not expressed in the blastoderm and (ii) binding sites in distal bound sequences (relative to transcription start sites) tend to be more conserved than those in proximal regions. Our approach is implemented as software, EMMA (Evolutionary Model-based cis-regulatory Module Analysis), ready to be applied in a broad biological context.	binding sites;biological evolution;blastoderm;carcinoma in situ;circumferential resection margin;computation;customer relationship management;dna binding site;emma;gene regulatory network;ligand binding domain;models of dna evolution;programming paradigm;sequence alignment;statistical model;transcription factor;transcription (software);transcription initiation site	Xin He;Xu Ling;Saurabh Sinha	2009	PLoS Computational Biology	10.1371/journal.pcbi.1000299	biology;multiple sequence alignment;bioinformatics;binding site;sequence analysis;genetics;alignment-free sequence analysis;transcription factor	Comp.	4.318977802806526	-58.860378536388865	177697
689e9228f61c2be32dce3d110b54663cca90031f	classifying next-generation sequencing data using a zero-inflated poisson model		Motivation With the development of high-throughput techniques, RNA-sequencing (RNA-seq) is becoming increasingly popular as an alternative for gene expression analysis, such as RNAs profiling and classification. Identifying which type of diseases a new patient belongs to with RNA-seq data has been recognized as a vital problem in medical research. As RNA-seq data are discrete, statistical methods developed for classifying microarray data cannot be readily applied for RNA-seq data classification. Witten proposed a Poisson linear discriminant analysis (PLDA) to classify the RNA-seq data in 2011. Note, however, that the count datasets are frequently characterized by excess zeros in real RNA-seq or microRNA sequence data (i.e. when the sequence depth is not enough or small RNAs with the length of 18-30 nucleotides). Therefore, it is desired to develop a new model to analyze RNA-seq data with an excess of zeros.   Results In this paper, we propose a Zero-Inflated Poisson Logistic Discriminant Analysis (ZIPLDA) for RNA-seq data with an excess of zeros. The new method assumes that the data are from a mixture of two distributions: one is a point mass at zero, and the other follows a Poisson distribution. We then consider a logistic relation between the probability of observing zeros and the mean of the genes and the sequencing depth in the model. Simulation studies show that the proposed method performs better than, or at least as well as, the existing methods in a wide range of settings. Two real datasets including a breast cancer RNA-seq dataset and a microRNA-seq dataset are also analyzed, and they coincide with the simulation results that our proposed method outperforms the existing competitors.   Availability and implementation The software is available at http://www.math.hkbu.edu.hk/∼tongt.   Contact xwan@comp.hkbu.edu.hk or tongt@hkbu.edu.hk.   Supplementary information Supplementary data are available at Bioinformatics online.		Yan Zhou;Xiang Wan;Baoxue Zhang;Tiejun Tong	2018	Bioinformatics	10.1093/bioinformatics/btx768	data mining;statistics;computer science;zero-inflated model;dna sequencing	Comp.	4.903415064308683	-52.45287751974383	178174
267903fd01949492edfb3ea4fbcd7cd2030e44d0	mitie: simultaneous rna-seq-based transcript identification and quantification in multiple samples	transcription genetic;software;animals;high throughput nucleotide sequencing;internet;rna;drosophila melanogaster;humans;sequence analysis rna	MOTIVATION High-throughput sequencing of mRNA (RNA-Seq) has led to tremendous improvements in the detection of expressed genes and reconstruction of RNA transcripts. However, the extensive dynamic range of gene expression, technical limitations and biases, as well as the observed complexity of the transcriptional landscape, pose profound computational challenges for transcriptome reconstruction.   RESULTS We present the novel framework MITIE (Mixed Integer Transcript IdEntification) for simultaneous transcript reconstruction and quantification. We define a likelihood function based on the negative binomial distribution, use a regularization approach to select a few transcripts collectively explaining the observed read data and show how to find the optimal solution using Mixed Integer Programming. MITIE can (i) take advantage of known transcripts, (ii) reconstruct and quantify transcripts simultaneously in multiple samples, and (iii) resolve the location of multi-mapping reads. It is designed for genome- and assembly-based transcriptome reconstruction. We present an extensive study based on realistic simulated RNA-Seq data. When compared with state-of-the-art approaches, MITIE proves to be significantly more sensitive and overall more accurate. Moreover, MITIE yields substantial performance gains when used with multiple samples. We applied our system to 38 Drosophila melanogaster modENCODE RNA-Seq libraries and estimated the sensitivity of reconstructing omitted transcript annotations and the specificity with respect to annotated transcripts. Our results corroborate that a well-motivated objective paired with appropriate optimization techniques lead to significant improvements over the state-of-the-art in transcriptome reconstruction.   AVAILABILITY MITIE is implemented in C++ and is available from http://bioweb.me/mitie under the GPL license.	algorithmic efficiency;approximation;arabic numeral 0;base sequence;bill zeller;biopolymer sequencing;c++;computation;context-sensitive language;correctness (computer science);deep sequencing;deep vein thrombosis;dynamic range;encode;experiment;fragmented object;futures studies;gene expression;godfried toussaint;graph - visual representation;hearing loss, high-frequency;heart rate variability;heuristic;integer (number);integer programming;large;libraries;linear programming;loss function;manuscripts;mathematical optimization;negative binomial distribution;numerous;optimization problem;preprocessor;quantitation;query priority - deferred;rna splicing;reading (activity);regina;sample variance;scientific publication;sensitivity and specificity;sequence number;solutions;throughput;transcript;transcription, genetic;trinity;funding grant;mixture	Jonas Behr;André Kahles;Yi Zhong;Vipin T. Sreedharan;Philipp Drewe;Gunnar Rätsch	2013		10.1093/bioinformatics/btt442	biology;the internet;rna;bioinformatics;genetics	Comp.	3.6963341698578587	-53.62903287716053	178590
2f2ad934979ce3d3ee0f11e99a796814f5cad75c	network motif discovery using subgraph enumeration and symmetry-breaking	protein protein interaction network;network motif;structure and function;symmetry breaking;system biology;biological network;transcriptional regulatory network	The study of biological networks and network motifs can yield significant new insights into systems biology. Previous methods of discovering network motifs – network-centric subgraph enumeration and sampling – have been limited to motifs of 6 to 8 nodes, revealing only the smallest network components. New methods are necessary to identify larger network sub-structures and functional motifs. Here we present a novel algorithm for discovering large network motifs that achieves these goals, based on a novel symmetry-breaking technique, which eliminates repeated isomorphism testing, leading to an exponential speed-up over previous methods. This technique is made possible by reversing the traditional network-based search at the heart of the algorithm to a motif-based search, which also eliminates the need to store all motifs of a given size and enables parallelization and scaling. Additionally, our method enables us to study the clustering properties of discovered motifs, revealing even larger network elements. We apply this algorithm to the protein-protein interaction network and transcription regulatory network of S. cerevisiae, and discover several large network motifs, which were previously inaccessible to existing methods, including a 29-node cluster of 15-node motifs corresponding to the key transcription machinery of S. cerevisiae.	algorithm;biological network;cluster analysis;image scaling;interaction network;network security;parallel computing;reversing: secrets of reverse engineering;sampling (signal processing);sequence motif;symmetry breaking;systems biology;time complexity;transcription (software)	Joshua A. Grochow;Manolis Kellis	2007		10.1007/978-3-540-71681-5_7	biology;symmetry breaking;biological network;computer science;bioinformatics;network motif;machine learning;data mining;systems biology	Comp.	3.294379200126055	-57.25592016660523	178650
1d832acbf2bd2bedae60d7dad9f5eb0d6cd118d2	a bayesian framework for estimating cell type composition from dna methylation without the need for methylation reference		Genome-wide DNA methylation levels measured from a target tissue across a population have become ubiquitous over the last few years, as methylation status is suggested to hold great potential for better understanding the role of epigenetics. Different cell types are known to have different methylation profiles. Therefore, in the common scenario where methylation levels are collected from heterogeneous sources such as blood, convoluted signals are formed according to the cell type composition of the samples. Knowledge of the cell type proportions is important for statistical analysis, and it may provide novel biological insights and contribute to our understanding of disease biology. Since high resolution cell counting is costly and often logistically impractical to obtain in large studies, targeted methods that are inexpensive and practical for estimating cell proportions are needed. Although a supervised approach has been shown to provide reasonable estimates of cell proportions, this approach leverages scarce reference methylation data from sorted cells which are not available for most tissues and are not appropriate for any target population. Here, we introduce BayesCCE, a Bayesian semi-supervised method that leverages prior knowledge on the cell type composition distribution in the studied tissue. As we demonstrate, such prior information is substantially easier to obtain compared to appropriate reference methylation levels from sorted cells. Using real and simulated data, we show that our proposed method is able to construct a set of components, each corresponding to a single cell type, and together providing up to 50% improvement in correlation when compared with existing reference-free methods. We further make a design suggestion for future data collection efforts by showing that results can be further improved using cell count measurements for a small subset of individuals in the study sample or by incorporating external data of individuals with measured cell counts. Our approach provides a new opportunity to investigate cell compositions in genomic studies of tissues for which it was not possible before.		Elior Rahmani;Regev Schweiger;Liat Shenhav;Eleazar Eskin;Eran Halperin	2017		10.1007/978-3-319-56970-3_13	biology;bioinformatics;genetics	ML	3.8686055005175355	-53.71064178893397	178718
e5189dc42ccaeca62e6bd376b53cbe1748d6a88d	neopepsee: accurate genome-level prediction of neoantigens by harnessing sequence and amino acid immunogenicity information	cancer;classification;immunoinformatics;neoantigen;next-generation sequencing	"""In cancer genomics, next generation sequencing data are usually used to detect somatic driver mutations for identifying the cause of tumorigenesis. However, non-driver somatic mutations, or passenger mutations, can also play an important role in cancer cell survival and treatment by generating aberrant short peptide sequences as known as """"neoantigens"""". Tumor-specific mutations form novel immunogenic peptides called neoantigens, which could be important to the recent promising outcomes of cancer immunotherapy, including immune checkpoint blockade. Many studies have tried to identify various sequence characteristics for prediction of immunogenicity; however, practical applications rely on a single predicted value (MHC-I binding affinity) with an arbitrary cut-off. Here, we developed Neopepsee, a method that applies a machine learning to predict personal neoantigen with next generation sequencing data. Neopepsee not only automates the entire computational procedure for immunogenicity prediction from raw data but also improves accuracy by harnessing 10 different features for classification, including conventional MHC-I and T-cell receptor binding affinity and amino acid characteristics (e.g., hydrophobicity, polarity and charge). Additionally, we found that protein sequence similarity to known pathogenic epitopes is a novel strong feature for classification. Tests with validated epitope datasets and independently proven neoantigens confirmed the remarkable improvement in accuracy. Application of Neopepsee to 224 public stomach adenocarcinoma data predicted neoantigens, whose burden is strongly correlated with patient prognosis. By providing a convenient platform with better accuracy, Neopepsee will be of many uses in cancer immunotherapy research, such as in developing predictive biomarkers and in designing personalized cancer vaccines."""	application checkpointing;machine learning;model of hierarchical complexity;personalization;processor affinity;sequence alignment;transaction processing system	Sora Kim;Han Sang Kim;Sangwoo Kim	2017		10.1145/3107411.3108196	pathology;medicine;computational biology;epitope;immunogenicity;genome;mhc class i;biomarker (medicine);false positive paradox;cancer immunotherapy;major histocompatibility complex	Comp.	8.695246748882035	-56.854955080010065	179084
ed32686132bb52d4939ef846aa4cc26f8a689981	comparison of phylogenetic trees through alignment of embedded evolutionary distances	evolution molecular;high dimensionality;phylogeny;gene transfer horizontal;computational biology bioinformatics;phylogenetic tree;partial correlation;multidimensional scaling;horizontal gene transfer;algorithms;source code;sequence alignment;evolutionary process;combinatorial libraries;protein interaction;computational biology;computer appl in life sciences;multigene family;biological process;microarrays;bioinformatics	The understanding of evolutionary relationships is a fundamental aspect of modern biology, with the phylogenetic tree being a primary tool for describing these associations. However, comparison of trees for the purpose of assessing similarity and the quantification of various biological processes remains a significant challenge. We describe a novel approach for the comparison of phylogenetic distance information based on the alignment of representative high-dimensional embeddings (xCEED: Comparison of Embedded Evolutionary Distances). The xCEED methodology, which utilizes multidimensional scaling and Procrustes-related superimposition approaches, provides the ability to measure the global similarity between trees as well as incongruities between them. We demonstrate the application of this approach to the prediction of coevolving protein interactions and demonstrate its improved performance over the mirrortree, tol-mirrortree, phylogenetic vector projection, and partial correlation approaches. Furthermore, we show its applicability to both the detection of horizontal gene transfer events as well as its potential use in the prediction of interaction specificity between a pair of multigene families. These approaches provide additional tools for the study of phylogenetic trees and associated evolutionary processes. Source code is available at http://gomezlab.bme.unc.edu/tools .	alignment;distance;embedding;gene transfer, horizontal;image scaling;interaction;mental association;multidimensional scaling;multigene family;phylogenetic tree;phylogenetics;quantitation;sensitivity and specificity;source code;trees (plant)	Kwangbom Choi;Shawn M. Gomez	2009		10.1186/1471-2105-10-423	computational biology;biology;phylogenetic tree;dna microarray;multidimensional scaling;computer science;bioinformatics;partial correlation;computational phylogenetics;tree rearrangement;sequence alignment;horizontal gene transfer;biological process;phylogenetics;source code	Comp.	4.123594911307341	-57.1223903853761	179143
9a785992742b473ddf5312893aafb74479bde099	optimal use of biological expert knowledge from literature mining in ant colony optimization for analysis of epistasis in human disease	human disease;ant colony optimization;aco method;optimal use;literature mining;exponential probability distribution function;linear distribution function;biological expert knowledge;mdr package;exhaustive mdr search;interacting dna sequence variation;exponential time;aco parameter;expert knowledge	The fast measurement of millions of sequence variations across the genome is possible with the current technology. As a result, a difficult challenge arise in bioinformatics: the identification of combinations of interacting DNA sequence variations predictive of common disease [1]. The Multifactor Dimensionality Reduction (MDR) method is capable of analysing such interactions but an exhaustive MDR search would require exponential time. Thus, we use the Ant Colony Optimization (ACO) as a stochastic wrapper. It has been shown by Greene et al. that this approach, if expert knowledge is incorporated, is effective for analysing large amounts of genetic variation[2]. In the ACO method integrated in the MDR package, a linear and an exponential probability distribution function can be used to weigh the expert knowledge. We generate our biological expert knowledge from a network of gene-gene interactions produced by a literature mining platform, Pathway Studio. We show that the linear distribution function of expert knowledge is the most appropriate to weigh our scores when expert knowledge from literature mining is used. We find that ACO parameters significantly affect the power of the method and we suggest values for these parameters that can be used to optimize MDR in Genome Wide Association Studies that use biological expert knowledge.	ant colony optimization algorithms;bioinformatics;gene regulatory network;interaction;multifactor dimensionality reduction;stochastic gradient descent;time complexity	Arvis Sulovari;Jeff Kiralis;Jason H. Moore	2013		10.1007/978-3-642-37189-9_12	bioinformatics;artificial intelligence;machine learning;data mining	Comp.	2.8183437945984946	-53.971936246622185	179234
d0b64b3a393065250e33ff9c455260e866a50ea8	multivariate imputation of genotype data using short and long range disequilibrium	bayesian network;decision tree;genetics;genetic marker;machine learning;snps;feature selection;long range;missing data;missing values;decision trees;linkage disequilibrium;imputation;single nucleotide polymorphism;bayesian networks	Missing values in genetic data are a common issue. In this paper we explore several machine learning techniques for creating models that can be used to impute the missing genotypes using multiple genetic markers. We map the machine learning techniques to different patterns of transmission and, in particular, we contrast the effect of short and long range disequilibrium between markers. The assumption of short range disequilibrium implies that only physically close genetic variants are informative for reconstructing missing genotypes, while this assumption is relaxed in long range disequilibrium and physically distant genetic variants become informative for imputation. We evaluate the accuracy of a flexible feature selection model that fits both patterns of transmission using six real datasets of single nucleotide polymorphisms (SNP). The results show an increased accuracy compared to standard imputation models.	geo-imputation	María M. Abad-Grau;Paola Sebastiani	2007		10.1007/978-3-540-75867-9_24	single-nucleotide polymorphism;econometrics;missing data;computer science;imputation;bioinformatics;machine learning;decision tree;bayesian network;feature selection;statistics	Robotics	2.7997827200505663	-52.365437037387025	179235
1bdf6a493fb0e695f0fb2f4e9e3193347ecf7d2a	inferring disease and gene set associations with rank coherence in networks	gene expression profile;optimal solution;ridge regression;efficient algorithm;artificial intelligent;science learning;variational analysis;gene set enrichment analysis;association analysis;high throughput;dna copy number;leave one out cross validation;candidate gene	MOTIVATION To validate the candidate disease genes identified from high-throughput genomic studies, a necessary step is to elucidate the associations between the set of candidate genes and disease phenotypes. The conventional gene set enrichment analysis often fails to reveal associations between disease phenotypes and the gene sets with a short list of poorly annotated genes, because the existing annotations of disease-causative genes are incomplete. This article introduces a network-based computational approach called rcNet to discover the associations between gene sets and disease phenotypes. A learning framework is proposed to maximize the coherence between the predicted phenotype-gene set relations and the known disease phenotype-gene associations. An efficient algorithm coupling ridge regression with label propagation and two variants are designed to find the optimal solution to the objective functions of the learning framework.   RESULTS We evaluated the rcNet algorithms with leave-one-out cross-validation on Online Mendelian Inheritance in Man (OMIM) data and an independent test set of recently discovered disease-gene associations. In the experiments, the rcNet algorithms achieved best overall rankings compared with the baselines. To further validate the reproducibility of the performance, we applied the algorithms to identify the target diseases of novel candidate disease genes obtained from recent studies of Genome-Wide Association Study (GWAS), DNA copy number variation analysis and gene expression profiling. The algorithms ranked the target disease of the candidate genes at the top of the rank list in many cases across all the three case studies.   AVAILABILITY http://compbio.cs.umn.edu/dgsa_rcNet   CONTACT kuang@cs.umn.edu.	candidate disease gene;copy number polymorphism;cross-validation (statistics);dna copy number variations;disease phenotype;experiment;gene expression profiling;gene ontology term enrichment;genome-wide association study;high-throughput computing;mental association;online mendelian inheritance in man;partial;software propagation;test set;throughput;variable rules analysis;algorithm;triangulation	TaeHyun Hwang;Wei Zhang;Maoqiang Xie;Jinfeng Liu;Rui Kuang	2011	Bioinformatics	10.1093/bioinformatics/btr463	high-throughput screening;biology;variational analysis;computer science;bioinformatics;genetic association;data mining;tikhonov regularization;candidate gene;genetics;cross-validation	Comp.	4.094349124884197	-55.65205120720198	179632
62f5fa1f135df3fbb30efcc0da246a6896c3afee	stronger findings for metabolomics through bayesian modeling of multiple peaks and compound correlations	sample size;metabolomics;mass spectrometry;bayes theorem	MOTIVATION Data analysis for metabolomics suffers from uncertainty because of the noisy measurement technology and the small sample size of experiments. Noise and the small sample size lead to a high probability of false findings. Further, individual compounds have natural variation between samples, which in many cases renders them unreliable as biomarkers. However, the levels of similar compounds are typically highly correlated, which is a phenomenon that we model in this work.   RESULTS We propose a hierarchical Bayesian model for inferring differences between groups of samples more accurately in metabolomic studies, where the observed compounds are collinear. We discover that the method decreases the error of weak and non-existent covariate effects, and thereby reduces false-positive findings. To achieve this, the method makes use of the mass spectral peak data by clustering similar peaks into latent compounds, and by further clustering latent compounds into groups that respond in a coherent way to the experimental covariates. We demonstrate the method with three simulated studies and validate it with a metabolomic benchmark dataset.   AVAILABILITY AND IMPLEMENTATION An implementation in R is available at http://research.ics.aalto.fi/mi/software/peakANOVA/.	bayesian network;benchmark (computing);cluster analysis;coherence (physics);experiment;mental suffering;metabolomics;rendering (computer graphics);silo (dataset);statistical cluster	Tommi Suvitaival;Simon Rogers;Samuel Kaski	2014		10.1093/bioinformatics/btu455	sample size determination;biology;econometrics;mass spectrometry;bioinformatics;metabolomics;data mining;mathematics;bayes' theorem;statistics	ML	4.8421342895483805	-53.56578319853775	179806
3a87372b8ce378d49a23d7f4ce1007ff81b8a59a	sparsely correlated hidden markov models with application to genome-wide location studies	transcription genetic;genomics;cd4 positive t lymphocytes;high throughput nucleotide sequencing;histones;chromatin immunoprecipitation;genome;models statistical;algorithms;humans;markov chains	MOTIVATION Multiply correlated datasets have become increasingly common in genome-wide location analysis of regulatory proteins and epigenetic modifications. Their correlation can be directly incorporated into a statistical model to capture underlying biological interactions, but such modeling quickly becomes computationally intractable.   RESULTS We present sparsely correlated hidden Markov models (scHMM), a novel method for performing simultaneous hidden Markov model (HMM) inference for multiple genomic datasets. In scHMM, a single HMM is assumed for each series, but the transition probability in each series depends on not only its own hidden states but also the hidden states of other related series. For each series, scHMM uses penalized regression to select a subset of the other data series and estimate their effects on the odds of each transition in the given series. Following this, hidden states are inferred using a standard forward-backward algorithm, with the transition probabilities adjusted by the model at each position, which helps retain the order of computation close to fitting independent HMMs (iHMM). Hence, scHMM is a collection of inter-dependent non-homogeneous HMMs, capable of giving a close approximation to a fully multivariate HMM fit. A simulation study shows that scHMM achieves comparable sensitivity to the multivariate HMM fit at a much lower computational cost. The method was demonstrated in the joint analysis of 39 histone modifications, CTCF and RNA polymerase II in human CD4+ T cells. scHMM reported fewer high-confidence regions than iHMM in this dataset, but scHMM could recover previously characterized histone modifications in relevant genomic regions better than iHMM. In addition, the resulting combinatorial patterns from scHMM could be better mapped to the 51 states reported by the multivariate HMM method of Ernst and Kellis.   AVAILABILITY The scHMM package can be freely downloaded from http://sourceforge.net/p/schmm/ and is recommended for use in a linux environment.	acth-independent macronodular adrenal hyperplasia;algorithmic efficiency;annotation;approximation;assumed;binding sites;biological science disciplines;closing (morphology);computation;computational complexity theory;converge;count data;ephrin type-b receptor 1, human;expectation–maximization algorithm;forward–backward algorithm;gene ontology term enrichment;hidden markov model;histones;inference;interaction;iterative method;kellis;linux;logistic regression;manuscripts;markov chain;maxima and minima;multiplication;probability;sequence number;silo (dataset);simulation;sourceforge;sparse matrix;statistical model;subgroup;tier 1 network;study of epigenetics	Hyungwon Choi;Damian Fermin;Alexey I. Nesvizhskii;Debashis Ghosh;Zhaohui S. Qin	2013	Bioinformatics	10.1093/bioinformatics/btt012	biology;markov chain;genomics;chromatin immunoprecipitation;bioinformatics;histone;data mining;genetics;statistics;genome	ML	3.534911037127686	-52.58921174894582	179881
09bbc6b2b24117e2cd31ec6fc0e3bd97fca00b02	modularity and community detection in semantic similarity networks trough spectral based transformation and markov clustering	semantic similarity;biological networks;spectral analysis	The availability of biological knowledge, recently encoded in ontologies such as the Gene Ontology, is leading the development of novel methods for the analysis of experimental data that integrate prior information. A recent trend consists in the use of Semantic Similarity Measures (SSMs) to quantify the functional similarity of biological molecules starting from qualitative data (i.e. their functions or localization within cells). A plethora of SSMs and analysis frameworks based on them have been recently proposed. There are, however, several issues in the use of SSMs still to be fully addressed, as well as their assessment with respect to biological features (e.g. is there any correlation between SSMs and biological properties such as sequence similarity?). In this work, after a brief introduction of the main SSMs, we dissect the ongoing assessment efforts.	computer cluster;gene ontology;markov chain monte carlo;ontology (information science);semantic similarity;sequence alignment	Pietro Hiram Guzzi;Marco Mina;Concettina Guerra;Mario Cannataro	2013		10.1145/2506583.2512382	biology;biological network;semantic similarity;computer science;bioinformatics;data mining;information retrieval	ML	4.541555191203906	-56.60615624132865	179897
6dbbadcfc49fd78536e28264a61f17b52856eb00	a computational framework to empower probabilistic protein design	protein design;amino acid sequence;models chemical;structure activity relationship;proteins;models statistical;algorithms;molecular sequence data;computer simulation;protein engineering;mutation;sequence analysis protein	MOTIVATION The task of engineering a protein to perform a target biological function is known as protein design. A commonly used paradigm casts this functional design problem as a structural one, assuming a fixed backbone. In probabilistic protein design, positional amino acid probabilities are used to create a random library of sequences to be simultaneously screened for biological activity. Clearly, certain choices of probability distributions will be more successful in yielding functional sequences. However, since the number of sequences is exponential in protein length, computational optimization of the distribution is difficult.   RESULTS In this paper, we develop a computational framework for probabilistic protein design following the structural paradigm. We formulate the distribution of sequences for a structure using the Boltzmann distribution over their free energies. The corresponding probabilistic graphical model is constructed, and we apply belief propagation (BP) to calculate marginal amino acid probabilities. We test this method on a large structural dataset and demonstrate the superiority of BP over previous methods. Nevertheless, since the results obtained by BP are far from optimal, we thoroughly assess the paradigm using high-quality experimental data. We demonstrate that, for small scale sub-problems, BP attains identical results to those produced by exact inference on the paradigmatic model. However, quantitative analysis shows that the distributions predicted significantly differ from the experimental data. These findings, along with the excellent performance we observed using BP on the smaller problems, suggest potential shortcomings of the paradigm. We conclude with a discussion of how it may be improved in the future.	amino acids;belief propagation;energy, physics;function (biology);functional design;graphical model;inference;internet backbone;marginal model;mathematical optimization;molecular design software;numerical analysis;probability;programming paradigm;projection screen;silo (dataset);small;software propagation;staphylococcal protein a;type conversion;vertebral column;exponential	Menachem Fromer;Chen Yanover	2008		10.1093/bioinformatics/btn168	computer simulation;mutation;biology;structure–activity relationship;computer science;bioinformatics;artificial intelligence;machine learning;mathematics;protein engineering;peptide sequence;genetics;protein design;statistics	Comp.	8.99366862899908	-58.48265136119781	180947
45bf007e38d6dee163f87a2851663573df7530bd	protvec: a continuous distributed representation of biological sequences		We propose a new approach for representing biological sequences. This method, named protein-vectors or ProtVec for short, can be utilized in bioinformatics applications such as family classification, protein visualization, structure prediction, disordered protein identification, and protein-protein interaction prediction. Using the Skip-gram neural networks, protein sequences are represented with a single dense n-dimensional vector. This method was evaluated by classifying protein sequences obtained from Swiss-Prot belonging to 7,027 protein families where an average family classification accuracy of 94%± 0.03% was obtained, outperforming existing family classification methods. In addition, our model was used to predict disordered proteins from structured proteins. Two databases of disordered sequences were used: the DisProt database as well as a database featuring the disordered regions of nucleoporins rich with phenylalanine-glycine repeats (FG-Nups). Using support vector machine classifiers, FG-Nup sequences were distinguished from structured Protein Data Bank (PDB) sequences with 99.81% accuracy, and unstructured DisProt sequences from structured DisProt sequences with 100.0% accuracy. These results indicate that by only providing sequence data for various proteins into this model, information about protein structure can be determined with high accuracy. This so-called embedding model needs to be trained only once and can then be used to ascertain a diverse set of information regarding the proteins of interest. In addition, this representation can be considered as pre-training for various applications of deep learning in bioinformatics. Our Web-based tool and trained data is available at Life Language Processing Website: http://llp.berkeley.edu, and will be regularly updated for calculation/classification of ProtVecs as well as visualization of biological sequences.	artificial neural network;bioinformatics;database;deep learning;disprot;job control (unix);peptide sequence;protein data bank;protein family;swiss-model;support vector machine;switzerland	Ehsaneddin Asgari;Mohammad R. K. Mofrad	2015	CoRR			Comp.	9.904712475848749	-55.70290651587371	181455
067f54525052ec5c5f1ce1a9643dfac045d35895	a new measurement for evaluating clusters in protein interaction networks	proteins biology computing cellular biophysics ontologies artificial intelligence pattern clustering;biology computing;cluster algorithm;functional annotation;protein protein interaction network;pattern clustering;protein function;protein complex;computational method;yeast functional module protein protein interaction network clustering protein complex identification protein functional module identification cellular organization protein function prediction f measure p value hf measure hierarchical consistency hierarchical similarity gene ontology;ontologies artificial intelligence;algorithm;proteins;proteins hafnium organizations biomedical measurements measurement uncertainty protein engineering;clustering;evaluation;evaluation protein protein interaction network clustering algorithm;cellular biophysics;protein interaction network;gene ontology	Clustering of protein-protein interaction networks is one of the most prevalent methods for identifying protein complexes and functional modules, which is crucial to understanding the principles of cellular organization and prediction of protein functions. In the past few years, many computational methods have been proposed. However, it is always a challenging task to evaluate how well the clusters are identified. Even for the most popular measurements, F-measure and Pvalue, bias exists for evaluating the identified clusters. In this paper, we propose a new measurement, named hF-measure, to evaluate clusters more finely and distinctly. First, we defined the hierarchical consistency and the hierarchical similarity. Then, we propose a new hierarchical measurement of hF-measure by taking into account the hierarchical organization of functional annotations and the functional similarities among proteins. The new measurement hF-measure can discriminate between different types of errors which cannot be distinguished by F-measure. The experimental results based on Gene Ontology (GO) and yeast functional modules show that hF-measure evaluates clusters more accurately when compared to F-measure.	algorithm;cellular organizational structure;cluster analysis;computation;f1 score;gene ontology;high-throughput computing;interaction network;throughput	Min Li;Xuehong Wu;Jianxing Wang;Yi Pan	2011	2011 IEEE International Conference on Bioinformatics and Biomedicine	10.1109/BIBM.2011.47	computer science;bioinformatics;evaluation;machine learning;data mining;multiprotein complex;cluster analysis	Comp.	4.664703028641002	-55.58702691883892	181782
54ce134739aa5f4df1880763c08e32a27ca96cc2	incorporating substrate sequence motifs and spatial amino acid composition to identify kinase-specific phosphorylation sites on protein three-dimensional structures	protein structure secondary;support vector machines;phosphorylation;amino acid sequence;computational biology bioinformatics;models molecular;internet;proteins;protein structure tertiary;amino acids;algorithms;combinatorial libraries;computer appl in life sciences;phosphotransferases;databases protein;microarrays;bioinformatics	Protein phosphorylation catalyzed by kinases plays crucial regulatory roles in cellular processes. Given the high-throughput mass spectrometry-based experiments, the desire to annotate the catalytic kinases for in vivo phosphorylation sites has motivated. Thus, a variety of computational methods have been developed for performing a large-scale prediction of kinase-specific phosphorylation sites. However, most of the proposed methods solely rely on the local amino acid sequences surrounding the phosphorylation sites. An increasing number of three-dimensional structures make it possible to physically investigate the structural environment of phosphorylation sites. In this work, all of the experimental phosphorylation sites are mapped to the protein entries of Protein Data Bank by sequence identity. It resulted in a total of 4508 phosphorylation sites containing the protein three-dimensional (3D) structures. To identify phosphorylation sites on protein 3D structures, this work incorporates support vector machines (SVMs) with the information of linear motifs and spatial amino acid composition, which is determined for each kinase group by calculating the relative frequencies of 20 amino acid types within a specific radial distance from central phosphorylated amino acid residue. After the cross-validation evaluation, most of the kinase-specific models trained with the consideration of structural information outperform the models considering only the sequence information. Furthermore, the independent testing set which is not included in training set has demonstrated that the proposed method could provide a comparable performance to other popular tools. The proposed method is shown to be capable of predicting kinase-specific phosphorylation sites on 3D structures and has been implemented as a web server which is freely accessible at http://csb.cse.yzu.edu.tw/PhosK3D/ . Due to the difficulty of identifying the kinase-specific phosphorylation sites with similar sequenced motifs, this work also integrates the 3D structural information to improve the cross classifying specificity.	amino acid sequence;amino acids;classification;computation;cross reactions;cross-validation (statistics);experiment;high-throughput computing;protein data bank;radial (radio);sql;sensitivity and specificity;sequence alignment;sequence motif;server (computer);server (computing);spectrometry;support vector machine;test set;throughput;video-in video-out;web server	Min-Gang Su;Tzong-Yi Lee	2013		10.1186/1471-2105-14-S16-S2	phosphorylation;biology;support vector machine;biochemistry;molecular biology;the internet;dna microarray;computer science;bioinformatics;peptide sequence	Comp.	9.69324357467195	-56.774210588733226	182241
906db9dfc69530939b4431b1fb7dcc46cc5b8f0c	bnarray: an r package for constructing gene regulatory networks from microarray data by using bayesian network	microarray data;bayesian network;regulatory network;directed graph;missing data;dna microarray data;gene regulatory network	UNLABELLED BNArray is a systemized tool developed in R. It facilitates the construction of gene regulatory networks from DNA microarray data by using Bayesian network. Significant sub-modules of regulatory networks with high confidence are reconstructed by using our extended sub-network mining algorithm of directed graphs. BNArray can handle microarray datasets with missing data. To evaluate the statistical features of generated Bayesian networks, re-sampling procedures are utilized to yield collections of candidate 1st-order network sets for mining dense coherent sub-networks.   AVAILABILITY The R package and the supplementary documentation are available at http://www.cls.zju.edu.cn/binfo/BNArray/.	algorithm;bayesian network;coherence (physics);collections (publication);dna microarray format;directed graph;documentation;gene regulatory network;missing data;sampling (signal processing);sampling - surgical action;subnetwork	Xiaohui Chen;Ming Chen;Kaida Ning	2006	Bioinformatics	10.1093/bioinformatics/btl491	biology;microarray analysis techniques;gene regulatory network;gene chip analysis;directed graph;missing data;computer science;bioinformatics;data science;bayesian network;data mining;microarray databases;genetics;statistics	Comp.	5.342954846838762	-55.34728555441957	182274
1440ec00df040bc24b24d9196d506142f8e3a623	learning pair-wise gene functional similarity by multiplex gene expression maps	animals;mice;brain;computational biology bioinformatics;artificial intelligence;algorithms;regression analysis;transcriptome;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	The relationships between the gene functional similarity and gene expression profile, and between gene function annotation and gene sequence have been studied extensively. However, not much work has considered the connection between gene functions and location of a gene's expression in the mammalian tissues. On the other hand, although unsupervised learning methods have been commonly used in functional genomics, supervised learning cannot be directly applied to a set of normal genes without having a target (class) attribute. Here, we propose a supervised learning methodology to predict pair-wise gene functional similarity from multiplex gene expression maps that provide information about the location of gene expression. The features are extracted from expression maps and the labels denote the functional similarities of pairs of genes. We make use of wavelet features, original expression values, difference and average values of neighboring voxels and other features to perform boosting analysis. The experimental results show that with increasing similarities of gene expression maps, the functional similarities are increased too. The model predicts the functional similarities between genes to a certain degree. The weights of the features in the model indicate the features that are more significant for this prediction. By considering pairs of genes, we propose a supervised learning methodology to predict pair-wise gene functional similarity from multiplex gene expression maps. We also explore the relationship between similarities of gene maps and gene functions. By using AdaBoost coupled with our proposed weak classifier we analyze a large-scale gene expression dataset and predict gene functional similarities. We also detect the most significant single voxels and pairs of neighboring voxels and visualize them in the expression map image of a mouse brain. This work is very important for predicting functions of unknown genes. It also has broader applicability since the methodology can be applied to analyze any large-scale dataset without a target attribute and is not restricted to gene expressions.	adaboost;annotation;body tissue;extraction;functional genomics;gene expression profiling;gene expression programming;html attribute;mammals;map;multiplexing;silo (dataset);supervised learning;unsupervised learning;voxel;wavelet;gene function	Li An;Haibin Ling;Zoran Obradovic;Desmond J. Smith;Vasileios Megalooikonomou	2012		10.1186/1471-2105-13-S3-S1	biology;dna microarray;transcriptome;computer science;bioinformatics;machine learning;data mining;gene expression profiling;gene prediction;regression analysis	Comp.	6.34444709391456	-56.24910692763197	182536
1ddfe6a6ae19f0ecdd660520f201299d36f59cce	maximum significance clustering of oligonucleotide microarrays	sample size;high density;oligonucleotide microarray;data analysis;differential expression;linear model	Affymetrix high-density oligonucleotide microarrays measure expression of DNA transcripts using probe sets, i.e. multiple probes per transcript. Usually, these multiple measurements are transformed into a single probeset expression level before data analysis proceeds; any information on variability is lost. In this work we demonstrate how individual probe measurements can be used in a statistic for differential expression. Furthermore, we show how this statistic can serve as a clustering criterion. A novel clustering algorithm using this maximum significance criterion is demonstrated to be more efficient with the measured data than competing techniques for dealing with repeated measurements, especially when the sample size is small.	affymetrix;akaike information criterion;algorithm;cluster analysis;microarray;spatial variability;transcript;statistical cluster	Dick de Ridder;Frank J. T. Staal;Jacques J. M. van Dongen;Marcel J. T. Reinders	2005	2005 IEEE Computational Systems Bioinformatics Conference - Workshops (CSBW'05)	10.1093/bioinformatics/bti788	sample size determination;biology;gene chip analysis;bioinformatics;linear model;data mining;data analysis;statistics	Comp.	4.52733544748088	-52.70975111701295	182548
226b33630ccad152859ad95ef7985a50fd89269a	improving the sensitivity of sample clustering by leveraging gene co-expression networks in variable selection	sample clustering;gene module discovery;gene regulatory networks;computational biology bioinformatics;gene co expression network;leukemia;variable selection;cluster analysis;colonic neoplasms;algorithms;humans;combinatorial libraries;computer appl in life sciences;gene expression profiling;microarrays;bioinformatics	Many variable selection techniques have been proposed for the clustering of gene expression data. While these methods tend to filter out irrelevant genes and identify informative genes that contribute to a clustering solution, they are based on criteria that do not consider the potential interactive influence among individual genes. Motivated by ensemble clustering, there is a strong interest in leveraging the structure of gene networks for gene selection, so that the relationship information between genes can be effectively utilized, while the selected genes are expected to preserve all the possible clustering structures in the data. We present a new filter method that uses the gene connectivity in the gene co-expression network as the evaluation criteria for variable selection. The gene connectivity measures the importance of the genes in term of their expression similarity with others in the co-expression network. The hard threshold and soft threshold transformations are employed to construct the gene co-expression networks. Both simulation studies and real data analysis have shown that the network based on soft thresholding is more effective in selecting relevant variables and provides better clustering results compared to the hard thresholding transformation and two other canonical filter methods for variable selection. Furthermore, a new module analysis approach is proposed to reveal the higher order organization of the gene space, where the genes of a module share significant topological similarity and are associated with a consensus partition of the sample space. We demonstrate that the identified modules can lead to biologically meaningful sample partitions that might be missed by other methods. By leveraging the structure of gene co-expression network, first we propose a variable selection method that selects individual genes with top connectivity. Both simulation studies and real data application have demonstrated that our method has better performance in terms of the reliability of the selected genes and sample clustering results. In addition, we propose a module recovery method that can help discover novel sample partitions that might be hidden when performing clustering analyses using all available genes. The source code of our program is available at http://nba.uth.tmc.edu/homepage/liu/netVar/ .	cluster analysis;feature selection;gene expression;gene regulatory networks;gene co-expression network;gene regulatory network;information;relevance;simulation;source code;thresholding (image processing);cell transformation;statistical cluster	Zixing Wang;F. Anthony San Lucas;Peng Qiu;Yin Liu	2013		10.1186/1471-2105-15-153	biology;gene regulatory network;dna microarray;fuzzy clustering;computer science;bioinformatics;data mining;gene expression profiling;cluster analysis;feature selection;genetics;clustering high-dimensional data	ML	6.361025069341327	-53.10074904300798	183074
4acbde407da696afbfa91f48a82ce7204ee00bc1	large-scale bayesian kinship analysis		Kinship prediction in forensics is limited to first degree relatives due to the small number of short tandem repeat loci characterized. The Genetic Chain Rule for Probabilistic Kinship Estimation can leverage large panels of single nucleotide polymorphisms (SNPs) or sets of sequence linked SNPs, called haploblocks, to estimate more distant relationships between individuals. This method uses allele frequencies and Markov Chain Monte Carlo methods to determine kinship probabilities. Allele frequencies are a crucial input to this method. Since these frequencies are estimated from finite populations and many alleles are rare, a Bayesian extension to the algorithm has been developed to determine credible intervals for kinship estimates as a function of the certainty in allele frequency estimates. Generation of sufficiently large samples to accurately estimate credible intervals can take significant computational resources. In this paper, we leverage hundreds of compute cores to generate large numbers of Dirichlet random samples for Bayesian kinship prediction. We show that it is possible to generate 2,097,152 random samples on 32,768 cores at a rate of 29.68 samples per second. The ability to generate extremely large number of samples enables the computation of more statistically significant results from a Bayesian approach to kinship analysis.		Siddharth Samsi;Bea Yu;Darrell O. Ricke;Philip Fremont-Smith;Jeremy Kepner;Albert Reuther	2018	2018 IEEE High Performance extreme Computing Conference (HPEC)	10.1109/HPEC.2018.8547549		HPC	3.2314115011917988	-52.18789739657445	183592
5337e04560b12d698f1a22c28032cc04b34e0fe6	correlation networks: biologically driven relationships from gene expression data	—bioinformatics;biology;co-expression;coregulation;correlation networks;gene expression;graph theory;neo4j;non-relational databases;transcriptomics	Genes that share transcription factors are biologically driven to show a more likely measurable correlation in their gene expression. No modern method of visualization displays these intricate co-expression and correlation patterns better than a graph. Structural observations about a co-expression graph can reveal the secrets of the biological system that it models, but experimentally validated co-expression graphs are pain-staking work to produce. Present day correlation network analysis shows potential for drawing conclusions from large volumes of biological systems data in an inexpensive and easy-to-produce way; however, work remains to confirm the appropriateness and scope of such methods for specific, scientific application. Toward this effort, we generated a Pearson correlation network from gene expression data available to the public from the National Center for Biotechnology Information's Gene Expression Omnibus repository. From this dataset, we predicted shared transcription factor regulation among cliques of genes sharing upstream genomic motifs. Finally, our predictions, and thus the model itself, was contrasted against experimentally confirmed gene co-regulation data. Our process tested the hypothesis that the incorporation of correlation networks can enhance the prediction of transcription factor co-regulation from gene expression and upstream sequence data. Ultimately, our experimental results did not show a larger portion of true positive results when compared to a randomized control. These initial results indicate that correlation networks may not be an appropriate outlet for detecting co-expression motifs. Work remains to see if correlation networks can be constructed and normalized in a way that brings them closer to representing true co-expression.	biological system;experiment;gene co-expression network;norm (social);randomized algorithm;sensor;transcription (software)	Grogan W. Huff;Kathryn Cooper	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217918	pearson product-moment correlation coefficient;computer science;bioinformatics;gene expression;gene;graph theory;genomics;transcriptome;normalization (statistics);transcription factor	Comp.	4.517882859041394	-56.93604544126387	183662
4d7afae2ba323350f8743294431f82789f6faa27	druglogit: logistic discrimination between drugs and nondrugs including disease-specificity by assigning probabilities based on molecular properties		The increasing knowledge of both structure and activity of compounds provides a good basis for enhancing the pharmacological characterization of chemical libraries. In addition, pharmacology can be seen as incorporating both advances from molecular biology as well as chemical sciences, with innovative insight provided from studying target-ligand data from a ligand molecular point of view. Predictions and profiling of libraries of drug candidates have previously focused mainly on certain cases of oral bioavailability. Inclusion of other administration routes and disease-specificity would improve the precision of drug profiling. In this work, recent data are extended, and a probability-based approach is introduced for quantitative and gradual classification of compounds into categories of drugs/nondrugs, as well as for disease- or organ-specificity. Using experimental data of over 1067 compounds and multivariate logistic regressions, the classification shows good performance in training and independent test cases. The regressions have high statistical significance in terms of the robustness of coefficients and 95% confidence intervals provided by a 1000-fold bootstrapping resampling. Besides their good predictive power, the classification functions remain chemically interpretable, containing only one to five variables in total, and the physicochemical terms involved can be easily calculated. The present approach is useful for an improved description and filtering of compound libraries. It can also be applied sequentially or in combinations of filters, as well as adapted to particular use cases. The scores and equations may be able to suggest possible routes for compound or library modification. The data is made available for reuse by others, and the equations are freely accessible at http://hermes.chem.ut.ee/~alfx/druglogit.html.	bootstrapping;categories;chemical library;coefficient;confidence intervals;data interpretation, statistical;disease regression;filter (signal processing);ligands;molecular biology;pharmacology;probability;profiling (computer programming);reuse (action);science;sensitivity and specificity;small molecule libraries;test case	Alfonso T. García-Sosa;Mare Oja;Csaba Hetényi;Uko Maran	2012	Journal of chemical information and modeling	10.1021/ci200587h	pharmacology;chemistry;toxicology;bioinformatics	Comp.	7.776871438387874	-54.60222112175178	183854
7dce9d3dd76188d57b394ae4923b5200bc01594e	an image score inference system for rnai genome-wide screening based on fuzzy mixture regression modeling	rna interference;animals;genomics;image segmentation;fluorescence imaging;databases genetic;regression model;image processing computer assisted;support vector;fuzzy logic;models genetic;drosophila;cells cultured;fluorescence microscopy;model integration;genome;microscopy fluorescence;reproducibility of results;robust method;algorithms;image analysis;regression analysis;pattern recognition automated;ground truth;high content screening;phenotype;gene function;information storage and retrieval;quantitative evaluation;gene knockdown techniques;image score inference;scoring system;biological process	With recent advances in fluorescence microscopy imaging techniques and methods of gene knock down by RNA interference (RNAi), genome-scale high-content screening (HCS) has emerged as a powerful approach to systematically identify all parts of complex biological processes. However, a critical barrier preventing fulfillment of the success is the lack of efficient and robust methods for automating RNAi image analysis and quantitative evaluation of the gene knock down effects on huge volume of HCS data. Facing such opportunities and challenges, we have started investigation of automatic methods towards the development of a fully automatic RNAi-HCS system. Particularly important are reliable approaches to cellular phenotype classification and image-based gene function estimation. We have developed a HCS analysis platform that consists of two main components: fluorescence image analysis and image scoring. For image analysis, we used a two-step enhanced watershed method to extract cellular boundaries from HCS images. Segmented cells were classified into several predefined phenotypes based on morphological and appearance features. Using statistical characteristics of the identified phenotypes as a quantitative description of the image, a score is generated that reflects gene function. Our scoring model integrates fuzzy gene class estimation and single regression models. The final functional score of an image was derived using the weighted combination of the inference from several support vector-based regression models. We validated our phenotype classification method and scoring system on our cellular phenotype and gene database with expert ground truth labeling. We built a database of high-content, 3-channel, fluorescence microscopy images of Drosophila Kc(167) cultured cells that were treated with RNAi to perturb gene function. The proposed informatics system for microscopy image analysis is tested on this database. Both of the two main components, automated phenotype classification and image scoring system, were evaluated. The robustness and efficiency of our system were validated in quantitatively predicting the biological relevance of genes.	biological processes;classification;functional genomics;ground truth;hcs clustering algorithm;image analysis;imaging techniques;inference engine;informatics (discipline);interference (communication);microscopy, fluorescence;phenotype;rna interference;relevance;satisfaction;score;watershed (image processing)	Jun Wang;Xiaobo Zhou;Fuhai Li;Pamela Bradley;Shih-Fu Chang;Norbert Perrimon;Stephen T. C. Wong	2009	Journal of biomedical informatics	10.1016/j.jbi.2008.04.007	computer vision;genomics;image analysis;computer science;bioinformatics;machine learning;data mining;genetics;regression analysis	Comp.	7.325689746607947	-56.31958872585378	184222
2a5f9095b94732bdd65edc9d7fb3781ddaa14494	protein complex prediction in large ontology attributed protein-protein interaction networks	topology;go annotation information;cellular function;ppi networks;prediction algorithms;topological structure;cso approach;proteins;clustering;protein complex prediction topology cellular biophysics proteins proteomics cso approach protein complex prediction large ontology attributed protein protein interaction networks cellular organization cellular function ppi networks topological structure gene ontology go annotation information proteins ontologies prediction algorithms correlation bioinformatics computational biology protein protein interaction clustering gene ontology;cellular organization;proteins ontologies prediction algorithms correlation bioinformatics computational biology;large ontology attributed protein protein interaction networks;protein protein interaction;ontologies;correlation;proteomics;computational biology;cso approach protein complex prediction large ontology attributed protein protein interaction networks cellular organization cellular function ppi networks topological structure gene ontology go annotation information;protein complex prediction;cellular biophysics;bioinformatics;gene ontology;topology cellular biophysics proteins proteomics	Protein complexes are important for unraveling the secrets of cellular organization and function. Many computational approaches have been developed to predict protein complexes in protein-protein interaction (PPI) networks. However, most existing approaches focus mainly on the topological structure of PPI networks, and largely ignore the gene ontology (GO) annotation information. In this paper, we constructed ontology attributed PPI networks with PPI data and GO resource. After constructing ontology attributed networks, we proposed a novel approach called CSO (clustering based on network structure and ontology attribute similarity). Structural information and GO attribute information are complementary in ontology attributed networks. CSO can effectively take advantage of the correlation between frequent GO annotation sets and the dense subgraph for protein complex prediction. Our proposed CSO approach was applied to four different yeast PPI data sets and predicted many well-known protein complexes. The experimental results showed that CSO was valuable in predicting protein complexes and achieved state-of-the-art performance.	algorithm;annotation;cellular organizational structure;chief security officer;cluster analysis;common scientific outline nci;dense subgraph;dual in-line package;gene ontology;hypothetical protein;mass effect trilogy;pixel density;protein complex;proton pump inhibitors;sparse matrix;protein protein interaction;statistical cluster	Yijia Zhang;Hongfei Lin;Zhihao Yang;Jian Wang;Yanpeng Li;Bo Xu	2013	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2013.86	protein–protein interaction;biology;prediction;computer science;bioinformatics;ontology;machine learning;data mining;mathematics;cluster analysis;proteomics;correlation	Comp.	4.965830739942553	-56.435241071	184911
133fe4af99f98cf8ca2e636309aa30587e610c31	an efficient algorithm to explore liquid association on a genome-wide scale	data interpretation statistical;saccharomyces cerevisiae;genome fungal;saccharomyces cerevisiae proteins;coexpression pattern;computational biology bioinformatics;gene expression;liquid association;algorithms;cell cycle;genome wide search;combinatorial libraries;computer appl in life sciences;gene expression profiling;microarrays;bioinformatics;cell cycle proteins	The growing wealth of public available gene expression data has made the systemic studies of how genes interact in a cell become more feasible. Liquid association (LA) describes the extent to which coexpression of two genes may vary based on the expression level of a third gene (the controller gene). However, genome-wide application has been difficult and resource-intensive. We propose a new screening algorithm for more efficient processing of LA estimation on a genome-wide scale and apply its use to a Saccharomyces cerevisiae data set. On a test subset of the data, the fast screening algorithm achieved >99.8% agreement with the exhaustive search of LA values, while reduced run time by 81-93 %. Using a well-known yeast cell-cycle data set with 6,178 genes, we identified triplet combinations with significantly large LA values. In an exploratory gene set enrichment analysis, the top terms for the controller genes in these triplets with large LA values are involved in some of the most fundamental processes in yeast such as energy regulation, transportation, and sporulation. In summary, in this paper we propose a novel, efficient algorithm to explore LA on a genome-wide scale and identified triplets of interest in cell cycle pathways using the proposed method in a yeast data set. A software package named fastLiquidAssociation for implementing the algorithm is available through http://www.bioconductor.org .	algorithm;brute-force search;controllers;gene ontology term enrichment;gene expression profiling;name;run time (program lifecycle phase);subgroup;triplet state;sporulation	Tina Gunderson;Yen-Yi Ho	2014		10.1186/s12859-014-0371-5	biology;gene expression;dna microarray;biotechnology;bioinformatics;cell cycle;gene expression profiling;genetics	Comp.	2.9401365945715576	-56.47605954627003	185165
5ab84c0d4d19499d3db18b4ebb671850322467c8	a novel algorithm for the analysis of array cgh data	dna;genomics;cancer;array cgh;edge detection;multiscale edge detection algorithm;testing;cloning;genetics;algorithm design and analysis dna genomics bioinformatics cloning testing cancer image edge detection biological cells diseases;biological cells;dna copy number aberrations;image edge detection;chromosomal locations;medical image processing;medical image processing cancer cellular biophysics dna edge detection genetics;diseases;biological data;comparative genomic hybridization array dna copy number aberrations chromosomal locations multiscale edge detection algorithm array cgh biological data;dna copy number;array cgh biological data;cellular biophysics;algorithm design and analysis;comparative genomic hybridization array;bioinformatics	DNA copy number aberrations are common in cancer and other diseases. Newly developed array CGH technologies enable simultaneous measurement of DNA copy numbers for tens of thousands of sites within a genome. In array CGH experiments, DNA copy number of a test DNA sample relative to the DNA copy number of a reference DNA sample is measured. These relative measurements are mapped to their corresponding chromosomal locations. DNA copy gains and losses are then detected as deviations from the normal reference at specific chromosomal locations. In this paper, we introduce a novel algorithm to automatically identify the regions of DNA copy number gain and loss from array CGH data through a multi-scale edge detection algorithm. We demonstrate the method on two array CGH datasets. Our results show that this method can be successfully applied for the analysis of array CGH biological data	algorithm;automatic identification and data capture;breakpoint;computer-generated holography;dna microarray;edge detection;experiment;information privacy;self-replicating machine;single molecule real time sequencing	Mehrnoush Khojasteh;Bradley P. Coe;Sohrab P. Shah;Rabab Kreidieh Ward;Wan L. Lam;Calum MacAulay	2006	2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings	10.1109/ICASSP.2006.1660519	algorithm design;genomics;edge detection;biological data;copy number analysis;computer science;bioinformatics;cloning;software testing;dna;cancer	Visualization	3.2972993790678293	-54.08157050628482	185254
04608c602703925257558e2feaf20a1d85bd7629	on selecting the best pre-processing method for affymetrix genechips	data distribution;gene expression;high throughput;correlation coefficient	Affymetrix High Oligonucleotide expression arrays, also known as Affymetrix GeneChips, are widely used for the high-throughput assessment of gene expression of thousands of genes simultaneously. Although disputed by several authors, there are non-biological variations and systematic biases that must be removed as much as possible before an absolute expression level for every gene is assessed. Several pre-processing methods are available in the literature and five common ones (RMA, GCRMA, MAS5, dChip and VSN) and two customized Loess methods are benchmarked in terms of data variability, similarity of data distributions and correlation coefficient among replicated slides in a variety of real examples. Besides, it will be checked how the variant and invariant genes can influence on preprocessing performance.	coefficient;dna microarray;heart rate variability;high-throughput computing;preprocessor;revolution in military affairs;throughput;usability testing	J. P. Florido;Héctor Pomares;Ignacio Rojas;José C. Calvo;José M. Urquiza;M. Gonzalo Claros	2009		10.1007/978-3-642-02478-8_106	high-throughput screening;gene expression;bioinformatics;data mining	Comp.	4.720064690616611	-52.89164082249611	185995
0b37bd2904d3d089d62914c84f3aef3f2769b49d	prediction of a gene regulatory network linked to prostate cancer from gene expression, microrna and clinical data	clinical data;cell lines;disease;systems biology;gene regulatory networks;male;progression;gene expression;prostatic neoplasms;mortality;proliferation;gene expression regulation neoplastic;cell line tumor;foxm1;module networks;algorithms;medicine and health sciences;humans;micrornas;gene regulatory network;microrna;gene expression profiling;aged;prostate cancer	MOTIVATION Cancer is a complex disease, triggered by mutations in multiple genes and pathways. There is a growing interest in the application of systems biology approaches to analyze various types of cancer-related data to understand the overwhelming complexity of changes induced by the disease.   RESULTS We reconstructed a regulatory module network using gene expression, microRNA expression and a clinical parameter, all measured in lymphoblastoid cell lines derived from patients having aggressive or non-aggressive forms of prostate cancer. Our analysis identified several modules enriched in cell cycle-related genes as well as novel functional categories that might be linked to prostate cancer. Almost one-third of the regulators predicted to control the expression levels of the modules are microRNAs. Several of them have already been characterized as causal in various diseases, including cancer. We also predicted novel microRNAs that have never been associated to this type of tumor. Furthermore, the condition-dependent expression of several modules could be linked to the value of a clinical parameter characterizing the aggressiveness of the prostate cancer. Taken together, our results help to shed light on the consequences of aggressive and non-aggressive forms of prostate cancer.   AVAILABILITY The complete regulatory network is available as an interactive supplementary web site at the following URL: http://bioinformatics.psb.ugent.be/webtools/pronet/.	bioinformatics;bioinformatics;body tissue;categories;causal filter;cell (microprocessor);cell cycle;cultured cell line;gene expression;gene ontology term enrichment;gene regulatory network;genes, vif;genetic heterogeneity;gleason's theorem;micrornas;mitosis;mutation;patients;personality disorders;population parameter;preparation;prostatic neoplasms;sap business one;score;silo (dataset);systems biology;uniform resource locator;web site;algorithm;cell growth	Eric Bonnet;Tom Michoel;Yves Van de Peer	2010		10.1093/bioinformatics/btq395	biology;gene regulatory network;bioinformatics;genetics;systems biology;microrna	Comp.	5.399427469479216	-57.99651773778029	186300
369a6e7ce9a3c320af1a8a726c6c940d9ae44cf7	feature generation and analysis applied to sequence classification for splice-site prediction	college park lise getoor islamaj;computer science feature generation and analysis applied to sequence classification for splice site prediction university of maryland;rezarta;dissertation;bioinformatics	"""Sequence classification is an important problem in many real-world applications. Sequence data often contain no explicit """"signals,"""" or features, to enable the construction of classification algorithms. Extracting and interpreting the most useful features is challenging, and hand construction of good features is the basis of many classification algorithms. In this thesis, I address this problem by developing a feature-generation algorithm (FGA). FGA is a scalable method for automatic feature generation for sequences; it identifies sequence components and uses domain knowledge, systematically constructs features, explores the space of possible features, and identifies the most useful ones. #R##N#In the domain of biological sequences, splice-sites are locations in DNA sequences that signal the boundaries between genetic information and intervening non-coding regions. Only when splice-sites are identified with nucleotide precision can the genetic information be translated to produce functional proteins. In this thesis, I address this fundamental process by developing a highly accurate splice-site prediction model that employs our sequence feature-generation framework. The FGA model shows statistically significant improvements over state-of-the-art splice-site prediction methods. #R##N#So that biologists can understand and interpret the features FGA constructs, I developed SplicePort, a web-based tool for splice-site prediction and analysis. With SplicePort the user can explore the relevant features for splicing, and can obtain splice-site predictions for the sequences based on these features. For an experimental biologist trying to identify the critical sequence elements of splicing, SplicePort offers flexibility and a rich motif exploration functionality, which may help to significantly reduce the amount of experimentation needed. In this thesis, I present examples of the observed feature groups and describe efforts to detect biological signals that may be important for the splicing process. #R##N#Naturally, FGA can be generalized to other biologically inspired classification problems, such as tissue-specific regulatory elements, polyadenylation sites, promoters, as well as other sequence classification problems, provided we have sufficient knowledge of the new domain."""	gene prediction;splice (system call)	Rezarta Islamaj Dogan	2007			bioinformatics;engineering;data science;data mining	NLP	2.8495688589751524	-57.82930129205808	186866
5c9414522c98c273e5bd4a289c06b17b389d8e8f	gads software for parametric linkage analysis of quantitative traits distributed as a point-mass mixture	quantitative traits;point mass mixture;distribution with spike;segregation analysis;large pedigree;parametric linkage;elston stewart algorithm	Often the quantitative data coming from proteomics and metabolomics studies have irregular distribution with a spike. None of the wide used methods for human QTL mapping are applicable to such traits. Researchers have to reduce the sample, excluding the spike, and analyze only continuous measurements. In this study, we propose a method for the parametric linkage analysis of traits with a spike in the distribution, and a software GADS, which implements this method. Our software includes not only the programs for parametric linkage analysis, but also the program for complex segregation analysis, which allows the estimation of the model parameters used in linkage. We tested our method on the real data about vertical cup-to-disc ratio, the important characteristic of the optic disc associated with glaucoma, in a large pedigree from a Dutch isolated population. Significant linkage signal was identified on chromosome 6 with the help of GADS, whereas the analysis of the normal distributed part of the sample demonstrated only a suggestive linkage peak on this chromosome. The software GADS is freely available at http://mga.bionet.nsc.ru/soft/index.html.	chromosomes, human, pair 6;decision support system;eaf2 gene;eye;generalized anxiety disorder;glaucoma;linkage (software);metabolomics;optic disk;proteomics;quantitative trait loci;the spike (1997);genetic linkage	Tatiana I. Axenovich;Irina V. Zorkoltseva	2012	Computational biology and chemistry	10.1016/j.compbiolchem.2011.11.004	biology;econometrics;bioinformatics;genetics;quantitative trait locus;statistics	Comp.	4.123090738830316	-53.14808248623487	187394
0e63e4722652912c53fe62e5419251c88761ab74	adhdgene: a genetic database for attention deficit hyperactivity disorder	genome wide association study;databases genetic;chromosome mapping;attention deficit disorder with hyperactivity;developmental psychology medical psychology;humans;linkage disequilibrium	With a worldwide prevalence of ~5%, attention deficit hyperactivity disorder (ADHD) has become one of the most common psychiatric disorders. The polygenetic nature of ADHD indicates that multiple genes jointly contribute to the development of this complex disease. Studies aiming to explore genetic susceptibility of ADHD have been increasing in recent years. There is a growing need to integrate the genetic data from various genetic studies to provide a comprehensive data set and uniform access for convenience of in-depth data mining. So far, there has been no such effort for ADHD. To address the genetic complexity of ADHD, we developed the ADHDgene database by integrating ADHD-related genetic factors by profound literature reading. Based on the data from the literature, extended functional analysis, including linkage disequilibrium analysis, pathway-based analysis and gene mapping were performed to provide new insights into genetic causes of ADHD. Moreover, powerful search tools and a graphical browser were developed to facilitate the navigation of the data and data connections. As the first genetic database for ADHD, ADHDgene aims to provide researchers with a central genetic resource and analysis platform for ADHD and is freely available at http://adhd.psych.ac.cn/.	attention deficit hyperactivity disorder;chromosome mapping;data mining;gene expression programming;gene regulatory network;genetic predisposition to disease;graphical user interface;hereditary diseases;hyperactive behavior;linkage (software);mental disorders;national dna database	Liuyan Zhang;Suhua Chang;Zhao Li;Kunlin Zhang;Yang Du;Jürg Ott;Jing Wang	2012		10.1093/nar/gkr992	genome-wide association study;linkage disequilibrium;biology;bioinformatics;genetics	Comp.	3.48884940481821	-56.33055548029932	187545
015ececae71183e679e7c4f275698167ab1a2a5e	rots: an r package for reproducibility-optimized statistical testing	test statistics;rna sequencing;gene expression;principal component analysis;data reduction;proteomic databases;microarrays;reproducibility	Differential expression analysis is one of the most common types of analyses performed on various biological data (e.g. RNA-seq or mass spectrometry proteomics). It is the process that detects features, such as genes or proteins, showing statistically significant differences between the sample groups under comparison. A major challenge in the analysis is the choice of an appropriate test statistic, as different statistics have been shown to perform well in different datasets. To this end, the reproducibility-optimized test statistic (ROTS) adjusts a modified t-statistic according to the inherent properties of the data and provides a ranking of the features based on their statistical evidence for differential expression between two groups. ROTS has already been successfully applied in a range of different studies from transcriptomics to proteomics, showing competitive performance against other state-of-the-art methods. To promote its widespread use, we introduce here a Bioconductor R package for performing ROTS analysis conveniently on different types of omics data. To illustrate the benefits of ROTS in various applications, we present three case studies, involving proteomics and RNA-seq data from public repositories, including both bulk and single cell data. The package is freely available from Bioconductor (https://www.bioconductor.org/packages/ROTS).	bioconductor;omics;proteomics;repository;sequence number;spectrometry;statistic (data);benefit	Tomi Suomi;Fatemeh Seyednasrollah;Maria K. Jaakkola;Thomas Faux;Laura L. Elo	2017		10.1371/journal.pcbi.1005562	biology;statistical hypothesis testing;data reduction;gene expression;dna microarray;rna-seq;computer science;bioinformatics;data science;reproducibility;data mining;statistics;principal component analysis	Comp.	5.1418912357450886	-52.65631025369599	188172
e4b0a26ef277eb83a51463edb005bbc417b0f788	effects of normalization on quantitative traits in association test	quantitative trait loci;sample size;small sample size;normal distribution;genetic effect;genetic variation;association study;computational biology bioinformatics;false positive rate;polymorphism;algorithms;combinatorial libraries;computational biology;computer appl in life sciences;polymorphism single nucleotide;quantitative trait;microarrays;bioinformatics	Quantitative trait loci analysis assumes that the trait is normally distributed. In reality, this is often not observed and one strategy is to transform the trait. However, it is not clear how much normality is required and which transformation works best in association studies. We performed simulations on four types of common quantitative traits to evaluate the effects of normalization using the logarithm, Box-Cox, and rank-based transformations. The impact of sample size and genetic effects on normalization is also investigated. Our results show that rank-based transformation gives generally the best and consistent performance in identifying the causal polymorphism and ranking it highly in association tests, with a slight increase in false positive rate. For small sample size or genetic effects, the improvement in sensitivity for rank transformation outweighs the slight increase in false positive rate. However, for large sample size and genetic effects, normalization may not be necessary since the increase in sensitivity is relatively modest.	causal filter;database normalization;eaf2 gene;normality unit;quantitative structure-activity relationship;quantity;simulation;trait;cell transformation	Liang Goh;Von Bing Yap	2009		10.1186/1471-2105-10-415	biology;bioinformatics;genetics;quantitative trait locus	PL	5.154984705595304	-53.475725613402815	188192
2664d79ed1bf6a51975e6ba04a7f32ada256fb2f	npebseq: nonparametric empirical bayesian-based procedure for differential expression analysis of rna-seq data	software;high throughput nucleotide sequencing;bayes theorem;computational biology bioinformatics;rna;algorithms;sequence alignment;sequence analysis rna;combinatorial libraries;computational biology;computer appl in life sciences;gene expression profiling;statistics nonparametric;microarrays;bioinformatics	RNA-seq, a massive parallel-sequencing-based transcriptome profiling method, provides digital data in the form of aligned sequence read counts. The comparative analyses of the data require appropriate statistical methods to estimate the differential expression of transcript variants across different cell/tissue types and disease conditions. We developed a novel nonparametric empirical Bayesian-based approach (NPEBseq) to model the RNA-seq data. The prior distribution of the Bayesian model is empirically estimated from the data without any parametric assumption, and hence the method is “nonparametric” in nature. Based on this model, we proposed a method for detecting differentially expressed genes across different conditions. We also extended this method to detect differential usage of exons from RNA-seq data. The evaluation of NPEBseq on both simulated and publicly available RNA-seq datasets and comparison with three popular methods showed improved results for experiments with or without biological replicates. NPEBseq can successfully detect differential expression between different conditions not only at gene level but also at exon level from RNA-seq datasets. In addition, NPEBSeq performs significantly better than current methods and can be applied to genome-wide RNA-seq datasets. Sample datasets and R package are available at http://bioinformatics.wistar.upenn.edu/NPEBseq .	alignment;base sequence;bioinformatics;digital data;exons;experiment;histocompatibility testing;protein profiling chips;r language;rna;sensor;sequence number;transcript;transcriptome	Yingtao Bi;Ramana V. Davuluri	2013		10.1186/1471-2105-14-262	biology;rna;dna microarray;computer science;bioinformatics;data science;sequence alignment;data mining;gene expression profiling;bayes' theorem;alignment-free sequence analysis	Comp.	4.309667666190992	-52.96251278854106	188412
eddadc0824a462903ef1bf42cf04aacc65e7eca2	detecting biological network organization and functional gene orthologs	evolution molecular;software;genomics;phylogeny;databases genetic;models biological;proteins;genome bacterial;genes bacterial	SUMMARY We developed a package TripletSearch to compute relationships within triplets of genes based on Roundup, an orthologous gene database containing >1500 genomes. These relationships, derived from the coevolution of genes, provide valuable information in the detection of biological network organization from the local to the system level, in the inference of protein functions and in the identification of functional orthologs. To run the computation, users need to provide the GI IDs of the genes of interest.   AVAILABILITY http://wall.hms.harvard.edu/sites/default/files/tripletSearch.tar.gz   CONTACT dpwall@hms.harvard.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;biological network;computation;genome;homology (biology);inference;network governance;roundup;sensor;sequence homology	Jike Cui;Todd F. DeLuca;Jae-Yoon Jung;Dennis P. Wall	2011		10.1093/bioinformatics/btr485	biology;fox proteins;genomics;bioinformatics;genetics	Comp.	3.9922603315208147	-58.429010989039924	188556
06741e8de1cc6070a9b58052031b475eb53bb703	empirical assessment of the impact of sample number and read depth on rna-seq analysis workflow performance	gene expression analysis;monocytes;rna-sequencing;read depth;sample number	RNA-Sequencing analysis methods are rapidly evolving, and the tool choice for each step of one common workflow, differential expression analysis, which includes read alignment, expression modeling, and differentially expressed gene identification, has a dramatic impact on performance characteristics. Although a number of workflows are emerging as high performers that are robust to diverse input types, the relative performance characteristics of these workflows when either read depth or sample number is limited–a common occurrence in real-world practice–remain unexplored. Here, we evaluate the impact of varying read depth and sample number on the performance of differential gene expression identification workflows, as measured by precision, or the fraction of genes correctly identified as differentially expressed, and by recall, or the fraction of differentially expressed genes identified. We focus our analysis on 30 high-performing workflows, systematically varying the read depth and number of biological replicates of patient monocyte samples provided as input. We find that, in general for most workflows, read depth has little effect on workflow performance when held above two million reads per sample, with reduced workflow performance below this threshold. The greatest impact of decreased sample number is seen below seven samples per group, when more heterogeneity in workflow performance is observed. The choice of differential expression identification tool, in particular, has a large impact on the response to limited inputs. Among the tested workflows, the recall/precision balance remains relatively stable at a range of read depths and sample numbers, although some workflows are more sensitive to input restriction. At ranges typically recommended for biological studies, performance is more greatly impacted by the number of biological replicates than by read depth. Caution should be used when selecting analysis workflows and interpreting results from low sample number experiments, as all workflows exhibit poorer performance at lower sample numbers near typically reported values, with variable impact on recall versus precision. These analyses highlight the performance characteristics of common differential gene expression workflows at varying read depths and sample numbers, and provide empirical guidance in experimental and analytical design.	experiment;impacted tooth;patients;quine (computing);rna;sequence number;tissue-specific gene expression	Alyssa Baccarella;Claire R. Williams;Jay Z. Parrish;Charles C. Kim	2018		10.1186/s12859-018-2445-2		Comp.	4.2227858011495	-53.99402741634827	188561
8c80a230270a2b0a86f33e2893fe29d05dcefe7e	exploring the lipoprotein composition using bayesian regression on serum lipidomic profiles	lipid profile;healthy control;high dimensionality;regression model;lipoprotein;serum lipids;model building;lipid metabolism;dynamic modelling;metabolic syndrome	MOTIVATION Serum lipids have been traditionally studied in the context of lipoprotein particles. Today's emerging lipidomics technologies afford sensitive detection of individual lipid molecular species, i.e. to a much greater detail than the scale of lipoproteins. However, such global serum lipidomic profiles do not inherently contain any information on where the detected lipid species are coming from. Since it is too laborious and time consuming to routinely perform serum fractionation and lipidomics analysis on each lipoprotein fraction separately, this presents a challenge for the interpretation of lipidomic profile data. An exciting and medically important new bioinformatics challenge today is therefore how to build on extensive knowledge of lipid metabolism at lipoprotein levels in order to develop better models and bioinformatics tools based on high-dimensional lipidomic data becoming available today.   RESULTS We developed a hierarchical Bayesian regression model to study lipidomic profiles in serum and in different lipoprotein classes. As a background data for the model building, we utilized lipidomic data for each of the lipoprotein fractions from 5 subjects with metabolic syndrome and 12 healthy controls. We clustered the lipid profiles and applied a regression model within each cluster separately. We found that the amount of a lipid in serum can be adequately described by the amounts of lipids in the lipoprotein classes. In addition to improved ability to interpret lipidomic data, we expect that our approach will also facilitate dynamic modelling of lipid metabolism at the individual molecular species level.	bioinformatics;class;drude particle;lipid metabolism disorders;lipoproteins;metabolic syndrome x	Marko Sysi-Aho;Aki Vehtari;Vidya R. Velagapudi;Jukka Westerbacka;Laxman Yetukuri;Robert Bergholm;Marja-Riitta Taskinen;Hannele Yki-Järvinen;Matej Oresic	2007	Bioinformatics	10.1093/bioinformatics/btm181	biology;biochemistry;lipid metabolism;model building;bioinformatics;blood lipids;regression analysis	Comp.	4.024751090980064	-54.58569101783763	188779
ce5293e40523a8552b6d97af5647431b0d5cb511	structural network analysis of biological networks for assessment of potential disease model organisms	interaction networks;structural pattern analysis;translational bioinformatics;disease pathway mining	Model organisms provide opportunities to design research experiments focused on disease-related processes (e.g., using genetically engineered populations that produce phenotypes of interest). For some diseases, there may be non-obvious model organisms that can help in the study of underlying disease factors. In this study, an approach is presented that leverages knowledge about human diseases and associated biological interactions networks to identify potential model organisms for a given disease category. The approach starts with the identification of functional and interaction patterns of diseases within genetic pathways. Next, these characteristic patterns are matched to interaction networks of candidate model organisms to identify similar subsystems that have characteristic patterns for diseases of interest. The quality of a candidate model organism is then determined by the degree to which the identified subsystems match genetic pathways from validated knowledge. The results of this study suggest that non-obvious model organisms may be identified through the proposed approach.	biological network;experiment;genetic engineering;interaction network;phenotype;population;social network analysis	Ahmed Ragab Nabhan;Indra Neil Sarkar	2014	Journal of biomedical informatics	10.1016/j.jbi.2013.10.011	bioinformatics;translational bioinformatics;data mining	Comp.	5.421311624470585	-58.12905982534764	188827
02e2d32266f823210b873e5c770aaf66ece44596	a methodology for multivariate phenotype-based genome-wide association studies to mine pleiotropic genes	quantitative trait loci;animals;female;simulation and modeling;mice;multivariate analysis;rats;middle aged;systems biology;genome wide association study;male;physiological cellular and medical topics;genetic pleiotropy;computational biology bioinformatics;cardiovascular diseases;risk factors;genetic predisposition to disease;adult;obesity;diabetes mellitus type 2;insulin;algorithms;bone density;humans;triglycerides;cholesterol;protein interaction maps;genetic markers;polymorphism single nucleotide;cohort studies;metabolic syndrome x;bioinformatics	Current Genome-Wide Association Studies (GWAS) are performed in a single trait framework without considering genetic correlations between important disease traits. Hence, the GWAS have limitations in discovering genetic risk factors affecting pleiotropic effects. This work reports a novel data mining approach to discover patterns of multiple phenotypic associations over 52 anthropometric and biochemical traits in KARE and a new analytical scheme for GWAS of multivariate phenotypes defined by the discovered patterns. This methodology applied to the GWAS for multivariate phenotype highLDLhighTG derived from the predicted patterns of the phenotypic associations. The patterns of the phenotypic associations were informative to draw relations between plasma lipid levels with bone mineral density and a cluster of common traits (Obesity, hypertension, insulin resistance) related to Metabolic Syndrome (MS). A total of 15 SNPs in six genes (PAK7, C20orf103, NRIP1, BCL2, TRPM3, and NAV1) were identified for significant associations with highLDLhighTG. Noteworthy findings were that the significant associations included a mis-sense mutation (PAK7:R335P), a frame shift mutation (C20orf103) and SNPs in splicing sites (TRPM3). The six genes corresponded to rat and mouse quantitative trait loci (QTLs) that had shown associations with the common traits such as the well characterized MS and even tumor susceptibility. Our findings suggest that the six genes may play important roles in the pleiotropic effects on lipid metabolism and the MS, which increase the risk of Type 2 Diabetes and cardiovascular disease. The use of the multivariate phenotypes can be advantageous in identifying genetic risk factors, accounting for the pleiotropic effects when the multivariate phenotypes have a common etiological pathway.	anthropometry;cardiovascular diseases;data mining;diabetes mellitus;frameshift mutation function;gene regulatory network;genome-wide association study;hypertensive disease;information;insulin resistance;mental association;metabolic syndrome x;nav1 gene;neoplasms;phenotype;plasma active;pleiotropic gene;quantitative trait loci;rna splicing;single nucleotide polymorphism;trpm3 gene;whole earth 'lectronic link;whole genome sequencing;nuclear receptor interacting protein 1	Sung Hee Park;Ji Young Lee;Sangsoo Kim	2011		10.1186/1752-0509-5-S2-S13	biology;obesity;biotechnology;bioinformatics;multivariate analysis;genetics;systems biology	ML	5.801609943697503	-55.18687561296236	189053
593a24467350e3c8d0af15e4da9b2cb0b2ab1661	a simplified approach to disulfide connectivity prediction from protein sequences	prediction method;model selection;amino acid;protein sequence;amino acid sequence;disulfides;binding sites;models chemical;public domain;computational biology bioinformatics;models molecular;proteins;machine learning;structure and function;nearest neighbor;prediction accuracy;protein binding;algorithms;molecular sequence data;combinatorial libraries;computer appl in life sciences;computer simulation;sequence analysis protein;microarrays;bioinformatics	Prediction of disulfide bridges from protein sequences is useful for characterizing structural and functional properties of proteins. Several methods based on different machine learning algorithms have been applied to solve this problem and public domain prediction services exist. These methods are however still potentially subject to significant improvements both in terms of prediction accuracy and overall architectural complexity. We introduce new methods for predicting disulfide bridges from protein sequences. The methods take advantage of two new decomposition kernels for measuring the similarity between protein sequences according to the amino acid environments around cysteines. Disulfide connectivity is predicted in two passes. First, a binary classifier is trained to predict whether a given protein chain has at least one intra-chain disulfide bridge. Second, a multiclass classifier (plemented by 1-nearest neighbor) is trained to predict connectivity patterns. The two passes can be easily cascaded to obtain connectivity prediction from sequence alone. We report an extensive experimental comparison on several data sets that have been previously employed in the literature to assess the accuracy of cysteine bonding state and disulfide connectivity predictors. We reach state-of-the-art results on bonding state prediction with a simple method that classifies chains rather than individual residues. The prediction accuracy reached by our connectivity prediction method compares favorably with respect to all but the most complex other approaches. On the other hand, our method does not need any model selection or hyperparameter tuning, a property that makes it less prone to overfitting and prediction accuracy overestimation.	algorithm;amino acid sequence;amino acids;binary classification;cysteine;database tuning;machine learning;model selection;multiclass classification;multiple encryption;overfitting;peptide sequence;pyschological bonding	Marc Vincent;Andrea Passerini;Matthieu Labbé;Paolo Frasconi	2007	BMC Bioinformatics	10.1186/1471-2105-9-20	computer simulation;biology;plasma protein binding;public domain;amino acid;dna microarray;computer science;bioinformatics;binding site;theoretical computer science;machine learning;protein sequencing;peptide sequence;k-nearest neighbors algorithm;model selection	Comp.	9.969573875410273	-55.871392988789474	189636
90ba28ab172ce6d83e45e828b28b2d184a10f6d5	integration of full-coverage probabilistic functional networks with relevance to specific biological processes	professor anil wipat;saccharomyces cerevisiae;functional integration;network performance;integrated networks;network analysis;dr jennifer hallinan;eprints newcastle university;gene ontology annotation;clustering;dr katherine james;open access;relevance;high throughput;biological process	Probabilistic functional integrated networks are powerful tools with which to draw inferences from high-throughput data. However, network analyses are generally not tailored to specific biological functions or processes. This problem may be overcome by extracting process-specific sub-networks, but this approach discards useful information and is of limited use in poorly annotated areas of the network. Here we describe an extension to existing integration methods which exploits dataset biases in order to emphasise interactions relevant to specific processes, without loss of data. We apply the method to high-throughput data for the yeast  Saccharomyces cerevisiae,  using Gene Ontology annotations for ageing and telomere maintenance as test processes. The resulting networks perform significantly better than unbiased networks for assigning function to unknown genes, and for clustering to identify important sets of interactions. We conclude that this integration method can be used to enhance network analysis with respect to specific processes of biological interest.	relevance	Katherine James;Anil Wipat;Jennifer Hallinan	2009		10.1007/978-3-642-02879-3_4	high-throughput screening;relevance;network analysis;computer science;bioinformatics;artificial intelligence;data mining;database;cluster analysis;network performance;biological process;functional integration	Comp.	4.9041400535172315	-56.532680263963776	190063
425dd6841a798f248f8b17d396e4fe2f4ae6d5b5	bayesian normalization and identification for differential gene expression data	measurement error model;intensity dependent normalization;differential gene expression;markov chain monte carlo;spotted microarray;bayesian analysis	Commonly accepted intensity-dependent normalization in spotted microarray studies takes account of measurement errors in the differential expression ratio but ignores measurement errors in the total intensity, although the definitions imply the same measurement error components are involved in both statistics. Furthermore, identification of differentially expressed genes is usually considered separately following normalization, which is statistically problematic. By incorporating the measurement errors in both total intensities and differential expression ratios, we propose a measurement-error model for intensity-dependent normalization and identification of differentially expressed genes. This model is also flexible enough to incorporate intra-array and inter-array effects. A Bayesian framework is proposed for the analysis of the proposed measurement-error model to avoid the potential risk of using the common two-step procedure. We also propose a Bayesian identification of differentially expressed genes to control the false discovery rate instead of the ad hoc thresholding of the posterior odds ratio. The simulation study and an application to real microarray data demonstrate promising results.	bayesian network;chamaecyparis lawsoniana;database normalization;errors-in-variables models;hoc (programming language);let expression;microarray;odds ratio;simulation;thresholding (image processing)	Dabao Zhang;Martin T. Wells;Christine D. Smart;William E. Fry	2005	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2005.12.391	econometrics;markov chain monte carlo;bayesian probability;bioinformatics;errors-in-variables models;mathematics;statistics	Comp.	5.386112505360794	-52.25309342645828	190689
05f9bcb870f84470deed669dd0a2fb125c3227af	an efficient concordant integrative analysis of multiple large-scale two-sample expression data sets		Motivation We have proposed a mixture model based approach to the concordant integrative analysis of multiple large-scale two-sample expression datasets. Since the mixture model is based on the transformed differential expression test P-values (z-scores), it is generally applicable to the expression data generated by either microarray or RNA-seq platforms. The mixture model is simple with three normal distribution components for each dataset to represent down-regulation, up-regulation and no differential expression. However, when the number of datasets increases, the model parameter space increases exponentially due to the component combination from different datasets.   Results In this study, motivated by the well-known generalized estimating equations (GEEs) for longitudinal data analysis, we focus on the concordant components and assume that the proportions of non-concordant components follow a special structure. We discuss the exchangeable, multiset coefficient and autoregressive structures for model reduction, and their related expectation-maximization (EM) algorithms. Then, the parameter space is linear with the number of datasets. In our previous study, we have applied the general mixture model to three microarray datasets for lung cancer studies. We show that more gene sets (or pathways) can be detected by the reduced mixture model with the exchangeable structure. Furthermore, we show that more genes can also be detected by the reduced model. The Cancer Genome Atlas (TCGA) data have been increasingly collected. The advantage of incorporating the concordance feature has also been clearly demonstrated based on TCGA RNA sequencing data for studying two closely related types of cancer.   Availability and Implementation Additional results are included in a supplemental file. Computer program R-functions are freely available at http://home.gwu.edu/∼ylai/research/Concordance.   Contact ylai@gwu.edu.   Supplementary information Supplementary data are available at Bioinformatics online.		Yinglei Lai;Fanni Zhang;Tapan K. Nayak;Reza Modarres;Norman H. Lee;Timothy A. McCaffrey	2017	Bioinformatics	10.1093/bioinformatics/btx061	parameter space;data mining;mixture model;statistics;concordance;multiset;autoregressive model;data set;normal distribution;bioinformatics;mathematics;generalized estimating equation	Comp.	5.259745308724294	-52.60321054200863	190746
12acb81a784b07702bef960eea500b8ac0e0de6c	a novel wavelet-based approach for predicting nucleosome positions using dna structural information	dna;genomics;ieee transactions;wavelet transforms biology computing dna genomics molecular biophysics molecular configurations proteins;genome analysis;structural feature;propeller twist structural characteristics wavelet based approach nucleosome positions dna structural information chromatin structure genome eukaryotic dna compaction nucleosome occupancy fuzzy nucleosomes structural perspective wavenuc computational approach continuous wavelet transformation;nucleosome positioning;genome analysis nucleosome positioning structural feature continuous wavelet transformation;continuous wavelet transformation;bioinformatics nucleosomes continuous wavelet transforms genomics dna computational biology;computational biology;propellers;continuous wavelet transforms;bioinformatics	Nucleosomes are basic elements of chromatin structure. The positioning of nucleosomes along a genome is very important to dictate eukaryotic DNA compaction and access. Current computational methods have focused on the analysis of nucleosome occupancy and the positioning of well-positioned nucleosomes. However, fuzzy nucleosomes require more complex configurations and are more difficult to predict their positions. We analyzed the positioning of well-positioned and fuzzy nucleosomes from a novel structural perspective, and proposed WaveNuc, a computational approach for inferring their positions based on continuous wavelet transformation. The comparative analysis demonstrates that these two kinds of nucleosomes exhibit different propeller twist structural characteristics. Well-positioned nucleosomes tend to locate at sharp peaks of the propeller twist profile, whereas fuzzy nucleosomes correspond to broader peaks. The sharpness of these peaks shows that the propeller twist profile may contain nucleosome positioning information. Exploiting this knowledge, we applied WaveNuc to detect the two different kinds of peaks of the propeller twist profile along the genome. We compared the performance of our method with existing methods on real data sets. The results show that the proposed method can accurately resolve complex configurations of fuzzy nucleosomes, which leads to better performance of nucleosome positioning prediction on the whole genome.	continuous wavelet;data compaction;elements;nucleosomes;qualitative comparative analysis;twist;wavelet transform;nucleosome location;nucleosome positioning	Yanglan Gan;Guobing Zou;Jihong Guan;Guangwei Xu	2014	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2014.2306837	biology;genomics;propeller;bioinformatics;genetics;dna	Comp.	2.970755793126404	-58.64166541683082	190827
333e4cd52be2a1d6390e92ce6f8bbe2eeb0d6bdc	a bayesian approach for the alignment of high-resolution nmr spectra	bayesian framework;high resolution;bayesian approach;genetic modification;nuclear magnetic resonance;spectrum;bayesian method;nmr spectroscopy;human genome project;phase spectral shift;amplitude baseline intensity variation;scientific knowledge;alignment;nuclear magnetic resonance nmr	Metabolic analysis with high-resolution nuclear magnetic resonance (NMR) enables simultaneous investigation of numerous chemical species in response to biochemical changes in subjects. When the analysis involves comparing two or more NMR spectra, it is essential to properly align them because small variations across different spectra influence the alignment and thus, interfere with direct comparisons between samples. We propose a new alignment method within the Bayesian modeling framework. The proposed method allows us to estimate the amplitude and phase shifts simultaneously and to obtain robust results in the existence of noise. Effectiveness of our proposed method is demonstrated through real NMR spectra in human plasma and a comparison study with dynamic time warping and correlated optimized warping, two widely used alignment methods in spectral data.	align (company);approximation algorithm;baseline (configuration management);bayesian network;computation;dynamic time warping;image resolution;jones calculus;mcgurk effect;order of approximation;plasma active;redshift;resonance;series expansion;statistical model;thomas p. moran	Seoung Bum Kim;Zhou Wang;Basavaraj Hiremath	2010	Annals OR	10.1007/s10479-008-0332-3	nuclear magnetic resonance spectroscopy;bayesian probability;bioinformatics;mathematics	Comp.	4.959220292547715	-54.05031368317948	191011
015d4f57f4419312b96fe7be4d186bab3664ca01	cancerome: a hidden informative subnetwork of the diseasome	cancerome;diseasome;disease similarity network;integrated human disease network;disease disease network	Neoplastic disorders are a leading cause of mortality and morbidity worldwide. Studying the relationships between different cancers using high throughput-generated data may elucidate undisclosed aspects of cancer etiology, diagnosis, and treatment. Several studies have described relationships between different diseases based on genes, proteins, pathways, gene ontology, comorbidity, symptoms, and other features. In this study, we first constructed an integrated human disease network based on nine different biological aspects, including molecular, functional, and clinical features. Next, we extracted the cancerome as a cancer-related subnetwork. Further investigation of cancerome could reveal hidden mechanisms of cancer and could be useful in developing new diagnostic tests and effective new drugs.		Mahdi Jalili;Ali Salehzadeh-Yazdi;Marjan Yaghmaie;Ardeshir Ghavamzadeh;Kamran Alimoghaddam	2016	Computers in biology and medicine	10.1016/j.compbiomed.2016.07.010	pathology;bioinformatics;data mining	Comp.	6.032932613979503	-57.21806177345672	191480
d5945a48e74203da397ee344f4a1b10b7fe2707e	effects of partial reporting of classification results	genomics;correlation data models error analysis bioinformatics training genomics joints;training;joints;gene expression;error analysis;classification rules;joint distribution behavior classification result partial reporting effects classification scheme classification rule feature selection method bioinformatics gene expression microarray data set;pattern classification;simulation study;pattern classification bioinformatics biological techniques data handling;feature selection;estimation error;data handling;biological techniques;correlation;error estimate;data models;bioinformatics	When proposing a new classification scheme, perhaps in the form of a classification rule or feature selection method, modelers in the bioinformatics literature typically report its performance on data sets of interest, such as gene-expression microarrays. These data sets often include thousands of features but a small number of sample points, which increases variability in feature selection and error estimation, resulting in highly imprecise reported performances. This suggests that the reported performance of the proposed scheme would be less correlated with and highly biased from the actual performance if only the best results are demonstrated. This paper confirms this by showing the behavior of the joint distributions of the minimum reported estimated errors and corresponding true errors as functions of the number of samples tested in a large simulation study using both modeled and real data.	bioinformatics;comparison and contrast of classification schemes in linguistics and metadata;error detection and correction;feature selection;heart rate variability;microarray;performance;simulation	Mohammadmahdi R. Yousefi;Jianping Hua;Chao Sima;Edward R. Dougherty	2010	2010 IEEE International Workshop on Genomic Signal Processing and Statistics (GENSIPS)	10.1109/GENSIPS.2010.5719688	biology;data modeling;genomics;gene expression;computer science;bioinformatics;group method of data handling;pattern recognition;data mining;feature selection;correlation;statistics	Vision	5.428391222160562	-52.27517999994185	191532
8d7d69f6149ab91dcefbf3a788fc65a0c39112d7	neural networks for genetic epidemiology: past, present, and future	health research;uk clinical guidelines;biological patents;genetic program;human disease;complex disease;europe pubmed central;disease susceptibility;citation search;statistical method;data mining and knowledge discovery;data mining;genetics;association study;computational biology bioinformatics;variable selection;uk phd theses thesis;grammatical evolution;life sciences;pattern recognition;human genome project;algorithms;genetic epidemiology;human genetics;association analysis;high throughput;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;neural network;evolutionary computing;bioinformatics	During the past two decades, the field of human genetics has experienced an information explosion. The completion of the human genome project and the development of high throughput SNP technologies have created a wealth of data; however, the analysis and interpretation of these data have created a research bottleneck. While technology facilitates the measurement of hundreds or thousands of genes, statistical and computational methodologies are lacking for the analysis of these data. New statistical methods and variable selection strategies must be explored for identifying disease susceptibility genes for common, complex diseases. Neural networks (NN) are a class of pattern recognition methods that have been successfully implemented for data mining and prediction in a variety of fields. The application of NN for statistical genetics studies is an active area of research. Neural networks have been applied in both linkage and association analysis for the identification of disease susceptibility genes. In the current review, we consider how NN have been used for both linkage and association analyses in genetic epidemiology. We discuss both the successes of these initial NN applications, and the questions that arose during the previous studies. Finally, we introduce evolutionary computing strategies, Genetic Programming Neural Networks (GPNN) and Grammatical Evolution Neural Networks (GENN), for using NN in association studies of complex human diseases that address some of the caveats illuminated by previous work.	active appearance model;backpropagation;bayesian network;biological evolution;biological neural networks;chamaecyparis lawsoniana;choice behavior;compiler;computation (action);computer engineering;computer science;data mining;disease susceptibility;evolutionary computation;feature selection;genetic epidemiology;genetic programming;grammatical evolution;heuristic (computer science);information explosion;jason;john reif;linkage (software);manuscripts;memory data register;neural networks;over-the-top content;pattern recognition;petri net;radial basis function;selection bias;single nucleotide polymorphism;software propagation;study of epidemiology;throughput;water wells;weakness;citation;genetic linkage;interest	Alison A. Motsinger-Reif;Marylyn DeRiggi Ritchie	2008	BioData Mining	10.1186/1756-0381-1-3	high-throughput screening;biology;genetic epidemiology;computer science;bioinformatics;data science;genetic association;data mining;grammatical evolution;genetics;human genetics	ML	3.6076191996752924	-56.92537169829483	191572
e7aab1cf059f9ca59ffa5f293266b352d90ad1c5	microarray results: how accurate are they?	sensitivity and specificity;alleles;serine endopeptidases;rna neoplasm;rna messenger;gene expression regulation enzymologic;computational biology bioinformatics;chip;cells cultured;gene expression regulation neoplastic;dna complementary;reproducibility of results;leukocytes mononuclear;algorithms;genes neoplasm;humans;dna microarray;combinatorial libraries;computational biology;computer appl in life sciences;gene expression profiling;oligonucleotide array sequence analysis;granzymes;leukemia lymphoid;microarrays;bioinformatics	DNA microarray technology is a powerful technique that was recently developed in order to analyze thousands of genes in a short time. Presently, microarrays, or chips, of the cDNA type and oligonucleotide type are available from several sources. The number of publications in this area is increasing exponentially. In this study, microarray data obtained from two different commercially available systems were critically evaluated. Our analysis revealed several inconsistencies in the data obtained from the two different microarrays. Problems encountered included inconsistent sequence fidelity of the spotted microarrays, variability of differential expression, low specificity of cDNA microarray probes, discrepancy in fold-change calculation and lack of probe specificity for different isoforms of a gene. In view of these pitfalls, data from microarray analysis need to be interpreted cautiously.	dna microarray format;dna, complementary;discrepancy function;heart rate variability;microarray analysis;protein isoforms;sensitivity and specificity	Ravi Kothapalli;Sean J. Yoder;Shrikant M. Mane;Thomas P. Loughran	2002		10.1186/1471-2105-3-22	biology;molecular biology;gene chip analysis;dna microarray;bioinformatics;microarray databases;genetics	Comp.	3.9458444137058155	-54.51973829683351	191597
ae347db4fa7aab950b1bcc6ad9399fcbe04f7759	integrated study to infer dynamic protein-gene interactions in human p53 regulatory networks	network inference;microarray expression data;dynamical genetic regulations dynamic protein gene interactions human p53 regulatory networks genetic regulatory networks microarray gene expression profiles mathematical models top down approach bottom up approach probability graphical models network structure dna repair pathway differential equation models optimal network model simulation error robustness property;dna repair pathway;mathematical model robustness biological system modeling computational modeling matlab dna;proteins biological techniques differential equations dna genetics molecular biophysics probability;dna repair pathway genetic regulation microarray expression data network inference;genetic regulation	Investigating the dynamics of genetic regulatory networks through high throughput experimental data, such as microarray gene expression profiles, is very important but challenging. One of the major hindrances in building detailed mathematical models for genetic regulation is the large number of unknown model parameters. To tackle this problem, a new integrated method is proposed by combining both the top-down and bottom-up approaches. Firstly, a top-down approach, using probability graphical models, is employed to predict the network structure of DNA repair pathway that involves p53 regulation. Then, a bottom-up approach, using differential equation models, is applied to study the detailed genetic regulations based on either a fully-connected regulatory network or gene networks inferred with the top-down approach. Optimal network is selected based on model simulation error and robustness property. Overall, the proposed new integrated method is efficient for studying large dynamical genetic regulations.	bottom-up proteomics;gene regulatory network;graphical model;interaction;mathematical model;microarray;simulation;throughput;top-down and bottom-up design	Junbai Wang;Qianqian Wu;Tianhai Tian	2015	2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2015.7359692	biology;bioinformatics;machine learning;genetics	Robotics	6.371208353024808	-59.108555326900984	191627
a02ed041a7faf062a831b3a616e20b13b52e9bce	biomedical network regulated by acanthopanacis cortex (wu-jia-pi) for ossification	databases;chemical compounds;bones;proteins;biological processes;bone tissue	Acanthopanacis Cortex (AC) is a Chinese herbal medicine (Wu-Jia-Pi in PinYin) which is recognized with therapeutic effect of “strengthening bone and sinew”, yet its regulating biological network is still obscure. In this study, started from AC's chemical compounds, their direct target proteins were filtered out. Then these targeted proteins were annotated with biological processes under the framework of Gene Ontology (GO) terms' hierarchical networks which were overrepresented and enriched with them with statistic significant p-value set to 0.05. In the biological process hierarchy networks, ossification formed a big one with bone formation associated biological processes. Further protein-protein interaction analysis with these targeted proteins and bone expressed ones formed a clear and concise protein-regulation network for ossification which should be responsible for the therapeutic effect of “strengthening bone and sinew”. This study proposed a new approach of analyzing biological functions of a specified Chinese herbal medicine targeting certain therapeutic effect.	arm cortex-m;biological network;gene ontology;tree network	Junping Zhan;Hongtao Guo;Yun Yang;Yutao Qi;Miaofeng Li;Xuwen He;Guang Zheng	2016	2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)	10.1109/FSKD.2016.7603378	bioinformatics;biological process	Comp.	5.09992203509222	-58.32092849445361	191674
3ed34c70064c6233b38be5908be9521a65a6e599	signal deconvolution based expression-detection and background adjustment for microarray data	microarray data;gene expression;background subtraction;expression detection	Background adjustment is an essential stage in analyzing DNA microarrays. Discriminating expressed genes from unexpressed ones (expression detection), and estimating the expression levels of weakly expressed genes, critically depend on accurate treatment of the background intensity. Current methods for background adjustment either do not deal with nonspecific hybridization or strongly depend on the reliability of control probes. Existing model-based methods have limited accuracy. A new platform-independent background adjustment algorithm is presented. The algorithm relies on the deconvoluted experimental signal distribution for evaluating the expression probability and adjusting the background of each probe. Considering expression detection, it is shown, for two-channels cDNA arrays and for the Affymetrix GeneChip platform, that the algorithm performs at least as good or better than control-probes-based algorithms. For the Affymetrix GeneChip arrays, it is further shown that the algorithm outperforms the robust multiarray (RMA) expression measure in estimating genomewide expression levels.		Moshe Havilio	2006	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2006.13.63	biology;microarray analysis techniques;molecular biology;gene expression;background subtraction;computer science;bioinformatics;data mining;genetics	Comp.	4.488756750947506	-54.11869810353386	192148
a337fbfa416bfc4c37eb76a6bd24bbf7db0e52de	dwnn-rls: regularized least squares method for predicting circrna-disease associations	circrna;circrna-disease association;gaussian interaction profile;kron-rls	Many evidences have demonstrated that circRNAs (circular RNA) play important roles in controlling gene expression of human, mouse and nematode. More importantly, circRNAs are also involved in many diseases through fine tuning of post-transcriptional gene expression by sequestering the miRNAs which associate with diseases. Therefore, identifying the circRNA-disease associations is very appealing to comprehensively understand the mechanism, treatment and diagnose of diseases, yet challenging. As the complex mechanism between circRNAs and diseases, wet-lab experiments are expensive and time-consuming to discover novel circRNA-disease associations. Therefore, it is of dire need to employ the computational methods to discover novel circRNA-disease associations. In this study, we develop a method (DWNN-RLS) to predict circRNA-disease associations based on Regularized Least Squares of Kronecker product kernel. The similarity of circRNAs is computed from the Gaussian Interaction Profile(GIP) based on known circRNA-disease associations. In addition, the similarity of diseases is integrated by the mean of GIP similarity and sematic similarity which is computed by the direct acyclic graph (DAG) representation of diseases. The kernels of circRNA-disease pairs are constructed from the Kronecker product of the kernels of circRNAs and diseases. DWNN (decreasing weight k-nearest neighbor) method is adopted to calculate the initial relational score for new circRNAs and diseases. The Kronecker product kernel based regularised least squares approach is used to predict new circRNA-disease associations. We adopt 5-fold cross validation (5CV), 10-fold cross validation (10CV) and leave one out cross validation (LOOCV) to assess the prediction performance of our method, and compare it with other six competing methods (RLS-avg, RLS-Kron, NetLapRLS, KATZ, NBI, WP). The experiment results show that DWNN-RLS reaches the AUC values of 0.8854, 0.9205 and 0.9701 in 5CV, 10CV and LOOCV, respectively, which illustrates that DWNN-RLS is superior to the competing methods RLS-avg, RLS-Kron, NetLapRLS, KATZ, NBI, WP. In addition, case studies also show that DWNN-RLS is an effective method to predict new circRNA-disease associations.		Cheng Yan;Jianxin Wang;Fang-Xiang Wu	2018		10.1186/s12859-018-2522-6		AI	7.379980924906195	-55.560170138545296	192433
1080db8d824fcc63c71a62269e0afe1b3ed1689c	predicting disordered regions in proteins based on decision trees of reduced amino acid composition	decision tree	Intrinsically unstructured proteins (IUPs) are proteins lacking a fixed three-dimensional structure or containing long disordered regions. IUPs play an important role in biology and disease. Identifying disordered regions in protein sequences can provide useful information on protein structure and function, and can assist high-throughput protein structure determination. In this paper, we present a system for predicting disordered regions in proteins based on decision trees and reduced amino acid composition. Concise rules based on biochemical properties of amino acid side chains are generated for prediction. Coarser information extracted from the composition of amino acids cannot only improve the prediction accuracy, but can also increase the learning efficiency. In cross-validation tests, with four groups of reduced amino acid composition, our system can achieve a recall of 80% at a 13% false positive rate for predicting disordered regions, and the overall accuracy can reach 83.4%. This prediction accuracy is comparable to most, and better than some, existing predictors. Advantages of our approach are high prediction accuracy for long disordered regions and efficiency for large-scale sequence analysis. Our software is freely available for academic use upon request.		Pengfei Han;Xiuzhen Zhang;Raymond S. Norton;Zhi-Ping Feng	2006	Journal of Computational Biology	10.1089/cmb.2006.13.1579	biology;biochemistry;computer science;bioinformatics;machine learning;decision tree	Comp.	9.054561310911383	-56.35151326200598	193107
c4c3e7e804b7c1f686183211fbf37fa8460406a0	computational identification of de-centric genetic regulatory relationships from functional genomic data		We developed a new computational technique to identify de-centric genetic regulatory relationship candidates. Our technique takes advantages of functional genomics data for the same species under different perturbation conditions, therefore making it complementary to current computational techniques including database search, clustering of gene expression profiles, motif matching, structural modeling, and network effect simulation methods. It is fast and addressed the need of biologists to determine activation/inhibition relationship details often missing in synthetic lethality or chip-seq experiments. We used GEO microarray data set GSE25644 with 158 different mutant genes in S. cerevisiae. We screened out 83 targets with 610 activation pairs and 93 targets with 494 inhibition pairs. In the Yeast Fitness database, 33 targets (40%) with 126 activation pairs and 31 targets (33%) with 97 inhibition pairs were identified. To be identified further are 50 targets with 484 activation pairs and 62 targets with 397 inhibition pairs. The aggregation test confirmed that all discovered de-centric regulatory relationships are significant from random discovery at a p-value=0.002; therefore, this method is highly complementary to others that tend to discover hub-related regulatory relationships. We also developed criteria for rejecting genetic regulator candidates x as a candidate regulator and assessing the ranking of the regulator-target relationship identified. The top 10 high suspected regulators determined by our criteria were found to be significant, pending future experimental verifications.	computation	Zongliang Yue;Ping Wan;Zhan Xie;Jake Yue Chen	2014		10.1007/978-3-319-08171-7_20	bioinformatics	Logic	4.680751054426024	-55.982603318475064	193331
6b3f0605079225f62fa014d7c356322256d27623	identification of co-evolving temporal networks		Biological networks describes the mechanisms which govern cellular functions. Temporal networks show how these networks evolve over time. Studying the temporal progression of network topologies is of utmost importance since it uncovers how a network evolves and how it resists to external stimuli and internal variations. Two temporal networks have co-evolving subnetworks if the topologies of these subnetworks remain similar to each other as the network topology evolves over a period of time. In this paper, we consider the problem of identifying co-evolving pair of temporal networks, which aim to capture the evolution of molecules and their interactions over time. Although this problem shares some characteristics of the well-known network alignment problems, it differs from existing network alignment formulations as it seeks a mapping of the two network topologies that is invariant to temporal evolution of the given networks. This is a computationally challenging problem as it requires capturing not only similar topologies between two networks but also their similar evolution patterns. We present an efficient algorithm, Tempo, for solving identifying coevolving subnetworks with two given temporal networks. We formally prove the correctness of our method. We experimentally demonstrate that Tempo scales efficiently with the size of network as well as the number of time points, and generates statistically significant alignments---even when evolution rates of given networks are high. Our results on a human aging dataset demonstrate that Tempo identifies novel genes contributing to the progression of Alzheimer's, Huntington's and Type II diabetes, while existing methods fail to do so.	algorithm;color gradient;correctness (computer science);experiment;interaction;network topology;whole earth 'lectronic link	Rasha Elhesha;Aisharjya Sarkar;Christina Boucher;Tamer Kahveci	2018		10.1145/3233547.3233686	machine learning;network topology;correctness;deterministic system;artificial intelligence;computer science;invariant (mathematics);biological network	ML	6.096042292730236	-58.738818844704454	193443
ed51d0f708437019ea3f56321ff2ddd146b69812	robust functional profile identification for dsc thermograms		Differential scanning calorimetry is an emerging technique with an attempt to characterize a subjectu0027s disease status according to heat capacity profiles, which are called thermograms. However, thermograms exhibit large shape variations, and the sample size is typically small. Therefore, it is important to extract robust characterization of thermograms representing the clinical status for further study. The current study identifies the representative heat capacity profiles from functional principle components which are derived from the bootstrap distribution of the deepest heat capacity function according to the functional data depth, instead of the original thermogram data set. 71 thermograms are obtained from two groups (healthy, cervical carcinoma), and functional PCA are conducted with the original thermogram data set and the bootstrap data set of the deepest heat capacity functions. Examining the first three PCs of the two groups between the two data sets, the bootstrap data set shows more distinctive difference in modes of variation between the two groups in comparison with the original thermogram data set, and the representative heat profiles are reconstructed with the PCs which are derived from the bootstrap sample sets. 90% confidence intervals of the representative heat profiles can be directly obtained from the same bootstrap set.		Amy M. Kwon;Dianxu Ren;Ming Ouyang;Nichola C Garbett	2015			econometrics;data mining;mathematics;statistics	NLP	6.33482356905223	-52.63036967508905	193549
4926b720c448d4bb0f8ed4ff207d566e583d9920	brni: modular analysis of transcriptional regulatory programs	transcription genetic;genomics;schizosaccharomyces;data interpretation statistical;expression pattern;expression profile;regulatory network;ensemble learning;learning model;gene regulatory networks;regulatory element;databases genetic;dna binding;computational biology bioinformatics;fission yeast;gene expression;models genetic;cluster analysis;gene expression regulation;cell division;artificial intelligence;algorithms;cell cycle;combinatorial libraries;computer appl in life sciences;article;microarrays;bioinformatics	Transcriptional responses often consist of regulatory modules – sets of genes with a shared expression pattern that are controlled by the same regulatory mechanisms. Previous methods allow dissecting regulatory modules from genomics data, such as expression profiles, protein-DNA binding, and promoter sequences. In cases where physical protein-DNA data are lacking, such methods are essential for the analysis of the underlying regulatory program. Here, we present a novel approach for the analysis of modular regulatory programs. Our method – Biochemical Regulatory Network Inference (BRNI) – is based on an algorithm that learns from expression data a biochemically-motivated regulatory program. It describes the expression profiles of gene modules consisting of hundreds of genes using a small number of regulators and affinity parameters. We developed an ensemble learning algorithm that ensures the robustness of the learned model. We then use the topology of the learned regulatory program to guide the discovery of a library of cis-regulatory motifs, and determined the motif compositions associated with each module. We test our method on the cell cycle regulatory program of the fission yeast. We discovered 16 coherent modules, covering diverse processes from cell division to metabolism and associated them with 18 learned regulatory elements, including both known cell-cycle regulatory elements (MCB, Ace2, PCB, ACCCT box) and novel ones, some of which are associated with G2 modules. We integrate the regulatory relations from the expression- and motif-based models into a single network, highlighting specific topologies that result in distinct dynamics of gene expression in the fission yeast cell cycle. Our approach provides a biologically-driven, principled way for deconstructing a set of genes into meaningful transcriptional modules and identifying their associated cis-regulatory programs. Our analysis sheds light on the architecture and function of the regulatory network controlling the fission yeast cell cycle, and a similar approach can be applied to the regulatory underpinnings of other modular transcriptional responses.	anatomy, regional;cell cycle;cell division;coherence (physics);composition;ensemble learning;gene expression;genomics;gnutella2;inference;motif;neural network simulation;polychlorinated biphenyls;processor affinity;schizosaccharomyces pombe;singlet fission;transcription, genetic;algorithm;dna binding	Iftach Nachman;Aviv Regev	2008	BMC Bioinformatics	10.1186/1471-2105-10-155	biology;gene regulatory network;genomics;molecular biology;regulation of gene expression;gene expression;dna microarray;bioinformatics;cell cycle;ensemble learning;cluster analysis;genetics;cell division	Comp.	3.93022924127966	-58.95932853520863	193628
dc322e62e7ef703237ac10e4c7caf85ea9cc7f6f	protein type specific amino acid substitution models for influenza viruses	biology computing;influenza virus;human health;phylogeny tree influenza virus amino acid substitution model;amino acid;protein sequence;amino acid substitution;influenza viruses;proteins;proteins influenza analytical models amino acids biological system modeling;phylogeny tree;protein sequence analysis;diseases;evolutionary process;social economics protein type specific amino acid substitution models protein sequence analysis systems protein databases influenza virus genomes flu model human health;microorganisms;amino acid substitution model;proteins biology computing diseases microorganisms	The amino acid substitution model (matrix) is a crucial part of protein sequence analysis systems. General amino acid substitution models have been estimated from large protein databases, however, they are not specific for influenza viruses. In previous study, we estimated the amino acid substitution model, FLU, for all influenza viruses. Experiments showed that FLU outperformed other models when analyzing influenza protein sequences. Influenza virus genomes consist of different protein types, which are different in both structures and evolutionary processes. Although FLU matrix is specific for influenza viruses, it is still not specific for influenza protein types. Since influenza viruses cause serious problems for both human health and social economics, it is worth to study them as specific as possible. In this paper, we used more than 27 million amino acids to estimate 11 protein type specific models for influenza viruses. Experiments showed that protein type specific models outperformed the FLU model, the best model for influenza viruses. These protein type specific models help researcher to conduct studies on influenza viruses more precisely.	acid;database;peptide sequence;sequence analysis;substitution model	Nguyen Van Sau;Cuong Cao Dang;Si Quang Le;Le Sy Vinh	2011	2011 Third International Conference on Knowledge and Systems Engineering	10.1109/KSE.2011.23	phylogenetic tree;amino acid;bioinformatics;protein sequencing;microorganism;antigenic shift	Comp.	8.814787966239368	-56.299420789411236	193707
623f752fe367490aa633f21b769e25def0dceae9	rip-chip enrichment analysis	large rip-chip dataset;supplementary data;rip-chip data;rip-chip enrichment analysis;necessary step;additional normalization;microarray data;additional experimental step;immunoprecipitation step;additional normalization step;rip-chip protocol	MOTIVATION RIP-chip is a high-throughput method to identify mRNAs that are targeted by RNA-binding proteins. The protein of interest is immunoprecipitated, and the identity and relative amount of mRNA associated with it is measured on microarrays. Even if a variety of methods is available to analyse microarray data, e.g. to detect differentially regulated genes, the additional experimental steps in RIP-chip require specialized methods. Here, we focus on two aspects of RIP-chip data: First, the efficiency of the immunoprecipitation step performed in the RIP-chip protocol varies in between different experiments introducing bias not existing in standard microarray experiments. This requires an additional normalization step to compare different samples and even technical replicates. Second, in contrast to standard differential gene expression experiments, the distribution of measurements is not normal. We exploit this fact to define a set of biologically relevant genes in a statistically meaningful way.   RESULTS Here, we propose two methods to analyse RIP-chip data: We model the measurement distribution as a gaussian mixture distribution, which allows us to compute false discovery rates (FDRs) for any cut-off. Thus, cut-offs can be chosen for any desired FDR. Furthermore, we use principal component analysis to determine the normalization factors necessary to remove immunoprecipitation bias. Both methods are evaluated on a large RIP-chip dataset measuring targets of Ago2, the major component of the microRNA guided RNA-induced silencing complex (RISC). Using published HITS-CLIP experiments performed with the same cell line as used for RIP-chip, we show that the mixture modelling approach is a necessary step to remove background, which computed FDRs are valid, and that the additional normalization is a necessary step to make experiments comparable.   AVAILABILITY An R implementation of REA is available on the project website (http://www.bio.ifi.lmu.de/REA) and as supplementary data file.	ago2 gene;chamaecyparis lawsoniana;cross-linking immunoprecipitation high-throughput sequencing;experiment;gene ontology term enrichment;gm(m);google map maker;high-throughput computing;micrornas;microarray;normal statistical distribution;phb2 gene;principal component analysis;rip-chip;ripk1 protein, human;rna;rna-induced silencing complex;requirement;scientific publication;silo (dataset);throughput;tissue-specific gene expression;web site	Florian Erhard;Lars Dölken;Ralf Zimmer	2013	Bioinformatics	10.1093/bioinformatics/bts631	computer science;bioinformatics;data mining;world wide web	Comp.	4.082247463676111	-53.75625246716531	193832
488d62c7c10504b92a157612e955db4a9e938985	identification of neutral biochemical network models from time series data	glucose 6 phosphate;sensitivity and specificity;simulation and modeling;lactococcus lactis;system modeling;systems biology;physiological cellular and medical topics;models biological;time series;computational biology bioinformatics;glucose;network topology;multivariate time series;data analysis;dynamic data;time factors;mathematical models;acetates;monte carlo method;parameter space;experiments;biochemical network;mathematical model;biological systems;time series data;algorithms;parameter estimation;methodology;monte carlo;kinetics;glycolysis;parameter optimization;lactic acid;bioinformatics;dynamic behavior	The major difficulty in modeling biological systems from multivariate time series is the identification of parameter sets that endow a model with dynamical behaviors sufficiently similar to the experimental data. Directly related to this parameter estimation issue is the task of identifying the structure and regulation of ill-characterized systems. Both tasks are simplified if the mathematical model is canonical, i.e., if it is constructed according to strict guidelines. In this report, we propose a method for the identification of admissible parameter sets of canonical S-systems from biological time series. The method is based on a Monte Carlo process that is combined with an improved version of our previous parameter optimization algorithm. The method maps the parameter space into the network space, which characterizes the connectivity among components, by creating an ensemble of decoupled S-system models that imitate the dynamical behavior of the time series with sufficient accuracy. The concept of sloppiness is revisited in the context of these S-system models with an exploration not only of different parameter sets that produce similar dynamical behaviors but also different network topologies that yield dynamical similarity. The proposed parameter estimation methodology was applied to actual time series data from the glycolytic pathway of the bacterium Lactococcus lactis and led to ensembles of models with different network topologies. In parallel, the parameter optimization algorithm was applied to the same dynamical data upon imposing a pre-specified network topology derived from prior biological knowledge, and the results from both strategies were compared. The results suggest that the proposed method may serve as a powerful exploration tool for testing hypotheses and the design of new experiments.	algorithm;anatomy, regional;behavior;biological system;dynamical system;estimation theory;experiment;gene regulatory network;map;mathematical model;mathematical optimization;mathematics;modelling biological systems;monte carlo method;network topology;population parameter;time series	Marco Vilela;Susana Vinga;Marco Maia;Eberhard O. Voit;Jonas S. Almeida	2009	BMC Systems Biology	10.1186/1752-0509-3-47	computer science;bioinformatics;time series;mathematical model;systems biology;monte carlo method	ML	7.018465231375886	-58.95830980559995	194230
69c4e29c1bc23197b0eceb0a5a052bf4e0b3bc0f	supervised method for construction of microrna-mrna networks: application in cardiac tissue aging dataset	rna bioinformatics biological tissues cardiology genetics genomics ontologies artificial intelligence proteins random processes;experiment studying aging microrna mrna network construction cardiac tissue aging dataset gene expression regulation target detection supervised regulatory network inference method target genes microrna expression trains random forests data sources gene ontology protein protein interactions benchmark data;aging gene expression radio frequency diseases bioinformatics educational institutions	MicroRNAs play an important role in regulation of gene expression, but still detection of their targets remains a challenge. In this work we present a supervised regulatory network inference method with aim to identify potential target genes (mRNAs) of microRNAs. Briefly, the proposed method exploiting mRNA and microRNA expression trains Random Forests on known interactions and subsequently it is able to predict novel ones. In parallel, we incorporate different available data sources, such as Gene Ontology and ProteinProtein Interactions, to deliver biologically consistent results. Application in both benchmark data and an experiment studying aging showed robust performance.	benchmark (computing);experiment;gene expression regulation;gene ontology;homology (biology);inference;interaction;micrornas;pierre robin syndrome;random forest;sensor;silo (dataset);supervised learning	Georgios N. Dimitrakopoulos;Konstantina Dimitrakopoulou;Ioannis A. Maraziotis;Kyriakos N. Sgarbas;Anastasios Bezerianos	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6943593	biology;bioinformatics;data mining;genetics	Visualization	6.860736293454261	-56.07720705023072	194456
6e71451b5380528ac7b36da7285616e90e32a724	meta-analysis based on weighted ordered p-values for genomic data with heterogeneity	genomics;probability;selected works;biostatistics;computational biology bioinformatics;bepress;algorithms;humans;meta analysis as topic;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	Meta-analysis has become increasingly popular in recent years, especially in genomic data analysis, due to the fast growth of available data and studies that target the same questions. Many methods have been developed, including classical ones such as Fisher’s combined probability test and Stouffer’s Z-test. However, not all meta-analyses have the same goal in mind. Some aim at combining information to find signals in at least one of the studies, while others hope to find more consistent signals across the studies. While many classical meta-analysis methods are developed with the former goal in mind, the latter goal has much more practicality for genomic data analysis. In this paper, we propose a class of meta-analysis methods based on summaries of weighted ordered p-values (WOP) that aim at detecting significance in a majority of studies. We consider weighted versions of classical procedures such as Fisher’s method and Stouffer’s method where the weight for each p-value is based on its order among the studies. In particular, we consider weights based on the binomial distribution, where the median of the p-values are weighted highest and the outlying p-values are down-weighted. We investigate the properties of our methods and demonstrate their strengths through simulations studies, comparing to existing procedures. In addition, we illustrate application of the proposed methodology by several meta-analysis of gene expression data. Our proposed weighted ordered p-value (WOP) methods displayed better performance compared to existing methods for testing the hypothesis that there is signal in the majority of studies. They also appeared to be much more robust in applications compared to the rth ordered p-value (rOP) method (Song and Tseng, Ann. Appl. Stat. 2014, 8(2):777–800). With the flexibility of incorporating different p-value combination methods and different weighting schemes, the weighted ordered p-values (WOP) methods have great potential in detecting consistent signal in meta-analysis with heterogeneity.	gene expression;genetic heterogeneity;meta analysis (statistical procedure);mind;order (action);p-value;sensor;simulation;version;weight	Yihan Li;Debashis Ghosh	2014		10.1186/1471-2105-15-226	biology;genomics;dna microarray;computer science;bioinformatics;data science;probability;data mining;biostatistics	AI	5.7450738032361235	-52.352649776280046	194601
fd428b54969c1fd84f92c68359f3ffd44201900b	in silico site of metabolism prediction for human ugt-catalyzed reactions		MOTIVATION The human uridine diphosphate-glucuronosyltransferase enzyme family catalyzes the glucuronidation of the glycosyl group of a nucleotide sugar to an acceptor compound (substrate), which is the most common conjugation pathway that serves to protect the organism from the potential toxicity of xenobiotics. Moreover, it could affect the pharmacological profile of a drug. Therefore, it is important to identify the metabolically labile sites for glucuronidation.   RESULTS In the present study, we developed four in silico models to predict sites of glucuronidation, for four major sites of metabolism functional groups, i.e. aliphatic hydroxyl, aromatic hydroxyl, carboxylic acid or amino nitrogen, respectively. According to the mechanism of glucuronidation, a series of 'local' and 'global' molecular descriptors characterizing the atomic reactivity, bonding strength and physical-chemical properties were calculated and selected with a genetic algorithm-based feature selection approach. The constructed support vector machine classification models show good prediction performance, with the balanced accuracy ranging from 0.88 to 0.96 on test set. For further validation, our models can successfully identify 84% of experimentally observed sites of metabolisms for an external test set containing 54 molecules.   AVAILABILITY AND IMPLEMENTATION  The software somugt based on our models is available at www.dddc.ac.cn/adme/jlpeng/somugt_win32.zip.	aromatics;acceptor (semiconductors);adverse reaction to drug;amino acid metabolism, inborn errors;aromatic-l-amino-acid decarboxylases;binding sites;blood urea nitrogen measurement;carboxyl group;carboxylic acids;experiment;feature selection;gene regulatory network;genetic algorithm;glucuronosyltransferase;hydroxyl radical;mathematical optimization;metabolism;natural science disciplines;nitrogen 99 % gas for inhalation;nucleotides;performance;pharmacology;protein family;pyschological bonding;software release life cycle;sugars;support vector machine;test set;thioctic acid;uridine diphosphate;xenobiotics;chemical properties	Jianlong Peng;Jing Lu;Qiancheng Shen;Mingyue Zheng;Xiaomin Luo;Weiliang Zhu;Hualiang Jiang;Kaixian Chen	2014	Bioinformatics	10.1093/bioinformatics/btt681	biochemistry	ML	9.728473859475608	-57.79622892529861	194802
7997fd0d62e94cdfe0894fa3eec4fdd091e61c59	experimental design strategy: weak reinforcement leads to increased hit rates and enhanced chemical diversity		High Throughput Screening (HTS) is a common approach in life sciences to discover chemical matter that modulates a biological target or phenotype. However, low assay throughput, reagents cost, or a flowchart that can deal with only a limited number of hits may impair screening large numbers of compounds. In this case, a subset of compounds is assayed, and in silico models are utilized to aid in iterative screening design, usually to expand around the found hits and enrich subsequent rounds for relevant chemical matter. However, this may lead to an overly narrow focus, and the diversity of compounds sampled in subsequent iterations may suffer. Active learning has been recently successfully applied in drug discovery with the goal of sampling diverse chemical space to improve model performance. Here we introduce a robust and straightforward iterative screening protocol based on naı̈ve Bayes models. Instead of following up on the compounds with the highest scores in the in silico model, we pursue compounds with very low but positive values. This includes unique chemotypes of weakly active compounds that enhance the applicability domain of the model and increase the cumulative hit rates. We show in a retrospective application to 81 Novartis assays that this protocol leads to consistently higher compound and scaffold hit rates compared to a standard expansion around hits or an active learning approach. We recommend using the weak reinforcement strategy introduced herein for iterative screening workflows.	active learning (machine learning);applicability domain;biological science disciplines;chemical space;design of experiments;drug discovery;flowchart;high-throughput satellite;importal;iteration;modulation;naive bayes classifier;neuritis, autoimmune, experimental;reagents;sampling (signal processing);sampling - surgical action;subgroup;thrombocytopenia;high throughput screening	Mateusz Maciejewski;Anne Mai Wassermann;Meir Glick;Eugen Lounkine	2015	Journal of chemical information and modeling	10.1021/acs.jcim.5b00054	simulation;bioinformatics;artificial intelligence	ML	8.406084751917883	-54.0060057007828	194907
8e7742512f894c2fde5f80c1f69acfa2d1dc2622	population genetic analysis of bi-allelic structural variants from low-coverage sequence data with an expectation-maximization algorithm	genomics;genetics population;alleles;genotype;high throughput nucleotide sequencing;polymorphism genetic;computational biology bioinformatics;likelihood functions;genome;algorithms;humans;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	Population genetics and association studies usually rely on a set of known variable sites that are then genotyped in subsequent samples, because it is easier to genotype than to discover the variation. This is also true for structural variation detected from sequence data. However, the genotypes at known variable sites can only be inferred with uncertainty from low coverage data. Thus, statistical approaches that infer genotype likelihoods, test hypotheses, and estimate population parameters without requiring accurate genotypes are becoming popular. Unfortunately, the current implementations of these methods are intended to analyse only single nucleotide and short indel variation, and they usually assume that the two alleles in a heterozygous individual are sampled with equal probability. This is generally false for structural variants detected with paired ends or split reads. Therefore, the population genetics of structural variants cannot be studied, unless a painstaking and potentially biased genotyping is performed first. We present svgem, an expectation-maximization implementation to estimate allele and genotype frequencies, calculate genotype posterior probabilities, and test for Hardy-Weinberg equilibrium and for population differences, from the numbers of times the alleles are observed in each individual. Although applicable to single nucleotide variation, it aims at bi-allelic structural variation of any type, observed by either split reads or paired ends, with arbitrarily high allele sampling bias. We test svgem with simulated and real data from the 1000 Genomes Project. svgem makes it possible to use low-coverage sequencing data to study the population distribution of structural variants without having to know their genotypes. Furthermore, this advance allows the combined analysis of structural and nucleotide variation within the same genotype-free statistical framework, thus preventing biases introduced by genotype imputation.	alleles;coverage data;expectation–maximization algorithm;genetics, population;genotype determination;geo-imputation;indel mutation;inference;nucleotides;one thousand;probability;reading (activity);sampling (signal processing);sampling - surgical action	José Ignacio Lucas-Lledó;David Vicente-Salvador;Cristina Aguado;Mario Cáceres	2013		10.1186/1471-2105-15-163	allele;biology;genomics;dna microarray;bioinformatics;genotype;genetics;genome	Comp.	3.099020584819255	-53.039528765679	195165
92a30166084ccce20f737a87e8cb1c23ad921c40	sparse regression based structure learning of stochastic reaction networks from single cell snapshot time series		Stochastic chemical reaction networks constitute a model class to quantitatively describe dynamics and cell-to-cell variability in biological systems. The topology of these networks typically is only partially characterized due to experimental limitations. Current approaches for refining network topology are based on the explicit enumeration of alternative topologies and are therefore restricted to small problem instances with almost complete knowledge. We propose the reactionet lasso, a computational procedure that derives a stepwise sparse regression approach on the basis of the Chemical Master Equation, enabling large-scale structure learning for reaction networks by implicitly accounting for billions of topology variants. We have assessed the structure learning capabilities of the reactionet lasso on synthetic data for the complete TRAIL induced apoptosis signaling cascade comprising 70 reactions. We find that the reactionet lasso is able to efficiently recover the structure of these reaction systems, ab initio, with high sensitivity and specificity. With only < 1% false discoveries, the reactionet lasso is able to recover 45% of all true reactions ab initio among > 6000 possible reactions and over 102000 network topologies. In conjunction with information rich single cell technologies such as single cell RNA sequencing or mass cytometry, the reactionet lasso will enable large-scale structure learning, particularly in areas with partial network structure knowledge, such as cancer biology, and thereby enable the detection of pathological alterations of reaction networks. We provide software to allow for wide applicability of the reactionet lasso.	anatomy, regional;biological system;cascade device component;lasso;network topology;resource bounded measure;sensitivity and specificity;snapshot isolation;sparse matrix;spatial variability;stepwise regression;synthetic data;time series	Anna Klimovskaia;Stefan Ganscha;Manfred Claassen	2016		10.1371/journal.pcbi.1005234	computer science;machine learning;pattern recognition;statistics	ML	5.825603563376994	-57.85735280013383	195295
565304976a25915b9cf9b5083bc5e8bbdcc1883e	a novel bioinformatics technique for predicting condition-specific transcription factor binding sites	gene expression;bioinformatics;biotechnology;in vitro;in vivo;databases;dna;dna microarray;genomics;transcription factor binding site;computer science;gene family;stochastic processes;high throughput;biological processes	The advent of high throughput sequencing and DNA microarray technologies along with the advances in bioinformatics have revolutionized biological research in the recent years. However, the precise mechanisms that control gene expression are largely unknown despite the numerous efforts to understand them. We describe a bioinformatics technique that can potentially identify condition-specific transcription factor binding sites. We applied our technique to cellular immortalization data set. Our analysis revealed similarities in upstream regions of CXCL gene family that explain condition-specific differential expression of genes CXCL1 and CXCL2, versus gene CXCL3.	bioinformatics;dna microarray;gene family;medical transcription;throughput;transcription (software);upstream (software development)	Valmik Desai;Purvesh Khatri;Arina Done;Aviva Friedman;Michael A. Tainsky;Sorin Draghici	2005	2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology		high-throughput screening;biology;genomics;molecular biology;gene expression;dna microarray;bioinformatics;gene family;in vitro;in vivo;biological process;genetics;dna;dna binding site	Comp.	4.042252469654347	-58.62098708485032	195481
8f1e4c99f81abcc9ed3c1fd4d775b5bf2cac335d	geometric de-noising of protein-protein interaction networks	sensitivity and specificity;protein protein interaction network;geometric graph;confidence level;ppis;yeast;saccharomyces cerevisiae;tandem affinity purification;complex network;geometric de noising;probabilities mathematical statistics;signal transduction;false negative;models biological;statistical significance;complexes;confidence;false positive rate;proteins;network model;reproducibility of results;life sciences;protein protein interaction;roc curve;protein protein interaction networks;algorithms;humans;interaction map;sets;protein interaction mapping;high throughput;computational biology;databases protein;bioinformatics	Understanding complex networks of protein-protein interactions (PPIs) is one of the foremost challenges of the post-genomic era. Due to the recent advances in experimental bio-technology, including yeast-2-hybrid (Y2H), tandem affinity purification (TAP) and other high-throughput methods for protein-protein interaction (PPI) detection, huge amounts of PPI network data are becoming available. Of major concern, however, are the levels of noise and incompleteness. For example, for Y2H screens, it is thought that the false positive rate could be as high as 64%, and the false negative rate may range from 43% to 71%. TAP experiments are believed to have comparable levels of noise.We present a novel technique to assess the confidence levels of interactions in PPI networks obtained from experimental studies. We use it for predicting new interactions and thus for guiding future biological experiments. This technique is the first to utilize currently the best fitting network model for PPI networks, geometric graphs. Our approach achieves specificity of 85% and sensitivity of 90%. We use it to assign confidence scores to physical protein-protein interactions in the human PPI network downloaded from BioGRID. Using our approach, we predict 251 interactions in the human PPI network, a statistically significant fraction of which correspond to protein pairs sharing common GO terms. Moreover, we validate a statistically significant portion of our predicted interactions in the HPRD database and the newer release of BioGRID. The data and Matlab code implementing the methods are freely available from the web site: http://www.kuchaev.com/Denoising.	biogrid;british informatics olympiad;chromatography, affinity;complex network;experiment;foremost;high-throughput computing;human protein reference database;image noise;matlab;network model;pixel density;processor affinity;proton pump inhibitors;purification of quantum state;sensitivity and specificity;tandem computers;throughput;two-hybrid screening;web site;protein protein interaction	Oleksii Kuchaiev;Marija Rasajski;Desmond J. Higham;Natasa Przulj	2009		10.1371/journal.pcbi.1000454	protein–protein interaction;high-throughput screening;biology;tandem affinity purification;confidence interval;false positive rate;computer science;bioinformatics;network model;machine learning;data mining;statistical significance;confidence;receiver operating characteristic;complex network;signal transduction;statistics	Comp.	6.758728070909185	-57.54494669062761	195612
c000af44785a2178f7cd4bed5c2fadc618280832	integrative network component analysis for regulatory network reconstruction	bayesian framework;microarray data;confidence level;regulatory network;high dimensionality;bayesian approach;time course;gene regulatory networks;gene expression data;chip;microarray data analysis;transcription factor;stability analysis;gene targeting;muscle regeneration;chip on chip;gene regulatory network;network component analysis	Network Component Analysis (NCA) has shown its effectiveness inregulator identification by inferring the transcription factor activity (TFA) whenboth microarray data and ChIP-on-chip data are available. However, the NCAscheme is not applicable to many biological studies due to the lack of completeChIP-on-chip data. In this paper, we propose an integrative NCA (iNCA) approachto combine motif information, limited ChIP-on-chip data, and geneexpression data for regulatory network inference. Specifically, a Bayesian frameworkis adopted to develop a novel strategy, namely stability analysis with topologicalsampling, to infer key TFAs and their downstream gene targets. TheiNCA approach with stability analysis reduces the computational cost by avoidinga direct estimation of the high-dimensional distribution in a traditionalBayesian approach. Stability indices are designed to measure the goodness of theestimated TFAs and their connectivity strengths. The approach can also be usedto evaluate the confidence level of different data sources, considering the inevitableinconsistency among the data sources. The iNCA approach has beenapplied to a time course microarray data set of muscle regeneration. The experimentalresults show that iNCA can effectively integrate motif information, ChIP-on-chip data and microarray data to identify key regulators and their gene targetsin muscle regeneration. In particular, several identified TFAs like those ofMyoD, myogenin and YY1 are well supported by biological experiments.		Chen Wang;Jianhua Xuan;Li Chen;Po Zhao;Yue Joseph Wang;Robert Clarke;Eric P. Hoffman	2008		10.1007/978-3-540-79450-9_19	biology;microarray analysis techniques;gene regulatory network;bioinformatics;data science;data mining;genetics	Vision	6.051260605587862	-54.46538700173678	196342
cdab9e893b8306555f5266d1e44a484f1572bf4a	bayesian modeling of chip-chip data using latent variables	latent variable;hidden markov model;transcription factor binding site;bayes theorem;bayesian method;computational biology bioinformatics;chip;chromatin immunoprecipitation;markov chain monte carlo;algorithms;histone modification;dna methylation;pattern recognition automated;combinatorial libraries;computational biology;computer appl in life sciences;gene expression profiling;sliding window;poisson distribution;bayesian model;microarrays;bioinformatics	The ChIP-chip technology has been used in a wide range of biomedical studies, such as identification of human transcription factor binding sites, investigation of DNA methylation, and investigation of histone modifications in animals and plants. Various methods have been proposed in the literature for analyzing the ChIP-chip data, such as the sliding window methods, the hidden Markov model-based methods, and Bayesian methods. Although, due to the integrated consideration of uncertainty of the models and model parameters, Bayesian methods can potentially work better than the other two classes of methods, the existing Bayesian methods do not perform satisfactorily. They usually require multiple replicates or some extra experimental information to parametrize the model, and long CPU time due to involving of MCMC simulations. In this paper, we propose a Bayesian latent model for the ChIP-chip data. The new model mainly differs from the existing Bayesian models, such as the joint deconvolution model, the hierarchical gamma mixture model, and the Bayesian hierarchical model, in two respects. Firstly, it works on the difference between the averaged treatment and control samples. This enables the use of a simple model for the data, which avoids the probe-specific effect and the sample (control/treatment) effect. As a consequence, this enables an efficient MCMC simulation of the posterior distribution of the model, and also makes the model more robust to the outliers. Secondly, it models the neighboring dependence of probes by introducing a latent indicator vector. A truncated Poisson prior distribution is assumed for the latent indicator variable, with the rationale being justified at length. The Bayesian latent method is successfully applied to real and ten simulated datasets, with comparisons with some of the existing Bayesian methods, hidden Markov model methods, and sliding window methods. The numerical results indicate that the Bayesian latent method can outperform other methods, especially when the data contain outliers.	aquaporin 1;archive;assumed;bacitracin;batman: arkham city;bayesian network;binary prefix;binding sites;cns disorder;cpu (central processing unit of computer system);central processing unit;chip-on-chip;class;deconvolution;design rationale;dummy variable (statistics);emoticon;experiment;flumazenil;gonatozygon aculeatum;hidden markov model;hierarchical database model;histones;html link type - copyright;index;integrated circuit;iteration;latent variable;manuscripts;markov chain monte carlo;metropolis;metropolis–hastings algorithm;microwave;mixture model;modified huffman coding;neoplasms;numerical analysis;operating system;paper;peer review;pubmed central;r language;recursion;requirement;scientific publication;silo (dataset);simulation;transcription factor;transcription (software);citation	Mingqi Wu;Faming Liang;Yanan Tian	2008		10.1186/1471-2105-10-352	chip;latent variable;sliding window protocol;biology;chromatin immunoprecipitation;dna microarray;variable-order bayesian network;markov chain monte carlo;bayesian probability;computer science;bioinformatics;machine learning;histone;dna methylation;gene expression profiling;poisson distribution;bayes' theorem;bayesian inference;genetics;hidden markov model;dna binding site	ML	4.734242276665867	-53.14596890681399	196359
59d045ee91a4a348db2c4e177fda4e61f1ec6512	virtual screening of bioassay data	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computer applications in chemistry;theoretical and computational chemistry;computational biology bioinformatics;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics	BACKGROUND There are three main problems associated with the virtual screening of bioassay data. The first is access to freely-available curated data, the second is the number of false positives that occur in the physical primary screening process, and finally the data is highly-imbalanced with a low ratio of Active compounds to Inactive compounds. This paper first discusses these three problems and then a selection of Weka cost-sensitive classifiers (Naive Bayes, SVM, C4.5 and Random Forest) are applied to a variety of bioassay datasets.   RESULTS Pharmaceutical bioassay data is not readily available to the academic community. The data held at PubChem is not curated and there is a lack of detailed cross-referencing between Primary and Confirmatory screening assays. With regard to the number of false positives that occur in the primary screening process, the analysis carried out has been shallow due to the lack of cross-referencing mentioned above. In six cases found, the average percentage of false positives from the High-Throughput Primary screen is quite high at 64%. For the cost-sensitive classification, Weka's implementations of the Support Vector Machine and C4.5 decision tree learner have performed relatively well. It was also found, that the setting of the Weka cost matrix is dependent on the base classifier used and not solely on the ratio of class imbalance.   CONCLUSIONS Understandably, pharmaceutical data is hard to obtain. However, it would be beneficial to both the pharmaceutical industry and to academics for curated primary screening and corresponding confirmatory data to be provided. Two benefits could be gained by employing virtual screening techniques to bioassay data. First, by reducing the search space of compounds to be screened and secondly, by analysing the false positives that occur in the primary screening process, the technology may be improved. The number of false positives arising from primary screening leads to the issue of whether this type of data should be used for virtual screening. Care when using Weka's cost-sensitive classifiers is needed - across the board misclassification costs based on class ratios should not be used when comparing differing classifiers for the same dataset.	academia (organization);biological assay;c4.5 algorithm;cross-reference;decision tree;naive bayes classifier;pharmaceutical bioinformatics;pharmacy (field);projection screen;pubchem;random forest;support vector machine;throughput;virtual screening;weka;benefit	Amanda C. Schierz	2009		10.1186/1758-2946-1-21	biology;medical research;medicine;computer science;bioinformatics;data science;data mining	Metrics	8.536947585269669	-53.07568669448107	196371
9d1dfef5dcba75eea61b8c3b453041ce3078ae67	camil: clustering and assembly with multiple instance learning for phenotype prediction	genomics;standards;support vector machines;sequential analysis;feature extraction;pipelines;diseases	The recent advent of Metagenome-Wide Association Studies (MGWAS) has allowed for increased accuracy in the prediction of patient phenotype (disease), but has also presented big data challenges. Meanwhile, Multiple Instance Learning (MIL) is useful in the domain of bioinformatics because, in addition to classifying patient phenotype, it can also identify individual parts of the microbiome that are indicative of that phenotype, leading to better understanding of the disease. We demonstrate a novel, efficient, and effective MIL-based computational pipeline to predict patient phenotype from MGWAS data. Specifically, we use a Bag of Words method, which has been shown to be one of the most effective and efficient MIL methods. This involves assembly of the metagenomic sequence data, clustering of the assembled contigs, extracting features from the contigs, and using an SVM classifier to predict patient labels and identify the most relevant read clusters. With the exception of the given labels for the patients, this entire process is de novo (unsupervised). We use data from a well-known MGWAS study of patients with Type-2 Diabetes and show that our pipeline significantly outperforms the classifier used in that paper, as well as other common MIL methods. We call our pipeline “CAMIL”, which stands for Clustering and Assembly with Multiple Instance Learning.	bag-of-words model;big data;bioinformatics;cluster analysis;computation;de novo transcriptome assembly;decision boundary;general-purpose modeling;metagenomics;multiple instance learning;nsa product types;support vector machine;unsupervised learning	Nathan Lapierre;Mohammad Arifur Rahman;Huzefa Rangwala	2016	2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2016.7822489	support vector machine;genomics;feature extraction;computer science;bioinformatics;sequential analysis;machine learning;data mining;pipeline transport	ML	9.682308515994238	-52.975360780871746	196537
c9a7f763d79b41e45fe723a07980fe3fc3907223	determination of sets of covariating gene expression using graph analysis on pairwise expression ratios		Motivation RNA quantiﬁcation experiments result in compositional data, however usual methods for compositional data analysis (additive log ratio [alr], centered log ratio [clr], isometric log ratio [ilr]) do not apply easily and give results difﬁcult to interpret.To handle this,a method based on disjoint subgraphs in a graph whose nodes are the quantiﬁed RNAs is proposed. Edges in the graph are deﬁned by lack of change in ratios of the corresponding RNAs between conditions.   Results The methodsis suitedforqRT-PCRandRNA-Seqdata analyses,and leadsto easy-to-interpret, graphical results and the identiﬁcation of set of genes that share a similar behavior when the studied condition changes.ForqRT-PCR data,ithas better statistical properties thanthe common ΔΔCq method.   Availability AnR package,SARP.compo,isavailable on CRAN.   Supplementary information Example scripts are available at Bioinformatics online as supplementary data.		Emmanuel Curis;Cindie Courtin;Pierre A Geoffroy;J L Laplanche;Bruno Saubaméa;Cynthia Marie-Claire	2018	Bioinformatics	10.1093/bioinformatics/bty629	power graph analysis;gene expression;computer science;pairwise comparison;bioinformatics	Comp.	4.724518458693044	-52.53896451764682	196704
96c21bcd1eada16a7af9a58e10bc2952c227d271	qsar modelling for drug discovery: predicting the activity of lrrk2 inhibitors for parkinson's disease using cheminformatics approaches		Parkinson’s disease is one of the most common neurodegenerative disorders in elder people and the leucine-rich repeat kinase 2 (LRRK2) is a promising target for its pharmacological treatment. In this paper, QSAR models for identification of potential inhibitors of LRRK2 protein are designed by using an in house chemical library and several machine learning methods. The applied methodology works in two steps: first, several alternative subsets of molecular descriptors relevant for characterizing LRRK2 inhibitors are identified by a feature selection software tool; secondly, QSAR models are inferred by using these subsets and three different methods for supervised learning. The performance of all these QSAR models are assessed by traditional metrics and the best models are analyzed in statistical and physicochemical terms.	cheminformatics;quantitative structure–activity relationship	Víctor Sebastián-Pérez;María Jimena Martínez;Carmen Gil;Nuria E. Campillo;Ana Martínez;Ignacio Ponzoni	2018		10.1007/978-3-319-98702-6_8	chemical library;cheminformatics;supervised learning;drug discovery;computational biology;molecular descriptor;lrrk2;feature selection;quantitative structure–activity relationship;computer science	ML	8.685994076676865	-57.174261205054414	197173
6f8f6f22810f2495f8cda79774152c5b680890a2	a novel approach for mining and fuzzy simulation of subnetworks from large biomolecular networks	biology computing;large biomolecular networks;subnetwork biomedical literature mining biomolecular network fuzzy logic information extraction;fuzzy simulation;regulatory system;cellular function;information extraction;dynamic model;fuzzy set theory biology computing data mining;cellular networks;interaction network;scale free network;indexing terms;data mining;cellular networks genetics context modeling predictive models humans diseases medical treatment computational modeling system testing computer networks;fuzzy set theory;genetics;genetic variation;computer networks;fuzzy logic;gene expression;comprehensive system;fuzzy rule based models;computational modeling;fuzzy rule base;side effect;diseases;system testing;time series data;cell cycle;predictive models;humans;network structure;biomedical literature mining;high throughput;medical treatment;subnetwork clustering;context modeling;biomolecular network;subnetwork;subnetwork clustering fuzzy simulation large biomolecular networks cellular function comprehensive system genetic variation regulatory system data mining fuzzy rule based models;literature search;genetic screening	Understanding the biomolecular network implementing cellular function goes beyond the old dogma of ldquoone gene: one functionrdquo; only through comprehensive system understanding can we predict the impact of genetic variation in the population, design effective disease therapeutics, and evaluate the potential side-effects of therapies. In this paper, we present a novel method to model the regulatory system that executes a cellular function, which can be represented as a biomolecular network. Our method consists of three steps. First, the biomolecular network is derived using data-mining approaches to extend the initial conceptual biomolecular network from the literature search, etc. Secondly, once the whole biomolecular network structure is complete, a novel scale-free network clustering approach is applied to obtain various subnetworks. Lastly, fuzzy rule based models are generated for the subnetworks and simulations are run to predict their behavior in the cellular context. The modeling results represent hypotheses that are tested against high-throughput data sets (microarrays and/or genetic screens) for both the natural system and perturbations. If computational results do not match experimental or previously published results, then new hypotheses are formed and they feed back into the data-mining and analyzing step to refine the biomolecular network for the next iteration. This is repeated until a good match between modeling and data is obtained. Notably, the dynamic modeling component of this method depends on the automated network structure generation of the first component and the subnetwork clustering, which are both essential to make the solution tractable. Experimental results on human gene interaction networks and gene expression time series data for the human cell cycle indicate that our approach is promising for subnetwork mining and simulation from large biomolecular networks, as it produces a better convergence between continuous modeling and experiments.	cluster analysis;cobham's thesis;computation;data mining;experiment;fuzzy logic;fuzzy rule;gene regulatory network;high-throughput computing;information management;interactome;iteration;knowledge base;metabolomics;metamodeling;microarray;network model;scalability;signal-to-noise ratio;simulation;subnetwork;system identification;throughput;time series	Xiaohua Hu;Bahrad A. Sokhansanj;Daniel Duanqing Wu;Yuchun Tang	2007	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2007.896248	fuzzy logic;interaction network;high-throughput screening;cellular network;gene expression;index term;computer science;bioinformatics;scale-free network;cell cycle;machine learning;genetic variation;time series;data mining;predictive modelling;context model;fuzzy set;computational model;system testing;information extraction;side effect	ML	6.386748764908326	-57.46115070997697	197220
63781c33edd38451da6dc899bef4fe2e7ef7ec78	prediction of human protein kinase substrate specificities	biochemistry;bioinformatics;catalysis;enzymes;learning (artificial intelligence);mass spectroscopy;molecular biophysics;molecular configurations;amino acid sequences;catalytic domain;enzymes;human protein kinase substrate specificities;machine learning models;mass spectrometry;mutual information;phosphorylation site;phosphosites;position-specific scoring matrices;protein sequencing;pssm matrices;kinase catalytic domain;phosphorylation sites;protein kinase specificity	In this paper we propose a new algorithm to predict the phosphorylation site specificities of 478 human protein kinases based on the primary structures of the catalytic domains of these enzymes. Existing methods deduce the specificity of a protein kinase through the alignment of the amino acid sequences of phospho-sites targeted by the kinase to generate a consensus sequence or they use machine learning models for recognition. However, for most protein kinases few if any substrates have been experimentally identified by protein sequencing and mass spectrometry. In this work, we used mutual information from a training set of over 200 protein kinases consensus phospho-site sequences and predicted amino acid interactions between kinases and their substrate phospho-sites to generate position-specific scoring matrices (PSSM). The results demonstrate that using our algorithm, knowledge of the primary amino acid sequence of the catalytic domain of these kinases is sufficient to predict their phosphorylation sites specificities and their PSSM matrices.	algorithm;consensus sequence;experiment;interaction;kerrison predictor;machine learning;mutual information;peptide sequence;position weight matrix;sensitivity and specificity;stochastic matrix;test set	Javad Safaei;Ján Manuch;Arvind Gupta;Ladislav Stacho;Steven Pelech	2010	2010 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2010.5706573	biology;biochemistry;enzyme;molecular biology;amino acid;mass spectrometry;bioinformatics;protein sequencing	Comp.	9.838442592582025	-57.28232400854975	197471
90569695f5df06b9326580bd5bf310b980739866	constraints on signaling networks logic reveal functional subgraphs on multiple myeloma omic data	answer set programming;omic data integration;regulatory network modeling	The integration of gene expression profiles (GEPs) and large-scale biological networks derived from Pathways Databases is a subject which is being widely explored. Existing methods are based on network distance measures among significantly measured species. Only a small number of them include the directionality and underlying logic existing in biological networks. In this study we approach the GEP-networks integration problem by considering the network logic but our approach does not require a prior species selection according to their gene expression level. We start by modeling the biological network representing its underlying logic using Logic Programming. This model points to reachable network discrete states that maximize a notion of harmony between the molecular species active or inactive possible states and the directionality of the pathways reactions according to their activator or inhibitor control role. Only then, we confront these network states with the GEP. From this analysis independent graph components are derived, each of them related to a fixed and optimal assignment of active or inactive states. These components allow us to decompose a large-scale network into subgraphs and their molecular species state assignments have different degrees of similarity when compared to the same GEP. We applied our method to study the set of possible states derived from a subgraph from the NCI-PID Pathway Interaction Database. This graph linked Multiple Myeloma (MM) genes to known receptors for this blood cancer.	biological network;database;gene co-expression network;gene expression programming;logic programming;nc (complexity);pid	Bertrand Miannay;Stéphane Minvielle;Florence Magrangeas;Carito Guziolowski	2017		10.1145/3107411.3110411	biological network;machine learning;artificial intelligence;bioinformatics;small number;answer set programming;logic programming;omics;mathematics;graph	Comp.	6.5638446926795275	-58.02701395066188	197785
b1976cb7d32ef79046151ba95e3268a702f8ce8b	a bayesian network-based approach for discovering oral cancer candidate biomarkers	pattern clustering belief networks cancer cellular biophysics feature extraction genetics genomics medical computing;gene interaction networks oral cancer gene expression data dbns;disease candidate biomarkers oral cancer candidate biomarkers head and neck region oral squamous cell carcinoma oscc neoplasms gene interaction network oral cancer genomic data dynamic bayesian networks dbn feature extraction clustering technique topological analysis method functional analysis method network nodes	Oral cancer can arise in the head and neck region. Due to the aggressive nature of the disease, which often leads to poor prognosis, Oral Squamous Cell Carcinoma (OSCC) constitutes the 8th most common neoplasms in humans. In the present work we formulate gene interaction network from oral cancer genomic data using Dynamic Bayesian Networks (DBNs). Four modules were extracted after applying a clustering technique to the network. We consequently explore them by applying topological and functional analysis methods in order to identify significant network nodes. Our analysis revealed that these important nodes may correspond to candidate biomarkers of the disease.	biological markers;cell (microprocessor);cluster analysis;dynamic bayesian network;extraction;interaction network;lip and oral cavity carcinoma;neoplasms;squamous cell carcinoma;statistical cluster	Konstantina Kourou;Konstantinos P. Exarchos;Costas Papaloukas;Dimitrios I. Fotiadis	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7320167	biology;pathology;bioinformatics;genetics	Visualization	6.263111471201522	-56.7572843635967	197791
8f6ba9680f0fe197b5258d920822ae507cb12348	breaking the hierarchy - a new cluster selection mechanism for hierarchical clustering methods	health research;uk clinical guidelines;hierarchical clustering;sensitivity and specificity;biological patents;biological and chemical;europe pubmed central;citation search;physiological cellular and medical topics;computational biology bioinformatics;uk phd theses thesis;number of clusters;life sciences;protein protein interaction;algorithms;uk research reports;medical journals;similarity measure;europe pmc;biomedical research;bioinformatics	Hierarchical clustering methods like Ward's method have been used since decades to understand biological and chemical data sets. In order to get a partition of the data set, it is necessary to choose an optimal level of the hierarchy by a so-called level selection algorithm. In 2005, a new kind of hierarchical clustering method was introduced by Palla et al. that differs in two ways from Ward's method: it can be used on data on which no full similarity matrix is defined and it can produce overlapping clusters, i.e., allow for multiple membership of items in clusters. These features are optimal for biological and chemical data sets but until now no level selection algorithm has been published for this method. In this article we provide a general selection scheme, the level independent clustering selection method, called LInCS. With it, clusters can be selected from any level in quadratic time with respect to the number of clusters. Since hierarchically clustered data is not necessarily associated with a similarity measure, the selection is based on a graph theoretic notion of cohesive clusters. We present results of our method on two data sets, a set of drug like molecules and set of protein-protein interaction (PPI) data. In both cases the method provides a clustering with very good sensitivity and specificity values according to a given reference clustering. Moreover, we can show for the PPI data set that our graph theoretic cohesiveness measure indeed chooses biologically homogeneous clusters and disregards inhomogeneous ones in most cases. We finally discuss how the method can be generalized to other hierarchical clustering methods to allow for a level independent cluster selection. Using our new cluster selection method together with the method by Palla et al. provides a new interesting clustering mechanism that allows to compute overlapping clusters, which is especially valuable for biological and chemical data sets.	adjacency matrix;appendix;archive;breadth-first search;checking (action);clique (graph theory);cluster analysis;cohesion (computer science);community;community-acquired infections;contain (action);correctness (computer science);deterministic algorithm;experiment;fever;financial cost;graph - visual representation;graph theory;group cohesiveness;hierarchical clustering;html link type - copyright;hungarian language;imre csiszár;manuscripts;maximal set;neoplasms;paper;peer review;pixel density;proton pump inhibitors;pseudocode;pubmed central;scientific publication;selection algorithm;sensitivity and specificity;similarity measure;subgroup;the matrix;time complexity;ward's method;checkpoint clamp complex location;citation;gamma-delta t-cell receptor;interest;protein protein interaction;statistical cluster	László A. Zahoránszky;Gyula Y. Katona;Péter Hári;András Málnási-Csizmadia;Katharina Anna Zweig;Gergely Zahoránszky-Köhalmi	2009	Algorithms for Molecular Biology : AMB	10.1186/1748-7188-4-12	protein–protein interaction;complete-linkage clustering;correlation clustering;constrained clustering;fuzzy clustering;computer science;bioinformatics;data science;canopy clustering algorithm;cure data clustering algorithm;data mining;hierarchical clustering;ward's method;single-linkage clustering;hierarchical clustering of networks	Comp.	4.480667739665823	-55.368659419509896	198220
01b744ca466eca025a2c5134a1f4e20f8244ad20	markov chain ontology analysis (mcoa)	animals;vocabulary controlled;probability;molecular sequence annotation;databases genetic;journal article;computational biology bioinformatics;gene expression regulation;algorithms;humans;parkinson disease;combinatorial libraries;computer appl in life sciences;gene expression profiling;markov chains;microarrays;bioinformatics	Biomedical ontologies have become an increasingly critical lens through which researchers analyze the genomic, clinical and bibliographic data that fuels scientific research. Of particular relevance are methods, such as enrichment analysis, that quantify the importance of ontology classes relative to a collection of domain data. Current analytical techniques, however, remain limited in their ability to handle many important types of structural complexity encountered in real biological systems including class overlaps, continuously valued data, inter-instance relationships, non-hierarchical relationships between classes, semantic distance and sparse data. In this paper, we describe a methodology called Markov Chain Ontology Analysis (MCOA) and illustrate its use through a MCOA-based enrichment analysis application based on a generative model of gene activation. MCOA models the classes in an ontology, the instances from an associated dataset and all directional inter-class, class-to-instance and inter-instance relationships as a single finite ergodic Markov chain. The adjusted transition probability matrix for this Markov chain enables the calculation of eigenvector values that quantify the importance of each ontology class relative to other classes and the associated data set members. On both controlled Gene Ontology (GO) data sets created with Escherichia coli, Drosophila melanogaster and Homo sapiens annotations and real gene expression data extracted from the Gene Expression Omnibus (GEO), the MCOA enrichment analysis approach provides the best performance of comparable state-of-the-art methods. A methodology based on Markov chain models and network analytic metrics can help detect the relevant signal within large, highly interdependent and noisy data sets and, for applications such as enrichment analysis, has been shown to generate superior performance on both real and simulated data relative to existing state-of-the-art approaches.	biological system;class;ergodicity;extraction;gene ontology term enrichment;gene expression programming;generative model;interdependence;markov chain;ontology (information science);rafivirumab;relevance;signal-to-noise ratio;silo (dataset);sparse matrix;stochastic matrix;structural complexity (applied mathematics)	H. Robert Frost;Alexa T. McCray	2011		10.1186/1471-2105-13-23	biology;markov chain;regulation of gene expression;dna microarray;computer science;bioinformatics;data science;probability;data mining;gene expression profiling;genetics	ML	5.505347668533664	-54.941992434210405	198244
7ac6287a538df6cbd8dbdde079684540471726fb	gene expression data modeling and validation of gene selection methods		"""Several gene selection methods have been proposed to identify sets of genes re- lated to a particular disease or to a particular functional status of the tissue. An open problem with gene selection methods consists in evaluating their perfor- mance; since we usually know only a smell subset of the genes involved in the onset of a status, and many times no relevant genes are known """"a priori"""". We propose an artificial system, based on modeling gene expression signatures, to generate synthetic gene expression data for validating gene selection methods. Comparison between gene selection methods using data generated through the artificial model are performed and preliminary results are reported."""	data modeling	Francesca Ruffino	2004		10.1007/1-4020-3432-6_9	bioinformatics;data mining;gene expression profiling	Comp.	7.25672716143434	-54.01491905334355	198432
85087853bec2deec58b27e9ecabe8f7cf7049b98	computational approach to structural analysis of protein-rna complexes	rna binding protein;interaction pattern;protein binding;structure analysis;structured data	Analyzing protein-RNA binding structures depends on a significant quantity of manual work. Therefore, the protein-RNA binding structures are generally studied individually or on a small-scale. The task of analyzing the protein-RNA binding structures manually becomes increasingly difficult as the complexity and number of protein-RNA binding structures increase. We have developed a set of algorithms for automatically analyzing the structures of the protein-RNA complexes at an atomic level and for identifying the interaction patterns between the protein and RNA. The algorithms were implemented and tested on the actual structure data of 51 protein-RNA complexes. It is believed that this is the first structural analysis of a large set of protein-RNA complexes. The results of the analysis will provide insight into the interaction patterns between a protein and RNA, and will be useful in predicting the structure of the RNA binding protein and the structure of the protein binding RNA.	algorithm;complexity;computation;hydrogen;sensitivity and specificity;structural analysis	Namshik Han;Hyunwoo Kim;Kyungsook Han	2003		10.1007/3-540-44863-2_15	plasma protein binding;data model;computer science;bioinformatics;rna-binding protein;structural analysis	Comp.	9.297668067714167	-58.673297056232066	198529
2d746c63bd1e94e144bcfe703be639ff45488629	modeling splicing sites with pairwise correlations	markov model;computer experiment;higher order;source code	MOTIVATION A new method for finding subtle patterns in sequences is introduced. It approximates the multiple correlations among residuals with pair-wise correlations, with the learning cost O(m(2)n) where n is the number of training sequences, each of length m. The method suits to model splicing sites in human DNA, which are reported to have higher-order dependencies.   RESULTS By computational experiments, the prediction accuracy of our model was shown to surpass that of previously reported Markov models for the prediction of acceptor sites in human.   AVAILABILITY The C++ source code is available on request from the authors.	acceptor (semiconductors);approximation algorithm;as-easy-as;boltzmann machine;c++;computation;experiment;markov chain;markov model;partial;protein truncation abnormality;rna splicing;source code	Masanori Arita;Koji Tsuda;Kiyoshi Asai	2002	Bioinformatics		higher-order logic;computer experiment;computer science;bioinformatics;machine learning;markov model;statistics;source code	Comp.	9.98698912690265	-56.64517199174754	198656
8656079ac5ab0d06842da4fe76b3a5c39bdb6ac6	considering unknown unknowns: reconstruction of nonconfoundable causal relations in biological networks	animals;mice;embryonic stem cells;cell differentiation;signal transduction;gene regulatory networks;bayes theorem;transcription factors;models genetic;gene expression regulation;cell proliferation;algorithms;computer simulation	Our current understanding of cellular networks is rather incomplete. We over look important but so far unknown genes and mechanisms in the pathways. Moreover, we often only have a partial account of the molecular interactions and modifications of the known players. When analyzing the cell, we look through narrow windows leaving potentially important events in blind spots. Network reconstruction is naturally confined to what we have observed. Little is known on how the incompleteness of our observations confounds our interpretation of the available data. Here we ask which features of a network can be confounded by incomplete observations and which cannot. In the context of nested effects models, we show that in the presence of missing observations or hidden factors a reliable reconstruction of the full network is not feasible. Nevertheless, we can show that certain characteristics of signaling networks like the existence of cross-talk between certain branches of the network can be inferred in a nonconfoundable way. We derive a test for inferring such nonconfoundable characteristics of signaling networks. Next, we introduce a new data structure to represent partially reconstructed signaling networks. Finally, we evaluate our method both on simulated data and in the context of a study on early stem cell differentiation in mice.	causal filter;cell differentiation process;cross-talk;data structure;departure - action;exanthema;inference;interaction;microsoft windows;partial;side effect (computer science);stem cell differentiation	Mohammad Javad Sadeh;Giusi Moffa;Rainer Spang	2013	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2013.0119	computer simulation;biology;gene regulatory network;regulation of gene expression;bioinformatics;data mining;bayes' theorem;cell growth;genetics;cellular differentiation;signal transduction;statistics;embryonic stem cell;transcription factor	Comp.	3.9352978930570712	-58.51750081879224	199012
21e2b7a3e717a5c7428e1f5332423b61c786ff71	joint inference of tissue-specific networks with a scale free topology	tissue specific networks joint inference nonhub nodes node penalties similar expression patterns jointnet tissue specific coexpression networks cell lineages human body gene expression profiles high throughput experimental techniques scale free topology;bioinformatics proteins correlation art yttrium prediction algorithms;neural nets bioinformatics biological techniques biological tissues cellular biophysics genetics	High-throughput experimental techniques have produced an enormous number of gene expression profiles for various tissues of the human body. Tissue-specificity is a key component in reflecting the potentially different roles of proteins in diverse cell lineages. One way of understanding the tissue specificity is by reconstructing the tissue-specific co-expression networks (CENs) to analyze the correlation between genes. A few methods have been developed for estimating CENs, but it still remains challenging in terms of both accuracy and efficiency. In this paper we propose a new method, JointNet, for predicting tissue-specific co-expression networks. JointNet is exploiting the observation that, functionally related tissues have similar expression patterns and thus, similar networks. It uses different node penalties for hubs and non-hub nodes to accurately estimate the scale-free networks. Our experimental results show that the resulting tissue-specific CENs are accurate and that our method outperforms the current state of the art.	design of experiments;gene co-expression network;sensitivity and specificity;throughput;usb hub	Somaye Hashemifar;Behnam Neyshabur;Jinbo Xu	2015	2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2015.7359696	biology;bioinformatics;data mining	Robotics	5.531863086734783	-56.48007234171299	199604
4d2c0baab37107f7e0504d85c9750a107e665e42	generalized logical model based on network topology to capture the dynamical trends of cellular signaling pathways	simulation and modeling;cancer;signaling pathways;systems biology;physiological cellular and medical topics;journal article;computational biology bioinformatics;dynamical system;algorithms;generalized logical model;bioinformatics	Cellular responses to extracellular perturbations require signaling pathways to capture and transmit the signals. However, the underlying molecular mechanisms of signal transduction are not yet fully understood, thus detailed and comprehensive models may not be available for all the signaling pathways. In particular, insufficient knowledge of parameters, which is a long-standing hindrance for quantitative kinetic modeling necessitates the use of parameter-free methods for modeling and simulation to capture dynamic properties of signaling pathways. We present a computational model that is able to simulate the graded responses to degradations, the sigmoidal biological relationships between signaling molecules and the effects of scheduled perturbations to the cells. The simulation results are validated using experimental data of protein phosphorylation, demonstrating that the proposed model is capable of capturing the main trend of protein activities during the process of signal transduction. Compared with existing simulators, our model has better performance on predicting the state transitions of signaling networks. The proposed simulation tool provides a valuable resource for modeling cellular signaling pathways using a knowledge-based method.	anatomy, regional;cell signaling;computation;computational model;kinetics;knowledge-based systems;logical data model;network topology;population parameter;protein phosphorylation;schedule (document type);sigmoid function;signal transduction;simulation;simulators;transduction (machine learning)	Fan Zhang;Haoting Chen;Li Na Zhao;Hui Liu;Teresa M. Przytycka;Jie Zheng	2015		10.1186/s12918-015-0249-9	computational biology;biology;computer science;bioinformatics;theoretical computer science;dynamical system;systems biology;signal transduction;cancer	Comp.	6.684074345381883	-59.112768319895736	199662
