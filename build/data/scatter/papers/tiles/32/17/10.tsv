id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
2d558f4c4797ce2b5f8d974bd23375077d8b642f	kernel k-means for categorical data	analyse amas;calculateur embarque;analisis datos;algorithme k moyenne;k means;kernel function;intelligence artificielle;feature space;classification;feasibility;data analysis;cluster analysis;hamming distance;analyse tâche;task analysis;funcion nucleo;distance hamming;fonction noyau;boarded computer;artificial intelligence;algoritmo k media;analyse donnee;k means algorithm;analisis cluster;appariement chaine;inteligencia artificial;experimental evaluation;string matching;categorical data;clasificacion;calculador embarque;distancia hamming;practicabilidad;faisabilite;donnee categorielle;dato categorico	Clustering categorical data is an important and challenging data analysis task. In this paper, we explore the use of kernel K-means to cluster categorical data. We propose a new kernel function based on Hamming distance to embed categorical data in a constructed feature space where the clustering is conducted. We experimentally evaluated the quality of the solutions produced by kernel K-means on real datasets. Results indicated the feasibility of kernel K-means using our proposed kernel function to discover clusters embedded in categorical data.	categorical variable;k-means clustering;kernel (operating system)	Julia Couto	2005		10.1007/11552253_5	kernel;kernel regression;feasibility study;kernel method;kernel fisher discriminant analysis;string kernel;kernel embedding of distributions;radial basis function kernel;kernel principal component analysis;computer science;machine learning;data mining;mathematics;tree kernel;variable kernel density estimation;polynomial kernel;algorithm;k-means clustering;kernel smoother	ML	7.976366557915984	-34.4949307561174	192664
4fde57c284dc0d450a69202829d99051274f7ecb	efficient algorithms for similarity measures over sequential data: a look beyond kernels	intruder detector;distance function;efficient algorithm;securite informatique;kernel function;metric;similitude;computer security;seguridad informatica;estructura datos;funcion nucleo;fonction noyau;similarity;intrusion detection systems;distancia;pattern recognition;metrico;structure donnee;reconnaissance forme;similitud;reconocimiento patron;detecteur intrus;detector intruso;data structure;similarity measure;systeme detection intrusion;metrique;distance	Kernel functions as similarity measures for sequential data have been extensively studied in previous research. This contribution addresses the efficient computation of distance functions and similarity coefficients for sequential data. Two proposed algorithms utilize different data structures for efficient computation and yield a runtime linear in the sequence length. Experiments on network data for intrusion detection suggest the importance of distances and even non-metric similarity measures for sequential data.	algorithm;bioinformatics;computation;computer security;data breach;data structure;euclidean distance;experiment;grams;intrusion detection system;machine learning;matthews correlation coefficient;n-gram;problem domain;unsupervised learning	Konrad Rieck;Pavel Laskov;Klaus-Robert Müller	2006		10.1007/11861898_38	data structure;metric;computer science;theoretical computer science;machine learning;mathematics;algorithm	ML	7.846289192001327	-34.57984446359192	193304
e45d0d55102bff2b68e58c2d565f584061900670	evaluation of machine learning algorithms for intrusion detection system		Intrusion detection system (IDS) is one of the implemented solutions against harmful attacks. Furthermore, attackers always keep changing their tools and techniques. However, implementing an accepted IDS system is also a challenging task. In this paper, several experiments have been performed and evaluated to assess various machine learning classifiers based on KDD intrusion dataset. It succeeded to compute several performance metrics in order to evaluate the selected classifiers. The focus was on false negative and false positive performance metrics in order to enhance the detection rate of the intrusion detection system. The implemented experiments demonstrated that the decision table classifier achieved the lowest value of false negative while the random forest classifier has achieved the highest average accuracy rate.	algorithm;bayesian network;confidentiality;dos;data mining;decision table;experiment;intrusion detection system;machine learning;memory-level parallelism;naive bayes classifier;partial template specialization;random forest;random tree;sensor	Mohammad Almseidin;Maen Alzubi;Szilveszter Kovacs;Mouhammd Alkasassbeh	2017	2017 IEEE 15th International Symposium on Intelligent Systems and Informatics (SISY)	10.1109/SISY.2017.8080566	decision table;algorithm design;artificial neural network;computer science;random forest;anomaly-based intrusion detection system;intrusion detection system;intrusion;machine learning;pattern recognition;artificial intelligence	Security	7.024135848710096	-37.60952972144189	193688
9f78e6e81a20d96e8c07cbf3d1cc111b410ff14a	practical real-time intrusion detection using machine learning approaches	decision tree;real time;false alarm rate;intrusion detection;probe;supervised machine learning;network intrusion detection;machine learning;denial of service;detection rate;feature selection;information gain;intrusion detection system	The growing prevalence of network attacks is a well-known problem which can impact the availability, confidentiality, and integrity of critical information for both individuals and enterprises. In this paper, we propose a real-time intrusion detection approach using a supervised machine learning technique. Our approach is simple and efficient, and can be used with many machine learning techniques. We applied different well-known machine learning techniques to evaluate the performance of our IDS approach. Our experimental results show that the Decision Tree technique can outperform the other techniques. Therefore, we further developed a real-time intrusion detection system (RT-IDS) using the Decision Tree technique to classify on-line network data as normal or attack data. We also identified 12 essential features of network data which are relevant to detecting network attacks using the information gain as our feature selection criterions. Our RT-IDS can distinguish normal network activities from main attack types (Probe and Denial of Service (DoS)) with a detection rate higher than 98% within 2s. We also developed a new post-processing procedure to reduce the false-alarm rate as well as increase the reliability and detection accuracy of the intrusion detection system.	intrusion detection system;machine learning;real-time locating system	Phurivit Sangkatsanee;Naruemon Wattanapongsakorn;Chalermpol Charnsripinyo	2011	Computer Communications	10.1016/j.comcom.2011.07.001	anomaly-based intrusion detection system;intrusion detection system;anomaly detection;computer science;machine learning;pattern recognition;data mining;feature selection;computer security;intrusion prevention system	Security	6.656084205978914	-37.38512229936274	194313
c4b769a54f2926117e8886ac39acaf9162d525bf	a hybrid conceptual clustering system	learning algorithm;abstraction hierarchy;conceptual modeling;conceptual clustering;dynamic environment;incremental learning;ternary relationship;genetic algorithm;entity relationship;higher normal forms	Conceptual clustering is used to organize observations into an abstract hierarchy which can be used to predict classes and/or attribute values. Typically this clustering has been done using either incremental or nonincrementallearning. Incremental learning suffers from the ordering problem, while nonincremental learning cannot handle a dynamic environment efficiently. This paper proposes a hybrid conceptual clustering system which uses two learning algorithms. The first stage is based on Genetic Algorithms and is used as a preprocessor for the second stage. The second stage is an incremental learning system. This hybrid conceptual clustering system overcomes the difficulties encountered by using either a nonincremental or an incremental learning system alone.	aggregate data;cluster analysis;conceptual clustering;evaluation function;experiment;genetic algorithm;hybrid system;machine learning;preprocessor;recursion;software release life cycle	Jungsoon P. Yoo;Chrisila C. Pettey;Sung K. Yoo	1996		10.1145/228329.228341	conceptual model;genetic algorithm;entity–relationship model;computer science;artificial intelligence;conceptual model;machine learning;data mining;conceptual clustering	AI	5.174059607218802	-31.11930735529347	194480
3d3a4ef4016b60af2d44a75efa6312211e87eaa4	intrusion detection using error correcting output code based ensemble	support vector machines;bagging;security of data error correction codes learning artificial intelligence;biological system modeling;intrusion detection;vegetation;learning systems;accuracy;ecoc approach error correcting output code based ensemble intrusion detection system computer security detection rate false alarm rate class imbalance problem bagging ensemble adaboost ensemble method hybrid ensemble error correcting output code approach;intrusion detection bagging support vector machines accuracy biological system modeling vegetation learning systems;error correcting output code ecoc intrusion detection ensemble	Intrusion Detection System is an essential part in computer security. Researchers have proposed many methods but most of them suffer from low detection rates and high false alarm rates. In this paper, we try to tackle the class imbalance problem, increase detection rates for each class and minimize false alarms in intrusion detection system. We test the performance of seven classifiers using Bagging and AdaBoost ensemble methods. We proposed a new hybrid ensemble for intrusion detection based on Error Correcting Output Code (ECOC) approach.	adaboost;bootstrap aggregating;computer security;ensemble learning;intrusion detection system	Shaza Merghani AbdElrahman;Ajith Abraham	2014	2014 14th International Conference on Hybrid Intelligent Systems	10.1109/HIS.2014.7086194	computer science;machine learning;pattern recognition;data mining;ensemble learning	EDA	7.043345814169296	-37.66364886269114	194824
419ce2c51673fe74eb1d7d15206ea4a4c1a3f2d7	visualizing class probability estimators	driving force;learning algorithm;visualizacion;apprentissage inductif;analyse fonctionnelle;intelligence artificielle;algorithme apprentissage;probabilistic approach;classification;visualization;aprendizaje por induccion;visualisation;functional analysis;modelo 2 dimensiones;enfoque probabilista;approche probabiliste;inductive learning;modele 2 dimensions;artificial intelligence;inteligencia artificial;computer science;algoritmo aprendizaje;working paper;clasificacion;two dimensional model;analisis funcional	Inducing classifiers that make accurate predictions on future data is a driving force for research in inductive learning. However, also of importance to the users is how to gain information from the models produced. Unfortunately, some of the most powerful inductive learning algorithms generate “black boxes”—that is, the representation of the model makes it virtually impossible to gain any insight into what has been learned. This paper presents a technique that can help the user understand why a classifier makes the predictions that it does by providing a two-dimensional visualization of its class probability estimates. It requires the classifier to generate class probabilities but most practical algorithms are able to do so (or can be modified to this end).	algorithm;bayesian network;decision tree;inductive reasoning;logistic regression;machine learning;statistical classification	Eibe Frank;Mark A. Hall	2003		10.1007/978-3-540-39804-2_17	functional analysis;multi-task learning;visualization;computer science;artificial intelligence;machine learning;algorithm	ML	8.953625248207366	-32.56791938315742	195406
78312291843854989a1ad097cbd5d473cba731bb	an integrated visual intrusion detection and analysis system	intrusion detection		intrusion detection system	Aurangzieb Zieb Rana;Mao Lin Huang	2004			computer vision;artificial intelligence;anomaly-based intrusion detection system;intrusion detection system;computer science	ML	7.090195389978919	-36.91268960860778	195943
2a2a4fc3de8a2c3a04ae622e083c5a6e6a74b09c	using bipartite anomaly features for cyber security applications	spam;feature extraction bipartite graph authentication principal component analysis supervised learning electronic mail;bipartite graphs;anomaly detection;authentication graphs;lateral movement;cyber security;supervised machine learning algorithm bipartite anomaly features cyber security applications bipartite graphs authentication data spam data auc improvement area under the curve improvement user computer matrix message term principal component analysis dimensionality reduction los alamos national laboratory authentication graph uci sms spam collection data set supervised classifier roc curve receiver operating characteristic curve auxiliary features bipartite anomaly scores spam detection disparate problems malicious lateral movement detection nonspam sms text messages spam sms text messages short message service text messages;anomaly detection spam authentication graphs lateral movement cyber security bipartite graphs;unsolicited e mail electronic messaging e mail filters graph theory matrix algebra pattern classification principal component analysis security of data support vector machines	In this paper we use anomaly scores derived from a technique for bipartite graphs as features for a supervised machine learning algorithm for two cyber security problems: classifying Short Message Service (SMS) text messages as either spam or non-spam and detecting malicious lateral movement within a network. While disparate problems, both spam and lateral movement detection can be viewed as bipartite graphs and we can compute bipartite anomaly scores for each situation. The bipartite anomaly scores by themselves are not very predictive, but used as auxiliary features can boost the receiver operating characteristic (ROC) curve of a supervised classifier. We examine the UCI SMS Spam Collection Data Set for the SPAM problem and use an authentication graph from Los Alamos National Laboratory. We create features by dimensionality reduction through principal component analysis (PCA) on the message-term or user-computer matrix, and then augment those features with anomaly scores. By using the anomaly scores we are able to improve the area under the curve (AUC) for the receiver operating characteristic (ROC) up to 27.5% for the spam data and 21.4% for the authentication data.	algorithm;anomaly detection;authentication;computer security;dimensionality reduction;lateral thinking;machine learning;principal component analysis;receiver operating characteristic;sensor;spamming;supervised learning	Eric L. Goodman;Joe Ingram;Shawn Martin;Dirk Grunwald	2015	2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)	10.1109/ICMLA.2015.69	spam;anomaly detection;bipartite graph;computer science;machine learning;data mining;internet privacy;world wide web	ML	6.175748043005354	-37.27185728780931	196385
2ace6e77b1f171f4c01c888214eaf9221edd6674	generalized entropy for splitting on numerical attributes in decision trees	knowledge representation;decision tree;decision tree classifier;divide and conquer	Decision Trees are well known for their training efficiency and their interpretable knowledge representation. They apply a greedy search and a divide-and-conquer approach to learn patterns. The greedy search is based on the evaluation criterion on the candidate splits at each node. Although research has been performed on various such criteria, there is no significant improvement from the classical split approaches introduced in the early decision tree literature. This paper presents a new evaluation rule to determine candidate splits in decision tree classifiers. The experiments show that this new evaluation rule reduces the size of the resulting tree, while maintaining the tree’s accuracy.	benchmark (computing);database;decision tree learning;experiment;greedy algorithm;knowledge representation and reasoning;time complexity;usability	Mingyu Zhong;Michael Georgiopoulos;Georgios C. Anagnostopoulos;Mansooreh Mollaghasemi	2006			machine learning;decision tree;decision tree learning;decision tree model;tree structure;incremental decision tree;decision stump;artificial intelligence;computer science;pattern recognition;id3 algorithm;alternating decision tree	ML	5.196030562253281	-32.290802694290186	196587
59dbae986e5b61d382c85285837ef17b8c8a98b0	on the ability of complexity metrics to predict fault-prone classes in object-oriented systems	complexity metrics;standard deviation;data collection;metrics;complexity;logistic regression;object oriented systems;lines of code;fault prone;concordant pairs;odd ratio;prediction;averaging method;logistic regression model;odds ratio	Many studies use logistic regression models to investigate the ability of complexity metrics to predict fault-prone classes. However, it is not uncommon to see the inappropriate use of performance indictors such as odds ratio in previous studies. In particular, a recent study by Olague et al. uses the odds ratio associated with one unit increase in a metric to compare the relative magnitude of the associations between individual metrics and fault-proneness. In addition, the percents of concordant, discordant, and tied pairs are used to evaluate the predictive effectiveness of a univariate logistic regression model. Their results suggest that lesser known complexity metrics such as standard deviation method complexity (SDMC) and average method complexity (AMC) are better predictors than the two commonly used metrics: lines of code (LOC) and weighted method McCabe complexity (WMC). In this paper, however, we show that (1) the odds ratio associated with one standard deviation increase, rather than one unit increase, in a metric should be used to compare the relative magnitudes of the effects of individual metrics on fault-proneness. Otherwise, misleading results may be obtained; and that (2) the connection of the percents of concordant, discordant, and tied pairs with the predictive effectiveness of a univariate logistic regression model is false, as they indeed do not depend on the model. Furthermore, we use the data collected from three versions of Eclipse to re-examine the ability of complexity metrics to predict fault-proneness. Our experimental results reveal that: (1) many metrics exhibit moderate or almost moderate ability in discriminating between fault-prone and not fault-prone classes; (2) LOC and WMC are indeed better fault-proneness predictors than SDMC and AMC; and (3) the explanatory power of other complexity metrics in addition to LOC is limited.	computational complexity theory	Yuming Zhou;Baowen Xu;Hareton K. N. Leung	2010	Journal of Systems and Software	10.1016/j.jss.2009.11.704	computer science;machine learning;logistic regression;statistics;odds ratio	Logic	4.30423574621682	-33.9801488336146	197085
b525cae980f90c293093aab2d6417876c94875a5	a data-distribution-based imbalanced data classification method for credit scoring using neural networks	accuracy data models neurons training biological neural networks artificial neural networks;imbalanced data;classification credit scroing imbalanced data data distribution;classification;data distribution;imbalanced credit data classification novel data distribution based imbalanced data classification method credit scoring model bp neural networks german credit dataset;credit scroing;pattern classification backpropagation finance neural nets	Credit scoring is always a hot topic for the researchers because of its profitability. In this paper, we proposed a novel data-distribution based imbalanced data classification method to construct the credit scoring model using BP neural networks. The method distinguished itself by focusing on the distribution of the data and artificially changes the probabilities of the sampling for the purpose of centralizing the edge samples. The German Credit Dataset is applied for verifying the effectiveness of the method, and the experiment results show that the classifiers constructed by the proposed method performs better for the imbalanced credit data classification.	authentication;centralisation;experiment;neural networks;sampling (signal processing);support vector machine	Dailing Zhang;Wei Xu	2013	2013 Sixth International Conference on Business Intelligence and Financial Engineering	10.1109/BIFE.2013.116	computer science;machine learning;pattern recognition;data mining	AI	8.564459246017561	-37.84211031675364	197426
66e2b91eb4ea48482d1cca4cd0f5e7517a244832	using cellular automata for improving knn based spam filtering	cellular automata;knn;machine learning	As rapid growth over the Internet nowadays, electronic mail (e-mails) has become a popular communication tool. However, junk mail also, known as spam has increasingly become a part of life for users as well as internet service providers. To address this problem, many solutions have been proposed in the last decade. Currently, content-based anti-spam filtering methods are an important issue; the spam filtering is considered as a special case of binary text categorization. Many machine learning techniques have been developed and applied to classify email as spam or non-spam. In this paper, we proposed an enhanced K-Nearest Neighbours (KNN) method called Cellular Automaton Combined with KNN (CA-KNN) for spam filtering. In our proposed method, a cellular automaton is used to identify which instances in training set should be selected to classify a new e-mail; CA-KNN selects the nearest neighbours not from the whole training set, but only from a reduced subset selected by a cellular automaton.	anti-spam techniques;automata theory;categorization;cellular automaton;cellular model;computer data storage;document classification;email filtering;internet;k-nearest neighbors algorithm;machine learning;organizing (structure);spamassassin;spamming;statistical classification;test set	Fatiha Barigou;Bouziane Beldjilali;Baghdad Atmani	2014	Int. Arab J. Inf. Technol.		computer science;machine learning;data mining;world wide web	Web+IR	4.96568197632528	-37.23526362358732	198360
9507a9a9d3424f4e91f1d5baf9b9451ae5250583	online anomaly detection for drinking water quality using a multi-objective machine learning approach		This document proposes the use of multi-objective machine learning in order to solve the problem of online anomaly detection for drinking water quality. Such problem consists of an imbalanced data set where events, the minority class, must be correctly detected based on a time series denoting water quality data and operative data. In order to develop two different robust systems, signal processing and feature engineering are used to prepare the data, while evolutionary multi-objective optimization is used for feature selection and ensemble generation. The proposed systems are tested with hold-out validation during optimization, and are expected to generalize well the predictions for future testing data.	anomaly detection;feature engineering;feature selection;machine learning;mathematical optimization;multi-objective optimization;signal processing;time series	Victor Henrique Alves Ribeiro;Gilberto Reynoso-Meza	2018		10.1145/3205651.3208202	computer science;anomaly detection;machine learning;signal processing;artificial intelligence;evolutionary computation;water quality;feature engineering;test data;feature selection	AI	8.688547845684235	-37.463348442808744	198616
b739cd151e38c2176cfad9583e43ae28194f29ac	compressed c4.5 models for software defect prediction	software;measurement;predictive models software measurement decision trees accuracy correlation data models;decision tree learner defect prediction software repository data mining;software repository;defect prediction;data mining;program debugging compressed c4 5 models software defect prediction software quality data mining machine learning methods prediction accuracy open source software spearman rank correlation coefficient decision tree;public domain software;accuracy;decision tree learner;software quality decision trees learning artificial intelligence program debugging public domain software;predictive models;program debugging;correlation;learning artificial intelligence;decision trees;software quality;data models	Defects in every software must be handled properly, and the number of defects directly reflects the quality of a software. In recent years, researchers have applied data mining and machine learning methods to predicting software defects. However, in their studies, the method in which the machine learning models are directly adopted may not be precise enough. Optimizing the machine learning models used in defects prediction will improve the prediction accuracy. In this paper, aiming at the characteristics of the metrics mined from the open source software, we proposed three new defect prediction models based on C4.5 model. The new models introduce the Spearman's rank correlation coefficient to the basis of choosing root node of the decision tree which makes the models better on defects prediction. In order to verify the effectiveness of the improved models, an experimental scheme is designed. In the experiment, we compared the prediction accuracies of the existing models and the improved models and the result showed that the improved models reduced the size of the decision tree by 49.91% on average and increased the prediction accuracy by 4.58% and 4.87% on two modules used in the experiment.	c4.5 algorithm;coefficient;data mining;decision tree;machine learning;mined;open-source software;optimizing compiler;software bug;tree (data structure)	Beijun Shen;Yuting Chen	2012	2012 12th International Conference on Quality Software	10.1109/QSIC.2012.19	data modeling;computer science;data science;machine learning;decision tree;data mining;accuracy and precision;predictive modelling;public domain software;correlation;software quality;measurement	SE	3.2317172961683163	-33.254591421498574	198648
add459d9d37743dc2baad703fe17f794cb6b5d3f	anomaly detection with partially observed anomalies		In this paper, we consider the problem of anomaly detection. Previous studies mostly deal with this task in either supervised or unsupervised manner according to whether label information is available. However, there always exists settings which are different from the two standard manners. In this paper, we address the scenario when anomalies are partially observed, i.e., we are given a large amount of unlabeled instances as well as a handful labeled anomalies. We refer to this problem as anomaly detection with partially observed anomalies, and proposed a two-stage method ADOA to solve it. Firstly, by addressing the difference between the anomalies, the observed anomalies are clustered, while the unlabeled instances are filtered to get potential anomalies and reliable normal instances. Then, with the above instances, a weight is attached to each instance according to the confidence of its label, and a weightedmulti-class model is built, which will be further used to distinguish different anomalies to the normal instances. Experimental results show that in the aforementioned setting, existing methods behave unsatisfactorily and the proposed method performs significantly better than all these methods, which validates the effectiveness of the proposed approach.	anomaly detection;experiment;malware;supervised learning;synthetic intelligence;unsupervised learning;verification and validation	Ya-Lin Zhang;Longfei Li;Jun Zhou;Xiaolong Li;Zhi-Hua Zhou	2018		10.1145/3184558.3186580	geophysics;anomaly detection;computer science	AI	5.9054326771080055	-37.078336349478036	199890
