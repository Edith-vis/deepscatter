id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
7cc9ee8edab9277feee8372e2721254d3ccf55bc	performance comparison between apache hive and oracle sql for big data analytics		Big data shall mean the massive volume of data that could not be stored, processed and managed by any traditional database management systems. Big Data Analytics becoming a comprehensive research area today this has attracted to all academia and industry to extract knowledge and information from a large amount of data. Oracle SQL is a prominent DBMS and is used worldwide. As the data goes bigger the running time is increasing in Oracle SQL. With the help of Apache Hive, we can do a large scale of data analysis in minimal time period. Apache Hive expedites for reading, writing and managing big datasets in distributed environment using SQL. Whereas Oracle SQL provides integrated development domain for running queries and scripts. In this paper, we have taken few queries for analysis for some smaller data sets as well as larger data sets and we have done an analysis for both Apache Hive and Oracle SQL environment.		Rotsnarani Sethy;Santosh Kumar Dash;Mrutyunjaya Panda	2016		10.1007/978-3-319-60618-7_14	oracle;sql;data mining;computer science;database;big data;distributed computing environment;scripting language;data set	ML	-32.861715518358146	-0.9079638107994434	197530
507cbc691d8ed205c734e94b1545aeba9af1abcc	scalable and queryable compressed storage structure for raster data		Compact data structures are storage structures that combine a compressed representation of the data and the access mechanisms for retrieving individual data without the need of decompressing from the beginning. The target is to be able to keep the data always compressed, even in main memory, given that the data can be processed directly in that form. With this approach, we obtain several benefits: we can load larger datasets in main memory, we can make a better usage of the memory hierarchy, and we can obtain bandwidth savings in a distributed computational scenario, without wasting time in compressing and decompressing data during data exchanges. In this work, we follow a compact data structure approach to design a storage structure for raster data, which is commonly used to represent attributes of the space (temperatures, pressure, elevation measures, etc.) in geographical information systems. As it is common in compact data structures, our new technique is not only able to store and directly access compressed data, but also indexes its content, thereby accelerating the execution of queries. Previous compact data structures designed to store raster data work well when the raster dataset has few different values. Nevertheless, when the number of different values in the raster increases, their space consumption and search performance degrade. Our experiments show that our storage structure improves previous approaches in all aspects, especially when the number of different values is large, which is critical when applying over real datasets. Compared with classical methods for storing rasters, namely netCDF, our method competes in space and excels in access and query times. © 2017 Elsevier Ltd. All rights reserved.	computer data storage;data compression;data structure;experiment;geographic information system;memory hierarchy;netcdf;raster data	Susana Ladra;José R. Paramá;Fernando Silva-Coira	2017	Inf. Syst.	10.1016/j.is.2017.10.007	data mining;database;elevation;scalability;computer science;information system;information retrieval;netcdf;raster data;data structure;raster graphics;memory hierarchy	DB	-28.863545062973863	1.7857365866591206	197578
7b3c7ab35b3f38b2bf5bb7a9b5ca736137239228	incorporating updates in domain indexes: experiences with oracle spatial r-trees	database indexing;query performance domain indexes oracle spatial r trees storage technique retrieval technique domain database spatial database text database xml gene sequence data transactional semantics deferred incorporate approach secondary table real data set immediate incorporate approach;query processing;tree data structures;query processing database indexing visual databases tree data structures transaction processing;indexation;transaction processing;spatial databases transaction databases xml information retrieval indexing proposals concurrent computing spatial indexes genetics tree data structures;visual databases	Much research has been devoted to scalable storage and retrieval techniques for domain databases such as spatial, text, XML and gene sequence data. Many efficient indexing techniques have been developed in this context. Given the improvement in the underlying technology, database applications are increasingly using domain data in transactional semantics. We examine the issue of when during the lifetime of a transaction is it better to incorporate updates in domain indexes. We present our experiences with R-tree indexes in Oracle. We examine two approaches for incorporating updates in spatial R-tree indexes: the first at update time, and the second at commit time. The first approach immediately incorporates changes in the index right away using system transactions and at commit time makes them visible to other transactions. The second approach, referred to as the deferred-incorporate approach, defers the updates in a secondary table and incorporates the changes in the index only at commit time. In experiments on real data sets, we compare the performance of the two approaches. For most transactions with reasonable number of update operations, we observe that the deferred approach outperforms the immediate-incorporate approach significantly for update operations and with appropriate optimizations achieves comparable query performance.	database;experiment;oracle spatial and graph;r-tree;scalability;table (database);xml	Kothuri Venkata Ravi Kanth;Siva Ravada;Ning An	2004	Proceedings. 20th International Conference on Data Engineering	10.1109/ICDE.2004.1320042	database index;database transaction;transaction processing;computer science;data mining;database;tree;view;information retrieval	DB	-28.710172503334356	4.072076334874631	197639
4c729f4709dad851af620d992cc03297c2da3f53	p2p-diet: one-time and continuous queries in super-peer networks	p2p system;agent platform;continuous time;data sharing;base donnee;reseau pair;e commerce;digital library;continuous query;interrogation base donnee;database;interrogacion base datos;base dato;temps continu;p2p;tiempo continuo;peer to peer p2p;intelligent system;overlay network;selective dissemination of information;p2p networks;peer to peer;autonomic computing;database query;open source	In peer-to-peer (P2P) systems a very large number of autonomous computing nodes (the peers) pool together their resources and rely on each other for data and services. P2P systems are application level virtual or overlay networks that have emerged as a natural way to share data and resources. The main application scenario considered in recent P2P data sharing systems is that of one-time querying: a user poses a query (e.g., “I want music by Moby”) and the system returns a list of pointers to matching files owned by various peers in the network. Then, the user can go ahead and download files of interest. The complementary scenario of selective dissemination of information (SDI) or selective information push is also very interesting. In an SDI scenario, a user posts a continuous query to the system to receive notifications whenever certain resources of interest appear in the system (e.g., when a song of Moby becomes available). SDI can be as useful as one-time querying in many target applications of P2P networks ranging from file sharing, to more advanced applications such as alert systems for digital libraries, e-commerce networks etc. At the Intelligent Systems Laboratory of the Technical University of Crete, we have recently concentrated on the problem of SDI in P2P networks in the context of project DIET (http://www.dfki.de/diet). Our work, summarized in [3], has culminated in the implementation of P2P-DIET, a service that unifies one-time and continuous query processing in P2P networks with superpeers. P2P-DIET is a direct descendant of DIAS, a Distributed Information Alert System for digital libraries, that was presented in [4]. P2P-DIET combines one-time querying as found in other super-peer networks and SDI as proposed in DIAS. P2P-DIET has been implemented on top of the open source DIET Agents Platform (http://diet-agents.sourceforge.net/) and it is available at http://www.intelligence.tuc.gr/p2pdiet.	autonomous robot;database;digital library;download;e-commerce;file sharing;information retrieval;library (computing);open-source software;overlay network;peer-to-peer;selective dissemination of information;sourceforge	Stratos Idreos;Manolis Koubarakis;Christos Tryfonopoulos	2004		10.1007/978-3-540-24741-8_56	digital library;overlay network;computer science;peer-to-peer;database;distributed computing;world wide web;autonomic computing	DB	-29.96995890489668	-1.9143238946226244	197712
121923af0e731ccf4c2638c5340851e0220b136f	advances in indexing for mobile objects	indexation	Spatio-temporal databases store information about the positions of individual objects over time. In many applications however, such as traffic supervision or mobile communication systems, only summarized data, like the average number of cars in an area for a specific period, or phones serviced by a cell each day, is required. Although this information can be obtained from operational databases, its computation is expensive, rendering online processing inapplicable. A vital solution is the construction of a spatiotemporal data warehouse. In this paper, we describe a framework for supporting OLAP operations over spatiotemporal data. We argue that the spatial and temporal dimensions should be modeled as a combined dimension on the data cube and present data structures, which integrate spatiotemporal indexing with pre-aggregation. While the well-known materialization techniques require a-priori knowledge of the grouping hierarchy, we develop methods that utilize the proposed structures for efficient execution of ad-hoc group-bys. Our techniques can be used for both static and dynamic dimensions.	aggregate function;algorithm;computation;data cube;data structure;hoc (programming language);insertion sort;numerical analysis;online analytical processing;online and offline;r+ tree;r-tree;real life;spatiotemporal database;temporal database;volatile memory;whole earth 'lectronic link	Pankaj K. Agarwal;Cecilia M. Procopiuc	2002	IEEE Data Eng. Bull.		data mining;search engine indexing;information retrieval;computer science;indexation	DB	-26.9024959614021	0.8034076750172886	198722
5e0e0194b861a9d558ed8724c1f844a369ff4893	smallclient for big data: an indexing framework towards fast data retrieval		Numerous applications are continuously generating massive amount of data and it has become critical to extract useful information while maintaining acceptable computing performance. The objective of this work is to design an indexing framework which minimizes indexing overhead and improves query execution and data search performance with optimum aggregation of computing performance. We propose SmallClient, an indexing framework to speed up query execution. SmallClient has three modules: block creation, index creation and query execution. Block creation module supports improving data retrieval performance with minimum data uploading overhead. Index creation module allows maximum indexes on a dataset to increase index hit ratio with minimized indexing overhead. Finally, query execution module offers incoming queries to utilize these indexes. The evaluation shows that SmallClient outperforms Hadoop full scan with more than 90% search performance. Meanwhile, indexing overhead of SmallClient is reduced to approximately 50 and 80% for index size and indexing time respectively.	algorithm;apache hadoop;b-tree;big data;block size (cryptography);clustered file system;data access;data retrieval;database index;disaster recovery;fault tolerance;full table scan;hit (internet);machine learning;mapreduce;overhead (computing);upload	Aisha Siddiqa;Ahmad Karim;Victor Chang	2016	Cluster Computing	10.1007/s10586-016-0712-4	computer science;operating system;data mining;database;information retrieval	DB	-30.58810964764099	-0.529075526255081	199006
dfa570687a4b73c04861bb12da8f4b13b4e09ebf	sap hana and its performance benefits		In-memory computing has changed the landscape of database technology. Within the database and technology field, advancements occur over the course of time that has had the capacity to transform some fundamental tenants of the technology and how it is applied. The concept of Database Management Systems (DBMS) was realized in industry during the 1960s, allowing users and developers to use a navigational model to access the data stored by the computers of that day as they grew in speed and capability. This manuscript is specifically examines the SAPHigh Performance Analytics Appliance(HANA) approach, which is one of the commonly used technologies today. Additionally, this manuscript provides the analysis of the first two of the four common main usecases to utilize SAP HANA's in-memory computing database technology. The performance benefits are important factors for DB calculations.Some of the benefits are quantified and the demonstrated by the defined sets of data.	computer;decibel;in-memory database;in-memory processing;management system;sap hana	Timur Mirzoev;Craig Brockman	2013	CoRR		computer science;data mining;database;world wide web	DB	-33.298641226742	0.05940381461519532	199149
63202f813a18c6c4abc282f4f0aa249bc01e2535	guest editorial: special issue on ranking in databases		In recent years, there has been a great deal of interest in developing effective techniques for ad-hoc search and retrieval in databases systems. In particular, a large number of emerging applications require exploratory querying on general-purpose or domain-specific databases; examples include users wishing to search bibliographic databases or catalogs of products such as homes, cars, cameras, restaurants, and photographs. Current database query languages such as SQL follow the Boolean retrieval model, i.e., tuples or elements that exactly satisfy the selection conditions laid out in the query are returned. While extremely useful for the expert user, this retrieval model is inadequate for ad-hoc retrieval by exploratory users who cannot articulate the perfect query for their needs; either their queries are very specific, resulting in no (or too few) answers, or are very broad, resulting in too many answers. To address the limitations of the Boolean retrieval model, top-k queries and ranking query results are gaining increasing importance. In fact, in many applications, ranking is an integral part of the semantics, e.g., keyword search, similarity search in multimedia as well as document databases. The increasing importance of ranking is directly derived from the explosion in the volume of data handled by current applications, which makes it almost impossible to process queries in the traditional compute-then-sort approach. This special issue of the Distributed and Parallel Databases solicited contributions that address novel and important challenges in supporting ranking in database systems. We received 17 submissions, out of which 4 original papers were accepted to the special issue.	bibliographic database;domain-specific language;floor and ceiling functions;general-purpose markup language;hoc (programming language);information retrieval;query language;sql;search algorithm;similarity search;standard boolean model	Ihab F. Ilyas	2009	Distributed and Parallel Databases	10.1007/s10619-009-7052-9	data mining;computer science;distributed computing;ranking	DB	-33.643870000371024	3.5576845339566594	199362
