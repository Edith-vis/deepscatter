id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
72115866bc97bd92a706d238fe06177704d66a37	retrieving images in fuzzy object-relational databases using dominant color descriptors	engineering;base relacional dato;base donnee;fuzzy set;procesamiento informacion;fuzzy data;database;base dato;conjunto difuso;ensemble flou;relational database;ingenierie;41a40;dominant fuzzy colors;object relational databases;information processing;base donnee relationnelle;fuzzy databases;ingenieria;sistema difuso;systeme flou;dominant color descriptor;fuzzy color descriptor;traitement information;fuzzy database;fuzzy system;image retrieval	In this paper a fuzzy approach for image retrieval on the basis of color features is presented. The proposal deals with vagueness in the color description and introduces the use of fuzzy database models to store and retrieve imprecise data. To face the color description, the concept of dominant fuzzy color is proposed, using linguistic labels for representing the color information in terms of hue, saturation and intensity. To deal with fuzzy data in our database model, we use a general approach which can support the manipulation of fuzzy objects in an object-relational database system. This allows the retrieval of images by performing flexible queries on the database. © 2006 Elsevier B.V. All rights reserved.	database model;fuzzy logic;image retrieval;object-relational database;relational database management system;vagueness	Jesús Chamorro-Martínez;Juan Miguel Medina;Carlos D. Barranco;Elena Galán-Perales;Jose Manuel Soto-Hidalgo	2007	Fuzzy Sets and Systems	10.1016/j.fss.2006.10.013	computer vision;information processing;image retrieval;relational database;fuzzy classification;computer science;artificial intelligence;data mining;mathematics;fuzzy set;information retrieval;fuzzy control system	AI	-27.576027931451794	8.675117871946663	165420
a33a4dca23e05bf8a355fb1c8a6869cb33ed7002	object migration in temporal object-oriented databases				Angelo Montanari;Elisa Peressi;Barbara Pernici	1994	Informatica (Slovenia)		object-based spatial database;database;object-oriented programming;computer science;deep-sky object;spatiotemporal database	DB	-30.969021757903167	9.188797334819387	166479
4ff3a2e89110ca24e0761e02529747e5fa07bd80	the entity-relationship time model and the conceptual rule language	entity relationship		entity–relationship model	Charalampos I. Theodoulidis;Pericles Loucopoulos;Benkt Wangler	1991				DB	-31.52954612561515	10.182200815541133	166981
7c68ea03b34085ae0819ec9db2aec830da67a7ff	xml schema element similarity measures: a schema matching context	xml schema;schema matching;similarity measure	In this paper, we classify, review, and experimentally compare major methods that are exploited in the definition, adoption, and utilization of element similarity measures in the context of XML schema matching. We aim at presenting a unified view which is useful when developing a new element similarity measure, when implementing an XML schema matching component, when using an XML schema matching system, and when comparing XML schema matching systems.	experiment;similarity measure;xml schema	Alsayed Algergawy;Richi Nayak;Gunter Saake	2009		10.1007/978-3-642-05151-7_36	xml validation;semi-structured model;relax ng;logical schema;xml schema;computer science;conceptual schema;document definition markup language;document structure description;star schema;data mining;xml schema;database;document schema definition languages;schematron;xml signature;database schema;xml schema editor;information retrieval;efficient xml interchange	DB	-32.90675115497691	5.799979461250811	167021
c93294034b0c47e58cbcc488f8445b7e4e6f87e6	extended k-d tree database organization: a dynamic multiattribute clustering method	k d tree;multiattribute;dynamic clustering;physical database design dynamic clustering method multiattribute partial match query;clustering methods information retrieval clustering algorithms tree data structures helium magnetic cores magnetic devices database systems degradation indexing;clustering method;physical database design;dynamic clustering method;partial match query	The problem of performing multiple attribute clustering in a dynamic database is studied. The extended K-d tree method is presented. In an extended K-d tree organization, the basic k-d tree structure after modification is used as the structure of the directory which organizes the data records in the secondary storage. The discriminator value of each level of the directory determines the partitioning direction of the corresponding attribute subspace. When the record insertion causes the data page to overload, the attribute space will be further partitioned along the direction specified by the corresponding discriminator.	auxiliary memory;cluster analysis;computer data storage;database design;database storage structures;datasheet;directory (computing);discriminator;tree structure	Jo-Mei Chang;King-Sun Fu	1981	IEEE Transactions on Software Engineering	10.1109/TSE.1981.230839	correlation clustering;data stream clustering;k-medians clustering;fuzzy clustering;computer science;canopy clustering algorithm;machine learning;cure data clustering algorithm;k-d tree;data mining;database;cluster analysis;single-linkage clustering;programming language;clustering high-dimensional data;conceptual clustering	DB	-28.043224105217465	4.375455207770288	167465
482798a84faefbb4aa69799b7ca51b47f7bbde05	correctness of query execution strategies in distributed databases	read only transactions;relation algebra;distributed database;management system;formal model;query optimization;distributed database access;correctness of database access;read only transaction;theoretical foundation;relational algebra	A major requirement of a Distributed DataBase Management System (DDBMS) is to enable users to write queries as though the database were not distributed (distribution transparency). The DDBMS transforms the user's queries into execution strategies, that is, sequences of operations on the various nodes of the network and of transmissions between them. An execution strategy on a distributed database is correct if it returns the same result as if the query were applied to a nondistributed database. This paper analyzes the correctness problem for query execution strategies. A formal model, called Multirelational Algebra, is used as a unifying framework for this purpose. The problem of proving the correctness of execution strategies is reduced to the problem of proving the equivalence of two expressions of Multirelational Algebra. A set of theorems on equivalence is given in order to facilitate this task. The proposed approach can be used also for the generation of correct execution strategies, because it defines the rules which allow the transformation of a correct strategy into an equivalent one. This paper does not deal with the problem of evaluating equivalent strategies, and therefore is not in itself a proposal for a query optimizer for distributed databases. However, it constitutes a theoretical foundation for the design of such optimizers.	acm transactions on database systems;correctness (computer science);distributed database;formal language;mathematical optimization;query optimization;relational database management system;turing completeness	Stefano Ceri;Giuseppe Pelagatti	1983	ACM Trans. Database Syst.	10.1145/319996.320009	query optimization;database tuning;relational algebra;computer science;theoretical computer science;relation algebra;management system;database;distributed computing;programming language;view;distributed database	DB	-28.290692887839523	10.267769301861353	168312
6e5f9c256fa3b54bd35fa6cfa87725ce6fc3c9d7	the semantics of reifying n-ary relationships as classes	institutional repositories;information model;fedora;vital;data model;relational model;vtls;ils	Many datamodelsdo not directly support -ary relationships.In mostcases,they areeitherreducedto some of their binaryprojectionsor directly translatedinto an -ary “relationshiprelation” in the relationalmodel. This paperaddressesthereificationof an -ary relationshipinto a new classwith binary relationshipsand studiesthepreservationof semanticsin thetranslation.It shows thatsomesemanticsmaybelost unlesssome explicit constraintsareaddedto thebinaryschema.		Mohamed Dahchour;Alain Pirotte	2002			relational model;data model;information model;computer science;data mining;database;world wide web	Arch	-32.43800200427099	10.50786194012085	168974
0a39cedc3e010ba532536f7076891eba919960c0	high level language constructs for relational database design			database design;high-level programming language;relational database	Michelle Connolly	1986				DB	-30.907216773583016	11.014446684686455	169191
5e203577fd08fc6c596952ce7a6a9713d59c93a9	orion 2.0: native support for uncertain data	uncertainty;database;data type;postgresql;probabilistic database;missing values;uncertain data;database management system;possible worlds	Orion is a state-of-the-art uncertain database management system with built-in support for probabilistic data as first class data types. In contrast to other uncertain databases, Orion supports both attribute and tuple uncertainty with arbitrary correlations. This enables the database engine to handle both discrete and continuous pdfs in a natural and accurate manner. The underlying model is closed under the basic relational operators and is consistent with Possible Worlds Semantics. We demonstrate how Orion simplifies the design and enhances the capabilities of two example applications: managing sensor data (continuous uncertainty) and inferring missing values (discrete uncertainty).	database engine;first-class function;missing data;null (sql);relational operator;uncertain data	Sarvjeet Singh;Chris Mayfield;Sagar Mittal;Sunil Prabhakar;Susanne E. Hambrusch;Rahul Shah	2008		10.1145/1376616.1376744	database theory;uncertainty;data type;computer science;probabilistic database;data science;data mining;database;possible world;database design	DB	-27.090799952182596	8.532334268343835	169356
58e4fd33ff3fe9abd522d02a2a44d06e57eb8adc	extending tree automata to obtain consistent query answer from inconsistent xml document	computers;finite element methods;node insertion;functional dependencies;node deletion;bottom up;data integrity;query processing;xml automata theory data integrity query processing tree data structures trees mathematics;update operations;information technology;update operations consistent query answering problem dtd functional dependencies foreign keys node insertion node deletion value modification minimal labelled xml document bottom up tree automaton integrity constraints inconsistent xml document;dtd;maintenance engineering;minimal labelled xml document;tree data structures;trees mathematics;functional dependency;automata;roads;consistent query answering problem;tree automata;integrity constraints;xml;value modification;xml document;automata theory;inconsistent xml document;automata xml educational institutions information technology education;query answering;bottom up tree automaton;foreign keys	Data may contain inconsistencies that violate integrity constraints, the consistent query answering problem attempts to find answers common for every possible repair. In this paper, we study how to handle the inconsistent XML document, which conforms to the DTD, while violates constraints. We consider three types of constraints, including functional dependencies, keys and foreign keys. We provide a repair framework for inconsistent XML document with three basic update operations: node insertion, node deletion and value modification. Following this approach, we introduce the concept of labelled XML document, which is an extension to the traditional tree model of XML with a function to indicate the unreliable nodes. We then give the definition of minimal labelled XML document, a representation of all possible repairs and can be used for consistent query answering. We provide a method for building an extended bottom-up tree automaton. The automaton can, in only one pass, not only check the validity of an XML document w.r.t DTD and integrity constraints, but also generate the corresponding minimal labelled XML document	data integrity;foreign key;functional dependency;node deletion;tree automaton;xml	Zijing Tan;Wei Wang;Baile Shi	2006	First International Multi-Symposiums on Computer and Computational Sciences (IMSCCS'06)	10.1109/IMSCCS.2006.223	well-formed document;xml catalog;xml validation;xml encryption;xml namespace;simple api for xml;relax ng;xml schema;computer science;theoretical computer science;document structure description;xml framework;data mining;xml database;xml schema;database;document schema definition languages;xml signature;xml schema editor	DB	-28.43363615108934	9.273287028153018	169393
8e60970fa25074c35f0fd17e9bee648fe733ba92	a performance analysis of semantic caching for xml query processing	information systems;query processing;performance;heterogeneous resources;extensible markup language xml;semi structured data;semantic caching;distributed systems	Caching is important for any system attempting to achieve high performance. The semantic caching is an approach trying to benefit from the certain knowledge of data semantics. The authors expect that this information might enable reuse of semantically close data rather than exactly equal to cached data in the traditional system. However, the major obstacle for extensive application of semantic caching for any data model or query language is the computational complexity of the query containment problem, which is, in general, undecidable. In this article the authors introduce and compare three approximate conservative query matching algorithms for semantic caching of semi-structured queries. The authors then analyze their applicability for distributed query processing. Based on this analysis, the authors outline few scenarios where semantic caching can be beneficial for query processing in a distributed system of heterogeneous semi-structured information resources.	cache (computing);profiling (computer programming);xml	Boris Novikov;Alice Pigul;Anna Yarygina	2013	IJKBO	10.4018/ijkbo.2013100103	query optimization;semantic computing;query expansion;web query classification;false sharing;computer science;database;web search query;world wide web;information retrieval;query language	SE	-30.352447087331914	6.502605713383892	169508
c559d164c5f6ce9a5bbbe5e5472c6708a33eab6e	a flexible extension of xpath to improve xml querying	settore inf 01 informatica;flexible query;xml retrieval;fuzzy set theory;xpath;xml document	This work presents a flexible XML selection language, FleXPath which allows the formulation of flexible constraints on both structure and content of XML documents. Some experimental results, obtained with a preliminary prototype, are described in order to show that the idea promises good results.	prototype;xml;xpath	Ernesto Damiani;Stefania Marrara;Gabriella Pasi	2008		10.1145/1390334.1390537	well-formed document;xml catalog;xml validation;xml encryption;simple api for xml;xml;relax ng;xml schema;streaming xml;computer science;xpath 2.0;document structure description;xml framework;data mining;xml database;xml schema;database;schematron;fuzzy set;xml signature;xml schema editor;information retrieval;efficient xml interchange	DB	-33.078765266216266	6.982592932926801	169638
28e189e421f088c93b4b59f711d022c119d3efb0	relational vs. object-oriented models for representing speech: a comparison using andosl data		Much effort has been expended by the speech community in designing and producing speech corpora and databases. However, considerably less thought has been given to the type of database model that best represents speech for optimal database access. This paper reviews an established database model, the relational database management system (RDBMS), as well as an emerging one, the object-oriented database management system (OODBMS). Both model types are compared by addressing identical queries to the same data that is separately represented under these respective systems. This is accomplished using an identical source of richly described speech data from ANDOSL (Australian National Database of Spoken Language). By identifying the strengths and weaknesses of both approaches new models can be defined that incorporate the best of both existing systems enabling more fluent and extensive extraction of knowledge from speech databases.	complexity;computation;computational resource;database model;impedance matching;lisp;programming language;programming paradigm;query language;relational database management system;requirement;sql;scalability;speech synthesis;text corpus;user requirements document	Toomas Altosaar;J. Bruce Millar;Martti Vainio	1999			pattern recognition;natural language processing;data model;object-oriented programming;computer science;artificial intelligence	DB	-30.31367131168095	10.175976146906793	169705
48562efef76d24ebc9aebea047a905cda1974e42	rpl: an expert system language with query power	database system;high level languages;expert systems;expert systems production systems relational databases database systems database languages intelligent systems memory query processing optimized production technology technology management;data staging rpl expert system language query power relational production language expert database systems system architecture two level database hierarchy rpl interpreter memory resident relational database;relational database;query languages;working memory;relational databases;relational databases expert systems high level languages query languages;expert system	The author introduces RPL (the relational production language) and explores the opportunities it presents for expert database systems. RPL is a language for developing expert systems that bridges the gap between expert systems and database systems. The author also introduces an expert database system architecture based on the RPL approach. Specifically, she proposes a two-level database hierarchy in which the systems' outer level comprises conventional databases and the inner level contains an RPL interpreter using a memory-resident relational database to replace working memory. The system then uses RPL rules to express and control data staging between levels. The author also discusses related work, describes ongoing research, and presents her conclusions.<<ETX>>	disk staging;expert system;relational database;system programming language;systems architecture	Lois M. L. Delcambre	1988	IEEE Expert	10.1109/64.10020	data definition language;query optimization;database theory;relational database management system;relational model;entity–relationship model;relational database;computer science;artificial intelligence;database model;data mining;database;view;database schema;expert system;information retrieval;alias;object-relational impedance mismatch;database design;query language	DB	-30.431711343146443	10.080801761697671	169969
1493345f443255880abd07c0b5aa8788b718b0ea	asic: algebra-based structural index comparison	xpath algebra;index structure;structural index;query optimization;query evaluation;indexation	Structural indices play a significant role in improving the efficiency of XML query evaluation. Being able to compare various structural indexing techniques is critical for a DBMS to select which indices to support, for the query optimizer to choose an index to use in query evaluation, and for DBAs to configure a database application. We present ASIC, an Algebra-based Structural Index Comparison framework that aids users in understanding the ability of different types of structural indices in answering XPath queries which have been characterized using the XPath algebra. ASIC allows users to select, configure and construct structural indices for comparison, guides users to compare the selected indices by evaluating queries of a particular XPath sub-algebra, and visually displays the index structures, query evaluation plans, and performance results for analysis and comparison.	application-specific integrated circuit;mathematical optimization;query optimization;xml;xpath	Yuqing Wu;Sofia Brenes;Tejas Totade;Shijin Joshua;Dhaval Damani;Michel Salim	2009		10.1145/1645953.1646329	sargable;query optimization;computer science;data mining;database;information retrieval	DB	-30.44669996793008	4.589155323732327	170054
8bb6c10802c5e74d0720537d35f8db95372108b8	semantics and efficient compilation for quantitative deductive databases	relation algebra;application expertise;quantitative deductive databases;expert systems;uncertainty;rule based;rule programmer;fixpoint theory;semantics;deductive databases relational databases logic programming expert systems uncertainty algebra calculus optimization methods data models power system management;coherent approach;rule compilation;practical application areas semantics efficient compilation coherent approach deductive database technology expert system applications logic programming quantitative deductive databases fixpoint theory rule programmer application expertise quantitative relational algebra target language rule compilation rule based expert systems uncertainty reasoning complex data;relational databases database theory expert systems logic programming;rule based expert systems;complex data;logic programming;algebra;practical application areas;power system management;target language;calculus;expert system applications;uncertainty reasoning;quantitative relational algebra;relational databases;logic programs;deductive database technology;efficient compilation;database theory;data models;optimization methods;deductive databases;expert system	A coherent approach is presented that extends relational and deductive database technology toward an integration of expert-system applications, which require sound and efficient capabilities to deal with uncertainty. Extending logic programming, the authors define the semantics of quantitative deductive databases, where fixpoint theory plays a central role. Calculus gives the rule programmer a great deal of flexibility to tailor the aggregation of certainties according to the application expertise at hand. Extending relational algebra, the authors also introduce a quantitative relational algebra as a suitable target language for rule compilation. This approach makes rule-based expert systems requiring uncertainty reasoning on large and complex data, feasible for a variety of practical application areas. >	database	Nikolaus Steger;Helmut Schmidt;Ulrich Güntzer;Werner Kießling	1989		10.1109/ICDE.1989.47274	data modeling;database theory;uncertainty;relational calculus;relational database;computer science;data mining;relation algebra;database;programming language;logic programming;expert system;complex data type	DB	-27.851302896397108	10.987237713872087	170562
9abe83b73c1d4807d5c4e5a43584f139d53d649f	implementing sequoia 2000 benchmark on shusse-uo and its performance	systeme intelligent;sistema inteligente;base donnee spatiale;estructura datos;intelligent system;base donnee orientee objet;structure donnee;object oriented databases;systeme gestion base donnee;information system;sistema gestion base datos;database management system;data structure;systeme information;sistema informacion	As an ODBMS, Shusse-Uo is built on Network Of Workstations (NOW). In Shusse-Uo, a storage manager based on distributed shared memory and a persistent programming language for object management are provided. In the paper, we introduce Shusse-Uo and discuss its features to deal with spatial data. Sequoia 2000 benchmark database is built on it. Performance tests of Shusse-Uo using Sequoia 2000 benchmark are performed. Some processing strategies are presented and the influences of clustering data on performance are analyzed, too. The results are compared with those of the related systems.	benchmark (computing);ibm sequoia;ultima online	Botao Wang;Hiroyuki Horinokuchi;Susumu Kuroki;Kunihiko Kaneko;Akifumi Makinouchi	1998			simulation;data structure;computer science;database;programming language;information system	ML	-27.818679597016605	5.6940890922870695	170727
d16330ef411b35a2292517d4914912c575464e43	foreword: deductive object-oriented databases	deductive object oriented database		database	Michael Kifer	1995	Journal of Intelligent Information Systems	10.1007/BF00961870	database theory;computer science;data mining;database;programming language	DB	-31.073978048155123	10.129390584586211	171976
1d9d1b7e3562a08d4834c66b1d21b35de602c839	on the computational complexity of cardinality constraints in relational databases	relational database;computational complexity	The theory of relational databases has attracted a great deal of attention recently [ 121. In this model data is arranged into one or more multi-column tables called relations. Each column corresponds to an attrihe. The values of the entries in a column are chosen from a set called the domain of the corresponding attribute. A relation is therefore a finite subset of the Cartesian product of the domains of its attributes. New relations can be constructed from given ones using certain algebraic operations on relations. If R is a relation, the a(R) is its set of attributes. If A E a(R), then Dom(Aj is the domain of the attribute A. Thus RQl A-(R) Dom(A). If t E R and X c a(R) then tx is a tuple t restricted to the attributes in X. The pojection on X of R is nx(R) = {tx I t E R}. The natural join is an ‘inverse’ of the projection operatsr, defined as follows: Let RI, . . . . Rm be relatio,r,S, then their natural join is defined as	cartesian closed category;computational complexity theory;linear algebra;rdf query language;relation (database);relational algebra;relational database	Paris C. Kanellakis	1980	Inf. Process. Lett.	10.1016/0020-0190(80)90013-7	database theory;discrete mathematics;complexity;relational model;decision tree model;relational database;computer science;theoretical computer science;database model;computational resource;data mining;mathematics;conjunctive query;computational complexity theory;asymptotic computational complexity;algorithm;descriptive complexity theory	DB	-26.491149953439166	9.554996696070097	174370
30b0cd91d9ad1f3d5882acbc58c73ef03b659351	multivalued dependency inferences in multilevel relational database systems	relational database system		multivalued dependency;relational database management system	Tzong-An Su;Gultekin Özsoyoglu	1989			data mining;relational model;relational database;conjunctive query;database;multivalued dependency;relational calculus;database theory;database design;computer science;functional dependency	AI	-30.893763120605104	9.188811117389175	174412
c6d238fdba47dd7a4ad519a1288f12f201eea4a7	a fuzzy temporal model and query language for fter databases	databases;erbium;fuzzy temporal query;query language;fter databases;fuzzy numbers;compounds;fuzzy number;database languages erbium uncertainty fuzzy systems data models context modeling fuzzy sets intelligent systems deductive databases application software;fuzzy temporal selection;tquel language;fuzzy set theory;fuzzy sets;query languages;fuzzy temporal selection er model fuzzy numbers fuzzy temporal query;adaptation model;temporal databases fuzzy set theory query languages;er model;tquel language query language fter databases fuzzy numbers fuzzy temporal query temporal language;temporal databases;temporal language;database languages;data models	In this paper, we propose a temporal extension to an extended ERT model and extend database temporal models to handle the fuzzy numbers. The concept of lifespan for entities and relationships is incorporated in the FTER model. We specify a fuzzy temporal query and update temporal language which is an extension from the TQuel language. The concepts of fuzzy temporal expressions, fuzzy temporal selection, fuzzy temporal join and fuzzy temporal projection are introduced, and their use in the query language is illustrated. We also discuss reducibility of the semantics to the language when applied to a static database and define the semantics of update operations.	entity;incident response team;query language;temporal expressions	Liguo Deng;Zhiheng Liang;Yong Zhang	2008	2008 Eighth International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2008.50	natural language processing;fuzzy classification;computer science;data mining;database;temporal database;query language	DB	-29.42029700692052	9.674847980392624	174563
b697193246f1ee09bd9adb22136d75fbddd57f1e	calendars, time granularities, and automata	granularite;grain size distribution;base donnee temporelle;temporal data;interrogation base donnee;interrogacion base datos;automaton;data mining;time management;granulometria;automata;temporal constraints;temporal database;workflow system;automate;database query	The notion of time granularity comes into play in a variety of problems involving time representation and management in database applications, including temporal database design, temporal data conversion, temporal database inter-operability, temporal constraint reasoning, data mining, and time management in workflow systems. According to a commonly accepted view, any time granularity can be viewed as the partitioning of a temporal domain in groups of elements, where each group is perceived as an indivisible unit (a granule). Most granularities of practical interest are modeled as infinite sequences of time granules, that present a repeating pattern and, possibly, temporal gaps within and between granules. Even though conceptually clean, this definition does not address the problem of providing infinite granularities with a finite representation to make it possible to deal with them in an effective way. In this paper, we present an automata-theoretic solution to such a problem that revises and extends the string-based model recently proposed by Wijsen [13]. We illustrate the basic features of our formalism and discuss its application to the fundamental problems of equivalence and classification of time granularities.	algorithm;automata theory;automaton;data mining;database design;date and time representation by country;finite-state machine;formal equivalence checking;grammar-based code;granule (oracle dbms);high- and low-level;human-readable medium;indivisible;interoperability;operability;ordinal data;regular expression;semantics (computer science);span and div;temporal database;turing completeness	Ugo Dal Lago;Angelo Montanari	2001		10.1007/3-540-47724-1_15	computer science;artificial intelligence;theoretical computer science;machine learning;data mining;database;distributed computing;automaton;temporal database;algorithm	DB	-29.51080446827998	10.123407463495798	174624
f5a5b510b53b19513863603546f48e215a2fc24a	an analytical comparison to two secondary index schemes: physical versus logical addresses	base donnee;mise a jour;database;base dato;pregunta documental;analyse;question documentaire;indexing;indexation;relacion;indizacion;query;analysis;puesta al dia;relation;updating;analisis	Abstract   The use of indexes usually improves the performance of queries but degrades the performance of updates, inserts and deletes. This paper focuses on reducing the cost of index maintenance when tuples are inserted or deleted. We present a scheme where secondary indexes contain logical as opposed to physical pointers. We develop an analytical model for the total cost of processing queries, updates, inserts and deletes, for this scheme and compare it with the cost of the typical secondary index scheme that uses physical pointers. We find by modifying the parameters that reduce the query cost, such as reducing the probability of occurrence of a query or reducing the average selectivity of a secondary key that the logical pointer scheme can achieve a better performance than the physical pointer scheme. However, selecting one scheme over the other is highly dependent on a number of parameters that are germane to the particular database application environment.		Edward Omiecinski	1993	Inf. Syst.	10.1016/0306-4379(93)90031-U	computer science;analysis;data mining;database;algorithm	DB	-27.86643261872045	4.25034603102924	174920
e93983f79480f135212828ffb4cb18a910c6d765	data abstraction, views and updates in rigel	relational data;generators;aggregation function;programming language;views;programming environment;data abstraction;relational data base systems;programming languages;type system;generic programming	Language constructs to support the development of data base applications provided in the programming language rigel are described. First, the language type system includes relations, views, and tuples as built-in types. Tuple-values are introduced to provide more flexibility in writing procedures that update relations and views.Second, an expression that produces sequences of values, called a generator, is defined which integrates relational query expressions with other iteration constructs found in general-purpose programming languages. As a result, relational expressions can be used in new contexts (e.g., as parameters to procedures) to provide new capabilities (e.g., programmer-defined aggregate functions).Lastly, a data abstraction facility, unlike those proposed for other data base programming languages, is described. It provides a better notation to specify the interface between a program and a data base and to support the disciplined use of views.All of these constructs are integrated into a sophisticated programming environment to enhance the development of well-structured programs.	abstraction (software engineering);aggregate data;general-purpose programming language;integrated development environment;iteration;programmer;relational database;type system;view (sql)	Lawrence A. Rowe;Kurt A. Shoens	1979		10.1145/582095.582107	fourth-generation programming language;first-generation programming language;protocol;declarative programming;language primitive;type system;data manipulation language;programming domain;reactive programming;relational database;computer science;theoretical computer science;third-generation programming language;functional logic programming;database;programming paradigm;procedural programming;symbolic programming;low-level programming language;inductive programming;fifth-generation programming language;programming language theory;programming language;generic programming;view;second-generation programming language;high-level programming language;comparison of multi-paradigm programming languages	PL	-29.655529113706766	11.202948378464505	175586
0c95c818a2ae5720361d0f15230bc125f13ec671	skyline with presorting	query processing;sorting;relational engine presorting pareto operator skyline operator sort filter skyline algorithm skyline queries;data engineering;relational databases;sorting pareto analysis database theory relational databases query processing;database theory;pareto analysis	The skyline, or Pareto, operator selects those tuples that are not dominated by any others. Extending relational systems with the skyline operator would offer a basis for handling preference queries. Good algorithms are needed for skyline, however, to make this efficient in a relational setting. We propose a skyline algorithm, SFS, based on presorting that is general, for use with any skyline query, efficient, and well behaved in a relational setting.	algorithm;clustered file system;external sorting;mathematical optimization;pareto efficiency;query optimization;skyline operator	Jan Chomicki;Parke Godfrey;Jarek Gryz;Dongming Liang	2003		10.1109/ICDE.2003.1260846	pareto analysis;database theory;information engineering;relational database;computer science;sorting;data mining;database;information retrieval	DB	-27.26470474177922	5.113036510702894	175633
9a848e13443fc896616079347e4bdc1d5d041da4	identifying and update of derived functions in functional databases	derived functions;functional programming data integrity database management systems;interactive design aid;redundant specification;data integrity;database management systems;interactive design aid derived functions functional databases consistency problems redundancies redundant specification conceptual schema updates;spatial databases data models computer science;functional programming;functional databases;conceptual schema;side effect;design and implementation;updates;spatial databases;consistency problems;computer science;redundancies;interaction design;data models	The consistency problems that arise in the design and implementation of functional databases are investigated. The notion of derived functions is used to capture the redundancies that are a common feature of the specification of fundamental databases. To maintain the consistency of databases in the presence of redundant specification, the derived functions in the conceptual schema are identified, and updates on derived functions are performed in a manner consistent with their derivations. An interactive design aid is developed to facilitate the identification of derived functions. Algorithms are developed of derived functions. Algorithms are developed that perform updates in a side-effect-free manner. >	database	Ramana Yerneni;Sitaram Lanka	1989		10.1109/ICDE.1989.47206	data modeling;computer science;conceptual schema;theoretical computer science;interaction design;data integrity;data mining;database;functional programming;side effect	DB	-30.211072573510112	10.895381155678137	175996
cb48f8c2f96ebddcecc68be4b4e13016bbc26ba4	loosely-coupled linkage of data from structured and semi-structured databases			database;linkage (software);semiconductor industry	Fahad M. Al-Wasil;W. Alex Gray	2004			database;data mining;computer science	DB	-33.18701137777485	8.903757954660115	176449
bf23f1730cdab54b1b8dc123dfb8998c64441b2b	an object-oriented rule evaluation scheme for logical databases in massively parallel environment		This paper extends an object-oriented approach to query processing in a deductive database with the consideration of deductive rules. In the object-oriented approach, each deductive rule and fact is represented as an active object, which acts with its own dedicated control sequences according to its functionality. All operations in objects are proceeded asynchronously. Since no object has global knowledge about the database, cooperation among objects is necessary in answering a query. While most of the conventional search strategies focus on some parts of the AND/OR tree expanded by a query at a time, the object-oriented approach can search down the AND/OR tree with a breadth-first strategy in parallel. As a result, all parts of the tree can be considered globally so that queries do not have to be evaluated in a tuple-by-tuple, operation-by-operation fashion; and the need of maintaining temporary relations can be eliminated.		Phillip C.-Y. Sheu;Won S. Lee	1994	International Journal on Artificial Intelligence Tools	10.1142/S0218213094000297	computer science;theoretical computer science;machine learning;data mining;database;range query	DB	-28.038627943559476	9.991104582483677	176496
44e1708eb9f7adc085240088326b5538da813ab4	retrieval and extraction by content of images in an object oriented database				Chabane Djeraba;Patrick Fargeaud;Henri Briand	1997			computer vision;object-oriented programming;artificial intelligence;computer science	DB	-31.23786086313907	8.66871062783056	176954
a0077c4575989c89c986fa02e274a0e72912bf24	relational storage and processing of two-dimensional diagrams	base relacional dato;relational database;base donnee relationnelle	Abstract   We present a relational representation of diagrams which accommodates the three fundamental categories of graphical object: points, lines and regions, uniformly. This representation permits a large variety of queries and processes to be performed on the graphical data using the extended relational algebra. We describe a relational picture editor, which we have implemented, which creates the diagrams in the first place and allows them to be displayed and modified. We discuss a low-level data structure, based on dynamic multipaging, which combines the best of the polygon and the pixel representations of pictures, and we examine the interactions of this data structure with the relational representation.	diagram	T. H. Merrett;B. Düchting	1985	Computers & Graphics	10.1016/0097-8493(85)90051-2	domain relational calculus;relational model/tasmania;relational model;codd's theorem;statistical relational learning;relational calculus;entity–relationship model;relational database;computer science;theoretical computer science;data mining;database;conjunctive query	OS	-29.688111167382125	9.356713244289152	177118
91c924c01b00a6196e93bfaa6c8c179a78629019	extended set operators for nested relations and complex objects	complex objects;satisfiability;object oriented database	Extended set operators defined originally for nested relations form a basis for the set operators for complex objects because  the common approach based on the application of set operators to sets of oids (based on the equality of oids) alone is not  sufficient as pointed out in the literature. Extended set operators operate directly on nested relations and produce nested  relations. Hence, restructuring of the operands and the result are not needed. We consider the set operators for nested relations  proposed in the literature and analyze them with respect to a property that we call information equivalence. We also show  that some of these operators are not information equivalent. Then we define new extended set operators and show that they  satisfy the information equivalence property. We also discuss different semantics (single value and complex object semantics)  of nested relations and define the extended set operators accordingly.  		Eser Sükan;Z. Meral Özsoyoglu	1995		10.1007/BFb0049145	object-based spatial database;theoretical computer science;object-oriented design;algorithm;satisfiability	DB	-27.84792288347327	10.182174068841123	177233
916ffb2fd12f89225a7d55212a871d977b0bfd64	triple-node hierarchies for object-oriented database indexing	query processing;aggregation index;index structure;aggregation;indexing;object oriented database systems;indexation;performance analysis;object oriented databases;object oriented database;inheritance	An indexing structure called triple-node hierarchy is proposed for enhancing query processing in object-oriented database systems. The proposed structure provides eecient support for object references along an aggregation hierarchy by maintaining direct mapping between objects of interested pairs of classes. The intermediate classes along the object path are maintained separately for update purpose. We show that the proposed structure can achieve better performance compared to the previously known methods. The superior performance is also demonstrated by a set of simulations based on a cost model that we have developed. With some mod-iication, the proposed structure can also provide fast support for object navigation in an integration of aggregation and inheritance hierarchies. Our results show that the extended triple-node hierarchy performs better than the best previous method known to us.	analysis of algorithms;mod database;simulation	Frank Hing-Wah Luk;Ada Wai-Chee Fu	1998		10.1145/288627.288685	search engine indexing;database theory;computer science;data mining;database;view;world wide web;database schema;information retrieval;database design	DB	-28.581481329543056	5.222003811781858	177364
0059711a184cedff9c0cb2704e51da84789a17c6	an empirical approach to query-subquery nets with tail-recursion elimination		We propose a method called QSQN-TRE for evaluating queries to Horn knowledge bases by integrating Query-Subquery Nets with a form of tail-recursion elimination. The aim is to improve the QSQN method by avoiding materialization of intermediate results during the processing. We illustrate the efficiency of our method by empirical results, especially for tail-recursive cases.	recursion (computer science);sql;tail call	Son Thanh Cao;Linh Anh Nguyen	2014		10.1007/978-3-319-10518-5_9	computer science;tail call;data mining;deductive database	Logic	-26.956123507719923	10.02570315717713	178280
584fbb9db1199f733b077fc0694cfc4740c1bd9c	distributed searching of k-dimensional data with almost constant costs	gestion informacion;information structure;base donnee repartie;distributed database;structure information;information retrieval;base donnee temporelle;estructura informacion;base repartida dato;1 dimensional;distributed data structure;worst case analysis;multi dimensional;recherche information;information management;message passing;distributed search;temporal databases;recuperacion informacion;information system;gestion information;systeme information;sistema informacion	In this paper we consider the dictionary problem in the scalable distributed data structure paradigm introduced by Litwin, Neimat and Schneider and analyze costs for insert and exact searches in an amortized framework. We show that both for the 1-dimensional and the k dimensional case insert and exact searches have an amortized almost constant costs, namely O ( log(1+A) n ) messages, where n is the total number of servers of the structure, b is the capacity of each server, and A = b 2 . Considering that A is a large value in real applications, in the order of thousands, we can assume to have a constant cost in real distributed structures. Only worst case analysis has been previously considered and the almost constant cost for the amortized analysis of the general k -dimensional case appears to be very promising in the light of the well known difficulties in proving optimal worst case bounds for k -dimensions.	amortized analysis;best, worst and average case;data structure;dictionary;extensibility;lazy evaluation;programming paradigm;scalability;server (computing);whole earth 'lectronic link	Adriano Di Pasquale;Enrico Nardelli	2000		10.1007/3-540-44472-6_19	message passing;amortized analysis;computer science;theoretical computer science;data mining;one-dimensional space;database;distributed computing;temporal database;information management;distributed database;information system	Theory	-28.197111999456713	5.674412906604016	178440
8d178fb630f999884a4855691a9075ec17cb1195	composite temporal events in active database rules: a logic-oriented approach	database system;active database;finite state machine;deductive databases	 Several database systems support active rules, and are currently beingextended with languages for detecting complex patterns of temporalevents. These languages have used for their definition and implementation,an assortment of formalisms ranging from Finite-State Machines, toPetri Nets and Event Graphs. In this paper, we show that the semanticsof deductive databases supply a more general and complete basis for thedefinition of such languages. In fact, we develop a model, whereby an... 	active database	Iakovos Motakis;Carlo Zaniolo	1995		10.1007/3-540-60608-4_32	database theory;database search engine;surrogate key;relational database;database model;data mining;database;view;database schema;information retrieval;database design;spatiotemporal database;component-oriented database	DB	-30.653128095920273	10.318827348819434	178488
860e1dc0fec530f962ae14a8b45199f06835a838	managing schema versions in a time-versioned non-first-normal-form relational database	relational database;schema versioning;normal form	Support of time versions is a very advanced feature in a DBMS. However, full flexibility of history processing is achieved only if we can also change the database schema dynamically, without touching the history. A technique for achieving this goal is here presented, in the frames of the Non-First- Normal-Form (NF2) relational data model. The environment is a pilot DBMS supporting this model, developed by the Advanced Information Management (AIM) project at the IBM Heidelberg Scientific Center. The technical solution pursues to minimize the storage space and the number of data versions. One way to achieve this is to avoid the immediate update of all data instances in the context of a schema change. Transformations between versions enable the correct interpretation of data. The management of time-related queries becomes complicated, when schema changes are involved. The paper describes a technique of applying global views over different schema versions, when formulating the queries and their results.	first normal form;relational database	Peter Dadam;Jukka Teuhola	1987		10.1007/978-3-642-72617-0_12	schema migration;information schema;relational database management system;relational model;relational calculus;semi-structured model;logical schema;entity–relationship model;relational database;knowledge management;conceptual schema;database normalization;database model;star schema;data mining;database;view;database schema;database design	DB	-31.81462790958402	9.714636976149405	178996
78c818d5179799ed4cb95a516231a33e175e32f4	automatic semantic object discovery and mapping from non-normalised relational database systems	base relacional dato;semantica formal;optimization technique;integration information;object database;data migration;formal semantics;relational database;database integration;semantique formelle;information integration;integracion informacion;base donnee orientee objet;base donnee relationnelle;relational database system;object oriented databases;systeme gestion base donnee;information system;sistema gestion base datos;database management system;systeme information;reverse engineering;sistema informacion	In this paper we present an algorithm which automatically discovers potential semantic object structures in a relation, which may be in non-2NF. This algorithm can be utilised in reverse engineering of relational schemas, data migration from relational to object database systems and database integration. The algorithm has been implemented, and we report on issues arising from this implementation including optimization techniques incorporated.		Sokratis Karkalas;Nigel J. Martin	2000		10.1007/3-540-40888-6_9	relational database management system;data migration;relational model;entity–relationship model;relational database;computer science;information integration;data integration;database model;formal semantics;data mining;database;change data capture;world wide web;graph database;information system;database design;reverse engineering	DB	-31.73472162081074	9.755594527260827	179002
c17c77eacb46d6bbe9f687d222acca458cf01817	the extended relational algebra, a basis for query languages	relation algebra;query language		relational algebra	T. H. Merrett	1978			domain relational calculus;discrete mathematics;rdf query language;query language;codd's theorem;conjunctive query;query optimization;query by example;sargable;computer science	DB	-29.91889292019912	8.910329255850282	179020
153d946842e7dc48f131be53abe6e9a214d0d59a	a graph method for keyword-based selection of the top-k databases	data sharing;distributed database;query processing;information retrieval;relational database;data storage;keyword search;graph;distributed databases;relational databases;database management system;data manipulation language;database summary	While database management systems offer a comprehensive solution to data storage, they require deep knowledge of the schema, as well as the data manipulation language, in order to perform effective retrieval. Since these requirements pose a problem to lay or occasional users, several methods incorporate keyword search (KS) into relational databases. However, most of the existing techniques focus on querying a single DBMS. On the other hand, the proliferation of distributed databases in several conventional and emerging applications necessitates the support for keyword-based data sharing and querying over multiple DMBSs. In order to avoid the high cost of searching in numerous, potentially irrelevant, databases in such systems, we propose G-KS, a novel method for selecting the top-K candidates based on their potential to contain results for a given query. G-KSsummarizes each database by a keyword relationship graph, where nodes represent terms and edges describe relationships between them. Keyword relationship graphs are utilized for computing the similarity between each database and a KS query, so that, during query processing, only the most promising databases are searched. An extensive experimental evaluation demonstrates that G-KS outperforms the current state-of-the-art technique on all aspects, including precision, recall, efficiency, space overhead and flexibility of accommodating different semantics.	computer data storage;data manipulation language;distributed database;experiment;graph (discrete mathematics);overhead (computing);preprocessor;relational database;relevance;repeatability;requirement;scoring functions for docking;search algorithm;windows legacy audio components	Quang Hieu Vu;Beng Chin Ooi;Dimitris Papadias;Anthony K. H. Tung	2008		10.1145/1376616.1376707	sargable;query optimization;database theory;relational database;computer science;probabilistic database;query by example;data administration;database model;data mining;database;view;database schema;distributed database;graph database;information retrieval;alias;database testing;database design;spatiotemporal database	DB	-31.437776705022213	4.222325496358083	179107
4a03c471865845a1b19aa4d427a6c2be6e08620d	a data model and data structures for moving objects databases	query language;image databases;spatio temporal databases;moving object database;spatial structure;data type;vldb;data model;internet;geo spatial;object oriented;data structure	We consider spatio-temporal databases supporting spatial objects with continuously changing position and extent, termed moving objects databases. We formally define a data model for such databases that includes complex evolving spatial structures such as line networks or multi-component regions with holes. The data model is given as a collection of data types and operations which can be plugged as attribute types into any DBMS data model (e.g. relational, or object-oriented) to obtain a complete model and query language. A particular novel concept is the sliced representation which represents a temporal development as a set of units, where unit types for spatial and other data types represent certain “simple” functions of time. We also show how the model can be mapped into concrete physical data structures in a DBMS environment.	data model;data structure;electron hole;query language;temporal database	Luca Forlizzi;Ralf Hartmut Güting;Enrico Nardelli;Markus Schneider	2000		10.1145/342009.335426	data modeling;object-based spatial database;semi-structured data;the internet;data structure;data type;data model;computer science;database model;data mining;database;programming language;object-oriented programming;spatial database;logical data model;information retrieval;database design;query language;spatial query;very large database	DB	-29.84638130728415	8.488065002711926	179510
ad3040bb382b95ec0f617989fbabda2e96a8da00	enriching the class diagram concepts to capture natural language semantics for database access	class diagram;database system;relation algebra;object oriented model;transformation model;natural language queries;natural language semantics;uml class diagram;conceptual schema;natural language;object oriented analysis;object oriented modeling oo modeling;database query;natural language processing;logical form	Research on accessing databases using natural languages usually utilizes an intermediate logical form for the mapping process from natural languages to database query languages. However, there is still much that needs to be accomplished to bridge the gap between natural language constructs and database schemas. In this paper, we present a translation scheme for transforming natural language queries into relational algebra through the class diagram representations. Based on a logical form developed by extending the UML class diagram notations, a transformation model is presented to support the automatic transformation of natural language queries into relational algebra by employing appropriate natural language processing techniques and object-oriented analysis methods. The proposed logical form has the advantage that it can be mapped from natural language constructs by referring to the conceptual schema modeled by class diagrams, and can be efficiently transformed into relational algebra for query execution. We believe the whole process could offer a clear and natural framework for processing natural language queries to retrieve data from database systems. 2008 Elsevier B.V. All rights reserved.	class diagram;conceptual schema;database schema;natural language processing;query language;relational algebra;syntax-directed translation;unified modeling language	Frank S. C. Tseng;Chun-Ling Chen	2008	Data Knowl. Eng.	10.1016/j.datak.2008.05.006	natural language processing;language identification;data definition language;natural language programming;universal networking language;question answering;communication diagram;data manipulation language;object language;entity–relationship model;data control language;computer science;class diagram;database;rdf query language;programming language;database schema;database design;query language;object constraint language;computational semantics	DB	-30.237329397265796	10.581561389281433	179540
637aed125498f2d19c69d62a073e7385d33e4769	reconciling point-based and interval-based semantics in temporal relational databases: a treatment of the telic/atelic distinction	database semantics;temporal data;relational database;artificial intelligent;database semantics point based semantics interval based semantics temporal relational databases telic atelic distinction three sorted temporal model coercion functions query time data models;temporal database;data models temporal databases relational databases database theory;temporal databases;relational databases;database theory;data models;relational databases artificial intelligence database languages algebra data models database systems standards publication bibliographies cognitive science	The analysis of the semantics of temporal data and queries plays a central role in the area of temporal databases. Although many different algebrae and models have been proposed, almost all of them are based on a point-based (snapshot) semantics for data. On the other hand, in the areas of linguistics, philosophy, and recently, artificial intelligence, an oft-debated issue concerns the use of an interval-based versus a point-based semantics. In this paper, we first show some problems inherent in the adoption of a point-based semantics for data, then argue that these problems arise because there is no distinction drawn in the data between telic and atelic facts. We then introduce a three-sorted temporal model and algebra including coercion functions for transforming relations of one sort into relations of the other at query time which properly copes with these issues.	artificial intelligence;relational database;snapshot (computer storage);temporal database	Paolo Terenziani;Richard T. Snodgrass	2004	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2004.1277816	database theory;relational model;entity–relationship model;relational database;computer science;probabilistic database;database model;data mining;database;temporal database;conjunctive query;view;information retrieval;database design;spatiotemporal database	DB	-28.15550522618731	8.98333257554887	179562
edd352f9993cd7674afe78152e4bce539990a413	the functional data model as the basis for an enriched database query language	database system;graph databases;semantic network;semantic networks;functional programming;data model;functional data model;functional data;functional language;database query	Conventional database languages rely on the user specifying what relations are to be used when evaluating a query. Consequently they preclude queries which involve searching for unspecified connections or associations in the database. In this paper we present Hydra, a functional language with all the facilities to define, update and query a database, which also enables users to carry out “associational” queries. Hydra uses a graph-based data model in which nodes represent values or entities and arcs the relationships between them. Associational facilities are made possible by the provision of built-in functions which find paths through the database graph. The mappings between sets of nodes in the database graph are represented as functions at the Hydra language level and it is as lists of such functions that associational results are returned. The use of a functional language is important since such languages allow functions to be returned as results; such an approach could not be adopted in a logic-based language which would not permit predicates to be returned as answers. Hydra also allows users to define general computational functions which are not considered to form part of the database. This use of two sets of functions achieves a computationally complete system which extends the query power of previous database systems without compromising their expressive or query power.	class hierarchy;computation;data definition language;data model;database schema;entity;first-class citizen;functional programming;graph (discrete mathematics);hydra (chess);programming language;prolog;relational database;type system	Robert Ayres	1999	Journal of Intelligent Information Systems	10.1023/A:1008700925537	online aggregation;data definition language;query optimization;database theory;data manipulation language;database tuning;data control language;computer science;theoretical computer science;database model;data mining;database;rdf query language;semantic network;programming language;functional programming;view;database schema;graph database;alias;database testing;database design;query language	DB	-28.527734751440736	10.000885842317492	179592
50bf8087ffd6e926c28d879c1ac1f90819ec0206	xml multimedia retrieval	busqueda informacion;text;multimedia retrieval;multimedia;information retrieval;xml language;chaine caractere;texte;base donnee multimedia;recherche information;cadena caracter;multimedia databases;xml document;texto;langage xml;lenguaje xml;character string	Multimedia XML documents can be viewed as a tree, whose nodes correspond to XML elements, and where multimedia objects are referenced in attributes as external entities. This paper investigates the use of textual XML elements for retrieving multimedia objects.	document;entity;xml schema	Zhigang Kong;Mounia Lalmas	2005		10.1007/11575832_24	xml catalog;xml validation;xml encryption;xml base;xml namespace;simple api for xml;xml;streaming xml;computer science;document type definition;document structure description;xml framework;xml database;xml schema;database;qname;xml signature;programming language;world wide web;xml schema editor;information retrieval;efficient xml interchange;sgml	DB	-33.68205704242328	7.556286098532727	180202
fce4e18a6bcef4f15b1dcd9210fad6240ed5dccb	similarity evaluation of xml documents based on weighted element tree model	frequent pattern;data management;element tree;clustering;similarity evaluation;xml;xml document;structural similarity	The logical presentation model of XML data is the basis of XML data management. After introducing XML tree models and frequent pattern models, in this paper we have proposed a novel Weighted Element Tree Model (WETM) for measuring the structural similarity of XML documents. This model is a concise form of XML tree models, so the efficiency of the operation on this model is higher than XML tree models. And comparing with frequent pattern models, the WETM enhances the expression ability of structural information of sub trees, which can appreciate the accuracy of similarity evaluation. Moreover, in order to compare the performance of the proposed evaluation algorithm, it is applied to XML documents clustering. The experimental results show that our algorithm is superior to the algorithms based on tree models or frequent pattern models.	xml	Chenying Wang;Xiaojie Yuan;Hua Ning;Xin Lian	2009		10.1007/978-3-642-03348-3_71	xml validation;simple api for xml;xml;xml schema;data management;computer science;document structure description;data mining;xml schema;database;information retrieval	DB	-32.20092632912059	5.440762061514707	180475
d8ff5b45af1e424433409ea2ce6e2ab837c2b1a4	on estimating block accesses in database organizations	blocking factor;number of block accesses;selection;database;variable block size;join;attribute cardinality estimation	In designing a physical database organization, one almost inevitably encounters the following estimating problem: Given k records to be retrieved oat of a f i le of n records organized into m blocks, how many of the m blocks have to be accessed? A correct solution to this problem was given by B. Yao. The solution as a function of Y(n, m, k) depends on the assumptions that n, m, and k are nonstochastic, as well as uniform block size. This paper examines the validity of this function when some of the assumptions are not true.	block size (cryptography);yao graph	W. S. Luk	1983	Commun. ACM	10.1145/182.358456	selection;computer science;theoretical computer science;data mining;database;mathematics	DB	-27.825918315061955	4.285432615006542	180555
aa6a1ab3516d100ebca527454d18059c6e77492c	a database interface for file updates	query language;database system;information loss;optimization technique;internal structure;satisfiability;communication channels;structured data	"""Database systems are concerned with structured data. Unfortunately,data is still often available in an unstructured manner (e.g., infiles) even when it does have a strong internal structure (e.g.,electronic documents or programs). In a previous paper [2], wefocussed on the use of high-level query languages to access suchfiles and developed optimization techniques to do so. In thispaper, we consider how structured data stored in files can beupdated using database update languages.The interest of using database languages to manipulate files istwofold. First, it opens database systems to<i>external</i> data. This concerns data residing infiles or data transiting on communication channels and possiblycoming from other databases [2]. Secondly, it provides high levelquery/update facilities to systems that usually rely on veryprimitive linguistic support. (See [6] for recent works in thisdirection). Similar motivations appear in [4, 5, 7, 8, 11, 12, 13,14, 15, 17, 19, 20, 21] In a previous paper, we introduced the notion of structuringschemas as a mean of providing a database view on structured dataresiding in a file. A structuring schema consists of a grammartogether with semantic actions (in a database language). We alsoshowed how queries <i>on files</i> expressed in ahigh-level query language (O<inf>2</inf>-SQL [3]) couldbe evaluated efficiently using variations of standard databaseoptimization techniques. The problem of update was mentioned therebut remained largely unexplored. This is the topic of the presentpaper. We argue that updates on files can be expressed convenientlyusing high-level database update languages that work on thedatabase view of the file. The key problem is how to propagate anupdate specified on the database (here a view) to the file (herethe physical storage). As a first step, we propose a<i>naive</i> way of update propagation: the databaseview of the file is materialized; the update is performed on thedatabase; the database is """"unparsed"""" to produce an updated file.For this, we develop an <i>unparsing</i> technique. Theproblems that we meet while developing this technique are relatedto the well-known view update problem. ( See, for instance [9, 10,16, 23].) The technique relies on the existence of an inversemapping from the database to the file. We show that the existenceof such an inverse mapping results from the use of restrictedstructuring schemas. The <i>naive</i> technique presents two majordrawbacks. It is inefficient: it entails intense data constructionand unparsing, most of which dealing with data not involved in theupdate. It may result in information loss: information in the file,that is not recorded in the database, may be lost in the process.The major contribution of this paper is a combination of techniquesthat allows to minimize both the data construction and theunparsing work. First, we briefly show how optimization techniquesfrom [2] can be used to focus on the relevant portion of thedatabase and to avoid constructing the entire database. Then weshow that for a class of structuring schemas satisfying a<i>locality</i> condition, it is possible to carefullycircumscribe the unparsing. Some of the results in the paper are negative. They should notcome as a surprise since we are dealing with complex theoreticalfoundations: language theory (for parsing and unparsing), andfirst-order logic (for database languages). However, we do presentpositive results for particular classes of structuring schemas. Webelieve that the restrictions imposed on these schemas are veryacceptable in practice. (For instance, all """"real"""" examples ofstructuring schemas that we examined are<i>local.</i>) The paper is organized as follows. In Section 2, we present theupdate problem and the structuring schemas; in Section 3, a naivetechnique for update propagation and the unparsing technique.Section 4 introduces a locality condition, and presents a moreefficient technique for propagating updates in local structuringschemas. The last section is a conclusion."""	database;high- and low-level;locality of reference;mathematical optimization;parsing;query language;software propagation;unparser;view (sql);whole earth 'lectronic link	Serge Abiteboul;Sophie Cluet;Tova Milo	1995		10.1145/223784.223854	data model;computer science;data mining;database;programming language;view;world wide web;database schema;database testing;database design;query language;satisfiability;channel	DB	-28.079635043793488	10.115796548133002	180918
ebd700e97d4878944143e00bae7214cad1a3a7f7	query driven simulation using simodula	previous simulation;object-oriented extension;early implementation phase;database system;process-oriented simulation language;simulation modeling environment;information retrieval;object oriented;complex system;computer science;switches;database systems;computer simulation;query language;simulation model;relational database system;computational modeling	This paper describes the design and early implementation phases of a simulation modeling environment that integrates a process-oriented simulation language and a database system with object-oriented extensions. User may interact with the system simply by formulating SQL-like queries to retrieve information stored from previous simulations, or indeed cause information to be automatically generated.	database;sql;simulation language	John A. Miller;Orville R. Weyrich	1989		10.1145/317755.317778	computer simulation;relational database management system;network switch;computer science;theoretical computer science;simulation modeling;database;programming language;object-oriented programming;computational model;query language	DB	-30.925341628156158	10.402707108720282	181080
bb953fc2f8953c74e67f6560e148fc8c29f96562	common-sense resolution of syntactic ambiguity in database queries	user interface;domain knowledge;natural language understanding;natural language;common sense;database query	In a natural language database query, the existence of syntactic ambiguity within the input utterance results in more than one possible interpretation of the input. This paper describes a procedure to resolve this type of ambiguity by making use of domain knowledge and information in the database schema, and by examining the sentential structure of the input utterance.		Lai Leng Hui;Ingrid Zukerman	1988		10.1007/3-540-52062-7_92	natural language processing;language identification;data definition language;natural language programming;question answering;data manipulation language;natural language user interface;data control language;computer science;artificial intelligence;database;rdf query language;natural language;user interface;view;database schema;information retrieval;domain knowledge;database design	DB	-32.467436644053315	8.67584759635606	181563
f6405bbcf89eccbd1aa313c2343d3b5565aab76e	database system concept by henry f. korth and abraham silberschatz	database manager;data manipulation language;henry f. korth;data abstraction;overall database system structure;book review;relational database design;data model;abraham silberschatz;database system concepts;major data model;new york;data definition language;data independence;database system concept	This book is an excellent introduction to database system concepts. In its fifteen chapters it covers data abstraction; data models, instances, and schemes; data independence; data definition language; data manipulation language; the database manager, administrator, and users; and overall database system structure. There are individual chapters on the four major data models: entity-relationship, relational, network, and hierarchical. There is also a chapter on the theory of relational database design, with normalization and data independence covered in detail.	abstraction (software engineering);connectionism;data definition language;data manipulation language;data model;database system concepts;database design;entity–relationship model;relational database	Grace C. N. Yeung	1987	SIGIR Forum	10.1145/30075.1096828	data modeling;data definition language;database theory;sql;relational model;entity–relationship model;data model;relational database;computer science;database model;data mining;database;world wide web;database schema;physical data model;information retrieval;database design	DB	-31.197677424234257	10.377774739742609	181661
91832de14acf9de3a1897a1d75d4dea7c15c1d24	extending semantics of relational operators for vague queries	extending semantics;relational operator;vague query	Queries with vague qualifications are taking growing interests in various applications such as decision supporting systems and advice giving systems. To accomodate the vagueness handling capabilities into the widely used relational framework, Level-1 Fuzzy Relational Data Model(FRDM-1) has been proposed in [3]. In this paper, we generalize the model to acquire more practical usefulness. We also describe how non-fundamental relational operators such as join and division can have extended semantics in the proposed model.	relational operator;vagueness	Doheon Lee;Myoung-Ho Kim	1993	Microprocessing and Microprogramming	10.1016/0165-6074(93)90080-5	codd's theorem;relational calculus;conjunctive query	DB	-26.8378982307972	9.092163435340318	181934
90e0b779b7c7a8cf6b548745a716dd1330561da3	information derivability analysis in logical information systems	precedence relations;logical system design;system dictionary;data model;inference rule;conceptual schema;derivability analysis;system design;information processing;logical information systems;information system;data manipulation language	Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. © 1983 ACM 0001-0782/83/1100-0933 75¢	information system	Antoni Olivé	1983	Commun. ACM	10.1145/182.358450	natural language processing;data manipulation language;logical schema;information processing;data model;computer science;conceptual schema;truth table;data mining;database;logical data model;information system;rule of inference;systems design	OS	-31.92734828524511	10.203869682924685	182066
679366b66cd92e79bea599e9774d7b2ad6f6127e	efficient and flexible lineage construction for probabilistic databases			lineage (evolution);probabilistic database	Sebastian Lehrack	2016			data mining;probabilistic logic;computer science	DB	-31.209445582183765	7.325816130549523	182126
937dbb6851418f18fb54acade8d06a5e5ba6a2f5	the logical access path schema of a database	views;databases joining processes information retrieval design optimization calculus data structures computer science;aggregation hierarchy;views aggregation hierarchy external logical subschema generalization hierarchy logical access path propositional calculus;propositional calculus;external logical subschema;logical access path;generalization hierarchy;database design;cumulant	"""A new schema which models the usage of the logical access paths of the database is proposed. The schema models all database activities (i.e., retrievals and updates), and integrates their logical access paths by recognizing common subpaths and increasing the """"weight"""" of the shared subpaths. The logical access path schema provides a comprehensive picture of the logical access paths, and the cumulative usage of the shared subpaths and/or intermediate results. The schema serves a dual purpose. Firstly, it is used as a model of the access requirements during the database design, and secondly, as the basis for optimization during the operation of the database."""	analysis of algorithms;database design;database schema;distributed computing;distributed database;level design;mathematical optimization;organizing (structure);requirement;routing	Nick Roussopoulos	1982	IEEE Transactions on Software Engineering	10.1109/TSE.1982.235886	non-classical logic;logical schema;computer science;theoretical computer science;truth table;database;propositional calculus;view;database schema;algorithm;database design;cumulant	DB	-28.461101825369248	9.915972381347085	182144
25eed7bbea4fbc5ffbe578fec1351db9061e2937	xml schema evolution by context free grammar inference	context free grammar;xml schema	Lint is automatically separated continuously from a dryer exhaust stream, rolled into string-like masses and released from a collecting screen where it is picked up by an auger conveyor and transported to a storage receptacle in compacted form.	schema evolution;xml schema	Julio C. T. da Silva;Martin A. Musicante;Aurora Trinidad Ramirez Pozo;Silvia Regina Vergilio	2007			streaming xml;xml schema (w3c);schematron;programming language;document structure description;relax ng;computer science;xml schema;xml schema editor;xml validation	NLP	-32.525060896491134	8.220192156518989	182398
408ee8e9e7cd3efd56b06d64888312e39fd1e202	order-sensitive xml query processing over relational sources: an algebraic approach	algebraic approach;relational data model;relational data;rewrite rule;query processing;publishing;bridges;null;data mining;algebra;xml;xml document;relational databases;xml query processing;computer science;encoding;data models;xml query processing relational databases data models data mining encoding algebra publishing computer science bridges	The XML data is order-sensitive. The order problem, that is how ordered XML documents and order-sensitive queries over it can be efficiently supported when mapped into the unordered relational data model, has not yet been adequately addressed. In this paper, we present a general approach for supporting order-sensitive XQuery-to-SQL translation that works irrespective of the chosen XML-to-relational data mapping and the selected order-encoding method. Our approach, called XSOT, utilizes an order-aware XML algebra representation. We propose order-sensitive rewriting rules at the algebraic level to eliminate the dependency of the order determining operators on the implicit XML view order. Furthermore, we introduce a series of order-sensitive optimization steps to transform the XML algebra tree for the purpose of efficient SQL translation. Lastly, we utilize a template-based approach using SQL-99 order features to generate SQL statements.	data model;linear algebra;mathematical optimization;relational database;relational model;rewriting;sql;xml;xquery	Ling Wang;Song Wang;Brian Murphy;Elke A. Rundensteiner	2005	9th International Database Engineering & Application Symposium (IDEAS'05)	10.1109/IDEAS.2005.40	xml validation;xml encryption;simple api for xml;xml;relax ng;xml schema;relational database;computer science;document structure description;xml framework;data mining;xml database;xml schema;database;xml signature;xml schema editor;information retrieval;efficient xml interchange	DB	-29.122104008494592	8.678594331614926	182849
62f1958a26f9b296c8aabd47d420545eaa7bed8c	answering preference queries with bit-sliced index arithmetic	bitmap indexes;bit sliced indexes;approximate queries;preference queries;indexation	Systems providing only exact match answers, without allowing any kind of preference or approximate queries, are not sufficient in many contexts. Many different approaches have been introduced, often incompatible in their setup or proposed implementation. This work shows how different kinds of preference queries (PREFER, preference SQL and skyline) can be combined and answered efficiently using bit-sliced index (BSI) arithmetic. This approach has been implemented in a DBMS and performance results are included, showing that the bit-sliced index approach is efficient not only in a prototype system, but in a real system.	approximation algorithm;bitmap;broadcast signal intrusion;lock (computer science);prototype;sql	Denis Rinfret	2008		10.1145/1370256.1370286	computer science;bitmap index;data mining;database;information retrieval	DB	-26.791068135944762	6.356427710598787	183038
c717da340263f18ac6692fb557cbd95545ea6304	the bulk index join: a generic approach to processing non-equijoins	database indexing;partition function;query processing;spatial join;efficient algorithm;nested loops;tree data structures database indexing query processing;index structure;tree data structures;worst case analysis;similarity join;indexation;writing multidimensional systems;algorithm implementation bulk index join nonequijoin processing index nested loops join algorithm outer relation records inner relation preexisting index structure generic code tree based index structure join predicate index structure design index structure functionality generic algorithm performance	Efficient join algorithms have been developed for processing different types of non-equijoins like spati join, band join, temporal join or similarity join. Each of these previously proposed join algorithms is tai lor-cut for a specific type of join, and a generalization of these algorithms to other join types is not obviou We present an efficient algorithm called bulk index join that can be easily applied to a broad class non-equijoins. Similar to the well-known hash join algorithms, the bulk index join performs in two phases In the build-phase, an appropriate index structure is created that serves as a partitioning function on the relation. In the probing-phase, the records of the second relation are probed against the first relation by us the index structure of the build-phase. In order to support both phases efficiently, we adopt a technique cently proposed for bulk loading index structures. We show that this technique can also be exploited probing the tuples of the second relation in bulk. Similar to the generic bulk loading approach, only a pr defined set of routines of the index structure is used for implementing our join algorithm. This set is gene ally available in tree-based index structures. The so-called band join serves as an example in this paper first discuss in detail how to apply our generic approach to the band join. Thereafter, we present a worst-c analysis and experimental results. Moreover, we show in our experiments that the well-known index nes loops join can benefit from performing queries in bulk as it is proposed for the probing-phase of the bu index join.	algorithm;best, worst and average case;data structure;database index;experiment;hash join;input/output;join (sql);whole earth 'lectronic link	Jochen Van den Bercken;Bernhard Seeger;Peter Widmayer	1999		10.1109/ICDE.1999.754937	hash join;database index;recursive join;nested loop join;computer science;theoretical computer science;block nested loop;join dependency;data mining;database;tree;partition function;sort-merge join	DB	-29.519811931210796	4.650850982297736	183078
cb4eb1667932fd094c5ce3f19016d59771bcdb4b	design of database schemata for logic design education system lodes	logic design;education system			Haiyan Xu;Takaki Kuroda	1989			data mining;database;logic synthesis;computer science;schema (psychology)	EDA	-31.64923244689507	11.19704096434022	183374
faec9909341ae3bfbeaa1f7e6c4c82f6ae29e7fc	optimizing queries with foreign functions in a distributed environment	data transmission;database system;optimisation;database theory query processing relational databases distributed databases computational complexity optimisation;query processing cost function database systems object oriented modeling delay computational efficiency data communication polynomials relational databases heuristic algorithms;multidatabase system;query processing;simulation;data processing;foreign function;polynomial complexity;query optimization;schema integration;response time model;distributed computer systems;query languages;distributed query processing;distributed environment;computational complexity;distributed databases;algorithms;optimization;relational databases;relational database query optimization foreign functions distributed database distributed query processing selection operations joins data transmission selection predicate evaluation response time model polynomial complexity np hard heuristic algorithm multidatabase systems schema integration;optimal algorithm;computer simulation;database theory;heuristic algorithm;problem solving	ÐForeign functions have been considered in the advanced database systems to support complex applications. In this paper, we consider optimizing queries with foreign functions in a distributed environment. In traditional distributed query processing, selection operations are locally processed before joins as much as possible so that the size of relations being transmitted and joined can be reduced. However, if selection predicates involve foreign functions, the cost of evaluating selections cannot be ignored. As a result, the execution order of selections and joins becomes significant, and the trade-off for reducing the costs of data transmission, join processing, and selection predicate evaluation needs to be carefully considered in query optimization. In this paper, a response time model is developed for estimating the cost of distributed query processing involving foreign functions. We explore the property of the problem and find an optimal algorithm with polynomial complexity for a special case of it. However, finding the optimal execution plan for the general case is NP-hard. We propose an efficient heuristic algorithm for solving the problem and the simulation result shows its good quality. The research result can also be applied to the advanced database systems and the multidatabase systems where the conversion function defined for the need of schema integration can be considered a type of foreign functions. Index TermsÐDistributed environment, foreign function, query optimization, response time model, simulation.	algorithm;apply;computation;computer data storage;database;feature selection;foreign key;heuristic (computer science);mathematical optimization;np-hardness;optimizing compiler;parallel computing;query optimization;query plan;relation (database);relational algebra;response time (technology);rewriting;selectivity (electronic);simulation;time complexity	Pauray S. M. Tsai;Arbee L. P. Chen	2002	IEEE Trans. Knowl. Data Eng.	10.1109/TKDE.2002.1019215	computer simulation;heuristic;query optimization;database theory;data processing;relational database;computer science;theoretical computer science;data mining;database;programming language;computational complexity theory;distributed database;query language;distributed computing environment;data transmission	DB	-27.480972221036442	4.913133543677354	184113
424d558d8f1eee1fb438ef535d5d8226b02edcff	transformation of xml data into xml normal form	xml schema;functional dependency;normal form	Normalization as a way of producing good database designs is a well understood topic for relational data. In this paper we discuss the problem of eliminating redundancies and preserving data dependencies in XML data when an XML schema is normalized. Normalization is one of the main tasks in relational database design, where 3NF or BCNF, is to be reached. However, neither of them is ideal: 3NF preserves dependencies but may not always eliminate redundancies, BCNF on the contrary – always eliminates redundancies but may not preserve constraints. In this paper we consider the possibility of achieving both redundancy-free and dependency preserving form of XML schema. We show how the XML normal form can be obtained for a class of XML schemas and a class of XML functional dependencies. We relate our approach to the decomposition algorithm proposed by Arenas and Libkin in [1].	algorithm;application domain;boyce–codd normal form;case preservation;data dependency;database design;database normalization;database schema;functional dependency;normalization property (abstract rewriting);redundancy (engineering);relational database;third normal form;xml namespace;xml schema;xml tree;xpath	Tadeusz Pankowski;Tomasz Pilka	2009	Informatica (Slovenia)		xml catalog;xml validation;xml encryption;simple api for xml;xml;relax ng;xml schema;streaming xml;computer science;document type definition;xs3p;document structure description;xml framework;xml database;xml schema;database;functional dependency;xml signature;programming language;xml schema editor;information retrieval;efficient xml interchange	DB	-28.712793758767095	8.978078040399332	184719
0b593e0377c73a8a1e5bb821f36dc852f719e983	a join-like operator to combine data cubes and answer queries from multiple data cubes	olap;data cubes;data integration	In order to answer a “joint” query from multiple data cubes, Pourabass and Shoshani [2007] distinguish the data cube on the measure of interest (called the “primary” data cube) from the other data cubes (called “proxy” data cubes) that are used to involve the dimensions (in the query) not in the primary data cube. They demonstrate in study cases that, if the measures of the primary and proxy data cubes are correlated, then the answer to a joint query is an accurate estimate of its true value. Needless to say, for two or more proxy data cubes, the result depends upon the way the primary and proxy data cubes are combined together; however, for certain combination schemes Pourabass and Shoshani provide a sufficient condition, that they call proxy noncommonality, for the invariance of the result.  In this article, we introduce: (1) a merge operator combining the contents of a primary data cube with the contents of a proxy data cube, (2) merge expressions for general combination schemes, and (3) an equivalence relation between merge expressions having the same pattern. Then, we prove that proxy noncommonality characterizes patterns for which every two merge expressions are equivalent. Moreover, we provide an efficient procedure for answering joint queries in the special case of perfect merge expressions. Finally, we show that our results apply to data cubes in which measures are obtained from unaggregated data using the aggregate functions SUM, COUNT, MAX, and MIN, and a lot more.	aggregate data;computational complexity theory;cubes;data cube;max;turing completeness	Francesco M. Malvestuto	2014	ACM Trans. Database Syst.	10.1145/2638545	online analytical processing;computer science;theoretical computer science;data integration;data mining;database;data cube	DB	-26.444585936953462	8.609594498156167	185106
187f9b0b16b199435eb57b0b077b55610e269096	xquery: a unified syntax for linking and querying general xml documents	xml document		xml;xquery	Steven J. DeRose	1998			xml signature;programming language;streaming xml;well-formed document;xquery;database;xml validation;xml schema editor;computer science;xml base;efficient xml interchange	DB	-33.39352569628585	7.710598388418182	185262
ef600ecb57adf2cb8edc3dd3cdecec1191bb9e30	from a niam conceptual schema into the optimal sql relational database schema			conceptual schema;database schema;object-role modeling;relational database;sql	C. M. R. Leung;G. M. Nijssen	1987	Australian Computer Journal		data mining;sql;schema migration;computer science;star schema;semi-structured model;information schema;database;database schema;database model;conceptual schema	DB	-31.505177836377733	9.429758261264015	185522
acb18c0143b690bde335c9c72bb4f3624f827a4f	the equivalence problem for relational database schemes	relation algebra;relational database	Mappings between the sets of instances of database schemes are used to define different degrees of equivalence. The available class of mappings and the set of dependencies allowed for defining schemes deal here as parameters. A comparison of the equivalences shows that there is only one natural kind of equivalence. For various cases we prove its decidability or undecidability. Besides we get a characterization of mappings expressible in the relational algebra without the difference.	relational database;turing completeness	Joachim Biskup;Uwe Räsch	1987		10.1007/3-540-19121-6_4	domain relational calculus;database theory;sql;discrete mathematics;nested set model;relational model;codd's theorem;relational theory;relational calculus;entity–relationship model;relational algebra;relational database;database normalization;database model;functional dependency;conjunctive query;database schema;object-relational impedance mismatch;database design	DB	-26.944208180234767	10.116956072194636	186687
08ae54e79c07af4a58946756be5820005ce6b65c	querying faceted databases	relation algebra;computer science	Faceted classification allows one to model applications with complex classification hierarchies using orthogonal dimensions. Recent work has examined the use of faceted classification for browsing and search. In this paper, we go further by developing a general query language, called the entity algebra, for hierarchically classified data. The entity algebra is compositional, with query inputs and outputs being sets of entities. Our language has linear data complexity in terms of space and quadratic data complexity in terms of time. We compare the expressive power of the entity algebra with relational algebra. We also describe an end-to-end query system based on the language in the context of an archeological database.	database;end-to-end principle;entity;expressive power (computer science);faceted classification;query language;relational algebra;time complexity	Kenneth A. Ross;Angel Janevski	2004		10.1007/978-3-540-31839-2_15	web query classification;computer science;theoretical computer science;data mining;relation algebra;database	DB	-30.35079438786358	8.345463898787859	186805
bad9d6a50eddd45c88a459356863215e489a1098	the enhancement of semijoin strategies in distributed query optimization	eficacia sistema;base donnee repartie;distributed database;interrogation base donnee;performance systeme;base repartida dato;interrogacion base datos;query optimization;system performance;data communication;information system;database query;systeme information;sistema informacion	We investigate the problem of optimizing distributed queries by using semijoins in order to minimize the amount of data communication between sites. The problem is reduced to that of finding an optimal semijoin sequence that locally fully reduces the relations referenced in a general query graph before processing the join operations. The optimization of general queries, in a distributed database system, is an important and challenging research issue. The problem is to determine a sequence of database operations which process the query while minimizing some predetermined cost function. Join is a frequently used database operation. It is also the most expensive, specifically in a distributed database system; it may involve large communication costs when the relations are located at different sites. Hence, instead of performing joins in one step, semijoins [1], are performed first to reduce the size of the relations so as to minimize the data transmission cost for processing queries [2]. In the next step, joins are performed on the reduced relations. as follows: (i) project R on the join attribute A (i.e. R(A)); (ii) Ship R(A) to the site containing S; (iii) Join S with R(A). The transmission cost of sending S to the site containing R for the join R ~n S can thus be reduced. There are two main methods to process a join operation between two relations. One is called the nondistributed join, where a join is performed between two unfragmented relations. The other is called the distributed join, where the join operation is performed between the fragments of relations. As pointed out in [5], the problem of query processing has been proved to be NP-hard. This fact justifies the necessity of resorting to heuristics. The remaining of this paper is organized as follows: preliminaries are given in Section 2. Section 3 defines the main characteristics of two semijoin-based query optimization heuristics; then, we present and discuss the join query optimization in a fragmented database. Finally, Section 5 concludes the paper.	distributed database;heuristic (computer science);join (sql);loss function;mathematical optimization;np-hardness;optimizing compiler;query optimization;relational algebra	Faïza Najjar;Yahya Slimani	1998		10.1007/BFb0057897	query optimization;computer science;data mining;database;distributed computing;distributed database;information system	DB	-26.789930408968733	4.829453893496852	186832
147afbcbbc04a8015e8bb22aff247cf2d796cd84	an approach for schema evolution in odmg databases	schema evolution	Schema evolution is the process of applying changes to a schema in a consistent way and propagating these changes to the instances while the database is in operation. However, when a database is shared by many users, updates to the database schema are always difficult. To overcome this problem, in this paper we propose a version mechanism for schema evolution in ODMG databases that preserves old schemas for continued support of existing programs running on the shared database when schema changes are produced. Our approach uses external schema definition techniques and is based on the fact that if a schema change is requested on an external schema, rather than modifying the schema, a new schema, which reflects the semantics of the schema change, is defined.	channel capacity;conceptual schema;database schema;deployment environment;object data management group;schema evolution;three-schema approach	Cecilia Delgado;José Samos;Manuel Torres	2004			logical schema;computer science;document structure description;database schema	DB	-32.21058928866922	11.19540792796269	187005
4d831bdada990d5ab6327af4aa74498c06de9cdc	probabilistic relational data mining with aggregates and hierarchies			relational data mining	Jianzhong Chen	2004				ML	-30.932074057759436	7.714191292403084	187036
29d4f822600cbad8c650aa39f72febd00ab10069	pix: a system for phrase matching in xml	libraries;legislation;information retrieval;data engineering;ranking function;engines;indexing;xml;lab on a chip;xml document;xml engines libraries lab on a chip information retrieval indexing data engineering legislation;query answering	021 3)4 1 561 7 8 9:56;$56861 <=8?>!9@8A1 7 9 B)CD1E5 F 1 G@HIB CD1J9K7!LM1 NPO HD1 7 8Q3)> 4 9@561 <R9@86O6>)HI7!SMHI7PT UWVWL)X$O Y!< 1 7 865 Z\[]HI7!O 1 T^UWVW9KCICDX _J5:568?46Y!O 8?Y 4 1 L 9 7 LPY)7!568?46Y!O 8?Y)4 1EL`HI7 abXK4 <R9@8?HDXK7286XcBQ1^HI7 861 46CD1 9 d@1EL`HI7e8?> 1f569g< 1 L X$O Y!< 1 7 8 h 3 > 4 9@561 < 9g86Oi> HI7!S/HI7jT^UWVk4 9KHD561E5l7!1 _=O6> 9 CICD1 7!S@1 5 Z mnY 4c56;$56861 </h 7!9@<R1 L o p q h 3Q1 4 <MHD865^3 > 4 9@561P< 9@86O6> HI7 SPHI7kT UWV L X$O Y!< 1 7 865f8?>!9@8fO X 7 869KHI7sr?<MHDG$1ELkO XK7 861 7 86t)Z uwv]1 ;xay1 9@8?Y 4 1MX a o p qfHD5:8?>!9@8zY!561 4 5:OE9K7W5?3{1 O HIab;P_:>)HDO6>}|M~$$`~$ M~$! $b~$ $) bjI$ $M_:> 1 7(< 9g86Oi> HI7 Sj9 3 > 4 9@561@Z o p qWY 561 5 HI7 dg1 4 861 L(HI7) L$HDO 1 5c9K7!Lk9 7j1 NPO HD1 7 8f1 d 9KCIY!9@8?HDXK79KCDSgXK46HD8?>!< 86X/OEX@<M3 Y 861P8?>!1 561E8fXKa< 9@86O6> 1E5f9K7!L`4 1 8?Y 467!5f9K7!56_:1 4 5f_:> 1 4 1l3 >)4 9g561 5 h HDS 7 X 4 1 L <R9K46v$Y 3.9 7 L2HDSK7!XK4 1 Lj9K7 7!X@869@8?HDX 7 5R9K4 1 >)HDS >)CIHDS > 861 L Z}y7}9@L L$HI 8?HDX 7 h @Y!1 4 ;c9K7!56_:1 4 5:9 4 1:56XK4 861 L Y!5?HI7 Sc9n4 9 7)v$HI7!SMa Y 7!O 8?HDXK7AZ:o p q HD5 HD<M3 CD1 < 1 7 861 L9g5P9K7 1 G$861 7!5?HDXK7sXKal^u^V u TMh 92a Y)CICIbF!1 L S@1 L T nY!1 4 ;/1 7 S HI7 1@ZJ:>!1^a Y 7 O 8?HDX 7 9 CIHD8?;2XKao p qMHD5Ja Y CICD;/HI7 861 SK4 9g861 L HI7 86X T nY 1 4 ; 9K7!L`3{1 4 <MHD865f9 7 9g8?Y)4 9 C:OEX@<fB)HI7!9@8?HDX 7jXKaT^ 9g8?>) B!9@561ELW568?46Y O 8?Y 4 1c< 9@86O6>)HI7!SP_:HD8?>W3)> 4 9@561c< 9@86O6> HI7 S Z 1. INTRODUCTION T UWVW1 7 OEXKY 4 9@S@1E5nY!561 4 5J86XlHI7!561 4 8:7 1E_.HI7)abX 4 < 9@8?HDX 7WHI7 86XMY 7) 568?46Y!O 8?Y 4 1 LP861 G$8zHI7 XK4 L 1 4J86X^3 4 X d@HDL)1f<RXK4 1J561 < 9 7 8?HDO 5:HI7/9fL X$O  Y!< 1 7 8 ZuJY Sg< 1 7 8?HI7!SY 7!568?46Y O 8?Y 4 1 LW861 G$8561 4 d@1 58?_:Xf3)Y 463QXg561 5  |c~$ 2~$W $E $\A   ^6f  E$ |c~$b $nHI7W8?>!1fXK46HDS HI7 9 C861 G$8 X 42~$  $b~$b^8?>!1WXK46HDS HI7 9 Cc861 G$8 _:HD8?>.7!1 _ 861 G$8 8?>!9@8c3)4 X d@HDL 1 5 9gL)L$HD8?HDXK7!9KC561 < 9K7 8?HDOE5 Z¢¡!XK4W1EG$9@<M3 CD1@hf8?>!1 T UWV£L)X$O Y!< 1 7 865 3 Y B)CIHD5?>!1 L¤B ;28?>!1 V HIB 4 9K4 ;}mna ¥:XK7!SK4 1 565P¦bV mf¥J§f ̈©ah© «¬O X 7) 869 HI7 CD9 4 S@1M3{XK4 8?HDXK7!5fXKa861 G$8 8?> 9g8^L 1 56O 46HIBQ1 9gO 8?HDXK7!5fHI7WB)HICICD5 ZRy7 8?> HD5^861EG$8 h)8?>!1^7!9@< 1 5JX a8?> 1f5?3QX 7 56X 4 5^X a 9MB HICIC9K4 1 < 9K46v]1 L/Y)3 Y!5?HI7!S¤8?>!1/869gSk­$®K ̄!°K±!®$°@2 3P9K7!L.9 7)7!X@869g8?HDXK7!5 h^1 <fBQ1 L L 1 L¤HI79 5?3{1 O HI ́!Of869@Sc­@μ °$°@¶@±!°@¶$·$3)h 9 4 1\HI7!561 4 861 L 86Xn3 4 X d@HDL)1f1 G@3 CD9K7!9@86X 4 ; HI7 abX 4 < 9@8?HDX 7 Z  7/X 4 L)1 4J86XM@Y!1 4 ;P861 G$8zHI7eT^UWV2L)X$O Y < 1 7 865 h 1 G@HD568?HI7!S y7 abXK46 <R9@8?HDXK7e ̧J1 8?46HD1 d 9KC¦  ̧ §1861EOi> 7)HD@Y!1 5JabXK4:3 > 4 9@561f< 9g86Oi> HI7 SRO XKY CDL B{1/Y 561 LQZ o^X _:1 dg1 4 hzHI7!L)1EG@HI7 S < 1 8?>!X$L)5 HI7s  ̧ 9g565?Y <R1(r?O X 7) 8?HDS Y)HD8;=XKacv$1E;$_:XK4 L 56t¤HI7£9k3 >)4 9g561j< 9@86O6>» ̈D© 1⁄4 ¬?Z1⁄2yaR< 9K46v$Y 3 HD529@L L 1 L£86X.861 G$8/HI7£9(L X$O Y!< 1 7 8 hR8?>)HD52O XK7 8?HDS Y)HD8;=< 9 ;(BQ1 CDXg568P9K7!L.3)> 4 9@561W< 9g86Oi> HI7!S3⁄47!1 1 L 5P86Xk9@OEO XKY 7 8 abXK4P8?>!1W9@L L 1 L . < 9 46v$Y)3AZ(¡ X 4P1 G$9@<c3)CD1@h 8?>!1W861 G$8kr?U/4 Z ¿ 7 S CIHD5?>HI7 8?4 X$L$Y OE1 L 8?> HD5^B)HICIC_:>)HDO6>k_9@5n4 1 ab1 464 1 LW86XP8?>!1 ¥:X@<R<MHD86861 1 X 72¡ HI7 9 7 O HD9 C [$1 4 d@HDO 1 56t/HD5f1 G$8?4 9gO 861 LWa 4 X@<À9PV mf¥L X$O Y!< 1 7 8f9 7 L2O XKY CDL BQ1 < X$L$HI ́ 1EL.9@5cabXKCICDX _J5 .rÁ­$®K ̄!°K±!®$°@2 3 U/4 Z ¿ 7!SKCIHD5?>s­$Â$®K ̄!°K±!®$°@2 3 HI7 8?4 X$L$Y O 1ELW8?>)HD5zB HICICA_:>)HDO6> _:9@5z4 1 ab1 464 1 L 86Xf8?>!1f¥:Xg< <MHD86861 1 XK7 ¡ HI7!9K7!O HD9KCl[1 4 d@HDOE1 56t)Zj:>!13 > 4 9@561.rU/4 Z2¿17!SKCIHD5?>(HI7 8?4 X$L$Y OE1 L 8?> HD5^B)HICICDt L)X$1 5^7!X@8 < 9@86O6>W8?>!1c< X$LHI ́!1 Lk861EG$8n9 7 ;$< XK4 1cY)7 CD1 565 ­$®K ̄!°K±!®$°@2 3MHD5/ !$?  LY 46HI7 S28?>!1x3 >)4 9g561/< 9g86Oi>AZ2\>!1P569@< 1 3 >)4 9g561f_:XKY CDLx7!X@8J< 9g86Oi> 1 HD8?>!1 4JHIa 8?>!1f861 G$8zHD5J< X$L$HI ́ 1ELW9@5zabX CI CDX _J5 fr?U/4 Z¿ 7 S CIHD5?>2­@μ °$°@¶@±!°@¶$·$3¡ XK4>)HD<R561 CIa 9 7 L U/4 Z1¥\X ;@7!1@Z ­$Â@μ °$°@¶@±!°@¶ ·@3^HI7 8?4 X$L$Y O 1ELk8?>)HD5^B HICIC_\> HDO6>k_:9g5n4 1 ay1 464 1 LW86XP8?> 1 ¥:X@< <cHD86861 1 XK7}¡ HI7!9K7!O HD9KC,[$1 4 d@HDO 1 56t Z y7}8?>)HD5cO 9@561gh 8?>!1 _:> X CD1 9K7 7!X@869@8?HDX 7 1 <fBQ1 L L)1 LjHI7­@μ °$°@¶@±!°@¶ ·$35?>!XKY CDL.BQ1}I$ $? M86X < 9g86Oi>}8?> 1 3 >)4 9g561@ZP:>$Y 5 hQHI7jX 4 L)1 4R86XxB{1 9KB CD1/86X XKÃQ1 4fF!1 G@HI B CD1^3)> 4 9@561f< 9g86Oi> HI7!SHI7eT^UWV2L)X$O Y < 1 7 865 h 8?>!1f56;$56861 <»5?>!XKY CDL >!9Kdg1J8?> 1 9KB HICIHD8?;P86XPI$ $?:b!   Ä:|M~$$c9 7 LW !$?nb!   Ä ~$  $b~$b $$ _:>!1 7W<R9@86O6>)HI7!S/9M3 > 4 9@561@Z 021fL)1E56O 46HIBQ1co p qx¦bo@> 4 9@561 < 9@86O6>)HI7!SWp 7 q$UWV § h$9 56;$56861E<ÅabX 4 3 >)4 9g561 < 9@86O6> HI7 S/HI7}T^UWV L)X$O Y!< 1 7 865 ZR 72o p q h)HD8^HD5^3QXg565?HIB)CD1 86X^abX 4 <lY CD9@861f@Y!1 46HD1 5J_:> 1 4 1n5?3{1 O HI ́!Of< 9K46v$Y 3W9 7 LP9K7 7!X@869@8?HDX 7 5 O 9 7(BQ1/HDSK7!XK4 1 L _:> 1 7 < 9@86O6>)HI7!Sj9k3)> 4 9@561@Zs:>)HD5Pab1 9@8?Y 4 1WHD5 HD<M3 CD1 < 1 7 861ELk9@5J9K72T nY!1 4 ;xaY)7!O 8?HDXK7}9K7!L/HD5naY)CICD;/HI7 861 S 4 9@861 L HI7 86XjT nY 1 4 ;  ̈I« ¬?Z :>!1 4 1 abX 4 1@hnY!561 4 5 O XKY CDL(9@5?v@Y 1 46HD1E5W8?> 9g8 O Xg<lB HI7 1^3 > 4 9@561f< 9g86Oi> HI7 SR_\HD8?> 1 G@HD568?HI7!SPT nY 1 4 ;fa Y 7 OE8?HDXK7!9KCIHD 8?HD1 5 Z ¡!XK41 G$9g<M3)CD1gh@HD8 HD513{X@565?HIB CD1^86XJ9@5?vfabX 48?> 13 9 4 9@SK4 9 3)>8?> 9g8 L 1 56O 46HIBQ1 5:B HICICD5^L 9@861 LPX 7WÆKY 7!1^Ç$h!aKÈ@ÈgÉ)h 5?3QX 7 56X 4 1 LxB ; U/4 ZÊ¿17  SKCIHD5?> 9 7 L 8?>!9@8O X 7 869KHI7P8?>!1:3)> 4 9@561Pr 4 1 ab1 464 1 L 86X 8?> 1O X@< <cHD86861 1 XK7  ́)7!9K7!O HD9 C 561 4 d@HDOE1 56tkHDSK7!XK46HI7!S(< 9K46v$Y 3 ­$Ë$°KÌ$ÌAÍ ¶$¶ ·$·$Î ±!ÏÌ!·$3 9K7!LkHDSK7!XK46HI7!S.9 7)7!X@869g8?HDXK7 ­@μ °$°@¶@±!°@¶ ·$3$Z/o p qWHD5MHD<M3 CD1 < 1 7 861 L 9@5R9K7 1 G$861 7!5?HDXK7 X af8?>!1W^u^VAu^T 56;$56861 <Ð ̈©EÈK¬h9`a Y CICIbF 1EL)Sg1 L T nY 1 4 ;x1 7 S HI7 1@Z :>!1\4 1E568zX aQ8?>)HD53)4 X 3QX@569 C HD5zX 4 S@9 7)HDÑ 1EL/9@5 abX CICDXK_J5 Z[$1 O 8?HDXK7ea SKHDdg1 5 9W< Xg8?HDd 9@8?HI7!Sk1 G$9@<c3)CD1@Z3⁄4[1EO 8?HDXK7 ÒW5?>!XK_J5c8?> 1 LHIÃ{1 4 1 7 8 < X$L$Y)CD1E5MHI7j8?>!1MHD<M3 CD1 < 1 7 869g8?HDXK7(X aJo p q ZA[$1 O 8?HDXK73⁄41⁄4/L 1 56O 46HIBQ1 5 8?>!1/ab1 9@8?Y 4 1 5PXKaco p q28?>!9@8P_:HICIC^BQ1WL 1 < X 7 568?4 9g861 L Zw[1EO 8?HDXK7sÇ HI7 8?4 X$L$Y O 1E5f56X@< 1^a Y!8?Y 4 1fLHI4 1 OE8?HDXK7!5M86X 1 7)>!9K7!O 1co p q Z 2. EXAMPLE T UWVWL)X$O Y!< 1 7 865<MHDSK> 8O XK7 869 HI7/CD9 4 S@1:3QXK4 8?HDX 7 5JX aQ861 G$88?> 9g8 >!9Kdg1lB{1 1 72561 < 9 7 8?HDO 9KCICD;}9KY!S@< 1 7 861EL _:HD8?>2< 9 46v$Y)329 7 LW9 7)7!XK 869@8?HDX 7 5cHI7.X 4 L)1 4P86X/3)4 X d@HDL 1W< XK4 1 HI7 abXK4 <R9@8?HDXK7XK7 8?>!1xX 46HDSKHI 7!9KC 861 G$8 Z[1 <R9K7 8?HDOWHI7)abX 4 < 9@8?HDX 7(HD5P9@L L)1 L 1 HD8?>!1 4/B ; HI7!561 4 8? HI7!S/< 9 46v$Y)3(¦b1gZ S ZhA­$®K ̄!°K±!®$°@2 3g§lr9K4 XKY 7!L)tW1 G@HD568?HI7!S2861 G$8^X 4fB ; 9@L L$HI7 S29x7!1 _=3)HD1EO 1 XKa\861 G$8f1 <fBQ1 L L)1 L2HI7j9/5?3Q1EO HI ́ OP< 9 46v$Y)3 ¦b1@Z S)ZDh­@μ °$°@¶@±!°@¶ ·@3$§ Z \>!1xHI7!561 4 8?HDX 7 XKaf<R9K46v$Y 3(9K7!Lj9K7 7 Xg869K 8?HDXK7!5^HI7}8?> 1c861 G$8^<cHDSK> 8^HI7 d 9KCIHDL 9@861 56X@< 1f3)> 4 9@561R< 9@86O6>)HI7!SxHI7 8?>!9@8f861 G$8 Zf:>!1 4 1 abX 4 1@hQHD8^HD5^HD<M3QXK4 869 7 8M86X BQ1R9KB CD1x86XP9gO O XKY 7 8 ayXK4c9@L L 1 Lj< 9K46v$Y 3j_:> 1 7j< 9@86O6> HI7 S29/3)> 4 9@561 HI7jT UWV(L)X$O Y) <R1 7 865 Z  7/X 4 L)1 4^86XcHICICIY 568?4 9g861 8?>)HD5JO X 7 OE1 467 h!_:1^OEXK7!5?HDL)1 4cT UWV L X$O  Y!< 1 7 865c3)4 X$L$Y OE1 L¤B ;k8?>!1/VQHIB)4 9 4 ;jmna,¥:XK7!SK4 1 565/ ̈D© a ¬?Z2:>!1 561 L X$O Y!< 1 7 865P9K4 1P3 9 4 8?HD9KCICD; 568?46Y O 8?Y 4 1 L 9K7!L¤OEXK7 869KHI7 CD9K4 Sg1/3QXK46 8?HDX 7 5fX a9K7 7 Xg869@861 L2861 G$8 Z\>!1f1 G$9g<M3)CD1RSKHDd@1 7 BQ1 CDXK_ HD5^9 8;@3) HDOE9KCL X$O Y <R1 7 8n3 Y)B CIHD5?>!1 LkB ;x8?>!1cV HIB 4 9K4 ;WXKa¥:X 7 S 4 1 565 ZJb8nL 1  56O 46HIBQ1 5^HI7 abXK4 < 9g8?HDXK7j9 BQXKY!8f9 B)HICIC5?Y!Oi>}9@5JHD865^56869@Sg1@hAO XK7!SK4 1 565 h 561E565?HDXK727$Y <fBQ1 4 h CD1 S HD5?CD9@8?HDX 7¤7$Y!<fBQ1 4f9 7 L/HD865:CDX$O 9g8?HDXK7AZfb8J9KCD56X L 1 56O 46HIB{1 5 HD865 9@O 8?HDX 7 Z}un7 9@OE8?HDXK7j> 9g5 92L)9g861x9 7 LjO X 7 869KHI7!5P9 3{XK4 8?HDXK7}XKaÊ861 G$8J8?> 9g8^L 1 56O 46HIBQ1E5nHD865^OEXK7 861 7 8J9K7!L/HD865^5?3{XK7!56XK4 5 Z ­KÓAÍ Ô$Ô ÓAÍ Ô$Ô$Î$®@¶ Ï@Õ]· Ö × p ± ¶$2 °@Ø@Ù!Ë ¶QÍ °±JÚb3 ­$Ë$°K± Õ$2 ·$®$®$3¤Û$Û Ü@¶@Ý Þ ß@à$á$â$ã ä$ä2­$Â$Ë$°K± Õ$2 ·$®$®@3 ­$®$·$®$® Í °K±!3.Û ®@¶ ®$·$®$® Í °K± ­$Â$®$·$®$® Í °K± 3 ­$Ô$·@ÕQÍ ®$ÎK±$Ù$Ì!3`åæ?âæWÛ ç$çj­$Â$Ô$·@ÕQÍ ®$ÎK±$Ù@Ì!3 ­$ËKÙ 2$2 ·K± ¶ Î$ËKÝ ÏKÌgÓ!·@2$3 p à è$å$ã.å ßKé!ä@ãjß@ê â$ã$o$â$ã ä@ã$à$è$ë@è p ì$ã ä ­$Â$ËKÙ 2$2 ·K± ¶ Î$ËÝ!Ï Ì$Ó!·K2 3 ­$Ï$Ë@¶QÍ °K±jØ Ï@¶ ·kÖÀ× í Ù$±!·kî ï/ð$Ü$Ü$ñzÚ3 ­$Ï$Ë@¶QÍ °K±!Î@Ø$·$®gË$3 ­$®K ̄!°K±!®$°@2 3Wò$2æ ã@± Õ Ô Í ®KÝ ­$Â$®K ̄!°K±!®$°@2 3ó?μ °@2 ÝAÍ Ì!®$·$Ô@μjÏK± Ø ­$Ë$°$Î$®K ̄!°K±!®$° 2 3`ò$2æPÞ °@ô@±!· ­$Â$Ë$°$Î$®K ̄!°K±®$°@2$3 õ2Í ± ¶$2 °@Ø@Ù!Ë$·@Ø ¶@ÝAÍ ® ÓAÍ Ô$Ô ö ÷ ÝAÍ ËKÝ ÷ Ï$®k2 ·@μ ·@2$2 ·@Øk¶ °j­@μ °$°@¶@±!°@¶ ·$3`øQÍ Ô$Ô$® Ë$°KÙ!Ô@ØkÓ!·k2 ·@μ ·@2$2 ·@Øk¶ °3⁄4Ì$Ù!Ô@¶QÍ  ̄!Ô$·2Ë$°KÌ$ÌAÍ ¶$¶ ·$·$® æ ­$Â@μ °$°@¶@±!°@¶]·$3`¶@Ý!· ­$Ë$°KÌ$ÌAÍ ¶$¶ ·@·$Î±!ÏKÌ·$3`Þ °KÌ$ÌAÍ ¶$¶ ·$· °K±êQÍ ±!ÏK±!Ë Í Ï$Ô ä$·@2$ùQÍ Ë$·$®2­$Â$Ë$°KÌ$ÌAÍ ¶$¶ ·@·$ÎK±ÏKÌ!·@3 æ@æ$æ ­$Â$Ï$Ë@¶QÍ °K±!ÎKØ ·g®$Ë$3 ­$Â$Ï$Ë@¶QÍ °K±!3 ­$ÂKÓAÍ Ô$Ô$3 ú X@861^8?>!9@8J8?>!1^3QXK4 8?HDX 72XKaÊ861 G$8J8?> 9g8nL 1 56O 46HIB{1 5^9 729@O 8?HDX 7(r HD5 OEXK>!1 4 1 7 86tk1 dg1 7jHIaf8?>!1/< 9 46v$Y)3jHD8PO X 7 869KHI7!5HD5c4 1 < X d@1 Lka 4 Xg< 8?>!1f861 G$8 Z ûJY 1k86Xj8?>!1 3 4 1 561 7!O 1kXKaR861 G$8/a 4 9gS@< 1 7 865/HI7=<MHDG$1EL=L)X$O Y) <R1 7 865 h @Y 1 46HD1E5^8?>!9@8JXK3Q1 4 9@861fXK7 8?>!1 561fL X$O Y <R1 7 865^X ab861 7 < 9Kv]1 Y!561.X a a Y CICI861 G$8j561 9K4 O6>£XK3{1 4 9@86X 4 5. ̈©EÒK¬Zü021¤O CD9@565?HIab;£8?>!1 561 @Y!1 46HD1 5^HI7 86XR8?>)4 1 1cO 9g861 S@X 46HD1 5  ýP+ $	agile software development;cdx format;cisco pix;compiler description language;cray xk7;holographic data storage;introduction to algorithms;lkb;lpx (form factor);optimization problem;xml	Sihem Amer-Yahia;Mary F. Fernández;Divesh Srivastava;Yu Xu	2003		10.1109/ICDE.2003.1260864	well-formed document;xml catalog;xml validation;binary xml;xml encryption;xml base;simple api for xml;xml;information engineering;xml schema;streaming xml;computer science;document type definition;document structure description;xml framework;xml database;xml schema;database;xml signature;world wide web;xml schema editor;cxml;information retrieval;efficient xml interchange	Theory	-33.516787302565454	7.171826015734376	187087
ec575f12fe4d9c08349ce613766fc0eaea9200f9	enterprise schema - an approach to ims logical database design.	database design			J. H. Tsao	1979			schema migration;database theory;semi-structured model;logical schema;database tuning;computer science;knowledge management;three schema approach;conceptual schema;database model;data mining;database;view;database schema;database design	DB	-31.793155825636415	9.97333125035754	187140
62f99f460551d764716bafb567a5d57f3e92336d	www data source selection with sqlfi	information resources;data source selection;fuzzy set;query processing;sql;sql boolean algebra cataloguing fuzzy set theory information resources information retrieval systems internet query processing;web interface;database;fuzzy queries;cataloguing;user preferences;fuzzy set theory;fuzzy sets;boolean algebra;expressive power;application domain;internet;querying systems;declarative languages;web interface data source selection world wide web information resources declarative languages user preferences application domain metadata catalog management querying language sql querying systems fuzzy sets fuzzy querying system sqlfi fuzzy queries database;information retrieval systems;world wide web;world wide web fuzzy systems fuzzy sets database systems boolean functions proposals ansi standards standards organizations database languages power system management;metadata catalog management;fuzzy querying system;sqlfi;querying language	World Wide Web is a great repository of information which requires declarative languages for querying it. In this context, an important problem to solve is the selection of the best data sources based in user preferences and application domain. For so doing it is necessary to manage a catalog with metadata describing data sources. Rigidity of traditional querying languages limits them to be used in this problem. Several extensions of SQL have been proposed in order to improve the expressive power of querying systems. One of them is SQLf with its extensions SQLf2 and SQLf3, which allow a great variety of flexible queries expressions involving user preferences, based on fuzzy sets. We have built a fuzzy querying system called SQLfi, which is an implementation for SQLf and its extensions. We propose to use SQLfi for building a catalog manager for data source selection in Web. It promises to be a more suitable solution to previous ones in both flexibility and performance	application domain;fuzzy set;sql;sqlf;user (computing);www;world wide web	Marlene Goncalves;Leonid José Tineo Rodríguez	2005	The 14th IEEE International Conference on Fuzzy Systems, 2005. FUZZ '05.	10.1109/FUZZY.2005.1452531	computer science;artificial intelligence;data mining;database;fuzzy set;information retrieval	DB	-33.44973642653763	6.7850332800534465	187613
ee5bcd2b678b7d608aa7ba69dabdb2e380277c54	miro web: integrating multiple data sources through semistructured data types	semistructured data	The MIROWeb Esprit project has developed a unique technology to integrate multiple data sources through an object-relational model with semistructured data types. It addresses the problem of integrating irregular Web sources and regular relational databases through a mediated architecture based on a hybrid model, supporting relational, object and semistructured features. The project data exchange format is XML, the new standard of the Web, and the pivot language is XMLQL, a query language based on XML templates from AT&T. The demonstration will show the data warehousing approach for mediation, based on Oracle 8 and a semistructured cartridge developed in the project for supporting XML and XMLQL queries.	estimation of signal parameters via rotational invariance techniques;object-relational database;oracle database;query language;relational database;relational model;world wide web;xml	Luc Bouganim;Tatiana Chan-Sine-Ying;Tuyet-Tram Dang-Ngoc;Jean-Luc Darroux;Georges Gardarin;Fei Sha	1999			computer science;data mining;database;world wide web	DB	-32.87519908656218	8.679044445903596	189350
721533c1c058cfdfba129d8e4a6bd66e34558c43	mixing querying and navigation in mix	relational databases query processing information resources application program interfaces hypermedia markup languages query languages distributed object management;hypermedia markup languages;information resources;query processing;query languages;document object model;query evaluation;application program interfaces;distributed object management;navigation xml cameras lenses graphical user interfaces information systems query processing information retrieval databases interleaved codes;relational databases;decontextualization mix system web based information systems relational databases views browsing application program interface information discovery api qdom querible document object model navigation driven query evaluation xml views xquery like language dom standard query processing	Web-based information systems provide to their users the ability to interleave querying and browsing during their information discovery efforts. The MIX system provides an API called QDOM (Querible Document Object Model) that supports the interleaved querying and browsing of virtual XML views, specified in an XQuery-like language. QDOM is based on the DOM standard. It allows the client applications to navigate into the view using standard DOM navigation commands. Then the application can use any visited node as the root for a query that creates a new view. The query/navigation processing algorithms of MIX perform decontextualization, i.e., they translate a query that has been issued from within the context of other queries and navigations into efficient queries that are understood by the source outside of the context of previous operations. In addition, MIX provides a navigation-driven query evaluation model, where source data are retrieved only as needed by the subsequent navigations.1	algorithm;application programming interface;document object model;information discovery;information retrieval;information system;interleaving (disk storage);mix;mathematical optimization;pipeline (computing);relational database;source data;xml;xquery	Pratik Mukhopadhyay;Yannis Papakonstantinou	2002		10.1109/ICDE.2002.994714	document object model;sargable;query optimization;query expansion;web query classification;relational database;computer science;query by example;data mining;database;rdf query language;programming language;web search query;view;world wide web;information retrieval;query language;object query language;spatial query	DB	-32.94272995183037	8.091524281468029	189774
f06996ec586d86d147f9db1cc7e6fe01eea3cdf1	on the number of keys of a relational database schema.	relational database	We i n troduce an inference system for deriving all keys of a relation schema. Then we show that the numb e r o f k eys of a relation schema R = hU; Fi is bounded by be jFj=e c.	database schema;inference engine;relation (database);relational database	Ralf Wastl	1998	J. UCS	10.3217/jucs-004-05-0547	sql;information schema;relational database management system;relational model;relational calculus;semi-structured model;entity–relationship model;relational database;computer science;database normalization;database model;data mining;database;conjunctive query;view;superkey;database schema;object-relational impedance mismatch;database design	DB	-30.916626039233996	9.260089625364587	190131
33f4e5d48b832a76e078d77d94b4060d41f72c9c	on tree pattern query rewriting using views	institute for integrated and intelligent systems;faculty of science environment engineering and technology;swinburne;query optimization;database management;necessary and sufficient condition;280108;query rewriting	We study and present our findings on two closely related problems on xpath rewriting using views when both the view and the query are tree patterns involving /,// and []. First, given view V and query Q, is it possible for Q to have an equivalent rewriting using V which is the union of two or more tree patterns, but not an equivalent rewriting which is a single pattern? This problem is of both theoretical and practical importance because, if the answer is no, then, to answer a query completely using the views, we should use more efficient methods, such as the PTIME algorithm of [12], to find the equivalent rewriting, rather than try to find the union of all contained rewritings and test its equivalence to Q. Second, given a set V of views, we want to know under what conditions a subset V ′ of the views are redundant in the sense that for any query Q, the contained rewritings of Q using the views in V ′ are contained in those using the views in V − V ′. Solving this problem can help us to, for example, choose the minimum number of views to be cached, or better design the virtual schema in a mediated data integration system, or avoid repeated calculation in query optimization. We provide necessary and sufficient conditions for the second problem, based on answers to the first problem. When the views produce comparable answers, we extend our findings to include the case where the intersection of views, in addition to the individual views, are used in the rewriting.	algorithm;mathematical optimization;p (complexity);query optimization;rewriting;turing completeness;xpath	Junhu Wang;Jeffrey Xu Yu;Chengfei Liu	2007		10.1007/978-3-540-76993-4_1	query optimization;computer science;theoretical computer science;data mining;database;view	DB	-26.569702303737916	7.267286099307241	190492
2acb032db075021b1f1ac52f84e69cee6b705a8b	generic schema mappings	second order;object oriented model;schema integration;schema mapping;data structure;data manipulation language	Schema mappings come in different flavors: simple correspondences are produced by schema matchers, intensional mappings are used for schema integration. However, the execution of mappings requires a formalization based on the extensional semantics of models. This problem is aggravated if multiple metamodels are involved. In this paper we present extensional mappings, that are based on second order tuple generating dependencies, between models in our Generic Role-based Metamodel GeRoMe. By using a generic metamodel, our mappings support data translation between heterogeneous metamodels. Our mapping representation provides grouping functionalities that allow for complete restructuring of data, which is necessary for handling nested data structures such as XML and object oriented models. Furthermore, we present an algorithm for mapping composition and optimization of the composition result. To verify the genericness, correctness, and composability of our approach we implemented a data translation tool and mapping export for several data manipulation languages.	algorithm;composability;correctness (computer science);data manipulation language;data structure;holism;intensional logic;mathematical optimization;metamodeling;schema (genetic algorithms);xml;xml namespace;xquery	David Kensche;Christoph Quix;Yong Li;Matthias Jarke	2007		10.1007/978-3-540-75563-0_11	data manipulation language;data structure;logical schema;computer science;theoretical computer science;star schema;database;programming language;second-order logic;data mapping	DB	-29.76622724077532	10.850849345874032	191446
a3a9271976d69913fe09462ebbe5b3fc9f519de3	a graphical design interface for xml schemas	xml schema;graphical interface;object oriented;user experience;visual field;graphic design	A graphical interface for designing XML Schemas is presented. The current version of this interface is based on the Schema for Object Oriented XML (SOX), but the constructs are easily generalizable for other schema representations as well. The main advantage is to use the two-dimensional visual field of graphical interface plus multiple windowing to capture more intuitively represent the hierarchical decomposition and re-usability of the XML element definitions. Initial user experience has been quite positive.		Ronald Lee	2001			xml validation;simple api for xml;xml;xml schema;geography markup language;streaming xml;computer science;xs3p;document structure description;xml framework;xml schema;database;programming language;user interface;world wide web;xml schema editor;graphical user interface testing	DB	-32.864486139332676	9.492671115256499	191822
2f6772276d9badb76897ada86acb3133bee926ce	mining xml data: a clustering approach	media;digital technology and the creative economy	XML data has become very popular to represent semi structured data. This has resulted in a growing amount of XML data on the web. This raises a need for languages and tools to manage collections of XML documents as well as to mine interesting information from them. Several attempts at developing XML mining techniques have been proposed. However the topic of mining XML data has received little attention as the data mining community has focused on the development of techniques for extracting common structure from heterogeneous XML data. This project aims to data mine XML data using the XML Query language XQuery. The data mining technique used is the clustering technique of the Nearest Neighbour Algorithm. This algorithm will be incorporated into XQuery expression which, when implemented using an XQuery implementation tool, will cluster distance based data within the XML document into groups, where the distance between the data is set by a given threshold. The implementation of the Nearest Neighbour algorithm hopes to be generic and implement a user interface which allows the user to load a XML document for its data to be clustered, choose the data to be clustered within that document, input the threshold and receive the clustered result in an output file. This work would allow XML distance data to be clustered with the Nearest Neighbour algorithm using XQuery, therefore providing a needed data mining implementation on XML data.	central processing unit;cluster analysis;data mining;data point;graphical user interface;nearest neighbour algorithm;query language;semiconductor industry;user interface;xml;xquery	Mohammad Saraee;Joanna Moaiad Aljibouri	2005			well-formed document;xml catalog;xml validation;binary xml;xml encryption;simple api for xml;xml;xml schema;streaming xml;computer science;document structure description;xml framework;data mining;xml database;xml schema;database;xml signature;world wide web;xml schema editor;efficient xml interchange	DB	-33.41132898185559	5.085422388557699	192535
7c9240a1b4ddfcdae7aab982e083f2d4ef41a9ab	an overview of the llunatic system		Data transformation and data cleaning are two very important research and application problems. Data transformation, or data exchange [7], relies on declarative schema mappings to translate and integrate data coming from one or more source schemas into a different target schema. Data cleaning, or data repairing [8], uses declarative dataquality rules in order to detect and remove errors and inconsistencies from the data. It is widely recognised that whenever mappings among different sources are in place, there is a strong need to clean and repair data. Despite this need, database research has so far investigated schema mappings and data repairing essentially in isolation. We present the LLUNATIC [11, 12] mapping and cleaning system, the first comprehensive proposal to handle schema mappings and data repairing in a uniform way. LLUNATIC is based on the intuition that transforming and cleaning data can be seen as different facets of the same problem, unified by their declarative nature. This declarative approach that allowed us to incorporate unique features into the system and apply it to wide variety of application scenarios.	declarative programming;plasma cleaning;sputter cleaning	Floris Geerts;Giansalvatore Mecca;Paolo Papotti;Donatello Santoro	2014			software;data mining;schema (psychology);data exchange;computer science;intuition	DB	-26.52227496206549	9.060313802225952	192654
5c8818b64a079070f568a9dde626c36144b1a7c4	query relaxation using malleable schemas	query relaxation;malleable schema;satisfiability;object relational databases;information management;relaxation scheme;information system;data structure	In contrast to classical databases and IR systems, real-world information systems have to deal increasingly with very vague and diverse structures for information management and storage that cannot be adequately handled yet. While current object-relational database systems require clear and unified data schemas, IR systems usually ignore the structured information completely. Malleable schemas, as recently introduced, provide a novel way to deal with vagueness, ambiguity and diversity by incorporating imprecise and overlapping definitions of data structures. In this paper, we propose a novel query relaxation scheme that enables users to find best matching information by exploiting malleable schemas to effectively query vaguely structured information. Our scheme utilizes duplicates in differently described data sets to discover the correlations within a malleable schema, and then uses these correlations to appropriately relax the users' queries. In addition, it ranks results of the relaxed query according to their respective probability of satisfying the original query's intent. We have implemented the scheme and conducted extensive experiments with real-world data to confirm its performance and practicality.	algorithm;data structure;experiment;information management;information system;linear programming relaxation;norm (social);object-relational database;relational database;statistical model;vagueness;xml schema	Xuan Zhou;Julien Gaugaz;Wolf-Tilo Balke;Wolfgang Nejdl	2007		10.1145/1247480.1247541	query optimization;data structure;computer science;theoretical computer science;data mining;database;information management;programming language;information system;query language;satisfiability	DB	-28.108060044183613	5.186621310040901	192993
df9e7145849f704e5f81134fe45e7f0201c86fd6	schema-independence in xml keyword search	information retrieval;information retrieval and web search;database management;xml	XML keyword search has attracted a lot of interests with typical search based on lowest common ancestor (LCA). However, in this paper, we show that meaningful answers can be found beyond LCA and should be independent from schema designs of the same data content. Therefore, we propose a new semantics, called CR (Common Relative), which not only can find more answers beyond LCA, but the returned answers are independent from schema designs as well. To find answers based on the CR semantics, we propose an approach, in which we have new strategies for indexing and processing. Experimental results show that the CR semantics can improve the recall significantly and the answer set is independent from the schema designs.	database schema;lowest common ancestor;operational semantics;response time (technology);search algorithm;stable model semantics;xml	Thuy Ngoc Le;Zhifeng Bao;Tok Wang Ling	2014		10.1007/978-3-319-12206-9_6	xml;computer science;document structure description;data mining;xml schema;database;xml schema editor;information retrieval	DB	-31.648723265833027	4.641320230119758	193217
412d602ac75daa55abd35322c77d98a66d815157	un modèle de production interactive de programmes de publication	lenguaje programacion;query language;dynamic document publishing;interfase usuario;document publie;programming language;user interface;database;base dato;lenguaje interrogacion;canonic instance;man machine interfaces;published document;base de donnees;langage programmation;langage base donnee;publish by example system;ambiguity;interface utilisateur;canonic document;langage interrogation;information system;ambiguedad;database languages;systeme information;documento publicado;ambiguite;sistema informacion	We propose an approach for producing database publishing programs by example. The main idea is to interactively build a canonical document, representative of the program output. The system infers from this document, without ambiguity, the publishing program. The end-user does not need to know a programming language, a query language or the database schema. We describe and comment a visual editor that shows how a user can rely on these concepts for intuitively producing publishing programs.		Sonia Guehis;David Gross-Amblard;Philippe Rigaux	2008	Ingénierie des Systèmes d'Information	10.3166/isi.13.5.107-130	natural language processing;computer science;artificial intelligence;database;world wide web;query language	Crypto	-32.956672637982	9.175244418432971	194192
f7eac0659be8e6001a06be9b0893763f629f18dd	performance evaluation of a parallel cascade semijoin algorithm for computing path expressions in object database systems	database system;parallel algorithm;performance evaluation;query processing;e commerce;digital library;object database;very large database;distributed objects;optimal path;indexation;scheduling strategy;path expression;high performance;path expressions;parallel processing	With the emerging of new applications, especially in Web, such as E-Commerce, Digital Library and DNA Bank, object database systems show their stronger functions than other kinds of database systems due to their powerful representation ability on complex semantics and relationship. One distinguished feature of object database systems is path expression, and most queries on an object database are based on path expression because it is the most natural and convenient way to access the object database, for example, to navigate the hyperlinks in a web-based database. The execution of path expression is usually extremely expensive on a very large database. Therefore, the improvement of path expression execution efficiency is critical for the performance of object databases. As an important approach realizing high-performance query processing, the parallel processing of path expression on distributed object databases is explored in this paper. Up to now, some algorithms about how to compute path expressions and how to optimize path expression processing have been proposed for centralized environments. But, few approaches have been presented for computing path expressions in parallel. In this paper, a new parallel algorithm for computing path expression named Parallel Cascade Semijoin (PCSJ) is proposed. Moreover, a new scheduling strategy called right-deep zigzag tree is designed to further improve the performance of the PCSJ algorithm. The experiments have been implemented in an NOW distributed and parallel environment. The results show that the PCSJ algorithm outperforms the other two parallel algorithms (the parallel version of forward pointer chasing algorithm (PFPC) and the index splitting parallel algorithm (IndexSplit) when computing path expressions with restrictive predicates and that the right-deep zigzag tree scheduling strategy has better performance than the right-deep tree scheduling strategy.	centralized computing;dna bank;database;digital library;distributed object;e-commerce;experiment;hyperlink;parallel algorithm;parallel computing;path expression;performance evaluation;pointer (computer programming);relational algebra;scheduling (computing);web application;world wide web	Guoren Wang;Ge Yu	2002	Journal of Computer Science and Technology	10.1007/BF02962206	parallel processing;digital library;fast path;computer science;theoretical computer science;operating system;machine learning;path expression;database;distributed computing;programming language	DB	-28.83112928049466	5.306418285219683	194410
a312c88ae54326acc62029a6fcb64def10284ce4	unifying functional and multivalued dependencies for relational database design	relational database	Abstract   We consider the problem of unifying functional dependencies (FDs) and multivalued dependencies (MVDs) in designing relational database schemes. Given a set  D  of dependencies (MVDs and FDs) over a universal scheme  U , we define a different set of MVDs over  U , called the envelope set for  D , so that a database scheme with respect to  D  can be designed by considering only the MVDs in the envelope set for  D , instead of treating MVDs and FDs in  D  separately. We show that a database scheme is in 4NF with respect to  D  (BCNF when  D  has only FDs) if it is 4NF with respect to the envelope set for  D . By utilizing the envelope set of dependencies we extend the conflict free property of sets of MVDs to apply to sets of FDs and MVDs. We show that if a set  D  of dependencies is extended conflict-free, then there exists an acyclic, joint lossless 4NF decomposition (BCNF) with respect to  D  which is also dependency preserving. Except for the case where  D  is a set of MVDs only, this was an open problem in the literature. We also show that, for a set  M  of MVDs, an acyclic join lossless 4NF decomposition exists if  M  does not split its keys. Given a set of dependencies  D , obtaining the envelope set for  D , determining whether  D  is extended conflict free, and if  D  is extended conflict free, then obtaining a dependency preserving, acyclic, join lossless, 4NF decomposition can be done in time polynomial in the size of  D .	database design;functional programming;multivalued dependency;relational database	Li-Yan Yuan;Z. Meral Özsoyoglu	1992	Inf. Sci.	10.1016/0020-0255(92)90054-C	relational database;computer science;data mining;database;mathematics;algorithm	DB	-27.54031527334276	10.05338884786751	194756
6a449c7766adf9f11f10bfda303a2da73f16b860	an internet query language based on intuitionistic linear logic	internet database languages logic web pages software engineering conference management engineering management application software information retrieval;query language;intuitionistic linear logic;information retrieval;linear logic theory of computation internet information retrieval;query languages;information retrieval internet query language intuitionistic linear logic;theory of computing;internet;theory of computation;query languages internet;linear logic;regular expression;internet query language	We propose an Internet query language based on intuitionistic linear logic. This language extends regular expressions with linear implications and additive (classical) conjunctions. To be precise, it allows goals of the form D -o G and G1&G2 where D is a text and G is a goal. The first goal is intended to be solved by adding D to the current text and then solving G. This goal is flexible in controlling the current text dynamically. The second goal is intended to be solved by solving both G1 and G2 from the current text. This goal is particularly useful for internet search.	gnutella2;internet;linear logic;query language;regular expression;utility functions on indivisible goods;web search engine	Keehang Kwon;JaeWoo Kim;Jang-Wu Jo	2007	5th ACIS International Conference on Software Engineering Research, Management & Applications (SERA 2007)	10.1109/SERA.2007.50	query optimization;query expansion;theory of computation;computer science;theoretical computer science;database;rdf query language;programming language;web search query;information retrieval;query language	DB	-33.11424036568968	6.707283777603879	195373
35adb1f606bf5bd58486d7832b682fa505dfab48	translate graphical xml query language to sqlx	modelizacion;query language;base donnee;graphical language;sql;xml language;interrogation base donnee;database;interrogacion base datos;base dato;semantics;semantica;semantique;lenguaje interrogacion;user assistance;modelisation;semistructured data;semantic model;semi structured data;assistance utilisateur;dato semi estructurado;asistencia usuario;modele donnee;langage interrogation;modeling;database query;langage xml;lenguaje xml;lenguaje grafico;langage graphique;data models;donnee semistructuree	Semi-structured data has become more and more attention-getting with the emergence of XML, and it has aroused much enthusiasm for integrating XML and SQL in database community. Due to the complexity of XQuery, graphical XML query languages have been developed to help users query XML data. In this paper, we propose a new XML-to-SQL solution on the base of ORA-SS, a rich semantic model for semi-structured data. We model the data by ORA-SS schema and store them in an ORDB. Based on ORA-SS, we developed a graphical XML query language GLASS that not only expresses the query constraints and reconstruction structure in XML view but also the relational semantic in the XML view. This paper focuses on the translation algorithm from GLASS to SQLX, an XML extension on traditional SQL.	algorithm;computer-aided software engineering;emergence;glass;graphical user interface;mathematical optimization;openraster;query language;query optimization;sql;semi-structured data;semiconductor industry;xml editor;xpath;xquery	Wei Ni;Tok Wang Ling	2005		10.1007/11408079_83	plain old xml;semantic data model;xml catalog;xml validation;data modeling;xml encryption;sql;simple api for xml;semi-structured data;xml;systems modeling;relax ng;xml schema;streaming xml;computer science;document type definition;document structure description;xml framework;xml database;xml schema;database;semantics;xml signature;programming language;world wide web;xml schema editor;query language;efficient xml interchange;sgml	DB	-33.09986477974753	9.426592935926625	195637
59af57745cbfdfbefc3b960fc0629a69caac5753	flexs - a logical model for physical data layout			logical data model	Hannes Voigt;Alfred Hanisch;Wolfgang Lehner	2014		10.1007/978-3-319-10518-5_7		DB	-30.838788311046457	8.9788827090178	196731
959baa1fe387cbabdcc729411be7bb935f56d8cb	making smalltalk a database system	database system;storage management;operational semantics;independent mappings;object oriented programming;data model;view update;smalltalk;complementary mappings;relational databases;path expressions;database theory	To overcome limitations in the modeling power of existing database systems and provide a better tool for database application programming, Servio Logic Corporation is developing a computer system to support a set-theoretic data model in an object-oriented programming environment We recount the problems with existing models and database systems We then show how features of Smalltalk, such such as operational semantics, its type hierarchy, entity identity and the merging of programming and data language, solve many of those problems Nest we consider what Smalltalk lacks as a database system secondary storage management, a declarative semantics, concurrency, past states To address these shortcomings, we needed a formal data model We introduce the GemStone data model, and show how it helps to define path expressions, a declarative semantics and object history in the OPAL language We summarize similar approaches, and give a brief overview of the GemStone system implementation	class hierarchy;computer data storage;concurrency (computer science);data model;database;gemstone/s object server;integrated development environment;operational semantics;path expression;set theory;smalltalk	George P. Copeland;David Maier	1984		10.1145/602259.602300	database theory;entity–relationship model;data model;relational database;computer science;database model;data mining;database;programming language;object-oriented programming;operational semantics;database schema;database testing;database design;component-oriented database	DB	-30.63886117757025	10.781360101607417	197409
1222113443fbe6dca1d14875a4f48fb5e5624d63	flextable: using a dynamic relation model to store rdf data	flextable;dynamic relational model;relational model;semantic web;adjustment cost;rdf data;schema evolution;lattice	Efficient management of RDF data is an important factor in realizing the Semantic Web vision. The existing approaches store RDF data based on triples instead of a relation model. In this paper, we propose a system called FlexTable, where all triples of an instance are coalesced into one tuple and all tuples are stored in relation schemas. The main technical challenge is how to partition all the triples into several tables, i.e. it is needed to design an effective and dynamic schema structure to store RDF triples. To deal with this challenge, we firstly propose a schema evolution method called LBA, which is based on a lattice structure to automatically evolve schemas while new triples are inserted. Secondly, we propose a novel page layout with an interpreted storage format to reduce the physical adjustment cost during schema evolution. Finally we perform comprehensive experiments on two practical RDF data sets to demonstrate that FlexTable is superior to the state-of-the-art approaches.	crystal structure;experiment;logical block addressing;schema evolution;semantic web	Yan Wang;Xiaoyong Du;Jiaheng Lu;Xiaofang Wang	2010		10.1007/978-3-642-12026-8_44	rdf/xml;cwm;relational model;computer science;sparql;semantic web;lattice;data mining;database;information retrieval;rdf schema	DB	-32.65283280134254	5.434739132087739	197915
71131278ba733d99007c201bec9ef4e10efc4a4d	data warehouse enhancement: a semantic cube model approach	data mart;data cube;data analysis;data semantics;information integration;semantic cube model;object oriented technology;data warehouse	Many data warehouse systems have been developed recently, yet data warehouse practice is not sufficiently sophisticated for practical usage. Most data warehouse systems have some limitations in terms of flexibility, efficiency, and scalability. In particular, the sizes of these data warehouses are forever growing and becoming overloaded with data, a scenario that leads to difficulties in data maintenance and data analysis. This research focuses on data-information integration between data cubes. This research might contribute to the resolution of two concerns: the problem of redundancy and the problem of data cubes’ independent information. This work presents a semantic cube model, which extends objectoriented technology to data warehouses and which enables users to design the generalization relationship between different cubes. In this regard, this work’s objectives are to improve the performance of query integrity and to reduce data duplication in data warehouse. To deal with the handling of increasing data volume in data warehouses, we discovered important inter-relationships that hold among data cubes, that facilitate information integration, and that prevent the loss of data semantics. 2006 Elsevier Inc. All rights reserved.	data cube;database;redundancy (engineering);scalability;semantic data model	Shi-Ming Huang;Tung-Hsiang Chou;Jia-Lang Seng	2007	Inf. Sci.	10.1016/j.ins.2006.12.022	idef1x;data modeling;data quality;data model;dimensional modeling;computer science;data virtualization;data science;information integration;data warehouse;data mining;database;data analysis;data cube	DB	-32.88854388372869	11.103857771017262	198127
9b2fda082f6f10957d306942915cd816509c7764	designing views to efficiently answer real sql queries	busqueda informacion;base relacional dato;optimisation;data integrity;optimizacion;sql;information retrieval;interrogation base donnee;interrogacion base datos;semantics;abstraction;article δημοσίeυση πeριοδικού;relational database;abstraccion;semantica;semantique;vista materializada;materialized view;recherche information;query evaluation;reecriture;base donnee relationnelle;optimization;materialized views;systeme gestion base donnee;rewriting;sistema gestion base datos;database management system;data management system;database query;reescritura;vue materialisee	The problem of optimizing queries in the presence of materialized views and the related view-design problem have recently attracted a lot of attention. Significant research results have been reported, and materialized views are increasingly used in query evaluation in commercial data-management systems. At the same time, most results in the literature assume set-theoretic semantics, whereas SQL queries have bagtheoretic semantics (duplicates are not eliminated unless explicitly requested). This paper presents results on selecting views to answer queries in relational databases under set, bag, and bag-set semantics. The results can be used under each of the three assumptions, to find sound and complete algorithms for designing views and rewriting queries efficiently.	acm transactions on database systems;algorithm;conjunctive query;data cube;materialized view;mathematical optimization;olap cube;online analytical processing;optimization problem;peer-to-peer;relational database;rewriting;sql;selection algorithm;set theory;sethi–ullman algorithm;xquery	Foto N. Afrati;Rada Chirkova;Manolis Gergatsoulis;Vassia Pavlaki	2005		10.1007/11527862_26	materialized view;computer science;data mining;database;semantics;information retrieval	DB	-27.407382123258003	5.503833645911183	198366
20c3b1d58e36bfadabe52ded94655a55016b3762	the method for xml schema integration by using a uml diagram	xml schema		diagram;unified modeling language;xml schema	Ying-Wen Bai;Ke-Sin Feng	2005			xml schema (w3c);streaming xml;document structure description;database;programming language;relax ng;xml schema;xml schema editor;xml validation;efficient xml interchange;computer science	DB	-33.10505073163146	8.312956714744175	198924
9ff9498b5294aae6b1348c408d55ccb42954fe14	a deductive data model for representing and querying semistructured data	data model	We show how the mechanisms of an active/deductive object-oriented model are capable of modeling the information available on the World Wide Web, the paradigmatic example of a large, distributed collection of poorly structured, heterogeneous information, consisting of documents connected by hypertext links. We exhibit the basic features of the object model, including the schema deenition language , the query language with multiple roles, the basic update operations, and a form of active rules, and a compilation of the mentioned features into a fragment of LDL++, which is essentially Datalog extended with non-determinism and a form of stratiied negation. The proposed compilation has a twofold aim. On one side, it should provide an abstract implementation level, where the object model is declaratively reconstructed and its semantics clariied. On the other side, the proposed compilation should form the basis of a realistic implementation, as LDL++ can be eeciently executed, and supports real side eeects.	compiler;data model;datalog;event condition action;hypertext;negation as failure;query language;world wide web	Fosca Giannotti;Giuseppe Manco;Dino Pedreschi	1997			information retrieval;data model;computer science	DB	-29.991098048347762	11.013533036595407	199634
55332ddea409227acf86253189c12a76b1cfa20f	storing and retrieving xpath fragments in structured p2p networks	distributed xml;p2p;data format;side effect;query evaluation;xpath;xml querying;p2p networks;peer to peer;path expressions	In this paper, we address the problem of storing and retrieving XML data over structured Peer-to-Peer (P2P) networks. These are becoming popular because of their access efficiency. An open problem with such networks is represented by the kinds of queries they can handle. In fact, file name lookups, used in popular unstructured networks, are not suitable for many new data formats. Keyword-based searches are also not appropriate for XML data, which must be identified by the whole path leading to an element, rather than by the sole element name. We discuss the extensions needed to properly identify XML data in structured P2P networks. A global document is split into various fragments, which are locally stored within the peers according to their own themes. Each fragment is enhanced with a set of few lightweight path expressions that have the convenient side effect of yielding a decentralized catalog. Since a mediated global schema would not be a reasonable assumption in an highly dynamic P2P network, we show that XPath query evaluation only relying on this catalog effectively biases the search towards particular peers. Our approach does not suffer the network and data size limits of previous proposals and is scalable for large P2P networks. To validate our ideas, we have devised XP2P, namely XPath for P2P, on which we have conducted a comprehensive experimental study using various XML datasets. 2006 Elsevier B.V. All rights reserved.	experiment;path expression;peer-to-peer;scalability;xml;xpath	Angela Bonifati;Alfredo Cuzzocrea	2006	Data Knowl. Eng.	10.1016/j.datak.2006.01.011	xml catalog;data access;xml validation;xml encryption;simple api for xml;xslt;xml schema;streaming xml;computer science;document structure description;xml framework;path expression;peer-to-peer;data mining;xml database;xml schema;database;xml signature;world wide web;xml schema editor;side effect;efficient xml interchange	DB	-33.32121819982601	4.383334181312839	199726
0624c6fd7a2aa08fe3d6c967c1a264750a3eac69	the bea/xqrl streaming xquery processor	query language;bea;data stream;high performance	In this paper, we describe the design, implementation, and performance characteristics of a complete, industrial-strength XQuery engine, the BEA streaming XQuery processor. The engine was designed to provide very high performance for message processing applications, i.e., for transforming XML data streams, and it is a central component of the 8.1 release of BEA’s WebLogic Integration (WLI) product. This XQuery engine is fully compliant with the August 2002 draft of the W3C XML Query Language specification. A goal of this paper is to describe how an efficient, fully compliant XQuery engine can be built from a few relatively simple components and well-understood technologies.	oracle weblogic server;programming language specification;query language;xml;xquery	Daniela Florescu;Chris Hillery;Donald Kossmann;Paul Lucas;Fabio Riccardi;Till Westmann;Michael J. Carey;Arvind Sundararajan;Geetika Agrawal	2003		10.1016/B978-012722442-8/50093-8	computer science;database;world wide web;information retrieval;query language	DB	-33.01664296317152	6.469379295803409	199995
