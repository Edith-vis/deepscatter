id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
4a80eef14af093aca593380f8c771def120bb0ae	scalability approaches for causal multicast: a survey	interconnection;vector clock;articulo;causal multicast;68n01;90b18;multicast protocol;version vector;scalability;68 00;68m14	Many distributed services need to be scalable: internet search, electronic commerce, e-government $$\ldots $$ … In order to achieve scalability those applications rely on replicated components. Because of the dynamics of growth and volatility of customer markets, applications need to be hosted by adaptive systems. In particular, the scalability of the reliable multicast mechanisms used for supporting the consistency of replicas is of crucial importance. Reliable multicast may propagate updates in a pre-defined order (e.g., FIFO, total or causal). Since total order needs more communication rounds than causal order, the latter appears to be the preferable candidate for achieving multicast scalability, although the consistency guarantees based on causal order are weaker than those of total order. This paper provides a historical survey of different scalability approaches for reliable causal multicast protocols.	adaptive system;causal consistency;causal filter;causality;data compaction;e-commerce;e-government;eventual consistency;fifo (computing and electronics);interconnection;lazy evaluation;multicast;scalability;software propagation;vector clock;volatility;web search engine	Rubén de Juan-Marín;Hendrik Decker;José Enrique Armendáriz-Iñigo;José M. Bernabéu-Aubán;Francesc D. Muñoz-Escoí	2015	Computing	10.1007/s00607-015-0479-0	version vector;real-time computing;multicast;scalability;ip multicast;inter-domain;reliable multicast;vector clock;protocol independent multicast;computer science;interconnection;pragmatic general multicast;distributed computing;distance vector multicast routing protocol;source-specific multicast;xcast;computer network;multicast address	DB	-32.126062574650284	47.5789265373603	178615
5322203536f7a35e5ebcaf4cc950c0e991efb62c	bridging the gap between distributed and multi-core computing, and soa and grid computing.	grid computing			Géraldine Cabannes	2008	ERCIM News		fabric computing;computer science;distributed computing;grid computing	HPC	-30.09132057218275	47.95830120284677	179326
10381f745c9e5b70487911312c878a8797fb0aa8	grid-based system for product design optimization	front end;design engineering;graphical interface;distributed computing;maintenance engineering;design optimization;product design design optimization graphical user interfaces computer aided engineering maintenance engineering design engineering productivity organizing monitoring distributed computing;optimization problem;graphical user interfaces;monitoring;distributed environment;organizing;computer aided engineering;grid service;finite element analysis;productivity;product design;service oriented architecture	This paper describes the progress of developing a Grid-based system for product design optimizations to increase the engineer's productivity by saving him tedious, manual, and error-prone work of organizing, maintaining, submitting and monitoring computational workflows comprising hundreds of jobs in a heterogeneous distributed environment. The approach is that once the optimization process is interactively defined through a GUI, the process runs asynchronously, automatically, and autonomously. This goal is being achieved through horizontal integration by employing a Service Oriented Architecture. The developed cyberinfrastructure comprises a collection of Grid services that automates creation, submission and monitoring of jobs. In addition, support is provided for accessing information needed to identify the reasons of failures, should any occur, The front end of the system augments a commercial, state-of-the-art user graphical interface (Abacus CAE) for defining a finite element analysis problem with custom GUI components for specifying the optimization problem and providing access to remote resources. The access to remote resources is achieved by embedding clients of Grid services in the Abacus CAE.	baseline (configuration management);cognitive dimensions of notations;computer-aided design;cyberinfrastructure;fault tolerance;finite element method;full scale;graphical user interface;grid computing;interactivity;job stream;mathematical optimization;optimization problem;organizing (structure);prototype;scheduling (computing);service-oriented architecture;simulation;tee (command);usb hub;x/open	Tomasz Haupt;Anupama Voruganti;Anand Kalyanasundaram;Igor Zhuk	2006	2006 Second IEEE International Conference on e-Science and Grid Computing (e-Science'06)	10.1109/E-SCIENCE.2006.79	maintenance engineering;human–computer interaction;computer science;operating system;graphical user interface;database;distributed computing;product design	HPC	-30.965431796013473	48.49775454214014	179575
8b73d778d0eba5eb37bbaa2d204c1d2e6dca7638	implementation of a service platform for online games	early experience;online game;core competencies;game hosting;multiplayer online games;performance metric;large scale;software development;on demand computing;utility computing;off the shelf;online games;open standard	Large-scale multiplayer online games require considerable investment in hosting infrastructures. However, the difficulty of predicting the success of a new title makes investing in dedicated server and network resources very risky. A shared infrastructure based on utility computing models to support multiple games offers an attractive option for game providers whose core competency is not in managing large server deployments.In this paper we describe a prototype implementation of a shared, on demand service platform for online games. The platform builds on open standards and off-the-shelf software developed to support utility computing offerings for Web-based business applications. We describe our early experience with identifying appropriate performance metrics for provisioning game servers and with implementing the platform components that we consider essential for its acceptance.	dedicated hosting service;game server;prototype;provisioning;server (computing);smoothing;software metric;utility computing	Anees Shaikh;Sambit Sahu;Marcel-Catalin Rosu;Michael Shea;Debanjan Saha	2004		10.1145/1016540.1016547	simulation;open standard;computer science;software development;operating system;distributed computing;game developer;utility computing;core competency;video game development;world wide web	Web+IR	-33.408065851379874	52.08014235597696	181666
7b7917f3026a8f13d6ec867b7b9a53e1bb056275	a grid advance reservation framework for co-allocation and co-reservation across heterogeneous local resource management systems	grid scheduling;grid applications;co allocation;grid;advance reservation;co reservation;resource management system	Co-allocation and co-reservation is a key capability of Grid schedulers for supporting some complex Grid applications, e.g., workflow. The chief enabling technology of co-allocation and co-reservation is Advance Reservation (AR), which is typically implemented by local Resource Management Systems (RMSs). As at present only a limited number of RMSs can support AR, and most of them use individual interface formats, it is rather difficult for Grid schedulers to manage Grid ARs across heterogeneous RMSs, including AR-incapable ones, through a uniform interface. In this paper we propose a Grid AR framework which can address the issue by means of a Grid AR manager that is able to externalize the AR functionality from local RMSs. An advanced Grid AR algorithm is implemented in the Grid AR manager, and a local AR API and Grid AR API is respectively defined to standardize the interaction between the Grid AR manager and local RMSs, as well as between high level Grid scheduler components and Grid AR manager. Based on a plugin architecture, the Grid AR framework is able to incorporate different types of local RMSs to implement Grid AR functionalities, irrespective of whether local RMSs support AR or not.	management system	Changtao Qu	2007		10.1007/978-3-540-68111-3_81	real-time computing;computer science;operating system;database;grid;drmaa;grid computing	HPC	-30.767457182812873	52.98411150807829	182745
801c6e140dc115700c3b8eb33826b053bd4a4222	the opencf: an open source computational framework based on web services technologies	web interface;web service;web portal;security requirements;high performance computer;open source	Web Services-based technologies have emerged as a technological alternative for computational web portals. Facilitating access to distributed resources through web interfaces while simultaneously ensuring security is one of the main goals in most of the currently existing manifold tools and frameworks. OpenCF, the Open Source Computational Framework that we have developed, shares these objectives and adds others, like enforced portability, generality, modularity and compatibility with a wide range of High Performance Computing Systems. OpenCF has been implemented using lightweight technologies (Apache + PHP), resulting in a robust framework ready to run out of the box that is compatible with standard security requirements.	open-source software;web service	Adrián Santos;Francisco Almeida;Vicente Blanco Pérez	2007		10.1007/978-3-540-68111-3_83	web service;web application security;web development;web modeling;data web;web mapping;web-based simulation;web design;web accessibility initiative;web standards;computer science;operating system;ws-policy;service-oriented architecture;web navigation;database;web intelligence;web engineering;user interface;web 2.0;world wide web;mashup	Web+IR	-32.57693500330209	52.47886227561352	183094
20c78f0940434a6bf4ae0ab38cfdf79d099f2553	toward a general i/o arbitration framework for netcdf based big data processing		On the verge of the convergence between high performance computing (HPC) and Big Data processing, it has become increasingly prevalent to deploy large-scale data analytics workloads on high-end supercomputers. Such applications often come in the form of complex workflows with various different components, assimilating data from scientific simulations as well as from measurements streamed from sensor networks, such as radars and satellites. For example, as part of the next generation flagship (post-K) supercomputer project of Japan, RIKEN is investigating the feasibility of a highly accurate weather forecasting system that would provide a real-time outlook for severe guerrilla rainstorms. One of the main performance bottlenecks of this application is the lack of efficient communication among workflow components, which currently takes place over the parallel file system. In this paper, we present an initial study of a direct communication framework designed for complex workflows that eliminates unnecessary file I/O among components. Specifically, we propose an I/O arbitrator layer that provides direct parallel data transfer among job components that rely on the netCDF interface for performing I/O operations, with only minimal modifications to application code. We present the design and an early evaluation of the framework on the K Computer using up to 4800 nodes running RIKEN’s experimental weather forecasting workflow as a case study.	big data;clustered file system;data assimilation;input/output;k computer;lunar lander challenge;message passing interface;microsoft outlook for mac;middleware;netcdf;next-generation network;radar;real-time transcription;simulation;streaming media;supercomputer;the verge;throughput	Jianwei Liao;Balazs Gerofi;Guo-Yuan Lien;Seiya Nishizawa;Takemasa Miyoshi;Hirofumi Tomita;Yutaka Ishikawa	2016		10.1007/978-3-319-43659-3_22	parallel computing;real-time computing;simulation;computer science;operating system;database;distributed computing	HPC	-28.23449401429193	52.9334320675912	183153
d4ede9c4e7196ba8d04d5c4c67b707902d5be390	distributed infrastructure for multiscale computing	computational modeling middleware educational institutions communities couplings data models;grid middleware;grid middleware distributed infrastructure multiscale computing multiscale system scientific discipline multidisciplinary multiscale model mapper project distributed multiscale simulation e infrastructure multitiered software infrastructure grid computing;multiscale infrastructures;universiteitsbibliotheek;middleware grid computing;grid middleware multiscale simulation multiscale infrastructures grid computing;middleware;grid computing;multiscale simulation	Today scientists and engineers are commonly faced with the challenge of modelling, predicting and controlling multiscale systems which cross scientific disciplines and where several processes acting at different scales coexist and interact. Such multidisciplinary multiscale models, when simulated in three dimensions, require large scale or even extreme scale computing capabilities. The MAPPER project is developing computational strategies, software and services to enable distributed multiscale simulations across disciplines, exploiting existing and evolving e-Infrastructure. The resulting multi-tiered software infrastructure, which we present in this paper, has as its aim the provision of a persistent, stable infrastructure that will support any computational scientist wishing to perform distributed, multiscale simulations.	coexist (image);computational scientist;cyberinfrastructure;ibm websphere extreme scale;mapper;monte carlo method;multiscale modeling;simulation	Stefan J. Zasada;Mariusz Mamonski;Derek Groen;Joris Borgdorff;Ilya Saverchenko;Tomasz Piontek;Krzysztof Kurowski;Peter V. Coveney	2012	2012 IEEE/ACM 16th International Symposium on Distributed Simulation and Real Time Applications	10.1109/DS-RT.2012.17	computational science;computer science;theoretical computer science;distributed computing;grid computing	HPC	-29.704826824971708	51.30229900245386	183538
72e709fa816a8ae9423f7ca59c029915e9272e02	cloudy emulation - efficient and scaleable emulation-based services		Emulation as a strategy for digital preservation is about to become an accepted technology for memory institutions as a method for coping a large variety of complex digital objects. Hence, the demand for ready-made and especially easy-to-use emulation services will grow. In order to provide user-friendly emulation services a scalable, distributed system model is required to be run on heterogeneous Grid or Cluster infrastructure. We propose an Emulation-as-a-Service architecture that simplifies access to preserved digital assets allowing end users to interact with the original environments running on different emulators. Ready-made emulation components provide a flexible web service API allowing for development of individual and tailored digital preservation workflows. This paper describes design and implementation of scalable emulation services as part of the bwFLA EaaS framework.	application programming interface;cloud computing;computer cluster;digital asset;distributed computing;emulator;scalability;usability;web service	Isgandar Valizada;Klaus Rechert;Konrad Meier;Dennis Wehrle;Dirk von Suchodoletz;Leander Sabel	2013			embedded system;emulation;computer science	HPC	-31.43227633761963	52.246255667133916	184122
87adf4418e9e27d4e3162c06972a7b06f83ec2c3	a dynamic resource management system for real-time online applications on clouds	multi-player online computer game;real-time online interactive applications;load balancing;multi-player online game;cloud resource allocation;real-time simulation;real-time online application;real-time user interactivity;cloud environment;challenging class;dynamic resource management system	multi-player online computer game;real-time online interactive applications;load balancing;multi-player online game;cloud resource allocation;real-time simulation;real-time online application;real-time user interactivity;cloud environment;challenging class;dynamic resource management system	management system;real-time transcription	Dominik Meiländer;Alexander Ploss;Frank Glinka;Sergei Gorlatch	2011		10.1007/978-3-642-29737-3_18	simulation;computer science;distributed computing;multimedia	Embedded	-27.928098109387367	49.74523583992068	184453
03562caa20415c2ce97d6c537773135cdaacc695	providing service level agreement using clustered web server partition mechanism			service-level agreement;web server	Kiejin Park;Hyeonjoo Go	2005			database;partition (number theory);service-level agreement;web server;distributed computing;computer science	Web+IR	-28.862029889630307	47.806057559767964	185317
169c8b3be66d04bd8997ec8354091ec84ef62d47	storage organization and management in tenex	new time-shared operating system;large list-processing computation;available system;core storage;process memory;storage organization;time-sharing environment;foremost requirement;sufficient memory;large process	In early 1969, BBN began an effort aimed at developing a new time-shared operating system. It was felt at the time that none of the commercially available systems could meet the needs of the research planned and in progress at BBN. The foremost requirement of the desired operating system was that it support a directly addressed process memory in which large list-processing computations could be performed. The cost of core storage prohibited the acquisition of sufficient memory for even one such process, and the problems of swapping such very large processes in a time-sharing environment made that solution technically infeasible as well.	address space;complexity;computation;computer memory;core storage;dynamic-link library;foremost;http 404;hash table;operating system;pdp-10;paging;subroutine;tops-20;time-sharing	Daniel L. Murphy	1972		10.1145/1479992.1479996	real-time computing;simulation;engineering;operations management	HPC	-27.307206231111014	52.81855310079702	186083
db3ba5d1692e03c1a982ba8f4959c6683c71be45	multi-vendor interoperability through sql access	sql access;multi-vendor interoperability	Several years ago, there was no general approach to providing widespread interoperability between databases and database tools from different sources. The interoperability solutions that did exist were primarily achieved through specific, point solutions that provided interoperability between a single pair of vendors. At the time, many companies were faced with the expensive and daunting possibility of creating tid supporting a number of these pair-wise solutions. The SQL Access Group was formed in order to provide common solutions to the multi-vendor interoperability and portability problems. Its primary foeus is to accelerate existing efforts in official standards bodies, such as ANSI and ISO, by providing input to the standards process. Unique to the group, is the concept of prototyping and demonstrating these standards in order to ensure their viability. The SQL Access Group is currently working in three areas: the SQL language (API), client-server formats and protocols (FAP), and a dynamic SQL-oriented, procedure call-based interfaee (CLI). A common definition for the SQL language is essential for application portability and for client-server interoperability, because SQL statements are communicated between client and server. The SQL Aeeess embedded SQL definition is based on SQL-89 with extensions from SQL2, some of which were originally proposed by SQL Aeeess. The spec%ication is published by X/open in cooperation with SQL Aeeess. Client-sewer communication is achieved through the use of formats and protocols that are based on the 1S0 Remote Database Aeeess (RDA) standard over an 0S1 network. The SQL Aeeess Group was instrumental in providing essential input into the RDA standard. The group is also finalizing a mapping of the formats and protocols for TCP/lP networks. The SQL Access Call-Level Interfaee (CLI) is a procedure call-based interface that will shortly be published as an X/open “snapshot” specification. It is intended to support the requirements of “shrink-wrapped” software vendors, and others wishing to use an alternative to embedded SQL, SQL Aeeess members are currently working towards products that implement one or more of the SQL Access standards. Digital Equipment Corporation is expecting to ship a SQL Access (FAP) Server in the near future. Microsoft Corporation has recently announced their Open Database Connectivity (ODBC) architecture, that has the SQL Aeeess CLI at its core. They expeet to ship ODBC in June 1992. Additional SQL Access-based products are expected from these and other sources in late 1992 and early 1993. The talk will deseribe The SQL Aeeess Group and elaborate on the areas in which the group is working. The relationship between the work of The SQL Access Group and the 1S0 SQL2 and Remote Database Access (RDA) standards will be explaind as well as their involvement with X/open. In addition, some parallels with other significant remote database access approached will be illustrated.	ansi escape code;application programming interface;client–server model;embedded sql;embedded system;face animation parameter;interoperability;open database connectivity;parallels desktop for mac;remote database access;requirement;sql access group;sql server compact;server (computing);shrink wrap contract;snapshot (computer storage);software portability;software prototyping;subroutine;wise solutions;x/open	Scott Newmann	1992		10.1145/130283.130345	data transformation services;semantic interoperability;interoperability;business intelligence markup language;language interoperability;open database connectivity;data mining;database;world wide web	DB	-33.10503618885961	51.40821236683331	188712
b1caaeef43f97899c9a86891032d503930c0dd1c	oscar testing with xen	packaging machines;virtual machine;mathematics;virtual machining;distributed computing;testing;computer networks;testing computer networks linux computer science mathematics laboratories virtual machining software packages packaging machines distributed computing;linux;computer science;software packages	The development of new OSCAR packages and of new releases is difficult because of the testing required for the ever growing set of supported Linux distributions. Each time, a new cluster has to be setup, including the full installation of the headnode system. At the same time, some paravirtualization software, like Xen, allows one to create a set of virtual machines on a single physical machine. Therefore, the use of Xen for cluster virtualization and OSCAR testing may be interesting. This document presents Xen-OSCAR, a framework based on Xen, which aims at providing a solution to create a virtual OSCAR cluster.	linux;oscar;virtual machine;x86 virtualization	Geoffroy Vallée;Stephen L. Scott	2006	20th International Symposium on High-Performance Computing in an Advanced Collaborative Environment (HPCS'06)	10.1109/HPCS.2006.31	embedded system;parallel computing;computer hardware;computer science;virtual machine;operating system;distributed computing;software testing;hypervisor;linux kernel	Arch	-27.131796850972197	51.98117083325562	188727
7cda5cfc39353324ca6f4ddf294303249d0b1e02	grid small and large: distributed systems and global communities	web services;software engineering;software reliability;distributed system;grid computing;earthquake engineering;computer science;distributed systems;application software;protocols;software performance;software development;couplings;software security;writing;resource sharing	Summary form only given. Grid technologies seek to enable collaborative problem solving and resource sharing within distributed, multi-organizational virtual organizations. Two characteristics of Grid environments make the engineering of systems and applications particularly challenging. First, we face the familiar difficulties that arise when developing software that must provide reliability, performance, and security in environments that may be heterogeneous, unpredictable, unreliable, and hostile; second, we must allow this software to be deployed, operated, and evolved in an environment characterized by multiple participants with different and perhaps conflicting views on system function and design. The author presents the work that is being done to address these challenges.	distributed computing;integrated development environment;problem solving;virtual organization (grid computing)	Ian T. Foster	2004	Proceedings. 26th International Conference on Software Engineering		software security assurance;shared resource;computing;software engineering process group;semantic grid;computer science;knowledge management;social software engineering;software framework;component-based software engineering;software development;middleware;software construction;software as a service;distributed computing;distributed design patterns;software walkthrough;software analytics;resource-oriented architecture;software deployment;world wide web;software requirements;grid computing;software system	SE	-31.37348110948921	47.83727273512552	189025
bed066efbebcd6e69f2bb277e29794849e7da0a4	towards ogsa compatibility in alternative metacomputing frameworks	distributed computing;distributed environment;grid service	Lately, grid research has focused its attention on interoperability and standards, such as Grid Services, in order to facilitate resource virtualization, and to accommodate the intrinsic heterogeneity of resources in distributed environments. To ensure interoperability with other grid solutions, it is important that new and emerging metacomputing frameworks conform to these standards. In particular, the H2O system offers several benefits, including lightweight operation, user-configurability, and selectable security levels; with OGSA compliance, its applicability would be enhanced even further In this contribution, a framework is presented which will augment the H2O-system with the functionality to produce and publish WSDL and GSDL documents for arbitrary third party pluglets, and thereby enhance OGSA compatibility.	interoperability;metacomputing;open grid services architecture;web services description language;x86 virtualization	Gunther Stuer;Vaidy S. Sunderam;Jan Broeckhove	2004		10.1007/978-3-540-24685-5_7	real-time computing;computer science;database;distributed computing;distributed computing environment	HPC	-32.499318386402024	52.59679086536309	189710
b046ad85f5eb88ff94c19f45433989d5478a61b5	fadi : a fault-tolerant environment for distributed processing systems			distributed computing;fault tolerance	Taha Mohammed Osman	1998				OS	-29.3246326657412	46.67090321232199	189857
77a1bd22bdf0245b756d4d2e9b073c4ec796b4f3	combining cloud and grid with a user interface		Increasing computing clouds are delivered to customers. Each cloud, however, provides an individual, non-standard user interface. The difference in cloud interfaces must burden the users when they work with several clouds for acquiring the services with expected price. This paper introduces an integrated framework that can be usedby cloudusers to access the underlying services in a uniform, cloud-independent manner. Theframework is anextention of a graphical griduser interface developed withinthe g-Eclipse project. The goal of building a clouduser interface on top of a grid interface is to combine cloudsandgrids into a singlerealm, allowing an easy interoperation between the two infrastructures.	cloud computing;eclipse;graphical user interface;interoperation	Jiaqi Zhao;Jie Tao;Mathias Stuempert;Moritz Post	2009		10.1007/978-3-642-12636-9_8	grid file	HCI	-31.441714728614986	52.37998817675372	190122
a4345888ec57289d0a67e8f4195273952e40d54a	on the discovery of brokers in distributed messaging infrastructures	broker networks;distributed messaging infrastructures;messaging middleware brokers discovery distributed messaging infrastructures communication requirements;messaging middleware;middleware electronic messaging;broker discovery;routing network servers message oriented middleware laboratories availability bandwidth degradation transport protocols energy management information management;broker networks broker discovery messaging middleware publish subscribe;communication requirements;publish subscribe;electronic messaging;middleware;brokers discovery	Increasingly messaging infrastructures are being used to support the communication requirements of a wide variety of clients, services, and proxies thereto. Typically, for various reason this messaging infrastructure is a distributed one with multiple constituent brokers. In the paper we present our scheme for the discovery of brokers in distributed messaging infrastructures based on the publish/subscribe paradigm. We also include empirical results from our experiments related to the implementation of our scheme	computer;experiment;national center for supercomputing applications;programming paradigm;proxy server;publish–subscribe pattern;requirement	Shrideep Pallickara;Harshawardhan Gadgil;Geoffrey C. Fox	2005	2005 IEEE International Conference on Cluster Computing	10.1109/CLUSTR.2005.347076	middleware;messaging pattern;computer science;operating system;middleware;database;publish–subscribe pattern;message broker;world wide web;computer network	Robotics	-31.67054457803976	50.15328793308358	190433
39c7115047769b55b06eb21aeabc11519966a1ac	a hierarchical distributed communication architecture for real-time auctions	real time	This paper presents a new hierarchical distributed communication architecture, called AHS (Auction Handling System), based on clusters. This architecture uses the IRC (Internet Relay Chat) channels and protocol facilities in order to support real-time auction applications (RTA). Coordination between distributed auction servers is needed to exchange and update some relevant auction information and to resolve the winning bid within a cluster. The problem is how to determine the best location of the auction server coordinator. For this purpose, we suggest the use of the Floyd-Warshall’s algorithm, which is a graph	auction algorithm;communications protocol;distributed computing;fairness measure;floyd–warshall algorithm;graph (discrete mathematics);graph theory;high availability;interaction;internet relay chat;load balancing (computing);platoon (automobile);polyphase quadrature filter;real-time clock;real-time transcription;scalability;server (computing);shortest path problem;simulation	Ilhem Abdelhedi Abdelmoula;Hella Kaffel Ben Ayed;Farouk Kamoun	2005			real-time computing;simulation;computer science;theoretical computer science	Networks	-29.40720202628997	47.420921767751416	190451
80b5064362e5db51ac8885a259179c90dc3454b7	a centralized data collection and management tool in the va: redcap			centralized computing	Erika Whittier;Denise M. Hynes;Peter Watson	2015			database;data collection;computer science	HCI	-27.563605910478252	51.33238718883085	191398
123c7c21c7bbfc074e2466d22f195a92775f2689	programming for dependability in a service-based grid	cluster computing;service provider;life cycle;programming paradigm;application software;grid applications;distributed computing;process support systems;web service;bioopera grid computing platform;computer applications;visual programming;internet;monitoring;programming paradigms;web services;service based grid infrastructure;internet grid computing visual programming workstation clusters;cluster computing service based grid infrastructure web services programming paradigms bioopera grid computing platform;middleware;computer science;workstation clusters;grid computing;grid computing application software web services computer science computer applications monitoring large scale systems distributed computing memory middleware;monitoring and control;memory;large scale systems	Service-based Grid infrastructures emphasize service composition rather than sharing of low level resources. The idea is to build Grid applications out of computational services provided by the different sites of the Grid. Recent developments in the area of Web services have strengthened this idea by standardizing procedures like service description, publication and invocation. What is still missing is the infrastructure necessary to support the complete life cycle of applications running on service based Grids, i.e., suitable programming paradigms, execution infrastructure, and the ability to monitor and control such computations. Moreover, once computations are made of composable services, dependability becomes a key issue that needs to be addressed by the infrastructure as it cannot be addressed separately by each individual service. To address these concerns, we have developed the BioOpera Grid computing platform. BioOpera is a process support system for dependable cluster computing that has been extended with additional functionality to provide adequate support for service-based Grids. In this paper we describe how BioOpera can be used to develop, execute, and administer highly dependable computations over service-based Grids.	autonomic computing;computation;computer cluster;data visualization;dependability;experiment;graphical user interface;grid computing;oracle grid engine;programming paradigm;service composability principle;usability;web service	Win Bausch;Cesare Pautasso;Gustavo Alonso	2003		10.1109/CCGRID.2003.1199365	web service;computer science;service delivery framework;operating system;database;distributed computing;programming paradigm;grid computing	HPC	-31.638270612370622	48.842844144316096	191787
78a8d74ca47756b6b8922e59a109a09ef565bd00	mjades: concurrent simulation in the cloud	libraries;analytical models;statistical analysis cloud computing distributed processing;discrete event simulation cloud computing;distributed processing;computational modeling analytical models adaptation models engines libraries middleware synchronization;computational modeling;engines;statistical analysis;synchronization;middleware;adaptation models;simulation engine mjades concurrent simulation cloud computing statistical validation distributed system web interface;cloud computing;discrete event simulation	"""The simulation of complex systems is a time expensive and resource consuming task. Furthermore, the statistical validation of simulation models or the need to compare the system behavior in several different conditions require many simulation runs. A viable solution to speed up the process is to run multiple simulations in parallel on a distributed system, for example by means of a web interface. In this context, the cloud computing paradigm can be of help, offering almost unlimited computing resources that can be leased as a service. In this paper we will present the structure of a new simulation engine """" in thecloud"""" (mJADES), which runs on the top of an ad-hoc federation of cloud providers and is designed to perform multiple concurrent simulations. Given a set of simulation tasks, mJADES is able automatically to acquire the computing resources needed from the cloud and to distribute the simulation runs to be executed."""	cloud computing;complex systems;distributed computing;hoc (programming language);mathematical optimization;ncsa mosaic;programming paradigm;scalability;simulation;software architecture;user interface	Massimiliano Rak;Antonio Cuomo;Umberto Villano	2012	2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems	10.1109/CISIS.2012.134	real-time computing;simulation;cloud computing;computer science;cloud testing;distributed computing;utility computing	HPC	-29.312801564925714	50.81999029677189	193150
41709c8e3f868b1fc4dffe0592cbe176e181e9d1	synchronization of multimedia data streams in open distributed environments	data stream;real time;distributed environment;multimedia data;communication channels;geographic distribution	This paper presents a study of synchronization mechanisms for real-time video, audio and text data streams. Synchronization is an important and complex issue when multimedia information, stored at geographically distributed locations, has to be transported to an end-system for presentation via various communication channels.		Peter Leydekkers;Bertjan Teunissen	1991		10.1007/3-540-55639-7_9	real-time computing;computer science;database;distributed computing;distributed computing environment;channel	DB	-31.344917610840383	46.81773607172505	193235
38713d47c7e8e3e64ac27643c5c48b1740440a34	managing distributed files with rns in heterogeneous data grids	metadata;grid applications;resource allocation;prototypes;grid computing heterogeneous data grid distributed file management resource namespace service hierarchical namespace management name to resource mapping grid resources middleware rns directory entries rns junction entries xml message metadata rns server;heterogeneous data;hierarchical namespace management;junctions middleware xml servers distributed databases planning prototypes;rns junction entries;junctions;rns directory entries;rns server;resource namespace service;distributed file management;servers;grid resources;file system;saga data grid grid computing interoperability file system rns metadata;xml;distributed databases;middleware;heterogeneous data grid;meta data;planning;interoperability;rns;name to resource mapping;grid computing;xml message;data grid;saga;file organisation;xml distributed databases file organisation grid computing meta data middleware resource allocation	This paper describes the management of files distributed in heterogeneous Data Grids by using RNS (Resource Namespace Service). RNS provides hierarchical namespace management for name-to-resource mapping as a key technology to use Grid resources for different kinds of middleware. RNS directory entries and junction entries can contain their own XML messages as metadata. We define attribute expressions in XML for the RNS entries and give an algorithm to access distributed files stored within different kinds of Data Grids. The example in this paper shows how our Grid application can retrieve the actual locations of files from the RNS server. An application can also access the distributed files as though they were files in the local file system without worrying about the underlying Data Grids. This approach can be used in a Grid computing system to handle distributed Grid resources.	algorithm;directory (computing);grid computing;middleware;residue number system;sequence read archive;server (computing);xml	Yutaka Kawai;Go Iwai;Takashi Sasaki;Yoshiyuki Watase	2011	2011 11th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing	10.1109/CCGrid.2011.19	computer science;operating system;database;distributed computing;metadata;world wide web;distributed database	HPC	-31.730038943325415	50.25530821654601	193409
06c26bd39815d8e83b00111747afe76555b9268b	new dynamic load balancing for parallel modified prefixspan	databases;organisms;frequent pattern;dynamic load balancing;personal communication networks;neck;amino acid sequence;proteins;load management;process control;pc cluster;clustering algorithms;amino acids;load management amino acids databases educational institutions personal communication networks proteins organisms clustering algorithms neck process control;high speed	A motif that is a featured pattern is discovered from the frequent patterns in amino acid sequences. To extract frequent patterns at high speed, a parallel Modified PrefixSpan with a master-worker paradigm was proposed. However, a master-worker paradigm has a performance limitation when the number of PCs increases. To address this disadvantage, the distributed worker paradigm is adapted to the parallel Modified PrefixSpan. In order to obtain an effective speed-up ratio, we propose a new dynamic load balancing. The characteristics of dynamic load balancing are a smallgrain task and a Cache-based Random Steal schema. When a 100-scale PC cluster was used, the experimental results showed a speed-up ratio of 95 times.	computer cluster;load balancing (computing);motif;programming paradigm	Makoto Takaki;Keiichi Tamura;Toshihide Sutou;Hajime Kitakami	2005	21st International Conference on Data Engineering Workshops (ICDEW'05)	10.1109/ICDE.2005.248	organism;real-time computing;computer science;bioinformatics;process control;database;distributed computing;peptide sequence;cluster analysis	DB	-27.465382731692493	47.79698494486216	193508
95e9760b92a9acfc52a09560c546633c6922c207	guest editors' introduction: asynchronous middleware and services	distributed system;middleware synchronization clocks asynchronous transfer mode algorithm design and analysis operating systems costs concurrent computing wikipedia scalability;web based systems;asynchronous transfer mode atm networking middleware publish subscribe distributed systems web based systems;atm networks;publish subscribe;web based system;middleware;distributed systems;asynchronous transfer mode atm networking;asynchronous transfer mode	Asynchronous middleware is playing an increasingly important role in distributed and Web-based systems. This issue's theme articles address some research and engineering challenges that remain before this technology can fully make good on its promises.	middleware	Doug Lea;Steve Vinoski;Werner Vogels	2006	IEEE Internet Computing	10.1109/MIC.2006.9	middleware;real-time computing;computer science;asynchronous transfer mode;middleware;distributed computing;publish–subscribe pattern;computer network	DB	-30.447273315209095	47.05409973929198	193771
6b732adba412ffc46425958dc2a4ab20b4d55ff1	reengineering j2ee servers for automated management in distributed environments	distributed system;systems re engineering internet java software maintenance;automated distributed environment management;web based applications;dynamic reconfiguration;software maintenance;application server;software systems;jonas reengineering;internet users;internet;distributed environment;on demand deployment legacy j2ee application server reengineering automated distributed environment management java 2 enterprise edition software systems internet users web based applications jonas reengineering;legacy j2ee application server reengineering;internet services;service level agreement;jonasalacarte;jonasalacarte reengineering jonas dynamic reconfiguration;java 2 enterprise edition;reengineering;on demand deployment;environmental management web server application software java art availability middleware computer architecture load management software systems;jonas;java;open source;systems re engineering	Reengineering a legacy J2EE application server makes it easier to deploy and reconfigure, especially in distributed environments. Java 2 Enterprise Edition application servers are complex software systems, usually implemented as assemblies of wrapped legacy parts, with each part providing a particular service. In addition, owing to the increasing number of Internet users, application server providers must improve their servers' performance and availability. Consequently, J2EE application servers are generally deployed in distributed environments, such as clusters. J2EE server administrators generally adopt ad hoc and script-based tools for configuration and deployment, but these tools can introduce many errors during deployment and execution. Indeed, configuration and deployment are the main sources of failure in Internet services. Furthermore, for Web-based applications, ensuring continuous service for a certain service-level agreement regardless of external events is important and requires the hosting servers to support dynamic reconfiguration. Moreover, it should be possible to dynamically update the server's code. However, existing open source J2EE servers don't allow for such reconfigurations. In this paper, we demonstrate how a simple reengineering of JOnAS can address these deployment and dynamic-reconfiguration issues. We also describe a deployment system that offers on-demand deployment of distributed systems and allows for dynamic reconfigurations.	application server;code refactoring;computer cluster;distributed computing;hoc (programming language);internet;jonas;java platform, enterprise edition;java version history;open-source software;server (computing);service-level agreement;software deployment;software system;system deployment;web application;web service	Takoua Abdellatif;Jakub Kornas;Jean-Bernard Stefani	2007	IEEE Distributed Systems Online	10.1109/MDSO.2007.65	web application;the internet;business process reengineering;computer science;operating system;database;distributed computing;programming language;software maintenance;java;world wide web;computer security;application server;server;distributed computing environment;computer network;software system;server farm	OS	-32.46208662267782	48.617896155047916	194402
20a80637a464cd4de1574cb907cf3651a3283e18	a distributed analysis and monitoring framework for the compact muon solenoid experiment and a pedestrian simulation	distributed computing;thesis;cms;distributed analysis;grid computing;experiment dashboard	The design of a parallel and distributed computing system is a very complicated task. It requires a detailed understanding of the design issues and of the theoretical and practical aspects of their solutions. Firstly, this thesis discusses in detail the major concepts and components required to make parallel and distributed computing a reality. A multithreaded and distributed framework capable of analysing the simulation data produced by a pedestrian simulation software was developed. Secondly, this thesis discusses the origins and fundamentals of Grid computing and the motivations for its use in High Energy Physics. Access to the data produced by the Large Hadron Collider (LHC) has to be provided for more than five thousand scientists all over the world. Users who run analysis jobs on the Grid do not necessarily have expertise in Grid computing. Simple, userfriendly and reliable monitoring of the analysis jobs is one of the key components of the operations of the distributed analysis; reliable monitoring is one of the crucial components of the Worldwide LHC Computing Grid for providing the functionality and performance that is required by the LHC experiments. The CMS Dashboard Task Monitoring and the CMS Dashboard Job Summary monitoring applications were developed to serve the needs of the CMS community.	dashboard;distributed computing;experiment;grid computing;large hadron collider;parallel computing;simulation software;thread (computing);worldwide lhc computing grid	Edward Karavakis	2010			embedded system;simulation;engineering;world wide web	HPC	-29.686341011572416	51.39331601780605	194606
24d6a012d1d95f8af468378edf14f60d823c8cff	resource bound analysis for database queries	sdss skyserver astronomical database;time limit;legitimate user;arbitrary sql;database query;resource access control policy;space resource usage;simple core database query;pointless query;typical database management system;relational database;upper bound;databases;database management system;query languages	Many scientific disciplines, such as biology and astronomy, are now collecting large amounts of raw data systematically and storing it centrally in relational databases for shared use by their communities. In many cases such systems accept arbitrary SQL queries submitted using a Web form. Typical database management systems do not provide support for enforcing resource access control policies to guard against expensive or pointless queries submitted accidentally by legitimate users or intentionally by attackers. Instead, such systems typically employ timeouts to halt queries that do not terminate within a reasonable period of time. This approach can limit misuse but cannot prevent it; moreover, it does not provide useful feedback for legitimate users whose queries exceed the time limit.  In this paper, we study a language-based technique for bounding the time and space resource usage of database queries. We introduce a cost semantics for a simple core database query language, define a type-based analysis for estimating an upper bound on the asymptotic running time of a query, and prove its soundness. We also discuss a prototype implementation which we have used to analyze typical SQL queries submitted to the SDSS SkyServer astronomical database.	access control list;best, worst and average case;denial-of-service attack;feedback;form (html);halting problem;prototype;query language;relational database;sql;spatial decision support system;terminate (software);time complexity;timeout (computing)	James Cheney;Morten Dahl	2008		10.1145/1375696.1375706	computer science;software engineering;programming language	DB	-26.452261446092347	49.67882109910227	197128
7734dbea0d51208b67b22513d3032d342df1d092	synthesizing generic experimental environments for simulation	parallel computing;computational grid;internet clouds;distributed processing;distributed computing;xml representation;xml representation generic experimental environments simulation run parallel computing distributed computing simulacrum computing grid;simulacrum;parallel and distributed computing;simulation run;internet;execution environment;clouds;computing grid;reproducibility of results;xml;xml distributed processing parallel processing;parallel processing;random environment;generic experimental environments	Experiments play an important role in parallel and distributed computing. Simulation is a common experimental technique that relies on abstractions of the tested application and execution environment but offers reproducibility of results and fast exploration of numerous scenarios. This article focuses on setting up the experimental environment of a simulation run. First we analyze the requirements expressed by different research communities. As the existing tools of the literature are too specific, we then propose a more generic experimental environment synthesizer called Simulacrum. This tool allows its users to select a model of a currently deployed computing grid or generate a random environment. Then the user can extract a subset of it that fulfills his/her requirements. Finally the user can export the corresponding XML representation.	distributed computing;grid computing;parallel computing;requirement;simulation;xml	Martin Quinson;Laurent Bobelin;Frédéric Suter	2010	2010 International Conference on P2P, Parallel, Grid, Cloud and Internet Computing	10.1109/3PGCIC.2010.37	computer science;theoretical computer science;database;distributed computing	HPC	-29.49187594121355	50.68026203772129	197378
d4e7d78486325fa35723a7bc131762cd2432adf4	the research of soft component library based on cloud computing	libraries;protocols;software reusability cloud computing distributed processing information retrieval object oriented programming software libraries;software libraries;information retrieval;computer model;distributed processing;industries;object oriented programming;software reuse soft component library development cloud computing technology distributed cl system architecture model retrieval model component based software development;virtual resource pool cloud computing software reuse component library;component library;computer architecture;computational modeling;software reusability;virtual resource pool;retrieval model;libraries cloud computing computational modeling protocols computer architecture industries;software reuse;cloud computing	Aimed at the problems that have appeared in the component library (CL) development at present, this paper introduces a distributed CL system based on cloud computing technology. The architecture and retrieval model of this system are also introduced. It can nicely meet the need of component retrieval for component requester through many distributed component base.	cloud computing;component-based software engineering;library (computing)	Hongyan Zhao;Yingjun Zhang;Jiangfeng Liu	2011	2011 First International Conference on Robot, Vision and Signal Processing	10.1109/RVSP.2011.55	common component architecture;computer science;theoretical computer science;software engineering;database	Robotics	-31.96541116370209	49.079485790857554	197520
ddea64a749c6bb850e9afd982415d5bc1b501397	developing a distributed agent-based and des simulation using portico and repast	ieee standards;open source software distributed simulation hybrid simulation high level architecture hla evolved agent based modeling discrete event simulation repast portico;distributed processing;agent based modeling;public domain software;multi agent systems;distributed agent based simulation interface runtime infrastructure portico software ieee 1516 hla standard hla 1 3 repast toolkit emergency departments ambulance service agent based model exemplar case study emergency medical services source code accessibility cost free access open source software hla technology high level architecture technology discrete event simulation distributed hybrid agent based simulation computation capacity multiple processors distributed simulation large scale simulations high skilled modelers simulation techniques organizations complexity systems analysis simulation modeling des simulation;systems analysis;repast;hla evolved;distributed simulation;hybrid simulation;high level architecture;systems analysis discrete event simulation distributed processing ieee standards multi agent systems public domain software;computational modeling object oriented modeling data models hospitals java standards interoperability;portico;open source software;discrete event simulation	Simulation modeling is a significant tool for systems analysis that is being used in industry and services for several years. As the world becomes more connected, organizations complexity increases and traditional simulation techniques often are inadequate to represent modern problems. Moreover, simulation building requires high-skilled modelers and experimentation with large-scale simulations is highly computation intensive exercise. Distributed simulation, by enabling experimentation across multiple processors over a network or the cloud, has the potential to provide solution for the required computation capacity. Additionally, reusability of models is supported by enabling individual models to interoperate. In this paper we demonstrate the development of a distributed hybrid agent-based and discrete event simulation using high level architecture (HLA) technology. We implemented our project in open source software which has the advantage of cost-free access and source code accessibility. Using emergency medical services as exemplar case study, we developed an agent-based model of an ambulance service and several discrete event simulations of accident and emergency departments using Repast toolkit. The interface runtime infrastructure was developed in portico software. We tested the performance of the 1.3 and the Evolved version of the IEEE 1516 HLA standard. The yielded results show that the overall performance of both HLA versions is satisfying. However, interestingly, HLA 1.3 performs better on a single processor while HLA Evolved demonstrates better performance when executing in a network.	accessibility;agent-based model;central processing unit;computation;experiment;high-level architecture;interoperability;open-source software;repast (modeling toolkit);run-time infrastructure (simulation);simulation	Athar Nouman;Anastasia Anagnostou;Simon J. E. Taylor	2013	2013 IEEE/ACM 17th International Symposium on Distributed Simulation and Real Time Applications	10.1109/DS-RT.2013.18	real-time computing;simulation;computer science;distributed computing	Arch	-28.81405226465006	50.5898442856522	197951
9cac822f13e2c404c52e2e8931ede1e3b5561c19	wade: a web-based automated parallel cad environment	electrical capacitance tomography;information resources;standard interfaces;design automation;fault simulator;concurrent computing;fault simulation;resource allocation;pricing;hardware description languages;contracts;job submission;testing;scheduling tool;circuit cad wade web based parallel cad environment design applications test applications standard interfaces remote machine job submission scheduling tool load balance parallel machines placement tool fault simulator vhdl simulator world wide web;computer networks;circuit simulation;wade;internet;scheduling;test applications;vhdl simulator;cities and towns;local computation;world wide web;placement tool;parallel machines;remote machine;circuits;software tools;design automation concurrent computing contracts electrical capacitance tomography software tools pricing computer networks circuits cities and towns testing;load balance;circuit cad;design applications;web based parallel cad environment;hardware description languages information resources internet circuit cad parallel machines scheduling resource allocation circuit simulation	In this paper, we present a novel framework of a webbased automated parallel CAD environment. The goal of this project is to make available to the CAD community a growing number of design and test applications that support standard interfaces and execute efficiently in a parallel environment. The design files of a user working in a remote machine are transparently shipped to the local Compute Center, the relevant computation is performed in a parallel environment and then the results are returned back to the user. A job submission and scheduling tool ensures proper load balance and maximal usage of the various parallel machines. The whole process is done efficiently and transparently without the user having to bother about any low-level details. At present, a number of parallel CAD tools including a placement tool, a fault simulator and a VHDL simulator are supported. Results from a preliminary implementation are impressive and show the feasibility of the approach. This research was supported in part by the Semiconductor Res earch Corporation under Contract SRC 95-DP-109, the Advanced Res earch Projects Agency under contract DAA-H04-94-G-0273 adminis tered by the Army Research Office and the National Science Foundation under contract NSF MIP 93-20854.	computation;computer-aided design;electronic design automation;fault simulator;high- and low-level;ibm notes;load balancing (computing);maximal set;remote computer;scheduling (computing);semiconductor research corporation;simulation;vhdl;world wide web	Dhruva R. Chakrabarti;Pramod G. Joisha;John A. Chandy;Krishnaswamy Krishnaswamy;Venkatram Krishnaswamy;Prithviraj Banerjee	1998		10.1109/HIPC.1998.738024	pricing;embedded system;electronic circuit;parallel computing;real-time computing;the internet;simulation;concurrent computing;resource allocation;computer science;load balancing;operating system;distributed computing;software testing;hardware description language;programming language;scheduling	HPC	-29.604685414829497	48.952499280626384	198104
ffa3549dcd2c671b006413b5106f3be5c4c956cf	secure remote compiling services on the grid	grid services;remote compiling;scientific computing;grid computing;service provider;heterogeneous computing	Grid computing [1, 2] is an emerging technique in parallel computing for distributed resource sharing and problem solving on a global scale for data-intensive or computation-intensive applications. It focuses on dynamic and heterogeneous cooperation of “virtual organizations,” innovative applications, and high performance [3]. The participation of scientists and experts in multiple disciplines also permits the implementation of scientific tasks, such as analyzing raw data streams, performing large-scale computations, designing cutting-edge technological products, collaborating on interdisciplinary research, and implementing a complicated scientific computing process [4]. Abstract	compiler;computation;computational resource;computational science;data-intensive computing;executable;grid computing;makefile;parallel computing;problem solving;trust (emotion);unix;virtual organization (grid computing)	Yaohang Li;Daniel Tsu-Tang Chen;Xiaohong Yuan;Huiming Yu;Albert C. Esterline	2005			distributed computing;drmaa;streams;computer science;grid computing;raw data;symmetric multiprocessor system;utility computing;semantic grid;shared resource	HPC	-29.511879910559053	51.70164641487509	198919
59624b9027ef7b1e95fefc32699511d3fa5d80c1	national distributed high performance computing infrastructure for pl-grid users		"""The article describes the PL-Grid computing infrastructure built as a result of the first PL-Grid-based project """"Polish Infrastruc- ture for Supporting Computational Science in the European Research Space"""", then enlarged, upgraded and improved during the PLGrid Plus project. Five Polish supercomputing sites joined forces to create a cross- country integrated computing service for our scientists. These sites were Cyfronet in Krakow, ICM in Warsaw, PSNC in Poznan, TASK in Gdansk and WCSS in WrocPL-Grid Infrastructure enables Polish scientists carrying out scientific research based on the simulations and large-scale calculations using the computing clusters as well as it provides convenient access to distributed computing resources."""	polish grid infrastructure pl-grid	Pawel Dziekonski;Franciszek Klajn;Lukasz Flis;Patryk Lason;Marek Magrys;Andrzej Ozieblo;Radoslaw Rowicki;Marcin Stolarek;Dominik Bartkiewicz;Marek Zawadzki;Marcin Pospieszny;Rafal Mikolajczak;Maciej Brzezniak;Norbert Meyer;Marcin Samson	2014		10.1007/978-3-319-10894-0_2	human–computer interaction;engineering;software engineering;data mining	HPC	-29.009402904171434	51.81614102038125	198935
9d2df6bcb451ea2b556fa953d70a415cbd68861b	optimistic fault-tolerant approach for mobile agent in multi-region mobile agent computing environment	mobile agent;fault tolerant		mobile agent	MaengSoon Baik;InSung Kang;Chong-Sun Hwang;Yunhee Kang	2003			computer science;mobile agent;distributed computing;fault tolerance	AI	-29.369877102698805	46.62051976764722	199443
9fb2f2c39032b7494bce9dba992c3d7eac188e42	frontier sets in large terrains	large terrain environments;frontier sets;interest management;decentralized online games;visibility	In current online games, player positions are synchronized by means of continual broadcasts through the server. This solution is expensive, forcing any server to limit its number of clients. With a hybrid networking architecture, player synchronization can be distributed to the clients, bypassing the server bottleneck and decreasing latency as a result. Synchronization in a decentralized fashion is difficult as each player must communicate with every other player. The communication requirements can be reduced by computing and exploiting frontier sets: For a pair of players in an online game, their frontier sets consist of the region of the game space in which each player may move without seeing (and without communicating to) the other player. This paper describes the first fast and space-efficient method of computing frontier sets in large terrains.	computation;emoticon;graphics processing unit;memory footprint;requirement;server (computing)	Shachar Avni;James Stewart	2010			simulation;visibility;computer science;distributed computing;multimedia	HPC	-27.260322326693622	49.830197736580665	199559
