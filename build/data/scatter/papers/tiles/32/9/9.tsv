id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
d2c73a6979db69c15e129a6e26c5e17f5aa4117c	a web design framework for improved accessibility for people with disabilities (wdfad)	user interface;e commerce;web accessibility;blind;non functional requirement;requirements;information and communication technology;web design;people with disabilities;web design framework;world wide web;everyday life;web development	Information and Communication Technology (ICT) such as the World Wide Web (WWW) has increasingly become embedded in everyday life and is progressively becoming indispensable for public, business, personal efficiency or even improvement of livelihoods [1]. Web users including People with Disabilities (PWDs) can conveniently undertake a number of tasks that would otherwise be difficult or impossible. But many Web applications such as e-learning, e-commerce and e-government are not accessible to PWDs including the blind. Through Web accessibility guidelines, Web developers can develop Web applications that are accessible to PWDs. However, majority of the available accessibility guidelines are difficult to integrate into existing developer workflows and rarely offer specific suggestions that are developer oriented. In this paper, we propose a Web Design Framework for Improved Accessibility for People with Disabilities (WDFAD). The WDFAD provides precise guidelines on how to develop Web applications that are accessible to PWDs particularly the blind. These are packaged according to the three components of Web applications namely; content, navigation and user interface. Using constructs of the Non Functional Requirements (NFR) Framework, Web accessibility design objectives are represented as primary goals and sub goals. The primary goals represent the high level accessibility design objectives, while the sub goals represent the requirements that need to be met in the Web development process in order to meet each primary goal. WDFAD also illustrates the overlaps between the process of meeting each primary goal. This unveils the optimal ways of achieving Web accessibility during Web design. The precise nature of WDFAD and its packaging according to the main components of Web applications makes Web accessibility requirements potentially easier to understand and apply by Web developers. Web Developers prefer precise and familiar tools due to their busy work life and daily interface and expression in formal instructions. In addition, the global versus local classification of Web accessibility requirements in WDFAD modularizes the web accessibility guidelines hence making them easier to understand, apply and update.	e-commerce;e-government;embedded system;high-level programming language;non-functional requirement;user interface;www;web 2.0;web accessibility;web application;web design;web developer;web development;world wide web	Rehema Baguma;Jude T. Lubega	2008		10.1145/1368044.1368077	web service;web application security;web development;web modeling;web analytics;web design;web accessibility initiative;web standards;computer science;knowledge management;ws-policy;web navigation;social semantic web;web accessibility;multimedia;web intelligence;web engineering;web 2.0;world wide web	Web+IR	-51.826367021522465	-41.19991699794574	149914
4e2dd0075caf11c451b3fc8345a064f74b86814d	photos on the go: a mobile application case study	photo browsing;mobile;user study;mobile phone;mobile applications;photographs;photo sharing;user research;mobile application	We designed and iterated on a photo browsing application for high-end mobile phones. The application, Zurfer, supports viewing of photos from the user, their contacts, and the general user population. Photos are organized using a channel metaphor, driven by multiple dimensions: social, spatial and topical. Zurfer was deployed to over 500 users; extensive user research was conducted with nine participants. The data from the deployment and the study exposes general themes of mobile application use, as well as requirements for mobile applications in the photos domain, mobile social applications, and entertainment-driven mobile applications.	iteration;mobile app;mobile phone;requirement;software deployment;usb on-the-go;user research	Mor Naaman;Rahul Nair;Vlad Kaplun	2008		10.1145/1357054.1357326	mobile search;mobile web;human–computer interaction;gsm services;mobile database;computer science;operating system;mobile technology;multimedia;mobile computing;world wide web	HCI	-54.31202778026147	-39.984688776972284	150049
357af45f9e6271592ee2fe1985e7cfaa27acdc9a	leveraging card-based collaborative activities as culturally situated design tools		This paper describes two examples of virtual card games serving as Culturally Situated Design Tools (CSDTs) for young people. CSDTs have promise in helping people to learn by connecting principles from computing with aspects of their heritage or gender. The development and deployment of card games on two cutting-edge platforms (mobile devices and multitouch tables) revealed novel ways to display information to users and important lessons for deploying them to young people.	mobile device;multi-touch;situated;software deployment	D. Scott McCrickard;DeMarcus Townsend;Woodrow W. Winchester;Tiffany Barnes	2011		10.1007/978-3-642-22098-2_47	human–computer interaction;knowledge management	HCI	-55.43779519963725	-38.321885674445504	150758
2683e5f5c3573e1accaf3009b7da5a0d76510d17	staging transformations for multimodal web interaction management	multimodal interface;mobile device;selected works;mixed initiative;program transformation;mixed initiative interaction;partial evaluation;interactive media;web dialogs;software framework;bepress;program transformations;out of turn interaction	Multimodal interfaces are becoming increasingly ubiquitous with the advent of mobile devices, accessibility considerations, and novel software technologies that combine diverse interaction media. In addition to improving access and delivery capabilities, such interfaces enable flexible and personalized dialogs with websites, much like a conversation between humans. In this paper, we present a software framework for multimodal web interaction management that supports mixed-initiative dialogs between users and websites. A mixed-initiative dialog is one where the user and the website take turns changing the flow of interaction. The framework supports the functional specification and realization of such dialogs using staging transformations -- a theory for representing and reasoning about dialogs based on partial input. It supports multiple interaction interfaces, and offers sessioning, caching, and co-ordination functions through the use of an interaction manager. Two case studies are presented to illustrate the promise of this approach.	accessibility;disk staging;functional specification;mobile device;multimodal interaction;personalization;software framework;dialog	Michael Narayan;Christopher Williams;Saverio Perugini;Naren Ramakrishnan	2004		10.1145/988672.988702	human–computer interaction;computer science;software framework;mobile device;database;multimedia;interactive media;programming language;world wide web;partial evaluation	Web+IR	-52.346765363896694	-39.109560847070824	151068
43f0e92093b06b17b3c3c5a38807a3d45e240e4c	touch and #tag: improving clothing experiences of people with visual impairment	user centered design;blindness;clothing labels;visual impairment	For people with visual impairment, many daily chores are burdensome and time-consuming. After discussions, we set a goal of improving clothing experiences of the visually impaired. After researches and interviews, we noticed that the visually impaired have to face many troubles when dealing with chores about clothes, which include doing laundry, shopping for new garments, and searching for what to wear every morning. In addition, we also realized that visually impaired people can take good care of themselves and their clothes, all they need is an easy approach to recognize their clothes. Accordingly, to achieve our goal, we designed a complete clothing label system along with some related products. The key design of our system is the tactile clothing labels, which can be either made by users or provided by clothing stores. With the labels, users can easily gain information of each article of clothing by themselves, making many tasks about clothes be done more efficiently.	chi;care-of address;tactile graphic	Ting-Ying Hsu;Zong-Yu Li;Hung-Yeh Lin;Yu-Han Liou;Chia-Ling Tsai	2016		10.1145/2851581.2890636	user-centered design;simulation;human–computer interaction;computer science;multimedia	HCI	-51.811403758238725	-42.496408416826945	151314
6ca9b291f02edd9096a256b97635dabae0ed31dc	vibrotactile tv for immersive experience	media studies;interaktionsteknik;signalbehandling;interaction technologies;datorsystem;computer systems;datoriserad bildanalys;media;haptic interfaces decision support systems media abstracts tv films multimedia communication;audio video signal vibrotactile tv immersive experience mobile devices immersive engagement emotional information augmented vibrotactile coding haptic enhancement multisensory approach;abstracts;signal processing;multimedia communication;decision support systems;manniska dator interaktion;medievetenskap;computerized image analysis;tv;haptic interfaces;telekommunikation;films;telecommunications	Audio and video are two powerful media forms to shorten the distance between audience/viewer and actors or players in the TV and films. The recent research shows that today people are using more and more multimedia contents on mobile devices, such as tablets and smartphones. Therefore, an important question emerges - how can we render high-quality, personal immersive experiences to consumers on these systems? To give audience an immersive engagement that differs from `watching a play', we have designed a study to render complete immersive media which include the `emotional information' based on augmented vibrotactile-coding on the back of the user along with audio-video signal. The reported emotional responses to videos viewed with and without haptic enhancement, show that participants exhibited an increased emotional response to media with haptic enhancement. Overall, these studies suggest that the effectiveness of our approach and using a multisensory approach increase immersion and user satisfaction.	edge enhancement;experience;haptic technology;immersion (virtual reality);mobile device;smartphone;tv tuner card;tablet computer	Shafiq ur Réhman;Muhammad Sikandar Lal Khan;Liu Li;Haibo Li	2014	Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific	10.1109/APSIPA.2014.7041631	simulation;human–computer interaction;computer science;multimedia	HCI	-51.445904972159056	-43.408823125514466	151733
d96f31cc92dd7800f42192f46c908fac3c338d43	"""""""hold my hand, baby"""": understanding engagement through the illusion of touch between human and agent"""	engagement;hci;illusion of touch;embodied agents;large display	This paper explores the quality of engagement between human and agent in large displays. We designed a musical application and introduced the illusion of touch as a novel interaction concept where the user and the agent interact through mediated virtual touch. We conducted a lab study to better understand the users' behaviors and engagement with our system. Our main findings from the design exploration are: 1) users are engaged in the interaction with an interactive agent even though the agent is not perceived as engaged by the user; 2) users are more involved in the experience when the agent is interactive; and 3) the agent's gaze is effective in grabbing the user's attention. These findings provide initial insights on designing for engagement in displays that make use of embodied agents and should be validated with a field study.	embodied agent;field research	David Jan Mercado;Gilles Bailly;Catherine Pelachaud	2016		10.1145/2851581.2892463	human–computer interaction;embodied agent;computer science;multimedia	HCI	-54.22085709817828	-44.23538348581925	152935
138d7b1c26ac72124350b1cecb1fb10eb03bacb1	guest editorial introduction to the special issue on biometric interfaces between ambient intelligence and augmented cognition	ambient intelligence	Ambient intelligence integrates computational intelligence into ubiquitous/pervasive computing environments and artifacts. Computers become embedded in our natural surroundings. They move to the background to better provide smart services to humans who perform into the foreground. The humans are helped by simple and effortless interactions, with computers attuned to all their senses, adaptive to their profile and context-sensitive, autonomic and last but not least secure and trustworthy. High-quality computing, communication and quality of service (QOS) access and personalized content must be available to everybody not only at anyplace, anytime, but even more importantly, at the right place, right time and by the right means. This fundamental view changes drastically the development of new technologies, focusing on bringing ‘‘digital intelligence’’ to future electronics products. The objective is to create and deliver new technologies that are more intuitive, intelligent and ‘‘human,’’ in order to allow the delivery of products that are easier to use and thus more helpful for people. Human authentication in ambient intelligence should preferably not be bound to voluntary or conscious user’s interactions with recognition equipment, but rather it should rely on the ability of an underlying control system to automatically and autonomously capture user’s characteristics and use them for identification, verification, and/or surveillance. Biometrics involves the automated authentication from personal physical appearance or behavioral traits. It further provides the needed context and personalization to interface and mediate between ambient intelligence and augmented cognition. Biometrics makes use of different sensory mechanisms to assess both identity and physiological (physical and cognitive) state. Augmented cognition extends users’ abilities in order to improve their performance and to provide for graceful degradation. Augmented cognition can parse both covert and overt communication, and it supports context switching. Augmented cognition provides the upper management layer needed to (a) make appropriate choices for bandwidth, context, and specific functionality; (b) adapt, prioritize and coordinate; (c) reduce the effects of cross-talk (‘‘modal’’) interference; and (d) handle in a flexible way time-varying inputs. Note that both the computer and the human subject have their ‘‘cognitive’’ abilities augmented to enhance their performance. Towards that end, one needs closed-loop control and reliable biometric interfaces, which are aware of subjects’ abilities, behaviors, emotions, intensions, and/ or immediate needs and responds accordingly. There is feedback, the biometric interface is adaptive, and anticipation is driven by predictions. Both context and the subjects’ (mental and physical states) models are attended to or inferred to leverage the connections between personal appearance, cognitive state, and behavior, in order to deliver smart services and logistic support. Though there has recently been a great deal of progress in biometrics, their use as interfaces between ambient intelligence and augmented cognition still lags behind. There is, however, a growing need to determine in a robust fashion both the physical and cognitive state of human subjects. This need is due, among other, to an aging population that requires health care management, intelligent infrastructures to alleviate cognitive overload, e.g., air traffic control and intelligent highways, education and training, and social networks. Towards that end, biometrics can assess among others awareness (vs. confusion), involvement and interest, understanding, and inner feelings and emotions, e.g., such as satisfaction. M. Nappi (u0026) H. Wechsler Fisciano, Italy e-mail: mnappi@unisa.it	ambient intelligence;augmented cognition;biometrics	Michele Nappi;Harry Wechsler	2011	J. Ambient Intelligence and Humanized Computing	10.1007/s12652-010-0036-9	ambient intelligence;human–computer interaction;computer science;artificial intelligence;multimedia	AI	-53.358711141702834	-43.76925250216079	153818
49a408065fcf33532bcce30a90d2a2cd0c055186	user configuration of activity awareness	user configuration;activity awareness;qa75 electronic computers computer science;configuration;ubiquitous systems	This paper describes an approach to user configura t on of activity awareness. This approach offers users increased fl exibility by allowing the use of multiple methods of configuration to be used wit hin a unified framework; these configuration methods can include context, po licy rules and automatic techniques of configuring behaviour. In this paper w describe the benefits of this flexibility and discuss a model of configurati on that can be used to support these features.	unified framework	Tony McBryan;Philip D. Gray	2009		10.1007/978-3-642-02481-8_113	configuration management database;human–computer interaction;computer science;knowledge management;configuration item;configuration	HCI	-52.93467067864747	-38.34643797292694	153952
f811f1de710f06c7cdd60a3ef0d7ac1adecc5513	aging users are still users	ambient assisted living;ageing users;hci	Today’s tech-savvy boomers will remain comfortable with technology as they age, though they may need different interfaces. They need help with evaluating technical resources, but they will continue to adapt, tailor, configure, and program those resources. They need assistants, not supervisors”.	technical support	Mary Shaw	2007			multimedia;human–computer interaction;business	HCI	-52.127619797967164	-39.92175703229712	153974
434085abcfb5bccc751cb1f788bed7032790b9a0	accessibility for people who are blind in public transportation systems	mobility;blind people;accessibility;transportation in the city	In order to support access for people who are blind to modes of transportation in the city, it is necessary to design technological tools that allow them to carry out activities safely, autonomously, and functionally. In this context, three mobile orientation and mobility support systems were designed for people who are blind to aid in their effective navigation using various modes of transportation in the city of Santiago, Chile. This work presents the most significant implications of the use of these systems.	accessibility	Jaime Sánchez;Márcia de Borba Campos;Matías Espinoza;Lotfi B. Merabet	2013		10.1145/2494091.2496002	simulation;computer science;accessibility;operating system;mobile computing	HCI	-50.28726744560382	-41.66778525152506	154714
77fa0faa10da32e42d558c8f84889aa1b68632f2	computer aids for participation in housing design		This paper describes two computer programs developed to promote design participation among future building users. The software developed allows the user to create his future housing layout by assembling symbols on a computer terminal screen and be constantly guided and apprised of the environmental, spatial, locational and legislative consequences of his design decisions.		J. R. Coleman	1973	Computer-Aided Design	10.1016/0010-4485(73)90071-7	human–computer interaction;engineering	EDA	-55.50217803650339	-38.46798674722677	154938
85970b24df92ec1100b89b7e3a667e777adc1a13	interactive sight demo: textual summaries of simple bar charts	information graphics;accessibility;natural language;visual impairments;visual impairment;graphic design;point interaction	Interactive SIGHT is a system that is intended to provide people with visual impairments access to the kind of information graphics found in popular media (i.e., electronic newspapers or magazines). The majority of such graphics are intended to convey a message; the graphic designer chose the graphic and its design in order to make a point. Interactive SIGHT, which is implemented as a browser extension that works on simple bar charts, provides a brief high-level summary of the graphic through natural language text that is conveyed to the user as speech. The user may request further information about the graphic through a follow-up question facility which allows many follow-up responses to be generated. The demo will illustrate the system's methodology on several bar charts that have been preloaded along with some accompanying text.	browser extension;chart;graphics;high- and low-level;infographic;interactivity;natural language	Seniz Demir;David Oliver;Edward Schwartz;Stephanie Elzer Schwartz;Sandra Carberry;Kathleen F. McCoy	2010		10.1145/1878803.1878864	graphic design;human–computer interaction;computer science;accessibility;graphic communication;linguistics;multimedia;natural language;infographic;world wide web;computer graphics (images)	HCI	-48.85784390191613	-39.57337970329046	155005
7ed3a7aa0dc902c61df74bc6434852e3e5c2a04b	how blind people can manage a remote control system: a case study		Remote Control Systems (RCSs) are increasingly being installed in homes and offices. Technology evolves very rapidly and sensors and devices are becoming smaller, smarter and more powerful. Mobile and Web apps are commonly used to remotely configure and control devices. Home control is especially valuable for blind people, since they can benefit from technology to control and turn on/off devices autonomously. Remote control can offer meaningful support, especially when devices are not directly accessible (e.g., thermostat to manage heating temperature). Therefore, if RCS interfaces are not accessible via screen reader, blind users may miss a great opportunity to achieve greater autonomy at home. This paper investigates the accessibility of the web user interfaces offered by RCSs for blind people. To do this, the Fibaro, a popular Remote Control System, was tested as a case study by analyzing the interaction via screen reader. Results indicate that accessibility and especially usability need to be improved to make interaction easier and more satisfying for blind people. To this aim, some suggestions are offered to aid developers in designing more accessible RCS user interfaces.	control system	Marina Buzzi;Francesco Gennai;Barbara Leporini	2017		10.1007/978-3-319-76111-4_8	thermostat;home automation;human–computer interaction;web application;autonomy;screen reader;usability;user interface;remote control;computer science	HCI	-50.159630863959165	-41.569596815907005	155023
249904f0d566c299835ab539fbb879977c87b326	context-centric design of automotive human-machine interfaces		Automotive human-machine interfaces are increasingly relying on situation awareness and context processing in order to improve the safety and user experience. Instead of introducing highly specialized and separated systems, which rely on specific human-machine interfaces tightly connected to the necessary context processing capabilities, this work suggests a bottom-up context-centric approach, designing the entire human-machine interaction around a well-defined context-processing service. In the first step, the context-centric interface design and all its components are defined. In the second step, several challenges necessary for successful implementation of the design are identified and dealt with. The biggest challenge is the size and the complexity of the knowledge model, containing all the context-relevant data. In addition, a software platform which implements all the necessary context processing services is proposed. Two innovative human-machine interfaces and a driving simulator are used to assess the approach. The ability to collect the context-relevant data through the human-machine interface is demonstrated, together with the ability to optimize the context-relevant queries placed by the human-machine interface and driver assistance applications.	bottom-up proteomics;driving simulator;human–computer interaction;knowledge representation and reasoning;simulation;user experience;user interface	Ljubo Mercep	2014			human–machine system;human–computer interaction;user experience design;automotive industry;situation awareness;systems engineering;engineering	HCI	-51.296424031573956	-38.69188793431651	155103
8dcc00741e7c14924f58df8d4775369f0c60322b	introducing adele: a personalized intelligent companion		This paper introduces ADELE, a Personalized Intelligent Compan- ion designed to engage with users through spoken dialog to help them explore topics of interest. The system will maintain a user model of information consumption habits and preferences in order to (1) personalize the user’s experience for ongoing interactions, and (2) build the user-machine relationship to model that of a friendly companion. The paper details the overall research goal, existing progress, the current focus, and the long term plan for the project.	interaction;personalization;user modeling;dialog	Brendan Spillane;Emer Gilmartin;Christian Saam;Ketong Su;Benjamin R. Cowan;Séamus Lawless;Vincent P. Wade	2017		10.1145/3139491.3139492	personalization;user modeling;multimedia;dialog box;computer science	AI	-54.096249352345936	-38.31976928735317	158128
873af821e379a44169f31af8ad48e054a999949c	#scanners 2 - the moment: a new brain-controlled movie		While many still consider interactive movies an unrealistic idea, current delivery platforms like Netflix, commercial VR, and the proliferation of wearable sensors mean that adaptive and responsive entertainment experiences are an immediate reality. Our prior work demonstrated a brain-responsive movie that showed different views of scenes depending on levels of attention and meditation produced by a commercialized home-entertainment brain sensor. Based on lessons learned, this demonstration exhibits the new interactions designed for our new brain-controlled movie, The MOMENT, being released in 2018.	interaction;sensor;wearable computer	Richard Ramchurn;Max L. Wilson;Sarah Martindale;Steve Benford	2018		10.1145/3170427.3186481	wearable computer;human–computer interaction;multimedia;entertainment;computer science	HCI	-53.320475636295605	-43.85503800564217	158940
dc7a79ade31b9ecd98f17f2cdaab1d4e9809b42b	cricking: customer-product interaction in retail using pervasive technologies	location;user modeling;rfid;cricking;human product interaction	The popularization of eCommerce has led to effective customer shopping experiences. Pervasive computing could bring the benefits of eCommerce to brick and mortar stores, merging both online and physical worlds into a unique system. We define crick as the extension of the (c)lick and b(rick) concept, by means of pervasive technologies. In this paper, we summarize our work-in-progress research on using pervasive Radio Frequency Identification (RFID) to sense human-product interaction. These cricks can be performed through diverse interfaces in the retail domain, and automatically receive feedback in different manners. We believe that integrating RFID and other pervasive technologies in retail stores is the next step to obtain comprehensive customer's user models and preferences. Retail management improvement, or personal and collaborative recommendations, are envisioned to be successful applications of cricking.	e-commerce;mortar methods;pervasive informatics;radio frequency;radio-frequency identification;ubiquitous computing	Rafael Pous;Joan Melià-Seguí;Anna Carreras;Marc Morenza-Cinos;Zulqarnain Rashid	2013		10.1145/2494091.2496015	radio-frequency identification;embedded system;user modeling;human–computer interaction;computer science;operating system;location;world wide web;computer security	HCI	-52.338034495046124	-40.75642943907789	160360
b1605bcfa0a136cb1a48214372948c9c2f9f3b35	multimodal input for computer access and augmentative communication	computer access;multimodal input;augmentative and alternative communication;research methodology;assistive technology;speech recognition;text generation;head pointing	This paper describes the overall goals of a project that focuses on multimodal input for computer access and Augmentative and Alternative Communication (AAC) systems. In particular the project explores the integration of speech recognition with headpointing. The first part of this project addresses the use of speech and head-pointing to replace the traditional keyboard and mouse. While either of these technologies can emulate both keyboard and mouse functions, it is hypothesized that the most advantageous use of each technology will come from integration such that each device's strength is utilized appropriately. To test this hypothesis, a series of experiments are planned. The first experiment compares (quantitatively and qualitatively) each technology in the context of text generation. The second experiment looks at typical pointing tasks (e.g., dragging) for each technology. The third experiment will look at the technologies in an integrated context. Because each of the technologies are themselves highly complex, significant time and effort has been devoted to pilot testing. Those results and the implications on our research methodology are presented in this paper.	advanced audio coding;drag and drop;experiment;game controller;multimodal interaction;natural language generation;norm (social);speech recognition	Alice Smith;John Dunaway;Patrick W. Demasco;Denise Peischl	1996		10.1145/228347.228361	natural language processing;speech recognition;computer science;methodology	HCI	-48.66307265761392	-44.934252995414596	161037
1735a6b47e3f05ff5b586e4b63fdbfc3607e81f0	design for outdoor mobile multimedia : representation, content and interactivity for mobile tourist guides	g000 computing and mathematical sciences		interactivity	Heloisa Candello	2012			mobile search;simulation;human–computer interaction;computer science;multimedia	HCI	-54.83520424641682	-38.488336905845024	161491
69f10068ff10d3b330fdf7ecccba0cb09f6c7e8a	after dialog went pervasive: separating dialog behavior modeling and task modeling	task modeling;short user response;telephone-based interactive response system;dialog system;users access information;information retrieval system;companies money;bus information;system initiative;us-based user;flat slot-filling model;dialog behavior modeling	Dialog Goes Pervasive Until recently, many dialog systems were information retrieval systems. For example, using a telephone-based interactive response system a US-based user can find flights from United (1-800-UNITED-1), get movie schedules (1-800777-FILM), or get bus information (Black et al., 2011). These systems save companies money and help users access information 24/7. However, the interaction between user and system is tightly constrained. For the most part, each system only deals with one domain, so the task models are typically flat slot-filling models (Allen et al., 2001b). Also, the dialogs are very structured, with system initiative and short user responses, giving limited scope to study important phenomena such as coreference. Smart phones and other mobile devices make possible pervasive human-computer spoken dialog. For example, the Vlingo system lets users do web searches (information retrieval), but also connects calls, opens other apps, and permits voice dictation of emails or social media updates1. Siri can also help users make reservations and schedule meetings2. These new dialog systems are different from traditional ones in several ways; they are multi-task, asynchronous, can involve rich context modeling, and have side effects in the “real world”: Multi-task – The system interacts with the user to accomplish a series of (possibly related) tasks. For example, a user might use the system to order a book and then say schedule it for book club a different task (e.g. requiring different backend DB lookups) but related to the previous one by the book informa-	behavior model;ccir system a;computer multitasking;dialog system;email;information retrieval;mobile device;mobile phone;siri;social media;vlingo	Amanda Stent	2012			natural language processing;simulation;speech recognition;computer science;machine learning;dialog system;world wide web	NLP	-54.33249794873895	-41.23587303683065	161910
90f56863606d2d0742bcee8d68563b6c9c517a5b	responsive task modelling	task modelling;touch based devices;responsive design	In this paper we present a new tool for specifying task models (Responsive CTT), which can be accessed through touch-based mobile devices such as smartphones and tablets as well. The tool is Web-based and responsive in order to provide adapted user interfaces to better support the most common activities in task modelling through various types of devices. We describe the relevant aspects to take into account for this purpose and how we have addressed them in designing the tool. We also report on first user tests.	mobile device;responsive web design;smartphone;tablet computer;user interface	Davide Anzalone;Marco Manca;Fabio Paternò;Carmen Santoro	2015		10.1145/2774225.2775079	simulation;computer hardware;computer science;multimedia	HCI	-51.51272695459741	-38.7348676567492	162571
9fcc0ac88e9aa82f5c42bedf76ad141f7bfa7389	a comparative study to evaluate the usability of context-based wi-fi access mechanisms		This paper presents a comparative study of six di erent tag and context based authentication schemes for open Wi-Fi access. All of the implemented methods require only a smartphone and an HTML5 capable webbrowser, making them interchangeable and easy to incorporate into existing infrastructure. We recruited 22 participants for the study and used two standardized questionnaires as well as additional metrics to assess whether further investment in a systematic usability analysis seems prudent. The evaluation shows that suitable alternatives for Wi-Fi authentication exist and points out their limitations and opportunities.	authentication;html;html5;klaus samelson;login;multimodal interaction;operating system;requirement;smartphone;usability	Matthias Budde;Till Riedel;Marcel Köpke;Matthias Berning;Michael Beigl	2014		10.1007/978-3-319-07446-7_44	usability lab;usability;usability inspection;user experience design;usability engineering;usability goals;computer security;authentication;computer science;html5	HCI	-49.04000631062312	-44.134780509043736	162623
2c39d0960350a44b63553f91b695276edf2becd5	expressing through digital photographs: an assistive tool for persons with aphasia	language comprehension;social isolation;aphasia;inclusive design;digital photographs;swinburne;storytelling;proxy based design;sharing experiences;brain injury	This paper describes the design of an assistive tool called CoCreation that can help people with aphasia to express daily experiences by utilizing digital photographs. CoCreation can upload the user’s pictures and can cluster them as a function of the time at which the pictures were taken. Pictures taken within a short period of time are assumed to highlight a single activity. The user is able to select a cluster and can edit the pictures by dragging icons or drawing on top of them, or by typing words to create a caption. The pictures set the context for a story, while the additional tools such as keyboard and drawing pad allow the user to add information that is considered useful for sharing the experience. The paper presents the detailed design process and the preliminary evaluation of CoCreation with an experienced speech therapist.	assistive technology;computer keyboard;drag and drop;experience;image;upload	Abdullah Al Mahmud;Yvonne Limpens;Jean-Bernard Martens	2012	Universal Access in the Information Society	10.1007/s10209-012-0286-8	simulation;universal design;human–computer interaction;computer science;multimedia;world wide web	HCI	-48.80388508003447	-39.84331099829434	162655
33a3abc3aa1828ee89f614613098275be201c421	steeringwheel: a locality-preserving magnification interface for low vision web browsing	accessibility;h.5.2. information interfaces and presentation: user interfaces-input devices and strategies;k.4.2. computers and society: social issues-assistive technologies for persons with disabilities;locality;low-vision;magnifier;user-interface;visual impairments;web-browsing	Low-vision users struggle to browse the web with screen magnifiers. Firstly, magnifiers occlude significant portions of the webpage, thereby making it cumbersome to get the webpage overview and quickly locate the desired content. Further, magnification causes loss of spatial locality and visual cues that commonly define semantic relationships in the page; reconstructing semantic relationships exclusively from narrow views dramatically increases the cognitive burden on the users. Secondly, low-vision users have widely varying needs requiring a range of interface customizations for different page sections; dynamic customization in extant magnifiers is disruptive to users' browsing. We present SteeringWheel, a magnification interface that leverages content semantics to preserve local context. In combination with a physical dial, supporting simple rotate and press gestures, users can quickly navigate different webpage sections, easily locate desired content, get a quick overview, and seamlessly customize the interface. A user study with 15 low-vision participants showed that their web-browsing efficiency improved by at least 20 percent with SteeringWheel compared to extant screen magnifiers.	browsing;customize;dial device component;interface device component;locality of reference;low sodium diet;principle of locality;usability testing;web navigation;web page	Syed Masum Billah;Vikas Ashok;Donald E. Porter;I. V. Ramakrishnan	2018	Proceedings of the SIGCHI conference on human factors in computing systems. CHI Conference	10.1145/3173574.3173594	magnification;web page;multimedia;personalization;locality;semantics;gesture;web navigation;computer science;user interface	HCI	-48.43766224656031	-41.88686844736768	163688
1e95f902ab5c998d5529b17acba4f690a6731637	multimedia for primary school children learning sign language	primary school;sign language;interaction;primary school children;multimedia application;user preferences;children;user testing	This research explores the design, development and user testing of a purpose built multimedia resource to assist hearing children in Primary school to learn Australian Sign Language (Auslan). The multimedia application consists of vocabulary instruction, a story, song, game and a series of questions. Children's preferences for characters and activities are investigated as are their opinion on the most appropriate number of signs per session and their enjoyment of learning Auslan in a multimedia environment.	user research;vocabulary	Kirsten Ellis	2009		10.1145/1738826.1738843	interaction;sign language;computer science;multimedia	Web+IR	-51.16480511038622	-43.841475957054655	163779
ad5964c9c6d986fb589e589ff07d785cd0061fa0	marker-based image recognition of dynamic content for the visually impaired	mobile;situational disability;accessibility;visually impaired	The access to information displayed in public spaces is a challenge faced by visually impaired people for which image processing techniques have the potential to deliver satisfactory solutions. However, object recognition algorithms must initially locate possible candidates in the images, which is a hard task in complex scenes. In this article, we introduce an image processing technique that relies on the incorporation of markers to panels and boards with fixed layouts displaying dynamic content. The markers allow: a) locating the objects to be recognized; b) correcting perspective in the input images; c) limiting the training set size for supervised learning; and d) guiding the visually impaired by indicating how they should position their devices for adequate pictures. The proposed technique can be used for automatic recognition of texts and images and is suitable for deployment on mobile devices, providing more independence to the citizens. Results of preliminary tests on vending machines show that this method is robust enough to be used in practice.	algorithm;computer vision;dynamic web page;emoticon;freedom of information laws by country;image processing;mobile device;outline of object recognition;software deployment;supervised learning;test set	Andréa Britto Mattos;Carlos H. Cardonha;Diego Gallo;Priscilla Avegliano;Ricardo Herrmann;Sergio Borger	2014		10.1145/2596695.2596707	computer vision;computer science;multimedia;communication	HCI	-49.57842789835876	-42.72996463754277	163984
fc1a448020ed68150770e914a8c07f8b7ae4a893	base of short answers	php language short answers base of short answers base of short questions closed learning system mobile phones free telephone number;human computer interaction;computer aided instruction;mobile handsets computer applications educational institutions testing computers informatics mobile communication;user interfaces computer aided instruction human computer interaction mobile computing;mobile computing;user interfaces	Base of short answers is a base of short questions (ussusaly one word) with a base of short answers (all together 160 characters). In this project I created a closed system of learning, apropriate for an school (pupils in the beginning create questions and answers, and after that use the base of short questions and short answers for learning on mobile phones and for testing in crosswords.) To avoid the monolitic view of the base on the screen I created several altenate systems for learning: free telephone number and softweare for crosswords. Al the systems are created in my technologies and tools, based on PHP language.	closed system;crossword;google questions and answers;in the beginning... was the command line;mobile phone;php;telephone number	Marino Jurinovic	2012	2012 Proceedings of the 35th International Convention MIPRO		simulation;human–computer interaction;computer science;operating system;multimedia;user interface;mobile computing	DB	-49.77367103728455	-42.948248834493135	164354
97244c3c50f425bf050613dc4ad787d61bfe3729	cai system with multi-media text through web browser for nc lathe programming	cai;nc lathe programming;multi-media;web browser;cmi	A new Computer Aided Instruction (CAI) system for NC lathe programming has been developed with use of multi-media texts including movies, animations, pictures, sound and texts through Web browser. Although many CAI systems developed previously for NC programming consist of text-based instructions, it is difficult for beginners to learn NC programming with use of them. In the developed CAI system, multi-media texts are adopted for the help of users’ understanding, and it is available through Web browser anytime and anywhere. Also the error log is automatically recorded for the future references. According to the NC programming coded by a user, the movement of the NC lathe is animated and shown in the monitor screen in front of the user. If its movement causes the collision between a cutting tool and the lathe, some sound and the caution remark are generated. If the user makes mistakes some times at a certain stage in learning NC, the corresponding suggestion is shown in the form of movies, animations, and so forth. By using the multimedia texts, users’ attention is kept concentrated during a training course. In this paper, the configuration of the CAI system is explained and the actual procedures for users to learn the NC programming are also explained too. Some beginners tested this CAI system and their results are illustrated and discussed from the viewpoint of the efficiency and usefulness of this CAI system. A brief conclusion is also mentioned.		Yoshio Mizugaki;Koichi Kikkawa;Masahiko Mizui;Keisuke Kamijo	2002		10.1007/0-387-23572-2_38	computer science;multimedia;client-side scripting;engineering drawing;computer graphics (images)	Web+IR	-48.6044195206216	-43.18458395807925	164355
c4bf9d015df05e32e88bc6e16fb5671c20591be4	advances in the study of hand gesture recognition systems for human computer interaction		Getting three-dimensional pose and orientation of parts of the body observed by one or more cameras is of great theoretical interest and widely applicable. Usually, computing devices interaction is accomplished by means of a mouse and a keyboard or by touching the screen, but otherwise, human beings relate to their surrounding world using hands, body, and voice in most of their daily activities, therefore, development of more natural and intuitive techniques for interacting with a variety of user interfaces is critical. In this paper, a review of recent research efforts in Human Computer Interaction (HCI), specifically in hand gesture recognition, is performed, analyzing the state-of-the-art methodology and discussing some important issues about.	computer mouse;gesture recognition;human computer;human–computer interaction;user interface	P. Rodrigo Díaz-Monterrosas;Rubén Posada-Gómez;Albino Martínez-Sibaja	2015	Research in Computing Science		computer vision;speech recognition;gesture recognition;communication;sketch recognition	HCI	-48.84050652739797	-42.40719928014938	164524
9f5e5272d9f76d0dbe98c2be3e4e19faf9d4b329	increasing user engagement with distributed public displays through the awareness of peer interactions	user engagement;media technology;human computer interaction;longitudinal study;technology enhanced learning;manniska datorinteraktion interaktionsdesign;medieteknik;public displays;video installation;social awareness;datavetenskap;computer science;experimentation;diary study;mobile interaction	Recent developments have shown a growing interest in interactive pervasive computing scenarios supported by public displays as well as their introduction into educational environments. Still, one of the biggest challenges in the design of public display systems is to engage users to interact and be motivated to do so. In this paper, we report a study exploring the potential effect of the awareness of peers' interactions with an educational video installation and the popularity of the display system on the user engagement. The awareness is facilitated by pop-up notifications and visualizations of interactions on the display screen. We conducted a six day long deployment of our system which included a diary study, during which we altered the display's dynamic behavior in order to test different conditions. The analysis of the diary reports and the progression of the users' interactions showed that the users found the presentations of peer interactions to be engaging, both with the display system as well as the social context around it.	color gradient;diary studies;experiment;interaction;interactivity;music visualization;simulation;software deployment;the pot calling the kettle black;ubiquitous computing	Maximilian Müller;Nuno Otero;Aris Alissandrakis;Marcelo Milrad	2015		10.1145/2757710.2757740	simulation;human–computer interaction;engineering;multimedia	HCI	-54.76184815931544	-42.59255537827757	164762
de92528a47d2ec0a6c878913f9368e2444032c6d	novel devices and interaction concepts for fluid collaboration		This thesis addresses computer-augmented collaborative work. More precisely, it focuses on co-located collaboration where co-workers get together at the same place, usually a meeting room. We assume co-workers to use both mobile devices (i.e. hand-held devices) and a static device (i.e., interactive table). These devices provide multiple output modalities, such as visual output and sound output. The co-workers are assumed to process digital content (e.g., document, videos etc.). According to both common experience and scientific evidence, co-workers o en switch between rather individual, self directed work and tightly shared group work; these working styles are denoted as loose and tight collaboration, respectively. The overarching goal of this thesis is to be er support seamless transitions between loose and tight collaboration, denoted as fluid collaboration. In order to support such fluid transitions between the two working styles, we have to reflect and mitigate conflicting requirements for both output modalities. In tight collaboration, co-workers appreciate proximity and equal access to content; both workspaces and content are shared. In loose collaboration, co-workers desire su icient space of their own and minimal interference of their contents and interaction. It was shown that in conventional se ings (e.g., interactive tables), a transition between tight and loose collaboration leads to limited personal workspace and thereby to workspace interference, clu er and other constraints. During collaboration, such interference concerns both visual and sound output. In light of these facts, further research on interactive devices (e.g., interactive tables and mobile devices) is needed to support fluid collaboration with di erent output modalities. These observations lead to the central research question of this thesis: How to support fluid co-located collaboration using visual and sound content? This thesis explores this question in three main research directions: (1) surface-based interaction, (2) spatial interaction and (3) embodied sound interaction, while (1) and (2) address visual content, (3) focuses on auditory content. In each direction, we conceptualized, implemented, and evaluated a set of device concepts plus corresponding interaction concepts, respectively. The first research direction, Surface-Based Interaction, contributes a novel tabletop, called Permulin, that provides (1) a group view providing a common ground during phases of tight collaboration, (2) private full screen views for each collaborator to sca old loosely coupled collaboration and (3) interaction and visualization techniques for sharing content in-between these views for coordination and mutual awareness. Results from an exploratory study and from a controlled experiment provide evidence for the following advancements: (1) Permulin supports fluid collaboration by allowing the user to transition fluidly between loose and tight collaboration. (2) Users perceive and use Permulin as both a cooperative and an individual device. Amongst others, this is reflected by participants occupying significantly larger interaction areas on Permulin than on a tabletop system. (3) Permulin provides unique awareness properties: participants were highly aware of each other and of their interactions during tightly coupled collaboration, while being able to unobtrusively perform individual work during loosely coupled collaboration.		Roman Lissermann	2014			simulation;sonic interaction design;engineering;multimedia;communication	HCI	-53.81503277959513	-43.99034932645605	165511
914e29c8092037950dd15ab685a7fcdb3be60130	towards a human machine interface concept for performance improvement of cycling		Exercising tends to be tedious and boring. Users search for means of entertainment during their workout. Motivation is an essential factor that inspires a person to maintain physical activity levels. A number of exercise bicycle manufacturers have enabled their equipment to port data signals to computers for the purpose of training logs. However, they all lack the motivational and the fun factors in their system. Many people face obstacles to improve their physical activity due to lack of accessibility to physical activity facilities and physical trainers. Technology can provide immediate personal assistance anywhere and anytime. In this paper, we present a persuasive game environment integrated to cycle training. The system measures the performance of a rider and visualizes a scenario through which the virtual bike trip leads. The players maintain their excitement while riding the bicycle to improve their performance on how to enhance cycling skills.		Menah El Bastawisy;Dirk Reichardt;Slim Abdennadher	2016		10.1007/978-3-319-50182-6_39	business;simulation;human–machine interface;android (operating system);cycling;performance improvement;persuasive technology	AI	-50.235212692203596	-44.95708589588932	165538
30cbd7a20d2544a507bc986a62a6003694fa6930	tangible interaction for stroke survivors: design recommendations	activity;user studies;codesign;co design;medicinsk apparatteknik;participatory design;tangible interaction;stroke	In this paper we outline the initial stages of a human centered design process aimed at the design of novel technology (tangible interactive objects) for stroke survivors. We found it useful to support standard methods, such as interviews and focus groups, with a video prototype in order to make the concept of tangible interaction, which was novel to our users, more clear. In addition we carried out a co-design workshop together with stroke survivors. Based on these activities, we present a set of preliminary design guidelines for tangible interaction for stroke survivors.	focus group;prototype;recommender system;tangible user interface	Charlotte Magnusson;Héctor A. Caltenco;David K. McGookin;Mikko Kytö;Ingibjörg Hjaltadóttir;Thóra B. Hafsteinsdóttir;Helga Jónsdóttir;Ingibjörg Bjartmarz	2017		10.1145/3024969.3025073	simulation;human–computer interaction;engineering;multimedia	HCI	-55.107532872160874	-38.555049670061194	165653
16d0d19c78dc850a597170700bc1f5cbce8ac867	analysis of web accessibility in social networking services through blind users' perspective and an accessible prototype			prototype;web accessibility	Janaína Rolan Loureiro;Maria Istela Cagnin;Débora Maria Barroso Paiva	2015		10.1007/978-3-319-21413-9_9	human–computer interaction;web accessibility initiative;computer science;web accessibility;multimedia;world wide web	Networks	-51.744576950606294	-39.42941035171691	165973
044814c08391ae1a1e262d93fed9130352cdc3dd	tangible interaction on tabletops for elderly people	human computer interaction;design innovation;games for elderly;tangible objects;tabletop;natural user interface	The urge to improve the life of older adults grows as this segment of society expands. Computers have an enormous potential to benefit the lives of older adults, however, the unawareness or disregard of their characteristics, renders technology, many times, impossible to use. Peripherals are a common obstacle when learning to operate computers, because the most common ones do not directly map the input in the user interface. It has been argued that touchand gesture-based user interfaces, due to their direct mapping of input, can reduce the obstacles that older adults face, when using the computer. To assess this, this paper presents a project that uses a multi-touch tabletop system as a gaming platform for older adults. Specifically, it reports on the low-fidelity prototype that was built to test whether tangible objects can be used. Conclusions regarding the viability of tangible objects for that purpose are also	computer;multi-touch;peripheral;prototype;rendering (computer graphics);tangible user interface	Tiago Marques;Francisco Maria Cruz Nunes;Paula Alexandra Silva;Rui Rodrigues	2011		10.1007/978-3-642-24500-8_61	simulation;human–computer interaction;engineering;multimedia	HCI	-48.94362971894222	-41.642417890920456	166489
e2b2099dfa0dd8de9ffa9819b98ff1cac69ff707	a co-located meeting support system by scoring group activity using mobile devices	interaction;meeting support;visualization;cscw	In this paper, we present a co-located meeting support system using mobile devices such as tablets and smartphones, which can use anywhere and easily set up. We have developed a system using tablets, and we re-designed its visualization and scoring methods for brainstorming. The system provides visual feedbacks of how long a person speaks to the other person and how long the person watches him/her. The system also provides two scores based on a balance degree of individual utterance and that of pair conversation as a group activity. The system is currently under experimentation.	feedback;mobile device;smartphone;tablet computer	Hiroyuki Adachi;Seiko Myojin;Nobutaka Shimada	2016		10.1145/2875194.2875230	simulation;human–computer interaction;engineering;multimedia	HCI	-51.41058807181125	-44.70901707704574	166759
b57f637b2e04b4bcf92e12158cc12852499d18ec	non-verbal interface of a personal agent based on symbiotic computing model	worker behavior symbiotic computing model groupware tools information sharing collaborative practice work awareness distant workplace partner agent watching omas platform;agent interaction;groupware;omas platform;user interfaces groupware interactive systems multi agent systems;agent based;computer model;face sensors;multi agent systems;quality of information;partner agent work awareness omas platform;sensor nodes;partner agent;interactive systems;face to face;user interfaces;work awareness;competitive advantage	Distributed workers working at distant places have been supported by various kinds of groupware tools which enable a sharing of information, documentation, schedule and communication among them, which have been introduced into face-to-face offices of enterprises at the beginning for improved performance, competitive advantage, innovation and general development of collaborative practice. However, due to difficulties for isolated workers to share work awareness of a distant workplace, a new framework to take empathetic care of each worker working at home or a isolated workplaces is required. In this paper, first, we propose a concept of a partner agent watching over a worker working with other co-workers at a distant workplace, and second, we design a partner agent running on the OMAS platform to communicate with other agents. The agent dedicated to a worker has functions to watch over him/her using various kinds of sensors and knowledge on behavior of workers at work.	agent-based model;care-of address;collaborative software;documentation;intelligent agent;knowledge representation and reasoning;sensor;telecommuting;dialog	Kenji Sugawara;Shigeru Fujita	2011	IEEE 10th International Conference on Cognitive Informatics and Cognitive Computing (ICCI-CC'11)	10.1109/COGINF.2011.6016162	simulation;human–computer interaction;engineering;knowledge management	HCI	-52.40770238253009	-38.59471206189909	166922
7cd4a9a7e43928d035359e522b16a02543f69a5b	spell: affecting thermal comfort through perceptive techniques	smart buildings;perception;temperature	Thermostats allow people to set the temperature they desire, even if personal thermal comfort perception is tied to a number of external stimuli [9]. Here we investigate dependability of people's thermal comfort, from the multi-sensory features of environment (light colors). We want to prototype a system that influences people's thermal comfort through other stimuli instead of temperature changing. The preliminary Spell research envisions a smart system for heating control that proactively compensates temperature variations using light color variations, accomplishing both the objectives: to satisfy user request for thermal comfort, while optimizing energy consumption. Two preliminary experiments were made: one demonstrates that people's perceived temperature is different from the actual temperature in a space; the second one shows how lights color affects the temperature perceived by people. As a result we derived preliminary guidelines for the prototyping the Spell system.	color;dependability;experiment;prototype;smart system	Annamaria Andrea Vitali;Donatella Sciuto;Marco Spadafora;Margherita Pillan;A. A. Nacci	2014		10.1145/2638728.2638790	simulation;temperature;building automation;perception	HCI	-50.60219265842667	-44.85155175017353	166971
e2c48874af68f38c5926855cac2c11a8d499cfee	a system for fast, full-text entry for small electronic devices	fitts law;text entry;keypad input;pen based;mobile phone;system design;mobile phones;mobile systems;adjacency matrix;stylus input;soft keyboard	A novel text entry system designed based on the ubiquitous 12-button telephone keypad and its adaptation for a soft keypad are presented. This system can be used to enter full text (letters + numbers + special characters) on devices where the number of keys or the keyboard area is limited. Letter-frequency data is used for assigning letters to the positions of a 3x3 matrix on keys, enhancing the entry of the most frequent Letters performed by a double-click. Less frequent letters and characters are entered based on a 3x3 adjacency matrix using an unambiguous, two-keystroke scheme. The same technique is applied to a virtual or soft keyboard layout so letters and characters are entered with taps or slides on an 11-button keypad. Based on the application of Fitts' law, this system is determined to be 67% faster than the QWERTY soft keyboard and 31% faster than the multi-tap text entry system commonly used on cell phones today. The system presented in this paper is implemented and runs on Palm OS PDAs, replacing the built-in QWERTY keyboard and Graffiti recognition systems of these PDAs.	adjacency matrix;double-click;event (computing);fitts's law;graffiti (palm os);letter frequency;mobile phone;multi-tap;operating system;palm os;personal digital assistant;plover	Saied Bozorgui-Nesbat	2003		10.1145/958432.958437	embedded system;speech recognition;computer hardware;computer science;operating system;fitts's law;adjacency matrix;systems design	HCI	-48.4078564975334	-43.416569780386475	167105
4148b7cb127f4498513852d4fce3f4c705a068eb	mallo: a distributed synchronized musical instrument designed for internet performance		The Internet holds a lot of potential as a music listening, collaboration, and performance space. It has become commonplace to stream music and video of musical performance over the web. However, the goal of playing rhythmically synchronized music over long distances has remained elusive due to the latency inherent in networked communication. The farther apart two artists are from one another, the greater the delay. Furthermore, latency times can change abruptly with no warning. In this paper, we demonstrate that it is possible to create a distributed, synchronized musical instrument that allows performers to play together over long distances, despite latency. We describe one such instrument, MalLo, which combats latency by predicting a musician’s action before it is completed. MalLo sends information about a predicted musical note over the Internet before it is played, and synthesizes this note at a collaborator’s location at nearly the same moment it is played by the performer. MalLo also protects against latency spikes by sending the prediction data across multiple network paths, with the intention of routing around latency.	internet;routing	Zeyu Jin;Reid Oda;Adam Finkelstein;Rebecca Fiebrink	2015			human–computer interaction;multimedia;musical;the internet;computer science	Networks	-53.03845162724081	-43.73187780878614	168414
60812c6637f846d5844fcc7cb7e04a350388e1ac	speech and hands-free interaction: myths, challenges, and opportunities		HCI research has for long been dedicated to better and more naturally facilitating information transfer between humans and machines. Unfortunately, humans' most natural form of communication, speech, is also one of the most difficult modalities to be understood by machines - despite, and perhaps, because it is the highest-bandwidth communication channel we possess. While significant research efforts, from engineering, to linguistic, and to cognitive sciences, have been spent on improving machines' ability to understand speech, the MobileHCI community (and the HCI field at large) has been relatively timid in embracing this modality as a central focus of research. This can be attributed in part to the unexpected variations in error rates when processing speech, in contrast with often-unfounded claims of success from industry, but also to the intrinsic difficulty of designing and especially evaluating speech and natural language interfaces. As such, the development of interactive speech-based systems is mostly driven by engineering efforts to improve such systems with respect to largely arbitrary performance metrics. Such developments have often been void of any user-centered design principles or consideration for usability or usefulness.  The goal of this course is to inform the MobileHCI community of the current state of speech and natural language research, to dispel some of the myths surrounding speech-based interaction, as well as to provide an opportunity for researchers and practitioners to learn more about how speech recognition and speech synthesis work, what are their limitations, and how they could be used to enhance current interaction paradigms. Through this, we hope that HCI researchers and practitioners will learn how to combine recent advances in speech processing with user-centred principles in designing more usable and useful speech-based interactive systems.	channel (communications);cognitive science;human–computer interaction;mobilehci;modality (human–computer interaction);natural language;speech processing;speech recognition;speech synthesis;usability;user-centered design	Cosmin Munteanu;Gerald Penn	2017		10.1145/3098279.3119919	human–computer interaction;management science;modalities;usability;design elements and principles;natural language;speech processing;usable;information transfer;computer science;speech synthesis	HCI	-51.02359125463118	-44.303449256037226	168926
fdfddd4db8f281d63c79fdf4a6ed8844d3acb128	optimizing user interaction for web-based mobile tasks	content based technique;user interfaces internet mobile computing;structure based technique;interaction burstiness;real time;interaction short cuts;web based mobile tasks;interaction context;form factor;automatic text copying;context mobile communication integrated circuits optimization monitoring browsers mobile handsets;trails;browsers;mobile web;internet;monitoring;user interaction sequences prediction;page pre fetching;waiting time;user experience;structure based technique web based mobile tasks mobile handsets cellular network mobile web related activity usability concern mobile interaction optimization system runtime construction interaction context interaction burstiness trails user interaction sequences prediction interaction short cuts automatic text copying form filling page pre fetching user interface enhancement content based technique;mobile web related activity;mobile communication;usability concern;cellular network;mobile handsets;user interface enhancement;optimization;runtime construction;sequence prediction;form filling;mobile computing;mobile interaction optimization system;user interaction;user interfaces;integrated circuits;context;mobile interaction	This paper describes the design and prototype implementation of MIntOS (Mobile Interaction Optimization System), a system for improving mobile interaction in web-based activities. MIntOS monitors users’ interactions both for gathering interaction history and for the runtime construction of interaction context. A simple approach based on interaction burstiness is used to break interaction sequences into Trails, which approximates user tasks. Such Trails are used to generate rules for online, context-sensitive prediction of future interaction sequences. Predicted user interaction sequences are then optimized to reduce the amount of user input and user wait time using techniques such as interaction short-cuts, automatic text copying and form-filling, as well as page pre-fetching. Such optimized interaction sequences are, at real-time, recommended to the user through UI enhancements in a non-intrusive manner.	context-sensitive grammar;context-sensitive help;mathematical optimization;mobile interaction;mobile phone;optimizing compiler;prototype;real-time transcription;user experience;user interface;web application	Dong Zhou;Ajay Chander;Hiroshi Inamura	2010		10.1109/SAINT.2010.63	user interface design;user;cellular network;user experience design;real-time computing;the internet;user modeling;computer user satisfaction;mobile web;interactive systems engineering;mobile interaction;mobile telephony;form factor;human–computer interaction;computer science;operating system;database;interactivity;user interface;mobile computing;world wide web;interaction technique	HCI	-50.20392956135458	-42.49610993742769	170267
c0ffc69b3e9fb0bf5759f930980ed81bb07a8300	the future of universal access? merging computing, design and engineering	alternative and augmentative communication aac;environmental control systems;universal access;t technology general;tablets;qa75 electronic computers computer science;accessibility;mechatronics	Technology is advancing at a fast pace while the shape and nature of computers continues to evolve, with tablets and smartphones illustrating the move away from the traditional notion of a laptop or desktop computer. Similarly, networking and sensing technologies are also developing rapidly and innovatively. All of these technologies have the potential to enfranchise users with severe functional impairments to be better able to control and interact with other people and their surroundings. However, this is only possible if those designing the novel systems based upon these new technologies consider such users’ needs explicitly. This paper examines how these technological advances can be employed to support these users in the near future. The paper further discusses issues such as the need for security as systems evolve from control of specific environments to a potential model for interaction in any location.	desktop computer;laptop;smartphone;user experience;user interface	Simeon Keates;David Bradley;Andrew Sapeluk	2013		10.1007/978-3-642-39194-1_7	simulation;human–computer interaction;engineering;multimedia	HCI	-49.15727433525556	-41.47593283259005	171540
e22b0fcc5fc420046b40317a8f1bafdd1b642696	service engagement model for mobile advertising based on user behavior	context awareness;smart mobile device;advertising data processing;smart phones;mobile advertising;advertising smart phones mobile communication sensors history computers;situation awareness;service engagement model contextual advertisement user interests smart mobile devices user behavior based mobile advertisement;behavioural sciences;user behavior;generating services;mobile computing;user behavior smart mobile device mobile advertising context awareness situation awareness generating services;smart phones advertising data processing behavioural sciences mobile computing	More and more people these days carry smart mobile devices, such as smartphones or tablet computers, with them. However, the advertisements that people usually see on their mobile devices are not context-sensitive. The advertisements might have nothing to do with the current surroundings of the user or be relevant to the user's interests. Thus a service engagement model for mobile advertising based on the users' behavior is needed. By providing interesting and contextual advertising to the user, the effect of the advertisements will be more powerful.	context-sensitive help;context-sensitive language;contextual advertising;mobile device;smart device;smartphone;tablet computer	Arto Kaasinen;Yongik Yoon	2013	The International Conference on Information Networking 2013 (ICOIN)	10.1109/ICOIN.2013.6496364	situation awareness;online advertising;mobile search;mobile web;behavioural sciences;computer science;operating system;mobile technology;multimedia;internet privacy;mobile computing;contextual advertising;mobile payment	Mobile	-54.6410245866606	-41.55199138537683	171891
0341e671d4797520c5c2dd31c802f14352bdf90c	mobile augmented reality system for marine navigation assistance	smartphone ergonomics outdoor ar application marine navigation assistance cognitive load issues electronic navigational devices bridge view vessels recreational boats software architecture pervasive system marine mobile augmented reality embedded system mmars;glass;software architecture augmented reality embedded systems ergonomics marine engineering marine navigation mobile computing smart phones;global positioning system;three dimensional displays;boats three dimensional displays global positioning system glass cameras augmented reality;augmented reality;cameras;boats	Augmented Reality devices are about to reach mainstream markets but applications have to meet user expectations in terms of usage and ergonomics. In this paper, we present a real-life outdoor AR application for marine navigation assistance that alleviates cognitive load issues (orientation between electronic navigational devices and bridge view) for vessels and recreational boats. First, we describe the current application and explain the requirements to draw relevant and meaningful objects. Secondly we present the software architecture of our pervasive system, which is compliant with different contexts and applications cases. Then, we detail our Marine Mobile Augmented Reality embedded System (MMARS). Finally, we present implementations on both Embedded system and smartphone.	augmented reality;embedded system;human factors and ergonomics;pervasive informatics;real life;requirement;smartphone;software architecture	Jean-Christophe Morgère;Jean-Philippe Diguet;Johann Laurent	2014	2014 12th IEEE International Conference on Embedded and Ubiquitous Computing	10.1109/EUC.2014.49	embedded system;augmented reality;computer-mediated reality;simulation;global positioning system;computer science;glass;multimedia	Mobile	-48.69721703830649	-41.364270416714376	172004
50819d73b6ed50dffcef651ff515a586840aaf7f	speed sonic across the span: building a platform audio game	audio games;sonification;user study;accessibility;platform games	We describe the design process and initial user study of an audio game created for the visually impaired. Until the advent of 3D graphics games, platform games where the player jumps from platform to platform, such as Mario and Sonic, [1] were wildly popular. Although many audio games have been developed over the past decade, the platform genre has been all but ignored. To fill this gap and to add to the limited choices visually impaired gamers have, we developed a platform game that can be also be played via audio-only interface and compared it to a traditional audio-visual version.	3d computer graphics;usability testing	Michael A. Oren	2007		10.1145/1240866.1240985	video game design;video game graphics;simulation;sonification;human–computer interaction;computer science;accessibility;game mechanics;multimedia;world wide web	HCI	-50.7815030825972	-39.10045534723788	173006
2af1d1aea2379f19a234189ff4e6031484a27a65	designing and evaluating buster: an indexical mobile travel planner for public transportation	context awareness;context aware;public transport;user study;acting out in situ;interface design;indexicality;indexation;mobile information system;mobile systems;field evaluation	This paper elaborates on previous research into the design and use of mobile information systems for supporting the use of public transportation. Contributing to this domain of HCI research, we describe the design and evaluation of a mobile travel planner, Buster, for the public city bus system of a large regional city in Denmark. Carrying on from on earlier research activities, we did contextual interviews, acting out of future scenarios in situ, and iterative paper prototyping to extend on previous design ideas and explore further the principle of indexicality in interface design for context-aware mobile systems. We then implemented a functional prototype application and evaluated it in the field.	calendaring software;contextual inquiry;human–computer interaction;information system;iteration;paper prototyping;personal digital assistant;prototype	Jesper Kjeldskov;Eva Andersen;Lars Hedegaard	2007		10.1145/1324892.1324897	simulation;indexicality;human–computer interaction;interface design;public transport;multimedia	HCI	-55.299587189791275	-39.10577258171553	173068
0904b8f34e93e5e71921ed7e387bd8a80d6eb02f	curationspace: cross-device content curation using instrumental interaction	cross device collaboration;content curation;instrumental interaction;curation work;smartwatch interaction	For digital content curation of historical artefacts, curators collaboratively collect, analyze and edit documents, images, and other digital resources in order to display and share new representations of that information to an audience. Despite their increasing reliance on digital documents and tools, current technologies provide little support for these specific collaborative content curation activities. We introduce CurationSpace -- a novel cross-device system to provide more expressive tools for curating and composing digital historical artefacts. Based on the concept of Instrumental Interaction, CurationSpace allows users to interact with digital curation artefacts on shared interactive surfaces using personal smartwatches as selectors for instruments or modifiers (applied to either the whole curation space, individual documents, or fragments). We introduce a range of novel interaction techniques that allow individuals or groups of curators to more easily create, navigate and share resources during content curation. We report insights from our user study about people's use of instruments and modifiers for curation activities.	digital curation;digital recording;interaction technique;smartwatch;usability testing	Frederik Brudy;Steven Houben;Nicolai Marquardt;Yvonne Rogers	2016		10.1145/2992154.2992175	data curation;computer science;multimedia;world wide web;information retrieval	HCI	-54.00444488328976	-41.58247569050723	173532
c63ad17798d9082196ad320b448b9f241c7e40cd	discount eye tracking: the enhanced restricted focus viewer	restricted focus viewer;eye-tracking;web;visual attention.;usability testing and evaluation;usability testing;eye tracking	This paper discusses the design and implementation of a unique software tool, the enhanced restricted focus viewer (ERFV), for tracking the visual attention of users in hyperlinked environments such as web sites. The software collects data such as mouse clicks along with the path of the user’s visual attention as they browse a site. Unlike traditional eye-tracking procedures, the ERFV requires no hardware other than a personal computer. In addition to cost and time savings, the ERFV also allows the administration of usability testing to groups of subjects simultaneously. The benefits of the ERFV are demonstrated through an experiment that evaluated the usability of two web sites that were equivalent in content but differed in terms of design.	approximation algorithm;browsing;entity–relationship model;eye tracking;hyperlink;personal computer;programming tool;robert frankenberg;usability testing;world wide web	Peter Tarasewich;Stephanie Fillion	2004			usability lab;heuristic evaluation;usability inspection;computer science;component-based usability testing;pluralistic walkthrough;multimedia;cognitive walkthrough;usability;eye tracking	HCI	-51.27718417581753	-39.64716944541287	173845
8893486946e789e0fba226c34c5ce2ddb2df11ca	ensembles of on-body devices	systems;mobile;wearables;mobile device;ecologies;mobile phone;ensembles;mobile systems;user interaction	With the continuing miniaturization of powerful computation into mobile devices, there exists an opportunity for re-envisioning how we interact with our personal technology.In addition to a core computational/interaction component such as a mobile phone, there could be substantial benefit to a user by offering an ensemble of multiple mobile devices that can be used together. Such devices could provide novel input or output capabilities, or distribute user interactions in a more effective way. Our goal with this proposed workshop is to foster discussion about what possibilities such collections of devices might offer.	computation;interaction;mobile device;mobile phone	Daniel Ashbrook;Kent Lyons	2010		10.1145/1851600.1851728	radio access network;mobile search;simulation;mobile web;wearable computer;human–computer interaction;computer science;operating system;mobile technology;mobile device;system;multimedia;mobile computing	HCI	-54.50150162470078	-39.37310988685055	175158
29c5db36cfd45bc4172a34a9138059875098ffcd	lifeclipper3 — an augmented walking experience field evaluation of an experience design approach for immersive outdoor augmented reality	art;design research;locative media;computer vision;media;streaming media;three dimensional displays;games media art streaming media augmented reality three dimensional displays meteorology;games;pervasive game;location based;ubiquitous computing;field evaluation augmented reality mixed reality reactive environment locative media location based ubiquitous computing pervasive game computer vision mobile computing experience design design research;augmented reality;ethnographic method lifeclipper3 media art project experience design approach immersive outdoor augmented reality game like experience visitor evaluation;mobile computing;mixed reality;field evaluation;user interfaces;meteorology;user interfaces augmented reality solid modelling;reactive environment;solid modelling;experience design	lifeClipper3 is a media art project in which a walk is audiovisually expanded into a game-like experience by means of “augmented reality” technologies. For visitors this creates an immersive experience which is unique in each case, and which challenges and calls into question habitual modes of perception. In this paper the “experience design” strategies used in lifeClipper3 are introduced, and examined by means of qualitative ethnographic methods in a visitor evaluation. The resulting insights are intended to be beneficial for similarly designed future AR art projects.	augmented reality;experience design;google art project;immersive technology;lifeclipper	Jan Torpus;Beatrice Tobler	2011	2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities	10.1109/ISMAR-AMH.2011.6093660	games;computer vision;augmented reality;simulation;media;design research;human–computer interaction;experience design;computer science;operating system;mixed reality;multimedia;user interface;mobile computing;ubiquitous computing	Visualization	-54.93634494795877	-39.220477615845176	175361
d94074b74a34d8a467b0ed9d0f7ac2850252d4da	thinking outside of the box or enjoying your 2 seconds of frame?	fixation duration;eye tracking;fixation density maps	The emergence of low cost eye tracking devices will make QS quantified self monitoring of eye movements attainable on next gen- eration mobile devices, potentially allowing us to infer reactions related to fatigue or emotional responses on a continuous basis when interact- ing with the screens of smartphones and tablets. In the current study we explore whether consumer grade eye trackers, despite their reduced spatio-temporal resolution, are able to monitor fixations as well as fre- quencies of saccades and blinks that may characterize aspects of atten- tion, and identify consistent individual patterns that may be modulated by our overall level of engagement.		Per Baekgaard;Michael Kai Petersen;Jakob Eg Larsen	2015		10.1007/978-3-319-20681-3_17	computer vision;simulation;eye tracking;computer science	HCI	-53.359574366366544	-44.13524659338709	175387
f274e592c7a1eb7bb08d805b2a3cf4b9a679769a	proximitäts- und aktivitätserkennung mit mobilen endgeräten	fakultat fur mathematik informatik und statistik;ddc 004;ddc 000	With the now widespread usage of mobile devices such as smartphones and tablets as well as body-worn technical gear (Wearables), the vision of a world in which computing resources are ubiquitously available has become reality. Based on these pervasively available technologies, context-aware applications, i.e., applications adapting their provided services to a user’s current situation, are becoming more and more feasible. A primary element of a user’s context is the proximity of the user to other users or objects. Proximity should not only be considered in a spatial manner but its meaning can be broadened to comprise any context element. In particular, the similarity of different users’ activities is an important information to infer their contextual closeness. With regard to spatial proximity, there is a range of standard technologies which on principle allow to perform proximity detection. However, they all face severe problems with regard to security and privacy of the participants in the proximity test. In this work, three new approaches for proximity detection are presented. Within the newly introduced systems, the contextual components „location“ and „activity“ are considered with different importance. The first approach uses Wifi signals from the surroundings to construct secure, i.e., unforgeable location tags, with which a privacy-preserving proximity test can be performed. While the first method is exclusively focused on spatial proximity, the second approach also implicitly considers the users’ activities. This technique is based on analyzing and comparing visual information obtained from body-mounted cameras. The basic idea of the third approach is that contextual proximity can also be obtained based on activities alone. By comparing sequences of activities, the proximity between participating users can be inferred. In order to be realizable, this approach needs very fine-grained activity recognition capabilities. The feasibility of the latter is also shown in this work. Summing up, in this work several ways are shown how to detect contextual proximity in a secure and privacy-preserving manner.	activity recognition;centrality;mobile device;privacy;smartphone;tablet computer;wearable computer	Marco Maier	2016			art;performance art	HCI	-53.6779018222978	-40.5266439499213	175504
25f351c2e108468fe46091bf72cfb8bafad0d0cc	mozart: a multimodal interface for conceptual 3d modeling	computer aided design;pilot study;multimodal interface;cad;multimodal input;statistical significance;computer graphic;3d model;lessons learned;multimodal system;ergonomics	There is a need for computer aided design tools that support rapid conceptual level design. In this paper we explore and evaluate how intuitive speech and multitouch input can be combined in a multimodal interface for conceptual 3D modeling. Our system, MozArt, is based on a user's innate abilities - speaking and touching, and has a toolbar/button-less interface for creating and interacting with computer graphics models. We briefly cover the hardware and software technology behind MozArt, and present a pilot study comparing our multimodal system with a conventional multitouch modeling interface with first time CAD users. While a larger study is required to obtain statistically significant comparison regarding efficiency and accuracy of the two interfaces, a majority of the participants preferred the multimodal interface over the multitouch. We summarize lessons learned and discuss directions for future research.	3d modeling;computer graphics;computer-aided design;level design;multi-touch;multimodal interaction	Anirudh Sharma;Sriganesh Madhvanath;Ankit Shekhawat;Mark Billinghurst	2011		10.1145/2070481.2070538	computer vision;simulation;human–computer interaction;computer science;human factors and ergonomics;computer aided design;multimodal interaction;cad;statistical significance;multimedia	HCI	-49.08908473592264	-42.31692229619882	175927
e6d3b009a643c521e4d7394292e07b075af391a4	on usable location privacy for android with crowd-recommendations	usable security and privacy;mobile;location;crowd sourcing	The boom of smart devices with location capabilities has also led to a boom of apps that use location data for many different purposes. While there are of course apps that require users' precise locations, such as navigation apps, many apps would work equally well with less precision. Currently, apps that request location information are granted access to location data with maximum precision or not at all. In this work we present a location obfuscation approach for Android devices, which focuses on the usability aspects. Based on results of focus group discussions n,=,19 we designed and implemented a solution that can be used by even unskilled users. When an app requests for location data the first time, the user configures accuracy of location data that is to be revealed to the app by selecting one of five precision levels. Unskilled users are supported by crowd-based recommendations.	android;recommender system	Benjamin Henne;Christian Kater;Matthew Smith	2014		10.1007/978-3-319-08593-7_5	computer science;mobile technology;internet privacy;location;world wide web;computer security	Security	-51.19131617367098	-42.28074032891165	176043
3e8e44d8df5601ad002fc7a3d46c3088df7d6040	modeling user performance for moving target selection with a delayed mouse		The growth in networking and cloud services provides opportunities to host multimedia on remote servers, but also brings challenges to developers who must deal with added delays that degrade interactivity. A fundamental action for many computer-based multimedia applications is selecting a moving target with the mouse. While previous research has modeled both moving target selection and target selection with delay, there have not been models of moving target selection with delay. Our work presents a user study that measures the effects of delay and target speed on the time to select a moving target with a mouse, with analysis of trends and derivation of a model. The analysis shows delay and speed impact target selection time exponentially and that selection time is well-represented by a model with three terms two with exponential relationships for delay and speed and one an important interaction term.	cloud computing;interactivity;time complexity;usability testing	Mark Claypool;Ragnhild Eg;Kjetil Raaen	2017		10.1007/978-3-319-51811-4_19	simulation	HCI	-49.04595027821206	-44.89890977233557	176109
4ce9db50f6ad6b4e8fad0a99969fdabb40627f0a	experiencing the presence of historical stories with location-based augmented reality		In the SPIRIT research project, a location-based Augmented Reality (AR) storytelling application has been developed with the goal to support the imagination of lively historical events at places of cultural significance. We describe a showcase scenario and report on its quantitative and qualitative evaluation, conducted at the Saalburg Roman fort, an outdoor museum site near Bad Homburg in Germany. 107 random voluntary visitors were observed using the app, before filling questionnaires that were then analyzed with SPSS. Specifics of the app include a novel interaction pattern that uses positioning sensors of mobile devices and image recognition to trigger content, featuring transparent videos as ghost-like overlays on the camera image of the environment. Results presented in this paper show that in general, the app was effective and fun to use. Further, there have been differences in the experience of presence concerning the AR representation, as well as in the comprehension and appreciation of the story’s content. Concluding, we discuss influencing parameters on the results and draft hypotheses for future work.	augmented reality	Ulrike Spierling;Peter J. Winzer;Erik Massarczyk	2017		10.1007/978-3-319-71027-3_5	multimedia;storytelling;computer science;augmented reality;interactive storytelling;mobile device;interaction design;comprehension;user experience evaluation;imagination	HCI	-55.084865601591716	-39.21434138503727	176239
4269f9bb9017f6412bbd937f0febc39e1c90272d	trends, challenges and opportunities in spoken dialogue research	voice search;spoken dialogue systems;ambient intelligence.	  Spoken dialogue technology has developed considerably over the past thirty years both in terms of research activity as well  as in terms of commercially deployed applications. This chapter presents an overview of trends in dialogue research based  on an analysis of papers that were presented at Eurospeech- Interspeech conferences in 1989, 1999, and 2009. Following this  some challenges are identified, in particular, the issues faced by individual researchers and those in small groups who wish  to build viable end-to-end dialogue systems and the difficulties that are often encountered by trying to access the many resources  and toolkits that are required for dialogue academic researchers when research. The chapter concludes with a discussion of  some opportunities for future research, including the integration of dialogue technology into voice search applications and  the application of spoken dialogue technology in ambient intelligence environments.    		Michael F. McTear	2011		10.1007/978-1-4419-7934-6_6	natural language processing	NLP	-51.07747992257275	-44.2302731017115	176351
6bcfe613297a2d30e87f4424caa73cf5628a2d58	a usability study of a mobile content sharing system	mobile content sharing;usability evaluation;usability study;numerical analysis;location based annotation;scientific computing;mobitop;human computer interface	We investigate the usability of MobiTOP (Mobile Tagging of Objects and People), a mobile location-based content sharing system. MobiTOP allows users to annotate real world locations with both multimedia and textual content and concurrently, share the annotations among its users. In addition, MobiTOP provides additional functionality such as clustering of annotations and advanced search and filtering options. A usability evaluation of the system was conducted in the context of a travel companion for tourists. The results suggested the potential of the system in terms of functionality for mobile content sharing. Participants agreed that the features in MobiTOP were generally usable as a content sharing tool. Implications and future work are also reported in this paper.		Alton Yeow-Kuan Chua;Dion Hoe-Lian Goh;Khasfariyati Razikin;Ee-Peng Lim	2011	J. Mobile Multimedia		numerical analysis;computer science;multimedia;internet privacy;world wide web;usability lab;usability inspection	HCI	-53.34727806375184	-41.86645636768276	177826
ab9c0635fb47c7a1c064f0149512c31559fba442	an investigation into web accessibility standards as a practical study with older and disabled citizens	web accessibility;standardisation;web design	To coincide with the growth of online services, website standards are progressing to evolve to maintain levels of consistency and usability amongst all web design. Another important aspect is also to include as many users and user groups as possible, especially older and disabled users, given the high potential benefits for those users from the online information, advices, and services. The changes brought about by standardising web design can be both large and small. Ideally the changes will be small enough to go unnoticed by users, but our aim was to see whether even the small changes can make reasonable differences for test users.	e-services;usability;web accessibility;web design	Thomas Bevan;Amr Ahmed	2007	ACM SIGACCESS	10.1145/1278234.1278236	web design;web accessibility initiative;web standards;computer science;web accessibility;multimedia;internet privacy;world wide web;standardization	HCI	-51.939506429703115	-40.87229125651647	179608
fea2f7ec2a0a0c19b78867460f03ecdd03ed514e	on adaptability of web sites for visually handicapped people	aide handicape;handicapped aid;site web;ayuda minusvalido;adaptability;software tool;adaptabilite;web pages;red www;accesibilidad;visually impaired users;reseau web;sensory handicap;handicap sensoriel;adaptabilidad;disability;low vision;malviendo;internet;incapacidad;accessibility;malvoyance;desventaja sensoria;world wide web;incapacite;sitio web;markup language;accessibilite;web site	Currently, the great majority of content published on the Internet is inaccessible to visually impaired users. Although designers have guidelines that guarantee the accessibility of pages constructed as well as software tools to facilitate this task, it is necessary to consider the user's perspective too, allowing him/her to participate in the restructuring or presentation process of contents. There are few software tools which are able to do this. In this paper we present KAI (Accessibility Kit for the Internet) that considers both the user and the designer. It classifies the different components of a published Web page and presents them to the user according to his/her needs. KAI is based on a new language, BML (Blind Markup Language) that helps authors to develop better structured pages. It provides two levels of independence: original Web code and user browser or navigation platform. KAI includes a mixed audio/touch browser (WebTouch) that enables selective reading of contents. The proposed accessibility kit uses several accessibility metrics to ensure that those pages transformed by KAI are more accessible than the original ones. In this paper we give an overview of the overall system.	accessibility;battle management language;google sites;html editor;internet;markup language;paging;web page;web search engine;world wide web	Mercedes Macías;Julia González	2002		10.1007/3-540-47952-X_28	adaptability;the internet;human–computer interaction;computer science;artificial intelligence;accessibility;operating system;web page;database;multimedia;markup language;world wide web;computer security	HCI	-51.78316212614564	-41.51242874937467	179668
b5cff17af729237a49c34cc630e493901148657b	tips for designing mobile phone web pages for the elderly	web pages;the elderly;mobile phone;web design;mobile phone web pages;aging effect	This paper proposes tips for designing Web pages appropriate for the elderly. The characteristics of mobile phone Web pages and the effects of aging are elucidated. The elderly had difficulty in reading texts, finding the focus, operating pages and input, and understanding the contents in some cases. Tips for designing Web pages that are appropriate for the elderly are proposed based on our observations.		Yoko Asano;Harumi Saito;Hitomi Sato;Lin Wang;Qin Gao;Pei-Luen Patrick Rau	2007		10.1007/978-3-540-73105-4_74	web service;mobile web;web design;human–computer interaction;computer science;web navigation;web page;multimedia;world wide web;web server	HCI	-50.894588028280246	-42.19668579373229	180331
90ac29a7668896e7ede944f092092950914f733b	emulating field research in the usability lab: lessons learned from stage design	usability contextual inquiry ethnography field research;design engineering;restaurant environment emulating field research stage design usability laboratory ethnography stage design techniques home environment office environment;usability interviews observers laboratories cameras schedules visualization;ethical aspects design engineering;ethical aspects	This case history describes a study that emulated field research in the usability laboratory, a methodology for gaining some benefits of ethnography when it is not practical to visit users' environments. We used stage design techniques to create three “environments”: home, office, and restaurant. In these environments, we learned some contextual information despite the controlled setting.	emulator;field research;usability lab	Stephanie Rosenbaum	2012	2012 IEEE International Professional Communication Conference	10.1109/IPCC.2012.6408593	pluralistic walkthrough;web usability;cognitive walkthrough;simulation;usability;human–computer interaction;agile usability engineering;engineering;system usability scale;usability engineering;universal usability;multimedia;heuristic evaluation;usability lab	Visualization	-53.20801771990074	-39.99778060132903	180347
4134113c219b3d856a533db6516dfcf342c29262	health shelf: interactive nutritional labels	interactive label;user centered design;nutritional label;health management;nutritional value;nutrition	"""""""Healthy Shelf"""" is an interactive nutritional label system. User-centered design process was used to create the labels with HTML and JavaScript for deployment on kiosks attached to supermarket shelves. Users change the serving size on the nutritional labels and the labels then calculate nutritional values. The interactive labels also display comparisons of nutritional values. We evaluated a prototype of the system and found that participants liked the idea of using interactive nutritional labels while shopping and they make more accurate serving size."""	html;javascript;prototype;software deployment;user-centered design	Sapna Bedi;Javier Diaz Ruvalcaba;Zoltan Foley-Fisher;Noreen Kamal;Vincent Tsao	2010		10.1145/1753846.1754161	user-centered design;human–computer interaction;health management system;multimedia;nutrition	HCI	-52.70298644796822	-42.68706612567805	180520
1fdc00507df947ba6f803f56df6cdec031604ff8	your way your missions: from location-based to route-based pervasive gaming	google map;pervasive computing;location;spatial database;route;design and implementation;games;pervasive game	In this paper, we describe the design and implementation of a route-based pervasive game named Your Way Your Missions (YWYM). Since the game obtains the planned routes of players and returns missions in the routes, players can play the game in a casual way, without changing their routes to respond to picked up missions. A self-reporting method is proposed to obtain the planned routes of players, and a corresponding route defining tool is developed upon Google Maps. Two approaches to realize route-based mission adaptation with spatial databases are presented.	location-based game;pervasive informatics;spatial database	Ling Chen;Steve Benford	2007		10.1145/1255047.1255100	simulation;geography;internet privacy;computer security	HCI	-50.693332932483194	-39.80042290609845	180545
06c31a98a9b910ab2674c73308c0e010bc21ed9a	using visualizations to review a group's interaction dynamics	meeting support;social visualization;cscw;visual system;face to face	We present a visualization system for reviewing the turn-taking patterns in a face-to-face meeting. Without the need to directly observe a group, a user can use the system to gain insight into the interaction dynamics of a meeting. We evaluated the visualizations by asking outside observers to make qualitative judgments about the individuals represented visually, and then compared their assessments to our own, made from direct observation of the meetings.		Joan Morris DiMicco;Katherine J. Hollenbach;Walter Bender	2006		10.1145/1125451.1125594	simulation;visual system;human–computer interaction;computer science;computer-supported cooperative work;multimedia;world wide web	HCI	-54.42195926612717	-44.29781663960528	180660
ed948d349d4e9a594cb6c3060519a0c393c38d52	toward truly personal chatbots: on the development of custom conversational assistants		Chatbots, i.e., conversational software agents able to interact with users via instant messaging channels like Messenger, WhatsApp or SMS, have the power to substantively simplify human-computer interaction thanks to their natural language paradigm. While this certainly helps to lower barriers, state-of-the-art chatbots prevalently provide access to generic, non-personalized features with relatively little usefulness. This may hinder adoption. To provide users with real value, we envision a kind of chatbot that is personal and helpful by providing services that are chosen and configured by the users themselves, for themselves. As the development of a one-size-fits-all, yet flexible and customizable bot is hard, if not impossible, we discuss requirements and design options that directly put the user into control of their own personal bot.	fits;human–computer interaction;instant messaging;natural language;personalization;programming paradigm;requirement;software agent;whatsapp messenger	Florian Daniel;Maristella Matera;Vittorio Zaccaria;Alessandro Dell'Orto	2018	2018 IEEE/ACM 1st International Workshop on Software Engineering for Cognitive Services (SE4COG)	10.1145/3195555.3195563	world wide web;mashup;end user;chatbot;software agent;natural language;computer science	HCI	-51.375745162842954	-38.2125357114992	180943
23c97b91096d5f3270b100d1f76a4e29707d7e56	orientation of attention in visual feedbacks during neurofeedback relaxation		The assumptions underlying differing approaches to interface design result, in part, on how attention is managed and categorized using theories from media studies. The authors propose the term intraface to refer to biofeedback or other interfaces that are designed to support users who direct their attention inward to inner physiological states. In this paper, the role of representing feedback data in abstract forms is compared in an experiment using Neurosky’s neurofeedback device. Although preliminary, the results suggest that mapping biofeedback data from a brain-computer interface (BCI) to highly abstract ambient animations is more effective for relaxation than mapping it to a highly familiar symbolic smiley face icon or to a progress bar. The authors propose that the relative success of the abstract ambient animation can be explained because this representation of biofeedback data is the form that requires the least amount of attention, and that designing biofeedback interfaces that distribute the attention, supports the need of users to the task of directing most of their attention to their inner physiological states.	brain–computer interface;categorization;direct inward dial;feedback;linear programming relaxation;microsoft windows;neurofeedback;reflection (computer graphics);relaxation (approximation);schematic;skeletal animation;theory	Mehdi Karamnejad;Diane Gromala;Amber Choo;Chris Shaw;Xin Tong	2014		10.5220/0004724801960203	psychology;cognitive psychology;developmental psychology;communication	HCI	-50.0686993975794	-43.958792138095255	181398
6e087ddc8a262659fa211a2c9dc26a41e758b989	voice user interface design patterns	design pattern;voice user interface	We present in this paper a set of design patterns we have mined in the area of Voice User Interfaces (VUI). In a previous paper [14], we introduced several patterns regarding fundamental issues of developing a voice application. In this paper we explore further aspects concerning the internal structure of an audio interface, the construction of the interaction style, the system response architecture, and implementation strategies to meet the demands of real world scenarios.	design pattern;mined;user interface design;voice user interface	Dirk Schnelle;Fernando Lyardet	2006			user interface design;user;10-foot user interface;shell;voice tag;natural user interface;user interface	HCI	-51.45630612034455	-38.72328147247827	182947
4a5c9926c71a562b2ca83c8fcd6720e8a1bf625e	navilite: a lightweight indoor location-aware mobile navigation service for the handicapped and the elderly	challenging task;economic return;available facility;lightweight location-aware navigation service;related information;indoor location-aware mobile navigation;barrier-free facility;danger zone;handheld phs mobile phone;suggested route;service assistance	Faced with the rapidly aging population, shrinking number of caregivers, and the promise of economic returns, the growing demand to provide more service assistance to handicapped persons and the elderly is a challenging task. In Japan, there are about 560,000 people who are in wheelchairs but they are rarely seen in public. One reason is that, they lack the information on the available facilities that cater to their needs once they go out to their destination. Providing these people with information on barrier-free facilities and other related information along their route will help boost their morale, build self-confidence, and self-reliance. In this paper, we describe the development towards a real-time and lightweight location-aware navigation service, called NaviLite, with particular focus on people in wheelchairs. We utilized the readily available handheld PHS mobile phone devices to display the location map, obstacles and danger zones within the periphery, and the suggested route to their destinations. We conducted preliminary experiments and discussed its results.		Toshihiro Uchibayashi;Bernady O. Apduhan;Itsujiro Arita	2008	J. Mobile Multimedia		complex systems;simulation;index term;computer science;multimedia;world wide web;computer security;computer network	Mobile	-50.22913667489306	-41.78758849133508	182994
152bd0fbb9caf5cd2e612df02662f4180ac3376a	assisted news reading with automated illustration	automated illustration;text to image;information processing;elderly people;audio visual	We all had the problem of forgetting about what we just read a few sentences before. This comes from the problem of attention and is more common with children and elderly. People feel either bored or distracted by something more interesting. This paper proposes an application to help people reading news by illustrating the news story. The application provides mechanisms to (1) select the best illustration for each scene and (2) to select the set of illustrations to improve the story sequence. The application proposed in this technical demo aims at improving the user's attention when reading news articles. The application implements several information processing techniques to generate an audio-visual presentation of the text news article.	information processing	Diogo Delgado;João Magalhães;Nuno Correia	2010		10.1145/1873951.1874311	computer vision;speech recognition;information processing;computer science;multimedia;world wide web	NLP	-52.11968133199433	-43.00279938719909	183842
bc2329558f292661de3d6e22593824dae1d17cbf	usability evaluation of dialogue designs for voiceprint authentication in automated telephone banking		This paper describes an empirical investigation of the usability of different dialogue designs for voiceprint authentication in automated telephone banking. Three strategies for voice authentication were evaluated in an experiment with 120 telephone banking end-users: 1-Factor (voiceprint authentication based on customers' utterances of their account number and sort code); 1-Factor with Challenge (1-Factor plus a randomly generated digit string); and 2-Factor (1-Factor plus secret information known only to the caller). The research suggests the 2-Factor approach is the most effective strategy in this context: results from a Likert questionnaire show it to be highly usable and it is rated highest in terms of both security and overall quality. Participants welcome the option to use voiceprint technology but the majority would prefer it to augment rather than replace existing security methods.	authentication;usability	Nancie Gunson;Diarmid Marshall;Fergus R. McInnes;Hazel Morton;Mervyn A. Jack	2014	IJTHI	10.4018/ijthi.2014040104	advertising;social psychology;world wide web;computer security	HCI	-49.162816095739835	-44.92987831892069	183843
c12d27fd13eee0179b91d515755830be16b68270	task-based prediction of interaction patterns for ambient intelligence environments	task patterns;ambient intelligence;task model;monitoring system;ambient intelligence environment;interaction pattern;pro active agent system;activity patterns;user interaction	In this paper we introduce a monitoring system to support the user executing tasks in an ambient intelligence environment. In contrast with traditional environments, the goal of the user can not always be defined beforehand, but is determined while the user interacts with the environment. The monitor observes the user's activities and learns to correlate a set of user actions with a goal. The system maps activities to a task model and reuses these models to take appropriate actions in later similar user actions that are observed.	ambient intelligence	Kristof Verpoorten;Kris Luyten;Karin Coninx	2007		10.1007/978-3-540-73105-4_132	simulation;ambient intelligence;human–computer interaction;computer science	HCI	-55.52563733144559	-44.827540213069476	184093
4460b8cb9099b3583797252bf8358ee28e92f6c1	enhancement of an internet browser and the human interface for user mobility	human interface			Davood Khalili	2004			world wide web;human–computer interaction;computer science;the internet;human interface device	HCI	-49.953155029524375	-38.463623400726426	185038
df6444a08f6cf1431732a438bba11bfbe31a9b6d	augmented reality 3d interactive advertisements on smartphones	mobile handsets advertising augmented reality mobile computing;3d interaction;high resolution;interactive visualization;augmented reality smart phones mobile handsets advertising cameras hardware laboratories computer networks mouth collaboration;smartphones;3d interactive advertisements;mobile phone;visual code design augmented reality 3d interactive advertisements smartphones mobile phones;mobile handsets;mobile phones;augmented reality;mobile computing;visual code design;advertising;qa76 computer software	Whilst augmented reality (AR) has been a prevalent research topic it has proved difficulty to implement and apply in commercial situations as it generally requires complex and expensive hardware. With the proliferation of mobile phones amongst the world population with ever increasing sets of advanced features such as cameras and high resolution screens AR has the opportunity to emerge from laboratories and enter the high street. In this paper we discuss a unique system that will allow complex and highly interactive visual 3- D adverts to be viewed on mobile phones equipped with cameras. The 3-D adverts are contained within a novel visual code design which allows the system to be deployed without the requirement for additional network infrastructure making it both practical and affordable for advertisers.	augmented reality;image resolution;mobile phone;smartphone;while	Fadi Chehimi;Paul Coulton;Reuben Edwards	2007	International Conference on the Management of Mobile Business (ICMB 2007)	10.1109/ICMB.2007.20	simulation;engineering;multimedia;internet privacy	HCI	-49.343300520419156	-39.29847985219526	185586
a7d91ae1fe75e3602e195a789a243a0d85eed868	program transformations for information personalization	formal model;selected works;bepress selected works;information retrieval;web modeling;web interaction;program transformation;information personalization;hierarchical hypermedia;hierarchical hypermedia information personalization navigation out of turn interaction program transformations partial evaluation program slicing web interaction web mining website transformation;information overload;personalization;information content;navigation;partial evaluation;dissertation;other dissertation;web mining;bepress;website transformation;program transformations;program slicing;out of turn interaction	Personalization constitutes the mechanisms and technologies necessary to customize information access to the end-user. It can be defined as the automatic adjustment of information content, structure, and presentation. The central thesis of this dissertation is that modeling interaction explicitly in a representation, and studying how partial information can be harnessed in it by program transformations to direct the flow of the interaction, can provide insight into, reveal opportunities for, and define a model for personalized interaction. To evaluate this thesis, a formal modeling methodology is developed for personalizing interactions with information systems, especially hierarchical hypermedia, based on program transformations. The predominant form of personalized interaction developed in this thesis is out-of-turn interaction, a technique which empowers the user to take the initiative in a user–system dialog by providing unsolicited, but relevant, information out-of-turn. Out-of-turn interaction helps flexibly bridge any mismatch between the user’s model of information seeking and the system’s hardwired hyperlink structure in a manner fundamentally different from extant solutions, such as multiple faceted browsing classifications and search tools. This capability is showcased through two interaction interfaces using alternate modalities to capture and communicate out-of-turn information to the underlying system: a toolbar embedded into a traditional browser for out-of-turn textual input and voice-enabled content pages for out-of-turn speech input. The specific research issues addressed involve identifying and developing representations and transformations suitable for general classes of hierarchical hypermedia, providing supplemental interactions for improving the personalized experience, and studying user’s (out-of-turn) interactions with resulting systems. For my parents and grandparents, for love, support, and presence.	embedded system;faceted classification;hyperlink;hypermedia;information access;information seeking;information system;interaction;personalization;program transformation;self-information;user interface;dialog	Saverio Perugini	2004	Computer Languages, Systems & Structures	10.1016/j.cl.2009.09.002	navigation;web mining;program slicing;web modeling;self-information;computer science;information overload;personalization;database;multimedia;world wide web;partial evaluation	HCI	-52.89299705828563	-39.52130440236392	185903
843b47c6b56a4c3e0db31545ce0f188fab346a7c	pre-purchase online information seeking: search versus browse	exploratory study;interface design	Recognizing the need to support both goal-directed and experiential behaviour in online shopping environments as a means of facilitating flow, this paper reports results from an exploratory study that investigates consumer preferences for Web-based product information display across browsing and searching tasks. Thirty-one participants performed two online shopping tasks (one searching and one browsing in nature) on predetermined e-tailing sites and were asked to evaluate the display of product information on these sites in helping them carry out these tasks. Results suggest three things: 1) information such as pricing, product description, retailer selection, retailer advice, and a good interface design are required in both tasks; 2) searching requires more detailed product information; and 3) browsing places greater emphasis on information about the retailer. Based on these findings, a theoretical framework for Web-based product information display is presented. With respect to the design of Web retailing sites, the study’s results imply the need to focus not only on goal-directed search, but also on non-directed browsing tasks as well. It is argued that adapting the design of e-tailing sites to the unique information display requirements of search and browse tasks could help promote more compelling online shopping experiences for consumers.	browsing;display device;e-commerce;experience;information seeking;online shopping;requirement	Brian Detlor;Susan Sproule;Chris Gupta	2003	J. Electron. Commerce Res.		economics;product description;marketing;exploratory research;interface design;multimedia;experiential learning;information seeking	HCI	-53.316134667887724	-41.55915526866693	186892
8ba1ce52eb11a23e3a7026769dda7ce10d424621	conversational awareness in text-based computer mediated communication	8999 other information and communication services;empirical study;user needs;instant messaging;support interface;conversational dock condock;swinburne;0803 computer software;school of engineering and science;interface design;group communication;multiple concurrent conversations;turn taking;computer mediated communication;conversational context;conversational awareness;respubid17114;instant messenger;geographic distribution;relaxed instant messenger rim;text based computer mediated communication txtcmc;focus context	Text-based computer-mediated communication (TxtCMC) supports an instant exchange of messages among geographically distributed people. TxtCMC, such as Instant Messaging and chat tools, has increasingly become widespread and popular at home and at work. Supporting conversational awareness is an important aspect of TxtCMC. Conversational awareness provides a user with information about the presence and activity of others, and therefore helps to establish a context for the user’s own activity. Unfortunately, current interface design of TxtCMC provides inadequate support for conversational awareness, especially in support for awareness of turn-taking, conversational context and multiple concurrent conversations. This research aims to address these three issues by (1) conducting an empirical study to identify the user need for conversational awareness and (2) designing an interface to support this type of awareness. This chapter presents two innovative prototypes, namely Relaxed Instant Messenger (RIM) and Conversational Dock (ConDock). RIM integrates a sequential interface with an adaptive threaded interface to support awareness of turn-taking and conversational context. ConDock adopts a focus + context visualisation technique to support awareness of multiple conversations. The evaluations of the two prototypes show that they meet their design objectives and were found useful in enhancing group communication.	computer-mediated communication;text-based (computing)	Minh Hong Tran;Yun Yang;Gitesh K. Raikundalia	2009		10.1007/978-1-84882-477-5_13	human–computer interaction;computer science;multimedia;communication	HCI	-55.07103447209062	-43.90912491078288	186922
88101325d90b1324204db32c4e628a3a3b5eed53	generalization of tooltips: an assistive technology extension		Software applications use tooltips to assist users to improve their understanding of icons. When hovering over an icon with the cursor, a short text description of the icon appears. Textbased tooltips are helpful for users without any literacy limitations. An extension was created to generalize tooltips for users with low text literacy. In this case study and to explore such generalization, video based tooltips show short South African Sign Language clips to assist those who use South African Sign Language as a first language. When the user hovers over an icon, a video appears with a short description of the icon in South African Sign Language. As a way to abstract tooltips, audio-based tooltips have also been developed, for users with language barriers, reading disabilities and those who are visually impaired. When hovering over an icon, a short audio description of the icon plays. Both audio and South African Sign Language video based tooltips have been pre-recorded. Through a web extension, users are able to select a tooltip preference for their Mozilla Firefox Browser for audio-based or video-based tooltips.		Saira-Banu Adams;William David Tucker;Isabella Margarethe Venter	2017		10.1007/978-3-319-71084-6_24	language barrier;first language;human–computer interaction;literacy;sign language;software design;audio description;icon;tooltip;computer science	HCI	-49.538756620284246	-44.17705522131943	187041
5020f4ae60a77fe00745655fe91159cc39ff2552	virtual and tangible user interfaces for social and accessible pervasive gaming	user interface development;physical impairment;tangible user interface;physical activity;pervasive game;assistive technology;talk	Nowadays, more advanced multimedia and feedback tools and assistive technologies enable enhanced gaming experiences. However, many publishers in the gaming market prefer to stay mainstream resulting in a limited variety of gaming experiences available to physically impaired gamers. This is especially the case for physically impaired gamers experiencing some social digression when playing computer games or complex physical games. We describe a simple pervasive gaming approach using tangible user interfaces developed in-house that involves both physical and virtual experiences. In real world, playing board games may be hard, tiring or perhaps impossible for disabled people. The challenge of our work is to allow for supplementing physical activities on such games using enhanced interface technologies.	assistive technology;experience;gaming computer;pc game;pervasive informatics;tangible user interface	Wendy Ann Mansilla;Andreas Schrader;Sönke Dohrn;Alma Salim	2006			user interface design;human–computer interaction;multimedia;natural user interface;user interface;world wide web	HCI	-51.61766607132688	-39.93074195076221	187196
f1fbbdcd1da05499a87e6ca98db9f5f5f23d4daf	modeling internet as a user-adapted speech service	voicexml;neural networks;internet modeling;speech interaction;conversational agents;multimodality;xhtml voice	The web has become the largest repository of multimedia information and its convergence with telecommunications is now bringing the benefits of web technology and hybrid artificial intelligence systems to hand-held devices. However, maximizing accessibility is not always the main objective in the design of web applications, specially if it is concerned with facilitating access for disabled people. This way, natural spoken conversation and multimodal conversational agents have been proposed as a solution to facilitate a more natural interaction with these kind of devices. In this paper, we describe a proposal to provide spoken access to Internet information that is valid not only to generate basic applications (e.g., web search engines), but also to develop dialog-based speech interfaces that facilitate a user-adapted access that enhances web services. We describe our proposal and detail several applications developed to provide evidences about the benefits of introducing speech to make the enormous web content accessible to all mobile phone users.		David Griol;Javier Ignacio Carbó Rubiera;José M. Molina López	2012		10.1007/978-3-642-28942-2_5	web service;web application security;web development;web modeling;speech recognition;web design;web accessibility initiative;web standards;computer science;machine learning;multimedia;web intelligence;web engineering;world wide web;artificial neural network	Web+IR	-49.875774489608204	-39.34046229593789	187824
00fc80678ce9f3c4cce54a591d5d982fd6c233f4	identifying the space buddies to track lost items		Locating missing or lost objects has always been a challenging task. RFID technology and participatory sensing based approaches have offered solutions but often their adoption was limited due to the high hardware costs or low active participation problem. With the introduction of iBeacon technology and smartphones having BLE capability, tracking such objects has become easier and cost-effective. Objects of care are labeled by attaching to them affordable iBeacon tags, and smartphones in the proximity of these tags sense their presence opportunistically through the applications running in the background. In this paper, we study the tracking of lost objects through the collaboration among users. We analyze the visit patterns of users at the same locations and develop a metric that quantifies for each user the potential benefit of others in terms of their capability of finding that user's lost objects. Depending on the predicted benefits, each user's preference list of other users is formed and then utilized to identify the space buddies who can best track her lost items. The identification is based on the adaption of the solution to the roommate matching problem. We apply the proposed system to two different location based social network datasets and show its effectiveness in different settings.	aggregate data;algorithm;ibeacon;internet privacy;matching (graph theory);participatory sensing;radio-frequency identification;simulation;smartphone;social network	Eyuphan Bulut;Boleslaw K. Szymanski	2017		10.1145/3055601.3055611	simulation;computer hardware;engineering;advertising	HCI	-52.24087560331737	-42.51402086952688	187856
19e52e256b4bae852dc5acfff2755784a65b4559	mobilesens: a ubiquitous psychological laboratory based on mobile device	mobile device;android;psychological research;general packet radio service gprs;behavior logger;mobilesens	In psychological research, it is difficult to acquire unintrusive, real-time and objective data under real-life non-experimental scenario. This article proposes a system (MobileSens) for automatically recording user behavior on Android mobile device (e.g., turning on device, sending messages, and web surfing), and uploading data to web server through General Packet Radio Service (GPRS) for subsequent analysis. During testing, MobileSens runs smoothly and efficiently on both the smartphone and tablet computer. It indicates that, in the future, this method of data acquisition can improve the performance of conducting psychological research.	android;data acquisition;download;mobile device;real life;real-time locating system;server (computing);smartphone;smoothing;tablet computer;upload;web server;world wide web	Ang Li;He Li;Rui Guo;Tingshao Zhu	2013	IJCBPL	10.4018/ijcbpl.2013040104	embedded system;engineering;world wide web;computer security	HCI	-53.11604131106564	-42.86531179047229	187992
c5bc070400fbcfaa0617f308e08b9f41a0648bd9	a novel obsolescence-based approach to event delivery synchronization in multiplayer games	multiplayer game	Revenues generated by video games typically surpass those provided by the cinematography industry. This large and emerging market is driving researchers and practitioners to develop innovative software techniques that allow game players to enjoy exciting and interactive game experiences, even when modern wireless handheld devices are used. In this scenario, there is a growing demand of distributed gaming architectures that are able to provide support to the development of interactive multiplayer networked game applications. To this aim, we have designed and developed an event delivery service for multiplayer networked games that drops obsolete events to guarantee an acceptable interaction degree among remote players, while maintaining the game state consistency. We report important results of an experimental study we have carried out that confirm the viability of our approach.		Stefano Ferretti;Marco Roccetti	2004	Int. J. Intell. Games & Simulation		game design;simulation;computer science;game mechanics;game developer;multimedia;video game development	Logic	-53.76631638039881	-42.802216609102764	188028
99bb2f172cddec95f27eeea629c792998aa54f85	reorganizing news web pages for mobile users	data intensive application;interfase usuario;text;navegacion informacion;informatique mobile;web pages;mobile device;red www;broadband network;user interface;navigation information;reseau web;information browsing;user preferences;texte;scenario;internet;argumento;comportement utilisateur;script;preferencia;world wide web;interface utilisateur;preference;user behavior;mobile computing;texto;comportamiento usuario;mobile user	Today the fastest growing communities of web users are mobile visitors who browse web pages using wireless PDAs and cellular phones. However, most web pages are optimized exclusively for desktop clients on the broadband network and are inconvenient to users with small screen mobile devices. They display only a few lines of text and cannot run client-side programs or scripts due to lack of system resources. Even worse, their connections are usually too slow to support most of the data-intensive applications. To address this problem, in this paper, we propose a news let scheme that makes it feasible to browse ordinary news web pages on small screen mobile devices. It first extracts news sections of user preference from news web pages and then automatically reorganizes them for convenient browsing on the mobile devices.	web page	Woncheol Kim;Eenjun Hwang;Wonil Kim	2003		10.1007/978-3-540-24580-3_30	web service;static web page;mobile search;the internet;mobile web;human–computer interaction;computer science;artificial intelligence;scenario;operating system;web navigation;web page;mobile device;database;distributed computing;multimedia;user interface;mobile computing;world wide web;computer security;broadband networks	HCI	-50.871017664720256	-41.3537169292249	188931
453bbca09d409cb5421656eac0e33fce8d7e8bec	a study of developing auditory icons for mobile phone service applications in taiwan region	mental models;metaphor;auditory icon	Mobile technology advancements incite expansive opportunity spaces in value-added services to users. This however also introduces critical user experience problems (visual occlusion/clutter). Dynamic contexts of use of mobile phones and diverse functionalities compete for users' visual attention. Interaction designers might need to rethink the design and evaluation of such user interface types. The present study aimed to explore the possible design concepts and rationales of auditory icons for mobile phone service applications in Taiwan region.	clutter;interaction design;mobile phone;user experience;user interface	Jiunde Lee;Yu-ning Chang	2013		10.1145/2493190.2494441	simulation;human–computer interaction;multimedia	HCI	-53.05056131729574	-38.90211071303261	189276
5e798b65eabb371ef065f0917b4e92a454f9ac4f	electric agents: combining television and mobile phones for an educational game	mobile device;mobile phone;educational games;educational game;pervasive game;mobile phones;augmented reality;interactive television;cross media;mobile augmented reality;pervasive games	"""Electric Agents is a cross-media game that presents new ways for children to actively engage with television content. In the game Manny, a member of the Pranksters, steals words out of the mouth of Hector, a member of The Electric Company team, and hides them to prevent the story from progressing. Children collaborate through a mobile augmented reality experience to find and collect the missing vocabulary words relevant to the show narrative. The players return the stolen words back to the show by """"throwing"""" the words towards the television using their mobile devices. This blend of a narrative and a game strives to make educational television content more engaging and participatory while fostering collaborative play and use of specific vocabulary words."""	augmented reality;hector;mobile device;mobile phone;television;vocabulary	Rafael Ballagas;Glenda Revelle;Kyle Buza;Hiroshi Horii;Koichi Mori;Hayes Raffle;Mirjana Spasojevic;Janet Go;Kristin Cook;Emily Reardon;Yun-Ta Tsai;Christopher Paretti	2011		10.1145/1999030.1999068	game design;simulation;engineering;game developer;multimedia;advertising;video game development	HCI	-54.73148889818132	-41.08388300188784	189506
2a68acc880e6ee01732d0fb00da0f8e442026fb8	research on car gesture interaction design based on the line design		There are a series of problems in the interaction design of car gestures, such as the weak consistency of interior interaction and external modeling, and the less contact between gesture design and cultural perceptual factors. In order to solve the above problems, from the perspective of feature line design, user experience experiment is used to extract the long path and short path features of car gesture interaction. According to these characteristics, combining with the knowledge of car modeling feature lines and the rules of line design in Chinese calligraphy, a HUD map display gesture application is designed for the target car based on the service design rule. The preliminary evaluation results show that the design method can improve the user’s interest and pleasure, and is helpful to the integrity and consistency of car design.	interaction design	Jing Chunhui;Jing Zhang	2017		10.1007/978-3-319-57931-3_50	simulation;pleasure;weak consistency;service design;experience design;user experience design;interaction design;gesture;computer science	HCI	-52.67425322450536	-40.57113849675533	190146
281d978d53e7fb2c88c5cccef041c53eadbce5e8	visualizing vocal expression	speech;voice;visualization;communication	Sound, especially speech, is ephemeral. It is a high-speed, ordered, multichannel stream that plays for a time, and leaves shadows of its presence in our memories. When we communicate, we exchange semantic, expressive, and relational messages. Most of our communicative power lies outside semantics, yet these expressive and relational exchanges are underexplored. We and others have experimented with visual representations of speech, yet little is known about the interpretability, usability, and efficacy of the visualizations; here we focus on interpretability. We provide a system for expressive vocal analysis, new voice visualizations which map vocal parameters to different designs, and a study focusing on the interpretability of the resulting voice visualizations.	usability	Mary Pietrowicz;Karrie Karahalios	2014		10.1145/2559206.2581331	natural language processing;speech recognition;visualization;computer science;speech;voice	HCI	-51.886471302537544	-44.866999272066714	190192
32134ea421341570d31d5f2663340ca31664f1ca	mobile devices in emergency medical services: user evaluation of a pda-based interface for ambulance run reporting	user evaluation;mobile device;usability study;medical care;first responder;emergency medical service;mobile systems;mobile application	The design of easy-to-use mobile systems for collecting and handling emergency medical care data in the field can significantly improve the effectiveness of rescue operations. In particular, this paper focuses on the design and evaluation of a mobile application that replaces ambulance run paper sheets. First, we discuss the limitations of traditional ambulance run paper sheets. Then, we present the PDA-based system we have developed. Finally, we discuss in detail the usability study we have carried out with first responders.	mobile app;personal digital assistant;usability testing	Luca Chittaro;Francesco Zuliani;Elio Carchietti	2007		10.1007/978-3-540-75668-2_3	simulation;engineering;medical emergency;mobile computing;computer security	HCI	-50.710492089083466	-42.4605889077708	191858
35afbba780a2b2886d6f270ffae72f1308cf745c	on the choice of transducer technologies for specific musical functions	input device;sound synthesis;real time;exploratory analysis;user testing;gestural control	This paper presents a study of gestural control applied to sound synthesis. It discusses an implementation of realtime gestural control of the CHANT software (Max/MSP). The input device consists of a Wacom graphic tablet instrumented with additional sensors. A study has been carried out on the selection of transducer technologies to match the available synthesis parameters, based on existing literature. In order to prove the validity of previous studies, different user tests have been devised and implemented. User reactions were annotated and further evaluated. An exploratory analysis of the tests’ results is presented which tends to validate previous works.	graphics tablet;input device;max;sensor;tablet computer;transducer	Marcelo M. Wanderley;Jean-Philippe Viollet;Fabrice Isart;Xavier Rodet	2000			speech recognition;acoustics;engineering;communication	HCI	-48.283040835251036	-44.417948285328336	192353
f20c37e64a170f8819a6a5daccea63f59367383f	surveying user reactions to recommendations based on inferences made by face detection technology		It is increasingly possible to use cameras and sensors to detect and analyze human appearance for the purposes of personalizing user experiences. Such systems are already deployed in some public places to personalize advertisements and recommend items. However, since these technologies are not yet widespread, we do not have a good sense of users' perceptions of the benefits and drawbacks of public display systems that use face detection as an input for personalized recommendations. We conducted a user study with a system that inferred participants' gender and age from a facial detection and analysis algorithm and used this to present recommendations in two scenarios (finding stores to visit in a mall and finding a pair of sunglasses to buy). This work provides an initial step towards understanding user reactions to a new and emerging form of implicit recommendation based on physical appearance.	algorithm;face detection;personalization;recommender system;sensor;usability testing	Jennifer Marlow;Jason Wiese	2017		10.1145/3109859.3109875	human physical appearance;face detection;personalization;data mining;computer science;facial recognition system;multimedia	HCI	-52.29471515507843	-42.506091243843805	192637
66c4d2c0eece8ac29755df62b321eb39749461ee	touch proxy interaction	face to face interactin;haptics;tangible interface;behavior change;cscw;group decision making;face to face;interaction design;tangible interfaces;haptic interaction	The purpose of this research is to build and evaluate collaborative touch devices that influence behavior change over individuals in small group situations. This paper presents touch proxy objects for collocated collaboration and communication. Touch proxy objects afford and represent touch in order to allow the sense of touch to be shared between people. This paper presents preliminary observations from studies performed on existing touch communication objects.		Angela Chang	2008		10.1145/1358628.1358740	group decision-making;human–computer interaction;computer science;interaction design;computer-supported cooperative work;behavior change;multimedia;haptic technology	HCI	-54.36425483058385	-43.78477276584202	193181
1fa5299487417df3bdbbf2b2d8dc51618895323d	pervasive gaming: status, trends and design principles	context awareness;pervasive computing;localization;gaming;game space visualization;orchestration	Pervasive games represent a radically new game form that transfers gaming experiences out into the physical world, weaving ICTs into the fabric of players׳ real environments. This emerging gaming mindset is rather challenging for developers exploring technologies and methods to achieve a high quality interactive experience for users, and designing novel and compelling forms of content. This paper follows a systematic approach in exploring the landscape of pervasive gaming. First, we present 18 representative pervasive game projects, following a generations-based classification. Then, we present a comparative view of those projects with respect to several design aspects. Lastly, we shed light on technological status and trends, design principles, developer guidelines, and research challenges for pervasive games development.	pervasive informatics	Vlasios Kasapakis;Damianos Gavalas	2015	J. Network and Computer Applications	10.1016/j.jnca.2015.05.009	context-aware pervasive systems;simulation;internationalization and localization;human–computer interaction;computer science;multimedia;orchestration;computer security;ubiquitous computing	Arch	-55.33660076812496	-38.20949735203946	193545
55ebecbb2f1aba90f085acff4ff3cec2dda0e577	making joining easy: case of an entertainment club website	usability testing;user interface;visual design;check out process;interface design;performance metric;website;marketing;shopping cart;music club;user experience;user testing;online advertising;visual systems;interaction model;user research;registration process;performance metrics;visual system;interaction design;joining club	The goal of this project was to design a site that would make the online process of joining the Columbia House Music or DVD club faster and easier. Faced with low conversion rates from online advertising, our challenge was to quickly solve the main problems with the existing join process, which were identified through user testing and site data logs.In response we designed a separate mini-site that reduced the entire process to 3 steps (and as many pages). The Club-based ecommerce experience is unique: the number of products a user selects is fixed, allowing us to implement a unique and transparent interaction model for the shopping cart design.The project was extremely successful. Conversion rates increased 180%. The design work for this project then set direction for subsequent visual and interface design projects for Columbiahouse.com.	columbia (supercomputer);e-commerce;online advertising;usability testing	Dena Fletcher;Annette Brookman	2002		10.1145/507752.507755	user experience design;online advertising;simulation;visual system;human–computer interaction;computer science;interface design;operating system;interaction design;multimedia;user interface;world wide web	HCI	-51.23186467870158	-39.43840426235336	193668
5813ac483484e60c698959e0c0328c2a5342013a	characterizing user behavior for speech and sketch-based video retrieval interfaces		"""From a user interaction perspective, speech and sketching make a good couple for describing motion. Speech allows easy specification of content, events and relationships, while sketching brings in spatial expressiveness. Yet, we have insufficient knowledge of how sketching and speech can be used for motion-based video retrieval, because there are no existing retrieval systems that support such interaction. In this paper, we describe a Wizard-of-Oz protocol and a set of tools that we have developed to engage users in a sketch- and speech-based video retrieval task. We report how the tools and the protocol fit together using \""""retrieval of soccer videos\"""" as a use case scenario. Our software is highly customizable, and our protocol is easy to follow. We believe that together they will serve as a convenient and powerful duo for studying a wide range of multi-modal use cases."""		Ozan Can Altiok;T. Metin Sezgin	2017		10.1145/3092919.3122801	computer vision;artificial intelligence;human–computer interaction;expressivity;software;computer science;sketch;use case;multimedia;user-centered design	HCI	-49.64668607354541	-43.103756803659614	193772
0739801afe29883d42fe7e43d492c3bec8ce78c2	designing shared gaze awareness for remote collaboration	computer supported collaborative work;design;eye tracking	In this project, we evaluate two different methods for highlighting shared gaze across two tasks with different collaborative properties. There are many factors to consider when designing shared gaze representations such as how much information to display and when to provide it so that it will be most useful. Unlike other non-verbal forms of communication such as deictic gesturing, gaze is not always intentionally communica-tive and therefore we need to think critically about when and how to display it. For each task, participants saw their partnerâ  s gaze displayed continuously, em-phasized either by previous fixation points or extended fixations. We discuss our findings and present design implications for shared gaze awareness based on inter-action traces and interviews with participants.		Jerry Li;Mia E. Manavalan;Sarah D'Angelo;Darren Gergle	2016		10.1145/2818052.2869097	psychology;computer vision;design;human–computer interaction;eye tracking;computer science;communication;management	HCI	-54.56474878286217	-44.027933649908576	194027
5a3dac7a91d4babc1be0916e8bad840dec5e8619	wise mobile icons organization: apps taxonomy classification using functionality mining to ease apps finding		Nowadays, every user has dozens of Apps on her/his mobile device. As time passes, it becomes increasingly difficult simply to find the desired App among those installed on the mobile device and launch it. In spite of several attempts to address this challenge, no good solution for this growing problem has yet been found. In this paper, we examine the idea of classifying Apps based on their functionality to allow users to find and access them easily. An App’s functionality is elicited from the textual description of the App, as retrieved from the App store, and enriched by content from additional online publications. The functional representation is then classified into classes and mapped into personal categories using functional hierarchical compact taxonomies that can be easily presented on the small screen of a mobile device. Experiments and user studies demonstrated the potential of this approach.		David Lavid Ben Lulu;Tsvi Kuflik	2016	Mobile Information Systems	10.1155/2016/3083450	embedded system;computer science;multimedia;mobile deep linking;internet privacy;world wide web;computer security	Mobile	-51.15758991975562	-41.42203986842412	194040
5d5486448a755d4c40025c72db22edc1c53fdc02	socio-technical environments supporting people with cognitive disabilities using public transportation	ubiquitous and pervasive computing;context aware computing;empirical study;universal design;user models;context aware;human computer interaction;complex;universal access;collaborative work;human centered transportation;public transport;socio technical systems;pervasive computing;real time;socio technical system;global position system;large scale system;dual use technologies;transport system;wireless communication;support system;monitoring system;prototyping;complex system;public transportation system;just in time;participatory design;social creativity;mobile agent;mobility agents;distributed cognition;assessment;national research council;user model;urban transport;active distributed support systems;cognitive disabilities	Public transportation systems are among the most ubiquitous and complex large-scale systems found in modern society. For those unable to drive such as people with cognitive disabilities, these systems are essential gateways for participation in community activities, socialization, and independence. To understand the magnitude and scope of this national problem, we highlight deficiencies identified in an international study by the Transportation Research Board of the National Research Council and present specific cognitive barriers identified in empirical studies of transportation systems in several U.S. cities.An interdisciplinary team of HCI researchers, urban transportation planners, commercial technologists, and assistive care specialists are now collaborating on the Mobility-for-All project to create architectures and prototypes that support those with cognitive disabilities and their caregivers. We have grounded our research and design efforts using a distributed cognition framework. We have derived requirements for our designs by analyzing “how things are” for individuals with cognitive disabilities who learn and use public transportation systems. We present a socio-technical architecture that has three components: a) a personal travel assistant that uses real-time Global Positioning Systems data from the bus fleet to deliver just-in-time prompts; b) a mobile prompting client and a prompting script configuration tool for caregivers; and c) a monitoring system that collects real-time task status from the mobile client and alerts the support community of potential problems. We then describe a phased community-centered assessment approach that begins at the design stage and continues to be integrated throughout the project.This research has broad implications for designing more human-centered transportation systems that are universally accessible for other disenfranchised communities such as the elderly or nonnative speaker. This project presents an “in-the-world” research opportunity that challenges our understanding about mobile human computer interactions with ubiquitous, context-aware computing architectures in noisy, uncontrolled environments; personalization and user modeling techniques; and the design of universally accessible interfaces for complex systems through participatory design processes.This article provides both a near-term vision and an architecture for transportation systems that are socially inclusive, technologically appealing, and easier for everyone to use.	cognitive tutor;complex systems;computer accessibility;context awareness;distributed cognition;emoticon;global positioning system;human computer;human–computer interaction;information technology architecture;personalization;real-time transcription;requirement;socialization;sociotechnical system;uncontrolled format string;user modeling	Stefan Carmien;Melissa Dawe;Gerhard Fischer;Andrew Gorman;Anja Kintsch;James F. Sullivan	2005	ACM Trans. Comput.-Hum. Interact.	10.1145/1067860.1067865	complex systems;simulation;universal design;human–computer interaction;computer science;knowledge management;ubiquitous computing	HCI	-53.18048220784609	-40.2146252055169	194057
ffb033c9061a2c93eee9f352dbf20a657441d61d	an information retrieval system for supporting casual conversation in wearable computing environments	content management;internet information retrieval system wearable computing speech recognition conversation content;information retrieval system;information retrieval;auxiliary information;internet;speech recognition ubiquitous computing information retrieval systems internet content management interactive systems;information retrieval systems;speech recognition;ubiquitous computing;wearable computer;interactive systems;information retrieval wearable computers humans computer displays application software speech recognition information analysis content based retrieval internet microcomputers	In the future, wearable computers are going to be exploited for different applications to support human life. In this paper, we present a new wearable computing system that supports daily conversation based on speech recognition and information retrieval technologies. In daily conversation, sometimes we do not know the meaning of a new word or we want to know more information about a topic. In such cases, we can get more information to make our conversation more interesting and fluent by receiving auxiliary information from a wearable computer. The proposed system analyzes conversation content and retrieves information related to ongoing conversations from the Internet to make them more interesting and beneficial. We have implemented a prototype system, and the results of actual use have shown the need for such a system.	experiment;information retrieval;internet;protologism;prototype;real-time transcription;speech recognition;wearable computer	Nga Viet Pham;Tsutomu Terada;Masahiko Tsukamoto;Shojiro Nishio	2005	25th IEEE International Conference on Distributed Computing Systems Workshops	10.1109/ICDCSW.2005.36	the internet;wearable computer;cognitive models of information retrieval;content management;computer science;multimedia;world wide web;ubiquitous computing;information retrieval;human–computer information retrieval	Robotics	-49.59513888181322	-38.72803923009018	194650
be0d524665214b40d0ce6f26cd3038f112783358	how to address smart homes with a social robot? a multi-modal corpus of user interactions with an intelligent environment		In order to explore intuitive verbal and non-verbal interfaces in smart environments we recorded user interactions with an intelligent apartment. Besides offering various interactive capabilities itself, the apartment is also inhabited by a social robot that is available as a humanoid interface. This paper presents a multi-modal corpus that contains goal-directed actions of naive users in attempts to solve a number of predefined tasks. Alongside audio and video recordings, our data-set consists of large amount of temporally aligned sensory data and system behavior provided by the environment and its interactive components. Non-verbal system responses such as changes in light or display contents, as well as robot and apartment utterances and gestures serve as a rich basis for later in-depth analysis. Manual annotations provide further information about meta data like the current course of study and user behavior including the incorporated modality, all literal utterances, language features, emotional expressions, foci of attention, and addressees.	cognitive science;intelligent environment;interaction design;literal (mathematical logic);modal logic;modality (human–computer interaction);robotics;smart environment;social robot;streaming media;temporal logic	Patrick Holthaus;Christian Leichsenring;Jasmin Bernotat;Viktor Richter;Marian Pohling;Birte Carlmeyer;Norman Köster;Sebastian Meyer zu Borgsen;René Zorn;Birte Schiffhauer;Kai Frederic Engelmann;Florian Lier;Simon Schulz;Philipp Cimiano;Friederike Eyssel;Thomas Hermann;Franz Kummert;David Schlangen	2016			social robot;natural language processing;artificial intelligence;robot;emotional expression;metadata;multimedia;computer science;smart environment;gesture;intelligent environment	Robotics	-50.077724327609275	-43.559299849635075	194686
2f1be25f5674f6a07741ce1d16e4d488339e217a	webhelpdyslexia: a browser extension to adapt web content for people with dyslexia	acessibilidade na web;dyslexia;web accessibility;artigo;dislexia	The Web is an essential resource widely used by many organizations, affecting the lives of countless people. Thus, it is essential to ensure that Websites are accessible in order for people with disabilities to enjoy all its benefits. Many studies have been dedicated to investigate Web accessibility issues for users with visual or motor disabilities. However, comparatively fewer studies have addressed accessibility for users with specific learning difficulties such as dyslexia. Furthermore, few tools provide support for dyslexic users during reading and browsing in Web content. The present study involved the design and implementation of a prototype extension for a Web browser that offers customization features of Web pages, based on requirements from problems encountered by users with dyslexia in related studies in the literature. The research involved the design, implementation and a preliminary user evaluation involving users with dyslexia in two iterative cycles. The implemented prototype included features to adjust layout characteristics of text and other features identified by means of feedback from users to aid concentration and dealing with difficult words, such as a “reading ruler”. The results obtained from this study highlighted the importance of providing further support in user agents to help dyslexic users and provide tools to help with linguistic issues. © 2015 The Authors. Published by Elsevier B.V. Peer-review under responsibility of organizing committee of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2015).	browser extension;carpal tunnel syndrome;color;download;iterative method;organizing (structure);prototype;requirement;software development;speech synthesis;usb decoration;usability;user agent;web accessibility;web content;web page;world wide web	Luis Otávio de Avelar;Guilherme Camillo Rezende;André Pimenta Freire	2015		10.1016/j.procs.2015.09.259	dyslexia;web development;web modeling;web design;human–computer interaction;web accessibility initiative;web standards;computer science;web navigation;web accessibility;data mining;multimedia;world wide web	HCI	-51.72406488561551	-41.45908794782988	195853
b485cb6dcc45604dc1defec38943f2ce7ec77833	va2: a visual analytics approach for evaluating visual analytics applications	time series data visual analytics qualitative evaluation thinking aloud interaction logs eye tracking;interaction logs;female;protocols;computer graphics;male;gaze tracking;navigation;eye interaction thinking pattern va2 approach visual analytics approach visual analytics applications visualization research human computer interaction eye tracking data analysis concurrent evaluation procedure;synchronization;adult;eye movements;data visualization;data visualization protocols gaze tracking synchronization navigation visual analytics;time series data;thinking aloud;humans;human computer interaction data analysis data visualisation;user computer interface;eye tracking;young adult;visual analytics;task performance and analysis;qualitative evaluation	Evaluation has become a fundamental part of visualization research and researchers have employed many approaches from the field of human-computer interaction like measures of task performance, thinking aloud protocols, and analysis of interaction logs. Recently, eye tracking has also become popular to analyze visual strategies of users in this context. This has added another modality and more data, which requires special visualization techniques to analyze this data. However, only few approaches exist that aim at an integrated analysis of multiple concurrent evaluation procedures. The variety, complexity, and sheer amount of such coupled multi-source data streams require a visual analytics approach. Our approach provides a highly interactive visualization environment to display and analyze thinking aloud, interaction, and eye movement data in close relation. Automatic pattern finding algorithms allow an efficient exploratory search and support the reasoning process to derive common eye-interaction-thinking patterns between participants. In addition, our tool equips researchers with mechanisms for searching and verifying expected usage patterns. We apply our approach to a user study involving a visual analytics application and we discuss insights gained from this joint analysis. We anticipate our approach to be applicable to other combinations of evaluation techniques and a broad class of visualization applications.	algorithm;digital humanities;evaluation method;exploratory search;eye movements;eye tracking;gain;grams;hl7 data type;human–computer interaction;imagery;interactive visualization;longest common substring problem;microsoft word for mac;modality (human–computer interaction);multi-source;n-gram;numerous;protocols documentation;source data;think aloud protocol;united states department of veterans affairs;usability testing;verification and validation;verifying specimen;visual analytics;gram	Tanja Blascheck;Markus John;Kuno Kurzhals;Steffen Koch;Thomas Ertl	2016	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2015.2467871	think aloud protocol;communications protocol;synchronization;computer vision;analytics;navigation;visual analytics;young adult;human–computer interaction;eye tracking;interactive visual analysis;computer science;time series;data mining;multimedia;cultural analytics;computer graphics;data visualization;statistics;eye movement	Visualization	-50.47539283548685	-43.661114551467584	195912
40b7cd5e7b44f8791e8c55d89b53eeb783a3a47a	the role of human web assistants in e-commerce: an analysis and a usability study	user modelling;electronic commerce;human computer interaction;computacion informatica;usability study;e commerce;digital library;user study;user studies;field trial;customer service;engineering and technology;teknik och teknologier;user satisfaction information;ciencias basicas y experimentales;world wide web;grupo a;computer attitudes;man machine systems;flexibility;home automation	Electronic commerce has recently shown enormous potential to take over a significant share of the sales market. There is a need to provide services that can reach individual computer users with different information profiles and levels of expertise. In this article the concept of Web assistants, human assistants working in an electronic Web shop, is presented. This human-computer collaboration provides intelligent and adaptive services via an integrated communication media. A prototype of a Web assistant system has been implemented. While browsing through the system the user can call for human assistance should the need arise. Presents the results of a usability study performed on the prototype system. Recent commercial moves in the direction discussed in this article increase the importance of the usability study. The results are encouraging, especially when it comes to the attitude aspects of usability. The subjects were extremely enthusiastic about the concept of Web assistants and its implications. The human Web assistant who participated in the field trial highlighted the importance of user modelling. Although the system is mainly in the context of electronic commerce, it can be used in many other contexts. These include home automation, digital libraries, and technical support, to name a few.	berg connector;customer support;dialog system;digital library;e-commerce;extensibility;handy board;home automation;information needs;internet research;library (computing);online chat;prototype;quality of service;requirement;routing;technical support;usability testing;user (computing);user modeling;world wide web	Johan Aberg;Nahid Shahmehri	2000	Internet Research	10.1108/10662240010322902	e-commerce;usability goals;web usability;home automation;usability;human–computer interaction;computer science;marketing;usability engineering;multimedia;web engineering;world wide web;computer security;usability lab;usability inspection	HCI	-52.030806189589214	-40.2421075560752	195939
9f7081c3f18151e758d60d9ee72fda34a8116d8b	virtual, augmented and mixed reality. applications of virtual and augmented reality	urban planning;geo elearning;augmented realitye learninggeo e learningurban planningeducational research;educational research;conference report;e learning;augmented reality;article	In this paper we propose a novel interaction technique that creates the illusion of tactile exploration of museum artefacts which are otherwise impossible to touch. The technique meets the contextual necessity, often requested by museum curators, to background technology and to direct the focus of the museum visitor’s experience to the artefact itself. Our approach relies on the combination of haptic interaction and the adaptation of a well-known illusion that enables museum visitors to make sense of the actual physical non-touchable artefact in an embodied way, using their sensory and motor skills. We call this technique Haptic Augmented Reality.	augmented reality;haptic technology;interaction technique;mixed reality;visual artifact	Janina Puig;David Fonseca;Sergi Villagrasa	2014		10.1007/978-3-319-07464-1	augmented reality;simulation;educational research;human–computer interaction;computer science;operating system;urban planning;database;multimedia	HCI	-53.75872480894048	-38.418017392742875	196240
f3bb54117c5bcf34a36077277b81a4a713f92a82	using eye-tracking for enhancing the museum visit experience	mobile eye tracking;context aware service;mobile guide;personalized information;smart environment	A smart context-aware mobile guide may provide the visitor with personalized relevant information from the vast amount of content available at the museum, adapted for his or her personal needs. Earlier studies relied on using sensors for location-awareness and interest detection. This work explores the potential of mobile eye-tracking and vision technology in enhancing the museum visit experience. We report here on satisfactory preliminary results from examining the performance of a mobile eye tracker in a realistic setting.	eye tracking;location awareness;personalization;sensor	Moayad Mokatren;Tsvi Kuflik;Ilan Shimshoni	2016		10.1145/2909132.2926060	simulation;human–computer interaction;computer science;multimedia;smart environment;world wide web	HCI	-53.8727864416838	-42.13235269857502	196324
ca118384f01abd84e2b15fe42e4bec9320f5c0f0	a multitask grocery assist system for the visually impaired: smart glasses, gloves, and shopping carts provide auditory and tactile feedback		"""According to the World Health Organization, """"285 million people are estimated to be visually impaired worldwide"""" [1]. Several technologies such as automatic text readers, Braille note makers, and navigation assistance canes have been developed to assist the visually impaired. Concurrent advances in computer vision and hardware technologies provide opportunities for a visual-assistance system that can be used in multiple contexts. As part of the Visual Cortex on Silicon program, we have been developing interfaces, algorithms, and hardware platforms to assist the visually impaired with a focus on grocery shopping. This article describes the various features that we have incorporated into this visual-assistance system so that it can be used in multiple contexts."""	algorithm;computer multitasking;computer vision;smart tv;smartglasses;wired glove	Siddharth Advani;Peter A. Zientara;Nikhil Shukla;Ikenna Okafor;Kevin M. Irick;Jack Sampson;Suman Datta;Narayanan Vijaykrishnan	2017	IEEE Consumer Electronics Magazine	10.1109/MCE.2016.2614422	embedded system;simulation;multimedia	ML	-48.748555441311986	-42.24555764943687	197040
44a41cdc17ee9d97570c808747826b69ba78e1f0	multi-viewer gesture-based interaction for omni-directional video	user defined gestures;proceedings paper;gesture elicitation;multi user interaction;omni directional video	Omni-directional video (ODV) is a novel medium that offers viewers a 360º panoramic recording. This type of content will become more common within our living rooms in the near future, seeing that immersive displaying technologies such as 3D television are on the rise. However, little attention has been given to how to interact with ODV content. We present a gesture elicitation study in which we asked users to perform mid-air gestures that they consider to be appropriate for ODV interaction, both for individual as well as collocated settings. We are interested in the gesture variations and adaptations that come forth from individual and collocated usage. To this end, we gathered quantitative and qualitative data by means of observations, motion capture, questionnaires and interviews. This data resulted in a user-defined gesture set for ODV, alongside an in-depth analysis of the variation in gestures we observed during the study.	3d television;motion capture;ocean data view	Gustavo Rovelo;Davy Vanacken;Kris Luyten;Francisco Abad;Emilio Camahort	2014		10.1145/2556288.2557113	simulation;gesture recognition;multimedia	HCI	-54.47517580179085	-42.21369426919604	197109
6b2598c04ad7539a720500b9e8213640ac257b41	exploring the role of ten universal values in using products and services	user values;user experience;empirical studies in hci;value sensitive design;hci design and evaluation methods		list of google products	Timo Partala;Sari Kujala	2016	Interacting with Computers	10.1093/iwc/iwv007	user experience design;human–computer interaction;computer science;knowledge management;multimedia	NLP	-54.673543441304524	-38.722851142990095	197174
fdfb51c8c5c40dda9be10ab6fa0565ca2e05b583	game design: motivation for mobile gaming created by new technologies	game design	Humans can have many different motives, e.g. pleasure and challenge, to play games. Rapidly evolving technologies in mobile devices have opened a new category of mobile gaming, e.g. by directly integrating motion sensors into the mobile devices. We have examined a few new technologies and what kind of motivation can be created by them.	humans;mobile device;mobile game;sensor	Natascha Jasmin Tiotuico;Olaf Kroll-Peters;Tino Stelter;Daniel Odry	2008			asynchronous communication;computer network;mobile technology;data processing system;game developer;modular design;multimedia;system bus;game design;computer science;game design document	HCI	-54.37657607105925	-39.51435945400841	197537
94192c52c48563dd1913b602d0d3945f1e255ca7	measuring cognitive workload in non-military scenarios criteria for sensor technologies	sensor system;power plant;sensors systems;augmented cognition;application;sensor chriteria;flight control	Augmented Cognition manifesting in the DARPA project is becoming of more and more interest to non-military application areas. First areas it is going to be applied are in flight control and power plant control. Measuring cognitive workload in the context of Augmented Cognition is bound to the application of sensor technologies and frameworks which are going to be applied to users. It is necessary to make Augmented Cognition Application in non-military areas as comfortable to the user as possible as we do not want to disturb her but to support her in her tasks. In this paper we will define criteria to be considered when designing Augmented Cognition applications in non-military environments.		Jörg Voskamp;Bodo Urban	2009		10.1007/978-3-642-02812-0_36	embedded system;real-time computing;simulation;engineering;augmented cognition	HCI	-50.63661867762938	-44.84192726384656	197666
8568bbb488cd7797faad8ffcb91989dd5d251173	human-computer interaction – interact 2015		This paper presents EmbodiNet, a novel system that augments distributed performance with dynamic, real-time, hands-free control over several aspects of the musicians’ sound, enabling them to seamlessly change volume, affect reverb and adjust their mix. Musical performance is a demanding activity necessitating multiple levels of communication among its participants, as well as a certain degree of creativity, playfulness and spontaneity. As a result, distributed musical performance presents a challenging application area for the “same time/different place” category of Computer-Supported Cooperative Work (CSCW). In fact, musicians wishing to play together over a network are typically limited by tools that differ little from standard videoconferencing. Instead, we propose leveraging the technology inherent to the distributed context towards meaningfully augmenting collaborative performance. In order to do so without introducing new paradigms that may require learning or that may distract musicians from their primary task, we have designed and evaluated embodied controls that capitalize on existing interpersonal interactions. Further designed to restore the spatial properties of sound that are typically absent in the distributed context, and apply the notion of “shared space” found in CSCW research, EmbodiNet also helps confer a greater level of co-presence than standard distributed performance systems. This paper describes the implementation of EmbodiNet, along with the results of a long-term collaboration and experiment with a three-piece band. The long-term collaboration helped illustrate the benefits of augmenting an artistic form of distributed collaboration, and resulted in a system that not only helped enhance our users’ sense of enjoyment and self-expression, but one that they would also likely use in the future.	computer-supported cooperative work;emergence;human–computer interaction;real-time clock	Julio Abascal;Simone D. J. Barbosa;Mirko Fetter;Tom Gross;Philippe A. Palanque;Marco A. Winckler	2015		10.1007/978-3-319-22668-2	haptic technology;user experience design;human–computer interaction;computer science	HCI	-53.83079351361913	-44.09524489851804	197958
eaee3666c2b212213b95cfb4b86bbff9c11f0964	towards the nestore e-coach: a tangible and embodied conversational agent for older adults		The ability to engage the user in a conversation and the credibility of the system are two fundamental characteristics of virtual coaches. In this paper, we present the architecture of a conversational e-coach for promoting healthy lifestyles in older age, developed in the context of the NESTORE H2020 EU project. The proposed system allows multiple access points to a conversational agent via different interaction modalities: a tangible companion that embodies the virtual coach will leverage voice and other non-verbal cues in the domestic environment, while a mobile app will integrate a text-based chat for a ubiquitous intervention. In both cases, the conversational agent will deliver personalized interventions based on behavior change models and will promote trust by means of emotionally rich conversations.	dialog system;embodied agent;embodied cognition;mobile app;personalization;text-based (computing);wireless access point	Mira El Kamali;Leonardo Angelini;Maurizio Caon;Giuseppe Andreoni;Omar Abou Khaled;Elena Mugellini	2018		10.1145/3267305.3274188	human–computer interaction;conversation;architecture;modalities;embodied cognition;behavior change;credibility;psychological intervention;computer science;dialog system	HCI	-53.99118489068023	-42.53297248553106	198393
bd6217b3ec30610a4c6247761a7f1d87418d15db	personalized mobile multimodal services: chat project experiences	user interaction;mobile application;natural language processing;mobile user	Despite optimistic expectations, the spread of multimodal mobile applications is proceeding slowly. Nevertheless the power of new high-end devices gives the opportunity to create a new class of application with advanced synergic multimodal features. In this paper we present the results the CHAT group achieved in defining and building a platform for developing synergic mobile multimodal services. CHAT is a project co-funded by Italian Ministry of Research, aimed at providing multimodal context-sensitive services to mobile users. Our architecture is based on the following key concepts: thin client approach, modular client interface, asynchronous content push, distributed recognition, natural language processing, speech driven semantic fusion. The core of the system is based on a mix of web and telecommunication technologies. This choice proved to be very useful to create high personalized context sensitive services. One of the main features is the possibility to push appropriate contents on the user terminal reducing unfriendly user interactions.	multimodal interaction	Giovanni Frattini;Federico Ceccarini;Fabio Corvino;Ivano De Furio;Francesco Gaudino;Pierpaolo Petriccione;Roberto Russo;Vladimiro Scotto di Carlo;Gianluca Supino	2008		10.1007/978-3-540-87991-6_25	mobile search;human–computer interaction;computer science;database;multimedia;world wide web	HCI	-54.642789731817075	-41.2449609681266	198736
10ba9c93e38a619a2c72b9911aafc303012f6330	qr-codes for the chronically homeless	cell phones;chronically homeless;contextual inquiry;homelessness;qr reader;qr codes;user testing;iterative design;information system	We propose a system to use QR codes and cheap cell phones to alleviate some challenges faced by the chronically homeless. We propose combining the affordability, simplicity and portability of cell phones with the fast emerging QR Code technology to develop an information system which could augment current data entry methods utilized by homeless service agencies. The system offers simple interfaces which employ QR Codes for configuring cell phones to perform basic functions such as setting up reminders. The system is robust to the loss of its components, individual phones and QR cards. We developed and refined our design concept through an iterative design process of contextual inquiry, persona development, prototyping, and user tests.	contextual inquiry;information system;iteration;iterative design;mobile phone;qr code;software portability	Meseret Gebrekristos;Ahmad Aljadaan;Kumud Bihani	2008		10.1145/1358628.1358947	iterative design;simulation;human–computer interaction;computer science;contextual inquiry;operating system;multimedia;world wide web;information system	HCI	-49.50944482667602	-41.592157789242336	198750
80e3434f04bcca59d615d162bed087fca5692a50	training blind people in the use of graphical user interfaces	blind users;graphic user interface	The need for training of blind people to use graphical user interfaces has arisen since the first access systems became available. Two different approaches on the basis of PC-based tutorial systems are described and their benefits for the blind user are investigated.	graphical user interface	Gerhard Weber;Helen Petrie;Dirk Kochanek;Sarah Morley	1994		10.1007/3-540-58476-5_101	user interface design;10-foot user interface;human–computer interaction;multimedia;natural user interface;user interface;world wide web	HCI	-49.15970628180288	-40.68855764452461	198963
55d77e655e0eca9e118f0eeddae202f280fb3ba7	igrocer- a ubiquitous and pervasive smart grocery shopping system	assistive devices;pervasive computing;smart phone;smart phones;assistive device;mobile commerce;ubiquitous computing	"""Emerging Smart phones are poised to give a whole new dimension to the way we shop, bank, and go about many of our everyday activities. iGrocer is a smart grocery shopping assistant, that re-defines grocery shopping. It is capable of maintaining nutrition profiles of its users. Particularly useful for elders and disabled shoppers, iGrocer can aid and advice users on what products to buy and what to avoid based on nutrition criteria and price constraints. Implemented on a smart phone with a barcode scanner accessory, iGrocer has a number of killer features that include: (1) ubiquitous shopping list: adding items to the shopping list by different means (e.g. simply scanning them when near empty, scanning and storing manufacturer coupons, planning the weekly menu right on the phone or through the web, and shopping for the necessary ingredient of a particular recipe, (2) quick and assisted in-store shopping: while shopping in the grocery store, iGrocer maps out the shortest shopping path with a map indicating the location of the next item on the list, and (3)automated check-out: iGrocer is capable of acting on behalf of the store and the customer to perform a trusted queue-less checkout. In this """"application-oriented"""" paper, we present the iGrocer concept and give details of its architecture and implementation. We also summarize the lessons learnt throughout its development and testing phases."""	barcode reader;map;mobile phone;point of sale;smartphone	Sangeetha Shekar;Prashant Nair;Abdelsalam Helal	2003		10.1145/952532.952658	mobile commerce;computer science;multimedia;world wide web;computer security;ubiquitous computing	AI	-52.042912828536245	-42.33079262565909	199176
023fa1e6ba92a7b22a267164eaec975a8a85479e	services surround you	contextual bookmark;web pages;physical virtual linkage;mobile phone;qa75 electronic computers computer science;content analysis;mobile camera phone;physical interaction;mobile interaction	Our daily life is pervaded by digital information and devices, not least the common mobile phone. However, a seamless connection between our physical world, such as a movie trailer on a screen in the main rail station and its digital counterparts, such as an online ticket service, remains difficult. In this paper, we present contextual bookmarks that enable users to capture information of interest with a mobile camera phone. Depending on the user’s context, the snapshot is mapped to a digital service such as ordering tickets for a movie theater close by or a link to the upcoming movie’s Web page.	camera phone;digital data;mobile phone;seamless3d;snapshot (computer storage);web page	Niels Henze;René Reiners;Xavier Righetti;Enrico Rukzio;Susanne Boll	2008	The Visual Computer	10.1007/s00371-008-0266-4	mobile search;mobile interaction;content analysis;gsm services;computer science;web page;multimedia;internet privacy;world wide web;computer graphics (images)	HCI	-53.6726499061462	-40.99875556208325	199197
63d136a437cc874ecfcbcaef1e6bfd955011412f	in-store consumer behavior: how mobile recommendation agents influence usage intentions, product purchases, and store preferences	theory of planned behavior;mobile device;personal digital assistant;technology acceptance model;innovation diffusion theory;satisfiability;business model;decision support system;information management;consumer behavior;information need;perceived usefulness	Product information given in purchase situations influences purchase behavior. In online purchase situations, the use of recommendation agents increases the value of product information as information becomes adaptive and thus more relevant to consumers’ information needs. Correspondingly, mobile recommendation agents (MRAs) may also increase the value of product information in bricks-and-mortar stores. In this sense, product information is not only adaptive but can also be requested at any place such as in front of products consumers are interested in. Because unprecedented, we investigate the use of a MRA that is virtually bound to a physical product via an RFID-enabled mobile device and provides product information. Based on Theory of Planned Behavior, Innovation Diffusion Theory, and Technology Acceptance Model, we develop a model to better understand the impact of MRAs on usage intentions, product purchases and store preferences of consumers. This model is then tested in a lab experiment (n = 47). Among high usability scores, results indicate that perceived usefulness of a MRA influences product purchases, predicts usage intentions and store preferences of consumers. Thus, new business models for retail stores can be considered in which MRAs satisfy both the information needs of consumers and the communication needs of retailers. 2010 Elsevier Ltd. All rights reserved.	android;business requirements;field research;floor and ceiling functions;graphical user interface;ibm tivoli access manager;information needs;interrupt descriptor table;mobile device;mobile phone;mortar methods;personalization;product bundling;purchasing;star filler;theory;usability	Tobias Kowatsch;Wolfgang Maass	2010	Computers in Human Behavior	10.1016/j.chb.2010.01.006	business model;information needs;decision support system;computer science;mobile device;information management;theory of planned behavior;satisfiability	AI	-52.65068873942128	-41.93715295482174	199258
5bf589bcdc0b1248505e321e3051287530e67481	users' view on context-sensitive car advertisements	online survey;context aware;content distribution;dynamic content	Cars are ubiquitous and offer large and often highly visible surfaces that can be used as advertising space. Until now, advertising in this domain has focused on commercial vehicles, and advertisements have been painted on and were therefore static, with the exception of car-mounted displays that offer dynamic content. With new display technologies, we expect static displays or uniformly-painted surfaces (e.g. onto car doors or the sides of vans and trucks) to be replaced with embedded dynamic displays. We also see an opportunity for advertisements to be placed on non-commercial cars: results of our online survey with 187 drivers show that more than half of them have an interest in displaying advertising on their cars under two conditions: (1) they will receive financial compensation, and (2) there will be a means for them to influence the type of advertisements shown. Based on these findings, as well as further interviews with car owners and a car fleet manager, we discuss the requirements for a context-aware advertising platform, including a context-advertising editor and contextual content distribution system. We describe an implementation of the system that includes components for car owners to describe their preferences and for advertisers to contextualize their ad content and distribution mechanism.	client-side;client–server model;context-sensitive help;digital distribution;display device;dynamic web page;embedded system;printing;real-time data;requirement;server (computing);server-side;user interface	Florian Alt;Christoph Evers;Albrecht Schmidt	2009		10.1007/978-3-642-01516-8_2	embedded system;simulation;telecommunications;computer science;dynamic web page;multimedia;computer security;contextual advertising	HCI	-52.23708375031577	-40.41898189638395	199266
858e3d31af0e3e3ee75bde0772882ce65719c055	supporting elementary-age children's searching and browsing: design and evaluation using the international children's digital library	interfaces;human computer interaction;interface design;usability;digital library	Elementary-age children (ages 6-11) are among the largest user groups of computers and the Internet. Therefore, it is important to design searching and browsing tools that support them. However, many interfaces for children do not consider their skills and preferences. Children are capable of creating Boolean queries using category browsers, but have difficulty with the hierarchies used in many category browsing interfaces because different branches of the hierarchy must be navigated sequentially and toplevel categories are often too abstract for them to understand. Based on previous research, we believed using a flat category structure, where only leaf-level categories are available and can be viewed simultaneously, might better support children. However, this design introduces many more items on the screen and the need for paging or scrolling, all potential usability problems. To evaluate these tradeoffs, we conducted two studies with children searching and browsing using two types of category browsers in the International Children’s Digital Library. Our results suggest that a flat, simultaneous interface provides advantages over a hierarchical, sequential interface for children in both Boolean searching and casual browsing. These results add to our understanding of children’s searching and browsing skills and preferences and also suggest guidelines for other children’s interface designers. MOTIVATION In both the European Union and the U.S., households with children are more likely to have computers and Internet access than households without children (Day et al., 2005; Demunter, 2005). In 2003, 42% of U.S. children age 5-9 and 67% of children age 10-13 used the Internet (NTIA, 2004). Around the world, children use the Internet for schoolwork, to play games, and to communicate with each other (Day et al., 2005; Livingstone, 2003). These activities often require searching and browsing, similar activities distinguished by a methodical approach with a specific goal in the former and an emphasis on progressive filtering of results based on visual scanning in the latter (Ahlberg & Shneiderman, 1999). Search engines and digital libraries with keyword or category-based interfaces are two of the most common, freely-accessible tools used to support both of these activities on the Internet. Search engine sites such as Yahooligans! (yahooligans.yahoo.com) and Ask Jeeves Kids (www.ajkids.com) are examples of portals that children can use to find age-appropriate content. Project Gutenberg (www.promo.net/pg) and the Rosetta Project (www.childrensbooksonline.org) are examples of large digital libraries with books for children. However, these and other web sites for children often have interfaces with one or more of three problems. First, they do not take into account the information processing and motor skills of children, specifically their difficulties manipulating small objects with a mouse (Strommen, 1994; Inkpen, 2001; Hourcade et al., 2003). Second, they do not consider children’s searching and browsing skills, specifically their difficulties with spelling, typing, and composing keyword queries (Moore & St. George, 1991; Borgman et al., 1995; Druin, 2005); understanding and navigating category structures (Rosch et al., 1976; Tversky, 1985; Marchionini & Teague, 1987); and understanding and creating Boolean queries (Neimark & Slotnick, 1970; Tversky & Kahneman, 1975; Reuter & Druin, 2005). Third, they do not consider how children prefer to search, presenting search criteria appropriate for adults, but not for children, who often like to search differently (Wendelin & Zinck, 1983; Moore & St. George, 1991; Kragler & Nolley, 1996; Druin, 2005).	book;boolean algebra;computer;daniel slotnick;digital library;information processing;internet access;learning to rank;library (computing);mutual information;paging;portals;scrolling;usability;user interface design;web search engine;word lists by frequency	Hilary Browne Hutchinson;Allison Druin;Benjamin B. Bederson	2007	JASIST	10.1002/asi.20646	design;digital library;simulation;usability;computer science;interface design;multimedia;user interface;world wide web	HCI	-52.05220290678023	-41.73261998231751	199636
0b921f67aabacb2f46d32dd2e003e8f86f7b2229	speech technology for universal access in interactive systems	universal access;interactive system;older people;elderly people	The problem discussed in this paper concerns how spoken interaction research can give a solution for the universal access for all. This paper will firstly report on the state of the art of speech technology for older people. Secondly, it will describe the case study of the selection of a French dictation system for a fundamental evaluation by elderly people. This session must be considered as a case study. We will place our approach with respect to NIST (http://www.nist.gov/speech/) and EAGLES [Gibbon 1997] evaluation contexts. Finally, we will give preliminary results mainly on the effect of the people age.	speech technology	Régis Privat;Nadine Vigouroux;Caroline Bousquet-Vernhettes;Philippe Truillet;Bernard Oriola	2001			human–computer interaction;computer science;multimedia;communication	HCI	-51.56545510489655	-44.091878974906635	199707
