id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
69142d9bb5e4af4bb040deefa1194fe48eb1b84c	formalising natural language specifications using a cognitive linguistics/configuration based approach	natural language sbvr business rules mda mde;mda;pragmatics;formal specification;information systems;vocabulary;semantics;natural languages;unified modeling language business data processing computational linguistics formal specification information systems knowledge based systems natural language processing;companies;unified modeling language vocabulary natural languages semantics companies pragmatics;mde;business data processing;natural language;sbvr;unified modeling language;computational linguistics;natural language business specification model driven engineering knowledge based configuration sbvr transformation uml class diagram natural language business rules formal representation sbvr standard semantics of business vocabulary and business rules information system formal model configuration based approach cognitive linguistics;natural language processing;business rules;knowledge based systems	This paper addresses the problem of transforming natural language business specifications into formal models suitable for use in information systems. In particular, the Semantics of Business Vocabulary and Business Rules (SBVR) standard is used as a starting point for both the natural language specifications and the formal representation. In recent years, SBVR-based approaches have been proposed for transforming natural language business rules into models, such as UML Class Diagrams, however, most focus on the transformations performed after the SBVR models have been created and, therefore, simplify or entirely neglect the natural language to SBVR transformation. There are a number of difficulties in transforming natural language into formal models, such as ambiguity and inconsistency. This paper presents a solution based on a unique combination of techniques from Cognitive Linguistics and Knowledge-based Configuration in order to transform natural language business specifications into SBVR models. We present a comparative survey of state-of-the-art approaches and argue that current solutions do not fulfil the criteria necessary to meet our goals. We demonstrate our approach and show how it improves translation of natural language business specifications into formal models and increases the level of automation for Model-Driven Engineering.	glossary;information system;knowledge representation and reasoning;knowledge-based configuration;model-driven architecture;model-driven engineering;model-driven integration;natural language;personalization;requirement;semantics of business vocabulary and business rules;software documentation;software quality;unified modeling language;user interface;well-formed element	Matt Selway;Georg Grossmann;Wolfgang Mayer;Markus Stumptner	2013	2013 17th IEEE International Enterprise Distributed Object Computing Conference	10.1109/EDOC.2013.16	natural language processing;natural language programming;semantics of business vocabulary and business rules;universal networking language;object language;computer science;computational linguistics;database;semantics;natural language;programming language;pragmatics	DB	-53.467073504951586	20.0099113216111	148986
d75c8f362493e841bb0c7699db6675001854331e	measuring the expressiveness of a constrained natural language: an empirical study	empirical study;formal specification;natural languages australia defense industry particle measurements writing systems engineering and theory automatic control;natural languages;side effect;natural language;requirement specification;requirements specification expressiveness measurement constrained natural language;conference proceeding;natural languages formal specification	It has been suggested that constraining a natural language (NL) reduces the degree of ambiguity of requirement specifications written in that language. There is also a tendency to assume that an inescapable side effect of constraining a natural language is a subsequent reduction in its expressiveness. The primary objective of this paper is to describe a technique that we have developed for empirically measuring the expressiveness of a constrained natural language (CNL) when used to specify the requirements in a particular application domain. Our simple yet practical and repeatable technique elucidates the individual contribution that each lexical entity of the CNL can make on the overall expressiveness of the CNL This technique is particularly useful for designing new CNLs, as well as situations where tailoring or streamlining existing CNLs for particular application domains is needed.	application domain;compute node linux;nl (complexity);natural language;requirement	Stephen Boyd;Didar Zowghi;Alia Farroukh	2005	13th IEEE International Conference on Requirements Engineering (RE'05)	10.1109/RE.2005.39	natural language processing;object language;specification language;computer science;natural language;programming language	SE	-53.57848597181986	21.708996381307816	149354
de0665cb9606a62e45d154165b95aa1813e475a7	towards probabilistic decision making on human activities modeled with business process diagrams	bpmn;activity theory;bayesian networks;engineering agent based systems	Agent-based technologies, originally proposed with the aim of assisting human activities, have been recently adopted in industry for automating business processes. Business Process Model and Notation (BPMN) is a standard notation for modeling business processes that provides a rich graphical representation that can be used for common understanding of processes but also for automation purposes. We propose a normal form of Business Process Diagrams (BPDs) based on Activity Theory that can be transformed into a Causal Bayesian Network, which in turn can be used to tackle with uncertainty introduced by human participants. We illustrate our approach on an Elderly health care scenario obtained from an actual contextual study.	business process;diagram	Hector G. Ceballos;Victor Flores-Solorio;Juan-Pablo García-Vázquez	2015			activity theory;computer science;knowledge management;artifact-centric business process model;artificial intelligence;bayesian network;management science;business process model and notation;business process;business process discovery;business rule;business process modeling	Vision	-54.438514803851554	19.974424659686452	149404
21940e58849da4f1e23fcf2d35fd719408f13b53	a generic approach to support a way-of-working definition	method engineering;system modelling;conceptual modelling;process modelling;process model;information system;meta model	Information System Engineering has made the assumption that an Information System is supposed to capture some excerpt of the real world history and hence has concentrated on systems modelling. Very little attention has been paid to the conceptual modelling process. However the emphasis on system modelling is shifting to process modelling. The particular process modelling approach being presented in this paper advocates the definition of a way-of-working (i.e. process models) to control and guide developers. The paper introduces a classification of the various kinds of evolution of objects and presents a decision-oriented process meta model to structure ways-of-working. We also describe some guidelines, related to our classification of object evolutions, to support method engineers in the task to define a way-of-working.	conceptual schema;information system;metamodeling;process modeling;systems modeling	Mario Moreno;Colette Rolland;Carine Souveyet	1994		10.1007/3-540-58113-8_183	conceptual model;systems engineering;software engineering;process modeling;empirical modelling	SE	-52.72295790952845	23.66446753140727	149735
9ee58f3091860390e940e606e14caa0dfb713563	supporting business process compliance in financial institutions - a model-driven approach		Recently, several approaches have been developed to check process models for compliance with laws and regulations. In this paper a contribution is made with respect to reducing the complexity of compliance checking by partially automating business process compliance (BPC) checking. We present a model checking approach that is able to check process models for BPC. In particular, we apply a generic pattern matching approach to the Semantic Business Process Modeling Language (SBPML) allowing for extended model checking not being restricted to predecessor-successor relationships. Finally, we apply the BPC checking approach to the example of a credit approval process from a realworld bank scenario using a demonstrator modeling software.	business process modeling language;model checking;model-driven integration;pattern matching	Jörg Becker;Philipp Bergener;Patrick Delfmann;Mathias Eggert;Burkhard Weiß	2011				SE	-54.98091897685233	19.774325207784567	149863
ab435e2a01d0980065f5f41fc186848ba9c65843	towards employing uml model mappings for platform indepedent user interface design.	logic design;user interface;levels of abstraction;user interface design;model based design	While model based design of platform independent application logic has already shown significant success, the design of platform independent user interfaces still needs further investigation. Nowadays, user interface design is usually platform specific or based on C-level cross-platform libraries. In this paper, we propose a MDA like design approach for user interfaces based on the transformation of UML models at different levels of abstraction. This enables platform independent design of user interfaces and a clear separation of UI and application logic design while enabling full use of native controls in the actual user interface implementation.	business logic;code generation (compiler);common platform;component-based software engineering;executable;information model;library (computing);model-driven architecture;model-driven engineering;principle of abstraction;prototype;unified modeling language;user interface design	Tim Schattkowsky;Marc Lohmann	2005			user interface design;user;user experience design;real-time computing;shell;human–computer interaction;computer science;systems engineering;user interface;graphical user interface testing	EDA	-48.66878323478023	24.327341078055834	150204
9c29ec77ff3ed9ee18a302f7b0faf05cf793d0a3	sddnet: a semantic network for software design and development domain via graph database		When building software systems, deciding implementation details manually for specific system requirements is time consuming and often leads to sub-optimal choices. An automated, knowledge-base driven approach to select from possible technology alternatives can replace or reduce manual effort in realizing these requirements. This motivated us to develop such a knowledge system which can ultimately help in opportune and cost-effective software development. We create a rich knowledgebase by automatic extraction of useful information from a large volume of existing documentation pertaining to software components and technologies that are used to build variety of business applications. We store the knowledge-base in a graph database. A semantic network depicting relations between concepts found in Software Design and Development (SDD) domain is constructed from the database. This knowledge-base can be queried for deducing additional facts about the concepts stored therein.	component-based software engineering;documentation;entity;graph database;inference engine;knowledge base;knowledge-based systems;requirement;semantic network;software design and development;software development;software system;system requirements	Shipra Sharma;Balwinder Sodhi	2016		10.1007/978-3-319-40985-6_7	domain analysis;semantic data model;semantic computing;wait-for graph;computer science;theoretical computer science;feature-oriented domain analysis;domain engineering;data mining;database;semantic technology;graph database	SE	-53.08686629789548	21.942015672412108	150508
2683e8cbe49eda3416aa1502cd2fac56972e42c0	assuring data interoperability through the use of formal models of visa payment messages	baseline analysis;process modeling;statistical analysis;uml models;data modeling;international payment standards;interoperability;payment messages;process model;data model;expected value;population model	Visa desires a high-quality payment experience for its cardholders, merchants, and Member banks. The application of formal techniques to model payment messages exchanged among the participants in a transaction has led to a substantial reduction in the incidence of interoperability problems. These occur when message fields that capture information about a transaction are incorrectly populated. Models allow the precise specification and shared understanding of the structure, semantics, and lifecycle of the data, and thereby enhance the overall payment experience. A monitoring environment is in place to analyze all transactions in the global VisaNet system against expected values and combinations of values specified in the models, and to take corrective action when interoperability issues are identified. Various standards activities are underway where models are applied to the creation of new financial messages and the evolution of existing ones.	data quality;end-to-end principle;formal methods;formal specification;incidence matrix;interoperability;population;uml tool;unified modeling language;virtual instrument software architecture	Joseph Bugajski;Philippe De Smedt	2007			clamping;computer network;data model;database;hoist (device);interoperability;payment;computer science	SE	-53.93326460179949	20.69773470760584	151196
039449432f63809f909b989bb378cb1ba92d7560	an evaluation of inter-organizational workflow modeling formalisms	information systems;uml;is;conceptual study;prototype validation;ontology	This paper evaluates the dynamic aspects of the UML in the context of inter-organizational workflows. Two evaluation methodologies are used. The first one is ontological and is based on the BWW (Bunge-Wand-Weber) models. The second validation is based on prototyping and consists in the development of a workflow management system in the aerospace industry. Both convergent and divergent results are found from the two validations. Possible enhancements to the UML formalism are suggested from the convergent results. On the other hand, the divergent results suggest the need for a contextual specification in the BWW models.	semantics (computer science);unified modeling language	Aymeric Dussart;Benoit Aubert;Michel Patry	2004	J. Database Manag.	10.4018/jdm.2004040104	unified modeling language;computer science;applications of uml;ontology;data mining;database;is;information system	SE	-55.33006689138306	21.077064768809993	151772
1a51231225a9c0b6bcaa32dfc202e0582de600f3	a construction approach for software agents using components	multi agent system;software agent;client server;distributed environment;software component;constructing method;profitability;software reuse	This paper presents a construction approach for software agents. A software agent is regarded as a main frame plus some components, and it is constructed by selecting suitable main frame and software components, assembling and running through the control mechanism on the main frame. The multi-agent system is organised on the Client/Server model. The developed system based on this method profits from software reuse in the distributed environment.	code reuse;component-based software engineering;mainframe computer;multi-agent system;software agent	Hong Liu;Zongkai Lin;Guangzhou Zeng	1999	ACM SIGSOFT Software Engineering Notes	10.1145/311963.312017	software distribution;long-term support;verification and validation;real-time computing;software sizing;computer science;systems engineering;engineering;package development process;backporting;software design;software framework;component-based software engineering;software development;software design description;software agent;operating system;multi-agent system;middleware;software construction;resource-oriented architecture;software deployment;client–server model;profitability index;distributed computing environment;software system	SE	-51.198154869122064	19.785242127389505	153504
963d3a8336f72e98e3f6cbafb4e2c91ef4f5c08e	what software engineering has to offer to agent-based social simulation		"""6.3 Illustrative Example: Normative Comparison in an Office Environment Up to now we have seen that Software Engineering in general and AOSE in particular offers a lot of support for developing ABSS models. Most of this support can be coined """"formal"""": at the heart are clearly given process models describing the different steps to go through when doing a simulation study. This is particularly important for less experienced modellers as these process models help to solve the problem of translating vague mental representations of models into descriptions that are more and more refined. These methodologies help to know where one should start when doing a simulation study. In the following we show based on an illustrative example that there is no need to be afraid of formal approaches, but that they can indeed be useful to support awareness about the actual model content when developing a model."""	agent-based social simulation;agent-oriented software engineering;artificial intelligence;computer science;journal of artificial societies and social simulation;multi-agent system;unified modeling language;vagueness	Peer-Olaf Siebers;Franziska Klügl-Frohnmeyer	2017		10.1007/978-3-319-66948-9_6	component-based software engineering;software construction;software engineering;agent-based social simulation;formal methods;software development;agent-oriented software engineering;software engineering process group;social software engineering;systems engineering;computer science	AI	-53.01106857934973	22.942810194319048	153655
c5566e98f9eb332b258b97320932972fa81d6c9c	top-down business process development and execution using quality of service aspects	business process development;service level;ws cdl;top down;service level agreements;web service;data format;automatic generation;ws bpel;service level agreement;quality of service;business process;top down modelling	This article may be used for research, teaching and private study purposes. Any substantial or systematic reproduction, redistribution , reselling , loan or sub-licensing, systematic supply or distribution in any form to anyone is expressly forbidden. The publisher does not give any warranty express or implied or make any representation that the contents will be complete or accurate or up to date. The accuracy of any instructions, formulae and drug doses should be independently verified with primary sources. The publisher shall not be liable for any loss, actions, claims, proceedings, demand or costs or damages whatsoever or howsoever caused arising directly or indirectly in connection with or arising out of the use of this material. Developing cross-organisational business processes is a challenging task. The partners have to agree on a common data format and meaning as well as on the quality of service (QoS) requirements each partner has to fulfil. The QoS requirements are typically described using service level agreements (SLAs) among the partners. In this paper, a top-down modelling approach for Web service based business processes is proposed to capture the functional and non-functional aspects using a choreography language (WS-CDL) which describes the message interactions among the participants. The choreography is annotated with SLAs for the different partners. For each partner in the process, an orchestration (in WS-BPEL) and the necessary Web service templates are automatically generated. The service level objectives (SLOs) from the partner SLAs are automatically translated into policies that can then be enforced by a BPEL engine during execution. The deployment of the WSDL files, the monitoring of QoS attributes and the execution of the BPEL process itself are then handled by the VRESCo SOA runtime. 1. Introduction Service-oriented architecture (SOA) represents an emerging paradigm to develop flexible and large-scale software systems using the Internet as the main infrastructure. Web services are one realisation of this paradigm by using well-established standards to describe and interact with other services.	business process execution language;compiler description language;cube;eclipse;entity;executable;global variable;interaction;middleware;primary source;programming paradigm;prototype;quality of service;requirement;scalability;service-level agreement;service-oriented architecture;service-oriented device architecture;software deployment;software system;top-down and bottom-up design;ws-trust;web services description language;web service	Florian Rosenberg;Anton Michlmayr;Schahram Dustdar	2008	Enterprise IS	10.1080/17517570802395626	web service;service level requirement;service level objective;business process execution language;quality of service;service level;differentiated service;computer science;service delivery framework;service design;top-down and bottom-up design;database;distributed computing;business process;management;law;world wide web	Web+IR	-48.34524682514057	18.45785755462204	154033
844b29b841592679541cd4c5153b83ceaff32089	a meta-model for formulating knowledge-based models of software development	life cycle;software systems;knowledge based models of software development;development process;software process modeling;software process model;levels of abstraction;software development;meta modeling model composition;knowledge based modelling;meta model;model composition;knowledge base	In this paper, we introduce a knowledge-based meta-model which serves as a uniied resource model for integrating characteristics of major types of objects appearing in software development models (SDMs). The URM consists of resource classes and a web of relations that link diierent types of resources found in diierent kinds of models of software development. The URM includes specialized models for software systems, documents, agents, tools, and development processes. The URM has served as the basis for integrating and interoperating a number of process-centered CASE environments. The major beneet of the URM is twofold: First, it forms a higher level of abstraction supporting SDM formulation that subsumes many typical models of software development objects. Hence, it enables a higher level of reusability for existing support mechanisms of these models. Second, it provides a basis to support complex reasoning mechanisms that address issues across diierent types of software objects. To explore these features, we describe the URM both formally and with a detailed example, followed by a characterization of the process of SDM composition, and then by a characterization of the life cycle of activities involved in an overall model formulation process.	computer-aided software engineering;knowledge-based systems;metamodeling;software agent;software development;software system	Peiwei Mi;Walt Scacchi	1996	Decision Support Systems	10.1016/0167-9236(96)00007-3	metamodeling;biological life cycle;knowledge base;verification and validation;software engineering process group;software sizing;computer science;knowledge management;package development process;software design;software framework;component-based software engineering;software development;software design description;software construction;systems development life cycle;empirical process;software analytics;resource-oriented architecture;goal-driven software development process;software development process;software system	SE	-52.661816113177885	24.59972056493246	154311
088b8e57ac503d2a7ac5c661f1a4121de5a2c8d9	automated software engineering: special issue on precise semantics for software modeling techniques (psmt'—an icse'98 workshop)	modeling technique;software engineering;formal method;development environment;case tool;automated software engineering	Over the last few years, there has been a growing recognition that the worlds of Formal Methods and CASE tool supported modelling techniques must come together to provide Software Engineers with soundly based, but notationally familiar, development environments and techniques. Since many engineering disciplines use what appear to be informal, sometimes iconic, languages as ‘interfaces’ to their mathematical languages for modeling application solutions, it seems plausible to try the same approach in Software Engineering. This means, effectively, that we should take extant Software Modeling Techniques and see if we can develop formal semantics for their notations, so as to provide software engineers with familiar tools, and also provide them with the possibility of performing the analyses and formal checks, on the one hand, and the support for transformational techniques being applied for implementation and code generation, on the other. In the longer term, effective formal notations may generate modeling techniques and notations which will then be adopted by Software Engineers. With this motivation in mind, the workshop on Precise Semantics for Software Modeling Techniques(PSMT)was organized in conjunction with ICSE’98 in Kyoto on April 20th, so as to take a critical look at recent thoughts and developments in this emerging area. Work based on three of the submissions of this workshop have been selected for inclusion in this issue of theAutomated Software Engineering journal.	code generation (compiler);computer-aided software engineering;formal methods;modeling language;semantics (computer science);software engineer	T. S. E. Maibaum;Bernhard Rumpe	2000	Automated Software Engineering	10.1023/A:1008714925733	personal software process;verification and validation;formal methods;software engineering process group;software verification;search-based software engineering;computer science;systems engineering;package development process;software design;social software engineering;software development;software engineering;software construction;development environment;software walkthrough;software analytics;software deployment;computer-aided software engineering;software development process;software requirements;software system;computer engineering	SE	-52.15813677731401	24.265016576310234	154823
162eca3a753e46ca590f47381b2fe6d4dd7d3f1e	attribute-based security verification of business process models		Business processes, as the instruments used by organisations to produce value, need to comply with a number of internally and externally imposed standards and restrictions. Since the majority of such processes involve the exchange of sensitive third party information, their compliance to security constraints needs to be verified before they can be implemented. Current attempts for the verification of security compliance of design-time business process models involve the transformation of both the model and the desired security properties into formal specifications, which can be then used as input for automated model checkers. Such an approach is usually costly both in terms of time and specialised knowledge, while also its coverage can be limited to specific types of security requirements. In this work we introduce an approach for the verification of security in business process models based on structural properties of the workflow of the process. To that end, we introduce a series of attributes to existing BPMN 2.0 concepts and algorithms for checking the compliance of a process model against the most common security requirements. Finally, a real-world business process is used to demonstrate and evaluate the applicability of our proposal.		Nikolaos Argyropoulos;Haralambos Mouratidis;Andrew Fish	2017	2017 IEEE 19th Conference on Business Informatics (CBI)	10.1109/CBI.2017.37	business process discovery;computer security model;business process modeling;artifact-centric business process model;business process model and notation;business process management;systems engineering;security testing;computer science;security information and event management	Security	-55.13072909612157	19.770446033741685	156209
e8034104897a99ecc3a1f543886a334f9bd23814	a semantic approach for process annotation and similarity analysis	process annotation;similarity analysis;quality of service;process analysis;semantic process modelling	Research in the area of process modelling and analysis has a long-established tradition. There a quite few formalisms for capturing processes, which are also accompanied by number of optimisation approaches. We introduce a novel approach, which employs semantics, for process annotation and analysis. In particular, we distinguish between target processes and current processes. Target processes describe how a process should ideally run and define a framework for current processes, which in contrast, capture how processes actually run in real-life use cases. In some cases, current processes do not match the traget processes and can even overhaul target processes. Therefore, one is interested in the similarity of the defined target process and current processes. The comparisons can consider different characteristics of processes such as service quality measures and dimensions. Current solutions try to convert processes to specific ontologies and perform process mining methods to discover hidden structures or try to support the managing of the execution. However, comparing target processes with current processes has not been addressed yet. To this end, we propose an new approach that is based on annotating processes with semantic information. We perform similarity analysis of target processes and current processes that exploits the semantics to show the added value of our approach. As part of the similarity analysis, we consider different service qualities and dimensions in order to determine how they influence both target and current process.	faceted classification;mathematical optimization;ontology (information science);process modeling;quality of service;real life;subject-matter expert;weak value	Tobias Weller	2016		10.1007/978-3-319-34129-3_57	quality of service;computer science;data science;machine learning;data mining;database;business process discovery	SE	-53.14058145114436	18.54410392427548	156280
1d02f66dd1a7add53d1234bf19d4fa71f888fcf7	usability of rational rose and visio in a software engineering course	rational rose;visio;student experience;experience;software engineering;survey results;questionnaire survey;visual modeling;usability;modeling tool	Rational Rose (Rose) and Microsoft Visio (Visio) are the two commonly used UML modeling tools in software engineering courses. In the fall of 2002, a project to evaluate the usability of Rose and Visio for UML modeling in an undergraduate software engineering class was started. Through a questionnaire survey, student experiences of using Rose and Visio for UML modeling were collected and analyzed. This paper outlines our findings from the research project, tool features, diagram creation, available documentation, multi-tasking ability and produced output.	computer multitasking;diagram;documentation;microsoft visio;rational rose;software engineering;uml tool;unified modeling language;usability	Rose Shumba	2005	SIGCSE Bulletin	10.1145/1083431.1083475	questionnaire;simulation;usability;computer science;software engineering	SE	-48.932992290159405	24.41236252885381	156978
d90748399d6bae3efb8a456620f38787c513a1ed	mining expressive and executable resource-aware imperative process models		Process mining extracts relevant information on executed business processes from historical data stored in event logs. The data typically available include the activities executed, temporal information and the resources in charge of their execution. With such data, the functional, behavioural and organisational perspectives of a process can be discovered. Many existing process mining approaches are capable of generating representations involving the first two perspectives with all types of processes. The extraction of simple and complex resource assignment rules has also been tackled with declarative process models. However, it is noticeable that despite imperative notations like BPMN are mostly used for process modelling nowadays, the existing process mining approaches for enriching such models with resource assignments cannot discover rules like separation of duties and do not produce executable resource-aware process models. In this paper we present an approach for mining resource-aware imperative process models that uses an expressive resource assignment language (RALph) with the de-facto standard notation BPMN. The organisational perspective of the resulting models can be automatically analysed thanks to the formal semantics of RALph. The method has been implemented and tested with a real use case.	executable;imperative programming	Cristina Cabanillas;Stefan Schönig;Christian Sturm;Jan Mendling	2018		10.1007/978-3-319-91704-7_1	data mining;business process;notation;process mining;separation of duties;semantics of logic;executable;process modeling;business process model and notation;computer science	HCI	-53.432482723993424	18.385600307310362	157444
0fe1ba0545cc7457c177f65c1e5c8a8379cdb5aa	eliciting multi-agent systems intentionality: from language extended lexicon to i* models	goal elicitation process multiagent systems language extended lexicon i models;bottom up;multi agent system;multiagent systems proposals scalability computer science software quality software engineering information resources;formal languages;i models;multi agent systems;formal verification;language extended lexicon;goal elicitation process;multi agent systems formal languages formal verification;multiagent systems	MAS methods still lack coverage to the goal elicitation process, especially on how to identify goals from corporate information, mission statements and from interviews with stakeholders. Only after eliciting goals we will be able to properly deal with goal models. On the other hand, intentionality models, for example the i* framework, are, usually, complex and difficult to read. By contrast, this paper proposes an indirect inquire process that can identify goals in a bottom-up and simple elicitation approach together with a proposal to reduce the problem of scalability of i* models.	bottom-up proteomics;intentionality;lexicon;scalability;top-down and bottom-up design	Antonio de Pádua Albuquerque Oliveira;Julio Cesar Sampaio do Prado Leite;Luiz Marcio Cysneiros;Claudia Cappelli	2007	XXVI International Conference of the Chilean Society of Computer Science (SCCC'07)	10.1109/SCCC.2007.8	natural language processing;computer science;systems engineering;knowledge management	SE	-54.60847688813636	20.234259164165692	159786
7677d3d4f4aad45b938a6fd1792303edbe7dce9c	object-centered process modeling: principles to model data-intensive systems	process model	New modeling approaches appeared in the last decade based on the premise that process structures in data-intensive landscapes are pushed by data-driven events. However, since emergent approaches, as artifact-centric, data-driven, product-based and document-based modeling, cover reduced subsets of all data-related needs, they have a limited practical impact [13]. This work structures the set of requirements to model responsive data-intensive systems, studies the emergent objectcentered approaches to retrieve a set of principles and, finally, defines a solution direction, centered in expressive object models and in model transformations, for the support of the introduced principles.	attachments;data-intensive computing;emergent;event-driven programming;executable;gene ontology term enrichment;graphical user interface;model transformation;object file;process (computing);process modeling;requirement	Rui Henriques;António Rito Silva	2010		10.1007/978-3-642-20511-8_62	systems modeling;chemical process modeling;computer science;function model;conceptual model;process modeling	SE	-50.79163866296053	20.408999258271834	160139
7a54e5397a6f911acbaac2d4ccf74f8ffdafdfc7	sml model-based management	xml testing prototypes scalability iso standards knowledge management hip large scale systems computer aided software engineering distributed computing;software architecture open systems;service modeling language;planetlab validation sml model based system management application specific details interoperability service modeling language;domain knowledge;model validation;service model;software architecture;sml model based system management;model based systems;model management;interoperability;planetlab validation;open systems;system management;use case;application specific details	"""Models enable a clear separation between domain knowledge and application-specific details. In the system management arena, there are multiple implementations of model-based system management solutions, but until now, there was no industry-wide agreement on a common language or paradigm to enable interoperability. A new standard has been proposed to describe IT Services, the service modeling language (""""SML""""). While SML enables interoperability, it still poses challenges in terms of scalable model stores, model validation, and use. This paper discusses an architecture for SML model management and validation and describe and evaluate a prototype implementation with a use case on system management of PlanetLab."""	interoperability;modeling language;planetlab;programming paradigm;prototype;scalability;systems management	Ricardo Rivaldo;Guilherme Germoglio;Flavio Santos;Yuan Chen;Dejan S. Milojicic;Robert Adams	2007	2007 10th IFIP/IEEE International Symposium on Integrated Network Management	10.1109/INM.2007.374707	use case;interoperability;software architecture;systems management;computer science;operating system;service-oriented modeling;database;regression model validation;open system;domain knowledge	OS	-51.908425489496324	24.411993745912294	161947
3c4c4090e0a54e6b990858c1b1857240aaa47375	can urml model successfully drools rules	dynamic change;software engineering;modeling language;business model;visual modeling;visual language;use case;open source	The use of rules in business modeling is becoming more and more important, in applications requiring dynamic change of behavior. A number of rule languages and tools have been proposed to the software engineering community. However, there are not too many visual languages for rule modeling. The goal of this paper is to investigate the modeling capabilities of UML-based Rule Modeling Language (URML) with respect of Drools rules. We choose Drools because is the most important and well known open source rule platform. It is friendly to both developers and business users, offers a lot of functionality but does not provide a visual modeling environment for rules. The Single Item English Electronic Auction Use Case is used to illustrate the modeling capabilities. The paper concludes that URML rules can model the large part of Drools rules but improvements of the modeling language are necessary.	drools;open-source software;software engineering;unified modeling language;visual modeling	Emilian Pascalau;Adrian Giurca	2008			use case;business model;semantics of business vocabulary and business rules;computer science;artificial intelligence;machine learning;data mining;database;modeling language;programming language;business rule	SE	-53.17826067322434	20.116068230301153	162748
499b0f5bd0f095f50ecba98bb202ead6bb34fa03	evaluating the potential for integrating the open and tropos metamodels	object oriented;conference proceeding	Methodologies involves both process elements and product elements. The OPEN Process Framework (OPF) focusses largely on process elements in the context of object-oriented systems development. The Tropos metamodel, on the other hand, focusses on early requirements engineering support for agent-oriented development. In a project to extend the OPF to support agentoriented developments, we investigate the potential for amalgamation of these two methodological approaches and their metamodels, describing how the metamodel integration has been initiated.	metamodeling;requirements engineering;software development process	Brian Henderson-Sellers;Paolo Giorgini;Paolo Bresciani	2003			computer science;systems engineering;data mining;database	SE	-54.97020311471528	22.72728284056467	163369
2cb7340f9080cccdef945b0ed4e3b293e3f53a36	semantic links in integrated modelling frameworks	integrated modelling frameworks;integrable model;integrated modelling;decision maker;model reuse;model linking;modelling framework;computer sciences;number of factors;temporal scale;mathematical model;ontologies;source code	It is commonly accepted that modelling frameworks offer a powerful tool for modellers, researchers and decision makers, since they allow the management, re-use and integration of mathematical models from various disciplines and at different spatial and temporal scales. However, the actual re-usability of models depends on a number of factors such as the accessibility of the source code, the compatibility of different binary platforms, and often it is left to the modellers own discipline and responsibility to structure a complex model in such a way that it is decomposed in smaller re-usable sub-components. What reusable and interchangeable means is also somewhat vague; although several approaches to build modelling frameworks have been developed, little attention has been dedicated to the intrinsic re-usability of components, in particular between different modelling frameworks. In this paper, we focus on how models can be linked together to build complex integrated models. We stress that even if a model component interface is clear and reusable from a software standpoint, this is not a sufficient condition for reusing a component across different integrated modelling frameworks. This reveals the need for adding rich semantics in model interfaces. © 2008 IMACS. Published by Elsevier B.V. All rights reserved.	accessibility;data structure;design pattern;domain-specific language;extensibility;mathematical model;monty newborn;ontology (information science);python;software framework;usability;vagueness;xml	Andrea Emilio Rizzoli;Marcello Donatelli;Ioannis N. Athanasiadis;Ferdinando Villa;David Huber	2008	Mathematics and Computers in Simulation	10.1016/j.matcom.2008.01.017	decision-making;computer science;ontology;mathematical model;data mining;management science;statistics;source code	AI	-53.36751813564663	23.002466698476074	163594
07f316b34de464fe0a8c155613e41b72ed133364	a language-centered approach to support environmental modeling with cellular automata		"""The application of methods and technologies of software engineering to environmental modeling and simulation (EMS) is common, since both areas share basic issues of software development and digital simulation. Recent developments within the context of """"Model-driven Engineering"""" (MDE) aim at supporting the development of software systems at the base of relatively abstract models as opposed to programming language code. A basic ingredient of MDE is the development of methods that allow the efficient development of """"domain-specific languages"""" (DSL), in particular at the base of language metamodels. DSLs are mainly characterized by providing expressive means for the specification of models that are particularly tailored towards the needs of users. Besides functional properties, a distinguishing feature of DSLs is the provision of non-functional properties that are related to pragmatics. However, existing investigations of MDE in software engineering and particularly EMS primarily focus on technical considerations, e.g. feasibility. This thesis shows how MDE and language metamodeling in particular, may support pragmatic aspects that reflect epistemic and cognitive aspects of scientific investigations. For this, DSLs and language metamodeling in particular are set into the context of """"model-based science"""" and """"model-based reasoning"""". It is shown that the specific properties of metamodel-based DSLs may be used to support those properties, in particular transparency, which are of particular relevance against the background of uncertainty, that is a characterizing property of EMS. The findings are the base for the formulation of an corresponding specific metamodel-based approach for the provision of modeling tools for EMS (Language-centered Approach, LCA). The implementation of a corresponding exemplary modeling tool provides a DSL (ECAL) for modeling with Cellular Automata that has been developed within this thesis. ECAL (Environmental Cellular Automata Language) is particularly tailored to reflect the formerly discussed pragmatic aspects of Cellular Automata modeling in EMS. The concepts of ECAL follow from a characterization of relevant Cellular Automata models and corresponding modeling tools as described in literature. ECAL represents a level of abstraction that aims at being general with respect to typical degrees of freedom of Cellular Automata for EMS, but it does not provide typical degrees of freedom of typical modeling tools, which follows from above mentioned considerations of pragmatics. In order to proof applicability of LCA and ECAL, ECAL has been used to reimplement published models. A particularly important feature of EMS is the inclusion of geo-spatial data (geodata). The integration of technology for processing geodata and simulation technology is a well-recognized field of scientific investigation. However, the integration of corresponding technologies at the base of metamodels is widely unrecognized, although influential efforts of standardization of geodata are widely based on language metamodels. This thesis suggests the integration of geodata processing and corresponding software at the base of metamodels. The modeling tool developed in this thesis shows the practical applicability of concepts."""	cellular automaton;digital subscriber line;domain-specific language;geographic information system;language code;metamodeling;model-based reasoning;model-driven engineering;model-driven integration;programming language;relevance;simulation;software development;software engineering;software system	Falko Theisselmann	2014			natural language processing;theoretical computer science;cellular automaton;domain-specific language;artificial intelligence;computer science	SE	-53.30833005809779	23.613336173899206	163640
980d3f55f711adaff366f0ee2310a8cd33a149a0	fmebp: a formal modeling environment of business process		This paper proposes a formal environment, named FMEBP, for modeling business processes. This environment is based on a transformation approach that translates Web services, described in BPEL language, to abstract specifications, written in a high-level real-time language called D-LOTOS. The interest of D-LOTOS language is provided from the fact that it is based on true-concurrency semantics and supports both timing constraints and actions durations. For assessing the proposed environment we study a specification of a Web services application.	business process	Imed Eddine Chama;Nabil Belala;Djamel-Eddine Saïdouni	2014		10.1007/978-3-319-11958-8_17	business analysis;business transformation;semantics of business vocabulary and business rules;business domain;systems engineering;knowledge management;artifact-centric business process model;business process management;process modeling;business process model and notation;process management;business process;modeling language;process mining;business process discovery;business rule;business process modeling;business activity monitoring;business architecture	DB	-53.98682968003136	19.46385076337673	163743
4d54185f9dcc6f13049ee891ed4b3fbff1629c43	why linq matters: cloud composability guaranteed	linq matter;software engineering;cloud composability	The benefits of composability are becoming clear in software engineering.	composability;language integrated query;software engineering	Brian Beckman	2012	Commun. ACM	10.1145/2133806.2133820	computer science;distributed computing	SE	-52.91065098642903	22.589391548525885	165151
d1f9036ae6f90abd14fe1f825f9760ee7b5f51bf	business process regulatory compliance is hard	complexity theory;business automata maintenance engineering process control complexity theory semantics;bismuth;np completeness;semantics;maintenance engineering;complexity;automata;computational complexity business data processing;computational complexity;abstracts;business;process control;compliance;tautology;business process;hamiltonian path;business process regulatory compliance problem np complete problem core language structured process	Verifying whether a business process is compliant with a regulatory framework is a difficult task. In the present paper we prove the hardness of the business process regulatory compliance problem by taking into account a sub-problem of the general problem. This limited problem allows to verify only the compliance of structured processes with respect to a regulatory framework composed of a set of conditional obligations including a deadline. Experimental evidence from existing studies shows that compliance is a difficult task. In this paper, despite considering a sub-problem of the general problem, we provide some theoretical evidence of the difficulty of the task. In particular we show that the source of the complexity lies in the core language of verifying conditional obligations with a deadline. We prove that for this simplified case verifying partial compliance belongs to the class of NP-complete problems, and verifying full compliance belongs to the class of coNP-complete problems. Thus by proving the difficulty of a simplified compliance problem we prove that the general problem of verifying business process regulatory compliance is hard.	business process;co-np;karp's 21 np-complete problems;verification and validation	Silvano Colombo Tosatto;Guido Governatori;Pierre Kelsen	2015	IEEE Transactions on Services Computing	10.1109/TSC.2014.2341236	hamiltonian path;maintenance engineering;complexity;np-complete;tautology;computer science;bismuth;process control;database;semantics;automaton;management science;business process;computational complexity theory;algorithm	Logic	-55.31845853380423	20.41687032272813	165272
a250134facd3e79d5974fc6cb357da206fb2d979	towards a domain-specific modeling language for customer data integration workflow	domain model;workflow specification problem;formal specification;marketing data processing;data integrity;workflow management software formal specification marketing data processing;domain modeling;domain specific modeling language;customer data integration domain modeling workflow specification workflow automation;customer data integration workflow;workflow automation;workflow management software;workflow specification;customer data integration;work in progress;workflow specification problem domain specific modeling language customer data integration workflow;humans mesh generation business communication demography error correction pervasive computing transformers algorithms data processing cleaning	This paper describes the workflow specification problem, how workflows are specified today, requirements for improved workflow specification, and begins to sketch a new domain-specific modeling language (DSML) approach for specifying intent that can be used to constructively generate a complete workflow meeting a collection of intent requirements. This is an interim report on work in progress.	directory services markup language;domain-specific modeling;modeling language;requirement;specification (regression)	Wesley Deneke;Joshua Eno;Wing Ning Li;Craig W. Thompson;John R. Talburt;Jonathan Loghry;David Nash;Jeff Stires	2008	2008 The 3rd International Conference on Grid and Pervasive Computing - Workshops	10.1109/GPC.WORKSHOPS.2008.49	workflow;xpdl;computer science;domain model;data mining;database;windows workflow foundation;workflow management system;workflow engine;workflow technology	DB	-51.726221787901935	21.25298473081547	165978
4591160a37e33102d222367c748a0ac8e515067f	information and software technologies	information retrieval;software engineering;information storage	In this paper, we describe a model for extracting rules that describe enterprise resource planning (ERP) system upgrade process. The rules are extracted automatically by analyzing programming code from completed ERP systems upgrade projects. Later those rules are verified and tuned by experienced programmer. The rules that we are extracting are described in the language equivalent to the first-order logic (i.e. expressivity of Turing machine). Nevertheless, we put a constrain on the rules description language by defining how knowledge base is used to define these rules. We require that ERP system code and ERP upgrade knowledge base must be transformed to a series of aligned strings without lost of expressivity. Such strong requirement ensures that we are able to use existing machine learning algorithms in the process of software development and upgrade. These series of strings are compared by strings manipulation algorithms and then differences are resolved by merge algorithm presented in this paper. We used Microsoft Dynamics NAV as an example to test usefulness of presented method but other systems can be used as well if they can be presented as series of code	automation;erp;enterprise resource planning;first-order logic;first-order predicate;knowledge base;language identification in the limit;machine learning;merge algorithm;programmer;software development;turing machine;viterbi algorithm	Alfonsas Misevicius;Evaldas Guogis	2012		10.1007/978-3-642-33308-8	verification and validation;computing;information engineering;package development process;social software engineering;software development;software construction;data mining;database;automated information system;software analytics;software deployment;information retrieval;software system;human–computer information retrieval	SE	-50.43473941618808	24.31872446557281	166696
2ccafd1c4fdabc292b24e44cb6ad98e3700468ac	a flyweight uml modelling tool for software development in heterogeneous environments	formal specification;user interface software engineering specification languages java formal specification uml modelling tool software development heterogeneous environment life cycle phase;life cycle;user interface;heterogeneous environment;software engineering;development environment;software engineering specification languages software requirements and specifications;specification languages;software development;cost efficiency;formal specification software engineering specification languages java;modeling tool;java	A large and growing variety of tools can support all kinds of UML modeling aspects: from model creation to advanced round-trip engineering of UML models and code. However, such tools aim at supporting specific life-cycle phases, but they often do not meet basic requirements arising in heterogeneous environments, UML education, early life-cycle phases, or agile processes: hassle-free tool deployment, support for fast model sketching, and flexible graphic export features. We present the freely available modeling tool UMLet we designed to specifically address these basic issues. It is a flyweight Java application that can easily be deployed in various development environments; it features an intuitive and pop-up-free user interface, while still providing output to common high-quality publishing formats. Thus, the tool UMLet provides an effective way to teach UML and to create and share UML sketches, especially in agile environments and during early life-cycle phases. Its user interface supports intuitive and exploratory modeling, its architecture makes distribution and deployment cost-efficient in heterogeneous environments.	software development;uml tool;unified modeling language	Martin Auer;T. Tschurtschenthaler;Stefan Biffl	2003		10.1109/EURMIC.2003.1231600	metamodeling;software requirements specification;uml tool;computer science;systems engineering;software development;requirement;software engineering;applications of uml;programming language	SE	-49.11882352502982	24.853545644564285	167874
ab1d206f172ead9b614ac926f80aa9f9dbeec5f4	on the requirements analysis process for domain-specific languages in the realm of multi-perspective hospital modelling	use scenarios requirements analysis process domain specific languages multiperspective hospital modelling dsml process model;medical information systems formal specification health care hospitals;hospitals analytical models biological system modeling cancer information systems oncology	The analysis of requirements for Domain-Specific Modelling Languages (DSMLs) can be very challenging, since prospective users often do not have a clear idea of a DSML. This is especially the case if prospective users lack a technical background. This paper reports on the use of a dedicated method to support the analysis of requirements for DSMLs in hospitals. Apart from an elaborate process model, the method recommends developing a specific kind of use scenarios that serve as a medium to get users involved. The presented work was part of a larger project that is aimed at developing multi-perspective hospital models.	application domain;diagram;directory services markup language;domain-specific language;graphical user interface;information systems research;iterative method;iterative refinement;microsoft outlook for mac;process modeling;programming paradigm;prospective search;refinement (computing);requirement;requirements analysis;software development	Michael Heß;Ulrich Frank;Monika Kaczmarek;Lars Erik Podleska;Georg Täger	2014	2014 IEEE 1st International Workshop on the Interrelations between Requirements Engineering and Business Process Management (REBPM)	10.1109/REBPM.2014.6890733	computer science;systems engineering;knowledge management;management science	SE	-53.9601811219925	20.023730093524318	168203
f3da2f1fb529aa75ba918b7dcfbf9822f9c36f84	seaflows toolset - compliance verification made easy		In the light of an increasing demand on business process compliance, the veri cation of process models against compliance rules has become essential in enterprise computing. The SeaFlows Toolset featured in this tool demonstration extends process-aware information system by compliance checking functionality. It provides a user-friendly environment for modeling compliance rules using a graph-based formalism. Modeled compliance rules can be used to enrich process models. To address a multitude of veri cation settings, SeaFlows Toolset provides two compliance checking components: The structural compliance checker derives structural criteria from compliance rules and applies them to detect incompliance. The data-aware compliance checker addresses the state explosion problem that can occur when the data dimension is explored during compliance checking. It performs context-sensitive automatic abstraction to derive an abstract process model which is more compact with regard to the data dimension enabling more e cient compliance checking. Altogether, SeaFlows Toolset constitutes a comprehensive and extensible framework for compliance checking of process models.	business process;context-sensitive grammar;documentation;enterprise software;graph (discrete mathematics);information system;microsoft outlook for mac;process modeling;programming tool;semantics (computer science);usability	Linh Thao Ly;David Knuplesch;Stefanie Rinderle-Ma;Kevin Göser;Manfred Reichert;Peter Dadam	2010			real-time computing;computer science;data mining;database	SE	-54.949224923085076	20.03270655469081	168798
557e20b33c30286baaeed162dfddff6ad73bfb87	passi: process for agent societies specification and implementation		PASSI (a Process for Agent Societies Specification and Implementation) is a step-by-step requirement-to-code methodology for designing and developing multiagent societies, integrating design models and concepts from both ObjectOriented software engineering and artificial intelligence approaches using the UML notation. The models and phases of PASSI encompass anthropomorphic representation of system requirements, social viewpoint, solution architecture, code production and reuse, and deployment configuration supporting mobility of agents. PASSI is made up of five models, concerning different design levels, and 12 activities performed to build multiagent systems. In PASSI, the UML notation is used as the modeling language, since it is widely accepted both in the academic and industrial environments.	agent-based model;artificial intelligence;multi-agent system;requirement;software deployment;software engineering;solution architecture;system requirements;unified modeling language	Massimo Cossentino;Valeria Seidita	2014		10.1007/978-3-642-39975-6_10	systems engineering;engineering;software engineering;management science	AI	-54.52836564787282	22.395214979490547	169046
a69f3624cc03edb150edde713c13596ef9d40ea9	a wizard of oz component-based approach for rapidly prototyping and testing input multimodal interfaces	vertical science platform;software tool;multimodal interface;component based approach;wizard of oz;research paper;multimodality;patents;research platform;journals;icar;researchers network	In this paper we present a novel approach for prototyping, testing and evaluating multimodal interfaces, OpenWizard. OpenWizard allows the designer and the developer to rapidly evaluate a non-fully functional multimodal prototype by replacing one modality or a composition of modalities that are not yet available by wizard of oz techniques. OpenWizard is based on a conceptual component-based approach for rapidly developing multimodal interfaces, an approach first implemented in the ICARE software tool and more recently in the OpenInterface tool. We present a set of wizard of oz components that are implemented in OpenInterface. While some wizard of oz (WoZ) components are generic to be reused for different multimodal applications, our approach allows the integration of tailored WoZ components. We illustrate OpenWizard using a multimodal map navigator.	component-based software engineering;dataflow;dynamic dispatch;multimodal interaction;principle of abstraction;programming tool;prototype;rapid application development;rapid prototyping;simulation;test data;wizard (software);wizard of oz experiment;workstation	Marcos Serrano;Laurence Nigay	2010	Journal on Multimodal User Interfaces	10.1007/s12193-010-0042-4	simulation;human–computer interaction;computer science;world wide web	SE	-48.811541823666865	23.68623070346828	169314
585a9aaf0a5a111c8d3ce1fa7fbe7f8c01df9872	system integration by developing adapters using a database abstraction	adapter generation;esi embedded systems innovation;ts technical sciences;model driven development;communication information;incremental view maintenance;infostructures;information society;informatics;distributed systems;systems integration	Context: Large software systems are usually developed by integrating several smaller systems, which may have been developed independently. The integration of such systems often requires the development of a custom adapter (sometimes called mediator or glue logic) for bridging any technical incompatibilities between the systems. Adapter development often focuses on how to respond to events from the external interfaces, e.g., by applying data conversions and performing events on (other) external interfaces. Such an operational focus is closely related to an implementation of the adapter, but it makes it complicated to reason about complex adapters. For example, it requires a lot of effort to understand the relation that the adapter establishes between the systems to be integrated, and to avoid any internal inconsistencies. Objective: This article investigates a way to develop adapters in terms of a more abstract, model-based specification. Experts from the application domain should be able to reason about the specification, and the specification should contain enough details to generate an implementation. Method: Based on a few industrial adapters from the domain of Maritime Safety and Security, we study ways to specify them conveniently, and ways to generate them efficiently. On this basis, we identify an approach for developing adapters. In turn, this approach is validated using an additional set of adapters. Results: After abstracting from the details of the interface technologies, the studied adapters could be generated using techniques for incremental view maintenance. This requires an adapter specification in terms of database views to relate the main semantic concepts in the application domain. Conclusion: For developing adapters, it can be useful to model all interface technologies as database operations. Thus adapters can be specified using database views, which improve the conceptual understanding of the adapters. Publish/subscribe-style adapters can then be generated using incremental view maintenance.		Arjan J. Mooij	2013	Information & Software Technology	10.1016/j.infsof.2012.08.015	computer science;systems engineering;engineering;software engineering;data mining;database;informatics;world wide web;system integration	Robotics	-51.81481051119054	20.083152213255367	170471
a6264ca91dced220260b41ff31e14fc079029994	epitomes of four other cases	language use;formal specification;building block;printed circuit board	Abstract   This document is one of the parts of the electronic version of the PhD thesis by S.F.M. van Vlijmen [42]. The goal of the PhD project was to get a better understanding of the problems with the integration of formal specification technique in the day to day software practice. The approach followed was to execute a number of projects in cooperation with industry on realistic cases.  In this document is reported on four other cases in a succint manner. For each case the system studied is described, the formal specification work done is discussed, and the case is evaluated.  The first case describes the modelling in PSF of a model of a production facility for printed circuit boards. The second case is about the modelling of telephone services following the Service Independent Building block architecture. The language used was again PSF. The third case is about the syntax of a language for the programming of railway safety systems. Here the language definition system ASF+SDF was used. The fourth and final case is about a system that optimizes the replacement schedules for light bulbs in traffic regulation systems. ACP, PSF and Pascal are the languages used.		Sebastiaan van Vlijmen	1999	Electr. Notes Theor. Comput. Sci.	10.1016/S1571-0661(05)01191-6	simulation;specification language;computer science;formal specification;printed circuit board;programming language;algorithm	ECom	-52.900128852550694	22.54888529397231	170475
2283bedae0f982e2ddd6552d188ed6de72806d71	tools for the creation of ims database designs from entity-relationship diagrams	entity relationship model;software tool;general and miscellaneous mathematics computing and information science;design technique;database design;database management system;programming;data base management;management 990200 mathematics computers;extended entity relationship;entity relationship	This paper presents an overview of a system of software tools that can be used in preparing database designs. The design technique is based on the Entity-Relationship model - the tools allow a designer to conveniently develop an Entity-Relationship model, from which an Extended Entity-Relationship model is produced. The extended Entity-Relationship model is used as input to tools that generate the basic design appropriate to the target database management system. This paper reports on only the tools to generate an IMS design from the extended Entity-Relationship model.	diagram;entity–relationship model	G. Margrave;Ewing L. Lusk;Ross A. Overbeek	1983			entity–relationship model;computer science;systems engineering;data mining;database;database design	EDA	-50.54563155437379	23.526751666814132	170845
6676b43d2a2b81cfd080a77e967d2e6ef912bef0	collaborative creation and versioning of modeling languages with metaedit+		Language engineering is a collaborative endeavor with several people creating and using the modeling languages and related generators. We describe key features of the MetaEdit+ multi-user version that support collaborative language engineering, evolution and use. Several language engineers can create and refine the same modeling language at the same time, see each other's changes, and version language definitions to version control systems. A key characteristic of MetaEdit+ is continuous integration of language definitions and of models created with the languages.	comment (computer programming);continuous integration;control system;diff utility;metaedit+;metamodeling;modeling language;multi-user;user interface;version control	Steven Kelly;Juha-Pekka Tolvanen	2018		10.1145/3270112.3270132	software engineering;modeling language;systems engineering;software versioning;metamodeling;code generation;computer science;domain-specific language;control system	PL	-49.46267273888656	24.97326815285001	170948
2b8a52423e0b6224098248eab576cdad6282b064	preface to wism 2011		The international workshop on Web Information Systems Modeling (WISM) aims to uncover the most recent developments in the field of model-driven design of Web Information Systems (WIS). This is the eighth edition of the workshop, after seven successful editions organized in Vancouver (2010), Amsterdam (2009), Barcelona (2008), Trondheim (2007), Luxembourg (2006), Sydney (2005), and Riga (2004). The extended abstract of the invited talk by de Oliveira et al. proposes concepts for Social Network Analysis to be applied for online Academic Social Networks. More specifically, it investigates the network analysis, work dissemination, and partner recommendation in an academic context. The social network based on co-author relationships among researchers is used as an example. The first paper by McGinnes proposes research directions for handling data exchange between heterogeneous WIS. These research directions are developed around the idea of building a basic ontology containing a simple set of shared concepts. The author argues that knowing the types of the shared concepts is not enough to ensure WIS interoperability, as WIS need be able to programmatically handle these types. The second paper by Aguilar et al. suggests a solution for selecting the appropriate WIS requirements in order to maximize the user satisfaction with respect to a prioritized list of non-functional requirements. The approach is based on detecting the Pareto front of candidate solutions and selecting the ones that ensure the fulfillment of the highly ranked non-functional requirements. For demonstration purposes the authors use the requirements of an online Conference Management System represented using the i∗ framework. The third paper by Boukhebouze et al. proposes UI-BPEL, an extension of BPEL that allows the modeling of user interaction (providing, selecting, and getting data by the user) in Web service composition. The main of goal of UI-BPEL is to allow the generation of user interfaces based on the described user interactions. This process is composed of two steps: the generation of an abstract user interface independent of any interaction modality and computing platform, and the generation of a concrete user interface based on the abstract user interface that is adapted to the user specific context. The fourth paper by Bianchini et al. describes an approach for rapid WIS development by composing existing Web APIs. The composition is based on selection patterns that exploit functional similarities and coupling criteria. For this purpose Web APIs are annotated using existing lightweight semantic models extended with semantically annotated events. We do hope that the previous synopsis has triggered the reader’s interest to have a closer look at the workshop proceedings. Last, we would also like to thank all the authors, reviewers, and participants for their input and support for the workshop.	business process execution language;coupling (computer programming);functional requirement;information system;interaction;interoperability;management system;modality (human–computer interaction);model-driven architecture;model-driven engineering;non-functional requirement;pareto efficiency;sensor;service composability principle;simple set;social network analysis;systems modeling;user interface;video synopsis;web service	Flavius Frasincar;Geert-Jan Houben;Philippe Thiran	2011		10.1007/978-3-642-24574-9_1	web service;web modeling;computer science;software engineering;data mining;database;operations research;world wide web	SE	-48.43188533704971	20.468822334025546	171159
57dcc501408d145fadf3e79f9ff638005be033ba	a component's framework based on the mvc pattern for the integration of data and tools on the molecular biology domain	molecular biology domain;biology computing;enterprise javabeans;javabeans;information extraction;javaserver faces;object oriented programming;data distribution;frameest;molecular biology;software reusability;molecular biophysics;distributed object management;enterprise javabean;mvc pattern;model view control pattern;software reuse mvc pattern data integration molecular biology domain information extraction frameest model view control pattern javaserver faces javabeans enterprise javabeans;software reusability biology computing distributed object management java molecular biophysics object oriented programming;software reuse;data integration;java data mining information analysis biology computing application software distributed databases biological system modeling software tools distributed computing pattern analysis;java	In the domain of molecular biology, applications extract and analyze information of heterogeneous sources of data, distributed in different databases and text files. These applications can also use many different tools available in the domain of molecular biology to analyze and format the information extracted from these data sources. This diversity of data sources and tools make difficult the integration of them on the applications of this domain. Willing to solve this problem, this paper presents a framework of components called FrameEST, based on the MVC (model view control) pattern that not only integrates data and tools, but also support the development based on reuse. The FrameEST was built using the JavaServer Faces (view and control layers), JavaBeans and Enterprise JavaBeans (model layer) technologies to facilitate the reuse of software. As an example, it is also presented an application of the molecular biology domain developed reusing the components of FrameEST	database;enterprise javabeans;javaserver faces;model–view–controller	Luiz Roberto Lombardo;Mauro Biajiz;Antônio Francisco do Prado	2006	2006 IEEE International Conference on Information Reuse & Integration	10.1109/IRI.2006.252446	domain analysis;real-time computing;computer science;data integration;domain engineering;database;javabeans;programming language;object-oriented programming;model–view–controller;java;information extraction;molecular biophysics	Visualization	-50.8188172055958	19.174575117738467	172113
e767709f357fedfde0987e5b308ff19274f423d2	a comparison of uml and owl in the travel domain		Recent research has focused towards determining the efficacy of using UML as an ontology modelling language [6, 7, 8, 12]. In this paper we compare the use of UML with the Web Ontology Language – OWL for modelling the travel domain. One conclusion resulting from this study is that OWL and UML were devised with different motivations, and for supporting different types of application domains. Owl benefits from a solid theoretical basis in description logic, which means it has a well defined semantics, formal properties are well understood, and there are known reasoning algorithms and implementations of the language. In addition to the model comparison we propose an ontology quality framework. The quality framework is one step towards defining quality measures for ontology modelling.	algorithm;description logic;model selection;unified modeling language;web ontology language	Jennifer Sampson	2004			uml tool	Web+IR	-54.20512694186081	22.092241972776943	172352
4614c9e7a214262adf143336a27b2a2c6db80b3f	trends on cots component identification	ontologies artificial intelligence software packages object oriented programming;proposals business ontologies taxonomy information analysis context aware services logic mechanical factors testing software systems;object oriented programming;ontologies artificial intelligence;commercial off the shelf package cots component identification description logic cots component discovery process cots component classification;description logic;software packages	Identification of COTS candidates is a complex activity itself. It implies not only dealing with an impressive number of possible candidates but also with unstructured information that requires a careful analysis. In this context, some proposals currently use description logics to develop an ontology for matching requested and provided services, or propose taxonomies for classification; others suggest extending the identification stage with a learning phase, which provides support to the COTS component discovery process. In this paper, we present common features and differences among some of these proposals, identifying relevant issues for COTS component classification and identification in the near future.	description logic	Alejandra Cechich;Annya Réquilé-Romanczuk;Javier Aguirre;Juan M. Luzuriaga	2006	Fifth International Conference on Commercial-off-the-Shelf (COTS)-Based Software Systems (ICCBSS'05)	10.1109/ICCBSS.2006.31	computer science;systems engineering;data mining;database	SE	-48.47109543479018	19.15186209320019	172998
fc9ff36ffcb231a0e2580647bf806db7b150023e	a reverse engineering method and experiences for industrial cobol system	formal specification;business rule;cobol;software maintenance;reverse engineering data mining steel information technology research and development data engineering costs information systems employment business process re engineering;reuse;data modeling;systems analysis;systems analysis reverse engineering cobol formal specification;restructuring;re engineering;reverse engineering;system restructuring reverse engineering method industrial cobol system business specification reusable business specification data oriented re engineering	One of the most important things in restructuring current system is to clarify business specification which are implemented in the current system Reverse engineering technology, which extracts reusable business specification from a system, is very effective for this purpose. We have developed DORE (Data Oriented ReEngineering), a re-engineering methodology for system restructuring, and tools that support reverse engineering. By using these methodology and tools, it becomes possible to extract business specification which should be implemented in the new system, from the current system In this paper, we present the re-engineering methodology and tools, and introduce a case study in Kawasaki Steel Corporation, in which those methodology and tools are used.	cobol;reverse engineering	Ikuyo Nagaoka;Katsuaki Sanou;Daisuke Ikeo;Michio Tsuda;Shin'ichi Akiba	1997		10.1109/APSEC.1997.640179	reliability engineering;data modeling;systems analysis;information engineering;system of systems engineering;computer science;systems engineering;engineering;software engineering;restructuring;system requirements specification;formal specification;reuse;cobol;programming language;software maintenance;business rule;reverse engineering	SE	-52.408951865092355	21.246191261660464	173489
16b530ab1c43b2974cf42839667971daa5006304	variability in business processes: automatically obtaining a generic specification		Abstract The existence of different process variants is inevitable in many modern organizations. However, variability in business process support has proven to be a challenge as it requires a flexible business process specification that supports the required process variants, while at the same time being compliant with policies and regulations. Declarative approaches could support variability, by providing rules constraining process behavior and thereby allowing different variants. However, manual specification of these rules is complicated and error-prone. As such, tools are required to ensure that duplication and overlap of rules is avoided as much as possible, while retaining maintainability. In this paper, we present an approach to represent different process variants in a single compound prime event structure, and provide a method to subsequently derive variability rules from this compound prime event structure. The approach is evaluated by conducting an exploratory evaluation on different sets of real-life business process variants, including a real-life case from the Dutch eGovernment, to demonstrate the effectiveness and applicability of the approach.		N. R. T. P. van Beest;Heerko Groefsema;Luciano García-Bañuelos;Marco Aiello	2019	Inf. Syst.	10.1016/j.is.2018.09.005	data mining;maintainability;business process;prime (order theory);business process modeling;computer science;temporal logic;event structure	DB	-55.22461939523476	19.92555321305498	174150
04b6204bc85c9fc500a72c9775b5b51334233876	network engineering for agile belief network models	elicitation;belief networks;management system;design and development;systems engineering;knowledge base agile belief network models large complex belief network model belief network engineering process spiral system lifecycle model numerical probability distributions random variables structural assumptions semantic information modeling decisions;semantic information;rapid prototyping;agile modeling;probability distribution;random variable;system development;prototypes power system modeling probability distribution knowledge engineering spirals random variables refining knowledge representation design engineering power engineering and energy;knowledge representation;belief network;knowledge base	ÐThe construction of a large, complex belief network model, like any major system development effort, requires a structured process to manage system design and development. This paper describes a belief network engineering process based on the spiral system lifecycle model. The problem of specifying numerical probability distributions for random variables in a belief network is best treated not in isolation, but within the broader context of the system development effort as a whole. Because structural assumptions determine which numerical probabilities or parameter values need to be specified, there is an interaction between specification of structure and parameters. Evaluation of successive prototypes serves to refine system requirements, ensure that modeling and elicitation effort are focused productively, and prioritize directions of enhancement and improvement for future prototypes. Explicit representation of semantic information associated with probability assessments facilitates tracing of the rationale for modeling decisions, as well as supporting maintenance and enhancement of the knowledge base. Index TermsÐBelief networks, knowledge representation, elicitation, systems engineering, rapid prototyping, agile modeling.	agile modeling;agile software development;bayesian network;canonical account;complex network;configuration management;design rationale;documentation;knowledge base;knowledge representation and reasoning;network model;numerical analysis;rapid prototyping;requirement;requirements elicitation;semantic network;system lifecycle;system requirements;systems design;systems engineering	Kathryn B. Laskey;Suzanne M. Mahoney	2000	IEEE Trans. Knowl. Data Eng.	10.1109/69.868902	probability distribution;random variable;knowledge base;computer science;knowledge management;artificial intelligence;machine learning;requirements elicitation;bayesian network;data mining;management system;management science;statistics	AI	-52.25129457306199	22.01523927608692	174416
d613dfd71bad0313ec2d0b05c9a619d190fe0d35	semi-automated model matching using version difference	pattern generation;data exchange;architecture engineering and construction;data model;schema matching;large scale;model matching;software development;software package;industry foundation classes;domain specificity	Interoperability of software is a critical requirement in the architecture, engineering, and construction (AEC) industry, where a number of data exchange standards have been created to enable data exchange among different software packages. To be able to comply with existing data exchange standards, the software developers need to match their internal data schemas to the schema defined in a standard and vice versa. The process of matching two large scale data models is time consuming and cumbersome when performed manually, and becomes even more challenging when a source and/or a target model is being updated frequently to meet the ever expanding real world requirements. While several prior studies discussed the need for approaches toward automated or semi-automated schema matching, an approach that builds on existing matches between two models has rarely been studied. In this paper, we present a semi-automated approach for model matching. This approach leverages a given set of existing matching between two models and upgrades those matching when a new version of a target model is released. The paper describes in detail a list of upgrade patterns generated and validated through a prototype by matching a domain-specific data model to several recent releases of the industry foundation classes.	semiconductor industry	Hongjun Wang;Burcu Akinci;James H. Garrett;Eric Nyberg;Kent A. Reed	2009	Advanced Engineering Informatics	10.1016/j.aei.2008.05.005	data exchange;semi-structured model;data model;computer science;artificial intelligence;software development;software engineering;data mining;database;world wide web	DB	-53.6537716178984	21.8974438042475	175445
b253694f10f7bbbe4c053255043aaa1167afd596	from ontology charts to class diagrams: semantic analysis aiding systems design	class diagram;semantic representation;unified process;business modelling;endnotes;uml class diagram;business model;system design;unified modelling language;software development;pubications;semantic analysis;object oriented paradigm	Despite the broader adoption of the Object Oriented paradigm of software development and the usefulness of the Unified Modelling Language, there still are aspects of business modelling not well captured and represented. Previous literature in Organisational Semiotics has shown that its methods could facilitate a converging process for reaching a semantic representation, which delivers an agreed business model. In this paper we define a process for informing UML class diagrams with results of Semantic Analysis. We provide a group of heuristic rules to aid the construction of a preliminary class diagram from an ontology chart.	class diagram;computer;first draft of a report on the edvac;heuristic;ontology chart;operating system;programming paradigm;semiotics;software development;systems design;unified modeling language	Rodrigo Bonacin;Maria Cecília Calani Baranauskas;Kecheng Liu	2004			semantic computing;communication diagram;computer science;knowledge management;function model;class diagram;data mining;database;business process model and notation;management;business process modeling	SE	-54.366699793461756	21.35845716757439	176192
e76773efba1222f27282f8659e4bc2e56814c2da	component-based software engineering	component based software engineering;system software;distributed computing;object oriented programming;software engineering;books;computer architecture;software architecture;ink;software engineering books object oriented modeling object oriented programming conferences computer architecture software architecture distributed computing ink system software;object oriented modeling;conferences	"""ick up just about any software trade journal, and you'll find yourself inundated with something about components: there's Microsoft's DNA, Sun's Enterprise JavaBeans and Java Platform for the Enterprise, IBM's San Francisco project, the componentization of SAP's R/3—the list goes on. It's easy to see that a discipline is emerging, and yet there's little agreement on what """" components """" and """" component-based software engineering """" are. We thought it would be both interesting and useful to take a snapshot of this emerging domain so as to help IEEE Software's readers understand some of its key aspects. In the last few years, components and component-based software engineering have gained substantial interest in the software community. Conceptually, CBSE unifies concepts from a number of software domains, such as object-oriented programming , megaprogramming, software architecture, and distributed computing. Indeed, it appears that the two main drivers for CBSE are the emergence of commercial distributed-computing infrastructures such as DCOM and Corba, and the increasing need for interoperability of independently developed software """" chunks. """" The rate of change in the software world is such that shortly after the ink dries on this issue, we can only hope to have captured a snapshot of a rapidly maturing domain. To this end, we were pleasantly surprised at the large number of Components are """" hot, """" and changing at a fast pace. Here are industry forecasts from t wo leaders in the field, followed by a state-of-the-practice over view and some of the latest work in CBSE."""	common object request broker architecture;component-based software engineering;distributed component object model;distributed computing;emergence;enterprise javabeans;ieee software;interoperability;java;snapshot (computer storage);software architecture	Wojtek Kozaczynski;Grady Booch	1998	IEEE Software	10.1109/MS.1998.714621	reference architecture;software architecture;model-driven architecture;architecture tradeoff analysis method;verification and validation;computing;software sizing;computer science;software design;social software engineering;software framework;component-based software engineering;software development;software engineering;software construction;software architecture description;software walkthrough;programming language;object-oriented programming;resource-oriented architecture;software deployment;software system;computer engineering	SE	-50.94323101957172	20.466010904042584	177007
38ade164a7e5eb284ec0003d76fa549870beeca5	preface to the special section on agent-oriented design methods and programming techniques for distributed computing in dynamic and complex environments	complex environment;programming technique;special section;agent-oriented design method	Agent-based approaches have become quite popular as design methods and programming techniques for, broadly understood, distributed computing. In particular, they turn out to be effective in the development of systems for dynamic and complex environments, where they can provide the needed flexibility and robustness. In this context, we can also observe that the field of agent technology is maturing. One of the key factors that influence this process is the gathered body of knowledge that allows ever more complete reflection on the nature of design and implementation of agent systems. These processes can be observed at all levels of the ‘‘software stack’’ represented through the specific topics covered in this special section. First, we can see the emergence of new formalisms for agent-based systems, for instance the AML or the API Calculus. Furthermore, existing methodologies for agent system design and implementation are starting to be supported by tools that not only allow top level (proto)formalization, but also guide the design process from the initial conceptualization towards the implementation (e.g. by generating foundations of the initial code). Separately, existing tools/platforms/environments have evolved through a number of releases, eliminating early stage problems and adding a number of new, important, features. Resulting products are becoming truly robust and flexible. Finally, open source products (e.g. JADE) are surrounded by user communities, which often generate powerful add-on components, further increasing the value of the existing solutions. Through all these processes, combined with an increasing number of demonstrator systems, we gain in-depth understanding of most important issues in the general area of Agent-Oriented Software Engineering (AOSE). These issueswill have to be addressed by futuremethodologies, formalisms, languages, and tools developed to support the design and implementation of agent systems. In this context, the workshop Agent Based Computing – from Model to Implementation (ABC:MI) held at Wisła, Poland, on 18–20October 2010, was a very interesting opportunity to involve researchers in the agent area in an in-depth discussion of their research work. The peculiarity of this workshop was its call for papers that explicitly connect the design aspects to the implementation ones. From this workshop, a need arose for a special section of a high quality journal, highlighting the current situation and reflecting the state of the art. Starting from these considerations, this special section of the journal Science of Computer Programming aims at proposing an up-to-date picture of the situation in AOSE in connection with the previously mentioned topics, by means of presenting high quality papers that show the state of the art in research work related to a pathway from the model of the problem domain to the actual agent-based solution.We invited the submission of the best papers from the ABC:MI workshop, and, at the same time, we made an open call in order to gather additional high quality papers. The call attracted 18 papers. After a thorough refereeing process, seven of themwere selected for publication. In the following, readers can find a brief summary of each paper. In ‘‘Towards a next-generation AOSE methodology’’, Michael Winnikoff and Hoa Khanh Dam consider the existence in the literature of a very large number of methodologies for the developing of agent systems. Their sheer number creates a challenge to practitioners, who need to select a methodology to adopt in their project(s). This situation seems to be analogous to that of object-oriented methodologies and notations before the successful introduction of the UML, and the authors argue that the time is ripe to begin the development of a next generation Agent-Oriented Software Engineering (AOSE) methodology, with the ultimate goal of the creation of a unified AOSE methodology. This paper outlines processes andmodels for such a next generation AOSEmethodology. The authors’ proposal is based on a comparative analysis of seven prominent AOSE methodologies, with identified strengths, weaknesses, commonalities and differences. ‘‘A model-driven CASE tool for developing and verifying regulated open MAS’’, by Emilia Garcia, Adriana Giret, and Vicente Botti, concerns the development of agent-based complex systems. In particular, the authors propose a CASE tool for supporting the agent developers in their jobs. Such a tool is based on model-driven technologies in order to integrate	api-calculus;add-ons for firefox;agent-based model;agent-oriented software engineering;application programming interface;complex systems;computer programming;computer-aided software engineering;conceptualization (information science);display resolution;distributed computing;emergence;gene regulatory network;hoa;jade;model-driven architecture;model-driven integration;open-source software;problem domain;qualitative comparative analysis;robustness (computer science);systems design;unified modeling language;verification and validation	Giacomo Cabri;Maria Ganzha	2013	Sci. Comput. Program.	10.1016/j.scico.2012.01.001	computational science;computer science;theoretical computer science;distributed design patterns	SE	-54.01985877685554	22.470399081051976	177150
e0284c509a4e21de9b8c8708f91ab2f6117e1589	modeling asset information for interoperable software systems	data models unified modeling language object oriented modeling mechanical factors semantics standards software;software;property management;standards;asset management;semantics;service oriented architecture meta model interoperability asset management property management;mechanical factors;manufacturing data processing;unified modeling language;industrial facility asset information modelling interoperable software systems technical infrastructure asset information sharing software tools semantical level service oriented architecture;software tools;interoperability;software tools manufacturing data processing open systems service oriented architecture;service oriented architecture;open systems;object oriented modeling;meta model;data models	Software of various domains needs to access information on assets in an industrial facility. For this purpose, it is not only necessary to provide the required technical infrastructure, but also to have a common understanding of the way assets are modeled. Since globally valid models are currently not available, sharing asset information between different software tools is hard to accomplish. In this paper, a basic model for information on assets is introduced, which only involves the common, fundamental concepts. The model is described both on a semantical level and with respect to its implementation. Finally, an outlook on the integration in a service-oriented architecture is given.	centralized computing;data model;information model;interoperability;microsoft outlook for mac;programming paradigm;prototype;service-oriented architecture;service-oriented device architecture;software system	David Kampert;Ulrich Epple	2012	IEEE 10th International Conference on Industrial Informatics	10.1109/INDIN.2012.6301179	reusability;computer science;systems engineering;software engineering;database	SE	-52.51005217305648	24.452297578049027	177336
c7e4562b21080d2d53b9efb2e25536512657b68d	task knowledge patterns reuse in multi-agent systems development	advisor finder;task knowledge patterns;swinburne;agent oriented modeling	Template-based knowledge models can be viewed as design patterns for specifying a task [12]. The models can serve as reusable artifacts during the development of a multi agent system using the MAS-CommonKADS methodology. However, based on our observation of existing patterns, we note limitations of reusing those patterns in agent development. This paper presents task knowledge patterns that are described through our improved agent oriented template structure. The improved template structure presented in this paper provides an alternative approach to defining task knowledge patterns by incorporating a two dimensional view of agent oriented models. The task knowledge patterns introduced in this paper describe task knowledge in an agent context, while explicitly providing a description designed to encourage use and reuse in agent oriented software development. A demonstration of the reuse of task knowledge patterns in agent oriented modelling is presented in this paper. Specifically we show how a particular task knowledge pattern, selection of relevant source materials, can be used to rapidly prototype an adviser finder multi-agent system.		Wai Shiang Cheah;Leon Sterling;Kuldar Taveter	2010		10.1007/978-3-642-25920-3_33	simulation;computer science;knowledge management;data mining;task analysis	AI	-50.44684217426045	21.723465206645773	178403
987251fd1ed18ae3476f76d15af3fb57141f8c8f	a strategy for reducing the effort for database schema maintenance	precisely defined schema transformations;schema transformation;schema design;formal specification;software maintenance;database management systems;process design;conceptual schema;systems analysis;documentation database systems process design costs;software reusability;database systems;database design process;design documentation;database design;precisely defined schema transformations database schema maintenance typical database design conceptual schema database management system dbms schema design documentation database design process schema design;dbms schema;database schema maintenance;typical database design;database management system;formal specification database management systems systems analysis software reusability software maintenance;documentation	In a typical database design, a conceptual schema which specifies the requirements about the database is first built. Then it is transformed, either in a single or in a multiple step, into a schema which is in a form suitable for the chosen database management system. When requirements change, the conceptual schema must be updated and the modifications must be propagated down to the DBMS schema, with possibly, a replaying of most processes that were carried out when the system was built. In order to minimize the effort required to propagate these changes, methods based on the reuse of the previous design documentation are often advised. These methods are generally only roughly specified. This partially reduces the advantages of reuse since it demands important choices that require a deep understanding of the whole database design process. The paper shows how this problem can be overcome in a framework in which the schema design is carried out through precisely defined schema transformations.	database schema	Donatella Castelli	1998		10.1109/CSMR.1998.665729	schema migration;process design;systems analysis;information schema;documentation;computer science;systems engineering;conceptual schema;data mining;formal specification;database;document schema definition languages;software maintenance;view;database schema;database design	DB	-51.03479960512498	22.851870977892045	178930
de6ea12417e5d7f290b8ed0e7e126b352e73cfda	archimedes: a model-driven framework for the specification of service-oriented architectures	service orientation;software architecture;model driven engineering	This paper presents a framework for the Model-Driven specification of Software Architectures, which is defined using the concepts behind Service-Orientation. The framework described, denominated as ArchiMeDeS, represents the following: a coherent solution to the problem of architecting the existing gap between the high-level configuration of a software system by describing the business entities and relationships required by a software solution, and its low-level representation, in which the technological aspects determine the final shape of the system, providing technical support to the previously identified business processes and constraints. We also provide a set of transformation rules, which semi-automatically advance in the Architecture specification. These rules allow progress to be made from conceptual architectural models to more technologically dependent ones. The feasibility of the proposed service-oriented framework is validated by showing its usage capabilities in the definition of a software solution in the field of neuroscience research.	acorn archimedes;model-driven architecture;service-oriented architecture	Marcos López Sanz;Esperanza Marcos	2012	Inf. Syst.	10.1016/j.is.2011.11.002	reference architecture;software architecture;model-driven architecture;software requirements specification;simulation;architectural pattern;computer science;software design;software framework;software development;data mining;database;software architecture description;resource-oriented architecture;software system	DB	-54.25286065198648	23.816709175442792	178960
01f48a8ae314e9169452cd8735600ea71498cb13	towards efficient business process clustering and retrieval: combining language modeling and structure matching	efficient approach;query business process;business process;industry best practice process;process description document;similar process;towards efficient business process;structure matching;process control flow;language modeling;overall process management;real-world business process	Large organizations tend to have hundreds of business processes. Discovering and understanding similarities among business processes can be useful to organizations for a number of reasons including better overall process management and maintenance. In this paper we present a novel and efficient approach to cluster and retrieve business processes. A given set of business processes are clustered based on their underlying topic, structure and semantic similarities. In addition, given a query business process, top k most similar processes are retrieved based on clustering results. In this work, we bring together two not wellconnected schools of work: statistical language modeling and structure matching and combine them in a novel way. Our approach takes into account both high-level topic information that can be collected from process description documents and keywords as well as detailed structural features such as process control flows in finding similarities among business processes. This ability to work with processes that may not always have formal control flows is particularly useful in dealing with real-world business processes which are not always described formally. We developed a system to implement our approach and evaluated it on several collections of industry best practice processes and real-world business processes at a large IT service company that are described at varied levels of formalisms. Our experimental results reveal that the combined language modeling and structure matching based retrieval outperforms structure-matching-only techniques in both mean average precision and running time measures.	best practice;business process;cluster analysis;composite data type;control flow;dataflow;documentation;high- and low-level;information retrieval;language model;process modeling;time complexity	Mu Qiao;Rama Akkiraju;Aubrey J. Rembert	2011		10.1007/978-3-642-23059-2_17	business domain;computer science;knowledge management;artifact-centric business process model;data science;process modeling;data mining;database;process mining;business process discovery;business rule;business process modeling	Web+IR	-52.985089733160294	18.423495502379883	179079
e4a4a4bc9e80ec64f81a6838fcdaf99a8220684a	using a collaboration model to classify artifacts in software product line for collaborative systems	artifact location enhancement collaboration model spl artifact classification enhancement software product line collaborative systems model driven development approach mdd models collaboration elements feature classification uml profile artifact reuse enhancement;unified modeling language collaborative work collaborative software computer integrated manufacturing analytical models computational modeling;profile software product lines mda mdd groupware collaborative systems;unified modeling language groupware pattern classification software product lines	Collaborative Systems can be constructed through Software Product Line (SPL) with the support of the Model-Driven Development (MDD) approach. However, models generated as SPL artifacts usually present only feature classification. Such models neither express the purpose of each SPL artifact of the systems composition nor the way they were associated with the collaboration elements. Therefore, to support the analysis and design of collaborative systems it is relevant to classify artifacts with the support of a collaborative model. This paper describes a way a collaboration model can be used to construct a UML profile. This profile is applied to MDD models that represent collaboration artifacts, enhancing the classification, location and reuse of artifacts in order to support the development of Collaborative Systems.	collaborative software;model-driven architecture;model-driven engineering;profile (uml);software product line;statistical classification;unified modeling language	Cristiana Pereira Bispo;José Maria N. David;Rita Suzana Pitangueira Maciel	2014	Proceedings of the 2014 IEEE 18th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2014.6846899	computer science;data mining;database	SE	-52.08770539162493	23.25586020119796	179254
70c01d49ede9a14ef6bb4602b0f03fa3647ddc6d	document recognition, semantics, and symbolic reasoning in reverse engineering of software	reverse engineering	The SoftDocs project at Concordia University investigates knowledge acquisition from software documents and the analysis of that knowledge for reverse engineering of legacy systems. It focusses on the recognition and analysis of diagrams rather than natural language processing of textual components of a software document. Rigorous analysis of diagrams requires a formal semantics for them, and utilises tools for symbolic reasoning.		Gregory Butler;Peter Grogono;Rajjan Shinghal;Indra A. Tjandra	1996		10.1007/3-540-61732-9_49	natural language processing;computer science;database;programming language;reverse engineering	SE	-50.32526251899505	24.662076657805038	179566
48b6cd8ab8a4504b10330f570f7ef3b59d44b88b	assisting end-user development in browser-based mashup tools	automated pattern;complex composition pattern;mashup model;composition knowledge;relevant composition pattern;intimate knowledge;knowledge reuse;end-user development;browser-based mashup tool;mashup application development;engines;web services;application development;programming;prototypes;data mapping;composition pattern;mashups;knowledge based systems;web api;context modeling;weaving	Despite the recent progresses in end-user development and particularly in mashup application development, developing even simple mashups is still non-trivial and requires intimate knowledge about the functionality of web APIs and services, their interfaces, parameter settings, data mappings, and so on. We aim to assist less skilled developers in composing own mashups by interactively recommending composition knowledge in the form of modeling patterns and fostering knowledge reuse. Our prototype system demonstrates our idea of interactive recommendation and automated pattern weaving, which involves recommending relevant composition patterns to the users during development, and once selected, applying automatically the changes as suggested in the selected pattern to the mashup model under development. The experimental evaluation of our prototype implementation demonstrates that even complex composition patterns can be efficiently stored, queried and weaved into the model under development in browser-based mashup tools.	end-user development;interactivity;mashup (web application hybrid);prototype;web application	Soudip Roy Chowdhury	2012	2012 34th International Conference on Software Engineering (ICSE)		web service;programming;computer science;knowledge-based systems;database;prototype;multimedia;context model;rapid application development;management;world wide web;weaving;composite pattern;mashup	SE	-49.672977948047354	21.15759167455265	179660
26a1a0b3bf83fe5cbdc8e4cee8d2ec118ab1187b	a comparison of using taverna and bpel in building scientific workflows: the case of cagrid		"""With the emergence of """"service oriented science,"""" the need arises to orchestrate multiple services to facilitate scientific investigation-that is, to create """"science workflows."""" We present here our findings in providing a workflow solution for the caGrid service-based grid infrastructure. We choose BPEL and Taverna as candidates, and compare their usability in the lifecycle of a scientific workflow, including workflow composition, execution, and result analysis. Our experience shows that BPEL as an imperative language offers a comprehensive set of modeling primitives for workflows of all flavors; while Taverna offers a dataflow model and a more compact set of primitives that facilitates dataflow modeling and pipelined execution. We hope that this comparison study not only helps researchers select a language or tool that meets their specific needs, but also offers some insight on how a workflow language and tool can fulfill the requirement of the scientific community."""		Wei Tan;Paolo Missier;Ian T. Foster;Ravi K. Madduri;David De Roure;Carole A. Goble	2010	Concurrency and computation : practice & experience	10.1002/cpe.1547	business process execution language;computer science;data science;data mining;database;programming language;functional programming	HPC	-50.19294488077172	21.629008897494487	180792
5496047ee7dae2fed7768785e2cc72c4c33174f6	managing license compliance in free and open source software development	license compliance;compatibility analysis;compliance management;rights expression languages;free and open source software	License compliance in Free and Open Source Software development is a significant issue today and organizations using free and open source software are predominately focusing on this issue. The non-compliance to licenses in free and open source software development leads to the loss of reputation and the high costs of litigation for organizations. Towards an automated compliance management, we use the Open Digital Rights Language to implement the clauses of open source software licenses in a machine interpretable way and propose a novel algorithm that analyzes compatibility between free and open source software licenses. Also, we describe a framework that inductively manages compliance of license clauses in a free and open source software development. We simulate and evaluate the formalized license compliance management by analyzing a real-time open source software project GRASS.	algorithm;comparison of free and open-source software licenses;real-time web;simulation;software development;software license;software project management	G. R. Gangadharan;Vincenzo D'Andrea;Stefano De Paoli;Michael Weiss	2012	Information Systems Frontiers	10.1007/s10796-009-9180-1	sqale;open format;software development;software asset management;database;open source hardware;world wide web;computer security	SE	-48.639992999418915	18.914339634653928	181013
bf55438ee5a90b449329f8d026073deaac418051	modeling of services and service collaboration in uml 2.0.		One of many definitions of Service-Oriented Architecture (SOA) says that SOA is an architectural style for building next-generation distributed information systems. If wc want to get a reliable arrd good working system, it must be well designed first. This paper deals with Scrvice-Oriented Architecture Design (SOAD), especially with modeling of scrviccs. F\rrthermore, abstraction layers of SOA are introduced and possiblc using of object oriented approach on each layer is discussed in this paper. Besides, three types of service collaboration are prcscntcd. The rnain objective of the paper is to dernonstrate how thesc typcs of collaboration can bc dcscribed in UML 2.0.	diagram;hypertext transfer protocol;ibm developerworks;information system;metamodeling;naruto shippuden: clash of ninja revolution 3;service-oriented architecture;service-oriented device architecture;unified modeling language	Petr Weiss;Jaroslav Zendulka	2007			uml tool;systems engineering;knowledge management;applications of uml;process management;services computing	SE	-52.26027758998082	20.416004155086068	181170
400e500f676748e25649ce87ddf5c550b93d507f	a new method of consensus building for open systems dependability	groupware;open systems groupware;deos;d case;dependability;buildings broadcasting context dictionaries tv personnel;agreement description database;d case writing consensus building method open systems dependability v model method d case collaborative construction d add agreement description database deos process business broadcasting system mission critical system commercial tv stations television stations d case integrity d case modification;agreement description database dependability deos d case consensus building;open systems;consensus building	This paper proposes a V-model method to build consensus on dependability of the target system through collaborative construction of D-Case aligned with the organizational structure of stakeholders. D-Case is an extended assurance case supported by D-ADD agreement description database in the DEOS process for open systems dependability. The example target system here is Business Broadcasting System, the mission-critical system of commercial TV stations. We identify four issues in consensus building using D-Case and show how they are overcome using the functionality of D-ADD in our method: 1) Ensuring the integrity of D-Case, 2) Identifying the area affected by a D-Case modification, 3) Writing D-Case with multiple authors, and 4) Clarifying the scope of responsibility of each stakeholder.	case modding;critical system;dependability;mission critical;v-model	Yukiko Yanagisawa;Takashi Ito;Makoto Takeyama;Yasuhiko Yokote	2013	2013 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)	10.1109/ISSREW.2013.6688910	reliability engineering;computer science;systems engineering;engineering;operating system;software engineering;dependability;database;open system;computer security	Embedded	-50.814737165554654	19.149130059403173	182535
25bb417f4ec8338c5da4fa380f01ae64ed734115	digging deep: software reengineering supported by database reverse engineering of a system with 30+ years of legacy	databases;software;cobol;data access statistics;software maintenance;database management systems;information retrieval;large scale software reengineering;wiki based redocumentation structure;data migration;data mining;data model;reverse engineering software performance relational databases collaborative software computer industry large scale systems information systems application software software reusability information technology;large scale;computer aided software engineering;database reverse engineering;heterogeneous in house information system;database driven cobol application;business;data access;legacy system large scale software reengineering database reverse engineering heterogeneous in house information system single purpose systems database driven cobol application data model wiki based redocumentation structure data access statistics;systems re engineering cobol data models database management systems information retrieval reverse engineering software maintenance;information system;legacy system;single purpose systems;documentation;reverse engineering;data models;systems re engineering	This paper describes the industrial experience in performing database reverse engineering on a large scale software reengineering project. The project in question deals with a highly heterogeneous in-house information system (IS) that has grown and evolved in numerous steps over the past three decades. This IS consists of a large number of loosely coupled single purpose systems with a database driven COBOL application at the centre, which has been adopted and enhanced to expose some functionality over the web. The software reengineering effort that provides the context for this paper deals with unifying these components and completely migrating the IS to an up-to-date and homogeneous platform. A database reverse engineering (DRE) process was tailored to suit the project environment consisting of almost 350 tables and 5600 columns. It aims at providing the developers of the software reengineering project with the necessary information about the more than thirty year old legacy databases to successfully perform the data migration. The application of the DRE process resulted in the development of a high-level categorization of the data model, a wiki based redocumentation structure and the essential data-access statistics.	business domain;cobol;categorization;code refactoring;column (database);data model;database;deprecation;documentation;high- and low-level;information system;loose coupling;reverse engineering;usage analysis;web application;wiki	Stefan Strobl;Mario Bernhart;Thomas Grechenig;Wolfgang Kleinert	2009	2009 IEEE International Conference on Software Maintenance	10.1109/ICSM.2009.5306293	data access;data migration;information engineering;data model;documentation;computer science;systems engineering;software engineering;database;cobol;programming language;software maintenance;legacy system;information system;reverse engineering	SE	-50.88739458751592	19.2053753051279	183003
03e2d4d84fd4bbba1b98f15229fca91ab9113276	a flexible tool suite for change-aware test-driven development of web applications	web requirements tdd change management web engineering;change management;test driven development;web engineering;navigation browsers testing publishing dsl software user interfaces;automatic generation;specification languages automatic test software internet program testing software tools;web requirements;internet;program testing;specification languages;automatic test software;domain specific language;software tools;web application development;automatic interaction test generation web application change aware test driven development flexible tool suite tdd improvement web requirements representation domain specific language;tdd	Though Web Applications development fits well with Test-Driven Development, there are some problems that hinder its success. In this demo we present a tool suite to improve TDD; the suite supports the representation of web requirements using a domain-specific language and the automatic generation of interaction tests among others.	domain-specific language;fits;requirement;test-driven development;web application	Esteban Robles Luna;Juan Burella;Julián Grigera;Gustavo Rossi	2010	2010 ACM/IEEE 32nd International Conference on Software Engineering	10.1145/1810295.1810359	test-driven development;web development;web modeling;computer science;software engineering;change management;database;web engineering;programming language;management;world wide web	SE	-49.63765431530963	24.728800519810104	183462
415cfe389e748f859452e2c6a667d47a5a36f160	comparison of design models: a systematic mapping study	model comparison;model similarity;model matching;mapping study	Context: Model comparison plays a central role in many software engineering activities. However, a comprehensive understanding about the state-of-the-art is still required. Goal: This paper aims at classifying and performing a thematic analysis of the current literature. Method: For this, we have followed well-established empirical guidelines to de ̄ne and perform a systematic mapping study. Results: Some studies (14 out of 40) provide generic model comparison techniques, rather than speci ̄c ones for UML diagrams. Conclusion: Fine-grained techniques are still required to support ever-present and complex model comparison tasks during the evolution of design models.	diagram;model selection;software design;software engineering;uml state machine	Lucian Gonçales;Kleinner Farias;Murillo Scholl;Maurício Veronez;Toacy Cavalcante de Oliveira	2015	International Journal of Software Engineering and Knowledge Engineering	10.1142/S021819401571014X	simulation;computer science;data mining;management science	SE	-55.17087585479342	21.82211057122872	183559
b544bc2f3903751a8223060bcfbafd35217fd42e	multi-agent software tool for management of design process in microelectronics	software tool;design process;project management;project scheduling multiagent software tool design process management microelectronics automated project planning;scheduling electronic engineering computing integrated circuit design multi agent systems project management;multi agent platforms;design process management;integrated circuit design;multi agent systems;mainstream games;scheduling;software tools process design microelectronics project management software prototyping computer architecture resource management application software uncertainty virtual prototyping;multiagent software tool;project scheduling;automated project planning;electronic engineering computing;microelectronics;teaching multi agent systems;cooperative work;project planning	The paper presents a software tool to support the management of design process in microelectronics. It is developed as a multi-agent prototype intended for automated project planning, scheduling and simulation as well as project tracking and control while managing cooperative work of a design team.	multi-agent system;programming tool;prototype;scheduling (computing);simulation;software agent	Vladimir Gorodetsky;Oleg Karsaev;Victor Konushy;Wolf-Ekkehard Matzke;Eyck Jentzsch;Vadim Ermolayev	2006	2006 IEEE/WIC/ACM International Conference on Intelligent Agent Technology	10.1109/IAT.2006.92	project management;personal software process;team software process;software project management;systems engineering;engineering;software design;software engineering;computer engineering	Robotics	-50.97391512208882	20.956829737069285	183825
eb089579da6b4992fa14836c36379d9ffb7f206b	bringing model-based systems engineering capabilities to project management: an application to prince2		PRINCE2 is arguably one of the most adopted process-based methods for project management. Currently, PRINCE2 is defined in a textual specification, which describes the principles, the themes, and the processes that project managers should apply in their management activities. Although the specification is well structured and mature, the specification does not provide a browsable digital representation that can be interactively used for learning and/or for the specification application during project management activities. This paper aims to overcome these limitations with the application of a modelbased systems engineering approach to represent the PRINCE2 specification in a model-based format. This can bring several benefits to the specification, including the availability of a graphical, comprehensive and digitally browsable visualization of the PRINCE2 processes, their inputs/outputs, and the constituting tasks. The modelbased format has been obtained by a top-down mapping of the PRINCE2 specifications, beginning with the process architecture in IDEF0 down to the individual tasks, roles, and tools in BPMN 2.0. Besides supporting PRINCE2 understanding and application, the model-based format can also serve as a baseline for further exploitations, such as consistency verification of the PRINCE2 specification and model-based process simulation for the governance of the PRINCE2 processes and of the project management activities. Keywords—project management; business process; model-based; systems engineering.	baseline (configuration management);business process model and notation;formal verification;graphical user interface;idef0;interactivity;model-based systems engineering;process architecture;simulation;theme (computing);top-down and bottom-up design	Diana Coppola;Andrea D'Ambrogio;Daniele Gianni	2016			program management;project management;prince2;model-based systems engineering;engineering;systems engineering	SE	-54.12916539852316	24.87276667304565	184405
ce3acef9de6eed2e34b62052b7ba85028bb72345	erroneous requirements: a linguistic basis for their occurrence and an approach to their reduction	formal specification;linguistics;natural languages;software tools;zeus;conceptual model;domain knowledge;domain map;domain semantics;formal specifications;linguistics;natural language;requirements specification;software engineering;software tool	John Knight received his Ph.D. in Computer Science from Newcastle in 1973. After two years at West Virginia University and seven years at NASA's Langley Research Center, he joined the UVa in 1981 as an associate professor of Computer Science. He spent 1987-89 at the Software Productivity Consortium, and was promoted to professor in 1992. He has directed six Ph.D. theses with three more in progress. He is the author or co-author of over 60 papers.	computer science;consortium;requirement	John C. Knight	2001		10.1109/HASE.2001.10000	domain analysis;natural language processing;requirements analysis;software requirements specification;domain;quantitative linguistics;computer science;engineering;feature-oriented domain analysis;software engineering;domain engineering;domain model;formal specification;natural language;programming language;domain knowledge	Logic	-51.663212042649285	25.158190907047782	185980
2de98e633db95a4e820663efd150d329047050d3	enabling end-users participation in an mdd-spl approach		Developing smart home systems that properly fit end-user needs is not always an easy task due to the lack of understanding that may exist between end-users and system developers. In the context of Software Product Lines, several approaches have been presented to improve the development of smart home system functionality. However, little support is provided to improve the interaction with end-users. In this work, we extend a Software Product Line based on Model-Driven Development with an interactive design tool that allows end-users to actively participate in the SPL. This tool allows end-users to configure the decision model that drives the production process of the software product line by themselves. In order to develop this tool we have been inspired by well-known and tested enduser techniques and interaction patterns that improve the user interface usability.	design tool;domain engineering;feature model;home automation;interactive design;model-driven engineering;model-driven integration;software product line;usability;user interface	F. Pérez;Pedro Valderas;Joan Fons	2009				HCI	-49.2430230855736	23.054071305462934	186662
164701a18c23f0f4ef1a426666c97aa260474a65	in support of user interface design in the rational unified process	rational unified process;extended tabular use case;user interface prototype;uml boundary class;use case;user interface design;ui element cluster;support artefact;user interface modelling;user interface element;user interface prototyping;software engineering;user interface;uml	The Rational Unified Process (RUP) is a use case driven iterative software engineering process User Interface design within the RUP involves user interface modelling and user interface prototyping. This paper describes two support artefacts extended tabular use cases and UI element clusters which provide a bridge between these two activities. They provide support for ‘flow of events’ storyboarding, the clustering of user interface elements and identification of UML boundary classes, and the initial sketching of user interface prototypes.	cluster analysis;data element;iteration;rational unified process;software development process;software engineering;storyboard;table (information);unified modeling language;user interface design	Chris Phillips;Elizabeth A. Kemp	2002			user interface design;use case;unified modeling language;user;user experience design;human action cycle;user modeling;human–computer interaction;natural language user interface;computer science;database;interface control document;user interface;rational unified process;graphical user interface testing;multiple document interface	SE	-48.34710431732837	23.071903060963457	186902
a2b250413968bd26b9e38f7bae0af7ef5d1f2b8a	a model-driven approach for deploying trading-based knowledge representation systems	platform-independent tkr system architecture;information systems;high-level description;management information systems;final tkr system implementation;model-driven approach;environmental management information system;model-driven engineering;software engineering;configuration model;trading-based knowledge representation system	Trading services are well-known solutions in Software Engineering for solving the interoperability and integration of software components and Information Systems (IS). This paper presents a Model-Driven Engineering (MDE) approach aimed to help designing and deploying Trading-Based Knowledge Representation (TKR) Systems, a subset of Management Information Systems (MIS). For this purpose, we have defined a set of modeling languages and supporting tools enabling: (a) the description of platform-independent TKR System architectures; (b) the high-level description of different deployment platforms; and (c) the creation of configuration models relating the two previous ones. These configuration models are then used as an input to a model-to-text transformation that generates the final TKR System implementation (code) from the selected platform. In order to demonstrate the feasibility and benefits of the proposed approach we also present a case study applied to an Environmental Management Information System (EMIS).	knowledge representation and reasoning;model-driven integration	José Andrés Asensio;Luis Iribarne;Nicolás Padilla;Cristina Vicente-Chicote	2011		10.1007/978-3-642-25126-9_28	computer science;systems engineering;theoretical computer science;data mining	NLP	-52.38251774621199	23.892392600620397	187083
126d24ee5640200937de08f19925ff8991775795	implementing structural measures over i* diagrams		Measuring is a key issue in any software-related activity. In the context of the i* framework, we are implementing Measufier, a prototype for measuring i* diagrams in terms of properties that may be derived from their structure (structural measures). The prototype works over i* diagrams represented by the iStarML interchange format, and provides some facilities for managing measures' catalogues, customizing the measures to the analyst needs, and computing the measure over particular diagrams.	prototype;state diagram	Daniel Colomer;Xavier Franch	2011			data mining;systems engineering;computer science	SE	-52.65268012998191	18.865122109121337	187668
f28f29e3fae766a905abb2f87d71a7639b65faa6	business rules layers between processes and workflow modeling: an object-oriented perspective	object oriented;business rules	Business rules can be de ned as statements about how the business is done i e about guidelines and restrictions with respect to states and processes in an organization Originally the term was used with reference to integrity conditions in Entity Relationship Models or in NIAM More powerful business rules can be described according to the Event Condition Action ECA paradigm developed for active Database Mana gement Systems From this point of view business rules trigger an action of the IS send an alerter to a human actor or de ne the feasible space for human actions There fore the rules are not necessarily prescriptive but may also be semi structured or soft Recently the important role of business rules in understanding the real system and thus in system analysis was stressed	active database;entity–relationship model;event condition action;object-role modeling;programming paradigm;semiconductor industry;system analysis	Gerhard Knolmayer	1998		10.1007/3-540-49255-0_44	business object;business logic;semantics of business vocabulary and business rules;business domain;computer science;knowledge management;artifact-centric business process model;business process management;process modeling;management science;business process model and notation;business process;programming language;object-oriented programming;business rule;business process modeling;workflow engine;specification pattern;business architecture;workflow technology	DB	-53.82315848884721	19.32083989025892	187670
7e429f2b7f34c4957d60de4067a444953ebf56e1	a reference framework for requirements and architecture in biomedical grid systems	formal specification;ucl;cancer detection bioinformatics grid computing computer science biomedical computing propulsion laboratories computer architecture educational institutions government;requirements engineering biomedical grid computing system conceptual tool software architecture;discovery;theses;conference proceedings;software architecture formal specification grid computing medical computing;medical computing;software architecture;digital web resources;ucl discovery;open access;ucl library;book chapters;open access repository;point of view;grid computing;early detection;grid system;ucl research	In this paper we introduce the work done to define a framework for requirements and architectural understanding in biomedical grid computing systems. A set of core requirements for biomedical grids have been identified on the basis of our experience in the analysis and development of several biomedical and other grid systems including the National Cancer Institute 's Early Detection Research Network (EDRN) in the US and the National Cancer Research Institute (NCRI) Platform in the UK. The requirements have been specified taking into account different points of view and are intended as a core set that can be extended on the basis of project specific aspects. These are also mapped to existing architectures of biomedical grid systems, and their constituent components. Such a framework is intended as a guide for equipping developers with conceptual tools to avoid costly mistakes when architecting biomedical grid systems.	edrn;grid systems corporation;grid computing;requirement	Chris Mattmann;Vito Perrone;Sean C. Kelly;Daniel J. Crichton;Anthony Finkelstein;Nenad Medvidovic	2007	2007 IEEE International Conference on Information Reuse and Integration	10.1109/IRI.2007.4296656	software architecture;computer science;operating system;software engineering;data mining;formal specification;database;world wide web;grid computing	HPC	-51.728090032702916	22.328229397051622	188869
3464d2a6e12ab67cb8e3ccdec8dd1dc3039f20b7	back-to-back testing of self-organization mechanisms		When developing SO mechanisms, mapping requirements to actual designs and implementations demands a lot of expertise. Among other things, it is important to define the right degree of freedom for the system that allows for self-organization. Back-to-back testing supports this hard engineering task by an adequate testing method helping to reveal failures in this design and implementation procedure. Within this paper we propose a model-based approach for back-to-back testing. The approach is built on top of the S# framework and integrated into the Visual Studio development environment, enabling the creation of executable test models with comprehensive tooling support for model debugging. By applying the concepts to a self-organizing production cell, we show how it is used to fully automatically reveal faults of a SO mech-	change control board;code refactoring;converge;debugging;executable;functional specification;heuristic (computer science);microsoft outlook for mac;microsoft visual studio;organizing (structure);requirement;robot;self-organization;service-oriented architecture;system configuration;test case;user error	Benedikt Eberhardinger;Axel Habermaier;Hella Seebach;Wolfgang Reif	2016		10.1007/978-3-319-47443-4_2	microsoft visual studio;debugging;adaptive system;implementation;quality assurance;systems engineering;self-organization;model-based testing;executable;computer science	SE	-50.5104357276469	24.407906502737305	189029
ebddb12fa4f7c5733208c5799e54e97cb1517ee4	approaching collaborative modeling as an uncertainty reduction process		Model-Driven Engineering (MDE) technologies aim to support the growing complexity of software systems. Models are increasingly becoming large and unmanageable, and hence difficult to be understood by humans and processed by machines. As a consequence, multi-user environments are necessary to enable designers to create and refine large models in a collaborative manner enabling the engineering, modularization and reuse. In this paper, we propose a model-driven approach to represent, manage and manipulate models edited in a collaborative manner. In particular, we propose to represent the solutions space (i.e, model versions) in an intensional manner by adopting a model with uncertainty. We define a plan to manage the uncertainty by selecting the desired design, to manipulate their collaborative models in manually or automatic way, and to exploit a collaborative environment for real time multi-user editing. The approach is showed by means of a motivating example that involves business models demonstrating the advantages of the proposed approach.	intensional logic;model-driven architecture;model-driven engineering;model-driven integration;multi-user;software system	Romina Eramo;Alfonso Pierantonio;Gianni Rosa	2016			management science;uncertainty reduction theory;computer science;systems engineering	SE	-50.33805060002309	22.44190736833854	190845
88d72dab8c2afff3c99ecb4ca0c9847e002b3ef9	applying multi-level modeling to data integration in product line engineering		Developing systems according to the Product Line Engineering (PLE) paradigm is a process in which different types of engineering artifacts are created with the aim of reusing them in different configurations of the same system. Ensuring that different system configurations satisfy various functional and non-functional properties is ensured by analyzing different artifacts but because they are maintained by different tools, sometimes even manually, achieving and especially automating such analyses is a challenging task. Overcoming this issue can be achieved through data integration of existing data which implies creating an information model that specifies how will the existing data fragments be related, captures relevant domain constraints, and most importantly captures the fact that some data objects are classes in one tool and instances in another. This paper reports on the experiences from applying the Multi-Level conceptual Theory (MLT), to the problem of information modeling for data integration in the PLE context. Being a Multi-Level Modeling, powertype-based framework, MLT allows separation of the class and instance facet of modeled entities while keeping them explicit. Some of the MLT modeling constructs are particularly useful for capturing the refinement levels of the modeled artifacts and for succinctly capturing constraints like disjointess or completeness among them. The paper also reports certain aspects of the studied case that could not be expressed using MLT. The studied case comes from a real data-integration project from the heavy vehicle manufacturer, Scania CV AB.	artifact (software development);categorization;entity;information model;media lovin' toolkit;model-driven integration;multi-level governance;programming language;programming paradigm;refinement (computing);seamless3d	Damir Nesic;Mattias Nyberg	2017			data integration;multilevel model;systems engineering;domain engineering;computer science	DB	-54.17986911533587	23.246171071248675	190866
787eff9a01b2fb68373ff7ce63acc7a61fd84d83	facilitating the transition from use case models to analysis models: approach and experiments	class diagram;measurement;restriction rules;controlled experiment;use case modeling;design;analysis model;use case template;experimentation;use case;sequence diagram;documentation	Use case modeling, including use case diagrams and use case specifications (UCSs), is commonly applied to structure and document requirements. UCSs are usually structured but unrestricted textual documents complying with a certain use case template. However, because Use Case Models (UCMods) remain essentially textual, ambiguity is inevitably introduced. In this article, we propose a use case modeling approach, called Restricted Use Case Modeling (RUCM), which is composed of a set of well-defined restriction rules and a modified use case template. The goal is two-fold: (1) restrict the way users can document UCSs in order to reduce ambiguity and (2) facilitate the manual derivation of initial analysis models which, when using the Unified Modeling Language (UML), are typically composed of class diagrams, sequence diagrams, and possibly other types of diagrams.  Though the proposed restriction rules and template are based on a clear rationale, two main questions need to be investigated. First, do users find them too restrictive or impractical in certain situations? In other words, can users express the same requirements with RUCM as with unrestricted use cases? Second, do the rules and template have a positive, significant impact on the quality of the constructed analysis models? To investigate these questions, we performed and report on two controlled experiments, which evaluate the restriction rules and use case template in terms of (1) whether they are easy to apply while developing UCMods and facilitate the understanding of UCSs, and (2) whether they help users manually derive higher quality analysis models than what can be generated when they are not used, in terms of correctness, completeness, and redundancy. This article reports on the first controlled experiments that evaluate the applicability of restriction rules on use case modeling and their impact on the quality of analysis models. The measures we have defined to characterize restriction rules and the quality of analysis class and sequence diagrams can be reused to perform similar experiments in the future, either with RUCM or other approaches.  Results show that the restriction rules are overall easy to apply and that RUCM results into significant improvements over traditional approaches (i.e., with standard templates, without restrictions) in terms of class correctness and class diagram completeness, message correctness and sequence diagram completeness, and understandability of UCSs.	apply;bit error rate;class diagram;correctness (computer science);design rationale;display resolution;document;experiment;natural language;norm (social);redundancy (engineering);requirement;sequence diagram;software engineering;unified modeling language	Tao Yue;Lionel C. Briand;Yvan Labiche	2013	ACM Trans. Softw. Eng. Methodol.	10.1145/2430536.2430539	use case;use-case analysis;use case diagram;computer science;software engineering;data mining;database;algorithm	SE	-55.37449154645975	24.299380232132982	192116
294f40a43af44ab10e563e31b33197b29c1328bb	support of scenario creation by generating event lists from conceptual models		In the requirements definition phase, conceptual models are used to understand the developing software. Although scenarios are often described on the basis of conceptual models, there are cases that necessary requirements are omitted in the scenarios when the scenarios are created manually. Herein we propose an approach to support scenario creation from conceptual models where event lists of scenarios, which include checkpoints to define requirements, are generated from conceptual models automatically. The conceptual models represent the core resources of the software, the owner of the core resources, and use cases as class diagrams. Then software engineers and their clients arrange the event lists and define requirements as scenarios on the basis of the checkpoints. Our approach can support describing scenarios with all the necessary requirements from conceptual models. To confirm the effectiveness of our approach, we compared our approach to the all-manual approach.	class diagram;conceptual schema;requirement;requirements analysis;software engineer;user interface	Kenta Goto;Shinpei Ogata;Junko Shirogane;Takako Nakatani;Yoshiaki Fukazawa	2015	2015 3rd International Conference on Model-Driven Engineering and Software Development (MODELSWARD)		use case;reliability engineering;unified modeling language;requirements analysis;software requirements specification;conceptual model;computer science;systems engineering;conceptual model;scenario;software engineering;domain model;data mining;computational model	SE	-54.93149412366423	23.523822314607656	192318
4c02aec94ebf4195bb11b23f8dba7604c090ee59	user interface prototyping - concepts, tools, and experience		In recent years the development of highly interactive software systems with graphical user interfaces has become increasingly common. The acceptance of such a system depends to a large degree on the quality of its user interface. Prototyping is an excellent means for generating ideas about how a user interface can be designed, and it helps to evaluate the quality of a solution at an early stage. We present the basic concepts behind user interface prototyping, a classification of tools supporting it and a case study of nine major industrial projects. Based on our analysis of these projects we present the following conclusions: prototyping is used more consciously than in recent years. No project applied a traditional life-cycle approach, which is one of the reasons why most of them were successful. Prototypes are increasingly used as a vehicle for developing and demonstrating visions of innovative systems.	graphical user interface;prototype;software system	Dirk Bäumer;Walter R. Bischofberger;Horst Lichter;Heinz Züllighoven	1996				SE	-49.41868223357093	23.538466159226378	192469
43f07344b248e240988de90868a29250f95524bf	normative requirements for business process compliance	business processes	Norms regulate the behaviour of their subjects and define what is legal and what is illegal. Norms typically describe the conditions under which they are applicable and the normative effects as a result of their applications. On the other hand, process models specify how a business operation or service is to be carried out to achieve a desired outcome. Norms can have a significant impact on how business operations are conducted and they can apply to the whole or a part of a business process. For example, they may impose conditions on the different aspects of a process (e.g., perform tasks in a specific sequence (control-flow), at a specific time or within a certain time frame (temporal aspect), by specific people (resources)). We propose a framework that provides the formal semantics of the normative requirements for determining whether a business process complies with a normative document (where a normative document can be understood in a very broad sense, ranging from internal policies to best practice policies, to statutory acts). We also present a classification of normal requirements based on the notion of different types of obligations and the effects of violating these obligations.	best practice;business process;cloud computing;cobham's thesis;composite video;control flow;dataflow;design pattern;high-level programming language;linearizability;np-completeness;petri net;real life;requirement;semantics (computer science);service-oriented architecture;software deployment;taxonomy (general);temporal logic;time complexity	Mustafa Hashmi;Guido Governatori;Moe Thandar Wynn	2013		10.1007/978-3-319-07950-9_8	reliability engineering;management science;business	SE	-55.46152032354954	20.203948891442845	192989
7849d0d7055cc73cecb76b5b2f7c9a4384efcca5	archimedean points: the essence for mastering change		Explicit Archimedean Point-driven (software) system development aims at maintaining as much control as possible via ‘things’ that do not change, and may radically alter the role of modeling and development tools. The idea is to incorporate as much knowledge as possible into the tools themselves. This way they become domain-specific, problem-specific, or even specific to a particular new requirement for a system already in operation. Key to the practicality of this approach is a much increased ease of tool development: it must be economic to alter the modeling tool as part of specific development tasks. The Cinco framework aims at exactly this kind of ease: once the intended change is specified, generating a new tool is essential a push button activity. This philosophy and tool chain are illustrated along the stepwise construction of a BPMN tool via a chain of increasingly expressive Petri net tools. By construction, the resulting BPMN tool has a conceptually very clean semantic foundation, which enables tool features like various consistency checks, type-controlled activity integration, and true full code generation.	bus mastering	Bernhard Steffen;Stefan Naujokat	2016	Trans. Found. Mastering Chang.	10.1007/978-3-319-46508-1_3	push-button;code generation;systems engineering;business process model and notation;software;petri net;runtime verification;computer science;archimedean point	HCI	-54.69596141810091	20.60083269759001	193884
9f7d1a96801534aa06c3d732bb7ee0a2c480b74e	constructs competition miner: process control-flow discovery of bp-domain constructs		Process Discovery techniques help a business analyst to understand the actual processes deployed in an organization, i.e. based on a log of events, the actual activity workflow is discovered. In most cases their results conform to general purpose representations like Petri nets or Causal nets which are preferred by academic scholars but difficult to comprehend for business analysts. In this paper we propose an algorithm that follows a top-down approach to directly mine a process model which consists of common BP-domain constructs and represents the main behaviour of the process. The algorithm is designed so it can deal with noise and not-supported behaviour. This is achieved by letting the different supported constructs compete with each other for the most suitable solution from top to bottom using ”soft” constraints and behaviour approximations. The key parts of the algorithm are formally described and evaluation results are presented and discussed.	algorithm;approximation;business process interoperability;causal filter;petri net;process modeling;programmable read-only memory;top-down and bottom-up design	David Redlich;Thomas Molka;Wasif Gilani;Gordon S. Blair;Awais Rashid	2014		10.1007/978-3-319-10172-9_9	business process discovery;systems engineering;process control;business process modeling;data mining;petri net;flow (psychology);business process management;computer science;workflow	ML	-55.063065714041116	18.259604959186778	194500
71a0bfa956e5e094d96b482d57873d173f66c800	maintaining consistency of cooperative software development activities	development process;software development	Maintaining consistency of objects produced during cooperative software development activities is an important issue in the development process eld. We propose a solution based on a speciic transaction protocol which mixes a non-semantic and a semantic approach. This protocol allows software development activities, organised in a base/sub-base hierarchy to cooperate by exchanging inconsistent results and obliges them to compensate these inconsistency. Consistency of result is considered regarding the way they are produced (correction of execution) and that they do not violate constraints (correction of results). We use a non-semantic protocol for the rst point and semantic protocol based on temporal logic for the second. The integration of both protocols allows to maintain the consistency of cooperative software development activities. This paper describes this hybrid protocol, how the semantic part is designed and how the two protocols are integrated.	software development;temporal logic	Hala Skaf-Molli;François Charoy;Claude Godart	1996			software engineering;software deployment;personal software process;software development process;software verification and validation;software construction;software engineering process group;software development;engineering;social software engineering;systems engineering	SE	-54.59579072384147	24.801336356197048	194570
7b0f6f4a8211406275228472b59131fde4ae46c7	undoing event-driven adaptation of business processes	history;sensors;event driven environments static process business logic business process adaptation;business engines monitoring history servers context sensors;event driven approach;adaptation event driven approach business process;servers;engines;monitoring;business data processing;adaptation;business;formal logic;dynamic adaptation;context;business process;formal logic business data processing	As business processes continue to gain relevance in different domains, dynamicity is becoming a great concern. Static processes no longer cover the actual needs of constantly changing environments, and process adaptation is a must in order to maintain competitive levels. While creating dynamically adaptable business processes can be a challenging task, undoing these adaptations is a natural functionality that has not been studied in depth. Straight forward approaches for unadaptation can easily end up with corrupted processes, bringing uncertainty to the whole business logic. In this paper we bring forward a solution for efficiently undoing a business process adaptation in event-driven environments, considering also the correlated adaptations that happened afterwards.	business logic;business process;event-driven architecture;event-driven finite-state machine;event-driven programming;relevance	Sébastien Mosser;Gabriel Hermosillo;Anne-Françoise Le Meur;Lionel Seinturier;Laurence Duchien	2011	2011 IEEE International Conference on Services Computing	10.1109/SCC.2011.58	simulation;engineering;knowledge management;operations management	Robotics	-55.053629312662615	18.345098568803444	194944
7e1ea459b668cbc45ec1cdd14b63f400c5be55d6	scientific workflow reuse through conceptual workflows on the virtual imaging platform	scientific workflow;semantic web technology;scientific workflows;domain knowledge;reusable component;reusable components;in silico	"""An increasing number of scientific experiments are """"in-silico"""": carried out at least partially using computers. Scientific Workflows have become a key tool to model and implement such experiments, but they tangle domain knowledge, technical know-how and non-functional concerns and are, as a result, difficult to understand, reuse or repurpose.  In order to ease Scientific Workflow Reuse, this paper defines a Conceptual Workflow model that is closer to the end-user's domain and intentions. By placing our model higher on the abstraction scale, we can separate concerns and emphasize the in-silico experiment inside the workflow, thus improving readability and re-usability.  The conceptual representation can then be transformed into a regular Abstract Scientific Workflow, exploiting both domain and non-functional knowledge that are captured and harnessed through the use of Semantic Web technologies."""	computer;experiment;semantic web;usability	Nadia Cerezo;Johan Montagnat	2011		10.1145/2110497.2110499	workflow;computer science;knowledge management;data science;data mining;database;windows workflow foundation;workflow management system;domain knowledge;workflow engine;workflow technology	AI	-49.8801329766929	21.522008498019126	195866
871a4d7d7f89388c7f37724b74e9bde4ee8becfc	restructuring of workflows to minimise errors via stochastic model checking: an automated evolutionary approach	cows;bpmn;enterprise risk management;safety assessment software tools;bpd;reliability analysis and risk assessment methods;pctl;sboat;csp;consequence modelling and management;safety management and decision making	This paper presents a framework for the automated restructuring of stochastic workflows to reduce the impact of faults. The framework allows for the modelling of workflows by means of a formalised subset of the BPMN workflow language. We extend this modelling formalism to describe faults and incorporate an intention preserving stochastic semantics able to model both probabilisticand non-deterministic	business process model and notation;iterative and incremental development;model checking;semantics (computer science)	Luke Thomas Herbert;Zaza Nadja Lee Hansen	2016	Rel. Eng. & Sys. Safety	10.1016/j.ress.2015.07.002	reliability engineering;computer science;systems engineering;communicating sequential processes;management science;business process model and notation;enterprise risk management;workflow management system;workflow technology	AI	-54.57873913612268	20.471302493889326	197863
f4001228998ae326093fefe1c81698c80f4326e6	topological functioning model for software development within mda (survey)		The approach called Topological Functioning Modeling for Model Driven Architecture (TFM4MDA) uses Topological Functioning Model (TFM) as a formal holistic problem domain model. The approach is revolutionary, because it brings formalism to the earliest stages of software development – the analysis of problem domain, and provides formal transformations to UML design models. A copious amount of effort has been put into the development of TFM4MDA. Furthermore, TFM has not always been used in software development. This paper represents a literature survey of 69 articles about TFM and its application. The goal of this work is to trace the research of TFM and TFM4MDA approach, to throw light on the results of the research, and to reveal some weaker areas of it. The goal is successfully achieved and the conclusions	business process;computation;computer-integrated manufacturing;diagram;domain model;embedded system;entity;holism;information system;mechatronics;metamodeling;model-driven architecture;problem domain;requirement;semantics (computer science);software development;unified modeling language	Arturs Solomencevs	2016		10.5220/0005922803150326	reliability engineering;systems engineering;engineering;database	SE	-54.63596866778249	23.710505418445308	197928
a9a1d742adb320d3c7b38c4b980c96021cb85713	configurable structure tree as a means to manage configurable business processes		A configurable Business Process (BP) is an abstract BP that engineers customize with respect to specific requirements. To keep track of the multiple and recurrent customizations that lead to a set of derived BPs, this paper proposes a knowledge-based approach that uses a new Process Structure Tree called configurable PST (cPST). A cPST abstracts a separate variability option of the configurable BP. All cPSTs should be equivalent to the set of all PSTs associated with the derived BPs that could originate from the same configurable BP. This paper also proposes a logic-based configuration model for capturing configuration details on the cBP and describing the cPST computing.	business process;knowledge base;program structure tree;requirement;spatial variability;structured programming	Wehbi Benallal;Mahmoud Barhamgi;Djamal Benslimane;Zakaria Maamar	2017	2017 IEEE 26th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE)	10.1109/WETICE.2017.62	computer science;business process;distributed computing;knowledge-based systems;cats	SE	-52.636548638416514	20.476329835952832	198016
5b882acc889a31b068d85c78ef928d73a1ff5e7d	model-driven development of a mediation service	business flexibility;manuals;software architecture semantic web;service composition;service oriented architectures;semantic interoperability;application integration;model driven development;software architecture;semantic web techniques model driven development mediation service service oriented architectures application integration business flexibility interoperability problem;mediation unified modeling language moon business semantic web java manuals;mediation;semantic web techniques;moon;system integration;interoperability service mediation service composition system integration;business;unified modeling language;semantic web;process model;service mediation;interoperability;interoperability problem;service oriented architecture;mediation service;java;perfect match	Although service-oriented architectures offer real benefits when pursuing application integration and business flexibility, there are still no satisfactory solutions for dealing with existing systems that need to cooperate while their services have no perfect match. In the case of incompatible services, a 'mediator' may be introduced which resolves (semantic) interoperability problems by intervening in the cooperation between systems. Building mediators is currently often a manual process, resulting in dedicated IT-driven solutions. This paper presents a framework to guide the development of mediators, with the following objectives: (i) uncover and capture the actual interoperability problem that needs to be solved; (ii) allow the involvement of non-IT (i.e., business) experts in the development of the solution; (iii) support evolution of the solution and re-use of results in case of changing interoperability requirements; (iv) facilitate automation of parts of the process. The framework is based on service-oriented, model-driven and semantic Web techniques. Available tool support for the different steps in the framework is indicated.	automated reasoning;business process execution language;business domain;information model;matchware mediator;model-driven architecture;model-driven engineering;model-driven integration;platform-independent model;programming paradigm;requirement;semantic web;semantic interoperability;service composability principle;service-orientation;service-oriented architecture;service-oriented device architecture;service-oriented software engineering;simulation;sinewave synthesis;web ontology language;web services description language;web service	Dick A. C. Quartel;Stanislav Pokraev;Rodrigo Mantovaneli Pessoa;Marten van Sinderen	2008	2008 12th International IEEE Enterprise Distributed Object Computing Conference	10.1109/EDOC.2008.39	semantic interoperability;computer science;knowledge management;software engineering;service-oriented architecture;data mining;database;law;world wide web	Robotics	-54.41024736888871	19.2739979114965	198232
8a0394096769f7d19f9380124967365a45456f12	a human centred approach to simulation: a case study of software to support system design and development	human centred simulation;production system design uses;simview;prototyping tool;complex graphic software;design and development;software prototyping;human centred simulation human centred approach simulation case study system design system development simulation software production system design uses expert tool graphics prototyping tool industrial context team based cellular manufacturing software packages complex graphic software automod sima low complexity simview;computer graphics;team based cellular manufacturing;simulation;software systems;low complexity;manufacturing industries;computer industry;expert tool;support system;simulation software;industrial context;design technique;sima;human factors;automod;design and implementation;system design;continuous improvement;human centred approach;humans software tools graphics computer industry manufacturing industries software standards software systems production systems software prototyping robustness;production systems;system development;robustness;software standards;software tools;humans;participatory design;production system design;user involvement;computer integrated manufacturing;graphics;computer graphics digital simulation computer integrated manufacturing human factors;digital simulation;cellular manufacturing;software packages	A technocentric approach to the use of simulation software in production system design uses it as an expert tool to assist system designers in a one ofs design. A human centred approach, in contrast, uses simulation sofmare to support teams of users to make key decisions about system design. In addition, it provides support for continued improvement and development activities by the users. In order to achieve these aims, the so&are must be easily usable by users, involve clear graphics to act as a protovping tool, and be suficiently robust to work within an industrial context. This paper describes three industrial experiences in the design and implementation of team based cellular manufacturing employing standard simulation software packages (highly complex graphic soffware: A UTOMOD, medium to high complexity: SIMA and low complexity: SIMKJEW) and accompanying standard participatory design techniques. Each failed to achieve the intended goal of human centred syslem design. Reflecting on this experience, principles for sojlware and design techniques capable of realising human centred simulation objective are offered.	graphics;production system (computer science);simulation software;systems design	Richard Badham;Paul Couchman;Steve Little	1995		10.1109/HICSS.1995.375662	personal software process;verification and validation;simulation;simulation software;computer science;graphics;human factors and ergonomics;package development process;software design;software development;software design description;software engineering;software construction;computer-integrated manufacturing;production system;software walkthrough;manufacturing;computer graphics;software deployment;robustness;software system;systems design	HCI	-50.12749363238656	20.749161613645082	198686
0373e4271863e09a6f3c174a25850e399125084b	relaxed compliance notions in adaptive process management systems	dynamical processes;process aware information systems;process management;process model;schema evolution	The capability to dynamically evolve process models over time and to migrate process instances to a modified model version are fundamental requirements for any process-aware information system. This has been recognized for a long time and different approaches for process schema evolution have emerged. Basically, the challenge is to correctly and efficiently migrate running instances to a modified process model. In addition, no process instance should be needlessly excluded from being migrated. While there has been significant research on correctness notions, existing approaches are still too restrictive regarding the set of migratable instances. This paper discusses fundamental requirements emerging in this context. We revisit the well-established compliance criterion for reasoning about the correct applicability of dynamic process changes, relax this criterion in different respects, and discuss the impact these relaxations have in practice. Furthermore, we investigate how to cope with non-compliant process instances to further increase the number of migratable ones. Respective considerations are fundamental for further maturation of adaptive process management technology.	correctness (computer science);database schema;dataflow;hoc (programming language);information system;linear programming relaxation;management system;microsoft outlook for mac;process modeling;regular language description for xml;requirement;schema evolution;whole earth 'lectronic link	Stefanie Rinderle-Ma;Manfred Reichert;Barbara Weber	2008		10.1007/978-3-540-87877-3_18	computer science;artificial intelligence;process modeling;data mining;database;management science	DB	-55.15362630176685	19.69859992517006	199109
ca2ab1a42b933dff4940f1eeedd54a9df2568f47	imitational studies with gpss world: new capabilities	new capability;gpss world;popular imitational modeling system;imitational study;modern level;various problem domain;extended gpss editor	We consider the problems of improving and applying, in various problem domains, the technological and software means of one of the most powerful and popular imitational modeling systems, namely GPSS World. We describe an extended GPSS editor that provides the user with the modern level of technology and new capabilities for imitational studies in industry and other fields.		Stanislav A. Vlasov;Vladimir V. Deviatkov;F. V. Isaev;M. V. Fedotov	2014	Automation and Remote Control	10.1134/S0005117914020179	simulation;human–computer interaction;computer science	EDA	-49.72591301357748	23.812726678610417	199260
b2d0cdcf8642857e155172d1536965737db3cd2f	automatic transformation tools of uml design models from virtual prototypes of multi-jointed robots		Most of robotic companies develop a control programming of multi-jointed robots, which spend too much time to manually adjust the moving functions of the robots. To solve this problem, we adapt the virtual prototyping (VP) to develop the control program of the robotic behaviors. For software engineers, in order for them to easily program this robot, we also apply metamodel mechanism to convert UML models with virtual prototyping model. We propose the automatic model transformation from the virtual prototyping model to UML models, which will then develop coding based on UML models. To prove our mechanism’s efficiency, we implement Robot to UML Translator (RUT) as our transformation rules with ATLAS transformational language. Lastly, we show experimental validation about the consistency of our proposed technique with an example of multi-joined robot prototype models.	atlas;bing translator;metamodeling;model transformation;prototype;remote utilities;robot;software engineer;unified modeling language	Hyun Seung Son;Robert Young Chul Kim	2017	Multimedia Tools and Applications	10.1007/s11042-017-5579-8	metamodeling;simulation;virtual prototyping;computer vision;artificial intelligence;computer science;coding (social sciences);model transformation;robot;transformational leadership;software;unified modeling language	Robotics	-50.436205082534784	23.960173379082516	199655
b5ac9277e6313d5ffdbe6bdbf22c471bfb017bbc	agent-oriented software engineering	multi agent system;agent oriented software engineering;meta model	Considering the great number of agent-oriented meth odologies that can be found in literature, and the fact that each one defines its own concepts and system s ructure, one of the main challenges in AgentOriented Software Engineering research is how to ma ke these methodologies interoperable. By defining in a non ambiguous way concepts used in a specific domain, meta-modelling may represent a step towards such an interoperability. Consequently the main objective of the AOSE TFG (Technical Forum Group) is to establish a strategy for identifying a common meta-model that could be widely adopted by the AOSE community. This paper sums up the approach used by this TFG which consists in (i) studying and comparing the meta-models related to some exist ing methodologies (ADELFE, Gaia, INGENIAS, PASSI, RICA and Tropos) in order to find commonalit ies and (ii) giving a clear and basic definition fo r the core concepts used in multi-agent systems for r elating and positioning them in a unified MAS metamodel. The first proposal, set up by the working gr oup, for this unified meta-model then concludes thi paper.	agent-oriented software engineering;gaia hypothesis;ingenias;interoperability;metamodeling;multi-agent system	Carole Bernon;Massimo Cossentino;Juan Pavón	2005	Knowledge Eng. Review	10.1017/S0269888905000421	metamodeling;computer science;artificial intelligence;multi-agent system;data mining;management science	SE	-54.783208467960954	22.59817740053837	199856
