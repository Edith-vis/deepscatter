id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
79eb73bcc32f62b17966b0cdab872095d23adcd9	towards agile application integration with m2m platforms	syntactical and semantic unification;m2m middleware;m2m;ontology	M2M (Machine-to-Machine) Technology makes it possible to network all kinds of terminal devices and their corresponding enterprise applications. Therefore, several M2M platforms were developed in China in order to collect information from terminal devices dispersed all over the local places through 3G wireless network. However, when enterprise applications try to integrate with M2M platforms, they should be maintained and refactored to adapt the heterogeneous features and properties of M2M platforms. Moreover, syntactical and semantic unification for information sharing among applications and devices are still unsolved because of raw data transmission and the usage of distinguished business vocabularies. In this paper, we propose and develop an M2M Middleware to support agile application integration with M2M platform. This middleware imports the event engine and XML-based syntax to handle the syntactical unification, makes use of Ontology-based semantic mapping to solve the semantic unification and adopts WebService and ETL techniques to sustain multi-pattern interactive approach, in order to agilely make applications integrated with the M2M platform. Now, the M2M Middleware has been applied in the China Telecom M2M platform. The operation results show that applications will cost less time and workload when being integrated with M2M platform.	agile application;agile software development	Menghan Chen;Beijun Shen	2012	TIIS	10.3837/tiis.2012.01.005	embedded system;computer science;operating system;machine to machine;ontology;middleware;data mining;database;world wide web	Robotics	-50.36583480793656	15.987166029709696	187020
3580c34b1d033581c0dc0e8662fb4be1273dd9ee	dynamic composition of cross-organizational features in distributed software systems	service composition;feature oriented;system of systems;software systems;aosd;cross organizational;user preferences;satisfiability;non functional requirement;dynamic composition;middleware;supply chain;service engineering	Companies offering software services to external customer organizations must ensure that the non-functional requirements of all these customer organizations are satisfied. However, in such a cross-organizational context where services are provided and consumed by different organizations, the implementation of features, for example security, is scattered across the services of the different organizations and cannot be condensed into a single module that is applicable to multiple services.  In this paper we present an aspect-based coordination architecture for dynamic composition of cross-organizational features in distributed software systems such as systems of systems or service supply chains. The underlying approach of this architecture is to specify the features at a higher level that abstracts the internal mechanism of the organizations involved. A coordination middleware dynamically integrates the appropriate features into the service composition, driven by metadata-based user preferences.	benchmark (computing);distributed computing;functional requirement;high- and low-level;identifier;middleware;non-functional requirement;prototype;service composability principle;software system;system of systems;user (computing)	Stefan Walraven;Bert Lagaisse;Eddy Truyen;Wouter Joosen	2010		10.1007/978-3-642-13645-0_14	system of systems;computer science;knowledge management;operating system;software engineering;middleware;database;supply chain;non-functional requirement;software system;satisfiability	SE	-51.385083515866604	16.40970231064287	187113
e622fbba3a3a0d09e3b422ca3d23e5bc1f931058	mining predictive process models out of low-level multidimensional logs		Process Mining techniques have been gaining attention, especially as concerns the discovery of predictive process models. Traditionally focused on workflows, they usually assume that process tasks are clearly specified, and referred to in the logs. This limits however their application to many real-life BPM environments (e.g. issue tracking systems) where the traced events do not match any predefined task, but yet keep lots of context data. In order to make the usage of predictive process mining to such logs more effective and easier, we devise a new approach, combining the discovery of different execution scenarios with the automatic abstraction of log events. The approach has been integrated in a prototype system, supporting the discovery, evaluation and reuse of predictive process models. Tests on real-life data show that the approach achieves compelling prediction accuracy w.r.t. state-of-the-art methods, and finds interesting activities’ and process variants’ descriptions.		Francesco Folino;Massimo Guarascio;Luigi Pontieri	2014		10.1007/978-3-319-07881-6_36	data science;data mining	ML	-53.059935822927656	18.051632714901306	187740
f9d8b1869de1840f00cc0970001696b887013581	a two tier, goal-driven workflow model for the healthcare domain			multitier architecture	Eric D. Browne;Michael Schrefl;James R. Warren	2003			data mining;workflow management system;knowledge management;computer science;health care;database;workflow	ML	-54.98562592988027	15.282291470039162	188984
cd43b82f0793f048d16d704c9eed9451252a0589	working with walt: how a cobot was developed and inserted on an auto assembly line		Collaborative robots (cobots) are a category of robots designed to work together with humans. By combining the fortes of the robot, such as precision and strength, with the dexterity and problem-solving ability of the human, it is possible to accomplish tasks that cannot be fully automated and improve the production quality and working conditions of employees [6], [16]. This article presents the results of the ClaXon project, which studies and implements interactions between humans and cobots in factories. The project has led to the integration of a cobot in the Audi car manufacturing plant in Brussels, Belgium.	cobot;humans;human–robot interaction;problem solving;requirement;robot;traction teampage;user requirements document	Ilias El Makrini;Shirley A. Elprama;Jan Van den Bergh;Bram Vanderborght;Albert-Jan Knevels;Charlotte I. C. Jewell;Frank Stals;Geert De Coppel;Ilse Ravyse;Johan Potargent;Jonathan Berte;Bram Diericx;Tim Waegeman;An Jacobs	2018	IEEE Robotics & Automation Magazine	10.1109/MRA.2018.2815947	simulation;engineering;task analysis;robot	Robotics	-55.04498918756505	11.27210472574532	189602
1ef331d6ecc43189b86158034caa60e9ed74370d	deadline control in holonic manufacturing using mobile agents	holonic manufacturing systems;agent based;real time;conceptual model;satisfiability;compensatory actions deadline control mobile agents high quality customized goods agent based holonic manufacturing systems reconfiguration product mixes malfunctions order size changes distributed shop floor environment holons hardware controller manufacturing task;computer integrated manufacturing software agents computer aided production planning production control;software agents;research and development;production control;mobile agents manufacturing systems real time systems control systems assembly hardware monitoring software agents decision making intelligent agent;computer aided production planning;mobile agent;computer integrated manufacturing	Manufacturing organizations have an ever-increasing need to produce and assemble high-quality, customized goods for quick delivery to market. Agent-based holonic manufacturing systems (HMS) are intended to support reconfiguration in this commercial environment by adapting to changes in product mixes, order sizes and malfunctions on the shop-floor. All of these changes must be performed in a distributed shop-floor environment while adhering to constraints imposed on the holons in terms of how they behave and interact in real-time. We examine the characteristics of holons based on mobile agents that migrate to the hardware controller responsible for executing the manufacturing task and monitor the status of execution for these tasks. Appropriate compensatory actions are then initiated to ensure that task deadlines are satisfied as much as possible. It is also argued that such a conceptual model will facilitate research and development of mobile agent-based holonic manufacturing systems with respect to HMS reconfiguration in real-time.	holon (philosophy);mobile agent	Martyn Fletcher;Robert W. Brennan;Douglas H. Norrie	2001		10.1109/DEXA.2001.953128	real-time computing;process development execution system;computer science;artificial intelligence;conceptual model;software agent;mobile agent;computer-integrated manufacturing;satisfiability	Robotics	-53.20908886849347	12.148304134281744	190606
020e4809f5eea4f63224495722809c615a61a995	standardized smart grid semantics using opc ua for communication		As many roadmaps and studies were developed focusing on smart grid standardization a set of core standards was identified. Some of them specify own data models and thus, create a need for harmonization to enable interoperability in terms of communications. On the level of data model integration, two data models play key roles in the future smart grid. On the one hand the Common Information Model and on the other hand IEC 61850-based models. Both were identified as core standards and are part of the IEC TC57 Seamless Integration Architecture, another recommended standard. In this contribution the OPC Unified Architecture, which is also a core standard specifying a server-client-architecture, is used to harmonize the two mentioned data models based on a common access layer. This leads to higher interoperability for, e.g., Energy Management Systems, Distribution Management Systems or SCADA systems.	automation;computer-integrated manufacturing;data model;floor and ceiling functions;human–computer interaction;iec 61131;iec 61131-3;information model;interoperability;management system;manufacturing execution system;microsoft outlook for mac;opc unified architecture;power domains;pure data;server (computing);unified modeling language;user agent	Sebastian Rohjans;Klaus Piech;Wolfgang Mahnke	2011	IBIS		opc unified architecture;systems engineering;ecology;architecture;data modeling;smart grid;standardization;data model;interoperability;iec 61850;biology	DB	-55.42379903943463	15.283131244709278	190876
03765c117e62feb8a5475569b3102ad33ad4e7f8	preliminary design and manufacturing planning integration using web-based intelligent agents	agent platform;computer aided design;agent based;software agent;agent communication;design optimization;integrated design;internet technology;collaborative environment;conceptual design;system integration;information exchange;intelligent agent;process development;production rate;process planning;product design;manufacturing system;object model;knowledge base	Software agents have been increasingly used in the product and process development in industry over the past years due to the rapid evolvement of the Internet technology. This paper describes agents for the integration of conceptual design and process planning. Agents provide mechanisms to interact with each other. This mechanism is important since both of those processes involve negotiations for optimization. A set of design and planning software agents has been developed. These agents are used in a computer-based collaborative environment, called a multi-agent platform. The main purpose of developing such a platform is to support product preliminary design, optimize product form and structure, and reduce the manufacturing cost in the early design stage. The agents on the platform have access to a knowledge base that contains design and planning rules. These rules are derived from an analysis of design factors that influence process and resource planning, such as product material, form, shape complexity, features, dimension, tolerance, surface condition, production volume, and production rate. These rules are used by process planning agents to provide process planners with information regarding selecting preliminary manufacturing processes, determining manufacturing resources, and constructing feedback information to product designers. Additionally, the agents communicate with WEB servers, and they are accessible by users through Internet browsers. During performing design and planning tasks, agents access the data pertinent to design and manufacturing processes by the programming interfaces of existing computer-aided design and manufacturing system. The agents are supported by a developed prototype agent platform. The agents and the platform enable the information exchange among agents, based on a previously developed integrated design and manufacturing process object model.	automated planning and scheduling;computer-aided design;enterprise resource planning;information exchange;intelligent agent;internet;knowledge base;mathematical optimization;multi-agent system;prototype;relevance;web application;world wide web	Shaw C. Feng	2005	J. Intelligent Manufacturing	10.1007/s10845-005-1655-4	knowledge base;multidisciplinary design optimization;information exchange;object model;process development execution system;computer science;systems engineering;engineering;knowledge management;artificial intelligence;software agent;conceptual design;computer-integrated manufacturing;product design;design technology;intelligent agent;system integration;product engineering	AI	-52.133982853007794	11.510452492647017	191020
687943ef870f08aa897f8c0742d5558c5c7e67e8	engineering process for capacity-driven web services	web service	This paper presents a novel approach for the engineering of capacity-driven Web services. By capacity, we mean how a Web service is empowered with several sets of operations from which it selectively triggers a set of operations with respect to some run-time environmental requirements. Because of the specificities of capacity-driven Web services compared to regular (i.e., mono-capacity) Web services, their engineering in terms of design, development, and deployment needs to be conducted in a complete specific way. Our approach define an engineering process composed of five steps: (1) to frame the requirements that could be put on these Web services, (2) to define capacities and how these capacities are triggered, and last but not least link these capacities to requirements, (3) to identify the processes in term of business logic that these Web services could implement, (4) to generate the source code, and (5) to generate the C apacity-driven Web Services Description Language ( C -WSDL).	browser user interface;business logic;electronic markets;iswc;information science;ontology (information science);p (complexity);requirement;requirements engineering;semantic web;software deployment;software engineering;springer (tank);web services description language;web service	Imen Benzarti;Samir Tata;Zakaria Maamar;Nejib Ben Hadj-Alouane;Mohamed Moez Yeddes	2010			web service;web application security;web development;web modeling;business process execution language;data web;web design;web standards;ws-policy;service-oriented architecture;web navigation;ws-addressing;database;services computing;web intelligence;web engineering;ws-i basic profile;web 2.0;law;world wide web;universal description discovery and integration	SE	-49.485954938393775	17.823042790957928	191256
9da3daa5c6461b906653b1a3cf44e9df0fc8b847	business process event log transformation into bayesian belief network		Business process (BP) mining has been recognized in business intelligence and reverse engineering fields because of the capabilities it has to discover knowledge about the implementation and execution of BP for analysis and improvement. Existing business knowledge extraction solutions in process mining context requires repeating analysis of event logs for each business knowledge extraction task. The probabilistic modelling could allow improved performance of BP analysis. Bayesian belief networks are a probabilistic modelling tool and the paper presents their application in BP mining. The paper shows that existing process mining algorithms are not suited for this, since they allow for loops in the extracted BP model that do not really exist in the event log, and presents a custom solution for directed acyclic graph extraction. The paper presents results of a synthetic log transformation into Bayesian belief network showing possible application in business intelligence extraction and improved decision support capabilities.	bayesian network;business process	Titas Savickas;Olegas Vasilecas	2014			knowledge extraction;business process;directed acyclic graph;data mining;process mining;bayesian network;probabilistic logic;decision support system;machine learning;business intelligence;computer science;artificial intelligence	AI	-53.38099843098342	17.479276969327742	192616
3d2f1a5289025445449db2139dd30dac1740303a	project venezia-gondola (a framework for p-commerce)	model view controller;004;peer to peer commerce ad hoc transaction jxta xml design patterns;distributed computing;lessons learned;peer to peer	A novel project named Venezia-Gondola (Project V-G) was presented, which describes an application platform that enables the activities of Peer-to-Peer commerce (P-Commerce). A new pattern called the Inverted Model-View-Controller (IMVC) pattern was claimed that is suitable for P-Commerce. The author also explains the principles of the Project V-G and possible architecture for future development.	model–view–controller;peer-to-peer	Raymond Gao	2005			computer science;database;distributed computing;world wide web	SE	-50.45158412176315	14.811840741355317	193391
614650e8cab6751489c3c3798e947aac972d6f40	pattern identification and classification in the translation from bpmn to bpel	web service;business process model;control flow;process model;reachability analysis;exhaustive search	BPMN is a notation for business process modeling. Process models can be complex, for instance, with unstructured (cyclic) topologies. BPEL, on the other hand, is the choice for web service orchestration. This paper presents an approach to systematically identifying and classifying subgraphs in a BPMN model that may be translated to BPEL code. Most of existing methods rely on exhaustive search. In contrast, we partition the BPMN model into single-entry single-exit regions which are then classified according to control flow information. This information is gathered by using a reachability analysis based on dataflow equations.		Luciano García-Bañuelos	2008		10.1007/978-3-540-88871-0_30	xpdl;computer science;data mining;database;world wide web	NLP	-52.570664668502246	17.607626839462664	193510
de0513de22559b3ebe6b8b8f50b0b3157c4ab75d	a model-driven approach for telecommunications network services definition	collaborative work;service provider;model transformation;present day;market timing;graphical model;service design;telecommunication networks;meta model	Present day Telecommunications market imposes a short concept-to-market time for service providers. To reduce it, we propose a computer-aided, model-driven, service-specific tool, with support for collaborative work and for checking properties on models. We started by defining a prototype of the Meta-model (MM) of the service domain. Using this prototype, we defined a simple graphical modeling language specific for service designers. We are currently enlarging the MM of the domain using model transformations from Network Abstractions Layers (NALs). In the future, we will investigate approaches to ensure the support for collaborative work and for checking properties on models.	model-driven integration;telecommunications network	Vanea Chiprianov;Yvon Kermarrec;Patrick D. Alff	2009		10.1007/978-3-642-03700-9_21	simulation;computer science;systems engineering;service delivery framework;operations management	ML	-48.76368468486379	17.959096964868483	193573
9812ca507637383a184f4c07de1af956d46fff49	storytelling integration of the internet of things into business processes		This paper discusses the integration of Internet of Things (IoT) into Business Processes (BPs). To define the business logic of thing-aware BPs, existing approaches extend traditional workflow languages (i.e., who does what, why, when, and where) with constructs like things’ roles. However, this way of defining the business logic restricts things’ operations and, thus, hinders them from initiating ad-hoc/opportunistic collaboration with peers. To overcome this limitation, we tap into the storytelling principles to introduce the concept of Process of Things (PoT) as a new way of integrating IoT into BPs. A PoT is specified as a story whose script indicates the characters that things will play as well as the scenes that will feature these things. A PoT, also, allows things to collaborate by offering value-added services to end-users. For demonstration purposes, a hospital scenario is implemented using a combination of real and simulated sensors along with different IoT technologies and communication protocols.	business process;internet of things	Zakaria Maamar;Mohamed Sellami;Noura Faci;Emir Ugljanin;Quan Z. Sheng	2018		10.1007/978-3-319-98651-7_8	business process;process management;business logic;business process management;communications protocol;storytelling;workflow;computer science;internet of things	ML	-49.894811830536746	15.750933305657128	195048
0b278bfbf5f556fe65e8ab0308b43764a89df7be	mda based generic c4isr effectiveness evaluation system	libraries;software architecture command and control systems;mda;satisfiability;flow independent model;fim;open architecture;software architecture;system evaluation;model driven architecture generic c4isr effectiveness evaluation system operational collaborative simulation system flow specific model fsm flow independent model fim;effectiveness evaluation;filtration libraries data models distributed databases data visualization containers;fsm;data visualization;distributed databases;fim mda effectiveness evaluation generic evaluation framework fsm;filtration;generic c4isr effectiveness evaluation system;command and control systems;generic evaluation framework;model driven architecture;operational collaborative simulation system;containers;data models;evaluation framework;flow specific model	In an operational collaborative simulation system, evaluation is always an important part to indicate validity, precision, robustness, reliability and other capabilities of the system. However, there is no generic evaluation tool accustomed to varied situations. This paper analyzes the current problem we confront, puts forward FSM (flow specific model) and FIM (flow independent model), and proposes an MDA (model driven architecture) based generic operational effectiveness evaluation framework, which is flexible and could satisfy various requirements. Finally, an evaluation platform based on the framework is introduced whose open architecture ensures that the platform can be extended conveniently to adjust itself to meet more different demands.		Yingchao Yue;Bin Xiao;Tianyuan Xiao;Wenhui Fan	2010		10.1109/FSKD.2010.5569670	data modeling;software architecture;real-time computing;simulation;filtration;open architecture;computer science;data mining;data visualization;satisfiability	SE	-50.19851083535119	17.346446334248352	195515
6220c603f7cf7dc2d5716842cb5db1dcd720d301	evolving commitments for self-adaptive socio-technical systems	software agents decision theory self adjusting systems;protocols;software adaptation;socio technical systems;trade off utility evolving commitments self adaptive socio technical systems sts software agents stakeholder requirements social commitments decision theoretic self adaptation framework candidate adaptation strategy contractual commitments adaptation procedure;motorcycles;adaptation models switches motorcycles estimation proposals lifting equipment protocols;estimation;software adaptation socio technical systems open systems agent commitments;agent commitments;lifting equipment;switches;adaptation models;open systems;proposals	Socio-technical systems (STSs) consist of human, hardware and software agents that work in tandem to fulfill stakeholder requirements. A specification for an STS consists of a set of (social) commitments among participating agents that serve as a contract among them. However, by their very nature, STSs are open, dynamic and continuously evolving along with their environments. To ensure that such systems continue to satisfy their requirements, the agents that comprise an STS must continuously adapt their behaviors to take into account risks and opportunities that arise at runtime. This paper presents a decision-theoretic self-adaptation framework that proposes candidate adaptation strategies for participating agents. These strategies are implementable by reconfiguration of plans or even changes in contractual commitments among agents. The adaptation procedure involves negotiating commitment changes and possible compensations to/from creditor agents. To evaluate the proposal, the paper also presents the results of an experimental study with a simulated STS, which confirms that success rates for achieving stakeholder goals and overall trade off utility can be improved significantly by incorporating evolving commitments to support STS adaptation.	content adaptation;experiment;jade;multi-agent system;real life;requirement;run time (program lifecycle phase);simulation;sociotechnical system;software agent;state diagram;theory	Xin Peng;Yi Xie;Yijun Yu;John Mylopoulos;Wenyun Zhao	2014	2014 19th International Conference on Engineering of Complex Computer Systems	10.1109/ICECCS.2014.22	communications protocol;estimation;simulation;network switch;computer science;engineering;sociotechnical system;management science;open system;management;lifting equipment	SE	-51.670721830472566	14.728962918773728	196739
64bbe66052ac656fa0867ed31c5169202a73b92e	a fog architecture for decentralized decision making in smart buildings		The integration of humans into smart buildings raises challenges between meeting individual preferences and the generic rules set to optimize energy effectiveness of interest to organizations. Merging the individual preferences of multiple occupants that share thermal zones compounds the challenge. To address related challenges, we have developed FRODO (Fog Architecture for Decision Support in Organizations), an architecture designed to establish a location- aware environment for conflict negotiation and decision support that is based on fog computing. This paper describes the model transformation from a centralized software architecture towards a decentralized Cyber-Physical System (CPS) which encompasses sensors, actuators, and the occupants of smart buildings. The transformation is implemented through MIBO, a framework that allows occupants to control their environment. MIBO has been extended to introduce a fog layer for improved negotiation and conflict resolution. This enables additional benefits to be optimized, such as increased quality of service, reduced latency, and improved security and resilience. The fog layer, introduced with FRODO, allows occupants and organizations to express and discuss conflicts in decision-making, at their point of origin.	centralized computing;cloud computing;cyber-physical system;decision support system;extensibility;fog computing;humans;model transformation;naruto shippuden: clash of ninja revolution 3;programming paradigm;quality of service;sensor;software architecture	Andreas Seitz;Jan Ole Johanssen;Bernd Brügge;Vivian Loftness;Volker Hartkopf;Monika Sturm	2017		10.1145/3063386.3063768	engineering;operations research;cartography	AI	-51.07964823738839	14.778114835827141	197231
3bfdae02a38c553c04754cea57dcca40cea95705	event-based real-time decomposed conformance analysis	real time monitoring;conformance analysis;process mining;event logs;conference report;process decomposition;conformance checking;external research report	Process mining deals with the extraction of knowledge from event logs. One important task within this research eld is denoted as conformance checking, which aims to diagnose deviations and discrepancies between modeled behavior and real-life, observed behavior. Conformance checking techniques still face some challenges, among which scalability, timeliness and traceability issues. In this paper, we propose a novel conformance analysis methodology to support the real-time monitoring of event-based data streams, which is shown to be more e cient than related approaches and able to localize deviations in a more ne-grained manner. Our developed approach can be directly applied in business process contexts where rapid reaction times are crucial; an exhaustive case example is provided to evidence the validity of the approach.	business process;conformance testing;mission critical;prototype;real life;real-time clock;real-time operating system;real-time transcription;scalability;traceability	Seppe K. L. M. vanden Broucke;Jorge Munoz-Gama;Josep Carmona;Bart Baesens;Jan Vanthienen	2014		10.1007/978-3-662-45563-0_20	reliability engineering;real-time computing;computer science;data mining	AI	-53.991681408517074	18.043946971233666	197688
8ee0d6358dbf84a1bb9ef5281b68479739cf6fd1	agent-based dynamic scheduling approach for collaborative manufacturing	virtual enterprises computer aided manufacturing dynamic scheduling groupware multi agent systems;agent based dynamic scheduling approach;groupware;brokers;collaborative work;service provider;virtual enterprises;design engineering;agent based;job shop scheduling;agent modeling;agent based model;satisfiability;virtual enterprise agent based dynamic scheduling approach collaborative manufacturing distributed multi agent approach coordinated intelligent rational agent;rational agent;dynamic environment;multi agent systems;collaborative manufacturing;agents;computer aided manufacturing;virtual enterprise;job design;dynamic scheduling computer aided manufacturing job design job shop scheduling collaborative work computer integrated manufacturing virtual manufacturing virtual enterprises international collaboration design engineering;distributed multi agent approach;coordinated intelligent rational agent;computer integrated manufacturing;virtual manufacturing;geographic distribution;dynamic scheduling;virtual enterprise agents brokers dynamic scheduling collaborative manufacturing;dynamic behavior	The rapidly changing market requires integrating information and collaborating among organizations to schedule jobs to machines that satisfy the objectives of service providers, and requesters. Moreover, delivering dynamic scheduling remains a major challenge especially when a diverse number of service providers and service requesters are geographically distributed. In this dynamic environment, scheduling usually involves complex and non-deterministic interactions between different participants. In this work, we propose a distributed multi-agent approach to model dynamic scheduling solution in manufacturing. We believe that agent-based model is appropriate due to its characteristics to support both dynamic behavior and distributed structure. The proposed approach is validated through a prototype implementation using the Coordinated Intelligent Rational Agent (CIR-Agent) model.	agent-based model;interaction;job stream;multi-agent system;prototype;rational agent;scheduling (computing);virtual enterprise	Raafat Aburukba;Hamada H. Ghenniwa;Weiming Shen	2007	2007 11th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2007.4281477	service provider;fair-share scheduling;rational agent;job shop scheduling;simulation;dynamic priority scheduling;job design;computer science;knowledge management;artificial intelligence;software agent;two-level scheduling;multi-agent system;computer-integrated manufacturing;management;satisfiability	Robotics	-52.404752661632116	13.27506032953321	198052
dc93c66d28fec58178e36f358afe79dac0a35604	quality models for web [2.0] sites: a methodological approach and a proposal	settore inf 01 informatica;iso iec 25010;web engineering;web;quality;web 2 0;quality model	This paper discusses a methodological approach to define quality models (QM) for Web sites of any kind, including Web 2.0 sites. The approach stresses the practical use of a QM, in requirement definition and quality assessment, during design & development processes or during site operation. An important requirement for such QMs is organization mapping, which allows who is in charge of quality management to easily identify the actors in the organization responsible for implementing or improving each specific quality characteristic. A family of QMs is proposed and compared with ISO/IEC 9126 and ISO 25010 QMs for software products and software-intensive computer systems.	iso/iec 9126;web 2.0	Roberto Polillo	2011		10.1007/978-3-642-27997-3_25	iso/iec 9126;web modeling;web standards;computer science;web engineering;web 2.0;world wide web	Web+IR	-49.360949433546374	17.662110607167318	198183
e8109f0320182515c050f8790ec2d1c0c62e203f	implementing e-business interoperability with vertical domain ap for web services	web service		business interoperability interface;web service	George Feuerlicht;Sooksathit Meesathit	2004			web development;world wide web;web standards;web coverage service;database;data web;web service;ws-i basic profile;web application security;ws-policy;computer science	Web+IR	-48.30845454568753	14.194875304694223	198460
f60c7b99812c6991c172b8a0ee2bbe296b201e39	a multi-agent self correcting architecture for distributed manufacturing supply chain	manufacturing systems;portfolio concept;manufacturing supply chains portfolios raw materials mathematical model;raw materials;supply chain algorithm portfolio cost distributed manufacturing multi agent architecture self correcting skill exploitation algorithm;distributed manufacturing supply chain;manufacturing process;multiagent self correcting architecture;supply chain costs;portfolios;algorithm portfolio;manufacturing plan;supply chains;multi agent systems;skill exploitation;supply chain management manufacturing systems multi agent systems;manufacturing;skill exploitation algorithm;distributed manufacturing;mathematical model;multi agent architecture;supply chain;self correcting;manufacturing process multiagent self correcting architecture distributed manufacturing supply chain distributed manufacturing environment manufacturing plan portfolio concept supply chain costs automatic selection skill exploitation manufacturing firms;cost;manufacturing firms;supply chain management;automatic selection;distributed manufacturing environment	Nowadays the supply chain for distributed manufacturing is gaining attention of the researchers worldwide. Realizing its significance this article proposes a self correcting multi-agent architecture for the supply chain for the distributed manufacturing environment. The main aim of the proposed architecture is to generate an effective manufacturing plan while exploring the algorithm portfolio concept to minimize the manufacturing and supply chain costs. This architecture focuses on automatic selection of best techniques and suppliers while making the tradeoff between the cost, availability, reliability, distance and quality of the products supplied. When the new order arrives, the proposed architecture explores the delicacy of the skill exploitation algorithm to simultaneously incorporate the new and old orders. This will help manufacturing firms to execute their manufacturing processes efficiently.	agent architecture;algorithm;distributed manufacturing;exploit (computer security);multi-agent system	Vikas Kumar;Nishikant Mishra	2011	IEEE Systems Journal	10.1109/JSYST.2010.2100195	supply chain management;systems engineering;computer-integrated manufacturing;supply chain	Robotics	-52.74515178251166	11.575179635960657	198884
0c9f705f45ee53a63498d750f3de4cf03b14cb1e	understanding the diversity of services based on users' identities	service adaptation;i modeling;personalization;context	Internet services involve complex networks of relationships among users and providers - human and automated - acting in many different capacities under interconnected and dynamic contexts. Due to the vast amount of information and services available, it is not easy for novice users to identify the right services that fit his purposes and preferences best. At the same time, it is not easy for service providers to build a service with a customizable set of features that satisfies the most people. This paper proposes to further extend the strategic actors modeling framework i* to analyze the diverse needs of users by modeling explicitly the personal characteristics, organizational positions, and service related roles. We assume that service users' needs and preferences are determined by their personal background, organizational roles, and the immediate operational context in combination. In this way, the origin of the diversity of service needs, quality preferences, and usage constraints, can be ascribed and used as a basis to make rationale selection from currently available types of services, and to reconfigure service interfaces and structures. Example usage scenarios of web services are used to illustrate the proposed approach.		Junjun Sun;Feng Liu;He Zhang;Lin Liu;Eric Kai-Hsiang Yu	2011		10.1007/978-3-642-21640-4_45	mobile qos;differentiated service;systems engineering;engineering;knowledge management;service delivery framework;service design;personalization;database;multimedia;services computing;tiered service;world wide web;service system	ML	-49.97397247671355	14.770373661782067	198968
bc26e2a3f4e3313240e449efbbaaf494c57fa5ed	enterprise resource planning: an applications' training aid based on semantic web principles	erp ontology;design and development;semantic web erp training;building block;erp system;business environment;erp training;ontology based training;enterprise resource planning;semantic web;user involvement;business process	An integrated ERP system is an asset for any organization using it, but since its full deployment requires increased cooperation between business units, there is a need to provide the users involved with appropriate training material, so that they can effectively and efficiently exploit the business processes, which very often change in a dynamic business environment. Existing training materials fail to represent effectively the implicit business knowledge in order to help the users understand the underlying structures and relationships. This paper proposes a prototype model for the design and development of ERP training material, where both the multimedia objects used in training scenarios and the knowledge built into them are captured and fully reusable. The proposed approach helps trainees understand: (i) which are the building blocks of an ERP application, (ii) how they relate with each other and (iii) how they can be used in order to solve business specific problems.	business process;erp;enterprise resource planning;prototype;semantic web;software deployment	Aristomenis M. Macris	2009		10.1007/978-3-642-04754-1_38	computer science;knowledge management;artifact-centric business process model;semantic web;data mining;database;business process;management;world wide web	AI	-53.75191453449684	13.981873423241655	199718
5dd61f963188c7be383f851b2bb53b74429a662d	easyticket: a ticket routing recommendation engine for enterprise problem resolution	management system;service provider;large data sets;social network;service industry	Managing problem tickets is a key issue in IT service industry. A large service provider may handle thousands of problem tickets from its customers on a daily basis. The efficiency of processing these tickets highly depends on ticket routing—transferring problem tickets among expert groups in search of the right resolver to the ticket. Despite that many ticket management systems are available, ticket routing in these systems is still manually operated by support personnel. In this demo, we introduce EasyTicket, a ticket routing recommendation engine that helps automate this process. By mining ticket history data, we model an enterprise social network that represents the functional relationships among various expert groups in ticket routing. Based on this network, our system then provides routing recommendations to new tickets. Our experimental studies on 1.4 million real-world problem tickets show that on average, EasyTicket can improve the efficiency of ticket routing by 35%.	enterprise social networking;recommender system;routing;social network	Qihong Shao;Yi Chen;Shu Tao;Xifeng Yan;Nikos Anerousis	2008	PVLDB	10.14778/1454159.1454193	tertiary sector of the economy;service provider;event correlation;management system;database;internet privacy;world wide web;ticket granting ticket;computer security;social network	DB	-50.46274125876667	12.694888781340001	199729
