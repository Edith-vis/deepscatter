id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
8f364ce0a4d75002c18f6d8a948719e8e6b6514e	camras: computer assisted mapping & records activity systems	records activity systems			William L. Bathke	1978				EDA	-51.69862069120316	-33.13079640738988	156075
33d6d5eb2b74b16dc95b0aa8f32eb02e5c0f80e9	acquiring and maintaining knowledge by natural multimodal dialog		v	multimodal interaction;dialog	Hartwig Holzapfel	2009			natural language processing;computer vision;communication	NLP	-50.12399824385238	-34.49027281889591	156231
b0ede7753decd9cefc85e176977e6095af6d5b2d	from augmented reality to augmented human	from augmented reality to augmented human;jun rekimoto;korea design research institute;한국디자인산업연구센터;증강현실을 넘어서 증강인간으로;idcc 2011	"""Traditionally, the field of Human Computer Interaction (HCI) was primarily concerned with designing and investigating interfaces between humans and machines. However, with recent technological advances the concept of """"enhancing"""", """"augmenting"""" or even """"redesigning"""" humans themselves is becoming not only interesting and intriguing but also very feasible and serious topic of scientific research and development. """"Augmented Human"""" is term that I use today to refer to this overall research direction. Although the term “augmentation” has long been used in HCI and AR communities since Douglas Engelbert’s landmark research on augmenting intelligence, I think the possibility of human augmentation is not limited to intellectual abilities and can be expound to physical abilities. I believe Augmented Human introduces a fundamental paradigm shift in HCI: from human-computer-interaction to human-computer-integration. In this talk, I will discuss rich possibilities and distinct challenges in enhancing human abilities with technology. I will introduce recent projects conducted by our research group including design and applications if wearable eye sensing for augmenting our perception and memory abilities, design of flying cameras as our external eyes, a home appliance that can increase your happiness, an organic physical wall/window that dynamically mediates the environment, and a human hand control system based on functional electrical stimulation."""	augmented reality;control system;functional electrical stimulation;human computer;humans;human–computer interaction;programming paradigm;wearable computer	Jun Rekimoto	2013		10.1109/ISMAR.2013.6671755	computer-mediated reality;simulation;human–computer interaction;engineering;mixed reality;multimedia	HCI	-55.35332754584365	-36.1523278028755	156304
ec5888d4d3a5bb94cb14c013f98051106ba6fecd	fun pledge 2.0: a funny platformers levels generator (rhythm based)		Procedural Content Generation is quite diffused in the field of video games design and development, since it can help in relieving designers from the burden of repetitive work, optimizing the development process, increasing re-playability, adapting games to specific audiences, and enabling new games mechanics. Anyway, when applying generative techniques, it is important not to forget that the main target is not optimization, but providing fun and compelling experiences to the player. In the present work, we tackle the issue of creating and testing an automated level editor for platform video games, starting from the work of [22,31]. The tool is aimed at producing levels that are both playable and fun, using as a starting point for the structure of the levels Afro-American musical rhythms. At the same time, it should guarantee maximum freedom to the level designer, and interactively suggest corrections functional to the quality of the player experience.	algorithm;embedded system;event dispatching thread;game engine;interactivity;level design;level editor;level structure;mathematical optimization;personalization;point of view (computer hardware company);procedural generation;refinement (computing);simulation	Claudio Mazza;Laura Anna Ripamonti;Dario Maggiorini;Davide Gadia	2017		10.1145/3125571.3125592	simulation;generative grammar;pledge;user experience design;rhythm;game design;turns, rounds and time-keeping systems in games;multimedia;game mechanics;computer science	HCI	-51.46560623913725	-37.34806194271057	157188
e346de7e873c1cd96b7eb96a4ae4ffa7a66efc0f	bio-sensed and embodied participation in interactive performance	interactive performances;audience engagement;bio sensing;bodily tracking;biodata	Designing for interactive performances is challenging both in terms of technology design, and of understanding the interplay between technology, narration, and audience interactions. Bio-sensors and bodily tracking technologies afford new ways for artists to engage with audiences, and for audiences to become part of the artwork. Their deployment raises a number of issues for designers of interactive performances. This paper explores such issues by presenting five design ideas for interactive performance afforded by bio-sensing and bodily tracking (i.e. Microsoft Kinect) developed during two design workshops. We use these ideas, and the related scenarios to discuss three emerging issues namely: temporality of input, autonomy and control, and visibility of input in relation to the deployment of bio-sensors and bodily tracking technologies in the context of interactive performances.	autonomy;british informatics olympiad;digital electronics;interaction;interactivity;kinect;performance;reflection (computer programming);sensor;software deployment	Asreen Rostami;Donald McMillan;Elena Márquez Segura;Chiara Rossitto;Louise Barkhuus	2017		10.1145/3024969.3024998	simulation;engineering;multimedia;communication	HCI	-55.300461647836116	-37.4447622066778	157902
12aec41eb4d0889a8799ef132388b9f982f55d72	advanced mobile lecture viewing: summarization and two-way navigation	recorded lectures;blackboard analysis;video summarization;ios;video skimming;mobile learning;ipad	"""In this work, the authors present a fully automated recorded lecture summarization tool and an innovative mobile iPad visualization tool. Summarization works for blackboard-based lectures by robustly extracting blackboard edits with great accuracy and high performance. Analysis output is then presented with overview and visual timelines along the original video to allow discovering lecture passages based on time. A second option allows students navigating contents in space by allowing revisiting blackboard elements directly by touching regions in the video. Proposed summarization, temporal and spatial navigation along with interactive visual annotations bring to recorded lectures the benefits that other digital learning material has long enjoyed and entice a younger generation of learners. DOI: 10.4018/jhcr.2012040104 International Journal of Handheld Computing Research, 3(2), 58-72, April-June 2012 59 Copyright © 2012, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. livering digital learning material. Additionally, with the advent of mobile platforms, reaching learners has never been this straightforward (Ormond, 2008). A second reason why eLearning has been received so warmly is the fact that most learning material has been significantly enhanced when going digital. For example textbooks and printed material have gained in interactivity and navigability allowing students to browse text and image-based material in small chunks and in the order that best suits their learning path, all while skipping unneeded content with unprecedented ease. Notable exceptions to such digital enhancements are recorded lecture videos. Although producing recorded lectures is more accessible and popular than ever, we cannot help wondering if at the other end students will be genuinely interested in resulting videos and their inherent media shortcomings. Video’s Media Limitations Ever since becoming mainstream video has largely remained unchanged: from videotape recordings to high definition broadcasts –all conceived with entertainment content in mind– video is still a rigid and linear medium. While general entertainment videos can be watched from beginning to end sequentially, and knowledge about the actual contents and their structure is not critical, recorded lectures are not suitable for such passive viewing. After all a typical lecture repository consists of hefty video files with dozens of recorded hours of overwhelmingly indistinguishable content. A typical video player, such as the one illustrated in Figure 1, doesn’t provide navigation cues other than an inexpressive timeline without any real useful information besides the current playing position and duration of the recording while lecture contents remain obscure. In most cases users have no other option than blindly jumping around the video, or even worse, skipping recorded lectures altogether because of frustration. With our research we intend to provide a complete solution for learners with intuitive information of recorded lecture contents to enable them to precisely find sections of interest and browse recordings without guesswork. At the same time we aim to leverage videos’ interactivity and navigation features by providing several visual cues and annotations features. In the next section we first describe an automated summarization tool that we have developed for blackboard-based recorded lectures. Later on we present our mobile visualization tool that combines source lecture videos with our summarization analysis output to provide a novel lecture viewing experience. SUMMARIZING LECTURES Summarization consists in discarding highly similar video sections while retaining only the most significant elements to succinctly describe the contents of a recording. Automated summarization is a hot research topic (Money & Agius, 2008) and lots of work has been done towards characterizing general videos where edition cuts, different camera angles, recording locations and multiple individuals clearly mark shot boundaries greatly simplifying automated scene’s feature extraction (Ciocca & Schettini, 2006a; Smith & Kanade, 1998). Summarizing documentary educational videos (Luo, Gao, Xue, Peng, & Fan, 2008; Song, Marchionini, & Oh, 2010) shares many aspects of general videos’ summarization techniques with visually recognizable passages and cinematography elements. As for digital slides-based presentations and lectures they are commonly summarized based on their already structured source files in PowerPoint or PDF file formats (Mittal, Pagalthivarthi, & Altman, 2006; Mukhopadhyay & Smith, 1999; Repp & Meinel, 2006). On the other hand, blackboard-based recorded lecture lack dramatic scene changes with mostly static shots: all the action takes place in an immutable indoor classroom and the main character, the lecturer, is by far the central character. Resulting recording passages seem all too 13 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/advanced-mobile-lectureviewing/67097?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Communications and Social Science, InfoSciCommunications, Online Engagement, and Media eJournal Collection, InfoSci-Journal Disciplines Computer Science, Security, and Information Technology, InfoSci-Journal Disciplines Engineering, Natural, and Physical Science. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""		Ernesto Rivera;Akinori Nishihara	2012	IJHCR	10.4018/jhcr.2012040104	multi-document summarization;human–computer interaction;computer science;automatic summarization;multimedia;world wide web;computer graphics (images)	HCI	-49.58642735764651	-37.12524030889838	158078
f2021b25db95d89055202b3fea9867971bbb1649	motion capture using the internet of things technology: a tutorial		is tutorial explores a variety of applications for Internet ofings (IoT) aided motion capture, drawing comparisons from dierent technologies and implementations. Various uses for these implementations will be discussed, as well as weighted against one another to analyse their advantages and disadvantages.	internet of things;motion capture	Kieran Gerard Holmes;Adam Coates;Mohammad Hammoudeh	2017		10.1145/3102304.3102344	implementation;web of things;multimedia;motion capture;internet of things;computer science	HCI	-53.37821421730284	-36.464107842220955	158100
7fb45228f8fe1ff08bf73450adad22f2811b45dc	teaching electronegativity and dipole moment in a tui	molecular modeling;learning effectiveness;electric moments;chemistry computing;computer aided instruction;rule based;interactive systems computer aided instruction teaching haptic interfaces chemistry computing electric moments;tangible user interface;three dimensional;interactive learning teaching electronegativity dipole moment tangible user interface 3d molecular models organic chemistry ac system chemistry education educational media;user experience;interactive learning;haptic interfaces;dipole moment;interactive systems;education chemistry grippers chemical elements user interfaces visualization usability electrons bonding augmented reality;teaching;organic chemistry	This paper describes how a tangible user interface (TUI) that was designed to construct molecules was extended to also visualize electronegativity and dipole moment. Using interactive tools working with the system, elements can be chosen from a booklet menu and composed into three-dimensional (3D) molecular models. The system is used to teach aspects of organic chemistry such as the octet ride. Based on user experience and expert interviews, a new mode to visualize electronegativity and dipole moment was realized. Evaluation of usability and the learning effectiveness of the AC system is in progress, also examining the dipole tool presented here. We currently compare AC with a ball-stick tool for chemistry education. The paper is an example of joint disciplines: Tangible UI, educational media for chemistry education, and interactive learning.	tangible user interface;usability;user experience	Morten Fjeld;Daniel Hobi;Lukas Winterthaler;Benedikt M. Voegtli;Patrick Juchli	2004	IEEE International Conference on Advanced Learning Technologies, 2004. Proceedings.	10.1109/ICALT.2004.1357659	rule-based system;three-dimensional space;user experience design;simulation;human–computer interaction;computer science;artificial intelligence;molecular model;multimedia	Robotics	-48.722769741804726	-34.21008926040263	158361
ca988237c817d77630ce37dd8da0cbdfc87f4fe4	towards a narrative theory of virtual reality	experience utilisateur;narrative;realite virtuelle;realidad virtual;narration;theorie narration;virtual reality;emergent narrative;role playing game;user experience;narracion;interactivite	Virtual Reality (VR), by its nature and characteristics, is of specific interest to the AI community, particularly in the domains of Storytelling and Intelligent Characters. We argue that VR must be considered a particular narrative medium alongside Theatre, Literature or Cinema. This paper reviews relevant work in narrative theory from Plato onwards, including the work and theories of literary critics [1], cinema critics [2–4] and theatrical dramaturges [5], and analyses the specific characteristics of VR relevant to this theory. Less studied media such as Live Role Playing Games, improvisational drama and participatory drama are also considered. Finally, this document argues for a participatoryprocess-oriented narrative, with particular attention to the specificities and particularities of stories and their possible representation, adapted to the narrative medium Virtual Reality.	biconnected component;cinema 4d;information source;interactivity;theory;unfolding (dsp implementation);virtual reality	Ruth Aylett;Sandy Louchart	2003	Virtual Reality	10.1007/s10055-003-0114-9	narrative inquiry;narrative criticism;narrative network;computer science;virtual reality;multimedia;narrative;narrative structure	Web+IR	-52.968956101879755	-31.82180721634018	158382
fd981312776d75d108c271276a6f565b449b167d	evaluating the future of hci: challenges for the evaluation of emerging applications	evaluation method	Current evaluation methods are inappropriate for emerging HCI applications. In this paper, we give three examples of these applications and show that traditional evaluation methods fail. We identify trends in HCI development and discuss the issues that arise with evaluation. We aim at achieving increased awareness that evaluation too has to evolve in order to support the emerging trends in HCI systems.	complex systems;context-aware pervasive systems;human–computer interaction;lazy evaluation;lexicon;multi-user;semiconductor consolidation;usability	Ronald Poppe;Rutger Rienks;Betsy van Dijk	2007		10.1007/978-3-540-72348-6_12	human–computer interaction;computer science;management science	HCI	-53.52879452026607	-36.802559965077435	158661
24ce61d07ad6644f75c7b37ffba218aff9d082fb	interfaces everywhere: interacting with the pervasive computer	smart artefacts;user interface;pervasive computing;wireless communication;sensors and actuators;everywhere interfaces;physical interface;tangible interaction;everyday life	Due to recent technological advances, it has become possible to integrate sensor and actuator technologies as well as wireless communication in everyday objects and environments. These developments open up a huge amount of innovative interaction scenarios, involving new forms of user interfaces. This half day tutorial gives an overview of the emerging field of everywhere interfaces, referring to computing devices that disappear within objects of everyday life and thus enable omnipresent physical interfaces to the digital world, describes the state of the art of sensor and actuator technologies and demonstrates the development of a smart artefact for controlling everyday environments.	interaction;pervasive informatics;sensor;user interface	Alois Ferscha;Clemens Holzmann;Michael H. Leitner	2006		10.1145/1111449.1111460	simulation;human–computer interaction;computer science;operating system;multimedia;user interface;ubiquitous computing;wireless	HCI	-53.11963279567774	-36.779329223724496	159022
491b27646b756756c63b232cee572569b8d9a4b8	dealing with complexity: uniting agents and direct manipulation (panel session	direct manipulation;anchored instruction;optimal solutions;intelligent learning environments;macrocontext microworlds;heuristic techniques;trip planning	Recent advances in cognitive science, multi-media technologies, and computer science have stimulated a growing interest in the innovative design and implementation of soft ware user-interfaces supporting computer-human interact ions. The CHI community has taken a strong interest in this subject area. There have been numerous conferences and workshops which have addressed a broad range of issues relating to “Advanced UIS”. Several active topics in this area include: (1) “perceptually rich UIS”, (2) “interface agent s“, (3) UIS based on end-user programming paradigms, (4) “knowledgebase” supported collaborate ive work environments, and (5) ad’qptive UIS. In the panel’s view, the human ~erspective is a crucial one in understanding the potential of UI software systems which are both usable and useful for user tasks.	chi;cognitive science;complexity;computer science;direct manipulation interface;end-user development;intelligent user interface;knowledge base;programming paradigm;rich user interaction;software system;warez	Doug Riecken;Pattie Maes;Ben Shneiderman;David Canfield Smith	1995		10.1145/223355.223504	simulation;artificial intelligence	ML	-54.94042717585441	-35.37567326558526	159428
6a789a2eb07f3b19838a3868dbb3420b1e02c9c6	issues in skill acquisition via human demonstration	skill acquisition via human;skill acquisition			Rüdiger Dillmann;Michael Kaiser	1996			knowledge management;dreyfus model of skill acquisition;computer science	HCI	-50.73487023933687	-34.45890144467464	159834
1c0dcc49dda9ff8ec0fd4888ceb3dfd2cbab966a	p2pmobilelearning: a content adaptation p2p application on mobile devices	distance education;mobile device;p2p;bittorrent;content adaptation;ubiquitous computing;p2p networks;peer to peer	Currently there is a growth on the access of Peer-to-Peer (P2P) networks content by mobile devices. However this access still limited, because a content generated in a device may be incompatible in another. Aiming to allow this access in a distance education environment this paper presents an application based on a P2P network with content adaptation on mobile devices. This application was developed to support activities of medicine students at the Federal University of Sao Carlos.	content adaptation;mobile device;peer-to-peer	Eduardo Felipe Zambom Santana;Antônio Francisco do Prado;Wanderley Lopes de Souza	2009		10.1145/1858477.1858519	distance education;mobile search;bittorrent;human–computer interaction;computer science;peer-to-peer;mobile device;multimedia;internet privacy;mobile computing;world wide web;ubiquitous computing	Mobile	-50.72133531020693	-31.184730224583106	160628
09ab12728db71ac163015a494df8f662bfdb31e8	taptell: interactive visual search for mobile task recommendation ☆	mobile recommendation;visual vocabulary;mobile visual search;visual intent;mobile user intention;interactive visual search;natural user interface;image retrieval	http://dx.doi.org/10.1016/j.jvcir.2015.02.007 1047-3203/ 2015 Elsevier Inc. All rights reserved. q This paper has been recommended for acceptance by Prof. M.T. Sun. ⇑ Corresponding author. E-mail addresses: ning.zhang@ryerson.ca (N. Zhang), tmei@microsoft.com (T. Mei), xshua@microsoft.com (X.-S. Hua), lguan@ee.ryerson.ca (L. Guan), spli@ microsoft.com (S. Li). 1 http://www.discoverbing.com/mobile/. 2 http://www.google.com/mobile/. 3 http://www.apple.com/ios/siri/. 4 Merriam-Webster Dictionary, 2002. Ning Zhang a,⇑, Tao Mei , Xian-Sheng Hua , Ling Guan , Shipeng Li b	algorithm;content-based image retrieval;dictionary;embedded system;google goggles;interactivity;mobile interaction;natural user interface;outline of object recognition;pixel;recommender system;region-based memory management;sampling (signal processing);touchscreen;vocabulary;ios	Ning Zhang;Tao Mei;Xian-Sheng Hua;Ling Guan;Shipeng Li	2015	J. Visual Communication and Image Representation	10.1016/j.jvcir.2015.02.007	computer vision;mobile search;image retrieval;computer science;multimedia;natural user interface;world wide web	AI	-49.433182999531844	-33.84864548430478	160705
2bf67fbf7f4f1330c430b97c3be00dac1969a811	affect modeling with field-based physiological responses				Jin-Hyuk Hong;Anind K. Dey	2015	Interacting with Computers	10.1093/iwc/iwu014	human–computer interaction;computer science	NLP	-52.044395105142975	-34.147529725828505	160978
c5ce43f2a40af0c748c0d7d85014c503b540fef5	bridging the gap between design for all and assistive devices	design for all		assistive technology;bridging (networking)	Julio Abascal;Antonio Abad Civit Balcells	2001			human–computer interaction;design for all;computer science;bridging (networking)	HCI	-52.994348185287365	-35.386727698859275	162075
8178bda33fc82735be642c8bcf15796ed6a0a21f	text emotion computing under cognition vision		The emotion computation is an artificial intelligence popular research area. This article in view of text emotion computation research present situation, introduces in the emotion recognition the cognition linguistics and the psychology knowledge, attempts solves the existing problem from a new angle. Learned from experiment's result, the text emotion cognitive model's experiment effect is good.	artificial intelligence;cognition;cognitive model;computation;emotion markup language;emotion recognition;glossary;topography	Jingzhong Wang;Lu Zhang	2009	Computer and Information Science		artificial intelligence;affective science	AI	-51.20028494185646	-31.988380390763588	162285
d40c032f0e9ad6ecc4bf37457876c08a7cea3a09	interactivity, inhabitation and pragmatist aesthetics			interactivity	Phillip D. Deen	2011	Game Studies		interactivity;multimedia;computer science;pragmatism;aesthetics	HCI	-52.817379982517636	-32.100713320902294	162540
ca09e472e4bfc75d72a9ed60dddf334b5a6aa04b	remote usability testing	remote usability testing	Imagine being able to collect data lie static and full motion screen images, user video, and user comments , through your computer. Think about observing from your office or lab as an evaluation participant worked in their own o&e. What if you could sample from an intercity, interregional, or international user base without having to leave your office or lab? Thanks to recent developments in the areas of information sharing and collabora-tive work tools, each of these objectives is now attainable Usability evaluators can now view computer networks and modem connections as frameworks upon which distributed usability labs can be constructed, and all network or modem accessible machines as potential windows into remote test sites. These remote test sites can range from a machine down the hall to one on the other side of the world. The technological building blocks needed to create remote testing facilities are now available, in varying degrees, on all major computing platforms (i.e., Unix, MS Windows, Macintosh, OS/2). With computer-to-computer video conferencing tools product development teams can now both see and listen to evaluation participants sitting in front of properly equipped computers anywhere in the world. They can observe evaluation participants as they examine and annotate screen shots or g documentation using shared whiteboard tools. Observers can also watch full motion images of f the participant's screen from remote locations H g as participants use their products. By mixing p and matching these technological building i blocks, usability specialists can conduct a myri-ad of usability engineering activities remotely.	computer;documentation;microsoft windows;modem;new product development;os/2;screenshot;unix;usability engineering;usability testing	Monty L. Hammontree;Paul Weiler;Nandini P. Nayak	1994	Interactions	10.1145/182966.182969	usability;computer science;system usability scale;usability engineering;usability lab;usability inspection	HCI	-48.281211481819	-37.342059928858994	162569
5a4c00aea7a19e8a4bf095928baef84539c487d5	mconduct: a multi-sensor interface for the capture and analysis of conducting gesture		The art of conducting has a long and well-established history, using physical gesture to convey musical intent and expressions. Conducting relies on visual communications to direct the ensemble as a coherent unit. The aim of this project is to capture and analyse the hand gestures of conducting in order to provide real-time, interactive multimodal feedback in a number of application contexts including visualisation. This paper presents the design and development of the interface involving hardware sensors and software analysis modules, and discusses the application of visualisation for conducting. The paper concludes with latest findings, future directions and the impact the research may have outside the realm of gesture communication application.	coherence (physics);multimodal interaction;real-time computing;real-time locating system;sensor	Joanne L. Armitage;Phoebe Bakanas;Joel Balmer;Paul Halpin;Kyle Hudspeth;Kia Ng	2012		10.1007/978-1-4471-5406-8_11	computer vision;computer science;gesture;artificial intelligence	HCI	-55.128126309215205	-37.33554839903056	163967
27dd654dc5aad1d9c3315fc081a283839389978f	tools that support human-human communication in the automated office	human-human communication;automated office			Ian D. Benest;D. Dukic	1990			human–computer interaction	HCI	-50.69502748464109	-34.62301742770635	164469
562b17e96600b4addcf91b791ec8c8e1fa0548cf	usability testing of a complex cds tool in the ed; lessons learned			usability testing	Anne Press;Lauren McCullagh;Sundas Kahn;Salvatore Pardo;Andy Schachter;Thomas G. McGinn	2015			usability;systems engineering;engineering	SE	-54.40278387847113	-34.45535844898814	164614
60fb1d5407c905a592e7b4c6d91b59f16190854f	dinnerware: why playing with food should be encouraged	edible circuits;food;dinnerware;responsive materials;edible interfaces	DinnerWare is an exploration of eating as a medium for computation and aesthetic expression. It consists of a dining service electronically equipped to react to the properties of the food that it holds and respond to a user's eating gestures.	computation	Marcelo Coelho	2009		10.1145/1520340.1520514	simulation;multimedia	ECom	-49.18747864481107	-35.926142994039026	164646
8318aa9d5ac7e62cb3ca6c81468080180d3b345e	internet of abilities: human augmentation, and beyond (keynote)	telepresence;jackin;human augmentation internet of abilities telepresence jackin;human augmentation;internet of abilities	"""Traditionally, the field of Human Computer Interaction (HCI) was primarily concerned with designing and investigating interfaces between humans and machines. However, with recent technological advances, the concepts of """"enhancing"""", """"augmenting"""" or even """"re-designing"""" humans themselves are becoming feasible and serious topics of scientific research as well as engineering development. """"Augmented Human"""" is a term that I use to refer to this overall research direction. Augmented Human introduces a fundamental paradigm shift in HCI: from human-computer-interaction to human-computer-integration, and out abilities will be mutually connected through the networks (what we call IoA, or Internet of Abilities, as the next step of IoT: Internet of Things). In this talk, I will discuss rich possibilities and distinct challenges in enhancing human abilities. I will introduce our recent projects including design of flying cameras as our remote and external eyes, a home appliance that can increase your happiness, an organic physical wall/window that dynamically mediates the environment, and an immersive human-human connection concept called """"JackIn."""""""	human computer;internet of things;programming paradigm	Jun Rekimoto	2017		10.1109/3DUI.2017.7893310	simulation;engineering;multimedia;communication	HCI	-55.33217171874019	-36.16687756013158	165753
8d3bc7c4c24fa1cace1dc0f35296ed3879e53de8	modèle d'interaction pour les systèmes mixtes	mixed systems;linking modality;hci;physical digital coupling;multimodality;augmented reality	My doctoral research deals with the design of mixed interactive systems. These systems seek to smoothly link the physical and data processing (digital) environments. Facing a lack of capitalization and help when designing such systems, my work address this problem and propose a model of interaction focusing on objects interacting with users. This model allows description, characterization and generation of interaction techniques. It aims at capitalizing existing research results. Pratical realisations in this doctoral study allow to test this model on concrete situations.	interaction technique;smoothing	Céline Coutrix	2007		10.1145/1541436.1541480	simulation;engineering;multimedia;communication	HCI	-52.41733307507172	-36.06072808752718	165805
aba8a4445a8bc7ce42f65fca4f0356ee9e5ab174	the social car: new interactive vehicular applications derived from social media and urban informatics	location based services;urban informatics;social web;automotive;geo web;100500 communications technologies;social media;urban data;080600 information systems	Digital information that is place- and time-specific, is increasingly becoming available on all aspects of the urban landscape. People (cf. the Social Web), places (cf. the Geo Web), and physical objects (cf. ubiquitous computing, the Internet of Things) are increasingly infused with sensors, actuators, and tagged with a wealth of digital information. Urban informatics research explores these emerging digital layers of the city at the intersection of people, place and technology. However, little is known about the challenges and new opportunities that these digital layers may offer to road users driving through today's mega cities. We argue that this aspect is worth exploring in particular with regards to Auto-UI's overarching goal of making cars both safer and more enjoyable. This paper presents the findings of a pilot study, which included 14 urban informatics research experts participating in a guided ideation (idea creation) workshop within a simulated environment. They were immersed into different driving scenarios to imagine novel urban informatics type of applications specific to the driving context.	digital data;internet of things;sensor;social media;ubiquitous computing;urban informatics;user interface;virtual reality;world wide web	Ronald Schroeter;Andry Rakotonirainy;Marcus Foth	2012		10.1145/2390256.2390273	simulation;engineering informatics;engineering;multimedia;world wide web	HCI	-54.3882912893887	-37.704397835648265	165807
03621c332422b2e5b6e1f9589f9c1514769a5a35	towards a process of building semantic multimodal dialogue demonstrators		A generic integration framework should allow us to build practical dialogue systems for specific use case scenarios. While domain-specific dialogue systems are simpler to achieve than more general, open-domain conversational dialogue systems, the integration into use cases and demonstration scenarios requires a lot of difficult integration work, especially in multimodal settings where different user devices such as touchscreens and PDAs are used. The challenges for those systems include, apart from the dialogue modelling task, the integration modelling for specific use case and demonstration scenarios. This paper reports on dialogue system prototype development based on ontology communication structures and we draw special attention to the process of how to build demonstration systems that include a task-oriented, information-seeking, or advicegiving dialogue as an important fragment of practical dialogue system development.	defense in depth (computing);dialog system;dialog tree;interpreter (computing);knowledge-based systems;linked data;mcgurk effect;multimodal interaction;obedience (human behavior);personal digital assistant;prototype;rm-odp;requirement;resource description framework;touchscreen;usability	Daniel Sonntag;Norbert Reithinger	2010			natural language processing;computer vision;computer science;artificial intelligence	NLP	-51.66910182969142	-37.62789229472819	166232
d56cc48f4a53d25644c93818531a75a6b3b2b9c1	understanding and modeling communication scenes	new technology;teleconferencing;instrumented meeting rooms;multimodal communication;ami amida research;advanced videoconferencing systems;layout information analysis humans ambient intelligence computer networks pervasive computing communications technology collaboration signal processing speech recognition;human human communication;computer enhanced communication tools;video communication teleconferencing;advanced videoconferencing systems human human communication computer enhanced communication tools ami amida research instrumented meeting rooms;speech recognition;audio visual;video communication;information analysis;scene analysis	This paper discusses the technologies required to better understand and model human-human communication, and to use the resulting technologies to build computer-enhanced communication tools. As networks and computers become more pervasive, groups are increasingly using technology to assist communication and collaboration and to reduce travel needs. The addition of new technologies based on advanced signal (audio-visual) processing and multimedia information analysis can have a positive impact on meetings and human communication. However, human communication is complex and is factored across several modalities. To address the problem requires major research efforts in several traditionally separate disciplines including unconstrained speech recognition, visual scene analysis, modeling individuals and groups through the joint processing of multiple information channels, and structuring, indexing and summarizing these multimodal communication scenes. Projects such as AMI/AMIDA (www. amiproiect.org) have made significant progress in these basic areas. AMI/AMIDA research revolves around instrumented meeting rooms and advanced videoconferencing systems which enable the collection, annotation, structuring, and browsing of multimodal meeting recordings.	computer;multimodal interaction;pervasive informatics;speech recognition;world wide web	Hervé Bourlard	2006	2006 IEEE Spoken Language Technology Workshop	10.1109/SLT.2006.326786	simulation;speech recognition;teleconference;computer science;multimedia;data analysis	Visualization	-49.44646710349408	-37.91880382083726	166935
76a4dfea6135a2f8f9a6bd141ce0bf861485cf32	ideal types of users based on subjective experiences of individualization-focused user-companion interaction				Julia Krüger;Mathias Wahl;Jörg Frommer	2015				HCI	-52.71283208345565	-32.601255321821114	166990
796b6e65114a4e3bdd8a47862910328927f6c2ab	generating educational interactive stories in computer role-playing games	educational stories;role playing game;story generation;role playing games;interactive storytelling;utility computing;computer games;computer game	The aim of interactive storytelling is to tell stories with the use of computers in a new and interactive way, which immerses the reader inside the story as the protagonist and enables him to drive its course in any desired direction. Interactive storytelling thus transforms conventional stories from static structures to dynamic and adaptive storyworlds. In this paper, we describe an innovative approach to interactive storytelling that utilizes computer roleplaying games, today’s most popular genre of computer games, as the storytelling medium in order to procedurally generate educational interactive stories.	computer;data structure;interactive storytelling;interactivity;pc game;prototype	Marko Divéky;Mária Bieliková	2009		10.1007/978-3-642-04636-0_46	simulation;human–computer interaction;computer science;operating system;utility computing;multimedia;interactive media	HCI	-49.94409239127353	-31.868540181073566	167442
c8e6e7d9f223bec814d5caec403db752eda8d632	beyond researchkit: user engagement with phendo, a novel app for self-tracking and research				Mollie McKillop;Sylvia English;Sharib A. Khan;Chintan Patel;Noémie Elhadad	2017				HCI	-53.800009715828544	-33.27413790185475	167618
6dd594df6d41d14eb9583f2e9e699c19dbe2f742	a haptic-audio human-computer interface : acquisition of indoor spatial knowledge by visually impaired people	human computer interaction;sonification;multimodal representation;haptic audio interface for visually impaired people;haptisch akustische schnittstelle fur sehbehinderte menschen;mensch computer interaktion;multimodale reprasentation	For the visually impaired it is important to acquire knowledge about environments in advance. Haptic-audio interfaces have been proven as appropriate to represent certain types of spatial knowledge in a non-visual manner. This dissertation elaborates on a haptic-audio interface that supports non-visual spatial knowledge acquisition of indoor environments. Three representational layers relevant for acquisition of indoor spatial knowledge using the haptic-audio interface are defined in the following: (a) knowledge concerning room access and the layout of individual rooms and whole flats, (b) knowledge about the location of functional facilities (such as, windows, radiators, and power-outlets), and (c) knowledge regarding the position of furniture. In correspondence, three research questions were investigated, namely (i) how to represent boundaries among areas and access to areas, (ii) how to represent linear spatial overlapping aroused by the presence of functional facilities, and (iii) how to represent 2-D spatial overlapping aroused by furniture pieces in rooms. Based on these considerations, a haptic-audio interface is implemented as non-visual floor plans that can be perceived with the PHANToM virtual force feedback device. In order to discuss the research questions mentioned above, a user-centered research methodology is employed in this dissertation. User behavior was observed and evaluated with help of usability studies. Users requirements and expectations were investigated through focus group studies. Based on empirical analyses of the three representation layers of the haptic-audio interface, this dissertation represents room access and layout of an indoor environment through virtual haptic models. Linear spatial overlaps are represented with the support of sonification. Further more, a two-phase haptic-audio exploration strategy is proposed to acquire spatial knowledge involving 2-D spatial overlapping: In the first phase, the floor plan on display is unfurnished and the functional facilities are sonified. Then in the second phase, virtualization of furniture pieces is further displayed. The empirical results show that spatial knowledge of room-access and layouts of indoor environments can be acquired by visually impaired people through exploration in haptic-audio virtual environment. Plausibility of acquiring spatial knowledge involving linear overlapping and 2-D overlapping is also presented.	emoticon;focus group;haptic technology;human–computer interaction;knowledge acquisition;microsoft windows;plausibility structure;requirement;sonification;two-phase locking;usability;user-centered design;virtual reality	Junlei Yu	2014			engineering;electrical engineering;performance art	HCI	-51.61646356560964	-36.283164129716496	167779
90135896d72261f3d773734e841018f90c844c67	coping with psychophysiological stress during multi-tasking in human-computer interaction	human computer interaction		human–computer interaction	Wolfram Boucsein;Florian Schaefer	1999			human–computer interaction;computer science	HCI	-52.44156539448424	-35.460298234172726	168320
b10fe52a889ae524a67165e49f3428dbb4c87e32	designing a museum multi-touch table for children		Tangible user interfaces allow children to take advantage of their experience in the real world with multimodal human interactions when interacting with digital information. In this paper we describe a model for tangible user interfaces that focuses mainly on the user experience during interaction. This model is related to other models and used to design a multitouch tabletop application for a museum. We report about our first experiences with this museum application.	digital data;multi-touch;multimodal interaction;tangible user interface;user experience	Betsy van Dijk;Frans van der Sluis;Anton Nijholt	2011		10.1007/978-3-642-30214-5_16	simulation;human–computer interaction;multimedia	HCI	-52.117337376017495	-36.241877068267726	169094
06f2eb04411a3dfa8a557a90bd6274a11f82f2aa	the impact of visual and background music congruity on media commercial's information effectiveness				Chandan Sarkar	2010			multimedia;advertising;psychology	Web+IR	-54.140835767836634	-32.45085762898738	169640
292ebb594ea900c6d3bbe9dc8cf8bfa7bccaeb96	computational objects and expressive forms: a design exploration	design process;computational objects;user study;hci;tangible interface;aesthetic interaction;design;interaction design;tangible interfaces	We suggest the concept of expressive forms as a rising design theme to explore aesthetics of computational objects. The theme, exemplified in our design exploration, attempts to synthesize a concept-driven design process and exploratory engagement with new forms and materials available to computational objects. We report the detailed process of designing the soft-spiky mouse including prototyping and a pilot user study, leading to a discussion about the experiential qualities and design implications of expressive forms for research on aesthetic interaction.	arduino;book;chi;communications of the acm;computation;computer;dipole antenna;human–computer interaction;interaction design;jung;modern tales;p (complexity);skin (computing);software design;text encoding initiative;usability testing	Heekyoung Jung;Youngsuk L. Altieri;Jeffrey Bardzell	2010		10.1145/1753846.1753997	design;user experience design;simulation;design process;human–computer interaction;sonic interaction design;computer science;object-oriented design;interaction design;multimedia;design education	HCI	-54.548319362096905	-36.047738369504664	170275
c683270d67cd3a399000581a0085ebf416c43864	spatial augmented reality - merging real and virtual worlds		Like virtual reality, augmented reality is becoming an emerging platform in new application areas for museums, edutainment, home entertainment, research, industry, and the art communities using novel Please provide your name and opengl code fragments implementation instructions examples of virtual reality. Just click on the book spatial, ar displays in new application. Oliver bimber and acm siggraph no particular. Just click on the impact of computer graphics techniques 3d tools and calibration. Many cg and to receive 7mb attachments augmented reality is of spatial. No part of spatial augmented reality which have taken approaches concerns everyone. If not please contact us at the authors have put together with requesting invitation.	acm siggraph;attachments;augmented reality;computer graphics;educational entertainment;head-up display;opengl;virtual reality;virtual world	Oliver Bimber;Ramesh Raskar	2005		10.1145/3250709		Visualization	-49.22151279874113	-36.83525098058891	171040
21f41dad14fceeb22bb2f1c8d94786b347609bd4	polytempo network: a system for technology-assisted conducting		This paper describes the current development of a system designed for the synchronization of musicians in polytempic music. In order to convey the tempo, an animation is used that resembles the gestures of a conductor, which is believed to be particularly comprehensible for musicians. This system offers an alternative to the use of a click track which is still the most common means for the purpose of synchronization. The possibility to combine several devices in a network allows for the synchronization of several players in ensemble music. It is hoped that this system promotes the creation and performance of music that exhibit ambitious tempo polyphony as well as spatial distribution of the musicians.		Philippe Kocher	2014			simulation;speech recognition;engineering;communication	HCI	-49.12498761538566	-35.84795734061226	171431
5b040371c4baa0cf001b76f903e9b2312648e3a0	virtual logic - the small machine				Louis H. Kauffman	2007	Cybernetics and Human Knowing		cognitive science;human–computer interaction;pointer machine;virtual finite-state machine;virtual machine;psychology	AI	-50.95284695004349	-33.4784301474083	173356
8152ccafd08c24a0162780d073ff7dee8bfebc2b	usability requirements of user interface tools			usability;user interface	Catherine Letondal;Stéphane Chatty;Greg Phillips;Fabien André;Stéphane Conversy	2010			human–computer interaction;usability;user interface;computer science	HCI	-51.9261562640317	-35.40023560161619	173870
276a6e186818121f981cc7ede47d56fc669b0b27	prototyping a context-aware framework for pervasive entertainment applications	users interaction;context awareness;sensor systems;context aware;game theory;mobile device;social interaction;sensors;information science;application software;user interface;social interaction mobile devices context awareness virtual augmented reality pervasive entertainment;prototypes;real time;contextual information;heterogeneous sensors;pervasive entertainment;virtual augmented reality;dedicated system architecture;qa75 electronic computers computer science;software architecture;virtual prototyping;research and development;3d model;ubiquitous operation;engines;spatial relation;three dimensional displays;2d models;context aware framework;games;mobile communication;peer to peer information exchange;mobile handsets;artificial intelligence;ubiquitous computing;computer science and informatics;peer to peer computing;augmented reality;system architecture;peer to peer;user interface paradigms;3d models;user interfaces;entertainment;context;mobile devices;socio technical framework;user interfaces entertainment peer to peer computing software architecture ubiquitous computing;point of interest;prototypes game theory engines user interfaces artificial intelligence application software virtual prototyping information science research and development sensor systems;peer to peer information exchange context aware framework pervasive entertainment dedicated system architecture users interaction mobile devices heterogeneous sensors user interface paradigms socio technical framework 2d models 3d models ubiquitous operation;real time systems	This paper presents research and development of dedicated system architecture, designed to enable its users to interact with each other as well as to access information on Points of Interest that exist in their immediate environment. This is accomplished through managing personal preferences and contextual information in a distributed manner and in real-time. The advantage of this system is that it uses mobile devices, heterogeneous sensors and a selection of user interface paradigms to produce a socio-technical framework to enhance the perception of the environment and promote intuitive interactions. Representation of the real-world objects, their spatial relations and other captured features are visualised on scalable interfaces, ranging from 2D to 3D models and from photorealism to stylised clues and symbols. The framework is fit for use in unknown environments and therefore suitable for ubiquitous operation. The presented prototype is multifaceted and capable of supporting peer-to-peer exchange of information in a pervasive fashion, usable in various contexts. The modalities of these interactions are explored and laid out particularly in the context of entertainment.	3d modeling;client-side;inter-process communication;interaction;mechatronics;mobile device;peer-to-peer;personalization;personally identifiable information;pervasive informatics;point of interest;prototype;real-time computing;real-time transcription;scalability;sensor;sociotechnical system;systems architecture;user interface	Stelios Papakonstantinou;Vesna Brujic-Okretic	2009	2009 Conference in Games and Virtual Worlds for Serious Applications	10.1109/VS-GAMES.2009.18	simulation;human–computer interaction;computer science;multimedia	HCI	-51.968528110704085	-36.70747619975268	174713
100803f397732c6bf4e969af8e0d05333d795bc1	conceptual design	design process;task model;design methods;user centered design;cognitive models;conceptual design;measurable objectives;task analysis;design techniques;user requirements;user interface design;product design;software design;usability	This full-day tutorial introduces conceptual design and a simple, user-centered framework for creating conceptual designs as a basis for organizing the functionality of a product and representing it in the user interface. It covers the purpose, context, benefits, examples, process, and hands-on application of the framework to a sample project.	hands-on computing;organizing (structure);user interface;user-centered design	Kathy Potosnak	1999		10.1145/632716.632808	user interface design;iterative design;user experience design;user-centered design;design process;usability;design methods;human–computer interaction;experience design;computer science;knowledge management;software design;user requirements document;environmental graphic design;task analysis;conceptual design;design language;design education;product design;design technology;user interface;design brief;generative design	HCI	-52.811399498816606	-36.72136353690605	175719
45bf5066a8aa4786aeca371e667106fe31087da0	challenges in designing inter-usable systems	cross platform systems;inter usability;interaction design	Interactive systems are increasingly interconnected across different devices and platforms. The challenge for interaction designers is to meet the requirements of consistency and continuity across these platforms to ensure the inter-usability of the system. In this paper we investigate the current challenges the designers are facing in the emerging fields of interactive systems. Through semi-structured interviews of 17 professionals working on interaction design in different domains we probed into the current methodologies and the practical challenges in their daily tasks. The identified challenges include but are not limited to: the inefficiency of using low-fi prototypes in a lab environment to test inter-usability and the challenges of “seeing the big picture” when designing a part of an interconnected system.	interaction design;interactivity;requirement;scott continuity;semiconductor industry;usability	Ville Antila;Alfred Lui	2011		10.1007/978-3-642-23774-4_33	simulation;human–computer interaction;computer science;interaction design	HCI	-54.107972149025194	-37.607935751160205	175757
df6c143d64680cc8eb2101f14db087b54a05885c	the conversational style of mothers interacting with their two- and five-year-old children			interaction	Tanja Schorch;Jens Brauer	2013				HCI	-50.87846553008622	-33.95368520112904	176249
7ae04f8ce4690753bded1b4faf21f343a258b566	pictures, audio and movies - positioned around me (pam-pam)	content management;search and retrieval;location based media discovery creative content production data retrieval data search media creation informal creative learning communities virtual spaces creative artifact dissemination creative artifact sharing teaching contexts global positioning system;learning community;audio visual systems;media communities context education mobile communication global positioning system mobile handsets;learning;teaching audio visual systems content management educational technology global positioning system information dissemination information retrieval mobile computing multimedia systems;information retrieval;location based media discovery;global position system;multimedia systems;global positioning system;system design;information dissemination;educational technology;mobile computing;virtual space;learning and teaching;teaching;system design global positioning system learning teaching location based media discovery	Many of the spaces that we inhabit have histories of creative content production, the houses we live in, the places we frequent, the places we work and the environment that forms our home. Some creative content can be accessed through our physical archives of books, images and moving pictures, however, this takes time to search and retrieve data from. This project is built on the concept of capturing some of the creative content produced linked to the physical places in which they were composed. This paper describes the design of a system for students to create and discover media in relation to their physical location. The idea behind the system is to facilitate the creation of informal creative learning communities through virtual spaces enabled by location based technologies. Therefore to encourage students to share, disseminate and discover creative artifacts linked to the places in which they are living. The paper outlines how the tool could be used in particular learning and teaching contexts and describes the plan for evaluating the tool over the duration of 2011.	archive;book;image;linux pam;point accepted mutation	Darren Mundy;Linda Hockley	2011	2011 IEEE 11th International Conference on Advanced Learning Technologies	10.1109/ICALT.2011.132	learning community;educational technology;simulation;global positioning system;content management;computer science;artificial intelligence;database;multimedia;mobile computing;world wide web;systems design	HCI	-49.37978229352619	-37.22944076791921	180579
72b4946c4d930eb8bc9a31fbad57ce4777b74690	perceptual intelligence: learning gestures and words for individualized, adaptive interfaces	adaptive interface		complex adaptive system	Alex Pentland;Deb Roy;Christopher Richard Wren	1999			natural language processing;speech recognition;computer science	AI	-50.41972469920252	-34.40983835174792	180583
f1b5510340a295d91f3654f79b955f41095c0d94	towards emotionally aware ai smart classroom: current issues and directions for engineering and education		Future smart classrooms that we envision will significantly enhance learning experience and seamless communication among students and teachers using real-time sensing and machine intelligence. Existing developments in engineering have brought the state-of-the-art to an inflection point, where they can be utilized as components of a smart classroom. In this paper, we propose a smart classroom system that consists of these components. Our proposed system is capable of making real-time suggestions to an in-class presenter to improve the quality and memorability of their presentation by allowing the presenter to make real-time adjustments/corrections to their non-verbal behavior, such as hand gestures, facial expressions, and body language. We base our suggested system components on existing research in affect sensing, deep learning-based emotion recognition, and real-time mobile-cloud computing. We provide a comprehensive study of these technologies and determine the computational requirements of a system that incorporates these technologies. Based on these requirements, we provide a feasibility study of the system. Although the state-of-the-art research in most of the components we propose in our system are advanced enough to realize the system, the main challenge lies in: 1) the integration of these technologies into a holistic system design; 2) their algorithmic adaptation to allow real-time execution; and 3) quantification of valid educational variables for use in algorithms. In this paper, we discuss current issues and provide future directions in engineering and education disciplines to deploy the proposed system.	algorithm;artificial intelligence;deep learning;emotion recognition;holism;mobile cloud computing;real-time locating system;real-time transcription;requirement;seamless3d;smart tv;smart card;systems design	Yelin Kim;Tolga Soyata;Reza Feyzi Behnagh	2018	IEEE Access	10.1109/ACCESS.2018.2791861	management science;body language;deep learning;distributed computing;systems design;visualization;structured systems analysis and design method;emotion recognition;gesture;computer science;artificial intelligence	AI	-54.344916377962896	-35.85079824245299	181745
d438b588509193c32df1055c912f5f92aa7a92b0	extending molic for collaborative systems design		Much interaction design research has been devoted to collaborative systems, resulting in diverse design methodologies. Despite these efforts, we still lack a widely adopted interaction model for collaborative systems design. In this paper, we present a study on model-based design approaches, focusing on their limitations with respect to the 3C Model of Collaboration. Based on the 3C Model, we propose an extension to MoLIC, an interaction design language grounded in semiotic engineering but with no support for collaboration. We then illustrate the expressiveness of the extended MoLIC in the interaction design representation of a collaborative document editor.	collaborative software;systems design	Luiz Gustavo de Souza;Simone D. J. Barbosa	2015		10.1007/978-3-319-20901-2_25	human–computer interaction;interaction model;semiotic engineering;collaboration;computer science;interaction design;expressivity	EDA	-55.2208494387698	-34.45145804430785	181847
2239fa9a8eae04a1407d009d65e74a61d596a798	first international workshop on user interfaces for crowdsourcing and human computation	software;user incentives;human computer interaction;human computation;user interfaces;crowdsourcing	Recent years witnessed an explosion in the number and variety of data crowdsourcing initiatives. From OpenStreetMap to Amazon Mechanical Turk, developers and practitioners have been striving to create user interfaces able to effectively and efficiently support the creation, exploration, and analysis of crowdsourced information.  The extensive usage of crowdsourcing techniques brings a major change of paradigm with respect to traditional user interface for data collection and exploration, as effectiveness, speed, and interaction quality concerns play a central role in supporting very demanding incentives, including monetary ones.  The First International Workshop on User Interfaces for Crowdsourcing and Human Computation (CrowdUI 2014), co-located with the AVI 2014 conference, brought together researchers and practitioners from a wide range of areas interested in discussing the user interaction challenges posed by crowdsourcing systems.	amazon mechanical turk;crowdsourcing;human-based computation;openstreetmap;programming paradigm;the turk;user interface	Alessandro Bozzon;Lora Aroyo;Paolo Cremonesi	2014		10.1145/2598153.2602225	crowdsourcing software development;human–computer interaction;computer science;data mining;user interface;world wide web;crowdsourcing	DB	-53.98417856099083	-37.09255788191934	181914
f37877653380daa019ecd1d6d68a396bee8af965	how mobile devices could change the face of serious gaming	serious games;smartphones;mobile games;talk		mobile operating system	Tim Dutz;Martin Knöll;Sandro Hardy;Stefan Göbel	2013	i-com	10.1515/icom.2013.0013	simulation;multimedia;internet privacy	HCI	-53.0301318572228	-33.7686761227165	182493
02ceed770e5596b12f07ec8d9cb8af6f67359394	usability recommendations in the design of mixed interactive systems	design process;systematic review;task model;user centered design;task modeling;interactive system;mixed interactive systems;interaction modeling;interaction model;interaction design;usability recommendations	Mixed Interactive Systems (MIS) are systems allowing several interaction forms resulting from the fusion between physical and digital worlds. Such systems being relatively new, the underlying design process leading to their design is not entirely defined, particularly in terms of user-centered design. The goal of this paper is to present an approach that attempts to identify, model and integrate available usability knowledge into a user-centered approach for the design of MIS. The approach consisted of: systematic review of the literature on MIS; selection and deciphering of usability recommendations under a common format; classification of the 141 usability recommendations obtained; and application of the recommendations to the design of a MIS case study (museum application).	interactivity;systematic review;usability	Syrine Charfi;Emmanuel Dubois;Dominique L. Scapin	2009		10.1145/1570433.1570475	usability goals;pluralistic walkthrough;web usability;component-based usability testing;cognitive walkthrough;user experience design;interactive systems engineering;usability;human–computer interaction;computer science;systems engineering;usability engineering;multimedia;heuristic evaluation;usability lab;usability inspection	HCI	-52.71741345667104	-36.94127999031505	182870
a42bd689ff2092c4fc0b5e80b4eee281a57df448	html5 game development	game design;computer games;gamification	A computer game, in addition to being playable and fun, has all of the characteristics of a modern high quality user interface. The ubiquity of multimedia web interfaces and gamification leads designers and developers to look at how games are designed and constructed. This course will take the attendee from initial concept through design to implementation of a basic web-based game, using accessible high level tools that could also be used equally in a research environment or an undergraduate classroom.	display resolution;gamification;html5;high-level programming language;pc game;user interface;video game development;web application	Jim R. Parker	2014		10.1145/2559206.2567814	video game design;first playable demo;game design;game development tool;simulation;level design;human–computer interaction;computer science;game mechanics;game art design;game developer;multimedia;game design document;video game development;game programming;game testing	HCI	-49.91241207327341	-31.66008633322883	183050
1a86c5bec882b35f2b44e2bd74248d8c454426e3	computer studio report: tri-college group for electronic music and related research				Wesley Fuller	1980			human–computer interaction;multimedia;electronic music;studio;engineering	ECom	-49.876634812419276	-33.67470234054208	183076
10af095ccd7cf141eb008dcc29926cca4a794f9a	augmenting the virtual domain with physical and social elements: towards a paradigm shift in computer entertainment technology	tabletop games;hybrid environments;computer games;tangible interfaces;entertainment	In this paper, means of enriching computer entertainment experiences by emphasizing physical and social game elements are discussed. A conceptual framework in which the relations between the virtual, the physical, and the social domains are modelled is presented. Interfaces that mediate between the domains are discussed along with a complementary software architecture that helps developing hybrid computer games. Finally, sample games that follow the approach of physical and social augmentation are presented.	experience;hybrid computer;pc game;programming paradigm;software architecture	Carsten Magerkurth;Timo Engelke;Maral Memisoglu	2004		10.1145/1067343.1067363	simulation;human–computer interaction;engineering;multimedia	HCI	-52.65844616969423	-36.66444486147855	183180
7892726c989c6f9896cc826588456dbebd6df187	towards reasoned modality selection in an embodied conversation agent		Comunicacio presentada a: the 17th International Conference, IVA 2017, celebrat del 27 al 30 du0027agost de 2017 a Estocolm, Suecia.	modality (human–computer interaction)	Carla Ten-Ventura;Roberto Carlini;Stamatia Dasiopoulou;Gerard Llorach Tó;Leo Wanner	2017		10.1007/978-3-319-67401-8_52	multimedia;social psychology;conversation;computer science;embodied cognition	AI	-51.214734388816915	-33.7338793049629	183639
059e1b5e8c8890b84fa07f61161a6a483a04b86b	introduction to: special issue on smartphone-based interactive technologies, systems, and applications		Smartphones (or smart mobile devices) have now truly become a ubiquitous computing device, a computer that the late Mark Weiser envisioned in his ubiquitous computing manifesto. Many applications that could only have been dreamed of have now become a reality due to the powerful computing resources, display, sensing, and networking capabilities of smartphones. With applications ranging from productivity, entertainment, enterprise, social networking, communications, and mixed reality, the smartphone is the “swiss army knife” of it all. However, there are still many untapped elements and unlimited possibilities: Smartphones can provide next-generation interactive systems with more intuitive and intelligent technologies and applications that have not been explored much in detail, especially through the use of mobile computing, sensing, and networking capabilities. Making uses of cyber and physical data accessible by smartphones at a location, new cyber-physical interactive technologies and systems can be designed and integrated to create novel functionalities, methods, and intelligences to interact with humans and environments for better social experiences, as well as more intelligent services and creative applications, such as recommendation systems, advertising platforms, and gaming applications that are interactive to the user smartphones on the spot in a physical environment and situation. This special issue of ACM Transactions on Multimedia Computing, Communications and Applications (TOMM) provides an opportunity to attract and bring together mobile computing, cyber-physical systems, ubiquitous computing, social computing, wireless networking, and multimedia communications researchers along with user interface designers and practitioners with diverse backgrounds to contribute articles on theoretical, practical, and methodological issues for next-generation interactive technologies, systems, and applications using smartphones. There were a record number of submissions (38 in total) for this special issue of ACM TOMM. Twelve high-quality, creative, and interesting articles were selected and accepted, which discuss various challenges and emerging directions of smartphone-based interactive technologies, systems, and applications. This special issue starts off with 5 articles concerning the technologies and applications for better uses and creations of visual/3D images and augmented reality (AR) in the smartphones The first article by Zhu et al. is titled “ShotVis: Smartphone-Based Visualization of OCR Information from Images” and it presents an approach to help smartphone users to easily read and organize text-based data captured by the smartphone’s camera. The captured images with textual data are first processed by optical character recognition, and the recognized information is readable through various intuitive visualization techniques selected and refined by smartphone users through on-screen interactions.	augmented reality;computer;cyber-physical system;enterprise social networking;experience;human-readable medium;interaction;interactivity;mixed reality;mobile computing;mobile device;optical character recognition;recommender system;row (database);smart device;smartphone;social computing;text corpus;text-based (computing);ubiquitous computing;user interface	James She;Alvin Chin;Feng Xia;Jon A Crowcroft	2015	TOMCCAP	10.1145/2820398	multimedia;human–computer interaction;computer science	HCI	-53.93932755154243	-36.97622301862146	184853
f209247c21ebed17c1a71f770d2b1b6de74e3385	exploring how people collaborate with a stranger: - analyses of verbal and nonverbal behaviors in abstract art reproduction				Haruka Shoda;Tomoki Yao;Noriko Suzuki;Mamiko Sakata	2015		10.1007/978-3-319-21073-5_38	human–computer interaction;computer science;abstract art;nonverbal communication	NLP	-50.570081409599226	-34.15608914296085	185841
4af80436f2f334bc81dff8921da73dc3dfcdb612	biotic games: integrating real living cells into digital game play		The advancement of biotechnology enables the novel medium of “biotic video games”. Biotic games are the playful interaction with living microscopic cells. In this conference contribution we will give a live demo of a low-cost biotic game kit that we developed which enables the wider distribution of biotic games. We present a 3Dprintable microscope containing four LEDs controlled by a joystick that enables human players to provide directional light stimuli to the motile single-celled organism Euglena gracilis. The cells’ behavior is displayed on the integrated smart phone. Real time celltracking couples these cells into interactive biotic video game play, i.e., the human player steers Euglena to play soccer with virtual balls and goals. The player’s learning curve in mastering this fun game is intrinsically coupled to develop a deeper knowledge about Euglena’s cell morphology and phototactic behavior. This kit is educational via construction and via play; its low cost and open soft/hardware should enable easy, wide adoption and further development. We invite the community to develop other games on this platform for education and entertainment. INTRODUCTION Biological technologies are becoming increasingly relevant in societies, creating a need for improved training and education. Interactive play and construction kits have been effective in steering student interest and engagement towards nurturing an interest in science [1], such as with video games and robots [2], [3]; integrating artistic and design aspects is also educationally important, hence the acronym STEAM (Science, Technology, Engineering, Art, Math) [4]. Equivalent activities in the life sciences are underdeveloped. We will give a live demo of a lowcost biotic video game [5], [6] kit (Fig.1) that we have developed in order to allows humans to playfully interact with living microorganisms. IMPLEMENTATION Biology – Euglena: As biological organism we chose Euglena gracilis, which are single-celled motile protists that are photosynthetic and phototactic (Fig. 2). Euglena are attracted or repelled by light based on its intensity (Fig.2C). This allows the player to control the orientation and direction of the Euglena via directional light stimuli. Euglena are widely used in educational settings. They are safe to use, educators are familiar with the organism, and many curricula exist for teaching students about Euglena. They are very popular as they are comparably large, have a vivid red eyespot and green cell body (Fig. 2B), and can survive multiple weeks without any care. Fig.1: We developed a biotic video game design kit that enables humans to playfully interact with single celled Euglena. A) Overview of the game-kit with a player applying light stimulus via joystick; smart phone displays video game environment. B) Schematic of components enabling humanbiology interaction. Fig.2: The game play features the phototactic behavior of the single-celled organism Euglena. A) Subcellular details of the organism are visible. B) Schematic of Euglena highlighted. C) Upon application of directional light stimuli, the player is able to induce collective motion away from the light (Note: all cells oriented to the right). (Scale: Length of Euglena ~50 μm)	bus mastering;collective motion;educational entertainment;fractal dimension;galaxy morphological classification;interactivity;joystick;robot;schematic;smartphone;steam;synthetic biology;video game design	Ingmar H. Riedel-Kruse;Honesty Kim;Lukas C. Gerber	2015			simulation;multimedia;computer science	HCI	-54.13383896665099	-35.146108537559414	186357
05413d62eae6d2185a04c52883866d119cb2a3e9	book review of studying mobile media: cultural technologies, mobile communication, and the iphone			mobile media;mobile phone	Zachary O'Leary	2012	First Monday		mobile web;computer science;mobile technology;multimedia;advertising;internet privacy	HCI	-53.55088094342356	-33.351521411006736	186815
37a55dbf4db0fe1f1fa17b1938f08515c84e3aac	mobile computing and ambient intelligence: the challenge of multimedia, 1.-4. may 2005	ambient intelligence;mobile computer		ambient intelligence;mobile computing		2005			simulation;ambient intelligence;human–computer interaction;multimedia;mobile computing	AI	-52.41781634878859	-34.958588089426875	186947
104cf38aeb7e89c595c97ab0d86948ae9ddbebec	design and development of a multimodal dialogue system to support university tutorship			dialog system;dialog tree;multimodal interaction	Zoraida Callejas Carrión;Ana M. Gutiérrez-Arranz;David Griol;Ramón López-Cózar;Nieves Ábalos;Gonzalo Espejo	2010		10.3233/978-1-60750-639-3-79	human–computer interaction;computer science	NLP	-50.400437139930325	-34.484455020188285	187181
93857773d4d35196d6c191f811b5a7db20fee9b7	promesses et contraintes de la joaillerie numérique interactive: un aperçu de l'état de l'art	wearable computer;miniaturization;wearable computing;usability;interaction technique;interactive digital jewelry	The miniaturization of electronic components paves the way for new interaction techniques for wearable computing. We briefly review interactive digital jewelry, an emerging subfield. We report the data of a limited poll about the way people perceive the prospect of digital jewelry. We then consider the constraints and the promise of digital jewelry, and finally classify the current solutions, which generally resort to gestural interaction.	electronic component;gesture recognition;interaction technique;linear algebra;wearable computer	Simon T. Perrault;Gilles Bailly;Yves Guiard;Eric Lecolinet	2011		10.1145/2044354.2044372	human–computer interaction;engineering;multimedia;computer graphics (images)	HCI	-53.85741026493669	-36.50969115525053	187439
c8bb5e0ea15d982c60cf04406203c0ff8c3a34bb	a collaborative dialogue model based on interaction between reactivity and deliberation	collaborative dialogue model	collaborative dialogue model		Takaaki Hasegawa;Yukiko I. Nakano;Tsuneaki Kato	1997		10.1145/267658.267671	knowledge management	NLP	-50.90881263796171	-34.08193969741819	187803
351a09ccde6b2ad937ca0604b60f0616264cda99	"""""""social engineering"""": towards a new paradigm for developing multi-user visualization systems"""	multi user systems;digital library;digital libraries;multi user;cscw;social agents;visual system;social agent		multi-user;programming paradigm;social engineering (security)	Javier Jaén Martínez;Leonidas Rigas	1998		10.1145/324332.324344	human–computer interaction;computer science;knowledge management;world wide web	DB	-48.409088299175394	-31.971679970653067	188054
0d1892573840b192d8acbeb51ed7f37d31da5bc3	questionable assumptions and misconceptions in ergonomic research on human-computer interaction: a discussion	human computer interaction		human factors and ergonomics;human–computer interaction	Jack Litewka	1987			human factors and ergonomics;human–computer interaction;computer science;simulation	HCI	-53.73631487661641	-35.52443943692092	188086
1a2a01cc6ccf1c1e27c3a8da8b434d2e896f4ff2	design of an annotation system for taking notes in virtual reality		The industry uses immersive virtual environments for testing engineering solutions. Annotation systems allow capturing the insights that arise during those virtual reality sessions. However, those annotations remain in the virtual environment. Users are required to return to virtual reality to access it. We propose a new annotation system for VR. The design of this system contains two important aspects. First, the digital representation of the annotations enables to access the annotation in both virtual and physical world. Secondly, the interaction technique for taking notes in VR is designed to enhance the feeling of bringing the annotations from the physical world to the virtual and vice versa. We also propose the first implementation of this design.	interaction technique;virtual reality	Damien Clergeaud;Pascal Guitton	2017	2017 3DTV Conference: The True Vision - Capture, Transmission and Display of 3D Video (3DTV-CON)	10.1109/3DTV.2017.8280398	mixed reality;computer science;human–computer interaction;immersion (virtual reality);multimedia;virtual machine;tangible user interface;instructional simulation;virtual reality;computer-mediated reality;annotation	Visualization	-50.43935736266351	-36.407290030975204	188161
78228e09ccf06631a3145ee98e47d2e2a2957693	the integration problem: interlacing language, action and perception			interlaced video;interlacing (bitmaps)	Stephen J. Cowley	2014	Cybernetics and Human Knowing		cognitive science;interlacing;psychology;perception	Robotics	-51.29222444318085	-32.050896211943396	190026
5593b62b6dc5ade34ce36c6f308b6c4251b7eec3	privacy protection filter using shape and color cues	eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems	The steady growth in the adoption of video surveillance systems emphasizes the need for privacy protection techniques. In this paper, we present a method inspired from image abstraction and non-photorealistic rendering fields for creating privacy protection filters. The effectiveness of the proposed filter has been demonstrated by assessing the intelligibility vs. privacy vs. pleasantness in a subjective evaluation framework using different videos.	closed-circuit television;intelligibility (philosophy);non-photorealistic rendering;privacy;unbiased rendering	Hajer Fradi;Yiqing Yan;Jean-Luc Dugelay	2014			simulation;engineering;multimedia;advertising	Vision	-53.85579038287243	-32.06626981599755	190494
3667c773a2c6eb87cb3f46dcc9de8824684d7de0	trusting experience oriented design	human computer interaction;manniska datorinteraktion interaktionsdesign;hci;human factors;trust in automation;affective experiences;experience oriented design;experience design	Although trust and affective experiences have been linked in HCI research, a connection between traditional trust research for automation and experience design has not be made. This paper aims to start this discussion by showing the connection between experience-oriented HCI design and trust in automation through an experimental study of the Lega, a companion device for enriching experiences in museums. An experience-oriented HCI design approach was used to create this device and although it is not traditional automation, this study presents the links found between this approach and the bases of trust in automation, performance, process, and purpose, with regards to experience qualities of transparency, ambiguity, and usefulness, respectively.	experience design;experiment;human–computer interaction;trust (emotion)	Aisling Ann O'Kane	2011		10.1145/1979742.1979517	human–computer interaction;experience design;computer science;knowledge management;human factors and ergonomics;multimedia	HCI	-53.77872479472278	-35.88090841721038	190522
c4aab1540c3c2413c38e047180fd400cf0de5266	transferring a virtual environment client session between independent opensimulator installations	training second life context production games computers;computers;training;games;production;second life;context	This paper describes the current mechanism of interconnecting independent OpenSimulator installations such that a client session can be transferred from one installation to another. It also describes the consequences of this mechanism and reflects on their possible impact.	opensimulator;virtual reality	Justin Clark-Casey	2013	2013 5th International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES)	10.1109/VS-GAMES.2013.6624246	simulation;human–computer interaction;computer science;multimedia	HPC	-49.522553536726406	-35.78717626266881	190581
d1e842c93eceb8649d4c2e2d2d10861e3e04e129	fall of humans: interactive tabletop games and transmedia storytelling	tabletop games;game design;qa75 electronic computers computer science;transmedia storytelling	This paper illustrates how transmedia storytelling can help introduce players to interactive tabletop games. To do so, we developed Fall of Humans (FoH), an experience that takes place over two games: Meat factory, a physical card game where players compete to create different zombies; and Uprising, a interactive tabletop game where players can get to see the zombies they have created come to life.	humans;interactivity	Mara Dionisio;Aditya Gujaran;Miguel Pinto;Augusto Esteves	2015		10.1145/2817721.2823477	video game design;simulation;human–computer interaction;engineering;multimedia	HCI	-49.46905305307955	-35.26607959009917	190958
4dabedfb59e0b1e3089eba3240965a79af283375	narrative agency and user experience in transmedia narratives: brazilian telenovelas case	transmedia;telenovela;user experience;interactivity	This short paper proposes a reflection about the transmedia strategies in brazilian telenovelas, more specifically on how is the user experience in this kind of narratives. The user experience design in these narratives in multiple platforms is key to this new paradigm of entertainment media, once the main objective of transmedia storytelling is to create engagement and immersion of the user in the narratives.	immersion (virtual reality);programming paradigm;user experience design	Mariane Harumi Murakami	2015		10.1145/2824893.2824911	human–computer interaction;engineering;knowledge management;multimedia	HCI	-53.23840362959305	-35.02200937996546	191614
99f13564d2caa1f3345830df3fc325d909640299	auramirror: reflections on attention	real time;information visualization;media art;computer vision;attentive user interface;ubiquitous computing;interactive art;attentive user interfaces	As ubiquitous computing becomes more prevalent, greater consideration will have to be taken on how devices interrupt us and vie for our attention. This paper describes Auramirror, an interactive art piece that raises questions of how computers use our attention. By measuring attention and visualizing the results for the audience in real-time, Auramirror brings the subject matter to the forefront of the audience's consideration. Finally, some ways of using the Auramirror system to help in the design of attention sensitive devices are discussed.	amiga reflections;computer;interactive art;microsoft forefront;real-time transcription;subject matter expert turing test;ubiquitous computing	Alexander W. Skaburskis;Roel Vertegaal;Jeffrey S. Shell	2004		10.1145/968363.968385	simulation;human–computer interaction;computer science;multimedia	HCI	-54.315685067347545	-36.92666635686843	191711
1049522c9d59bbebe4805bbc0077e33a75dbb2ce	sentiment analysis on youtube: a brief survey		Sentiment analysis or opinion mining is the field of study related to analyze opinions, sentiments, evaluations, attitudes, and emotions of users which they express on social media and other online resources. The revolution of social media sites has also attracted the users towards video sharing sites, such as YouTube. The online users express their opinions or sentiments on the videos that they watch on such sites. This paper presents a brief survey of techniques to analyze opinions posted by users about a particular video.	sentiment analysis;social media	Muhammad Zubair Asghar;Shakeel Ahmad;Afsana Marwat;Fazal Masood Kundi	2015	CoRR		computer science;multimedia;internet privacy;world wide web	HCI	-55.04260990181713	-32.10332740673979	192705
8ff24c03703baa40e6dec6afb2226ac042c381e3	staying in the flow with zoomable user interfaces	slide presentations;software tool;interaction techniques;sensemaking;zoomable user interface;zoomable user interfaces zuis;staying in the flow;interaction technique	This research aims to investigate a collection of interactions in 2D workspaces with the goal of helping users stay in the flow of their activity. These interactions will be explored in the context of two software tools designed to support information work. The first tool, Niagara, addresses the early phases of this work that involve organization and synthesis. CounterPoint, the second tool, targets the later stages of this work that concern the authoring, delivery, and understanding of presentations.	digital zoom;interaction;ultrasparc t1;user interface;workspace	Lance Good	2002		10.1145/506443.506475	human–computer interaction;computer science;multimedia;zoom;world wide web;interaction technique	HCI	-54.67582406952164	-37.45299538248875	193122
64ac1b1dea093c37b18abdd91f28a9a133d61b2f	evaluating new interaction paradigms in sen teaching: defining the experiment	informatica	New devices have made their way into everyday life in recent years, opening the doors to new ways of interacting with computers, providing different, and potentially better, solutions to some problems. But this raises the question of if there is any way of measuring whether or not these new devices are suitable. This paper presents a strategy for evaluating the suitability of new interaction devices in the context of teaching children with special educational needs.	computer;experiment;interaction	Paloma Cantón;José L. Fuertes;Ángel Lucas González;Loïc Martínez	2014		10.1007/978-3-319-08596-8_73	simulation;computer science;engineering	HCI	-50.722760166396384	-32.68615205474495	193601
cbc8e80146bcf08fbecb1be56da829b623cc3754	supporting co operative work through ubiquitous awareness filtration mechanisms	qa75 electronic computers computer science computer software			Rameshsharma Ramloll	2000			computing;human–computer interaction;computer science;software engineering;computer engineering	HCI	-53.51680783685116	-34.725133999039436	196113
6a497312cb58cf4f85103659eb8bf2aab5e62eba	the world is not a desktop		"""What is the metaphor for the computer of the future? The intelligent agent? The television (multimedia)? The 3-D graphics world (virtual reality)? The StarTrek ubiquitous voice computer? The GUI desktop, honed and refined? The machine that magically grants our wishes? I think the right answer is """"none of the above"""", because I think all of these concepts share a basic flaw: they make the computer visible."""	desktop computer;flaw hypothesis methodology;graphical user interface;graphics;intelligent agent;television;the machine;virtual reality	Mark Weiser	1994	Interactions	10.1145/174800.174801	virtual desktop	Graphics	-50.0818730460803	-35.77542266925925	196345
d5c6f3506bdb557770b8e97db3a59e52ce4e6144	virtual/mixed/augmented reality laboratory research for the study of augmented human and human-machine systems	virtual reality;human centered design;augmented human;participatory design;augmented reality;mixed reality	In this work we introduce a new research concept called Augmented Human, and consider how it may benefit from prior research efforts. In essence, the paper describes the long research history of a specific Virtual/Mixed/Augmented Reality (VR/MR/AR) laboratory and reflects how it may well be employed as a premise for Augmented Human research and the design of new human-machine systems. The paper briefly describes how constitutive laboratory research has already been employed for some years in more than a hundred company cases, which have exploited participatory design and human-centered design for the human-machine system development. The paper describes further how the latest cases have moved closer to the human boundary level and thus oriented towards Augmented Human research. This fifth generation VR/MR/AR/AH laboratory has taken the form of an open cave-like environment with a motion platform, 3D sound, haptics, VR/AR Head-mounted displays and physical objects.	augmented reality;fifth generation computer;human–machine system;motion simulator;user-centered design	Kaj Helin;Jaakko Karjalainen;Timo Kuula;Nicolas Philippon	2016	2016 12th International Conference on Intelligent Environments (IE)	10.1109/IE.2016.35	computer-mediated reality;simulation;reality–virtuality continuum;human–computer interaction;engineering;mixed reality;multimedia	Robotics	-54.535211820973075	-35.911369047953386	196445
f1579b3a5dab92bbe2d5af1fec3984a24672cbcf	proposing a scientific paper retrieval and recommender framework	scientific paper recommender systems;scientific paper retrieval systems;conference paper	In this paper, we propose a framework that combines aspects of user role modeling and user-interface features with retrieval and recommender systems components. The framework is based on emergent themes identified from participants feedback in a user evaluation study conducted with a prototype assistive system. 119 researchers participated in the study for evaluating the prototype system that provides recommendations for two literature review and one manuscript writing tasks.	actor (uml);computer-supported cooperative work;emergence;foobar;futures studies;joint conference on digital libraries;kaya identity;library (computing);prototype;recommender system;user interface;web service	Aravind Sesagiri Raamkumar;Schubert Foo;Natalie Lee-San Pang	2016		10.1007/978-3-319-49304-6_12	personalization;data mining;computer science;recommender system;information retrieval	Web+IR	-54.63940714482654	-34.086966250853116	196561
a33834b5e2f290a95b04fbe97b41bea07ffbbbfd	a ux-driven design method for building gamification system		Gamification is an efficient design strategy to enhance user experiences. ‘Design’ is based on the actual needs, ‘Game’ creates virtual experiences, ‘Gamification’ is a program that takes the real needs as the goal and the game system as the framework. The program builds a real and virtual mixed product service system. This paper presents a user experience driven three-level design method on gamification system, which corresponds user experiences in three levels of nature, process, and interface. In this paper, some examples are presented to verify the applicability of the design method on gamification system. It is foreseeable that gamification will be an important means of creating the full user experience combined the virtual and real world.	a/ux;digital life;gamification;level design;software design pattern;user experience	Bing Ning	2018		10.1007/978-3-319-91797-9_9	simulation;user experience design;product-service system;service system;design strategy;computer science	HCI	-54.79609207529871	-37.71139638511411	196720
b380fce71e8312caa09f1be7f57c61506c07208e	5 th workshop on software and usability engineering cross-pollination: patterns, usability and user experience	software engineering;crosspollination;user experience;patterns;usability	"""The workshop focuses on how process models, methods and knowledge from the area of Human-Computer Interaction can be integrated and adopted to support and enhance traditional software engineering processes. In its 5 edition this workshop will investigate the application of usability engineering methods that are adapted to fit the evaluation of advanced interfaces and how usability and user experience evaluation methods can be incorporated to support design decisions and changes in standard software development. This workshop is organized by the IFIP working group 13.2 """"Methodologies for User-Centered Systems Design""""."""	human–computer interaction;international federation for information processing;software development;software engineering;systems design;usability engineering;user experience evaluation	Peter Forbrig;Regina Bernhaupt;Marco A. Winckler;Janet Wesson	2011		10.1007/978-3-642-23768-3_131	usability goals;pluralistic walkthrough;web usability;component-based usability testing;cognitive walkthrough;user experience design;interactive systems engineering;usability;human–computer interaction;agile usability engineering;computer science;system usability scale;social software engineering;usability engineering;universal usability;pattern;heuristic evaluation;usability lab;usability inspection	SE	-54.63350910612818	-34.321028217522965	196980
574358a19977b9e4d99b9c63d8d27e1e1894e031	autonomous behaviour in tangible user interfaces as a design factor	autonomous user interfaces;design framework;tangible user interfaces	In this paper I want to express my ideas of using autonomous behaviour in Tangible User Interfaces to create a compelling and new kind of interaction between humans and computers. I motivate this approach by reviewing related research, which indicates that people are fascinated by autonomous tangible objects and apply rules of social behaviours towards these objects. The intention is to gain from this effect to leverage human-computer interaction. The idea is not necessary to improve the user performance or results, but to create a more believable and enjoyable smart object interaction. In this work I try to find key concepts and characteristics which are important while designing and implementing such systems.	autonomous robot;autonomy;computer;human–computer interaction;tangible user interface	Diana Nowacka	2014		10.1145/2540930.2558132	simulation;human–computer interaction;engineering;multimedia;user interface	HCI	-53.90608196217648	-37.62492987315693	197158
3bcd458758c61fd394ee845ed5d609cfe66a7316	factors affecting spacial awareness in non-stereo visual representations of virtual, real and digital image environments			digital image	Dayang Rohaya Awang Rambli	2004				HCI	-52.05749371392943	-32.19901941488221	197408
d58ed2d13d8e477d7e4ea2e7852b749de334d743	a conversational agent for food-ordering dialog based on venusdictate.				Hsien-Chang Wang;Jhing-Fa Wang;Yi-Nan Liu	1997			communication;human–computer interaction;dialog box;computer science;dialog system	NLP	-50.42001591412462	-34.47803741941894	197473
269024db094aa47897a29382de5c49de40d1b1cd	the bridge - a transmedia dialogue between tv, film and gaming				Herlander Elias	2014		10.1007/978-3-319-07668-3_53	simulation;engineering;multimedia;advertising	NLP	-53.74017512924121	-32.73628527531152	199508
2dd97f6f7a078fc07df57a390d1175b931679987	designing, modelling and implementing interactive systems	interactive system	The development of Interactive Systems is an emerging research field that is getting more and more importance due to the increasing level of user interaction that current computer applications demands. In this moment we can consider it as a mature field in which we can find very useful and ground breaking research being conducted in such areas as Web design, user-centered design, usability, ubiquitous computing, virtual reality, to name but a few. The desire to improve and innovate, coupled with the impulse to achieve impossible challenges regarding interaction, makes this area especially attractive. The Ninth International Conference INTERACCIÓN’08 promoted by the Spanish Association on Human–Computer Interaction (AIPO) was organized in conjunction with the Seventh Edition of the International Conference on Computer-Aided Design of User Interfaces (CADUI’08). This joint event held in Albacete, Spain, was a fruitful and stimulating international forum for exchanging ideas and experiences in the area of Human-Computer Interaction. Many researchers, students and practitioners from all over the world attended the conferences. Of all the technical papers presented in both events, 13 papers were selected for publication in this special issue. All the selected papers were submitted and followed a round of reviews to assess their quality in line with the requirements of the journal. This Special Issue covers the design, modeling and implementation of interactive systems, and provides a set of interesting research papers that are focused in the emerging frontier between Software Engineering and Human Computer Interaction fields. The design of mobile interactive systems is the topic covered in two papers. In the paper by Nilsson, design patterns for user interface for mobile applications are described. De Sá et al. present an environment that supports an easy and flexible design of tailored digital artefacts for mobile devices. The use of modeling techniques to design interactive systems is the research field of the next papers. Chavarriaga and Macias present a model-driven approach to building modern semantic-Webbased user interfaces. Iñesta et al. propose a framework and authoring tool for an extension of the UIML language. How to include usability requirements and model driven engineering of Web Information Systems is the research presented by Molina and Toval. The integration of usability evaluation and mod-	design pattern;human computer;human–computer interaction;information system;international conference on computer-aided design;mobile app;mobile device;model-driven architecture;model-driven engineering;requirement;software engineering;systems biology;uiml;ubiquitous computing;usability;user interface;user-centered design;virtual reality;web design	José A. Gallud;María Dolores Lozano	2009	Advances in Engineering Software	10.1016/j.advengsoft.2009.01.015	simulation;computer science	HCI	-54.647806009445475	-34.77767810711481	199514
5ca6272c79cbfd2afef7ab2adccdb150d4ff8a2a	the viscous display: a transient adaptive interface for collective play in public space	interpersonal communication;learning algorithm;mobile device;wireless;real time;underground public art;tangible user interface;adaptive interface;learning system;social network;real time graphics;social networks;mobile communication;public space;transient	The Viscous Display explores the exchange of social information through transient public interfaces. Shaped by principles of 'underground public art', the Viscous Display is conceived as a novel mobile communication medium, where messages can be shared in public spaces. Inspired by biological learning systems; the Viscous Display learns sensorial information that form along traces of a participant's touch and maps this information onto a flexible display. Because it is made up of inexpensive materials, the Viscous Display is also a disposable artifact that may be collected in public spaces. It combines multi-modal sensing, learning algorithms, and a pliable silicone display.	algorithm;flexible display;machine learning;map;modal logic;tracing (software)	Lily Shirvanee;Glorianna Davenport	2004		10.1145/988834.988879	computer vision;real-time computing;simulation;human–computer interaction;computer science;artificial intelligence;operating system;multimedia;social network;interpersonal communication;computer graphics (images)	HCI	-50.54389159962735	-37.384137636081526	199575
