id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
bd89bf02f5140fa62ad0da21d88095c93423ddd1	comparison of cairs and status information storage and retrieval software over a 3 month period	databases;comparative analysis;information systems;information retrieval;computer programs;information storage;foreign countries;public agencies;online systems;search strategies;information storage and retrieval	Following a period of about a year in which “desk” assessments were made of information storage and retrieval packages to narrow the options down, the software packages CAIRS and STATUS were evaluated operationally in the Ministry of Agriculture, Fisheries and Food, during a the period between February and July 1981. The packages, loaded on to separate computers, were used to build up databases and databanks based on existing technical information/library services. As far as possible, direct comparison were made from implementation through to retrievals. A range of types of services from bibliographic (library) through to factual text and numeric data ranging across several Divisions of the Ministry were covered. Input and retrieval was remotely via GPO lines and private wire networks. The paper presents the major conclusions with particular emphasis on the databank component of the trial. INTRODUCTION The Ministry of Agriculture, Fisheries and Food (MAFF) carries out its functions through HQ offices, Regional, Divisional and Area offices, major laboratories, small specialist units and experimental farm and horticultural stations. There are about 13,000 staff altogether of whom about 45% are specialists and about 75% are out of London. Until recently computing has almost exclusively been centred at one office where two ICL 1904s machines have only lately become geared up to take on-line interactive working from remote offices. There has also been use of bureaux and with the increasing availability of cheap mini and micro-computers more and more local computing has been carried out. On the bibliographic side, in addition, quite extensive use of bureaux like Lockheed, now Dialog, has been made for on-line literature searches. In 1979 a preliminary study of the likely computing needs for MAFF over the next 15 years was carried out, prior to a full study commencing at the end of 1979. One of the outcomes was the formation of a Working Party to be specially concerned with information storage and retrieval (ISR) computing, as against for example statistical analysis, modelling, payment of grants, and working up results from laboratory equipment. Representing all the specialist areas of MAFF the Working Party quickly persuaded the Computer Review Team that software packages existed to meet potential ISR requirements and following paper/desk studies it was agreed that two packages should be tested. One was CAIRS, produced and marketed by the Leatherhead Food RA, and the other STATUS, originating from AERE, Harwell but now franchised by several computer hardware suppliers. For the record it shoud be noted that CAIRS also is now available to run on a wide range of computers. ICL Dataskil provided the STATUS software for the trial. Unlike some situations, procurement of software and hardware in Civil Service establishments and particularly in Central Government Departments has to follow carefully stipulated lines so that it was not possible for the Working Party to state at that stage that it wanted “package Y” and, funds being available, go and buy it. Sceptics have argued that with the time and resources spent specifying, justifying and testing, one could have written off an experimental capital expense and have had several years tPaper presented to the 8th Cranfield Conference on Mechanised Information Transfer 21-24 July 1981	computer data storage;computer hardware;database;group policy;icl;information systems research;level of measurement;library (computing);microcomputer;online and offline;procurement;requirement;traffic collision avoidance system;dialog	P. O'N. Hoey	1982	Inf. Process. Manage.	10.1016/0306-4573(82)90035-8	qualitative comparative analysis;relevance;computer science;data mining;database;information retrieval;information system;search engine;human–computer information retrieval	Web+IR	-69.18899924591483	-23.564407493027048	159204
9e8c5dc95c84c47173c66e4deae2e853b5b46a4a	legal theory, sources of law and the semantic web	universiteitsbibliotheek;semantic web	Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: http://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.		Alexander Boer	2009		10.3233/978-1-60750-003-2-i	web modeling;semantic web rule language;web standards;computer science;knowledge management;data science;semantic web;social semantic web;data mining;owl-s	Web+IR	-66.38088977255842	-18.47194162043282	159643
d24c217cd9d340f4e91bedd83d5d88e4a131c945	digitally reconstructing the great parchment book: 3d recovery of fire-damaged historical documents		The Great Parchment Book of the Honourable the Irish Society is a major surviving historical record of the estates of the county of Londonderry (in modern day Northern Ireland). It contains key data about landholding and population in the Irish province of Ulster and the city of Londonderry and its environs in the mid-17th century, at a time of social, religious, and political upheaval. Compiled in 1639, it was severely damaged in a fire in 1786, and due to the fragile state of the parchment, its contents have been mostly inaccessible since. We describe here a long-term, interdisciplinary, international partnership involving conservators, archivists, computer scientists, and digital humanists that developed a low-cost pipeline for conserving, digitizing, 3D-reconstructing, and virtually flattening the fire-damaged, buckled parchment, enabling new readings and understanding of the text to be created. For the first time, this article presents a complete overview of the project, detailing the conservation, digital acquisition, and digital reconstruction methods used, resulting in a new transcription and digital edition of the text in time for the 400th anniversary celebrations of the building of Londonderry’s city walls in 2013. We concentrate on the digital reconstruction pipeline that will be of interest to custodians of similarly fire-damaged historical parchment, whilst highlighting how working together on this project has produced an online resource that has focussed community reflection upon an important, but previously inaccessible, historical text.	historical document	Kazim Pal;Nicola Avery;Pete Boston;Alberto Campagnolo;Caroline De Stefani;Helen Matheson-Pollock;Daniele Panozzo;Matthew Payne;Christian Schüller;Chris Sanderson;Chris Scott;Philippa Smith;Rachael Smither;Olga Sorkine-Hornung;Ann Stewart;Emma Stewart;Patricia Stewart;Melissa Terras;Bernadette Walsh	2017	DSH	10.1093/llc/fqw057	visual arts;engineering;archaeology;cartography	ML	-67.80481639049401	-20.245913259646528	159932
3b3c125cbc1a18e026f27fccc11af7d9bf7def68	the notarial archives, valletta: starting from zero		The main objective of this paper is to talk about my work as a book and paper conservator in the light of the current rehabilitation project at the Notarial Archives in St Christopher Street, Valletta. With its six centuries of manuscript material spread over two kilometres of shelving, the state of preservation of the archives has presented numerous challenges over the last years. The EU funds granted in recent months are a crucial investment that will ensure the safeguarding of the collection, but putting one's house in order is not just about money. A number of other considerations such as careful planning, multidisciplinary collaboration, clever marketing, accessibility, team-building and creating a clear vision for the future have been some of the central factors that continue to contribute to the success of this project. A discussion on the general preservation and conservation strategies that are being undertaken for the project will also be given.	archive;kde accessibility project;money	Theresa Zammit Lupi	2017		10.1145/3103010.3103025	multidisciplinary collaboration;public relations;world wide web;safeguarding;computer science;database	NLP	-67.57460955209484	-19.226951568853202	161076
afc8c1f5ff99c58684cb72918b44d39cc391c75c	sigart on aaai's founding: the chairman's message, 1980		As you probably know, the American Association for Artificial Intelligence (AAAI) is being formed. The field of AI is mature enough that a national scientific organization is needed. Much of the immediate motivation for forming AAAI came from a growing sentiment within the U.S. AI community for a regularly-scheduled national conference. Could not SIGART function as this national AI organization? Under the current structure, SIGs are set up as arms of ACM and as such must obtain ACM approval for most significant actions, including budgets, new publications, sponsorship of conference, and interactions with non-ACM organizations. This structure may be appropriate for a “special interest group” (although we would argue that more autonomy would be beneficial to the SIGs and to ACM), but not for a national scientific organization, which needs far more independence. So a new society is born, and adds to the list of organizations directly relevant to main-line AI in the U.S.: SIGART, the International Joint Conferences on AI (IJCAI), and Artificial Intelligence (the AI Journal). Each has somewhat different emphasis and constituency: AAAI an in25th Anniversary Issue	coat of arms;interaction;international joint conference on artificial intelligence	Lee D. Erman	2005	AI Magazine	10.1609/aimag.v26i4.1836	library science;special interest group;artificial intelligence;publishing;operations research;computer science	AI	-64.587114066708	-19.00211690330942	161393
4bf3e1cf2cfccb87aaa6914ad119cbdd4d01605b	toward an electronic copyright management system	automation;publishing industry;computer networks;management system	Work is going forward at CNRI, in conjunction with ARPA and the Library of Congress, on the design and implementation of an Electronic Copyright Management System (EMCS) to demonstrate the licensing of rights and permissions, payment of any royalties, and the electronic deposit, registration, and recordation of copyright works and related documents in a computer network environment. A variety of economic, social, and legal issues need to be addressed by both rightsholders and users in the course of this project. Cooperation among the copyright, computer, and communications industries concerned, taking into account the balance between protection for copyright works and the needs of the public for access to information, is essential if such a capability is to become a valuable maketplace tool	management system	John R. Garrett;Patrice A. Lyons	1993	JASIS	10.1002/(SICI)1097-4571(199309)44:8%3C468::AID-ASI5%3E3.0.CO;2-W	library science;digital library;project;telecommunications;computer science;requirement;automation;management system;management;operations research;computer security;systems design	DB	-68.14769487415967	-17.541768155570526	162467
2a40a215c878ac25275d65f5224742ee61fa72ed	stanford encyclopedia of philosophy: a dynamic reference work	engineering;linear algebra;front end;computational problems;computational servers;project management;collaborative work;history;stanford encyclopedia of philosophy;dynamic reference work creation;financial management;information retrieval;encyclopaedias;interactive interfaces;back end processing system;web interface;dynamic reference work management stanford encyclopedia of philosophy academic reader general reader online publishing project web interface back end processing system front end feature dynamic reference work creation;information visualization;computational science;online front ends encyclopaedias humanities electronic publishing internet information retrieval;encyclopedias permission electronic publishing web server dynamic scheduling financial management project management navigation collaborative work history;online front ends;navigation;numerical analysis;internet;notification system;humanities;permission;front end feature;numerical methods;digitization;tagging early modern texts;online publishing project;mathematical software;electronic publishing;web server;solvers;general reader;collaborative writing;encyclopedias;software reuse;dynamic reference work management;academic reader;learning environments;history of science;dynamic scheduling	The primary goal of the Stanford Encyclopedia of Philosophy project $< $http://plato.stanford.edu/$>$ is to produce an authoritative and comprehensive reference work devoted to the academic discipline of philosophy that will be kept up to date ally so as to remain useful to those in academia and the general public. To accomplish this goal we have designed and implemented web-based software by which academic philosophers can collaboratively write and maintain such a `dynamic reference work'. Our implementation has features that are not found in any other online reference work in any discipline, and that enable the profession of philosophy to maintain such a reference work without the cost or level of staff support required for traditional reference work publishing.	http 404;reference work;web application	Edward N. Zalta;Colin Allen;Uri Nodelman	2001		10.1145/379437.379789	project management;information visualization;numerical analysis;computer science;linear algebra;electronic publishing;world wide web	HCI	-63.96852019688937	-17.26430907990042	162777
28ad2661a385888451be759f796dba20d22b16ea	collaboration through open superposition: a theory of the open source way	information systems development;socio technical system;collaboration;administracion de empresas;materiality;economia y empresa;grupo a;coordination;open source	Code Explanation and Example Management Codes Management Work done to organize other work. This includes planning, setting deadlines or announcing “phases” like code/string freezes, assigning or rejecting tasks. This includes re-structuring the infrastructure and declaring bugs fixed, or patches applied (closing trackers). Assigning credit Thanking people, adjusting the credits file, etc. Review Codes Validation Validating a coding technique, fix, or approach (before or while it is being done). Review Work done to review other work, including checking in code written by others. This includes work that rejects patches, etc. Production Codes Core production Work that directly contributes to the project’s outcomes, either through working application code or through production of user interface elements (logos, etc.); e.g., implementing a feature (not necessarily a check in, since could be checked in on behalf of someone else). Polishing Smaller changes that polish core production contributions; e.g., typos, integrations, etc. Documentation Codes Documentation Work that documents the code, application or activities. Includes pointers across venues (e.g., in a bug tracker saying that a patch has been submitted). Self-Planning Work that documents one’s own future activities (planning others’ work is management work). Supporting Codes Use information provision Providing or seeking information about using the software; e.g., use cases, often RFEs and bug reports. Code information provision Providing or seeking suggestions about the code, including how to complete work (code examples or pseudo-code, if it compiles or is a patch against SVN then code production work). This includes a developer seeking more information from a peripheral member. Testing Testing application functionality. This includes requesting more information from users in bug reports.	bug tracking system;closing (morphology);code;data validation;documentation;patch (computing);peripheral;pointer (computer programming);pseudocode;software bug;user interface	James Howison;Kevin Crowston	2014	MIS Quarterly		psychology;social science;simulation;economics;materiality;engineering;electrical engineering;artificial intelligence;marketing;operations management;management;social psychology;world wide web;engineering drawing;collaboration	SE	-67.80415723163378	-17.29811089627985	163350
6579344322475ee5ef0fd00b0066051cb43974e4	developing computational biology	periodicals as topic;information dissemination;computational biology	S cientific research is an international endeavor, and computational biology is no exception. Last year we were fortunate enough to attend conferences and visit laboratories in a number of different countries and developing economies. Some of those countries had wellestablished programs in computational biology, while others had fledgling efforts in place and big plans. Because of its cost structure, computational biology is a particularly promising field for emerging economies. Each country we visited had unique features in areas such as the education programs they offered, the types of research being undertaken, and the ways that research is funded. Each nation also has unique challenges, and many nations are developing so quickly that people who leave them for study abroad may find programs entirely different when they return. Given these differences and rapid developments, we feel that there is much we can learn from each other. To this end we have begun a series of Perspective articles from computational biologists in a variety of countries, each of whom offers their personal perspectives on the history, current status, and future of computational biology in their region. We asked the authors to describe the specific challenges they have faced, their perceived strengths, as well as to discuss the institutions (government and private), opportunities, and difficulties of computational biology in their country as a whole. This month we begin the series with a Perspective on the development of computational and genomic biology in Mexico from two of the leaders in the field. Dr. Rafael Palacios de la Lama is a foreign member of the US National Academy of Sciences and one of the world’s experts on the genetics of Rhizobium and genome dynamics. Dr. Julio Collado-Vides is currently a professor and the Director of the Center for Genomic Sciences at the Universidad Nacional Autonoma de México, a leader in understanding regulation of the complete Escherichia coli genome. In their article, we learn about the pioneering effort of a Mexican research group participating in the E. coli genome project. E. coli was the first among still few bacterial genomes with quality predictions of operons and upstream regulatory elements. Various other ambitious projects are under way in Mexico, such as determining the DNA sequence of the genome of Phaseolus vulgaris. To these ends, the authors educate an elite set of undergraduates in genomic sciences. Beyond Mexico, in the coming months we will be touring a number of countries where computational biology is expanding. The Intelligent Systems in Molecular Biology (ISMB) conference brought close to a thousand computational biologists to Fortaleza, Brazil, in the summer of 2006. Memories of that experience will revive as we read about the character and nature of research efforts that are being undertaken in Brazil. We will learn also about the unique challenges of doing computational biology in Cuba, a country impacted by the US embargo, yet with a determined education system and a strong research emphasis. The passion of Cuban scientists is an inspiration, and their soup-to-nuts approach to research represents an interesting solution to their situation. We can also expect perspectives from South Africa, Thailand, Argentina, and China, shedding light on current approaches in these countries to a young, rapidly evolving, and changing discipline. We hope reading these accounts will inspire you to comment, or to write a Perspective on computational biology in your part of the world. If you are interested, please e-mail us at ploscompbiol@plos.org, and we will be happy to send you guidelines for a submission. The pursuit of scientific endeavors around the world allows individuals and nations to capitalize on their potential. It furthers progress and mutual understanding where political and other means have reached their limits. We hope you will learn from the differing approaches and enjoy reading these viewpoints as much as we did. &	academy;comment (computer programming);computation (action);computational biology;conferences;email;genome;genome, bacterial;google summer of code;impacted tooth;intelligent systems for molecular biology;laboratory;linear algebra;nut device component;operon;published comment;regulatory submission;science;thermoactinomyces vulgaris ab:acnc:pt:ser:qn	Philip E. Bourne;Steven E. Brenner	2007	PLoS Computational Biology	10.1371/journal.pcbi.0030157	biology;computer science;bioinformatics;operations research	Comp.	-65.7736035129764	-20.309503805831866	163510
b6d972b57d0480b88f6a5214a9d30ee234a7b4ce	de in slovenia: where are we?	distance education;university education;information and communication technology;information society	Expansion of distance education (DE) is one of the characteristics of the information society by which we can judge the level of development in a society. As we witnessed many changes in Slovenia in the last ten years we were interested in what is happening in DE as a modern way of education.DE in Slovenia is still developing, so the institutions that offer it are rather rare. An exception is the Faculty of Economics in Ljubljana. Generally, the realisation of DE is vaguely supported by Information and Communication Technology (ICT) in Slovenia. The influence of ICT is more likely to be seen in the variety of pre-university educational offerings, where a number of Web sites can be found.		Viktorija Sulcic;Dusan Lesjak	2001			distance education;information and communications technology;computer science;media studies	DB	-68.0050568658878	-22.34717015784293	163635
d52cf5b0a5bbaef6baca7c22e721297431e62f3f	sdc experiences wtih large data bases	large data	SDC operates a large-data-base system that permits users all over the United States and in several foreign countries to search very large bibliographic files interactively, by means of a terminal and telephone connection. Developing extensive use of such systems requires not only technical considerations--such as proper selection and handling of data base elements--but also a massive educational effort, to help provide the large user community necessary to share the sizable costs of data base acquisition, file development, and storage. The growing acceptance of on-line retrieval services attests to the success of that effort, as well as to their inherent cost-effectiveness.	base;computer terminal;cost effectiveness;databases;experience;handling (psychology);interactivity;license;online and offline;published database;smart data compression;virtual community	Carlos A. Cuadra	1975	Journal of chemical information and computer sciences	10.1021/ci60001a014	chemistry;computer science	DB	-69.92307634392344	-23.16604309453366	163725
c5c4c37dd705639d6fd6e905368df2da2b16cedc	editorial: entry points for computing education research	computing education research;methodology	The goal of this editorial is to to provide entry points into the literature on making and warranting claims in the social and behavioral sciences that might be of use to computing educators. In addition, we provide some heuristic advice on getting started and continuing along this direction based on our experience as computing education researchers.	entry point;heuristic	Josh D. Tenenberg;Robert McCartney	2011	TOCE	10.1145/1921607.1921608	simulation;computer science;knowledge management;management science	HCI	-67.519750459956	-22.694705568013692	164667
610873c0dac810da8ffa59348cfbd29a8f792ff7	president's farewell message [president's message]	farewell message;outstanding volunteer	For the past two years, itu0027s been my privilege and honor to be your societyu0027s president. The honor has been made all the greater because we are a society of volunteers, each giving of our time and knowledge to others in the hopes that collectively we can make things better. None of us is here because we have to be here; weu0027re here because we want to be here. And itu0027s my belief that we have the most outstanding volunteers in any society that Iu0027ve ever known.		David B. Fogel	2009	IEEE Comp. Int. Mag.	10.1109/MCI.2009.934566	computer science;management;artificial intelligence;honor	Visualization	-63.39930337156143	-20.67720716447636	164921
02d765a931da0f2e54db476a8ff776dc4d3b724e	information literacy and information management: a 21st century paradigm partnership	information literacy;information management	In the last five or six years a ‘‘new’’ information resources paradigm has been emerging on the world stage with increasing attention. It is called ‘‘information literacy’’ and I believe the concept can be fairly credited to the library and educational communities, rather than the ICT communities. Certainly, Google has precipitated widespread interest in this new paradigm’s potential. As the saying that has by now become a cliché’ goes: ‘‘what good does it do you to retrieve 1 million hits from an online Internet search?’’ In a very real sense, you are worse off than you were before, because now you realize that there is an enormous amount of information ‘‘out there’’ but you have not learned how to search efficiently enough so that you retrieve only the information you need, and not one citation more. But this is far more than a search and retrieval challenge. It is, in my view, at bottom an information management challenge. Google searches are posing stark realities for everyone that are very closely related to the core notions behind the information management idea. For example:	information literacy;information management;library (computing);out there;programming paradigm	Forest Woody Horton	2006	Int J. Information Management	10.1016/j.ijinfomgt.2006.03.009	computer science;knowledge management;information literacy;personal information management;management science;information management;information system	Web+IR	-69.1185280912262	-22.761565548125404	165534
a51fec25a6d6b259beb50ba08639c71cd01412a8	machine-readable views		"""Society of American Archivists Ever,.., annual m~ting of the Society of American Archivists has Its ups and downs for those interested in the archival administration of machlne-re.adable records. The Atlanta conference was no exception. Interest in automated records has apparently moved into the mainstream. This was clear when chairs and repr~,entatives from various committees and task forces ~licited the involvement of the newly restructured Committee on Automated Recor~ & Techniques (CART) in projects of common concern. Conversely, when approached by CART, other groups ~nerousiv allowed time on already crowded agend~ to hear CART proposals and Initiatives of mutual Interest. ~e';e:'~! wo;'kshops and formal sessions were exclusively devote~ to automated records. Each was well attended. Audiences frequently included leaders of the Society current and former officers, council members, and chairs of a variety of task forc~, sections and commlttes. Additionally, se,,eral presentations in more traditional sessions alluded to the impact which today's electronic record keeping practices wil l have on the archives of tomorrow. For me, the otherwise solid conference, had t,vo disappointments. The first came on a proposal to the College and University ,.Section. Building on earlier successful work with the American Association of C~)lleg. late Reglstrars and Adm issions Officers, CART proposed to Identify call .ego and university or~nlzations and associat]ons whose members create and maintain records and to work with them to develop guldelines for pr~ervmg archival ,±~umentation, especially in machine-readable form. When CART outlined its proposal to the C:&U ,.Section meeting, the group responded with indifference. The socOlld disappointment came in a session on """"Documenting the AIDS Crisis"""". AIDS ma,/ be the first epidemic foueht with the computer. To Oocumen[ AIDS ann tne struggle against ~t must, therefore, involve the lona-term preservatmn of some m~mne-reaoable ret"""".ords. And some of the records must come from the Centers for Disease Control ; CDe~ prince candidate is CDC:'s AIDS Database containing m lcrolevel data from the Case Report Form. Yet the representative from CDC mace no reference to the archival retention of this or any other non-,xjgregated master file or database. When questioned, the CDC representative acknowl .edged that no such plan5 existed. This not only violates legal requirements but also abr .agates social responsibility: ,Seemingly, CDC erroneou-~ly belmve that pubhshing tabular data m the Weekly Morbidity ond Mortality f~eports /ulfi l is its ieg.ai and sociai obiigatmns. For all our ~kes, lets hope that CDC is managing the battle against the epldemlc more effectively than it ~s managing its informat]on resources."""	archive;database;decision tree learning;human-readable medium;interaction technique;prince;rom cartridge;requirement;software documentation;table (information)	Thomas E. Brown	1988	Archives and Museum Informatics	10.1007/BF02888568		DB	-64.8332401868419	-19.073433719146184	165757
fd3510dadc2c1de7075f7ec06eb7bd38e711f2b9	risks to the public		Edited by PGN (Risks Forum Moderator, Chair of the ACM Committee on Computers and Public Policy), with contributions by others as indicated. Opinions are individual rather than organizational, with usual disclaimers implied. We address problems relating to software, hardware, people, and other circumstances relevant to computer systems. References (R i j) to the online Risks Forum denote RISKS vol i number j. Cited RISKS items generally identify contributors and sources, together with URLs. Official RISKS archives are available at www.risks.org, with nice html formatting and a search engine courtesy of Lindsay Marshall at Newcastle; http://catless.ncl.ac.uk/Risks/i.j.html; also at ftp://www.sri.com/risks .	archive;computer hardware;google moderator;html;web search engine	Peter G. Neumann	2016	ACM SIGSOFT Software Engineering Notes	10.1145/2967307.2967310		Web+IR	-65.87128663722044	-17.831827360537538	165930
ada327639f3e6a879d00461b029917196a96f295	wide open spaces	open space;broadband network;spectrum;rural area	AUSTRALIA is known as a country with plenty of space,and comparatively few people to populate it.When you think about the fact that there are six cities in China with a greater population than the whole of the 3.5 million-square-km area of the Great Southern Land,perspectives may change.It is one of the backdrops to the formation of the Australian character.Many cannot just go around the corner fortheir weekly groceries.Sometimes it may even be delivered by airplane.In some regions,it might be a few hours’drive to a neighbor’s place.		Neil Savage	2010	Commun. ACM	10.1145/1839676.1839704	spectrum;telecommunications;rural area;computer network;broadband networks	Networks	-68.38304031657098	-21.536956751324656	166013
22a3b552a32b49ed8e494575771b08cd747931d3	one year later: a large system conversion	first year experience	During the period that we were going through the acquisition process—talking to vendors and to management and users at other installations—conversion was, of course, in the back of our minds. The staff at other installations was unanimous: conversion should be avoided at all costs; your users will be totally dissatisfied; it cannot be done successfully; your career will come to a screeching halt; don't do it! This, from people who might have contemplated a change of vendors but who had never actually undertaken a conversion. With the exception of the IBM salesmen, the vendors were, understandably, very low-key about how a major change in machines might be handled. They did, of course, promise the complete support of their corporations. But on the whole, they chose to ignore this topic.  Well, it is one year later—our users are not totally dissatisfied; I think we are doing it reasonably successfully; our careers have not come to a screeching halt—and, in fact, we would happily undertake a major conversion project again. Our first year experiences have not been bad; they've been good. Here is our story:	halting problem;lambda calculus;mind	Suzanne Greenberg;Edward M. Krol	1977		10.1145/800101.803284	simulation;engineering;operations management;management	Web+IR	-63.80951468703803	-23.27520989452227	166639
0feea4cf89c75fa03a4a4a1c1246f296ebf923ab	computer augmented research and scientific misconduct	scientific community;scientific research;scientific ethics;computer augmented research;scientific misconduct;science education;fraud;falsi- fication;plagiarism;internet;degree mills;spectrum	Internet and CD-ROMs are now important sources of scientific research. Obviously, these computerized tools complement and supplement libraries. For some they seem to replace libraries, and web presentations of published works are used as seemingly infinite resource of texts for term papers, examination work and even research papers. There is evidence that the use of modern information technology, especially the Internet and CD-ROMs, boosts questionable or even illegal forms of scientific publication. The spectrum of scientific misconduct is broadened by their easily accessible repertoire of research material up to the spread of falsified degrees. This process could be and should be countered by (self-)regulations, technical means, and, most important, education in order keep science as a public process alive.	cd-rom;internet;library (computing);scientific literature	Wolfgang Coy	2002			engineering ethics;research ethics;applied mathematics;political science;engineering physics	HPC	-68.6250381716777	-20.507348734300095	166875
11ece6a248aba06fc636e3caf4dea9dfb0a2c475	electronic scholarly monographs: issues and challenges for the uk		The literature on electronic publishing reveals that scant attention has been paid to the area of scholarly monographs. This paper reports on a recent and rare investigation into the nature and provision of electronic scholarly monographs and textbooks in the UK. Publishing structures are delineated; the physical characteristics of electronic scholarly monographs are reviewed; and issues associated with their nature and content are discussed. Problems of bibliographical control and of quality are also explored. Learned Publishing (2000)13, 15–24	armstrong's axioms;email;fax;library (computing);library science;orchard;sy telecom;user agent	Richard Lonsdale;C. J. Armstrong	2000	Learned Publishing	10.1087/09531510050145515	media studies;computer science	HCI	-68.86737383178031	-17.647350914393936	167120
9d8fd8c150f251b56230293231f6ce8486329cc4	a societal sentiment analysis: predicting the values and ethics of individuals by analysing social media content.		Figure 3: ''Unity in Diversity'': City-Wise Indian Values: An analysis on Twitter data of 20 most populous cities of India. ❖Achievement (AC): The value here comes from setting goals and then achieving them. ❖Benevolence (BE): Those who tend towards being benevolent are very philanthropic, they seek to help others and provide general welfare. ❖Conformity (CO): This category of people obey clear rules and structures. ❖Hedonism (HE): Hedonists are those who simply enjoy themselves. ❖Power (PO): The ability to control others is important to people who possess this value and power will be actively sought by dominating others and control over resources. ❖Security (SE): Those who seek security value, health and safety to a greater extent than other people (perhaps because of childhood woes). ❖Self-direction (SD): Individuals who are selfdirected, enjoy being independent and are outside the control of others. ❖Stimulation (ST): Is closely related to hedonism, nevertheless the goals are slightly different. In this case, pleasure is acquired specifically from excitement and thrill. ❖Tradition (TR): A traditionalist respects practices of the past, doing things blindly because they are customary. ❖Universalism (UN): Individuals who seek social justice and tolerance for all.	conformity;populous;project safe childhood;sentiment analysis;social media;un-go episode:0 inga chapter;unity	Amitava Das;Björn Gambäck;Tushar Maheshwari;Aishwarya N. Reganti;Samiksha Gupta;Anupam Jamatia;Upendra Kumar	2017		10.18653/v1/e17-1069	sentiment analysis;natural language processing;artificial intelligence;computer science;social media	HCI	-64.18860519011541	-20.897963132295256	167506
d06f4b91f7dfc6a27ada392c74064e8949ec335c	listening to the quiet voices: unlocking the heart of engineering grand challenges	listening	According to the National Academy of Engineering, the list for the Grand Challenges for Engineering are: (1) Make solar energy economical; (2) Provide energy from fusion; (3) Develop carbon sequestration methods; (4) Manage the nitrogen cycle; (5) Provide access to clean water; (6) Restore and improve urban infrastructure; (7) Advance health informatics; (8) Engineer better medicines; (9) Reverseengineer the brain; (10) Prevent nuclear terror; (11) Secure cyberspace; (12) Enhance virtual reality; (13) Advance personalized learning; and (14) Engineer the tools of scientific discovery. Surely, it may be difficult to find many who would find any reason to disagree with the identification of any of these topics for both the present and future engineers. Rather than object to what is included, I would like to raise the issue of what has been neglected in this list and far too often in engineering—listening to the quiet voices that speak from within each of us from our heart. I am suggesting the act of listening as one additional entry for this most important list.	academy;cyberspace;emoticon;grand challenges;informatics;personalization;virtual reality	George D. Catalano	2012	IJESJP		appreciative listening;simulation;engineering;artificial intelligence;informational listening;communication	HCI	-68.50812993293185	-19.730164321034934	167515
afef8d901a212c0ebb8fd0d9b60c8e5ece9d9123	from the editor's desk		We have had an exciting few months with the Journal of Digital Imaging. I am so pleased to report that we are in a growth phase with the Journal of Digital Imaging (JDI). We have grown to larger, more frequent issues with very high-quality content. In an attempt to move articles from online—first to the print issues, we have been publishing larger issues, and by the beginning of 2012, we will have and will attempt to continue to have only a two to three issue backlog which means completed articles will be published in print from 4 to 6 months after online—first. To make JDI more accessible to its readers, the full-text content is now also available in PubMed Central (PMC). PMC is a free full-text archive of biomedical and life sciences journal literature at the US National Institutes of Health's National Library of Medicine (NIH/NLM). JDI articles are made available freely accessible in PMC upon 1 year of issue publication and content is available dating back to volume 16 (2003). The greater availability of JDI content made through PMC provides various benefits and potential advantages. Authors enjoy the benefit of further dissemination of their work, and in turn, the journal receives increased visibility and exposure. The major advantage of expanding the visibility of the journal is the potential gain of article downloads and citations. Since JDI was made available in PMC in March 2011, there has been more than 12,000 full-text article downloads on PMC alone! Please visit JDI in PMC at http://www.ncbi.nlm.nih. gov/pmc/journals/1429/. Issues of JDI published prior to our on-line presence were digitized and are available at SpringerLink for everyone. To get to JDI on SpringerLink, either link through from www.siimweb.org/jdi or go to www.springerlink.com and search for the Journal of Digital Imaging. We received the news that our standard impact factor for 2010 increased to 1.413 from the 2009 standard impact factor of 0.956. We now rank 69 out of 111 in Radiology, Nuclear Medicine, and Medical Imaging Journals in 2010, up from our ranking of 80 out of 104 in Radiology, Nuclear Medicine, and Medical Imaging Journals in 2009. Our 5year impact factor for 2010 increased to 1.427 from the 2009 5-year impact factor of 1.192. We thank all our authors, associate editors, reviewers, and SIIM editorial staff for their support for the Journal of Digital Imaging and look forward to continuing to grow in size and stature.	archive;biological science disciplines;body height;digital imaging;editorial;goto;human height;java platform debugger architecture;journal;large;medical imaging;national library of medicine (u.s.);netware loadable module;online and offline;paramyotonia congenita (disorder);phenylmercuric chloride;pubmed central;radiology;radionuclide imaging;scientific publication;sixty nine;united states national institutes of health;benefit;citation	Janice C. Honeyman-Buck	2011	Journal of Digital Imaging	10.1007/s10278-011-9415-9		Comp.	-67.54941111024657	-20.25151320655674	168988
5414b4ebf0bb4d245e1dbc0e599e61b8e4bd05ac	the availability and persistence of web references in d-lib magazine	digital library;data collection	We explore the availability and persistence of URLs cited in articles published in D-Lib Magazine. We extracted 4387 unique URLs referenced in 453 articles published from July 1995 to August 2004. The availability was checked three times a week for 25 weeks from September 2004 to February 2005. We found that approximately 28% of those URLs failed to resolve initially, and 30% failed to resolve at the last check. A majority of the unresolved URLs were due to 404 (page not found) and 500 (internal server error) errors. The content pointed to by the URLs was relatively stable; only 16% of the content registered more than a 1 KB change during the testing period. We explore possible factors which may cause a URL to fail by examining its age, path depth, top-level domain and file extension. Based on the data collected, we found the half-life of a URL referenced in a D-Lib Magazine article is approximately 10 years. We also found that URLs were more likely to be unavailable if they pointed to resources in the .net, .edu or country-specific top-level domain, used non-standard ports (i.e., not port 80), or pointed to resources with uncommon or deprecated extensions (e.g., .shtml, .ps, .txt).	deprecation;http 404;kilobyte;list of http status codes;persistence (computer science);server (computing);server side includes	Frank McCown;Sheffan Chan;Michael L. Nelson;Johan Bollen	2005	CoRR		digital library;computer science;data mining;internet privacy;world wide web;data collection	Security	-66.20928586583737	-17.832024884000475	169000
e5ef2b3fd03bff748c5bf1b574660a545aa02d9f	implications of technological advances for access to the cultural heritage of selected countries in sub-saharan africa	digital documents;driving force;cultural heritage;information technology;access to information;information and communication technology;sub saharan africa;technological change	Public records and archives constitute a valuable part of sub-Saharan Africa’s (SSA) cultural heritage. However, technological advances threaten long-term access to public records and archives. The computer (and its associated technologies) is the major driving force behind the technological changes affecting access to information. The use of information technologies has led to the proliferation of digital information. There are significant challenges associated with ensuring access to digital materials into the future as compared with traditionally paper-based information. A recent survey of selected countries from SSA revealed that long-term access to records and archives is going to be hampered by lack of resources and plans for ensuring access to information resulting from the use of information and communication technologies (ICTs). The development of strategies for managing digital documents over time is key to accessing the cultural heritage of SSA by the present and future generations. D 2004 Elsevier Inc. All rights reserved. 1. Background and context Public records and archives generated by government functions, activities, procedures, and processes are part and parcel of sub-Saharan Africa’s (SSA) valuable cultural heritage. Technological advances threaten long-term access to public records and archives. The major driving force behind the technological changes affecting the storage and retrieval of 0740-624X/$ – see front matter D 2004 Elsevier Inc. All rights reserved. doi:10.1016/j.giq.2004.01.003 * Fax: +27-33-260-5972. E-mail address: ngulubep@nu.ac.za. P. Ngulube / Government Information Quarterly 21 (2004) 143–155 144 information has been the computer and its associated technologies. Computers are considered as the major solution to the inadequate government information systems in Africa. Thus, long-term accessibility to records is becoming a critical issue because of the increasing use of information and communication technologies (ICTs) in documenting government transactions. The use of information and communication technologies has led to the proliferation of digital information. There are significant challenges associated with ensuring access and preserving digital materials into the future as compared with traditionally paper-based information. The key problem of digital objects with regard to preserving and making them accessible overtime is that electronic resources regardless of whether they are created initially through digitization or are ‘‘born’’ digital are subject to technological obsolescence and physical deterioration, and knowledge of their life expectancy remains relatively undeveloped. It is evident that there is need to devise measures for their preservation if continued access to them is to be guaranteed. In spite of this, plans for preserving digital information and making it accessible for the present and future are inadequate in subSaharan Africa. Without procedures for digital preservation, it is going to be difficult if not impossible to have access to important cultural objects like public records and archives. Public archives and records belong to the public so they must be accessible as evidence for decisions and actions for which governments are accountable to citizens. According to Guercio, The principal role of the record is, in fact, that of rendering the act or fact, which is the subject of the record in its original administrative context, accessible and knowable across time and space. Accessible records and archives facilitate continuity in decision making as well as providing evidence of past activities and historical precedence for future generations. Without records and archives, it would be difficult for people to learn from past successes or failures. The society’s ability to have ready access to essential evidence that documents the rights of citizens, the actions of government officials, and the national experience would be equally limited. Events of 1999 in Kosovo undoubtedly show the importance of documentary materials. Slobodan Milosevic’s invading forces sought to systematically destroy records pertaining to land, financial, citizenship, and genealogical entitlements of the Albanian community. The aim was to destroy the community’s economic and political rights and cultural identity. It takes an event like this to remind humankind of the importance of its cultural heritage. Ultimately, any artefact or document of cultural value is likely to benefit society if it is accessible to both the present and future generations. Access to information is denied if desirable existing information is not available for whatever reason. Technological advances are likely to become one of the causes of inaccessibility of the cultural heritage of subSaharan Africa if strategies of harnessing the potential advantages of information technology (IT) overlook measures to facilitate continued access to information generated during the process. P. Ngulube / Government Information Quarterly 21 (2004) 143–155 145 2. Preserving access to electronic records As a result of technological advances, electronic resources are becoming a significant part of the cultural and intellectual heritage of many countries, and countries in subSaharan Africa are no exception. However, the exploitation of digital technology to . . . produce documents, databases, and publications of all kinds has led to an impending crisis, resulting from the absence of available techniques for ensuring that digital information will remain accessible, readable, and usable in the future. Deposit libraries as well as other libraries, archives, government agencies, and organisations must find ways to ensure the longevity of digital artefacts or risk the loss of vast amounts of information and human heritage. By virtue of being a series of ones and zeros (bits) that are machine-coded means that access to electronic resources largely depends on preserving the key that translates the code. The obsolescence of digital technology can mean loss of access to the information stored with that equipment. Thus, the major concern in the management of electronic resources is as follows: If bits survive, will they be still accessible when hardware and software change? If nothing is done in sub-Saharan Africa to address this major matter, technological advancement characterized by the use of information technology is going to render the life of digital cultural objects, to borrow a phrase from Thomas Hobbes, ‘‘nasty, brutish and short.’’ It is evident that although digital materials are becoming very prevalent in our society, many organizations have not addressed the issues of long-term preservation and use of digital information in a serious fashion. For instance, a survey commissioned by the Research Libraries Group (RLG), a U.S.-based not-for-profit membership corporation of over 160 universities, national libraries, archives, historical societies, and other institutions with remarkable collections for research and learning, investigated the digital preservation needs of member institution revealed a striking lack of . . . policies or even codified practices for preserving ‘‘born-digital’’ and converted-to-digital materials but virtually all those surveyed expect such preservation to be part of their operations by 2001. Generally speaking, the United States only started to seriously address digital preservation in 1999. According to Brindley and Jones, the impetus to preserve digital materials was given by U.S. Taskforce on Digital Archiving seminal report. As result of work of the U. S. Taskforce, the Joint Information Systems Committee (JISC) and the British Library in the UK sponsored the first workshop on digital preservation. Thereafter, the Joint Information Systems Committee and the National Preservation Office commissioned a series of research reports highlighting various aspects of digital preservation. It is evident that governments in developed countries have led initiatives to fund digitization programs to facilitate more efficient and effective utilization of digital technology. Although, the developing world has made significant strides in preserving digital materials, until recently, the emphasis has been on specific institution-based projects rather than on developing a digital preservation agenda at both the national and international level. Even P. Ngulube / Government Information Quarterly 21 (2004) 143–155 146 though digital preservation is still relatively undeveloped, it is encouraging that projects have been initiated to save the digital heritage. Such initiatives are conspicuous by their absence in SSA. In a study carried out in Ghana, Uganda, and Zimbabwe, it was discovered that the countries do not have the capacity to manage electronic records. Mutiti also came to the same conclusion in her study of the technological infrastructure and its utilization in Botswana, Kenya, Lesotho, Malawi, Mozambique, Namibia, South Africa, Swaziland, Tanzania, Zambia, and Zimbabwe. It is evident that most countries in SSA are not seriously addressing the issues related to the preservation of digital records and archives. Some instances have been reported whereby vital cultural information has been lost into obsolete hardware and software. For instance, in Zimbabwe the Salary Service Bureau, a government department that is responsible for processing civil servants’ salaries and pensions, lost all the information created and stored on computer tapes between 1980 and 1994. The problem only surfaced when a newly introduced computer-based information system could not read most of the older computer tapes. Similar cases are likely to be experienced in many countries in SSA as they further embrace information technology because they do not have adequate plans for the preservation of electronic information. In fact, electronic records are being created in many public institutions in SSA, and some are being mismanaged and los	accessibility;archive;case preservation;database;digital data;digital electronics;digital rights management;document;fax;freedom of information laws by country;human-readable medium;information systems;information system;jones calculus;library (computing);scott continuity;software documentation;visual artifact	Patrick Ngulube	2004	Government Information Quarterly	10.1016/j.giq.2004.01.003	technological change;information and communications technology;cultural heritage;environmental resource management;sociology;law;information technology	HCI	-68.73312817748439	-19.75094700465542	169185
381583ec642b6c82e84ee315219cf0343024a31c	common ground: hypermedia, human augmentation, and the web	common ground	"""is a watershed period for computing with the 50th anniversaries for Vannevar Bush's seminal article """" As We May Think, """" computing itself (marked from the construction of the ENIAC), and ACM. It is a time in which the notion of human augmentation which underlay Bush's article is taking on entirely new meanings, and during which the global electronic village is becoming a reality. CHI 96's theme, Common Ground, could be taken as the theme of the entire year—a year in which the research, Internet, and user communities forge a new alliance. Conferences are freeze-frame snapshots of the work of a community at a given point in time. They provide invaluable opportunities for integrating the current state of that work. What is needed in addition is a resource that provides continuity across communities and time, linking together people and ongoing projects as the work develops. A web site can provide that and can be an ongoing resource that, in reflecting the past and present work of a community, influences the future directions that community takes. Brown University is developing such a web site from hypertext conference, workshop, and symposia materials archiving the roots of past work and reflecting current research, people, institutions, and commercial projects. Immediate plans for the contents of the site include: digitized videotapes of the Bush Symposium, a hypertext of symposium transcripts , and dynamic tracking of research and commercial developments, including projects, people, institutions, publications, conferences , and themes. In this note I describe some of the interrelated ideas and the people who are presenting them in a series of conferences, and then close with more details about the Web site plans. by Brown University and MIT honoring the 50th anniversary of the publication of Bush's """" As We May Think """" reported on the legacy of Bush's article over the last 50 years and identified themes that are very much in the forefront of work being done today: human mind/body augmentation; information struc-turing, retrieval, and transmission; and computer supported collaborative work. (See interactions iii.2.) Hypertext '96 March 16 – 20, Washington, DC Information structuring, retrieval, and transmission are traditionally the domain of this annual conference; this year was no exception. What was interesting, however, was how these concerns have broadened to encompass the entire set of computer applications, the Web, and whole user communities. Thus we saw 1) a workshop and several papers on open …"""	archive;as we may think;chi;computer;eniac;forge;hypermedia;hypertext;interaction;internet;microsoft forefront;mind;scott continuity;watershed (image processing);world wide web	Rosemary Michelle Simpson	1996	Interactions	10.1145/234813.234815	human–computer interaction;computer science;engineering;multimedia;world wide web	Web+IR	-63.33102584620158	-18.604822686430257	169893
794c17c5d6c115481f0fd81832ccf63e09d71fdf	how to succeed in graduate school: a guide for students and advisors	graduate student	 This paper attempts to raise some issues thatare important for graduate students to be successfuland to get as much out of the processas possible, and for advisors who wish to helptheir students be successful. The intent is notto provide prescriptive advice -- no formulas forfinishing a thesis or twelve-step programs for becominga better advisor are given -- but to raiseawareness on both sides of the advisor-studentrelationship as to what the expectations are andshould be for this... 		Marie desJardins	2008	ACM Crossroads	10.1145/1375972.1375975	computer science	HCI	-67.48152748977166	-22.905688190054203	170915
c082ed9fd72d792b67c397e907af788892fc3967	is hci homeless?: in search of inter-disciplinary status	inter-disciplinary status;hci homeless	Depending on how you look at it, human-computer interaction has either no home or many homes. We’re multidisciplinary without having become particularly interdisciplinary. The first HCI papers were Human Factors & Ergonomics, which is often located in Industrial Engineering departments. Business and Management schools then initiated relevant Information Systems research. CHI originally comprised mainly Cognitive Psychologists, with an influx from Computer Science some years later. HCI is now on the rise in Information and Design schools and departments. Is this a positive instance of letting a thousand flowers bloom, or a dire Franklinian, “We must all hang together or we shall all hang separately?” If computers become invisible or disappear, the study and practice of human-computer interaction may be everywhere and nowhere. But HCI seems challenging enough to deserve to have a spotlight on it somewhere. To try to understand why different strands of HCI research and practice have not converged, I have been examining the history and interviewing participants in it. Everyone has a unique perspective, choosing what to emphasize and what to skip over. I have collected some perspectives in this article (though they are not comprehensive—add your own!). The measure of a perspective is less whether it is right or wrong than whether or not it is useful: In this case, does it help us understand the field’s state of fragmentation and the possibilities for more effective integration? Three Faces of HCI. I will focus on the three long-standing threads of research shown in Figure 1. Human Factors reaches back to the World Wars and earlier application of “scientific management” to the design of assembly lines and other work processes. Information Systems arose around the needs of business computing that spread in the late 1960s. These fields were active when a computer was so expensive that it had to be kept in continual use, with most hands-on users, in Brian Shackel’s words, “almost slaves to feed it” [1]. Nondiscretionary use also marked the earlier human factors work on assembly lines and military technology (aviation psychologists formed the Human Factors Society after World War II). Efficiency and error reduction in skilled use were emphasized, with some focus on training to develop skill. To demonstrate small but valuable improvements in tasks such as data entry required controlled experiments and rigorous analyses of the sort identified by Don Norman in his column this issue [2]. Mandatory use was the norm through the mid-’70s, but visionary engineers, prototype developers, and writers anticipated a future in which people would use computers not because it was a job requirement but because they wanted to, because it “augmented their intellect” [3] or made jobs more enjoyable. When small mini-computers, home computers, personal computers, and workstations arrived, the visions began to be realized. Discretionary computer use has been a focus of CHI from the beginning. What difference does this make? For example, for understanding people’s reactions to a new discretionary technology, controlled experiments and statistical analysis are less effective, and often less necessary. Mandatory vs. Discretionary Hands-On Use. Figure 2 color codes these research threads to illustrate the distinction around discretion in use. Those interested in details—full names, acronyms and book titles; why items are positioned where they are; and what	brian;chi;code;computer science;dbpedia;discretionary access control;experiment;fragmentation (computing);hands-on computing;hang (computing);human factors and ergonomics;human-based computation;human–computer interaction;industrial engineering;information systems research;information system;intellect;job stream;minicomputer;personal computer;prototype;tag (game);workstation	Jonathan Grudin	2006	Interactions	10.1145/1109069.1109108	multimedia;human–computer interaction;engineering;discipline	HCI	-64.79242411596763	-23.310337088407117	171375
b0c3a7f2c5bbc306749ff949ff0531486769bffc	new directions in legal information processing	lawyers;computers;police;legislation;text;information systems;legal aid;information retrieval;data management;legal problems;data processing equipment;criminal justice;law enforcement;information processing;artificial intelligence;laws;information system;automation	Present areas of application of computers to the law fall into three broad categories: (1) those involving applications of business accounting techniques such as in tax preparation and client billing, (2) those involving data management techniques such as law enforcement, criminal justice, and keyword legal source material information systems, and (3) those involving on-line file manipulation in such areas as text-editing and drafting. These systems demonstrate that computers can work very well with problems that can be expressed in terms of numbers or information that can be handled on the basis of its external form.	computer;electronic billing;information processing;information system;online and offline;technical drawing	Robert T. Chien;P. B. Maggs;Fred A. Stahl	1971		10.1145/1478873.1478944	public relations;political science;data mining;computer security	DB	-68.72270434630563	-17.08616051929368	172216
59dc6e8f4dd61c3d0ec208a82ee08cc8e1b791a7	acm's annual report	annual report	have taken root and we now see tangible evidence of their success. It was a year that solidified ACM’s global reach with established hubs in Europe, India, and China finishing their first year of operation with significant growth in membership, chapters, and conferences. Indeed, ACM membership reached another all-time high for the ninth consecutive year and much of that growth can be traced to the success of ACM’s international initiatives. It was also a year that marked great strides in ACM’s commitment to improving the image and health of the computing discipline. Computer Science Education Week proved a sizeable success in promoting the importance of computer science education to a mass audience. ACM-W launched a presence (and conference) in India encouraging women from the region to explore the limitless opportunities of a career in computer science. ACM’s Educational Policy Committee and Computer Science Teachers Association issued a landmark report on the vital need for the U.S. to create a strong K−12 computer science education program. And the Dot Diva campaign—the NSF-funded grant to ACM and WGBH-Boston to develop a new image for computing—launched a dynamic new Web site advocating computer science as a desirable career path. And it was a year that introduced major enhancements to the “crown jewel” of Association—the ACM Digital Library—that now boasts increased functionality, sophisticated improvements to the citation pages, and new browser capabilities. I am particularly pleased to report that it was a year ACM and the IEEEComputer Society began to explore myriad ways the two organizations might work together to capitalize on the healthy competition that has served our profession well over the decades (see my ACM President’s Letter on page 8). And I look forward this year to further examining new ways for the Association to utilize social networking to add value to the membership community. The following pages summarize some of the highlights of a truly eventful year in the life of ACM. As always, we are indebted to our devoted volunteers, members, and industry partnerships for constantly propelling us to do better.	computer science;crown group;digital library;emoticon;ibm notes	Alain Chesnais	2012	Commun. ACM	10.1145/2063176.2063179	computer science	Theory	-63.68550402290016	-19.026835730436698	172417
b48d3ccccf01b3d8ace3110b8dff12ba652b3f37	maintenance of expert systems: life-cycle validity	life cycle;software systems;molecular data;knowledge base;expert system	"""It is well known in the business computing community that program and data base maintenance are the largest component of the software system life cycle (Boehm, 1981). Little concern has been raised about the maintenance of knowledge bases of expert systems. The majority of interest in maintenance (which might be classified as being validity over the life cycle of the expert system (Mostow. 1985), and in the maintenance of consistency of a data base (Balzer et al. 1983). One commercial selling strategy of expert systems is that they do not change with time like human knowledge. A person who doesn't change with time however, is not necessarily an intelligent person. An expert system without maintenance is """"an old fogey,"""" unable to learn new things. In a preliminary study on now to implement a data base for critical evaluation of atomic and molecular data (Cann and Nicholls, 1980), it was decided to incorporate names of researchers, dates of data added as well as critical notes on methods and recommendations on results. The reasons for this were to be able to compare and update experimental data with time and with new experimental results. But, new results are not always better. Often, older values are obtained through more thorough study then some newer results. There are several different types of errors that can exist in data or knowledge bases."""	database;expert system;information system;knowledge base;software system;system lifecycle	John McCallum	1985	SIGART Newsletter	10.1145/1056313.1056316	biological life cycle;legal expert system;knowledge base;computer science;knowledge management;artificial intelligence;data mining;subject-matter expert;expert system;software system	AI	-66.66854267655934	-23.69034968908401	174221
720c81b486a48049745191d8e4d7cf97b4bf4446	authors and readers: the keys to success of failure for electronic publishing	quality control;cost effectiveness;feedback;computer mediated communication;electronic publishing	ALTHOUGH T ERE ARE MANY POSSIBLE links and ways to join them in the publishing chain for scholarly journal articles, the first and last links are always authors and readers. Unless it satisfies the motivations and goals of both authors and readers, electronic publishing cannot completely succeed. One of the most frequently cited advantages of electronic publishing is the loss of distinction between readers and authors and the shared motivation of both to have more opportunities for collaboration. Unfortunately, many goals of authors and readers are not shared. Authors are primarily motivated by career advancement and long-term contributions to their discipline, readers by keeping up in their field and work-related tasks. Many other factors enter into the process as well-some of which coincide while others conflict. INTRODUCTION The process of electronic publishing on commercial online systems traditionally involves many interrelated, but mostly separate, parts. These parts may be depicted as steps leading to a completed search request or, more commonly, as links that together form an information generation and use chain. Each component is dependent on the others, and together the whole leads to something greater than the parts. Like a value chain within a company’s operations, an information generation/use chain forms a system of interdependent activities, Carol Tenopir, School of Information Sciences, 804 Volunteer Blvd. University of Tennessee, Knoxville, T N 37996 LIBRARY TRENDS, Vol. 43, No. 4, Spring 1995, pp. 571-91	coexist (image);download;email;feedback;human height;interdependence;tron	Carol Tenopir	1995	Library Trends			HCI	-67.94510430487085	-18.111263049243096	175360
47f803c5dcc0311228a2f3fb5091235abd50fe38	the people process in text processing teaching text processing in a university environment	front end;text processing;self esteem;training program	The “Office of the 80's” is front-page copy today. Terms such as “automated office” and “office of the future” receive an amazing amount of attention from the media. These are new concepts we live with in a business environment, and many universities are either investigating how they can best get a piece of the action, or are in the process of implementing new systems that will “revolutionize” how their administrative and departmental offices do business. Departments are witnessing the installation of their first word processor, greeting its arrival with a mixture of wonder and, quite often, overblown expectations. The sales person said it was easy to use, quoted figures about enormous productivity increases, and about coming of age in computing. Promises, promises, but what is the reality of the situation for office personnel of the front end of such innovation?  How we introduce text processing and how we train people determines the success or failure of the transformation from typewritten to future office. We must identify and respond to the particular needs of this relatively new user community. As Richard Wiersba noted, “Technology should magnify human capabilities, not replace them.”(1)  Training programs must be developed with a clear understanding of the requirements of office personnel, as well as an understanding of the goals of the organization. Management support for training projects must be assured, with management aware of the specific conditions needed for success.  Instructor attitudes must convey respect for the present skills of the employee. This is an essential element and one that is often overlooked in our enthusiasm for the new and “advanced” approach. If you respect what people bring to the learning situation, you free them to tackle the new challenge. Improved self-esteem and improved productivity go hand in hand.	office of the future;requirement;virtual community;wonder	Madge Grant Brochet	1981		10.1145/800079.802566	simulation;engineering;operations management;multimedia	DB	-65.31831885573799	-23.437746384365404	177078
586da69ce1bcd1ff9f1c51713172fdd5d370da0e	supplement to a “bibliography of bibliometrics and citation indexing & analysis” (trita-lib-2013)	indexation	"""The references listed below constitute a supplement and an update of """"A Bibliography of Bibliometrics and Citation Indexing & Analysis"""", which was published in December 1980 in the report series """"Stockholm Papers in Library and Information Science"""", with the report number TRITA-LIB-2013. That bibliography, and its companion report """"An Outline of Bibliometrics and Citation Analysis"""" (TRITA-LIB-6014) can be obtained either from the address above or directly from the publisher, Royal Institute of Technology Library, S-100 44 Stockholm, Sweden. The bibliography (TRITA-LIB-2013) listed 2032 items on citations, citation analysis, citation indexes and bibliometrics. Studies of library use and of the coverage of abstracting and indexing journals and services were excluded as a rule, but included if bibliometric techniques and distributions had been applied or citation analysis used as a tool or instrument. The same delimitations hold for the present supplement, which covers the period from May 1978 to December 1980. The bibliography, which stopped at December 1979, had an incomplete coverage of the period from May 1978. Some older material, part of which was kindly brought to attention by the users of the bibliography has also been included. All notices of failures of ommission or errors of commission will be greatly appreciated. Those with a deep or continuing interest in bibliometrics and citation analysis will be pleased to learn that Alan Pritchard, in collaboration with Glenn Wittig, has at last published a first part of his bibliography. (""""Bibliometrics. A Bibliography and an Index, Volume I: 1874-1959"""" . Can be obtained from ALLM Books, 4 Knutsford Avenue, Watford, Herts WD2 4EL, England, at a price of s ($12.00)). Alan Pritchard is also distributing a newsletter """"Bibliometrics Bulletin"""" of which 3 issues have appeared. The scope of Pritehard's bibliography is wider than the present one, and no cross-checking between them has been done so far, but discussions are being held on the possibilities of pooling efforts and establishing a bibliographic database, especially as both of them exist in machine-readable form. The temptation to apply various bibliometric techniques to the present bibliography and its supplement has been avoided for the moment. The only figure that will be provided in this context is the number of items published in 1980, which is 135."""	bibliographic database;bibliometrics;citation analysis;citation index;dalton pritchard;delimiter;human-readable medium;indexing and abstracting service;library and information science	Roland Hjerppe	1982	Scientometrics	10.1007/BF02021064	computer science;citation analysis;information retrieval	ML	-63.77926462711546	-19.65017649823163	177543
1bf6c63f86e58aab1bb63a8154055d50be5df51d	"""multimedia cd-rom as a medium for manuscript preservation and dissemination: the design and development of """"treasures of islam"""""""		The paper discusses the use of electronic publishing for the preservation and dissemination of rare manuscript material. It is based both upon the authors’ earlier work on multimedia integration and upon their experience of designing and developing “Treasures of Islam: Art and Design in Islamic Manuscripts”. This trilingual multimedia CD-ROM (with interfaces in English, French and Arabic) contains rare or unique art work, together with a number of complete texts, selected from a collection of Islamic manuscripts held in the Department of Rare Books at McGill University. It combines text, still images, video sequences, music and voices. The paper deals with the following issues: Content selection (selection criteria, authentication); Digitization; Authoring system; Interface design; Information-seeking approaches; Multimedia integration; Multilingualism; Copyright; and Production and marketing. The paper also discusses CD-ROM versus the Web as a publication medium for this type of material. Manuscript Collections Manuscripts traditionally have posed major problems for libraries and archives charged with the twin but contradictory tasks of preservation and dissemination. Typically manuscripts are produced in limited numbers, and therefore any particular copy is likely to be rare, and perhaps even unique. This in turn may place a considerable financial value on the manuscript. Furthermore, manuscripts tend to exist in a more fragile state than, for example, published books. The manuscript may lack any kind of binding or cover, and indeed may comprise a single sheet of paper. If the manuscript is old it may also suffer from the various problems associated with paper and ink degeneration. It is therefore not surprising that many institutions place a very considerable onus on preservation. This can involve such measures as climate control and special storage containers. An additional major means to promote conservation, however, is simply to restrict access to the manuscript; each time a manuscript is handled it risks further physical degeneration. This can encourage policies ranging from refusal to lend the manuscript to other institutions, through restriction to use in a special room (where, for example, pens are banned), to the extreme where the manuscript is only available for display behind glass. Requests to photocopy or even photograph the manuscript may well be denied for fear that the manuscript will be damaged in the process. Such conservation practices are understandable with rare, fragile and valuable manuscripts. They do conflict, nevertheless, with the expectation that archives and especially libraries will actively promote the use of their collections. Some manuscripts may be important works of art in their own right, worthy of viewing much as might be a museum or gallery exhibit. But in many cases legitimate requests will be made to handle the manuscript, read it and copy it; refusal to accede to such requests for fear of damage will support the conservation role only at the expense of the dissemination role. Electronic replication of manuscripts offers one solution to this dilemma. Once the replication has been undertaken, limitless copies can be made with no degradation of quality and no need for further handling of the manuscript (in contrast to photocopying). When the importance of the manuscript lies in its beauty (for example, in its calligraphy or illustrations) the electronic version should be able to capture the full glory of the original. It may also be feasible and beneficial to enhance the original manuscript in the electronic version by, for example, scholarly commentary, indexing or translation into one or more languages. The copies then can easily be disseminated to remote users. Furthermore, the owners of the original may be able to generate income from sales of the electronic versions. It is not surprising, therefore, that a growing number of institutions should be turning to electronic storage and dissemination of rare manuscript collections. The Memory of the World project undertaken by UNESCO is an especially prominent example of a coordinated global attempt to safeguard and disseminate documentary treasures that are in danger (Courrier & Large, 1997). Such a solution, however, is not without its problems. This paper explores the issues involved in electronic replication of rare manuscripts, drawing especially upon the authors’ experience of designing and creating one such product. It also discusses the advantages and disadvantages of the two most popular electronic technologies for such work: CD-ROMs and the World Wide Web. Treasures of Islam The Islamic Studies Library, and the Rare and Special Collections Division of the Library at McGill University contain impressive holdings of manuscripts from the Islamic world. These include texts on jurisprudence, philosophy and theology in Arabic, Persian and Ottoman Turkish dating back as far as the thirteenth century. Many are in a fragile condition, inadequately documented and not easily available to the public. Islamic manuscripts are valued not only for their intellectual content but also for their physical beauty. Authors, calligraphers, painters and binders collaborate to produce works of art. As such, they provided a rich source from which to select the content of what would become the Treasures of Islam, a multimedia CD-ROM published in 1999 by McGill University. The Treasures of Islam CD-ROM comprises four sections: 40 examples of Islamic calligraphy in several different styles including Kufi, Thuluth and Naskh; 42 miniature paintings representing a variety of styles and sources; 16 richly decorated lacquer bindings; and eight complete manuscripts dating from the thirteenth to the nineteenth centuries. In addition, a short video clip and spoken summaries of each section are included. Three separate language versions of the interface are provided on the disc: Arabic, French and English. Not only the interface itself, but all supplementary texts (introductions to each section and captions for each image) and speech segments are available in the three languages. During the design and development of Treasures of Islam many decisions had to be taken concerning content, digitization, authorware, the interface, information seeking approaches, multimedia integration, multilingualism, copyright, and production and marketing. The solutions to these problems had to relate to the specific product under development, but the issues raised are generic and likely to be encountered by many multimedia developers. Content Although electronic versions of manuscripts can be used for preservation and dissemination, a considerable amount of time and effort must be expended in order to achieve this end. The content must justify the expense, and this is especially the case if it is intended to market commercially the product to cover costs or to generate income. Several selection criteria can be employed, including the rarity of the manuscript, its aesthetic interest, its financial value, and the level of demand for access to it. Decisions on content normally will be taken by subject experts rather than the technical designers. In the case of Treasures of Islam, for example, the Librarian of the Islamic Studies Library and the Curator of the Rare and Special Collections Division provided their expertise for content selection. Many of the manuscripts had not been well documented, and in order to present them on the CDROM in a meaningful fashion it was necessary for further research. Such an eventuality had not been anticipated by the developers, and indeed funds were unavailable within the digitization project for this kind of work. Fortunately, the Islamic Studies Librarian (Adam Gacek) generously was willing to undertake the necessary scholarship regardless. The lesson to be drawn here is that when planning such a project it should not be assumed that the manuscripts can be transferred to a new medium without provision for scholarly as well as technical assistance. Another consideration for content is the copyright status of the material selected for inclusion. The developers must be certain that they have the right to use the material without infringing copyright. Obviously this is especially important if it is intended to produce a commercial product for sale. Even if copyright is not a problem, the library or archive custodians may be reluctant to subject the manuscript to the rigors of scanning, a necessary step in digitization. Assurances may be demanded that every care will be taken with the manuscript, and it may be necessary to arrange that scanning be undertaken in the manuscript department, thereby obviating the need to remove it to the digitization project’s premises. The sound content of Treasures of Islam caused a number of problems. A decision was made to include background music, which naturally had to have links with the Islamic world. It proved difficult to find suitable music, even though only short segments of a few minutes’ duration were required for looping. Copyrighted music could not be used (unless copyright permission was obtained and any royalty fees accepted), and finally a local Islamic musician agreed to record for the CD-ROM (using the recording facilities of McGill’s Faculty of Music). Voice commentaries were required in the three languages of the CD-ROM, and after much experimentation with various voices and primitive amateur recording equipment, the Canadian Broadcasting Corporation (CBC) was hired to provide both professional readers and professional recording facilities. Digitization The manuscripts must be converted from paper to a digital version by scanning each page. Text can be stored as ASCII code very economically (a CD-ROM will hold around 250,000 manuscript pages). The situation is very different for still images, and especially for sound or video. The short high quality video clip of one minute on Treasures	adobe authorware;archive;authentication;book;cd-rom;case preservation;display resolution;elegant degradation;image scanner;information seeking;librarian;library (computing);name binding;part-of-speech tagging;photocopier;requests;technical drawing;video clip;world wide web	Andrew Large;Jamshid Beheshti;Haidar Moukdad	2000			multilingualism;computer science;world wide web;multimedia;electronic publishing;digitization;authoring system;cd-rom;authentication;information seeking;islam	Web+IR	-67.23571091556735	-19.324648774853138	177791
53455d5094e0f61929e2a7f15d1003e6600dd4e7	information work in the internet age: localizing, evaluating and representing resources		The amount of data on the internet continues to grow. At the same time, funding for professional information work for collection building, quality assessment and content representation is reduced. The Layer Model responds to these challenges associated with the internet. The Layer Model shows how information providers can restrict the information work dedicated to content representation to small collections and, at the same time, allows users to access much larger collections. Transfer modules apply intellectual information work to documents outside a core. This article shows how the Layer Model can be extended in order to integrate automatic quality assessment and automated collection building. 1 Information Services in the Internet Age The explosion of online information and the technological advance offer great opportunities for the information industry. At the same time, however, they paradoxically pose a threat to many business models. The following opinions often expressed by users sum up some of these threats: • Everything is available for free. Why should anyone pay for content, access or intellectual information work? • If something is online, then it must be accessible. Intellectual information work seems unnecessary. • I can find everything by myself. The availability of free information tools and their ease of use makes less experienced users believe that information retrieval and access are solved problems. The availability of free information tools which are based on a large amount of data leads to satisfying results in many cases. One example are internet search engines. However, information professionals have pointed out the low overall retrieval quality of general purpose search engines and the lack of advanced search options they provide. The retrieval quality of these tools seems to be far behind the quality of systems optimized for a specific task, as comparisons have shown (Hawking 2000). The continuing growth of the internet makes information retrieval and access ever more troublesome. The task of Dieses Dokument wird unter folgender creative commons Lizenz veröffentlicht: http://creativecommons.org/licenses/by-nc-nd/2.0/de/	information retrieval;internet;usability;web search engine	Thomas Mandl	2004			the internet;data mining;search engine;information system;usability;business model;restrict;information industry;commons;computer science	Web+IR	-69.1834678437102	-22.713000711959843	178225
0f990ba8060cd380326c949d517fbc13e9bd1ef9	the ombudsman: forecasting conflict resolution. is it worth asking an expert?	forecasting conflict resolution;conflict resolution	All good fiction writers know that a story seldom interests readers if it does not involve conflict? conflicts between individuals, institutions, nations, and between all of these and natural forces. Our interest in life mirrors this. Good news is no news; our media reports on strikes, international disagree ments, legal disputes, terrorism, and political antago nism every day. Our interest in these conflicts, and in their resolu tion, can be more than a passing curiosity Correctly anticipating a disputeu0027s outcome can be advanta geous. Accurately foreseeing the resolutions of inter national or civil conflicts could save lives or avert		Paul Goodwin	2007	Interfaces		actuarial science;economics;computer science;management;operations research	HCI	-65.99337855658614	-21.141227736635884	179489
cdb83d1105581386f93cac922dde492df9515186	mooers' law: in and out of context	information needs;information retrieval	Mooers’ Law, widely referenced in the literature of Library and Information Science, has generally been misinterpreted as concluding that customers will tend not to use Information Retrieval systems that are too difficult or frustrating, when in fact the law addresses the reluctance of customers to use any type of IR system, regardless of its faults or merits, within an environment in which having information requires more effort than not having it. An expansion of Mooers’ original law is proposed, based upon a “Scale of Information Retrieval Environments,” which includes not only those types of environments addressed by Mooers, but those in which a premium is placed upon having information, as well as those in which the effort required from having information vs. not having it is fairly evenly balanced.	information retrieval;library and information science	Brice Austin	2001	JASIST	10.1002/asi.1114	information needs;information science;computer science;artificial intelligence;operations research;information retrieval;information system;theory	Web+IR	-68.35155246024134	-22.487305043275686	180108
8e909702df8f94cfc6be77853cd4db228a720c8e	challenges and accomplishments in u.s. prison libraries	bibliotheque;text;prison libraries united states;library and information services to incarcerated persons global perspectives;north america;america del norte;amerique du nord;library service;amerique;milieu carceral;etats unis;estados unidos;american library association;medio carcelario;carceral environment;america;biblioteca;library;development policy	This article focuses on the evolution of prison library services in the United States and the changes in the roles and purposes of prison libraries over the last two centuries. The development of standards and guidelines for prison libraries under the leadership of the American Library Association and the American Correctional Association is discussed. The characteristics of the offender population are described as well as how prison libraries have responded to the specific needs of this special user group. The challenges of the unique prison environment are highlighted, especially as they relate to the delivery of library services. Examples of successful library services and programs are included, with descriptions of technology projects, resources for prison library staff, collection development policies, law library services, literacy programs, and resources to assist inmates with the transition back to society. Development of Prison Libraries Access to reading materials and information is provided in practically all federal and state correctional institutions in the United States. Such access is also provided in most local jails, although the level and quality of these services are not easily ascertained. Library facilities, library collections, and library services in the federal prison system fall under the jurisdiction of the Federal Bureau of Prisons, U.S. Department of Justice. Each of the fifty states has its own department of corrections (or similarly named agency) with responsibility for the state correctional facilities and their libraries. Counties and municipalities administer jails and detention centers and often have agreements with local public libraries and/or community volunteer groups to provide reading materials and other library 491 lehmann/united states services to inmates. Larger jails often have designated library spaces but may not have professional librarians on staff. Offenders convicted of a federal crime serve their sentence in federal institutions; offenders convicted of state crimes serve their sentence in a state facility; defendants awaiting trial are incarcerated in local jails, and some convicted offenders with short sentences (mainly less than one year) may also serve their sentence in a jail. As of December 31, 2009, more than 1.6 million prisoners were under the jurisdiction or legal authority of state and federal correctional officials. At midyear 2009, about 1 in every 198 U.S. residents was imprisoned with a sentence of more than one year, a rate of 504 prisoners per 100,000 U.S. residents (Bureau of Justice Statistics, 2010b). At midyear 2009, 767,620 inmates were held in custody in local jails (Bureau of Justice Statistics, 2010a). The number of inmates in state and federal prisons has increased nearly sevenfold from less than 200,000 in 1970 to 1,518,559 by 2008 (The Sentencing Project, http:// www.sentencingprojecct.org). The United States experienced a major prison construction boom over the last twenty-five years that, however, appears to have slowed down somewhat over the last five years. Most of these new facilities include a library with general interest materials and legal collections. Hundreds of new prison librarian and support staff positions have been created but, due to the economic downturn over the last couple of years, most states have seen it necessary to eliminate or freeze many state positions, including prison librarians and teachers. The Directory of State Prison Librarians, maintained by the Maryland Correctional Education Libraries, shows the total number of prison libraries in all states to be about 950 (June 2010), with about two-thirds of these having designated library staff, not all librarians, however. Approximately twenty-five states employ a central prison library or institution services coordinator/consultant, either within the department of corrections or on the state library staff. A few states have regional correctional library coordinators (Maryland, 2009, November 10). Early prisons (aptly named “penitentiaries”) from the beginning of the nineteenth century had some collections of books for the moral and religious education of the prisoners. The “librarians” were almost all members of the clergy. The main purpose of reading was believed to be strengthening of character, religious devotion, and what we today would call behavior modification. By the mid-nineteenth century, penology (the study, theory, and practice of prison management and criminal rehabilitation) had become more scientific, and criminologists claimed that they knew the reasons for criminal behavior and, consequently, how to reform criminals. The Prison Congress in 1870 beckoned in the Progressive Period and the Prison Reform Movement, which advocated for rehabilitation instead of retribution, and for education and rewards for good behavior. The prison library was seen as one of these incentives. The content of 492 library trends/winter 2011 the prisoners’ reading would be determined by the prison administration, and only materials that furthered the reformative goals of the institution were allowed. During the first decades of the twentieth century, a number of studies on prison libraries were published by both prison reformers and the American Library Association (ALA), and in 1930, the American Correctional Association (ACA) issued a manual for prison libraries. The following year, Austin MacCormick, the distinguished prison educator, published The Education of Adult Prisoners, which states that “The possible values of directed reading are almost limitless, especially in the field of adult education. Reading must be moral and ‘directed’” (Maryland, November 10, 2009).1 The following four decades saw an unprecedented growth in prison libraries, mainly in the federal prison system. The rationale for the federal prison library development was stated by MacCormick in the 1950 American Prison Association’s Library Manual for Correctional Institutions: “The proper function and true value of an institution library are clear-cut and incontestable. It is not merely a time-killing recreational device. . . . Properly organized, directed, and utilized, the institution library is an instrument of wholesome recreation, of direct and indirect education, and of mental health. Books are for many prisoners a bridge to the free world; over that bridge they can pass to a better world with a broader horizon than they ever knew before” (p. 4). Unfortunately, it was not until the 1970s that this impetus for prison libraries took hold at the state level. A major factor contributing to the development of libraries in state correctional facilities was the Library Services and Construction Act (LSCA), authorized by Congress in 1966. LSCA set aside money for institutional library services (correctional and mental health facilities). The federal funds would be administered by state library agencies that were given a certain flexibility in developing eligibility criteria. Funding for institutional library services had maintenance-of-effort requirements, which contributed to a minimum level of local funding also being allocated. A considerable number of prison libraries and some librarian positions were established with LSCA money. When LSCA was replaced by the Library Services and Technology Act (LSTA) in 1997, the new act no longer included designated funds for institutions. Another very important factor, leading to the development of law library collections in prisons was the 1977 U.S. Supreme Court decision, Bounds v. Smith, 430. U.S. 817 (1977). After decades of litigation by prisoners to obtain venues for appealing their sentences and challenging conditions of their confinement, Bounds stipulated that all prisons must provide “meaningful access to the courts through people trained in the law or through law library collections.” The Federal Bureau of Prisons and most states chose the library option, and over the next two decades large 493 lehmann/united states sums of money were spent to purchase legal collections and to keep them updated. The mandate for legal materials always took precedence over the development and maintenance of the general library collections. In 1996, the U.S. Supreme Court, in its Lewis v. Casey decision (518 U.S. 804), narrowed the interpretation of Bounds and limited the parameters under which state correctional agencies were obligated to provide inmates with legal assistance and resources. Some states eliminated their legal collections and replaced them with access to paralegals; other states reduced existing prison legal collections, while maintaining the primary case law, federal and state codes, and administrative rules. Around the year 2000, some state correctional agencies began to convert their print-based legal collections to electronic collections and made them available on CDROM and DVD. Today, the CD-ROM/DVD collections are rapidly being replaced by Web-based “correctional” legal information products, developed by the major legal publishers. Access to these Web-based resources, of course, presupposes that a secure network infrastructure is in place and that inmates are permitted to use computers. To guide the development of general prison library collections (as opposed to legal collections), the American Library Association in 1981 issued Library Standards for Adult Correctional Institutions, a publication endorsed by the American Correctional Association (ACA). These standards emphasized building collections according to the needs and interests of the prison population and developing community connections. A new and greatly expanded edition of the ALA Standards was published in 1992, Library Standards for Adult Correctional Institutions, and the Library Standards for Juvenile Correctional Facilities came out in 1999. Both are tools for the planning, implementation, and evaluation of library services and define acceptable levels of service. Working g	american cryptogram association;authorization;automated planning and scheduling;book;cd-rom;code;computer;design rationale;intranet;librarian;library (computing);mass effect trilogy;money;public library;replicator (stargate);requirement;stanford prison experiment;web service	Vibeke Lehmann	2011	Library Trends	10.1353/lib.2011.0001	library science;gerontology;library;engineering;public administration;management;genetics	Web+IR	-68.73630828698515	-19.034530382805645	180259
6b586254c5ba93530aa8db4f2c29ed152b98302e	icer conference report		On a humid Midwestern summer week this past August, the 11th International Computer Education Research (ICER) conference took place on the campus of the University of Nebraska at Omaha. This year's conference saw over a 40% increase in attendance, breaking all prior attendance records from the first ten ICERs. Even with 118 delegates representing 8 unique countries, the conference format stayed true to its roots as a single-track conference with lively discussions about the latest research on computing education.	delegate (cli);icer;lively kernel	Brian Dorn;Quintin I. Cutts	2015	SIGCSE Bulletin	10.1145/2856332.2856333	operations research	HPC	-62.893086477630185	-18.595008843630595	180650
a899b45a2418355058c3b2e98d213dec7d00b0b3	what are we doing with our lives?: nobody cares about our concurrency control research		"""Most of the academic papers on concurrency control published in the last five years have assumed the following two design decisions: (1) applications execute transactions with serializable isolation and (2) applications execute most (if not all) of their transactions using stored procedures. But results from a recent survey of database administrators indicates that these assumptions are not realistic. This survey includes both legacy deployments where the cost of changing the application to use either serializable isolation or stored procedures is not feasible, as well as new """"greenfield"""" projects that not encumbered by prior constraints. As such, the research produced by our community is not helping people with their real-world systems and thus is essentially irrelevant. I know this because I am guilty of writing these papers too.  In this talk/denouncement, I will descend from my ivory tower and argue that we need to rethink our agenda for concurrency control research. Recent trends focus on asking the wrong questions and solving the wrong problems. I contend that the real issues that will have the most impact are not easily solved by more """"clever"""" algorithms. Instead, in many cases, they can only be solved by hardware improvements and artificial intelligence."""	algorithm;artificial intelligence;concurrency control;relevance;serializability;stored procedure;world-system	Andrew Pavlo	2017		10.1145/3035918.3056096	parallel computing;real-time computing;distributed computing	DB	-63.18256146902592	-22.871105086637062	181065
b34522ba1cb44107f507eaa425e7239e10fdbcef	evaluating the 1881 census transcription: a pilot survey of hertfordshire	history;article	Introduction This survey arose from an invitation received to attend a workshop at the University of Essex held 17-18 September 1998, hosted by the staff of the History Data Service of the UK Data Archive, to discuss the uses of the 1881 census transcription which had been coordinated by the Genealogical Society of Utah (hereafter GSU) in alliance with the Federation of Family History Societies. This invaluable resource, now held by the History Data Service, was being supplied on request to historians in datasets of various sizes to facilitate both teaching and research, and the main purpose of the meeting was to determine the needs of end-users with a view to discovering the most appropriate ways of developing and distributing the data. Somewhat surprisingly, there appeared to be minimal concern about the quality of the transcription, despite the fact that there was significant anecdotal testimony that should have given historical researchers cause for concern. As the coordinator of an ongoing project to work with family historians on computerising the 1851 and 1891 Hertfordshire censuses, I had received numerous personal communications concerning the 1881	archive;medical transcription;transcription (software)	Nigel Goose	2001	History and Computing	10.3366/hac.2001.13.2.181	demography;geography;computer science;genealogy;cartography	Web+IR	-68.20255214709438	-19.251508381584966	181197
2b0ce538d70fd4b3469266d67792b02799419dec	social network games with obligatory product selection	universiteitsbibliotheek	Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: http://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.	game theory;privacy;social network	Krzysztof R. Apt;Sunil Simon	2013		10.4204/EPTCS.119.16	simulation;computer science;mathematics;mathematical economics	Web+IR	-66.44075355836667	-18.619630976628436	181227
cac32e7792858476e104ac388496812ed2965e41	message from the editor	consumer electronics;ieee transactions;t-ce;open access publishing	Most IEEE transactions, journals and letters now use a hybrid journal model which permits both traditional subscription-based content as well as Open Access (OA) author-pays content. IEEE TAB have approved a current discounted OA fee of $1750, plus any overlength and color page charges if applicable, which is less than the original fee of $3000 per article. Any OA papers published within a hybrid journal will be included in all media types offered by that title.		Robert Simon Sherratt	2012	IEEE Trans. Consumer Electronics	10.1109/TCE.2012.6414972		Visualization	-64.58624372459626	-17.13339531553843	182107
d4beb52a34f0088f5db5851641a19b2d0e6ea485	a joint european mass storage specification effort	working group;european centre for medium range weather forecasts;formal specification;storage management;scientific data;data processing;weather forecasting;suppliers;storage media;large scale;mass storage requirements;weather forecasting electrochemical machining large scale systems data processing europe writing proposals production file systems laboratories;requests for proposals;electrochemical machining;mass storage system;request for proposal;writing;production;formal specification storage media storage management natural sciences computing research initiatives;large scale scientific data processing sites;installations;research initiatives;joint european mass storage specification effort;europe;natural sciences computing;proposals;suppliers mass storage requirements joint european mass storage specification effort european centre for medium range weather forecasts large scale scientific data processing sites requests for proposals installations;file systems;european centre for medium range weather forecast;large scale systems	In September 1993, a workshop on mass storage requirements was held at the European Centre for Medium-Range Weather Forecasts (ECMWF) with the objective of discussing, and hopefully finding a common approach to, the problems facing large-scale scientific data processing sites in Europe and elsewhere. The outcome of the workshop was a cooperative venture to develop a specification for a mass storage system that could meet, or come close to meeting, the needs of most of the sites represented in the working group. The hope was to demonstrate a common direction and a common set of interests in the group, thus influencing developers and suppliers of large mass storage systems to align their offerings more closely with the group's needs. By allowing free access to the specification itself, we hope to provide a valuable resource for those who write requests for proposals (RFPs) in the area of mass storage systems. This effort is still in its early stages. The eventual results are intended to be of use to both installations and suppliers, resulting in a better outcome for all those working in large mass storage systems in scientific environments. >	mass storage	Dick Dixon	1994		10.1109/MASS.1994.373043	simulation;data processing;computer science;request for proposal;marketing;data mining;database;management;operations research	HPC	-67.05868071857076	-20.085777811772086	183177
73c85095f42a34ed81263258feaff704a27f073b	page turning in multiprogrammed computers	multiprogrammed computer	Dear Editor: Not long ago several leading members of the ACM stated quite positively to me that programs, decks, listings, etc. which are distributed by the SNARE Distribution Agency to members of SHARE are not available to nonmembers. In the interests of better communication between organizations and people, I wish to bring to the attention of all interested parties the following section from the SHARE Reference Manual (p. 2.01-19, dated 6/6/62: Article X-B SHARE Policy Concerning Distribution to Non-Members: SHARE wishes the information contributed by its members for distribution through the SHARE Distribution Agency to be made as accessible as is practicable to any one in the computing field who has a legitimate interest in the information. To this effect, the membership confers on the SHARE Distribution Agency the right to distribute to non-members any of the material that the members contribute for formal SHARE distribution. I hope this will clear the air somewhat and help make more available some of the excellent algorithms available through SNARE. The address of the SrmRE Distribution Agency is: Mr. issue of the Communications. Although the notion of printer plotting has received little publicity, it is by no means new. In November of 1955, Mr. Robert J. Hunn and I, then with DuPont, described a UNIVAC I program for preparing contour diagrams with the high speed printer, plotting values computed from second degree polynomials in four variables. We designed this program specifically for certain statistical application, and subsequent to its completion it saw considerable use. The presentation was made at the UNIVAC Systems Programmers' Conference held in New York and was reported in the June, 1957 issue of The Programmer, a publication unhappily now defunct. At the same time we were bold enough to extend the concept to a broader class of plotting applications and included a set of subroutines in the GP Compiler library for UNIVAC I. These routines regarded the printer as a strip-chart recorder, admitted a variety of choices of superimposed grids and scale factors, and could be used either to plot already tabulated data or to plot values as they were computed. Mr. Leslie Shaw, then with Remington Rand, prepared these programs. More recently Mr. Michael Lesk and I have exploited these programs with the object of a graphical presentation of certain statistics on the occurrence of nouns in text, for purposes of the automatic identification of document content. We …	automatic identification and data capture;cliff shaw;compiler;computer;diagram;graphical user interface;lesk algorithm;leslie speaker;polynomial;printer (computing);programmer;rand index;robert;subroutine;univac i	Leon Bloom;M. Michael Cohen;Sigmund N. Porter	1962	Commun. ACM	10.1145/355580.369052	computer hardware;operating system	Web+IR	-63.41184140724633	-19.55589251050123	183894
16854c8a1f94b83ffd2f8c5a7a6286dafae0029e	peer-to-peer file sharing		The use of file-sharing networks and software to download and share copyrighted works like software, music, movies, television programs, and books can violate copyright laws. Both the person who makes an illegal copy of a copyrighted work available and the person who receives or downloads an illegal copy have violated the law and Stanford policies. Many file-sharing programs have default settings that share copyrighted files, such as music and movies, through the Internet. Before enabling any of these programs students, faculty, or staff must read the fine print, make sure to understand the program itself, and only use such programs lawfully. Under the Digital Millennium Copyright Act (DMCA), copyright owners are entitled to notify Internet service providers, such as Stanford, that IP addresses linked to the Stanford network are sharing copies of music, movies, or other content without authorization. The law requires the University to respond to such complaints by eliminating access to the infringing materials. Stanford will disconnect students who fail to respond to a DMCA complaint promptly. Furthermore, the University also will suspend or terminate computer access to the Stanford network, including termination of the SUNet ID, to members of the community who continue to violate copyright laws. Finally, the University will take action through the student, employee, or faculty disciplinary processes if necessary. Beyond University consequences, copyright holders may file civil lawsuits against copyright infringers seeking extensive monetary damages. If compelled by a lawful subpoena, Stanford may be required to identify students, faculty, staff, or others who have violated copyright law. For more information about file-sharing, refer to Residential Computing's online resource, File-Sharing and Copyright Law (http:// rescomp.stanford.edu/info/dmca) web site.	authorization;book;digital millennium copyright act;download;id-wsf;internet;peer-to-peer file sharing;terminate (software)	Peers regularly join;leave the network	2009		10.1007/978-0-387-39940-9_3265	fork;self-certifying file system;torrent file;indexed file;memory-mapped file;device file;computer file;zap file;computer science;class implementation file;stub file;versioning file system;operating system;unix file types;ssh file transfer protocol;journaling file system;database;open;distributed file system;data file;file system fragmentation;world wide web;file area network;file control block	Security	-66.53150619075645	-18.894180245035546	184438
0f18b145c8c17f0082e081fd05d6df7869402eb0	founding an organization theory of work policy as imperative regimes of regulated freedom for itc development		"""This paper proposes a theory of imperative regimes of regulated freedom as they relate to the development of policy for Information Communication Technology. Policy is characterized here as an imperative regime of regulated freedom, guiding people in both objective (regulated reasoning) and subjective (heuristic commonsense freedom) decision making to guide communities’ to achieve needed work outcomes. The paper includes: researching organizing as being the practical nature of our work, building a new theory of reorganization for people working, developing human imperative regimes of regulated freedom to guide communities’ work, and developing policies which are societies’ own artifacts helping communities work together. The paper then focuses on the human work domain, which involves policy making governing societies’ cultural and social organizations, in general, and the importance of policymaking for Information Communication Technology, in particular. DOI: 10.4018/jicthd.2012070104 40 International Journal of Information Communication Technologies and Human Development, 4(3), 39-55, July-September 2012 Copyright © 2012, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. needs relative those outcomes we select to meet those needs. The crux of this dilemma rests in the nature of the energy and information exchange required of us in doing our work. This is because of the gap between deciding what our needs are and doing the energy/information exchange required to meet those needs. Thus there develops a schism between the deciders (policy makers) and the doers (people doing the work) and meeting communal needs sharing by the outcomes equitably. Researching organizing as being the nature of our work. What are organizations that we have so many theories about them? Perhaps one of the main causes of theories on organizations is the fact that organizations have come to play an ever larger role in our public and private lives. Businesses, social groups, and governments abound with organizations and us within in them. What, then, is organization? How does organization evolve? Or has organization always been with us? In their paper, “A future for organization theory: living in and living with changing organizations,” James Walsh, Alan Meyer, and Claudia Bird Schoonhoven remark as to the state of our understanding organization: The field of organization theory is adrift. The press for ‘relevance’ is but one symptom of a field that has lost its bearings. scholarship that was once so relevant is now irrelevant (or worse) the answer is to change our research foci. The theories we developed to comprehend the Management Revolution no longer have the traction they once did. Organization and management theory is uniquely positioned to ask and answer questions that speak to the defining characteristics of our new century. The future is ours. We need to seize it (Walsh, Meyer, & Schoonhoven, 2006). Organization theories tend to be moreabout organizations and their management than about the nature of organization itself. There are many definitions of organizations. Most of them come to a generic base: organizations are people working together for a common outcome (Harmon & Mayer, 1986). Organization theories tend to focus on a particular aspect of organizations in order to address the organization issues of the historical moment. For example, Max Weber’s bureaucratic organization focused on economic efficiency, the scientific management approaches of Frederick Taylor and others focused on effectiveness, while the human relations theories of Kurt Lewin and others focused on participation, performance, and learning. Each new organization theory usually proposes its own framework and much of its own terminology. Although new organization theories are traditionally built upon past theories, they often tend to develop into separate schools, often at theoretical odds with each other. Another view: “There is no such thing as the theory of organizations” (Shafritz & Ott, 1996). During the process of applying Action Training & Research (AT&R) as designed by Neely Gardner to public policy development a theory research workshopwas first conducted in 1995 at Kaunas University of Technology in Lithuania. The workshop/symposium researched the question of “What is organization?” as part of their research project to use the AT&R approach for changing organizations. In this case the key research step was to explore the issue of: What is Organization? The exploratory workshop/symposium used the genealogy of language as their method to research the origin of the word organization. In selecting a genealogical approach to conduct their research on organization they took note of Nietzsche’s warning against using genealogy of language as a method of research: “all concepts in which an entire process is semantically concentrated elude definition, only that which has no history is definable” (Spivak, 1988). Likewise, Benedict Anderson points out the potential value to research using this genealogical approach on language. First, one notes the primordialness of languages, even those known to be modern. No one can give a date for the birth of any language. Each looms up imperceptible out of the horizonless past. (Insofar as homo sapiens 15 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/founding-organization-theorywork-policy/69973?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Communications and Social Science. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""	adrift;hadamard transform;heuristic;imperative programming;information exchange;librarian;organizational behavior;organizing (structure);over-the-top content;relevance;theory;traction teampage;web page	Raymon R. Bruce	2012	IJICTHD	10.4018/jicthd.2012070104	economics;operations management;management science;sociology;management;law;economic growth	Web+IR	-68.85077268268739	-19.458774523876528	184517
1e0dcec8ba7cc953e7813f6265d1766ccf928459	a university-based approach to the diffusion of knowledge management concepts and practice	corporate strategy;best practice;knowledge management;software systems;knowledge codification and classification;chief knowledge officer;knowledge generation;business school;trust based organizations;knowledge transfer;diffusion of it practice;knowledge creation	"""This paper addresses the diffusion of Knowledge Management concepts, principles, and cases into university courses. Although we are now living in a world of gigabit transmission systems and terabyte storage, there are still long delays that often occur before industry practice finds its way into university courses. Knowledge Management practices have been elaborated in books, articles, cases, and symposia for almost a decade, with particular acceleration during recent years. Yet only a small number of universities offer KM courses, and few are offered at top business schools. In order to speed the assimilation of KM courses to universities, we describe the essential tools and resources needed in order to give our colleagues a head start in the preparation for KM courses. We also hope to facilitate the university's traditional role as an agent for diffusing best practices and sound principles to a broader audience. To achieve this, we present an approach that brings together the intellectual territory, books, resources, and a few early lessons we have learned into a """"toolkit"""" that should aid teachers in several disciplines in planning and delivering KM courses at the university level. The resources for KM teaching are abundant and include dozens of books, hundreds of articles, extensive WWW resources, and a fast-growing group of cases. We provide samples of the most suitable resources. The crucial question for preparing a KM course is the intellectual territory that can be covered. We present eight recommended modules, including: Knowledge Creation, History of KM Theory/Concepts, The Importance of Trust, Knowledge Coding, and Hardware/ Software/Systems, KM ROI/Evaluation. Since many approaches or emphases for KM courses are possible, we suggest four examples, each including different proportions of the core modules. These course approaches are: Current Industry Practice, KM History, Concepts and Theory, Human/Personnel Factors, and Hardware, Software, Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists requires prior specific permission and/or a fee. SIGCPR '99 New Orleans LA USA Copyright ACM 1999 1-58113-063-5/99/04...$5.00 and Systems. A matrix matches resources, modules, and approaches to help a professor personalize and save considerable time in the preparation of a KM course. KM seems ready to evolve into a robust body of concepts and practices that will be taught far beyond business schools. We hope that the concepts and recommendations presented in this paper will speed the diffusion process."""	best practice;book;data assimilation;gigabit;knowledge management;personalization;region of interest;terabyte;www	Stephen Ruth;Jeffrey Theobald;Virgil Frizzell	1999		10.1145/299513.299716	engineering;knowledge management;management science;personal knowledge management;management	DB	-69.43393421780382	-17.51099470859931	184608
a1bdb46e3341197a81e94792aa9d0b9bea3724d9	self-reliance of the koha acquisition module for managing procurement of printed books: an academic library perspective		Purpose The automation of library acquisition is a balancing act which involves dealing with institutional procurement policies, administration, vendors, finance, books, internal audit, reporting and, above all, tracking. Very few studies have dealt with the operational difficulties of the transition from manual to automated acquisition using Koha. The objective of this paper is to investigate the self-reliance of Koha in handling all stages of procurement, starting from suggestions to receiving an ordered title, and to discuss the constraints and difficulties faced during the process. Design/methodology/approach Based on internal documentation spanning a period of four years, the paper provides a first-hand account of the experience of the transition from manual to automated acquisition using Koha at the Indian Institute for Human Settlements (IIHS) Library, Bangalore. Findings The study reveals that Koha is partially self-reliant in an academic setup where acquisition is dynamic in nature; however, cust...	book;koha;language acquisition device (computer);printing;procurement	Amrutraj Ravi Benahal	2018	The Electronic Library	10.1108/EL-12-2016-0263	multimedia;computer science;automation;internal audit;systems engineering;internal documentation;procurement	HCI	-67.93599762449517	-17.627085736146377	185347
55a75abd0808867b82222475c3585a97dfb6c270	the european dbms scene	european dbms scene	"""Nineteen seventy-four was an active year in Europe for those interested in the expanding world of DBMS. Apart from the spate of """"data'base"""" seminars, we had a number of interesting conferences and symposia. On the beautiful Mediterranean island of Corsica in early April, IFIP TC2 organized an invited working conference wi th the catch-al l t i t le of """"Data Base Management Systems."""" Somehow it caught quite a large number of highly theoretical papers, al though there were occasional refreshing breaths of practicality. Theory is fine if the theoreticians do not loose track of making it crystal clear how their ideas can help in practice. As a get-together for some 60 peers from Europe and North America, the conference was a great success. The proceedings, i nc lud ing transcribed discussions, have already been published by North Holland. In May, the French national organization tRIA ran a very successful and well-attended (some 120) symposium in Namur, Belgium, wi th the tit le """"Data Structure Models for Information Systems."""" The organizers had four levels of model rea l world, functional, implementation and physical. Mike Senko, Jim Fry and AI Fillat came over to present Yankee know-how by giving three of the eleven formal presentations. On the last day, small working parties met to discuss functional data structure description, physical implementation, and data manipulat ion methods. The proceedings are to be published by the Institute d' lnformatique in Namur. In August in Stockholm, we had IFIP 74, and it was gratifying to observe that DBMS is becoming a meaningful topic and numerous papers (both invited and contr ibuted) were given."""	database;ifip working group 2.1;information system;international federation for information processing;purely functional data structure;resources, events, agents (accounting model);sensitivity index;transmit and receive integrated assembly	T. William Olle	1974	DATA BASE	10.1145/1017558.1017559	computer science;knowledge management;electrical contacts;map projection;anode;mechanical engineering	DB	-63.76242344601949	-18.805479683571512	185520
7d6c2c86017d549d9022653341e44104475f9415	aftermath of a prediction: f. w. lancaster and the paperless society	bibliometrie;ciencia informacion;multiple perspectives;lancaster f w;text;information science;lancaster f wilfrid frederick wilfrid 1933;bibliometria;library and information science;carriere professionnelle;carrera profesional;career;bibliometrics;science information	Professor Lancaster’s audacious prediction of a paperless society by the end of the twentieth century is examined from multiple perspectives. Rationales for the prognostication, textual and contextual; reception by the profession; and impact on the literature of library and information science are reviewed. Bibliometric data is introduced in support of the extensive citation links to Lancaster’s core writings. The accuracy of Lancaster’s prediction and the leavening insights of the collateral literature are considered. Defining the Experience Sometimes we call upon fiction to explain and to make us wiser. The transition from print dominance to paperless ascendancy was one of many important historical shifts. The change from scroll to codex and the introduction of moveable type were also hugely significant innovations. Linking them all together, Thomas Wharton tells us that: Within every book there lies concealed a book of nothing. Don’t you sense it when you read a page brimming with words? The vast gulf of emptiness beneath the frail net of letters. The ghostliness of the letters themselves. Giving a semblance of life to things and people who are really nothing. Nothing at all. No, it was the reading that mattered, I eventually understood, not whether the pages were blank or printed. The Mohammedans say that an hour of reading is one stolen from paradise. (Wharton, 2002, pp. 75–76) Aftermath of a Prediction: F. W. Lancaster and the Paperless Society	ascendancy;audacious;bibliometrics;gulf of evaluation;half-life 2: episode one;library and information science;movable type;paperless office;paperless society;printing	Arthur P. Young	2008	Library Trends	10.1353/lib.0.0002	psychology;library science;information science;bibliometrics;computer science;engineering;sociology;management;operations research;world wide web	PL	-63.560660005180885	-21.792163781022822	185641
1faaa4d763a494230485c46d421e3f2eece9b6e3	vidyanidhi: indian digital library of electronic theses	library and information science	In response to UNESCO's Call and subsequent directions, NDLTD proposes to undertake a project to develop the International Guide for the Creation of ETDs (hereafter, the Guide). Though most of the proposed work will be undertaken at no charge to UNESCO, the following subsections detail and explain those items to be paid for through a contract between UNESCO and Virginia Tech, acting as agent for NDLTD. Direct costs: • = $2000 for VIDYANIDHI: Indian Digital Library of Electronic Theses o Shalini Urs (Director, from University of Mysore) will coordinate work to ensure suitability of the Guide for developing countries. • = $4000 for ISTEC to handle Spanish and to ensure suitability for Ibero-America o Johann van Reenen (Director, Library Linkages, ISTEC), will coordinate work on a Spanish version and ensure suitability for Ibero-America. • = $1500 for Australian Digital Theses Project o Marian Bate (Project Leader) will coordinate work to ensure suitability for Australasia and the Pacific Rim. • = $1500 for Joseph Moxley, Professor of English, to edit the Guide • = $3375 wages plus $1055 tuition for ½ time graduate research assistant at Virginia Tech to handle the French translation and assist in other phases of project, Fall 2000 • = $640 for travel, to ensure integration of the Guide in all 3 languages • = Subtotal of direct expenses: $14,070 Indirect costs: $5922 indirect cost, based on 45.5% charge on direct costs Total: $19,992 1.2 Budget Explanation Funds are requested largely ($9K direct out of $14K total direct) to allow work by the teams from Australia, India, and Ibero-America. Virginia Tech costs are limited to a small amount of travel plus funding of a ½ time graduate research assistant. Work by the co-principal investigators at Virginia Tech and their staffs will be contributed as cost sharing to the project, as will many other efforts by NDLTD members and supporters around the globe. Each partner will play a unique role in helping develop the International Guide for the Creation of ETDs (the Guide). Overall project coordination will take place at Virginia Tech (see Section 2.1), with guidance from the NDLTD Steering Committee (see Appendix A.1). The UNESCO-specified topics: • = establishment of budget, • = model workflow, • = legal requirements, and • = proposals for funding, by their very nature, may require different treatment in each nation. Accordingly, for these topics, the various partners (especially those discussed …	digital library;pacific rim;requirement;technical support;weatherstar	Shalini R. Urs;K. S. Raghavan	2001	Commun. ACM	10.1145/374308.374361	digital library;computer science;world wide web;information retrieval;library catalog	Robotics	-67.78135176154986	-18.445171151739636	186896
47da5987d77a337f24c14d8771cc51330a72a050	the price of services	offre service;grain size;service provider;recompense;service information;pricing;functional properties;distributed computing;service web;web service;fijacion precios;orientado servicio;intergiciel publication souscription;service utilisateur;recompensa;reward;tariffication;intergicial editor suscriptor;grosor grano;tarification;price dynamics;servicio informacion;calculo repartido;oriente service;information service;servicio usuario;service discovery;user service;proposals;publish subscribe middleware;calcul reparti;fixation prix;servicio web;tarificacion;service oriented;grosseur grain	HOUSTON – Oct. 2, 2009 – Quanta Services, Inc. (NYSE: PWR) today announced the closing on Oct. 1, 2009 of the acquisition of Price Gregory Services, Incorporated, a leading transmission pipeline infrastructure service provider. In connection with the acquisition, Quanta issued approximately 10.9 million shares of Quanta common stock and paid approximately $96 million in cash to the stockholders of Price Gregory Services.	closing (morphology);quanta computer;quantum	Justin O'Sullivan;David Edmond;Arthur H. M. ter Hofstede	2005		10.1007/11596141_50	forward price;service provider;pricing;web service;price's model;law of one price;computer science;database;service discovery;law;world wide web;price mechanism;reservation price;grain size	Mobile	-68.4122921165888	-19.963356279384076	187157
987b1903ae083dda87f9179e03dc4cbd7eb4e0e4	large child pornography ring busted in texas		But because not all law enforcement officers are familiar with technology, not all departments are trained to effectively deal with the problem.“It’s really a new area for police”, Fairstein said. An “unevenness of response” exists based on how technologically sophisticated and well-funded law enforcement is, she said. Large cities are more likely to have a computer crimes unit, whereas smaller departments often are unable to specialize.“They’re not equipped to handle it right now”, agreed Morgan Wright, a former Kansas state trooper and police detective who heads up the advanced training unit of the International Association of Computer Investigative Specialists in Virginia.“It’s not that they don’t want to, it’s just that they haven’t been trained.”	certified forensic computer examiner;cybercrime;morgan	Bill Hancock	2000	Computers & Security	10.1016/S0167-4048(00)04014-1	internet privacy;computer security	Arch	-64.79992863507928	-20.95081609718966	187446
8596b7bc50416f4a82dd2d5fc1a7e5e1ce1f7e5f	phyllis s. morgan. n. scott momaday: remembering ancestors, earth, and traditions: an annotated bio-bibliography. norman: university of oklahoma press, 2010. 396p. alk. paper, $39 (isbn 9780806140544). lc2009-030036		"""The enormous contributions made by N. Scott Momaday (b. 1934) to Native Ameri-can culture and modern literature are on brilliant exhibit in this bio-bibliography from the University of Oklahoma's celebrated American Indian Literature and Critical Studies series. While the bio-bibliography format is a departure for this series, which is otherwise populated with novels, anthologies, and critical essays, the quality of Phyllis S. Morgan's work lends this book the authority and gravity required to match the Press' reputation in the field of Native American Studies. Morgan's portrait of the acclaimed Kiowa writer is divided into three parts, a biography and chronology, a thoroughly collected and classified annotated bibliography of Momaday's works, and an equally thorough account of works about Momaday and his writing. Together these sections animate for the student and researcher of both Native American literature and literature in general the work of one of the world's great writers. For the casual lover of poetry and fiction, Morgan's composition of a life entwined in stories and letters is also a portrait of the social life of the arts and a reminder that the craft of literature, in its highest form, draws from and amplifies the experience, place, and spirit of the artist. The volume is set in motion by Kenneth Lincoln's evocative introduction. Here the Pulitzer Prize-winning Momaday is placed in the nested contexts of Kiowa traditions, the culture of mid-century New Mexico, the Native American Renaissance , and the wider world of letters. By liberally quoting Momaday's poems in his introduction, Lincoln prepares the reader for the bio-bibliographic tour that follows. In fact, the clarity and strength of Momaday's voice are allowed to echo throughout the volume. Morgan's biographic essay, """" A Life in a Rich and Exotic World, """" maps Moma-day's life by marking transitions that coincide with his travels. The reader is furnished with a map to chart the episodes her biography unfolds. Ample space is devoted to chronicling Momaday's formative years, his childhood in New Mexico, his family, and his education and college years. Morgan then describes each of Momaday's residences in higher education as a professor of literature and as an accomplished author. She sketches his associations and his collaborations, but she also captures the structure of feeling that he develops as he endeavors to take each place he inhabits into his identity and work. The chronology that follows further underscores a theme made so …"""	british informatics olympiad;international standard book number;item unique identification;map;morgan;population;renaissance;theme (computing)	David Michalski	2010	C&RL		library science;bibliography;computer science;environmental ethics	HCI	-63.49671370451513	-20.60047170351375	188280
50936acff42ea9cff389e6f0b59a24245c838fde	incentivizing reproducibility		A SCIENTIFIC RESULT is not truly established until it is independently confirmed. This is one of the tenets of experimental science. Yet, we have seen a rash of recent headlines about experimental results that could not be reproduced. In the biomedical field, efforts to reproduce results of academic research by drug companies have had less than a 50% success rate, a resulting in billions of dollars in wasted effort. b In most cases the cause is not intentional fraud, but rather sloppy research protocols and faulty statistical analysis. Nevertheless, this has led to both a loss in public confidence in the scientific enterprise and some serious soul searching within certain fields. Publishers have begun to take the lead in insisting on more careful reporting and review, as well as facilitating government open science initiatives mandating sharing of research data and code. But what about experimental computer science? Fortunately, we haven't been in the headlines. But, it is rare for research studies in computing to be reproduced. On the surface this seems odd, since we have an advantage over science done in wet labs. For us, the object of study is often software, so it, along with the associated experimental scaffolding , is a collection of bits that can be easily shared for the purpose of audit and inspection, for an assisted attempt at replication, or for building upon the work to advance science further or to transfer technologies to commercial use. Certainly the situation is a bit more complex in practice, but there is no reason for us not to be leaders in practices that enable audit and reuse when technically and legally possible. Some communities within ACM have taken action. SIGMOD has been a true pioneer, establishing a reproducibility review of papers at the SIGMOD conference since 2008. The Artifact Evaluation for Software Conferences initiative has led to formal evaluations of artifacts (such as software and data) associated with papers in 11 major conferences since 2011, including OOPSLA, PLDI, and ISSTA. Here the extra evaluations are optional and are performed only after acceptance. In 2015 the ACM Transactions on Mathematical Software announced a Replicated Computational Results initiative, c also optional, in which the main results of a paper are independently replicated by a third party (who works cooperatively with the author and uses author-supplied artifacts) before acceptance. The ACM Transactions on Modeling and Computer Simulation is also now doing …	computer science;computer simulation;experiment;mathematical software;programming language design and implementation	Ronald F. Boisvert	2016	Commun. ACM	10.1145/2994031	theoretical computer science;computational science;reproducibility;computer science	SE	-65.67486833380124	-19.933267099670104	188909
60a68ac1027c063e642bfc1f9947daee143e5af2	running a computer efficiently	computational efficiency	The title of this paper may be presumptuous , but it may be considered a goal if not an achievement. The paper describes some methods which have been adopted in the Computation Centre towards efficient operating of the computing laboratory based on FERUT, the Ferranti Electronic high speed digital computer at the University of Toronto. The difficulties which arise are much like those found in other computing laboratories. Briefly these difficulties are: 1. Operations can be limited by lack of problems, programmers, or machine time, and it is desirable to have a schedule with these factors in good balance. 2. There are university, government, and commercial groups working almost independently on the computer and the exchange of information must be made easy. 3. It is easy to waste time on the computer , and standard practices should be set up to help operators use sensible methods for program development and production work. 4. Good machine time is a valuable commodity and accurate records must be kept for each of the machine users. Since the Computation Centre depends upon earned income to supplement its grants, a realistic system of cost accounting must be found or financial ruin will result. Before showing how we try to meet the difficulties, the organisation of the Computation Centre will be briefly described. FERUT was purchased by the National Research Council and Defence Research of Canada who make it available, along with an annual grant, to the University of Toronto Computation Centre. The Centre undertakes to provide, without further charge, twenty hours** per month of good machine time to each of the National Research Council, the Defence Research Board, and the Atomic Energy Company of Canada. Time over and above this is purchased at standard commercial rates. Each of the three above organisations has a full-time programmer at the University, and the Computation Centre staff provide advice and extra programming help. Other groups who have either purchased time or had problems run for them include the Hydro Electric Power Commission of Ontario, the A. V. Roe Company of Canada, the Dominion Observatory, the Manufacturers Life Assurance Company, Eastman Kodak, Ray-theon, the Texaco Corporation, and various persons at the University of Toronto and other universities. 1. Before we acquired FERUT, we had been using I.B.M. Machines and there was a fair backlog of computing experience and problems. It is now clear that there is more than enough …	computation;computer;programmer;utec	Calvin C. Gotlieb	1954	J. ACM	10.1145/320776.320781	computer science;mathematics;cost efficiency	Theory	-68.8315340156985	-23.855335286367605	188927
e92781bd91c8e35179069f3f20aec0499c5b4b24	digital reunification of the parthenon and its sculptures	resource constraint;parthenon;reconstruction;structured light;archaeology;sculptures;3d scanning	The location, condition, and number of the Parthenon sculptures present a considerable challenge to archeologists and researchers studying this monument. Although the Parthenon proudly stands on the Athenian Acropolis after nearly 2,500 years, many of its sculptures have been damaged or lost. Since the end of the 18th century, its surviving sculptural decorations have been scattered to museums around the world. We propose a strategy for digitally capturing a large number of sculptures while minimizing impact on site and working under time and resource constraints. Our system employs a custom structured light scanner and adapted techniques for organizing, aligning and merging the data. In particular this paper details our effort to digitally record the Parthenon sculpture collection in the Basel Skulpturhalle museum, which exhibits plaster casts of most of the known existing pediments, metopes, and frieze. We demonstrate our results by virtually placing the scanned sculptures on the Parthenon.	organizing (structure);sequence alignment;structured light	Jessi Stumpfel;Chris Tchou;Nathan Yun;Philippe Martinez;Tim Hawkins;Andrew Jones;Brian Emerson;Paul E. Debevec	2003		10.2312/VAST/VAST03/041-050	structured light;computer science	HCI	-67.39863617006323	-20.615988155278863	189786
ed507ae52bb89c3f33944e71cab21a5fa2d07039	est clustering at geniusnet, the german embnet node		"""1 1 3 3 5 8 10 14 16 21 25 27 Editorial It is the end of 1998 and its been an interesting year. EMBnet celebrated its tenth anniversary. The genome of Caenorhabditis elegans was finally finished, more or less on schedule. After several static years, a new gapped version of Blast was released. SRS and Swissprot both went commercial. Although commercialisation is often viewed as a """"bad thing"""" by academics, it can have some very positive fallout. If carried out sensibly it should guarantee income enough to ensure continuity. It should also provide the salaries of those who will continue to maintain and develop products which are useful to the entire community. Getting paid also puts an obligation on the product or service provider: to write that tedious but necessary manual and documentation, and to respond to users questions and suggestions quickly and effectively. It is obvious to those of us in the EMBnet community that the infrastructure which EMBnet nodes provide is an essential part of world bioinformatics. Training, documentation , advice, consultancy, specialised and local databases, software development and hardware maintenance are all vital underpinnings of effective research. Unfortunately, those who use and appreciate the services that the nodes provide are rarely those responsible for supporting and funding them. So we have seen several disruptive """"rationalisations"""" across our community in recent months. SEQNET, the United Kingdom National Node, has been united with the HGMP-RC, one of the Specialist EMBnet Nodes located on the Hinxton Genome Campus. Let us hope that this merger will be transparent to users and have all the positive benefits that the responsible funding agencies hope for and expect. A much less agreeable and well-planned change has occurred at the Netherlands EMBnet node. We understand that the manager of the EMBnet grant from the European Union, Jan Noordik, is on """"indefinite leave of absence"""" while the role of the CAOS/CAMM Centre is reconsidered. It is to be sincerely hoped that such local goings-on will not have an adverse effect on EMBnet as a whole; EMBnet cannot and should not interfere in local arrangements. Jan has been a tireless supporter and promoter of EMBnet over the last decade. He deserves and will surely receive the support of the entire EMBnet community. This issue of embnet.news gives us a seasonal overview of networks in a big country by Christoph Sensen. An interview with Peter Stoehr, …"""	blast;bioinformatics;database;documentation;embnet.journal;fallout;jan bergstra;schedule (computer science);scott continuity;software development;uniprot	Martin Ebeling;Peter Ernst;Mechthild Falkenhahn;Karl-Heinz Glatting;Agnes Hotz-Wagenblatt;A. Kühl;Ge Zhang;Sándor Suhai	1998			bioinformatics;cluster analysis;embnet;biology;german	Metrics	-64.71616263265244	-20.404468065263927	189962
46402a98b49e19e7e705ff20c0d2d6464cb9ede3	not for the love of money: pursuing a library career	library school;librarianship;motivation	Purpose – The purpose of this article is to describe the reasons people decide to attend library school. Design/methodology/approach – The article focuses on motivations discussed in the relevant literature. Findings – The article finds that service to others is a consistent reason for entering the profession. Originality/value – The article is the author’s farewell.	love of money	Norm Medeiros	2014	OCLC Systems & Services	10.1108/OCLC-01-2014-0002	motivation;law	HCI	-67.6989847457052	-22.461499084909573	190709
7ccbfb8c46bb989a8426d7a29921946305d46630	urls link rot: implications for electronic publishing	computers;medicines;ahi;parasomnias;mathematics;cpap;agricultural;http errors;forensic journals;bruxism;subject wise publications;forensic;rdi;osa;biology;search indianjournals;osas;toxicology;snoring;ohs;social science;subject wise journals;applied science;e publishing;research articles;indian publications;restless leg syndrome;environment;wayback machine;link rot;eds;non invasive ventilation;obesity;insomnia;statistics;indianjournals;web citations;medicine;agriculture;plant research;sleep disorders;biotechnology;management;dental devices;mask;indian journals;indianjournals with advance search;veterinary	In recent years the authors of scholarly publications have relied on e-resources. But e-resources have raised the question of permanency on the web. In this context, this article investigates the availability, persistence of Uniform Resource Locator (URL) citations cited in two Library and Information Science (LIS) journal articles published by Emerald Publishers during 2008 and 2012. In total, 2477 URLs cited in 406 research articles published in two LIS journals spanning a period of five years (2008– 2012) were extracted. The study found that 23.81 per cent (2, 477 out of 10, 400 references) of URLs were cited in these journal articles. 49.53 per cent of URL citations were not accessible and the remaining 51.47 per cent of URL citations were still accessible. The study used W3C link checker to identify HTTP errors associated with missing URLs. HTTP 500 error message—‘page not found’ was the overwhelming message that represented 39.18 per cent of all HTTP error messages. This study attempts to focus on URLs link rot and its implications for electronic publishing.	link rot	D. Vinay Kumar;B. T. Sampath Kumar;D. R. Parameshwarappa	2015	World Digital Libraries	10.18329/09757597/2015/8105	alternative medicine;medicine;world wide web	HCI	-66.39191500675607	-17.806223620449455	191424
cee7f77e99330ecd6f3f1a2e19a34045c23f6715	universal system for creating and applying: electronic encyclopaedias for the internet	encyclopedias	Electronic encyclopedias are intended both for the general user and the professionals seeking consultation. Those encyclopedias has a special place in the electronic libraries since it has the possibility to construct search systems that provides automatic answers to intellectual inquiries of the information consumers. The special approach to the organization of document storage as knowledge bases, makes the application of electronic encyclopedias for the users problems decision possible, with the help of knowledge processing procedures. The work on creating the universal system VEDA to construct electronic document storehouses and mechanisms of their processing are conducted in the Internet center of the Kuban University.	knowledge base;library (computing)	K. I. Kostenko;B. E. Levitskij	2000			world wide web;the internet;chain drive;pressing;transverse plane;stringer;oscillation;computer science	ECom	-69.83995189992731	-22.984716750001056	191595
205221a7a0750caa9f1c553125bcc97378e54815	book review: competing with knowledge: the information professional in the knowledge management age	knowledge management	This book is presented as a practical handbook of 'Knowledge Management' and is ‘essential reading... for those seeking career development through Knowledge Management’ (from the blurb). It claims it is ‘about the emerging knowledge economy, how that economy is changing the way people live and work, and the environment and organizations in which they move’ (from the introduction). The target readership is threefold; firstly, those ‘intrigued by knowledge management and the emerging knowledge economy’, secondly, ‘information professionals’ who will be stimulated ‘to continue to explore the potential impact on their careers and work’ and thirdly, ‘those from other professions and backgrounds’ whose interest in the relevance and value of information management (my italics) skills’ will be further engaged. However, none of these groups is likely to be satisfied by this book because the authors themselves do not appear to be clear about what Knowledge Management is. To say it is ‘managing the balance of people, processes and technology that determines the organization and its relationship with its market’ (p. 37) hardly distinguishes it from normal management practice. The aims, which are to ‘know what you know, learn what you need to know and use knowledge effectively’ (p. 39) are equally valid but unexceptional and do not justify the considerable claims for Knowledge Management. For example, a promotional leaflet from MCB University Press Journal of Knowledge Management starts off: ‘What makes an organization really valuable? How is it that some companies can increase their book value or equity by 900%? Take, for example, Intel. In their 1996 Annual Report the company reported $24 billion in assets. The market value of their shares at this time was $110 billion.’ – actually just over 450 per cent. The publishers of this journal claim that what rendered the company profitable was its ‘grasp of the principles that underpin Knowledge Management’, which is a very grand claim. It is this sort of hyperbole and statements such as ‘There is no universally accepted definition of the term [knowledge management], perhaps reflecting its essential character, its unique interpretation by the organization that adopts the philosophy’ (from the book under review) that make many library and information professionals doubt whether it is anything more than an attempt to aggrandize what library and information professionals already do. I want to begin by considering whether Knowledge Management is in fact a subject or a theory. It is aligned with two complementary theories. The first is that of the knowledge economy – a theory that dates back to the early 1960s when management guru Peter Drucker was contending that knowledge had become the foundation of the modern economy, as we have shifted ‘from an economy of goods [to]... a knowledge economy’ (Drucker 1969). It is now argued that we have evolved into a society where the ‘distinguishing characteristic... is that knowledge and organization are the prime creators of wealth’ (Karunaratne 1986). The second theory is that of the ‘Information Society’ of which Daniel Bell is generally seen as the progenitor. He sees in the emergence of a white collar society (and hence, information work) and the decline of industrial labour, changes as profound as the end of class-based political conflict, more communal consciousness, and the development of equality between the sexes. In Bell's view, knowledge has become the most important production factor in modern economies. It is the basis of the exercise of power, it produces gains in productivity, and it ensures business competitiveness. What we have, therefore, is a post-industrial theory of business and society. However, none of this theory is mentioned in the book under review, and this is I think because the authors do not recognize Knowledge Management as a theory but as a skill. However, in a sentence which might have come from Drucker, they write ‘The wealth of a nation no longer depends on its ability to acquire and convert raw materials, but on the abilities and intellect of its citizens and the skills with which organizations harness and develop these abilities.’ (p. 4). In fact, throughout the book the authors display an uncertainty about whether what they are discussing is a practical attribute or a theory of society. This essential problem is caused by the vagueness of the subject. For example, ‘People in KM positions represent a wide variety of educational experiences ... The understanding of sociology, anthropology, linguistics and organizational behaviour is an essential part of KM ... More significant (my italics) is that the team members bring a wide variety of experience to the job.’ (p. 100). What Knowledge Management requires is Renaissance Woman or Man. This feeling that anything goes in Knowledge Management is exacerbated by the provision of all sorts of	consciousness;emergence;experience;information management;information professional;intellect;knowledge management;leaflet;need to know;organizational behavior;relevance;renaissance;theory;vagueness	Edward Dudley;Alasdair MacNaughtan	2001	JOLIS	10.1177/096100060103300410	organizational learning;data management;computer science;knowledge management;knowledge engineering;management science;sociology;information management;personal knowledge management	AI	-64.6730852237399	-22.6650851688513	191912
13f855912159cbe683b73fa998fdee8abfc181b4	computer technology in data-base publishing	production system;chemical engineering;information dissemination;information service;chemical structure;scientific and technical information	The experience and the expectations of a large scientific society publisher of chemical and chemical engineering information tools provide a broad context for considering the history and probable future impact of computer technology on information dissemination. Chemical Abstracts Service (CAS) was in good health for half a century before computer technology was available in practical application to the production of information services. It is now in satisfactory technical and economic health largely because computer technology is available.  Early applications of computers to practical word and chemical structure manipulation were for the most part probes to determine how, or even if, the machines could be useful. Today the computer is the heart of the CAS production system in the same sense as the reactors are the heart of a chemical plant. Regardless of the forms or media of the output, the computer is essential to their production.  The future sees computers as the means by which all scientific and technical information dissemination activities can be helped to coordinate their functions and improve their services to information users.	computer;database;production system (computer science)	D. B. Baker;R. E. O'Dette	1977		10.1145/1499402.1499478	computing;computer science;engineering;management information systems;operations research	HPC	-68.96480904625331	-20.2264891310275	192218
dcc11d27c64bd7ab9375904bc62da3ccb9416e3e	digital image processing, 4th edition	digital image processing;image processing	he second edition of Pratt’s Digital Image rocessing has been a well-thumbed memer of the reviewer’s library for a number f years. As the author states in the preface o the fourth edition, this book is an “inustrial strength” introduction to digital mage processing. Collected in one place re discussions of most image processing opics, complete with extensive references o key papers in each arena. When asked to olve a new problem, or create a new soution for an old problem, the reviewer freuently starts with Pratt to see how others ave previously addressed the topic. More nteresting, perhaps, is the ability to review ther seemingly unrelated topics in the hance to realize new linkages and syneries that can result in invention. The trength of Digital Image Processing in his regard is the easy accessibility of the ext for the nonexpert on any given topic. ach subject is treated concisely with all he advanced details left to the cited refernces. One quickly gets the gist of the roblem and its basic solutions. In short, his book provides a painless entry into the arious arenas of digital image processing. It is an inherent liability of any encylopedic work that new important topics urface and beg for inclusion. This is the tated motivation for the subsequent ediions of this book. Also new to the fourth dition is the PIKS Scientific API software upplied as a CD affixed to the back cover f the book. With interest in these updates, he reviewer decided to add the fourth ediion to his library. The book is divided into six parts. Part on Continuous Image Characterization is argely the obligatory review of basic Fouier mathematics, the human visual system, nd photometry and colorimetry. In keepng with the brief expositional tone of the ook, one finds largely just an organized resentation of the essential results with eferences to the classic texts in the field uch as Goodman’s Introduction to Fouier Optics and Wyszecki and Stiles’ Color	accessibility;application programming interface;digital image processing;ext js javascript framework;gist;knuth–morris–pratt algorithm;on-off keying	William K. Pratt;James E. Adams	2007	J. Electronic Imaging	10.1117/1.2744044	computer vision;image analysis;dynamic imaging;analog image processing;color image;image processing;computer science;digital image processing;digital imaging;microscope image processing;automatic image annotation;digital image	Graphics	-63.01600559460086	-19.31965891169413	192355
31a6294c2548c7c147cc7161e321889dbd300c71	patents: when they make sense and when they do not	legal aspects;technological innovation;patents copyright protection legal aspects technological innovation;invention patent protection;copyright protection;patents	News stories involving patents appear to be never ending. Some patent lawsuits result in awards in millions, tens of millions, and occasionally hundreds of millions of dollars or more for the patent owners. Some patent lawsuits result in invalidation of patents and assessments of attorney fees against the losing patent owners. Patent law seems to be in constant flux: court cases frequently introduce new changes into the law through their decisions and Congress seems to frequently change the patent law through a series of legislations. Debates rage on whether there are too many patents and whether certain technologies should be even eligible for patenting. All of this can generate some uncertainty as to whether pursuing patents makes sense for an engineer with an invention or the engineer’s company. Engineers and companies can benefit from considering several factors when determining whether pursuing patents makes sense. I . PURPOSES FOR A PATENT	ati rage;mechatronics;peer-to-patent;proceedings of the ieee	Christopher R. Hutter	2016	Proceedings of the IEEE	10.1109/JPROC.2016.2526606	engineering ethics;engineering	DB	-66.42847359861933	-20.189778368445182	194037
09017c94b5b7163e5e092754100908d98446c65f	a new era for research and development?	dp industry;research and development management;academic research community research and development computer industry companies investments economy;research and development;dp industry research and development management;internal standard;research and development educational institutions us government industrial relations computer industry computer science collaborative software industrial economics environmental economics technological innovation	0 7 4 0 7 4 5 9 / 0 2 / $ 1 7 . 0 0 © 2 0 0 2 I E E E A cursory glance at the computer industry’s spending on research and development might draw attention to individual companies’ investments. In a continued tight economy, expenditures on blue-sky research might seem especially dispensable. Yet industry R&D executives as well as academic researchers agree that focusing too sharply on one company’s addition or deletion of $100 million or $200 million from a $5 billion research budget might be akin to gauging the success of majorleague baseball by focusing on whether the New York Yankees trade a sixthor seventh-round draft choice for a player to be named later. Regardless of individual corporations’ spending, these experts say, the entire R&D environment is changing due to rapidly evolving technology, including converging computing and communications functions; innovative partnerships between the academic community and industry; the increasing importance of international standards bodies; and lastly, the US Congress’s flurry of activity in the wake of the 11 September terror attacks. This last factor might prove to be as critical to technology R&D as the Soviet Union’s 1957 launch of Sputnik was to jump-starting the US space program. “If we would have had this conversation before Sept. 11, I would have said I was very fearful we had stopped planting seed corn for the IT industry,” says Pat Gelsinger, chief technology officer at Intel. “All our fundamental research efforts were happening around microbiology. We had stopped investing in core IT infrastructure or materials research.” However, in the wake of the attacks, the House of Representatives’ Science Committee introduced two bills with far-ranging implications for researchers. HR 3394 allocates almost $900 million for cyber-security research, funneled through grants to the National Science Foundation and the National Institute of Standards and Technology. The House passed the bill, which is now in committee in the Senate. A companion bill, HR 3400, earmarks nearly $7 billion in R&D funding for six federal agencies (NSF, NIST, the Department of Energy, the National Oceanographic and Atmospheric Administration, and the Environmental Protection Agency), increasing R&D funding by 46 percent through 2007. That bill is currently in the Committee on Science, Space, and Technology. “I’m hopeful,” Gelsinger says, adding a note of caution. “If they’re really into real seed corn we in the industry can take advantage of, if it’s going to be a breath of fresh life into the DARPA of old, then I’m encouraged. If it’s in fact about cybersecurity that ends up being very near-term and narrowly focused in the defense space and we have to wait 20 years for it to come out of defense—and I don’t mean that in any way as a negative statement—it’s not going to have broader general impact on the general computer and information industry.” Mary L. Good, dean of the Donaghey College of Information Science and Systems Engiin the news	computer security;emoticon;general computer corporation;ibm notes;information science;sputnik;the new york times	Greg Goth	2002	IEEE Software	10.1109/MS.2002.1003466	engineering management;economics;engineering;software engineering;internal standard;management;economic growth	ML	-64.98141812209244	-20.207904131773134	195425
aeca6f169d8f52aa6d9ce72851e95ccef62cc202	semnet : the knowledge representation of lolita		The full-text may be used and/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for personal research or study, educational, or not-for-pro t purposes provided that: • a full bibliographic reference is made to the original source • a link is made to the metadata record in Durham E-Theses • the full-text is not changed in any way The full-text must not be sold in any format or medium without the formal permission of the copyright holders. Please consult the full Durham E-Theses policy for further details.	knowledge representation and reasoning;lolita	Sengan Baring-Gould	2000				Security	-66.63206898989044	-17.02552507901633	195500
2fabdd1604ef2a4ab8feec317066e415e3f3efcd	viewpoint: technological access control interferes with noninfringing scholarship	technological access control;noninfringing scholarship	When copyrighted works are distributed in digital form, publishers sometimes attach “technical access control”—such as encryption—that controls the mode of use. For example, an electronic book could be viewed but not printed, or a movie could be shown on a screen but not copied. However, technical access control prevents many kinds of uses of the material that would not be considered copyright infringement—making a copy for personal use, searching the material, and so on. Therefore, until 1998 it was legal for the owner of a copy of a copyrighted work to circumvent the access control for a noninfringing use. (Circumvention for the purpose of infringing on the copyright, for instance, redistributing copies, has never been legal.) The Digital Millennium Copyright Act of 1998 provides that “no person shall circumvent a technological measure that effectively controls access to a work protected under this title” and makes circumvention a federal felony. However, the Librarian of Congress is given regulatory power to exempt certain classes of work from the prohibition on circumvention of technical access restrictions. (It is interesting to note there is a quadruple negative in the law.) The Copyright Office of the Library of Congress has solicited public comment as part of the process of determining whether there are particular classes of copyrighted works that shall be exempted from the prohibition because persons who are users of those classes of works “are, or are likely to be in the succeeding threeyear period, adversely affected by virtue of the prohibition in their ability to make noninfringing uses of that particular class of works under this title.” Public comments (including this one) can be viewed at the Library of Congress Web site (lcweb.loc.gov/ copyright/1201).	access control;digital millennium copyright act;e-book;encryption;librarian;printing;quadruple-precision floating-point format	Andrew W. Appel;Edward W. Felten	2000	Commun. ACM	10.1145/348941.348968	knowledge management;management	Security	-66.70499213584101	-18.487700723076333	195902
fb459afda0216c7a157799f7cbaffeb72ac02c5c	risks to the public		Edited by Peter G. Neumann (Risks Forum Moderator and Chairman of the ACM Committee on Computers and Public Policy), plus personal contributions by others, as indicated. Opinions expressed are individual rather than organizational, and all of the usual disclaimers apply. We address problems relating to software, hardware, people, and other circumstances relevant to computer systems. To economize on space, we include pointers to items in the online Risks Forum: (R i j) denotes RISKS vol i number j. Cited RISKS items generally identify contributors and sources, together with URLs. Official RISKS archives are available at www.risks.org (which redirects to Newcastle and gets you nice html formatting and a search engine courtesy of Lindsay Marshall; http://catless.ncl.ac.uk/Risks/i.j.html gets you (R i j)) and at ftp://www.sri.com/risks .	apply;archive;computer hardware;google moderator;html;pointer (computer programming);web search engine	Peter G. Neumann	2008	ACM SIGSOFT Software Engineering Notes	10.1145/1344452.1344457		Web+IR	-65.86325000279611	-17.865369010235458	196053
3f56a496c4c7420787ab04a231c79c71bf7d6e51	business: new kid on the block: marketing organizations and interaction design	interaction design	Sometimes the things that are frustrating about a project turn out to be the most valuable aspects. We recently worked with a company that recognized the necessity of usable design to the success of their e-commerce strategy. But, they were not sure how to plan for usability, so they turned to us for help. The project team had many questions that just begged for an organizational study, but no one wanted another report filled with recommendations that would sit on the shelf. Instead, the clients agreed to have us demonstrate a usability evaluation on a Web site. We assured them that, in a real-life evaluation like the one we were about to undertake, the important organizational issues would emerge naturally. Rather than merely talking about them, we could begin to solve them. The marketing staff were considered a key stakehold-er. Not only did they buy into the importance of usabil-ity, but they also had a lot of input into the e-commerce strategy. Furthermore, they might use an eventual in-house usability lab for focus groups—and might even be the ones to administer it. Plus, because they already had experience with screeners, knew about the market seg-mentation, and were the internal experts in interviewing and facilitating, they were designated as our main collaborators for setting up the study. It looked like Marketing had been put in the driver's seat for this project and might be establishing itself as the eventual organizational owner of usability. As we rolled up our sleeves to work with the lead marketing representative, things got interesting right away. The time we spent negotiating every aspect of the study seemed much greater than usual. Time was consumed in going over minutiae of the evaluation script, which the marketing person thought must be followed verbatim. The list of highly structured questions she wanted in the protocol kept growing. Her emphasis on constructing rating scales to measure user opinions of the site began to remind us of a graduate course in psychometrics. She also believed that the sample had to closely reflect the com-pany's existing off-line customer base, including matching its complex segmentation. So many decision rules	e-commerce;energy (psychological);focus group;interaction design;minutiae;online and offline;real life;usability lab	David A. Siegel	2001	Interactions	10.1145/361897.361908	public relations;human–computer interaction;computer science;engineering;marketing;interaction design;advertising	HCI	-65.97768373879225	-23.201801477137046	196387
600e74c1bfd9dbc9134a664401fb7e976ae9b979	#1reasonwhy: game communities and the invisible woman		As Cliff Bleszinski [6] states in his blog post the video game community has its own type of religious police charged with enforcing a doctrine regarding gender representation within the gaming community. From the difficulties faced by Anita Skareesian to the resignation of Jennifer Hepler, women who are visible within the industry regularly face threats from the very people who claim to be their entertainment comrades. With the rise of the #1ReasonWhy hashtag on Twitter in 2012, the experiences of women who aren’t in gaming community’s spotlight were also brought to the forefront. This paper uses a thematic analysis of tweets made between November 26th 29th in the #1ReasonWhy to examine how the explicit and implicit threats of violence, rape, and harassment have manifested within the working world of game development. Through examination of these tweets the authors will show how these threats both from the general gaming community and inside the office workspace shape the experiences of women and continue the decades long cycle of limited participation by women. The authors point out how the cultural dialogue about the potential good games offer to our society may be outweighed by the hostile community climate which places those who could benefit most at risk.	blog;dbpedia;experience;hashtag;microsoft forefront;sumlock anita calculator;video game development;virtual woman;virtual community;workspace	Bridget Marie Blodgett;Anastasia Salter	2014			simulation;multimedia;computer science	HCI	-65.37687855256655	-22.04415574559659	197255
a0e227176ae2c828ae7b760207ee52083317c344	20 years of computers and informatics in austria's secondary academic schools	new technology;information technology;technologie information;informatique theorique;enseignement;educacion;tecnologia informacion;teaching;computer theory;ensenanza;informatica teorica	The way in which Austrian schools have reacted to the needs of a growing digital society has been, all things considered, a success story. This is remarkable as schools in general are not necessarily places where excessive progress takes place. Many teachers are rather conservative and not willing to take part in every new promising development unless they are fully convinced of its benefits. This applies especially to teachers who are now confronted with introducing new technologies. Unlike the more or less established subject Informatics, the overall penetration of information technology in education is still at the beginning. We have to remember that the present situation has not appeared from nowhere, but has to be seen as a result of a comparatively short, but all the more turbulent history with roots already in the seventies. The official start for the subject Informatics in the secondary academic schools in Austria (AHS) can be dated back to 1985 when all these schools have been equipped with computers for the first time. “History does nothing; it does not possess immense riches, it does not fight battles. It is men, real, living, who do all this” is a quotation from Karl Marx and can be applied very well to the development of Informatics in Austrian general educating schools. Even if the visible changes in hardware, software and curricula are remarkable enough it should be pointed out that this short history was a history of people behind these developments, enthusiastic teachers as well as responsible policy makers in that field.	informatics	Peter Micheuz	2005		10.1007/978-3-540-31958-0_3	computer science;artificial intelligence;operations research;information technology;algorithm	NLP	-65.27866384516952	-23.903634746457605	197755
2b26d94cae5b99300633e586c2fc45c782d6dbcc	on-line serials control system in a large biomedical library: 1) description of the system	medical libraries;library technical processes;control system;online systems;library automation;serials	Abstract#R##N##R##N#An on-line serials control system with particular emphasis on storage and maintenance concepts is described. The system, operational since January, 1971, has evolved from a former batch card system and remains completely compatible with it. The system allows real-time display and updating of all elements of the file. Consequently all check-in, bindery, and claims operations, as well as new entries and data field changes are accomplished on a real-time basis. All programs are in PL/1. Required equipment is an IBM time-shared facility with 100 K memory available for the applications programs, and IBM 2260 display units.#R##N##R##N##R##N##R##N#This article is the first of three. The second is concerned with an analysis of inverted file retrieval features and the third compares the operation of the on-line with the batch system, comparable manual operations, and discusses costs.	control system	James Fayollat	1972	JASIS	10.1002/asi.4630230507	library science;computer science;control system;database;world wide web;information retrieval	Robotics	-69.813744267565	-23.134977021504774	197956
1be8b0116869ddd3ff4b4ce142914a1ef53f690f	the second-order effects of steve jobs	second order;developpement logiciel;new technology;internet apple computers dp industry innovation management;conversations with computing;dp industry;innovation steve jobs apple products next products internet world wide web;apple computers;steve jobs;innovation management;innovation;internet;desarrollo logicial;software development;conversations with computing apple steve jobs;estructura producto;apple;innovacion;structure produit;product structure	M uch has been written about Steve Jobs’ amazing leadership at Apple and how he transformed the company into one of the world’s most recognizable and profitable brands after his return from NeXT. But if you look closer, it’s easy to find examples of how Jobs-inspired Apple and NeXT products were platforms for many of the amazing innovations we take for granted today. Between 1987 and 1997, we experienced a Cambrian-like explosion of completely new ideas bursting from computer science research labs into broader society at an unprecedented rate. Although Jobs wasn’t directly involved in the innovations around the Internet and World Wide time you clicked here [on the NeXT], you had another window, every time you clicked on a diagram, you had the diagram in another window, when you clicked on a map, you got the map in PostScript, scalable and perfectly printable.	computer science;diagram;internet;postscript;scalability	Charles R. Severance	2012	IEEE Computer	10.1109/MC.2012.31	innovation;the internet;simulation;innovation management;computer science;artificial intelligence;software development;software engineering;management;computer security;second-order logic	Theory	-67.36913678891167	-21.686719232606173	199045
29bf37eedc63b9ba7b9fe43f4ded1f8efbdb6bfc	spreadsheet hell		This management paper looks at the real world issues faced by practitioners managing spreadsheets through the production phase of their life cycle. It draws on the commercial experience of several developers working with large corporations, either as employees or consultants or contractors. It provides commercial examples of some of the practicalities involved with spreadsheet use around the enterprise. 1 ACKNOWLEDGEMENTS The author would like to thank all the contributors from the smurfonspreadsheets blog for sharing their commercial experiences. 2 INTRODUCTION 60% of large companies feel 'Spreadsheet Hell' describes their reliance on spreadsheets either completely or fairly well. The same survey noted spreadsheet use at 100% of all respondents, the only universal technology. (Durfee, 2004). It’s pretty hard to overstate the importance of spreadsheets to modern business life. (Croll, 2005) found the City of London to be heavily dependent, with most respondents suggesting that spreadsheets were critical to the ongoing viability of the markets and by extension of the City itself. So we have a completely business critical resource, perhaps like the corporate network or email, and yet in general there appears to be no identifiable person or body responsible for managing it. In many organisations the responsibility falls through the gap between the IT department and the business users. Or it did, Sarbanes Oxley raised the profile of what was once every organisations dirty little secret. 3 BACKGROUND Here are some approximate timings of recent representative spreadsheet based projects undertaken by the contributors: 1. Development = 3 months, live so far 14 months 2. Development = 6 months, live so far 4 years 3. Development = 12 months, live so far 9 years 4. Development = 5 months, live so far 7 years In all cases the development phase was less than 25% of the total live to date figure, in some cases it is less than 10%. And yet much of the documentation seems to focus on	approximation algorithm;blog;documentation;email;hacker croll;spreadsheet	Simon Murphy	2007	CoRR			HCI	-66.41329205430978	-21.237615897948046	199373
01ac6d7a77440306e5affe93bba3d4d79e4c39a4	accessibility and decay of web citations in five open access isi journals	decay;open access publishing;internet research;electronic resources;inter computer links;accessibility;web citation;open access;journals;uniform resource locators;online access	Purpose – The aim of this paper is to scrutinize the accessibility and decay of web references (URLs) cited in five open access social sciences journals indexed by ISI.Design/methodology/approach – After acquiring all the papers published by these journals during 2002‐2007, their web citations were extracted and analyzed from an accessibility point of view. Moreover, for initially missed citations complementary pathways such as using Internet Explorer and the Google search engine were employed.Findings – The study revealed that at first check 73 per cent of URLs are accessible, while 27 per cent have disappeared. It is notable that the rate of accessibility increased to 89 per cent and the rate of decay decreased to 11 per cent after using complementary pathways. The “.net” domain, with an availability of 96 per cent (a decay of 4 per cent) has the greatest stability and persistence among all domains, while the most stable file format is PDF, with an availability of 93 per cent (a decay of 7 per cent).Ori...	accessibility;information sciences institute	Mohammad Karim Saberi;Hoda Abedi	2012	Internet Research	10.1108/10662241211214584	internet research;computer science;accessibility;data mining;internet privacy;world wide web	Theory	-66.90513593180462	-17.741717649883302	199654
