id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
cf7edd3a5e92fb5591c41b871004b14403954b70	heap recycling for lazy languages	lazy functional programming;garbage collection;run time system;type based program analysis;compile time garbage collection;program analysis;functional language;functional programming language;semantics of programming languages	Pure functional programming languages preclude destructive updates of heap-allocated data. In such languages, all newly computed algebraic values claim freshly allocated heap space, which typically causes idiomatic programs to be notoriously inefficient when compared to their imperative and impure counterparts. We partly overcome this shortcoming by considering a syntactically light language construct for enabling user-controlled in-place updates of algebraic values. The resulting calculus, that is based on a combination of type-based uniqueness and constructor analysis, is guaranteed to maintain referential transparency and is fully compatible with existing run-time systems for nonstrict, pure functional languages.	computer recycling;functional programming;imperative programming;in-place algorithm;language construct;lazy evaluation;linear algebra;memory management;programming idiom;programming language;referential transparency	Jurriaan Hage;Stefan Holdermans	2008		10.1145/1328408.1328436	program analysis;fourth-generation programming language;first-generation programming language;declarative programming;uniqueness type;reactive programming;computer science;theoretical computer science;third-generation programming language;functional logic programming;programming paradigm;fifth-generation programming language;programming language theory;garbage collection;programming language;functional programming;second-generation programming language;comparison of multi-paradigm programming languages;algorithm;control flow analysis;semantics	PL	-21.527642958899712	24.458484310448448	160122
319932ff3d51905bb0557c8076982b1e6c22c8e9	on implementing prolog in functional programming	variable structure;programming language;functional programming;denotational semantic	This report surveys techniques for implementing the programming language Prolog. It focuses on explaining the procedural semantics of the language in terms of functional programming constructs. The techniquessuccess continuations andproof streams are introduced, and it is shown how Horn clause interpreters can be built upon them. Continuations are well known from denotational semantics theory, in this paper it is shown that they are viable constructs in actual programs. Other issues include implementation of logical variables, structure sharing vs. structure copying, determinacy, builtin predicates, andcut.	continuation;denotational semantics;functional programming;horn clause;indeterminacy in concurrent computation;operational semantics;programming language;prolog	Mats Carlsson	1984	New Generation Computing	10.1007/BF03037326	first-generation programming language;constraint programming;declarative programming;very high-level programming language;language primitive;horn clause;programming domain;reactive programming;computer science;theoretical computer science;functional logic programming;programming paradigm;procedural programming;symbolic programming;inductive programming;fifth-generation programming language;programming language theory;programming language;functional programming;prolog;logic programming;operational semantics;programming language specification;algorithm;semantics	PL	-22.59807400935794	23.141949629096647	160274
ef623900b89be332421e5776b5c41c2d1688fe86	a bottom-up adaption of earley's parsing algorithm	bottom up	"""I n t r o d u c t i o n : in a compiler for a standard programming language, parsing is surely the step which is, by now, the best handled. Although the design of an efficient error recovery scheme, for example, is a still difficult problem, most of the work may be automated using parser generators or, more generally, compiler-compilers [4]. Although parsing may no longer be a problem for programming languages, there are still areas where this automatic generation of parsers is not possible, due to the limited class of grammars which can be handled this way. This happens, for example, for the processing of natural languages, whose underlying grammars are ambiguous, or for the interactive environments built for the """"new generation of programming languages"""" (specification languages, functional or logic programming languages) which offer, often, a too restricted user-interface. These new programming languages, with a very high degree of abstraction, should include syntactical facilities to ease, as most as possible, the work for the user: presence of a flexible syntax, overloading of operators, user-defined coercions to introduce sub-types. . ."""	algorithm;bottom-up parsing;compiler;functional programming;logic programming;natural language;operator overloading;programming language;specification language;user interface	Frédéric Voisin	1988		10.1007/3-540-50820-1_46	terminal and nonterminal symbols;precomputation;parse tree;minification;parsing;algorithm;computer science;top-down and bottom-up design	PL	-24.53841570778043	24.439791511189053	160509
894e269bfa1401524e99cb5866593a8fb749012d	beluga: programming with dependent types, contextual data, and contexts	logical framework;programming language;functional programming;pattern matching;dependent types;functional language	The logical framework LF provides an elegant foundation for specifying formal systems and proofs and it is used successfully in a wide range of applications such as certifying code and mechanizing metatheory of programming languages. However, incorporating LF technology into functional programming to allow programmers to specify and reason about formal guarantees of their programs from within the programming language itself has been a major challenge. In this paper, we present an overview of Beluga, a framework for programming and reasoning with formal systems. It supports specifying formal systems in LF and it also provides a dependently typed functional language that supports analyzing and manipulating LF data via pattern matching. A distinct feature of Beluga is its direct support for reasoning with contexts and contextual objects. Taken together these features lead to a powerful language which supports writing compact and elegant	algorithm;automated theorem proving;church–rosser theorem;code coverage;compiler;correctness (computer science);dependent type;formal system;functional programming;interactivity;local consistency;logical framework;mathematical induction;natural deduction;pattern matching;programmer;programming language;prototype;quantifier (logic);recursion (computer science);subject reduction;twelf;type system	Brigitte Pientka	2010		10.1007/978-3-642-12251-4_1	fourth-generation programming language;first-generation programming language;dependent type;declarative programming;very high-level programming language;logical framework;language primitive;specification language;programming domain;reactive programming;functional reactive programming;computer science;functional logic programming;pattern matching;programming paradigm;procedural programming;symbolic programming;inductive programming;fifth-generation programming language;programming language theory;programming language;functional programming;programming language specification;high-level programming language;algorithm	PL	-22.581297082078084	22.738080291517917	161137
14042894669c599d64cfdeef0ac6f819c0df69a2	species and functors and types, oh my!	generic programming;automatic test generation;species library;basic theory;functional programming;language design;expressive language;combinatorial species;functional programming community;continued study;data type;algebraic data types	The theory of combinatorial species, although invented as a purely mathematical formalism to unify much of combinatorics, can also serve as a powerful and expressive language for talking about data types. With potential applications to automatic test generation, generic programming, and language design, the theory deserves to be much better known in the functional programming community. This paper aims to teach the basic theory of combinatorial species using motivation and examples from the world of functional programming. It also introduces the species library, available on Hackage, which is used to illustrate the concepts introduced and can serve as a platform for continued study and research.	function object;functional programming;generic programming;semantics (computer science)	Brent A. Yorgey	2010		10.1145/1863523.1863542	design process;data type;computer science;artificial intelligence;philosophy of language;combinatorial species;algebraic data type;programming language;functional programming;generic programming;theory;algorithm	PL	-24.75167130275795	21.16331829960351	161172
4b9d1c481af24a3d52abf0e255eb7db55822f71a	color: a coq library on well-founded rewrite relations and its application to the automated verification of termination certificates	computacion informatica;ciencias basicas y experimentales;matematicas;grupo a	Termination is an important property of programs; notably required for programs formulated in proof assistants. It is a very active subject of research in the Turing-complete formalism of term rewriting. Over the years many methods and tools have been developed to address the problem of deciding termination for speci c problems (since it is undecidable in general). Ensuring reliability of those tools is therefore an important issue. In this paper we present a library formalizing important results of the theory of well-founded (rewrite) relations in the proof assistant Coq. We also present its application to the automated veri cation of termination certi cates, as produced by termination tools. The sources are freely available at http://color.inria.fr/.	color;coq (software);correctness (computer science);dependent type;dershowitz–manna ordering;directory (computing);formal verification;hol (proof assistant);hugo thiemann;isabelle;path ordering (term rewriting);proof assistant;recursion;rewrite (programming);rewriting;semantics (computer science);termination analysis;turing completeness;undecidable problem;usability;verification and validation;word lists by frequency	Frédéric Blanqui;Adam Koprowski	2011	Mathematical Structures in Computer Science	10.1017/S0960129511000120	computer science;programming language;algorithm	Logic	-20.015364172333147	20.798303715145355	162069
a5a948ffded9f8822169e1bbec643456493f2527	implementing constraint imperative programming languages: the kaleidospace'93 virtual machine		Constraint Imperative Programming (CIP) languages integrate declarative constraints with imperative state and destructive assignment, yielding a powerful new programming paradigm. However, CIP languages are difficult to implement efficiently due to complex interactions between the two donor paradigms. Neither the virtual machines for classical object-oriented languages, nor those for existing constraint languages, are suitable for implementing CIP languages, as each assumes a purely imperative or a purely declarative computation model. We have developed a new virtual machine for CIP languages, the K-machine, an imperative machine with an incremental constraint solver and a constraint-based, rather than value-based, data store. This virtual machine allows user-defined constraints to be defined using constraint constructor definitions which are the CIP analog to method definitions. Similar to methods, these constructors are able to reference variables indirectly through many levels of pointers. The K-machine maintains relations between objects in the presence of state change to these indirectly referenced objects. The K-machine is capable of supporting a wide variety of CIP languages, including our most recent: Kaleidoscope'93.	assignment (computer science);constraint programming;data store;imperative programming;interaction;model of computation;programming paradigm;solver;virtual machine	Gus Lopez;Bjørn N. Freeman-Benson;Alan Borning	1994		10.1145/191080.191118		PL	-22.034861739129152	24.886622827572662	162108
559e02eb32fe70f20c490659ee72dc901e9fccf8	analysis of recursive types in lisp-like languages	recursive types;type checking;graph grammar	We introduce a new algorithm to analyze recursive, structured types. It derives information from object uses (accesser functions with type checking), as well as from object allocation. The type description is a form of graph grammar and is naturally finite even in the presence of loops. The intended use of the algorithm is to discover and remove unnecessary type checks, but it can be augmented to provide alias information as well.	algorithm;graph rewriting;lisp;recursion (computer science);structured type;type system	Edward Wang;Paul N. Hilfinger	1992		10.1145/141471.141544	computer science;recursive data type;theoretical computer science;algebraic data type;programming language;algorithm	PL	-21.832462931005267	24.37596041040359	162558
c2abfdfbc150980bf327a04d536e1456cfe68a22	globaldsl 2013: first workshop on the globalization of domain specific languages	programming language;language composition;modeling language;domain specific language;software language engineering;program composition;model composition	The first edition of GlobalDSL'13 in Montpellier has tried to bring together the programming language and model communities to work on the globalization of the domain specific languages. The experiment has been really exciting and we got some interesting cross-fertilizations of the two areas.	domain-specific language;experiment;programming language	Benoît Combemale;Walter Cazzola;Robert B. France	2013		10.1145/2489812.2489813	natural language processing;language identification;fourth-generation programming language;first-generation programming language;natural language programming;very high-level programming language;universal networking language;language primitive;object language;programming domain;computer science;domain-specific language;language industry;third-generation programming language;linguistics;compiled language;low-level programming language;modeling language;natural language;fifth-generation programming language;programming language;language technology;second-generation programming language;high-level programming language	NLP	-25.44343295462234	21.6434755788853	163237
db5c86b696c796e7fb336eb44dd0ca86fa144c84	a structure based measurement of software	theoretical model;cognitive modeling with heuristics;control flow graph;machine learning;learning strategy;data dependence;control flow;heuristics;graph model;structure analysis;generic programming	Graph models have been useful abstraction for examining the programmer's perspective of the static structure of imperative programs. A number of Graph models referring to control flow and data dependencies have appeared in the literature. The primary objective of this research is to develop a more general graph-theoretic model for describing programs written in arbitrary imperative languages and to compute a structural measure based on this abstraction. The proposed model is a synthesis of the control flow graph and the data dependency graph. This new unified abstraction, called the Generalized Program Graph (GPG), is structurally equivalent to the string from of a program. However, because of its graph structure, the new model is better suited for structural analysis of a program than original string form.	control flow graph;data dependency;gnu privacy guard;graph theory;imperative programming;programmer;structural analysis	Narayan C. Debnath	1989		10.1145/75427.1030288	dependency graph;computer science;clique-width;artificial intelligence;theoretical computer science;heuristics;machine learning;database;graph;structural analysis;moral graph;programming language;generic programming;control flow;algorithm;graph rewriting;control flow graph	SE	-22.276668100432975	24.99730004919047	163288
b5f2b63ec17522dca96846d1332cf5d3d923429b	compiling techniques for boolean expressions and conditional statements in algol 60	boolean expression;conditional statement;compiling technique	"""[n this note compiling routines will be described for Boolean expressions involving the operators V , / ~ and -1. The Boolean variables allowed include relational expressions. These routines will then be used in describing proeedures for compiling conditional statements and Boolean assignment statements as defined in AL(mL 60. Any at tempt to describe a general compiling algorithm immediately presents the following problem: If an algorithm is constructed to produce efficient object programs for a particular machine it will be a highly specialized routine. For this reason an intermediate language is being used for the object code of the compiling routines being developed at Berkeley. In this note """"object code"""" and """"object machine"""" will imply this intermediate language and a hypothetical machine whose order code is the intermediate language. Appendix I contains a description of those portions of the intermediate language which are used by the routines to be described in this paper."""	algol 60;algorithm;bsd;boolean expression;compiler;conditional (computer programming);object code	Harry D. Huskey;William H. Wattenburg	1961	Commun. ACM	10.1145/366062.366098	computer architecture;boolean expression;programming language;boolean data type;algorithm	PL	-25.848222461993693	24.912744197455208	163528
7de33f52bc4c8abdeed7025184fc53f7961f7548	test plan generation using formal grammars	formal grammar	A test plan generation algorithm is proposed for systems such as process-control systems or transaction-processing systems. Input to the algorithm is a description of the functional requirements for a given system. This is converted to an augmented finite state automaton (fsa) from which a regular grammar is derived. The grammar is used to generate test “sentences” each of which describes a sequence of stimuli to be applied to the system under test and responses required of the system under test.	test plan	Jonathan A. Bauer;Alan B. Finger	1979			grammar systems theory;natural language processing;context-sensitive grammar;id/lp grammar;synchronous context-free grammar;prefix grammar;operator-precedence grammar;regular grammar;computer science;regular tree grammar;formal grammar;context-free grammar;programming language;attribute grammar;unrestricted grammar;adaptive grammar;grammar-based code;stochastic context-free grammar;mildly context-sensitive grammar formalism;algorithm;lexical grammar	NLP	-24.63662589974268	19.696583166862883	163940
a9db4c67a37c9fdafa01f7d42471dbd76f5c0511	compiling embedded languages	optimizing compiler;embedded language;code generation;data type;image synthesis;code motion;functional language;domain specificity	Functional languages are particularly well-suited to the interpretive implementations of Domain-Specific Embedded Languages (DSELs). We describe an implemented technique for producing optimizing compilers for DSELs, based on Kamin's idea of DSELs for program generation. The technique uses a data type of syntax for basic types, a set of smart constructors that perform rewriting over those types, some code motion transformations, and a back-end code generator. Domain-specific optimization results from chains of domain-independent rewrites on basic types. New DSELs are defined directly in terms of the basic syntactic types, plus host language functions and tuples. This definition style makes compilers easy to write and, in fact, almost identical to the simplest embedded interpreters. We illustrate this technique with a language Pan for the computationally intensive domain of image synthesis and manipulation.		Conal Elliott;Sigbjorn Finne;Oege de Moor	2003	J. Funct. Program.	10.1017/S0956796802004574	data type;computer science;theoretical computer science;optimizing compiler;programming language;functional programming;algorithm;code generation	PL	-23.37514254853463	24.59837789066807	164149
1df9cfc54cd590360835e9d82c2a4027768fccb2	induction, domains, calculi: strachey's contributions to programming-language engineering	computer program;inductive definition;programming language;lambda calculus;denotational semantic;induction;denotational semantics;semantic description;semantic domains	In collaboration with his colleagues at Oxford, Christopher Strachey pioneered the analysis of programming languages in terms of semantic features. Three of Strachey’s contributions—inductive definition of semantics, semantic-domain definitions, and calculi for semantic description—are presented, and their consequences on languages research are described. Strachey’s impact, present and future, on the computer programming “mainstream” is also outlined.	computer programming;mathematical induction;programming language;recursive definition	David A. Schmidt	2000	Higher-Order and Symbolic Computation	10.1023/A:1010066127644	natural language processing;polymorphism;computer science;lambda calculus;programming language;denotational semantics;algorithm	PL	-24.188426197865773	21.38612640314085	165855
0515eb6274a9da574d3609518493fb47c09c0e83	formalizing openmp performance properties with asl	evaluation performance;representacion conocimientos;performance evaluation;evaluacion prestacion;lenguaje;conception;langage;specification language;analyse performance;performance analysis;diseno;design;lenguaje especificacion;language;knowledge representation;representation connaissances;langage specification;analisis eficacia	Performance analysis is an important step in tuning performance critical applications. It is a cyclic process of measuring and analyzing performance data which is driven by the programmers hypotheses on potential performance problems. Currently this process is controlled manually by the programmer. We believe that the implicit knowledge applied in this cyclic process should be formalized in order to provide automatic performance analysis for a wider class of programming paradigms and target architectures. This article describes the performance property specification language (ASL) developed in the APART Esprit IV working group which allows specifying performance-related data by an object-oriented model and performance properties by functions and constraints defined over performance-related data. Performance problems and bottlenecks can then be identified based on useror tool-defined thresholds. In order to demonstrate the usefulness of ASL we apply it to OpenMP by successfully formalizing several OpenMP performance properties.	bottleneck (software);estimation of signal parameters via rotational invariance techniques;openmp;profiling (computer programming);programmer;programming paradigm;property specification language	Thomas Fahringer;Michael Gerndt;Graham D. Riley;Jesper Larsson Träff	2000		10.1007/3-540-39999-2_41	knowledge representation and reasoning;design;simulation;specification language;computer science;artificial intelligence;language;programming language;algorithm	HPC	-25.71366981729917	24.67868330108412	166094
29b2b62555b21a3d4786cfccbbf41073e9d88d24	gipsy - a platform for the investigation on intensional programming languages	programming language		lucid	Joey Paquet;Aihua Wu	2005			very high-level programming language;programming language;comparison of multi-paradigm programming languages;fifth-generation programming language;fourth-generation programming language;third-generation programming language;programming language theory;second-generation programming language;programming domain;computer science	Robotics	-24.430187535494035	22.319274899950205	166111
49a18708cf31e03bfbebb79e1a0a019765d28447	abstract state machines and computationally complete query languages	machine abstraite;base relacional dato;query language;temps polynomial;abstract state machine;computer model;maquina abstracta;state machine;relational database;lenguaje interrogacion;abstract machine;temps calcul;polynomial time;base donnee relationnelle;langage interrogation;tiempo computacion;computation time;tiempo polinomial	state machines and computationally complete query languages Andreas Blass Mathematics Department University of Michigan Ann Arbor, MI 48109-1109 USA Yuri Gurevich Microsoft Research One Microsoft Way Redmond, WA 98052 USA research.microsoft.com/~gurevich/ Jan Van den Bussche University of Limburg (LUC) B-3590 Diepenbeek Belgium.	abstract state machines;microsoft research;query language;yuri gurevich	Andreas Blass;Yuri Gurevich;Jan Van den Bussche	2000		10.1007/3-540-44518-8_3	natural language processing;time complexity;relational database;computer science;artificial intelligence;theoretical computer science;operating system;machine learning;database;mathematics;distributed computing;abstract machine;programming language;algorithm;query language;abstract state machines	Robotics	-22.828858949273823	18.379319452724022	166177
c50ef03da9ba3fc57edfaae5b07722edee133734	verifying a class: combining testing and proving	software company;class c w;class c;metamathematical problem;algebraic structure;specification s.;class pqs;software engineering;object-oriented software;specification atpq	The problem of correctness of a class C w.r.t. a specificationS is discussed. A formal counterpart of the problem is the question well known in meta athematics, whether an algebraic structure is a model of a given theory. Now, this metamathema tical problem has to be adapted to the context of software engineering. As a theory we consider the (algorithmic) specification S. The algebraic structureAC induced by the class C is our candidate for a model of S. Remark, that this problem differs from the correctness’ problem of an algorit hm w.r.t. a preand a post-conditions. In the paper we consider the specification ATPQ of priority queues and the class PQS, and we verify the correctness of this class with respect to the specificati onATPQ. Programmers and software companies prefer to test software instead of proving it. Surely, proving is more difficult, testing is easier. In this article we combi ne these two approaches. Hence, the following actions appear in our method of verification: expe riment, observe, formulate hypotheses, prove. It is our hope that this method is of general use and ada pts well to many practical cases of verification of object-oriented software. ∗Address for correspondence: Faculty of Mathematics and Nat ural Sciences, University Cardinal Stefan Wyszyński, Wó ycickiego 1/3, 01-938 Warszawa, Poland 306 G. Mirkowska et al. / Experimenting, Observing, Proving	ada;algorithm;correctness (computer science);experiment;linear algebra;network address translation;priority queue;programmer;software engineering;ural (computer)	Grazyna Mirkowska;Andrzej Salwicki;Oskar Swida	2009	Fundam. Inform.	10.3233/FI-2009-152	correctness;discrete mathematics;computer science;theoretical computer science;mathematics;programming language;algorithm	Logic	-20.297651775567086	20.593642189472558	166799
3f1206fe1ea743d02982aec2aee56942d3de8211	the limits of mathematics	algorithmic information theory	In a remarkable development, I have constructed a new definition for a self-delimiting universal Turing machine (UTM) that is easy to program and runs very quickly. This provides a new foundation for algorithmic information theory (AIT), which is the theory of the size in bits of programs for self-delimiting UTM’s. Previously, AIT had an abstract mathematical quality. Now it is possible to write down executable programs that embody the constructions in the proofs of theorems. So AIT goes from dealing with remote idealized mythical objects to being a theory about practical down-to-earth gadgets that one can actually play with and use. This new self-delimiting UTM is implemented via software written in a new version of LISP that I invented especially for this purpose. This LISP was designed by writing an interpreter for it in Mathematica that was then translated into C. I have tested this software by running it on IBM RS/6000 workstations with the AIX version of UNIX.	aix;advanced intelligent tape;algorithmic information theory;delimiter;executable;interpreter (computing);lisp;new foundations;rs/6000;universal turing machine;unix;wolfram mathematica;workstation	Gregory J. Chaitin	1996	J. UCS	10.3217/jucs-002-05-0270	computer science;artificial intelligence;theoretical computer science;algorithm;algorithmic information theory	PL	-21.479493429389322	18.41709428902364	166855
e33e021ec14fa365a985b6fcb3f48c4ee86c747a	discussion on the ideal of program correctness by tony hoare	endnotes;pubications	Institute for Computing Research, London South Bank University, UK. Email: josephmb@lsbu.ac.uk It is always a pleasure to listen to Tony Hoare and I am grateful to Fionn for this opportunity to open the discussion of Tony’s lecture. I should like to begin by mentioning that I am personally indebted to Tony, having spent 9 years at Oxford’s Programming Research Group, first as a postgraduate student and subsequently as a postdoctoral researcher working for Tony. That experience has held me in good stead in my academic career. Tonight’s lecture has been about the correctness of programs, but the subject of programming language design has not been mentioned. I find the omission somewhat surprising since Tony has contributed so much to that subject. In the past, he has observed that the inclusion of complex features in a programming language not only leads to unreliable compilers, but also makes it difficult for programmers to understand the programs they write and so take responsibility for their correctness. Programmers should be able to think about programs in an implementationindependent way. Tony’s many contributions to programming language design include the ‘record’ (as incorporated in Algol W), recursive data structures, monitors and communicating sequential processes. In proposing these features, he became increasingly concerned with ‘correctness rules’. Such rules facilitate reasoning about program text using the tools of discrete mathematics (in particular, predicate calculus and set theory). They liberate the programmer from the tedium of operational reasoning. I wonder what Tony thinks of the complexity of today’s programming languages? Is a ‘program verifier’ unimaginable for programming languages that include so many sophisticated features and vast libraries of functions? Or perhaps, the correctness of programs has become more obvious because the languages encourage modularity and use of abstract data types (such as sets and maps)? 2. CLIFF JONES	algol w;apl;abstract data type;communicating sequential processes;compiler;correctness (computer science);data structure;discrete mathematics;email;first-order logic;hoare logic;library (computing);map;monitor (synchronization);programmer;programming research group;programming language;recursion;set theory	Tony Hoare	2007	Comput. J.	10.1093/comjnl/bxl079	computer science;mathematics;algorithm	PL	-20.711502285475152	19.91616465023658	167369
6e5cc611d0d18e3f95ac0e0748f76fd9a9a1db1c	comparison of object-oriented programming languages: the enterprise modeling framework perspective	object oriented programming languages;enterprise modeling		enterprise modelling	Krishnamurthy Srinivasan;Sundaresan Jayaraman	1994	JOOP		integrated enterprise modeling;programming language;modeling perspective;computer science;natural language processing;comparison of multi-paradigm programming languages;fourth-generation programming language;programming language theory;third-generation programming language;fifth-generation programming language;second-generation programming language;artificial intelligence	PL	-25.650199254601258	21.884801841798033	167563
81f86ffba62f7b4a94aa412a4c80c291f5962e3e	strategic polymorphism requires just two combinators	reference model;functional programming;design space;polymorphism;generating function;term rewriting;functional language;generic programming	In previous work, we introduced the notion of functional strategies : first-class generic functions that can traverse terms of any type while mixing uniform and types cific behaviour. Functional strategies transpose the notion of term rewriting strategies (with cov erage of traversal) to the functional programming paradigm. Meanwhile, a number of Haskell-based models and combinator suites were proposed to support generic programming with functional strategies. In the present paper, we provide a compact and matured recons truction of functional strategies. We capture strategic polymorphism by just two primitive combi nators. This is done without commitment to a specific functional language. We analyse the design spac e for implementational models of functional strategies. For completeness, we also provide an ope rational reference model for implementing functional strategies (in Haskell). We demonstrate the gen erality of our approach by reconstructing representative fragments of the Strafunski library for functional strategies.	functional programming;generic function;generic programming;haskell;programming paradigm;reference model;rewriting;strafunski;traverse;tree traversal	Ralf Lämmel;Joost Visser	2003	CoRR		polymorphism;generating function;reference model;programming domain;reactive programming;computer science;theoretical computer science;functional logic programming;mathematics;programming paradigm;inductive programming;programming language;functional programming;generic programming;algorithm	PL	-19.624735144755107	23.588874212979608	167686
0e39284ea29ab0bafe0f5e2e3ed65913dbcf0ee1	formal constraints on memory management for composite overloaded operations	systematic run-time assertion checking;memory leak;formal constraint;overloaded operator;memory management rule;run-time assertion checking;formal statement;current fortran;economical memory recycling;composite overloaded operation;composite overloaded expression;memory management	The memory management rules for abstract data type calculus presented by Rouson, Morris & Xu [15] are recast as formal statements in the Object Constraint Language (OCL) and applied to the design of a thermal energy equation solver. One set of constraints eliminates memory leaks observed in composite overloaded expressions with three current Fortran 95/2003 compilers. A second set of constraints ensures economical memory recycling. The constraints are preconditions, postconditions and invariants on overloaded operators and the objects they receive and return. It is demonstrated that systematic run-time assertion checking inspired by the formal constraints facilitated the pinpointing of an exceptionally hard-to-reproduce compiler bug. It is further demonstrated that the interplay between OCL's modeling capabilities and Fortran's programming capabilities led to a conceptual breakthrough that greatly improved the readability of our code by facilitating operator overloading. The advantages and disadvantages of our memory management rules are discussed in light of other published solutions [11,19]. Finally, it is demonstrated that the run-time assertion checking has a negligible impact on performance.	memory management	Damian W. I. Rouson;Xiaofeng Xu;Karla Morris	2006	Scientific Programming		parallel computing;real-time computing;computer science;operating system;programming language;computer security;algorithm;memory management	HPC	-21.101355849142085	24.615258509400064	167693
3dd6b096276c166081f4416ef957becc8a432966	improving recursive functions by inverting the order of evaluation	lenguaje programacion;programmation;programming language;sistema informatico;regle transformation;structure controle;program transformation;qa 76 software;estrategia;computer system;transformation programme;programacion;strategy;computer programming;recursive function;transformacion programa;programmation transformationnelle;funcion recursiva;langage programmation;fonction recursive;systeme informatique;strategie;programming	Baiten, E.A., Improving recursive functions by inverting the order of evaluation, Science of Computer Programming 18 (1992) 139-179. The paper presents a synthetic view of transformations that invert the order of evaluation of recursive functions. Techniques for linear recursive functions are presented. A consideration of stacks motivates the introduction of a general control structure for tabulation. Several transformations for tree-like recursive functions are given.	computer programming;control flow;recursion (computer science);synthetic intelligence;table (information)	Eerke A. Boiten	1992	Sci. Comput. Program.	10.1016/0167-6423(92)90008-Y	programming;strategy;computer science;artificial intelligence;computer programming;programming language;μ-recursive function;μ operator;algorithm	DB	-20.322672309376497	23.392375203310177	167743
949c480b69baf41ff53a2a8f7ef68b3220160eab	comments on several syntax rules in ada95	lenguaje programacion;regle inference;record aggregate;syntax;programming language;ada;syntax rule;syntaxe;inference rule;langage programmation;exception handler;ada language;sintaxis;record variant part;regla inferencia;case statement	This paper points out the demerits in the syntax rules of several syntactical elements (i.e., the record variant_part, the record_aggregate, the named array_aggregate, the case_statement and the exception_handler) in the Ada95 Reference Manual [ARM95], and puts forward some constructive amendments to these syntax rules.	ada;exception handling	Baowen Xu	1998	SIGPLAN Notices	10.1145/274930.274940	natural language processing;abstract syntax;ada;syntax;computer science;programming language;algorithm;rule of inference	DB	-23.826991082247197	19.07516100938904	167949
34ccad97c16123e02154089df8bb19b929f71a30	analyzing and compressing assembly code	attribute grammars;data compression;storage management;abstract machine;recursive evaluation;evaluation by need;lisp;circularity tests	This paper describes the application of a general data compression algorithm to assembly code. The system is retargetable and generalizes cross-jumping and procedural abstraction. It can be used as a space optimizer that trades time for space, it can turn assembly code into interpretive code, and it can help formalize and automate the traditionally ad hoc design of both real and abstract machines.	algorithm;assembly language;data compression;hoc (programming language);mathematical optimization	Christopher W. Fraser;Eugene W. Myers;Alan L. Wendt	1984		10.1145/502874.502886	data compression;computer science;theoretical computer science;lisp;abstract machine;programming language;algorithm	HCI	-22.676701441655702	24.10734807144697	168325
1e8d048650125e3e7780af83827833eef637ef38	a brief look at extension programming before and now	different theoretical basis;additional comment;extension facility;extension programming;language system;macro language;brief look;short analysis	We try to bind together some old and some new: what is an extension. In addition, we give a short analysis of extension facilities in three language systems with slightly different theoretical basis. We compare Ada 9x, Oberon and Macro Language, with additional comments to e.g., C++.	ada;c++;oberon	Liisa Räihä	1995	SIGPLAN Notices	10.1145/199873.199875	computer science;programming language;algorithm	PL	-25.7434281302757	23.337854885878702	168629
dca21edd36499bdbc7f8842fc8b83aa019336ee0	tunable static inference for generic universe types	object ownership;tunable static inference;tunable static type inference;ownership type system;ownership type;generic universe type;interesting ownership structure;classical type system;static inference tool;correct universe typing;generic universe types;inference tool	Object ownership is useful for many applications, including program verification, thread synchronization, and memory management. However, the annotation overhead of ownership type systems hampers their widespread application. This paper addresses this issue by presenting a tunable static type inference for Generic Universe Types. In contrast to classical type systems, ownership types have no single most general typing. Our inference chooses among the legal typings via heuristics. Our inference is tunable: users can indicate a preference for certain typings by adjusting the heuristics or by supplying partial annotations for the program. We present how the constraints of Generic Universe Types can be encoded as a boolean satisfiability (SAT) problem and how a weighted Max-SAT solver finds a correct Universe typing that optimizes the weights. We implemented the static inference tool, applied our inference tool to four real-world applications, and inferred interesting ownership structures.	boolean satisfiability problem;encode;encapsulation (networking);formal verification;heuristic (computer science);maximum satisfiability problem;memory management;modifier key;overhead (computing);programmer;solver;synchronization (computer science);type inference;type system;universe	Werner Dietl;Michael D. Ernst;Peter Müller	2011		10.1007/978-3-642-22655-7_16	real-time computing;computer science;theoretical computer science;programming language;algorithm	PL	-19.574037944005998	24.592763473540785	168789
e01da755eaefbf48b105573500b541b914f3d3b7	parallelizing imperative functional programs: the vectorization monad	functional programming;type inference;template matching	Traditionally a vectorizing compiler matches the iterative constructs of a program against a set of predefined templates. If a loop contains no dependency cycles then a map template can be used; other simple dependencies can often be expressed in terms of fold or scan templates. This paper addresses the template matching problem within the context of functional programming. A small collection of program identities are used to specify vectorizable for-loops. By incorporating these program identities within a monad, all well-typed for-loops in which the body of the loop is expressed using the vectorization monad can be vectorized. This technique enables the elimination of template matching from a vectorizing compiler, and the proof of the safety of vectorization can be performed by a type inference mechanism. c © 1996 Academic Press Limited	automatic parallelization;automatic vectorization;compiler;fold (higher-order function);for loop;functional programming;imperative programming;iterative method;monad (functional programming);programming language;template matching;type inference	Jonathan M. D. Hill;Keith M. Clarke;Richard Bornat	1996	J. Symb. Comput.	10.1006/jsco.1996.0031	template matching;computer science;theoretical computer science;type inference;programming language;functional programming;algorithm	PL	-20.050671933325834	24.94379046639222	168905
b734a1b7dca4b0f771cc2523ac26b155c7a56015	geogebra tools with proof capabilities		We report about significant enhancements of the complex algebraic geometry theorem proving subsystem in GeoGebra for automated proofs in Euclidean geometry, concerning the extension of numerous GeoGebra tools with proof capabilities. As a result, a number of elementary theorems can be proven by using GeoGebra’s intuitive user interface on various computer architectures including native Java and web based systems with JavaScript. We also provide a test suite for benchmarking our results with 200 test cases.	automated theorem proving;computer architecture;geogebra;java;javascript;linear algebra;test case;test suite;user interface	Zoltán Kovács;Csilla Sólyom-Gecse	2016	CoRR		computer science;theoretical computer science;mathematics;algorithm	SE	-20.633895571918366	20.593761704150516	169010
5ffa9dddf59e3630aaf83b90b1b7c909a5337d75	formal semantics and interpreters in a principles of programming languages course	programming language;formal semantics;compilers;design patterns;point of view;object oriented languages;java	Most junior-senior level programming languages courses approach the subject either from the point-of-view of principles (concepts) of programming languages or from the perspective of understanding languages through writing progressively more complex interpreters. In this paper we show how to use formal semantics in a series of interpreter assignments in a principles or concepts-based course. The interpreter assignments make the semantics more concrete for students while providing a deeper understanding of concepts.	first-order predicate;formal specification;functional programming;hoare logic;interpreter (computing);programming language;scope (computer science);semantics (computer science);symposium on principles of programming languages;type system;vagueness;web page	Kim B. Bruce	1999		10.1145/299649.299799	natural language processing;fourth-generation programming language;compiler;software design pattern;formal language;declarative programming;formal semantics;action semantics;computer science;theoretical computer science;third-generation programming language;formal semantics;compiled language;programming paradigm;abstract family of languages;fifth-generation programming language;programming language theory;programming language;object-oriented programming;well-founded semantics;java;operational semantics;second-generation programming language;comparison of multi-paradigm programming languages;denotational semantics;semantics	PL	-24.330075651054695	22.04623596386772	169295
c083eef1e9255c156055217e4e036ddccc16e2e1	parsing with c++ deferred expressions	deferred expression	A technique for constructing embedded grammar-based parsers in C++ was described in [1]. This paper presents an extension to that technique which allows parsing actions to be specified directly as part of the grammar, rather than indirectly (as function calls).	c++;embedded system;parsing	Damian Conway	1994	SIGPLAN Notices	10.1145/185009.185011	programming language;computer science;parsing;expression (mathematics)	PL	-24.003179949763087	24.864768003497904	169366
c1bc13d037346230c184db1e641e017ac331cca6	ml: metalanguage or object language?	proof assistant;types;proof assistants;lcf;functional programming;ml;metalanguage;polymorphism;object language	My talk will celebrate Robin Milneru0027s contribution to functional programming via a combination of reminiscences about the early days of ML and speculations about its future.	functional programming;object language	Michael J. C. Gordon	2010		10.1145/1863543.1863545	polymorphism;object language;metalanguage;computer science;proof assistant;programming language;functional programming;algorithm	PL	-22.152691531198624	21.04972633840194	169461
a4df5e8acbd6b3ae740c75012febf5a3e0f7fa5f	extending languages by leveraging compilers: from modelica to optimica	automatic control;parser generators;attribute grammars;computer languages;formal theory;object oriented model;processors reusable software design tools design techniques formal definitions formal theory;compiler generators;optimica compilers object oriented programming parser generators abstract syntax trees attribute grammars code generation software reuse modelica;abstract data types;modelica;code generation;abstract syntax trees;object oriented programming;compilers;grammars;design technique;software reusability abstract data types compiler generators computational linguistics grammars object oriented programming;reglerteknik;software reusability;design techniques;datavetenskap datalogi;computational linguistics;computer science;design tools;software design;synthesizers;software reuse;program processors;formal definitions;optimica;object oriented modeling;object oriented modeling program processors object oriented programming java costs computer languages synthesizers computer science automatic control;java;reusable software;processors	Constructing compilers using ordinary object-oriented programming takes advantage of parser generators to construct abstract syntax trees (ASTs) and uses the Visitor design pattern to program traversals that resolve names and types and to generate code. Although this plain approach allows some reuse and modularization, it's possible to go much further by combining object orientation with recent advances in at tribute grammars to build highly extensible compilers.	abstract syntax tree;compiler;compiler-compiler;design pattern;visitor pattern	Görel Hedin;Johan Åkesson;Torbjörn Ekman	2011	IEEE Software	10.1109/MS.2010.62	computer architecture;compiler;computer science;software design;theoretical computer science;computational linguistics;central processing unit;automatic control;modelica;programming language;object-oriented programming;java;abstract data type;code generation	PL	-26.06843024976409	23.67451642744263	169715
8ca05cc171de7b945d01d0cd0c3c0de2c798fbb7	automated termination analysis for incompletely defined programs	analyse terminaison;printing;analisis terminacion;intelligence artificielle;logical programming;program verification;probleme terminaison;analisis programa;termination analysis;performance programme;verificacion programa;programmation logique;impression;termination problem;artificial intelligence;eficacia programa;program analysis;program performance;inteligencia artificial;analyse programme;verification programme;programacion logica;impresion;problema terminacion	Incompletely defined programs provide an elegant and easy way to write and to reason about programs which may halt with a run time error by throwing an exception or printing an error message, e.g. when attempting to divide by zero. Due to the presence of stuck computations, which arise when calling incompletely defined procedures with invalid arguments, we cannot use the method of argument bounded algorithms for proving termination by machine. We analyze the problem and present a solution to improve this termination analysis method so that it works for incompletely defined programs as well. Our technique of proving the termination of incompletely defined programs maintains performance as well as simplicity of the original method and proved successful by an implementation in the verification tool eriFun .	algorithm;computation;data structure;division by zero;error message;exception handling;halting problem;printing;recursion;run time (program lifecycle phase);semiconductor industry;termination analysis	Christoph Walther;Stephan Schweitzer	2004		10.1007/978-3-540-32275-7_22	program analysis;computer science;artificial intelligence;termination analysis;programming language;algorithm	Logic	-19.38877539958959	23.016382256344578	169832
dfe556abe9eb953553f9a0ecab331341c1f841d1	a simplifier for untyped lambda expressions	syntax;programming language;lambda calculus;automatic programming;compilers;control sequences;rewrite systems;partial evaluation;structured programming;algorithms;optimization;abstract interpretation;programming languages	Many applicative programming languages are based on the call-by-value lambda calculus. For these languages tools such as compilers, partial evaluators, and other transformation systems often make use of rewriting systems that incorporate some form of beta reduction. For purposes of automatic rewriting it is important to develop extensions of beta-value reduction and to develop methods for guaranteeing termination. This paper describes an extension of beta-value reduction and a method based on abstract interpretation for controlling rewriting to guarantee termination. The main innovations are (1) the use of rearrangement rules in combination with beta-value reduction to increase the power of the rewriting system and (2) the definition of a non-standard interpretation of expressions, the generates relation, as a basis for designing terminating strategies for rewriting.	abstract interpretation;abstract rewriting system;applicative programming language;compiler;lambda calculus	Louis Galbiati;Carolyn L. Talcott	1990		10.1007/3-540-54317-1_103	typed lambda calculus;computer science;theoretical computer science;lambda calculus;programming paradigm;fifth-generation programming language;programming language;confluence;second-generation programming language;comparison of multi-paradigm programming languages;algorithm	PL	-21.946427670402645	23.293150894648686	170179
b7ee2e8cf7facd19607858cfd143ede990421a0d	implementing high-level identification specifications	programming language	Identi cation is the task of nding the relation between used identi er occurrences and the declared entities of a program. In [PH91b] and [PH92], we presented a new speci cation method for identi cation in programming languages. This method is related to visibility descriptions in language reports de ning the identi cation in terms of validity and hiding of bindings in program ranges. Whereas the cited papers are concerned with semantics and speci cation properties of the method, this paper focusses on the implementation techniques. In particular, we show how compiler front ends can be generated from such high{level identi cation speci cations. The implementation combines instantiation and partial evaluation of expressions with a generated global table mechanism.	compiler;entity;language binding;partial evaluation;programming language;universal instantiation	Arnd Poetzsch-Heffter	1992		10.1007/3-540-55984-1_7	natural language processing;fourth-generation programming language;first-generation programming language;computer architecture;very high-level programming language;programming domain;computer science;programming language implementation;extensible programming;functional logic programming;programming paradigm;procedural programming;symbolic programming;inductive programming;fifth-generation programming language;programming language theory;programming language;programming language specification;high-level programming language	PL	-24.350063006408668	23.504573483142764	170342
44a350064cbe9fa462960f811c61fd5b926c50e5	sensala: a dynamic semantics system for natural language processing		Here we describe SENSALA, an open source framework for the semantic interpretation of natural language that provides the logical meaning of a given text. The framework’s theory is based on a lambda calculus with exception handling and uses contexts, continuations, events and dependent types to handle a wide range of complex linguistic phenomena, such as donkey anaphora, verb phrase anaphora, propositional anaphora, presuppositions and implicatures. Title and Abstract in Russian Sensala: Система динамической семантики для обработки естественного языка В данной статье описывается Sensala – программная система семантической интерпретации естественного языка с открытым исходным кодом, позволяющая получить логический смысл текста. Теоретическим фундаментом для системы послужило лямбда исчисление с обработкой исключений, а использование контекстов, продолжений, событий и зависимых типов позволяет системе интерпретировать широкий спектр таких лингвистических явлений, как «ослиная» анафора, глагольная анафора, пропозициональная анафора, пресуппозиция и импликатура.	anaphora (linguistics);continuation;dependent type;exception handling;lambda calculus;natural language processing;open-source software;programming language;prototype;semantic interpretation;semantics (computer science);software engineering	Daniyar Itegulov;Ekaterina Lebedeva;Bruno Woltzenlogel Paleo	2018			natural language processing;artificial intelligence;semantics;computer science	NLP	-24.979039284365598	19.77894195505951	170893
0e93219fad92d4eea7b9737fa80b9036e59501fb	a parsing methodology for the implementation of visual systems	grammar;lr parsing;visual language compiler compiler;multidimensional grammars;visual programming environment generation;systeme visuel;programming environments;compilateur;graphical language;flow graph languages parsing methodology visual systems visual language compiler compiler vlcc grammar based graphical system visual programming environment generation positional grammar context free grammars string concatenation lr parsing yacc like tool automatic compiler generation visual languages multidimensional grammars;programming environment;helium;generacion automatica;compiler generators;context free grammars;parsing methodology;plr parsing;production visual system programming environments program processors multidimensional systems flowcharts performance analysis;grammaire multidimensionnelle;positional grammar;automatic compiler generation;software engineering;automatic generation;visual programming;medio ambiente programacion;graphics system;grammars;visual languages;generation automatique;grammar based graphical system;string concatenation;context free grammar;grammaire;visual programming environments;performance analysis;visual language;genie logiciel;analizador sintaxico;production;flow graph languages;visual systems;vlcc;software tools;parser;program compilers;visual system;analyseur syntaxique;software tools visual programming programming environments compiler generators visual languages grammars;flowcharts;program processors;gramatica;multidimensional systems;environnement programmation;lenguaje grafico;langage graphique;yacc like tool;visual parser generation	The Visual Language Compiler-Compiler (VLCC) is a grammar-based graphical system for the automatic generation of visual programming environments. In this paper the theoretical and algorithmic issues of VLCC are discussed in detail. The parsing methodology we present is based on the “positional grammar” model. Positional grammars naturally extend context-free grammars by considering new relations in addition to string concatenation. Thanks to this, most of the results from LR parsing can be extended to the positional grammars inheriting the well known LR technique efficiency. In particular, we provide algorithms to implement a YACC-like tool embedded in the VLCC system for automatic compiler generation of visual languages described by positional grammars. Index Terms —Visual programming environments, multidimensional grammars, visual parser generation, pLR parsing, flow-	algorithm;compiler;compiler-compiler;concatenation;context-free grammar;context-free language;embedded system;graphical user interface;indexed grammar;lr parser;parsing;private label rights;visual language;visual programming language;whole earth 'lectronic link;yacc	Gennaro Costagliola;Andrea De Lucia;Sergio Orefice;Genny Tortora	1997	IEEE Trans. Software Eng.	10.1109/32.637392	natural language processing;l-attributed grammar;parsing expression grammar;computer science;theoretical computer science;parsing;s-attributed grammar;extended affix grammar;context-free grammar;programming language	PL	-25.36345054087794	23.814925947721107	171313
504f61b87cba15ab5d3f6ad0c26d39459b9e5cf8	streams à la carte: extensible pipelines with object algebras (artifact)	004;object algebras streams extensibility domain specific languages expression problem library design	In Streams à la carte we address extensibility shortcomings in libraries for lazy-streaming queries with a new design. The architecture underlying this design borrows heavily from Oliveira and Cook’s object algebra solution to the expression problem, extended with a design that exposes the push/pull character of the iteration, and an encoding of higherkinded polymorphism. In this library we apply our design to Java and show that the addition of full extensibility is accompanied by high performance, matching or exceeding that of the original, highly-optimized Java streams library. In this artifact we present a fundamental set of sequential operators map, filter, reduce, count, take/limit and iterate. Additionally we present the behaviors that are discussed in the paper: push, pull, fused pull, logging, id (for blocking terminal operators), future (for non-blocking terminal operators). 1998 ACM Subject Classification D.2.2. Software libraries, D.1.5 Object-oriented Programming, D.3.3 Language Constructs and Features	blocking (computing);expression problem;extensibility;graphics pipeline;iteration;java;lazy evaluation;library (computing);linear algebra;nosql;non-blocking algorithm;streams	Aggelos Biboudis;Nick Palladinos;George Fourtounis;Yannis Smaragdakis	2015	DARTS	10.4230/DARTS.1.1.9	computer science;theoretical computer science;database;algorithm	PL	-23.087503773041533	25.00497057616227	171448
d2859f232af62d2ed5895465cbfc6a5bf6ea2db5	implementation of propagation-based constraint solver in ims		Article compiling the main ideas of creating propagation-based constraint solver, theoretical basis of constraint programming its implementation in IMS (Insertion Modeling System) and creating prototype of IMS constraint solver.	compiler;constraint programming;layer (electronics);propagator;prototype;software propagation;solver	Igor Ol. Blinov	2013			constraint programming;mathematical optimization;constraint satisfaction problem;computer science	AI	-22.645022889737447	22.375024502465457	172205
ec43c251b2267dc1c1e8eefce63f954c0f1844ce	upv-curry: an incremental curry interpreter	semantica operacional;operational semantics;program transformation;logical programming;transformation programme;functional programming;program optimization;transformacion programa;semantique operationnelle;programmation logique;informatique theorique;programmation fonctionnelle;optimisation programme;functional logic programming;programacion logica;programacion funcional;computer theory;optimizacion programa;informatica teorica	Functional logic programming integrates the best features of modern functional and logic languages. The multi-paradigm declarative language Curry is an extension of Haskell which is intended to become a standard in the area. In this paper, we present UPV-Curry, an eecient and quite complete implementation of Curry based on a new, incremental deenition of its basic evaluation mechanism. We compare UPV-Curry with already existing implementations of other Curry interpreters.	curry;declarative programming;functional logic programming;haskell;programming paradigm	María Alpuente;Santiago Escobar;Salvador Lucas	1999		10.1007/3-540-47849-3_20	combinatory logic;computer science;artificial intelligence;functional logic programming;program optimization;programming language;functional programming;operational semantics;algorithm	PL	-21.109224056861546	23.020221702773945	172779
64b005ff9e4e414e020c0d1a700d02167b7fd81f	compiling embedded languages	semantica denotacional;optimizing compiler;embedded language;code generation;program transformation;data type;specification programme;transformation programme;functional programming;evaluation partielle compilateur;program generation;image synthesis;transformacion programa;denotational semantics;programmation fonctionnelle;compilateur optimisation;code motion;functional language;optimizing compilers;program specification;programacion funcional;especificacion programa;domain specificity;semantique denotationnelle;partial evaluation compilers	Fun tional languages are parti ularly well-suited to the implementation of interpreters for domain-spe i embedded languages (DSELs). We des ribe an implemented te hnique for produ ing optimizing ompilers for DSELs, based on Kamin's idea of DSELs for program generation. The te hnique uses a data type of syntax for basi types, a set of smart onstru tors that perform rewriting over those types, some ode motion transformations, and a ba k-end ode generator. Domain-spe i optimization results from hains of rewrites on basi types. New DSELs are de ned dire tly in terms of the basi synta ti types, plus host language fun tions and tuples. This de nition style makes ompilers easy to write and, in fa t, almost identi al to the simplest embedded interpreters. We illustrate this te hnique with a language for the omputationally intensive domain of image synthesis and manipulation.	code generation (compiler);domain-specific language;embedded system;interpreter (computing);loop-invariant code motion;mathematical optimization;optimizing compiler;programming language;rendering (computer graphics);rewriting	Conal Elliott;Sigbjorn Finne;Oege de Moor	2000		10.1007/3-540-45350-4_5	data type;computer science;theoretical computer science;operating system;optimizing compiler;database;programming language;functional programming;denotational semantics;algorithm;code generation	PL	-23.34128858719843	24.419439765435996	173548
679a17a94ef3644083dc987ca37c14f0babf6f2f	automatic generation of r2r mappings from correspondence assertions			minimal mappings	Valéria Magalhães Pequeno;Vânia Maria Ponte Vidal;Tiago Vinuto;Helena Galhardas	2015				Vision	-20.16106050612147	19.30327158402638	173731
93680754e2b9c325b07c673f6f2c83ccc1b94d3d	efficient prolog programming	ecriture programme;machine abstraite;lenguaje programacion;compilacion;metodologia;programming language;program writing;prolog;escritura programa;sistema informatico;warren abstract machine;maquina abstracta;computer system;system programming;logical programming;methodologie;abstract machine;efficient programming;performance programme;programmation systeme;programmation logique;programacion sistema;langage programmation;compilation;eficacia programa;systeme informatique;program performance;methodology;programacion logica	This paper presents some basic programming strategies for Prolog programmers. The strategies are based on knowledge about the operational behaviour of the Warren Abstract Machine ( WAM). The aim is to provide simple principles for making programs both faster and less space-consuming. The programming hints given are mostly local, i.e. only a single clause or procedure need be considered at a time.	basic programming;program transformation;programmer;prolog;warren abstract machine	Timo Knuutila	1992	Softw., Pract. Exper.	10.1002/spe.4380220302	constraint programming;declarative programming;horn clause;programming domain;computer science;functional logic programming;methodology;abstract machine;programming paradigm;procedural programming;symbolic programming;inductive programming;fifth-generation programming language;programming language;prolog;logic programming;system programming;algorithm	PL	-20.718353919331356	23.32878875754994	173814
0969e9264cdf70b2bfbab242f5707607ca7f6d81	generalizing symbolic execution to library classes	generic model;data type;test input generation;symbolic execution;model checking;korat;constraint solving;program analysis;large classes	Forward symbolic execution is a program analysis technique that allows using symbolic inputs to explore program executions. The traditional applications of this technique have focused on programs that manipulate primitive data types, such as integer or boolean. Recent extensions have shown how to handle reference types at their representation level. The extensions have favorably been backed by advances in constraint solving technology, and together they have made symbolic execution applicable, at least in theory, to a large class of programs. In practice, however, the increased potential for applications has created significant issues with scalability of symbolic execution to programs of non-trivial size---the ensuing path conditions rapidly become unfeasibly complex.We present Dianju, a new technique that aims to address the scalability of symbolic execution. The fundamental idea in Dianju is to perform symbolic execution of commonly used library classes (such as strings, sets and maps) at the abstract level rather than the representation level. Dianju defines semantics of operations on symbolic objects of these classes, which allows Dianju to abstract away from the complexity that is normally inherent in library implementations, thus promising scalable analyses based on symbolic execution.	constraint satisfaction problem;map;mental representation;program analysis;reference type;scalability;string (computer science);symbolic execution	Sarfraz Khurshid;Yuk Lai Suen	2005		10.1145/1108792.1108817	program analysis;model checking;data type;computer science;theoretical computer science;symbolic data analysis;programming language;concolic testing;symbolic trajectory evaluation;algorithm	SE	-19.356975649558787	24.99064593438561	173815
168b6ed22aafcf682031438531cdac960853e3be	hol-csp: mechanised formal devlopment mof concurrent processes			hol (proof assistant)	Haykal Tej	2003				Logic	-21.7292643890435	20.92564641248075	174134
a0fc679e7e3d99c275f51d0f71f6f5869385383d	reimplementation and reinterpretation of the copycat project		We present the reinterpreted and reimplemented Copycat project, an architecture solving letter analogy domain problems. To support a flexible implementation change and rigor testing process, we propose a implementation method in DrRacket by using functional abstraction, naming system, initialization, and structural reference. Finally, benefits and limitations are analyzed for cognitive architectures along the lines of Copycat.	cognitive architecture;copycat (software);lambda calculus;racket	Hongyi Huang	2018	CoRR			SE	-25.59477088016512	22.192555462366347	174492
378adbac020aa566e8c99a1bb2c8ab1547b4f3e8	error repair in shift-reduce parsers	detection erreur;compilacion;deteccion error;error recovery;generation code;correction erreur;generacion codigo;code generation;generation time;shift reduce;bison;least cost;error correction;analizador sintaxico;compilation;parser;translator writing system;correccion error;error detection;analisis semantico;analyse semantique;analyseur syntaxique;semantic analysis;yacc	Local error repair of strings during CFG parsing requires the insertion and deletion of symbols in the region of a syntax error to produce a string that is error free. Rather than precalculating tables at parser generation time to assist in finding such repairs, this article shows how such repairs can be found during shift-reduce parsing by using the parsing tables themselves. This results in a substantial space saving over methods that require precalculated tables. Furthermore, the article shows how the method can be integrated with lookahead to avoid finding repairs that immediately result in further syntax errors. The article presents the results of experiments on a version of the LALR(1)-based parser generator Bison to which the algorithm was added.	algorithm;compiler-compiler;context-free grammar;experiment;shift-reduce parser;syntax error;table (database)	Bruce J. McKenzie;Corey Yeatman;Lorraine De Vere	1995	ACM Trans. Program. Lang. Syst.	10.1145/210184.210193	parser combinator;error detection and correction;speech recognition;canonical lr parser;parsing expression grammar;computer science;bottom-up parsing;programming language;top-down parsing;algorithm	PL	-24.831690276000256	24.806214906334088	175077
dd4cb3a1fbe9c0842ac59e76aba09a55a595b009	antlrworks: an antlr grammar development environment	antlr grammar;domain-specific grammar debugger;grammar developer;grammar development;grammar editor;grammar fragment result;grammar interpreter;parser non-determinism;parser non-determinism visualizer;complete development environment;antlr grammar development environment	Programmers tend to avoid using language tools, resorting to ad-hoc methods, because tools can be hard to use, their parsing strategies can be difficult to understand and debug, and their generated parsers can be opaque black-boxes. In particular, there are two very common difficulties encountered by grammar developers: Understanding why a grammar fragment results in a parser nondeterminism and determining why a generated parser incorrectly interprets an input sentence. This paper describes ANTLRWorks, a complete development environment for ANTLR grammars that attempts to resolve these difficulties and, in general, make grammar development more accessible to the average programmer. The main components are a grammar editor with refactoring and navigation features, a grammar interpreter, and a domain-specific grammar debugger. ANTLRWorks’ primary contributions are a parser nondeterminism visualizer based upon syntax diagrams and a time-traveling debugger that pays special attention to parser decision-making by visualizing lookahead usage and speculative parsing during backtracking.	antlr;bsd;backtracking;black box;code refactoring;compiler;debugger;debugging;hoc (programming language);intellij idea;java;open-source software;parse tree;parser combinator;parsing;plug-in (computing);programmer;speculative execution;stepping level;syntax diagram	Jean Bovet;Terence Parr	2008	Softw., Pract. Exper.	10.1002/spe.872	natural language processing;parser combinator;compiler-compiler;link grammar;speech recognition;lalr parser;ll grammar;parsing expression grammar;operator-precedence grammar;top-down parsing language;computer science;syntactic predicate;affix grammar;operating system;parsing;graphical user interface;development environment;programming language;attribute grammar;adaptive grammar;top-down parsing	NLP	-25.269825264215534	24.728501869208664	175727
59b3d3114bb503abde8c778db309ff68c7b60be1	the design and implementation of an interactive proof editor	attribute grammar computer software mathematics;thesis or dissertation;ipe;attribute grammar;design and implementation;interactive proofs;context sensitive structure;interactive proof editor		interactive proof system;proof assistant	Brian Ritchie	1988			computer science;proof assistant;programming language;algorithm	HCI	-20.586702919186436	20.513343733054224	176873
7663b3af6507894cbc8f92cce87350f7db7ad26a	panel session: commercial applications of constraint programming	constraint programming	Constraint programming is a quite young research area, but (a part of) it has already successfully made its way to end users, as witnessed by the examples given above. However, these first applications shows that some very interesting problems should be studied and solved before constraint programming becomes mature.	constraint programming	David Kurlander;Jean-François Puget;Jeff Heisserman	1994		10.1007/3-540-58601-6_112	concurrent constraint logic programming;mathematical optimization;constraint programming;real-time computing;constraint satisfaction;reactive programming;computer science;database;inductive programming;programming language	HCI	-22.49432597133895	19.352564108196923	177190
7960b264a43efdeb65df884bda238d71c4022d4e	semantics of programming languages	semantics of programming languages	"""class Expression { abstract Expression smallStep(State state) throws CanNotReduce; abstract Type typeCheck(Environment env) throws TypeError; } abstract class Value extends Expression { final Expression smallStep(State state) throws CanNotReduce{ throw new CanNotReduce(""""I’m a value""""); } }class Value extends Expression { final Expression smallStep(State state) throws CanNotReduce{ throw new CanNotReduce(""""I’m a value""""); } } class CanNotReduce extends Exception{ CanNotReduce(String reason) {super(reason);} } class TypeError extends Exception { TypeError(String reason) {super(reason);}} class Bool extends Value { boolean value; Bool(boolean b) { value = b; } public String toString() { return value ? """"TRUE"""" : """"FALSE""""; } Type typeCheck(Environment env) throws TypeError { return Type.BOOL; } } class Int extends Value { int value; Int(int i) { value = i; } public String toString(){return """"""""+ value;} Type typeCheck(Environment env) throws TypeError { return Type.INT; } } class Skip extends Value { public String toString(){return """"SKIP"""";} Type typeCheck(Environment env) throws TypeError { return Type.UNIT; } }"""	abstract type;emoticon;env;programming language;return statement;return type;semantics (computer science)	Robert D. Tennent	1991			natural language processing;fourth-generation programming language;first-generation programming language;very high-level programming language;language primitive;formal semantics;action semantics;computer science;third-generation programming language;semantics;linguistics;programming paradigm;low-level programming language;fifth-generation programming language;programming language theory;programming language;operational semantics;second-generation programming language;high-level programming language;denotational semantics;semantics;computational semantics	Theory	-23.69095567225903	21.540564812131056	177368
4df7d1844e5b1554655b578417a97ec28ef687c3	generating denotational semantics from algebraic semantics for event-driven system-level language	denotational semantic;modelling language;normal form;unifying theories of programming	As a system-level modelling language, SystemC possesses several novel features such as delayed notifications, notification cancelling, notification overriding and delta-cycle. We have explored the denotational semantics [15] for SystemC using Unifying Theories of Programming (abbreviated as UTP) [6], where algebraic laws can be achieved based on the denotational model.#R##N##R##N#In this paper, we consider the inverse work; i.e., generating the denotational semantics from algebraic semantics for SystemC. A complete set of algebraic laws is explored. The concept of head normal from is applied in supporting the calculation. We also explore the simulation of algebraic laws and head normal form. Based on this, the mechanical derivation of denotational semantics from algebraic semantics is also studied.	denotational semantics;event-driven finite-state machine	Huibiao Zhu;Fan Yang;Jifeng He	2010		10.1007/978-3-642-16690-7_15	normalisation by evaluation;action semantics;theoretical computer science;domain theory;normal-form game;programming language;denotational semantics of the actor model;operational semantics;denotational semantics;algorithm	PL	-23.382419129268133	22.86309838813962	177526
44c62ccafbb94b80b17f40e871f1e2afd1723640	program verification by reduction to semi-algebraic systems solving	program verification;ranking function;generic programming	The discovery of invariants and ranking functions plays a central role in program verification. In our previous work, we investigated invariant generation and non-linear ranking function discovering of polynomial programs by reduction to semi-algebraic systems solving. In this paper we will first summarize our results on the two topics and then show how to generalize the approach to discovering more expressive invariants and ranking functions, and applying to more general programs. keywords Program Verification, Ranking Functions, Invariants, Polynomial Programs, Semi-Algebraic Systems, Quantifier Elimination	abstract interpretation;algebraic equation;algorithm;decision problem;entity–relationship model;formal verification;gröbner basis;issac;invariant (computer science);journal of symbolic computation;lecture notes in computer science;lexmark international, inc. v. static control components, inc.;linear algebra;linear programming;loop invariant;nonlinear system;polynomial;quantifier (logic);ranking (information retrieval);sigsam;sass;semiconductor industry;static program analysis;time complexity;yang	Bican Xia;Lu Yang;Naijun Zhan	2008		10.1007/978-3-540-88479-8_20	computer science;theoretical computer science;machine learning;programming language;generic programming	Logic	-19.316667197418706	19.619997766441077	177804
633ada62dadb3f1c0fe79b8f0b0759e868441100	data linkage algebra, data linkage dynamics, and priority rewriting	priority rewrite system;data linkage dynamics;universiteitsbibliotheek;term rewrite system;garbage collection;rewrite systems;dynamic data structure;data linkage;molecular dynamic;logic in computer science;model of computation;data linkage algebra	We introduce an algebra of data linkages. Data linkages are intended for modelling the states of computations in which dynamic data structures are involved. We present a simple model of computation in which states of computations are modelled as data linkages and state changes take place by means of certain actions. We describe the state changes and replies that result from performing those actions by means of a term rewriting system with rule priorities. The model in question is an upgrade of molecular dynamics. The upgrading is mainly concerned with the features to deal with values and the features to reclaim garbage.	data structure;dynamic data;dynamization;linkage (software);model of computation;molecular dynamics;rewriting	Jan A. Bergstra;Kees Middelburg	2013	Fundam. Inform.	10.3233/FI-2013-950	model of computation;molecular dynamics;computer science;theoretical computer science;distributed computing;garbage collection;programming language;algorithm	DB	-20.389436730354028	22.08253517078935	178208
7183297f438ff0aaaecda85a54967fb5800872ef	starlet: an affix-based compiler compiler designed as a logic programming system	static checking;operational semantics;logic programs	We present STARLET, a new compiler compiler which compiles Extended Affix G r a m m a r s defining a translation into an executable program : the translator. We look at its operational semantics and we focus on the points which are close to or different from Prolog procedural semantics. We discuss the two interwoven issues which are Program Reliability (due to many static checks) and Program Efficiency (optimizations at compile time). Both are reached through a systematic use of grammatical properties. I I n t r o d u c t i o n Our research group has been working on grammatical programming development i.e. an approach to software construction based on compiling methods [Beney-86], Compiler compilers are designed as high-level programming environments and if compiler writing is the major application field, we also investigate other application fields [Fr~con 89].	algorithm;artificial intelligence;compile time;compiler;compiler-compiler;debugging;executable;experiment;expert system;high- and low-level;high-level programming language;impredicativity;logic programming;naruto shippuden: clash of ninja revolution 3;operational semantics;programming tool;prolog;software construction;usability	Jean Beney;Jean-François Boulicaut	1990		10.1007/3-540-53669-8_75	computer architecture;compiler;compiler correctness;interprocedural optimization;computer science;theoretical computer science;compiler construction;programming language;operational semantics;functional compiler	PL	-24.99835086977512	23.3087138147139	178499
359550fba95284c28971c91ca0ccbe5e8507ed1c	the rewriting logic semantics project: a progress report	k;maude;semantics;rewriting logic;programming languages	Rewriting logic is an executable logical framework well suited for the semantic definition of languages. Any such framework has to be judged by its effectiveness to bridge the existing gap between language definitions on the one hand, and language implementations and language analysis tools on the other. We give a progress report on how researchers in the rewriting logic semantics project are narrowing the gap between theory and practice in areas such as: modular semantic definitions of languages; scalability to real languages; support for real time; semantics of software and hardware modeling languages; and semantics-based analysis tools such as static analyzers, model checkers, and program provers.	executable;logic programming;logical framework;model checking;modeling language;real-time computing;rewriting;scalability;static program analysis	José Meseguer;Grigore Rosu	2013	Inf. Comput.	10.1016/j.ic.2013.08.004	formal language;potassium;action semantics;rewriting;computer science;theoretical computer science;formal semantics;semantics;ontology language;abstract family of languages;fifth-generation programming language;programming language;well-founded semantics;operational semantics;second-generation programming language;denotational semantics;algorithm	PL	-24.257096382607546	21.548285418728543	179401
e4cb003838321e70cfc2c48f78f85b976dfbcc3e	a theory of lazy imperative timing		Lazy evaluation was introduced as a programming language execution strategy in 1976 by Peter Henderson and Jim Morris [2], and by David Turner [6], and is now part of several programming languages, including Gofer, Miranda, and Haskell. It was introduced into the setting of functional programming, and has mainly stayed there, although it is just as applicable to imperative programs [0]. The name “lazy evaluation” is appropriate in the functional setting, but in the imperative setting it is more appropriately called “lazy execution”.	apl;david turner (computer scientist);functional programming;haskell;imperative programming;lazy evaluation;miranda;norm (social);programming language	Eric C. R. Hehner	2018	CoRR	10.4204/EPTCS.282.1	theoretical computer science;computer science	PL	-21.16371315530984	21.253684682955885	179440
615d3430112fc2d62d7c5773014f94cad3b967f1	integration of automated reasoning and computer algebra systems	computacion informatica;automated reasoning;computer algebra system;ciencias basicas y experimentales;grupo a		automated reasoning;computer algebra system	Olga Caprotti;Volker Sorge	2005	J. Symb. Comput.	10.1016/j.jsc.2004.12.001	automated reasoning;algorithm	Logic	-19.446110872741837	18.570601185934837	179946
80c58fb5631e0c6abbbe6011238a2eaa3cc8422e	parallel and distributed implementation of concurrent logic programming language kl1			concurrent logic programming;kl1;programming language	Keiji Hirata;Reki Yamamoto;Akira Imai;Hideo Kawai;Kiyoshi Hirano;Tsuneyoshi Takagi;Kazuo Taki;Akihiko Nakase;Kazuaki Rokusawa	1992			first-generation programming language;parallel computing;computer architecture;functional logic programming;concurrent logic programming;computer science;logic programming;programming language implementation;fifth-generation programming language;concurrent constraint logic programming;programming domain	PL	-24.445751729248464	22.794487198793103	180602
3a5b06c7f3c98e5be21fa363fd4742bd07021988	compositional security-preserving refinement for concurrent imperative programs			imperative programming	Toby C. Murray;Robert Sison;Edward Pierzchalski;Christine Rizkallah	2016	Archive of Formal Proofs			Logic	-22.381106541871784	21.2221388432453	181035
be3d684bc8947c43a8aca875d2b9703b940656af	coherence of subsumption for monadic types	subtypings a;computational metalanguage;computational effect;monadic type;conversion function	One approach to give semantics to languages with subtypes is by translation to target languages without subtyping: subtypings A ≤ B are interpreted via conversion functions A → B. This paper shows how to extend the method to languages with computational effects, using Moggiu0027s computational metalanguage.	monad (functional programming);subsumption architecture	Jan Schwinghammer	2009	J. Funct. Program.	10.1017/S0956796808006886	programming language;algorithm	PL	-22.76405247431194	22.089996688401346	181193
2af49912fb4e66b92a619537af9f6630e0bf07c0	dimensional flowcharting		SUlMMARY By introducing the idea of axes Dimensional Flowcharting clarifies the representation of sequential and parallel operations. Step-Wise Refinement is added to give an improved method of representing and understanding the design of software. Many of the disadvantages of conventional flowcharting are removed. The dimensionality concept is carried through to the construction of working programs and a dimensional programming language is described.	flowchart;iso 10303;programming language;refinement (computing)	Robert W. Witty	1977	Softw., Pract. Exper.	10.1002/spe.4380070503		PL	-20.65095302995465	21.861994184922246	181304
93fd420860f94763c7be7e85e4996dadfdd151de	formal specification and metaprogramming in the express language			formal specification;metaprogramming	Yamine Aït Ameur;Frederic Besnard;Patrick Girard;Guy Pierra;Jean-Claude Potier	1995			programming language;formal specification;natural language processing;computer science;object language;specification language;metaprogramming;metacompiler;artificial intelligence	PL	-24.17902371823598	21.28947781248999	182052
4ccb500cdf4de548275fba521942b0beb838525a	nua-prolog: an extension to the wam for parallel andorra.		The Andorra Kernel Language (AKL), also known as the Agents Kernel Language, is a logic programming language that combines both don’t know nondeterminism and stream programming. This thesis reports on the design and construction of an abstract machine, the DAM, for the parallel execution of AKL programs. Elements of a compiler for the DAM are also described. As part of the development of the DAM, a bottom-up abstract interpretation for AKL and a logic semantics for the AKL, based on interlaced bilattices have also been developed. This thesis reports on the abstract interpretation and the logical semantics. This thesis is less than 100,000 words in length, exclusive of tables, bibliography and appendices.	abstract interpretation;abstract machine;bottom-up parsing;compiler;interlaced video;nondeterministic algorithm;programming language;prolog;stream processing	Doug Palmer;Lee Naish	1991			programming language;prolog;computer science	PL	-21.51022101598446	22.513779304336644	182082
a78ffe2c22f6ca27ae602863a6a945227a13f571	loop headers in lambda-calculus or cps			lambda calculus	Andrew W. Appel	1994	Lisp and Symbolic Computation			Logic	-22.368724526482744	21.173217458024784	183057
4d4dac8f17a73d0ee0d53ebb60fc6652c21641d0	asm refinement preserving invariants	electronic purses;run. key words: refinement;dynamic logic;mondex;commuting dia- grams;abstract state machines;forward simulation;security;data refinement;theorem prover;abstract state machine	This paper gives a definition of ASM refinement suitable for the verification that a protocol implements atomic transactions. We used this definition as the basis of the formal verification of the refinements of the Mondex case study with the interactive theorem prover KIV. The refinement definition we give differs from the one we gave in earlier work which preserves partial and total correctness assertions of ASM runs. The reason is that the main goal of the refinement of the Mondex protocol is to preserve a security invariant, while total correctness is not preserved. To preserve invariants, the definition of generalized forward simulation is limited to the use of “small” diagrams, which contain of a single protocol step. We show a technique that allows to use the natural “big” diagrams that consist of an atomic action being refined by a full protocol	automated theorem proving;correctness (computer science);diagram;formal verification;invariant (computer science);linearizability;mondex;proof assistant;refinement (computing);simulation;state diagram	Gerhard Schellhorn	2008	J. UCS	10.3217/jucs-014-12-1929	data mining;combustion;cylinder;computer science;oil burner;lever;algorithm;connecting rod;electric discharge in gases;mechanical engineering	Logic	-19.37329314706022	21.399426603468413	183114
0f6b327d59651b1e6f14b614f7caffce673013b0	coupling catch clauses with local declarations	exceptions;theoretical computer science;featherweight java;computational theory and mathematics;typed calculus;language design	We propose an alternative to the usual try-catch construct, where catch clauses are coupled with the declaration of a local variable, rather than with an arbitrary expression. That is, in case initialization of the local variable fails, they provide an alternative computation which does not depend on such variable. This alternative mechanism subsumes the standard one and allows a more natural and functional programming style. We illustrate such advantages by some paradigmatic examples. The proposal is formalized as an extension of Featherweight Java (FJ) with a type system which can be proved to be sound.	computation;declaration (computer programming);functional programming;java;local variable;programming style;type system	Paola Giannini;Marco Servetto;Elena Zucca	2016		10.1145/2955811.2955817	computer science;theoretical computer science;algorithm	PL	-21.68943539123117	24.538184574447833	184079
89a2439b1771a9b30bb8eb03968d403e67911e52	using randomization in the teaching of data structures and algorithms	programming assignments;code maintenance;software engineering;cs2;data structure	We describe an approach for incorporating randomization in the teaching of data structures and algorithms. The proofs we include are quite simple and can easily be made a part of a Freshman-Sophomore Introduction to Data Structures (CS2) course and a Junior-Senior level course on the design and analysis of data structures and algorithms (CS7/DS&amp;A). The main idea of this approach is to show that using randomization in data structures and algorithms is safe and can be used to significantly simplify efficient solutions to various computational problems. We illustrate this approach by giving examples of the use of randomization in some traditional topics from CS2 and DS&amp;A.	computation;computational problem;data structure;randomized algorithm	Michael T. Goodrich;Roberto Tamassia	1999		10.1145/299649.299679	data structure;computer science;theoretical computer science;programming language;algorithm	Theory	-22.234433107475386	18.40572828162368	184498
5c2e9c962a9c6c27bc6be6c59fc9e60679115242	towards the integration of functions, relations and types in an ai programming language	computerlinguistik;programming language;naturliche sprache;kunstliche intelligenz	This paper describes the design and implementation of the programming language PC-Life. This language integrates the functional and the logic-oriented programming style and feature types supporting inheritance. This combination yields a language particularly suited to knowledge representation, especially for application in computational linguistics.	computation;computational linguistics;knowledge representation and reasoning;logic programming;programming language;programming style	Rolf Backofen;Lutz Euler;Günther Görz	1990		10.1007/978-3-642-76071-6_34	natural language processing;fourth-generation programming language;first-generation programming language;natural language programming;very high-level programming language;language primitive;object language;specification language;programming domain;computer science;programming language implementation;extensible programming;functional logic programming;programming paradigm;symbolic programming;low-level programming language;inductive programming;fifth-generation programming language;programming language theory;programming language;language technology;programming language specification;high-level programming language;algorithm	AI	-25.307043740731903	21.936540645036153	184519
0e70ce20f5d916bbb4f243569cfd34e5de58df5c	the poplog program development system		Of the programming environments developed for artificial-intelligence systems, POPLOG is special in that it supports three different languages: POP-11, LISP and PROLOG. Since some problems are better dealt with using one language and some another, a system that combines three has advantages. The components of the POPLOG system are described in detail, and the requirements for its implementat ion are outlined.	artificial intelligence;pop-11;poplog;prolog;requirement	Allan Ramsay	1984	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(84)90253-9	computer science;fifth-generation programming language;programming language;algorithm	Robotics	-25.273976333133955	22.593550814793907	184708
01de2badcf382d884a2f149b0048125f0813bc66	reverse program calculation supported by code slicing	auxiliary variable;algebraic specification;mutual recursion;formal specification;application software;formal specifications;calculation;formal methods;programming algebra;formal semantics;software engineering;functional programming;formal method;semantic functions;algebra;algebraic specification reverse engineering program slicing calculation;calculus;program variables;generic programming schemata;c code;catamorphisms;reverse engineering application software algebra formal specifications software engineering functional programming calculus hardware software design documentation;auxiliary variables imploding;reverse program calculation;code slicing;legacy code formal specifications reconstruction;word count program reverse program calculation code slicing formal methods semi formal methods programming algebra legacy code formal specifications reconstruction formal semantics program variables constructive style auxiliary variables imploding mutual recursion semantic functions generic programming schemata catamorphisms paramorphisms c code haskell;program slicing;word count program;software design;documentation;haskell;paramorphisms;reverse engineering;generic programming;semi formal methods;hardware;constructive style	"""This paper sketches a discipline for reverse engineering which combines formal and semi-formal methods. Among the former is the """"algebra of programming"""", which we apply in """"reverse order"""" so as to reconstruct formal specifications of legacy code. The latter includes code slicing, used as a means of trimming down the complexity of handling the formal semantics of all program variables at the same time. A strong point of the approach is its constructive style. Reverse calculations go as far as imploding auxiliary variables, introducing mutual recursion (if applicable) and transforming semantic functions into standard generic programming schemata such as cata/paramorphisms. We illustrate the approach by reversing a piece of code (from C to Haskell) already studied in the code-slicing literature: the word-count (wc) program."""		Gustavo Villavicencio;José Nuno Oliveira	2001		10.1109/WCRE.2001.957808	formal methods;documentation;computer science;theoretical computer science;operating system;software engineering;formal specification;programming language;algorithm	SE	-23.07743880937747	23.81410683926565	185371
9de1caad8fb0ca1b7eb77131521e54b540cef8b6	a system for automatic drafting encoding	software systems;hybrid approach;symbol recognition	A comple te s o f t w a r e system f o r automat ic d r a f t i n g encoding i s desc r i bed . T h i s system decomposes t h e o r i g i n a l d r a f t i n t o a g raph i c p r i m i t i ve -based d e s c r i p t i o n , s u i t a b l e f o r subsequent CAD process ing. Problems r e l a t i v e t o t h e b ina r i z a t i o n phase and t h e symbol r e c o g n i t i o n s t e p a r e a l s o covered and a h y b r i d approach i s p ro -	computer-aided design;data compression;operating system;spec#;system f;unix	Vito Cappellini;Franco Flamigni;Alessandro Mecocci	1988			simulation;speech recognition;computer science;software system	AI	-26.332903210683657	19.897141308543045	185612
dfa04438f286d9886366f9390f65c8853e3fd6f2	eresye: artificial intelligence in erlang programs	expert systems;production system;artificial intelligent;object oriented;intelligent system;ontologies;erlang;rete algorithm;expert system	This paper describes ERESYE, a tool for the realization of intelligent systems expert systems) using the Erlang language. ERESYE is a rule production system that allows rules to be written as Erlang function clauses, providing support for their execution. ERESYE is also able to support object-oriented concepts and ontologies thanks to a suitable ontology handling tool, providing means to translate object-based concepts into an Erlang form. The architecture of ERESYE and its basic working scheme are described in the paper. A comparison with CLIPS, one of the most known tools for expert system programming, is also made. The description of some examples of ERESYE usage are provided to show the effectiveness and the validity of the proposed solution, which opens new and interesting application scenario for Erlang.	artificial intelligence;c++;clips;erlang (programming language);expert system;java;logic programming;object-based language;ontology (information science);production system (computer science);rewriting;system programming;turing completeness	Antonella Di Stefano;Francesca Gangemi;Corrado Santoro	2005		10.1145/1088361.1088373	erlang;computer science;ontology;rete algorithm;database;production system;programming language;object-oriented programming;expert system	AI	-25.479727894831175	20.715107282451857	185628
03ce584beafeac7ed9f201af37df3c4194b66a6c	logic engines as interactors	agent oriented programming language constructs;programming language;and forward;building block;logic engines;agent oriented programming;generalized iterators;language extension;metaprogramming	We introduce a new programming language construct, Interactors, supporting the agent-oriented view that programming is a dialog between simple, self-contained, autonomous building blocks. We define Interactors as an abstraction of answer generation and refinement in Logic Engines resulting in expressive language extension and metaprogramming patterns, including emulation of Prolog’s dynamic database. A mapping between backtracking based answer generation in the callee and “forward” recursion in the caller enables interaction between different branches of the callee’s search process and provides simplified design patterns for algorithms involving combinatorial generation and infinite answer streams. Interactors extend language constructs like Ruby, Python and C#’s multiple coroutining block returns through yield statements and they can emulate the action of monadic constructs and catamorphisms in functional languages.	agent-oriented programming;algorithm;application programming interface;autonomous robot;backtracking;catamorphism;control flow;design pattern;emulator;fluent interface;iterator;language construct;metaprogramming;monad (functional programming);pl/i;programmer;programming language;programming productivity;prolog;python;recursion;refinement (computing);ruby;software development;symbolic computation;dialog	Paul Tarau	2008		10.1007/978-3-540-89982-2_61	metaprogramming;fourth-generation programming language;first-generation programming language;very high-level programming language;language primitive;programming domain;computer science;theoretical computer science;functional logic programming;programming paradigm;fifth-generation programming language;programming language;logic programming;high-level programming language;algorithm	PL	-23.175729285714855	22.82366035225931	186282
6c2a80a3a8b846b3d96e5f62a758cf507937a1b1	a little history and a fortran 90 summary	forma libre;lenguaje programacion;modulo;appel procedure;standards;development;programming language;free form;evolucion;desarrollo;fortran 90;language summary;forme libre;standards development;llamada procedimiento;developpement;estructura datos;norma;langage programmation;structure donnee;fortran;data structure;procedure call;module;norme;evolution	Some of the history of the development of the Fortran language is presented, from a de facto standard early in the 1950s at IBM to the major revision that Fortran 90 represents. The article concludes with a short description of the major features of the language.	fortran	Jeanne Adams;Walter S. Brainerd	1996	Computer Standards & Interfaces	10.1016/0920-5489(96)01003-3	module;data structure;computer science;evolution;programming language;algorithm;modulo	Visualization	-25.87901168758008	23.695749746882903	186598
a7d4ec2a5daba3a6af5af4fc0c181c07d877238f	evolp: an implementation	stable model semantics	In this paper we present an implementation of EVOLP under the Evolution Stable Model semantics, based on the transformation defined in [1]. We also discuss optimizations used in the implementation.	benchmark (computing);logic programming;program optimization;stable model semantics	Martin Slota;João Leite	2007		10.1007/978-3-540-88833-8_16	stable model semantics;computer science;theoretical computer science;programming language;operational semantics;algorithm	DB	-21.826312158391623	22.410212405760962	186694
3fd92d64fed4976a6d85cb4a9d5b7001df278adb	type-checking systems with particular applications to functional languages	computer science		functional programming;type system	H. K. F. Yeung	1976			natural language processing;computer science;theoretical computer science;ontology language;programming language theory;second-generation programming language;comparison of multi-paradigm programming languages	Logic	-24.140192463508463	22.12853726459943	186836
8fec740468a904bafe16594e9ce4b64fcfdb7eb7	reasonably programmable literal notation		General-purpose programming languages typically define literal notation for only a small number of common data structures, like lists. This is unsatisfying because there are many other data structures for which literal notation might be useful, e.g. finite maps, regular expressions, HTML elements, SQL queries, syntax trees for various languages and chemical structures. There may also be different implementations of each of these data structures behind a common interface that could all benefit from common literal notation. This paper introduces typed literal macros (TLMs), which allow library providers to define new literal notation of nearly arbitrary design at any specified type or parameterized family of types. Compared to existing approaches, TLMs are uniquely reasonable. TLM clients can reason abstractly, i.e. without examining grammars or generated expansions, about types and binding. The system only needs to convey to clients, via secondary notation, the inferred segmentation of each literal body, which gives the locations and types of spliced subterms. TLM providers can reason modularly about syntactic ambiguity and expansion correctness according to clear criteria. This paper incorporates TLMs into Reason, an emerging alternative front-end for OCaml, and demonstrates, through several non-trivial case studies, how TLMs integrate with the advanced features of OCaml, including pattern matching and the module system. We also discuss optional integration with MetaOCaml, which allows TLM providers to be more confident about type correctness. Finally, we establish these abstract reasoning principles formally with a detailed type-theoretic account of expression and pattern TLMs for “core ML”.	correctness (computer science);data structure;general-purpose programming language;global variable;html;literal (computer programming);literal (mathematical logic);map;modular programming;name binding;ocaml;pattern matching;regular expression;secondary notation;type theory	Cyrus Omar;Jonathan Aldrich	2018	PACMPL	10.1145/3236801	programming language;parsing;notation;correctness;pattern matching;regular expression;data structure;syntax;rule-based machine translation;computer science	PL	-24.33643278111956	25.194724579461564	187038
070f50d13d8442eadc55886612276f4ba499aae1	a language for interactive audio applications	efficient implementation;interactive system;signal processing;object oriented approach;functional language;high level language;real time computing	Interactive systems are difficult to program, but high-level languages can make the task much simpler. Interactive audio and music systems are a particularly interesting case because signal processing seems to favor a functional language approach while the handling of interactive parameter updates, sound events, and other real-time computation favors a more imperative or object-oriented approach. A new language, Serpent, and a new semantics for interactive audio have been implemented and tested. The result is an elegant way to express interactive audio algorithms and an efficient implementation.	algorithm;computation;event-driven programming;functional programming;high- and low-level;ibm notes;ibm research;imperative programming;real-time cmix;signal processing;technical support;very high-level programming language	Roger B. Dannenberg	2002			natural language processing;universal networking language;language primitive;specification language;data control language;computer science;programming language implementation;theoretical computer science;low-level programming language;modeling language;programming language;language technology	PL	-25.62892064577045	22.682733677815953	187321
3421ed6f9d77e736ed20fc425fa62cd86b974edd	finite domain constraints in the ml functional language	finite domain constraints;constraint logic programs;chip;finite domain;functional languages constraint handling;logic programming computer languages programming profession search problems problem solving equations circuit simulation arithmetic functional programming merging;functional languages;constraint handling;constraint solving;constraint satisfaction problem;linear equations;linear equations finite domain constraints ml functional language handling constraints finite domains constraint logic programming constraint satisfaction problems problem solving example;functional language;problem solving	W e propose an extension of the ML language for handling constraints in finite domains, as originally proposed by the C H I P Constraint Logic Programming Language, following and edend ing techniques originating f r o m Constraint Satisfaction Problems. This makes i t possible for the programmer to declaratively combine in a single application both purely functional parts and constraint sohing parts for ef ic ient handling of discrete search problems. In order t o show ihe effect iveness of this approach, we present a simple demonstrative problem-solving example using finite domain constraints such as linear equations and disequations.	constraint logic programming;constraint satisfaction;functional programming;linear equation;problem solving;programmer;programming language	Emmanuel Chailloux;Christian Codognet;Philippe Codognet	1994		10.1109/TAI.1994.346401	chip;constraint logic programming;concurrent constraint logic programming;mathematical optimization;constraint programming;binary constraint;constraint satisfaction;programming domain;constraint learning;computer science;constraint graph;constraint satisfaction dual problem;complexity of constraint satisfaction;linear equation;inductive programming;constraint;fifth-generation programming language;programming language;functional programming;satisfiability modulo theories;constraint satisfaction problem;algorithm;hybrid algorithm;local consistency;backtracking	AI	-22.54850074468953	19.51161394963674	187475
bcb22490832217f24c2d220422fbb1750cc91d35	alternatives to two classic data structures	leftist heaps;maxiphobic heaps;red black trees;data structure	Red-black trees and leftist heaps are classic data structures that are commonly taught in Data Structures (CS2) and/or Algorithms (CS7) courses. This paper describes alternatives to these two data structures that may offer pedagogical advantages for typical students.	algorithm;data structure;fibonacci heap;leftist tree;red–black tree	Chris Okasaki	2005		10.1145/1047344.1047407	red–black tree;data structure;computer science;programming language;algorithm	Theory	-22.419815975183344	18.337099827498502	188626
260f5e640fca3be835c77049ebd27e8e9f78e474	one, none, a hundred thousand specification languages - response	specification language			Giorgio Levi	1986			specification language;programming language;computer science	Logic	-23.853625397717238	21.04564111321312	188833
60157c73d28ae34c0ff9edf02520fb2c317582b1	specification of compilers as abstract data type representations	abstract data type;data type	This paper presents a method for specifying and proving compilers. This method is based on the algebraic data types ideas. The main points are :rnrnrnto each language is associated an algebraic abstract data type.rnrnrnthe semantic value of a program is given as a term of this data type.rnrnrnthe translation of the semantic values of source programs into semantic values of target programs is specified and proved as the representation of an algebraic data type by another one.	abstract data type;compiler	Marie-Claude Gaudel	1980		10.1007/3-540-10250-7_21	composite data type;type conversion;parallel computing;type family;data type;computer science;recursive data type;database;programming language;abstract data type;generalized algebraic data type;complex data type	PL	-23.033841454101744	23.514448589581143	188926
58f9a66ad85ddd0e477776e7f751e95f8b3f2eb0	an algebraic semantics for the object specification language troll light	specification language;transition systems;information system;state transition	Within the KORSO project we have developed the object speciication language TROLL light which allows to describe the part of the world to be modeled as a community of concurrently existing and communicating objects. Recently, we have worked out the basic notions of a pure algebraic semantics for our language. The main underlying idea is to present a transition system where the states represent the states of the speciied information system, and state transitions are caused by the occurrence of nite sets of events. This semantics is formulated by representing states and state transitions as algebras. The various constructs of TROLL light are uniied to general axioms restricting the possible interpretations for TROLL light object descriptions.	algebraic semantics (computer science);information system;linear algebra;open research;specification language;transition system	Martin Gogolla;Rudolf Herzig	1994		10.1007/BFb0014434	natural language processing;object language;specification language;computer science;theoretical computer science;programming language;programming language specification;language of temporal ordering specification	AI	-24.11484942960009	19.68504520769408	189764
56f1e23dee78e2089728a176c00f00f5faf6efbf	logical-framework-based program development	logical framework;theorem prover;program development;first order logic	Permission to make digital/hard copy of part or all of this work for personal or classroom use is granted without fee provided that the copies are not made or distributed for profit or commercial advantage, the copyright notice, the title of the publication, and its date appear, and notice is given that copying is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.		David A. Basin	1998	ACM Comput. Surv.	10.1145/289121.289122	non-classical logic;logical framework;computer science;truth table;logical conjunction;first-order logic;automated theorem proving;programming language;algorithm	DB	-20.955041250498436	19.630206542115936	190134
220079f23f2ad4cd5b422cc7b74084cec575a95e	associative program retrieval using partially-ordered behavioral abstractions of a program.	partial order			Hideaki Suzuki;Naohisa Takahashi	1994			partially ordered set;computer science	ML	-22.647212170577962	20.022934272896535	190159
5bd50cb5f03457b048e501236c148bc965e72b8c	graph grammars and operational semantics	operational semantics;graph grammar;semantics of programming languages	Transformations of graphlike expressions are called correct if they preserve a given functional semantics of the expressions. Combining the algebraic theories of graph grammars (cf. [lo]) and programming language semantics (cf. [l]) it will be proved that the correctness of transformation rules carries over to the correctness of derivations via such rules. Applying this result to LISP we show that a LISP interpreter represented by a graph grammar is correct with respect to the functional semantics of graphlike LISP expressions.	correctness (computer science);graph rewriting;linear algebra;operational semantics;programming language;semantics (computer science)	Peter Padawitz	1978		10.1007/BFb0025732	natural language processing;context-sensitive grammar;tree-adjoining grammar;formal language;formal semantics;action semantics;type erasure;theoretical computer science;formal semantics;semantics;programming language;well-founded semantics;operational semantics;denotational semantics;computational semantics;graph rewriting	PL	-23.020022403503976	21.857153242993043	190201
82269d583a5305ab3bb9b3c5bff23709f40fd55e	a programming language with natural persistence	programming language;language design and implementation;language design;object persistence	As data persistence is very poorly supported by current programming systems, we have initiated a research project to improve this situation. The result is the new programming language Persistent Active Oberon, which directly institutionalizes persistence as a fundamental concept and liberates the programmer from writing complicated code for database interactions.	apl;active oberon;interaction;pl/i;persistence (computer science);persistent data structure;programmer;programming language	Luc Bläser	2006		10.1145/1176617.1176649	natural language processing;fourth-generation programming language;first-generation programming language;natural language programming;system prevalence;very high-level programming language;language primitive;data manipulation language;object language;specification language;programming domain;data control language;computer science;programming language implementation;theoretical computer science;extensible programming;functional logic programming;programming paradigm;symbolic programming;low-level programming language;fifth-generation programming language;programming language theory;programming language;programming language specification;high-level programming language	PL	-25.071139084993284	22.50914679685279	193775
b98938ac2d910fc06f255ff5d107df9850f73e39	generic programming within dependently typed programming	dependently typed programming;generic programming;dependent types	We show how higher kinded generic programming can be represented faithfully within a dependently typed programming system. This development has been implemented using the Oleg system. The present work can be seen as evidence for our thesis that extensions of type systems can be done by programming within a dependently typed language, using data as codes for types.	admissible numbering;code;dependent type;generic programming;kind (type theory);type system	Thorsten Altenkirch;Conor McBride	2002			real-time computing;programming language;algorithm	PL	-22.65129774606869	23.615263242417427	193813
0c229e32ec6bf291ac74ef5cb474789f84f0aad4	denotational semantics of shape: past, present and future	programming language;shape analysis;higher order;denotational semantic;polymorphism;static analysis	Abstract   Past work on the semantics of vectors and arrays provides a denotational semantics for the new, higher-order, polymorphic array programming language FISh, that uses static analysis to determine array shapes. This semantics will be combined with that of shape polymorphism to underpin a language that will support both shape analysis and shape polymorphism on both arrays and inductive types.	denotational semantics	C. Barry Jay	1999	Electr. Notes Theor. Comput. Sci.	10.1016/S1571-0661(04)80081-1	polymorphism;normalisation by evaluation;higher-order logic;computer science;theoretical computer science;domain theory;shape analysis;programming language;denotational semantics of the actor model;operational semantics;static analysis;denotational semantics;algorithm	Theory	-22.66520746488529	21.978974828649275	193964
09661a6bb7578979e42c75d6ce382baba64d4981	proving theorems about lisp functions	program verification;theorem proving;automatic theorem proving	We d e s c r i b e some s i m p l e h e u r i s t i c s comb in ing e v a l u a t i o n and ma themat i ca l i n d u c t i o n wh ich we have implemented in a program t h a t a u t o m a t i c a l l y p roves a wide v a r i e t y o f theorems about r e c u r s i v e LISP f u n c t i o n s . The method the program uses t o gene ra te i n d u c t i o n f o r m u l a s i s d e s c r i b e d a t l e n g t h . The theorems proved by t h e p r o ­ gram i n c l u d e t h a t REVERSE i s i t s own i n v e r s e and t h a t a p a r t i c u l a r SORT program is c o r r e c t . Append ix B c o n t a i n s a l i s t o f the theorems p roved by t h e p r o g r a m .	append;artificial intelligence;i/o controller hub;n-gram	Robert S. Boyer;J. Strother Moore	1973	J. ACM	10.1145/321864.321875	discrete mathematics;hol;computer science;mathematics;automated theorem proving;programming language;algorithm	AI	-20.310210483384918	19.283244499963075	194048
80540575e0545ca74fd1af83f934190625bc84d5	mechanization of program construction in martin-loef's theory of types			type theory	Andrew Ireland	1989				Logic	-19.826679814077178	18.856104522192776	194053
5ed62509d17414a80eb7b5cc9fb10401df6f4aa9	a backtracking lr algorithm for parsing ambiguous context-dependent languages	context free grammar;context dependent;data structure	Parsing context-dependent computer languages requires an ability to maintain and query data structures while parsing for the purpose of influencing the parse. Parsing ambiguous computer languages requires an ability to generate a parser for arbitrary context-free grammars. In both cases we have tools for generating parsers from a grammar. However, languages that have both of these properties simultaneously are much more difficult to parse. Consequently, we have fewer techniques. One approach to parsing such languages is to endow traditional LR systems with backtracking. This is a step towards a working solution, however there are number of problems. In this work we present two enhancements to a basic backtracking LR approach which enable the parsing of computer languages that are both context-dependent and ambiguous. Using our system we have produced a fast parser for C++ that is composed of strictly a scanner, a name lookup stage and parser generated from a grammar augmented with semantic actions and semantic 'undo' actions. Language ambiguities are resolved by prioritizing grammar declarations.	algorithm;backtracking;c++;computer language;context-free grammar;context-free language;context-sensitive language;data structure;lr parser;lookup table;parsing;undo	Adrian D. Thurston;James R. Cordy	2006		10.1145/1188966.1188972	natural language processing;parser combinator;memoization;lalr parser;canonical lr parser;data structure;parsing expression grammar;operator-precedence grammar;top-down parsing language;computer science;bottom-up parsing;syntactic predicate;theoretical computer science;context-dependent memory;parsing;glr parser;s-attributed grammar;syntax;extended affix grammar;database;context-free grammar;programming language;ambiguous grammar;recursive descent parser;top-down parsing;lr parser;simple lr parser	NLP	-24.443667320976044	24.497196387073085	194451
1bdd8ad3ad8590ecfb9b346f2af637b1c35e689b	abstract answer set solvers	davis putnam logemann loveland;answer sets;dpll procedure;bepress selected works;asp sat;davis putnam logemann loveland procedure;answer set solvers;answer set solvers smodels asp sat backtracking davis putnam logemann loveland procedure dpll procedure;transition systems;backtracking;logic programs;smodels	"""Answer Set Solvers Yuliya Lierler University of Nebraska at Omaha, ylierler@unomaha.edu Follow this and additional works at: https://digitalcommons.unomaha.edu/compsicfacproc Part of the Computer Sciences Commons This Conference Proceeding is brought to you for free and open access by the Department of Computer Science at DigitalCommons@UNO. It has been accepted for inclusion in Computer Science Faculty Proceedings & Presentations by an authorized administrator of DigitalCommons@UNO. For more information, please contact unodigitalcommons@unomaha.edu. Recommended Citation Lierler, Yuliya, """"Abstract Answer Set Solvers"""" (2008). Computer Science Faculty Proceedings & Presentations. 6. https://digitalcommons.unomaha.edu/compsicfacproc/6 Abstract Answer Set SolversAnswer Set Solvers Yuliya Lierler University of Texas at Austin yuliya@cs.utexas.edu Abstract Nieuwenhuis, Oliveras, and Tinelli showed how to describe enhancements of the Davis-Putnam-Logemann-Loveland algorithm using transition systems, instead of pseudocode. We design a similar framework for three algorithms that generate answer sets for logic programs: SMODELS, ASP-SAT with Backtracking, and a newly designed and implemented algorithm SUP. This approach to describing answer set solvers makes it easier to prove their correctness, to compare them, and to design new systems.Nieuwenhuis, Oliveras, and Tinelli showed how to describe enhancements of the Davis-Putnam-Logemann-Loveland algorithm using transition systems, instead of pseudocode. We design a similar framework for three algorithms that generate answer sets for logic programs: SMODELS, ASP-SAT with Backtracking, and a newly designed and implemented algorithm SUP. This approach to describing answer set solvers makes it easier to prove their correctness, to compare them, and to design new systems."""	answer set programming;authorization;backjumping;backtracking;computer science;correctness (computer science);dpll algorithm;disjunctive normal form;logic programming;marco dorigo;michael gelfond;pseudocode;putnam model;simple update protocol;software upgrade protocol;stable model semantics;vladimir lifschitz	Yuliya Lierler	2008		10.1007/978-3-540-89982-2_35	computer science;answer set programming;dpll algorithm;algorithm;backtracking	AI	-20.48743230292758	20.057284570666077	194754
f8cdc0e34b7d9759b1a8347d08ed6b9e8e17d9b5	camlflow: a caml to data-flow graph translator	data flow graph	We presentCAMLFLOW, a customCAML to data-flow graph (DFG) compiler.CAMLFLOW was designed to provide a front-end to various implementation-level parallel programming CASE tools taking DFGs for algorithm specification. It allows large and complex DFGs to be described in a t extual and concise manner, using the facilities of the CAML LIGHT functional language. Compared to other graph notation systems, the main originality of CAMLFLOW lies in its ability to define higher-order polymorphic graph patterns.	algorithm;caml;compiler;data-flow analysis;dataflow;functional programming;parallel computing	Jocelyn Sérot	2000			natural language processing;computer science;clique-width;theoretical computer science;graph;programming language	PL	-23.681979924444867	24.771837084562918	194778
e45ab19c39fa5d8eb8a4a786867c4030afb454a5	a machine description facility for compiler testing	program processors application software computer aided instruction computational modeling high level languages wiring registers system testing performance evaluation contracts;computer model;data type;program verification;compiler testing;compilers;program verification compilers compiler testing correctness data types lisp machine description languages program testing;correctness;program testing;lisp;high level language;machine description languages;data types;intermediate representation	Requirements for a machine description facility for compiler testing are discussed. The compiler testing procedure consists of proving that programs are correctly translated by the compiler at hand. This is achieved by use of a common intermediate representation for both the source and object programs. The intermediate representation for the object program is built by use of a process termed symbolic interpretation. This process interprets a set of procedures which describe the effects of machine language instructions corresponding to the target machine on a suitable computation model in a manner consistent with an execution level definition of the high level language. Some of the important factors which enter into such a definition are discussed. These include architectural constraints posed by the target machine, and a description facility for memory and data types. Once such a definition is formulated, the actual instruction set of the target machine can be described. The highlights and limitations of such a definition facility are discussed in the context of a specific LISP implementation on a PDP-10 computer.	accumulator (computing);address space;array data structure;bessel filter;correctness (computer science);decompiler;executable;gnu compiler collection;high-level programming language;intermediate representation;linear algebra;lisp;machine code;memory management;model of computation;pdp-1;pdp-10;pascal;status register	Hanan Samet	1977	IEEE Transactions on Software Engineering	10.1109/TSE.1977.231159	computer simulation;hand coding;computer architecture;compiler;parallel computing;interpreter;data type;compiler correctness;computer science;operating system;compiler construction;program optimization;optimizing compiler;bootstrapping;programming language;functional compiler	PL	-26.282820649351386	24.49076376721315	194946
238256c49f836bef9b43ce5766b3276345aff173	transforming generate-and-test programs to execute under committed-choice and-parallelism	parallelisme;lenguaje programacion;et parallelisme;programming language;prolog;multiple solution;program transformation;swinburne;logical programming;transformation programme;parallelism;transformacion programa;paralelismo;choice models;programmation logique;langage programmation;parallel programs;programacion logica	This paper concerns the exploitation of user transparent inherent parallelism of pure Prolog programs using program transformation. We describe a novel paradigmenumerate-and-filter for transforming generate-and-test programs for execution under the committed-choice model extended to incorporate multiple solutions based on set enumeration. The paradigm simulates OR-parallelism by stream AND-parallelism integrating OR-parallelism, AND-parallelism, and stream parallelism. Generate-and-test programs are classified into three categories:simple generate-and-test, recursively embedded generate-and-test, and deeply intertwined generate-and-test. The intermediate programs are further transformed to reduce structure copying and metacalls. Algorithms are presented and demonstrated by transforming the representative examples of different classes of generate-and-test programs to Flat Concurrent Prolog equivalents. Statistics show that the techniques are efficient.	algorithm;choice modelling;embedded system;parallel computing;program transformation;programming paradigm;prolog;recursion	Arvind K. Bansal;Leon Sterling	1989	International Journal of Parallel Programming	10.1007/BF01379187	parallel computing;computer science;theoretical computer science;operating system;programming language;prolog;algorithm	PL	-20.96323390215411	23.65913003091027	195033
be91313fc4f44865a997bd2080985c104e163653	certified programming with dependent types - a pragmatic introduction to the coq proof assistant			coq (software);dependent type;proof assistant	Adam Chlipala	2013				PL	-21.726318863775408	20.687448337199065	197865
842fe083b01b8b6b396d2a053de9a26dba66e52c	transforming the .net intermediate language using path logic programming	program transformation;intermediate language;logic programming;compiler optimisations;program analysis;logic programs;obfuscation;meta programming	Path logic programming is a modest extension of Prolog for the specification of program transformations. We give an informal introduction to this extension, and we show how it can be used in coding standard compiler optimisations, and also a number of obfuscating transformations. The object language is the Microsoft .NET intermediate language (IL).	.net framework;compiler;logic programming;object language;program transformation;prolog	Stephen Drape;Oege de Moor;Ganesh Sittampalam	2002		10.1145/571157.571171	program analysis;metaprogramming;first-generation programming language;compiler;dynamic compilation;declarative programming;very high-level programming language;obfuscation;language primitive;horn clause;programming domain;computer science;theoretical computer science;functional logic programming;common intermediate language;programming paradigm;symbolic programming;low-level programming language;inductive programming;datalog;fifth-generation programming language;programming language;intermediate language;prolog;logic programming;programming language specification;high-level programming language;algorithm	PL	-22.70394141179394	23.97903925377222	199061
