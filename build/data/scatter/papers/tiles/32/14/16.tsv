id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
326b8273aab512aa3a2baac04c8eb849f812cf24	relevance as deduction: a logical view of information retrieval	belief function;logical framework;nonmonotonic logic;information retrieval;logic in computer science;point of view;relevance feedback	The problem of Information Retrieval is, given a set of documents D and a query q, providing an algorithm for retrieving all documents in D relevant to q. However, retrieval should depend and be updated whenever the user is able to provide as an input a preferred set of relevant documents; this process is known as relevance feedback. Recent work in IR has been paying great attention to models which employ a logical approach; the advantage being that one can have a simple computable characterization of retrieval on the basis of a pure logical analysis of retrieval. Most of the logical models make use of probabilities or similar belief functions in order to introduce the inductive component whereby uncertainty is treated. Their general paradigm is the following: find the nature of conditional d → q and then define a probability on the top of it. We just reverse this point of view; first use the numerical information, frequencies or probabilities, then define your own logical consequence. More generally, we claim that retrieval is a form of deduction. We introduce a simple but powerful logical framework of relevance feedback, derived from the well founded area of nonmonotonic logic. This description can help us evaluate, describe and compare from a theoretical point of view previous approaches based on conditionals or probabilities. The first difficulty one encounters towards a logical approach to Information Retrieval is how one should view the algorithm which returns a set of relevant documents. Our proposal is to see such an algorithm as a proof. However, this proof is not classical because, as it is widely recognized, q → d, where q is a query and d a document relevant to q, is not conveyed by the material implication (see [vR86],[vR89]). Also, as the set of data which this proof is based is subject to updating, nonmotonicity arises. Since there is no need of nesting implications, implication and deduction can be identified and therefore our starting point is to axiomatize a deduction q ∼ d. The consequence relation ∼ will reflect the properties that relevance satisfies. A similar approach where nonmonotonic 1	algorithm;computable function;conditional (computer programming);document;information retrieval;logical framework;natural deduction;non-monotonic logic;numerical analysis;point of view (computer hardware company);programming paradigm;relevance feedback;whole earth 'lectronic link	Gianni Amati;Konstantinos Georgatos	2000	CoRR		non-classical logic;logical reasoning;logical framework;logical consequence;computer science;non-monotonic logic;truth table;machine learning;data mining;information retrieval;algorithm	Web+IR	-14.692889560853061	6.659670806380175	131663
aa8be93a4bdd14d191248ced1ecad8688168805b	variations of constrained default logic	default logic	A b s t r a c t . Recently a variant of Reiter 's default logic, called constrained default logic, has been developed in order to overcome certain shortcomings of the original approach. In this paper, we introduce a very simple but powerful extension of constrained default logic, called preconstrained default logic. We demonstrate that adding certain preconstraints to default theories results in very expressive systems: Apar t from representing heuristic control information, pre-constraints provide simple mechanisms for dealing with default lemmas and for incorporating priorities. Finally, we describe how pre-constrained default logic is related to other well-known approaches.	default logic;heuristic	Torsten Schaub	1993		10.1007/BFb0028215	computer science;artificial intelligence;default logic	AI	-15.680232638828043	9.244028903052161	131708
36b73466306d98823250d594c28a62dcb1cccb16	exception-based knowledge updates		Existing methods for dealing with knowledge updates differ greatly depending on the underlying knowledge representation formalism. When Classical Logic is used, updates are typically performed by manipulating the knowledge base on the model-theoretic level. On the opposite side of the spectrum stand the semantics for updating Answer-Set Programs that need to rely on rule syntax. Yet, a unifying perspective that could embrace both these branches of research is of great importance as it enables a deeper understanding of all involved methods and principles and creates room for their cross-fertilisation, ripening and further development. Furthermore, from a more pragmatic viewpoint, such a unification is a necessary step in addressing updates of hybrid knowledge bases consisting of both a classical and a rule component. This paper bridges the seemingly irreconcilable approaches to updates. It introduces a novel monotonic characterisation of rules, dubbed RE-models, and shows it to be a more suitable semantic foundation for rule updates than SE-models. Then it proposes a generic scheme for specifying semantic rule update operators, based on the idea of viewing a program as the set of sets of RE-models of its rules; updates are performed by introducing additional interpretations – exceptions – to the sets of RE-models of rules in the original program. The introduced scheme is then used to define particular rule update operators that are closely related to both classical update principles and traditional approaches to rules updates, enjoying a range of plausible syntactic as well as semantic properties. In addition, these operators serve as a basis for a solution to the long-standing problem of state condensing for two of the foundational rule update semantics, showing how they can be equivalently defined as binary operators on some class of logic programs. Finally, the essence of these ideas is extracted to define an abstract framework for exception-based update operators, viewing a knowledge base as the set of sets of models of its elements. It is shown that the framework can capture a wide range of both modeland formula-based classical update operators, and thus serves as the first firm formal ground connecting classical and rule updates.	exception handling;knowledge base;knowledge representation and reasoning;semantics (computer science);theory;unification (computer science)	Martin Slota;João Leite	2017	CoRR		classical logic;theoretical computer science;knowledge representation and reasoning;operator (computer programming);syntax;knowledge base;semantics;formalism (philosophy);binary operation;computer science	AI	-17.040603402065145	8.033112074372026	132999
e0eaa91b4ee9bbebeba9336d957c9c18da38902c	error-statistical elimination of alternative hypotheses	theory of evidence;experimental model;science philosophy;equivalence principle;philosophie des sciences	I consider the error-statistical account as both a theory of evidence and as a theory of inference. I seek to show how inferences regarding the truth of hypotheses can be upheld by avoiding a certain kind of alternative hypothesis problem. In addition to the testing of assumptions behind the experimental model, I discuss the role of judgments of implausibility. A benefit of my analysis is that it reveals a continuity in the application of error-statistical assessment to low-level empirical hypotheses and highly general theoretical principles. This last point is illustrated with a brief sketch of the issues involved in the parametric framework analysis of tests of physical theories such as General Relativity and of fundamental physical principles such as the Einstein Equivalence Principle.	aris express;high- and low-level;jean;numerical relativity;scott continuity;theory;turing completeness;uncertainty principle	Kent Staley	2007	Synthese	10.1007/s11229-007-9294-2	epistemology;mathematics;equivalence principle;quantum mechanics	AI	-14.491402615726937	4.6050511499544635	133200
ff661ceab11a5461421fce637c2f78de059c4edf	integrating rules and description logics by circumscription		We present a new approach to characterizing the semantics for the integration of rules and first-order logic in general, and description logics in particular, based on a circumscription characterization of answer set programming, introduced earlier by Lin and Zhou. We show that both Rosati’s semantics based on NM-models and Lukasiewicz’s answer set semantics can be characterized by circumscription, and the difference between the two can be seen as a matter of circumscription policies. This approach leads to a number of new insights. First, we rebut a criticism on Lukasiewicz’s semantics for its inability to reason for negative consequences. Second, our approach leads to a spectrum of possible semantics based on different circumscription policies, and shows a clear picture of how they are related. Finally, we show that the idea of this paper can be applied to first-order general stable models.	answer set programming;circumscription (logic);description logic;first-order logic;first-order predicate;stable model semantics	Qian Yang;Jia-Huai You;Zhiyong Feng	2011			well-founded semantics;circumscription;algorithm	AI	-14.918138824378033	6.516419625907381	133229
37d46cbc263633f63ee61fe3f60df351fdb80fca	possibilistic justification logic: reasoning about justified uncertain beliefs	realization theorem;modal logic;possibilistic logic;justification logic	Justification logic originated from the study of the logic of proofs. However, in a more general setting, it may be regarded as a kind of explicit epistemic logic. In such logic, the reasons a fact is believed are explicitly represented as justification terms. Traditionally, the modeling of uncertain beliefs is crucially important for epistemic reasoning. Graded modal logics interpreted with possibility theory semantics have been successfully applied to the representation and reasoning of uncertain beliefs; however, they cannot keep track of the reasons an agent believes a fact. This article is aimed at extending the graded modal logics with explicit justifications. We introduce a possibilistic justification logic, present its syntax and semantics, and investigate its metaproperties, such as soundness, completeness, and realizability.	agent-based model;classical modal logic;epistemic modal logic;logic programming;natural deduction;possibility theory;qml;reason maintenance	Che-Ping Su;Tuan-Fang Fan;Churn-Jung Liau	2017	ACM Trans. Comput. Log.	10.1145/3091118	modal logic;predicate logic;dynamic logic;normal modal logic;discrete mathematics;description logic;higher-order logic;epistemic modal logic;many-valued logic;intuitionistic logic;intermediate logic;non-monotonic logic;computational logic;mathematics;probabilistic logic network;accessibility relation;logic;term logic;multimodal logic;algorithm;philosophy of logic;autoepistemic logic	AI	-15.42479078157189	6.44036142549298	133428
2e99d6ca7ba1649d359bad842eddd0ef19358b25	une remarque sur les systèmes complets d'identités rationnelles		Une regle deductive tres simple permet de relier des problemes de completude souleves par Conway et Salomaa		Maurice Boffa	1990	ITA		calculus;mathematics;axiom;logic;algorithm;algebra	Crypto	-12.542995224532955	10.269944910408721	133951
59c61a5fc3d64512932f83ad8eabe02ae84f6066	an aspic-based legal argumentation framework for deontic reasoning	deontic modalities dynamic legal argumentation input output logic	In the last years, argumentation theory has been exploited to reason about norms, argue about enforced obligations and permissions, and establish the validity of norms seen as argumentative claims. In this paper, we start from the dynamic legal argumentation framework recently proposed by Prakken and Sartor, and we extend their ASPIC-based system by introducing deontic modalities, to include also normative concepts like factual and deontic detachment, and normative dynamics. Properties of the original and proposed legal argumentation system are presented and discussed, and related to deontic logic and logics of normative systems.	argumentation framework;defeasible reasoning;deontic logic;input/output;quantifier (logic);turing completeness;universal quantification;while	Leon van der Torre;Serena Villata	2014		10.3233/978-1-61499-436-7-421	computer science;knowledge management;artificial intelligence;deontic logic;algorithm	AI	-16.48757614291927	6.1767109796011574	134033
779526c091856567fc79f681a626e7080a600680	problems in epistemic space	humanidades;epistemic possibility;filosofia etica;bounded reasoning;impossible worlds;rationality;possible worlds	When a proposition might be the case, for all an agent knows, we can say that the proposition is epistemically possible for the agent. In the standard possible worlds framework, we analyze modal claims using quantification over possible worlds. It is natural to expect that something similar can be done for modal claims involving epistemic possibility. The main aim of this paper is to investigate the prospects of constructing a space of worlds—epistemic space— that allows us to model what is epistemically possible for ordinary, non-ideally rational agents like you and me. I will argue that the prospects look dim for successfully constructing such a space. In turn, this will make a case for the claim that we cannot use the standard possible worlds framework to model what is epistemically possible for ordinary agents. ∗I would especially like to thank Ben Blumson, Weng Hong Tang, and an anonymous referee from the Journal of Philosophical Logic for extensive comments on the paper. I would also like to thank David Chalmers, Alan Hájek, Hui Chieh Loy, Wolfgang Schwarz, Johanna Seibt, and audiences at Aarhus University and National University of Singapore for very helpful discussion of earlier versions of this paper.	database;epistemic possibility;expect;inferential programming;maximal set;modal logic;our world;possible world;rational agent;wolfgang von kempelen's speaking machine	Jens Christian Bjerring	2014	J. Philosophical Logic	10.1007/s10992-012-9257-z	philosophy;rationality;epistemology;artificial intelligence;mathematics;possible world;epistemic possibility	AI	-12.078812595844443	8.719571162739484	134656
857241bc39d794f401d72a02905b965a0408b1b5	computing abduction by using tms with top-down expectation	bottom up;top down;stable models;integrity constraints;logic programs;abductive logic programming	We present a method to compute abduction in logic programming. We translate an abductive framework into a normal logic program with integrity constraints and show the correspondence between generalized stable models and stable models for the translation of the abductive framework. Abductive explanations for an observation can be found from the stable models for the translated program by adding a special kind of integrity constraint for the observation. Then, we show a bottom-up procedure to compute stable models for a normal logic program with integrity constraints. The proposed procedure excludes the unnecessary construction of stable models on early stages of the procedure by checking integrity constraints during the construction and by deriving some facts from integrity constraints. Although a bottom-up procedure has the disadvantage of constructing stable models not related to an observation for computing abductive explanations in general, our procedure avoids the disadvantage by expecting which rule should be used for satisfaction of integrity constraints and starting bottom-up computation based on the expectation. This expectation is not only a technique to scope rule selection but also an indispensable part of our stable model construction because the expectation is done for dynamically generated constraints as well as the constraint for the observation. Ó 2000 Elsevier Science Inc. All rights reserved.		Noboru Iwayama;Ken Satoh	2000	J. Log. Program.	10.1016/S0743-1066(99)00076-X	computer science;artificial intelligence;machine learning;top-down and bottom-up design;mathematics;programming language;algorithm;abductive logic programming	DB	-16.865742030585206	7.589669754607102	135016
726256cf3e6cb324ca5678f85b443c1414380347	book review: r. j. g. b. de queiroz, a. g. de oliveira, d. m. gabbay, the functional interpretation of logical deduction			natural deduction	Adrian Rezus	2015	Studia Logica	10.1007/s11225-015-9612-5	philosophy;epistemology;linguistics	NLP	-12.819486749627425	10.38546088925889	135402
cbb3154f463f9fa22b180061d302eed72085612c	epistemic states guiding the rational dynamics of information	abduction;boolean algebra;epistemic states;belief revision;total preorders;belief change;possible worlds	An epistemic state here means a total preorder on the set of possible worlds. Simple epistemic states, with one or two equivalence classes, correspond to belief sets. Relative to a fixed belief set t, we define a comparative order on belief sets, expressing that 'y sorts the worlds closer to the way in which t sorts them than x does'. This induces a Boolean algebra, ordered very differently from, but isomorphic to the Lindenbaum-Tarski algebra under the isomorphism which sends x to x ↔ t. The isomorphism allows us to classify each inferential or conjectural step as being either in concord or in discord with the beliefs t. So t may now guide the logical dynamics of inference and conjecture, and hence of corroboration, refutation, diagnosis, abduction, etc. Going from belief sets to more general epistemic states, we show how similar constructions may guide AGM belief change.		Johannes Heidema;Isabella C. Burger	2000		10.1007/3-540-44533-1_30	boolean algebra;discrete mathematics;computer science;artificial intelligence;mathematics;possible world;belief revision;algorithm	ECom	-15.109964581197689	7.438970368446676	136016
058b43a244c99e5821b5ad3e613c24851ccf2062	diagrammatic reasoning in frege’s begriffsschrift		In Part III of his 1879 logic Frege proves a theorem in the theory of sequences on the basis of four definitions. He claims in Grundlagen that this proof, despite being strictly deductive, constitutes a real extension of our knowledge, that it is ampliative rather than merely explicative. Frege furthermore connects this idea of ampliative deductive proof to what he thinks of as a fruitful definition, one that draws new lines. My aim is to show that we can make good sense of these claims if we read Frege’s notation diagrammatically, in particular, if we take that notation to have been designed to enable one to exhibit the (inferentially articulated) contents of concepts in a way that allows one to reason deductively on the basis of those contents.	array data structure;deductive database;definition;diagram;euclid;frege;frege's propositional calculus;logical relations	Danielle Macbeth	2012	Synthese	10.1007/s11229-012-0068-0	epistemology;pure mathematics;mathematics;algorithm	Crypto	-12.11885304952233	5.9199717380731895	136230
3450d1e6d56344aaa75a6f6dbb75380b32edf522	meaning and context in children's understanding of gradable adjectives	language comprehension;pragmatics;semantic representation;comprehension du langage;experience;semantics;gradation;semantique;enfant;pragmatique;meaning;signification;child;context dependent;experiment;adjectif;adjective;representation semantique	This paper explores what children and adults know about three specific ways that meaning and context interact: the interpretation of expressions whose extensions vary in different contexts (semantic context dependence); conditions on the felicitous use of expressions in a discourse context (presupposition accommodation) and informative uses of expressions in contexts in which they strictly speaking do not apply (imprecision). The empirical focus is the use of unmodified (positive form) gradable adjectives (GAs) in definite descriptions to distinguish between two objects that differ in the degree to which they possess the property named by the adjective. We show that by 3 years of age, children are sensitive to all three varieties of context– meaning interaction and that their knowledge of this relation with the definite description is appropriately guided by the semantic representations of the GA appearing in it. These findings suggest that children’s semantic representations of the GAs we investigated and the definite determiner the are adult-like and that they are aware of the consequences of these representations when relating meaning and context. Bolstered by adult participant responses, this work provides important experimental support for theoretical claims regarding the semantics of gradable predicates and the nature of different types of ‘interpretive variability’, specifically semantic context dependence v. pragmatic tolerance of imprecision.	information;norm (social);predicate (mathematical logic);software release life cycle	Kristen Syrett;Christopher Kennedy;Jeffrey Lidz	2010	J. Semantics	10.1093/jos/ffp011	experiment;philosophy;gradation;context-dependent memory;semantics;linguistics;meaning;pragmatics	NLP	-13.76235118113361	5.387937129787613	136484
e6636d88bf7cf86e046cf32e907a2ed28e9da2e0	worlds, models and descriptions	philosophy of science;cognitive science;lexical semantics;knowledge based system;formal semantics;modal logic;natural language;possible worlds;formal language;model theory	"""Since the pioneering work by Kripke and Montague, the term possible world has appeared in most theories of formal semantics for modal logics, natural languages, and knowledge-based systems. Yet that term obscures many questions about the relationships between the real world, various models of the world, and descriptions of those models in either formal languages or natural languages. Each step in that progression is an abstraction from the overwhelming complexity of the world. At the end, nothing is left but a colorful metaphor for an undefined element of a set W called worlds, which are related by an undefined and undefinable primitive relation R called accessibility. For some purposes, the resulting abstraction has proved to be useful, but as a general theory of meaning, the abstraction omits too many significant features. So much information has been lost at each step that many philosophers, linguists, and psychologists have dismissed model-theoretic semantics as irrelevant to the study of meaning. This article examines the steps in the process of extracting the pair (W,R) from the world and the way people talk about the world. It shows that the Kripke worlds can be reinterpreted as part of a Peircean semiotic theory, which can also include contributions from many other studies in cognitive science. Among them are Dunn's semantics based on laws and facts, the lexical semantics preferred by many linguists, psychological models of how the world is perceived, and philosophies of science that relate theories to the world. A full integration of all those sources is far beyond the scope of this article, but an outline of the approach suggests that Peirce's vision is capable of relating and reconciling the competing sources. Published in Studia Logica, Special Issue Ways of Worlds II, 84:2, 2006, pp. 323-360. 1. Models for Modality As a de facto standard for modal logic, Kripke semantics is usually adopted for any kind of intensional logic, and logicians rarely ask fundamental questions about its suitability: Although a Tarski-style model is a set-theoretic construction whose elements correspond to things that are assumed to exist, what features of a Kripke-style model enable it to cross the boundary between what is and what must be, ought to be, or is believed to be? Since a Kripke model derives modality from a set of possible worlds and an accessibility relation among worlds, doesn't it presuppose a more primitive notion of modality that lies hidden in the -ible suffixes of possible and accessible? If not, by what magic can a Kripke model derive ought from is? If so, what makes possible worlds possible or accessible? Could that more primitive notion of modality be formalized? Can the modal axioms be derived from a more primitive notion that avoids the possible worlds and the accessibility relation? What formal mechanisms could support such a derivation? Would it be as powerful and flexible as Kripke semantics? Or more so? Could it explain the bewildering variety of axioms for modality? Could it enable different modes of modality to be expressed in the same sentence? Could it support multimodal reasoning? How? An alternate semantics proposed by Hintikka (1961, 1963) and extended by Dunn (1973) may answer or at least clarify these questions. Instead of possible worlds, Hintikka assumed maximally consistent sets of propositions called model sets with an alternativity relation between model sets that is equivalent to Kripke's accessibility relation between worlds. Informally, Hintikka's model sets could be considered descriptions of Kripke's worlds. Formally, model sets have more structure that permits a wider range of operations. Dunn took advantage of that structure to distinguish a subset of each model set called laws: 1. Each model set Mi is considered the facts that describe the corresponding world wi. 2. For each world wi, Dunn assumed a subset Li of Mi called the laws of wi. 3. Then Dunn defined accessibility from the world wi to the world wj to mean that the laws Li of the first world are a subset of the facts Mj of the second world: R(wi,wj) ≡ Li⊂Mj. According to this definition, the laws of the first world wi remain true in the second world wj, but they may be demoted from the status of laws to merely contingent facts. 4. Finally, Dunn showed that this construction is a conservative refinement of Kripke's theory, since any Kripke model structure (W,R,Φ) can be converted to one of Dunn's model structures by replacing every world w in W with the set M of propositions that are true in w and the set L of propositions that are necessarily true in w: M = {p | Φ(p,w) = true}. L = {p | (∀u ∈ W)(R(w,u) Φ( ⊃ p,u) = true}. This construction generates a model in Dunn's sense for every model in Kripke's sense. It holds for the normal models (Kripke 1963), in which every law is also a fact, and for the non-normal models (Kripke 1965), in which some laws might not be facts. In deontic logic, for example, the laws are obligatory, but sinners might violate them. For such models, R is not reflexive because a non-normal world is not accessible from itself. (This, by the way, is one more example of the nonintuitive nature of Kripke models: it seems odd to say that any world could be inaccessible from itself, especially the real world because it happens to have sinners.) With Dunn's construction, the accessibility relation is no longer primitive, and modal semantics does not depend on imaginary worlds. Instead, modality depends on the choice of laws, which could be laws of nature or merely human rules and regulations. Every theorem proved with Kripke's models is also true of Dunn's models, but the additional structure available with model sets enables new operations, theories, and applications to be explored. Furthermore, vague questions about the meaning of modality can be stated more precisely as """"Who or what determines the laws?"""" Any mention of a lawgiver threatens to invoke the twin demons of subjectivism and psychologism, which Kripke's sets seem to avoid. Montague (1967) explicitly stated his goal of replacing messy human attitudes with sets: """"It has for fifteen years been possible for at least one philosopher (myself) to maintain that philosophy, at this stage in history, has as its proper theoretical framework set theory with individuals and the possible addition of empirical predicates."""" With sets as the ultimate ontology, everything is reducible to constructions built from a single primitive, the empty set: { }. The next step is to construct the set whose only member is the the empty set, {{ }}, or iterations of such emptiness ad infinitum: {{ }, {{ }}, {{{ }}}, ...}. Like Montague, Quine preferred to reduce everything to sets, but one of his former students, who later spent many years working as an assistant to Gödel, came to deplore the emptiness of such constructions. Wang (1986) called Quine's critical, but reductionist approach logical negativism: Quine merrily reduces mind to body, physical objects to (some of) the place-times, placetimes to sets of sets of numbers, and numbers to sets. Hence, we arrive at a purified ontology which consists of sets only.... I believe I am not alone in feeling uncomfortable about these reductions. What common and garden consequences can we draw from such grand reductions? What hitherto concealed information do we get from them? Rather than being overwhelmed by the result, one is inclined to question the significance of the enterprise itself. (p. 146) In support of this view, Wang quoted a personal letter from C. I. Lewis about the state of philosophy in 1960: It is so easy... to get impressive 'results' by replacing the vaguer concepts which convey real meaning by virtue of common usage by pseudo precise concepts which are manipulable by 'exact' methods — the trouble being that nobody any longer knows whether anything actual or of practical import is being discussed. (p. 116) As this discussion indicates, many questions about the meaning of modality are not adequately answered by Kripke semantics. In fact, the possible worlds themselves raise serious ontological and epistemological questions. Their contribution to the study of meaning is a mathematical structure whose relevance to language, communication, and the intentions of the people who communicate is certainly not obvious. The five sections of this article explore these issues and their relationship to possible worlds and to the laws and facts that describe them: 1. This first section has presented the one-to-one mapping between possible worlds and sets of laws and facts. That mapping preserves all the axioms and theorems of Kripke semantics, and it makes the laws that determine modality accessible to critical analysis. 2. The next section discusses philosophical issues about the derivation of laws and facts from the analysis and observation of worlds or situations, either real or imaginary. The conclusion is that observation alone is insufficient to derive the laws or principles that determine modal and intentional properties. 3. A more promising source of laws is Peirce's theory of signs, which covers the full range of semiotic issues from epistemology and philosophy of science to formal ontology with its applications to linguistics and computer science and finally to methods of reasoning, communication, and purposive action in and on the world. 4. Since Dunn's semantics shifts the focus of modal semantics from possible worlds to propositions, Section 4 replaces the definition of proposition as a set of possible worlds with a more fine-grained definition as an equivalence class of sentences. 5. The concluding section discusses new representations in linguistics and new methods of reasoning in artificial intelligence that become available when the formalism is expressed in terms of laws and facts. An earlier article (Sowa 2003) presented nested graph models as a family of general structures for Dunn's semantics that coul"""	accessibility relation;artificial intelligence;cognitive science;color gradient;complexity;computer science;consistency model;contingency (philosophy);cyber-security regulation;deontic logic;formal language;formal ontology;gödel;hoare logic;imaginary time;impossible world;intensional logic;iteration;john f. sowa;knowledge-based systems;kripke semantics;mathematical structure;modal logic;modality (human–computer interaction);montague grammar;multimodal interaction;natural language;one-to-one (data model);parse tree;possible world;quine (computing);reductionism;refinement (computing);relevance;semantics (computer science);semiotics;set theory;turing completeness;undefined behavior;vagueness	John F. Sowa	2006	Studia Logica	10.1007/s11225-006-9012-y	modal logic;natural language processing;philosophy of science;lexical semantics;formal language;formal semantics;philosophy;epistemology;computer science;artificial intelligence;knowledge-based systems;formal semantics;mathematics;linguistics;possible world;impossible world;natural language;programming language;operational semantics;model theory	AI	-12.810874368645143	4.976488530006138	136978
8b384ef75b9510ab09a81134ba4019591749068f	comparative logic as an approach to comparison in natural language	syntagme nominal complexe;comparaison;logique comparative;formal semantics;comparison;comparative logic;semantique formelle;anglais;natural language;semantique logique;linguistique mathematique;logical semantics;adjectif;adjective;mathematical linguistics	"""Montague grammarians cl^T"""" that tlic logical analysis 01 language skccdicd in standard textbooks of first order logic is too coarse to be appropriate to such natural languages as English. In the following we shall defend the opposite view—at least as far as a very narrow fragment of English is concerned, traditional logical analysis is perfectly adequate provided we are ready to pay the price of abandoning classical logic in favour of logics containing a sufficiently rich stock of logical constants. Within the framework of Casari's comparative logic, we shall outline a model of a restricted fragment of English. We shall address such issues as the construction of complex noun phrases, the distinction between gradable and vague adjectives, the structure of comparative sentences and of antonym adjectival pairs. 1 I N T R O D U C T I O N Montague grammar (Montague 1974, especially 188—270) is generally regarded as a considerable refinement of the traditional logical analysis of natural languages, as usually outlined in the first chapters of any textbook of elementary logic This is of course true. The orthodox analysis works fine for simple and mostly ad hoc examples, but breaks down as soon as slightly more complicated constructions are examined. Think of adjectives like big, wide, good, etc According to Reichenbach (1947), an advocate of the traditional view, complex noun phrases consisting of an adjective in prenominal position and a common noun can be given a conjunctive reading. (1) and (2) below, for example, are equivalent: (1) Horses are four-legged animals; (2) Horses are four-legged and horses are animals. But this is no longer the case with the forementioned adjectives, sometimes called relative (in contrast -with, four-legged and the like, termed absolute) since they involve a 'reference class'. (3) and (4) are by no means equivalent: (3) Dumbo is a small elephant; (4) Dumbo is small and Dumbo is an elephant 68 Comparative Logic as an Approach to Comparison in Natural Language Montague concludes that adjectives cannot be treated as ordinary predicates. For traditional logic, adjectives, intransitive verbs and common nouns are nothing but one-place predicates. According to Montague, however, they fall under three distinct syntactic categories. In particular, adjectives are syntactical operators mapping noun phrases to other noun phrases; semanticaUy, they correspond to functions from properties to properties (properties, in turn, are sets of individual concepts, Le. sets of functions from possible worlds to individuals). Is this multiplication of categories praeter necessitatem? It would be nice if we could prove that it is. In what follows, we shall endorse a 'generalized conjunctive reading' of such sentences as (3) above. For this purpose, we shall introduce a noncommutative conjunction A * B, to be read approximately as 'A, taking into account that B\ This connective will be shown to have a rather natural algebraic interpretation. Comparative sentences are considered as yet another shortcoming of the received view. Given the sentence a is more P than b, traditional logic regards 'is more P than' as a standard two-place predicate, Le. it leaves it unanalysed. Several theories, which we shall review below, have been proposed to amend this apparent flaw, each one of them considerably enlarging the logical apparatus of first order theories or their ontological background. Here we shall suggest an 'implicative reading' of comparative sentences, involving nothing else than standard predicates (corresponding to positive adjectives) and. a nonstandard implication connective. Generally speaking, we shall try to account for the above-mentioned natural language constructions not by increasing the number of the ordinary categories of logical morphology and syntax, but by proceeding to a more fine-grained investigation of prepositional connection. In order to save classical logical analysis, we shall give up classical logic and adopt a different framework, based on Casari's comparative logic (Casari 1987, 1989, 1990, 1997). It must be emphasized that the primary focus of the present proposal is on suggesting a new field of application for comparative logic, rather than on providing new insights into the semantical structure of adjectives and comparison in natural language. Hence, we shall be rather selective in the choice of the examined natural language constructions (see, however, section 6 for a broader discussion). The formal build-up of the corresponding model will only be outlined. In section 2, we shall briefly """"review the main rival theories of adjectives. In section 3 we shall do the same for theories of comparison. In section 4 we shall discuss the philosophical basis of comparative logic, focusing on its application to the reconstruction of comparative sentences and complex"""	first-order logic;first-order predicate;flaw hypothesis methodology;galaxy morphological classification;hoc (programming language);linear algebra;logical connective;logical constant;montague grammar;natural language;possible world;predicate (mathematical logic);refinement (computing);theory;vagueness;yet another	Francesco Paoli	1999	J. Semantics	10.1093/jos/16.1.67	non-classical logic;philosophy;formal semantics;linguistics	NLP	-11.861866164653032	6.153159083371079	137444
107dca4c5e04dc95c4d4a7b616da21051f633c7e	avicenna on the quantification of the predicate (with an appendix on [ibn zur'a])				Ahmad Hasnawi	2008		10.1007/978-1-4020-8405-8_11	philosophy;artificial intelligence;algorithm	Logic	-12.72788941867967	10.9765792644381	138071
c3ce69ea76a2b2a9cecbfe93dd0788a3d7a3ccad	truth, proofs and functions	prueba;constructivism;truth;type;mathematics;constructive mathematics;fonction;verite;function;metalangage;constructivisme;preuve;metalanguage;matematicas;funcion;tarski a;proof;heyting a;brouwer l e j;realisabilite;mathematiques	There are two different ways to introduce the notion of truthin constructive mathematics. The first one is to use a Tarskian definition of truth in aconstructive (meta)language. According to some authors, (Kreisel, van Dalen, Troelstra ... ),this definition is entirely similar to the Tarskian definition of classical truth (thesis A).The second one, due essentially to Heyting and Kolmogorov, and known as theBrouwer–Heyting–Kolmogorov interpretation, is to explain informally what it means fora mathematical proposition to be constructively proved. According to other authors (Martin-Löfand Shapiro), this interpretation and the Tarskian definition of truth amount to thesame (thesis B). My aim in this paper is to show that thesis A is only reasonable, that thesis Bis false and to answer the following question: what is defined by the Tarskian definition ofconstructive truth?	brouwer–heyting–kolmogorov interpretation	Jean Fichot	2003	Synthese	10.1023/A:1026274716840	philosophy;epistemology;metalanguage;constructivism;pure mathematics;proof;mathematics;linguistics;type;function;algorithm;constructivism	Crypto	-12.289808733193691	4.758679011521822	138346
8b33f4a1b0662c193cc97ebba9d4a0428d4260a4	ontology, reduction, emergence: a general frame	relational model	In a scientific context, ontological commitments should be considered as supervenient over accepted scientific theories. This implies that the primarily ontological notions of reduction and emergence of entities of different kinds should be reformulated in terms of relations between existing empirical theories. For this, in turn, it is most convenient to employ a model-theoretic view of scientific theories: the identity criterion of a scientific theory is essentially given by a class of models. Accordingly, reduction and emergence are to be seen as particular kinds of relations between (some) models of different theories that subsume the same (or a similar) “experiential field”. The set-theoretical notion of an echelon-set proves to be crucial for this purpose: The domains in the models of the reduced theory are echelon-sets over the domains of the reducing theory. Finally, it is argued that emergence may plausibly be interpreted as akin to but weaker than reduction.	emergence;entity;general frame;reduction (complexity);row echelon form;theory	C. Ulises Moulines	2006	Synthese	10.1007/s11229-006-9011-6	relational model;philosophy;epistemology;pure mathematics;mathematics;algorithm	AI	-15.082806266471927	4.843216342001637	139197
240c720ab867a98a80e534cbcdd269c8b9ae447c	logical bilattices and inconsistent data	inference mechanisms formal logic uncertainty handling;lattices computer science application software logic programming;paraconsistent logic logical bilattices inconsistent data proof systems efficient inferences;inference mechanisms;uncertainty handling;formal logic	The notion of a bilattice was rst proposed by Ginsberg as a general framework for many applications. This notion was further investigated and applied for various goals by Fitting. In the present paper we develop proof systems, which correspond to bilattices in an essential way. We then show how to use those bilattices for ef-cient inferences from possibly inconsistent data. For this we incorporate certain ideas of Kifer and Lozin-skii concerning inconsistencies, which happen to suit well the framework of bilattices. The outcome is a paraconsistent logic with a lot of desirable properties.	curve fitting;paraconsistent logic	Ofer Arieli;Arnon Avron	1994		10.1109/LICS.1994.316044	epistemology;theoretical computer science;data mining;mathematics;logic;algorithm	Logic	-17.67618758962171	7.088154057760805	139398
6d1b184464a4689481fbb98d60f9acfc8c694316	on the expressiveness of spatial constraint systems		Epistemic, mobile and spatial behaviour are commonplace in today’s distributed systems. The intrinsic epistemic nature of these systems arises from the interactions of the elements of which they are comprised. Most people are familiar with digital systems where users share their beliefs, opinions and even intentional lies (hoaxes). Models of such systems must take into account the interactions with others as well as the distributed quality presented by them. Spatial and mobile behaviour are exhibited by applications and data moving across possibly nested spaces defined by, for example, friend circles, groups, and shared folders. Thus a solid understanding of the notion of space and spatial mobility as well as the flow of epistemic information is relevant in many models of today’s distributed systems. In order to analyze knowledge, space, and mobility in distributed systems, we expand upon the mathematically simple and elegant theory of constraint systems (cs), used to represent information and information change in concurrent systems. In the formal declarative model known as concurrent constraint programming, constraint systems provide the basic domains and operations for the semantic foundations of this model. Spatial constraint systems (scs’s) are algebraic structures that extend cs’s for reasoning about basic spatial and epistemic behaviour such as belief and extrusion. Both, spatial and epistemic assertions, can be viewed as specific modalities. Other modalities can be used for assertions about time, knowledge and even the analysis of groups among other concepts used in the specification and verification of concurrent systems. In this thesis we study the expressiveness of spatial constraint systems in the broader perspective of modal and epistemic behaviour. We shall show that spatial constraint systems are sufficiently robust to capture inverse modalities and to derive new results for modal logics. We shall show that we can use scs’s to express a fundamental epistemic behaviour such as knowledge. Finally we shall give an algebraic characterization of the notion of distributed information by means of constructors over scs’s.	modal logic	Michell Guzmán;Frank D. Valencia	2016		10.4230/OASIcs.ICLP.2016.16	algorithm;constraint programming;dynamic logic (modal logic);constraint logic programming;computer science;multimodal logic;theoretical computer science;normal modal logic;constraint satisfaction;concurrent constraint logic programming;epistemic modal logic	AI	-13.800051400801406	7.475816291518978	139733
72752f69e7681e1b3ca5e754bfbba6d91cc6d68a	communication across viewpoints	information viewpoint;automated reasoning;natural deduction;reflective theories;common knowledge;knowledge representation;metalevel theories;viewpoints;contexts	"""The situation which occurred in a dream provides the framework for discussing properties of the theory of viewpoints and in particular the issue of diierent denotations from diierent perspectives. We introduce the principle of \referent sharing"""" in communications and argue that common knowledge resulting from communication should only use constants whose referent is \manifest"""" to the parties involved."""		Giuseppe Attardi;Maria Simi	1998	Journal of Logic, Language and Information	10.1023/A:1008211103003	knowledge representation and reasoning;computer science;knowledge management;artificial intelligence;mathematics;automated reasoning;natural deduction;common knowledge	NLP	-16.702667855920847	4.214381312253751	140098
fe2fc84847efef4677b89cf99e65a07f4a215091	a plea for pragmatics	pragmatics;semantics;filosofi;container index;indexation;philosophy;interpretation;speaker intentions;theoretical philosophy;indexicals;teoretisk filosofi	Let intentionalism be the view that what proposition is expressed in context by a sentence containing indexicals depends on the speaker’s intentions. It has recently been argued that intentionalism makes communicative success mysterious and that there are counterexamples to the intentionalist view in the form of cases of mismatch between the intended interpretation and the intuitively correct interpretation. In this paper, I argue that these objections can be met, once we acknowledge that we may distinguish what determines the correct interpretation from the evidence that is available to the audience, as well as from the standards by which we judge whether or not a given interpretation is reasonable. With these distinctions in place, we see that intentionalism does not render communicative success mysterious, and that cases of mismatch between the intended interpretation and the intuitively correct one can easily be accommodated. The distinction is also useful in treating the Humpty Dumpty problem for intentionalism, since it turns out that this can be treated as an extreme special case of mismatch.	christopher blizzard;interpretation (logic)	Jonas Åkerman	2008	Synthese	10.1007/s11229-008-9365-z	philosophy;epistemology;interpretation;mathematics;semantics;linguistics;pragmatics	AI	-13.136358780318815	4.5670393938892655	140500
2d7c10cb1603530db67da94dd9c6c09fe6d1ba3c	a posteriori knowledge: from ambiguous knowledge and undefined information to knowledge	ambiguous knowledge;reasoning and action;local knowledge;external research report;agm pradigm	Incomplete worlds or ambiguous actions are topics that encourage research in theories about reasoning and action (Brewka and Hertzberg 1993). Driankov's model-based approaches propose to deal with the problem using Belnap's four-valued logic. Incompleteness or ambiguity is clarified by postconditions that apply whenever persistence conditions are inhibited. In this paper, Driankov's semantics is used in a formalisation that captures the dynamic character of knowledge and belief. Ambiguous knowledge is present in several kinds of situations that formally correspond with knowing that a disjunction is true, but it is not known which element of the disjunction makes it true. We define an a posteriori knowledge operator that allows to extend knowledge from ambiguous knowledge or undefined information, being in the meanwhile, potential knowledge and/or belief. The expansion operation of AGM paradigm (Gardefors 1988) is used to explore the possibilities from ambiguous information.	undefined value	Matías Alvarado	1995		10.1007/3-540-60112-0_2	traditional knowledge;empirical evidence;artificial intelligence;body of knowledge;knowledge-based systems;mathematics;procedural knowledge	AI	-16.277467167097853	4.667123691858858	140514
bc22984b30316d543b2811268ff74cbbba377b3d	model checking of restricted ctl* formulas using alck	model checking	Introduction The purpose of model checking technique is to verify whether the implemented computer program (the model) satisfies the specified requirements (the formulas). Now let K be the Kripke model representing the behavior of the system and R be the set of formulas. The model checking process verifies whether every formula in R is satisfied by the model, which has I as the set of initial states. Formally, it checks whether ∀f ∈ R,∀s ∈ I : K, s f is true or not. We propose an approach to perform model checking of the restricted CTL* formula based on the top of description logics reasoning services. This approach allows us to build the ontology of the atomic propositions used both in the model and in the formula. We realize our approach by performing the following steps: (i) representing the model in the assertion box (ABox) of the description-logic based knowledge base, (ii) defining the ontology of atomic propositions in the terminology box (TBox) of the knowledge base, (iii) defining a part of the formal semantics of CTL* logic on top of the DL semantics, (iv) defining the translation rules for the formula.	abox;assertion (software development);atomic sentence;ctl*;computer program;description logic;knowledge base;kripke semantics;model checking;requirement;semantics (computer science);tbox	Taufiq Rochaeli;Claudia Eckert	2007			discrete mathematics;model checking;knowledge base;abox;atomic sentence;description logic;ctl*;mathematics;assertion;semantics	AI	-16.79246245697834	10.543751780349202	140555
de570f924b9b59387b216514553338fb9036d20b	belief-revision, the ramsey test, monotonicity, and the so-called impossibility results	belief revision;rational belief	Peter Gärdenfors proved a theorem purporting to show that it is impossible to adjoin to the AGM-postulates for belief-revision a principle of monotonicity for revisions. The principle of monotonicity in question is implied by the Ramsey test for conditionals. So Gärdenfors’ result has been interpreted as demonstrating that it is impossible to combine the Ramsey test for conditionals with the basic postulates for rational belief-revision. It is shown here that this interpretation of Gärdenfors’ result is unwarranted. A new diagnosis is offered of a methodological error made in the statement of the key principle of monotonicity. Crucial applications of this principle in Gärdenfors’ proof require one to regard as revisions what are really expansions. If monotonicity is stated only for genuine revisions, then Gärdenfors’ proof does not go through. Nor can it; for, when the monotonicity principle for revisions is correctly formulated, one can actually establish a contrary consistency result. This requires only a slight adjustment to the postulates of AGM-theory, in order to ensure that the three operations of expansion, contraction, and revision trichotomize the domain of theorychanges. It is further shown that being careful in this way about the proper domains of definition of the three operations of expansion, contraction, and revision also disposes of another, more direct, impossibility result, due to Arló-Costa, that targets the Ramsey test. §	automated theorem proving;belief revision;care-of address;commotion (animation);contingency (philosophy);precondition;rendering (computer graphics)	Neil Tennant	2008	Rew. Symb. Logic	10.1017/S1755020308090023	philosophy;mathematics;belief revision;algorithm	Theory	-12.649474928002604	5.064794527163178	140642
8d2ee112557388eb07ed2e8079e7e4dddeb5a2b7	applications of lyndon homomorphism theorems to the theory of minimal models	minimal model;minimal semantics;preservation properties	This paper contains, among others, a concise proof (proof 6.2) of the following fact (theorem 2.7): For every ∀∪Neg-theory Σ and every positive sentence φ, It is demonstrated in this paper (corollary 5.2) that the necessary and sufficient condition for φ, guaranteeing the truthfulness of the above equivalence for every Σ⊆∀, is that φ is equivalent to a sentence which does not contain in a scope of negation an occurrence of a relation symbol other than the equality symbol. The proofs have been constructed using classical model-theoretic tools, thus supporting the thesis that classical logic is adequate for expressing and investigating non-monotonic reasoning patterns.		Marek A. Suchenek	1990	Int. J. Found. Comput. Sci.	10.1142/S0129054190000059	complete theory;combinatorics;discrete mathematics;mathematics;algorithm	Logic	-14.431995168369061	8.192777703818482	140825
4fe7a2b44b3983eda1fc8ad1c4c47b9c315dc02e	completeness and decidability results for a logic of contrary-to-duty conditionals	basic formal-logical;earlier version;deontic logic;part ii;decidable axiomatization;constituent modality;decidability result;handbook chapter;jones logic;new inference rule;contrary-to-duty conditional scenario	This article has two parts. In Part I, we briefly outline the analysis of ‘contrary-to-duty’ obligation sentences presented in our 2002 handbook chapter ‘Deontic logic and contrary-to-duties’, with a focus on the intuitions that motivated the basic formal-logical moves we made. We also explain that the present account of the theory differs in two significant respects from the earlier version, one terminological, the other concerning the way the constituent modalities interconnect. Part II is the principal contribution of this article, in which we show that it is possible to define a complete and decidable axiomatization for the Carmo and Jones logic, a problem that was still open. The axiomatization includes two new inference rules; we illustrate their use in proofs, and show that on the basis of this axiomatization we can recover all the axioms and rules considered in ‘Deontic logic and contrary-to-duties’, and used there in the analysis of contrary-to-duty conditional scenarios.	axiomatic system;deontic logic;jones calculus	José Carmo;Andrew J. I. Jones	2013	J. Log. Comput.	10.1093/logcom/exs009	discrete mathematics;epistemology;artificial intelligence;deontic logic;mathematics;algorithm	Logic	-14.721219171238726	6.571540232513211	140888
ce83ac5135626d33a1e079ede59f605cfd76c12c	in praise of belief bases: doing epistemic logic without possible worlds		We introduce a new semantics for a logic of explicit and implicit beliefs based on the concept of multi-agent belief base. Differently from existing Kripke-style semantics for epistemic logic in which the notions of possible world and doxastic/epistemic alternative are primitive, in our semantics they are non-primitive but are defined from the concept of belief base. We provide a complete axiomatization and a decidability result for our logic.	accessibility relation;agent-based model;axiomatic system;belief revision;doxastic logic;epistemic modal logic;introspection;linear discriminant analysis;model checking;multi-agent system;possible world	Emiliano Lorini	2018			machine learning;praise;computer science;artificial intelligence;epistemic modal logic;possible world	AI	-16.359636882748354	6.073735328868595	140992
0a80d24d91742f986b58c92ab18446b66dd43920	deduction with supernormal defaults	query answering;closed world assumption;partial order	In this paper we consider supernormal defaults [Poo88] with a strict partial order defining their priorities [Bre91]. We investigate their relation to minimal or preferential entailment and show that the semantics given in [Bre91] has to be modified in order to be equivalent to a preferential model approach. Concering the multiple extension problem, we introduce the careful view as an alternative to the credulous and skeptical one, which is needed to handle the generalized closed world assumption [Min82] within this framework. Given this “declaritive semantics” of such default theories, we will present a deduction algorithm for query answering. Compared to other approaches, the algorithm is quite efficient and general. Especially, it is able to generate disjunctive answers, to support the credulous, skeptical and careful view; and to cut fruitless search paths early. In order to check the applicability of defaults as soon as possible, we introduce the notion of a partial extension.	alan dix;algorithm;bottom-up parsing;closed-world assumption;david makinson;deductive database;disjunctive normal form;expressive power (computer science);gerhard j. woeginger;locality of reference;maximal set;natural deduction;preferential entailment;prolog;prototype;sld resolution;schmitt trigger;semantics (computer science);two-phase commit protocol;udo of aachen	Stefan Brass	1991		10.1007/BFb0030392	epistemology;artificial intelligence;communication	AI	-17.06811369377908	9.922014084352401	141103
96b7320cf77e402514bccee4bf03e749014f41aa	a note on applicability of the incompleteness theorem to human mind	reflection principle	Abstract We shall present some relations between consistency and reflection principles which explain why is Godelu0027s incompleteness theorem wrongly used to argue that thinking machines are impossible.	gadu-gadu	Pavel Pudlák	1999	Ann. Pure Appl. Logic	10.1016/S0168-0072(98)00044-X	calculus;mathematics;reflection principle	Logic	-12.006457578310036	4.944558662306681	142665
151017ae7663f8a81ed9dfda05d08ced3dd40fa0	a rational extension of stable model semantics to the full propositional language	intuitionistic logic;equilibrium model semantics;stable model semantics;non monotonic reasoning;supported semantics	Answer set programming is the most appreciated framework for non-monotonic reasoning. Stable model semantics, as the semantics behind this success, has been subject to many extensions. The two main such extensions are equilibrium models and FLP semantics. Despite their very interesting foundations, they both have two problems: they cannot guarantee either minimality, or rationality of their intended models. That is, both these semantics allow models in which some atoms are self-justified (i.e., the only possible reason for including those atoms in the model are those atoms themselves). Present paper extends stable model semantics to the full propositional language while guaranteeing both properties above. Our extension is called supported because it guarantees the existence of noncircular justifications for all atoms in a supported model. These goals are achieved through a form of completion in intuitionistic logic. We also discuss how supported models relate to other semantics for non-monotonic reasoning such as equilibrium models. Finally, we discuss the complexity of reasoning about supported models and show that the complexity of brave/cautious reasoning in supported semantics remains as before, i.e., the rationality property comes for no additional cost.	answer set programming;autoepistemic logic;default logic;intuitionistic logic;logic programming;non-monotonic logic;rationality;regular expression;stable model semantics;turing completeness;whole earth 'lectronic link;windows fundamentals for legacy pcs	Shahab Tasharrofi	2013			discrete mathematics;formal semantics;stable model semantics;intuitionistic logic;computer science;proof-theoretic semantics;formal semantics;mathematics;programming language;well-founded semantics;operational semantics;denotational semantics;algorithm;computational semantics	AI	-15.585296928194785	9.780087344506633	142813
5958d51bd4ccf7052233a3248fa636f3418da5c9	a universal formalism to express decompositions, functional dependencies and other constraints in a relational database	relational database;functional dependency	A general formalism, called the general dependencies, is presented. The multivalued, mutual, join and functional dependencies can be expressed in this formaiism. Some properties of general dependencies are stated and their influence on the decomposition and the partial decomposition of a relation is studied. The class of general dependencies is compared with other classes of dependencies. It is proved that every set of functional dependencies can be expressed by a single genera! dependency. The same property holds for the multivalued dependencies. Finally the concept of functional dependency is generalized.	functional dependency;genera;multivalued dependency;relational database;semantics (computer science)	Jan Paredaens	1982	Theor. Comput. Sci.	10.1016/0304-3975(82)90057-3	discrete mathematics;armstrong's axioms;dependency theory;relational database;acyclic dependencies principle;computer science;theoretical computer science;join dependency;database;mathematics;functional dependency;fourth normal form;multivalued dependency	DB	-15.906964155358498	11.177235185626005	143047
f46755f59da271f32db7a648b002a2ac7c5e9a0e	relevance in belief revision	belief revision;knowledge representation;possible world semantics	Possible-world semantics are provided for Parikh's relevance-sensitive axiom for belief revision, known as axiom (P). Loosely speaking, axiom (P) states that if a belief set K can be divided into two disjoint compartments, and the new information ? relates only to the first compartment, then the second compartment should not be effected by the revision of K by ?. Using the well-known connection between AGM revision functions and preorders on possible worlds as our starting point, we formulate additional constraints on such preorders that characterise precisely Parikh's axiom (P). Interestingly, the additional constraints essentially generalise a criterion of plausibility between possible worlds that predates axiom (P). A by-product of our study is the identification of two possible readings of Parikh's axiom (P), which we call the strong and the weak versions of the axiom. Regarding specific operators, we show that Dalal's belief revision operator satisfies both weak and strong (P), and it is therefore relevance-sensitive.	belief revision;consistency model;plausibility structure;possible world;relevance	Pavlos Peppas;Mary-Anne Williams;Samir Chopra;Norman Y. Foo	2015	Artif. Intell.	10.1016/j.artint.2015.08.007	urelement;zermelo–fraenkel set theory;knowledge representation and reasoning;axiom schema;axiom of extensionality;discrete mathematics;axiom independence;action axiom;computer science;artificial intelligence;non-well-founded set theory;scott's trick;mathematics;axiom of choice;possible world;belief revision;s;algorithm;constructive set theory	AI	-15.556418609353987	7.427494091711567	143165
dcbb69c728f595b79db4e1f36a9ed0b0b49e77f8	distributional logic programming for bayesian knowledge representation	probabilistic logic programming;bayesian inference;classification and regression trees;logic programming;knowledge representation;bayesian networks	We present a formalism for combining logic programming and its flavour of nondeterminism with probabilistic reasoning. In particular, we focus on representing prior knowledge for Bayesian inference. Distributional logic programming (Dlp), is considered in the context of a class of generative probabilistic languages. A characterisation based on probabilistic paths which can play a central role in clausal probabilistic reasoning is presented. We illustrate how the characterisation can be utilised to clarify derived distributions with regards to mixing the logical and probabilistic constituents of generative languages. We use this operational characterisation to define a class of programs that exhibit probabilistic determinism. We show how Dlp can be used to define generative priors over statistical model spaces. For example, a single program can generate all possible Bayesian networks having N nodes while at the same time it defines a prior that penalises networks with large families. Two classes of statistical models are considered: Bayesian networks and classification and regression trees. Finally we discuss: (1) a Metropolis–Hastings algorithm that can take advantage of the defined priors and the probabilistic choice points in the prior programs and (2) its application to real-world machine learning tasks.	digital light processing;knowledge representation and reasoning;logic programming;machine learning;nondeterministic algorithm;program transformation;programming language;prolog;relevance;swi-prolog;static program analysis	Nicos Angelopoulos;James Cussens	2017	Int. J. Approx. Reasoning	10.1016/j.ijar.2016.08.004	knowledge representation and reasoning;probabilistic ctl;bayesian programming;probabilistic relevance model;computer science;artificial intelligence;machine learning;pattern recognition;bayesian network;data mining;mathematics;probabilistic logic;inductive programming;bayesian inference;probabilistic argumentation;logic programming;probabilistic logic network;statistics;subjective logic	AI	-14.826362856941568	6.530125779694431	143841
72c473082475a4a5b2fa4ec45e6de0ba2f3391d1	possibilistic networks: a new setting for modeling preferences		Possibilistic networks are the counterpart of Bayesian networks in the possibilistic setting. Possibilistic networks have only been studied and developed from a reasoning-under-uncertainty point of view until now. In this short note, for the first time, one advocates their interest in preference modeling. Beyond their graphical appeal, they can be shown to provide a natural encoding of preferences agreeing with the inclusion-based partial order applied to the subsets of preferences violated in the different situations. Moreover they do not encounter the limitations of CP-Nets in terms of representation capabilities. They also enjoy a logical counterpart that may be used for consistency checking. This short note provides a comparative discussion of the merits of possibilistic networks with respect to other existing preference modeling frameworks.	bayesian network;cp/m;graphical user interface	Nahla Ben Amor;Didier Dubois;Héla Gouider;Henri Prade	2014		10.1007/978-3-319-11508-5_1	artificial intelligence;data mining;mathematics	AI	-15.953425183440947	6.920089647410952	144135
e96085f5b3ce48922196cf438406d1049928e0b2	weak familiarity and anaphoric accessibility in dynamic semantics	anaphora;accessibility;familiarity;dynamic semantics;discourse	The accessibility constraints imposed on anaphora by dynamic theories of discourse are too strong because they rule out many perfectly felicitous cases. Several attempts have been made by previous authors to rectify this situation using various tactics. This paper proposes a more viable approach that involves replacing Heim’s notion of familiarity with a generalized variant due to Roberts. This approach is formalized in hyperintensional dynamic semantics, and a fragment is laid out that successfully deals with some problematic examples.	accessibility;anaphora (linguistics);denotational semantics;formal language;programming language;the pawn	Scott Martin	2011		10.1007/978-3-642-32024-8_19	natural language processing;computer science;linguistics;communication	AI	-12.89149401820836	6.519424792045699	144791
1da247de0885bd45aba54e8bf702eb1eb2da050c	preference-based argumentation handling dynamic preferences built on prioritized logic programming	nonmonotonic reasoning;preferred answer set;prioritized logic programming;dynamic paf;preference-based argumentation;dynamic preference;interesting relationship;hierarchical plp;preference-based argumentation framework;cal p;hierarchical prioritized logic program	To treat dynamic preferences correctly is crucially required in the fields of argumentation as well as nonmonotonic reasoning. To meet such requirements, first, we propose a hierarchical Prioritized Logic Program (or a hierarchical PLP, for short), which enhances the formalism of Sakama and Inoue’s PLP so that it can represent and reason about dynamic preferences. Second, using such a hierarchical PLP as the underlying language, the proposed method defines the preference-based argumentation framework (called the dynamic PAF ) built from it. This enables us to argue and reason about dynamic preferences in argumentation. Finally we show the interesting relationship between semantics of a hierarchical PLP given by preferred answer sets and semantics of the dynamic PAF given by P-extensions.	argumentation framework;logic programming;non-monotonic logic;pl/p;requirement;semantics (computer science)	Toshiko Wakaki	2011		10.1007/978-3-642-25044-6_27	computer science;artificial intelligence;theoretical computer science;algorithm	AI	-17.55314990646519	8.167849799517843	144957
7f28aefd725080316b8b54132711eaed23fce87a	on the complexity of entailment in propositional multivalued logics	neural network;artificial intelligence;complex system;nonlinear dynamics;common method	Multivalued logics have a long tradition in the philosophy and logic literature that originates from the work by Łukaszewicz in the 1920s. More recently, many AI researchers have been interested in this topic for both semantic and computational reasons. Multivalued logics have indeed been frequently used both for their semantic properties and as tools for designing tractable reasoning systems. We focus here on the computational aspects of multivalued logics. The main result of this paper is a detailed picture of the impact that the semantic definition, the synthactic form and the assumptions on the relative sizes of the inputs have on the complexity of entailment checking. In particular we show new polynomial cases and generalize polynomial cases already known in the literature for various popular multivalued logics. Such polynomial cases are obtained by means of two simple algorithms, sharing a common method.	algorithm;cobham's thesis;description logic;polynomial	Marco Cadoli;Marco Schaerf	1996	Annals of Mathematics and Artificial Intelligence	10.1007/BF02136173	monoidal t-norm logic;t-norm fuzzy logics;discrete mathematics;mathematics;algorithm	AI	-14.116201082709129	7.448696398319354	144987
3e8c9ab49681a283b1500fb566c18fcf91757667	ontology and formal semantics - integration overdue	semantics;natural language semantics;formal semantics;artificial intelligent;natural language;artificial intelligence;common sense;computational linguistics	In this note we suggest that difficulties encountered in natural language semantics are, for the most part, due to the use of mere symbol manipulation systems that are devoid of any content. In such systems, where there is hardly any link with our commonsense view of the world, and it is quite difficult to envision how one can formally account for the considerable amount of content that is often implicit, but almost never explicitly stated in our everyday discourse. The solution, in our opinion, is a compositional semantics grounded in an ontology that reflects our commonsense view of the world and the way we talk about it in ordinary language. In the compositional logic we envision there are ontological (or first-intension) concepts, and logical (or second-intension) concepts, and where the ontological concepts include not only Davidsonian events, but other abstract ob-It will be demonstrated here that in such a framework, a number of challenges in the semantics of natural language can be properly and uniformly addressed.	commonsense reasoning;intension;natural language	Walid S. Saba	2007	CoRR		natural language processing;statistical semantics;lexicology;formal semantics;computer science;artificial intelligence;computational linguistics;proof-theoretic semantics;formal semantics;semantics;natural language;well-founded semantics;operational semantics;denotational semantics;computational semantics	NLP	-13.467581493483385	5.581087246592934	145093
e1a547426c913a9ce7345d190684ff93489dbde6	circumscription and implicit definability	artificial intelligent;definability theory mathematical logic;artificial intelligence	We explore some connections between the technique of circumscription in artificial intelligence and the notion of implicit definition in mathematical logic. Implicit definition can be taken as the informal intent, but not necessarily the formal result, of circumscription. This raises some questions for logical theory and suggests some implications for artificial intelligence practice. The principal implication is that when circumscription ‘works’ its conclusions can be explicitly described.	artificial intelligence;circumscription (logic)	Jon Doyle	1984	Journal of Automated Reasoning	10.1007/BF00244277	discrete mathematics;computer science;artificial intelligence;mathematics;circumscription;algorithm	AI	-14.264947764175169	5.984374556919806	145885
c25d3329f2b7ebcb9781bf9bbc7522f94b655f65	validity and necessity	truth;kripke s a;operator;carnap r;formalism;necessity;semantics;necessite;verite;quantification;semantique;validite;modality;camap;modal logic;validity;monde possible;operateur;universal;model;universel;modele;possible world semantics;description;kripke;formalisme;possible worlds;modalite;model theory	In this paper I argue against the commonly received view that Kripke’s formal Possible World Semantics (PWS) reflects the adoption of a metaphysical interpretation of the modal operators. I consider in detail Kripke’s three main innovations vis-à-vis Carnap’s PWS: a new view of the worlds, variable domains of quantification, and the adoption of a notion of universal validity. I argue that all these changes are driven by the natural technical development of the model theory and its related notion of validity: they are dictated by merely formal considerations, not interpretive concerns. I conclude that Kripke’s model theoretic semantics does not induce a metaphysical reading of necessity, and is formally adequate independently of the specific interpretation of the modal operators.	microsoft personal web server;modal logic;modal operator;possible world;theory	Roberta Ballarin	2005	J. Philosophical Logic	10.1007/s10992-004-7800-2	philosophy;epistemology;mathematics;semantics;possible world;algorithm	Logic	-13.380195273906722	5.793955023569568	145889
ffe7ac9ecb6e2ecbabb4fc9b28f5aad3161cd813	leptokurtosis, litotes and other seemingly diseased techniques in statistics and syntactics				Adam Grummitt	2009			litotes;statistics;mathematics	DB	-12.127504426394742	9.907964621859293	145921
e56662f6a3c81062d86f19a98c73194ce928f7b8	two-sorted point-interval temporal logics	complexity;interval temporal logic;satisfiability;temporal reasoning;decidability;point and interval temporal logics	There are two natural and well-studied approaches to temporal ontology and reasoning: point-based and interval-based. Usually, interval-based temporal reasoning deals with points as particular, duration-less intervals. Here we develop explicitly two-sorted point-interval temporal logical framework whereby time instants (points) and time periods (intervals) are considered on a par, and the perspective can shift between them within the formal discourse. We focus on fragments involving only modal operators that correspond to the inter-sort relations between points and intervals. We analyze their expressiveness, comparative to interval-based logics, and the complexity of their satisfiability problems. In particular, we identify some previously not studied and potentially interesting interval logics.		Philippe Balbiani;Valentin Goranko;Guido Sciavicco	2011	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2011.10.004	decidability;t-norm fuzzy logics;combinatorics;discrete mathematics;complexity;interval temporal logic;computer science;mathematics;algorithm;satisfiability	Logic	-15.088352182379543	10.735975003124612	146091
de408911b25be082e6b856294f20b97527df3694	computing abductive argumentation in answer set programming	answer set programming;decision problem;exception handling;abductive logic programming;knowledge base	In our daily life, humans often argue with each other using abductive knowledge which includes not only facts known to be true but also hypotheses that may be expected to be true. This paper presents a novel approach to find out every skeptical (resp. credulous) explanation which is the set of hypotheses needed to skeptically (resp. credulously) justify the argument supporting a disputer's claim based on abductive knowledge base under the specified argumentation semantics. The main subject of this paper is the definition of the Abductive Argumentation Framework which is equivalent to the widely adopted Dung's framework except handling hypotheses, and from which skeptical (resp. credulous) explanations in argumentation can be defined. In general, there are multiple explanations under the specified argumentation semantics. Our approach is capable of finding out all of them by means of applying traditional abductive logic programming to our previous work of computing argumentation semantics in answer set programming (ASP). Thus this study eventually reveals the greatest advantage of applying ASP to the crucial decision problems in the research field of argumentation.	abductive reasoning;answer set programming;stable model semantics	Toshiko Wakaki;Katsumi Nitta;Hajime Sawamura	2009		10.1007/978-3-642-12805-9_12	computer science;artificial intelligence;machine learning;algorithm;abductive logic programming	AI	-16.38667422037535	6.695452975902688	146304
106a1d7bd66de0b390351d9e576666573d14e263	on defense strength of blocking defeaters in admissible sets	conflicting argument;defeat relation;extended argumentation framework;argument defender;new admissibility notion;symmetric conflict;admissible set;argument defense;defense strength;new argumentation semantics;extended framework	Extended argumentation framework is a formalism where defeat relations are determined by establishing a preference between arguments involved in symmetric conflicts. This process possibly leads to blocking situations, where conflicting arguments are found to be incomparable or equivalent in strength. In this work we introduce new argumentation semantics for extended frameworks, by taking into account the strength of an argument defense. Each of these new admissibility notions relies on the presence of blocking defeaters as argument defenders.	admissible heuristic;argumentation framework;blocking (computing);enterprise architecture framework;maximal set;rational agent;relevance;semantics (computer science)	Diego C. Martínez;Alejandro Javier García;Guillermo Ricardo Simari	2007		10.1007/978-3-540-76719-0_17	artificial intelligence;algorithm	AI	-17.135420792735413	4.949398251170543	146638
a4dcc284d4ac6b795a4ec5c00d46a4c035bcba2c	sloopy identity	sloopy identity	Although sloppy interpretation is usually accounted for by theories of ellipsis, it often arises in non-elliptical contexts. In this paper, a theory of sloppy interpretation is provided which captures this fact. The underlying idea is that sloppy interpretation results from a semantic constraint on parallel structures and the theory is shown to predict sloppy readings for deaccented and paycheck sentences as well as relational-, event-, and one-anaphora. It is further shown to capture the interaction of sloppy/strict ambiguity with quantification and binding. Finally, it is compared with other approaches to sloppy identity, in particular [4,12] [5]. 1 I n t r o d u c t i o n Sloppy interpretation involves two clauses: a source or antecedent clause and a t a r g e t clause that is, a clause containing a proform (the t a r g e t p r o f o r m ) . When the antecedent of the target proform also contains a proform (the source p r o f o r m ) , a sloppy interpretation may arise. In this case, the interpretation of the target proform differs from the interpretation of its source antecedent in the interpretation of the source proform. For instance, in: Example 1. Jon 1 [washes his: car] 2. Peter does2 too. the VP-ellipsis does has, among others, the sloppy interpretation washes Peter 's car (indeed, this is the preferred reading). The interpretation is sloppy because whereas in the source clause Jon washes his car the source proform his is interpreted as Jon, in the target clause Peter does too, it is re-interpreted as Peter. Although it is most often associated with VP-ellipsis, the phenomenon of sloppy identity is in fact very pervasive, and can occur in a wide range of configurations for instance: deaccenting (example 2 where the deaccented material is in bold face), paycheck sentences (example 3), VPE as a source proform (examples 4 and 5), non-pronominal referential elements involving implicit arguments (examples 6 and 7), event anaphora (examples 8 and 9) and one-anaphora (example i0):. ' The material occuring between brackets represents the interpretation being considered, in this case, the sloppy interpretation. Most examples are from [15].	anaphora (linguistics);hans-peter seidel;name binding;pervasive informatics;theory;video processing engine	Claire Gardent	1996		10.1007/BFb0052158	cultural identity;identity formation	Vision	-12.83206240164385	5.2826638414655465	147317
c385864306a038ca25a9e5e51157db65e6ae3eb8	bipolar queries: some inspirations from intention and preference modeling		The concept of a bipolar query, meant as a database query that involves both mandatory and optional conditions is discussed from the point of view of flexible database querying and modeling of more sophisticated user’s intentions and preferences. Aggregation of the matching degrees against the negative and positive conditions to derive an overall matching degree is considered taking as the point of departure the Lacroix and Lavency approach [25] for bipolar queries. It is shown that the use of a multiple valued logic based formalism for the representation of positive and negative desires in the context of intention modeling proposed by Casali, Godo and Sierra [8, 7] can be employed to extend the approach to bipolar queries. Both the approaches have roots in the seminal Dubois and Prade’s view of bipolarity in the possibilistic setting (cf. for a comprehensive review Dubois and Prade [17]).		Janusz Kacprzyk;Slawomir Zadrozny	2012		10.1007/978-3-642-24666-1_14	fuzzy logic;machine learning;logical connective;mathematics;formalism (philosophy);artificial intelligence	Robotics	-18.87169265968633	6.8899539982048825	148338
22b796eeb124ca10ef04988eeafafbaff4fe614b	languages and designs for probability judgment	probability judgment	Theories of subjective probability are viewed as formal languages for analyzing evidence and expressing degrees of belief. This article focuses on two probability langauges, the Bayesian language and the language of belief functions (Shafer, 1976). We describe and compare the semantics (i.e., the meaning of the scale) and the syntax (i.e., the formal calculus) of these languages. We also investigate some of the designs for probability judgment afforded by the two languages.		Glenn Shafer;Amos Tversky	1985	Cognitive Science	10.1207/s15516709cog0903_2	psychology;natural language processing;imprecise probability;computer science;probability interpretations;social psychology;algorithm	EDA	-14.310642637352009	4.41299256863196	148615
a1b5f8830ed6588620f90486e75d7faa1bfe6add	logics for geographic information	mereotopology;geographic information system;geographic information;key words spatial logic;formal semantics;satisfiability;modal logic;completeness;spatial logic	Abstract. We provide an overview of recent results in spatial logic, and discuss their relevance for the development of formal representations of geographic knowledge. Several proposed “spatial” logics are explored. We discuss their applicability to computational geography, and ultimately investigate their credentials as logics of space. A “non-revisionist” adequacy criterion for spatial logics is proposed, according to which a logic is truly a spatial logic only if all consistent sets of sentences of that logic are realizable in a classical model of space. Various proposed spatial logics can be shown not to satisfy this criterion. The observations constitute incompleteness results for certain spatial logics, because they show that consistent sets of formulae in these logics do not have models of the intended sort. The implications of these results are discussed with reference to the role of logics as spatial description languages for geographical information systems (GIS). Finally, we describe a complete calculus for plane mereotopology, which has recently been developed.		Oliver Lemon;Ian Pratt-Hartmann	1999	Journal of Geographical Systems	10.1007/s101090050006	modal logic;t-norm fuzzy logics;discrete mathematics;classical logic;description logic;higher-order logic;computation tree logic;completeness;non-monotonic logic;formal semantics;mathematics;geographic information system;probabilistic logic;kripke semantics;accessibility relation;algorithm;statistics;mereotopology;satisfiability	DB	-13.548524658205803	8.403733504467791	148650
32b665436852dfcccc59321ad73e64f658162f13	a psychological analysis of preference semantics in conditional logics for preference representation		"""Qualitative and comparative preference statements of the form """"prefer α to β"""" are useful components of many applications. This statement leads to the comparison of two sets of alternatives: the set of alternatives in which α is true and the set of alternatives in which β is true. Different ways are possible to compare two sets of objects leading to what is commonly known as preference semantics. The choice of the semantics to employ is important as they differently rank-order alternatives. Existing semantics are based on philosophical and non-monotonic reasoning grounds. In the meanwhile, they have been widely and mainly investigated by AI researchers from algorithmic point of view. In this paper, we come to this problem from a new angle and complete existing theoretical investigations of the semantics. In particular, we provide a comparison of the semantics on the basis of their psychological plausibility by evaluating their closeness to human behavior."""		Souhila Kaci;Eric Raufaste	2014		10.1007/978-3-319-11508-5_18	artificial intelligence;formal semantics;data mining;mathematics;well-founded semantics;operational semantics;denotational semantics;algorithm;computational semantics	AI	-14.564568715181823	5.390710072888671	150240
7688753cff0f2e74d10744639653971a17187ebb	a logic of knowledge and belief for recursive modeling: a preliminary report	decision theoretic;recursive modeling;deductive reasoning;possible worlds semantics;preliminary report;deductive method;wise men example;multiagent environment;multiagent reasoning;possible world;kripke structure	To make informed decisions in a multiagent environment, an agent needs to model itself, the world, and the other agents, including the models that those other agents might be employing. We present a framework for recursive modeling that uses possible worlds semantics, and is based on extending the Kripke structure so that an agent can model the information it thinks that another agent has in each of the possible worlds, which in turn can be modeled with Kripke structures. Using recursive nesting, we can define the propositional attitudes of agents to distinguish between the concepts of knowledge and belief. Through the Three Wise Men example, we show how our framework is useful for deductive reasoning, and we suggest that it might provide a meeting ground between decision theoretic and deductive methods for multiagent reasoning.	recursion	Piotr J. Gmytrasiewicz;Edmund H. Durfee	1992			computer science;knowledge management;artificial intelligence;machine learning;algorithm	ML	-17.796151545117755	4.343377041994435	150343
32b44139e67322e6c76183ebecbc6d40cdd52d33	from bayesian epistemology to inductive logic	inductive logic;bayesian epistemology;objective bayesianism;probability logic;bayesianism;b philosophy general;probabilistic logic;maxent;maximum entropy	Inductive logic admits a variety of semantics (Haenni et al. (2011) [7, Part 1]). This paper develops semantics based on the norms of Bayesian epistemology (Williamson, 2010 [16, Chapter 7]). Section 1 introduces the semantics and then, in Section 2, the paper explores methods for drawing inferences in the resulting logic and compares the methods of this paper with the methods of Barnett and Paris (2008) [2]. Section 3 then evaluates this Bayesian inductive logic in the light of four traditional critiques of inductive logic, arguing (i) that it is language independent in a key sense, (ii) that it admits connections with the Principle of Indifference but these connections do not lead to paradox, (iii) that it can capture the phenomenon of learning from experience, and (iv) that while the logic advocates scepticism with regard to some universal hypotheses, such scepticism is not problematic from the point of view of scientific theorising.	bayesian network;inductive reasoning	Jon Williamson	2013	J. Applied Logic	10.1016/j.jal.2013.03.006	predicate logic;dynamic logic;zeroth-order logic;higher-order logic;paraconsistent logic;principle of bivalence;philosophy;epistemology;many-valued logic;computer science;artificial intelligence;bunched logic;predicate functor logic;computational logic;mathematics;linguistics;probabilistic logic;logic;term logic;multimodal logic;second-order logic;algorithm;statistics;philosophy of logic;autoepistemic logic	AI	-13.890537990251211	4.560504503802769	150397
5cfb3e9a45ae7658ac654f808fae19a8aa8fc060	type theory and its meaning explanations		At the heart of intuitionistic type theory lies an intuitive semantics called the “meaning explanations”; crucially, when meaning explanations are taken as definitive for type theory, the core notion is no longer “proof” but “verification”. We’ll explore how type theories of this sort arise naturally as enrichments of logical theories with further judgements, and contrast this with modern proof-theoretic type theories which interpret the judgements and proofs of logics, not their propositions and verifications.	intuitionistic type theory	Jonathan Sterling	2015	CoRR		mathematics;algorithm	PL	-13.089320615636776	4.916156291270508	151091
0b33256c2c75149c5183539b5f51c7d51775f431	a model for non-monotonic reasoning using dempster's rule	non monotonic reasoning	Considerable attention has been given to the problem of non-monotonic reasoning in a belief function framework. Earlier work (M. Ginsberg) proposed solutions introducing meta-rules which recognized conditional independencies in a probabilistic sense. More recently an e-calculus formulation of default reasoning (J. Pearl) shows that the application of Dempster's rule to a non-monotonic situation produces erroneous results. This paper presents a new belief function interpretation of the problem which combines the rules in a way which is more compatible with probabilistic results and respects conditions of independence necessary for the application of Dempster's combination rule. A new general framework for combining conflicting evidence is also proposed in which the normalization factor becomes modified. This produces more intuitively acceptable results.	conditional entropy;default logic;non-monotonic logic	Mary McLeish	1990			computer science;artificial intelligence;data mining;mathematics;algorithm	AI	-15.824582763698782	6.708344606079948	151094
982ed578043b6740c94d017bfb83596192ccdd4a	interpreting disjunctive logic programs based on a strong sense of disjunction	minimal model;query processing;strong disjunctive database sdd;disjunctive logic programs;disjunctive logic programming;deductive databases	This paper studies a strong form of disjunctive information in deductive databases. The basic idea is that a disjunctionA ∨B should be considered true only in the case when neitherA norB can be inferred, but the disjunctionA ∨B is true. Under this interpretation, databases may be inconsistent. For those databases that are consistent, it is shown that a unique minimal model exists. We study a fixpoint theory and present a sound and complete proof procedure for query processing in consistent databases. For a class of inconsistent databases, we obtain a declarative semantics by selecting an interpretation that maximizes satisfaction, and minimizes indefiniteness. Two notions of negation are introduced.	deductive database;disjunctive normal form;fixed point (mathematics);information theory;knaster–tarski theorem;logic programming	James J. Lu;Monica D. Barback;Lawrence J. Henschen	1993	Journal of Automated Reasoning	10.1007/BF00881796	database theory;theoretical computer science;mathematics;disjunctive syllogism;programming language;disjunctive normal form;algorithm	DB	-17.416987424734145	9.101863263043866	151255
4cdbec97728c741de6ae894e57ffe7b37489be59	preference reasoning	preference modelling frameworks: soft constraints and cp-nets. soft constraints	A formalism to model many kinds of preferences Efficient tools to find the most preferred scenarios One or many agents expressing their preferences Outline Different kinds of preferences Representing preferences Soft constraints CP nets Comparison between them Combining soft constraints and CP nets Approximation: from CP nets to soft constraints CP nets + (soft) constraints Positive and negative preferences Aggregating preferences Possibility and impossibility results on preference aggregation	approximation;cp/m;fairness measure;local consistency;preference learning;semantics (computer science);software propagation	Francesca Rossi	2005		10.1007/11562931_2	preference learning	AI	-17.665380442542926	8.037805011426606	151775
0565c7898407b72abad77a59a63771545239b1e1	rough polyadic modal logics	fuzzy set;rough set theory;artificial intelligent;modal logic;rough set	ABSTRACT Rough polyadic modal logics, introduced in the paper, contain modal operators of many arguments with a relational semantics, based on the Pawlak's rough set theory. Rough set approach is developed as an alternative to the fuzzy set philosophy, and has many applications in different branches in Artificial Intelligence and theoretical computer science	modal logic;rough set	Dimiter Vakarelov	1999	Journal of Applied Non-Classical Logics	10.1080/11663081.1991.10510769	normal modal logic;discrete mathematics;rough set;computer science;artificial intelligence;mathematics;accessibility relation;algorithm;dominance-based rough set approach	Logic	-13.990477021448571	10.57231557056059	152102
a447aa78635105075df2a3a4b09b1d208872b646	modularity and relevant logic	logica formal;pertinencia;modularite;raisonnement;exactitude;pertinence;razonamiento;formal logic;clause horn;relevance;reasoning;logique formelle			James W. Garson	1989	Notre Dame Journal of Formal Logic	10.1305/ndjfl/1093635079	natural language processing;relevance;epistemology;artificial intelligence;mathematics;logic;reason;algorithm	Logic	-13.57413882313572	9.764544458592743	152299
d469e2a0a2355442260fe54a9cc97aa95b1f7e55	axiomatic foundations of acceptability semantics	argumentation;semantics;axiomatic foundations	An argument is a reason or justification of a claim. It has an intrinsic strength and may be attacked by other arguments. Hence, the evaluation of its overall strengthbecomes mandatory, especially for judging the reliability of its claim. S uch an evaluation is done by acceptability semantics. The aim of this paper is to set up the foundationsof acceptability semantics. Foundations are important not only for a better understanding of the evaluation process in general, but also for clarifying the basic assumptions underlying seman tics, for comparing different (families of) semantics and i dentifying families of semantics that have not been explored ye t. The paper defines the building blocks of a semantics. It introduces keyconceptsandprincipleson which an evaluation is based. Each concept (principle) is described by an axiom. We investigate properties of semantics that satisfy the axioms, show the foundations of the two crucial notions of rein statement and defence, and analyse some existing semantics against the axioms.	artificial intelligence	Leila Amgoud;Jonathan Ben-Naim	2016			formal semantics;argumentation theory;proof-theoretic semantics;formal semantics;semantics;axiomatic semantics;well-founded semantics;operational semantics;denotational semantics;algorithm;computational semantics	AI	-15.295907308118498	5.56352255823086	152639
9086685f1c5a119563434b1702d38aa9ad02753b	belief revision in a discrete temporal probability-logic	inductive inference;expressive power;discrete time;knowledge base;belief revision	We describe a discrete time probability logic for use as the representation language of a temporal knowledge base In addition to the usual expressive power of a discrete temporal logic our language allows for the speci cation of non universal generaliza tions in the form of statistical assertions This is similar to the probability logic of Bacchus but di ers in the inference mech anisms In particular we discuss two in teresting and related forms of inductive in ference interpolation and extrapolation Interpolation involves inferences about a time interval or point contained within an interval for which we have relevant statis tical information Extrapolation extends statistical knowledge beyond the interval to which it pertains These inferences can be studied within a static temporal knowl edge base but the further complexity of dynamically accounting for new observa tions makes matters even more interesting This problem can be viewed as one of be lief revision in that new observations may con ict with current beliefs which require updating As a rst step toward a full edged temporal belief revision system we consider the tools of inductive logic We suggest that Carnap s method of con rma tion may serve as a simple mechanism for belief revision	belief revision;extrapolation;inductive reasoning;interpolation;knowledge base;limbo;naruto shippuden: clash of ninja revolution 3;software development kit;temporal logic	Scott D. Goodwin;Howard J. Hamilton;Eric Neufeld;Abdul Sattar;André Trudel	1994			belief revision;expressive power;inductive reasoning;discrete time and continuous time;knowledge base;probabilistic logic;natural language processing;artificial intelligence;machine learning;mathematics	AI	-14.437663305560744	9.371274222509154	153077
66e83e2385ce5611637d199ef4cd31f1307fd58f	towards efficient belief update for planning-based web service composition	semantic web service;web service composition;upper bound	At the “functional level”, Semantic Web Services (SWS) are described akin to planning operators, with preconditions and effects relative to an ontology; the ontology provides the formal vocabulary and an axiomatisation of the underlying domain. Composing such SWS is similar to planning. A key obstacle in doing so effectively is handling the ontology axioms, which act as state constraints. Computing the outcome of an action involves the frame and ramification problems, and corresponds to belief update. The complexity of such updates motivates the search for tractable classes. Herein we investigate a class that is of practical relevance because it deals with many commonly used ontology axioms, in particular with attribute cardinality upper bounds which are not handled by other known tractable classes. We present an update computation that is exponential only in a comparatively uncritical parameter; we present an approximate update which is polynomial in that parameter as well.	approximation algorithm;axiomatic system;cobham's thesis;computation;polynomial;precondition;ramification problem;relevance;semantic web service;sinewave synthesis;time complexity;vocabulary;world sudoku championship	Jörg Hoffmann	2008		10.3233/978-1-58603-891-5-558	upper ontology;computer science;artificial intelligence;theoretical computer science;machine learning;data mining;database;upper and lower bounds	AI	-19.089120773463907	9.225442101447088	153318
2b418c516ed212b109975e2ee811b651dab35fde	three-valued plurivaluationism of vague predicates		Disagreeing with Williamson on vagueness, the author proposes a solution that he calls “three-valued plurivaluationism” to the age-old sorites paradox. In essence, it is a three-valued semantics for a first-order language with identity with the additional suggestion that a vague language has more than one correct interpretation. Unlike the traditional three-valued approach to a vague language, the so-called three-valued plurivaluationism, so the author argues, can accommodate the phenomenon of higher-order vagueness. And, unlike the tr`aditional three-valued approach to a vague language, the so-called three-valued purivaluationism, so the author argues, can also accommodate the phenomenon of penumbral connection when equipped with “suitable conditionals”. The author also shows that this three-valued purivaluationism is a natural consequence of a restricted form of Tolerance Principle (TR) and a few related ideas, and argues that (TR) is well-motivated by considerations of how we learn, teach, and use vague predicates.	first-order logic;first-order predicate;vagueness	Wen-Fang Wang	2015		10.1007/978-3-662-48561-3_31	sorites paradox;semantics;predicate (grammar);artificial intelligence;phenomenon;vagueness;mathematics	PL	-13.169061032244493	5.818450552447272	154802
6d8cb340d4554d9323c736dd78941a7316b835b6	harmonising natural deduction	natural deduction;science philosophy;classical logic;philosophie des sciences	Prawitz proved a theorem, formalising ‘harmony’ in Natural Deduction systems, which showed that, corresponding to any deduction there is one to the same effect but in which no formula occurrence is both the consequence of an application of an introduction rule and major premise of an application of the related elimination rule. As Gentzen ordered the rules, certain rules in Classical Logic had to be excepted, but if we see the appropriate rules instead as rules for Contradiction, then we can extend the theorem to the classical case. Properly arranged there is a thoroughgoing ‘harmony’, in the classical rules. Indeed, as we shall see, they are, all together, far more ‘harmonious’ in the general sense than has been commonly observed. As this paper will show, the appearance of disharmony has only arisen because of the illogical way in which natural deduction rules for Classical Logic have been presented.	natural deduction	Barry Hartley Slater	2007	Synthese	10.1007/s11229-007-9197-2	judgment;classical logic;philosophy;epistemology;deduction theorem;pure mathematics;mathematics;sequent calculus;natural deduction;algorithm	AI	-12.918981545989476	5.41042771311477	154971
15cae8f7d9d80ec65ce66f1fb19edb5ced1be508	a note on parameterised knowledge operations in temporal logic		We consider modeling the conception of knowledge in terms of temporal logic. The study of knowledge logical operations is originated around 1962 by representation of knowledge and belief using modalities. Nowadays, it is very good established area. However, we would like to look to it from a bit another point of view, our paper models knowledge in terms of linear temporal logic with past. We consider various versions of logical knowledge operations which may be defined in this framework. Technically, semantics, language and temporal knowledge logics based on our approach are constructed. Deciding algorithms are suggested, unification in terms of this approach is commented. This paper does not offer strong new technical outputs, instead we suggest new approach to conception of knowledge (in terms of time).	algorithm;graph coloring;linear temporal logic;logical connective;unification (computer science)	Vladimir V. Rybakov	2014	CoRR		linear temporal logic;artificial intelligence;knowledge-based systems;data mining;mathematics;procedural knowledge;algorithm	AI	-15.843022634324912	8.084313867459649	154990
3649724c665a232acbc3521b59584d3c6ae16cc5	an s4f-related monotonic modal logic		This paper introduces a novel monotonic modal logic, allowing us to capture the nonmonotonic variant of the modal logic S4F: we add a second new modal operator into the original language of S4F, and show that the resulting formalism is strong enough to characterise the logical consequence of (nonmonotonic) S4F, as well as its minimal model semantics. The latter underlies major forms of nonmonotonic logic, among which are (reflexive) autoepistemic logic, default logic, and nonmonotonic logic programming. The paper ends with a discussion of a general strategy, naturally embedding several nonmonotonic logics of a similar floor structure on which a (maximal) cluster sits.	accessibility relation;autoepistemic logic;default logic;formal system;hector levesque;logic programming;maximal set;modal logic;modal operator;non-monotonic logic	Ezgi Iraz Su	2017			discrete mathematics;modal logic;monotonic function;mathematics	AI	-15.468628303276489	9.502557731710125	155149
9d25e4e8ec5a5a0d6b362c42e1a0a6149bf2dce2	minimal unsatisfiability: models, algorithms and applications (invited paper)	debugging;description logics minimal unsatisfiability modeling task reasoning task overconstrained representations boolean logic minimal unsatisfiable sub formula database knowledgebase artificial intelligence formal methods operations research;iterative algorithms;boolean functions;approximation algorithms;computability;logic;testing;operations research;iterative algorithms testing logic artificial intelligence operations research educational institutions algorithm design and analysis boolean functions computational complexity debugging;computational modeling;computability boolean functions;computational complexity;heuristic algorithms;artificial intelligence;programming;algorithm design and analysis;concrete	The task of modeling and reasoning about real-world problems often involves analyzing overconstrained representations, where not all constraints of a problem can be simultaneously satisfied. The need to analyze over-constrained (or unsatisfiable) problems occurs in many settings, including data and knowledge bases, artificial intelligence, applied formal methods, operations research and description logics. In most cases, the problem to solve is related with some form of minimal unsatisfiability, i.e. an irreducible set of constraints that explains unsatisfiability. This paper provides an overview of some of the computational problems related with minimal unsatisfiability in Boolean logic, including the identification of one minimal unsatisfiable sub-formula and the identification of all minimal unsatisfiable sub-formulas. In addition, the paper briefly overviews practical applications of minimal unsatisfiability. Finally, the paper highlights recent work on minimal unsatisfiability in other domains.	algorithm;artificial intelligence;boolean algebra;computation;computational problem;description logic;formal methods;heuristic;irreducibility;knowledge base;logical connective;operations research;satisfiability modulo theories	Joao Marques-Silva	2010	2010 40th IEEE International Symposium on Multiple-Valued Logic	10.1109/ISMVL.2010.11	programming;discrete mathematics;concrete;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;computability;debugging;logic;approximation algorithm;algorithm;algebra	AI	-18.686568108832052	10.031022095990224	155246
98ff5743c73cf342a012b3548f19a15a8cad8059	paraconsistent query answering systems	contradiction;logica multivalente;circonscription;interrogation base donnee;interrogacion base datos;semantics;semantica;semantique;circumscription;logique multivalente;logique ordre 1;classical logic;query answering;contradiccion;multivalued logic;database query;first order logic;circonscripcion;logica orden 1;paraconsistent logic	Classical logic predicts that everything (thus nothing useful at all) follows from inconsistency. A paraconsistent logic is a logic where inconsistency does not lead to such an explosion, and since in practice consistency is difficult to achieve there are many potential applications of paraconsistent logics in query answering systems. We compare the paraconsistent and the non-monotonic solutions to the problem of contradictions. We propose a many-valued paraconsistent logic based on a simple notion of indeterminacy. In particular we describe the semantics of the logic using key equalities for the logical operators. We relate our approach to works on bilattices. We also discuss and provide formalizations of two case studies, notably the well-known example involving penguins and a more interesting example in the domain of medicine. Paraconsistent logic can be seen as an alternative, for example, to nonmonotonic logic. Non-monotonists reject monotony because they think that there are experiences (most of the time involving birds) which show that monotony is wrong and in particular leads to some contradictions. But one who thinks the paraconsistent way would reject the principle of non contradiction and not monotony. The strategy of the paraconsistentist is more imaginative, he accepts to see penguins flying in the sky of Hawai’s beaches and pink floyds surfing on Antarctica’s permafrost. It seems to us that the future shall give the preference to paraconsistent logic taking in account the progress of genitical biology which already produces chicken without feathers, and in the future we may have flying pigs. In such an absurd world, it will make no sense to reason by default, because everything could be true by default. J.-Y. Béziau The Future of Paraconsistent Logic Logical Studies Online Journal 2 (1999) p. 12	experience;indeterminacy in concurrent computation;logical connective;non-monotonic logic;paraconsistent logic;whole earth 'lectronic link	Jørgen Villadsen	2002		10.1007/3-540-36109-X_29	principle of explosion;classical logic;paraconsistent logic;computer science;artificial intelligence;disjunction introduction;first-order logic;semantics;linguistics;circumscription;algorithm	AI	-15.948188320904078	9.755353773427682	155525
6b0380b0acaf9b28bde01f9a07bcb8f775cdab1c	local probabilistic deduction from taxonomic and probabilistic knowledge-bases over conjunctive events	inference rule;linear program;conditional probability;knowledge base	Abstract   We elaborate locally complete inference rules for probabilistic deduction from taxonomic and probabilistic knowledge-bases over conjunctive events. We integrate the presented inference rules into a local probabilistic deduction technique, which exploits taxonomic knowledge for an efficient representation of conjunctive events. This local probabilistic deduction technique is less incomplete and more efficient than already existing local approaches to probabilistic deduction. However, we show that it cannot compete with global probabilistic deduction by linear programming. Surprisingly, we can provide examples of globally very incomplete probabilistic deductions in the presented local approach. More generally, we even show that all systems of inference rules for probabilistic deduction in taxonomic and probabilistic knowledge-bases over conjunctive events that have a limited number of probabilistic formulas in the premises of their inference patterns are globally incomplete. Furthermore, we show that the presented local approach is not more efficient than the linear programming approach for that framework. We conclude that probabilistic deduction by the iterative application of inference rules on interval restrictions for conditional probabilities, even though considered very promising in the literature so far, is very limited in its field of application.	natural deduction	Thomas Lukasiewicz	1999	Int. J. Approx. Reasoning	10.1016/S0888-613X(99)00006-7	knowledge base;discrete mathematics;probabilistic analysis of algorithms;probabilistic ctl;conditional probability;probabilistic relevance model;computer science;artificial intelligence;machine learning;data mining;mathematics;probabilistic logic;probabilistic argumentation;statistics;rule of inference;divergence-from-randomness model	AI	-18.5362699292853	8.689408162048183	155787
c39978afa1b635d3924ed14ef4d7510588a318c5	structural correspondence between theories and convergence to truth	correspondence;structural realism;convergence to truth	This paper utilizes a logical correspondence theorem (which has been proved elsewhere) for the justification of weak conceptions of scientific realism and convergence to truth which do not presuppose Putnam’s no-miracles-argument (NMA). After presenting arguments against the reliability of the unrestricted NMA in Sect. 1, the correspondence theorem is explained in Sect. 2. In Sect. 3, historical illustrations of the correspondence theorem are given, and its ontological consequences are worked out. Based on the transitivity of the concept of correspondence, a correspondence-based notion of convergence to truth is developed in Sect. 4. In the final Sect. 5 it is argued that the correspondence theorem together with the assumption of ‘minimal realism’ yields a justification of a weak version of scientific realism, which is then compared to metaphysical realism and to instrumentalism.	vergence;vertex-transitive graph	Gerhard Schurz	2010	Synthese	10.1007/s11229-010-9784-5	philosophy;epistemology;structuralism;mathematics;algorithm	AI	-12.786906006589463	4.428740746309011	156086
7b75d2dd9bbd7b0e324d528645288816fa5ee345	introducing attempt in a modal logic of intentional action	belief;atomic operation;molecular dynamics;discrete time;intelligence artificielle;logical programming;dynamique moleculaire;molecular dynamics method;modal logic;croyance;programmation logique;logique modale;logica modal;artificial intelligence;operacion atomica;methode dynamique moleculaire;inteligencia artificial;intencion;dinamica molecular;creencia;tiempo discreto;temps discret;programacion logica;situation calculus;intention;operation atomique;metodo dinamico molecular	The main objective of this work is to develop a multi-modal logic of Intention and Attempt. We call this logic LIA. All formal results are focused on the notion ofattempt . We substitute the dynamic molecular notion actionby his atomic constituent attemptand define the former from the latter. The relations between attempts, goals, beliefs and present-directed intentions are studied. A section of the paper is devoted to the analysis of the relations of our modal logic with a situation calculus-style approach.	iso/iec 10967;modal logic;situation calculus	Emiliano Lorini;Andreas Herzig;Cristiano Castelfranchi	2006		10.1007/11853886_24	epistemic modal logic;epistemology;artificial intelligence;mathematics;accessibility relation;multimodal logic;algorithm	Logic	-17.504257260006842	10.853389050474592	156744
33c4dbc05dbb10bd02cea0e827ab7eb436690eca	a general framework for knowledge compilation	knowledge compilation;computational efficiency;knowledge base	Computational eeciency is a central concern in the design of knowledge representation systems. In order to obtain eecient systems it has been suggested that one should limit the form of the statements in the knowledge base or use an incomplete inference mechanism. The former approach is often too restrictive for practical applications, whereas the latter leads to uncertainty about exactly what can and cannot be inferred from the knowledge base. We present a third alternative, in which knowledge given in a general representation language is translated (compiled) into a tractable form | allowing for eecient subsequent query answering. We show how propositional logical theories can be compiled into Horn theories that approximate the original information. The approximations bound the original theory from below and above in terms of logical strength. The procedures are extended to other tractable languages (for example, binary clauses) and to the rst-order case. Finally, we demonstrate the generality of our approach by compiling concept descriptions in a general frame-based language into a tractable form.	approximation algorithm;cobham's thesis;compiler;computation;correctness (computer science);general frame;horn clause;knowledge base;knowledge compilation;knowledge representation and reasoning;theory	Henry A. Kautz;Bart Selman	1991		10.1007/BFb0013538	knowledge base;computer science;knowledge management;data science;knowledge-based systems;open knowledge base connectivity;data mining;knowledge extraction	AI	-18.627299803288984	8.846952435927498	156778
be1915189c1d2f32ef18ecfd2e58cd30ae2cadcc	t-delp: a temporal extension of the defeasible logic programming argumentative framework	temporal forward reasoning;argumentation-based defeasible logic;logical consequence;temporal process;delp logical framework;temporal extension;temporal logic program;temporal fact;temporal aspect;temporal parameter;temporal literal;defeasible logic programming argumentative	The aim of this paper is to offer an argumentation-based defeasible logic that enables forward reasoning with time. We extend the DeLP logical framework by associating temporal parameters to literals. A temporal logic program is a set of temporal literals and durative rules. These temporal facts and rules combine to into durative arguments representing temporal processes, that permit us to reason defeasibly about future states. The corresponding notion of logical consequence, or warrant, is defined slightly different from that of DeLP, due to the temporal aspects. As usual, this notion takes care of inconsistencies, and in particular we prove the consistency of any logical program whose strict part is consistent. Finally, we define and study a sub-class of arguments that seem appropriate to reason with natural processes, and suggest a modification to the framework that is equivalent to restricting the logic to this class of arguments.	care-of address;defeasible logic;defeasible reasoning;literal (mathematical logic);logic programming;logical framework;persistence (computer science);temporal logic	Pere Pardo;Lluis Godo	2011		10.1007/978-3-642-23963-2_38	linear temporal logic;interval temporal logic;computation tree logic;artificial intelligence;mathematics;algorithm;temporal logic of actions	AI	-17.03062640694408	8.831562715886283	157349
b3ace7cd97cd98983ac9010bdc6230f073b3a27b	a proof-theoretic semantic analysis of dynamic epistemic logic		The present paper provides an analysis of the existing proof systems for dynamic epistemic logic from the viewpoint of proof-theoretic semantics. Dynamic epistemic logic is one of the best known members of a family of logical systems which have been successfully applied to diverse scientific disciplines, but the proof theoretic treatment of which presents many difficulties. After an illustration of the proof-theoretic semantic principles most relevant to the treatment of logical connectives, we turn to illustrating the main features of display calculi, a proof-theoretic paradigm which has been successfully employed to give a proof-theoretic semantic account of modal and substructural logics. Then, we review some of the most significant proposals of proof systems for dynamic epistemic logics, and we critically reflect on them in the light of the previously introduced proof-theoretic semantic principles. The contributions of the present paper include a generalisation of Belnap’s cut elimination metatheorem for display calculi, and a revised version of the display-style calculus D.EAK [30]. We verify that the revised version satisfies the previously mentioned proof-theoretic semantic principles, and show that it enjoys cut elimination as a consequence of the generalised metatheorem.		Sabine Frittella;Giuseppe Greco;Alexander Kurz;Alessandra Palmigiano;Vlasta Sikimic	2016	J. Log. Comput.	10.1093/logcom/exu063	epistemology;computer science;artificial intelligence;mathematics;algorithm	PL	-15.012421999128849	6.5925124075328405	157396
339d71f5749e946d927cd7cfa59587941aa5dae3	evaluating argumentation semantics with respect to skepticism adequacy	argumentacion;argumentation;classe etat;securite;incertidumbre;uncertainty;semantics;intelligence artificielle;satisfiability;semantica;semantique;classification;state class;safety;clase estado;artificial intelligence;incertitude;inteligencia artificial;seguridad;clasificacion	Analyzing argumentation semantics with respect to the notion of skepticism is an important issue for developing general and wellfounded comparisons among existing approaches. In this paper, we show that the notion of skepticism plays also a significant role in order to better understand the behavior of a specific semantics in different situations. Building on an articulated classification of argument justification states into seven distinct classes and on the definition of a weak and a strong version of skepticism relation, we define the property of skepticism adequacy of an argumentation semantics, which basically consists in requiring a lesser commitment when transforming a unidirectional attack into a mutual one. We then verify the skepticism adequacy of some literature proposals and obtain the rather surprising result that some semantics fail to satisfy this basic property.	mike lesser	Pietro Baroni;Massimiliano Giacomin	2005		10.1007/11518655_29	uncertainty;biological classification;artificial intelligence;mathematics;semantics;algorithm;satisfiability	AI	-14.274590002396534	5.864440723452593	157599
8c8081e764309777dc566bfa2e08a49af3572184	"""two variations on the theme of """"useful four-valued logic"""""""			four-valued logic	Dmitry V. Zaitsev	2005	Multiple-Valued Logic and Soft Computing			EDA	-12.727291366137758	10.989756607223788	158282
1e6246a304ce25d02cb11f9b7aee89efac0a15a0	the pleasures of anticipation: enriching intuitionistic logic	kripke s a;anticipation;regle;logique des propositions;semantics;negation;semantique;conservation;consequence;connexion;intuitionistic logic;propositional logic;logique intuitionniste;classical logic;rauszer c;extension;rule;relation;point of interest	We explore a relation we call ‘anticipation’ between formulas, where A anticipates B (according to some logic) just in case B is a consequence (according to that logic, presumed to support some distinguished implicational connective →) of the formula A→ B. We are especially interested in the case in which the logic is intuitionistic (propositional) logic and are much concerned with an extension of that logic with a new connective, written as “a”, governed by rules which guarantee that for any formula B, aB is the (logically) strongest formula anticipating B. The investigation of this new logic, which we call ILa, will confront us on several occasions with some of the finer points in the theory of rules and with issues in the philosophy of logic arising from the proposed explication of the existence of a connective (with prescribed logical behaviour) in terms of the conservative extension of a favoured logic by the addition of such a connective. Other points of interest include the provision of a Kripke semantics with respect to which ILa is demonstrably sound, deployed to establish certain unprovability results as well as to forge connections with C. Rauszer’s logic of dual intuitionistic negation and dual intuitionistic implication, and the isolation of two relations (between formulas), head-implication and head-linkage, which, though trivial in the setting of classical logic, are of considerable significance in the intuitionistic context.	forge;intuitionistic logic;kripke semantics;linkage (software);logical connective;point of interest	Lloyd Humberstone	2001	J. Philosophical Logic	10.1023/A:1012264614940	predicate logic;dynamic logic;zeroth-order logic;linear logic;discrete mathematics;classical logic;point of interest;higher-order logic;paraconsistent logic;conservation;philosophy;law of thought;many-valued logic;intuitionistic logic;relation;intermediate logic;predicate functor logic;negation;mathematics;semantics;anticipation;logical connective;linguistics;minimal logic;propositional calculus;truth value;logic;multimodal logic;algorithm;philosophy of logic;autoepistemic logic	Logic	-12.532546142644971	5.183248189016058	158550
47760a85f5f2cf57627fd279c45b5131e8e24df2	extending probabilistic dynamic epistemic logic	probability;modal logic;epistemic logic;dynamic epistemic logic	This paper aims to extend in two directions the probabilistic dynamic epistemic logic provided in Kooi’s paper (J Logic Lang Inform 12(4):381–408, 2003) and to relate these extensions to ones made in van Benthem et al. (Proceedings of LOFT’06. Liverpool, 2006). Kooi’s probabilistic dynamic epistemic logic adds to probabilistic epistemic logic sentences that express consequences of public announcements. The paper (van Benthem et al., Proceedings of LOFT’06. Liverpool, 2006) extends (Kooi, J Logic Lang Inform 12(4):381–408, 2003) to using action models, but in both papers, the probabilities are discrete, and are defined on trivial σ-algebras over finite sample spaces. The first extension offered in this paper is to add a previous-time operator to a probabilistic dynamic epistemic logic similar to Kooi’s in (J Logic Lang Inform 12(4):381–408, 2003). The other is to involve non-trivial σ-algebras and continuous probabilities in probabilistic dynamic epistemic logic.	dynamic epistemic logic;epistemic modal logic;lawrence m. breed;liverpool;operational semantics;eric	Joshua Sack	2009	Synthese	10.1007/s11229-009-9555-3	modal logic;predicate logic;dynamic logic;zeroth-order logic;normal modal logic;description logic;higher-order logic;epistemic modal logic;philosophy;epistemology;many-valued logic;intermediate logic;probability;mathematics;probabilistic logic;probabilistic argumentation;probabilistic logic network;logic;multimodal logic;algorithm;autoepistemic logic	AI	-14.402930598895974	9.077431580233588	158759
7e68c144d66b12877586b949332d75419ae40b5b	prior and possibly not existing		In classical quantificational logic, every individual constant is assigned a value from the domain of discourse, thus ensuring that every instance of $$\exists x(x=\alpha )$$ ∃ x ( x = α ) is valid and so a theorem of a complete logic. Standard tense and modal logics validate a rule of necessitation, according to which, crudely, every theorem is always and necessarily true. Combining these two generates the result that everything always and necessarily exists. In a number of works from the late 1950s through to his death in 1969, Prior worked to develop tense and modal logics that avoided these results. Prior’s key idea was to reject the rule of necessitation. In this essay, I present and criticize Prior’s account of the contingency of existence and offer a more satisfying account that shares many of the virtues of Prior’s account.	domain of discourse;modal logic;non-logical symbol	Michael Nelson	2015	Synthese	10.1007/s11229-015-0906-y	discrete mathematics;mathematics;algorithm	Logic	-12.991421377996966	4.2424044945187935	159026
0e0ba634c880b7ba43a6df0058a0c319adca2543	action concepts for describing organised interaction	theseaction concept;organised interaction;action concepts;main aim;modal logic;conditional logic;formal characterisation;tradition inthe logical characterisation;deontic logic;modal action operator;act description;employedby kanger;formal logic;formal specifications;law;logic;mathematics;authorization	The main aim of this paper is to propose a set of action concepts useful for describing organised interaction. These action concepts focus on two distinctions: the distinction between “direct” and “indirect” action, and the distinction between “successful” and “not necessarily successful”		Filipe A. A. Santos;Andrew J. I. Jones;José Carmo	1997		10.1109/HICSS.1997.10062	modal logic;predicate logic;dynamic logic;normal modal logic;description logic;higher-order logic;epistemic modal logic;artificial intelligence;deontic logic;signature;accessibility relation;logic;multimodal logic;algorithm;philosophy of logic;autoepistemic logic;strict conditional	AI	-16.247082214224818	4.9764745931354	161044
3d3ed40677be1130312938ee7baf74e0ca92e3a2	a stit-logic for extensive form group strategies	agency;history;extensive form games;interaction;logic;modal logic;intelligent agent;extensive form games modal logic agency interaction;possible worlds;agent programming;conferences;logic intelligent agent history conferences	We present the logic $\textsf{G.STRAT}$ for reasoning about group strategies. To enable a modal semantics for reasoning about group strategies, strategy profiles will be viewed as structured possible worlds. Although the general logic is undecidable and not finitely axiomatizable for systems with 3 agents or more, we identify more well-behaved logics like $\textsf{ATL}$, and temporal \emph{stit}-logics as fragments. We explain our aim to apply the logics to reasoning about multi-agent programs, such as the programs of 2APL. Finally, we discuss several properties of (multi-)agency expressible in the logic. Among these properties is an axiom characterizing a basic form of autonomy.	2apl;autonomy;modal logic;multi-agent system;possible world;undecidable problem	Jan M. Broersen	2009	2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2009.331	modal logic;predicate logic;dynamic logic;modal μ-calculus;linear temporal logic;interaction;description logic;higher-order logic;epistemic modal logic;computer science;intermediate logic;artificial intelligence;non-monotonic logic;axiom s5;agency;accessibility relation;logic;intelligent agent;multimodal logic;algorithm;philosophy of logic	AI	-17.40182581951874	4.84322252318927	161270
458ec207194419f9b7e3fb536bf8c6b864fdf829	a logic of games and propositional control	liverpool;propositional control;strategic games;repository;solution concepts;modal logic;effectivity functions;game solvability;university;solution concept;strategic game;social choice theory	We present a logic for reasoning about strategic games. The logic is a modal formalism, based on the Coalition Logic of Propositional Control, to which we add the notions of outcomes and preferences over outcomes. We study the underlying structure of powers of coalitions as they are expressed in their effectivity function, and formalise a collection of solution concepts. We provide a sound and complete axiomatisation for the logic, and we demonstrate its features by applying it to some problems from social choice theory.	axiomatic system;modal logic;semantics (computer science)	Nicolas Troquard;Wiebe van der Hoek;Michael Wooldridge	2009		10.1145/1558109.1558146	modal logic;dynamic logic;zeroth-order logic;complete theory;modal μ-calculus;classical logic;social choice theory;description logic;intuitionistic logic;artificial intelligence;well-formed formula;accessibility relation;multimodal logic;solution concept;algorithm;autoepistemic logic	AI	-14.828165556076955	8.494340386576113	161515
79e92e76e4c66eb1a7f67c671620d920692c19fa	semantic paradox of material implication	implication;conditional;logique et philosophie du langage;conditionnel;consistance;philosophical logics and philosophyof language;consistency	Les caracteristiques contestables du conditionnel verifonctionnel se rencontrent meme dans les conditionnels du 1 ordre qui n'entrainent ni enchâssement, ni presence d'autres connecteurs. L'A. etablit une condition de consistance sur des partitions de conditionnels sans reclamer des assignations de valeurs de verite a des propositions primitives.	epr paradox	Robert Brandom	1981	Notre Dame Journal of Formal Logic	10.1305/ndjfl/1093883397	mathematics;linguistics;consistency;algorithm	NLP	-12.763183378830398	10.133474479010207	161875
28145479397230639ce5dd23a736f013d36c53b5	introduction to relative truth	journal article	Nor are meta-linguistic claims such as ‘the proposition that Socrates was a philosopher is true’, ‘what John asserted at 3 o’clock on January 15, 2002 is false’, and ‘Since John said that it’s raining on January 15, 2002, and Mary said that it’s not raining on January 15, 2002, John and Mary disagree about whether it is raining on January 15, 2002’. There are two reasons why such talk, in standard semantics, would be at best loosely true (see also Glanzberg’s contribution to this double issue). Firstly, standard semantics does not assume that utterances of sentences make implicit reference to worlds (A), and secondly, standard semantics does not assume that there is only		Berit Brogaard	2007	Synthese	10.1007/s11229-007-9288-0	philosophy;epistemology	NLP	-12.485782113206417	4.233136584096921	162918
e930de24be4bd48a2392eff432e75ae28649393d	possibilistic reasoning in multi-context systems: preliminary report	artificial intelligence and image processing not elsewhere classified;institute for integrated and intelligent systems;conference output;faculty of science environment engineering and technology;artificial intelligence and image processing;080199	This paper makes the first attempt to establish a framework for possibilistic reasoning in (nonmonotonic) multi-context systems, called possibilistic MCS. We first introduce the syntax for possibilistic MCS and then define its equilibrium semantics based on Brewka and Eiter's nonmonotonic multi-context systems. Then we investigate several properties and develop a fixoint theory for possibilistic MCS.		Yifan Jin;Kewen Wang;Lian Wen	2012		10.1007/978-3-642-32695-0_18	computer science;artificial intelligence;machine learning;data mining;operations research	Logic	-17.141416764548296	4.692756870778558	163489
10584a87f5e0a8df34f7ff8898e3502591cde643	slacker semantics: why superficiality, dependency and avoidance of commitment can be the right way to go	indexation	This paper discusses computational compositional semantics from the perspective of grammar engineering, in the light of experience with the use of Minimal Recursion Semantics in DELPH-IN grammars. The relationship between argument indexation and semantic role labelling is explored and a semantic dependency notation (DMRS) is introduced.	minimal recursion semantics;semantic role labeling;way to go	Ann A. Copestake	2009			natural language processing;computer science;linguistics;algorithm	AI	-13.006972172280918	7.579680249757069	163529
88e84d961a91fe8548612ac285da31943b659aa7	expanding argumentation frameworks: enforcing and monotonicity results	special class;monotonicity result;account possible change;monotonicity results;proof standard;dung-style argumentation framework;impossibility result;corresponding change;justification state;augmented argumentation framework;expanding argumentation frameworks;new argument	This paper addresses the problem of revising a Dung-style ar gumentation framework by adding finitely manynewarguments which may interact with old ones. We study the behavior of the extensions of an argumentat ion framework if we extend it (new information) and/or change the underlying s emantics (change of proof standards). We show both possibility and impossibilit y results related to the problem of enforcing a desired set of arguments. Furthermore w e will prove some monotonicity results for a special class of expansions with r espect to the cardinality of the set of extensions and the justification state.		Ringo Baumann;Gerhard Brewka	2010		10.3233/978-1-60750-619-5-75	algorithm	ML	-15.46764059334636	7.411010862232482	164212
25ded0e59b2c7a4d017ce93dad2edd7634ecb2ed	towards a probability theory based on moisil logic	probability theory;extension theorem;conditional probability	In this paper a concept of probability de®ned on a Lukasiewicz-Moisil algebra is proposed. We take some steps in developing the theory, including an extension theorem and some results related to conditional probabilities on Lukasiewicz-Moisil algebras. Key words Lukasiewicz-Moisil algebras, States, Conditional states 1 Introduction In probability theory one accepts the hypothesis that the set of events associated with a trial has a structure of Boolean algebra. This principle holds if the trial is governed by the laws of classical logic. On the other hand, many trials follow the action of other logics. For any logic, the sets of events are structured by the operations of the corresponding Lindenbaum-Tarski algebra. The second step in developing a probability theory for a logical system is to de®ne an appropriate concept of probability. For a probability theory based on Lukasiewicz logic the set of events must have a structure of MV-algebra [2, 5]. A comprehensive study of probabilities de®ned on MV-algebras can be found in the monography [19]. A natural problem is to develop a probability theory associated with the n-valued Moisil propositional logic [1, 15]. In this case, the set of events will be an n-valued Lukasiewicz-Moisil algebra (LMn-algebra). To de®ne a notion of probability on an Lukasiewicz algebra seems to be more dif®cult. In [9] we have introduced the concept of i-state as a probability which acts at level i. An i-state is a function which satis®es some ``probability axioms'' with respect to some new operations i and i de®ned in terms of LMn-algebra laws. This approach does not solve the problem of de®ning an appropriate notion of probability on an LMn-algebra. Any MVn-algebra A has a canonical structure of LMnalgebra LA. Thus a probability on the LMn-algebra LA must be induced by a probability on the MVn-algebra A. The aim of this paper is to study a concept of probability (on an Lukasiewicz-Moisil algebra) satisfying this condition. In [7] there was proved that any probability on the Boolean center CA of an MVn-algebra A can be uniquely extended to a probability on A. This theorem allows us to characterize a probability on an MVn-algebra in terms of the operations of LA. This will suggest a concept of probability on an arbitrary LMn-algebra. In Section 2 we remind some basic de®nitions and results concerning LMn-algebras and MVn-algebras. In Section 3 we de®ne the states on LMn-algebras, we prove some of their properties and we introduce the concepts of r-state and continuous state. The main result in Section 4 is an extension theorem for continuous states. Section 5 is concerned with conditional states on LMn-algebras. 2 LMn-algebras and MV-algebras Gr.C. Moisil introduced in 1940 the 3-valued Lukasiewicz algebras as algebraic models for the 3-valued Lukasiewicz logics. In 1941 he de®ned the n-valued Lukasiewicz algebras. A. Rose showed that the Lukasiewicz implication cannot be de®ned in n-valued Lukasiewicz algebras for n 5, so they do not correspond to the n-valued Lukasiewicz logics. Thus the structures created by Moisil led to other logical systems, so called Mosil logics. Now these algebras are known under the name of LukasiewiczMoisil algebras (cf. [1]). On the other hand C.C. Chang de®ned in 1958 the MV-algebras as algebraic structures of in®nite valued Lukasiewicz logic ([2]). The MVn-algebras introduced by R. Grigolia in 1997 are adequate algebraic models for the n-valued Lukasiewicz logics ([11]). The n-valued Lukasiewicz-Moisil algebras (LMn-algebras) are polynomially equivalent to the MVn-algebras for n  3 and n  4 (see [16] and [12]). Every MVn-algebra can be endowed with a canonical structure of LMn-algebra ([12]). Let n be a natural number, n 2 and I  f1; . . . ; ng. De®nition 2.1 An n+1-valued Lukasiewicz-Moisil algebra (or an LMn1-algebra) is a structure L;_;^; 0; 1;N;u1; . . . ;un h i, where L;_;^;N; 0; 1 h i is a De Morgan algebra and u1, . . ., un : L ÿ! L are bounded lattices morphisms such that: LM1. uix _ Nuix  1; uix ^ Nuix  0 for all i 2 I; LM2. uiujx  ujx for all i, j 2 I; LM3. uiNx  Nujx for all i, j 2 I with i j  n 1; LM4. u1x u2x unx LM5. The determination principle: uix  uiy for all i 2 I implies x  y. Original paper Soft Computing 4 (2000) 19±26 Ó Springer-Verlag 2000	agile software development;boolean algebra;de morgan's laws;formal system;linear algebra;mv-algebra;morgan;ne (complexity);propositional calculus;soft computing;springer (tank);unix-like;łukasiewicz logic	George Georgescu;Ioana Leustean	2000	Soft Comput.	10.1007/s005000050076	conditional probability distribution;probability theory;combinatorics;probability axioms;discrete mathematics;imprecise probability;standard probability space;conditional probability;probability measure;conditional expectation;normalizing constant;regular conditional probability;conditioning;tree diagram;chain rule;mathematics;law of total probability;algebra of random variables;posterior probability;bayes' theorem;conditional mutual information;conditional event algebra;conditional probability table	Logic	-13.211690068033777	7.157187154578239	164266
e980c8ebe1a4cee1df7c5d16f5e227252b68934f	a first-order semantics for golog and congolog under a second-order induction axiom for situations	program semantics;congolog;golog;the situation calculus;first order logic	Golog and ConGolog are languages defined in the situation calculus for cognitive robotics. Given a Golog program δ, its semantics is defined by a macroDo(δ, s, s′) that expands to a logical sentence that captures the conditions under which performing δ in s can terminate in s′. A similar macro is defined for ConGolog programs. In general, the logical sentences that these macros expand to are second-order, and in the case of ConGolog, may involve quantification over programs. In this paper, we show that by making use of the foundational axioms in the situation calculus, in particular, the second-order closure axiom about the space of situations, these macro expressions can actually be defined using first-order sentences. Introduction Golog [Levesque et al., 1997] and ConGolog [De Giacomo, Lespérance, and Levesque, 2000] are Algol-like programming languages defined in the situation calculus [McCarthy, 1968; Reiter, 2001]. They are intended for high-level control of agents, including both physical robots and virtual agents [Reiter, 2001; Burgard et al., 1999; Funge, 2000; Lespérance, Levesque, and Ruman, 1997; McIlraith and Son, 2002]. They include non-determinism, and in the case of ConGolog, concurrency. The semantics of Golog programs is axiomatized in logic by macro expansions [Levesque et al., 1997]: given a Golog program δ and two situation terms s and s′, the macro expression Do(δ, s, s′) is used to denote that s′ is a terminating situation of performing δ in s. There may be more than one possible terminating situation as the program may be indeterminate. In general, the macro expression Do(δ, s, s′) expands into a second-order sentence because δ may have loops. In the case of ConGolog programs, which are extensions of Golog programs with some concurrency operators, De Giacomo, Lespérance and Levesque [2000] introduced a one-step transition predicate Trans(δ, s, δ′, s′) (performing δ in s for one step may end up in situation s′ with δ′ as the remaining program to be performed) and a final predicate Final(δ, s) (program δ terminates in s). The Do macros are then defined using these predicates, and in general expand to sentences that are not only second-order, but also involve quantification over programs. Copyright c © 2014, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. The second-order formulas that are needed in Golog and ConGolog macro expansions are fundamentally the same as the ones for defining transitive closures. One of the foundational axioms of the situation calculus is a second-order one that defines the space of situations as the transitive closure of do(a, s) starting at the initial situation S0. In this paper, we show that this second-order foundational axiom can be used to capture loops and recursions so that for Golog and ConGolog programs, the macro expression Do(δ, s, s′) can in fact be defined using first-order sentences. The situation calculus We first briefly review the situation calculus used for Golog and ConGolog. For more details, see [Reiter, 2001; Lin, 2007]. The language of the situation calculus is a manysorted one with sorts action for actions, situation for situations, and other domain dependent ones. There is a constant S0 of sort situation, and a function do : action × situation→ situation. The foundational axioms say that the set of situations consists exactly of those that can be constructed from S0 using function do(a, s) (we assume that variables in displayed formulas are universally quantified from outside):	algol;artificial intelligence;cognitive robotics;concurrency (computer science);esoteric programming language;first-order predicate;hector levesque;high- and low-level;indeterminacy in concurrent computation;intelligent agent;newman's lemma;nondeterministic algorithm;recursion;robot;sentence (mathematical logic);situation calculus;terminate (software);transitive closure;universal quantification	Fangzhen Lin	2014			computer science;artificial intelligence;first-order logic;algorithm	AI	-12.518041884321821	8.575952371281947	164881
932f31af99715f66999f8609da9f298ca95e2aac	handling incoming beliefs	intelligence artificielle;logique en informatique;apprentissage;informatique et langage	Most logic-based approaches to knowledge and belief change in artificial intelligence assume that when a new piece of information comes up, it should be merely added to the current beliefs or knowledge when this does not lead to inconsistency. This paper addresses situations where this assumption does not hold. The focus is on the construction of Boolean standard-logic knowledge and belief bases in this context. We propose an approach to handle incoming beliefs that can require some formulas reconstruction or a form of preemption to be performed.	artificial intelligence;belief revision;first-order predicate;interaction;literal (mathematical logic);negation as failure;non-monotonic logic;preemption (computing)	Philippe Besnard;Éric Grégoire	2013		10.1007/978-3-642-39787-5_17	computer science;artificial intelligence;operations research;algorithm	AI	-17.222668898903585	6.549700617025025	164925
264ef4a7be23359024ad4eee996910f7b864febc	representing reified relations in loom	equivalence relation;propositional knowledge;knowledge representation;reification	Abstract This paper discusses the semantics and usage of reification as applied to relations and tuples. The reification of a tuple is a proposition object possessing a case role for each domain attribute in the tuple. The reification of a set of fillers of a role is an object sometimes referred to as a ‘roleset’. In the course of defining reification mechanisms for the Loom knowledge representation system, we have unearthed several open issues that come into focus when considering equivalence relations between these kinds of reified objects. Another type of reification produces an individual that represents a view of another individual filling a particular role. We present a number of semantic variations of this reification operation, and argue that the unbridled application of such reification operators has the potential to overwhelm the representation mechanism. We suggest that a regimen that merges various similar but non-equivalent classes of individuals might be preferable to a system that insists o...		Robert M. MacGregor	1993	J. Exp. Theor. Artif. Intell.	10.1080/09528139308953767	knowledge representation and reasoning;reification;computer science;artificial intelligence;reification;descriptive knowledge;equivalence relation;algorithm	AI	-17.120275197170912	7.8995620610529524	165206
19cc9fff36d94625398395db677b60b8ce781193	similarities and differences in the mathematical formalizations of the retinex model and its variants		Edwin H. Land and John J. McCann introduced the Retinex model as a computational theory of color vision. However, they specified the details of Retinex rather algorithmically and not mathematically and this opened the way to a multitude of different interpretations of their model, many times even contradicting ones. The aim of this paper is to present a systematic and self-contained overview about these different interpretations and the corresponding mathematical formalizations in terms of variational principles and partial differential equations.		Edoardo Provenzi	2017		10.1007/978-3-319-56010-6_5	artificial intelligence	Vision	-14.24405298581931	6.538349720595786	165718
751642c435258bf20bceea4bd08d9f0bf975ad18	need to know: questions and the paradox of epistemic obligation	deontic logic;access control policy	Åqvist’s paradox of epistemic obligation can be solved, if we use knowledge-wh instead of knowledge-that in specifications of the ‘need to know’: the knowledge which an agent in a certain organisational role is required to have. Knowledge-wh is knowledge of an answer to a question, which depends on the context. We show how knowledge-wh can be formalised in a logic of questions, which is combined with standard deontic logic to represent epistemic obligations. We demonstrate that under the new interpretation, the paradox can no longer be derived. The resulting logic is useful for representation of access control policies.	access control;deontic logic;need to know	Joris Hulstijn	2008		10.1007/978-3-540-70525-3_11	philosophy;epistemology;knowledge management;deontic logic;linguistics;algorithm	AI	-15.76414030378115	4.47026477163771	166389
88b9d70ee67f40c8c25304d78813fce32b6c4919	a logic for representing grammatical knowledge	grammatical knowledge;knowledge representation;model theory;grammar;logic	Feature structures are partially speciied, record-like structures which are employed in many recent grammar formalisms to represent linguistic objects of various kinds. Building on previous approaches to the logical representation of linguistic knowledge, this paper presents a logical language which is suuciently expressive to allow for the encoding of recursive constraints on feature structures. A particular concern of this paper is to show how formulas of the logic can be used to capture the denotation of a grammar considered as a recursive deenition of a class of linguistic objects. However, the logic may be of interest to researchers working in the area of general knowledge representation.	definite clause grammar;formal system;knowledge representation and reasoning;natural deduction;parsing;recursion;theory;well-formed formula	B. Keller	1992			natural language processing;description logic;multimodal logic;autoepistemic logic	NLP	-17.748891117743625	9.95989186065392	166587
1a254d2ef0558b97740fd1999151a76310ebda01	modelling legal reasoning in a mathematical environment through model-theoretic semantics	max sat;lexicographic semantics;conditional logic;legal reasoning;artificial intelligent;nonmonotonic reasoning;mathematical model;artificial intelligence and law;combinatorial optimization;defeasible reasoning;knowledge base	We introduce a mathematical model of legal reasoning using an underlying conditional logic semantics, to allow its tractability in some special cases. The main idea is to capture the entailment of legal consequences through a model of 0-1 programming. For such task, first we model legal reasoning with Lehmann's Lexicographic semantics and then we translate it to an instance of weighted MAXSAT problem, in order to compute the logical consequences of legal reasoning. Hence, combinatorial optimization algorithms can be used to yield the legal consequences of defeasible reasoning over legal conditional knowledge bases.	algorithm;combinatorial optimization;defeasible reasoning;lexicographical order;mathematical model;mathematical optimization;maximum satisfiability problem;theory	Samuel M. Brasil;Berilhes Borges Garcia	2003		10.1145/1047788.1047833	opportunistic reasoning;legal expert system;case-based reasoning;knowledge base;qualitative reasoning;combinatorial optimization;computer science;artificial intelligence;maximum satisfiability problem;non-monotonic logic;model-based reasoning;machine learning;mathematical model;psychology of reasoning;reasoning system;automated reasoning;deductive reasoning;defeasible reasoning;algorithm	AI	-18.27168016961902	10.291804230195115	166896
6409faf50a35c8ebbb5b1fccae66198c5d4d8947	a method in linguistic reasoning on a knowledge base representing by sentences with linguistic belief degree	knowledge base	In this paper we shall introduce a notion of formal knowledge base consisting of statements associated with linguistic truth degrees and a set of inference rules handling this kind of statements. A deductive reasoning method based on these inference rules will be examined. The logical foundation of this method is linguistic valued logic based on extended hedge algebras and, based on this basis, the consistency of the knowledge base will be considered.	knowledge base	Cat-Ho Nguyen	1996	Fundam. Inform.	10.3233/FI-1996-283403	natural language processing;computer science;artificial intelligence;model-based reasoning;knowledge-based systems;mathematics;algorithm	AI	-17.925304664956734	7.2751243543320445	168067
f40865473c2afb9053c92eb3469868721a04ed80	characterizing equivalence notions for labelling-based semantics	equivalence notions;abstract argumentation	A central question in knowledge representation is the following: given some knowledge representation formalism, is it possible, and if so how, to simplify parts of a knowledge base without affecting its meaning, even in the light of additional information? The term strong equivalence was coined in the literature, i.e. strongly equivalent knowledge bases can be locally replaced by each other in a bigger theory without changing the semantics of the latter. In contrast to classical (monotone) logics where standard and strong equivalence coincide, it is possible to find ordinary but not strongly equivalent objects for any nonmonotonic formalism available in the literature. This paper addresses these questions in the context of abstract argumentation theory. Much effort has been spent to characterize several argumentation tailored equivalence notions w.r.t. extension-based semantics. In recent times labelling-based semantics have received increasing attention, for example in connection with algorithms computing extensions, proof procedures, dialogue games, dynamics in argumentation as well as belief revision in general. Of course, equivalence notions allowing for replacements are of high interest for the mentioned topics. In this paper we provide kernel-based characterization theorems for semantics based on complete labellings as well as admissible labellings w.r.t. eight different equivalence notions including the aforementioned most prominent one, namely strong equivalence.	admissible heuristic;algorithm;argumentation framework;belief revision;black box;embedded system;expect;external ray;graph labeling;input/output;interaction;knowledge base;knowledge representation and reasoning;level of detail;morgan marquis-boire;requirement;semantics (computer science);strong duality;turing completeness;word lists by frequency;monotone	Ringo Baumann	2016			logical equivalence;computer science;algorithm	AI	-15.409784746794216	8.854158545068893	168116
7de0b4c397aab74f9f92317c28799c484fa49ae5	translating preferred subtheories into structured argumentation			theory (mathematical logic)	P. M. Thang;Hien Thu Luong	2014	J. Log. Comput.	10.1093/logcom/ext049	argumentation theory;mathematics;algorithm;natural language processing;artificial intelligence	ECom	-13.601419091742297	9.634180986230986	168334
22df7b90487b0dc188b7849d8582c4bc54d6539d	which semantics for neighbourhood semantics?	satisfiability problem;required bisimulation;alternative proposal;elegant notion;suitable notion;loose neighbourhood semantics;main tool;neighbourhood semantics;simple extension;natural notion;satisfiability;knowledge;belief	In this article we discuss two alternative proposals for neighbourhood semantics (which we call strict and loose neighbourhood semantics, N= and N⊆ respectively) that have been previously introduced in the literature. Our main tools are suitable notions of bisimulation. While an elegant notion of bisimulation exists forN⊆, the required bisimulation for N= is rather involved. We propose a simple extension of N= with a universal modality that we call N=(E), which comes together with a natural notion of bisimulation. We also investigate the complexity of the satisfiability problem for N⊆ and N=(E). 1 Epistemic Logic and Neighbourhood Semantics Epistemic logic, the logic that studies notions like agents’s beliefs and knowledge, is an important and long-standing area of research in artificial intelligence [Fagin et al., 1995]. In epistemic logic, the formula [α]φ is used to represent that agent α believes or knows that φ is the case. When the agent α is understood by context, or when we are not interested on modelling the behaviour of different agents at the same time, we will usually write [ ]φ instead of [α]φ. In the rest of this article we will discuss the case for a single agent. By adding the [ ] operator to classical propositional logic, we can already express a number of interesting properties. For example, the formula [ ](φ ∧ ψ) → ([ ]φ ∧ [ ]ψ) intuitively says that if an agent believes or knows the conjunction of two facts φ and ψ, then it also knows both φ and ψ. Epistemic logic is usually considered a member of the large family of modal logics [Blackburn et al., 2001], and as we will discuss in this article, it shares with them many of their properties (e.g., characterizations in terms of bisimulations, good computational behavior, etc.). But, as it is well known (see [Vardi, 1986]), semantics specified over standard Kripke models in terms of possible worlds and accessibility relations [Blackburn et al., 2001] have some undesired epistemic properties. The reason is that even the weakest logic definable in terms of Kripke models (i.e., the modal logic K defined as ∗Work partially done while Master’s student at Departamento de Computación, FCEyN, UBA, Argentina. the set of those modal formulas valid on the class of all Kripke structures) may be already too strong for modeling knowledge or belief. For example, Kripke semantics makes valid all instances of the formula scheme ([ ]φ ∧ [ ](φ → ψ)) → [ ]ψ and the inference rule |= φ then |= [ ]φ, while both are unintuitive under an epistemic interpretation of [ ]. If we read [ ] as knowledge, they would require an agent to know all tautologies, and to be able to effectively draw all consequences of its knowledge. This is what is called the logical omniscience problem, and it was already discussed in [Hintikka, 1975]. [Vardi, 1986] proposes to adopt a different semantics, originally introduced in [Montague, 1968; 1970] and [Scott, 1968] in a different setup. This alternative semantics uses the notion of neighbourhoods to define the meaning of the epistemic operator. The intuitive idea is that an agent’s knowledge is characterized not by a set of possible worlds but rather by an explicit set of propositions known by the agent. More precisely, we can define epistemic structures as follows. Definition 1 (Epistemic Structure). An epistemic structure is a tupleM = 〈W,N, ‖ · ‖M〉 where • W 6= ∅ is a set (of possible worlds). • N is a function mapping elements from W to sets of subsets of W (i.e., N(w) ⊆ ℘(W ), for each w in W ). We will usually write Nw instead of N(w) and call Nw the neighbourhoods of w. • ‖ · ‖M is an assignment function from the set of propositional symbol to subsets of W (i.e., ‖p‖M ⊆ W , for each propositional symbol p ∈ PROP). 3 Throughout the paper, letM be the model 〈W,N, ‖ · ‖M〉 andM′ be the model 〈W ′, N ′, ‖ · ‖M〉. Notice that, instead of the standard accessibility relation between worlds in a Kripke model, an epistemic structure specifies, for each world w ∈ W , a set of sets Nw. As we can represent a proposition P by a set of possible worlds, the intuition is that if P ∈ Nw then P is known in w. Given a modelM we can extend ‖ · ‖M to all formulas in the language. The boolean cases are standard: ‖¬φ‖M = W\‖φ‖M, ‖φ ∧ ψ‖M = ‖φ‖M ∩ ‖ψ‖M. The [ ] operator, on the other hand, has been defined in two different ways in the literature, giving origin to two different operators that we will note [⊆] and [=]: ‖[=]φ‖M = {w | ∃X ∈ Nw such that X = ‖φ‖M}, ‖[⊆]φ‖M = {w | ∃X ∈ Nw such that X ⊆ ‖φ‖M}. The [=] operator is the most widely used, and it is the one originally introduced in [Vardi, 1986]. We will call this semantics the strict neighbourhood semantics N=, because for [=]φ to be true at w, ‖φ‖M should be one of the neighbourhoods of w, i.e., ‖φ‖M ∈ Nw. The [⊆] operator on the other hand, is slightly weaker. We only require ‖φ‖M to cover at least one of the neighbourhoods of w and not to exactly coincide with it. We will call this weaker semantics the loose neighbourhood semantics N⊆, and it has been mentioned by van Benthem in a number of articles (e.g., [Aiello and van Benthem, 2002]). It is easy to see that the two semantics are indeed different: Example 2. Consider the epistemic structure	accessibility relation;artificial intelligence;bisimulation;boolean algebra;boolean satisfiability problem;computation;epistemic modal logic;fagin's theorem;intelligent agent;karp's 21 np-complete problems;kripke semantics;modality (human–computer interaction);montague grammar;np-completeness;possible world;propositional calculus;propositional variable;semantics (computer science)	Carlos Areces;Diego Figueira	2003				AI	-14.384156619687065	7.562739089924225	168355
c0572a31479024c71f06b820b0f119299e39cd84	coherent integration of databases by abductive logic programming	knowledge bases;semantics;artificial intelligent;consistency model;theoretical analysis;abductive logic programming;constraints;information;querying inconsistent databases	We introduce an abductive method for a coherent integration of independent datasources. The idea is to compute a list of data-facts that should be inserted to the amalgamated database or retracted from it in order to restore its consistency. This method is implemented by an abductive solver, called Asystem, that applies SLDNFA-resolution on a meta-theory that relates different, possibly contradicting, input databases. We also give a pure model-theoretic analysis of the possible ways to ‘recover’ consistent data from an inconsistent database in terms of those models of the database that exhibit as minimal inconsistent information as reasonably possible. This allows us to characterize the ‘recovered databases’ in terms of the ‘preferred’ (i.e., most consistent) models of the theory. The outcome is an abductive-based application that is sound and complete with respect to a corresponding model-based, preferential semantics, and – to the best of our knowledge – is more expressive (thus more general) than any other implementation of coherent integration of databases.	abductive logic programming;abductive reasoning;coherence (physics);coherent;data integrity;deductive database;emoticon;first-order predicate;mathematical optimization;national fund for scientific research;non-monotonic logic;operational semantics;ptc integrity;paraconsistent logic;priest;semantic reasoner;solver;theory	Ofer Arieli;Marc Denecker;Bert Van Nuffelen;Maurice Bruynooghe	2004	J. Artif. Intell. Res.	10.1613/jair.1322	information;computer science;artificial intelligence;theoretical computer science;consistency model;machine learning;data mining;semantics;algorithm;abductive logic programming	DB	-18.3436682117163	8.509276215544325	168428
ae4beaf35503c8f728ec1878bb00c3dfc507866d	qualitative representation of spatio-temporal knowledge		Abstract In this paper we present PCT ( Position-Connection-Time ), a formalism capable of representing spatio-temporal knowledge in a qualitative fashion. This framework achieves an expressive power comparable to other classic spatial relation formalisms describing common topological and directional spatial relations. In addition, PCT introduces new classes of relations based both on the position of the objects and on their interconnections, and incorporates the notion of time within spatial relations in order to describe dynamic contexts. In this way, PCT is also able to model spatial arrangements that change over time, e.g., moving objects.		Giuseppe Della Penna;Sergio Orefice	2018	J. Vis. Lang. Comput.	10.1016/j.jvlc.2018.10.002	expressive power;theoretical computer science;rotation formalisms in three dimensions;formalism (philosophy);spatial relation;computer science	NLP	-16.18742075282611	10.391358147840666	168500
0ce8b02553cfb8ee19e3d33dca717b2d4ed821c9	quantifying disagreement in argument-based reasoning	argumentation;aggregation;belief revision;distance measures;complete labellings	An argumentation framework can be seen as expressing, in an abstract way, the conflicting information of an underlying logical knowledge base. This conflicting information often allows for the presence of more than one possible reasonable position (extension/labelling) which one can take. A relevant question, therefore, is how much these positions differ from each other. In the current paper, we will examine the issue of how to define meaningful measures of distance between the (complete) labellings of a given argumentation framework. We provide concrete distance measures based on argument-wise label difference, as well as based on the notion of critical sets, and examine their properties.	argumentation framework;case-based reasoning;knowledge base	Richard Booth;Martin Caminada;Mikolaj Podlaszewski;Iyad Rahwan	2012			computer science;artificial intelligence;distance measures;belief revision;algorithm	AI	-16.57196439696469	6.744174378334602	168642
62db17c75d2d3df3402955a013be7a8d11edfce4	integration of information in four-valued logics under non-uniform assumptions	logics of knowledge four valued logics integrating information distributed environment central server inconsistency;logic programming;four valued logics;distributed environment;logic programming multivalued logic;integration of heterogeneous information;integrating information;logics of knowledge;logic programs;multivalued logic;inconsistency;central server	We study the problem of integrating information coming from different sources in a distributed environment. We assume a central server that collects facts from sources and tries to combine them using a set of logical rules, i.e. a logic program. We provide a formal framework for the integration of information in such a setting, under non-uniform assumptions on the missing information.	curve fitting;denotational semantics;logic programming;server (computing)	Yann Loyer;Nicolas Spyratos;Daniel Stamate	2000		10.1109/ISMVL.2000.848618	t-norm fuzzy logics;non-classical logic;discrete mathematics;classical logic;description logic;computer science;theoretical computer science;non-monotonic logic;mathematics;programming language;logic programming;accessibility relation;algorithm;distributed computing environment	Theory	-18.703781260165172	7.558249251164565	169098
328412ecba81f4a05516baa3681b4c7cef3b5d6e	listen to me! public announcements to agents that pay attention - or not	action models;intelligence artificielle;logique en informatique;apprentissage;informatique et langage;attention based announcement logic	In public announcement logic it is assumed that all agents pay attention (listen to/observe) to the announcement. Weaker observational conditions can be modelled in event (action) model logic. In this work, we propose a version of public announcement logic wherein it is encoded in the states of the epistemic model which agents pay attention to the announcement. This logic is called attention-based announcement logic, abbreviated ABAL. We give an axiomatization and prove that complexity of satisfiability is the same as that of public announcement logic, and therefore lower than that of action model logic [2]. We exploit our logic to formalize the concept of joint attention that has been widely discussed in the philosophical and cognitive science literature. Finally, we extend our logic by integrating attention change.	axiomatic system;cognitive science	Hans van Ditmarsch;Andreas Herzig;Emiliano Lorini;François Schwarzentruber	2013		10.1007/978-3-642-40948-6_8	psychology;artificial intelligence;social psychology;algorithm	AI	-16.990914030081573	4.44585283133628	169254
35dc67179dc12e0959fa5658ec9f23ba8d00df9f	editorial: logic and games	logic;semantics;philosophy;artificial intelligence			Paul Dekker;Marc Pauly	2002	Journal of Logic, Language and Information	10.1023/A:1015549927830	dynamic logic;description logic;epistemic modal logic;philosophy;epistemology;computer science;artificial intelligence;game semantics;computational logic;semantics;linguistics;symbolic artificial intelligence;automated reasoning;axiomatic semantics;logic;term logic;multimodal logic;algorithm;philosophy of logic;autoepistemic logic	Logic	-13.36540334006121	11.210107406883006	169464
b3d1bcdad169ccb2ac7542ce46d793bb9f6ebca4	reasoning about time in the situation calculus	total order;temporal logic;first order;situation calculus	We extend the ontology of the situation calculus to provide for the representation of time and event occurrences. We do this by defining a time line corresponding to a sequence of situations (calledactual situations) beginning with the initial situation. Actual situations are totally ordered and the actions that lead to different actual situations are said to haveoccurred. This extension to the situation calculus permits one to express truths about the state of the world at different times. For example, we can state that at some point in the future certain fluents will be true. We can also express constraints on the occurrences of events, for example, that after releasing a cup, it will eventually hit the floor. Our version of the situation calculus subsumes other temporal logics. In particular, we show that the modaltemporal logic of concurrency [4] can be embedded in the extended situation calculus. Our extension can also realize the essential features of other first-order proposals for reasoning about time commonly used for AI purposes (e.g. Allen [1], Kowalski and Sergot [6]).	concurrency (computer science);embedded system;first-order predicate;fluent (artificial intelligence);situation calculus;timeline	Javier Pinto;Raymond Reiter	1995	Annals of Mathematics and Artificial Intelligence	10.1007/BF01530822	fluent calculus;process calculus;temporal logic;computer science;artificial intelligence;first-order logic;mathematics;event calculus;situation calculus;total order;algorithm	AI	-16.620012607092843	9.358389815779699	169648
4d70792542257eacce285aa33b19743742192a3c	an algebraic model for implementing expert systems based on the knowledge of different experts	symbolic computing;multivalued logics;groebner bases	The aim of this paper is to expound an original algebraic model for managing the knowledge provided by different expert humans when developing expert systems. This model is conceived as an extension of classical propositional logics in which each proposition is associated with a set of human experts who agree with it. In our model, the logical notions of tautological consequence and consistency of a set of formulae are reformulated taking into account the criteria and the knowledge of the different experts. The core of the paper is related to the discovery of a remarkable relation between these redefined logical concepts with the calculation of Groebner bases on an ideal of polynomials. © 2014 IMACS. Published by Elsevier B.V. All rights reserved.	definition;expert system;gröbner basis;linear algebra;polynomial	Antonio Hernando;Eugenio Roanes-Lozano	2015	Mathematics and Computers in Simulation	10.1016/j.matcom.2014.05.003	discrete mathematics;mathematics;algorithm	AI	-13.997443043492755	9.019948061263173	169938
c6f7ea1ac61e6766e0e0b162841624ca99b7cab7	variations on a montagovian theme	journal article	What are the objects of knowledge, belief, probability, apriority or analyticity? For at least some of these properties, it seems plausible that the objects are sentences, or sentence-like entities. However, results from mathematical logic indicate that sentential properties are subject to severe formal limitations. After surveying these results, I argue that they are more problematic than often assumed, that they can be avoided by taking the objects of the relevant property to be coarse-grained (“sets of worlds”) propositions, and that all this has little to do with the choice between operators and predicates.	entity	Wolfgang Schwarz	2012	Synthese	10.1007/s11229-012-0173-0	philosophy;epistemology;mathematics;algorithm	DB	-13.460131629477258	4.502853777833639	169967
9ad15e7d394425805a3e1078da73de00d205cc57	probabilistic quantifier logic for general intelligence: an indefinite probabilities approach	general intelligence;inference rule;natural language;probabilistic logic	Indefinite probabilities are a novel technique for quantifying uncertainty, which were created as part of the PLN (Probabilistic Logic Networks) logical inference engine, which is a key component of the Novamente Cognition Engine (NCE), an integrative AGI system. Previous papers have discussed the use of indefinite probabilities in the context of a variety of logical inference rules, but have omitted discussion of quantification. Here this gap is filled, and a mathematical procedure is provided allowing the propagation of indefinite probabilities through universal and existential quantifiers, and also through a variety of fuzzy quantifiers corresponding to natural language quantifiers (such as “few”, “man”, “a lot”, “hardly any”, etc.). Proper probabilistic handling of various quantifier transformation rules is also discussed. Together with the ideas in prior publications, and a forthcoming sequel paper on indefinite probabilities for intensional inference, these results allow probabilistic logic based on indefinite probabilities to be utilized for the full scope of inferences involved in intelligent reasoning. To illustrate the ideas and algorithms involved, we give two concrete examples: Halpern’s “crooked lottery” predicate, and a commonsense syllogism that uses fuzzy quantifiers together with the standard PLN term logic deduction rule.	algorithm;artificial intelligence;bottleneck (engineering);cognition;computer;control system;inference engine;intensional logic;lottery scheduling;natural deduction;natural language;natural language understanding;power-line communication;probabilistic logic network;quantifier (logic);software propagation;universal quantification	Matthew Iklé;Ben Goertzel	2008			computer science;artificial intelligence;machine learning;g factor;probabilistic logic;natural language;probabilistic logic network;algorithm;rule of inference	AI	-14.488495278658752	9.686870440231234	170131
71af7424a40880a5313f39f6cc70e460414bf8cb	finding admissible and preferred arguments can be very hard	nonmonotonic reasoning	Bondarenkoet al. have recently proposed an extension of the argumentation-theoretic semantics ofadmissibleandpreferred arguments , originally proposed for logic programming only, to a number of other nonmonotonic reasoning formalisms. In this paper we analyse the computational complexity ofcredulousand sceptical reasoning under the semantics of admissible and preferred arguments for (the propositional variant of) some well-known frameworks for nonmonotonic reasoning, i.e. Theorist, Circumscription and Autoepistemic Logic. While the new semantics have been assumed to mitigate the computational problems of nonmonotonic reasoning under the standard semantics of stable extensions, we show that in many cases reasoning under the new semantics is computationally harder than under the standard semantics. In particular, for Autoepistemic Logic, the sceptical reasoning problem under the semantics of preferred arguments is located at the fourth level of the polynomial hierarchy, two levels above the same problem under the standard semantics. In some cases, however, reasoning under the new semantics becomes easier – reducing to reasoning in the monotonic logics underlying the nonmonotonic frameworks.	admissible heuristic;autoepistemic logic;circumscription (logic);computational complexity theory;computational logic;computational problem;default logic;logic programming;non-monotonic logic;polynomial hierarchy;qp state machine frameworks	Yannis Dimopoulos;Bernhard Nebel;Francesca Toni	2000			deductive reasoning;algorithm;polynomial hierarchy;computer science;logic programming;non-monotonic logic;circumscription;semantics;reasoning system;autoepistemic logic	AI	-16.170233521290097	7.691998452192616	170229
42dad12b7c6161a8e9986d1c445f2857bb46d297	optimality theory through default logic.	linguistique;sistema experto;conflict;language theory;base connaissance;lenguaje especializado;intelligence artificielle;teoria lenguaje;logica defecto;specification language;hierarchical classification;linguistica;natural language;conflicto;classification hierarchique;artificial intelligence;base conocimiento;lenguaje especificacion;logique defaut;inteligencia artificial;systeme expert;langage specialise;conflit;optimality theory;default logic;special purpose language;langage specification;clasificacion jerarquizada;theorie langage;knowledge base;expert system;linguistics	Optimality Theory is an approach to linguistic problems which is based on rules with exceptions, resorting to a ranking among rules to resolve conflicts arising from competing rules. In such a way, dealing with linguistic problems amounts to applying rules with exceptions: That is reasoning. A related issue is then about a formalization of the logic at work. An immediate candidate is Default Logic which is dedicated to reasoning from rules with exceptions. Moreover, there are versions of default logic with priorities. We show that Default Logic is well-suited as a specification language capturing Optimality Theory and suggests that implementations of default logic can be applied to run experiments with grammatical interaction in the sense of Optimality Theory and beyond.	default logic;exception handling;experiment;specification language	Philippe Besnard;Robert E. Mercer;Torsten Schaub	2002		10.1007/978-3-540-39451-8_8	natural language processing;knowledge base;specification language;computer science;artificial intelligence;philosophy of language;non-monotonic logic;natural language;default logic;expert system;algorithm	AI	-18.432595666119227	10.599435124936845	170690
2241aba7d2398abd20c07a153361c834be31b027	taxonomic linear theories	nonmonotonic logic;semantic network;knowledge representation;default logic;linear logic	"""A semantic network is a structure for representing knowledge as a pattern of interconnected nodes and edges. This paper focuses on the means linear logic offers to represent these networks. In order to compare our inferences, we have chosen one nonmonotonic logic: default logic [9] serves as a reference. The main result proves the equivalence between linear logic and default logic in taxonomic default theories. We hope this will help to better understand the relations between nonmonotonicity and defeasible knowledge representation. 1 I n t r o d u c t i o n A semantic network is a structure for representing knowledge as a pattern of interconnected nodes and edges. The nodes represent concepts or properties of a set of individuals whereas the edges represent relations between concepts. The network can be viewed as a hierarchy of concepts according to levels of generality. A more specific concept is said to inherit properties from its subsumers. The formalisation of human reasoning requires that some kinds of uncertain knowledge be represented in semantic networks as default edges: for example, we expect the concept of bird to be more specific than the concept of flying object, even if some species cannot fly. Generally speaking, we consider networks with default and exception edges, dealing respectively with defeasible and exceptional knowledge. Nonmonotonic logics (see [2] for example) were developed in the last decade in order to represent defaults and exceptions in a logical way: the set of inferred grounded facts is the set of properties inherited by concepts. In this paper, we investigate the problem of formalising inheritance in semantic networks with default and exception links in a standard logic, namely linear logic ; this research was undertaken after a short paper by Girard [6]. In nonmonotonic logics, if T and S are two sets of formulae it is not necessarily true that the set of theorems of TUS is included in the set of theorems of T; in other words, if A,B, C are three formulae, """"C is provable from A"""", doesn't necessarily lead to """"C is provable from A and B"""". Of course, linear logic is monotonic; however, its linear implication behaves non-monotonically with respect to the """"times"""" connective so, although the sequent A ~-C is provable in linear logic the sequent A """"times"""" B ~-C is not necessarily provable in linear logic. Linear logic is therefore able to formalise problems which have so far been handled using nonmonotonic logics. In what follows, only semantic networks with default and exception links are considered. An exception is a direct inhibition of a concept: an exception link between A and B means that A is not a B (or A does not have the property B) whatever the"""	default logic;defeasible reasoning;description logic;knowledge representation and reasoning;linear logic;logical connective;non-monotonic logic;provable security;semantic network;the times;turing completeness	Christophe Fouqueré;Jacqueline Vauzeilles	1993		10.1007/BFb0028191	predicate logic;dynamic logic;zeroth-order logic;knowledge representation and reasoning;linear logic;discrete mathematics;linear temporal logic;description logic;higher-order logic;paraconsistent logic;many-valued logic;computer science;intermediate logic;artificial intelligence;non-monotonic logic;predicate functor logic;machine learning;computational logic;mathematics;semantic network;default logic;substructural logic;multimodal logic;algorithm;philosophy of logic;autoepistemic logic	AI	-14.585518863359319	8.477268341262034	170735
292d994eedea9a78b7205e385da3a8adb0540478	situationist deontic logic	norm;obligation;semantics;filosofi;satisfiability;logique deontique;semantique;deontic logic;situationnisme;situationism;philosophy;preference;norme	Situationist deontic logic is a model of that fraction of normative discourse which refers to only one situation and one set of alternatives. As we can see from a whole series of well-known paradoxes, standard deontic logic (SDL) is seriously mistaken even at the situationist level. In this paper it is shown how a more realistic deontic logic can be based on the assumption that prescriptive predicates satisfy the property of contranegativity. A satisfactory account of situation-specific norms is a necessary prerequisite for a successful treatment of more complex normative structures.	deontic logic	Sven Ove Hansson	1997	J. Philosophical Logic	10.1023/A:1004233913104	situationism;philosophy;artificial intelligence;deontic logic;mathematics;semantics;linguistics;algorithm;norm;satisfiability	Logic	-14.177213150628422	4.521720598776979	170831
0778144139e1ec395a84fb05221abfab18b39600	a local approach to reasoning under incosistency in stratified knowledge bases	knowledge base	"""This paper investigates an approach for reasoning under inconsistency in a """"local"""" way, in priodtized knowledge bases. In such bases, the higher the layer, the more certain, the more reliable are the formulas stored in this layer, The proposed approach is based on the notion of (consistent) argument whose strength depends on the layer of the least certain formulas involved in the argument. Each formula in the base is also associated with a """"level of paraconsistency"""" which reflect to what extent there exists arguments that support both a formula and its negation. Three consequence relations are presented and compared. Two of them aim at maximizing the certainty degree and/or at minimizing the level of paraconsistency of the conclusion. The third one produces consequences that are safely supported in the sense that there exists an undefeated argument for them (whose certainty is greater than its paraconsistency)."""	knowledge base;paraconsistent logic	Salem Benferhat;Didier Dubois;Henri Prade	1995		10.1007/3-540-60112-0_5	knowledge base;computer science;knowledge management;artificial intelligence;machine learning;data mining	AI	-16.975438558967884	7.109275521756805	171377
3e80f22ca4836d2431427d37f161524789affa68	optimal regression for reasoning about knowledge and actions	propositional case;common knowledge;optimal regression algorithm;frame problem.;. reasoning about actions and change;multiple agent;frame problem;observation action;reasoning about knowl- edge;situation calculus;optimal decision procedure;assignment operator;modal operator;dynamic epistemic logic	We show how in the propositional case both Reiter’s and Scherl & Levesque’s solutions to the frame problem can be modelled in dynamic epistemic logic (DEL), and provide an optimal regression algorithm for the latter. Our method is as follows: we extend Reiter’s framework by integrating observation actions and modal operators of knowledge, and encode the resulting formalism in DEL with announcement and assignment operators. By extending Lutz’ recent satisfiability-preserving reduction to our logic, we establish optimal decision procedures for both Reiter’s and Scherl & Levesque’s approaches: satisfiability is NP-complete for one agent, PSPACE-complete for multiple agents and EXPTIMEcomplete when common knowledge is involved.	algorithm;burstein–moss effect;cognition;compiler;decision problem;dynamic epistemic logic;encode;epistemic modal logic;frame problem;hector levesque;modal operator;np-completeness;nondeterministic finite automaton;ontic;pspace;pspace-complete;polynomial;polynomial-time reduction;sayre's paradox;semantics (computer science);situation calculus;time complexity	Hans van Ditmarsch;Andreas Herzig;Tiago De Lima	2007			artificial intelligence;machine learning;algorithm	AI	-16.575144727852866	9.04153185634012	171495
00bc917448e8d12696c64fb95e9c00c4334bc108	note on the scope of truth-functional logic	truth;naturel;coincidence;regle;fonction;conditional;logics;langage;negation;natural;verite;validite;function;conditionnel;premisse;validity;connexion;natural language;contre partie;premise;language;paraphrase;rule;logique;conclusion	A plausible and popular rule governing the scope of truth-functional logic is shown to be indequate. The argument appeals to the existence of truth-functional paraphrases which are logically independent of their natural language counterparts. A more adequate rule is proposed.		David Sherry	1999	J. Philosophical Logic	10.1023/A:1004367312707	natural;philosophy;epistemology;negation;mathematics;linguistics;language;natural language;function;algorithm;validity	Logic	-13.219130201221862	6.423251556573399	171774
3fb436c9cc482ad69521a6ece9c6637291e3cbf7	a formal bi-logic framework for the mental processes		This paper addresses questions of the transition related to conscious processes and unconscious processes, namely aims to substantiating a primary framework to the following open question: The vast majority of brain activity is non-conscious. What is the criterion to distinguish the non-conscious activities from conscious ones? To support our answers in a principled way, we present a general framework for the study of mental processes resting on two main principles: firstly, we endorse Matte Blanco’s principle of symmetry by giving central stage to the concept of unconscious processes. Secondly, to structure and combine the notions of infinity and partwhole equivalence in a mathematical logic method, moreover we base our work on modern non-classical logics in the disposition of context-dependency, as forcefully put forward by CJS Clarke. In particular, we employ the paraconsistent logic as the underlying logical system for defining the general framework for mental processes, highly structural and formal representation, called bi-logic framework.	edmund m. clarke;electroencephalography;formal system;lambda calculus;matte display;paraconsistent logic;turing completeness	Tzu-Keng Fu	2012			artificial intelligence;computer science;mathematical logic;unconscious mind;natural language processing;equivalence (measure theory);infinity;disposition;paraconsistent logic	Logic	-13.633066303836529	5.046346604955907	171824
d8289cc8cd75a2c29e6de07715891074a0904746	constructive knowledge: what agents can achieve under imperfect information	strategic ability;imperfect information;model checking;epistemic logic;alternating time temporal logic	We propose a non-standard interpretation of Alternating-t ime Temporal Logic with imperfect information, for which no commonly accepted sema ntics has been proposed yet. Rather than changing the semantic structures, we generaliz the usual interpretation of formulae insinglestates tosetsof states. We also propose a new epistemic operator for “prac tical” or “constructive” knowledge, and we show that the new lo gic (which we call Constructive Strategic Logic) is strictly more expressive than most exis ting solutions, while it retains the same model checking complexity. Finally, we study properties of constructive knowledge and other operators in this non-standard semantics.	model checking;temporal logic	Wojciech Jamroga;Thomas Ågotnes	2007	Journal of Applied Non-Classical Logics	10.3166/jancl.17.423-475	model checking;discrete mathematics;linear temporal logic;description logic;higher-order logic;epistemic modal logic;intuitionistic logic;computer science;artificial intelligence;perfect information;mathematics;multimodal logic;algorithm;temporal logic of actions	AI	-16.228920708838455	8.587296889238393	172363
1fd3423d2ac2eb51f3363910e412e677fbcdd2a5	dynamics of inductive inference in a unified framework	learning;case base reasoning;uni ed framework;analogies;bayesian updating;rule based;bayesian reasoning;probabilistic model;induction;dynamics;theories;inductive inference;case based reasoning;weight change;inference;data generation process;rule based reasoning	We present a model of inductive inference that includes, as special cases, Bayesian reasoning, case-based reasoning, and rulebased reasoning. This unified framework allows us to examine how the various modes of inductive inference can be combined and how their relative weights change endogenously. For example, we establish conditions under which an agent who does not know the structure of the data generating process will decrease, over the course of her reasoning, the weight of credence put on Bayesian vs. non-Bayesian reasoning. We illustrate circumstances under which probabilistic models are used until an unexpected outcome occurs, whereupon the agent resorts to more basic reasoning techniques, such as case-based and rule-based reasoning, until enough data are gathered to formulate a new probabilistic model. We thank Daron Acemoglu, Dirk Bergemann, Eddie Dekel, Drew Fudernberg, Gabi Gayer, Offer Lieberman, George Mailath, an associate editor, and two referees for comments and suggestions. Tel-Aviv University, HEC, Paris, and Cowles Foundation, Yale University. ISF Grant 396/10 and ERC Grant 269754 are gratefully acknowledged. Department of Economics, Yale University. National Science Foundation grant SES0850263 is gratefully acknowledged. Tel-Aviv University, The Ohio State University, and the InterDisciplinary Center in Herzliya. ISF Grant 396/10 is gratefully acknowledged. Dynamics of Inductive Inference in a Unified Framework Itzhak Gilboa, Larry Samuelson, David Schmeidler May 22, 2012	bayesian network;crc-based framing;case-based reasoning;eddie (text editor);gabi software;inductive reasoning;logic programming;pamela samuelson;statistical model;unified framework	Itzhak Gilboa;Larry Samuelson;David Schmeidler	2013	J. Economic Theory	10.1016/j.jet.2012.11.004	rule-based system;opportunistic reasoning;abductive reasoning;qualitative reasoning;transduction;adaptive reasoning;inductive reasoning;model-based reasoning;data mining;psychology of reasoning;reasoning system;deductive reasoning;bayesian inference	AI	-18.179306814792056	9.212093672798572	172418
1ef3c6f0f701a9e00c4c9f0ec09cc33356f3f55f	merging without mystery or: variables in dynamics semantics	referent;nom;name;dynamique;theorie de la representation du discours;semantics;semantique;value;reference systems;dynamics;wijsbegeerte;formal system;dynamique de la logique predicative;valeur;systeme formel;variable	In this paper we discuss the treatment of variables in dynamic seman tics Referent systems are introduced as a exible mechanism for working with variables In a referent system we carefully distinguish the variables themselves both from the machinery by which we manipulate them their names and from the information that we store in them their values It is shown that the referent systems provide a natural basis for dynamic semantics The semantics with referent systems is compared with the familiar formalisms in dynamic semantics DRT and DPL Introduction to Dynamic Semantics	denotational semantics;privilege level;programming language;variable (computer science)	C. F. M. Vermeulen	1995	J. Philosophical Logic	10.1007/BF01048354	philosophy;variable;mathematics;semantics;linguistics;algorithm	AI	-17.360437764525166	10.435256516983584	172586
ad900f5ae1a84ea06f4125451a07c92d9fefb4d3	preference logic grammars: fixed point semantics and application to data standardization	default reasoning;fixed point;xsb;well founded semantics;logic programming;reasoning with preferences;data extraction;non monotonic reasoning;logic programs;natural language processing	The addition of preferences to normal logic programs is a convenient way to represent many aspects of default reasoning. If the derivation of an atom A1 is preferred to that of an atom A2, a preference rule can be defined so that A2 is derived only if A1 is not. Although such situations can be modelled directly using default negation, it is often easier to define preference rules than it is to add negation to the bodies of rules. As first noted in [6], for certain grammars, it may be easier to disambiguate parses using preferences than by enforcing disambiguation in the grammar rules themselves. In this paper we define a general fixed-point semantics for preference logic programs based on an embedding into the well-founded semantics, and discuss its features and relation to previous preference logic semantics. We then study how preference logic grammars are used in data standardization, the commercially important process of extracting useful information from poorly structured textual data. This process includes correcting misspellings and truncations that occur in data, extraction of relevant information via parsing, and correcting inconsistencies in the extracted information. The declarativity of Prolog offers natural advantages for data standardization, and a commercial standardizer has been implemented using Prolog. However, we show that the use of preference logic grammars allow construction of a much more powerful and declarative commercial standardizer, and discuss in detail how the use of the non-monotonic construct of preferences leads to improved commercial software.  2002 Published by Elsevier Science B.V. ✩ A preliminary version of this article appeared in Proceedings of the 1999 International Conference on Logic Programming and Non-Monotonic Reasoning, by Baoqiu Cui, Terrance Swift and David S. Warren. This paper does not reflect the official positions of the US Defense Logistics Agency or the US Customs Service. * Corresponding author. E-mail addresses: bcui@us.ibm.com (B. Cui), tswift@cs.sunysb.edu (T. Swift). 1 The work presented here was largely done while the author was affiliated with the Computer Science Department, SUNY at Stony Brook. 0004-3702/02/$ – see front matter  2002 Published by Elsevier Science B.V. PII: S0004-3702(02) 00 18 56	atom;brookgpu;commercial software;computer science;default logic;fixed point (mathematics);international conference on logic programming;logistics;non-monotonic logic;parsing;personally identifiable information;prolog;rule 184;swift (programming language);text corpus;truncation;warren abstract machine;well-founded semantics;whole earth 'lectronic link;word-sense disambiguation	Baoqiu Cui;Theresa Swift	2002	Artif. Intell.	10.1016/S0004-3702(02)00185-6	higher-order logic;stable model semantics;computer science;artificial intelligence;non-monotonic logic;data mining;fixed point;programming language;well-founded semantics;default logic;logic programming;multimodal logic;algorithm	AI	-15.671799645235224	11.041025856806478	172688
041463c4a4ac053e0896c9d2fbc0806fb1c5dade	california semantics meets the great fact	lenguaje natural;logique mathematique;langage naturel;logica matematica;mathematical logic;natural language;analisis semantico;analyse semantique;semantic analysis			Steven J. Wagner	1986	Notre Dame Journal of Formal Logic	10.1305/ndjfl/1093636684	natural language processing;mathematical logic;computer science;mathematics;linguistics;natural language;algorithm	Theory	-18.61573991794367	11.144307419696572	172869
5009c3af7c4c20ea70045a26275f961f99e85ecf	a semantic without syntax 1		Here, by introducing a version of “Unexpected hanging paradox” we try to open a new way and a new explanation for paradoxes, similar to liar paradox. Also, we will show that we have a semantic situation which no syntactical logical system could support that. In the end, we propose a claim as a question. Based on this claim, having an axiomatic system for computability theory is not possible. In fact we will show that the method applied here could yields us as a generalized result, some Theories like Physic is not axiomatizable.	axiomatic system;computability theory;formal system	Farzad Didehvar	2012	CoRR		computer science;artificial intelligence;mathematics;algorithm	NLP	-13.482689648494889	6.37110521191214	173123
c055c96e0623bfe9199b87b1114036c689e57e25	another view of autoepistemic logic and truth maintenance system	nonmonotonic reasoning;stable set;knowledge representation	In this paper, we present a novel Autoepistemic Logic (NAE) that subsumes both Moore's original Autoepsteimc logic (AE) and Konolige's stronger extensions. The semantics of the logic is characterized by a combination of AE extensions and minimum stable theories. Although the logic is still based on fixpoints, it always has a NAE extension for any AE theory. Unlike Konolige's strongly-grounded AE extension, strongly-grounded NAE extension is syntax-independent and always exists. In particular, it is shown that strongly-grounded NAE can provide a complete semantics to Truth Maintenance System (TMS) because NAE can additionally account for backtracking routines in TMS. In contrast, strongly-grounded AE can only capture the semantical aspect of TMS that is free of backtracking.		Y. J. Jiang	1991		10.1007/3-540-54563-8_115	knowledge representation and reasoning;stable model semantics;computer science;artificial intelligence;non-monotonic logic;data mining;algorithm;autoepistemic logic	AI	-16.513493904133828	9.713047564215797	173496
0b78864e263dc3470f6a340c0ea64168ee80e6b2	an analysis of knowledge representation schemes for high level vision	object recognition;artificial intelligent;propositional logic;classical logic;knowledge representation	"""1 I N T R O D U C T I O N Although progress is being made in high level vision (HLV) on many different fronts, it is becoming apparent that some foundations must be established to provide coherence for the different research areas. Currently, it is difficult to compare different systems, even if they attempt to solve the same problem. Such systems use a large number of widely divergent knowledge representation schemes, which include constraints (algebraic, geometric, symbolic), graphs, logics, rules and neural nets; they also require different inputs (e.g. edges, orientations, etc.) and produce different outputs. What is needed is: (1) a metric for judging the efficiency of the different techniques; and (2) a means of testing and guaranteeing the completeness and correctness of the systems (e.g. to determine if all correct interpretations are identified). A logical framework for depiction and image interpretation has recently been introduced """"as a foundation for the specification, design and implementation of vision"""" systems [10]. This framework ensures correctness with respect to task and algorithm levels, and, in conjunction with the criteria proposed by Mackworth [4], is a means of system specification at least as good as any other KR language. This paper analyses the criteria necessary for an implementation language, criteria which have not been analysed as closely in vision as in artificial intelligence (AI). In addition to the criteria of [4], we assume polynomial-time algorithms to be a necessary criterion, since scene understanding must almost always done quickly. In exarnining the criteria necessary for a HLV KR language, we study logic in particular, for several reasons: (1) logic is the most important AI KR language; (2 ) the isomorphism between diagnostic reasoning (a sub-field within AI) and HLV ([10], [9]) suggests that the tools (specifically logic) used for diagnostic reasoning can be used for HLV as well; and (3) it is important to know whether logic is suitable not just for specification but also for implementation of HLV systems."""	algorithm;artificial intelligence;artificial neural network;constraint (mathematics);correctness (computer science);eisenstein's criterion;graph (discrete mathematics);high-level programming language;knowledge representation and reasoning;linear algebra;logical framework;object language;time complexity	Gregory M. Provan	1990		10.1007/BFb0014903	dynamic logic;natural language processing;knowledge representation and reasoning;classical logic;description logic;interval temporal logic;computer science;cognitive neuroscience of visual object recognition;machine learning;computational logic;mathematics;propositional calculus;multimodal logic;algorithm;autoepistemic logic	AI	-17.994373169026858	9.460163827081738	173600
6b721b63b3620157b8b9fd1933bf70f681f04f4c	the intensional many - conservativity reclaimed	humanidades;filosofia etica	Following on Westerstahl’s argument that many is not Conservative [9], I propose an intensional account of Conservativity as well as intensional versions of EXT and Isomorphism closure. I show that an intensional reading of many can easily possess all three of these, and provide a formal statement and proof that they are indeed proper intensionalizations. It is then discussed to what extent these intensionalized properties apply to various existing readings of many.		Harald Bastiaanse	2014	J. Philosophical Logic	10.1007/s10992-013-9301-7	philosophy;epistemology;pure mathematics;mathematics;intensional logic;algorithm	Theory	-12.371890422405784	5.218634320502859	174020
ed874d3f0b202e0103b269f702a9152027a44af4	a note concerning the paradoxes of strict implication and lewis's system s1		It has been shown by Lewis and Langford that the postulate B8, is not deducible in SI. From this it follows that neither are the paradoxes of strict implication deducible in that system. However, the following weaker—but perhaps philosophically equally important—analogues are deducible:	strict conditional	Soren Hallden	1948	J. Symb. Log.		calculus;algorithm	Logic	-12.399229783718837	4.505799394246542	174049
38471e80094a4dbdf17ca60d8ee84010cd86d808	the semantics of induction and the possibility of complete systems of inductive inference	inductive inference	Abstract   The semantics of inductive inference is treated from the hypothetico-deductive point of view. It is shown that, in the language of first-order predicate calculus for example, inductive inference systems can be designed with the property of relative completeness, i.e., relative to a set of sentences (the body of evidence) and to the level of deductive power available to the system.	inductive reasoning	B. Meltzer	1970	Artif. Intell.	10.1016/0004-3702(70)90006-8	natural language processing;discrete mathematics;inductive bias;computer science;inductive reasoning;inductive probability;mathematics;algorithm	AI	-13.077887394114734	8.451186688036154	175896
8990b7af4a2fde0246a541b7770ed9298d1b8f27	declarative statistical modeling with datalog		Formalisms for specifying general statistical models, such as probabilistic-programming languages, typically consist of two components: a specification of a stochastic process (the prior), and a specification of observations that restrict the probability space to a conditional subspace (the posterior). Use cases of such formalisms include the development of algorithms in machine learning and artificial intelligence. We propose and investigate a declarative framework for specifying statistical models on top of a database, through an appropriate extension of Datalog. By virtue of extending Datalog, our framework offers a natural integration with the database, and has a robust declarative semantics (that is, semantic independence from the algorithmic evaluation of rules, and semantic invariance under logical program transformations). Our proposed Datalog extension provides convenient mechanisms to include common numerical probability functions; in particular, conclusions of rules may contain values drawn from such functions. The semantics of a program is a probability distribution over the possible outcomes of the input database with respect to the program; these possible outcomes are minimal solutions with respect to a related program that involves existentially quantified variables in conclusions. Observations are naturally incorporated by means of integrity constraints over the extensional and intensional relations. We focus on programs that use discrete numerical distributions, but even then the space of possible outcomes may be uncountable (as a solution can be infinite). We define a probability measure over possible outcomes by applying the known concept of cylinder sets to a probabilistic chase procedure. We show that the resulting semantics is robust under different chases. We also identify conditions guaranteeing that all possible outcomes are finite (and then the probability space is discrete). We argue that the framework we propose retains the purely declarative nature of Datalog, and allows for natural specifications of statistical models.	algorithm;artificial intelligence;cylinder seal;data integrity;datalog;declarative programming;existential quantification;intensional logic;machine learning;numerical analysis;program transformation;programming language;statistical model;stochastic process	Vince Bárány;Balder ten Cate;Benny Kimelfeld;Dan Olteanu;Zografoula Vagena	2014	CoRR		theoretical computer science;data mining;database;datalog;programming language;algorithm	DB	-16.96484349528386	9.395013059132424	175922
0cee926a42fa029db83e30b3f11fc9981343bf1a	temporal qualitative coalitional games	coalitional games;logic;complete axiomatization;satisfiability;repeated game;expressive power;repeated games;solution concept	Qualitative Coalitional Games (QCGs) are a version of coalitional games in which an agent's desires are represented as goals which are either satisfied or unsatisfied, and each choice available to a coalition is a set of goals, which would be jointly satisfied if the coalition made that choice. A coalition in a QCG will typically form in order to bring about a set of goals that will satisfy all members of the coalition. In this paper, we introduce and study Temporal QCGs (TQCGs), i.e., games in which a sequence of QCGs is played. In order to represent and reason about such games, we introduce a linear time temporal logic of QCGs, known as £ (TQCG). We give a complete axiomatization of £ (TQCG), use it to investigate the properties of TQCGs in a small example, identify its expressive power, establish its complexity, characterise classes of TQGCs with formulas from our logical language, and formulate several (temporal) solution concepts for TQCGs.	axiomatic system;linear temporal logic;liverpool;modal logic;natural language;occam's razor	Thomas Ågotnes;Wiebe van der Hoek;Michael Wooldridge	2006		10.1145/1160633.1160662	repeated game;algorithm	AI	-16.628385187534228	8.493044462162926	176099
8ed68fa7d1c19f204889e223745caf39bbd73468	definability and commonsense reasoning	teoria demonstracion;regle inference;commonsense reasoning;theorie preuve;logical framework;proof theory;nonmonotonic logic;auto reference;language theory;axiomatic;circonscription;epistemologie;self reference;semantics;definability;punto fijo;logique propositionnelle;theorie modeles;intelligence artificielle;teoria lenguaje;raisonnement;semantica;semantique;circumscription;fixed point equation;logica defecto;fixed point;inference rule;axiomatico;modal logic;theorie equationnelle;nonmonotonic reasoning;propositional logic;logic of provability;point fixe;logique ordre 1;logique modale;razonamiento;epistemology;logica modal;artificial intelligence;logique defaut;inteligencia artificial;logica proposicional;reasoning;epistemologia;axiomatique;default logic;teoria modelos;lenguaje formal;fix point;equational theory;fixed points;definissabilite;first order logic;theorie langage;formal language;regla inferencia;circonscripcion;model theory;logica orden 1;contextual reasoning;teoria ecuacional;langage formel	The deenition of concepts is a central problem in commonsense reasoning. Many themes in nonmonotonic reasoning concern implicit and explicit deenability. Implicit deenability in nonmonotonic logic is always relative to the context-the current theory of the world. We show that xed point equations provide a generalization of explicit deenability, which correctly captures the relativized context. Theories expressed within this logical framework provide implicit deenitions of concepts. Moreover, it is possible to derive these xed points entirely within the logic.	commonsense reasoning;logical framework;non-monotonic logic	Gianni Amati;Luigia Carlucci Aiello;Fiora Pirri	1997	Artif. Intell.	10.1016/S0004-3702(96)00049-5	discrete mathematics;commonsense reasoning;computer science;artificial intelligence;non-monotonic logic;mathematics;semantics;fixed point;algorithm	AI	-13.824539431689024	9.857457871092691	176119
0d90c66b9109b521983d377669df9a7f8774d2d6	integrating classical and intuitionistic type theory	formalization;logique mathematique;logica matematica;mathematical logic;intuitionist logic;type theory;logique intuitionniste;formalizacion;formalisation;logica intuicionista	Developpement du0027un cadre conceptuel simple prolongeant les mathematiques classiques et englobant certains traits des mathematiques intuitionnistes	intuitionistic type theory	Robert C. Flagg	1986	Ann. Pure Appl. Logic	10.1016/0168-0072(86)90042-4	mathematical logic;discrete mathematics;intuitionistic logic;mathematics;programming language;type theory;algorithm	Logic	-12.781984674791792	10.519919603386004	176796
b3dc63fe3ff1fb597d6a5e5581fbd735dcf4a375	prosum-prolog system for uncertainty management		In this paper we present a system which uses knowledge represented in the form of production rules accompanied by uncertainty degrees. The uncertainty of a rule is given by using the method from SLOP and FRIL: a support pair, which comprises a necessary and possible support and can be interpreted as an interval in which the unknown probability lies. Giving the knowledge in this form, our system generates a Turbo Prolog program which has included the operations for uncertainty management. In this version, two kinds of rules for support logic programming are implemented but the user can propose the other ones, by using the dialogue with the system. Semantic unification differs from that used in FRIL; we use generalized belief functions.	prolog;uncertainty quantification	Ion Iancu	1997	Int. J. Intell. Syst.	10.1002/(SICI)1098-111X(199709)12:9%3C615::AID-INT1%3E3.0.CO;2-M	fuzzy logic;knowledge base;symbolic computation;uncertainty;computer science;artificial intelligence;machine learning;mathematics;prolog;expert system;algorithm	DB	-18.04748684465762	7.199814838288961	177373
fcc393fef9c13124e37de8b1cbc38b4a448c5321	building epistemic logic from observations and public announcements		We study an epistemic logic where knowledge is built from what the agents observe (including higher-order visibility) and what the agents learn from public announcements. This fixes two main drawbacks of previous observability-based approaches where who sees what is common knowledge and where the epistemic operators distribute over disjunction. The latter forbids the modeling of most of the classical epistemic problems, starting with the muddy children puzzle. We integrate a dynamic dimension where both facts of the world and the agents’ observability can be modified by assignment programs. We establish that the model checking problem is PSPACE-complete.	axiomatic system;boolean satisfiability problem;dynamic epistemic logic;epistemic modal logic;kleene star;model checking;multimodal interaction;multimodal logic;pspace;pspace-complete;password;s5 (modal logic)	Tristan Charrier;Andreas Herzig;Emiliano Lorini;Faustine Maffre;François Schwarzentruber	2016			model checking;operator (computer programming);epistemic possibility;algorithm;observability;computer science;common knowledge;dynamic epistemic logic;artificial intelligence;epistemic modal logic	AI	-17.49784709247873	4.7857700224397135	177390
8656993e9abe4c47d01a2cbd79e244fa96c9cade	exploiting functional dependencies in qualitative probabilistic reasoning	functional dependency;probabilistic reasoning	Functional dependencies restrict the potential interactions among variables connected in a probabilistic network. This restriction can be exploited in qualitative probabilistic reasoning by introducing deterministic variables and modifying the inference rules to produce stronger conclusions in the presence of functional relations. I describe how to accomplish these modifications in qualitative probabilistic networks by exhibiting the update procedures for graphical transformations involving probabilistic and deterministic variables and combinations. A simple example demonstrates that the augmented scheme can reduce qualitative ambiguity that would arise without the special treatment of functional dependency. Analysis of qualitative synergy reveals that new higher-order relations are required to reason effectively about synergistic interactions among deterministic variables.	functional dependency;graphical user interface;ibm i;interaction;synergy	Michael P. Wellman	1990			probabilistic analysis of algorithms;qualitative reasoning;probabilistic relevance model;computer science;theoretical computer science;machine learning;mathematics;functional dependency;probabilistic logic;probabilistic argumentation;algorithm	AI	-17.55409915725769	9.356751720561054	177447
18044611b486f9cbfe93824098bb9bddbda57bbb	independent natural extension	coherent lower prevision;strong product;linear time algorithm;natural extension;epistemic irrelevance;artificial intelligent;imprecise probability;epistemic independence;independent natural extension;factorisation;graphical model;coherent lower previsions	We introduce a general definition for the independence of a number of finite-valued variables, based on coherent lower previsions. Our definition has an epistemic flavour: it arises from personal judgements that a number of variables are irrelevant to one another. We show that a number of already existing notions, such as strong independence, satisfy our definition. Moreover, there always is a least-committal independent model, for which we provide an explicit formula: the independent natural extension. Our central result is that the independent natural extension satisfies so-called marginalisation, associativity and strong factorisation properties. These allow us to relate our research to more traditional ways of defining independence based on factorisation.	coherence (physics);existential quantification;ibm notes;many-to-many;monoid factorisation;one-to-many (data model);relevance;requirement;sap business one;switzerland	Gert de Cooman;Enrique Miranda;Marco Zaffalon	2011	Artif. Intell.	10.1016/j.artint.2011.06.001	imprecise probability;computer science;artificial intelligence;machine learning;mathematics;graphical model;factorization;algorithm	AI	-12.610786350202225	9.024032952193732	177824
6c25c1054823874d6b10759acfca8a3664a69784	basic influence diagrams and the liberal stable semantics	abstract and assumption based argumentation;decision tables and decision making;influence diagram;decision table	This paper is concerned with the general problem of constructing decision tables and more specifically, with the identification of all possible outcomes of decisions. We introduce and propose basic influence diagrams as a simple way of describing problems of decision making under strict uncertainty. We then establish a correspondence between basic influence diagrams and symmetric generalised assumption-based argumentation frameworks and adopt an argumentationbased approach to identify the possible outcomes. We show that the intended solutions are best characterised using a new semantics that we call liberal stability. We finally present a number of theoretical results concerning the relationships between liberal stability and existing semantics for argumentation.	argumentation framework;decision table;denotational semantics;influence diagram	Paul-Amaury Matt;Francesca Toni	2008			decision table;influence diagram;computer science;artificial intelligence;management science;algorithm;business decision mapping	AI	-17.136424198820272	5.719373430549022	178739
2882b6271ada52de2e6c767e39aedd73b297cc0b	credibility-limited improvement operators		In this paper we introduce and study credibility-limited improvement operators. The idea is to accept the new piece of information if this information is judged credible by the agent, so in this case a revision is performed. When the new piece of information is not credible then it is not accepted (no revision is performed), but its plausibility is still improved in the epistemic state of the agent, similarly to what is done by improvement operators. We use a generalized definition of Darwiche and Pearl epistemic states, where to each epistemic state can be associated, in addition to the set of accepted formulas (beliefs), a set of credible formulas. We provide a syntactic and semantic characterization of these operators.	andrew donald booth;encode;iteration;ordinal data;pino;plausibility structure	Richard Booth;Eduardo L. Fermé;Sébastien Konieczny;Ramón Pino Pérez	2014		10.3233/978-1-61499-419-0-123	artificial intelligence;algorithm	AI	-14.463315192971956	5.572177796603023	179146
9fb8f25914f355341012053d7dcf2a75d4a9bc53	an algebraic approach to belief contraction and nonmonotonic entailment	algebraic approach;satisfiability;belief revision;necessary and sufficient condition;cumulant	Abstract   The approach of Alchourron, Gardenfors and Makinson to belief contraction is treated algebraically. This is then used to give an algebraic treatment of nonmonotonic entailment in the context of a belief set. The algebra used is a preboolean algebra whose elements are sets of sentences and whose order relation is  restricted entailment . Under plausible assumptions restricted entailment is computable. It can also be shown that ordinary entailment can be retrieved from the family of entailments with finite restrictions. Nonmonotonic closure or consequence   C  , defined algebraically, satisfies inclusion, supraclassicality and distribution, but satisfaction of idempotency and cumulativity depend on certain conditions being fulfilled. Casting the notions of belief contraction and nonmonotonic entailment in algebraic formalism facilitates the understanding and analysis of these ideas. For example, necessary and sufficient conditions are given for nonmonotonic closure to be equal to ordinary closure:   C  =  Cn  .	belief revision;non-monotonic logic	Lee Flax	2007	J. Applied Logic	10.1016/j.jal.2006.03.006	discrete mathematics;computer science;artificial intelligence;mathematics;preferential entailment;belief revision;algorithm;statistics;cumulant;satisfiability	AI	-15.17860355283136	8.62609142494202	179239
1ad582a0f18e8350365dc4bdedb90fc804f9b76b	perceptual simulations can be as expressive as first-order logic		Theories asserting that human reasoning is based on perceptual simulations often suppose these simulations are of concrete individual objects and the specific relations that hold among them. However, much human knowledge involves assertions about which relations do not hold, generalities over large numbers of objects and conditional facts. Can simulation theories explain how the mind represents these forms of knowledge, or are they inferior in their expressive power to knowledge representation schemes based on logical formalisms designed specifically to deal with negative, conditional and quantificational knowledge? In this paper, we show how assertions about mental simulations can in fact straightforwardly express all the concepts that comprise first-order logic, including negation, conditionals and both universal and existential quantification. We also speculate on how to extend this approach to deal with probabilistic and more expressive logics.	existential quantification;expressive power (computer science);first-order logic;first-order predicate;knowledge representation and reasoning;mind;physical object;quantitation;simulation;theory (mathematical logic)	Hiroyuki Uchida;Nicholas L. Cassimatis;J. R. Scally	2012	Cognitive Processing	10.1007/s10339-012-0444-1	algorithm	AI	-15.19111399993744	5.658395434888233	179395
4f97b28e3255ce6003d02a2aab64ac0d6436817c	spacetime-entangled networks (i) relativity and observability of stepwise consensus		Consensus protocols can be an effective tool for synchronizing small amounts of data over small regions. We describe the concept and implementation of entangled links [1], applied to data transmission, using the framework of Promise Theory as a tool to help bring certainty to distributed consensus. Entanglement describes co-dependent evolution of state. Networks formed by entanglement of agents keep certain promises: they deliver sequential messages, endto-end, in order, and with atomic confirmation of delivery to both ends of the link. These properties can be used recursively to assure a hierarchy of conditional promises at any scale. This is a useful property where a consensus of state or ‘common knowledge’ is required. We intentionally straddle theory and implementation in this discussion.	consensus (computer science);numerical relativity;promise theory;quantum entanglement;recursion;stepwise regression	Paul Borrill;Mark Burgess;Alan Karp;Atsushi Kasuya	2018	CoRR		spacetime;quantum entanglement;theory of relativity;observability;synchronizing;distributed computing;consensus;straddle;hierarchy;mathematics	Logic	-18.137047349654015	4.301207080739635	179400
ca438e6bbee75fc0272bc2aa813d966c33e6a22c	an interval-based temporal relational calculus for events with gaps	expressive power;binary relation;common sense	Abstract Traditional interval-based representations of time assume interval convexity, i.e., that intervals are uninterrupted. This assumption makes it difficult to represent the common sense notion of a single event with ‘gaps’. Having a representation of this species of event contributes favorably to the ability of the human or machine to solve certain tasks, such as planning or database retrieval. This paper defines two kinds of discourse and knowledge object which comprise collections of convex intervals. Although other researchers have suggested the need for a relaxation of the assumption of convexity in event representation, there has been no attempt to offer a concise representation of gapped events. The formulation employed here to introduce gapped events is an extension of James Allen's interval-based approach to time representation. Allen's calculus of thirteen binary relations defined between two convex intervals is generalized to a matrix of binary relations between each pair of subintervals o...	relational calculus	Robert A. Morris;Lina Khatib	1991	J. Exp. Theor. Artif. Intell.	10.1080/09528139108915283	computer science;artificial intelligence;machine learning;binary relation;expressive power;algorithm	AI	-18.839092096396588	7.954346934208712	179551
21dc592150f7388dab7e9cc2801dbdc6f5b0c2cf	a denotational semantics for the starburst production rule language	denotational semantic;starburst;computer science;production rule;deductive databases	Researchers often complain that the behavior of database production rules is difficult to reason about and understand, due in part to the lack of formal declarative semantics. It has even been claimed that database production rule languages inherently cannot be given declarative semantics, in contrast to, e.g., deductive database rule languages. In this short paper we dispute this claim by giving a denotational semantics for the Starburst database production rule language.	deductive database;denotational semantics;formal grammar	Jennifer Widom	1992	SIGMOD Record	10.1145/140979.140980	natural language processing;normalisation by evaluation;action semantics;computer science;database;programming language;denotational semantics of the actor model;operational semantics;denotational semantics	DB	-18.468384130806843	10.311838950645772	179773
336e54334f7604ec18f7fd9f8e45d8a56786e23f	implication connectives for logics with right weakening	satisfiability	"""We study non-monotonic inference relations, focusing on the properties of the underlying monotonic consequence relation. This sheds new light on the general properties that may or may not be satisfied by a nonmonotonic relation. We let the underlying consequence relation to be any monotonic logic, indicating under what precise conditions it gives rise to a non-monotonic inference relation that obeys major principles such as right weakening and the rule of detachment. We begin to explore the border line that non-monotonic relations cannot cross if they are to enjoy these properties. This work may be considered either as a constructive opposition, or as a complement, to the previous work about the general properties of nonmonotonic inference relations. 1 I n t r o d u c t i o n Incomplete information cannot be dealt with adequately using standard logics that are characterized as inference relations satisfying a few properties including the so-called monotony. In fact, inference relations failing monotony (i.e., non-monotonic systems) have emerged as a solution to the formalization of some common sense reasoning problems. Only recently have the properties of non-monotonic inference relations been studied carefully [Gab85, Mak88, BesS8, KLM90, FLM91]. Most of these papers focus on weakening the requirement for monotony and investigate various ways to do it. Here, we focus on the properties of a non-monotonic inference relation t -~ relative to an underlying monotonic inference relation ~( that is, a s tandard logic). Such a combination is indeed the case in almost all the non-monotonic formalisms up to date. We aim at identifying how the properties of the """"basic"""" relation ~influence the properties of the relation b~. This paper may be considered as a sequel to [Bes88] which defined several notions such as CMP (compound modus ponens), later known as """"right weakening"""" when b is classical logic: Sb~ A 8 b A'-~ B 8 b ~ B We keep the former name CMP to emphazise that we do not demand b to be classical logic but we only require b to obey reflexivity: 8 b A whenever A E 8"""	commonsense reasoning;complement (complexity);failing badly;failure;logical connective;non-deterministic turing machine;non-monotonic logic	Philippe Besnard;Yves Moinard	1994		10.1007/BFb0035969	computer science;satisfiability	Logic	-14.003824060139133	6.74068878419741	180767
7d05faf32a2cc0ffb24ee4a42da6c5517da8d349	on the complexity of computing the justification status of an argument	labeling-based semantics;different level;comprehensive study;acceptance status;argument w;arbitrary argumentation semantics;labeling-based justification status;computational property	Motivation We adress the problem of: Determining the acceptance status of an argument in abstract argumentation (Given a semantics for computing the extensions). Motivation We adress the problem of: Determining the acceptance status of an argument in abstract argumentation (Given a semantics for computing the extensions). Traditional: Skeptical and/or Credulous Acceptance. Wu and Caminada recently proposed a new approach: The Justification Status of an Argument.	decision problem	Wolfgang Dvorák	2011		10.1007/978-3-642-29184-5_3	epistemology;mathematics;algorithm	AI	-16.061816891385323	5.5765519761225075	181396
b6da61acad526df2843b362a1d1bc4224130f63b	interacting explicit evidence systems	multi agent system;logic of proofs;modal logic;multi modal logic;common knowledge;epistemic logic;explicit evidence;justification logic	Logic of proofs $\mathsf{LP}$ , introduced by S. Artemov, originally designed for describing properties of formal proofs, now became a basis for the theory of knowledge with justification (cf. S. Artemov, Evidence-based common knowledge, Technical report TR–2004018, CUNY Ph.D. Program in Computer Science, 2005). So far, in epistemic systems with justification the corresponding “evidence part”, even for multi-agent systems, consisted of a single explicit evidence logic. In this paper we introduce logics describing two interacting explicit evidence systems. We find an appropriate formalization of the intended semantics and prove the completeness of these logics with respect to both symbolic and arithmetical models. Also, we find the forgetful projections for the two-agent justification logics which are extensions of the bimodal logic $\mathsf{S4}^{2}$ .	computer science;formal proof;interaction;multi-agent system	Tatiana Yavorskaya	2007	Theory of Computing Systems	10.1007/s00224-007-9057-y	modal logic;predicate logic;dynamic logic;t-norm fuzzy logics;normal modal logic;discrete mathematics;classical logic;description logic;higher-order logic;epistemic modal logic;principle of bivalence;many-valued logic;intuitionistic logic;computer science;intermediate logic;multi-agent system;computational logic;mathematics;accessibility relation;logic;substructural logic;multimodal logic;algorithm;common knowledge;philosophy of logic;autoepistemic logic	Logic	-15.264899713121942	8.017163313457907	181984
0e625084aee64d8b6ce0b4e5443322e0a8eab265	on the use of an atms for handling conflicting desires	autonomous agents;atms.;bdi;proof theory;autonomous agent	This paper presents a revised version of a framework proposed in (Amgoud 2003) which computes consistent sets of intentions from a conflicting set ofdesiresand a set ofbeliefs. That framework enables us to restate the problem of computing intentions in the context of argumentation theory. Indeed, interacting arguments are interpreted as competing plans for achieving some desire, or conflicting plans for achieving different desires. Another important contribution of this paper is to present an ATMS-based proof theory for that framwork. Indeed, we show that the different concepts defined and used in (Amgoud 2003) can be restated taking advantage of the well-known Assumptionbased Truth Maintenance System (de Kleer 1986a; 1986b).	interaction;reason maintenance;type system;whole earth 'lectronic link	Leila Amgoud;Claudette Cayrol	2004			argumentation theory;autonomous agent;proof theory;algorithm;computer science;reason maintenance;artificial intelligence	AI	-17.793652767820035	5.422561955755008	182337
86007dd9f092f9acc8beed4346f109090e4d632f	on the computational interpretation of ckn for contextual information processing	mathematical proofs;calculus;contextual analysis;information processing;information resources management;generalization	In the journal article [8] we introduce a modal λ-calculus λCKn whose type system corresponds to the constructive multi-modal logic CKn. This logic is a constructive refinement of the classical multi-modal logic Kn which forms the heart of the class of description logics used in semantic information processing. λCKn constitutes the core of a functional language for information processing in this application domain. Being strongly typed, it offers static type checking to support safe contextual reasoning in relational structures like those treated by description logics. Here we provide detailed mathematical proofs for the results presented in [8]. Accordingly, this report is not meant as a self-contained technical exposition of the whys and hows of λCKn. It is merely a collection of ancillary material to complement the main article [8] to which the reader is referred for more information. An early version of this work appeared at the 3rd International Workshop on Logics, Agents and Mobility (LAM 2010). We are grateful for the support by the German Research Council (DFG) who funded this research as part of the project SPACMODL under grant No. ME 1427/4-1. 1 The Structure of Normal Form Proofs Proposition 1. Every expression typeable under the rules of Fig. 1 and Fig. 2 is in normal form. Proof. The proof proceeds by induction on the structure of the typing derivation. The statement is obvious for the base case of rule Axm and the induction steps for left rules ∨L, ∃L, the right rules ∧R, ∨R1, ∨R2, ⊃R, ∃R as well as ∀R. For the left rules ∧L1, ∧L2, ⊃L, ∀L we use the fact that if nf is a normal form and y a free variable in nf , then the substitutions nf Jπ1 x/yK, nf Jπ2 x/yK, nf Jxnf ′/yK and nf Jx@b/yK are again normal forms. For rule Ax f we observe that if nf is a normal form, then so is nf JΓ̂/ΓK.	a-normal form;application domain;beta normal form;computation;database normalization;description logic;free variables and bound variables;functional programming;information processing;logic programming;mathematical induction;modal logic;recursion;refinement (computing);simply typed lambda calculus;structural induction;type system;xfig	Michael Mendler;Stephan Scheele	2014	Fundam. Inform.	10.3233/FI-2014-984	generalization;discrete mathematics;information processing;computer science;artificial intelligence;machine learning;mathematics;mathematical proof;algorithm;algebra	Logic	-15.421582460901195	10.6689744153726	182352
1e16eff955809e3fb4caa7b940ca7fea3147b4af	from causal models to counterfactual structures	artificial intelligent;expressive power;causal models;possible worlds	Galles and Pearl [1998] claimed that “for recursive models, the causal model framework does not add any restrictions to counterfactuals, beyond those imposed by Lewis’s [possible-worlds] framework.” This claim is examined carefully, with the goal of clarifying the exact relationship between causal models and Lewis’s framework. Recursive models are shown to correspond precisely to a subclass of (possible-world) counterfactual structures. On the other hand, a slight generalization of recursive models, models where all equations have unique solutions, is shown to be incomparable in expressive power to counterfactual structures, despite the fact that the Galles and Pearl arguments should apply to them as well. The problem with the Galles and Pearl argument is identified: an axiom that they viewed as irrelevant, because it involved disjunction (which was not in their language), is not irrelevant at all.	causal filter;causal model;counterfactual conditional;possible world;recursion (computer science);relevance	Joseph Y. Halpern	2010	Rew. Symb. Logic	10.1017/S1755020312000305	discrete mathematics;philosophy;epistemology;mathematics;possible world;expressive power;algorithm;causal model	AI	-15.36188598304822	6.68641786001927	182395
5e7c052ce996507d87cede87c04a084b8efbc055	tableaux for the lambek-grishin calculus	context free;expressive power;natural language	Categorial type logics, pioneered by Lambek ([8]), seek a proof-theoretic understanding of natural language syntax by identifying categories with formulas and derivations with proofs. We typically observe an intuitionistic bias: a structural configuration of hypotheses (a constituent) derives a single conclusion (the category assigned to it). Acting upon suggestions of Grishin ([3]) to dualize the logical vocabulary, Moortgat proposed the Lambek-Grishin calculus (LG, [11]) with the aim of restoring symmetry between hypotheses and conclusions. We propose a theory of labeled modal tableaux ([14]) for LG, inspired by the interpretation of its connectives as binary modal operators in the relational semantics of [6]. After a brief recapitulation of LG’s models in §1, we define our tableaux in §2 and ensure soundness and completeness in §3. Linguistic applications are considered in §4, where grammars based on LG are shown to be context-free through use of an interpolation lemma. This result complements [10], where LG augmented by mixed associativity and -commutativity was shown to exceed LTAG in expressive power.	context-free language;farkas' lemma;interpolation;intuitionistic logic;kripke semantics;logical connective;modal logic;natural language;theory;vocabulary	Arno Bastenhof	2010	CoRR		computer science;artificial intelligence;linguistics;natural language;expressive power;algorithm	Logic	-12.24797608819466	7.930510526409083	183210
3cdc194311fbfba16fef18ef9bd0b1665d58003e	answer sets for prioritized logic programs	answer set;prioritized logic program;knowledge representation and reasoning;conflict resolution	Connict resolution is an important issue in knowledge representation and reasoning. A common idea of solving connicts in reasoning is to add preferences in the underlying reasoning mechanism. This paper describes extensions of Gelfond and Lifschitz's extended logic programs 5] by adding preference information. We rst propose prioritized logic programs (PLPs) in which the preference is expressed statically. An extended answer set semantics is provided for PLPs. We then extend PLPs to dynamic PLPs (DPLPs) in which the preference can be expressed dynamically. The semantics of DPLPs is deened in terms of answer sets of the corresponding PLPs. By illustrating typical examples, we show how connicts between rules are resolved in PLPs and DPLPs. We also investigate basic properties of PLPs and DPLPs in detail.	knowledge representation and reasoning;logic programming;resolution (logic);stable model semantics;vladimir lifschitz	Yan Zhang;Norman Y. Foo	1997			knowledge representation and reasoning;description logic;stable model semantics;computer science;artificial intelligence;theoretical computer science;answer set programming;conflict resolution;data mining;algorithm	AI	-17.603424737823623	8.437428400622455	183790
f50047f09556fe711649c1c6ce4040c7f929aaab	requantification, underquantification and partial focus in indefinites		Based on an intricate pattern concerning the interpretation of indefinites in both monoand biclausal sentences with adverbial quantifiers, we propose an analysis which combines the idea that restrictorand nucleus situations/events of adverbial quantifiers are related via initially underspecified matching functions (Rothstein 1995) with pragmatic assumptions concerning preferences for the specification of these matching functions as well as the independently motivated pragmatic principle Maximize Presuppositions! (MP, Heim 1991). We show that neither the traditional situation semantics approach to adverbial quantification which assumes both restrictorand scope minimization (von Fintel 1994) nor a revision of this picture using neo-Davidsonian events (Herburger 2001) is able to account for the full pattern in a uniform manner. Finally, we provide additional evidence that the Novelty Condition (Heim 1982) does not exist as an independent principle and that its putative effects, where they occur, can be derived from MP (cf. Singh 2011).		Stefan Hinterwimmer;David Schueler	2015	J. Semantics	10.1093/jos/ffu012	philosophy;linguistics	AI	-14.039873857188676	5.848077490877215	184057
b7eb66116ff2d1e1c5563c45feddbe46a7c1965d	nonmonotonic reasoning as prioritized argumentation	default reasoning;argumentation;logic;inference rule;nonmonotonic reasoning;default logic nonmonotonic reasoning prioritized argumentation monotonic inferences inference rule priority constrained inferences knowledge representation language first order formulas default reasoning;default logic;priority;logic nonmonotonic reasoning;birds logic programming knowledge representation constraint theory;representability	This paper proposes a formalism for nonmonotonic reasoning based on prioritized argumentation. We argue that nonmonotonic reasoning in general can be viewed as selecting monotonic inferences by a simple notion of priority among inference rules. More importantly, these types of constrained inferences can be speciied in a knowledge representation language where a theory consists of a collection of rules of rst order formulas and a priority among these rules. We recast default reasoning as a form of prioritized argumentation, and illustrate how the parameterized formulation of priority may be used to allow various extensions and modiications to default reasoning. We also show that it is possible, but more diicult, to express prioritized argumentation by default logic: even some particular forms of prioritized argumentation cannot be represented modularly by defaults under the same language.	default logic;knowledge representation and reasoning;non-monotonic logic;semantics (computer science)	Jia-Huai You;Xianchang Wang;Li-Yan Yuan	2001	IEEE Trans. Knowl. Data Eng.	10.1109/69.971190	computer science;artificial intelligence;non-monotonic logic;machine learning;mathematics;reasoning system;deductive reasoning;default logic;probabilistic argumentation;logic;algorithm	AI	-17.138793471438184	8.537319068113101	184149
f01284dba9b731c03c6432d7ba4bdfb77a631bad	a normal simulation of coalition logic and an epistemic extension	game theory;temporal logic;discrete time;modal logic;ai planning	In this paper we show how coalition logic can be reduced to the fusion of a normal modal STIT logic for agency and a standard normal temporal logic for discrete time, and how this multi-modal system can be suitably extended with an epistemic modality. Both systems are complete, and we provide a new axiomatization for the STIT-fragment. The epistemic extension enables us to express that agents see to something under uncertainty about the present state or uncertainty about which action is being taken. In accordance with established terminology in the planning community, we call this version of STIT the 'conformant STIT'. The conformant STIT enables us to express that agents are able to perform a uniform strategy. As a final word of recommendation for this paper we want to point out that its subject is at the junction of four academic fields, viz. modal logic, philosophy, game-theory and AI-planning.	automated planning and scheduling;axiomatic system;game theory;modal logic;modality (human–computer interaction);simulation;temporal logic;viz: the computer game	Jan M. Broersen;Andreas Herzig;Nicolas Troquard	2007		10.1145/1324249.1324264	modal logic;predicate logic;dynamic logic;normal modal logic;game theory;discrete time and continuous time;linear temporal logic;epistemic modal logic;temporal logic;computer science;artificial intelligence;mathematics;accessibility relation;multimodal logic;algorithm	AI	-14.814885694876171	8.440281672336745	184546
46ce24665dba71e239a817d893bfcba02abda641	general fuzzy answer set programs	answer sets;answer set programming;constraint satisfaction;fuzzy logic;qa75 electronic computers computer science;valued constraint satisfaction;answer set programs;qa76 computer software	A number of generalizations of answer set programming have been proposed in the literature to deal with vagueness, uncertainty, and partial rule satisfaction. We introduce a unifying framework that entails most of the existing approaches to fuzzy answer set programming. In this framework, rule bodies are defined using arbitrary fuzzy connectives with monotone partial mappings. As an approximation of full answer sets, k–answer sets are introduced to deal with conflicting information, yielding a flexible framework that encompasses, among others, existing work on valued constraint satisfaction and answer set optimization.		Jeroen Janssen;Steven Schockaert;Dirk Vermeir;Martine De Cock	2009		10.1007/978-3-642-02282-1_44	fuzzy logic;stable model semantics;constraint satisfaction;type-2 fuzzy sets and systems;computer science;artificial intelligence;answer set programming;data mining;algorithm	AI	-19.024980074447203	7.4769929264096975	184999
8912f12cff572aa5d61449c21f969494095fd132	a meta-logic of inference rules: syntax	propositional logic	This work was intended to be an attempt to introduce the meta-language for working with multiple-conclusion inference rules that admit asserted propositions along with the rejected propositions. The presence of rejected propositions, and especially the presence of the rule of reverse substitution, requires certain change the definition of structurality.		Alex Citkin	2014	CoRR		mathematics;propositional calculus;algorithm	NLP	-12.588714637267302	6.717767598750912	185455
7d5772de7ca519b5e970d26c148dd246693854f9	operators vs. arguments: the ins and outs of reification	temporal logic;artificial intelligent;present day;knowledge representation	So-called ‘reified temporal logics’ were introduced by researchers in Artificial Intelligence (AI) in the early 1980s, and gave rise to a long-running series of debates concerning the proper way to represent states, events, causation, action, and other notions identified as crucial to the knowledge representation needs of AI. These debates never resulted in a definitive resolution of the issues under discussion, and indeed continue to produce aftershocks to the present day; none the less, we are now sufficiently far removed in time from their heyday for it to be a worthwhile exercise to stand back and review them as a connected piece of history.	artificial intelligence;causality;knowledge representation and reasoning	Antony Galton	2005	Synthese	10.1007/s11229-005-5516-7	knowledge representation and reasoning;temporal logic;philosophy;epistemology;mathematics;operations research;algorithm	AI	-13.08902040826235	4.7322112333000295	185503
b37e54b5870d42ac912aaa17a7227619fda66af7	d-separation: strong completeness of semantics in bayesian network inference		We present an algorithm, called Semantics in Inference (SI), that uses d-separation to denote the semantics of every potential constructed during exact inference in discrete Bayesian networks. We establish that SI possesses four salient features, namely, polynomial time complexity, soundness, completeness, and strong completeness. SI provides a better understanding of the theoretical foundation of Bayesian networks and can be used for improved clarity, as shown via an examination of Bayesian network literature.	algorithm;bayesian network;emoticon;np-completeness;polynomial;soundness (interactive proof);time complexity	Cory J. Butz;Wen Yan;Anders L. Madsen	2013		10.1007/978-3-642-38457-8_2	fiducial inference;frequentist inference;machine learning;data mining;bayesian statistics;algorithm;statistics	AI	-16.061174871921672	8.183214833526213	186492
2e194d2cb6e2c2b8ff00b9bc9ac371afb26613cc	semantics for reasoning with contradictory extended logic programs	extended logic programs;contradictions;procedural semantics.;declarative semantics;rule prioritization;monotone operator	Extended programs are normal programs extended with classical negation. Because of the classical negation in the head of the rules, an extended logic program can be contradictory. Human reasoning is often based on conflicting evidence and on assumptions which are not always valid. Our goal is to derive useful conclusions from programs that may be contradictory. We consider rules to be defaults. Rule prioritization can be viewed as a tool to specify confidence information about these defaults. We present a new semantics for extended programs with rule prioritization, called contradiction-free semantics (CFS). CFS is defined as the least fixpoint of a monotonic operator. Every extended program with rule prioritization has at least one stable c-model. We show that the CFS of a program P coincides with the least stable c-model of P. A sound and complete proof procedure to answer queries based on CFS is described.	climate forecast system;fixed point (mathematics);least fixed point;logic programming;non-monotonic logic;rule 184	Anastasia Analyti;Sakti Pramanik	1994			dynamic logic (modal logic);discrete mathematics;bunched logic;axiomatic semantics;non-monotonic logic;stable model semantics;negation;well-founded semantics;predicate functor logic;mathematics	AI	-16.526099828878912	9.277108572333823	187218
396e6d6bd6e8ffc5cff791f3174cada3770afacf	sentences, belief and logical omniscience, or what does deduction tell us?		We propose a model for belief which is free of presuppositions. Current models for belief suffer from two difficulties. One is the well known problem of logical omniscience which tends to follow from most models. But a more important one is the fact that most models do not even attempt to answer the question what it means for someone to believe something, and just what it is that is believed. We provide a flexible model which allows us to give meaning to beliefs in general contexts, including the context of animal belief (where action is usually our only clue to a belief), and of human belief which is expressed in language. §	brouwer–heyting–kolmogorov interpretation;catherine;concordance (publishing);formal system;hoc (programming language);jean;natural deduction;pittsburgh supercomputing center;whole earth 'lectronic link;yet another;eric	Rohit Parikh	2008	Rew. Symb. Logic	10.1017/S1755020308090059	epistemology;artificial intelligence	AI	-13.504031214574267	5.256587214855998	187457
1cb98835774966ed73d4c895a1cbde2872125e63	what agents can probably enforce	satisfiability;alternating time temporal logic atl;alternating time temporal logic	Alternating-time Temporal Logic (ATL) is probably the most influential logic of strategic ability that has emerged in recent years. The idea of ATL is centered around cooperation modalities: 〈〈A〉〉γ is satisfied if the group A of agents has a collective strategy to enforce temporal property γ against the worst possible response from the other agents. So, the semantics of ATL shares the “all-or-nothing” attitude of many logical approaches to computation. Such an assumption seems appropriate in some application areas (life-critical systems, security protocols, expensive ventures like space missions). In many cases, however, one might be satisfied if the goal is achieved with reasonable likelihood. In this paper, we try to soften the rigorous notion of success that underpins ATL.	alternating-time temporal logic;computation;information;model checking;numerical analysis;pspace;time complexity	Nils Bulling;Wojciech Jamroga	2009	Fundam. Inform.	10.3233/FI-2009-0089	artificial intelligence;mathematics;algorithm;satisfiability	AI	-17.8715374321811	4.2788601721827	188019
39f509e766d53d2bb27dc52082e1c2c767b25fb1	a model-theoretic analysis of monotonic knowledge	semantic model;theoretical analysis	We present a semantic model for knowledge with the following properties: (1) Knowledge is necessarily correct, (2) agents are logically omniscient, i.e., they know all the consequences of their knowledge, and (3) agents are positively introspective, i.e., they are aware of their knowledge, but not negatively introspective, i.e., they may not be aware of their ignorance. We argue that this is the appropriate model for implicit knowledge. We investigate the properties of the model, and use it to formalize the notion of circumscribed knowledge.	theory	Moshe Y. Vardi	1985			semantic data model;computer science;knowledge management;artificial intelligence;body of knowledge;knowledge-based systems;mathematics;procedural knowledge	AI	-16.169330086250856	4.278184374091023	188402
da1bef46af83dafc85a30283e4d9ed352bd1e4f4	complexity classifications for propositional abduction in post's framework	boolean function;computational complexity;non monotonic reasoning;knowledge base	In this paper we investigate the complexity of abduction, a fundamental and important form of non-monotonic reasoning. Given a knowledge base explaining the world’s behavior it aims at finding an explanation for some observed manifestation. In this paper we consider propositional abduction, where the knowledge base and the manifestation are represented by propositional formulae. The problem of deciding whether there exists an explanation has been shown to be Σp2-complete in general. We focus on formulae in which the allowed connectives are taken from certain sets of Boolean functions. We consider different variants of the abduction problem in restricting both the manifestations and the hypotheses. For all these variants we obtain a complexity classification for all possible sets of Boolean functions. In this way, we identify easier cases, namely NP-complete, coNP-complete and polynomial cases. Thus, we get a detailed picture of the complexity of the propositional abduction problem, hence highlighting sources of intractability. Further, we address the problem of counting the explanations and draw a complete picture for the counting complexity.	abductive reasoning;co-np;counting problem (complexity);knowledge base;logical connective;np-completeness;non-monotonic logic;polynomial;propositional calculus	Nadia Creignou;Johannes Schmidt;Michael Thomas	2012	J. Log. Comput.	10.1093/logcom/exr012	knowledge base;discrete mathematics;computer science;mathematics;propositional variable;boolean function;computational complexity theory;algorithm	AI	-15.728527700812267	8.179285588955445	188406
dfc94ad357e55ef11daf2168348db845458aaa24	relevance and revision - about generalizing syntax-based belief revision	syntax-based belief revision;belief revision	This paper proposes a syntax-based revision-procedure for belief sets structured by an arbitrary relevance pre-ordcr and an elementary epistemic dependency relation and investigates the consequences for the Gaerdenforsian rationality postulates. In particular, it generalizes Nebel's epistemic relevance revision.	belief revision;relevance	Emil Weydert	1992		10.1007/BFb0023425	belief revision	AI	-14.845084065418286	6.219952188646255	189143
fded33d9b6e03eccd9106543e0d6ac499b91f802	thought-contents and the formal ontology of sense	sense;belief;logique intensionnelle;attitude propositionnelle;transparence;relation semantique;pensee;presentation;property;croyance;attribution;meaning;language of thought;contenu;property a;propriete;sens;transparency;code;formal ontology;contents;thought;intensional logic;condition de verite	This paper articulates a formal theory of belief incorporating three key theses: (1) belief is a dyadic relation between an agent and a property; (2) this property is not the belief’s truth condition (i.e., the intuitively self-ascribed property which the agent must exemplify for the belief to be true) but is instead a certain abstract property (a “thoughtcontent”) which contains a way of thinking of that truth condition; (3) for an agent a to have a belief “about” such-and-such items it is necessary that a possesses a language of thought, Ma , and that a (is disposed as one who) inwardly affirms a sentence of Ma in which there are terms that denote those objects. Employing an extended version of E. Zalta’s system ILAO, the proffered theory locates thought-contents within a typed hierarchy of “senses” and their “modes of presentation”, the provisional definitions of which (suppressing complications added later to accommodate the contents of beliefs about beliefs) are as follows. A mode of presentation of e is a ternary relation of the sort [λxyz z is a name in My that denotes x, and Deyz] in which De is an e-determiner – a relation between agents and their mental expressions imposing a syntactico-semantic condition sufficient for such an expression to denote e therein. A sense of an entity e is an abstract property that “contains” a mode of presentation Re of e by dint of encoding its property-reduct [λx(∃y)(∃z)Rexyz]. In particular, a thought-content is a sense T of an ordinary first-order property P containing a mode of presentation whose P -determiner DP is such that, for any y and z, DP yz entails that z is a λ-abstract [λv S] of My in which S is a sentence whose non-logical parts stand in appropriate semantic relations to the constituents of T ’s (some of which may themselves be senses). Where Ia is agent a’s dedicated self-demonstrative and |T | is the mode of presentation contained in a thought-content T , the belief relation itself is then characterized as obtaining between a and T iff a( is disposed as one who) inwardly affirms the substitution instance S(Ia/v) of a sentence S in Ma such that |T |(P, a, [λv S]). The aforementioned “constituents” and “appropriate semantic relations” are formally characterized so as to permit a system of canonical descriptions for thought-contents of arbitrary complexity. These canonical descriptions are then employed to chart the nature and interrelations of belief de re, de dicto and de se and to identify the source of opacity in belief ascription.	complexity;dyadic transformation;emoticon;exemplification;first-order predicate;formal ontology;pdf/a;substitution (logic)	Steven E. Boër	2003	J. Philosophical Logic	10.1023/A:1022896025635	philosophy;epistemology;artificial intelligence;thought;attribution;belief;linguistics;property;transparency;meaning;intensional logic;code;sense	AI	-12.938640327094786	5.491062998805745	189596
49d78e3cccabc998a14458b90bca9711faa43dff	a subjective logic based extensional approach to non-monotonic reasoning under uncertainty and its application to visual surveillance		The majority of recent work in analysis of visual surveillance have focused on automated perception aspects based on computer vision technology. However, little attention has been paid to higher level semantic analysis upon such perception data. In this dissertation, we approach the higher level semantic analysis from the artificial logical reasoning stance. First, we propose the use of logic programming and subjective logic for knowledge and uncertainty representation. Second, we propose inference schemes for contradiction handling, ambiguous rule modeling, bidirectional conditional reasoning and diagnostic abduction. Each of fore-mentioned aspects are presented with case studies to show the feasibility of the proposed reasoning framework in visual surveillance.	non-monotonic logic	Seunghan Han	2012			model-based reasoning;automated reasoning;subjective logic;contradiction;logical reasoning;machine learning;inference;reasoning system;logic programming;computer science;artificial intelligence	AI	-16.31019508302258	6.2856220197229	189798
0144b11b572ff40bdaa618ec3bb38e79e9831212	case law in extended argumentation frameworks	liverpool;argumentation;game theory;repository;dialogue games;university;evolution	In this paper we discuss how recent developments in argumentation frameworks, most notably Extended Argumentation Frameworks, can inform the representation of a body of case law using abstract argumentation techniques. This builds on previous work which has first used abstract Argumentation Frameworks, and then Value based Argumentation Frameworks for this purpose.  Extended Argumentation Frameworks augment Argumentation Frameworks to not only allow arguments to be attacked, but also attacks to be attacked. This allows argumentation based reasoning about information normally assumed to be metalevel to the object level domain of argumentation, including argumentation over preferences, values and the audience based ranking of values promoted by arguments. The Extended Argumentation Frameworks can then be rewritten as standard Argumentation Frameworks, so that cases, and values and their rankings relevant to the cases, can be reasoned about using standard dialogue games for Argumentation Frameworks. In this way precedents can be represented as collections of arguments and dialogues using these arguments. Now, when confronted with a new case, these dialogues may be used to identify ways of deploying the arguments in the new case so as to reach a favourable position.	argumentation framework	Trevor J. M. Bench-Capon;Sanjay Modgil	2009		10.1145/1568234.1568248	game theory;computer science;knowledge management;artificial intelligence;evolution;management science;probabilistic argumentation	AI	-17.210267840590646	5.151521933052646	190033
45eb2493f0672070806b3a7a9f5c8d9f0d299c7d	justified beliefs by justified arguments	liverpool;repository;modal logic;epistemic logic;product logics;university;argumentation theory	The paper addresses how the information state of an agent relates to the arguments that the agent endorses. Information states are modeled in doxastic logic and arguments by recasting abstract argumentation theory in a modal logic format. The two perspectives are combined by an application of the theory of product logics, delivering sound and complete systems in which the interaction of arguments and beliefs is investigated.	doxastic logic;modal logic;state (computer science)	Davide Grossi;Wiebe van der Hoek	2014			modal logic;epistemic modal logic;doxastic logic;artificial intelligence;argumentation theory;accessibility relation;logic;multimodal logic;algorithm;philosophy of logic	AI	-16.424057090912846	5.994919870981605	190117
c89494e13406235270b4185b2be6ac61a2c0bb6f	processing inconsistency of knowledge on semantic level	distributed environment;intelligent system;consensus problem	Inconsistency of knowledge may appear in many situations, especially in distributed environments in which autonomous programs operate. Inconsistency may lead to conflicts, for which the resolution is necessary for correct functioning of an intelligent system. Inconsistency of knowledge in general means a situation in which some autonomous programs (like agents) generate different versions (or states) of knowledge on the same subject referring to a real world. In this paper we propose two logical structures for representing inconsistent knowledge: conjunction and disjunction. For each of them we define the semantics and formulate the consensus problem, the solution of which would resolve the inconsistency. Next, we work out algorithms for consensus determination. Consensus methodology has been proved to be useful in solving conflicts and should be also effective for knowledge inconsistency resolution.	algorithm;artificial intelligence;autonomous robot;consensus (computer science);intelligent agent;resolution (logic);software agent	Ngoc Thanh Nguyen	2005	J. UCS	10.3217/jucs-011-02-0285	consensus;computer science;knowledge management;artificial intelligence;data mining;distributed computing environment	AI	-18.27304562185898	5.5691240032571985	190472
f3dee864560e6c4813c6ee2449a5610f227e9b9f	an argumentation system for reasoning with lpm		Inconsistent knowledge-bases can entail useful conclusions when using the three-valued semantics of the paraconsistent logic LP. However, the set of conclusions entailed by a consistent knowledge-base under the three-valued semantics is smaller than set of conclusions entailed by the knowledge-base under a two-valued semantics. Preferring conflict-minimal interpretations of the logic LP; i.e., LPm, reduces the gap between these two sets of conclusions. Preferring conflict-minimal interpretations introduces nonmonotonicity. To handle the non-monotonicity, this paper proposes an assumption-based argumentation system. Assumptions needed to close branches of a semantic tableaux form the arguments. Stable extensions of the set of derived arguments correspond to conflict minimal interpretations and conclusions entailed by all conflict-minimal interpretations are supported by arguments in all stable extensions.	consistency (knowledge bases);longest prefix match;method of analytic tableaux;paraconsistent logic	Wenzhao Qiao;Nico Roos	2014		10.3233/978-1-61499-419-0-753	algorithm	AI	-16.664724632772682	7.642123865293433	190531
83aa8265e2e7b8f7619cdebe9cda64db1c7803f4	notes on ginsberg's multivalued logics	commonsense reasoning;representacion conocimientos;representation des connaissances;raisonnement non monotone;logica multivalente;circonscription;demonstration de theoremes;intelligence artificielle;raisonnement;circumscription;multivalued logics;theorem proving;logique multivalente;nonmonotonic reasoning;logique par defaut;razonamiento;non classical logics;artificial intelligence;inteligencia artificial;reasoning;knowledge representation;multivalued logic;raisonnement de sens commun;representation connaissances;circonscripcion;raisonnement sense commun;logique non classique	The use of multivalued logics for knowledge representation and nonmonotonic reasoning has often been advocated, in particular within the general framework proposed by Ginsberg in his paper “Multivalued logics: a uniform approach to reasoning in artificial intelligence.” His system is based on a multivalued logic with an arbitrary number of truth values classified with respect to two partial orders, a truth order and a knowledge order. This classification is very interesting and gives an intuitive appeal to the framework. In this paper the work by Ginsberg is critically reviewed, pointing out some flaws and ways to overcome them. Moreover, we present some ideas on how to modify the original schema in order to obtain a more semantically well-founded framework.#R##N##R##N##R##N##R##N#L'utilisation de la Iogique multivalente pour la representation des connaissances et le raisonnement non monotone a souvent ete preconisee, en particulier a l'interieur du cadre general propose par Ginsberg dans son article intitule? Multivalued logics: a uniform approach to reasoning in artificial intelligence ? Son systeme est base sur une logique multivalente comportant un nombre arbitraire de valeurs de verite classees selon deux ordres partiels: un ordre de verite et un ordre de connaissances. Cette classification est tres interessante et donne un attrait intuitif au cadre. Dans cet article, l'auteur examine le travail de Ginsberg, y releve des lacunes et propose des moyens de les corriger. De plus, il expose certaines idees en vue de modifier le schema original et ainsi obtenir un meilleur cadre du point de vue de la semantique.	description logic	Marco Schaerf	1991	Computational Intelligence	10.1111/j.1467-8640.1991.tb00390.x	knowledge representation and reasoning;commonsense reasoning;computer science;artificial intelligence;non-monotonic logic;automated theorem proving;circumscription;reason;algorithm	AI	-13.488085357209888	9.689173869806499	191362
5d8bf36fbf0396f0c1b5c3a114085be3d819ccef	an information-based theory of conditionals	cognitive science;conditional logic;formal semantics;information flow;natural language;knowledge representation;situation semantics;possible worlds;information theory	We present an approach to combining three areas of research which we claim are all based on information theory: knowledge representation in Artificial Intelligence and Cognitive Science using prototypes, plans, or schemata; formal semantics in natural language, especially the semantics of the ‘if-then’ conditional construct; and the logic of subjunctive conditionals first developed using a possible worlds semantics by Stalnaker and Lewis. The basic premise of the paper is that both schema-based inference and the semantics of conditionals are based on Dretske’s notion of information flow and Barwise and Perry’s notion of a constraint in situation semantics. That is, the connection between antecedent A and consequent B of a conditional ‘if A were the case then B would be the case’ is an informational relation holding with respect to a pragmatically determined utterance situation. The bridge between AI and conditional logic is that a prototype or planning schema represents a situation type, and the background assumptions underlying the application of a schema in a situation correspond to channel conditions on the flow of information. Adapting the work of Stalnaker and Lewis, the semantics of conditionals is modeled by a refinement ordering on situations: a conditional ‘if A then B’ holds with respect to a situation if all the minimal refinements of the situation that support A also support B. We present new logics of situations, information flow, and subjunctive conditionals based on three-valued partial logic that formalizes our approach, and conclude with a discussion of the resulting theory of conditionals, including the “paradoxes” of conditional implication, the difference between truth conditions and assertability conditions for subjunctive conditionals, and the relationship between subjunctive and indicative conditionals. 1. Information Flow and Schema-Based Inference The aim of this paper is to combine three strands of research, in artificial intelligence, semantics, and logic. One basic question concerns the semantics of schemata or other Received November 27, 2000; printed August 30, 2002 2001 Mathematics Subject Classification: Primary, 68T27	artificial intelligence;cognitive science;conditional (computer programming);counterfactual conditional;database schema;information flow;information theory;knowledge representation and reasoning;mathematics subject classification;natural language;possible world;printing;prototype;refinement (computing);semantics (computer science)	Wayne Wobcke	2000	Notre Dame Journal of Formal Logic	10.1305/ndjfl/1038234607	natural language processing;information flow;formal semantics;formal science;action semantics;epistemology;information theory;game semantics;theoretical computer science;formal semantics;mathematics;linguistics;possible world;natural language;well-founded semantics;operational semantics;denotational semantics;cognitive semantics;algorithm;computational semantics	AI	-15.842104885748848	6.6668959638572165	191442
f23fe055599e530ea98b140d812c45ac7951918e	conversational inferences: the hard way and the easy way	conversational inferences;relrevance;the cooperative principle;conversational implicature;rationality;conversational maxims	This paper proposes a general theory of conversational inferences which distinguishes two kinds of inferences: the hard way and the easy way. The theory accounts for a wider range of non-literal utterance meanings than Gricean and relevance theories and is motivated by the types of utterances in which the hearer fails to infer non-	assertion (software development);failure;literal (mathematical logic);relevance;retry;theory;type physicalism;web accessibility	Yukiko Kawaguchi	2003			natural language processing;artificial intelligence;machine learning;computer science;utterance	NLP	-13.778802186746429	5.069169881898484	191679
c6dd72fbd2eb5d75941c8adca94c20f61fbeba98	a compositional semantics for focusing subjuncts	frame-based semantic formalism;semantics captures pragmatic subtlety;two-part representation;compositional semantics	A compositional semantics for focusing subjuncts-words such as only, even, and also--is developed from Rooth's theory of association with focus. By adapting the theory so that it can be expressed in terms of a frame-based semantic formalism, a semantics that is more computationally practical is arrived at. This semantics captures pragmatic subtleties by incorporating a two-part representation, and recognizes the contribution of intonation to meaning.	semantics (computer science)	Daniel Lyons;Graeme Hirst	1990			natural language processing;lexicology;formal semantics;computer science;formal semantics;linguistics;well-founded semantics;operational semantics;denotational semantics;computational semantics	NLP	-17.735012353135797	8.490252192928779	192130
e57b51a5b978aacc978410fa459d1588f76c598a	truth as an epistemic ideal	warrant;truth;wright;crispin;bepress selected works;crispin wright;logics;inquiry;cs peirce;intuitionistic logic;inquiry kripke semantics pierce c s superassertibility truth warrant wright crispin;peirce;c s;kripke semantics;logique;superassertibility	Several philosophers—including C. S. Peirce, William James, Hilary Putnam and Crispin Wright—have proposed various versions of the notion that truth is an epistemic ideal. More specifically, they have held that a proposition is true if and only if it can be fixedly warranted by human inquirers, given certain ideal epistemic conditions. This paper offers a general critique of that idea, modeling conceptions of ideality and fixed warrant within the semantics that Kripke developed for intuitionistic logic. It is shown that each of the two plausible notions of fixed warrant faces difficulties and that, moreover, “truth” defined in terms of either of them is distressingly dependent upon one’s conception of idealized inquiry and perhaps also upon one’s standards of warrant.		John Nolt	2008	J. Philosophical Logic	10.1007/s10992-007-9068-9	philosophy;epistemology;intuitionistic logic;inquiry;mathematics;kripke semantics;algorithm	AI	-12.660715030447216	4.204747872344171	192314
5e8c8c954b95933c30f40f13aef354d591b70a15	complete assumption labellings		Recently, argument labellings have been proposed as a new (equivalent) way to express the extension semantics of Abstract Argumentation (AA) frameworks. Here, we introduce a labelling approach for the complete semantics in Assumption-Based Argumentation (ABA), where labels are assigned to assumptions rather than whole arguments. We prove that the complete assumption labelling corresponds to the complete extension semantics in ABA, as well as to the complete extension semantics and the complete argument labelling in AA.	aba problem;algorithm;graph labeling;qp state machine frameworks	Claudia Schulz;Francesca Toni	2014		10.3233/978-1-61499-436-7-405	natural language processing;argumentation theory;labelling;artificial intelligence;discrete mathematics;semantics;computer science	AI	-15.150811840936248	10.561319854466522	192660
111296e0d2208faf0b0123dc24d6be796fd0ae4f	preservation of obligations in a temporal and deontic framework	temporal logic;satisfiability;product;deontic logic	We study logical properties that concern the preservation of future-directed obligations that have not been fulfilled yet. Our starting point is a product of temporal and deontic logics. We investigate some modifications of the semantics of the product in order to satisfy preservation properties, without loosing too much of the basic properties of the product. We arrive at a semantics in which we only consider ideal histories that share the same past as the current one, and that enables a characterization of the states in which the obligations propagate. These are the states where any obligation of a formula that concerns the present moment is not violated. When there are such violations, the deontic realm switches to a lower level of ideality.	deontic logic;network switch	Jan M. Broersen;Julien Brunel	2007		10.1145/1329125.1329339	product;temporal logic;computer science;artificial intelligence;deontic logic;algorithm;satisfiability	Logic	-17.177680270521936	6.764451235536371	192926
65fa801c9b5510e9d49db1aca515b4c0e01a64f7	ai*ia 99: advances in artificial intelligence		Logical approaches to nonmonotonic reasoning have been developed within di erent technical settings thus making it di cult to establish correspondences among them and to identify common under lying principles In this paper we argue that the most well known non monotonic reasoning formalisms are actually characterized by two closure assumptions a minimal knowledge assumption and an autoepistemic as sumption We justify this thesis by introducing generalized default logic GDL obtained through a simple and natural generalization of Reit er s default logic which fully captures both closure assumptions We then analyze the relationship between GDL and nonmonotonic modal logics in particular Moore s autoepistemic logic and Lifschitz s logic of minimal knowledge and negation as failure showing the existence of a full correspondence between these modal formalisms and GDL Such a correspondence gives us a uni ed reading of nonmonotonic reasoning for malisms in terms of the above two assumptions in particular it clari es the relationship between default and autoepistemic logic	artificial intelligence;autoepistemic logic;default logic;fuzzy logic;modal logic;negation as failure;non-monotonic logic	Evelina Lamma;Paola Mello	2000		10.1007/3-540-46238-4	artificial intelligence;computer science	AI	-15.588406673799232	7.343382438764619	193289
8bc178ec15623bbef25bb361b0b32fe04759180a	modelling phenomena and dynamic logic of phenomena	field theory;uncertain reasoning;complex phenomena;model generation;dynamic logic;computational complexity;model uncertainty;theory change;model simplicity;polynomial models;similarity measure;model generality	Modeling a complex phenomenon such as the mind presents tremendous computational complexity challenges. Modeling field theory (MFT) addresses these challenges in a non-traditional way. The main idea behind MFT is to match levels of uncertainty of the model (also, a problem or some theory) with levels of uncertainty of the evaluation criterion used to identify that model. When a model becomes more certain, then the evaluation criterion is adjusted dynamically to match that change to the model. This process is called the Dynamic Logic of Phenomena (DLP) for model construction and it mimics processes of the mind and natural evolution. This paper provides a formal description of DLP by specifying its syntax, semantics, and reasoning system. We also outline links between DLP and other logical approaches. Computational complexity issues that motivate this work are presented using an example of polynomial models.	agent-based model;algorithm;cognition;cognitive model;cognitive science;computation;computational complexity theory;computer program;data mining;decision problem;deep linking;digital light processing;dynamic logic (modal logic);first-order logic;first-order predicate;humans;lazy evaluation;leonid perlovsky;machine learning;mathematical model;mathematical optimization;media foundation;pattern recognition;polynomial;process modeling;quantum field theory;reasoning system;monotone	Boris Kovalerchuk;Leonid I. Perlovsky;Gregory R. Wheeler	2012	Journal of Applied Non-Classical Logics	10.1080/11663081.2012.682439	dynamic logic;epistemology;computer science;artificial intelligence;machine learning;mathematics;field theory;computational complexity theory;algorithm;descriptive complexity theory	AI	-18.170993814993462	5.461043766290611	193381
37cf7c68c982027c1f1fe171467f4c16526ae44b	a general recursive schema for argumentation semantics		In argumentation theory, Dung’s abstract framework provides a unifying view of several alternative semantics based on the notion of extension. Recently, a new semantics has been introduced to solve the problems related to counterintuitive results produced by literature proposals. In this semantics, an important role is played by a recursive schema in the definition of extensions. This paper proves that all the semantics encompassed by Dung’s framework adhere to this property, not previously considered in the literature, which we call SCC-recursiveness . We argue that this notion plays a general role in the definition and computation of argumentation semantics.	computation;operational semantics;recursion (computer science);scc compliant	Pietro Baroni;Massimiliano Giacomin	2004			action semantics;theoretical computer science;formal semantics;well-founded semantics;operational semantics;denotational semantics;algorithm;computational semantics	AI	-16.22783798345655	5.802800554680582	193620
9e36506e18254122df7c21483dc359eb4d499cb1	tableau-based revision in shiq		Introduction The problem of revising a description logic-based ontology (called DL ontology) is closely related to the problem of belief revision which has been widely discussed in the literature. Among early works on belief revision, the AGM theory (Alchourrón et al., 1985) introduced intuitive and plausible constraints (namely AGM postulates) which should be satisfied by any rational belief revision operator. However, it is not trivial to adapt belief revision operators to DLs because DLs have their own features (Flouris et al., 2005) (Qi and Yang, 2008). One main difficult for such revision is that DL ontologies often incur infinitely many models. To address this issue, we propose a finite set of finite structures, namely a set MT(O) of completion trees, for characterizing a possibly infinite set of models of an ontology O. Then, we define a distance over a set of completion trees. This distance allows one to determine how far an ontology is from another one. Another problem our approach has to address is that there may not exist a revision ontology such that (i) it is expressible in the logic used for expressing initial ontologiesO,O′, and (ii) it admits exactly a set of models MT(O,O′) computed from MT(O) and MT(O′). For this reason, we borrow the notion of maximal approximation (De Giacomo et al., 2007) which allows us to build a minimal revision ontology admitting MT(O,O′). Construction of the revision ontology First, we define a novel tableau algorithm, namely TA, for a SHIQ ontology without individuals by replacing expansion v-, u-, t, ch-rules by a new rule, namely sat-rule which chooses a subset S from a set sub(O) including all sub-concepts of a SHIQ ontology O. Note that all concepts in the form of conjunctions or of disjunctions are removed from sub(O) and replaced with their conjuncts and disjuncts. This can be performed by a function Flat(C) that flattens conjunctions and disjunctions of a concept C into subsets of sub-concepts occurring in C. For example, Flat(A u (∃R.B t C)) = {{A,∃R.B}, {A,C}}. sat-rule. If sat-rule has never been applied to a node x then we choose a subset S ⊆ sub(O) such that L(x) ∪ ⋃	algorithm;approximation;belief revision;boolean satisfiability problem;description logic;maximal set;method of analytic tableaux;ontology (information science);yang	Thinh Dong;Chan Le Duc;Philippe Bonnot;Myriam Lamolle	2015			operator (computer programming);belief revision;description logic;discrete mathematics;infinite set;ontology (information science);ontology;mathematics;finite set	AI	-16.989719782444407	10.93637385930055	194222
717a58deed4a70dd2ef30e34de5095e2b9b4af7e	the carneades model of argument and burden of proof	argument structure;modelizacion;argumentacion;systems;argumentation;formal specification;argument graphs;logic;semantics;legal argument;burden of proof;intelligence artificielle;dialogue;specification formelle;modelisation;especificacion formal;proof standards;argument evaluation;games;mathematical model;artificial intelligence;argumentation schemes;inteligencia artificial;modeling	We present a formal, mathematical model of argument structure and evaluation, taking seriously the procedural and dialogical aspects of argumentation. The model applies proof standards to determine the acceptability of statements on an issue-by-issue basis. The model uses different types of premises (ordinary premises, assumptions and exceptions) and information about the dialectical status of statements (stated, questioned, accepted or rejected) to allow the burden of proof to be allocated to the proponent or the respondent, as appropriate, for each premise separately. Our approach allows the burden of proof for a premise to be assigned to a different party than the one who has the burden of proving the conclusion of the argument, and also to change the burden of proof or applicable proof standard as the dialogue progresses from stage to stage. Useful for modeling legal dialogues, the burden of production and burden of persuasion can be handled separately, with a different responsible party and applicable proof standard for each. Carneades enables critical questions of argumentation schemes to be modeled as additional premises, using premise types to capture the varying effect on the burden of proof of different kinds of questions.	application domain;computable function;diagram;exception handling;experiment;formal system;functional programming;mathematical model;programming language;scheme;test case	Thomas F. Gordon;Henry Prakken;Douglas Walton	2007	Artif. Intell.	10.1016/j.artint.2007.04.010	games;computer science;artificial intelligence;mathematical model;formal specification;mathematics;semantics;logic;algorithm;statistical proof	NLP	-14.820488215432936	4.212444587752841	194597
de0a31aa111ea41bd887551ebd946fc79180c5e3	propositions, propositional attitudes and belief revision	belief revision;communication theory	In this paper I will propose a new approach to certain semantic puzzles due to Frege, Kripke and others, and the question of propositional attitudes, via the notion of belief revision. The principal logical tool used for setting up the solution is the notion an individual theory. I shall suppose that each individual has his or her own theory consisting of the sentences the individual accepts. It is this theory, which together with the individual’s preferences leads to a choice of some actions over others; it is this theory out of which the individual communicates; and it is this theory which is revised when a communication, in the form of a sentence uttered by another, is heard or otherwise received. The theory may also be revised as a result of an experience with the “world” as might happen when someone without an umbrella gets wet and adds “It is raining” to his theory. There is also a community theory Tc which consists of sentences which we all accept and which, in the varous puzzles, has a different notion of possibility from that of the individual’s theory. Thus there is conflict between these two theories not only about what is true or what is known, but even about what is possible. It turns out that most of the puzzles considered in the literature are puzzles about reconciling these two theories. A crucial aspect of this way of looking at the puzzles is that the central role of truth conditions as the determinants of meaning is rejected and more flexible, purely syntactic tools are used. It will be argued that the truth theoretic view of meaning is not an adquate tool for semantics, and abandoning it makes the problems much more amenable. This need not imply abandoning truth, but merely dethroning it from its central role as a foundation for semantics. ∗Research supported by grants from NSF and CUNY-FRAP program. I thank Jonathan Adler, Samir Chopra, Arthur Collins, Horacio Arlo Costa, Dov Gabbay, Wolfram Hinzen, Richard Mendelson, Josephine Papst, Robert Stainton and Claudine Verheggen for helpful comments.	belief revision;fraps;frege;ibm notes;theory	Rohit Parikh	1998			belief revision;algorithm;communication theory;artificial intelligence;mathematics	AI	-12.592088596981819	4.202424949724325	195126
28038ec6dd7ee83dd86d168b681eab81600d7cb4	argumentation-based abduction in disjunctive logic programming	pre2009 other artificial intelligence;institute for integrated and intelligent systems;incomplete information;faculty of engineering and information technology;280213;disjunctive logic programming	In this paper we propose an argumentation-based semantic framework , called DAS, for disjunctive logic programming. The basic idea is to translate a disjunctive logic program into an argumentation-theoretic framework. One unique feature of our proposed framework is to consider the disjunctions of negative literals as possible assumptions so as to represent incomplete information. In our framework, three semantics PDH, CDH and WFDH are deened by three kinds of acceptable hypotheses to represent credulous, moderate and skeptical reasoning in AI, respectively. Further more, our semantic framework can be extended to a wider class than that of disjunctive programs (called bi-disjunctive logic programs). In addition to being a rst serious attempt of establishing an argumentation-theoretic framework for disjunctive logic programming, DAS integrates and naturally extends many key semantics, such as the minimal models, EGCWA, the well-founded model, and the disjunctive stable models. In particular , novel and interesting argumentation-theoretic characterizations of the EGCWA and the disjunctive stable semantics are shown. Thus the framework presented in this paper does not only provide a new way of performing argumentation (abduction) in disjunctive deductive databases, but also is a simple, intuitive and unifying semantic framework for disjunctive logic programming.	abductive reasoning;computational diffie–hellman assumption;deductive database;disjunctive normal form;logic programming;theory;well-founded semantics;whole earth 'lectronic link	Kewen Wang	2000	J. Log. Program.	10.1016/S0743-1066(00)00004-2	stable model semantics;artificial intelligence;theoretical computer science;mathematics;disjunctive syllogism;disjunctive normal form;complete information;algorithm	AI	-17.382767298843838	10.36614490020147	195189
04f65d5ada3014b12df428b8c9ffd6a09eb11bac	a general framework for expressing preferences in causal reasoning and planning	query language;logical representations of preferences;maximal element;causal reasoning;satisfiability;second language;transition systems;binary relation;planning;knowledge representation;preferences	We consider the problem of incorporating arbitrary preferences in planning systems. A preference may be seen as a goal or constraint that is desirable, but not necessary, to satisfy. We work within the context of transition systems; however, our results are applicable to general planning formalisms. To begin, we define a query language for specifying arbitrary conditions that may be satisfied by a history, or interleaved sequence of world states and actions. Given this, we specify a second language in which preferences are defined. A single preference defines a binary relation on histories, so that in an ordered pair of histories the second history is preferred to the first. From this, one can define global preference orderings on the set of histories, the maximal elements of which are the preferred histories. The approach is very general and flexible; thus it constitutes a “base” language in terms of which higher-level operators may be defined. The approach can be used to express others, and so serves as a common basis in which such approaches can be expressed and compared.	automated planning and scheduling;causal filter;maximal set;ordered pair;query language;semantics (computer science);transition system;wasp	James P. Delgrande;Torsten Schaub;Hans Tompits	2007	J. Log. Comput.	10.1093/logcom/exm046	planning;knowledge representation and reasoning;maximal element;causal reasoning;computer science;artificial intelligence;binary relation;mathematics;algorithm;query language;satisfiability	AI	-17.202039106973096	9.00005785510373	196199
3e8cd4ae450bd55f42b37284d69c6fa6f918065c	hierarchic reasoning in local theory extensions	theorie locale;theorie type;local theory;automatic proving;tipo dato;intelligence artificielle;demostracion automatica;logical programming;data type;demonstration automatique;programmation logique;type theory;artificial intelligence;decidibilidad;inteligencia artificial;teoria local;type donnee;decidabilite;programacion logica;deduccion;decidability;deduction	We show that for special types of extensions of a base theory, which we call local, efficient hierarchic reasoning is possible. We identify situations in which it is possible, for an extension T1 of a theory T0, to express the decidability and complexity of the universal theory of T1 in terms of the decidability resp. complexity of suitable fragments of the theory T0 (universal or ∀∃). These results apply to theories related to data types, but also to certain theories of functions from mathematics.	principle of locality;theory	Viorica Sofronie-Stokkermans	2005		10.1007/11532231_16	decidability;discrete mathematics;data type;computer science;artificial intelligence;mathematics;programming language;type theory;algorithm	Logic	-17.013208646916183	11.213403486433487	196547
5083511d5cfc110d6a7ff7b2cb3924e340b515d4	a measure-free approach to conditioning	syntax;probability;variables;logic;semantics;mathematical logic;fuzzy sets;boolean algebra;test and evaluation;diagnosis general;algebra;theory;operators personnel;statistical inference;motivation;reprints;knowledge based systems	"""In an earlier paper, a new theory of measurefree""""conditional""""objects was presented. In this paper, emphasis is placed upon the motivation of the theory. The central part of this motivation is established through an example involving a knowledge-based system. In order to evaluate combination of evidence for this system, using observed data, auxiliary at tribute and diagnosis variables, and inference rules connecting them, one must first choose an appropriate algebraic logic description pair (ALDP): a formal language or syntax followed by a compatible logic or semantic evaluation (or model). Three common choices- for this highly non-unique choice - are briefly discussed, the logics being Classical Logic, Fuzzy Logic, and Probability Logic. In all three,the key operator representing implication for the inference rules is interpreted as the often-used disjunction of a negation (b =>a) = (b'v a), for any events a,b. However, another reasonable interpretation of the implication operator is through the familiar form of probabilistic conditioning. But, it can be shown - quite surprisingly - that the ALDP corresponding to Probability Logic cannot be used as a rigorous basis for this interpretation! To fill this gap, a new ALDP is constructed consisting of""""conditional objects"""", extending ordinary Probability Logic, and compatible with the desired conditional probability interpretation of inference rules. It is shown also that this choice of ALDP leads to feasible computations for the combination of evidence evaluation in the example. In addition, a number of basic properties of conditional objects and the resulting Conditional Probability Logic are given, including a characterization property and a developed calculus of relations."""	computation;formal language;fuzzy logic;knowledge-based systems;linear algebra	I. R. Goodman	1988	Int. J. Approx. Reasoning		predicate logic;fuzzy logic;variables;zeroth-order logic;complete theory;boolean algebra;statistical inference;mathematical logic;discrete mathematics;description logic;motivation;higher-order logic;syntax;algebraic sentence;many-valued logic;intuitionistic logic;computer science;artificial intelligence;bunched logic;non-monotonic logic;predicate functor logic;machine learning;probability;mathematics;semantics;proof calculus;signature;probabilistic logic network;logic;substructural logic;multimodal logic;theory;algorithm;statistics;rule of inference;autoepistemic logic	AI	-14.677715829443741	10.028543979798036	196655
aba100b64536415b83c6550fe93f388a1528f8f0	issues in designing logical models for norm change	formal model;deontic logic;formal logic	The aim of this paper is to raise awareness of some issues in designing (formal) models for norm change. I start by positioning this research in a broader context. Then I will briefly recall several concepts and problems from deontic logic, which is the field primarily concerned with notions like `norm', `obligation', `right', etc. Then I proceed with what I regard the main contribution of the paper: the distinction of four categories of problems one faces when thinking about formal logical models for norm change.		Jan M. Broersen	2008		10.1007/978-3-642-02377-4_1	artificial intelligence;deontic logic;mathematics;algorithm;philosophy of logic	NLP	-14.529003895663609	4.216540245101009	196808
b29eeffc9ebb404805036cfcf037776894271f31	resource-adaptive model generation as a performance model	model generation;natural language understanding;language processing;performance model;cost estimation;optimization model	Model generation calculi, close relatives of tableau calculi for theorem proving, can be used as competence models for semantic natural language understanding. Unfortunately, existing model generation calculi are not yet plausible as performance models of actual human processing, since they fail to capture computational aspects of human language processing. We outline an extended model generation calculus that solves the most unpleasant computational inadequacy; In the extended calculus, tableau expansion rules are equipped with costs, and model construction is a process that optimizes model quality under resource constraints with respect to these costs. We embed the new calculus into an abstract inference machine and illustrate the possibilities of this approach by presenting a partial theory of definite descriptions in this setting. In this case study, the constants in the universe are given saliences, that are maintained across the model generation process. This additional data serves as one important source of information for model quality and resource cost estimation.	automated theorem proving;computation;information source;method of analytic tableaux;natural language understanding	Michael Kohlhase;Alexander Koller	2003	Logic Journal of the IGPL	10.1093/jigpal/11.4.435	natural language processing;speech recognition;machine learning;cost estimate	AI	-18.596320468761125	8.559359308596054	196995
75b6f4923c9c4d3163ae4739596aef6628d97f61	paraconsistent analytic implication			paraconsistent logic	Harry Deutsch	1984	J. Philosophical Logic	10.1007/BF00297573	discrete mathematics;mathematics	Logic	-12.207694449852976	11.16292779745449	197083
0f508e61079487f17d7e87c1f4577686c75d64fb	on the bipolarity in argumentation frameworks		In this paper, we propose a survey of the use of bipolarity in argumentation frameworks, i.e. the presence of two kinds of entities (a positive entity and a negative entity). An argumentation process follows three steps: building the arguments and the interactions between them, valuating the arguments using or not the interactions and finally defining the acceptability of the arguments. This paper shows on various applications and with some formal definitions that bipolarity appears (in some cases since always) and can be used in each step of this process under different forms.	argumentation framework;entity;gene ontology term enrichment;interaction;knowledge representation and reasoning;os-tan;word lists by frequency	Leila Amgoud;Claudette Cayrol;Marie-Christine Lagasquie-Schiex	2004		10.1002/int.20307	machine learning;argumentation theory;natural language processing;artificial intelligence;computer science	AI	-16.485522106737807	4.605365868175193	197362
2340b5a851534176fa05f48d1d8f851aca2d8bd0	knowledge and social laws	multi agent system;alternating time temporal epistemic logic;knowledge;social laws;model checking;epistemic logic;alternating time temporal logic	In this paper we combine existing work in the area of social laws with a framework for reasoning about knowledge in multi-agent systems. The unifying framework in which this is done is based on Alternating-time Temporal Logic (ATL), to which semantics we add epistemic accessibility relations (to deal with the knowledge), actions (in order to naturally talk about allowed and forbidden actions) and updates (to model the effect of the implementation of the constraint in a social law). Apart from a constraint, a social law has an objective: in our formalism, such objectives may refer to the knowledge that agents possess or do not possess. The result is a framework in which we can, for example, express that a desirable property (objective) of a social law is that one agent has the ability to bring about a certain type of knowledge in another agent, or that if one agent knows something, then it should behave in a certain way. We illustrate our approach with a case study, and we use model checking to demonstrate that properties of social laws with respect to this case study.	accessibility;alternating-time temporal logic;intelligent agent;model checking;multi-agent system;semantics (computer science)	Wiebe van der Hoek;Mark Roberts;Michael Wooldridge	2005		10.1145/1082473.1082576	model checking;computer science;knowledge management;artificial intelligence;multi-agent system;knowledge;algorithm	AI	-17.002428737380313	5.4707464929944924	197614
bec1b49f4bda326ede07e5ce81c0e5931c37472c	the nature of information: a relevant approach	proof theory;logic;theorie de l information;semantics;relevant logic;semantique;logique philosophique;theorie des modeles;sciences de l information;logique relevante;philosophical logic;information;information sciences;information theory;logique;logica;model theory	In “General Information in Relevant Logic” (Synthese 167, 2009), the semantics for relevant logic is interpreted in terms of objective information. Objective information is potential data that is available in an environment. This paper explores the notion of objective information further. The concept of availability in an environment is developed and used as a foundation for the semantics, in particular, as a basis for the understanding of the information that is expressed by relevant implication. It is also used to understand the nature of misinformation. A form of relevant logic—called “LOI” for “logic of objective information”—is presented and the relationship between the justification of its proof theory and the semantics is discussed. This relationship is rather reciprocal. Intuitive features of the logic are used to interpret and justify aspects of the model theory and intuitive aspects of the model theory are used to interpret and justify features of the logic. Information conditions are presented for the connectives and the way that they fit into the theory of information is discussed.	caret;dynamic epistemic logic;epistemic modal logic;feedback;information;linear logic;logical connective;situated;theory	Edwin D. Mares	2010	Synthese	10.1007/s11229-010-9737-z	information algebra;information;philosophy;epistemology;information theory;philosophical logic;proof theory;mathematics;semantics;logic;algorithm;model theory	AI	-14.84784852005503	5.950404497138799	197642
60bf5a3667155172fb5c9503bf32b08d471bd279	unified derivation of some linguistic laws (die vereinheitlichte ableitung linguistischer gesetze)				Gejza Wimmer;Gabriel Altmann	2005			calculus;derivation;mathematics	NLP	-12.434519540682222	10.443004651876231	197800
ccf0e303eada78795649bd9edd589e66c57c0565	recognizing unnecessary inference	automated reasoning	Intell igent reasoners sometimes draw conclusions that lack new or relevant information. Similarly, automated reasoning systems can produce formulas that are not necessary for the problem at hand. We concentrate on the problem of unnecessary inference in the context of resolution based systems. In such systems several strategies have been developed that allow for the deletion of clauses wi thout sacrificing completeness. Unfortunately these strategies fai l to recognize other frequently generated unnecessary formulas. We wi l l present a generalized subsumption theorem that can be used to recognize such formulas and to develop new deletion methods which retain completeness. 1 I n t r o d u c t i o n Intell igent reasoners expend much effort deciding what information is necessary for the problem at hand. When a conclusion is drawn we decide if it contains new and relevant information. It is well known that the performance of automated reasoning systems can be enhanced by el iminat ing unnecessary formulas. In such systems conclusions drawn from unnecessary formulas are also unnecessary. Failure to prevent the generation of these formulas can lead to rapid combinatorial explosion [Wos, 1988]. In this paper we concentrate on the problem of recognit ion of unnecessary formulas in the context of resolut ion based systems. In such systems several strategies have been developed that allow for the deletion of clauses wi thout sacrificing completeness. Common strategies include subsumption, tautology el imination, and demodulat ion. The subsumption strategy eliminates clauses that are instances of other clauses. The demodulation strategy pertains to clauses containing the equality predicate. Using this strategy demodulators are used to rewrite clauses that are subsequently deleted. Unfortunately these strategies fail to recognize other frequently generated unnecessary formulas. A less obvious way in which resolution based systems produce unnecessary formulas is related to skolemization. Skolem functions have the effect of automatically creating names for new objects, but sometimes too many names are creThe main result discussed here can be viewed as a generalization of subsumption. This result can be used to develop new deletion methods and to show that these methods do not sacrifice completeness. Using deletion methods we have developed, we were able to prove certain theorems from Hilbert 's axioms for geometry. These theorems present a significant challenge to automated systems due to the constructive nature of the proofs. For a discusion of these theorems see [Benanav, 1988]. In section 2 we discuss an example that illustrates a subtle way in which resolution systems generate unnecessary formulas and present informal arguments as to why these formulas are unnecessary. In later sections we define more precisely what we mean by unnecessary clauses and how to recognize them. 2 The Naming Problem In mathematical arguments one often sees inferences that assert the existence of some object and give it a name. Subsequently, other inferences are made that refer to the object by this name. This process is so natural 366 Automated Deduction	automated reasoning;automated theorem proving;hilbert space;natural deduction;reasoning system;resolution (logic);rewrite (programming);semantic reasoner;skolem normal form;subsumption architecture	Dan Benanav	1989			discrete mathematics;computer science;artificial intelligence;mathematics;automated reasoning;algorithm	AI	-16.47467687370603	10.87691580943705	198210
6b4a25b55a32d9b0980c6ebce4d1c61698d3f7fd	on the application of the disjunctive syllogism in paraconsistent logics based on four states of information	quasi classical;four valued logics;paraconsistent reasoning;paraconsistent logic	We identify three classes of four-state paraconsistent logics according to their different approaches towards the disjunctive syllogism, and investigate three representatives of these approaches: Quasiclassical logic, which always accepts this principle, Belnap’s logic, that rejects the disjunctive syllogism altogether, and a logic of inconsistency minimization that restricts its application to consistent fragments only. These logics are defined in a syntactic and a semantic style, which are linked by a simple transformation. It is shown that the three formalisms accommodate knowledge minimization, and that the most liberal formalism towards the disjunctive syllogism is also the strongest among the three, while the most cautious logic is the weakest one.	decision problem;description logic;disjunctive normal form;information;paraconsistent logic;resolution (logic);semantics (computer science)	Ofer Arieli	2010			principle of explosion;paraconsistent logic;hypothetical syllogism;polysyllogism;disjunctive syllogism;algorithm	AI	-15.85993645692753	7.690147490066608	198228
53b909eed06abedc81ef1fa921245c1b9f93c4c3	concerning some proposals for quantum logic	quantum logic		quantum logic	C. W. Leininger	1969	Notre Dame Journal of Formal Logic	10.1305/ndjfl/1093893590	quantum logic;mathematics	Theory	-11.896878130262476	10.926305697165798	198280
fdca9055271675d807559ab17897e6e9e1dd6149	a temporal extension to the parsimonious covering theory	abductive reasoning;theoretical foundation	 . In this work we propose a temporal extension to the ParsimoniousCovering Theory (PCT). PCT provides a theoretical foundation forthe diagnostic reasoning process as an abductive reasoning based associationsbetween causes with their consequences. Our temporal extensionof PCT allows one to associate to a disease a temporal evolution of itssymptoms.The elimination of temporally inconsistent hypotheses minimizes one ofthe greatest problems of PCT: the solution for a particular... 	covering space;occam's razor	Alexandre de Melo Rezende;Jacques Wainer	1996		10.1007/3-540-61859-7_21	abductive reasoning;computer science;artificial intelligence;machine learning;algorithm	NLP	-15.98179117975381	8.495648908692651	198378
8a8a09d0a9b6a3ec4fd11fa0e23bf729043e9670	a qualitative approach to face uncertainty in decision models	decision models;outranking relations;partial comparability;four valued logic;preference modeling	Abstract   Inaccurate determination, uncertainty, imprecision and ambiguity are often present in complex decision situations where decision aid is requested. Instead of reducing complexity via quantitative models of preferences, as traditional preference modeling does, it may be necessary to represent these situations explicitly. There exist operational methods that face these problems, the principal reference being the partial comparability theory. The lack of an axiomatization however limits the operational potentialities of this theory. In the paper an axiomatic foundation of the partial comparability theory is outlined based on a sound and complete four valued logic (the truth values “true”, “false”, “unknown”, “contradictory” are accepted). This logic is extended to the first order predicate calculus. Four basic preference relations are thus defined, namely: strict preference, weak preference, indifference and incomparability. The operational perspectives are discussed in the paper as some problems in multicriteria methods can be solved in a much easier and natural way. Moreover non monotonic reasoning devices could be built enhancing the potentialities of the theory.		Alexis Tsoukiàs	1994	Decision Support Systems	10.1016/0167-9236(94)90047-7	decision model;artificial intelligence;machine learning;welfare economics;algorithm	SE	-15.785128185844158	6.533580336230369	199020
683d68dcbcfd9ec440da77b975e55113001cb40d	logic programming with strong negation	logic programs	"""We show how a negation operation which allows for the possibility to represent explicit negative information can be added to Protog without essentially altering its computational structure. 1 Background and Aims In [Pearce & Wagner 1989] we have outlined a general approach to the representation and processing of negative information which we believe should have promising applications in AI. We also sketched there an application of our ideas to logic programming, by showing (for the propositional case) how standard Prolog ca~l be extended by adding strong negation. In this paper we elaborate further on our idea of logic programming with strong negation and generaiise our earlier results. According to the standard view, a togic program is a set of definite Horn clauses. Thus, logic programs are regarded as syntactically restricted first order theories within the framework of classical logic. Correspondingly, the proof-theory of logic programs is considered as the specialised version of classical resolution, known as SLD-resolution. This view, however, neglects the fact that a program clause, a0 eal, a2 , . . . , a~,, is an expression of a fragment of positive logic 1 rather than an implicational formula of classical logic. The elassieaI interpretation of logic programs, therefore, seems to be a semantical overkill. It should be clear that in order to explain the deduction mechanism of Prolog one does not have to refer to the indirect method of SLD-resolution which checks for the refutability of the contrary. It is certainly more natural to view"""" Prolog's proof procedure as a kind of naturM deduction, as, e.g., in [Hallngs & Sehroeder-Heister 1987] and [Miller 1989]. This also is more in line with the intuitions of a Prolog programmer. Since Prolog is the paradigm, logic programming semantics should take it as a point of departure. la subsystem of intuitionistic logic"""	computation;horn clause;intuitionistic logic;linear algebra;logic level;logic programming;natural deduction;programmer;programming paradigm;prolog;quantum information;sld resolution;stable model semantics;theory	David Pearce;Gerd Wagner	1989		10.1007/BFb0038700	dynamic logic;description logic;higher-order logic;horn clause;stable model semantics;many-valued logic;intuitionistic logic;negation as failure;intermediate logic;predicate functor logic;functional logic programming;computational logic;prolog;logic programming;substructural logic;multimodal logic;algorithm;philosophy of logic;autoepistemic logic	AI	-13.060932575129025	7.014147118752301	199422
