id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
24e3acb72799a360dfd8aa0b8ba25fa8d1c59ce6	a new stochastic optimization algorithm to decompose large nonnegative tensors	nonnegative tensor factorization ntf;stochastic optimization big data tensors candecomp parafac cp decomposition missing data multilinear algebra nonnegative tensor factorization ntf;tensile stress;tensile stress signal processing algorithms linear programming mathematical model optimization matrix decomposition big data;missing data handling nonnegative tensor decompositions iterative deterministic optimization algorithms data volume big data information extraction stochastic algorithm cp decomposition candecomp parafac decomposition huge nonnegative 3 way tensors;big data tensors;stochastic optimization;big data;matrix decomposition;linear programming;mathematical model;optimization;missing data;signal processing algorithms;multi linear algebra;candecomp parafac cp decomposi tion;tensors big data data handling iterative methods stochastic programming	In this letter, the problem of nonnegative tensor decompositions is addressed. Classically, this problem is carried out using iterative (either alternating or global) deterministic optimization algorithms. Here, a rather different stochastic approach is suggested. In addition, the ever-increasing volume of data requires the development of new and more efficient approaches to be able to process “Big data” tensors to extract relevant information. The stochastic algorithm outlined here comes within this framework. Both flexible and easy to implement, it is designed to solve the problem of the CP (Candecomp/Parafac) decomposition of huge nonnegative 3-way tensors while simultaneously enabling to handle possible missing data.	algorithm;big data;iterative method;mathematical optimization;missing data;stochastic optimization;stochastic process	Xuan Thanh Vu;Sylvain Maire;Caroline Chaux;Nadège Thirion-Moreau	2015	IEEE Signal Processing Letters	10.1109/LSP.2015.2427456	mathematical optimization;combinatorics;big data;missing data;linear programming;stochastic optimization;machine learning;mathematical model;mathematics;stress;matrix decomposition	Vision	78.76396281209989	-4.398024691654467	182617
0b2a5a485acb2646025f2692dc5e34bc7d663e30	on asymptotic incoherence and its implications for compressed sensing of inverse problems	compressed sensing;standards;wavelet transforms compressed sensing fourier transforms image sampling inverse problems polynomials signal sampling;coherence compressed sensing standards magnetic resonance imaging inverse problems sensors transforms;sensors;polynomial bases asymptotic incoherence compressed sensing inverse problems local incoherence optimal sampling strategy fourier sampling wavelet sparsity power law;magnetic resonance imaging;transforms;coherence;inverse problems;wavelet transforms compressed sensing fourier transforms nonuniform sampling polynomials	Recently, it has been shown that incoherence is an unrealistic assumption for compressed sensing when applied to many inverse problems. Instead, the key property that permits efficient recovery in such problems is the so-called local incoherence. Similarly, the standard notion of sparsity is also inadequate for many real-world problems. In particular, in many applications, the optimal sampling strategy depends on asymptotic incoherence and the signal sparsity structure. The purpose of this paper is to study asymptotic incoherence and its implications toward the design of optimal sampling strategies and efficient sparsity bases. How fast asymptotic incoherence can decay in general for isometries is determined. Furthermore, it is shown that Fourier sampling and wavelet sparsity, while globally coherent, yield optimal asymptotic incoherence as a power law up to a constant factor. Sharp bounds on the asymptotic incoherence for Fourier sampling with polynomial bases are also provided. A numerical experiment is also presented to demonstrate the role of asymptotic incoherence in finding good subsampling strategies.	asymptote;chroma subsampling;coherence (physics);compressed sensing;numerical analysis;polynomial;sampling (signal processing);sparse matrix;wavelet	Alexander Daniel Jones;Ben Adcock;Anders C. Hansen	2016	IEEE Transactions on Information Theory	10.1109/TIT.2015.2508562	mathematical optimization;combinatorics;mathematical analysis;coherence;inverse problem;sensor;magnetic resonance imaging;mathematics;compressed sensing	ML	80.67551187452392	-2.9088151570145877	186593
1f523baeab92b5d69f7d4c1a6ea18d37b8a305ab	new fast-ica algorithms for blind source separation without prewhitening	blind source separation;fast-ica;pre-whitening	This paper focuses on proposing a new fast-ICA algorithm without prewhitening. First, existing fast-ICA method is reviewed. then, by combing the separating vector in the existing fast-ICA algorithm with the prewhitening matrix, we propose a new separating vector, which is used to separate statistically independent component from the observed data without prewhitening. The iterative rule of new separating vector is developed. Finally, the effectiveness of this new algorithm is verified by computer simulations.	algorithm;blind signal separation;fastica;independent computing architecture;source separation	Jimin Ye;Ting Huang	2011		10.1007/978-3-642-23220-6_73	econometrics;speech recognition;computer science;statistics	ML	80.65131575257779	-7.187442464155999	187684
696ed97b752825320cf2e1ba15ea5467221c9d98	joint matrices decompositions and blind source separation: a survey of methods, identification, and applications	eigenvalues and eigenfunctions;context awareness;higher order statistics joint matrices decompositions blind source separation eigenvalue decomposition singular value decomposition svd evd signal processing spectral analysis principal component analysis dimensionality reduction independent component analysis pca ica covariance matrix time lagged covariance matrices quadratic spatial time frequency matrices;symmetric matrices;matrix decomposition;covariance matrices;principle component analysis;source separation covariance matrices independent component analysis principal component analysis singular value decomposition;symmetric matrices source separation matrix decomposition covariance matrices eigenvalues and eigenfunctions principle component analysis context awareness;source separation	Matrix decompositions such as the eigenvalue decomposition (EVD) or the singular value decomposition (SVD) have a long history in signal processing. They have been used in spectral analysis, signal/noise subspace estimation, principal component analysis (PCA), dimensionality reduction, and whitening in independent component analysis (ICA). Very often, the matrix under consideration is the covariance matrix of some observation signals. However, many other kinds of matrices can be encountered in signal processing problems, such as time-lagged covariance matrices, quadratic spatial time-frequency matrices [21], and matrices of higher-order statistics.	blind signal separation;dimensionality reduction;independent computing architecture;independent component analysis;noise (electronics);principal component analysis;signal processing;singular value decomposition;source separation;spectral density estimation;the matrix;whitening transformation	Gilles Chabriel;Martin Kleinsteuber;Eric Moreau;Hao Shen;Petr Tichavský;Arie Yeredor	2014	IEEE Signal Processing Magazine	10.1109/MSP.2014.2298045	estimation of covariance matrices;matrix analysis;econometrics;mathematical optimization;canonical correlation;matrix multiplication;mathematics;singular spectrum analysis;matrix decomposition;singular value decomposition;matrix;statistics;symmetric matrix;principal component analysis	ML	80.4906630069808	-8.167345921024395	187792
8bebced801decff71a1644e6519cd32066a967eb	analysis of source sparsity and recoverability for sca based blind source separation	traitement signal;analisis componente principal;separacion ciega;separation aveugle source;melangeage;blind source separation;probabilistic approach;sparse component analysis;blind separation;enfoque probabilista;approche probabiliste;signal processing;principal component analysis;separacion senal;analyse composante principale;separation aveugle;representacion parsimoniosa;separation source;mixing;source separation;sparse representation;procesamiento senal;mezclado;representation parcimonieuse	One (of) important application of sparse component analysis (SCA) is in underdetermined blind source separation (BSS). Within a probability framework, this paper focuses on recoverability problem of underdetermined BSS based on a two-stage SCA approach. We consider a general case in which both sources and mixing matrix are randomly drawn. First, we present a recoverability probability estimate under the condition that the nonzero entry number of a source column vector is fixed. Next, we define the sparsity degree of a signal, and establish the relationship between the sparsity degree of sources and recoverability probability. Finally, we explain how to use the relationship to guarantee the performance of BSS. Several simulation results have demonstrated the validity of the probability estimation approach.	blind signal separation;serializability;source separation;sparse matrix	Yuanqing Li;Andrzej Cichocki;Shun-ichi Amari;Cuntai Guan	2006		10.1007/11679363_103	econometrics;computer science;machine learning;signal processing;pattern recognition;sparse approximation;mathematics;blind signal separation;mixing;statistics;principal component analysis	AI	80.1377756349745	-8.642217392327437	188864
841570ab739f0fc643fab8127812605a38610c9d	single autoterms selection for blind source separation in time-frequency plane	blind source separation;time frequency	We address in this paper a method to perform blind separation of over-determined instantaneous linear mixtures of non-stationary sources. Our contribution is focused on the identification of single source autoterms which correspond to diagonal Spatial Time-Frequency Distribution of the sources vector with only one non-zero diagonal entry. These latter matrices are processed into an iterative joint-diagonalization scheme which provides an estimation of the mixing matrix.	blind signal separation;iterative method;major stationary source;source separation;stationary process	Ales Holobar;Cédric Févotte;Christian Doncarli;Damjan Zazula	2002	2002 11th European Signal Processing Conference		mathematical optimization;analytical chemistry;mathematics;blind signal separation;statistics	Vision	80.54383450241781	-8.032969527151439	189588
24c91026e99f78df8e605deaa3982e9cbefd2e17	estimating the mixing matrix in sparse component analysis (sca) based on partial k-dimensional subspace clustering	subspace fitting;sparse component analysis sca;blind source separation;sparse component analysis;linear model;subspace clustering;underdetermined blind source separation bss	One of the major problems in underdetermined Sparse Component Analysis (SCA) in the field of (semi) Blind Source Separation (BSS) is the appropriate estimation of the mixing matrix, A, in the linear model X=AS, especially where more than one source is active at each instant of time. Most existing algorithms require the restriction that at each instant (i.e. in each column of the source matrix S), there is at most one single dominant component. Moreover, these algorithms require that the number of sources must be determined in advance. In this paper, we proposed a new algorithm for estimating the matrix A, which does not require the restriction of single dominant source at each instant. Moreover, it is not necessary that the exact number of sources be known a priori.	cluster analysis;clustering high-dimensional data;sparse	Farid Movahedi Naini;G. Hosein Mohimani;Massoud Babaie-Zadeh;Christian Jutten	2008	Neurocomputing	10.1016/j.neucom.2007.07.035	speech recognition;computer science;machine learning;linear model;pattern recognition;sparse approximation;blind signal separation	ML	80.24734855228185	-8.41704457436026	190820
e15974df7a4b2bb1a859ab3024139cfad795af69	non-linear local polynomial regression multiresolution methods using \ell ^1 ℓ 1 -norm minimization with application to signal processing			comparison of archive formats;multiresolution analysis;polynomial;signal processing	Francesc Aràndiga;Pep Mulet;Dionisio F. Yáñez	2014		10.1007/978-3-319-22804-4_2	mathematical optimization;polynomial regression;pattern recognition;statistics	ML	79.72295182746689	-4.688084367014034	190947
71d7766c06ea766159aa2b0126adb05d2a33a3e1	iteratively reweighted two-stage lasso for block-sparse signal recovery under finite-alphabet constraints				Malek Messai;Abdeldjalil Aïssa-El-Bey;Karine Amis;Frédéric Guilloud	2019	Signal Processing	10.1016/j.sigpro.2018.11.007		ML	79.4011546711073	-5.152454265680978	191670
b9c0ba1e5c8c01de2b0cddeea50163f24ead2aef	analysis of exercise ventilation with autoregressive model and hilbert-huang transform			autoregressive model;hilbert space	Hsueh-Ting Chu;Tieh-Cheng Fu	2014		10.3233/978-1-61499-484-8-185	computer science;mathematical analysis;hilbert–huang transform;parallel computing;ventilation (architecture);autoregressive model	Vision	80.58510607416727	-3.693756294768623	193557
65982f73eb254b8e82cba5d75e5bc40859c3aa95	progressive correction for deterministic dirac mixture approximations	nonlinear filters;kernel;approximate algorithm;density measurement;approximation algorithms;approximation method;particle measurements;nonlinear filter;delta modulation approximation methods approximation algorithms density measurement kernel monte carlo methods particle measurements;state estimation;delta modulation;nonlinear filtering deterministic dirac mixture approximations monte carlo particle filtering implicit adaptive resolution systematic dirac mixture approximation continuous likelihood function progressive correction scheme particle degeneration problem smooth density representation quality;approximation theory;smoothing methods;smoothing methods approximation theory monte carlo methods nonlinear filters particle filtering numerical methods signal representation;monte carlo method;signal representation;nonlinear filtering state estimation;approximation methods;monte carlo methods;nonlinear filtering;particle filtering numerical methods	Since the advent of Monte-Carlo particle filtering, particle representations of densities have become increasingly popular due to their flexibility and implicit adaptive resolution. In this paper, an algorithm for the multiplication of a systematic Dirac mixture (DM) approximation with a continuous likelihood function is presented, which applies a progressive correction scheme, in order to avoid the particle degeneration problem. The preservation of sample regularity and therefore, representation quality of the underlying smooth density, is ensured by including a new measure of smoothness for Dirac mixtures, the DM energy, into the distance measure. A comparison to common correction schemes in Monte-Carlo methods reveals large improvements especially in cases of small overlap between the likelihood and prior density, as well as for multi-modal likelihoods.	algorithm;approximation;color gradient;complex system;computational complexity theory;dirac delta function;mathematical optimization;modal logic;monte carlo method;nonlinear programming;nonlinear system;particle filter;sampling (signal processing);vii	Patrick Ruoff;Peter Krauthausen;Uwe D. Hanebeck	2011	14th International Conference on Information Fusion		econometrics;mathematical optimization;mathematics;statistics	Vision	80.58558476146459	-3.105903142706844	194670
712714f0733510e0f8a3634932d739a1e193544b	distributed sparse linear regression	iterative method;traitement signal;teledetection;radio logicial;cognitive radios;unite centrale;fused lasso;linear regression input variables training data central processing unit costs data privacy context wireless communication cognitive radio collaboration;mise a jour;soft thresholding operations;convergence;multiplying circuits;threshold detection;espectro radio;multipliers;learning;sensors;telecommunication sans fil;nonnegative garrote;distributed sparse linear regression;spectre radio;central unit;detection conjointe;regression coefficients;relacion convergencia;continuous variable;nonnegative garrote distributed sparse linear regression linear regression problems regression coefficients central processing unit wireless communications cognitive radios radio frequency power spectrum density alternating direction method multipliers soft thresholding operations inter agent communication elastic net fused lasso;linear regression;metodo direccion alternada;paralelisacion;taux convergence;regression analysis cognitive radio numerical analysis;convergence rate;methode direction alternee;agent communication;adaptive lasso;radio frequency power spectrum density;power spectrum density;sparse estimation;software radio;metodo iterativo;algorithme;aprendizaje;actualizacion;elastic net;wireless communication;algorithm;vida privada;detection seuil;power spectral density;apprentissage;linear regression problems;deteccion umbral;radio logicielle;radio frequency;numerical analysis;densite spectrale puissance;analisis regresion;cognitive radio;private life;estimation;wireless communications;joint detection;methode iterative;chromium;telecomunicacion sin hilo;signal processing;remote sensing;parallelisation;distributed linear regression;relational model;teledeteccion;regresion lineal;economic aspect;estimacion parametro;parallelization;communication cost;circuit multiplicateur;analyse regression;vie privee;global optimization;unidad central;regression analysis;optimization	The Lasso is a popular technique for joint estimation and continuous variable selection, especially well-suited for sparse and possibly under-determined linear regression problems. This paper develops algorithms to estimate the regression coefficients via Lasso when the training data are distributed across different agents, and their communication to a central processing unit is prohibited for e.g., communication cost or privacy reasons. A motivating application is explored in the context of wireless communications, whereby sensing cognitive radios collaborate to estimate the radio-frequency power spectrum density. Attaining different tradeoffs between complexity and convergence speed, three novel algorithms are obtained after reformulating the Lasso into a separable form, which is iteratively minimized using the alternating-direction method of multipliers so as to gain the desired degree of parallelization. Interestingly, the per agent estimate updates are given by simple soft-thresholding operations, and inter-agent communication overhead remains at affordable level. Without exchanging elements from the different training sets, the local estimates consent to the global Lasso solution, i.e., the fit that would be obtained if the entire data set were centrally available. Numerical experiments with both simulated and real data demonstrate the merits of the proposed distributed schemes, corroborating their convergence and global optimality. The ideas in this paper can be easily extended for the purpose of fitting related models in a distributed fashion, including the adaptive Lasso, elastic net, fused Lasso and nonnegative garrote.	algorithm;augmented lagrangian method;central processing unit;coefficient;cognitive radio;complexity;elastic map;elastic net regularization;experiment;feature selection;inter-process communication;lasso;numerical method;overhead (computing);parallel computing;radio frequency;sparse matrix;spectral density;thresholding (image processing)	Gonzalo Mateos;Juan Andrés Bazerque;Georgios B. Giannakis	2010	IEEE Transactions on Signal Processing	10.1109/TSP.2010.2055862	cognitive radio;telecommunications;computer science;linear regression;signal processing;mathematics;wireless;statistics;global optimization	ML	78.80972797243287	-8.262594749662858	196975
edf6da6d7ce0644223a024f16444dee354e2db0e	a grid-less approach to underdetermined direction of arrival estimation via low rank matrix denoising	super resolution doa estimation low rank matrix recovery music nested and coprime arrays nuclear norm minimization;signal denoising direction of arrival estimation signal classification;arrays covariance matrices direction of arrival estimation multiple signal classification estimation noise reduction antenna arrays;music like subspace method grid less approach underdetermined direction of arrival estimation doa estimation narrowband sources antenna array sensors sparse arrays sparse estimation techniques low rank matrix denoising approach;signal classification;direction of arrival estimation;signal denoising	The problem of direction of arrival (DOA) estimation of narrowband sources using an antenna array is considered where the number of sources can potentially exceed the number of sensors. In earlier works, the authors showed that using a suitable antenna geometry, such as the nested and coprime arrays, it is possible to localize O(M2) sources using M sensors. To this end, two different approaches have been proposed. One is based on an extension of subspace based methods such as MUSIC to these sparse arrays, and the other employs l1 norm minimization based sparse estimation techniques by assuming an underlying grid. While the former requires the knowledge of number of sources, the latter suffers from basis mismatch effects. In this letter, a new approach is proposed which overcomes both these weaknesses. The method is hybrid in nature, using a low rank matrix denoising approach followed by a MUSIC-like subspace method to estimate the DOAs. The number of sources is revealed as a by-product of the low rank denoising stage. Moreover, it does not assume any underlying grid and thereby does not suffer from basis mismatch. Numerical examples validate the effectiveness of the proposed method when compared against existing techniques.	apriori algorithm;direction of arrival;low-rank approximation;noise reduction;numerical method;sensor;signal-to-noise ratio;simulation;snapshot (computer storage);sparse matrix;taxicab geometry	Piya Pal;Palghat P. Vaidyanathan	2014	IEEE Signal Processing Letters	10.1109/LSP.2014.2314175	mathematical optimization;pattern recognition;mathematics;statistics		79.59958649583203	-7.48392404114576	198255
b5ccd0030f4bd0e1aac256fe2c3968c663238e18	design of gaussian mixture models using matching pursuit	gaussian mixture model;matching pursuit	In this paper, a new design algorithm for estimating the parameters of Gaussian Mixture Models is presented. The method is based on the matching pursuit algorithm. Speaker Identification is considered as an application area. The estimated GMM performs as good as the EM algorithm based model. Computational complexity of the proposed method is much lower than the EM algorithm.	analysis of algorithms;computational complexity theory;expectation–maximization algorithm;matching pursuit;mixture model	Khaled Ben Fatma;A. Enis Çetin	1999			mathematical optimization;mixture model;computational complexity theory;matching pursuit;expectation–maximization algorithm;mathematics	ML	77.88900767104708	-8.701273134957987	198690
