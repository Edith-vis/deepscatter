id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
44fce80520e3f0212d78d2543106076d8cf5b05f	the huller: a simple and efficient online svm	online algorithm;learning algorithm;methode noyau;algorithme en ligne;large dataset;algorithme apprentissage;algoritmo en linea;classification;support vector;metodo nucleo;machine exemple support;kernel method;maquina ejemplo soporte;vector support machine;algoritmo aprendizaje;clasificacion	We propose a novel online kernel classifier algorithm that converges to the Hard Margin SVM solution. The same update rule is used to both add and remove support vectors from the current classifier. Experiments suggest that this algorithm matches the SVM accuracies after a single pass over the training examples. This algorithm is attractive when one seeks a competitive classifier with large datasets and limited computing resources.	algorithm;experiment;kernel (operating system);requirement;statistical classification	Antoine Bordes;Léon Bottou	2005		10.1007/11564096_48	margin classifier;support vector machine;kernel method;online algorithm;margin;biological classification;computer science;artificial intelligence;machine learning;mathematics;algorithm	ML	20.363968974501656	-38.20373029423273	171175
18e2f508c236fc655c0e776116eeb5f9956b7dda	graph-based multiple-instance learning for object-based image retrieval	unlabeled data;multiple instance;multiple instance learning;semi supervised learning;object based image retrieval;iterative solution;image retrieval	We study in this paper the problem of using multiple-instance semi-supervised learning to solve object-based image retrieval problem, in which the user is only interested in a portion of the image, and the rest of the image is considered as irrelevant. Although many multiple-instance learning (MIL) algorithms have been proposed to solve object-based image retrieval problem, most of them only have a supervised manner and do not fully utilize the information of the unlabeled data in the image collection. In this paper, to make use of the large amount of unlabeled data, we present a semi-supervised version of multiple-instance learning, i.e. multiple-instance semi-supervised learning (MISSL). By taking into account both the multiple-instance property and the semi-supervised property simultaneously, a novel regularization framework for MISSL is presented. Based on this framework, a graph-based multiple-instance learning (GMIL) algorithm is developed, in which three kinds of data, i.e. labeled data, semi-labeled data, and unlabeled data simultaneously propagate information on a graph. Moreover, under the same framework, GMIL can be reduced to a novel standard MIL algorithm (GMIL-M) by ignoring unlabeled data. We theoretically prove the convergence of the iterative solutions for GMIL and GMIL-M. We apply GMIL algorithm to solving object-based image retrieval problem, and experimental results show the superiority of the proposed method. Some experiments on standard MIL problems are also provided to show the competitiveness of the proposed algorithms compared with state-of-the-art MIL algorithms.	algorithm;experiment;image retrieval;iterative method;matrix regularization;multiple-instance learning;object-based language;relevance;semi-supervised learning;semiconductor industry;supervised learning	Changhu Wang;Lei Zhang;HongJiang Zhang	2008		10.1145/1460096.1460123	semi-supervised learning;unsupervised learning;image retrieval;computer science;machine learning;pattern recognition;data mining;information retrieval	AI	24.005766690753852	-43.35042784951474	171200
e5637361be5b95adf7b7b49892de9f8f519d429d	fuzzy clustering with multiple kernels	resolution weights;multiple kernels;cluster algorithm;pattern clustering;fuzzy c mean;kernel;high dimensionality;measurement;generic model;support vector machines;convex programming;prototypes;kernel function;indexing terms;feature space;fuzzy set theory;data sets fuzzy c means with multiple kernels fuzzy clustering adaptive cluster model data points high dimensional feature space optimal convex combination optimal kernel induced feature map gaussian kernels resolution specific weight;fuzzy clustering;data analysis;self organising feature maps;self organising feature maps convex programming data analysis fuzzy set theory pattern clustering;gaussian kernel;clustering algorithms;bandwidth;optimization;kernel clustering algorithms prototypes bandwidth optimization support vector machines measurement;support vector machine;cluster model;fuzzy c means clustering;resolution weights fuzzy clustering multiple kernels;convex combination	In this paper, the kernel fuzzy c-means clustering algorithm is extended to an adaptive cluster model which maps data points to a high dimensional feature space through an optimal convex combination of homogenous kernels with respect to each cluster. This generalized model, called Fuzzy C-Means with Multiple Kernels (FCM-MK), strives to find a good partitioning of the data into meaningful clusters and the optimal kernel-induced feature map in a completely unsupervised way. It constructs the kernel from a number of Gaussian kernels and learns a resolution specific weight for each kernel function in each cluster. This allows better characterization and adaptability to each individual cluster. The effectiveness of the proposed algorithm is demonstrated for several toy and real data sets.	algorithm;cluster analysis;data point;dhrystone;feature vector;fuzzy clustering;fuzzy cognitive map;kernel (operating system);loss function;optimization problem;unsupervised learning	Naouel Baili;Hichem Frigui	2011	2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011)	10.1109/FUZZY.2011.6007412	support vector machine;mathematical optimization;convex optimization;computer science;machine learning;pattern recognition;mathematics;variable kernel density estimation	Vision	20.98822520655442	-40.78284085116367	171328
39cd76eb1c3692210aedd2901f2f561e91c25272	novel kernels and kernel pca for pattern recognition	kernel principal component analysis;learning algorithm;visual databases feature extraction image classification learning artificial intelligence principal component analysis;feature recognition;kernel principal component analysis pattern recognition databases extraterrestrial measurements classification algorithms computational intelligence robotics and automation usa councils polynomials;natural variation;kernel function;image classification;kernel pca method;feature space;feature extraction;principal component analysis;pattern recognition;kernel pca;kernel method;image analysis;learning artificial intelligence;linear classification learning algorithm;linear space;principal component analysis kernel pca method pattern recognition feature recognition image analysis problem linear classification learning algorithm;image analysis problem;visual databases	Kernel methods are a mathematical tool that provides a generally higher dimensional representation of given data set in feature space for feature recognition and image analysis problems. Typically, the kernel trick is thought of as a method for converting a linear classification learning algorithm into non-linear one, by mapping the original observations into a higher-dimensional non-linear space so that linear classification in the new space is equivalent to non-linear classification in the original space. Moreover, optimal kernels can be designed to capture the natural variation present in the data. In this paper we present the performance results of fifteen novel kernel functions and their respective performance for kernel principal component analysis on five select databases. Empirical results show that our kernels perform as well and better than existing kernels on these databases.	algorithm;database;feature recognition;feature vector;image analysis;kernel method;kernel principal component analysis;linear classifier;nonlinear system;pattern recognition;polynomial	Jason C. Isaacs;Simon Y. Foo;Anke Meyer-Bäse	2007	2007 International Symposium on Computational Intelligence in Robotics and Automation	10.1109/CIRA.2007.382927	principal component regression;kernel method;kernel fisher discriminant analysis;string kernel;image analysis;kernel embedding of distributions;radial basis function kernel;kernel principal component analysis;computer science;machine learning;pattern recognition;data mining;graph kernel;tree kernel;variable kernel density estimation;polynomial kernel;kernel smoother	AI	23.43272435981774	-40.26398843236097	171358
947cb5c9a1e03d1c8e586b884c174be654a61241	multiple kernel learning based on local and nonlinear combinations	support vector machines;kernel support vector machines vectors proposals silicon compounds colon training;microarray classification support vector machines kernel machines microarrays multiple kernel learning;support vector machines data handling learning artificial intelligence;lnlmkl multiple kernel learning nonlinear combinations local combinations optimal kernel mkl data dependent combinations linear combinations support vector machine svm localized nonlinear multiple kernel learning;data handling;learning artificial intelligence	In recent years, different methods based on kernels have been used with success in a variety of tasks such as classification. However, in the typical use of these methods, the choice of the optimal kernel is crucial to improve the performance of a specific task. So, instead of selecting a single kernel, multiple kernel learning (MKL) has been proposed which uses a combination of kernels, where the weight of each kernel is optimized in the training stage. MKL methods use kernels in linear, nonlinear or data-dependent combinations. Methods based on MKL have performed better than methods using a single kernel such as the Support Vector Machine (SVM). In this article, we propose a new MKL method, which is based on a local (data dependent) and nonlinear combination of different kernels using a gating model for selecting the appropriate kernel function. We call our proposal as localized nonlinear multiple kernel learning (LNLMKL). In our experiments for binary microarray classification, different kernels were used in SVM and different kernels combinations were used for our proposal and for the other MKL methods. Finally, we report the results of these experiments using eight high-dimensional microarray data sets demonstrating that our proposal have performed better than the other methods analyzed.	data dependency;experiment;kernel (operating system);math kernel library;microarray;multiple kernel learning;nonlinear system;statistical classification;support vector machine	Marks Calderon-Niquin;Jorge Carlos Valverde-Rebaza	2012	2012 XXXVIII Conferencia Latinoamericana En Informatica (CLEI)	10.1109/CLEI.2012.6427179	least squares support vector machine;kernel method;string kernel;kernel embedding of distributions;radial basis function kernel;machine learning;pattern recognition;data mining;graph kernel;mathematics;tree kernel;polynomial kernel	ML	19.82258212909266	-39.72725123548842	171496
a07b19412371306407f94997465bdde67836d7a6	semi-supervised variable weighting for clustering	conference proceeding	Semi-supervised learning, which uses a small amount of labeled data in conjunction with a large amount of unlabeled data for training, has recently attracted huge research attention due to the considerable improvement in learning accuracy. In this work, we focus on semisupervised variable weighting for clustering, which is a critical step in clustering as it is known that interesting clustering structure usually occurs in a subspace defined by a subset of variables. Besides exploiting both labeled and unlabeled data to effectively identify the real importance of variables, our method embeds variable weighting in the process of semi-supervised clustering, rather than calculating variable weights separately, to ensure the computation efficiency. Our experiments carried out on both synthetic and real data demonstrate that semisupervised variable weighting significantly improves the clustering accuracy of existing semi-supervised k -means without variable weighting, or with unsupervised variable weighting.	algorithm;authorization;cluster analysis;computation;experiment;feature selection;loss function;optimization problem;semi-supervised learning;semiconductor industry;supervised learning;synthetic data;synthetic intelligence;unsupervised learning	Ling Chen;Chengqi Zhang	2011		10.1137/1.9781611972818.74	econometrics;computer science;pattern recognition;statistics	AI	22.916971404406233	-41.65209342927564	172139
199f012385dcb335b7e763562d12a510a48330f3	improved sparse least-squares support vector machine classifiers	optimization problem;sparse ls svm;least squares support vector machines;support vector machine;pruning method;least squares support vector machine	The least-squares support vector machines (LS-SVM) can be obtained by solving a simpler optimization problem than that in standard support vector machines (SVM). Its shortcoming is the loss of sparseness and this usually results in slow testing speed. Several pruning methods have been proposed. It is found that these methods can be further improved for classification problems. In this paper a different reduced training set is selected to re-train LS-SVM. Then a new procedure is proposed to obtain the sparseness. The performance of the proposed method is compared with other typical ones and the results indicate that it is more effective. r 2006 Elsevier B.V. All rights reserved.	least squares support vector machine;mathematical optimization;neural coding;optimization problem;sparse matrix;statistical classification;test set	Yuangui Li;Chen Lin;Weidong Zhang	2006	Neurocomputing	10.1016/j.neucom.2006.03.001	optimization problem;support vector machine;least squares support vector machine;computer science;machine learning;pattern recognition;data mining;sequential minimal optimization;relevance vector machine;structured support vector machine	AI	20.968389883922296	-38.59766019380607	172434
4abe48bf9be58abfd290f30bc378d17404ac0608	instance-based domain adaptation in nlp via in-target-domain logistic approximation	domain adaptation;instance adaptation;transfer learning	In the field of NLP, most of the existing domain adaptation studies belong to the feature-based adaptation, while the research of instance-based adaptation is very scarce. In this work, we propose a new instance-based adaptation model, called in-target-domain logistic approximation (ILA). In ILA, we adapt the source-domain data to the target domain by a logistic approximation. The normalized in-targetdomain probability is assigned as an instance weight to each of the source-domain training data. An instance-weighted classification model is trained finally for the cross-domain classification problem. Compared to the previous techniques, ILA conducts instance adaptation in a dimensionalityreduced linear feature space to ensure efficiency in highdimensional NLP tasks. The instance weights in ILA are learnt by leveraging the criteria of both maximum likelihood and minimum statistical distance. The empirical results on two NLP tasks including text categorization and sentiment classification show that our ILA model has advantages over the state-of-the-art instance adaptation methods, in crossdomain classification accuracy, parameter stability and computational efficiency. Introduction For many NLP tasks, e.g., text categorization, sentiment classification, etc., it is nowadays very easy to obtain a large collection of labeled data from different domains in the vast amount of Internet texts. But not all of them are useful for training a desired target-domain classifier. Thus, it is necessary for us to employ an instance adaptation technique to identify the most important training instances, and increase their weights in the training process. However, to the best of our knowledge, most existing work for domain adaptation in NLP employs feature-based adaptation, while the research of instance-based adaptation is very scarce (Jiang and Zhai, 2007; Pan and Yang, 2010; Xia et al., 2013a). The instance adaptation methods were mainly proposed by the machine learning community in the past. In machine learning, “instance adaptation” is   also   termed   “covariate shift”  or  “instance  selection  bias”,  where   the  key  problem is density ratio estimation (DRE). Series of kernel-based methods were proposed to solve the DRE problem (Shimodaira, 2000; Huang et al., 2007; Sugiyama et al., 2007; Tsuboi et al., 2008; Kanamori et al., 2009). Among them, the KLIEP algorithm (Sugiyama et al., 2007) is the representative one. It estimates the density ratio based on a linear model in a Gaussian kernel space. However, the kernel-based methods are mostly designed under tasks of low-dimensional continuous distributions. It is hard to apply them directly to tasks of high-dimensional discrete distributions. E.g., if KLIEP is applied to such tasks, it is difficult to choose a suitable kernel function. The kernel function mapping in high-dimensional feature space is also computationally impractical. In this work, we propose a new instance adaptation model, called in-target-domain logistic approximation (ILA), to adapt the source-domain training data to the target domain by a logistic approximation. In ILA, instance adaptation is conducted in a linear feature space, rather than a complex kernel space. A domain-sensitive feature selection method is proposed furthermore to reduce the dimensionality of the linear feature space. Both make ILA efficient for high-dimensional NLP tasks. More recently, Xia et al. (2013b) proposed an instance weighting approach via PU learning (PUIW) for domain adaptation in sentiment classification. Although PUIW is applicable to high-dimensional NLP tasks, the instance weights are learnt by two separated steps in PUIW. The instance weight learning is not efficient, and the adaptation performance depends heavily on the preset value of the calibration parameter. In ILA, the instance weights are Instance-Based Domain Adaptation in NLP via In-Target-Domain Logistic Approximation Rui Xia, Jianfei Yu, Feng Xu, and Shumei Wang Copyright © 2014, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence	algorithm;approximation;artificial intelligence;categorization;computation;document classification;domain adaptation;feature selection;feature vector;kernel density estimation;linear model;machine learning;marginal model;natural language processing;selection bias;user space;yang	Rui Xia;Jianfei Yu;Feng Xu;Shumei Wang	2014			transfer of learning;computer science;machine learning;pattern recognition;data mining	AI	19.228774688042094	-40.36485838640112	173121
964b4a8feb314285a44d37e60205303607b7183c	fuzzy least squares twin support vector clustering		In this paper, we have formulated a fuzzy least squares version of recently proposed clustering method, namely twin support vector clustering (TWSVC). Here, a fuzzy membership value of each data pattern to different cluster is optimized and is further used for assigning each data pattern to one or other cluster. The formulation leads to finding k cluster center planes by solving modified primal problem of TWSVC, instead of the dual problem usually solved. We show that the solution of the proposed algorithm reduces to solving a series of system of linear equations as opposed to solving series of quadratic programming problems along with system of linear equations as in TWSVC. The experimental results on several publicly available datasets show that the proposed fuzzy least squares twin support vector clustering (F-LS-TWSVC) achieves comparable clustering accuracy to that of TWSVC with comparatively lesser computational time. Further, we have given an application of F-LS-TWSVC for segmentation of color images.	algorithm;cluster analysis;computation;duality (optimization);least squares;linear equation;mike lesser;nonlinear system;quadratic programming;system of linear equations;time complexity	Reshma Khemchandani;Aman Pal;Suresh Chandra	2016	Neural Computing and Applications	10.1007/s00521-016-2468-4	correlation clustering;constrained clustering;least squares support vector machine;mathematical optimization;data stream clustering;k-medians clustering;fuzzy clustering;flame clustering;machine learning;data mining;mathematics;cluster analysis;clustering high-dimensional data	ML	21.88176126792029	-39.0318786346249	173585
53adc55a0a7d02a7ad44089ccaa2574dbd4076d7	pattern classification by concurrently determined piecewise linear and convex discriminant functions	tecnologia industrial tecnologia mecanica;piecewise linear;computacion informatica;data mining;classification;discriminant function;learning methods;machine learning;ciencias basicas y experimentales;pattern classification;distance metric;linear program;mixed integer and linear programming;tecnologias;grupo a	This paper develops a new methodology for pattern classification by concurrently determined k piecewise linear and convex discriminant functions. Toward the end, we design a new l1-norm distance metric for measuring misclassification errors and use it to develop a mixed 0–1 integer and linear program (MILP) for the k piecewise linear and convex separation of data. The proposed model is meritorious in that it considers the synergy as well as the individual role of the k hyperplanes in constructing a decision surface and exploits the advances in theory and algorithms and the advent of powerful softwares for MILP for its solution. With artificially created data, we illustrate pros and cons of pattern classification by the proposed methodology. With six benchmark classification datasets, we demonstrate that the proposed approach is effective and competitive with well-established learning methods. In summary, the classifiers constructed by the proposed approach obtain the best prediction rates on three of the six datasets and the second best records for two of the remaining three datasets. 2006 Elsevier Ltd. All rights reserved.	algorithm;benchmark (computing);decision boundary;discriminant;linear programming;piecewise linear continuation;statistical classification;synergy;taxicab geometry	Hong Seo Ryoo	2006	Computers & Industrial Engineering	10.1016/j.cie.2006.06.015	mathematical optimization;piecewise linear function;metric;biological classification;linear programming;artificial intelligence;machine learning;linear classifier;discriminant function analysis;mathematics;algorithm;statistics	AI	21.467916443572214	-39.5369320686062	173714
ed3d0945c3fc69475cd33ace69978a3e32efcfbd	low-rank kernel space representations in prototype learning		In supervised learning feature vectors are often implicitly mapped to a high-dimensional space using the kernel trick with quadratic costs for the learning algorithm. The recently proposed random Fourier features provide an explicit mapping such that classical algorithms with often linear complexity can be applied. Yet, the random Fourier feature approach remains widely complex techniques which are difficult to interpret. Using Matrix Relevance Learning the linear mapping of the data for a better class separation can be learned by adapting a parametric Euclidean distance. Further, a low-rank representation of the input data can be obtained. We apply this technique to random Fourier feature encoded data to obtain a discriminative mapping of the kernel space. This explicit approach is compared with a differentiable kernel vector quantizer on the same but implicit kernel representation. Using multiple benchmark problems, we demonstrate that a parametric distance on a RBF encoding yields to better classification results and permits access to interpretable prediction models with visualization abilities.	prototype;user space	Kerstin Bunte;Marika Kaden;Frank-Michael Schleif	2016		10.1007/978-3-319-28518-4_30	machine learning;pattern recognition;tree kernel	OS	23.766765154729377	-41.41072443570682	173934
070413373ff0e3f4f4de93c2d9237533ddd54d72	multilinear tensor-based non-parametric dimension reduction for gait recognition	subspace learning;small sample size;dimension reduction;small sample size problem;gait recognition;theoretical analysis;multi linear tensor	The small sample size problem and the difficulty in determining the optimal reduced dimension limit the application of subspace learning methods in the gait recognition domain. To address the two issues, we propose a novel algorithm named multi-linear tensor-based learning without tuning parameters (MTP) for gait recognition. In MTP, we first employ a new method for automatic selection of the optimal reduced dimension. Then, to avoid the small sample size problem, we use multi-linear tensor projections in which the dimensions of all the subspaces are automatically tuned. Theoretical analysis of the algorithm shows that MTP converges. Experiments on the USF Human Gait Database show promising results of MTP compared to other gait recognition methods.	algorithm;dimensionality reduction;discriminant;experiment;gait analysis;machine learning	Changyou Chen;Junping Zhang;Rudolf Fleischer	2009		10.1007/978-3-642-01793-3_104	computer science;machine learning;pattern recognition;mathematics;statistics;dimensionality reduction	Vision	24.07523767790464	-40.512381674060926	174056
4bc4ef8c62e574fd6f4093952611027b6b86f61e	a sequential multitask learning algorithm for pattern recognition	training data pattern recognition accuracy resource management face memory management neural networks;pattern recognition problems sequential multitask learning algorithm sequential multitask learning model resource allocating network multitask pattern recognition learning functions multilabel recognition semisupervised task learning active learning extended ran mtpr training data multiple class labels semi supervised setting generalization performance;pattern recognition learning artificial intelligence;pattern recognition;learning artificial intelligence	In this work, we extend the sequential multitask learning model called Resource Allocating Network for Multi-Task Pattern Recognition (RAN-MTPR) by introducing the following new learning functions: multi-label recognition, semi-supervised task learning and active learning. The extended RAN-MTPR can learn a training data with multiple class labels, can handle a semi-supervised setting for task learning, and can actively request class labels for unsure inputs. We evaluate the performance of the extended RAN-MTPR, and we know that the above three functions work well to enhance the generalization performance for pattern recognition problems.	algorithm;computer multitasking;multi-label classification;pattern recognition;semiconductor industry	Tomoyasu Takata;Daisuke Higuchi;Seiichi Ozawa	2012	2012 IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL)	10.1109/DevLrn.2012.6400827	semi-supervised learning;unsupervised learning;instance-based learning;feature;computer science;artificial intelligence;machine learning;pattern recognition;stability;competitive learning;active learning;artificial neural network;generalization error	Vision	22.73866521141288	-44.75023326072722	174310
ae8cc8db9e05c79adad03da64a4a9ba0b00f4eb5	large scale local online similarity/distance learning framework based on passive/aggressive		Similarity/Distance measures play a key role in many machine learning, pattern recognition, and data mining algorithms, which leads to the emergence of metric learning field. Many metric learning algorithms learn a global distance function from data that satisfy the constraints of the problem. However, in many real-world datasets that the discrimination power of features varies in the different regions of input space, a global metric is often unable to capture the complexity of the task. To address this challenge, local metric learning methods are proposed that learn multiple metrics across the different regions of input space. Some advantages of these methods are high flexibility and the ability to learn a nonlinear mapping but typically achieves at the expense of higher time requirement and overfitting problem. To overcome these challenges, this research presents an online multiple metric learning framework. Each metric in the proposed framework is composed of a global and a local component learned simultaneously. Adding a global component to a local metric efficiently reduce the problem of overfitting. The proposed framework is also scalable with both sample size and the dimension of input data. To the best of our knowledge, this is the first local online similarity/distance learning framework based on PA (Passive/Aggressive). In addition, for scalability with the dimension of input data, DRP (Dual Random Projection) is extended for local online learning in the present work. It enables our methods to be run efficiently on high-dimensional datasets, while maintains their predictive performance. The proposed framework provides a straightforward local extension to any global online similarity/distance learning algorithm based on PA. Experimental results on some challenging datasets from machine vision confirm that the extended methods considerably enhance the performance of related global ones without increasing the time complexity.	algorithm;data mining;disaster recovery plan;emergence;linear discriminant analysis;machine learning;machine vision;nonlinear system;overfitting;pattern recognition;random projection;scalability;time complexity	Baida Hamdan;Davood Zabihzadeh;Reza Monsefi	2018	CoRR		distance measures;metric (mathematics);machine learning;overfitting;scalability;sample size determination;distance education;artificial intelligence;nonlinear system;mathematics;random projection	ML	21.08596031967715	-44.84330541887464	174730
3d3db966cde7e2ae4facb37af1538a90ab85f1a5	a cutting plane algorithm for multiclass kernel discriminations	quadratic programming;image recognition;kernel;quadratic program;cutting plane;support vector machines;indexing terms;data mining;support vector;cutting plane algorithm;technology management;optimization problem;kernel machine;engineering management;support vector machine classification;kernel support vector machines support vector machine classification industrial engineering technology management engineering management quadratic programming data mining image recognition large scale systems;multiclass classification;industrial engineering;large scale systems	The problem of multiclass discrimination consists in classifying patterns into a set of finite classes. Usually, a multiclass problem is decomposed into multiple binary ones and the results of the binary problems are integrated for multiclass discrimination. These discriminators, however, could result in multi-classified and/or unclassified points. Therefore, we need some tie breaking mechanisms to handle the conflict. There exist several approaches which generate all discriminators in one optimization problem. In this paper, we consider the formulation introduced by Crammer and Singer [3]. They introduce a quadratic programming problem with a very large number of variables which is hard to optimize. Using a cutting plane procedure, we propose a new algorithm which solves the problem in a finite number of iterations. The results of experiments on five datasets show that the proposed method achieves higher classification performance than the traditional methods by using binary algorithms.	algorithm;computation;cutting-plane method;experiment;integer programming;iteration;kernel (operating system);mathematical optimization;multiclass classification;numerical analysis;optimization problem;quadratic equation;quadratic programming;support vector machine	Tien-Fang Kuo;Yasutoshi Yajima	2006	2006 IEEE International Conference on Granular Computing	10.1109/GRC.2006.1635787	support vector machine;mathematical optimization;computer science;machine learning;multiclass classification;pattern recognition;data mining;mathematics;quadratic programming	Robotics	20.8812267469426	-39.32652616559669	176080
e21657df4c17d1e5845d2b480ffbc8a94ff39dfb	a self-organizing tensor architecture for multi-view clustering		In many real-world applications, data are often unlabeled and comprised of different representations/views which often provide information complementary to each other. Although several multi-view clustering methods have been proposed, most of them routinely assume one weight for one view of features, and thus inter-view correlations are only considered at the view-level. These approaches, however, fail to explore the explicit correlations between features across multiple views. In this paper, we introduce a tensor-based approach to incorporate the higher-order interactions among multiple views as a tensor structure. Specifically, we propose a multi-linear multi-view clustering (MMC) method that can efficiently explore the full-order structural information among all views and reveal the underlying subspace structure embedded within the tensor. Extensive experiments on realworld datasets demonstrate that our proposed MMC algorithm clearly outperforms other related state-of-the-art methods.		Lifang He;Chun-Ta Lu;Yong Chen;Jiawei Zhang;Linlin Shen;Philip S. Yu;Fei Wang	2018	2018 IEEE International Conference on Data Mining (ICDM)	10.1109/ICDM.2018.00126	artificial intelligence;tensor;machine learning;architecture;computer science;cluster analysis;correlation;linear programming;subspace topology	DB	23.877236311200893	-43.667762866035766	176125
47751b86913c2561a01fae2cb74d57f8efeb2c7e	a powerful discriminative approach for selecting the most efficient unit in dea		Abstract Data envelopment analysis (DEA) is a mathematical approach deals with the performance evaluation problem. Traditional DEA models partition the set of units into two distinct sets: efficient and inefficient. These models fail to get more information about efficient units whereas there are some applications, known as selection-based problems, where the concern is selecting only a single efficient unit. To address the problem, several mixed integer linear/nonlinear programming models are developed in the literature using DEA. The aim of all these approaches is formulating a model with more discriminating power. This paper presents a new nonlinear mixed integer programming model with significantly higher discriminating power than the existing ones in the literature. The suggested model lets the efficiency score of only a single unit be strictly greater than one. It is observed that the discrimination power of the model is high enough for fully ranking all units. More importantly, a linearization technique is used to formulate an equivalent mixed integer linear programming model which significantly decreases the computational burden. Finally, to validate the proposed model and also compare with some recent approaches, two numerical examples are utilized from the literature. Our founding points out the superiority of our model over all the previously suggested models from both theoretical and practical standpoints.		Mehdi Toloo;Maziar Salahi	2018	Computers & Industrial Engineering	10.1016/j.cie.2017.11.011	operations management;mathematical optimization;discriminative model;nonlinear programming;nonlinear system;partition (number theory);linearization;integer programming;data envelopment analysis;machine learning;ranking;artificial intelligence;mathematics	SE	21.529950620127405	-39.024363935891934	176269
0d96c9d14f079b7b8b6b56b4fa86f611a4ff237f	semi-supervised low-rank mapping learning for multi-label classification	会议论文;multimedia systems category theory computer vision image classification learning artificial intelligence;correlation data models complexity theory yttrium optimization multimedia communication manifolds;slrm semisupervised low rank mapping learning multilabel classification automatic multimedia data categorization computer vision machine learning	Multi-label problems arise in various domains including automatic multimedia data categorization, and have generated significant interest in computer vision and machine learning community. However, existing methods do not adequately address two key challenges: exploiting correlations between labels and making up for the lack of labeled data or even missing labels. In this paper, we proposed a semi-supervised low-rank mapping (SLRM) model to handle these two challenges. SLRM model takes advantage of the nuclear norm regularization on mapping to effectively capture the label correlations. Meanwhile, it introduces manifold regularizer on mapping to capture the intrinsic structure among data, which provides a good way to reduce the required labeled data with improving the classification performance. Furthermore, we designed an efficient algorithm to solve SLRM model based on alternating direction method of multipliers and thus it can efficiently deal with large-scale datasets. Experiments on four real-world multimedia datasets demonstrate that the proposed method can exploit the label correlations and obtain promising and better label prediction results than state-of-the-art methods.	algorithm;augmented lagrangian method;categorization;computer vision;machine learning;multi-label classification;semi-supervised learning;semiconductor industry	Liping Jing;Liu Yang;Jian Yu;Michael K. Ng	2015	2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2015.7298755	computer vision;computer science;machine learning;pattern recognition;data mining;statistics	Vision	24.17173225663164	-44.11384202807015	176933
32da6810401cd0608a1e0798e462a5b440bb361a	fast online incremental learning on mixture streaming data		The explosion of streaming data poses challenges to feature learning methods including linear discriminant analysis (LDA). Many existing LDA algorithms are not efficient enough to incrementally update with samples that sequentially arrive in various manners. First, we propose a new fast batch LDA (FLDA/QR) learning algorithm that uses the cluster centers to solve a lower triangular system that is optimized by the Cholesky-factorization. To take advantage of the intrinsically incremental mechanism of the matrix, we further develop an exact incremental algorithm (IFLDA/QR). The Gram-Schmidt process with reorthogonalization in IFLDA/QR significantly saves the space and time expenses compared with the rank-one QR-updating of most existing methods. IFLDA/QR is able to handle streaming data containing 1) new labeled samples in the existing classes, 2) samples of an entirely new (novel) class, and more significantly, 3) a chunk of examples mixed with those in 1) and 2). Both theoretical analysis and numerical experiments have demonstrated much lower space and time costs (2 ∼ 10 times faster) than the state of the art, with comparable classification accuracy.	algorithm;cholesky decomposition;computational complexity theory;experiment;fastest;feature learning;linear discriminant analysis;numerical analysis;schmidt decomposition;stream (computing);streaming media;the matrix;triangular matrix	Yi Wang;Xin Fan;Zhongxuan Luo;Tianzhu Wang;Maomao Min;Jiebo Luo	2017			incremental learning;machine learning;artificial intelligence;computer science;streaming data	AI	20.650052404986393	-39.03879559541102	177195
c9f3cb98fd8ad2054e3e01a424076ca45246694a	non-uniqueness of solutions of 1-norm support vector classification in dual form	optimisation;kernel;numerical optimization procedure;support vector machines;numerical optimization procedure 1 norm support vector classification support vector machines svm non uniqueness information;non uniqueness information;numerical optimization;testing;uniqueness of solution;optimization problem;training data;optical character recognition software;efficient implementation;time series analysis;static var compensators support vector machines optimization support vector machine classification kernel training data equations;support vector classification;pattern classification;support vector machines optimisation pattern classification;static var compensators;support vector machine classification;image analysis;svm;support vector machine;1 norm support vector classification;algorithm design and analysis	Most of previous research efforts on support vector machines (SVMs) were directed toward efficient implementations and practical applications. In this work, we concentrate on a different aspect of SVMs. Specifically, we investigate the non-uniqueness of SVM solutions. The key features of this work include (1) we concentrate on the cases where the dual solutions are not unique, whereas the primal solutions are unique; (2) our test for non-uniqueness can be directly applied to data points without solving the SVC optimization problem, namely, the non-uniqueness information is obtained before any numerical optimization procedure is employed.	data point;mathematical optimization;numerical analysis;optimization problem;scalable video coding;support vector machine	Jia-Rui Zhang;Shih-Yu Chiu;Leu-Shing Lan	2008	2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)	10.1109/IJCNN.2008.4634230	support vector machine;mathematical optimization;image analysis;computer science;machine learning;pattern recognition;mathematics	Visualization	22.251683117340438	-39.233364990383926	177532
954d9b10abac8f90de56a4fa44e783999c3fbbb5	comparison of random subspace and voting ensemble machine learning methods for face recognition				Mehmet Yaman;Abdulhamit Subasi;Frank Rattay	2018	Symmetry	10.3390/sym10110651		AI	18.270685302077773	-41.8954056210789	178287
1a7e155ea2a00cad5a899c570ba0329a199cda86	correction of noisy labels via mutual consistency check	non convex optimization and spannogram framework;parzen window estimation;noisy annotation;mutual consistency;label correction	Label noise can have severe negative effects on the performance of a classifier. Such noise can either arise by adversarial manipulation of the training data or from unskilled annotators frequently encountered in crowd sourcing (e.g. Amazon mechanical turk). Based on the assumption that an expert has provided some fraction of the training data, where labels can be assumed to be true, we propose a new pre-processing method to identify and correct noisy labels via a mutual consistency check using a Parzen window classifier. While the resulting optimization problem turns out to be a combinatorial problem, we design an efficient algorithm for which we provide approximation guarantees. Extensive experimental evaluation shows that our method performs similar and often much better than existing methods for the detection of noisy labels, thus leading to a boost in performance of the resulting classifiers.	algorithm;amazon mechanical turk;approximation;crowdsourcing;data point;kernel density estimation;mathematical optimization;np-hardness;optimization problem;preprocessor;provable prime;statistical classification;support vector machine;the turk;window function	Sahely Bhadra;Matthias Hein	2015	Neurocomputing	10.1016/j.neucom.2014.10.083	computer science;machine learning;pattern recognition;data mining;statistics	ML	17.64988020744103	-40.45738721486272	178928
ed6c7caed5933e15ceb76a71c720778716cff693	driving style classification using a semisupervised support vector machine		Supervised learning approaches are widely used for driving style classification; however, they often require a large amount of labeled training data, which is usually scarce in a real-world setting. Moreover, it is time-consuming to manually label huge amounts of driving data due to uncertainties of driver behavior and variances among the data analysts. To address this problem, a semisupervised approach, a semisupervised support vector machine (S3VM), is employed to classify drivers into aggressive and normal styles based on a few labeled data points. First, a few data clusters are selected and manually labeled using a $ k$ -means clustering method. Then, a specific differentiable surrogate of a loss function is developed, which makes it feasible to use standard optimization tools to solve the nonconvex optimization problem. One of the most popular quasi-Newton algorithms is then used to assign the optimal label to all of the training data. Finally, we compare the S3VM method with a support vector machine method for classifying driving styles from different amounts of labeled data. Experiments show that the S3VM method can improve the classification accuracy by about 10% and reduce the labeling effort by using only a few labeled data clusters among huge amounts of unlabeled data.	algorithm;cluster analysis;data point;loss function;mathematical optimization;monte carlo method;newton;optimization problem;quasi-newton method;semi-supervised learning;supervised learning;support vector machine	Wenshuo Wang;Junqiang Xi;Alexandre Chong;Lin Li	2017	IEEE Transactions on Human-Machine Systems	10.1109/THMS.2017.2736948	supervised learning;kernel (linear algebra);machine learning;computer science;semi-supervised learning;support vector machine;training set;cluster analysis;hidden markov model;artificial intelligence;pattern recognition;optimization problem	ML	22.411627707011476	-38.48373523545648	179367
22dc5cd7f83b19c6c517ef7ca9a0ba8bad035aef	ica-based binary feature construction	calculo de variaciones;traitement signal;analisis componente principal;separacion ciega;separation aveugle source;blind source separation;independent component analysis;reduccion ruido;blind separation;calcul variationnel;feature construction;signal processing;principal component analysis;noise reduction;donnee binaire;reduction bruit;analyse composante principale;analyse composante independante;separation aveugle;modele donnee;dato binario;rapport signal bruit;relacion senal ruido;binary data;analisis componente independiente;signal to noise ratio;procesamiento senal;variational calculus;data models	Binary data becomes more and more abundant, arising from areas as diverse as bioinformatics, e-businesses and paleontological research. The processing of binary data requires appropriate tools and methods for tasks such as exploratory analysis, feature construction and denoising. These necessarily must follow the specific distributional characteristics of the data and cannot be accomplished with tools that exist for continuous valued data analysis. Previous successes of Independent Component Analysis (ICA) [5] make it an important statistical principle worthy of investigation for tackling such problems. However, contrarily to continuous-valued signals, work on ICA methods for binary data has been very scarce [4, 3]. A few methods exist, though, that seek binary sources [9, 10] from continuous data. Due to the discrete combinatorial nature of the problem, these latter works resort to search heuristics [10] or indeed an exhaustive search [9], that are, at best, computationally intensive. In this paper we develop a linear ICA model for binary data. We employ a probabilistic framework and make use of the variational methodology to alleviate the computational demand. Application examples will demonstrate the workings of our approach and its advantages over other binary data models.	binary data;bioinformatics;brute-force search;calculus of variations;data model;feature vector;heuristic (computer science);independent computing architecture;independent component analysis;noise reduction;web search engine	Ata Kabán;Ella Bingham	2006		10.1007/11679363_18	independent component analysis;data modeling;econometrics;speech recognition;computer science;machine learning;signal processing;noise reduction;mathematics;blind signal separation;signal-to-noise ratio;statistics;calculus of variations;principal component analysis	ML	23.832960020930322	-38.49831645893173	179775
3ce3986ff630362722ec06f70007caea851040f1	a model-based sampling and sample synthesis method for auto identification in computer vision	image sampling;sample size;high dimensionality;auto identification feature selection method domain knowledge incorporation machine learning system pattern classification field training sample data set computer vision model based sampling sample synthesis method;image classification;curse of dimensionality;feature space;computer vision;domain knowledge;large scale;machine learning;feature extraction;sampling methods computer vision speech synthesis learning systems pattern classification costs machine learning humans sun large scale systems;pattern classification;pattern recognition;feature selection;feature extraction computer vision image classification image sampling;sampling theory	"""The need for a large sample size grows exponentially with the dimensionality of the feature space (""""curse of dimensionality""""), which increases the labor cost during the training procedure and severely restricts the number of the practical applications. While feature selection methods can often alleviate the problems associated with the curse of dimensionality, complex large scale pattern recognition problems may not be amenable to features selection approach due to large intrinsic dimensionality. In such situations, the only effective solution to conquer the complications of the high-dimensional functions is to incorporate knowledge about the data that is correct. How to incorporate the domain knowledge with the specific machine learning system has been widely studied in the pattern classification field. In this paper, we will explore a novel method to synthesize a larger, valid training sample data set based on a smaller set of the key samples that are collected by a model based sampling theory that incorporates the domain knowledge of the computer vision. In addition to reducing the training sample size in the learning procedure, our emphasis is on providing practical advice on how to incorporate domain knowledge to design and simplify a vision based pattern classification model."""	automatic identification and data capture;color;computer vision;curse of dimensionality;cylinder seal;feature selection;feature vector;hexahedron;knowledge integration;machine learning;pattern recognition;sampling (signal processing);simulation;statistical classification;test set;texture mapping	Nanfei Sun;Norman Haas;Jonathan H. Connell;Sharath Pankanti	2005	Fourth IEEE Workshop on Automatic Identification Advanced Technologies (AutoID'05)	10.1109/AUTOID.2005.5	computer vision;curse of dimensionality;computer science;machine learning;pattern recognition	Vision	19.27834148973726	-44.51887563740902	180248
1a9afb1a03af4d1cc094e56229baee7bdc33027d	a bayesian belief network classifier for predicting victimization in national crime victimization survey	bayesian belief network	This paper presents the development of a Bayes net classifier for prediction of a victimization attribute value for the National Crime Victimization Survey dataset. The National Crime Victimization Survey dataset has over 250 attributes and 216,000 data points, and as such poses a large-scale problem context for classifier development. The classifier was developed using the Weka machine learning software workbench. A set of structural and parameter learning algorithms for the Bayesian belief network were employed in a development effort while ensuring that the computational complexity in both time and space remained within affordable bounds. A number of structural learning algorithms, including local versions of hill-climbing and K2, provided a classification performance of 99% on the testing data. Simulation results indicate that it is feasible to develop a successful Bayesian belief network classifier for the victimization attribute of the National Crime Victimization Survey data.	algorithm;bayesian network;computational complexity theory;data point;hill climbing;machine learning;simulation;weka;workbench	Michael Riesen;Gürsel Serpen	2009			encoder;statistical time division multiplexing;data mining;video quality;quantization (signal processing);a priori and a posteriori;bitstream;computer security;multiplexing;computer science;communication channel	AI	17.866092576859327	-39.04170827096422	180328
ea91fad3a76b38736d01a18778603a4deb074de9	dearank: a data-envelopment-analysis-based ranking method	listwise;boosting;data envelopment analysis;learning to rank	A new weak-ranker construction method based on Data Envelopment Analysis technique is presented. Each weak ranker represents a feature subset drawn from the complete feature space. Two linear programming models are formulated, both of which treat the documents to be ranked as the decision making units. By solving the models, we construct a pool of weak-ranker candidates from the optimal weight vectors, and then develop DEARank algorithm based on Boosting technique. We conduct extensive experiments on LETOR 3.0 and LETOR 4.0 collections, with twelve well-known algorithms as the baselines. The experimental results indicate that DEARank is a competitive learning to rank algorithm.	algorithm;baseline (configuration management);boosting (machine learning);competitive learning;data envelopment analysis;experiment;feature vector;learning to rank;linear programming	Chunheng Jiang;Wenbin Lin	2014	Machine Learning	10.1007/s10994-014-5442-3	computer science;machine learning;pattern recognition;data mining;data envelopment analysis;mathematics;boosting;learning to rank	ML	19.789714872712395	-41.789070941385354	180437
8b22e11507ff69032ac6455731100fe60b879f84	on the relation between multi-instance learning and semi-supervised learning	learning algorithm;semi supervised learning;machine learning;multi instance;support vector machine	Multi-instance learning and semi-supervised learning are different branches of machine learning. The former attempts to learn from a training set consists of labeled bags each containing many unlabeled instances; the latter tries to exploit abundant unlabeled instances when learning with a small number of labeled examples. In this paper, we establish a bridge between these two branches by showing that multi-instance learning can be viewed as a special case of semi-supervised learning. Based on this recognition, we propose the MissSVM algorithm which addresses multi-instance learning using a special semi-supervised support vector machine. Experiments show that solving multi-instance problems from the view of semi-supervised learning is feasible, and the MissSVM algorithm is competitive with state-of-the-art multi-instance learning algorithms.	algorithm;experiment;machine learning;semi-supervised learning;semiconductor industry;supervised learning;support vector machine;test set	Zhi-Hua Zhou;Jun-Ming Xu	2007		10.1145/1273496.1273643	semi-supervised learning;unsupervised learning;robot learning;support vector machine;feature learning;multi-task learning;instance-based learning;preference learning;error-driven learning;algorithmic learning theory;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;inductive transfer;learning classifier system;stability;competitive learning;computational learning theory;active learning;generalization error	ML	22.62612749405608	-44.66501866270192	180669
0523566ae9271321593c0f228236fc7dfcac1fee	learning global cost function for face alignment	regression analysis face recognition haar transforms learning artificial intelligence neural nets optimisation;optimisation;neural nets;cost function shape face training databases neural networks;face recognition;regression analysis;learning artificial intelligence;generalization performance global cost function face alignment facial processing applications deformable shape model empirical cost functions robust optimization step learning process boosted input selection algorithm for regression bisar haar like features neural network;haar transforms	Face alignment is a crucial step in many facial processing applications. It has received extensive attention in the last two decades. The general approach consist in estimating the parameters of a deformable shape model, which minimize a cost function. Most of the existing methods are based on empirical cost functions. In this paper we propose to learn an ideal global cost function (i.e. the quality of the alignment) as convex as possible in order to lead to a simple and robust optimization step. This learning process relies on the Boosted Input Selection Algorithm for Regression (BISAR). It selects the best set of Haar-like features as input of a Neural Network to predict the value of the cost function. Performance of this method is evaluated on unseen data from the training database. The generalization performance is assessed on unseen data from unrelated datasets. This approach is also favorably compared with a state-of-the-art method.	approximation algorithm;artificial neural network;haar wavelet;loss function;manifold alignment;mathematical optimization;robust optimization;selection algorithm	Kevin Bailly;Maurice Milgram;Philippe Phothisane;Erwan Bigorgne	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		facial recognition system;computer vision;computer science;artificial intelligence;machine learning;pattern recognition;artificial neural network;regression analysis	Vision	22.180227293796626	-40.61727099925358	181224
7b1c96c375d4fc2be210221a1dfc76db94021fbe	towards global explanations for credit risk scoring		In this paper we propose a method to obtain global explanations for trained blackbox classifiers by sampling their decision function to learn alternative interpretable models. The envisaged approach provides a unified solution to approximate nonlinear decision boundaries with simpler classifiers while retaining the original classification accuracy. We use a private residential mortgage default dataset as a use case to illustrate the feasibility of this approach to ensure the decomposability of attributes during pre-processing.	approximation algorithm;nonlinear system;preprocessor;sampling (signal processing)	Irene Unceta;Jordi Nin;Oriol Pujol	2018	CoRR			AI	18.113019637669556	-39.98175938348928	182059
cd3a971b034d2bc66b000338bf6bff35c73fe301	active learning for semi-supervised clustering based on locally linear propagation reconstruction	locally linear embedding;active learning;manifold learning;semi supervised clustering	The success of semi-supervised clustering relies on the effectiveness of side information. To get effective side information, a new active learner learning pairwise constraints known as must-link and cannot-link constraints is proposed in this paper. Three novel techniques are developed for learning effective pairwise constraints. The first technique is used to identify samples less important to cluster structures. This technique makes use of a kernel version of locally linear embedding for manifold learning. Samples neither important to locally linear propagation reconstructions of other samples nor on flat patches in the learned manifold are regarded as unimportant samples. The second is a novel criterion for query selection. This criterion considers not only the importance of a sample to expanding the space coverage of the learned samples but also the expected number of queries needed to learn the sample. To facilitate semi-supervised clustering, the third technique yields inferred must-links for passing information about flat patches in the learned manifold to semi-supervised clustering algorithms. Experimental results have shown that the learned pairwise constraints can capture the underlying cluster structures and proven the feasibility of the proposed approach.		Chin-Chun Chang;Po-Yi Lin	2015	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2014.11.006	constrained clustering;mathematical optimization;computer science;machine learning;pattern recognition;mathematics;nonlinear dimensionality reduction;active learning;cluster analysis	ML	23.211250821720377	-43.89307344853639	182268
5a22417fae038d1f82bf4fe7fd1cd0d373fe4de2	fast and scalable structural svm with slack rescaling		We present an efficient method for training slackrescaled structural SVM. Although finding the most violating label in a margin-rescaled formulation is often easy since the target function decomposes with respect to the structure, this is not the case for a slack-rescaled formulation, and finding the most violated label might be very difficult. Our core contribution is an efficient method for finding the most-violatinglabel in a slack-rescaled formulation, given an oracle that returns the most-violating-label in a (slightly modified) margin-rescaled formulation. We show that our method enables accurate and scalable training for slack-rescaled SVMs, reducing runtime by an order of magnitude compared to previous approaches to slack-rescaled SVMs.	scalability;slack variable;support vector machine	Heejin Choi;Ofer Meshi;Nathan Srebro	2016			mathematical optimization;machine learning;data mining;mathematics	ML	20.806928645176846	-38.351619201707216	182296
d0b72e94902ae5b2b09f40db8e107d1f6a59b68a	supervising topic models with gaussian processes		Abstract Topic modeling is a powerful approach for modeling data represented as high-dimensional histograms. While the high dimensionality of such input data is extremely beneficial in unsupervised applications including language modeling and text data exploration, it introduces difficulties in cases where class information is available to boost up prediction performance. Feeding such input directly to a classifier suffers from the curse of dimensionality. Performing dimensionality reduction and classification disjointly, on the other hand, cannot enjoy optimal performance due to information loss in the gap between these two steps unaware of each other. Existing supervised topic models introduced as a remedy to such scenarios have thus far incorporated only linear classifiers in order to keep inference tractable, causing a dramatical sacrifice from expressive power. In this paper, we propose the first Bayesian construction to perform topic modeling and non-linear classification jointly. We use the well-known Latent Dirichlet Allocation (LDA) for topic modeling and sparse Gaussian processes for non-linear classification. We combine these two components by a latent variable encoding the empirical topic distribution of each document in the corpus. We achieve a novel variational inference scheme by adapting ideas from the newly emerging deep Gaussian processes into the realm of topic modeling. We demonstrate that our model outperforms other existing approaches such as: (i) disjoint LDA and non-linear classification, (ii) joint LDA and linear classification, (iii) joint non-LDA linear subspace modeling and linear classification, and (iv) non-linear classification without topic modeling, in three benchmark data sets from two real-world applications: text categorization and image tagging.	gaussian process	Melih Kandemir;Taygun Kekec;Reyyan Yeniterzi	2018	Pattern Recognition	10.1016/j.patcog.2017.12.019	machine learning;artificial intelligence;topic model;latent dirichlet allocation;dimensionality reduction;data modeling;curse of dimensionality;mathematics;pattern recognition;linear classifier;language model;latent variable	Vision	19.93667868694897	-44.82798247885575	182316
0910c5dba9fc02ae9c2912e38a66e2648c63a17a	1-norm support vector machines	efficient algorithm;support vector machine	The standard2-norm SVM is known for its goodperformancein twoclassclassi£cation. In this paper , we considerthe 1-norm SVM. We arguethatthe1-normSVM mayhave someadvantageover thestandard 2-norm SVM, especiallywhenthereare redundantnoisefeatures.We alsoproposeanef£cientalgorithmthatcomputesthewholesolutionpath of the 1-norm SVM, hencefacilitatesadapti ve selectionof the tuning parameterfor the1-normSVM.	support vector machine;ur, ur/web	Ji Zhu;Saharon Rosset;Trevor J. Hastie;Robert Tibshirani	2003			support vector machine;computer science;machine learning;pattern recognition;data mining;ranking svm;structured support vector machine	ML	22.63538544739902	-39.68563035489731	183126
8c76f1751386909809d2a8cd2a8de4805799d11f	boosting for graph classification with universum		Recent years have witnessed extensive studies of graph classification due to the rapid increase in applications involving structural data and complex relationships. To support graph classification, all existing methods require that training graphs should be relevant (or belong) to the target class, but cannot integrate graphs irrelevant to the class of interest into the learning process. In this paper, we study a new universum graph classification framework which leverages additional “non-example” graphs to help improve the graph classification accuracy. We argue that although universum graphs do not belong to the target class, they may contain meaningful structure patterns to help enrich the feature space for graph representation and classification. To support universum graph classification, we propose a mathematical programming algorithm, ugBoost, which integrates discriminative subgraph selection and margin maximization into a unified framework to fully exploit the universum. Because informative subgraph exploration in a universum setting requires the search of a large space, we derive an upper bound discriminative score for each subgraph and employ a branch-and-bound scheme to prune the search space. By using the explored subgraphs, our graph classification model intends to maximize the margin between positive and negative graphs and minimize the loss on the universum graph examples simultaneously. The subgraph exploration and the learning are integrated and performed iteratively so that each can be beneficial to the other. Experimental results and comparisons on real-world dataset demonstrate the performance of our algorithm.	binary prefix;boosting (machine learning);branch and bound;discriminative model;duality (optimization);emoticon;expectation–maximization algorithm;feature vector;graph (abstract data type);information;lagrangian (field theory);mathematical optimization;programming paradigm;relevance;unified framework;vanish (computer science)	Shirui Pan;Jia Wu;Xingquan Zhu;Guodong Long;Chengqi Zhang	2016	Knowledge and Information Systems	10.1007/s10115-016-0934-z	implicit graph;combinatorics;null model;null graph;clique-width;machine learning;pattern recognition;data mining;mathematics;graph;complement graph	ML	20.697052309996973	-43.84292255944492	183338
ff4d379837907859a5a32440f34a61ba3f35e49e	auc maximization with k-hyperplane		Area Under the ROC Curve (AUC) is a reliable metric for measuring the quality of the classification performance on imbalanced data. The existing pairwise learn to rank linear algorithms can optimize the AUC metric efficiently, but lack modeling the nonlinearity underlying the data. The large scale and nonlinear distribution of many real world data render the kernelized variants of these linear classifiers impractical. In this paper, we propose a linear K-hyperplane classifier for AUC maximization. The proposed method employs a set of linear pairwise classifiers in order to approximate the nonlinear decision boundary. More specifically, we define a set of landmark points using unsupervised algorithm, and associate each landmark with a linear pairwise classifier. These linear classifiers are learned jointly on pairs of instances where each instance in the pair is weighted based on its distance from the corresponding landmark point. We use a local coding algorithm to estimate the weights of the instances. Experiments on several benchmark datasets demonstrate that our classifier is efficient and able to achieve roughly comparable AUC classification performance as compared to kernalized pairwise classifier. The proposed classifier also outperforms the linear RankSVM classifiers in terms of AUC performance.	approximation algorithm;benchmark (computing);decision boundary;expectation–maximization algorithm;experiment;fast fourier transform;kernel method;landmark point;learning classifier system;learning to rank;linear classifier;linear code;mathematical optimization;nonlinear system;receiver operating characteristic	Majdi Khalid;Indrakshi Ray;Hamidreza Chitsaz	2017	CoRR		hyperplane;artificial intelligence;machine learning;nonlinear system;mathematics;classifier (linguistics);pairwise comparison;decision boundary;landmark point;maximization	ML	21.84620889536726	-40.904556736106606	183362
532eaee9f492c848b7d55d55451fd05c2ba8ba4c	out-of-sample extensions for non-parametric kernel methods	kernel;manifolds;support vector machines;out of sample extensions hyperkernels inductive learning kernel methods nonparametric kernel learning;risk management;geometry;hilbert space;face recognition;期刊论文;kernel hilbert space risk management face recognition support vector machines geometry manifolds	Choosing suitable kernels plays an important role in the performance of kernel methods. Recently, a number of studies were devoted to developing nonparametric kernels. Without assuming any parametric form of the target kernel, nonparametric kernel learning offers a flexible scheme to utilize the information of the data, which may potentially characterize the data similarity better. The kernel methods using nonparametric kernels are referred to as nonparametric kernel methods. However, many nonparametric kernel methods are restricted to transductive learning, where the prediction function is defined only over the data points given beforehand. They have no straightforward extension for the out-of-sample data points, and thus cannot be applied to inductive learning. In this paper, we show how to make the nonparametric kernel methods applicable to inductive learning. The key problem of out-of-sample extension is how to extend the nonparametric kernel matrix to the corresponding kernel function. A regression approach in the hyper reproducing kernel Hilbert space is proposed to solve this problem. Empirical results indicate that the out-of-sample performance is comparable to the in-sample performance in most cases. Experiments on face recognition demonstrate the superiority of our nonparametric kernel method over the state-of-the-art parametric kernel methods.	algorithm;data point;facial recognition system;hilbert space;hyper-heuristic;hyperactive behavior;inductive reasoning;internationalization and localization;kernel (operating system);kernel density estimation;kernel method;normal statistical distribution;transduction (machine learning)	Binbin Pan;Wensheng Chen;Bo Chen;Chen Xu;Jianhuang Lai	2017	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2015.2512277	kernel;kernel regression;support vector machine;kernel method;mathematical optimization;kernel;string kernel;kernel embedding of distributions;radial basis function kernel;risk management;manifold;kernel principal component analysis;computer science;machine learning;pattern recognition;reproducing kernel hilbert space;graph kernel;mathematics;tree kernel;variable kernel density estimation;polynomial kernel;representer theorem;kernel smoother;hilbert space	ML	24.334965253784222	-40.00706591301448	183648
1cba4c08b3880b7481a1c04f53abee28d87907b7	recursive task mapping using adaptive system partitioning based on feature vectors	adaptive system;feature vector		adaptive system;feature (machine learning);recursion (computer science)	J. C. Jacob;S.-Y. Lee	1995			adaptive system;feature (computer vision);recursion;machine learning;computer science;feature vector;artificial intelligence;pattern recognition	Robotics	18.77738307022563	-44.077563111073374	183734
5bd830a02d7cf589d7144dbaa5e639d86691f725	classification in high-dimensional feature spaces: random subsample ensemble	performance measure;ensemble classification;dimensionality curse random subsample ensemble machine learning ensembles high dimensional feature spaces lower dimensional feature subspaces classification subtask domain base learner ensemble machine learner context random subsample ensemble benchmark machine learners data sets algorithm scalability data sparsity information loss;machine learning algorithms;machine learning ensembles;random subspace curse of dimensionality ensemble classification high dimensional feature space;information loss;high dimensionality;support vector machines;pattern classification data analysis feature extraction learning artificial intelligence;training;data sparsity;curse of dimensionality;space technology machine learning algorithms machine learning scalability computational complexity principal component analysis application software performance evaluation computational efficiency computer science;feature space;base learner;dimensionality curse;high dimensional feature space;accuracy;data analysis;classification subtask domain;machine learning;algorithm scalability;random subspace;feature extraction;classification algorithms;prediction accuracy;random subsample ensemble;pattern classification;high dimensional feature spaces;learning artificial intelligence;data sets;lower dimensional feature subspaces;ensemble machine learner context;benchmark machine learners	This paper presents application of machine learning ensembles, which randomly project the original high dimensional feature space onto multiple lower dimensional feature subspaces, to classification problems with high-dimensional feature spaces. The motivation is to address challenges associated with algorithm scalability, data sparsity and information loss due to the so-called curse of dimensionality. The original high dimensional feature space is randomly projected onto a number of lower-dimensional feature subspaces. Each of these subspaces constitutes the domain of a classification subtask, and is associated with a base learner within an ensemble machine-learner context. Such an ensemble conceptualization is called as random subsample ensemble. Simulation results performed on data sets with up to 20,000 features indicate that the random subsample ensemble classifier performs comparably to other benchmark machine learners based on performance measures of prediction accuracy and cpu time. This finding establishes the feasibility of the ensemble and positions it to tackle classification problems with even much higher dimensional feature spaces.	algorithm;algorithmic efficiency;benchmark (computing);central processing unit;computation;conceptualization (information science);curse of dimensionality;ensemble learning;feature vector;machine learning;randomness;scalability;simulation;spaces;sparse matrix	Gürsel Serpen;Santhosh Pathical	2009	2009 International Conference on Machine Learning and Applications	10.1109/ICMLA.2009.26	statistical classification;support vector machine;curse of dimensionality;feature vector;feature extraction;computer science;machine learning;pattern recognition;data mining;accuracy and precision;ensemble learning;data analysis;feature;data set	ML	18.467424048932894	-44.72823123594217	184086
2075002e87bef14da12e4adf0bf30522be62fda9	weakly supervised clustering: learning fine-grained signals from coarse side information		Consider a classification problem where we do not have access to labels for individual training examples, but only have average labels over subpopulations. We give practical examples of this setup, and show how these classification tasks can usefully be analyzed as weakly supervised clustering problems. We propose three approaches to solving the weakly supervised clustering problem, including a latent variables model that performs well in our experiments. We illustrate our methods on an industry dataset that was the original motivation for this research.	categorization;cluster analysis;experiment;latent variable;my life as a teenage robot	Stefan Wager;Alexander Blocker;Niall Cardin	2013	CoRR		computer vision;machine learning;data mining	ML	21.33025594029452	-44.500247748762995	184253
0c7cdbf203472e97438c7f85d35486823027e5e6	variable selection using svm-based criteria		We propose new methods to evaluate variable subset relevance with a view to variable selection. Relevance criteria are derived from Support Vector Machines and are based on weight vector ‖w‖2 or generalization error bounds sensitivity with respect to a variable. Experiments on linear and non-linear toy problems and real-world datasets have been carried out to assess the effectiveness of these criteria. Results show that the criterion based on weight vector derivative achieves good results and performs consistently well over the datasets we used.	feature selection;generalization error;nonlinear system;relevance;support vector machine	Alain Rakotomamonjy	2003	Journal of Machine Learning Research			ML	19.560496610824213	-39.778696878716644	184306
20d4181dfecc3003b28e3ff6ee4fe6312e5be2ed	integrating features and similarities: flexible models for heterogeneous multiview data		We present a probabilistic framework for learning with heterogeneous multiview data where some views are given as ordinal, binary, or real-valued feature matrices, and some views as similarity matrices. Our framework has the following distinguishing aspects: (i) a unified latent factor model for integrating information from diverse feature (ordinal, binary, real) and similarity based views, and predicting the missing data in each view, leveraging view correlations; (ii) seamless adaptation to binary/multiclass classification where data consists of multiple feature and/or similarity-based views; and (iii) an efficient, variational inference algorithm which is especially flexible in modeling the views with ordinalvalued data (by learning the cutpoints for the ordinal data), and extends naturally to streaming data settings. Our framework subsumes methods such as multiview learning and multiple kernel learning as special cases. We demonstrate the effectiveness of our framework on several real-world and benchmarks datasets.	algorithm;benchmark (computing);cluster analysis;latent variable;missing data;multiclass classification;multiple kernel learning;ordinal data;recommender system;seamless3d;statistical classification;stream (computing);variational principle	Wenzhao Lian;Piyush Rai;Esther Salazar;Lawrence Carin	2015			computer science;machine learning;pattern recognition;data mining	AI	24.052503572385945	-44.80070535586888	184485
b881290b49952c3d062f5db6512228522d5199af	development of kernel fisher discriminant model using the cross-entropy method	eigenvalues and eigenfunctions;cross entropy;optimal solution;eigen decomposition method;optimisation;eigen decomposition;kernel;kernel method accuracy cross entropy discriminant analysis eigen decomposition;fast rates of convergence;linear discriminate analysis;kernel shape curve fitting phase detection image segmentation iterative algorithms pattern recognition information science data mining computer graphics;eigen decomposition method kernel fisher discriminant model cross entropy method nonlinear discriminant analysis optimization problem class variance fisher lda;data mining;feature space;nonlinear discriminant analysis;discriminant analysis;optimization problem;decomposition method;accuracy;optimisation eigenvalues and eigenfunctions entropy;kernel fisher discriminant;class variance;fisher lda;kernel fisher discriminant model;kernel method;optimization;entropy;numerical experiment;cross entropy method;algorithm design and analysis;sonar	In this paper, the cross-entropy (CE) method is proposed to solve non-linear discriminant analysis or Kernel Fisher discriminant (CE-KFD) analysis. CE through certain steps can find the optimal or near optimal solution with a fast rate of convergence for optimization problem. While, KFD is to solve problem of Fisher’s linear discriminant in a kernel feature space F by maximizing between class variance and minimizing within class variance. Through the numerical experiments, we found that CE-KFD demonstrates the high accuracy of the results compared to the traditional methods, Fisher LDA and kernel Fisher (KFD) with eigen decomposition method.	algorithm;cross entropy;cross-entropy method;eigen (c++ library);experiment;feature vector;kernel (operating system);linear discriminant analysis;mathematical optimization;nonlinear system;numerical analysis;optimization problem;rate of convergence	Budi Santosa;Andiek Sunarto	2009	2009 International Conference of Soft Computing and Pattern Recognition	10.1109/SoCPaR.2009.138	optimization problem;algorithm design;kernel method;entropy;mathematical optimization;kernel fisher discriminant analysis;kernel;eigendecomposition of a matrix;decomposition method;cross-entropy method;feature vector;computer science;machine learning;pattern recognition;optimal discriminant analysis;mathematics;accuracy and precision;linear discriminant analysis;cross entropy;fisher kernel;sonar;statistics	Vision	24.01642063634136	-39.84611394765901	184511
15bce8864a15c20cf483e18099f3601b94673565	premise selection for theorem proving by deep graph embedding		We propose a deep learning-based approach to the problem of premise selection: selecting mathematical statements relevant for proving a given conjecture. We represent a higher-order logic formula as a graph that is invariant to variable renaming but still fully preserves syntactic and semantic information. We then embed the graph into a vector via a novel embedding method that preserves the information of edge ordering. Our approach achieves state-of-the-art results on the HolStep dataset, improving the classification accuracy from 83% to 90.3%.	deep learning;feature selection;first-order logic;graph embedding	Mingzhe Wang;Yihe Tang;Jian Wang;Jia Deng	2017			premise;discrete mathematics;combinatorics;graph embedding;machine learning;artificial intelligence;deep learning;null graph;voltage graph;automated theorem proving;embedding;invariant (mathematics);mathematics	ML	20.954010857254644	-44.40221162746537	187197
a6e046b5b5689380a7af8661cb68e5cdaafdb00c	ensemble clustering using factor graph	factor graph;ensemble clustering;belief propagation;super object;automatic cluster number estimate	In this paper, we propose a new ensemble clustering approach termed ensemble clustering using factor graph (ECFG). Compared to the existing approaches, our approach has three main advantages: (1) the cluster number is obtained automatically and need not to be specified in advance; (2) the reliability of each base clustering can be estimated in an unsupervised manner and exploited in the consensus process; (3) our approach is efficient for processing ensembles with large data sizes and large ensemble sizes. In this paper, we introduce the concept of super-object, which serves as a compact and adaptive representation for the ensemble data and significantly facilitates the computation. Through the probabilistic formulation, we cast the ensemble clustering problem into a binary linear programming (BLP) problem. The BLP problem is NP-hard. To solve this optimization problem, we propose an efficient solver based on factor graph. The constrained objective function is represented as a factor graph and the max-product belief propagation is utilized to generate the solution insensitive to initialization and converged to the neighborhood maximum. Extensive experiments are conducted on multiple real-world datasets, which demonstrate the effectiveness and efficiency of our approach against the state-of-the-art approaches. & 2015 Elsevier Ltd. All rights reserved.	approximation algorithm;belief propagation;best, worst and average case;cluster analysis;computation;consensus clustering;experiment;factor graph;linear programming;mathematical optimization;np-hardness;non-maskable interrupt;optimization problem;pattern recognition;software propagation;solver;unsupervised learning	Dong Huang;Jianhuang Lai;Chang-Dong Wang	2016	Pattern Recognition	10.1016/j.patcog.2015.08.015	correlation clustering;constrained clustering;mathematical optimization;k-medians clustering;fuzzy clustering;computer science;machine learning;factor graph;consensus clustering;pattern recognition;mathematics;cluster analysis;statistics;belief propagation	AI	20.521293288806042	-42.1165132999771	187675
61614387208b9f98795513823b68f002b6a4d4e3	exploiting task-feature co-clusters in multi-task learning	task feature relationships;co cluster structure;multi task learning	In multi-task learning, multiple related tasks are considered simultaneously, with the goal to improve the generalization performance by utilizing the intrinsic sharing of information across tasks. This paper presents a multitask learning approach by modeling the task-feature relationships. Specifically, instead of assuming that similar tasks have similar weights on all the features, we start with the motivation that the tasks should be related in terms of subsets of features, which implies a co-cluster structure. We design a novel regularization term to capture this task-feature co-cluster structure. A proximal algorithm is adopted to solve the optimization problem. Convincing experimental results demonstrate the effectiveness of the proposed algorithm and justify the idea of exploiting the task-feature relationships.	algorithm;computer cluster;computer multitasking;mathematical optimization;multi-task learning;optimization problem	Linli Xu;Aiqing Huang;Jianhui Chen;Enhong Chen	2015			multi-task learning;simulation;computer science;artificial intelligence;machine learning	AI	23.188177005159154	-43.474377151270765	188444
a9633f042724c5ba572f52061ad20b5a36ec69c2	discriminant analysis based on kernelized decision boundary for face recognition	minimisation;reconnaissance visage;busqueda informacion;analisis contenido;minimization;base donnee;analisis estadistico;image processing;facies;methode noyau;structural risk minimization;information retrieval;optimal decision;analisis decision;database;procesamiento imagen;base dato;minimizacion;kernel fisher;traitement image;decision analysis;text classification;discriminant analysis;analyse discriminante;feature vector;decision optimale;methode matricielle;large scale;analisis discriminante;content analysis;face recognition;statistical analysis;recherche information;metodo nucleo;machine exemple support;analyse statistique;matrix method;pattern recognition;metodo matriz;kernel method;reconnaissance forme;support vector machine;maquina ejemplo soporte;analyse contenu;vector support machine;reconocimiento patron;analyse decision;decision optimal	Computer School, Harbin Institute of Technology, China ICT-ISVISION Joint R&D Lab for face recognition, ICT, CAS, China {Bczhang, Xlchen, Wgao}@jdl.ac.cn Abstract. A novel nonlinear discriminant analysis method, Kernelized Decision Boundary Analysis (KDBA), is proposed in our paper, whose Decision Boundary feature vectors are the normal vector of the optimal Decision Boundary in terms of the Structure Risk Minimization principle. We also use a simple method to prove a property of Support Vector Machine (SVM) algorithm, which is combined with the optimal Decision Boundary Feature matrix to make our method consistent with the Kernel Fisher method(KFD). Moreover, KDBA is easily used in its applications, and the traditional Decision Boundary Analysis implementations are computationally expensive and sensitive to the size of the problem. Text classification problem is first used to testify the effectiveness of KDBA. Then experiments on the large-scale face database, the CAS-PEAL database, have illustrated its excellent performance compared with some popular face recognition methods such as Eigenface, Fisherface, and KFD.	algorithm;analysis of algorithms;decision boundary;eigenface;experiment;facial recognition system;kernel (operating system);kernel method;linear discriminant analysis;nonlinear system;normal (geometry);statistical classification;support vector machine	Baochang Zhang;Xilin Chen;Wen Gao	2005		10.1007/11527923_101	matrix method;support vector machine;minimisation;kernel method;optimal decision;feature vector;facies;structural risk minimization;content analysis;image processing;decision analysis;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;decision boundary	Vision	23.54046653863088	-39.264042245858	188544
5e7d9491138d9e47fe63c28b6b6254add834dbba	effective crowd expertise modeling via cross domain sparsity and uncertainty reduction		Characterizations of crowd expertise is vital to online applications where the crowd plays a central role, such as StackExchange for question-answering and LinkedIn as a workforce market. With accurately estimated worker expertise, new jobs can be assigned to the right workers more effectively and efficiently. Most existing methods solely rely on the sparse worker-job interactions, leading to poorly estimated expertise that does not generalize well to a large amount of unseen jobs. Though transfer learning can utilize external domains to mitigate the sparsity, the auxiliary domains can themselves suffer from incomplete information, leading to inferior performance. There is a lack of principled framework to handle the sparse and incomplete data to achieve better expertise modeling. Based on multitask learning, we propose a framework that uses the knowledge learned from one domain to gradually resolve the data sparsity or incompleteness problem in the other alternatively. Experimental results on several question-answering datasets demonstrate the effectiveness and convergence of the iterative framework.	computer multitasking;interaction;iterative method;job stream;question answering;sparse matrix;stack exchange	Sihong Xie;Qingbo Hu;Weixiang Shao;Jingyuan Zhang;Jing Gao;Wei Fan;Philip S. Yu	2016		10.1137/1.9781611974348.73	computer vision;simulation;computer science;machine learning	AI	19.166827831325776	-43.82477022382086	188619
1e71dd7c1a5e11b33b0ec7e4d2824320deaa1a91	enhancing binary relevance for multi-label learning with controlled label correlations exploitation		Binary relevance (BR) is regarded as the most intuitive solution to learn from multi-label data, which decomposes the multi-label learning task into a number of independent binary learning tasks (one per class label). To amend its potential weakness of ignoring label correlations, many correlation-enabling extensions to BR have been proposed based on two major strategies, i.e. assum- ing random correlations with chaining structure or taking full-order correlations with stacking structure. However, in both strategies label correlations are only ex- ploited in an uncontrolled manner, which may be problematic when error-prone and uncorrelated class labels arise. In this paper, to fulfill controlled label corre- lations exploitation, a novel enhancement to BR is proposed based on a two-stage filtering procedure. In the first stage, error-prone class labels are pruned from the label space based on holdout validation. In the second stage, closely-related class labels are identified based on supervised feature selection by viewing unpruned labels as features. Extensive experiments across fourteen multi-label data sets confirm the superiority of controlled label correlations exploitation, especially when large number class labels exist in the label space.	multi-label classification;relevance	Yu-Kun Li;Min-Ling Zhang	2014		10.1007/978-3-319-13560-1_8	computer science;artificial intelligence;machine learning;data mining	Vision	23.022360815389465	-44.38837270291375	188649
2884ff0d58a66d42371b548526d685760e514043	large-scale nonlinear facial image classification based on approximate kernel extreme learning machine	learning artificial intelligence approximation theory face recognition image classification image representation;large scale nonlinear facial image classification memory requirements standard elm approach facial image representations facial image datasets approximate kernel extreme learning machine;kernel training approximation methods training data optimization time complexity;approximate methods nonlinear facial image classification extreme learning machine	In this paper, we propose a scheme that can be used in large-scale nonlinear facial image classification problems. An approximate solution of the kernel Extreme Learning Machine classifier is formulated and evaluated. Experiments on two publicly available facial image datasets using two popular facial image representations illustrate the effectiveness and efficiency of the proposed approach. The proposed Approximate Kernel Extreme Learning Machine classifier is able to scale well in both time and memory, while achieving good generalization performance. Specifically, it is shown that it outperforms the standard ELM approach for the same time and memory requirements. Compared to the original kernel ELM approach, it achieves similar (or better) performance, while scaling well in both time and memory with respect to the training set cardinality.	approximation algorithm;computer performance;computer vision;image scaling;kernel (operating system);nonlinear system;requirement;test set	Alexandros Iosifidis;Anastasios Tefas;Ioannis Pitas	2015	2015 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2015.7351242	computer vision;radial basis function kernel;machine learning;pattern recognition;mathematics	Vision	22.48361803014775	-40.76266159383672	189192
8edd97ea4f71cf2b785a051155d379f889e619b3	boosting with structural sparsity	stopping criterion;parameter space	We derive generalizations of AdaBoost and related gradient-based coordinate descent methods that incorporate sparsity-promoting penalties for the norm of the predictor that is being learned. The end result is a family of coordinate descent algorithms that integrate forward feature induction and back-pruning through regularization and give an automatic stopping criterion for feature induction. We study penalties based on the l1, l2, and l∞ norms of the predictor and introduce mixed-norm penalties that build upon the initial penalties. The mixed-norm regularizers facilitate structural sparsity in parameter space, which is a useful property in multiclass prediction and other related tasks. We report empirical results that demonstrate the power of our approach in building accurate and structurally sparse models.	adaboost;algorithm;boosting (machine learning);coordinate descent;gradient;kerrison predictor;mathematical model;sparse matrix	John C. Duchi;Yoram Singer	2009		10.1145/1553374.1553412	mathematical optimization;computer science;machine learning;pattern recognition;mathematics;parameter space;statistics	ML	23.176120218592015	-43.50832441723283	189738
bf6e1cd21cc2be1ee3805e271aa718e2ab0fa9b2	a semi-supervised framework for mmms-induced fuzzy co-clustering with virtual samples		Although the goal of clustering is to reveal structural information from unlabeled datasets, in cases with partial structural supervisions, semi-supervised clustering is expected to improve partition quality. However, in many real applications, it may cause additional costs to provide an enough amount of supervised objects with class labels. A virtual sample approach is a practical technique for improving classification quality in semi-supervised learning, in which additional virtual samples are generated from supervised objects. In this research, the virtual sample approach is adopted in semi-supervised fuzzy co-clustering, where the goal is to reveal object-item pairwise cluster structures from cooccurrence information among them. Several experimental results demonstrate the characteristics of the proposed approach.	biclustering;semiconductor industry	Daiji Tanaka;Katsuhiro Honda;Seiki Ubukata;Akira Notsu	2016	Adv. Fuzzy Systems	10.1155/2016/5206048	computer science;machine learning;pattern recognition;data mining	OS	20.565563852830888	-42.81086859365861	189829
9e8f8e427b5ac7edfb219bd9cbd0d7d77a6d0e31	transfer ordinal label learning	transfer learning classifier selection domain adaptation ordinal regression sentiment analysis source sample selection bias;journal article;pattern classification;pattern classification learning artificial intelligence;ordinal classifier ensemble transfer ordinal label learning labeled data classifier design informative label acquisition source sample selection bias source domain distribution;learning artificial intelligence	Designing a classifier in the absence of labeled data is becoming a common encounter as the acquisition of informative labels is often difficult or expensive, particularly on new uncharted target domains. The feasibility of attaining a reliable classifier for the task of interest is embarked by some in transfer learning, where label information from relevant source domains is considered for complimenting the design process. The core challenge arising from such endeavors, however, is the induction of source sample selection bias, such that the trained classifier has the tendency of steering toward the distribution of the source domain. In addition, this bias is deemed to become more severe on data involving multiple classes. Considering this cue, our interest in this paper is to address such a challenge in the target domain, where ordinal labeled data are unavailable. In contrast to the previous works, we propose a transfer ordinal label learning paradigm to predict the ordinal labels of target unlabeled data by spanning the feasible solution space with ensemble of ordinal classifiers from the multiple relevant source domains. Specifically, the maximum margin criterion is considered here for the construction of the target classifier from an ensemble of source ordinal classifiers. Theoretical analysis and extensive empirical studies on real-world data sets are presented to study the benefits of the proposed method.	class;experiment;feasible region;file spanning;information;kernel;maximum cut;mental suffering;ninety nine;ordinal position;ordinal data;pitted medical device material;programming paradigm;selection bias;signature;statistical classification;tlr4 gene;tracer;benefit	Chun-Wei Seah;Ivor W. Tsang;Yew-Soon Ong	2013	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2013.2268541	computer science;artificial intelligence;machine learning;pattern recognition;data mining;statistics	ML	20.06795090278336	-43.70809659380092	189859
c1e07099cdd4a7f67fb9e51903b5d53458478682	semi-supervised distance metric learning in high-dimensional spaces by using equivalence constraints		This paper introduces a semi-supervised distance metric learning algorithm which uses pairwise equivalence (similarity and dissimilarity) constraints to discover the desired groups within high-dimensional data. In contrast to the traditional full rank distance metric learning algorithms, the proposed method can learn nonsquare projection matrices that yield low rank distance metrics. This brings additional benefits such as visualization of data samples and reducing the storage cost, and it is more robust to overfitting since the number of estimated parameters is greatly reduced. The proposed method works in both the input and kernel induced-feature space, and the distance metric is found by a gradient descent procedure that involves an eigen-decomposition in each step. Experimental results on high-dimensional visual object classification problems show that the computed distance metric improves the performances of the subsequent classification and clustering algorithms.	algorithm;cluster analysis;dimensionality reduction;eigen (c++ library);feature vector;gradient descent;kernel (operating system);machine learning;mathematical optimization;overfitting;performance;semiconductor industry;sigmoid function;spaces;turing completeness	Hakan Cevikalp	2009		10.1007/978-3-642-11840-1_18	mathematical optimization;combinatorics;discrete mathematics;distance matrix;metric;intrinsic metric;machine learning;chebyshev distance;mathematics;geometry;equivalence of metrics;string metric;jaro–winkler distance;statistics	ML	24.54767213095978	-41.295126586232264	189986
f759bbdb34ba064c36d0942becbd7925be8405b3	support vector mixture for classification and regression problems	quadratic programming;quadratic program;radial basis function networks support vector machine mixture of experts model pattern classification regression analysis quadratic programming dimensionality polynomial networks;quadratic programming learning systems feedforward neural nets pattern classification statistical analysis;hierarchical mixture of experts;support vector machines support vector machine classification quadratic programming risk management learning systems postal services databases iron jacobian matrices piecewise linear techniques;support vector;learning systems;statistical analysis;radial basis function network;pattern classification;feedforward neural nets;support vector machine	In this paper, we study the incorporation of the support vector machine (SVM) into the (hierarchical) mixture of experts model to form a support vector mixture. We show that, in both classification and regression problems, the use of a support vector mixture leads to quadratic programming (QP) problems that are very similar to those for a SVM, with no increase in the dimensionality of the QP problems. Moreover, a support vector mixture, besides allowing for the use of different experts in different regions of the input space, also supports easy combination of different architectures such as polynomial networks and radial basis function networks.	alpha compositing;computation;mixture model;overhead (computing);polynomial;quadratic programming;radial (radio);radial basis function;statistical classification;support vector machine	J. Tin-Yau Kwok	1998		10.1109/ICPR.1998.711129	support vector machine;least squares support vector machine;mathematical optimization;feature vector;computer science;machine learning;pattern recognition;mathematics;sequential minimal optimization;relevance vector machine;quadratic programming;structured support vector machine	ML	20.001899832655322	-39.01083429256864	190072
e2955af0223bd959c37e7d839db61bba68929a4d	domain class consistency based transfer learning for image classification across domains		Distribution mismatch between the modeling data and the query data is a known domain adaptation issue in machine learning. To this end, in this paper, we propose a l2,1-norm based discriminative robust kernel transfer learning (DKTL) method for high-level recognition tasks. The key idea is to realize robust domain transfer by simultaneously integrating domain-class-consistency (DCC) metric based discriminative subspace learning, kernel learning in reproduced kernel Hilbert space, and representation learning between source and target domain. The DCC metric includes two properties: domain-consistency used to measure the between-domain distribution discrepancy and class-consistency used to measure the within-domain class separability. The essential objective of the proposed transfer learning method is to maximize the DCC metric, which is equivalently to minimize the domain-class-inconsistency (DCIC), such that domain distribution mismatch and class inseparability are well formulated and unified simultaneously. The merits of the proposed method include (1) the robust sparse coding selects a few valuable source data with noises (outliers) removed during knowledge transfer, and (2) the proposed DCC metric can pursue more discriminative subspaces of different domains. As a result, the maximum class-separability is also well guaranteed. Extensive experiments on a number of visual datasets demonstrate the superiority of the proposed method over other state-of-the-art domain adaptation and transfer learning methods.	benchmark (computing);coefficient;computer vision;data point;discrepancy function;discriminative model;domain adaptation;eigen (c++ library);experiment;high- and low-level;hilbert space;kernel (operating system);lagrange multiplier;linear separability;machine learning;maxima and minima;natural deduction;neural coding;shadow volume;source data;sparse matrix;the matrix	Lei Zhang;Jian Yang;David Zhang	2017	Inf. Sci.	10.1016/j.ins.2017.08.034	instance-based learning;semi-supervised learning;discriminative model;artificial intelligence;mathematics;machine learning;online machine learning;inductive transfer;active learning (machine learning);multi-task learning;feature learning;pattern recognition	AI	24.043249941780626	-42.98952705742146	192332
04877884c459d34fbc3d2b4b10477e292b0b4ce8	joint multi-label classification and label correlations with missing labels and feature selection		Abstract Multi-label classification problem is a key learning task where each instance may belong to multiple class labels simultaneously. However, there exists four main challenges: (a) designing an effective multi-label classifier, (b) learning the high-order asymmetric label correlations automatically, (c) reducing the dimensionality of feature space, (d) dealing with both the full labels and missing labels cases. In this paper, we directly address the above four problems in a unified learning framework, and propose a novel Multi-Label classification approach joint with label correlations, Missing labels and Feature selection, named MLMF. The proposed MLMF not only makes the joint learning of independent binary classifiers, but also allows the joint learning of multi-label classification and label correlations. Meanwhile, the shared sparse feature structure among labels are selected by l 2 , 1 -norm. Furthermore, MLMF can also handle missing labels. Experimental results on sixteen multi-label data sets in terms of six evaluation criteria demonstrate that MLMF outperforms the state-of-the-art multi-label classification algorithms.		Zhi-Fen He;Ming Yang;Yang Gao;Hui-Dong Liu;Yilong Yin	2019	Knowl.-Based Syst.	10.1016/j.knosys.2018.08.018	machine learning;artificial intelligence;feature selection;multi-label classification;existential quantification;feature vector;statistical classification;curse of dimensionality;feature structure;computer science;data set	Vision	23.439011293880885	-43.60726606956806	192460
5b7e04efd8f967c69130a4e08b9d659e00ebc5cd	multi-class leveraged k-nn for image classification	gaussian kernel;k nearest neighbor;feature space;computer vision	The k-nearest neighbors (k-NN) classification rule is still an essential tool for computer vision applications, such as scene recognition. However, k-NN still features some major drawbacks, which mainly reside in the uniform voting among the nearest prototypes in the feature space. In this paper, we propose a new method that is able to learn the “relevance” of prototypes, thus classifying test data using a weighted k-NN rule. In particular, our algorithm, called Multi-class Leveraged k-nearest neighbor (MLNN), learns the prototype weights in a boosting framework, by minimizing a surrogate exponential risk over training data. We propose two main contributions for improving computational speed and accuracy. On the one hand, we implement learning in an inherently multiclass way, thus providing significant computation time reduction over one-versus-all approaches. Furthermore, the leveraging weights enable effective data selection, thus reducing the cost of k-NN search at classification time. On the other hand, we propose a kernel generalization of our approach to take into account real-valued similarities between data in the feature space, thus enabling more accurate estimation of the local class density. We tested MLNN on three datasets of natural images. Results show that MLNN significantly outperforms classic k-NN and weighted k-NN voting. Furthermore, using an adaptive Gaussian kernel provides significant performance improvement. Finally, the best results are obtained when using MLNN with an appropriate learned metric distance.	computation;computer vision;feature vector;inner class;k-nearest neighbors algorithm;prototype;relevance;test data;time complexity	Paolo Piro;Richard Nock;Frank Nielsen;Michel Barlaud	2010		10.1007/978-3-642-19318-7_6	computer science;machine learning;pattern recognition;data mining;statistics	ML	17.523611614115943	-41.016261206721964	193266
2536978d9514a29467b45b67563d8b03740909cf	a support vector approach to censored targets	survival analysis model support vector technique censored target;support vector machines;convex programming;perforation;support vector machines regression analysis;controlled experiment;support vector machines training data oncological surgery data mining performance analysis data analysis kernel clustering algorithms support vector machine classification statistical analysis;support vector;survival time;support vector technique;censored data;censored target;survival analysis;global optimization;regression analysis;support vector machine;survival analysis model	Censored targets, such as the time to events in survival analysis, can generally be represented by intervals on the real line. In this paper, we propose a novel support vector technique (named SVCR) for regression on censored targets. SVCR inherits the strengths of support vector methods, such as a globally optimal solution by convex programming, fast training speed and strong generalization capacity. In contrast to ranking approaches to survival analysis, our approach is able not only to achieve superior ordering performance, but also to predict the survival time very well. Experiments show a significant performance improvement when the majority of the training data is censored. Experimental results on several survival analysis datasets demonstrate that SVCR is very competitive against classical survival analysis models.	censoring (statistics);convex optimization;maxima and minima;run time (program lifecycle phase);scalability	Pannagadatta K. Shivaswamy;Wei Chu;Martin Jansche	2007	Seventh IEEE International Conference on Data Mining (ICDM 2007)	10.1109/ICDM.2007.93	support vector machine;computer science;machine learning;pattern recognition;data mining;statistics;global optimization	Robotics	20.628517119063503	-39.935140220265005	193414
789942fea08ece738ba6d7ec944051b40fc58cd2	multimodal similarity gaussian process latent variable model		Data from real applications involve multiple modalities representing content with the same semantics from complementary aspects. However, relations among heterogeneous modalities are simply treated as observation-to-fit by existing work, and the parameterized modality specific mapping functions lack flexibility in directly adapting to the content divergence and semantic complicacy in multimodal data. In this paper, we build our work based on the Gaussian process latent variable model (GPLVM) to learn the non-parametric mapping functions and transform heterogeneous modalities into a shared latent space. We propose multimodal Similarity Gaussian Process latent variable model (m-SimGP), which learns the mapping functions between the intra-modal similarities and latent representation. We further propose multimodal distance-preserved similarity GPLVM (m-DSimGP) to preserve the intra-modal global similarity structure, and multimodal regularized similarity GPLVM (m-RSimGP) by encouraging similar/dissimilar points to be similar/dissimilar in the latent space. We propose m-DRSimGP, which combines the distance preservation in m-DSimGP and semantic preservation in m-RSimGP to learn the latent representation. The overall objective functions of the four models are solved by simple and scalable gradient decent techniques. They can be applied to various tasks to discover the nonlinear correlations and to obtain the comparable low-dimensional representation for heterogeneous modalities. On five widely used real-world data sets, our approaches outperform existing models on cross-modal content retrieval and multimodal classification.	biologic preservation;gaussian process;genetic heterogeneity;gradient descent;latent variable model;modal logic;modality (human–computer interaction);multimodal interaction;nonlinear system;normal statistical distribution;scalability;semantic similarity;similarity learning	Guoli Song;Shuhui Wang;Qingming Huang;Qi Tian	2017	IEEE Transactions on Image Processing	10.1109/TIP.2017.2713045	modalities;artificial intelligence;latent variable model;mathematics;artificial neural network;pattern recognition;data modeling;multimodal learning;parameterized complexity;probabilistic latent semantic analysis;machine learning;gaussian process	ML	22.243547060478353	-44.03017844442646	194336
67d66be0e91c8464c1fca4ca7730c0b01966e5d9	quadratic optimization fine tuning for the support vector machines learning phase	decomposition;support vector machines;initialization strategies;quadratic optimization	This work presents a comparative analysis of specific, rather than general, mathematical programming implementation techniques of the quadratic optimization problem (QP) based on Support Vector Machines (SVM) learning process. Considering the Karush-Kuhn-Tucker (KKT) optimality conditions, we present a strategy of implementation of the SVM-QP following three classical approaches: (i) active set, also divided in primal and dual spaces, methods, (ii) interior point methods and (iii) linearization strategies. We also present the general extension to treat large-scale applications consisting in a general decomposition of the QP problem into smaller ones, conserving the exact solution approach. In the same manner, we propose a set of heuristics to take into account for a better than a random selection process for the initialization of the decomposition strategy. We compare the performances of the optimization strategies using some well-known benchmark databases.	mathematical optimization;quadratic programming;support vector machine	Miguel González-Mendoza;Rodolfo Ibarra-Orozco;Ariel L. García-Gamboa;Neil Hernández-Gress;Jaime Mora-Vargas;Juan Carlos López Pimentel	2014	Expert Syst. Appl.	10.1016/j.eswa.2013.08.019	support vector machine;mathematical optimization;computer science;machine learning;control theory;mathematics;decomposition;quadratic programming	ML	21.682387826196287	-38.97124961399154	195569
68d2da67156267f27e70f83c3393bfbb80bb620d	learning dynamic bayesian network discriminatively for human activity recognition	belief networks;object recognition;object recognition belief networks learning artificial intelligence maximum likelihood estimation;maximum likelihood estimation;training bayesian methods hidden markov models humans data models testing optimization;learning artificial intelligence;em algorithm dynamic bayesian network human activity recognition temporal events dbn models maximizing likelihood expected likelihood highest posterior probability classification criteria discriminative parameter learning approach hybrid dbn complete data incomplete data	The purpose of this paper is to develop an approach to learn dynamic Bayesian network (DBN) discriminatively for human activity recognition. DBN is a generative model widely used for modeling temporal events in human activity recognition. The parameters of the DBN models are usually learned through maximizing likelihood or expected likelihood. However, activity is often recognized through identifying the activity class with the highest posterior probability. Hence, there is discrepancy between the learning and classification criteria. In this paper, we focus on developing a discriminative parameter learning approach for hybrid DBNs that has a consistent criterion during training and testing. Our approach is applicable to parameter learning with both complete data and incomplete data, and empirical studies show the proposed discriminative learning approach outperforms the maximum likelihood or EM algorithm in activity recognition tasks.	activity recognition;discrepancy function;discriminative model;dynamic bayesian network;expectation–maximization algorithm;experiment;generative model;statistical classification;test set	Xiaoyang Wang;Qiang Ji	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;maximum likelihood;statistics	AI	19.602164847562843	-41.11786516439737	195746
77b355a1806265a9d1b2a38b98f352b9c71c378d	comparing clustering with pairwise and relative constraints: a unified framework	pairwise constraints;relative constraints;semi supervised clustering	Clustering can be improved with the help of side information about the similarity relationships among instances. Such information has been commonly represented by two types of constraints: pairwise constraints and relative constraints, regarding similarities about instance pairs and triplets, respectively. Prior work has mostly considered these two types of constraints separately and developed individual algorithms to learn from each type. In practice, however, it is critical to understand/compare the usefulness of the two types of constraints as well as the cost of acquiring them, which has not been studied before. This paper provides an extensive comparison of clustering with these two types of constraints. Specifically, we compare their impacts both on human users that provide such constraints and on the learning system that incorporates such constraints into clustering. In addition, to ensure that the comparison of clustering is performed on equal ground (without the potential bias introduced by different learning algorithms), we propose a probabilistic semi-supervised clustering framework that can learn from either type of constraints. Our experiments demonstrate that the proposed semi-supervised clustering framework is highly effective at utilizing both types of constraints to aid clustering. Our user study provides valuable insights regarding the impact of the constraints on human users, and our experiments on clustering with the human-labeled constraints reveal that relative constraint is often more efficient at improving clustering.	algorithm;cluster analysis;experiment;machine learning;semi-supervised learning;semiconductor industry;tagged union;unified framework;usability testing	Yuanli Pei;Xiaoli Z. Fern;Teresa Vania Tjahja;Rómer Rosales	2016	TKDD	10.1145/2996467	correlation clustering;constrained clustering;fuzzy clustering;machine learning;pattern recognition;cure data clustering algorithm;data mining;mathematics;cluster analysis;brown clustering;clustering high-dimensional data;conceptual clustering	AI	20.420522549940035	-42.69181650513516	196058
daca9d03c1c951ed518248de7f75ff51e5c272cb	feature learning using bayesian linear regression model	covariance structure feature learning bayesian linear regression model data representation machine learning domain knowledge unsupervised learning restricted boltzmann machine rbm factor analysis statistical method;data models computational modeling accuracy bayes methods feature extraction testing linear regression;regression analysis covariance analysis data structures learning artificial intelligence	Data representation plays a key role in many machine learning tasks. Specific domain knowledge can help design some features, but it often needs a long time to handcraft them. On the other hand, unsupervised learning can automatically learn a good representation of either labeled or unlabeled data. Currently one of the dominant approaches is the restricted Boltzmann machine (RBM). In this paper, we investigate an alternative approach for feature learning, which is based on Bayesian linear regression model. This model can also be denoted as Factor analysis, which is a statistical method for modeling the covariance structure of high dimensional data, but has not been used for feature learning. We will compare the proposed framework with RBM on different kinds of computer vision applications. Experiment results on different datasets are reported to demonstrate the effectiveness of the proposed feature learning framework.	bayesian network;computer vision;converge;expectation–maximization algorithm;experiment;factor analysis;feature learning;hidden variable theory;machine learning;restricted boltzmann machine;unsupervised learning	Siqi Nie;Qiang Ji	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.267	semi-supervised learning;unsupervised learning;feature learning;multi-task learning;algorithmic learning theory;feature vector;feature;wake-sleep algorithm;computer science;online machine learning;machine learning;pattern recognition;data mining;deep learning;ensemble learning;supervised learning;computational learning theory;k-nearest neighbors algorithm;active learning;statistics;dimensionality reduction;generalization error	ML	19.574132361048058	-41.10471293117468	196402
dd26dada0e952875c8cb255badb9d1d2575edc9b	a kernelized non-parametric classifier based on feature ranking in anisotropic gaussian kernel		Abstract Non-parametric methods make no assumptions about the form of data distribution and estimate it directly from the data. Kernel density estimation is a non-parametric method which estimates the probability density function of an unknown distribution. To estimate the density using a kernel estimator, it is necessary to have a bandwidth selection procedure. This paper proposes a kernelized non-parametric classifier based on feature ranking in anisotropic Gaussian kernel (KNR-AGK) and focuses on the selection of different bandwidths in kernel density estimation. KNR-AGK uses the rank of features to learn the parameters of an anisotropic Gaussian kernel and considers these ranks as kernel bandwidths in different dimensions. In the proposed method, the rank of features is also used for feature selection based on filter methods to exclude low-ranked features that have a negative impact on the performance of KNR-AGK. To evaluate the performance of the proposed method, comprehensive experiments are conducted on several benchmark datasets. Experiment results show that the proposed classifier has better performance than Gaussian kernel density estimation based classifier.	kernel method	Razieh Sheikhpour;Mehdi Agha Sarram;Mohammad Ali Zare Chahooki;Robab Sheikhpour	2017	Neurocomputing	10.1016/j.neucom.2017.06.035	machine learning;kernel (statistics);artificial intelligence;kernel embedding of distributions;polynomial kernel;kernel method;kernel density estimation;pattern recognition;mathematics;multivariate kernel density estimation;variable kernel density estimation;radial basis function kernel	AI	17.368455573534305	-40.99617721464472	196652
10ee421fa1903aed71fe1acf0cd77f1819663e5c	preference learning with extreme examples	bayesian framework;gaussian process;partial order	In this paper, we consider a general problem of semi-supervised preference learning, in which we assume that we have the information of the extreme cases and some ordered constraints, our goal is to learn the unknown preferences of the other places. Taking the potential housing place selection problem as an example, we have many candidate places together with their associated information (e.g., position, environment), and we know some extreme examples (i.e. several places are perfect for building a house, and several places are the worst that cannot build a house there), and we know some partially ordered constraints (i.e. for two places, which place is better), then how can we judge the preference of one potential place whose preference is unknown beforehand? We propose a Bayesian framework based on Gaussian process to tackle this problem, from which we not only solve for the unknown preferences, but also the hyperparameters contained in our model.	bayesian network;benchmark (computing);expectation propagation;gaussian process;preference learning;selection algorithm;semi-supervised learning;semiconductor industry	Fei Wang;Bin Zhang;Ta-Hsin Li;Wen Jun Yin;Jin Dong;Tao Li	2003			partially ordered set;artificial intelligence;machine learning;data mining;gaussian process;mathematics	ML	17.953298345165123	-38.01667287969905	197115
b799cc922478f1f5681f24d614623c360a060bb8	feature selection for least squares projection twin support vector machine	least squares projection twin support vector machine;twin support vector machine;feature selection	In this paper, we propose a new feature selection approach for the recently proposed Least Squares Projection Twin Support Vector Machine (LSPTSVM) for binary classification. 1-norm is used in our feature selection objective so that only non-zero elements in weight vectors will be chosen as selected features. Also, the Tikhonov regularization term is incorporated to the objective of our approach to reduce the singularity problems of Quadratic Programming Problems (QPPs), and then to minimize its 1-norm measure. This approach leads to a strong feature suppression capability, called as Feature Selection for Least Squares Projection Twin Support Vector Machine (FLSPTSVM). The solutions of FLSPTSVM can be obtained by solving two smaller QPPS arising from two primal QPPs as opposed to two dual ones in Twin Support Vector Machine (TWSVM). Thus, FLSPTSVM is capable of generating sparse solutions. This means that FLSPTSVM can reduce the number of input features for a linear case. Our linear FLSPTSVM can also be extended to a nonlinear case with the kernel trick. When a nonlinear classifier is used, the number of kernel functions required for the classifier is reduced. Our experiments on publicly available datasets demonstrate that our FLSPTSVM has comparable classification accuracy to that of LSPTSVM and obtains sparse solutions. & 2014 Elsevier B.V. All rights reserved.	binary classification;experiment;feature selection;kernel method;least squares;nonlinear system;quadratic programming;sparse matrix;support vector machine;technological singularity;zero suppression	Jianhui Guo;Ping Yi;Ruili Wang;Qiaolin Ye;Chunxia Zhao	2014	Neurocomputing	10.1016/j.neucom.2014.05.040	least squares support vector machine;mathematical optimization;feature vector;computer science;machine learning;linear classifier;pattern recognition;mathematics;relevance vector machine;feature selection;structured support vector machine	AI	22.063447746358435	-39.33064607568369	197247
c6bc3b691c042d2011c8586b58131286b79454bc	cross-domain knowledge transfer using semi-supervised classification	supervised classification;support vector;domain knowledge;text classification;experimental evaluation	Traditional text classification algorithms are based on a basic assumption: the training and test data should hold the same distribution. However, this identical distribution assumption is always violated in real applications. Due to the distribution of test data from target domain and the distribution of training data from auxiliary domain are different, we call this classification problem cross-domain classification. Although most of the training data are drawn from auxiliary domain, we still can obtain a few training data drawn from target domain. To solve the cross-domain classification problem in this situation, we propose a two-stage algorithm which is based on semi-supervised classification. We firstly utilizes labeled data in target domain to filter the support vectors of the auxiliary domain, then uses filtered data and labeled data from target domain to construct a classifier for the target domain. The experimental evaluation on real-world text classification problems demonstrates encouraging results and validates our approach.	machine learning;semi-supervised learning;semiconductor industry	Yi Zhen;Chunping Li	2008		10.1007/978-3-540-89378-3_36	support vector machine;computer science;artificial intelligence;machine learning;pattern recognition;data mining;one-class classification;domain knowledge	AI	19.042652847621135	-42.857849706551576	197547
019ecae7db014776ab2bcded5b66820ea2dc8600	analysis of the performance of ensemble of perceptrons	performance analysis neurons neural networks management training boosting convergence cities and towns physics;perceptrons;benchmark problem;perceptrons learning artificial intelligence pattern classification;learning space perceptron ensemble performance analysis nonlinear classification problems competitive training mechanism;performance analysis;pattern classification;learning artificial intelligence	In this study we analyze the performance of an ensemble model composed of several perceptrons that can effectively deal with nonlinear classification problems. Although each member of the ensemble can only deal with linear classification problems, through a competitive training mechanism, the ensemble is able to automatically allocate a part of the learning space that is linearly separable to each member, thus decomposing non-linear classification problems into several more manageable linear problems. In this paper, we gave the performance analysis of the ensemble with regard to some benchmark problems.	benchmark (computing);linear classifier;linear separability;nonlinear system;perceptron	Pitoyo Hartono;Shuji Hashimoto	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.247248	computer science;artificial intelligence;perceptron;machine learning;pattern recognition;ensemble learning	Robotics	19.395585555042178	-39.19805241196786	198450
d428693f09a07a2b804ef3a8a9c1752c9b7666f2	on the impact of distance metrics in instance-based learning algorithms		In this paper we analyze the impact of distinct distance metrics in instance-based learning algorithms. In particular, we look at the well-known 1-Nearest Neighbor (NN) algorithm and the Incremental Hypersphere Classifier (IHC) algorithm, which proved to be efficient in large-scale recognition problems and online learning. We provide a detailed empirical evaluation on fifteen datasets with several sizes and dimensionality. We then statistically show that the Euclidean and Manhattan metrics significantly yield good results in a wide range of problems. However, grid-search like methods are often desirable to determine the best matching metric depending on the problem and algorithm.	algorithm;instance-based learning	Noel Lopes;Bernardete Ribeiro	2015		10.1007/978-3-319-19390-8_6	machine learning	Theory	20.46305192442034	-44.54029330515259	198470
128b237d7991b008f38120c5945d403738ce9dea	direct convex relaxations of sparse svm	inner product;support vector;feature weighting;linear program;binary classification;support vector machine;convex relaxation;semidefinite program	Although support vector machines (SVMs) for binary classification give rise to a decision rule that only relies on a subset of the training data points (support vectors), it will in general be based on all available features in the input space. We propose two direct, novel convex relaxations of a non-convex sparse SVM formulation that explicitly constrains the cardinality of the vector of feature weights. One relaxation results in a quadratically-constrained quadratic program (QCQP), while the second is based on a semidefinite programming (SDP) relaxation. The QCQP formulation can be interpreted as applying an adaptive soft-threshold on the SVM hyperplane, while the SDP formulation learns a weighted inner-product (i.e. a kernel) that results in a sparse hyperplane. Experimental results show an increase in sparsity while conserving the generalization performance compared to a standard as well as a linear programming SVM.	binary classification;data point;linear programming relaxation;quadratic programming;quadratically constrained quadratic program;semidefinite programming;sparse matrix;support vector machine	Antoni B. Chan;Nuno Vasconcelos;Gert R. G. Lanckriet	2007		10.1145/1273496.1273515	support vector machine;least squares support vector machine;mathematical optimization;computer science;linear programming;machine learning;pattern recognition;mathematics	ML	22.066957589992057	-39.10402780739345	199029
1f9fe1427a7d15601cc634e6002b87d393b30fd1	classifying faces with discriminant isometric feature mapping	reconnaissance visage;learning algorithm;image processing;data description;image databank;procesamiento imagen;manifold learning;algorithme apprentissage;traitement image;geodesic distance;face recognition;internet;kernel fisher discriminant;banco imagen;banque image;data visualization;isometric feature mapping isomap;pattern recognition;error rate;visualisation donnee;reconnaissance forme;reconocimiento patron;algoritmo aprendizaje;local linear embedding;description donnee	Recently proposed manifold learning algorithms, e.g. Isometric feature mapping (Isomap), Locally Linear Embedding (LLE), and Laplacian Eigenmaps, are based on minimizing the construction error for data description and visualization, but not optimal from classification viewpoint. A discriminant isometric feature mapping for face recognition is presented in this paper. In our method, the geodesic distances between data points are estimated by Floyd's algorithm, and Kernel Fisher Discriminant is then utilized to achieve the discriminative nonlinear embedding. Prior to the estimation of geodesic distances, the neighborhood graph is constructed by incorporating class information. Experimental results on two face databases demonstrate that the proposed algorithm achieves lower error rate for face recognition.	discriminant;isometric projection	Ruifan Li;Cong Wang;Hongwei Hao;Xuyan Tu	2005		10.1007/11579427_57	computer vision;geodesic;the internet;image processing;word error rate;computer science;machine learning;pattern recognition;mathematics;nonlinear dimensionality reduction;data visualization	AI	23.87885527207071	-40.02844313237244	199382
153b702d0a0a7b7ad79446a1e872edb660691ee6	a discriminative learning framework with pairwise constraints for video object classification	robust 3d face tracking;sequential state estimation problem;robust 3d face tracking.;real tracking example;theoretical convergence proof;image feature space;random projection;tracking quality measurement;particle filter;particle fil- tering;hybrid sampling solution;particle filtering;state space;considerable noise;ransac;real application;sampling efficiency;face tracking;statistical test;particle filters;filtering;noise reduction;robustness;image features;sampling methods;convergence	To deal with the problem of insufficient labeled data in video object classification, one solution is to utilize additional pairwise constraints that indicate the relationship between two examples, i.e., whether these examples belong to the same class or not. In this paper, we propose a discriminative learning approach which can incorporate pairwise constraints into a conventional margin-based learning framework. Different from previous work that usually attempts to learn better distance metrics or estimate the underlying data distribution, the proposed approach can directly model the decision boundary and, thus, require fewer model assumptions. Moreover, the proposed approach can handle both labeled data and pairwise constraints in a unified framework. In this work, we investigate two families of pairwise loss functions, namely, convex and nonconvex pairwise loss functions, and then derive three pairwise learning algorithms by plugging in the hinge loss and the logistic loss functions. The proposed learning algorithms were evaluated using a people identification task on two surveillance video data sets. The experiments demonstrated that the proposed pairwise learning algorithms considerably outperform the baseline classifiers using only labeled data and two other pairwise learning algorithms with the same amount of pairwise constraints.		Rong Yan;Jian Zhang;Jie Yang;Alexander G. Hauptmann	2004	Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.	10.1109/CVPR.2004.10	computer simulation;computer vision;metric;image processing;computer science;machine learning;pattern recognition;statistics	Vision	21.18829090244094	-42.08740827744976	199435
5fb509cf7760c86d1209eef3709d6756eafae21f	task relationship modeling in lifelong multitask learning	engineering;online multitask learning;dissertation;task space partition;artificial intelligence;feature selection;lifelong learning;computer science;multitask learning	Multitask Learning is a learning framework which explores the concept of sharing training information among multiple related tasks to improve the generalization error of each task. The benefits of multitask learning have been shown both empirically and theoretically. There are a number of fields that benefit from multitask learning such as toxicology, image annotation, compressive sensing etc. However, majority of multitask learning algorithms make a very important key assumption that all the tasks are related to each other in a similar fashion in multitask learning. The users often do not have the knowledge of which tasks are related and train all tasks together. This results in sharing of training information even among the unrelated tasks. Training unrelated tasks together can cause a negative transfer and deteriorate the performance of multitask learning. For example, consider the case of predicting in vivo toxicity of chemicals at various endpoints from the chemical structure. Toxicity at all the endpoints are not related. Since, biological networks are highly complex, it is also not possible to predetermine which endpoints are related. Training all the endpoints together may cause a negative effect on the overall performance. Therefore, it is important to establish the task relationship models in multitask learning. Multitask learning with task relationship modeling may be explored in three different settings, namely, static learning, online fixed task learning and most recent lifelong learning. The multitask learning algorithms in static setting have been present for more than a decade and there is a lot of literature in this field. However, utilization of task relationships in multitask learning framework has been studied in detail for past several years only. The literature which uses feature selection		Meenakshi Mishra	2015			computer science;artificial intelligence;data science;machine learning	ML	21.54083415235652	-44.061879077956824	199527
83251026bb9ab184832b74a6571144df040814a9	a new ensemble method for multi-label data stream classification in non-stationary environment	pattern clustering data handling pattern classification;concept drift;multilabel cluster based classifiers;pattern clustering;nonstationary environment;ensemble learning;voting method new ensemble method multilabel data stream classification nonstationary environment realistic applications multilabel dynamic ensemble mlde approach multilabel cluster based classifiers mlcc;multi label classification;training;prediction algorithms;mlde approach;testing;accuracy;accuracy testing classification algorithms heuristic algorithms prediction algorithms training clustering algorithms;realistic applications;mlcc;heuristic algorithms;new ensemble method;classification algorithms;pattern classification;voting method;clustering algorithms;data stream classification ensemble learning concept drift multi label classification;multilabel dynamic ensemble;multilabel data stream classification;data handling;data stream classification	Most existing approaches for the data stream classification focus on single-label data in non-stationary environment. In these methods, each instance can only be tagged with one label. However, in many realistic applications, each instance should be tagged with more than one label. To address the challenge of classifying multi-label stream in evolving environment, we propose a novel Multi-Label Dynamic Ensemble (MLDE) approach. The proposed MLDE integrates a number of Multi-Label Cluster-based Classifiers (MLCCs). MLDE includes an adaptive ensemble method and an ensemble voting method with two important weights, subset accuracy weight and similarity weight. Experimental results reveal that MLDE achieves better performance than state-of-the-art multi-label stream classification algorithms.	algorithm;concept drift;experiment;integrated development environment;multi-label classification;performance;semi-supervised learning;semiconductor industry;stationary process;synthetic intelligence	Ge Song;Yunming Ye	2014	2014 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2014.6889846	prediction;computer science;concept drift;machine learning;group method of data handling;pattern recognition;data mining;accuracy and precision;software testing;ensemble learning;cluster analysis	AI	18.143033126452202	-42.13580327023858	199671
