id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
c95ed8dec801262e5839ebc3fe17e6e73107b69d	gate-delay fault diagnosis using the inject-and-evaluate paradigm	gate delay fault diagnosis algorithm;forward approach;six valued simulation;circuit faults;fault simulation;glitching outputs;circuit analysis computing delays fault simulation integrated logic circuits multivalued logic;very large scale integration;prediction algorithms;circuit simulation;fault diagnosis circuit faults very large scale integration circuit testing prediction algorithms predictive models circuit simulation algorithm design and analysis robustness delay;logic ics;inject and evaluate paradigm;faulty outputs;glitching outputs gate delay fault diagnosis algorithm inject and evaluate paradigm fault injection fault evaluation six valued simulation forward approach composite syndromes faulty outputs logic ics glitches;robustness;glitches;predictive models;circuit testing;integrated logic circuits;multivalued logic;fault injection;circuit analysis computing;composite syndromes;algorithm design and analysis;fault evaluation;delays;fault diagnosis	We propose an algorithm for gate-delay fault diagnosis. It is based on the inject-and-evaluate paradigm [1], in which the fault site(s) are predicted through a series of injections and evaluations. Unlike the backtrace algorithm that predicts the fault site by tracing the syndrome at a faulty output back into the circuit, this approach mainly relies on the six-valued simulation. In such a forward approach, the accuracy is much higher because all the composite syndromes at all faulty outputs are considered simultaneously. We also analyze the effects of glitches and take them into account in our algorithm. As a result, the proposed approach is robust and applicable even when there are glitching outputs or when the delay size is relatively small. Experimental results show that the number of fault candidates produced by this approach is only 4.8 within 10 seconds of CPU time.	algorithm;benchmark (computing);central processing unit;experiment;glitch;glitching;programming paradigm;propagation delay;randomness;simulation;stack trace	Horng-Bin Wang;Shi-Yu Huang;Jing-Reng Huang	2002		10.1109/DFTVS.2002.1173508	algorithm design;electronic engineering;real-time computing;prediction;computer science;stuck-at fault;theoretical computer science;fault model;predictive modelling;very-large-scale integration;glitch;statistics;robustness	EDA	22.60435397433621	51.79294660381208	134704
6dba5195126fdc031657377765b0af87e1240fdf	snap: a novel hybrid method for circuit reliability assessment under multiple faults		This paper proposes a novel method for the assessment of circuit reliability, termed SNaP. Since it combines the properties of both simulation-based and analytical solutions, the proposed method is considered hybrid. Furthermore, it has the ability to deal with the occurrence of multiple faults while taking logic masking into account. As opposed to other reliability methods found in the literature, the proposed method has a linear complexity with the number of gates, which allows for the evaluation of complex circuits. The results presented are in good agreement with other methods in the literature.		Samuel Nascimento Pagliarini;Arwa Ben Dhia;Lirida A. B. Naviner;Jean-François Naviner	2013	Microelectronics Reliability	10.1016/j.microrel.2013.07.027	reliability engineering;engineering;engineering drawing;algorithm	EDA	23.344715671255567	51.42014487679254	134909
3eabdc6e342a6b4a9592c7e13e2ba9e8e4a1efdf	optimal reconfiguration functions for column or data-bit built-in self-repair	circuit optimisation;integrated circuit testing;integrated memory circuits;logic design;logic testing;maintenance engineering;reconfigurable architectures;system-on-chip;bisr optimal reconfiguration functions;soc;column bisr;data-bit level built-in self-repair;dynamic repair scheme;embedded memories;memory failures;multiple fault repair;repairable unit size reduction;single test pass	In modern SoCs, embedded memories occupy the largest part of the chip area and include an even larger amount of active devices. As memories are designed very tightly to the limits of the technology they are more prone to failures than logic. Thus, memories concentrate the large majority of defects and affect circuit yield dramatically. As a matter Built-In Self-Repair is gaining importance. This work presents optimal reconfigurations functions for memory built-in self-repair on the data-bit level. We also present a dynamic repair scheme that allows reducing the size of the repairable units. The combination of these schemes allows repairing multiple faults affecting both regular and spare units, by means of low hardware cost. The scheme uses a single test pass, resulting on low test and repair time.	bit-level parallelism;electronic circuit;embedded system;overhead (computing);static random-access memory;system on a chip	Michael Nicolaidis;Nadir Achouri;Slimane Boutobza	2003			maintenance engineering;system on a chip;embedded system;electronic engineering;real-time computing;computer science;engineering;software testing	EDA	20.503203814451744	53.029852823055634	136146
e32ac5d4f936587d9137de8e0b96c0fd8fd34108	efficient calculation of boolean relations for multi-level logic optimization	many valued logics boolean functions logic design;many valued logics;logic design;boolean functions;boolean functions logic circuits logic design design optimization flexible printed circuits electronic design automation and methodology data structures circuit synthesis microelectronics wire;binary decision diagram boolean relations multilevel logic optimization bdd based calculation	A new exact technique is presented to calculate the maximal Boolean relation for an arbitrary subcircuit in a multi-level logic circuit. The new technique significantly reduces the memory required for BDD-based Boolean relation calculation. It therefore permits the calculation of Boolean relations for much more complex circuits than was previously possible. The efficiency of the technique is demonstrated on various benchmark circuits. An application to multi-level logic optimization is shown. >	logic optimization	Bernd Wurth;Norbert Wehn	1994		10.1109/EDTC.1994.326812	boolean algebra;boolean circuit;and-inverter graph;circuit minimization for boolean functions;discrete mathematics;reed–muller expansion;logic synthesis;logic optimization;boolean domain;boolean expression;logic gate;logic family;product term;standard boolean model;theoretical computer science;mathematics;combinational logic;boolean function;digital electronics;algorithm	EDA	18.510730310870485	46.52477668133324	137277
12708d332038a55aad87c9586262756c141cf5d7	hannibal: an efficient tool for logic verification based on recursive learning	learning (artificial intelligence);hannibal;sparc workstation elc;c6288;c6288nr;combinational circuits;expert systems;internal equivalencies;logic verification;multiplier;recursive learning;redundancy-free version;verification tools	TMs paper introduces a new approach to logic verification of combinational circuits, which is based on recursive learning [1]. In particular, the described method efficiently extracts equivalences between inlernal nodes of the two circuits to be verified. We present a tool, HANNIBAL, which is very efficient for many practical verification problems where such internal equivalences exist. The presented method can also be used to drastically accelerate other verification tools. Experimental results clearly show the efficiency of HANNIBAL. For example, HANNIBAL verifies the multiplier c6288 against the redundancy-free version c62881u in only 48 seconds on a Spsrc Workstation ELC.	combinational logic;recursion;workstation	Wolfgang Kunz	1993		10.1145/259794.259884	embedded system;computer architecture;electronic engineering;computer science;theoretical computer science;combinational logic;algorithm;computer engineering	Logic	19.976698184666354	49.021867723807006	137525
fbc20623c7e6e40d5eb7bf2564a1390a10c68c95	aliasing probability in multiple input linear signature automata for q-ary symmetric errors	shift registers delays feedback finite automata logic testing markov processes;linear feedback shift register;primitive polynomial;propagation delay aliasing probability multiple input linear signature automata q ary symmetric errors linear automata signature registers linear feedback shift registers linear cellular automata independent bit error model signature analyzer two state markov process closed form expression primitive polynomials circuit complexity;circuit complexity;automata circuit testing circuit faults built in self test computer errors registers polynomials automatic testing cities and towns markov processes;feedback;propagation delay;shift registers;logic testing;finite automata;markov process;markov processes;cellular automata;delays	The aliasing probability in single and multiple input linear automata signature registers (LASRs: linear feedback shift registers (LFSRs) and linear cellular automata) has been widely studied under the independent bit error model. Aliasing in a class of multiple-input LASRs (MILASRs) under the q-ary symmetric error model is examined. By modeling the signature analyzer as a two state Markov process, it is shown that the closed form expression previously derived for aliasing probability for multiple-input LFSRs with primitive polynomials holds for a far more general class of linear automata signature analyzers, including all multiple-input LFSRs. An easily verifiable criterion is given to determine whether a MILASR falls into this category. It is shown that for q-ary symmetric errors, the circuit complexity and the propagation delay can be minimized by using a set of m single bit LFSRs. >	aliasing;automata theory;automaton	Geetani Edirisooriya;John P. Robinson	1991		10.1109/ICCD.1991.139917	cellular automaton;quantum finite automata;computer science;theoretical computer science;markov process;finite-state machine;algorithm	Logic	22.334308725005847	48.272808976575696	137669
6fd07c6cc71787a8367cd8db9b9e1d3ebe31ac10	synthesis of x-tolerant convolutional compactors	convolutional codes;x tolerant convolutional compactor synthesis;data compression;paper technology;impulse testing;polynomials;time factors;integrated circuit testing fault tolerance built in self test data compression;built in self test;compaction;fault tolerance;manufacturing;integrated circuit testing;compaction circuit testing convolutional codes graphics paper technology manufacturing time factors polynomials impulse testing combinational circuits;circuit testing;embedded testing;graphics;embedded testing x tolerant convolutional compactor synthesis fault tolerance;combinational circuits	The paper presents a very efficient method for synthesis of convolutional compactors capable of tolerating a number of unknown states in a single time frame while providing very high compaction ratios.	data compaction;maximal set;polynomial;software design;steiner tree problem	Janusz Rajski;Jerzy Tyszer	2005	23rd IEEE VLSI Test Symposium (VTS'05)	10.1109/VTS.2005.81	data compression;compaction;embedded system;fault tolerance;electronic engineering;convolutional code;real-time computing;computer science;engineering;graphics;combinational logic;manufacturing;algorithm;statistics;polynomial	Embedded	22.018327930683853	49.571280441299294	137850
0f9a22fe0b323d441eeec2c7c39c6a300599f7d5	signature rollback - a technique for testing robust circuits	analytical models;circuit testing robustness delay redundancy circuit faults system testing flip flops latches clocks analytical models;circuit faults;clocks;rollback and recovery;circuit design;test quality and reliability robust design embedded test time redundancy rollback and recovery;testing;time redundancy;standard structural test;transient analysis;chip;integrated circuit design;structural testing;noncritical transient failures;robust circuit testing;redundancy;registers;classical fault models;integrated circuit testing;embedded test;yield loss;noncritical failures;test quality and reliability;robustness;transient analysis integrated circuit design integrated circuit testing;static parameter variations;fault model;yield loss signature rollback robust circuit testing static parameter variations dynamic parameter variations circuit design robust design standard structural test classical fault models noncritical failures embedded test noncritical transient failures;analytical model;robust design;dynamic parameter variations;signature rollback	Dealing with static and dynamic parameter variations has become a major challenge for design and test. To avoid unnecessary yield loss and to ensure reliable system operation a robust design has become mandatory. However, standard structural test procedures still address classical fault models and cannot deal with the non-deterministic behavior caused by parameter variations and other reasons. Chips may be rejected, even if the test reveals only non-critical failures that could be compensated during system operation. This paper introduces a scheme for embedded test, which can distinguish critical permanent and non-critical transient failures for circuits with time redundancy. To minimize both yield loss and the overall test time, the scheme relies on partitioning the test into shorter sessions. If a faulty signature is observed at the end of a session, a rollback is triggered, and this particular session is repeated. An analytical model for the expected overall test time provides guidelines to determine the optimal parameters of the scheme.	embedded system;fault model;overhead (computing);soft error	Uranmandakh Amgalan;Christian Hachmann;Sybille Hellebrand;Hans-Joachim Wunderlich	2008	26th IEEE VLSI Test Symposium (vts 2008)	10.1109/VTS.2008.34	chip;reliability engineering;electronic engineering;real-time computing;telecommunications;computer science;engineering;circuit design;test compression;fault model;software testing;processor register;redundancy;robustness;integrated circuit design	EDA	21.47584492943729	52.105939970782565	137964
7b55249b357ec1b301a19178897cf175bedc3717	single output distributed two-rail checker with diagnosing capabilities for bus based self-checking architectures	two rail checker;on line testing;bus based systems	This paper proposes a distributed two-rail checker architecture which is specifically targeted to self-checking bus-based systems. The architecture makes use of a single bus line to provide error indication. With respect to conventional two-rail checkers additional diagnosing capabilities are provided. The checker is totally-self-checking with respect to stuck-at faults. It features also good self-testing properties with respect to parametric faults, such as bridgings and delay faults.		Michele Favalli;Cecilia Metra	2002	J. Electronic Testing	10.1023/A:1015031121350	embedded system;electronic engineering;real-time computing;engineering;control bus	EDA	22.557757184785935	50.80910840444464	138102
fd64b2c1c6f53f4e0d25b006f894c25f498450e9	divide and conquer diagnosis for multiple defects	multiple defects diagnosis;multiple defects;silicon elemental semiconductors failure analysis integrated circuit reliability integrated circuit testing;layout automatic test pattern generation accuracy;failure analysis hard to detect defects easy to detect defects diagnosis software benchmark circuits;diagnosis	This paper presents a novel diagnosis technique for multiple defects. This technique proposes a simple heuristic to partition the failures log so that hard-to-detect defects and easy-to-detect defects are likely to be separated. This technique requires only commercial diagnosis software with a simple add-on tool. No customized diagnosis software is needed. Simulations on benchmark circuits demonstrated the effectiveness of the proposed technique. Real silicon experiments on a real industrial product have been verified by physical failure analysis that our technique does not lead to wrong diagnosis for single defect cases.	add-ons for firefox;benchmark (computing);experiment;failure analysis;heuristic;software bug	Shih-Min Chao;Po-Juei Chen;Jing-Yu Chen;Po-Hao Chen;Ang-Feng Lin;Chien-Mo James Li;Pei-Ying Hsueh;Chun-Yi Kuo;Ying-Yen Chen;Jih-Nung Li	2014	2014 International Test Conference	10.1109/TEST.2014.7035362	reliability engineering;electronic engineering;engineering;medical diagnosis;forensic engineering	EDA	22.06612025699499	52.505051042775925	138606
70a364c260d197782993b027321346f5fa430548	algorithmic synthesis of high level tests for data path designs	fault localization;algorithm design and analysis manufacturing automatic test pattern generation very large scale integration automatic testing semiconductor device modeling adders circuit faults circuit testing integrated circuit synthesis;circuit faults;very large scale integration;automatic test pattern generation;automatic testing;state machine;high level data path designs;universal tests;indexing terms;design defects;high level tests;algorithmic synthesis;localized checking experiments;adders;semiconductor device modeling;manufacturing defects;logic testing;manufacturing defect coverage;manufacturing;integrated circuit synthesis;circuit testing;design verification;counters;comparators algorithmic synthesis high level tests data path designs design verification programs high level data path designs design defects manufacturing defects localized checking experiments state machine controllers manufacturing defect coverage universal tests counters adders;data path designs;comparators;design verification programs;algorithm design and analysis;state machine controllers	Algorithmic techniques are proposed to synthesize design verification programs for high level data path designs that target design defects as well as manufacturing defects. Some categories of design defects are identified. A methodology, based on localized checking experiments, is proposed to synthesize state machine controllers in data path designs that enhance manufacturing defect coverage using design verification programs. Some example designs are considered that demonstrate the effectiveness of the proposed techniques. A heuristic to generate universal tests for manufacturing defect coverage is proposed. This heuristic has been successfully applied for real design implementations of counters, adders, and comparators.	comparator;computer-aided design;experiment;finite-state machine;heuristic;high-level programming language;high-level synthesis;software bug	Nirmal R. Saxena;Ravi Tangirala;Ajay Srivastava	1993	FTCS-23 The Twenty-Third International Symposium on Fault-Tolerant Computing	10.1109/FTCS.1993.627339	electronic engineering;computer science;theoretical computer science;computer engineering	EDA	20.3925578619403	49.90900235350552	138710
32760964373193c8109dcb195a47384eb579399f	scalable delay fault bist for use with low-cost ate	thermal constraints;bist;tecnologia electronica telecomunicaciones;ip cores;chip;sat;delay testing;symbolic methods;tecnologias;grupo a	We present a BIST architecture based on a Multi-Input Signature Register (MISR) expanding single input vectors into sequences, which are used for testing of delay faults. Input vectors can be stored on-chip or in the ATEs in the latter case, a low speed tester can be employed though the sequences are applied at-speed to the block-under-test. The number of input vectors (and thus the area demand on-chip or ATE memory requirements) can be traded for the test application time.#R##N##R##N#We propose several methods for generating input vectors, which differ in test application time, area requirements and algorithm run-time. As all of them require only a two-pattern test as input, IP cores can be handled by these methods.#R##N##R##N#The block-under-test can be switched off for some amount of time between application of consecutive input vectors. We provide arguments why this approach may be the only way to meet thermal and power constraints. Furthermore, we demonstrate how the BIST scheme can use these cool-down breaks for re-configuration.	built-in self-test	Ilia Polian;Bernd Becker	2004	J. Electronic Testing	10.1023/B:JETT.0000023681.25483.59	chip;embedded system;electronic engineering;real-time computing;telecommunications;computer science;engineering	EDA	20.41376405526944	51.69152961896631	138733
552902ec61fa9ca6b022966a3f599d88d06568d1	autofix: a hybrid tool for automatic logic rectification	symbol manipulation;concepcion asistida;computer aided design;synthese circuit;diagrama binaria decision;design automation;diagramme binaire decision;multiple errors;integrated circuit;logic design;boolean functions;correction erreur;automatic testing;engineering change problem;erroneous combinational circuit;circuit vlsi;automatic logic units;integrated circuit testing logic cad circuit cad error correction symbol manipulation binary decision diagrams combinational circuits automatic testing;circuito integrado;circuito logico;indexing terms;sufficient conditions;design optimization;circuit combinateur;rectification;process design;hybrid approach;vlsi circuit;binary decision diagrams;circuit logique;structural correspondence;data structures;error correction;necessary and sufficient condition;partial corrections;combiner circuit;iscas 85 benchmark circuits autofix automatic logic rectification erroneous combinational circuit symbolic binary decision diagram techniques partial corrections input vector set error responses multiple errors engineering change problem single gate correction structural correspondence;integrated circuit testing;conception assistee;automatic logic units error correction process design logic design design optimization computer errors combinational circuits data structures boolean functions sufficient conditions;sintesis circuito;input vector set;circuit cad;error responses;automatic logic rectification;correccion error;circuito vlsi;rectificacion;correction partielle;single gate correction;logic cad;circuito combinador;logic circuit;computer errors;circuit synthesis;circuit integre;autofix;iscas 85 benchmark circuits;combinational circuits;binary decision diagram;symbolic binary decision diagram techniques;engineering change	We address the problem of rectifying an erroneous combinational circuit. Based on the symbolic binary decision diagram techniques, we consider the rectification process as a sequence of partial corrections. Each partial correction reduces the size of the input vector set that produces error responses. Compared with the existing approaches, this approach is more general, and thus, suitable for circuits with multiple errors and for the engineering change problem. Also, we derive the necessary and sufficient condition of general single-gate correction to improve the quality of rectification. To handle larger circuits, we develop a hybrid approach that makes use of the information of structural correspondence between specification and implementation. Experiments are performed on a suite of industrial examples as well as the entire set of ISCAS’85 benchmark circuits to demonstrate its effectiveness.	benchmark (computing);binary decision diagram;combinational logic;image rectification;influence diagram;list of http status codes;logic gate;rectifier	Shi-Yu Huang;Kuang-Chien Chen;Kwang-Ting Cheng	1999	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.784128	process design;electronic engineering;logic synthesis;multidisciplinary design optimization;error detection and correction;index term;data structure;electronic design automation;logic gate;computer science;electrical engineering;theoretical computer science;integrated circuit;computer aided design;combinational logic;boolean function;binary decision diagram;algorithm;rectification	EDA	20.18743896126365	48.8725464725279	139075
9583407e1a34b0a65b0f360c1bf31bf6d9238b9d	antirandom vs. pseudorandom testing	bridging faults pseudorandom testing antirandom testing test vector space iscas benchmarks;circuit faults;iscas benchmarks;vector space;pseudorandom testing;circuit testing circuit faults hamming distance high definition video read only memory monitoring equations fault detection;hamming distance;monitoring;antirandom testing;fault detection;logic testing;high definition video;bridging faults;fault coverage;circuit testing;test vector space;read only memory	This paper introduces the concept of antirandom testing where each test applied is chosen such that its total distance from all previous tests is maximum. This spans the test vector space to the maximum extent possible for a given number of vectors. This strategy results in a higher fault coverage when the number of vectors that are applied is limited. Results on several ISCAS benchmarks show this strategy to be very effective when a high fault coverage needs to be achieved with a limited number of test vectors. The superiority of the antirandom testing approach is even more significant for testing bridging faults.	bridging (networking);fault coverage;pseudorandomness;software testing;test vector	Shen Hui Wu;Yashwant K. Malaiya;Anura P. Jayasumana	1998		10.1109/ICCD.1998.727054	electronic engineering;real-time computing;hamming distance;fault coverage;vector space;computer science;theoretical computer science;operating system;read-only memory;fault detection and isolation	SE	20.649274483986467	52.14993981035143	139491
0da7bb5279fd5a0eef40e2b444106421e978fbd4	test application time and volume compression through seed overlapping	matrix algebra integrated circuit design integrated circuit testing logic design automatic test pattern generation;circuit testing vectors integrated circuit testing compaction pins permission very large scale integration software testing sun automatic test pattern generation;logic design;automatic test pattern generation;deterministic test;matrix algebra;test compression;integrated circuit design;scan chain concealment;xor network;integrated circuit testing;deterministic test time compression volume compression seed overlapping scan chain concealment scc scheme test time volume requirement test vector seed don t care bit atpg algorithm xor network;soc test	We propose in this paper an extension on the Scan Chain Concealment technique to further reduce test time and volume requirement. The proposed methodology stems from the architecture of the existing SCC scheme, while it attempts to overlap consecutive test vector seeds, thus providing increased flexibility in exploiting effectively the large volume of don't-care bits in test vectors. We also introduce modified ATPG algorithms upon the previous SCC scheme and explore various implementation strategies. Experimental data exhibit significant reductions on test time and volume over all current test compression techniques.	algorithm;international conference on services computing;source code control system;test compression;test vector	Wenjing Rao;Ismet Bayraktaroglu;Alex Orailoglu	2003		10.1145/775832.776020	embedded system;electronic engineering;scan chain;logic synthesis;boundary scan;computer science;theoretical computer science;automatic test pattern generation;operating system;test compression;algorithm;integrated circuit design	EDA	20.006038425494925	52.552220471860885	139585
e6d8efa34e23a064db4454702c996e1dd47970b3	fault diagnosis using functional fault models for vhdl descriptions	circuit faults;very large scale integration;sequential circuits;first principle;failure analysis;dictionaries;logic testing;circuit testing;pattern analysis;fault model;fault diagnosis circuit faults hardware circuit testing very large scale integration logic testing dictionaries sequential circuits failure analysis pattern analysis;fault diagnosis;hardware	This paper describes algorithms for fault diagnosis of computer hardware modeled in VHDL [1,2,3,4]. Given a VHDL description, the compiler creates an internal representation. For fault diagnosis, a hierarchical approach using the stuck-at fault model a t the first level and the arbitrary failure model a t the second level, is used. The diagnosis algorithm reasons from first principles using constraint suspension.	compiler;computer hardware;fault model;medical algorithm;stuck-at fault;vhdl	Vijay Pitchumani;Pankaj Mayor;Nimish Radia	1991		10.1109/TEST.1991.519525	failure analysis;electronic engineering;real-time computing;fault coverage;first principle;computer science;engineering;stuck-at fault;automatic test pattern generation;fault model;sequential logic;very-large-scale integration;algorithm;software fault tolerance	AI	20.2190549992211	49.91614220215387	140250
3e5273e8ac7a2c97148acf8eed90a5067cc872c0	state encoding algorithm for peak current minimisation	minimisation;switching;diseno circuito;peak current minimisation;maquina estado finito;state encoding algorithm;heuristic method;circuit design;pseudo boolean expressions;espace etat;metodo heuristico;boolean expression;boolean algebra;algorithme;high strength current;algorithm;miniaturisation;codificacion;finite state machines;pseudo boolean expressions state encoding algorithm peak current minimisation chip reliability synchronous finite state machine circuits;synchronous finite state machine circuits;state space;expresion booleana;expression booleenne;fiabilite circuit integre;coding;conmutacion;low power electronics;courant intense;vlsi;chip reliability;corriente intensa;conception circuit;miniaturization;methode heuristique;miniaturizacion;integrated circuit reliability;espacio estado;machine etat fini;electronique faible puissance;vlsi boolean algebra finite state machines minimisation;commutation;finite state machine;codage;algoritmo	As the silicon process technology advances, chip reliability becomes more and more important. One of the critical factors that affect the chip reliability is the peak current in the circuit. In particular, high current peaks at the time of state transition in synchronous finite state machine (FSM) circuits often make the circuits very unstable in execution. This work addresses the state encoding problem with the objective of minimising peak current in FSMs. Unlike the previous power-aware state encoding algorithms, where the primary objective is to reduce the amount of switching activities of state register and the problem of reducing peak current has not been addressed at all or considered as a secondary objective, which obviously severely limits the search space of state encoding for minimising peak current, our algorithm, called SAT-pc, places the importance on the reliability, that is, peak current. Specifically, the authors solve two important state encoding problems in two phases: (Phase 1) the authors present a solution to the problem of state encoding for directly minimising peak current, by formulating it into the SAT problem with pseudo-Boolean expressions, which leads to a full exploration of the search space; (Phase 2) the authors then propose an efficient SAT-based heuristic to solve the state re-encoding problem for minimising switching power without deteriorating the minimum peak current obtained in Phase 1. Through an experimentation using MCNC benchmarks, it is shown that SAT-pc is able to reduce the peak current by 51 and 35%, compared to POW3 [4] that minimises the switching power only and POW3[14] + [24] that minimises the switching power and then peak current, respectively.	algorithm	Y. Lee;T. Kim	2011	IET Computers & Digital Techniques	10.1049/iet-cdt.2009.0082	boolean algebra;minimisation;electronic engineering;boolean expression;computer science;state space;circuit design;miniaturization;very-large-scale integration;coding;finite-state machine;algorithm;low-power electronics	HCI	18.01348574632437	51.474113947425955	140423
cf0ad43f0fa1a16c6a03069befeacedf71386830	on-line fault detection for bus-based field programmable gate arrays	reconfiguration;digital circuit;tolerancia falta;concepcion asistida;field programmable gate array;computer aided design;reconfiguracion;logic simulation;mission critical systems;resource constraint;architecture systeme;fault tolerant;integrated circuit;detection panne;field programmable gate arrayas;digital system fault tolerance;on line;en linea;failure detection;autoprueba;on line built in self testing;circuito integrado;programmable logic arrays;indexing terms;red puerta programable;self testing;autotest;reseau porte programmable;circuit numerique;circuit simulation;built in self test;monitoring;mission critical applications;digital systems;fault detection;fault tolerance;fault detection field programmable gate arrays programmable logic arrays hardware monitoring built in self test logic devices manufacturing system testing mission critical systems;on line fault scanning methodology;manufacturing;circuito numerico;logic simulation bus based field programmable gate arrays on line built in self testing mission critical applications resource constraints on line fault scanning methodology;conception assistee;system testing;arquitectura sistema;en ligne;field programmable gate arrays;system architecture;deteccion falla;bus based field programmable gate arrays;tolerance faute;circuit integre;logic devices;circuit simulation field programmable gate arrays built in self test fault diagnosis logic simulation;fault diagnosis;resource constraints;hardware	We introduce a technique for on-line built-in selftesting (BIST) of bus-based field programmable gate arrays (FPGA’s). This system detects deviations from the intended functionality of an FPGA without using special-purpose hardware, hardware external to the device, and without interrupting system operation. Such a system would be useful for mission-critical applications with resource constraints. The system solves these problems through an on-line fault scanning methodology. A device’s internal resources are configured to test for faults. Testing scans across an FPGA, checking a section at a time. Simulation on a model FPGA supports the viability and effectiveness of such a system.	built-in self-test;canonical account;fault detection and isolation;field-programmable gate array;interrupt;mission critical;online and offline;simulation	N. R. Shnidman;William H. Mangione-Smith;Miodrag Potkonjak	1998	IEEE Trans. VLSI Syst.	10.1109/92.736139	embedded system;fault tolerance;electronic engineering;reconfigurable computing;computer science;engineering;electrical engineering;computer aided design;field-programmable gate array;systems architecture;computer engineering	EDA	22.743573740822413	50.609676229556776	140541
d3cc74863526f4756955e1e22dfc033322b44528	on embedding test sets into hardware generated sequences	generators;circuit faults;don t care values embedding test set hardware generated sequence binary counter;radiation detectors;embedding test set;binary counter;filling;system on a chip;embedded systems;radiation detectors built in self test circuit faults generators hardware filling system on a chip;built in self test;hardware generated sequence;embedded systems built in self test circuit analysis computing;don t care values;circuit analysis computing;hardware	In this paper a novel algorithm is presented for embedding test sets containing don’t care values into sequences generated by binary counters. Experiments carried out on randomly generated test sets reveal that the proposed scheme results in shorter test sequences compared to randomly filling the don’t care bits with ‘0’ and ‘1’ values. Furthermore, comparison with schemes that have been proposed in the open literature for embedding test sets into hardware-generated sequences reveal that the proposed schemes presents comparable results, while in many cases it performs better.	algorithm;experiment;procedural generation;randomness;reliability engineering;test card;test case;test set	Dimitris J. Kavvadias;S. Sinitos;Ioannis Voyiatzis;Hera Antonopoulou;Costas Efstathiou	2010	2010 14th Panhellenic Conference on Informatics	10.1109/PCI.2010.44	system on a chip;real-time computing;computer science;theoretical computer science;particle detector	EDA	20.41963050836782	51.78181845438699	140627
4eef2a901ff16e3f86770016724df570e0cbbba4	applying march tests to k-way set-associative cache memories	computers;observability;microprocessors;cache storage;test algorithms;random access memory;complexity theory;application software;sram chips cache storage integrated circuit testing microprocessor chips;memory testing;controllability;transformations;marching sequence march tests k way set associative cache memory embedded microprocessor cache memory in system test test algorithms sram memory transformations lru replacement;cache memory;k way set associative cache memory;testing;arrays;indexes;march test;embedded microprocessor cache memory;memory test cache memories march test;sram memory;integrated circuit testing;marching sequence;cache memory microprocessors system testing random access memory hardware control engineering computing embedded computing observability controllability application software;system testing;lru replacement;memory test;in system test;control engineering computing;march tests;embedded computing;microprocessor chips;cache memories;hardware;sram chips	Embedded microprocessor cache memories suffer from limited observability and controllability creating problems during in-system test. The application of test algorithms for SRAM memories to cache memories thus requires opportune transformations. In this paper we present a procedure to adapt traditional march tests to testing the data and the directory array of k-way set-associative cache memories with LRU replacement. The basic idea is to translate each march test operation into an equivalent sequence of cache operations able to reproduce the desired marching sequence into the data and the directory array of the cache.	algorithm;cpu cache;cache (computing);complexity;directory (computing);embedded system;fault model;microprocessor;overhead (computing);page replacement algorithm;pseudorandomness;static random-access memory;system testing	Simone Alpe;Stefano Di Carlo;Paolo Prinetto;Alessandro Savino	2008	2008 13th European Test Symposium	10.1109/ETS.2008.25	transformation;bus sniffing;database index;computer architecture;cache-oblivious algorithm;snoopy cache;application software;parallel computing;cache coloring;observability;page cache;controllability;cpu cache;computer hardware;cache;computer science;write-once;cache invalidation;control theory;adaptive replacement cache;software testing;smart cache;memory organisation;cache algorithms;cache pollution;system testing	Embedded	19.60569466550557	49.99536743986092	140912
85a5624ed759c5c6bf03ead994ec3c83d8668649	on application of output masking to undetectable faults in synchronous sequential circuits with design-for-testability logic	design for testability;fault simulation;sequential circuits;dft logic;design for testability logic;fault detection;fault effects;redundant faults;synchronous sequential circuits;undetectable faults	Design-for-testability (DFT) for synchronous sequential circuits causes redundant faults in the original circuit to be detectable in the circuit with DFT logic. It has been argued that such faults should not be detected in order to avoid reducing the yield unnecessarily. One way to deal with such faults is to mask (or ignore) their fault effects when they appear on the circuit outputs, without masking the detection of faults that need to be detected. To investigate the extent to which this can be accomplished, we describe a procedure for masking the effects of redundant faults of the original circuit under a given test set generated for the circuit with DFT logic. The procedure attempts to maximize the number of redundant faults that are masked while minimizing (or holding to zero) the number of other masked faults.	design for testing	Irith Pomeranz;Sudhakar M. Reddy	2003		10.1145/996070.1009989	slew rate;electronic engineering;real-time computing;logic optimization;asynchronous circuit;fault indicator;computer science;electrical engineering;stuck-at fault;design for testing;sequential logic;static timing analysis;register-transfer level;algorithm	EDA	22.01890224011932	51.16708800421312	141018
270d65c5892793f61566a53c1380db63ab50faec	a bist pla design for high fault coverage and testing by an interleavingly crosspoint counting	test application time;logic testing built in self test logic arrays logic design;logic arrays;response evaluator circuits;interleavingly crosspoint counting;circuit faults;logic design;multiple faults bist pla design high fault coverage interleavingly crosspoint counting programmable logic array crosspoint devices test application time consecutive product lines test pattern generator response evaluator circuits shift registers counters single faults;product line;programmable logic arrays;single faults;consecutive product lines;interleaved codes;built in self test;test pattern generators;crosspoint devices;programmable logic array;shift registers;logic testing;bist pla design;fault coverage;circuit testing;test pattern generator;counters;built in self test programmable logic arrays circuit faults logic testing circuit testing logic devices logic design interleaved codes test pattern generators shift registers;high fault coverage;logic devices;multiple faults	A built-in-self testable (BIST) programmable logic array (PLA) is designed where an interleaving counting technique of crosspoint (cp) devices on the product lines has been used. The proposed technique reduces the test application time by a substantial amount. To implement this idea, the product lines are re-arranged according to the number of cp devices. After re-arranging, if two consecutive product lines differ by more than one cp device then a single product line is added in between these two lines in contrast to multiple ones. The test pattern generator and response evaluator circuits are simple and consist of mainly shift registers and counters which reduce the delay per test as opposed to conventional parity checkers. The proposed technique has extremely high fault coverage. All the single faults and most of the multiple faults are covered. Even in the worst case, the fault coverage is close to 100%. >	built-in self-test;fault coverage;programmable logic array	Md. Abdul Mottalib;P. Dasgupta	1994		10.1109/ICVD.1994.282668	embedded system;electronic engineering;logic synthesis;real-time computing;fault coverage;programmable logic array;computer science;shift register;algorithm	EDA	21.03414952682656	51.32777049939804	141147
60479d30daa7828fd360df53f8b58b0819a3544b	jump scan: a dft technique for low power testing	design for testability;degradation;circuit faults;circuit power dissipation jump scan dft technique low power testing mux scan design design for testability area overhead speed degradation j scan;clocks;circuit testing clocks design for testability power dissipation circuit faults system on a chip system testing frequency degradation automatic test pattern generation;automatic test pattern generation;area overhead;clocks boundary scan testing integrated circuit testing low power electronics design for testability;speed degradation;system on a chip;j scan;boundary scan testing;mux scan design;low power;power dissipation;jump scan;low power electronics;integrated circuit testing;system testing;circuit testing;low power testing;frequency;circuit power dissipation;dft technique	This paper presents a Jump scan technique (or J-scan) for low power testing. The J-scan shifts two bits of scan data per clock cycle so the scan clock frequency is halved without increasing the test time. The experimental data show that the proposed technique effectively reduces the test power by two thirds compared with the traditional MUX scan. The presented technique requires very few changes in the existing MUX-scan design for testability methodology and needs no extra computation. The penalties are area overhead and speed degradation.	ct scan;clock rate;clock signal;computation;design for testing;digital forensics framework (dff);elegant degradation;graham scan;multiplexer;overhead (computing);routing	Min-Hao Chiu;Chien-Mo James Li	2005	23rd IEEE VLSI Test Symposium (VTS'05)	10.1109/VTS.2005.51	system on a chip;embedded system;electronic engineering;scan chain;real-time computing;degradation;computer science;engineering;dissipation;automatic test pattern generation;operating system;frequency;design for testing;system testing;low-power electronics	EDA	20.16115057596497	53.27488480997327	141425
137f856b9fd5fb33079354c85a4005dd9ac434fd	blasys: approximate logic synthesis using boolean matrix factorization		Approximate computing is an emerging paradigm where design accuracy can be traded off for benefits in design metrics such as design area, power consumption or circuit complexity. In this work, we present a novel paradigm to synthesize approximate circuits using Boolean matrix factorization (BMF). In our methodology the truth table of a sub-circuit of the design is approximated using BMF to a controllable approximation degree, and the results of the factorization are used to synthesize a less complex subcircuit. To scale our technique to large circuits, we devise a circuit decomposition method and a subcircuit design-space exploration technique to identify the best order for subcircuit approximations. Our method leads to a smooth trade-off between accuracy and full circuit complexity as measured by design area and power consumption. Using an industrial strength design flow, we extensively evaluate our methodology on a number of testcases, where we demonstrate that the proposed methodology can achieve up to 63% in power savings, while introducing an average relative error of 5%. We also compare our work to previous works in Boolean circuit synthesis and demonstrate significant improvements in design metrics for same accuracy targets.	approximate computing;approximation algorithm;approximation error;boolean circuit;circuit complexity;heuristic (computer science);literal (mathematical logic);logic synthesis;mathematical optimization;numerical analysis;open-source software;programming paradigm;software metric	Soheil Hashemi;Hokchhay Tann;Sherief Reda	2018	2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC)	10.1145/3195970.3196001	real-time computing;logical matrix;logic synthesis;mathematical optimization;approximation algorithm;boolean circuit;circuit complexity;logic gate;design flow;computer science;factorization	EDA	17.461183817282045	47.778160771579	141619
4fc3489f860415cedab3d69f820e087ebd7e1097	logic restructuring using node addition and removal	circuit faults logic gates merging redundancy wires benchmark testing optimization;circuit faults;logic design;optimization technique;node addition and removal;observability don t care logic implication node addition and removal node merging;wires;satisfiability;logic implication;redundancy;logic gates;time 39 h node addition node removal logic restructuring technique node merging technique satisfiability based bounded sequential equivalence checking optimization technique verification time;computational complexity;logic testing;merging;node merging;observability don t care;optimization;logic testing circuit optimisation logic design;circuit optimisation;automatic test pattern generator;logic gate;equivalence checking;benchmark testing	This paper presents a logic restructuring technique named node addition and removal (NAR). It works by adding a node into a circuit to replace an existing node and then removing the replaced node. Previous node-merging techniques focus on replacing one node with an existing node in a circuit, but fail to replace a node that has no substitute node. To enhance the node-merging techniques on logic restructuring and optimization, we propose an NAR approach in this paper. We first present two sufficient conditions that state the requirements of added nodes for safely replacing a target node. Then, an NAR approach is proposed to quickly detect the added nodes by performing logic implications based on these conditions. We apply the NAR approach to circuit minimization together with two techniques: redundancy removal and mandatory assignment reuse. We also apply it to satisfiability (SAT)-based bounded sequential equivalence checking (BSEC) to reduce the computation complexity of SAT solving. The experimental results show that our approach can enhance our prior automatic test pattern generation-based node-merging approach. Additionally, our approach has a competitive capability of circuit minimization with 44 times speedup compared to a SAT-based node-merging approach. For BSEC, our approach can work together with other optimization technique to save a total of approximately 39-h verification time for all the benchmarks.	algorithm;benchmark (computing);boolean satisfiability problem;central processing unit;circuit minimization for boolean functions;computation;formal equivalence checking;mathematical optimization;nar 2;node (computer science);requirement;speedup;test card;turing completeness	Yung-Chih Chen;Chun-Yao Wang	2012	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2011.2167327	electronic engineering;real-time computing;logic gate;computer science;engineering;theoretical computer science;mathematics;algorithm	EDA	18.490959823330208	48.55042645969419	142419
e3e319f29416ff10b5bc55d83b47bd00c0733e22	a new lfsr with d and t flip-flops as an effective test pattern generator for vlsi circuits	concepcion circuito;arquitectura circuito;autoprueba;circuit design;circuit vlsi;circuit architecture;autotest;vlsi circuit;built in self test;fiabilite circuit;circuit reliability;architecture circuit;conception circuit;test pattern generator;circuito vlsi;digital circuits;flip flop	In the paper authors analyse properties of the various structures of linear registers (LFSRs) that are used as the test pattern generators in VLSI circuits. It is shown that the majority of them have one or more of the following drawbacks: • large area overhead that is caused by the large number of XOR gates, • reduced operational frequency due to presence of the long connection in the main feed-back loop and the high fan-out on the outputs of the flip-flops, • inflexible structure that cannot be easily redesigned and adjusted to the needs of the digital circuit efficient testing.#R##N##R##N#In the paper we present a new type of LFSR that is free from all mentioned above disadvantages. We also develop the algebraic description of its operation and the methods of its designing. Finally we give numerous examples of its structures for different lengths of the register.	flops;flip-flop (electronics);linear-feedback shift register;very-large-scale integration	Tomasz Garbolino;Andrzej Hlawiczka	1999		10.1007/3-540-48254-7_22	embedded system;engineering;circuit design;digital electronics	EDA	21.328270699576922	48.692399722566144	142616
c00d7bd1239a33151d7b5fd597c851404c9111dc	on detecting transition faults in the presence of clock delay faults	circuit faults;integrated circuit;clocks;circuit faults clocks delay logic gates vectors automatic test pattern generation integrated circuit modeling;automatic test pattern generation;logic testing fault diagnosis;launch on capture test;clock delay fault;benchmark circuits transition fault detection clock delay faults shrinking timing margins high speed digital circuits fault models test generation method gate transition fault launch on capture test environment standard stuck at atpg tool stuck at fault detection modeling logic atpg process;launch on capture test test generation clock delay fault transition fault;vectors;logic gates;integrated circuit modeling;logic testing;test generation;digital circuits;fault model;automatic test pattern generator;transition fault;logic gate;high speed;fault diagnosis	Shrinking timing margins for modern high speed digital circuits require a careful reconsideration of faults and fault models. In this paper, we discuss detection of transition faults in the presence of small clock delay faults. We first show that in the presence of a delay fault on a clock line some transition faults may fail to be detected. We propose a test generation method for detecting such faults (simultaneous presence of two faults) which consist of a gate transition fault and a clock delay fault assuming launch-on-capture test environment. The proposed test generation method employs a standard stuck-at ATPG tool. In our test generation methodology, the conditions for detecting a clock delay fault are converted into those for detecting a stuck-at fault, by adding some modeling logic during the ATPG process. Experimental results for benchmark circuits show the effectiveness of the proposed methods.	benchmark (computing);clock signal;deployment environment;digital electronics;fault model;sensor;stuck-at fault;time complexity	Yoshinobu Higami;Hiroshi Takahashi;Shin-ya Kobayashi;Kewal K. Saluja	2011	2011 Asian Test Symposium	10.1109/ATS.2011.33	embedded system;electronic engineering;fault;real-time computing;fault coverage;logic gate;fault indicator;engineering;stuck-at fault	EDA	21.636663558087587	52.13366388307464	143169
e1282b07bf32503b7870aec592a23fea0de6fbc2	applying testability analysis for integrated diagnostics	design process;automatic testing;antitank missile launcher testability analysis integrated diagnostics system testability interactive process replaceable unit groups false alarm tolerance;fault tolerant computing;built in self test;system design;iterative design;fault tolerant computing automatic testing built in self test;fault isolation;system testing tracking loops process design performance evaluation logic testing performance analysis missiles error correction time measurement job design	The use of measures that evaluate system testability at a specific time during system design is demonstrated. The measures were detailed in a previous article (see ibid., vol.9, no.1, p.40-54 (1992)). The measures improve testability as part of an interactive process. The objective in applying the testability measures is to minimize ambiguity in replaceable unit groups while minimizing the amount of testing and the number of tests. The problems of excess information provided by a test set, ambiguity arising from deficiencies in the test set, multiple failure, and the test set's effect on false-alarm tolerance are examined. The analysis techniques are applied to a specific example, the antitank missile launcher, and the ways in which the testability of that system might be improved are discussed.<<ETX>>	offset binary;software testability;systems design;test set	John W. Sheppard;William R. Simpson	1992	IEEE Design & Test of Computers	10.1109/54.156160	iterative design;reliability engineering;embedded system;electronic engineering;real-time computing;design process;computer science;engineering;test compression;design for testing;test management approach;fault detection and isolation;systems design	SE	23.093688073868226	50.42795396799907	143705
ac131a3a9fd94fb633b79471b705e331b1b2fd0e	alaptf: a new transition fault model and the atpg algorithm	process variation;fault model	The work presents a new transition fault model called as late as possible transition fault (ALAPTF) model. The model aims at detecting smaller delays, which be missed by both the traditional transition fault model and the path delay model. The model makes sure that each transition is launched as late as possible at the fault site, accumulating the small delay defects along its way. Because some transition faults may require multiple paths to be launched, the simple path-delay model miss such faults. Results on ISCAS'85 and ISCAS'89 benchmark circuits shows that for all the cases, the new model is capable of detecting smaller gate delays and produces better results in case of process variations. For all circuits, on an average, 30% of the time the transition reaches later than traditional models. The algorithm proposed also detects robust and non-robust paths along with the transition faults and the execution time is linear to the circuit size.	algorithm;benchmark (computing);fault model;path (graph theory);run time (program lifecycle phase);sensor	Puneet Gupta;Michael S. Hsiao	2004	2004 International Conferce on Test	10.1109/ITC.2004.27	electronic engineering;real-time computing;simulation;computer science;engineering;stuck-at fault;fault model;process variation;algorithm	EDA	21.502084649942308	52.01328215165761	145102
076fe47f760b080d8562aa5b479a4cd53e243427	efficient cancer therapy using boolean networks and max-sat-based atpg	drugs;circuit faults drugs logic gates vectors integrated circuit modeling cancer;circuit faults;integrated circuit;cancer;growth factor;computability;automatic test pattern generation;exact solution;medical computing automatic test pattern generation boolean algebra cancer computability drugs gene therapy genetics;optimal drug selection cancer therapy boolean networks max sat based atpg gene related diseases signaling pathway cancer treatment automatic test pattern generation algorithm boolean satisfiability stuck at fault model signalling fault representation weighted partial max sat formulation fault identification;genetics;boolean algebra;medical computing;boolean satisfiability;cancer treatment;vectors;logic gates;cancer therapy;boolean network;integrated circuit modeling;fault coverage;signaling pathway;fault model;automatic test pattern generator;gene regulatory network;logic gate;gene therapy;fault identification	Cancer and other gene related diseases are usually caused by a failure in the signaling pathway between genes and cells. These failures can occur in different areas of the gene regulatory network, but can be abstracted as faults in the regulatory function. For effective cancer treatment, it is imperative to identify faults and select appropriate drugs to treat the fault. In this paper, we present an extensible Max-SAT based automatic test pattern generation (ATPG) algorithm for cancer therapy. This ATPG algorithm is based on Boolean Satisfiability (SAT) and utilizes the stuck-at fault model for representing signalling faults. A weighted partial Max-SAT formulation is used to enable selection of the most effective drug. Several usage cases as presented for fault identification and drug selection. These include the identification of testable faults, optimal drug selection for single/multiple known faults, and optimal drug selection for overall fault coverage. Experimental results on growth factor (GF) signaling pathways demonstrate that our algorithm is flexible, and can yield an exact solution for each feature in much less than 1 second.	algorithm;boolean network;boolean satisfiability problem;fault coverage;fault model;grammatical framework;imperative programming;maximum satisfiability problem;stuck-at fault;test card	Pey-Chang Kent Lin;Sunil P. Khatri	2011	2011 IEEE International Workshop on Genomic Signal Processing and Statistics (GENSIPS)	10.1109/GENSiPS.2011.6169450	biology;electronic engineering;logic gate;computer science;theoretical computer science;mathematics;algorithm	EDA	18.49694067849228	48.83956583094434	145256
d8db14528ceaf497560667764735aaa9e4f3738a	hybrid bist optimization using reseeding and test set compaction	pseudorandom test pattern;classical bist;test time;test quality;pre-computed deterministic test pattern;test set generation;hybrid bist optimization;hybrid bist method;hybrid bist;test response compaction;test memory constraint;automatic test pattern generation;linear feedback shift register;fault coverage	Classical built-in self-test (BIST) approaches are largely based on pseudorandom testing, and using linear feedback shift registers (LFSR) for test set generation and test response compaction. In this paper, we are concentrating on one possible extension of the classical BIST, namely hybrid BIST, where pseudorandom test patterns are complemented with pre-computed deterministic test patterns to increase the fault coverage and to reduce test time. We will propose a novel method for hybrid BIST optimization, based on reseeding and test set compaction. The objective is to minimize the test time at given test memory constraints, without losing test quality. We will compare the proposed method with hybrid BIST methods developed earlier and analyze its suitability for testing core-based systems.	built-in self-test;data compaction;test set	Gert Jervan;Elmet Orasson;Helena Kruus;Raimund Ubar	2007		10.1109/DSD.2007.4341529	computer architecture;real-time computing;fault coverage;automatic test pattern generation;test compression;linear feedback shift register	EDA	20.346162287938643	51.416521754439174	145292
a61e184cda4765bba76b4d0b04cedc1bea8627a2	a novel rtl atpg model based on gate inherent faults (gif-po) of complex gates		This paper starts with a comprehensive survey on RTL ATPG. It then proposes a novel RTL ATPG model based on ”Gate Inherent Faults” (GIF). These GIF are extracted from each complex gate (adder, case-statement, etc.) of the RTL source code individually. They are related to the internal logic paths of a complex gate. They are not related to any net/signal in the RTL design. It is observed, that when all GIF on RTL are covered (100%) and the same stimulus is applied, then all gate level stuck-at faults of the netlist are covered (100%) as well. The proposed RTL ATPG model is therefore synthesis independent. This is shown on ITC’99 testcases. The applied semi-automatic test pattern generation process is based on functional simulation.	adder (electronics);gif;logic simulation;netlist;semiconductor industry;test card	Tobias Strauch	2016	CoRR		real-time computing;netlist;parallel computing;source code;automatic test pattern generation;computer science;adder	EDA	19.225609516102878	48.99259904792587	145673
2ee1d4ac99de4a92184563c5124a12d119453c71	reseeding-oriented test power reduction for linear-decompression-based test compression architectures			data compression;test compression	Tian Chen;Dandan Shen;Xin Yi;Huaguo Liang;Xiaoqing Wen;Wei Wang	2016	IEICE Transactions		data compression;embedded system;parallel computing;computer science;test compression;linear feedback shift register;statistics	EDA	19.912998300742334	52.15837119624883	145972
be39cc5db1b3e18f9f39b6e9fbb0f013f36af114	the problem of test latency in machine diagnosis	multiple fault isolation delayed sensor alarm data diagnostic inference engine test latency machine diagnosis;real time diagnosis;real time;delayed sensor alarm data;radiation detectors;temperature sensors;multiple fault isolation;delay engines fault diagnosis inference algorithms sensor systems system testing signal processing algorithms large scale systems temperature sensors real time systems;fault diagnosis diagnostic reasoning;test latency inference engine multiple fault isolation real time diagnosis;engines;estimation;diagnostic inference engine;inference algorithms;inference engine;diagnostic reasoning;signal processing algorithms;machine diagnosis;test latency;fault isolation;fault diagnosis	The impact of delayed sensor alarm data upon a diagnostic inference engine appears not to be well appreciated. In this paper, we illustrate the effect of sensor latency, and we propose an inference approach to obviate it.	inference engine	Ozgur Erdinc;Craig Brideau;Peter Willett;Thia Kirubarajan	2008	IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans	10.1109/TSMCA.2007.909545	embedded system;estimation;real-time computing;computer science;artificial intelligence;particle detector;fault detection and isolation;inference engine;statistics	Embedded	24.458885289307602	49.82820450077565	147229
7e50c442220c9fe6cfec2aada46956612a78d270	an effective defect-oriented bist architecture for high-speed phase-locked loops	design for testability;fault simulation;built in self test bist;phase lock loop;boundary scan testing;phase locked loops;chip;defect oriented testing;built in self test;test methods;integrated circuit testing;pll;fault coverage;900 mhz defect oriented bist architecture high speed phase locked loops charge based frequency measurement bist test stimulus test output fault simulations fault coverage;self checking circuits;high speed;high speed integrated circuits;built in self test phase locked loops voltage controlled oscillators circuit faults circuit testing charge pumps area measurement voltage measurement frequency conversion counting circuits;boundary scan testing built in self test phase locked loops high speed integrated circuits integrated circuit testing fault simulation	We propose a new method of defect-oriented testing of PLL using charge-based frequency measurement BIST (CF-BIST) technique. As no test stimulus is required and the test output is pure digital, low-cost and practical implementation of on-chip BIST for a PLL is possible. Fault simulations using the 900 MHz PLL from National Semiconductor Corp. show higher fault coverage than previous test methods.	built-in self-test;software bug	Seongwon Kim;Mani Soma;Dilip Risbud	2000		10.1109/VTEST.2000.843850	embedded system;electronic engineering;real-time computing;phase-locked loop;engineering;control theory;pll multibit	EDA	23.715672047709955	52.55844286684879	147528
02bdd4206fc131640e4fc8128db06c35142a67a0	implicit pseudo boolean enumeration algorithms for input vector control	leakage;leakage current;subthreshold current;input vector control;switching circuits;search space;efficient algorithm;decision diagram;state dependence;multilevel systems;upper bound;sat;binary decision diagrams;leakage power;permission;energy consumption;cmos logic circuits;power dissipation;batteries;low power electronics;symbolic methods;pseudo boolean;modes of operation;power;cmos;switching cost;combinational circuits;binary decision diagram;multilevel systems costs batteries permission energy consumption low power electronics cmos logic circuits combinational circuits subthreshold current switching circuits	In a CMOS combinational logic circuit, the subthreshold leakage current in the standby state depends on the state of the inputs. In this paper we present a new approach to identify the minimum leakage set of input vectors (MLS). Applying a vector in the MLS is known as Input Vector Control (IVC), and has proven to be very useful in reducing gate oxide leakage and sub-threshold leakage in standby mode of operation. The approach presented here is based on Implicit Enumeration of integer-valued decision diagrams. Since the search space for minimum leakage vector increases exponentially with the number of primary inputs, the enumeration is done with respect to the minimum balanced cut of the digraph representation of the circuit. To reduce the switching power dissipated when the inputs are driven to a given state (during entry into and exit from the standby state), we extend the MLS algorithm to compute a bounded leakage set (BLS). Given a bound of standby leakage, we present an algorithm for computing minimal switching cost partial input vectors such that the leakage of the circuit is always less than the upper bound.	algorithm;block cipher mode of operation;boolean satisfiability problem;cmos;circuit switching;combinational logic;covering problems;diagram;directed graph;gate oxide;ibm notes;logic gate;power electronics;sleep mode;spectral leakage	Kaviraj Chopra;Sarma B. K. Vrudhula	2004	Proceedings. 41st Design Automation Conference, 2004.	10.1145/996566.996774	electronic engineering;real-time computing;computer science;control theory;mathematics;leakage;algorithm	EDA	18.169243693838858	50.30741567603557	147698
97a4f3b658c5646270204ee3c8098851fe955ade	constructive multi-phase test point insertion for scan-based bist	near complete stuck at fault coverage multi phase test point insertion scan based bist constructive methodology divide and conquer approach test points fixed values;divide and conquer methods;boundary scan testing;built in self test;built in self test circuit testing circuit faults costs logic automatic test pattern generation circuit simulation laboratories hardware graphics;logic testing;integrated circuit testing;fault coverage;logic testing built in self test boundary scan testing divide and conquer methods integrated circuit testing fault diagnosis;divide and conquer;fault diagnosis	This paper presents a novel test point insertion technique which, unlike the previous ones, is based on a constructive methodology. A divide and conquer approach is used to partition the entire test into multiple phases. In each phase a group of test points targeting a specific set of faults is selected. Control points within a particular phase are enabled by fixed values, resulting in a simple and natural sharing of the logic driving them. Experimental results demonstrate that complete or near-complete stuck-at fault coverage can be achieved by the proposed technique with the insertion of a few test points and a minimum number of phases.	built-in self-test;control point (mathematics);fault coverage;insertion sort;olap cube;simulation;software bug;stuck-at fault;test point	Nagesh Tamarapalli;Janusz Rajski	1996		10.1109/TEST.1996.557122	reliability engineering;electronic engineering;scan chain;divide and conquer algorithms;boundary scan;fault coverage;computer science;stuck-at fault;theoretical computer science;automatic test pattern generation;test compression;mathematics;algorithm	EDA	21.310126091257406	51.02269427772571	148385
be4e523b33da80af6a1f3e67ca70f1adf7796c97	towards an automatic generation of diagnostic in-field sbst for processor components	microcomputers automatic test software logic design;logic design;hand coded test program automatic generation diagnostic infield sbst processor components diagnostic software based self test program multiplexer based components control logic generated test program;automatic test software;microcomputers;band pass filters timing	This paper deals with a diagnostic software-based self-test program for multiplexer based components in a processor. These are in particular the read ports of a multi-ported register file and the bypass structures of an instruction pipeline. Based on the detailed analysis of both multiplexer structures, first a manually coded diagnostic test program is presented. This test program can detect all single and multiple stuck-at data- and address faults in a multiplexer structure. But it does not fully cover the control-logic of the bypass. By further refinements a 100% fault coverage for single stuck-at faults, including the control logic, is finally obtained. Based on these results, an ATPG-assisted method for the generation of such a diagnostic test program is described for arbitrary processor components. This method is finally applied to the multiplexer structures for which the manually coded test program is available. The test length and test coverage of the generated test program and of the hand-coded test program are compared.	algorithm;fault coverage;instruction pipelining;multiplexer;register file	Mario Schölzel;Tobias Koal;Stephanie Roder;Heinrich Theodor Vierhaus	2013	2013 14th Latin American Test Workshop - LATW	10.1109/LATW.2013.6562676	computer architecture;real-time computing;fault coverage;computer science;automatic test pattern generation;test compression;test suite;test management approach;computer engineering;test harness	SE	20.439617851701318	50.21190225169299	149766
889e94247fd7a1b591693aa80f6967fbc8258db4	implementation of threshold nets by integer linear programming	integer linear programming;integer linear programming switches operational amplifiers switching circuits propagation delay boolean functions resistors capacitors zero voltage switching logic;boolean functions;switching circuits;logic;operational amplifiers;propagation delay;capacitors;resistors;zero voltage switching;switches;integer linear program		integer programming;linear programming	Melvin A. Breuer	1965	IEEE Trans. Electronic Computers	10.1109/PGEC.1965.264120	propagation delay;mathematical optimization;electronic engineering;discrete mathematics;integer programming;computer science;mathematics;logic	EDA	19.703448342299	46.45698129106121	150352
652e22e89636c2d0dbbad67801e5c9221b335bc1	bdd variable ordering for interacting finite state machines	a priori bound;efficient algorithm;communication complexity;tellurium;testing;upper bound;automata;binary decision diagrams;community structure;data structures;binary decision diagrams automata upper bound data structures logic functions electronic switching systems tellurium read only memory testing explosions;logic functions;electronic switching systems;explosions;cumulant;read only memory;finite state machine	We address the problem of obtaining good variable orderings for the BDD representation of a system of interacting finite state machines (FSMs). Orderings are derived from the communication structure of the system. Communication complexity arguments are used to prove upper bounds on the size of the BDD for the transition relation of the product machine in terms of the communication graph, and optimal orderings are exhibited for a variety of regular systems. Based on the bounds we formulate algorithms for variable ordering. We perform reached state analysis on a number of standard verification benchmarks to test the effectiveness of our ordering strategy; experimental results demonstrate the efficacy of our approach. The algorithms described in this paper have been implemented in HSIS, a hierarchical synthesis and verification tool currently under development at Berkeley.	algorithm;communication complexity;finite-state machine;interaction	Adnan Aziz;Serdar Tasiran;Robert K. Brayton	1994	31st Design Automation Conference	10.1145/196244.196379	mathematical optimization;electronic engineering;discrete mathematics;data structure;computer science;theoretical computer science;communication complexity;tellurium;mathematics;automaton;software testing;finite-state machine;upper and lower bounds;read-only memory;community structure;algorithm;statistics;cumulant	EDA	19.677850665756598	47.30054931296286	150683
cd6af0c6c84541cbf455c41e7e421e63f9f147c0	about signal flow graph techniques for sequential circuits	signal flow graph;sequential circuits;logic;flow graphs;flow graphs sequential circuits equations logic		signal-flow graph	Janusz A. Brzozowski;Edward J. McCluskey	1964	IEEE Trans. Electronic Computers	10.1109/PGEC.1964.263787	discrete mathematics;graph product;engineering;clique-width;theoretical computer science;voltage graph;sequential logic;modular decomposition;logic;algorithm;control flow graph	EDA	19.41819207885517	47.04279240937454	150960
af89c9e9610d9efe1fc4de6204fd8dc0c0bac6e9	a limited exponential complexity algorithm for increasing the testability of digital circuits by testing-module insertion	generation;complexite;design for testability;sequential machines;single line stuck at faults;circuit faults;logic design;circuit testing digital circuits logic testing circuit faults logic gates logic circuits design for testability upper bound merging combinational circuits;placement algorithm;automatic testing;logic circuits;circuit numerique;upper bound;essai;logic gate level;logic gates;logic testing automatic testing digital circuits logic design;test generation algorithm;logic testing;merging;limited exponential complexity algorithm;testing module insertion;test generation;circuit testing;digital circuits;resultat experimental;worst case complexity;logic gate;sequential machines testability improvement limited exponential complexity algorithm digital circuits testing module insertion single line stuck at faults logic gate level test generation algorithm design for testability worst case complexity placement algorithm;testability improvement;circuit integre;conception modulaire;combinational circuits	The authors describe a method for increasing the testability of digital circuits for single line stuck-at faults at the logic gate level by the addition of controllable and observable points in structures called testing modules. They also present a test generation algorithm that generates complete test sets, i.e. test sets that cover every possible fault, for increasingly large subcircuits. The test generation algorithm forms the basis for the design-for-testability method described. The authors introduce the concept of exhaustive test generation and of test set reduction, and show that the worst-case complexity of test generation can be estimated on the basis of the these concepts, without having to perform worst-case test generation. They describe the testing-module placement algorithm, whose aim is to reduce the complexity of test generation. It is based on the estimated complexity of test generation as developed. The extension of the method to sequential machines is briefly discussed. >	algorithm;digital electronics;time complexity	Irith Pomeranz;Zvi Kohavi	1992	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.124403	electronic engineering;test data generation;fault coverage;logic gate;computer science;engineering;theoretical computer science;automatic test pattern generation;test compression;mathematics;algorithm	EDA	20.96990444283287	49.175598150633725	151061
34f0ab57eb547cd491cd80882a88f2675e871b7d	multi-level synthesis for safe replaceability	safe replaceability;original design;interacting environment;sequential digital design;existing design;initial state;gate-level design;multi-level synthesis;safe replacement;replacement design;safe replacement condition;new design;satisfiability;algorithm design and analysis;sequential circuits;input output;routing;logic design;state transition diagram;digital design	We describe the condition that a sequential digital design is a safe replacement for an existing design without making any assumptions about a known initial state of the design or about its environment. We formulate a safe replacement condition which guarantees that if an original design is replaced by a new design, the interacting environment cannot detect the change by observing the input-output behavior of the new design; conversely, if a replacement design does not satisfy our condition an environment can potentially detect the replacement (in this sense the replacement is potentially unsafe). Our condition allows simplification of the state transition diagram of an original design. We use the safe replacement condition to derive a sequential resynthesis method for area reduction of gate-level designs. We have implemented our resynthesis algorithm and we report experimental results.	algorithm;interaction;level of detail;logic synthesis;multi-level governance;state diagram;state transition table	Carl Pixley;Vigyan Singhal;Adnan Aziz;Robert K. Brayton	1994		10.1145/191326.191510	embedded system;routing;electronic engineering;logic synthesis;real-time computing;computer science;register-transfer level;algorithm	EDA	18.91484049150326	48.37166476401957	151311
ab92d8c30f60d95dbbe69d7760e8bd552cd46696	an exact solution to the minimum size test pattern problem	minimal model;logic testing combinational circuits computability linear programming integer programming automatic test pattern generation built in self test;circuit testing test pattern generators logic testing built in self test circuit faults combinational circuits automatic testing circuit synthesis logic programming integer linear programming;computability;automatic test pattern generation;exact solution;optimization problem;built in self test;integer programming;logic testing;linear programming;test generation;test pattern generator;combinational circuit;benchmark circuits exact solution minimum size test pattern problem test pattern generation single stuck at faults combinational circuits built in self test integer linear programming propositional satisfiability;integer linear program;propositional satisfiability;combinational circuits	This paper addresses the problem of test pattern generation for single stuck-at faults in combinational circuits, under the additional constraint that the number of specified primary input assignments is minimized. This problem has different applications in testing including the identification of don't care conditions to be used in the synthesis of Built-In Self-Test (BIST) logic. The proposed solution is based on an integer linear programming (ILP) formulation which builds on an existing propositional satisfiability (SAT) model for test pattern generation. The resulting ILP formulation is linear on the size of the original SAT model for test generation, which is linear on the size of the circuit. Nevertheless, the resulting ILP instances represent complex optimization problems, that require dedicated ILP algorithms. Preliminary results on benchmark circuits validate the practical applicability of the test pattern minimization model and associated ILP algorithm.	test card	Paulo F. Flores;Horácio C. Neto;Joao Marques-Silva	1998		10.1109/ICCD.1998.727097	integer programming;computer science;linear programming;theoretical computer science;combinational logic;algorithm	Theory	18.363224580148962	48.86015743029026	151428
9a75b5799c86e516e308feff76185e0dfb946be1	an efficient bist method for distributed small buffers	system on chip testing bist method distributed small buffers built in self testing concurrent testing spatially distributed embedded memory modules redundant read write operations march method rsmarch low hardware overhead short test time high fault coverage split mode test method serial interface technique soc testing;distributed memory;march method;concepcion asistida;design for testability;computer aided design;built in self test circuit testing system testing automatic testing computer science random access memory sequential analysis hardware size control read write memory;random access memory;metodologia;methode essai;system on chip soc testing;systeme embarque;integrated circuit;memoria compartida;integrated memory circuits;automatic testing;rsmarch;spatially distributed embedded memory modules;buffer storage;circuito separador;built in self testing;sequential analysis;circuito integrado;size control;effet dimensionnel;methodologie;system on a chip;essai circuit integre;algorithme;short test time;distributed small buffers;algorithm;embedded systems;low hardware overhead;built in self test;parallel architectures;split mode test method;sistema sobre pastilla;architecture parallele;spatial distribution;system on chip;separator circuit;size effect;soc testing;logic testing;test methods;built in self testing bist;redundant read write operations;integrated circuit testing;vlsi;conception assistee;system testing;fault coverage;concurrent testing;memory test;conception pour test;circuit testing;circuit separateur;systeme sur puce;computer science;read write memory;efecto dimensional;test method;methodology;serial interface technique;memoire repartie;vlsi built in self test integrated circuit testing integrated memory circuits system on chip buffer storage logic testing;system on chip testing;bist method;high fault coverage;circuit integre;embedded memory arrays;hardware;algoritmo;metodo ensayo	In this work, we propose a new built-in self-testing (BIST) method that is able to concurrently test a set of spatially distributed embedded-memory modules with different sizes. Using the concept of redundant read-write operations, we develop a new march method, called RSMarch, to efficiently test each memory module. The new method has the advantages of low hardware overhead, short test time, and high-fault coverage. The total test time is dominated by large-size modules. To further reduce the test time, we also propose a split-mode test method to virtually partition each large memory array into smaller modules, which can be tested simultaneously.	built-in self-test	Wen-Ben Jone;Der-Cheng Huang;S. C. Wu;Kuen-Jong Lee	2002	IEEE Trans. VLSI Syst.	10.1109/TVLSI.2002.800532	system on a chip;embedded system;electronic engineering;parallel computing;real-time computing;computer science;operating system;computer aided design;test compression;test method;statistics	EDA	19.092058955454554	52.14670246526958	151458
13c14e10b72ab42cad88a44d6b59551a19c33b72	retiming for delay recovery after dft insertion on interdie paths in 3-d ics	design for testability;automatic test pattern generation;flip flops;delay recovery wrapper insertion atpg wrapper boundary cells stack level retiming modular processor logic on logic 3d benchmark simulations die level retiming logic redistribution design for test insertion bypass mode prebond scan test prebond through silicon via boundary register gated scan flops kgd test die wrappers 3d integrated circuits stack yield prebond known good die test 3d ics interdie paths dft insertion;three dimensional integrated circuits automatic test pattern generation circuit simulation delay circuits design for testability flip flops integrated circuit testing integrated logic circuits;circuit simulation;delay circuits;integrated circuit testing;tsv 3 d integration kgd retiming test wrapper;integrated logic circuits;delays registers logic gates through silicon vias clocks integrated circuit interconnections;three dimensional integrated circuits	Pre-bond known-good-die (KGD) test is necessary to ensure stack yield for the future adoption of 3-D integrated circuits. Die wrappers that contain boundary registers at the interface between dies have been proposed as a solution for KGD test. It has been shown in the literature that if gated scan flops (GSFs) are substituted for traditional scan flops in the boundary register, then both pre-bond through-silicon-via (TSV) and pre-bond scan test can be performed. The drawback of die wrappers is that two clocked stages are added to each path that crosses a die boundary. In this paper, a bypass mode is added to GSFs to avoid the extra clock stages and retiming is used to recover the additional delay added to TSV paths by design-for-test insertion. Retiming is performed at both die and stack level, and a logic redistribution is proposed to improve the results of die-level retiming. The proposed methods are evaluated through simulations using two logic-on-logic 3-D benchmarks and one modular processor partitioned between two dies. Results show that in most cases, retiming at both the die-level and stack-level is sufficient for recovering the delay added by wrapper boundary cells in cores where all logic and dies are unfixed. Stuck-at ATPG is performed to demonstrate that wrapper insertion and retiming have little impact on pattern count. The area overhead due to wrapper insertion is shown to increase as a circuit is partitioned across an increasing number of stack layers, but the area overhead can be reduced using retiming.	algorithm;benchmark (computing);ct scan;call stack;clock rate;design for testing;die (integrated circuit);flops;fast fourier transform;integrated circuit;overhead (computing);retiming;simulation;test card;through-silicon via	Brandon Noia;Krishnendu Chakrabarty	2014	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2013.2289857	electronic engineering;parallel computing;real-time computing;engineering;retiming;automatic test pattern generation;design for testing	EDA	18.815696383070627	53.12585071100047	151463
8fea7dae27086b5d646fc193f9bf03793f0c8226	a parallel system for test pattern generation	digital circuit;concepcion asistida;computer aided design;architecture systeme;integrated circuit;generateur forme;implementation;performance;generador forma;circuito integrado;transputer;test;ensayo;circuit numerique;ejecucion;essai;parallel systems;pattern generator;circuito numerico;conception assistee;arquitectura sistema;test pattern generator;systeme parallele;parallel system;rendimiento;system architecture;circuit integre;sistema paralelo	Abstract   The problem of generating test sequences for digital circuits is a crucial one in the area of electronic CAD. While a significant effort has been done to develop new and more powerful algorithms to solve it, the required CPU times are still unacceptable in many cases. A different approach based on the use of general-purpose MIMD architectures is presented in this paper. The attention is devoted to combinational circuits described at the gate level, although the same concepts can be extended to synchronous sequential circuits; faults are modeled as permanent single stuck-ats. A parallelization strategy is proposed, together with an implementation on a transputer-based machine. The resulting system significantly speeds-up the test generation process: its performance is discussed, reporting also the experimental results obtained on the standard set of benchmark combinational circuits.		Gianpiero Balboni;Gianpiero Cabodi;Silvano Gai;Matteo Sonza Reorda	1993	Parallel Computing	10.1016/0167-8191(93)90047-O	embedded system;parallel computing;simulation;performance;computer science;integrated circuit;computer aided design;digital pattern generator;software testing;implementation;digital electronics;algorithm;systems architecture	HPC	20.94186960236118	48.62942184723616	151659
270c477997c1e3dcb9106217e5bf81a7e5cbc7aa	aliasing in multiple-valued test data compaction	error model aliasing multiple valued test data compaction multiple input shift registers output compaction multiple valued logic circuits ternary quaternary misrs;many valued logics;logic circuits;shift registers logic circuits logic testing many valued logics;compaction circuit testing logic circuits built in self test circuit faults automatic testing logic testing cities and towns very large scale integration wiring;shift registers;logic testing;multiple valued;multiple valued logic	The possibility of using multivalued instead of binary linear multiple input shift registers (MISRs) for output compaction of multiple-valued logic circuits is discussed. The use of multivalued MISRs avoids the need for decoding the signals. A framework for examining aliasing in multiple-valued circular MISRs is presented. The exact aliasing probability is obtained for ternary and quaternary MISRs under an independent error model for an arbitrary test length. It is shown that multivalued MISRs perform better than their binary counterparts. >	aliasing;data compaction;test data	Geetani Edirisooriya;John P. Robinson	1992		10.1109/ISMVL.1992.186776	electronic engineering;discrete mathematics;logic gate;logic family;computer science;mathematics;shift register;algorithm	SE	21.671909473697912	48.51206276670823	151850
f8ce5eeb8acbc36f0f50cdc991c4fd4b5904da14	a remark on determining the number of states of a sequential machine	automatic control;minimization;boolean functions;automatic testing;logic;presses;sequential analysis;boolean functions algorithm design and analysis automatic testing sequential analysis minimization switching systems logic presses digital control automatic control;switching systems;digital control;algorithm design and analysis	Results in the literature on sequential machines prove that it is not possible to determine the minimal form of a machine by external measurements. By changing the concept of external measurement, an ``effective solution'' to this identification problem is given. The solution utilizes an important result in the theory of sequential relations.		Michael A. Harrison	1967	IEEE Trans. Electronic Computers	10.1109/PGEC.1967.264788	control engineering;digital control;computer science;theoretical computer science;sequential analysis;automatic control;control theory;mathematics;sequential logic;logic;algorithm	EDA	22.764804112276845	47.015700293491975	152289
f82a704e043bc9c223ea542a23b4f3dcdc25a012	scan-based bist using an improved scan forest architecture	benchmark circuits scan based bist scan forest architecture scan testing test data volume reduction scan flip flop regrouping test per scan test architecture fault coverage;flip flops;boundary scan testing;network topology;built in self test;network topology boundary scan testing flip flops built in self test logic testing;logic testing;fault coverage;built in self test circuit testing flip flops clocks costs circuit faults benchmark testing hardware computer science broadcasting;flip flop	Scan forest is an efficient scan architecture which can reduce the test application cost, test power of scan testing and test data volume greatly. The scan forest is modified for scan-based BIST. Techniques are used to make the existing scan forest architecture to an improved scan forest that is more suitable for BIST. A scan flip-flop regrouping technique is introduced to make the scan flip-flop groups have similar sizes. Sufficient experimental results show that the proposed techniques improve the popular test-per-scan test architecture greatly on fault coverage and test length. It is shown according to the experimental results that test length is reduced 77.3% on average for all benchmark circuits.	benchmark (computing);built-in self-test;flops;fault coverage;flip-flop (electronics);test data;turing test	Dong Xiang;Ming-Jing Chen;Kaiwei Li;Yu-Liang Wu	2004	13th Asian Test Symposium	10.1109/ATS.2004.78	embedded system;scan chain;parallel computing;real-time computing;boundary scan;fault coverage;computer science;engineering;test compression;network topology	EDA	20.11872748210646	52.44628753663277	152507
06148bd742db271fd086aeaf99035995314184b6	speeding up model checking by exploiting explicit and hidden verification constraints	constraint optimization state space methods cost accounting testing buildings data structures boolean functions algorithm design and analysis circuit optimization performance analysis;explicit verification constraint;virtualization;boolean functions;component;data mining;formal verification;model checking;logic partitioning electronic design automation formal verification logic cad;data structures;state space;integrated circuit modeling;mathematical model;run time support;state space partition;state space partition model checking explicit verification constraint hidden verification constraint;logic partitioning;logic cad;reconfigurable computers;hidden verification constraint;benchmark testing;electronic design automation	Constraints represent a key component of state-of-the-art verification tools based on compositional approaches and assume--guarantee reasoning. In recent years, most of the research efforts on verification constraints have focused on defining formats and techniques to encode, or to synthesize, constraints starting from the specification of the design.  In this paper, we analyze the impact of constraints on the performance of model checking tools, and we discuss how to effectively exploit them. We also introduce an approach to explicitly derive verification constraints hidden in the design and/or in the property under verification. Such constraints may simply come from true design constraints, embedded within the properties, or may be generated in the general effort to reduce or partition the state space. Experimental results show that, in both cases, we can reap benefits for the overall verification process in several hard-to-solve designs, where we obtain speed-ups of more than one order of magnitude.	encode;embedded system;model checking;state space	Gianpiero Cabodi;Paolo Camurati;Luz Garcia;Marco Murciano;Sergio Nocco;Stefano Quer	2009	2009 Design, Automation & Test in Europe Conference & Exhibition	10.1109/DATE.2009.5090934	model checking;benchmark;virtualization;electronic design automation;formal verification;computer science;state space;theoretical computer science;mathematical model;component;runtime verification;boolean function;programming language;algorithm;functional verification	EDA	17.611193932307305	47.57525007662888	152515
deecb2f677ed63797339b94b5f64e53ab170e900	test pattern selection for defect-aware test	propagation path function test pattern selection defect aware test lsi stuck at fault transition fault n detection test fault excitation function;circuit faults delay automatic test pattern generation bridges logic gates fault detection;resistive open fault;logic testing automatic test pattern generation fault diagnosis integrated circuit reliability large scale integration;circuit faults;automatic test pattern generation;bridges;large scale integration;logic gates;fault detection;logic testing;resistive bridging fault;test pattern selection;integrated circuit reliability;resistive open fault test pattern selection defect aware resistive bridging fault;automatic test pattern generator;logic gate;defect aware;fault diagnosis	With shrinking of LSIs, the diversification of defective mode becomes a critical issue. As a result, test patterns for stuck-at faults and transition faults are insufficient to detect such defects. N-detection tests have been known as an effective way for achieving high defect coverage, but the large number of test pattern counts is the problem. In this paper, we propose metrics based on the fault excitation functions and the propagation path function to evaluate test patterns for transition faults. We also propose the method for selecting the test patterns from the N-detection test set. From the experimental results, we show that the set of selected test patterns can detect the larger number of faults than other test set with the same number of test patterns.	bridging (networking);diversification (finance);fault coverage;fault model;software bug;software propagation;test card;test set	Yoshinobu Higami;Hiroshi Furutani;Takao Sakai;Shuichi Kameyama;Hiroshi Takahashi	2011	2011 Asian Test Symposium	10.1109/ATS.2011.24	reliability engineering;electronic engineering;real-time computing;fault coverage;logic gate;engineering;automatic test pattern generation;test compression	SE	21.62175003140592	53.143880643865465	152735
f3a2e2c561728008558873331ddd5e01e78de8df	a parallel genetic algorithm for automatic generation of test sequences for digital circuits	parallel genetic algorithm;automatic generation;genetic algorithm;digital circuits	The paper deals with the problem of Automatic Generation of Test Sequences for digital circuits. Genetic Algorithms have been successfully proposed to solve this industrially critical problem; however, they have some drawbacks, e.g., they are often unable to detect some hard to test faults, and require a careful tuning of the algorithm parameters. In this paper, we describe a new parallel version of an existing GA-based ATPG, which exploits competing sub-populations to overcome these problems. The new approach has been implemented in the PVM environment and has been evaluated on a workstation network using some of the standard benchmark circuits. The results show that it is able to significantly improve the results quality (by testing some critical faults) at the expense of increased CPU time requirements	genetic algorithm	Fulvio Corno;Paolo Prinetto;Maurizio Rebaudengo;Matteo Sonza Reorda	1996		10.1007/3-540-61142-8_583	parallel computing;real-time computing;genetic algorithm;computer science;theoretical computer science;distributed computing;digital electronics;algorithm	EDA	18.898365600244134	50.819286000670154	153212
de3c8ee11bfe0c5dc760e211b0fbf0cfead2680e	adaptive fault detection and diagnosis of ram interconnects	random access memory;fault detection and diagnosis;reading and writing	We give three new algorithms to compute tests for faults in the interconnects of random access memories (RAM) using only read and write operations. Diagnosis of address line faults is the most difficult step. Our Adaptive Diagnosis Algorithm (ADA) considers each address line separately. Single line faults are easy to diagnose, so the objective is to ascertain which address lines are free of faults, thereby pruning impossible multi-line faults. Our Consecutive Diagnosis Algorithm (CDA) uses a more complicated and lengthier test sequence. However, with CDA, interpreting the test results is easier and the diagnostic resolution is superior. Our third algorithm, Adaptive Diagnosis Algorithm with Repair (ADAR), relies upon additional testing after repair in order to diagnose more faults than would otherwise be possible. ADAR has three test stages with two repair stages between them.	electrical connection;random-access memory	Jun Zhao;Fred J. Meyer;Fabrizio Lombardi	1999	J. Electronic Testing	10.1023/A:1008396604722	embedded system;parallel computing;real-time computing;engineering	Logic	19.401011655104636	50.98248566270091	153720
1b5216ab1bc827542c0c27a2cc11121f403ce661	self-testing checker design for incomplete m-out-of-n codes	computers;circuit faults;logic testing codes field programmable gate arrays logic design;built in self test circuit faults field programmable gate arrays single event upsets computers educational institutions;fpga realization self testing checker design incomplete m out of n codes stc codewords;built in self test;single event upsets;field programmable gate arrays	This paper presents the synthesis of self-testing checker (STC) for a subset of l codewords of m-out-of-n code. We consider FPGA realization of the checker.	code word;field-programmable gate array	Natalia Butorina	2014	Proceedings of IEEE East-West Design & Test Symposium (EWDTS 2014)	10.1109/EWDTS.2014.7027072	electronic engineering;real-time computing;programmable logic array;computer science;theoretical computer science	Embedded	21.995790850475213	48.5162644204092	153856
42ef1fdb434a06321db81c23a8f29008ae60b087	a classical parameter identification method and a modern test generation algorithm	component connection model ccm;parameter identification;analog circuits;faulty diagnosis;sensitivity analysis;test generation;fault coverage;tolerance;fault model	Many methods have been presented for the testing and diagnosis of analog circuits. Each of these methods has its advantages and disadvantages. In this paper we propose a novel sensitivity analysis algorithm for the classical parameter identification method and a continuous fault model for the modern test generation algorithm, and we compare the characteristics of these methods. At present, parameter identification based on the component connection model (CCM) cannot ensure that the diagnostic equation is optimal. The sensitivity analysis algorithm proposed in this paper can choose the optimal set of trees to construct an optimal CCM diagnostic equation, and enhance the diagnostic precision. But nowadays increasing attention is being paid to test generation algorithms. Most test generation algorithms use a single value in the fault model. But the single values cannot substitute for the actual faults that may occur, because the possible faulty values vary over a continuous range. To solve this problem, this paper presents a continuous fault model for the test generation algorithm which has a continuous range of parameters. The test generation algorithm with this model can improve the treatment of the tolerance problem, including the tolerances of both normal and faulty parameters, and enhance the fault coverage rate. The two methods can be applied in different situations.	algorithm	Ting Long;Houjun Wang;Bing Long	2011	CSSP	10.1007/s00034-010-9228-y	fault coverage;analogue electronics;engineering;artificial intelligence;stuck-at fault;automatic test pattern generation;machine learning;fault model;sensitivity analysis;algorithm;statistics	EDA	24.428853944285187	51.26481126062928	154392
ebbc42a9acc357b2552afd025875775a817d730b	interconnect diagnosis of bus-connected multi-ram systems	wiring integrated circuit interconnections random access storage integrated memory circuits fault diagnosis driver circuits;integrated memory circuits;chip;integrated circuit interconnections;test operations interconnect diagnosis bus connected multi ram systems interconnect faults shorts stuck at faults multiple ram chips bcmrs multiple line types bus lines driver lines disjoint busses testing objectives maximal diagnosis;driver circuits;read write memory random access memory fault diagnosis joining processes fault detection system testing computer science electrical fault detection hip electronic switching systems;random access storage;wiring;object detection;fault diagnosis	This paper presents a novel approach for detection and diagnosis (with no confounding or aliasing) of interconnect faults (short and stuck-at) in a system consisting of multiple RAM chips connected through busses. These systems (referred to as a bus-connected multi RAM systems, or BCMRS) are characterized by multiple types of lines (bus and driver lines), disjoint busses (address and data) as well as by the presence of memories (whose number is given by D). Different testing objectives (detection and maximal diagnosis) are considered. An extensive analysis of the faults is pursued to characterize their impact on the BCMRS as well as on the test operations (such as WRITE and READ).	aliasing;bus (computing);maximal set;random-access memory	Jun Zhao;Fred J. Meyer;Fabrizio Lombardi	1999		10.1109/MTDT.1999.782682	chip;embedded system;electronic engineering;parallel computing;telecommunications;computer science;engineering	EDA	21.745747809679873	51.78863696787059	154425
cac704eeb3b371e9cb53b2e91712ca1fbbe9ad3b	a novel heuristic method for application-dependent testing of a sram-based fpga interconnect	table lookup vectors field programmable gate arrays circuit faults testing integrated circuit interconnections complexity theory;configuration generation;logic simulation;complexity theory;circuit faults;configuration generation field programmable gate array fpga interconnect testing multiple fault detection test configurations;interconnect testing;multiple fault detection;greedy algorithms;table lookup circuit complexity circuit simulation fault diagnosis field programmable gate arrays greedy algorithms integrated circuit interconnections logic simulation sram chips;testing;field programmable gate array fpga;circuit complexity;circuit simulation;vectors;integrated circuit interconnections;xilinx virtex4 fpga heuristic method application dependent testing sram based fpga interconnect fault coverage exponential complexity heuristic algorithm polynomial algorithm greedy algorithm net selection configuration generation process execution complexity lut walsh coding logic based simulation iscas89 sequential benchmark;test configurations;field programmable gate arrays;table lookup;fault diagnosis;sram chips	This paper presents a new method for generating configurations for application-dependent testing of a SRAM-based FPGA interconnect. This method connects an activating input to multiple nets, thus generating activating test vectors for detecting stuck-at, open, and bridging faults. This arrangement permits a reduction in the number of redundant configurations, thus also achieving a reduction in test time for application-dependent testing at full fault coverage. As the underlying solution requires an exponential complexity, a heuristic algorithm that is polynomial and greedy in nature (based on sorting) is used for net selection in the configuration generation process. It is proved that this algorithm has an execution complexity of O(L3) (where L is the number of LUTs in the design). The proposed method requires at most log2(M + 2) configurations (where M denotes the number of activating inputs) as Walsh coding is employed. Moreover, it is scalable with respect to LUT inputs. Extensive logic-based simulation results are provided for ISCAS89 sequential benchmark designs implemented on Xilinx Virtex4 FPGAs; these results shows that the proposed method achieves a considerable reduction in the number of test configurations compared with methods found in the technical literature (on average, a reduction of 49.5 percent).	benchmark (computing);bridging (networking);emulator;fault coverage;fault model;field-programmable gate array;greedy algorithm;hadamard transform;heuristic (computer science);logic simulation;polynomial;scalability;sensor;sorting;static random-access memory;time complexity	Thulasiraman Nandha Kumar;Fabrizio Lombardi	2013	IEEE Transactions on Computers	10.1109/TC.2011.247	circuit complexity;embedded system;greedy algorithm;parallel computing;computer science;theoretical computer science;logic simulation;software testing;algorithm;field-programmable gate array	EDA	19.57541013932764	50.22410205552735	154493
b8a8749843f8106c58ac61667aadfaec0e6cce9b	achieving at-speed structural test	multicycle paths;bist;pins;frequency domain analysis;automatic test pattern generation;flip flops;sequential analysis;frequency domains;structural testing;at speed testing;built in self test;logic testing;at speed structural test;circuit testing;frequency domains at speed structural test bist at speed testing multicycle paths;frequency domain;circuit testing timing built in self test automatic test pattern generation sequential analysis flip flops frequency domain analysis logic testing pins;timing	In addition to structural test, BIST offers an alternative low-cost approach to at-speed testing. How should BIST be implemented to address at-speed testing? What issues remain to be solved? How can we deal with multicycle paths and different frequency domains? The author describes BIST implementation techniques to answer these questions.	built-in self-test	Stephen Pateras	2003	IEEE Design & Test of Computers	10.1109/MDT.2003.1232253	electronic engineering;real-time computing;engineering;frequency domain;algorithm;statistics	SE	21.474012927883415	51.97521339244536	154596
d480f00e50efa928bee049ce1895c95b4a5827b9	a new algorithm for the selection of control cells in boundary-scan interconnect test	control cell selection;interconnect test;boundary scan	This paper presents an algorithm for the generation of the values to be loaded in the control cells of a Boundary-Scan (BS) chain during an interconnect test. The algorithm selects several groups of control cells while avoiding that two or more drivers excite the same net at the same time, allowing every net to be active for every test vector and testing every driver after the execution of the overall test process. It allows for 100% detection of short, open, stuck-at and driver transition faults on fully controllable and observable BS nets on virtually any BS board. In fact, only two minor requirements are imposed: (1) the sets of nets affected by two different control cells must be disjoint or one of them must be included in the other; (2) every net of a set affected by a control cell must have the same number of drivers. In addition, the algorithm can be implemented very easily, avoiding the need to explore all the possible combinations of values to be loaded in the control cells.	algorithm;boundary scan;device driver;excite;fault coverage;fault detection and isolation;observable;requirement;test vector	Ángel Quirós-Olozábal;Ma de los Ángeles Cifredo Chacón	2009	J. Electronic Testing	10.1007/s10836-008-5091-1	embedded system;electronic engineering;real-time computing;boundary scan;computer science;engineering	EDA	23.347628780261605	50.26205208164701	154621
c5329d8a0ae1a915dc037a40f7b64907c5d5165d	basic properties and a construction method for fail-safe logical systems	control systems;lighting control;motor drives;velocity control;road accidents;logic design;logic;traffic control;satisfiability;error correction in logical design;reliable logical networks;redundancy;fail safe logical design;error correction;redundancy in logical design;reliable logical networks error correction in logical design fail safe logical design logical design redundancy in logical design;circuits;logical design;design methodology lighting control logic circuits redundancy motor drives control systems traffic control road accidents velocity control;design methodology	"""In this paper, the authors study """"fail-safe"""" propershould be in the OFF state whenever the motor control ties of logical systems, finding the conditions that the basic logical m fails. In functions of fail-safe logical systems should satisfy and also identisyste these systems, it is desirable that failure fying the allowable failures for the basic logical function circuits. of elements composing the system should not cause the With these results, the authors present a systematic representation output error with greater loss. If the loss caused by of fail-safe logical systems, and an effective method of logical design erroneously deriving 1 instead of 0 is greater than the for fail-safe systems. loss caused by deriving 0 instead of 1, we call this a """"O"""	effective method;fail-safe	Hisashi Mine;Yoshihaki Koga	1967	IEEE Trans. Electronic Computers	10.1109/PGEC.1967.264664	logical possibility;decidability;control engineering;non-classical logic;and-inverter graph;logical reasoning;logical framework;logical consequence;computer science;engineering;control system;electrical engineering;theoretical computer science;truth table;logical conjunction;redundancy;logic;logical data model;algorithm;satisfiability	Logic	23.19058432618585	46.45189477184025	155196
5a8af2317be5f39ec0a02ad2139cf85d94dce66e	modeling and detection of dynamic errors due to reflection- and crosstalk-noise	test sequences generation;3 bit adder circuit dynamic errors crosstalk noise reflection test sequences generation error modeling error durations gate delays transmission line delays testability combinational circuits;error durations;crosstalk noise;circuit noise;crosstalk;uncertainty;delay lines;logic;circuit layout;distributed parameter circuits;testability;transmission line theory;transmission line delays;adders;electromagnetic wave reflection;error modeling;acoustic reflection;logic testing;3 bit adder circuit;crosstalk circuit testing acoustic reflection logic distributed parameter circuits delay lines uncertainty electromagnetic reflection circuit noise combinational circuits;circuit testing;electromagnetic reflection;combinational circuit;circuit noise combinational circuits logic testing circuit layout crosstalk electromagnetic wave reflection transmission line theory adders;gate delays;reflection;combinational circuits;transmission line;dynamic errors	A new algorithm for the generation of test sequences to detect dynamic errors due to re ection and crosstalk noise in combinational circuits is presented. Based on the circuit level a new approach for error modeling including the duration of re ection and crosstalk errors, is described. The presented algorithm takes the high in uence of error durations as well as gate and transmission line delays on the testability into account.	algorithm;combinational logic;crosstalk;transmission line	Jürgen Schrage	1997		10.1109/ASPDAC.1997.600273	electronic engineering;real-time computing;telecommunications;computer science;electrical engineering;transmission line;combinational logic;algorithm	EDA	22.77600416489611	51.49600911804831	155609
797449f3d00d18188f0cae3e686364c23b9f059f	design method and test structure to characterize and repair tsv defect induced signal degradation in 3d system	signal degradation;tsv defect;integrated circuit testing;test methodology;recovery structure;three-dimensional integrated circuits;recovery circuit;test/recovery structure;signal fidelity;stand alone simulations;signal recovery circuit;induced signal degradation;through silicon vias;3d system;proposed structure;full-chip physical design;integrated circuit design;3d integrated circuit;design methodology;moderate signal degradation;test structure;physical design;design method;degradation;finite state machine;chip;resistance	In this paper we present a test structure and design methodology for testing, characterization, and self-repair of TSVs in 3D ICs. The proposed structure can detect the signal degradation through TSVs due to resistive shorts and variations in TSV. For TSVs with moderate signal degradations, the proposed structure reconfigures itself as signal recovery circuit to improve signal fidelity. The paper presents the design of the test/recovery structure, the test methodologies, and demonstrates its effectiveness through stand alone simulations as well as in a full-chip physical design of a 3D IC.	detection theory;elegant degradation;physical design (electronics);simulation;software bug;three-dimensional integrated circuit;through-silicon via	Minki Cho;Chang Liu;Daehyun Kim;Sung Kyu Lim;Saibal Mukhopadhyay	2010	2010 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)		embedded system;electronic engineering;design methods;telecommunications;computer science;engineering;electrical engineering;finite-state machine	EDA	24.359848827993137	53.002020409853685	155658
b31f73352f4f7ef3d5c6cd13f1f0826276b2259a	diagnosis framework for locating failed segments of path delay faults	segment delays;search space;very large scale integration;vlsi circuit optimisation delays fault diagnosis integrated circuit testing linear programming;faulty segments;fault diagnosis circuit faults timing failure analysis delay effects circuit synthesis very large scale integration circuit testing linear programming clocks;delay effects;longest path;linear constraint;linear constraints;vlsi circuit;circuit path delays;integrated circuit testing;linear programming;vlsi;diagnosis tools;linear program;path delay fault;faulty segments path delay faults diagnosis tools vlsi circuit circuit path delays linear constraints linear programming segment delays;path delay faults;circuit optimisation;delays;circuit optimization;fault diagnosis;delay bound	Diagnosis tools can be used to speed up the process for finding the root causes of functional or performance problems in a VLSI circuit. In this paper, we proposed a method to locate possible segments that cause extra delays on circuit paths. We use the delay bounds of the tested paths to build linear constraints. By guiding the solutions of the above linear constraints with a linear programming solver, we can identify segments with extra delays. Also, with the ranks of segment delays, we can prioritize the search for possible locations of failed segments. In the diagnosis framework, we also propose to reduce the search space by identifying indistinguishable segments. Essentially, we cannot separate segments in the same category no matter which segments have faults. This approach greatly increases the efficiency of the diagnosis process. In the experimental results, for most cases of injecting 10% of the longest paths delays, the probabilities are over 90% for locating faulty segments within the list of top-ten candidates, and the average rankings are among the top 5 suspect locations	approximation;fault model;iteration;linear programming;longest path problem;software bug;solver;static timing analysis;very-large-scale integration	Ying-Yen Chen;Min-Pin Kuo;Jing-Jia Liou	2005	IEEE International Conference on Test, 2005.	10.1109/TEST.2005.1583997	electronic engineering;real-time computing;linear programming;mathematics;distributed computing;very-large-scale integration	EDA	18.624908857453306	51.4191391582698	155842
d12c59ab2145bf095a95aab065b73a498ac45c85	teaching asynchronous design in digital integrated circuits	null convention logic;electronic engineering education teaching digital integrated circuits integrated circuit design asynchronous circuits educational courses hardware description languages;design flow;hardware description languages;speed independent;vhdl digital integrated circuits teaching asynchronous digital circuit design electrical engineering curriculum null convention logic threshold gates logic gates full adder very high speed integration circuit hardware description language simulation;integrated circuit design;digital integrated circuits;educational courses;electronic engineering education;asynchronous circuits;electrical engineering;digital circuits;hardware description language;logic gate;digital integrated circuits integrated circuit design asynchronous logic circuits hardware design languages electronics engineering education;high speed integrated circuits;teaching;design methodology	To introduce the basis of asynchronous digital circuit design in an electrical engineering curriculum, Null Convention Logic is presented as an innovative asynchronous paradigm. The design flow from concept to circuit implementation is discussed. First, two completeness criteria are required for speed independency: symbolic completeness of expression and completeness of input. Second, threshold gates with hysteresis are primary components, which are used to build logic gates, full adder, and registers. As an example, a 4 /spl times/ 4 multiplier is constructed based on these threshold gates. Finally, an example of very-high-speed integration circuit hardware description language (VHDL) simulation is given to help students practice and understand the asynchronous design methodology.	adder (electronics);asynchronous circuit;design flow (eda);digital electronics;electrical engineering;hardware description language;hysteresis;integrated circuit design;logic gate;np-completeness;nested context language;programming paradigm;simulation;vhdl	Jiann S. Yuan;Weidong Kuang	2004	IEEE Transactions on Education	10.1109/TE.2004.825923	education;electronic engineering;asynchronous circuit;computer science;engineering;electrical engineering;theoretical computer science;hardware description language;register-transfer level;computer engineering	EDA	19.602567941227708	46.76566943643595	156178
d57bcf4668ee1729c4af0ab2f9f814c91d385990	a functional bist approach for fir digital filters	stuck at fault coverage;circuit faults;automatic test pattern generation;finite impulse response filter;fir digital filter;fir digital filters;digital filter;impulse testing;built in self test;test pattern generators;registers;built in self test finite impulse response filter digital filters circuit testing circuit faults impulse testing registers test pattern generators automatic test pattern generation robots;digital filters;robots;fault coverage;fault location built in self test digital filters;functional bist approach;circuit testing;functional level;predetermined patterns;filter implementation;stuck at fault coverage functional bist approach fir digital filters functional level predetermined patterns filter implementation;fault location	Presents a functional level built-in self-test of digital filters. This BIST technique is based on predetermined patterns which are not dependent on the filter implementation. Many examples show that stuck-at fault coverage is about 98%.<<ETX>>	built-in self-test;digital filter;fault coverage;finite impulse response;stuck-at fault	C. Counil;Gaston Cambon	1992	Digest of Papers. 1992 IEEE VLSI Test Symposium	10.1109/VTEST.1992.232730	embedded system;electronic engineering;real-time computing;digital filter;computer science;engineering;electrical engineering	EDA	24.20170895642407	51.55295816713596	156259
56bbd65478035237e29763eec5423a2cd20f6f84	maintaining proximity to functional operation conditions under enhanced-scan tests based on functional broadside tests	semiconductor device testing;circuit faults;clocks;functional broadside tests;reachable states;proximity functional operation conditions enhanced scan tests functional broadside tests two pattern test functional clock cycles scan in states high transition fault coverage;transition faults;enhanced scan;circuit faults vectors switches delay clocks fault tolerance fault tolerant systems;vectors;fault tolerant systems;fault tolerance;switches;transition faults enhanced scan functional broadside tests reachable states	In a circuit with enhanced-scan, any two-pattern test can be applied to detect delay faults. However, the tests may deviate substantially from functional operation conditions, and result in overtesting. Functional broadside tests create functional operation conditions during their functional clock cycles by using reachable states as scan-in states. To maintain a proximity to functional operation conditions under enhanced-scan, the procedure described in this paper generates enhanced-scan tests that differ from functional broadside tests only in small numbers of values. Experimental results show that it is possible to achieve high transition fault coverage under this constraint.	clock signal;fault coverage	Irith Pomeranz	2012	2012 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)	10.1109/DFT.2012.6378230	reliability engineering;fault tolerance;electronic engineering;real-time computing;network switch;computer science;engineering;control theory	Embedded	21.442164376441625	51.34003417300177	157043
5079a64f2ca0a0fd12d37d67fa308086f0acd116	proptest: a property based test pattern generator for sequential circuits using test compaction	circuit testing test pattern generators sequential circuits sequential analysis compaction circuit faults circuit simulation logic testing permission computational modeling;low computational complexity proptest property based test pattern generator sequential circuits test compaction static compaction test sequences high fault coverages;image processing;test compaction;circuit faults;test sequences;automatic test pattern generation;sequential circuits;low computational complexity;sequential analysis;fpga;high fault coverages;circuit simulation;reconfigurable architecture;static compaction;integrated circuit testing sequential circuits logic testing automatic test pattern generation computational complexity circuit analysis computing integrated logic circuits;computational modeling;test pattern generators;permission;compaction;computational complexity;logic testing;integrated circuit testing;test generation;fault coverage;circuit testing;test pattern generator;integrated logic circuits;property based test pattern generator;circuit analysis computing;proptest	We describe a property based test generation procedure that uses static compaction to generate test sequences that achieve high fault coverages at a low computational complexity. A class of test compaction procedures are proposed and used in the property based test generator. Experimental results indicate that these compaction procedures can be used to implement the proposed test generator to achieve high fault coverage with relatively smaller run times.	computational complexity theory;data compaction;fault coverage	Ruifeng Guo;Sudhakar M. Reddy;Irith Pomeranz	1999		10.1145/309847.310019	compaction;electronic engineering;real-time computing;fault coverage;image processing;computer science;automatic test pattern generation;sequential analysis;test compression;sequential logic;computational complexity theory;computational model;algorithm;field-programmable gate array	EDA	20.178508513533686	49.69804030683454	157287
0d18a2cc167f9d3395a4d8f4d560c000608fefc3	qbf-based boolean function bi-decomposition	boolean satisfiability;computed decomposition;qbf-based bi-decomposition;quantified boolean formulas;earlier work;qbf-based boolean function;clear improvement;two-input simple logic gate;boolean function bi-decomposition;logic synthesis;cost function;computer model;data structures;benchmark testing;boolean functions;logic gate;integrated circuit;logic gates;measurement;boolean function;stochastic analysis;binary decision diagram;logic design;real time systems;computational modeling;computability;data structure	Boolean function bi-decomposition is ubiquitous in logic synthesis. It entails the decomposition of a Boolean function using two-input simple logic gates. Existing solutions for bi-decomposition are often based on BDDs and, more recently, on Boolean Satisfiability. In addition, the partition of the input set of variables is either assumed, or heuristic solutions are considered for finding good partitions. In contrast to earlier work, this paper proposes the use of Quantified Boolean Formulas (QBF) for computing bi-decompositions. These bi-decompositions are optimal in terms of the achieved quality of the input set of variables. Experimental results, obtained on representative benchmarks, demonstrate clear improvements in the quality of computed decompositions, but also the practical feasibility of QBF-based bi-decomposition.	boolean satisfiability problem;heuristic;logic gate;logic synthesis;true quantified boolean formula	Huan Chen;Mikolás Janota;Joao Marques-Silva	2012	2012 Design, Automation & Test in Europe Conference & Exhibition (DATE)		boolean algebra;boolean circuit;and-inverter graph;circuit minimization for boolean functions;discrete mathematics;reed–muller expansion;logic synthesis;boolean network;data structure;boolean expression;logic gate;product term;standard boolean model;computer science;maximum satisfiability problem;theoretical computer science;karp–lipton theorem;mathematics;boolean function;algorithm;parity function	EDA	17.82054841990754	47.81251110787406	157608
4cf3dbdd2b19061b5e424cdabc08aa1987670342	a memory grouping method for sharing memory bist logic	microprocessor;shared memory;semiconductor memories;integrated memory circuits;diagonal routing;self testing;logic testing built in self test integrated circuit testing integrated memory circuits;memory bist logic;built in self test;logic testing;built in self test memory grouping method memory bist logic memory bist wrapper;integrated circuit testing;manhattan routing;memory bist wrapper;memory grouping method;logic circuit testing;built in self test circuit testing frequency logic testing signal generators information science sequential analysis memory management scheduling time factors	With the increasing demand for SoCs to include rich functionality, SoCs are being designed with hundreds of small memories with different sizes and frequencies. If memory BIST logics were individually added to these various memories, the area overhead would be very high. To reduce the overhead, memory BIST logic must therefore be shared. This paper proposes a memory-grouping method for memory BIST logic sharing. A memory-grouping problem is formulated and an algorithm to solve the problem is proposed. Experimental results showed that the proposed method reduced the area of the memory BIST wrapper by up to 40.55%. The results also showed that the ability to select from two types of connection methods produced a greater reduction in area than using a single connection method.	algorithm;built-in self-test;overhead (computing);system on a chip	Masahide Miyazaki;Tomokazu Yoneda;Hideo Fujiwara	2006	Asia and South Pacific Conference on Design Automation, 2006.	10.1145/1118299.1118457	shared memory;interleaved memory;electronic engineering;parallel computing;real-time computing;computer science;operating system;memory map	EDA	19.470510267440297	52.469370833366064	158035
086693c6df5be55896628fc5bbcae94a1c1d1993	choosing the right mix of at-speed structural test patterns: comparisons in pattern volume reduction and fault detection efficiency	design tool;fault simulation;pattern generation;texas instruments;n detect coverage metrics delay fault test delay fault simulation test optimizations;structural testing;delay fault test;fault detection;path delay fault;testing fault detection delay automatic test pattern generation test pattern generators instruments built in self test pattern analysis qualifications clocks;n detect coverage metrics;fault model;delay fault simulation;test optimizations	The generation, qualification and validation of structural patterns for transition and path delay faults present several problems due to various design, tools and tester constraints. This paper proposes a flow for the generation and selection of a reduced set of structural patterns for at-speed testing, based on pattern reuse across different fault models, and based on metrics of minimum single detect and a qualified N-detect coverage. Patterns generated using ATPG and deterministic BIST techniques are considered for large representative SOC designs. It is shown that significant reduction of up to 35% in the pattern volume is achieved without compromising the test quality. These pattern selection techniques are being deployed in different designs in Texas Instruments (India).	bridging (networking);built-in self-test;experiment;fault coverage;fault detection and isolation;fault model;mathematical optimization;non-deterministic turing machine;pattern language;simulation;slack variable;structural pattern;stuck-at fault;system on a chip;test automation;test card	Sameer Goel;Rubin A. Parekhji	2005	14th Asian Test Symposium (ATS'05)	10.1109/ATS.2005.36	reliability engineering;electronic engineering;real-time computing;fault coverage;fault indicator;computer science;engineering;stuck-at fault;automatic test pattern generation;test compression;fault model;fault detection and isolation	EDA	21.417727798048134	52.53677284322685	158625
30d179d4af9b2ba36aa9d72e4e57e46b3d554794	rebisr: a reconfigurable built-in self-repair scheme for random access memories in socs	reconfigurable built in self repair scheme;random access memories;yield improvement built in redundancy analysis bira built in self repair bisr built in self test bist march test random access memory ram;random access memory;ram;built in self repair bisr;march 14n test;built in self test bist;redundancy analysis;contracts;yield improvement;testing;built in redundancy analysis bira;march 14n test rebisr reconfigurable built in self repair scheme random access memories soc reconfigurable built in redundancy analysis circuit rebira circuit ram adaptively reconfigurable fusing methodology;circuit analysis;setup time;built in self test;march test;adaptively reconfigurable fusing methodology;redundancy;system on chip built in self test integrated circuit reliability integrated circuit testing random access storage;random access memory read write memory testing redundancy algorithm design and analysis costs built in self test contracts circuit analysis performance analysis;system on chip;performance analysis;random access memory ram;integrated circuit testing;random access storage;normal modes;soc;read write memory;integrated circuit reliability;reconfigurable built in redundancy analysis circuit;rebira circuit;built in self repair;algorithm design and analysis;rebisr	Built-in self-repair (BISR) technique has been widely used to repair embedded random access memories (RAMs). This paper presents a reconfigurable BISR (ReBISR) scheme for repairing RAMs with different sizes and redundancy organizations. An efficient redundancy analysis algorithm is proposed to allocate redundancies of defective RAMs. In the ReBISR, a reconfigurable built-in redundancy analysis (ReBIRA) circuit is designed to perform the redundancy algorithm for various RAMs. Also, an adaptively reconfigurable fusing methodology is proposed to reduce the repair setup time when the RAMs are operated in normal mode. Experimental results show that the ReBISR scheme can achieve high repair rate (i.e., the ratio of the number of repaired RAMs to the number of defective RAMs). The area cost of the ReBISR is very small, which is only about 2.7% for four RAMs (one 4 Kbit RAM, one 16 Kbit RAM, one 128 Kbit RAM, and one 512 Kbit RAM). Moreover, the time overhead of redundancy analysis is very small. For example, the ratio of the redundancy analysis time to the test time for a 512 Kbit RAM tested by a March-14 test with solid data backgrounds is only about 0.25%. On the other hand, the proposed fusing scheme can achieve about 86.94% reduction of repair setup time in comparison with a typical fusing scheme for 20 512 × 16 × 64-bit RAMs of which each RAM has one spare row and one spare column.	64-bit computing;brute-force search;canonical account;embedded system;flip-flop (electronics);kilobit;normal mode;overhead (computing);random access;random-access memory;search algorithm;simulation;system on a chip	Tsu-Wei Tseng;Jin-Fu Li;Chih-Chiang Hsu	2010	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2009.2017906	system on a chip;embedded system;electronic engineering;parallel computing;real-time computing;computer science	EDA	19.793851942011507	52.67673309348036	158688
d360c1dc0584c8f62fcc311952a772d58751a736	activ-locstep: a test generation procedure based on logic simulation and fault activation	sequential circuits;synchronizing sequences;fault activation;automatic test software;test sequence length test generation procedure activ locstep logic simulation fault activation synchronous sequential circuits test sequences randomized search fault oriented test generation fault free circuit faulty circuit;synchronous sequential circuits;logic testing;test generation;circuit analysis computing;logic cad;logic testing circuit testing circuit faults circuit simulation electrical fault detection fault detection sequential circuits computational modeling sequential analysis synchronous generators;random search;simulation based test generation;automatic test software circuit analysis computing logic cad logic testing sequential circuits	We present a test generation procedure for synchronous sequential circuits referred to as ACTIV-LOCSTEP. Like its predecessor LOCSTEP, ACTN-LOCSTEP generates test sequences at low computational costs by using randomized search and avoiding fault oriented test generation. However, ACTIV-LOCSTEP is fundamentally different from LOCSTEP, being based on the following observation. Consider an input sequence C that consists of a transient C/sub 1/, followed by a periodic part C/sub 2/ that takes the fault free circuit through a cycle of states. Suppose that a fault f is activated during the cycle. If the same input sequence does not create a cycle in the faulty circuit, or creates a cycle of a different length than the one traversed by the fault free circuit, then f is likely to be detected after several repetitions of C/sub 2/ In the resulting procedure, the test sequence length is controlled by restricting the length of the input sequence C and the number of repetitions of the periodic part. Our experiments indicate that relatively short sequences and small numbers of repetitions of the periodic part of the sequence allow large numbers of faults to be detected.	experiment;interactive whiteboard;logic simulation;randomized algorithm	Irith Pomeranz;Sudhakar M. Reddy	1997	Proceedings of IEEE 27th International Symposium on Fault Tolerant Computing	10.1109/FTCS.1997.614087	electronic engineering;real-time computing;logic optimization;fault coverage;asynchronous circuit;computer science;stuck-at fault;automatic test pattern generation;sequential logic;synchronous circuit;algorithm	EDA	21.409515535565287	50.61253500174832	159212
0c7bc55e9bc249ed10f967b61d4f79b8c549d7d2	identification of unsettable flip-flops for partial scan and faster atpg	unsettable flip-flops identification;partial scan;sequential circuit;faster atpg;state justification;hip-hops;iscas89 circuits;iscas89 circuit;state element;unsettable flip-flop;state elements;early backtracks;sequential circuits test generation;deterministic test generation;transformed circuits;logic testing;test generation;state space;atpg;difficult-to-set hip-hops;sequential circuit test generation;sequential circuits	State justification is a time-consuming operation in test generation for sequential circuits. In this paper, we present a technique to rapidly identify state elements (hip-hops) that are either difficult to set or unsettable. This is achieved by performing test generation on certain transformed circuits to identify state elements that are not settable to specific logic values. Two applications that benefit from this identification are sequential circuit test generation and partial scan design. The knowledge of the state space is shown to be useful in creating early backtracks in deterministic test generation. Partial scan selection is also shown to benefit from the knowledge of the difficult-to-set hip-hops. Experiments on the ISCAS89 circuits are presented to show the reduction in time for test generation and the improvements in the testability of the resulting partial scan circuits.	backtracking;flops;flip-flop (electronics);sequential logic;software testability;state space	Ismed Hartanto;Vamsi Boppana;W. Kent Fuchs	1996	Proceedings of International Conference on Computer Aided Design	10.1145/244522.244533	electronic engineering;scan chain;real-time computing;computer science;state space;engineering;automatic test pattern generation;test compression;sequential logic;algorithm	EDA	21.357632907280088	50.64394069033274	160153
e2d9e220b71201905c9a44d17b715f7b0d3219dc	novel transient fault hardened static latch	error correction codes;circuit faults;positive feedback;logic;inverters;latches circuit faults feedback aerospace electronics error correction codes space technology logic radiation hardening transient analysis inverters;transient analysis;feedback;aerospace electronics;transient fault;space technology;latches;power delay product;radiation hardening;qa76 computer software	In this paper we analyze the effects of transient faults (TFs) affecting the internal nodes of conventional latch structures and we propose a new latch design which allows to tolerate such faults. In particular, we show that standard latches using back-to-back inverters for their positive feedback are very susceptible to glitches on their internal nodes. We propose a new latch that is hardened with respect to transient faults on the internal nodes and that provides lower power-delay product than classical implementations and alternate hardened solutions, while featuring a comparable or lower area overhead.	flip-flop (electronics);glitch;inverter (logic gate);overhead (computing);positive feedback;power–delay product;radiation hardening;sampling (signal processing);soft error;tree (data structure)	Martin Omaña;Daniele Rossi;Cecilia Metra	2003		10.1109/TEST.2003.1271074	electronic engineering;real-time computing;positive feedback;radiation hardening;computer science;engineering;electrical engineering;feedback;space technology;logic	EDA	20.82929894024117	53.05519439425964	161331
857d76154a92812192c56b5e7ebccbbad67044ba	reverse engineering of asynchronous boolean networks	reverse engineering;boolean network		boolean network;reverse engineering	Cheng Zheng;Zhi Geng	2010			machine learning;artificial intelligence;boolean network;computer science;theoretical computer science;reverse engineering;boolean circuit;asynchronous communication;and-inverter graph	DB	19.49198758460566	46.92119030632445	162147
7663eb141d39260dafa9c4588f2a5aa40110b78c	on-line error detection and bist for the aes encryption algorithm with different s-box implementations	bist;electronic mail;concurrent computing;stuck at faults on line error detection bist aes encryption algorithm s box implementations concurrent checking parity modification pseudo random test input generator pseudo random cipher texts;circuit faults;s box implementations;automatic test pattern generation;random number generation;pseudo random test input generator;random testing;cryptography logic testing automatic test pattern generation random number generation built in self test error detection;aes encryption algorithm;concurrent checking;built in self test;parity modification;cryptography;stuck at faults;fault detection;fault tolerance;pseudo random cipher texts;logic testing;circuit testing;on line error detection;error detection;computer errors;built in self test cryptography circuit faults fault detection concrete concurrent computing circuit testing computer errors fault tolerance electronic mail;concrete	"""In this paper we experimentally investigate the efficiency of concurrent checking for the AES encryption algorithm (Rijndael) by parity modification according to K. Wu et al. (2004). Also we propose a simple BIST method. For BIST the implementation of the AES algorithm itself is used as well as a pseudo-random test input generator and a compactor of the test results. Thereby we utilized the property of the AES algorithm that arbitrarily given plain texts are encrypted by the successive rounds into """"pseudo-random"""" cipher texts which are the (test) inputs for the next round. The complete data path of the AES algorithm is simulated as a netlist of AND-, NAND-, OR-, NOR- and XOR-gates. All possible single stuck-at faults are injected and simulated. For a special implementation of the S-boxes all errors within the data path of the AES algorithm due to single stuck-at faults are immediately detected."""	algorithm;built-in self-test;cipher;combinational logic;encryption;error detection and correction;exclusive or;experiment;logic gate;netlist;online and offline;parity bit;precomputation;pseudorandomness;s-box	Vitalij Ocheretnij;G. Kouznetsov;Ramesh Karri;Michael Gössel	2005	11th IEEE International On-Line Testing Symposium	10.1109/IOLTS.2005.51	random testing;fault tolerance;parallel computing;real-time computing;concrete;concurrent computing;random number generation;computer science;cryptography;theoretical computer science;automatic test pattern generation;aes implementations;statistics	Logic	22.007178434833243	48.921720185109066	162319
371f2908b1f3d29571c5440834780dc8b1fbb7a7	$x$-canceling misr architectures for output response compaction with unknown values	design for testability;gaussian processes;integrated circuit testing	In this paper, an X-tolerant multiple-input signature register (MISR) compaction methodology that compacts output responses containing unknown X values is described. Each bit of the MISR signature is expressed as a linear combination in terms of Xs by symbolic simulation. Linearly dependent combinations of the signature bits are identified with Gaussian elimination and XORed to remove X values and yield deterministic values. Two X-canceling MISR architectures are proposed and analyzed with industrial designs. This paper also shows the correlation between the estimated result based on idealized modeling and the actual data for real circuits for error coverage, hardware overhead, and other metrics. Experimental results indicate that high error coverage can be achieved with X-canceling MISR configurations and it highly correlates with actual results.	data compaction;exclusive or;fault coverage;gaussian elimination;overhead (computing);symbolic simulation;unsharp masking	Joon-Sung Yang;Nur A. Touba	2012	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2012.2193579	electronic engineering;real-time computing;simulation;computer science;design for testing;gaussian process;mathematics;statistics	EDA	20.64484854534896	50.91993709462369	162402
9022043aa9cf60d11d9e11b0917cc9bd7a5488af	advanced synchronous scan test methodology for multi clock domain asics	test vectors;bist;multi clock design style;skew insensitive test programs;clock structures;logic testing boundary scan testing clocks application specific integrated circuits vlsi integrated circuit testing automatic test pattern generation;integrated circuit;standard library elements;clocks;very large scale integration;automatic test pattern generation;pattern generation;clock domain transitions;boundary scan testing;program generation;clocks circuit testing central processing unit system testing very large scale integration telecommunications automatic test pattern generation built in self test test pattern generators circuit simulation;circuit simulation;vlsi integrated circuits;structural testing;built in self test;test pattern generators;two phase clocking scheme;application specific integrated circuits;socs;logic testing;integrated circuit testing;vlsi;system testing;multi clock domain asics;circuit testing;structured test programs;two phase clocking scheme synchronous scan test methodology multi clock domain asics vlsi integrated circuits socs multi clock design style clock structures clock domain transitions structured test programs atpg bist test vectors skew insensitive test programs standard library elements;synchronous scan test methodology;central processing unit;telecommunications;atpg	"""6,3) INTEGRATED CIRCUITS LIKE COMPLEX !3)#S AND 3/#S OFTEN REQUIRE A MULTI CLOCK DESIGN STYLE FOR FUNCTIONAL AND OR PERFORMANCE REASONS %SPECIALLY IN TELECOM APPLICATIONS THERE ARE OFTEN MANY COMPLEX CLOCK STRUCTURES AND CLOCK DOMAIN TRANSITIONS NECESSARY 4HIS REQUIREMENT COMPLICATES THE GENERATION OF STRUCTURED TEST PROGRAMS 3CAN !40' """")34 WITH CURRENT KNOWN METHODS 2ESULTS ARE LOTS OF TEST VECTORS WHICH LEAD TO LONG #05 AND TESTER TIMES FOR PATTERN GENERATION SIMULATION AND TEST APPLICATION -UCH EFFORT IS NEEDED TO GENERATE SKEW INSENSITIVE TEST PROGRAMS AND VERIFY THEM 4HIS ARTICLE DESCRIBES A NEW APPROACH OF SCAN TEST IMPLEMENTATION AND GENERATION OF TEST PROGRAMS FOR MULTI CLOCK SYSTEMS """"Y ADDITION OF A SMALL AND SIMPLE TEST CIRCUIT WITH STANDARD LIBRARY ELEMENTS A ALMOST PUSH BUTTON SOLUTION IS NOW POSSIBLE %FFORT FOR TEST PROGRAM GENERATION #05 AND TESTER TIME IS REDUCED SIGNIFICANTLY """"Y USE OF A SIMPLE TIMESET SKEW PROBLEMS ARE ELIMINATED SINCE THE CIRCUIT IS FULLY SYNCHRONOUSLY TESTED BY A TWO PHASE CLOCKING SCHEME"""	application-specific integrated circuit;small;synchronization (computer science)	Josef Schmid;Joachim Knäblein	1999		10.1109/VTEST.1999.766653	embedded system;computer architecture;electronic engineering;real-time computing;clock skew;computer science;engineering;electrical engineering;automatic test pattern generation;operating system;test compression;timing failure;very-large-scale integration;digital clock manager;cpu multiplier	EDA	18.276686064763634	50.68017843961936	163408
a242546dc8717682fc74434e1c4c24520a0dd2ba	derivation of optimal test set for detection of multiple missing-gate faults in reversible circuits	multiple missing gate fault detection;circuit faults;logic gates circuit faults integrated circuit modeling arrays semiconductor device modeling quantum computing testing;quantum gates cmos logic circuits fault diagnosis logic testing;repeated gate fault;efficient algorithm;reversible circuits;universal test set missing gate faults quantum computing reversible logic testable design;cmos circuits;missing gate faults;testing;stuck at fault;quantum gates;single missing gate fault;arrays;quantum computation;partial missing gate fault;quantum gate;reversible logic;logic synthesis;logic gates;quantum k cnot gates;quantum computer;semiconductor device modeling;cmos logic circuits;integrated circuit modeling;logic testing;optimal test set;fault model;quantum computing;universal test set;fault diagnosis;quantum k cnot gates reversible circuits optimal test set multiple missing gate fault detection logic synthesis quantum computation stuck at fault cmos circuits single missing gate fault repeated gate fault partial missing gate fault;testable design	— Logic synthesis of reversible circuits has received considerable attention in the light of advances recently made in quantum computation. Implementation of a reversible circuit is envisaged by deploying several special types of quantum gates, such as k-CNOT. Although the classical stuck-at fault model is widely used for testing conventional CMOS circuits, new fault models, namely single missing-gate fault (SMGF), repeated-gate fault (RGF), partial missing-gate fault (PMGF), and multiple missing-gate fault (MMGF), have been found to be more suitable for modeling defects in quantum k-CNOT gates. This article presents an efficient algorithm to derive an optimal test set (OTS) for detection of multiple missing-gate faults in a reversible circuit implemented with k-CNOT gates. It is shown that the OTS is sufficient to detect all single missing-gate faults (SMGFs) and all detectable repeated gate faults (RGFs). Experimental results on some benchmark circuits are also reported.	algorithm;benchmark (computing);cmos;computation;controlled not gate;fault model;logic synthesis;quantum computing;quantum gate;reversible computing;stuck-at fault;test set	Dipak Kumar Kole;Hafizur Rahaman;Debesh Kumar Das;Bhargab B. Bhattacharya	2010	2010 19th IEEE Asian Test Symposium	10.1109/ATS.2010.15	electronic engineering;fault coverage;stuck-at fault;theoretical computer science;mathematics;quantum computer;algorithm;quantum gate	EDA	22.374091150515927	51.40863464905709	163982
cc2503bfb51f7a7829fed7f842493b68334752f0	fault bundling: reducing machine evaluation activity in hierarchical concurrent fault simulation	circuit faults circuit simulation circuit testing electrical fault detection fault detection performance evaluation acceleration sequential circuits;machine list organization fault bundling hierarchical concurrent fault simulation error data multilist traversal;machine list organization;performance evaluation;circuit faults;fault simulation;multiprocessing systems automatic testing digital simulation electronic engineering computing error analysis fault location;automatic testing;sequential circuits;acceleration;multilist traversal;error data;error analysis;circuit simulation;fault bundling;hierarchical concurrent fault simulation;fault detection;circuit testing;electronic engineering computing;multiprocessing systems;electrical fault detection;digital simulation;fault location	A method of bundling error data is proposed which should significantly reduce the amount of explicit functional evaluation required for hierarchical concurrent simulation. The bundling operation is carried out at run time, and so is different from but complementary to approaches such as WRAP[l], which compress unnecessary or uninteresting portions of circuit hierarchy. The technique is exact; it does not cause the simulation to become probabilistic. This work extends the concept of multi-list traversal (MLT). In short, a hierarchy is imposed on the conventional machine list which matches the design hierarchy of the circuit under simulation. The resulting improvement in machine list organization is expected to prevent multiple evaluations of behavioral primitives for collections of faults which present the same input value.	parameter (computer programming);run time (program lifecycle phase);simulation;tree traversal	William H. Nicholls;Mani Soma	1988		10.1109/TEST.1988.207838	acceleration;reliability engineering;embedded system;electronic engineering;parallel computing;real-time computing;computer science;engineering;operating system;sequential logic;fault detection and isolation	EDA	20.257784322872336	50.00667304309332	164208
2ef39272953b9879a58c647291d966a3f59fa969	exact computation of maximally dominating faults and its application to n-detection tests	boolean functions;automatic test pattern generation;binary decision diagrams;exact computation;logic testing;automatic test pattern generation fault diagnosis logic testing boolean functions binary decision diagrams;circuit faults circuit testing fault detection application software size control electrical fault detection data structures boolean functions linear approximation;atpg n detection test sets stuck at faults unmodeled defects maximally dominating faults exact set high quality test sets fault dominance formal techniques bdd based procedure exact computation;fault diagnosis	n-detection test sets for stuck-at faults have been shown to be useful in detecting unmodeled defects. It was also shown that a set of faults, called maximally dominating faults, can play an important role in controlling the increase in the size of an n-detection test set as n is increased. In an earlier work, a superset of the maximally dominating fault set was used. In this work, we propose a method to determine exact sets of maximally dominating faults. We also define a new type of n-detection test sets based on the exact set of maximally dominating faults. We present experimental results to demonstrate the usefulness of this exact set in producing high-quality n-detection test sets.	computation;edge dominating set;sensor;software bug;test set	Ilia Polian;Irith Pomeranz;Bernd Becker	2002		10.1109/ATS.2002.1181677	electronic engineering;discrete mathematics;fault coverage;computer science;theoretical computer science;automatic test pattern generation;mathematics;boolean function;algorithm	EDA	21.30239785148329	49.9510738035852	164486
c3a0e1b6a55ffe89046aef5b28ebb26f43e1339d	combining gas and symbolic methods for high quality tests of sequential circuits	single observation time test strategy;fault simulation;multiple observation time test strategy;sequential circuits;genetics;sequential circuit atpg;genetic algorithm;fault coverage;symbolic simulation;automatic test pattern generator	A symbolic fault simulator is integrated in a Genetic Algorithm (GA) environment to perform Automatic Test Pattern Generation (ATPG) for synchronous sequential circuits. In a two phase algorithm test length and fault coverage as well are optimized. Furthermore, not only the Single Observation Time Test Strategy is supported, but also test patterns with respect to the Multiple Observation Time Test Strategy are generated. However, there are circuits that are hard to test using random pattern sequences, even if these sequences are genetically optimized. Thus, deterministic aspects are included in the GA environment to improve fault coverage. Experiments demonstrate that both a priori time consuming strategies, the symbolic simulation approach and the GA, can be combined at reasonable costs: Tests with higher fault coverages and considerably shorter test sequences than previously presented approaches are obtained.		Martin Keim;Nicole Drechsler;Rolf Drechsler;Bernd Becker	2001	J. Electronic Testing	10.1023/A:1011193725824	real-time computing;genetic algorithm;fault coverage;computer science;engineering;stuck-at fault;theoretical computer science;automatic test pattern generation;test compression;sequential logic;algorithm	EDA	21.8054874174719	50.67396465376872	164556
2724428a5f023b0cec6f4367a265c810df6f1257	a novel algorithm to extract two-node bridges	microprocessors;circuit faults;fault simulation;efficient algorithm;fault modeling;data mining;statistical analysis;permission;integrated circuit modeling;integrated circuit testing;circuit testing;bridge circuits circuit faults data mining circuit testing integrated circuit modeling permission microprocessors integrated circuit testing statistical analysis algorithm design and analysis;hard faults;algorithm design and analysis;test vector generation;bridge circuits	Defect based testing is based on the premise that it is possible to extract high probability defects viz. bridges and opens using layout and defect data. We present a very efficient algorithm to extract two-node bridges from layout. Comparison results with a popular tool show that our algorithm is considerably faster and that it has higher capacity.	algorithm;software bug;viz: the computer game	Sujit T. Zachariah;Sreejit Chakravarty;Carl D. Roth	2000		10.1145/337292.337780	algorithm design;electronic engineering;real-time computing;computer science;algorithm;computer engineering	SE	22.0846603829133	52.33720975036995	164602
89a5625a3854a75cab25d92763352a398b7a53cf	an efficient methodology for generating optimal and uniform march tests	built in self test integrated circuit testing integrated memory circuits production testing integrated circuit manufacture fault diagnosis;fault combinations;decoding;integrated memory circuits;memory manufacture;automatic testing;uniform march tests;sufficient conditions;automatic generation;built in self test;compact representation;necessary and sufficient condition;fault detection;manufacturing;integrated circuit testing;memory ics;fault detection automatic testing sufficient conditions built in self test manufacturing read write memory decoding;fault coverage;read write memory;production testing;bist architecture;ic testing uniform march tests fault coverages optimal tests bist architecture fault combinations memory manufacture memory ics;optimal tests;integrated circuit manufacture;ic testing;fault diagnosis;fault coverages	A large number of march tests that provide different fault coverages have been published and a few methodologies have been presented for automatically generating march tests. This paper presents a new methodology for generating optimal and uniform march tests. The new methodology uses a compact representation of faults, generates necessary and sufficient conditions for their detection, and generates tests using the conditions along with the properties of march tests. The methodology is demonstrated as being more efficient than those previously presented. It has been used to (a) generate new optimal tests that are uniform, which are desired to simplify BIST architecture, (b) prove the optimally of some well-known tests such as March C-, and (c) generate a complete set of optimal march tests for different combinations of faults. The proposed approach hence provides memory manufacturers with an optimal test to cover the types of faults that are likely to occur in their memories.		Sultan M. Al-Harbi;Sandeep K. Gupta	2001		10.1109/VTS.2001.923444	reliability engineering;embedded system;electronic engineering;real-time computing;fault coverage;computer science;engineering;manufacturing;fault detection and isolation	AI	21.155916889483986	51.561987076420664	164628
6f377bdfc7b30ed714002b4372cfad95b1c7e602	diagnosis and correction of multiple logic design errors in digital circuits	digital circuit;debugging;concepcion asistida;triple design errors;computer aided design;integrated circuit;etude theorique;logic design;boolean functions;very large scale integration;correction erreur;logic design error correction digital circuits boolean functions very large scale integration circuit synthesis process design timing debugging circuit testing;circuito integrado;indexing terms;experimental result;process design;circuit numerique;multiple logic design errors;integrated circuit design;gate level netlist;triple design errors multiple logic design errors digital circuits gate level netlist error diagnosis error correction error search correction algorithm double design errors;digital integrated circuits;error correction;logic testing;circuito numerico;estudio teorico;error diagnosis;resultado experimental;vlsi;conception assistee;circuit testing;error search correction algorithm;design error;integrated logic circuits;correccion error;theoretical study;digital circuits;resultat experimental;diagnosis;logic cad;integrated circuit design logic design error correction fault diagnosis logic testing logic cad vlsi integrated logic circuits digital integrated circuits;circuit synthesis;circuit integre;diagnostico error;double design errors;diagnostic erreur;fault diagnosis;error diagnostic;timing	This paper presents a technique to correct multiple logic design errors in a gate-level netlist. A number of methods have been proposed for correcting single logic design errors. However, the extension of these methods to more than one error is still very limited. We direct our attention to circuits with a low multiplicity of errors. By assuming different error dependency scenarios, multiple errors are corrected by repeatedly applying a single error search and correction algorithm. Experimental results on correcting double-design errors and triple-design errors on ISCAS and MCNC benchmark circuits are included.	digital electronics;logic synthesis	Pi-Yu Chung;Ibrahim N. Hajj	1997	IEEE Trans. VLSI Syst.	10.1109/92.585227	electronic engineering;non-sampling error;computer science;electrical engineering;theoretical computer science;computer aided design;very-large-scale integration;digital electronics;algorithm	EDA	20.428856487335814	49.026437358258946	164685
dbd275be2b5dea531dc4942716f61170008fce0d	"""packaging technologies for the 500 mhz vlsi test system """"ultimate"""""""	automatic testing;packaging;chip;packaging very large scale integration system testing large scale integration timing accuracy costs electronics cooling space heating laboratories;vlsi automatic testing integrated circuit testing packaging;integrated circuit testing;vlsi;thermal conductivity;500 mhz automatic testing ic testing vlsi test system ultimate packaging signal quality heat removal cost water cooled frame thermal conduction elements;power consumption	The prototype VLSI test system ULTIMATE has a 1024-pin capability at 500-MHz test rate and a timing accuracy of +or-50 ps. A novel packaging method improves signal quality, heat removal, and cost. ULTIMATE's compact water cooled frame and thermal conduction elements enable 10001 W/L power consumption at a packing density of 270 chips/L. >	very-large-scale integration	Yoshimitsu Sakagawa;Yusio Akazawa;Naoaki Narumi;Akira Yoshii;Tsuneta Sudo	1988		10.1109/TEST.1988.207789	chip;embedded system;packaging and labeling;electronic engineering;telecommunications;computer science;engineering;electrical engineering;very-large-scale integration;thermal conductivity	EDA	23.67229341404393	53.18482417857128	164945
0ccf0cbff092d2f9aa254119ee7b1033694c0b99	analysis of digital circuits through symbolic reduction	verification;digital circuit;modelizacion;metodo matematico;mathematical method;etude theorique;efficient algorithm;verification model extraction digital circuits symbolic reduction semi algorithmic method finite state models analog circuit level model behavior preserving omega automata homomorphic transformations;algorithme;circuit numerique;modelisation;algorithm;analog circuits;digital circuits circuit analysis computing;circuito numerico;estudio teorico;methode mathematique;circuit analysis digital circuits circuit simulation switching circuits circuit testing predictive models switches automatic testing automata helium;verificacion;theoretical study;digital circuits;circuit analysis computing;modeling;algoritmo	The authors describe a semi-algorithmic method to extract finite-state models from an analog circuit-level model by means of homomorphic (behavior preserving) transformations. Properties to be verified are defined by omega -automata. Efficient algorithms for testing language containment of automata can then be applied to verify properties of the finite-state models. Proof of the property in the finite-state model guarantees the property in the analog circuit-level model over a continuous range of input waveforms and circuit parameters. While in practice this method applies directly only to smaller circuit components, it can be used to analyze larger circuits as well by deriving a hierarchy of increasingly abstract models, through repeated applications of homomorphic transformations. Examples of extraction, homomorphism, and verification are described. >	digital electronics	Robert P. Kurshan;Kenneth L. McMillan	1991	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.97615	electronic engineering;computer science;engineering;electrical engineering;theoretical computer science;mathematics;digital electronics;algorithm	EDA	20.41659497809368	46.914119484295796	165378
67e49af005074e90565d67422323b731801d762e	built-in self-test for ghz embedded srams using flexible pattern generator and new repair algorithm	emitter coupled logic;automatic test pattern generation;pattern generation;embedded systems;finite state machines;built in self test;redundancy;cmos memory circuits;ecl cmos srams ghz embedded srams bist scheme flexible pattern generator repair algorithm on macro two dimensional redundancy analyzer fault detection performance degradation microcode based pattern generator fsm based on macro redundancy analyzer;integrated circuit testing;embedded systems sram chips cmos memory circuits emitter coupled logic integrated circuit testing built in self test redundancy automatic test pattern generation fault diagnosis finite state machines;built in self test random access memory circuit testing circuit faults redundancy hardware pattern analysis test pattern generators degradation automata;finite state machine;fault diagnosis;sram chips	This paper presents a built-in self-test (BIST) scheme, which consists of a flexible pattern generator and a practical on-macro two-dimensional redundancy analyzer, for GHz embedded SRAMs. In order to meet the system requirements and to detect a wide variety of faults or performance degradation resulting from recent technology advances, the microcode-based pattern generator can generate flexible patterns. A practical new repair algorithm for the Finite State Machine (FSM)-based onmacro redundancy analyzer is also presented. It can be implemented with simple hardware and can show fairly good performance compared with conventional software-based algorithms.	algorithm;built-in self-test;elegant degradation;embedded system;finite-state machine;microcode;requirement;static random-access memory;system requirements;triple modular redundancy	Shigeru Nakahara;Keiichi Higeta;Masaki Kohno;Toshiaki Kawamura;Keizo Kakitani	1999		10.1109/TEST.1999.805644	reliability engineering;embedded system;electronic engineering;parallel computing;real-time computing;computer science;automatic test pattern generation;operating system;finite-state machine;redundancy;algorithm;emitter-coupled logic	EDA	19.879080251816898	51.932306407094416	165758
41c4311cc638846961e542912087647d40da5dfe	machine learning and structural characteristics for reverse engineering		In the past years, much of the research into hardware reverse engineering has focused on the abstraction of gate level netlists to a human readable form. However, none of the proposed methods consider a realistic reverse engineering scenario, where the netlist is physically extracted from a chip. This paper analyzes how errors caused by this extraction and the later partitioning of the netlist affect the ability to identify the functionality. Current formal verification based methods, which compare against a golden model, are incapable of dealing with such erroneous netlists. Two new methods are proposed, which focus on the idea that structural similarity implies functional similarity. The first approach uses fuzzy structural similarity matching to compare the structural characteristics of an unknown design against designs in a golden model library using machine learning. The second approach proposes a method for inexact graph matching using fuzzy graph isomorphisms, based on the functionalities of gates used within the design. For realistic error percentages, both approaches are able to match more than 90% of designs correctly. This is an important first step for hardware reverse engineering methods beyond formal verification based equivalence matching.		Johanna Baehr;Alessandro Bernardini;Georg Sigl;Ulf Schlichtmann	2019		10.1145/3287624.3288740	matching (graph theory);equivalence (measure theory);image processing;netlist;fuzzy logic;reverse engineering;formal verification;computer science;machine learning;circuit extraction;artificial intelligence	EDA	19.40914789015735	48.72341632346369	165903
f8c03c2bb835cc24d685c50ad4f86fe40c7e922e	mfbist: a bist method for random pattern resistant circuits	design for testability;design tool;integrated circuit layout;automatic testing;pattern generation;built in self test;cmos logic circuits;logic testing;integrated circuit testing;hardware overhead evaluation mfbist design tool test per clock bist technique random pattern resistant circuits multiple idler register segments selective bit fixing multiple biased pseudorandom pattern generators 100 fault coverage detectable single stuck at faults bist architecture automatic cmos layouts;circuit layout cad;fault coverage;logic partitioning;logic cad;integrated circuit testing built in self test logic testing automatic testing design for testability logic partitioning logic cad circuit layout cad integrated circuit layout cmos logic circuits;built in self test benchmark testing circuit testing clocks circuit faults hardware registers test pattern generators electrical fault detection fault detection	Thzs paper presents a test per clock B I S T technzque that uses multzple adler regaster segments wath selectzve bat-fixzng drzven by multaple bzased pseudorandom pattern generators to provade 100% fault coverage of detectable sangle stuck-at faults The technzque as partacularly effectzve for random pattern reszstant carcuzts A BIb'T archatectuw that supports this technzque, and a desagn tool (h4FBIST)thal implements the techiique are presented. The amount of hardware overhead 25 contiolled by user-speczfied parameters and can meet t'arying deszgn speczficataoiis Results and comparzsons wzth przor technaques are presented for combznataonal benchmarks and combinational versaons of sequentzal benchmark czrcuzts To better E Z aluate hardwore overhead. autonzatac C'.kfOS layouts were performed f o r the benchmark czrcuats. The results show that thc addataonal area overhead, relatzve to that requzred by pseudorandom test per clock deszgns. zs small	benchmark (computing);built-in self-test;combinational logic;fault coverage;overhead (computing);pseudorandomness	Mohammed F. AlShaibi;Charles R. Kime	1996		10.1109/TEST.1996.556960	reliability engineering;computer architecture;electronic engineering;real-time computing;fault coverage;engineering;electrical engineering;design for testing;integrated circuit layout	EDA	20.614114942710764	51.43425197454388	166054
45dc0467533ccf62a34b18f7925233698d674b31	a probabilistic method to determine the minimum leakage vector for combinational designs	probability combinational circuits computability leakage currents logic design;probability;combinational logic circuits;logic design;probabilistic method;computability;combinational designs;probabilistic heuristic;np hard problem;sat solver combinational designs leakage power consumption np hard problem signal probabilities minimum leakage vector probabilistic heuristic;leakage power;leakage currents;leakage power consumption;threshold voltage energy consumption very large scale integration intrusion detection equations power supplies spice switching circuits mos devices np hard problem;minimum leakage vector;signal probabilities;sat solver;modes of operation;combinational circuits	"""""""Parking"""" a circuit in a minimum leakage state during its standby mode of operation is one of the techniques of reducing leakage power consumption in a circuit. However, the problem of finding this minimum leakage state is NP-hard. In this paper, we present a heuristic approach to determine the input vector which minimizes leakage for a combinational design. Our approach utilizes approximate signal probabilities of internal nodes to aid in finding the minimum leakage vector. We use a probabilistic heuristic to select the next gate to be processed, as well as to select the best state of the selected gate. A fast SAT solver is employed to ensure the consistency of the assignments that are made in this process. Experimental results indicate that our method has very low run-times, with excellent accuracy, compared to existing approaches"""	approximation algorithm;block cipher mode of operation;boolean satisfiability problem;combinational logic;heuristic;np-hardness;sleep mode;solver;spectral leakage	Kanupriya Gulati;Nikhil Jayakumar;Sunil P. Khatri	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1693066	electronic engineering;logic synthesis;computer science;probabilistic method;theoretical computer science;probability;np-hard;mathematics;computability;combinational logic;boolean satisfiability problem;algorithm	EDA	18.238500994594382	50.36693113896745	166124
79f3e1c1fc994aea71693545053690dcf78ac196	essential hazard correction without the use of delay elements	speed of asynchronous switching circuits;asynchronous switching circuits;logic element;essential hazard correction;minimal delay realizations;asynchronous switching circuits essential hazard correction minimal delay realizations without delay elements speed of asynchronous switching circuits;without delay elements	A method of essential hazard correction avoiding the insertion of delay elements into the feedback branches of an asynchronous switching circuit was suggested in a recent paper by Armstrong, Friedman, and Menon [4]. This method is always easily applicable when the line stray delays can be neglected, but the resulting circuit often contains branches with more than two levels of logical elements.	armstrong's axioms;jaishankar menon;nat friedman;switching circuit theory	Jan Hlavicka	1970	IEEE Transactions on Computers	10.1109/T-C.1970.222902	real-time computing;computer science;control theory	EDA	22.614714432427466	46.8507382449467	166577
5a3c79ca3f1320161ca8eb3f7402ba43ca078005	high-quality transition fault atpg for small delay defects	algebraic test generation;boolean algebraic test generation;circuit faults;automatic test pattern generation;delay effects;testing;boolean algebra;compact quality tests;delay faults;test pattern generators;algebra;multivalued algebra;propagation delay;critical path;fault detection;logic testing;manufacturing;automatic test pattern generation atpg;test generation;generating function;circuit testing;multivalued logic;automatic test pattern generator;small delay defects;electrical fault detection;delays;high quality transition fault atpg	A new framework is proposed to generate compact quality tests to detect small delay defects by activating and propagating transition faults only along implicitly kept sensitizable critical paths. It is shown how to implicitly generate functions to derive tests for the proposed framework. The novelty of the method relies on a multivalued algebra that is used to generate the test functions with a single circuit traversal, independent of the number of critical paths. Experimental results demonstrate the effectiveness of the method.	distribution (mathematics);fault coverage;portable document format;test card;test set	Mahilchi Milir Vaseekar Kumar;Spyros Tragoudas	2007	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/TCAD.2006.884863	boolean algebra;propagation delay;generating function;electronic engineering;discrete mathematics;computer science;automatic test pattern generation;critical path method;mathematics;software testing;manufacturing;fault detection and isolation;algorithm	EDA	21.80908830483759	50.79059817765398	167273
8627b0c38030bfda7fe7b3adcfedffe63ef704f5	extended bdd's: trading off canonicity for structure in verification algorithms	combinational multipliers logic circuits verification binary decision diagrams semicanonical representation;multiplying circuits combinatorial circuits data structures logic testing;multiplying circuits;combinatorial circuits;data structures;logic testing;data structures boolean functions binary decision diagrams formal verification combinational circuits logic circuits design automation circuit synthesis size control reluctance generators;binary decision diagram	The authors present an extension to binary decision diagrams (BDDs) that exploits the information contained in the structure of the circuit to produce a compact, semicanonical representation. The extended BDDs (XBDDs) retain many of the advantages of BDDs while at the same time allowing one to deal with larger circuits. Using XBDDs, it is possible to verify circuits for which the BDDs could not be built in the same amount of space. Results of the application of XBDDs to combinational multipliers are presented. >	algorithm	Seh-Woong Jeong;Bernard Plessier;Gary D. Hachtel;Fabio Somenzi	1991		10.1109/ICCAD.1991.185305	boolean circuit;discrete mathematics;data structure;computer science;theoretical computer science;mathematics;programming language;binary decision diagram;digital electronics;algorithm	Logic	18.598500007760226	46.654013331041824	167509
8a6e33e8448e5f9b3b80d38bb32c4a4d83b71410	non stuck fault testing of cmos vlsi.				John J. Zasio	1985			very-large-scale integration;electronic engineering;computer science;cmos	EDA	22.919700281043983	51.91813908223805	167523
665f64959659cafd8f44b192a564c6951ce31840	on-line testing of switched-capacitor filters	design for testability;on line testing;switched capacitor filters;analog circuits;concurrent test switched capacitor filters area overhead replication programmable biquad control logic information redundancy;redundancy;switched capacitor filters active filters design for testability redundancy;circuit testing system testing redundancy analog circuits band pass filters communication switching control systems programmable control flexible printed circuits signal processing;active filters;switched capacitor	Proposes a new solution to alleviate the area overhead when replication is used in switched-capacitor filters. This new approach, although based on the voter mechanism, only requires a programmable biquad and some control logic as extra components (instead of the full duplication of the system). To some extent, it can be considered a first intent to apply information redundancy for the concurrent test of analog circuits.<<ETX>>	overhead (computing);redundancy (information theory);switched capacitor	José Luis Huertas;Diego Fernández Vazquez;Adoración Rueda	1992	Digest of Papers. 1992 IEEE VLSI Test Symposium	10.1109/VTEST.1992.232732	control engineering;electronic engineering;real-time computing;switched capacitor;analogue electronics;engineering;electrical engineering;design for testing;redundancy;active filter	Embedded	24.49454990236795	50.933271100854725	168462
277938cabcec8846cf8b7811f3744175fc6e8a2c	compact: a hybrid method for compressing test data	gzip compact hybrid method test data compression overall throughput automatic test equipment download time burrows wheeler transformation test patterns run length coding;data compression;test data compression;automatic testing;automatic test equipment;compression test;hybrid method;test data compression throughput automatic test equipment automatic testing arithmetic dictionaries laboratories data compression test pattern generators workstations;application specific integrated circuits;integrated circuit testing automatic testing data compression runlength codes application specific integrated circuits;runlength codes;integrated circuit testing;compression ratio;burrows wheeler transform	The overall throughput of automatic test equipment (ATE) is sensitive to the download time of test data. An effective approach to the reduction of the download time is to compress test data before the download. The authors introduced a test data compression method which outperforms other methods for compressing test data [8]. Our previous method is based on the Burrows-Wheeler transformation on the sequence of test patterns and runlength coding. In this paper, we present a new method, called COMPACT, which further improves our previous method. The key idea of COMPACT is to employ two data compression schemes, run-length coding for data with low activity and GZIP for data with high activity. COMPACT increases the compression ratio of test data, on average, by 1.9 times compared with our previous method.	built-in test equipment;burrows–wheeler transform;data compression;download;netbsd gzip / freebsd gzip;run-length encoding;test card;test data;throughput	Masahiro Ishida;Dong Sam Ha;Takahiro J. Yamaguchi	1998		10.1109/VTEST.1998.670850	data compression;embedded system;automatic test equipment;data compression ratio;electronic engineering;computer hardware;computer science;theoretical computer science;automatic test pattern generation;operating system;burrows–wheeler transform;test compression;compression ratio;lossless compression;application-specific integrated circuit;statistics	SE	19.65953561012155	52.30496546882216	168560
f4e2407ac96b07e04aaca647432067d9fed931ca	effective scan chain failure analysis method		In order to improve the testability of a digital design, most internal flip-flops are changed into scan cells that are connected together to build shift registers called scan chains. Scan chain failures remain the most challenging sources of difficulty in fault localization. This is complementary to fault localization of products with working scan chains, in which the fault diagnosis tools are delivering quite satisfying results. However, if the scan chain itself is broken, either the entire chain or a larger segment out of the chain is reported as a fail. Only in some best case scenario can the diagnosis identify the failing flip flop. This is evenmore challenging if the scan chain and related ATPG structures operate only in compressed mode. In any case, even if a defect is found in scan chain diagnosis, the tools would report only the failing flip flop and do not provide any additional information for fault localization. Here we review the various diagnosis methods applied specifically to the broken scan chain and show additional physical fault isolation methods when the result of such diagnosis is not sufficient.	best, worst and average case;flops;failure analysis;failure cause;fault detection and isolation;flip-flop (electronics);logic synthesis;markov chain;physical information;reliability engineering;shift register;simulation;software bug;test card	Etienne Auvray;Paul Armagnat;Luc Saury;Maheshwaran Jothi;Michael Brügel	2017	Microelectronics Reliability	10.1016/j.microrel.2017.07.024	engineering;reliability engineering;scan chain	EDA	21.700054050405125	52.395817955805164	169146
3c710d98450e7bea4ea972952ff2e412150d6a59	a c-testable 4-2 adder tree for an easily testable high-speed multiplier	multiplier;design for testability	A C-testable 4-2 adder tree for an easily testable high-speed multiplier is proposed, and a recursive method for test generation is shown. By using the specific patterns that we call ‘alternately inverted patterns, ’ the adder tree, as well as partial product generators, can be tested with 14 patterns regardless of its operand size under the cell fault model. The test patterns are easily fed through the partial product generators. The hardware overhead of the 4-2 adder tree with partial product generators for a 64-bit multiplier is about 15%. By using a previously proposed easily testable adder as the final adder, we can obtain an easily testable high-speed multiplier.	adder (electronics)	Nobutaka Kito;Kensuke Hanai;Naofumi Takagi	2010	IEICE Transactions		arithmetic;discrete mathematics;serial binary adder;design for testing;mathematics;multiplier;carry-save adder;adder	DB	21.437138973306713	48.1197539666026	169169
6e45091c6f7e5c64e82cddaab2a79ae029b2ced9	probabilistic bug localization via statistical inference based on partially observed data	probabilistic bug localization root causing circuit bugs high speed i o link circuit circuit parameter posterior distribution probabilistic graphical models nonlinear subcircuit model circuit blocks circuit failure partially observed data statistical inference;statistical analysis mixed analogue digital integrated circuits network synthesis;integrated circuit modeling graphical models probabilistic logic controllability decision feedback equalizers mathematical model bayes methods;inclusion method;dc analysis;transistor circuits simulation;nonlinear equations	Upon the observation of a circuit failure, problematic circuit blocks and parameters need to be localized before they can be fixed or bypassed -- this has traditionally been highly manual and problem-specific. In this paper, we present a bug localization methodology that automatically identifies and ranks potential root-causes probabilistically. We model linear and nonlinear sub-circuits using the corresponding probabilistic graphical models, and formulate the bug localization problem as a statistical inference problem given partially observed data. We infer the posterior distribution of underlying circuit parameters, which provides a statistical measure of whether the bug lies in each sub-circuit. We have verified this methodology on a high-speed I/O link circuit, and have demonstrated its effectiveness of root-causing circuit bugs.	algorithm;graphical model;input/output;mixed-signal integrated circuit;nonlinear system;software bug;spec#	Sangho Youn;Chenjie Gu;Jaeha Kim	2014	2014 51st ACM/EDAC/IEEE Design Automation Conference (DAC)	10.1145/2593069.2593190	electronic engineering;nonlinear system;computer science;theoretical computer science;machine learning;statistics	EDA	22.665665589303625	50.79412407198768	170416
7e9aa37a3cc25eb77a7d77b01efe98b18436e411	low-power weighted pseudo-random bist using special scan cells	switching activity;random testing;built in self test;low power;normal modes;fault coverage;weighted pseudo random testing	In this paper, a technique for weighted pseudo-random built-in self-test (BIST) of VLSI circuits is proposed, which uses special scan cells and a new weight selection algorithm to achieve low power dissipation. It is based on weighted pseudo-random scan testing in which only 3 weight values are used - 2 fixed values (0 or 1) and 1 random value (0.5). A new weight selection algorithm is used to select a set of weights that achieves high fault coverage while reducing power. The idea is to minimize power by careful selection of the set of scan cells having fixed values (0 or 1) in order to reduce switching activity. To implement this in hardware, a new scan cell design is proposed that can do scan and capture in the normal mode as well as fixed-bit mode. The new scan cell hardware increases the area of a typical circuit by less than 4%, but reduces power by as much as 96%, as indicated in experiments performed on benchmark circuits.	benchmark (computing);built-in self-test;experiment;fault coverage;normal mode;pseudorandomness;selection algorithm;very-large-scale integration	Shalini Ghosh;Eric MacDonald;Sugato Basu;Nur A. Touba	2004		10.1145/988952.988974	random testing;electronic engineering;scan chain;real-time computing;fault coverage;normal mode;mathematics;algorithm	EDA	20.302060612515003	52.539220289621355	170982
97f6d95fe96c8f74cce88ee8b44d86163d5185c7	analog ic design automation. i. automated circuit generation: new concepts and methods	analog simulation;generation;automatic;concepcion asistida;topology;computer aided design;optimisation;synthese circuit;concepcion circuito;design automation;biomedical measurements;implantation topometrie;optimizacion;integrated circuit;etude theorique;switching circuits;validacion;generacion;circuit design;simulacion numerica;circuito analogico;automatisation;circuito integrado;correction;automatico;layout;automatizacion;circuit topology;network analysis;circuit corrector;production process;extraccion;network topology mos analogue integrated circuits integrated circuit design circuit cad circuit optimisation;corrections;network topology;isaid design system;analog circuits;integrated circuit design;circuit adjustments;analog circuit;hierarchical generation;application specific integrated circuits;signal processing;analog integrated circuits;mos analogue integrated circuits;simulation numerique;mos transistors;estudio teorico;processus fabrication;analog ic design;conception assistee;automatique;correccion;automated circuit generation;sintesis circuito;system development;schema bloc;validation;function block diagram;optimization;conception circuit;circuit cad;qualitative reasoning;theoretical study;analog integrated circuits design automation signal processing digital circuits radiation detector circuits application specific integrated circuits topology biomedical measurements switching circuits analog circuits;digital circuits;circuit optimisation;simulacion analogica;analyse circuit;topological modifications analog ic design design automation automated circuit generation integrated circuit design isaid design system circuit corrector hierarchical generation mos transistors circuit topology qualitative reasoning circuit adjustments transistor size adjustments;radiation detector circuits;transistor size adjustments;extraction;topological modifications;circuit analogique;circuit synthesis;analisis circuito;circuit integre;proceso fabricacion;simulation analogique	The research presented in this paper is concerned with the automation of analog integrated circuit design and, in particular, with a description of methods and techniques employed by the ISAID design system developed at Imperial College, UK. ISAID is comprised of two modules: the circuit generator and the circuit corrector. The circuit generator is based on newly developed methods that are used to handle hierarchical generation of topologies and size MOS transistors so that the performance of designed circuits compare satisfactorily with their specifications. To avoid long design times, simulation is used only after the generation of an initial circuit topology. Simulated performances may therefore be found to differ from the required. One novel feature of the proposed methodology is that in such cases a circuit corrector is invoked to correct the initial design. The circuit corrector is essentially a novel application of qualitative reasoning, which, without iterative simulation analyses performance trade-offs, thereby selects circuit adjustments-transistor size adjustments or topological modifications-that would improve the problematic performances. Several design examples have demonstrated the benefits of the ISAID design approach. >	electronic design automation;integrated circuit design	Christofer Toumazou;Costas A. Makris	1995	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.370422	equivalent circuit;mixed-signal integrated circuit;iterative design;physical design;embedded system;electronic engineering;analogue electronics;computer science;engineering;electrical engineering;computer aided design;circuit design;signal processing;integrated circuit development;design layout record;circuit extraction;engineering drawing;integrated circuit design	EDA	17.880202172912956	50.463315700321985	171152
f831e9b36e8f4c754e8f08c99308545a7e420f5a	a scan cell architecture for inter-clock at-speed delay testing	microprocessors;design for testability;test pattern generation;circuit faults;logic design;clocks;delay fault;clocks computer architecture microprocessors circuit faults delay logic gates testing;automatic test pattern generation;testing;scan cell architecture;phase locked loops;chip;computer architecture;interclock logic;phase locked loops automatic test pattern generation clocks delays integrated circuit testing;at speed testing;inter clock logic design for testability dft scan cell architecture delay testing at speed testing;logic gates;delay testing;design for testability dft;global routing;delay fault scan cell architecture interclock at speed delay testing high speed semiconductor chip interclock logic atpg tools test pattern generation internal pll clocks;high speed semiconductor chip;integrated circuit testing;interclock at speed delay testing;test pattern generator;internal pll clocks;atpg tools;high speed;delays;industrial design;inter clock logic	At-speed delay testing is inevitable for improving the test quality of modern high-speed semiconductor chips. This paper presents a scan cell architecture for at-speed testing of delay faults in inter-clock logic. The technique utilizes commercially available ATPG tools for test pattern generation and internal PLL clocks for test pattern application. The hardware modification is contained within the scan cells and no additional global routing is required. Simulation results using three industrial designs demonstrate that the technique is effective in detecting delay faults in inter-clock logic.	12-hour clock;business logic;cell (microprocessor);clock signal;fault coverage;phase-locked loop;routing;semiconductor;sensor;simulation;software testing;test card	Kyoung Youn Cho;Rajagopalan Srinivasan	2011	29th VLSI Test Symposium	10.1109/VTS.2011.5783723	chip;embedded system;electronic engineering;scan chain;logic synthesis;real-time computing;phase-locked loop;industrial design;logic gate;telecommunications;computer science;engineering;automatic test pattern generation;test compression;design for testing;software testing	EDA	21.271741219743912	52.60620369138449	171814
b3a65e85a9c2e3f950dab6085c44032ffd2d3dc0	concurrently self-checking structures for fsms	concurrently self-checking structure	Abstract Design of concurrently self-checking Finite-State Machines is taken into account, with the aim of obtaining a fault coverage as high as possible (within a given fault model) while keeping the modified structure reasonably simple. A code-based approach is presented, suitable for unidirectional faults. It is seen that simple restrictions to synthesis of the combinatorial network (in the case of random logic) allow to consider such a fault model as acceptable, while there are no constraints if PLAs are used. In particular, a solution based on a modified Berger code is discussed, and results obtained for a set of benchmark FSMs are considered. A simplified structure is further introduced.		Mariagiovanna Sami;Donatella Sciuto;Renato Stefanelli	1993	Microprocessing and Microprogramming	10.1016/0165-6074(93)90096-4	theoretical computer science;algorithm	Crypto	21.663870001426478	47.55596524426698	171958
fabda43c1beaab79d21bdf95dd6cffd4d68f91b7	cont: a concurrent test generation system	verification;metodologia;integrated circuit;combinatorial circuits;systeme cont;automatic testing;system testing test pattern generators circuit faults circuit testing fault detection combinational circuits electrical fault detection very large scale integration large scale integration design for testability;generateur essai;circuito integrado;methodologie;logic testing automatic testing circuit analysis computing combinatorial circuits integrated circuit testing;logic testing;integrated circuit testing;test generation;test pattern generator;single target fault combinational logic circuits logic ic testing cont concurrent test generation system tgm s test generation mode concurrency fault lists backtrack;verificacion;methodology;circuit analysis computing;circuit integre	Ahsrrucr-In thir paper we propose a new te\t pattern generation sjsteni. called CONT (CONcurrent Test generation) \?stem. l h r CONT system consists of two modes for test generation, l ( ; h l C (CONI' algorithm) and ' lG\ l -S. The T(;hI-C generate\ fault lists concurrentl> in the proce\s of test generation in order to speed up test generation. I n the process of test generation of the T<;hl-C', the priniar) input value is not changed hut a target fault is switched to another one using the fault list when hacktrack occurs. The 'lG3l-S generate\ a test pattern without changing a target fault. Experimental results show that the CON'I s> stem i \ an efficient te\t generation s! stem.	algorithm;parameter (computer programming);test card	Yuzo Takamatsu;Kozo Kinoshita	1989	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.35548	embedded system;electronic engineering;real-time computing;verification;computer science;engineering;electrical engineering;automatic test pattern generation;integrated circuit;methodology;algorithm	EDA	20.707991348376698	49.5931565055342	172192
93f098ac9c25a554c3b6e7e13883cd30df9c18f1	a design verification methodology based on concurrent simulation and clock suppression	clock suppression;concurrent simulation;design verification;simulation slowdown;simultaneous simulation;cases concurrently;serial simulation;design verification methodology;concurrent case simulation;large clock fanouts;large network;algorithms;complexity;design automation;accuracy;statistical mechanics;thermal equilibrium;design methodology;visualization	This Paper outlines a methodology for design verification of very large networks based on Concurrent Simulation and Clock Suppression. Concurrent Simulation is expected to yield a 30:1 to 600:1 speed advantage over conventional (serial) simulation when roughly 5,000 “good machines” are simulated concurrently. This speed advantage increases with the number of concurrent machines.   Clock Suppression is an auxiliary technique to avoid simulation slowdowns if very large networks with very large clock fanouts must be simulated.   The methodology proposed here for design verification is “Concurrent Case Simulation”, i.e., the simultaneous simulation of distinct sets of input patterns. Advantages of this method are (1) speed, (2) the fundamental ability to simulate cases concurrently, (3) to observe differences between cases in a more economic, simpler, and more natural style than with serial simulation, (4) to run many more cases than would be possible with serial simulation, (5) and the fact that running cases against each other establishes a powerful design verification philosophy.	simulation;zero suppression	Ernst G. Ulrich	1983	20th Design Automation Conference Proceedings		embedded system;electronic engineering;complexity;real-time computing;simulation;visualization;design methods;electronic design automation;statistical mechanics;computer science;thermal equilibrium;theoretical computer science;accuracy and precision;algorithm	EDA	17.84804355797305	53.12858541169029	172427
d208e5c16c52e29b6b794cd63ca4eafc43992e2a	the production of completion signals by asynchronous, iterative networks	logic arrays;clocks;delay effects;wires;iterative methods;production circuits wires iterative methods logic arrays clocks monitoring delay effects propagation delay adders;monitoring;adders;propagation delay;production;circuits;delay time;large classes	In a synchronous circuit an operation is complete puts and outputs, each cell has a set of wxires connected when a given number of clock times have elapsed since it was begun. to the outside world. The states on these wires will be In an asynchronous network no such indication is available, and we must either rely on the network to inform us of completion, or wait called the primary input and output states of the cell. for the worst-case delay. The second method is undesirable because Finally, the lateral inputs and outputs incident upon the nornally the network will complete its operation long before the boundaries of the array are available for communicaworst-case delay time has elasped. It will be shown here that, for tion with the outside world, and will be known as bounda large class of iterative circuits, the network can be designed to ary states. (These definitions are illustrated for the oneinform us of completion. Moreover, this can be done without recourse dimensional case in Fig. 1.) to monitoring all lateral states (to see when none are changing).	best, worst and average case;input/output;iterative method;lateral thinking;synchronous circuit	William M. Waite	1964	IEEE Trans. Electronic Computers	10.1109/PGEC.1964.263775	propagation delay;electronic circuit;electronic engineering;real-time computing;delay calculation;computer science;engineering;processing delay;electrical engineering;elmore delay;iterative method;network delay;algorithm;adder;queuing delay	EDA	23.384058567581278	46.908860825158726	172753
021428f59dfe726969ca5868d1d37530e700ee6a	automatic import of custom designs into a cell-based environment using switch-level analysis and circuit simulation		Digital MOS transistor designs are imported into an environment of cell-based tools by division of the design into gate-level components followed by the automatic generation of their logical and timing views. Symbolic switch-level analysis divides the design into channel-connected components and provides estimates of their logical behavior. Then, electrical simulation verifies or corrects the logical model and yields a tiw”ng view.	connected component (graph theory);electronic circuit simulation;transistor	Ronald B. Stewart;Véronique Anjubault;Philippe Garcin;Jacques Benkoski	1992			electronic engineering;connected component;network analysis;engineering;electrical engineering;capacitance;microelectronics;computer engineering	EDA	18.041670064687587	49.181063775278574	172791
d3474602a1053c7e60c20da3b177b2cb451bc36c	efficient ubist implementation for microprocessor sequencing parts	bist;concurrent error detection;integrated circuit;microprocessor sequencing part;lfsr;signature analyser;totally self checking circuits;strongly code disjoint checkers;fault coverage;self checking circuits;ubist	In this paper we first present an improved self-checking solution for the sequencing part of the Motorola MC 68000 microprocessor. compared to previous self-checking proposals for this microprocessor, the present scheme decreases the area overhead and simplifies the complexity of both functional circuits and checkers. In addition, the unified BIST method introduced recently, is applied to this scheme. This method uses a merging of self-checking and BIST techniques and allows a high fault coverage for all tests needed for the integrated circuits, e.g. off-line test for fabrication faults and for maintenance, and on-line concurrent error detection in the field.	microprocessor	Michael Nicolaidis	1995	J. Electronic Testing	10.1007/BF00996438	reliability engineering;embedded system;electronic engineering;parallel computing;real-time computing;fault coverage;computer science;engineering;integrated circuit;linear feedback shift register	Logic	20.901545386350175	51.745126559899575	172819
329357e4a9935514bb397fcd6e48fc03ddac922c	a parallel generation system of compact iddq test sets for large combinational circuits	power supplies;parallel generation system;circuit faults;iterative improvement based method;automatic test pattern generation;cmos circuits;cmos circuits large combinational circuits parallel generation system compact iddq test sets compact iddq test generation system bringing fault detection iterative improvement based method two level parallel processing technique test generation speed up deterministic atpg fault efficiency;fault efficiency;test generation speed up;electric current measurement;iterative methods;compact iddq test sets;cmos logic circuits;compact iddq test generation system;fault detection;two level parallel processing technique;logic testing;integrated circuit testing;system testing;test generation;iterative methods combinational circuits logic testing parallel processing cmos logic circuits integrated circuit testing electric current measurement fault diagnosis automatic test pattern generation;circuit testing;circuit testing system testing combinational circuits circuit faults electrical fault detection automatic test pattern generation parallel processing power supplies logic testing fault detection;bringing fault detection;iddq testing;combinational circuit;compact test generation;high performance;parallel processing;large combinational circuits;electrical fault detection;fault diagnosis;deterministic atpg;combinational circuits;atpg	This paper presents a high performance compact IDDQ test generation system for detecting bridging faults, targeting large circuits. This system is based on the iterative-improvement-based method [5]. We use two-level parallel processing technique for speeding up the test generation significantly, and invoke the assist of a deterministic ATPG for attaining 100% fault efficiency. The experimental results demonstrate its effectiveness.	bridging (networking);combinational logic;computer;experiment;iddq testing;iterative method;parallel computing;prototype;sensor;test card;test set	Tsuyoshi Shinogi;Terumine Hayashi	1999		10.1109/ATS.1999.810746	parallel processing;electronic engineering;real-time computing;computer science;engineering;automatic test pattern generation;iddq testing;combinational logic;algorithm;computer engineering	EDA	20.261953817902132	49.82928700154916	172833
1653609840dd781fd45193e05caa7b0836f99c88	optimal evaluation clocking of self-resetting domino pipelines	cycle time;worst case time borrowing optimal evaluation clocking self resetting domino pipelines high performance clocking methodology clock rate circular pipeline ring cycle time worst case combinational logic delay race through problems;clocks;race through problems;logic;delay effects;ring cycle time;drives;optimal evaluation clocking;pipelines;explosives;worst case combinational logic delay;clock rate;robustness;circuits;circuit cad;latches;clocks pipelines latches logic delay effects circuits robustness timing drives explosives;circuit optimisation;circuit optimisation clocks pipeline processing combinational circuits delays logic cad circuit cad;logic cad;high performance;clock skew;self resetting domino pipelines;pipeline processing;delays;worst case time borrowing;combinational circuits;timing;high performance clocking methodology;circular pipeline	We describe a high performance clocking methodology for domino pipelines. Our technique maximizes the clock rate of the circular pipeline (“ring”) while maintaining the ring cycle time to be the worst-case combinational logic delay around the ring. It is relatively immune to global clock skew, incurs no latch overhead, allows up to 50% time borrowing, and offers a robust way of preventing race-through problems, adjusted for the worst-case time borrowing.	best, worst and average case;clock rate;clock skew;combinational logic;overhead (computing);pipeline (computing)	Kenneth Y. Yun;Ayoob E. Dooply	1999		10.1109/ASPDAC.1999.759728	electronic engineering;parallel computing;real-time computing;clock skew;computer science;engineering;clock rate;programming language;logic;robustness	EDA	17.44509571829068	52.37947735412869	172897
e726254c29deacfde8b64daa3f98c397868b69d1	a fast built-in redundancy analysis for memories with optimal repair rate using a line-based search tree	optimal solution;bist;redundancy analysis ra;random access memory;solution optimale;line based search tree;integrated circuit yield;semiconductor memory;built in self repair bisr;systems on a chip;cost function;systeme embarque;integrated circuit;almacenamiento informacion;bira;integrated memory circuits;estudio comparativo;autoprueba;built in self test bist;redundancy analysis;circuito integrado;autoreparation;yield improvement;testing;autotest;system on a chip;capacite stockage;capacidad memoria;algorithme;etude comparative;algorithm;embedded systems;search trees;information storage;capacite memoire;built in self test;yield improvement built in redundancy analysis line based search tree memory capacity systems on a chip soc embedded memories storage capacity built in self test bist bira;redundancy;memory capacity;sistema sobre pastilla;system on chip;matriz formadora;capacidad almacenaje;yield improvement built in self repair bisr built in self test bist redundancy analysis ra;autoreparacion;system on chip built in self test embedded systems integrated circuit yield integrated memory circuits redundancy;solucion optima;storage capacity;comparative study;semiconductor device manufacture;built in redundancy analysis;porcentaje perdida;die;embedded memories;stockage information;soc;redundancy built in self test testing random access memory system on a chip semiconductor device manufacture cost function hardware semiconductor memory product development;systeme sur puce;loss rate;matrice formage;built in self repair;circuit integre;hardware;algoritmo;taux perte;product development	With the growth of memory capacity and density, test cost and yield improvement are becoming more important. In the case of embedded memories for systems-on-a-chip (SOC), built-in redundancy analysis (BIRA) is widely used as a solution to solve quality and yield issues by replacing faulty cells with extra good cells. However, previous BIRA approaches focused mainly on embedded memories rather than commodity memories. Many BIRA approaches require extra hardware overhead to achieve the optimal repair rate, which means that 100% of solution detection is guaranteed for intrinsically repairable dies, or they suffer a loss of repair rate to minimize the hardware overhead. In order to achieve both low area overhead and optimal repair rate, a novel BIRA approach is proposed and it builds a line-based searching tree. The proposed BIRA minimizes the storage capacity requirements to store faulty address information by dropping all unnecessary faulty addresses for inherently repairable die. The proposed BIRA analyzes redundancies quickly and efficiently with optimal repair rate by using a selected fail count comparison algorithm. Experimental results show that the proposed BIRA achieves optimal repair rate, fast analysis speed, and nearly optimal repair solutions with a relatively small area overhead.	algorithm;canonical account;die (integrated circuit);embedded system;overhead (computing);requirement;search tree;system on a chip;traffic collision avoidance system	Woosik Jeong;Ilkwon Kang;Kyowon Jin;Sungho Kang	2009	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2008.2005988	system on a chip;embedded system;electronic engineering;real-time computing;computer science;engineering;operating system	EDA	19.179377067475567	52.78948764586141	173073
024661d11667dedfa5d94b898a0b6da717b9be35	closing the gap between analog and digital	signal generators;circuit faults;fault simulation;circuit faults circuit testing circuit simulation digital circuits automatic testing integrated circuit testing analog circuits benchmark testing permission signal generators;automatic testing;fault modeling;analog circuits;circuit simulation;permission;integrated circuit testing;circuit testing;digital circuits;fault model;hard faults;test vector generation;benchmark testing	This paper presents a highly effective method for parallel hard fault simulation and test specification development. The proposed method formulates the fault simulation problem as a problem of estimating the fault value based on the distance between the output parameter distribution of the fault-free and the faulty circuit. We demonstrate the effectiveness and practicality of our proposed method by showing results on different designs. This approach extended by parametric fault testing has been implemented as an automated tools set for IC testing.	closing (morphology);digital data;effective method;page fault;parameter (computer programming);semiconductor device fabrication;simulation	Khaled Saab;Naim Ben Hamida;Bozena Kaminska	2000		10.1145/337292.337775	embedded system;benchmark;electronic engineering;real-time computing;fault coverage;analogue electronics;computer science;electrical engineering;stuck-at fault;fault model;digital electronics;signal generator	EDA	22.362153365950775	52.33067778699461	173423
04a5f088816aa82823dbfc69ee12017cb1b7a07f	variation-aware fault grading	fault grading;circuit faults;fault simulation;statistical fault coverage variation aware fault grading iterative flow test set extreme parameter variation circuit coverage massively parallel statistical fault simulation gpgpu;automatic test pattern generation;gpgpu;process variations;logic gates;sat based;integrated circuit modeling;circuit faults delay logic gates integrated circuit modeling automatic test pattern generation robustness;robustness;gpgpu process variations fault grading monte carlo fault simulation sat based atpg;monte carlo;fault simulation fault location;fault location;atpg	An iterative flow to generate test sets providing high fault coverage under extreme parameter variations is presented. The generation is guided by the novel metric of circuit coverage, calculated by massively parallel statistical fault simulation on GPGPUs. Experiments show that the statistical fault coverage of the generated test sets exceeds by far that achieved by standard approaches.	algorithm;data compaction;experiment;fault coverage;general-purpose computing on graphics processing units;heuristic;iterative method;simulation;test set	Alexander Czutro;Michael E. Imhof;J. Jiang;Abdullah Mumtaz;Matthias Sauer;Bernd Becker;Ilia Polian;Hans-Joachim Wunderlich	2012	2012 IEEE 21st Asian Test Symposium	10.1109/ATS.2012.14	electronic engineering;parallel computing;real-time computing;fault coverage;computer science;engineering;stuck-at fault;theoretical computer science;automatic test pattern generation	EDA	21.321375370242638	52.79193548119097	173594
2fe87664c18980390f58423f92b50367d7e809bd	reducing test data volume using external/lbist hybrid test patterns	circuit testing logic testing built in self test circuit faults system testing costs logic design automatic testing manufacturing automatic test pattern generation;circuit faults;motorola powerpc microprocessor;logic design;logic built in self test;automatic test pattern generation;automatic testing;external tester;built in self test;hybrid test pattern;pseudorandom test data;stumps architecture;logic testing;manufacturing;automatic test pattern generation microprocessor chips logic testing built in self test;deterministic test data;system testing;fault coverage;circuit testing;microprocessor chips;industrial design;stumps architecture hybrid test pattern logic built in self test external tester fault coverage atpg pseudorandom test data deterministic test data motorola powerpc microprocessor;atpg	A common approach for large industrial designs is to use logic built-in self-test (LBIST) followed by test data from an external tester. Because the fault coverage with LBIST alone is not suficient, there is a need to top-up the fault coverage with additional deterministic test patterns from an external tester. This paper proposes a technique of combining LBIST and deterministic ATPG to form “hybrid test patterns ’’ which merge pseudo-random and deterministic test data. Experiments have been done on the Motorola PowerPCTM microprocessor core to study the proposed hybrid test patterns. Hybrid test patterns provide several advantages: I ) can be applied using STUMPS architecture [Bardell 821 with a minor modification, 2) significantly reduce external test data stored in tester memory, 3) reduce the number of pseudorandom pattems by orders of magnitude, thus addressing power issues.	data applied;fault coverage;logic built-in self-test;multi-core processor;powerpc;pseudorandomness;randomness;test card;test data	Debaleena Das;Nur A. Touba	2000		10.1109/TEST.2000.894198	computer architecture;electronic engineering;industrial design;engineering;automatic test pattern generation;computer engineering	EDA	20.543262578808726	52.17412601685824	174518
930d9656bb3fc1fe89e5ccb757a74c4cf9c2a98d	an easily testable optimal-time vlsi-multiplier	vlsi design;fault model	We consider the design of a ‘tree-multiplier’, which is a modified version of a Wallace tree-multiplier [16] made suitable for VLSI design by Luk and Vuillemin [12]. It is shown that 4 log(n) + 3 test patterns suffice to exhaustively test the multiplier with respect to the ‘cellular fault model’ (which includes tests for all single stuck at faults). Some slight modifications of the multiplier prove, that these tests can be applied without increasing the number of input ports substantially.	fault model;test card;very-large-scale integration;wallace tree	Bernd Becker	1987	Acta Informatica	10.1007/BF00292108	computer science;fault model;mathematics;very-large-scale integration;algorithm	EDA	21.448924487346694	47.94251980730649	174925
73efb80ad2bec79f9b2f9474842aac2095a8d804	low-cost modular totally self-checking checker design for m-out-of-n code	tolerancia falta;detection erreur;concepcion circuito;deteccion error;codigo prueba;on line testing;time complexity;totally self checking;circuit design;circuit faults fault detection adders hardware logic testing circuit testing automatic testing system testing electrical fault detection information services;digital arithmetic computational complexity vlsi adders fault tolerant computing logic testing;ripple carry adder;fault tolerant computing;computational complexity;adders;fault tolerance;logic testing;vlsi;arquitectura modular;digital arithmetic;checker circuit;conception circuit;totally self checking checker;error detection;code essai;modular architecture;modular structure low cost modular totally self checking checker design m out of n code adders ripple carry adders t variable two rail code checker tree time complexity vlsi;tolerance faute;test code;architecture modulaire;m out of n code	We present a low-cost (hardware-efficient) and fast totally self-checking (TSC) checker for m-out-of-n code, where m/spl ges/3, 2m+1/spl les/n/spl les/4m. The checker is composed of four special adders which sum the 1s in the primary inputs added by appropriate constants, two ripple carry adders which sum the outputs of the biased-adders, and a t-variable two-rail code checker tree which compares the outputs of the two ripple carry adders, where k=[log/sub 2/(n-m)+1]. All the modules are composed of 2-input gates and inverters. Compared with previous nonmodular methods, our TSC checker has a lower hardware and time complexity. Our method reduces the hardware complexity and circuit delay of the checker from O(n/sup 2/) to O(n) and from O(n) to O(log/sub 2/n), respectively. Compared with recent modular methods, our TSC checker has about the same hardware and time complexity, but is applicable to a much broader range of n. In summary, our method is superior to existing methods for the considered range of n. In addition, our TSC checker can easily be tested (the test set size of our TSC checker is relatively small) and implemented in VLSI for its modular structure.		Wen-Feng Chang;Cheng-Wen Wu	1999	IEEE Trans. Computers	10.1109/12.795123	embedded system;parallel computing;computer science;theoretical computer science;algorithm;adder	Embedded	21.713334464517892	48.218683001866474	175408
7c5690adb18a9ab80a628f83be734cae4653c375	layout-aware pseudo-functional testing for critical paths considering power supply noise effects	layout-aware pseudofunctional testing;integrated circuit testing;functionally-reachable test cube;power supply noise effect;power supply circuits;conventional structural test pattern;delay faults;true critical path;automatic test pattern generation;power supply noise effects;benchmark circuit;critical path;testing delay fault;novel layout-aware pseudo-functional testing;circuit under-testing;layout-aware pseudo-functional testing;functional constraint;integrated circuit layout;iscas'89 benchmark circuits;test cube;circuit layout information;structural test patterns;critical paths;circuit over-testing;generating function;optimization;network on chip;noise;functional testing;logic gates;system on chip;data mining	When testing delay faults on critical paths, conventional structural test patterns may be applied in functionally-unreachable states, leading to over-testing or under-testing of the circuits. In this paper, we propose novel layout-aware pseudo-functional testing techniques to tackle the above problem. Firstly, by taking the circuit layout information into account, functional constraints related to delay faults on critical paths are extracted. Then, we generate functionally-reachable test cubes for every true critical path in the circuit. Finally, we fill the don't-care bits in the test cubes to maximize power supply noises on critical paths under the consideration of functional constraints. The effectiveness of the proposed methodology is verified with large ISCAS'89 benchmark circuits.	benchmark (computing);circuit diagram;critical path method;don't-care term;functional testing;olap cube;power supply;test card;unreachable memory	Xiao Liu;Yubin Zhang;Feng Yuan;Qiang Xu	2010	2010 Design, Automation & Test in Europe Conference & Exhibition (DATE 2010)		system on a chip;embedded system;generating function;electronic engineering;real-time computing;logic gate;computer science;engineering;noise;automatic test pattern generation;critical path method;functional testing;integrated circuit layout;network on a chip	EDA	21.42101781229011	52.53089648693044	175805
ee0aa982dc4d6d75d00c0a3d40064c60d99d0c5a	test patterns of multiple sic vectors: theory and application in bist schemes	generators;silicon carbide;clocks;radiation detectors;built in self test bist;test pattern generator tpg;counting circuits built in self test;vectors radiation detectors clocks silicon carbide logic gates generators built in self test;counting circuits;built in self test;low power;vectors;logic gates;size 45 nm multiple sic vectors test pattern generator tpg built in self test bist scheme multiple single input change vectors scan chain reconfigurable johnson counter scalable sic counter minimum transition sequence class test per clock scheme test per scan scheme msic sequences low input transition density circuit under test iscas benchmarks scan design;single input change sic;test pattern generator tpg built in self test bist low power single input change sic	This paper proposes a novel test pattern generator (TPG) for built-in self-test. Our method generates multiple single-input change (MSIC) vectors in a pattern, i.e., each vector applied to a scan chain is an SIC vector. A reconfigurable Johnson counter and a scalable SIC counter are developed to generate a class of minimum transition sequences. The proposed TPG is flexible to both the test-per-clock and the test-per-scan schemes. A theory is also developed to represent and analyze the sequences and to extract a class of MSIC sequences. Analysis results show that the produced MSIC sequences have the favorable features of uniform distribution and low input transition density. The performances of the designed TPGs and the circuits under test with 45 nm are evaluated. Simulation results with ISCAS benchmarks demonstrate that MSIC can save test power and impose no more than 7.5% overhead for a scan design. It also achieves the target fault coverage without increasing the test length.	built-in self-test;fault coverage;low-power broadcasting;markov chain;mixed-signal integrated circuit;overhead (computing);performance;ring counter;scalability;simplified instructional computer;simulation;static random-access memory;test card	Feng Liang;Luwen Zhang;Shaochong Lei;Guohe Zhang;Kaile Gao;Bin Liang	2013	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2012.2195689	embedded system;electronic engineering;real-time computing;logic gate;mathematics;particle detector	EDA	20.597595003387806	51.54935971717955	175868
8e335a9b3cd80b45e806297908e02e03ef4f5cf7	synthesis method of finite state machines based on state minimization for low power design		A new method for the synthesis of finite state machines (FSMs) is proposed. In this method, such optimization criterion as the power consumption is taken into account already at the stage of minimizing internal states. In addition, the proposed method allows one to minimize the number of transitions and input variables of the FSM. The method is based on sequential merging of two internal states. For this purpose, the set of all pairs of states that can be merged is found, and the pair that best satisfies the optimization criteria is chosen for merging. The sequential algorithm is used for low power state encoding. Experimental results show, that the dissipated power is less by 7% comparing to traditional methods.	finite-state machine	Adam Klimowicz	2017		10.1007/978-3-319-59105-6_45	computer science;merge (version control);artificial intelligence;logic synthesis;machine learning;finite-state machine;minification;sequential algorithm;mathematical optimization	EDA	17.55106424662641	49.53616136363349	176439
2b235cfee1ce0cd745e9827d795a9beb2e03e7bc	direct methods for synthesis of self-monitoring state machines	automated synthesis;logic testing finite state machines logic design;convolutional codes;self monitoring state machines;logic design;clocks;macro cell cad system layout overhead self monitoring state machines synthesis methods state assignments checking invariants signature monitoring automated synthesis generalized monitor architecture finite state machine near zero error detection latency;state machine;condition monitoring computerized monitoring runtime shift registers contracts delay convolutional codes process control error correction clocks;contracts;runtime;layout overhead;checking invariants;computerized monitoring;finite state machines;state assignments;near zero error detection latency;condition monitoring;error correction;shift registers;signature monitoring;logic testing;process control;error detection;synthesis methods;finite state machine;direct method;macro cell cad system;generalized monitor architecture	The authors consider synthesis methods that yield state assignments with checking invariants amenable to signature monitoring. They describe an automated synthesis approach based on a novel, generalized monitor architecture and prove that, for any given finite-state machine (FSM), a special, methodology-consistent state assignment exists. The state assignment permits each state's reference signature to be extracted directly from the state code. This eliminates the need for explicit reference-signature storage and yields continuous monitoring with near zero error-detection latency at each state. A practical tool that implements these synthesis algorithms can, in 37 seconds, generate state assignments for all 41 MCNC synthesis benchmark FSMs. Layout overhead comparisons obtained with an FSM macro-cell CAD system show that this technique can require as little as 52.3% of traditional duplication's layout area. >	finite-state machine	Scott H. Robinson;John Paul Shen	1992		10.1109/FTCS.1992.243570	real-time computing;computer science;theoretical computer science;algorithm	EDA	20.903904525310487	47.884580192855495	176530
6662af0416603923f655e38b1739d1105c86e91f	dual-polarity logic as a design tool	plugs;design tool;logic design;boolean functions;switching circuits;logic circuits;protection;radio frequency;circuit testing;logic design circuit testing logic circuits switches admittance radio frequency boolean functions switching circuits plugs protection;admittance;switches		design tool	Paul M. Kintner	1959	IRE Trans. Electronic Computers	10.1109/TEC.1959.5219527	control engineering;boolean circuit;circuit minimization for boolean functions;electronic engineering;logic synthesis;logic optimization;diode–transistor logic;logic level;asynchronous circuit;logic gate;logic family;network switch;computer science;engineering;electrical engineering;programmable logic device;pass transistor logic;mathematics;sequential logic;diode logic;admittance;integrated injection logic;combinational logic;boolean function;digital electronics;radio frequency;register-transfer level;algorithm;resistor–transistor logic;emitter-coupled logic	EDA	19.630440903032973	46.79680572369737	176816
2d1c2deaf7c6e6b6ba4ded545c823a6691f48ed2	design for testability and built-in self-test for vlsi circuits	design for testability;built in self test	Abstract   The special characteristics of VLSI and VHSI (very high-speed integrated) circuits - their high speed of operation and their poor accessibility to external probing — have aggravated the problems of test-pattern generation and testing. As circuit technologies advance to higher speeds and larger scales of integration, new approaches will be required to test the high speed and very dense circuits which may contain both multiple ‘stuck’ type and non ‘stuck’ type faults. Hence, it might be necessary to consider testing approaches in a new light. This paper surveys built-in self-test approaches, which seem to be preferred over external testing and have a good potential for future testing requirements. Built-in self-test schemes implemented in microprocessor-based systems are highlighted.	built-in self-test;design for testing;software testability	Hideo Fujiwara	1986	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(86)90094-3	real-time computing;computer science;test compression;design for testing	EDA	22.666761585899174	52.70780626759804	176898
880962976b6c55ad75210d5339b616b8712dfcab	on the complete convergence of bordered nets	instruments;convergence;boolean functions;application software;logic;wire;adders;convergence circuits adders wire partial response channels application software logic instruments boolean functions;partial response channels;circuits;complete convergence	A procedure is described for minimizing the number of states in an asynchronous sequential function when the restriction exists that the input cannot change while the sequential function is in an unstable state. Furthermore, a procedure is described for minimizing the number of states in a sequential function when the restriction also exists that each output can change at most once during the time required for a transition from one stable state to another.		George C. Sethares	1967	IEEE Trans. Electronic Computers	10.1109/PGEC.1967.264618	electronic engineering;application software;discrete mathematics;convergence;computer science;electrical engineering;mathematics;logic;algorithm	EDA	22.728198962673893	46.81957718039732	177702
f6fe8f24382fd11f3066afb9a6311f0a02224d56	design of cmos checkers with improved testability of bridging and transistor stuck-on faults	testability;design technique;checker;bridging fault;self checking circuits;cmos	This work presents a design technique for CMOS static and dynamic checkers (to be used in self-checking circuits), that allows the detection of all internal single transistor stuck-on and bridging faults causing unacceptable degradations of the circuit dynamic performance (but not logical errors). Such a technique exploits simple voltage detector circuits to make sure that the intermediate faulty voltages inevitably produced by the faults of interest are always propagated at the checker output as logic errors. With the use of our technique, the main disadvantages of static checkers, so far preventing their use in practical applications, are overcome. The method has been applied to the particular case of two-rail (static as well as dynamic) checkers and its validity has been verified by means of electrical level simulations.	bridging (networking);cmos;simulation;transistor	Cecilia Metra;Michele Favalli;Piero Olivo;Bruno Riccò	1995	J. Electronic Testing	10.1007/BF00993127	testability;embedded system;electronic engineering;real-time computing;computer science;cmos	EDA	23.049707375623335	52.13098760840381	178055
8b646ff33541c9e70044ce19e06af6c340896414	feasibility and effectiveness of the algorithm for overhead reduction in analog checkers	concurrent error detection;analog circuits hardware fault tolerance electrical fault detection fault detection error correction circuit faults analog computers reliability engineering digital circuits;analog circuits;analog operators all non zero solutions analog checkers self checking circuit reliability error detection error correction linear analog circuits hardware overhead reduction solution existence conditions passive elements;logic testing;analogue circuits;error detection;digital circuits;logic testing analogue circuits error detection fault diagnosis;fault diagnosis	Self-checking in analog circuits is more dificult than in digital circuits. The technique proposed by Abhijit Chatterjee can address concurrent error detection and correction in linear analog circuits and hence the reliability of the original circuit is greatly improved. However, hardware overhead is an important issue in this technique, which has never been addressed before. This paper proposes an algorithm for reduction of hardware overhead in the analog checker, and also presents a serial of theoretic results, including the concept of all-non-zero solutions and several existence conditions of such solutions. As the basis of the algorithm, these results are new in the mathematic world and can be used to verify feasibility and effectiveness of the algorithm. Without changing the original circuit, the proposed algorithm can not only reduce the number of passive elements, but also the number of analog operators so that the error detection circuitry in the checker has optimal hardware overhead.	algorithm;analogue electronics;digital electronics;electronic circuit;error detection and correction;overhead (computing);theory	Yingquan Zhou;Mike W. T. Wong;Yinghua Min	1995		10.1109/FTCS.1995.466974	mixed-signal integrated circuit;electronic engineering;real-time computing;computer science;theoretical computer science	EDA	22.40688605270586	49.49506674568865	178853
c5c55cf77b4a24b93fb27ed58427cc827895305f	modular verification of multipliers	decision diagram;modular arithmetic;modular verification;arithmetic circuit	We present a new method for the efficient verification of multipliers and other arithmetic circuits. It is based on modular arithmetic like Kimura's approach, and on composition, like Hamaguchi's approach. It differs from both in several important respects, which make it more robust. The technique builds the residue Algebraic Decision Diagram (ADD) of as many variables as the number of outputs in the multiplier and composes the implementation circuit from the outputs to the inputs into the residue. Finally, the residue ADD is checked against the specification. 1 I n t r o d u c t i o n The verification of arithmetic circuits has been the subject of much recent work [8, 9, 14, 20, 6, 17, 13]. Multipliers have been recognized earlier on as difficult cases for verification methods based on decision diagrams. Bryant [8] proved that the BDDs for array multipliers grow exponentially in size regardless of the variable order. Experiments show that the growth is proportional to 23n/2, and that it is impractical to build BDDs for multipliers with n > 12. Henceforth, several approaches have been proposed based on some relaxation of the variable ordering requirement. For instance, Burch proposed splitting one input variable into several ones, so as to eliminate the reconvergent fanout at the root of the BDD explosion [9]. Jain later extended this idea by allowing a variable to appear multiple times along a path in the BDD, each time with a different index [14]. Plessier, on the other hand, devised a technique based on a semi-canonical representation, that is, one that mixed pure BDDs with a structural representation of the multiplier [20]. A similar approach was presented in [1]. All the approaches were able to deal with multipliers with 16 bits at most. A major step forward in the verification of multipliers was made possible by the introduction of Multiplicative Binary Moment Diagrams (*BMDs) by Bryant [6]. *BMDs afford very compact, word-level representations of many arithmetic functions, including multipliers, but not dividers. Word-level representations are functions mapping bit vectors to integers. Two verification methods for multipliers based on *BMDs have been devised. Bryant has proposed a hierarchical *This work was supported in part by NSF/DARPA grant MIP-94-22268 and SRC contract 95-DJ-560.	arithmetic circuit complexity;binary moment diagram;bit array;decision problem;gary kimura;ibm notes;linear programming relaxation;reconvergent fan-out;robustness (computer science);semiconductor industry	Kavita Ravi;Abelardo Pardo;Gary D. Hachtel;Fabio Somenzi	1996		10.1007/BFb0031799	modular arithmetic;computer architecture;influence diagram;theoretical computer science	Logic	18.47048408801914	46.89916697173106	179016
b1a8a89a765e1b953df86992da0aff7482279dae	stg decomposition: internal communication for si implementability	gyroscopes delay chromium integrated circuits silicon partitioning algorithms context;silicon;gyroscopes;control resynthesis;state space methods;decomposition;logic design;control resynthesis stg decomposition internal communication si implementability logic synthesis speed independent circuits complexity problems state space explosion csc conflicts;internal communication;complexity problems;stg;resynthesis;speed independent;state space methods circuit complexity logic design;circuit complexity;resynthesis stg decomposition speed independent csc;logic synthesis;chromium;speed independent circuits;csc;csc conflicts;state space explosion;integrated circuits;stg decomposition;context;partitioning algorithms;si implementability	Logic synthesis of speed independent circuits based on STG decomposition is a promising approach to tackle complexity problems like state-space explosion. Unfortunately, decomposition can result in components that in isolation have irreducible CSC conflicts. Generalising earlier work, we show how to resolve such conflicts by introducing internal communication between the components. The new algorithms are successfully applied to some benchmarks, including very complex STGs arising in the context of control resynthesis.	algorithm;benchmark (computing);irreducibility;logic synthesis;microsoft outlook for mac;star trek generations;state space	Dominic Wist;Mark Schäfer;Walter Vogler;Ralf Wollowski	2010	2010 10th International Conference on Application of Concurrency to System Design	10.1109/ACSD.2010.15	embedded system;internal communications;logic synthesis;real-time computing;computer science;algorithm	EDA	17.832593700680487	48.19736543234579	179614
3760e26edb586109aa279babfff702ce650bd73a	on non-statistical techniques for fast fault coverage estimation	fault simulation;small sample size;fault coverage estimation;sequential circuits;sampling technique;hyperactivity reduction;test generation;fault coverage;tolerance;statistical techniques;flip flop	We present fast, dynamic fault coverage estimation techniques for sequential circuits that achieve high degrees of accuracy and significant reductions in the number of injected faults and faulty-event evaluations. In the proposed techniques, we dynamically reduce injection of hyperactive faults as well as faults whose effects never propagate to a flip-flop or primary output. Suppression and over-specification of potential fault-effects are also investigated to reduce faulty-event evaluations. Experiments show that our methods give very accurate estimates with frequently greater speedups than the sampling techniques for most circuits. Most significantly, the proposed techniques can be combined with the sampling approach to obtain speedups comparable to small sample sizes and retain estimation accuracy of large fault samples.	fast fourier transform;fault coverage	Michael S. Hsiao	1999	J. Electronic Testing	10.1023/A:1008332723359	reliability engineering;sampling;electronic engineering;real-time computing;fault coverage;engineering;sequential logic	EDA	23.93670336430637	51.62114040716254	179936
5d4636cbf43a324af84588f7b4456dba5fca2a19	f/logic - an interactive fault and logic simulator for digital circuits	circuit design;number of factors;present day;digital circuits;digital simulation	Digital simulators are becoming a standard and necessary CAD tool in the circuit design process. The acceptance of this design aid is a result of a number of factors, the predominant one being the over-whelming size and complexity of present day logic circuits and the requirement that a complete test plan be developed for these circuits. Another factor is that recent generation logic simulators have proven to be very flexible tools, capable of simulating very large circuits with a high degree of precision.	broadcast delay;central processing unit;circuit design;computer-aided design;digital electronics;flip-flop (electronics);logic gate;logic simulation;printed circuit board;printing;requirement;test plan	Philip S. Wilcox;H. Rombeek	1976		10.1145/800146.804797	mixed-signal integrated circuit;embedded system;boolean circuit;electronic engineering;logic optimization;logic level;asynchronous circuit;logic family;computer science;electrical engineering;theoretical computer science;circuit design;pass transistor logic;sequential logic;integrated injection logic;digital electronics;register-transfer level;resistor–transistor logic;computer engineering;logic analyzer	EDA	18.509307455675557	49.35199094626027	180066
b66f89897e44555aa990418bb7e9e378165df24f	static timing model extraction for combinational circuits	static timing analysis;combinational circuit;extraction method	For large circuits, static timing analysis (STA) needs to be performed in a hierarchical manner to achieve higher performance in arrival time propagation. In hierarchical STA, efficient and accurate timing models of sub-modules need to be created. We propose a timing model extraction method that significantly reduces the size of timing models without losing any accuracy by removing redundant timing information. Circuit components which do not contribute to the delay of any input to output pair are removed. The proposed method is deterministic. Compared to the original models, the numbers of edges and vertices of the resulting timing models are reduced by 84% and 85% on average, respectively, which are significantly more than the results achieved by other methods.	combinational logic;deterministic algorithm;high-level programming language;input/output;merge algorithm;merge sort;preprocessor;recursion;software propagation;static timing analysis;time of arrival;unit propagation;vertex (geometry)	Bing Li;Christoph Knoth;Walter Schneider;Manuel Schmidt;Ulf Schlichtmann	2008		10.1007/978-3-540-95948-9_16	electronic engineering;parallel computing;real-time computing;computer science;combinational logic;static timing analysis	EDA	19.07397797573151	51.21672229689511	180575
e1327fa05e28a86b0c6ead012466bc09560fa929	tao: regular expression-based register-transfer level testability analysis and optimization	microprocessors;digital signal processors;design for testability;diseno circuito;optimisation;optimizacion;integrated circuit;registro rtl;data path;testabilite;signal design;automatic testing;test generation time;circuit design;controller;sequential analysis;high level test generation;circuito integrado;synthese haut niveau;testability analysis;indexing terms;camino datos;application specific instruction processors;testability;sintesis alto nivel;high level synthesis;supervisor;register transfer level rtl test generation;algebra;sequential test;application specific integrated circuits;application specific integrated circuit;benchmark circuits;asics;test synthesis;controleur;logic testing;application specific programmable processors;integrated circuit testing;niveau transfert registre;vlsi;application specific processors;digital signal processor;rtl controller data path circuits;test generation;chemin donnees;digital signal processing chips;fault coverage;testabilidad;optimization;conception circuit;conception pour test;circuit testing;design for test;circuit optimisation;aspps;circuit testing sequential analysis optimization methods design for testability benchmark testing integrated circuit testing signal design algebra application specific integrated circuits application specific processors;register transfer level testability analysis;register transfer level;asips;test synthesis testability analysis register transfer level testability analysis optimization rtl controller data path circuits application specific integrated circuits asics application specific programmable processors aspps application specific instruction processors asips digital signal processors microprocessors benchmark circuits test generation time high level test generation;regular expression;benchmark testing;circuit integre;fault diagnosis	In this paper, we present testability analysis and optimization (TAO), a novel methodology for register-transfer level (RTL) testability analysis and optimization of RTL controller/data path circuits. Unlike existing high-level testing techniques that cater restrictively to certain classes of circuits or design styles, TAO exploits the algebra of regular expressions to provide a unified framework for handling a wide variety of circuits including application-specific integrated circuits (ASICs), application-specific programmable processors (ASPPs), application-specific instruction processors (ASIPs), digital signal processors (DSPs), and microprocessors. We also augment TAO with a design-for-test (DFT) framework that can provide a low-cost testability solution by examining the tradeoffs in choosing from a diverse array of testability modifications like partial scan or test multiplexer insertion in different parts of the circuit. Test generation is symbolic and, hence, independent of bit width. Experimental results on benchmark circuits show that TAO is very efficient, in addition to being comprehensive. The fault coverage obtained is above 99% in all cases. The average area and delay overheads for incorporating testability into the benchmarks are only 3.2% and 1.0%, respectively. The test generation time is two-to-four orders of magnitude smaller than that associated with gate-level sequential test generators, while the test application times are comparable.	mathematical optimization;register-transfer level;regular expression;tao	Srivaths Ravi;Ganesh Lakshminarayana;Niraj K. Jha	2001	IEEE Trans. VLSI Syst.	10.1109/92.974896	embedded system;digital signal processor;computer architecture;electronic engineering;parallel computing;computer science;test compression;design for testing;application-specific integrated circuit	EDA	19.374630125957605	49.314465490843645	180901
14e12ec32f087aadc9bfad239a3936d1bbf71bfd	statistical time borrowing for pulsed-latch circuit designs	random variable;statistical pulse width allocation;combinational circuits;size 45 nm;clock period;yield constraint yc;allocation algorithm;deterministic pulse width allocation;timing;sequencing overhead;time borrowing;pulse width;logic design;short pulse;combinational block;statistical time borrowing;pulsed-latch circuit design;flip-flops;timing analysis;timing yield;yield constraint;predefined width;pulsed-latch circuit designs;image recognition;resource management;soc;circuit design;satisfiability	Pulsed-latch inherits the advantage of latch in less sequencing overhead while taking the advantage of flip-flop in its convenience during timing analysis. Even though this advantage comes from the fact that pulsed-latch uses a short pulse, it is still capable of a small amount of time borrowing. A problem of allocating pulse width (out of a few predefined widths), where each width is modeled by a random variable, is formulated for minimizing the clock period of pulsed-latch circuits; this is equivalent to assigning a random variable that represents the amount of time borrowed by the combinational block between each latch pair. A statistical approach is important in this problem because assuming +3σ of all pulse widths does not represent the worst case. An allocation algorithm called SPWA as well as an algorithm to compute timing yield is proposed. In experiments with 45-nm technology, compared to the case of no time borrowing, the clock period was reduced by 12.2% and 11.7% on average when the yield constraint Yc is 0.85 and 0.95, respectively; this is compared to the deterministic counterpart called DPWA, which reduced the clock period by 7.6% and 7.3%. More importantly, DPWA failed to satisfy the yield constraints in four (out of eleven) circuits while the yield constraints were always satisfied in SPWA.	algorithm;benchmark (computing);best, worst and average case;clock rate;cluster analysis;combinational logic;constraint (mathematics);experiment;flops;flip-flop (electronics);meltwater entrepreneurial school of technology;overhead (computing);pulse (signal processing);pulse-width modulation;static timing analysis;vii	Seungwhun Paik;Lee-eun Yu;Youngsoo Shin	2010	2010 15th Asia and South Pacific Design Automation Conference (ASP-DAC)		system on a chip;random variable;embedded system;electronic engineering;parallel computing;logic synthesis;real-time computing;computer science;resource management;circuit design;mathematics;combinational logic;static timing analysis;statistics;satisfiability	EDA	18.069371821432412	53.097395792912884	181136
1e5e513561b270300a42e36b5c24a67c2628e091	signal transition graph transformations for initializability	graph theory;logic design;sequential circuits;asynchronous circuit design signal transition graph stg transformations initializability trigger module;signal transition graph;trigger circuits sequential circuits asynchronous sequential logic logic design graph theory;trigger circuits;asynchronous sequential logic;circuit synthesis signal synthesis national electric code logic testing circuit testing very large scale integration dh hemts asynchronous circuits logic circuits usa councils	We present a method of transforming a functionally uninitializable signal transition graph (STG) into a functionally initializable STG. The design of a trigger module is described to illustrate the transformations. >	graph rewriting;signal transition	Savita Banerjee;Rabindra K. Roy;Srimat T. Chakradhar;Dhiraj K. Pradhan	1994		10.1109/EDTC.1994.326794	electronic engineering;logic optimization;asynchronous circuit;logic family;computer science;theoretical computer science;sequential logic;algorithm	Logic	19.668053961498494	47.29784463151162	181577
b0c0cf2946bfc575c37eac23f31de543e3f3277d	simulation strategy after model checking: experience in industrial soc design	logic simulation;logic design;computer bugs system testing assembly electronics industry large scale integration industrial electronics electronic mail reduced order systems fabrication control systems;simulation strategy;model checking;logic design logic simulation;industrial soc design simulation strategy model checking;industrial soc design	There have been many works reporting the success of model checking in finding the bugs that are not detected by the simulation. On the contrary, in this paper, we show the bugs that can escape from the model checking, and present the simulation strategy and speed up techniques to detect those bugs. The main focus of this paper is to show clearly the importance and the role of a simulation as a complement to the model checking.		Hoon Choi;Byeong-Whee Yun;Yun-Tae Lee	2000		10.1109/HLDVT.2000.889563	model checking;embedded system;logic synthesis;real-time computing;simulation;computer science;logic simulation;programming language;algorithm	EDA	18.7918202404198	49.355102149208	181647
f967afa6956badf07edcd1397321d7ac4731af4a	"""comments on """"multiple fault detection in combinational network"""""""	fault detection	In the above paper, 1 the authors have defined complete test, closed fault set, fault set graph, and undetected fault set as follows.	combinational logic	Bella Bose	1979	IEEE Trans. Computers	10.1109/TC.1979.1675254	fault;real-time computing;fault coverage;fault indicator;computer science;stuck-at fault;automatic test pattern generation;fault model;distributed computing;fault detection and isolation;algorithm	Vision	22.96440932091444	49.485299186536544	181737
c20cbd9818e0ce6e5f69d02dbbe08f137e721659	on finding a minimal set of diagnostic tests	diagnostic test;circuit faults;decoding;switching circuits;weight control;terminology;circuit testing;circuit faults circuit synthesis laboratories weight control switching circuits circuit testing decoding terminology;circuit synthesis	A method is described for constructing a set of input patterns able to detect every given failure of a combinational network. The result may not be a minimal set of tests, but it is surely a complete test.		Frank O. Hadlock	1967	IEEE Trans. Electronic Computers	10.1109/PGEC.1967.264778	electronic engineering;computer science;theoretical computer science;circuit extraction;terminology;algorithm;diagnostic test	EDA	21.892092659530512	49.35930009467482	181990
5f33322078a94506a67ee918ac8fb099240bf161	on n-detection test sets and variable n-detection test sets fortransition faults	automatic test pattern generation;logic testing;integrated circuit testing;path delay fault;circuit testing circuit faults delay electrical fault detection fault detection timing combinational circuits logic circuits very large scale integration cities and towns;timing integrated circuit testing logic testing automatic test pattern generation;atpg n detection test sets variable n detection test sets transition faults defects detection timing behavior path delay faults delay fault coverage;timing	We study the effectiveness of n-detection test sets based on transition faults in detecting defects that affect the timing behavior of a circuit. We use path delay faults as surrogates for unmodeled defects, and show that the path delay fault coverage achieved by an n-detection transition fault test set increases significantly as n is increased. We also introduce a method to reduce the number of tests included in an n-detection test set by using different values of n for different faults based on their potential effect on the defect coverage. The resulting test sets are referred to as variable n-detection test sets.		Irith Pomeranz;Sudhakar M. Reddy	2000	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.833205	reliability engineering;electronic engineering;real-time computing;fault coverage;fault indicator;engineering;stuck-at fault;automatic test pattern generation;test compression;mathematics	EDA	21.697897456178428	51.60567948882168	182321
e72aa768fcb49d677d44b080ef98e02b5408be0e	a dft method for core-based systems-on-a-chip based on consecutive testability	graph theory;design for testability;test access mechanism;consecutive testability;system testing system on a chip clocks logic testing design for testability design methodology linear programming performance evaluation timing delay;graph theory integrated circuit testing design for testability integrated circuit design integer programming timing vlsi delays logic testing application specific integrated circuits;system on a chip;delay faults dft method core based systems on a chip consecutive testability core based socs design for testability method integer programming problem test patterns propagation test responses propagation asic system clock speed consecutive transparency properties interconnect testing logic faults stuck at faults timing faults;integrated circuit design;integer programming;application specific integrated circuits;logic testing;integrated circuit testing;vlsi;integer program;core based systems on a chip;consecutive transparency;delays;timing	This paper introduces a new concept of testability of core-based systems-on-a-chip (SoCs) called consecutive testability and proposes a design-for-testability (DFT) method for making a given SoC consecutively testable based on an integer programming problem. For a consecutively testable SoC, testing can be performed as follows. Test patterns of a core are propagated to the core inputs from the SoC inputs consecutively at the speed of the system clock. Similarly the test responses are propagated to the SoC outputs from the core outputs consecutively at the speed of the system clock. The propagation of test patterns and responses is achieved by using the consecutive transparency properties of surrounding cores and interconnects between cores. All interconnects can be tested in a similar fashion. Therefore, the method can test not only logic faults such as stuck-at faults, but also timing faults such as delay faults that require consecutive application of test patterns at system clock speed.	system on a chip	Tomokazu Yoneda;Hideo Fujiwara	2001		10.1109/ATS.2001.990280	system on a chip;embedded system;electronic engineering;real-time computing;integer programming;computer science;graph theory;design for testing;application-specific integrated circuit;very-large-scale integration;integrated circuit design	NLP	20.88153633954467	51.481301835117264	183399
e055c8c18341a1e306aa32993db88d4ca4f7caf2	comparative study of ca-based prpgs and lfsrs with phase shifters	bist ca based prpgs ca based lfsrs phase shifters randomness properties 1d linear hybrid cellular automata linear feedback shift registers pseudo random pattern generators testing applications cellular automata based configurations;bist;pins;testing applications;phase shifters;linear feedback shift registers;automatic test pattern generation;automatic testing;automatic test pattern generation cellular automata shift registers phase shifters built in self test logic testing integrated circuit testing;pattern generation;linear feedback shift register;1d linear hybrid cellular automata;randomness properties;built in self test;hybrid power systems;phase shifter;shift registers;logic testing;integrated circuit testing;cellular automata based configurations;system testing;phase shifters built in self test circuit testing automatic testing radio access networks hardware system testing graphics hybrid power systems pins;circuit testing;pseudo random pattern generators;ca based prpgs;cellular automata;ca based lfsrs;graphics;radio access networks;hardware	The paper presents a comparative study of randomness properties of patterns generated by one-dimensional linear hybrid cellular automata (LHCA) and linear feedback shift registers (LFSRs) with phase shifters on their outputs. It is shown that properly synthesized phase shifters allow LFSRs to match performance of the LHCAs as pseudo-random pattern generators (PRPGs), in marked contrast to several suggestions that LHCAs can outperform LFSRs in variety of testing applications.		Janusz Rajski;Grzegorz Mrugalski;Jerzy Tyszer	1999		10.1109/VTEST.1999.766671	cellular automaton;electronic engineering;real-time computing;computer science;phase shift module;graphics;theoretical computer science;automatic test pattern generation;shift register;linear feedback shift register;system testing;algorithm	Crypto	22.18953014830283	48.826547663984115	183470
6eaefbb63eb72425954b248d0a65c4a5845f8081	new types of digital comparators	circuit sizes digital comparators clocked cross coupled inverters analogical techniques;coupled circuits digital integrated circuits comparators circuits logic gates;comparators circuits;logic gates;digital integrated circuits;coupled circuits;inverters clocks voltage logic circuits capacitors feedback circuits capacitance coupling circuits digital circuits boolean functions;digital circuits	We present in this paper new types of digital comparator circuits based on clocked crosscoupled inverters. They are digital circuits but they are implemented with analogical techniques. Therefore they have differents siz’es. The circuits are fast and small compared with traditional implementations.	clock rate;digital comparator;digital electronics;inverter (logic gate)	José Antonio Hidalgo López;Juan Carlos Tejero-Calado;José Fernández Ramos;Alfonso Gago Bohórquez	1995		10.1109/ISCAS.1995.521443	mixed-signal integrated circuit;control engineering;boolean circuit;electronic engineering;electronics;logic level;logic gate;computer science;engineering;electrical engineering;integrated injection logic;digital electronics;clock signal	EDA	23.41211447220783	52.313331879836106	183799
bef43534d22561b8b18425d857114a52fce6e2f6	a general technique for designing totally self-checking checker for 1-out-of-n code with minimum gate delay	optimal solution;error detection codes;detection erreur;logic arrays;concepcion circuito;deteccion error;solution optimale;nor nor pla;integrated circuit;logic design;traductor;1 out of n code;estudio comparativo;nor array;sistema informatico;circuit design;circuit vlsi;traducteur;circuito integrado;computer system;general techniques;controle;chip;etude comparative;nor nor pla totally self checking checker 1 out of n code minimum gate delay translator nor array;design technique;fault tolerant computing;vlsi circuit;minimum gate delay;solucion optima;logic testing;comparative study;control;conception circuit;systeme informatique;totally self checking checker;translator;error detection;circuito vlsi;logic testing delays error detection codes fault tolerant computing logic arrays logic design;circuit integre;circuit faults delay programmable logic arrays hardware electrical fault detection fault detection built in self test very large scale integration decoding computer applications;delays;check	An efficient technique for designing a totally self-checking checker for 1/11 code ( I I > 3 ) with minimum possible gate delay is proposed. The checker consists of a 1/11 to k / 2 k translator and a k/2X code checker. The translator is implemented using a NOR array and checker using a NOR-NOR PLA. The design technique is applicable for all but a few values of R . It has been shown that the checkers constructed using the proposed technique occupy minimum or near minimum chip area depending on the value of n . This new technique also has the advantage over existing ones in terms of speed or hardware.	programmable logic array;propagation delay	D. L. Tao;Carlos R. P. Hartmann;Parag K. Lala	1992	IEEE Trans. Computers	10.1109/12.256456	check;chip;embedded system;parallel computing;logic synthesis;real-time computing;error detection and correction;telecommunications;computer science;operating system;integrated circuit;circuit design;comparative research;algorithm;scientific control	EDA	21.337732014431584	48.74604867610041	183951
f7b2008d839011df97a0d49af739725091ded5a5	an efficient graph representation for arithmetic circuitverification	decision diagrams formal verification floating point arithmetic digital arithmetic multiplying circuits;decision diagrams;multiplicative power hybrid decision diagram;multiplying circuits;bmd;decision diagram;bdd;floating point multiplier graph representation arithmetic circuit hierarchical verification data structure multiplicative power hybrid decision diagram boolean vector integer multiplier;indexing terms;formal verification floating point arithmetic circuit simulation microprocessors data structures vectors encoding helium costs logic;phdd;formal verification;compact representation;graph representation;binary moment diagram;hybrid decision diagram;digital arithmetic;floating point;floating point arithmetic;data structure;hdd	In this paper, we propose a new data structure called multiplicative power hybrid decision diagrams (*PHDDs) to provide a compact representation for functions that map Boolean vectors into integer or floating-point (FP) values. The size of the graph to represent the IEEE FP encoding is linear with the word size. The complexity of FP multiplication grows linearly with the word size. The complexity of FP addition grows exponentially with the size of the exponent part, but linearly with the size of the mantissa part. We applied *PHDDs to verify integer multipliers and FP multipliers before the rounding stage, based on a hierarchical verification approach. For integer multipliers, our results are at least six times faster than binary moment diagrams. Previous attempts at verifying FP multipliers required manual intervention, but we verified FP multipliers before the rounding stage automatically.	graph (abstract data type)	Yirng-An Chen;Randal E. Bryant	2001	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.969437	mathematical optimization;electronic engineering;discrete mathematics;fp;data structure;computer science;floating point;theoretical computer science;mathematics;programming language;algorithm	EDA	18.692423524048195	46.70050818361858	184492
21369bd58f962b21edfdbaa6af385d23a5d78be8	enhancing sat-based bounded model checking using sequential logic implications	databases;constraint handling computability asynchronous sequential logic;boolean constraint propagation;sequential signal correlations;state space methods;iscas89 benchmark circuits;boolean functions;search space;computability;automatic test pattern generation;sequential circuits;logic;safety properties;nontrivial implications;power engineering and energy;satisfiability solver;bounded model checking;power engineering computing;circuit under verification;circuit under verification bounded model checking sequential logic implications sequential signal correlations time frame boundaries nontrivial implications preprocessing conjunctive normal form database satisfiability solver boolean constraint propagation iscas89 benchmark circuits;data structures;logic data structures boolean functions sequential circuits explosions automatic test pattern generation state space methods power engineering computing power engineering and energy databases;conjunctive normal form database;constraint handling;explosions;sequential logic implications;sat solver;preprocessing;asynchronous sequential logic;time frame boundaries	We present a novel technique of improving the SAT-based Bounded Model Checking, by inducing powerful sequential signal correlations (crossing time-frame boundaries) into the original CNF formula of the unrolled circuit. A quick preprocessing on the circuit-under-verification, builds a large set of direct and indirect sequential implications. The non-trivial implications (spanning multiple time-frames) are converted into two-literal clauses. These clauses are quickly replicated throughout the unrolled sequential circuit, and appended to the existing CNF database. The added clauses prune the overall search space of SAT-solver engine and provide correlation among the different variables, which enhances the Boolean Constraint Propagation (BCP). Experimental Results for checking difficult instances of random safety properties on ISCAS'89 benchmark circuits show that more than 148x speedup can be achieved over the conventional approach.	benchmark (computing);boolean satisfiability problem;bulk copy program;conjunctive normal form;file spanning;literal (computer programming);literal (mathematical logic);local consistency;model checking;preprocessor;sequential logic;solver;speedup	Rajat Arora;Michael S. Hsiao	2004	17th International Conference on VLSI Design. Proceedings.	10.1109/ICVD.2004.1261028	discrete mathematics;data structure;computer science;theoretical computer science;automatic test pattern generation;mathematics;computability;programming language;logic;algorithm	EDA	18.758437412391686	48.1124751913894	184623
0ae63dff411ffcc52049924332b989ece0dd03a8	locating stuck faults in analog circuits	circuit under test;automatic testing;stuck at faults linear analog circuits bridging faults multiple analog fault diagnosis precision test conditions ideal switches stuck open locations;automatic testing analogue integrated circuits fault diagnosis integrated circuit testing;analog circuits;analogue integrated circuits;operational amplifier;circuit faults analog circuits fault diagnosis electrical fault detection fault detection switches circuit analysis dictionaries circuit testing analog integrated circuits;integrated circuit testing;constitutive equation;fault diagnosis	A new approach is proposed in this paper to detect the stuck faults in linear analog circuits. Ideal switches are inserted to indicate stuck-at, bridging and stuck-open locations. Then the resulting circuit is analyzed and stuck faults are directly identified. A recently developed method for multiple analog fault diagnosis is used eliminating a need for fault dictionary approach. The effect of locating stuck-at, bridging and stuckopen faults is modeled with full precision of resulting test conditions. An analog IC μA741 is given as an example.	analogue electronics;bridging (networking);dictionary;network switch	Janusz A. Starzyk;Dong Liu	2002		10.1109/ISCAS.2002.1010183	mixed-signal integrated circuit;operational amplifier;embedded system;electronic engineering;real-time computing;analogue electronics;fault indicator;engineering;stuck-at fault;control theory;constitutive equation	EDA	23.196306635311345	51.95278005171181	184668
4aa82d89c0b8bde30a47455aa87a2608ce03b997	novel synthesis methodology for fault tolerant reversible circuits by bounded model checking for linear temporal logic	fault tolerant;reversible circuit;model checking;parity preserving	Reversible circuit is of interest due to the characteristics of low energy consumption. This paper proposes a new scheme for synthesizing fault tolerant reversible circuits. A two-step method is put forward to convert an irreversible function into a parity-preserving reversible circuit. By introducing model checking for linear temporal logic, we construct a ̄nite state machine to synthesize small reversible gates from elementary 1-qubit and 2-qubit gates, which is more automatic than the methods proposed previously. Constrains are increased so as to reduce the synthesis time in the two step method. The parity-preserving gate constructed by the two-step method has characteristics of low quantum cost because the quantum representation obtained from the counterexample for a given function in each step has the minimum quantum cost. In order to further reduce the quantum cost and decrease the synthesis time, the semi paritypreserving gates are put forward for the ̄rst time. These gates are parity-preserving when the auxiliary input is set to 0 and opposite parity when 1. Maintaining good robustness of the system in performing speci ̄c function, semi parity-preserving gate is conducive to detecting the stuck-at fault and partial gate fault in reversible circuits. The innovation of this paper is introducing the formal method to synthesis small fault tolerant gate, so as to construct the circuit with robust (semi) parity-preserving gates.	algorithm;circuit design;fault tolerance;finite-state machine;formal methods;format-preserving encryption;linear temporal logic;logic gate;model checking;parity bit;quantum circuit;quantum wire;reversible computing;semiconductor industry;sensor;stuck-at fault	Ming-Cui Li;Ri-Gui Zhou	2015	Journal of Circuits, Systems, and Computers	10.1142/S0218126615500917	model checking;reversible computing;fault tolerance;electronic engineering;toffoli gate;three-input universal logic gate;computer science;theoretical computer science;quantum circuit;mathematics;algorithm	EDA	18.96264837342211	47.7240036654806	184687
940b9370e023629de8d100c731d64f9c04136a8e	low power test compression technique for designs with multiple scan chain	design for testability;inverters;energy consumption hardware design for testability inverters benchmark testing computer science production systems system testing electronic design automation and methodology manufacturing;electronic design automation and methodology;low power;energy consumption;manufacturing;production systems;system testing;computer science;power consumption;benchmark testing;hardware	This paper presents a new DFT technique that can significantly reduce test data volume as well as scan-in power consumption for multiscan-based designs. It can also help to reduce test time and tester channel requirements with small hardware overhead. In the proposed approach, we start with a pre-computed test cube set and fill the don’t-cares with proper values for joint reduction of test data volume and scan power consumption. In addition we explore the linear dependencies of the scan chains to construct a fanout structure only with inverters to achieve further compression. Experimental results for the larger ISCAS’89 benchmarks show the efficiency of the proposed technique.	apple multiple scan 14 display;don't-care term;fan-out;inverter (logic gate);overhead (computing);precomputation;requirement;test compression;test data;turing test	Youhua Shi;Nozomu Togawa;Masao Yanagisawa;Tatsuo Ohtsuki;Shinji Kimura	2005	14th Asian Test Symposium (ATS'05)	10.1109/ATS.2005.76	reliability engineering;embedded system;benchmark;electronic engineering;real-time computing;computer science;engineering;test compression;design for testing;production system;manufacturing;system testing	EDA	20.26230809029388	53.341048163769166	186793
3a906038859df2f7ae9dc0db0d1018b42a6e714a	untestable fault identification using recurrence relations and impossible value assignments	benchmark testing fault diagnosis sequential circuits combinational circuits;circuit faults;execution time;automatic test pattern generation;sequential circuits;recurrence relations;value analysis;nontrivial multiple node conflicts;combinational benchmark circuits;sequential benchmark circuits;test pattern generators;engines;execution time untestable fault identification recurrence relations impossible value assignments unexcitable nets identification sequential benchmark circuits combinational benchmark circuits nontrivial multiple node conflicts combinational circuits;fault detection;net generation;recurrence relation;untestable fault identification;fault diagnosis circuit faults sequential circuits automatic test pattern generation circuit testing fires fault detection test pattern generators engines electrical fault detection;circuit testing;impossible value assignments;unexcitable nets identification;fires;benchmark testing;electrical fault detection;fault identification;fault diagnosis;combinational circuits	This paper presents two novel and low cost techniques that can be used for the purpose of untestable fault identification. First, we present a new theorem and a practical method using static implications to identify unexcitable nets using recurrence relations in sequential circuits. Since each unexcitable net generally infers to more than one untestable fault, this theorem helps us to quickly identify significantly more sequentially untestable faults. In addition to discovering unexcitable nets using recurrence relations, we propose a second approach that aims at quickly identifying non-trivial multiple-node conflicts, which can then be used to identify additional untestable faults in both combinational and sequential circuits. Unlike previous techniques that concentrate on identifying local conflicts in the circuit, our approach efficiently extends the conflicting value analysis across multiple levels in the circuit to identify more untestable faults. Application of our techniques to both combinational and sequential benchmark circuits showed that significantly more untestable faults can be identified using the proposed approaches, with low overhead in terms of both memory and execution time.	benchmark (computing);combinational logic;overhead (computing);recurrence relation;run time (program lifecycle phase)	Manan Syal;Michael S. Hsiao	2004	17th International Conference on VLSI Design. Proceedings.	10.1109/ICVD.2004.1260967	reliability engineering;electronic engineering;real-time computing;recurrence relation;computer science;engineering;algorithm	EDA	21.312086373251088	50.87404450571749	187171
ad4b40155fcc9cb243937ac03b304d44f03d0bfb	lfsr based hybrid pattern scheme achieving low power dissipation and high fault coverage	switching activity;circuit under test;circuit faults;flip flops;pattern generation;testing;random testing;built in self test;low power;test pattern generators;hybrid power systems;system on chip;system on chip built in self test integrated circuit testing;integrated circuit testing;fault coverage;benchmark circuits hardware overhead scan based test pattern generator circuit under test seed selected random test pattern generator 3 weight weighted random built in self test;test pattern generator;hardware;power dissipation circuit testing circuit faults test pattern generators hardware electrical fault detection fault detection benchmark testing switching circuits costs	This paper presents a low hardware overhead scan-based test pattern generator (TPG) that can reduce switching activity in circuit under test (CUT) during test and also achieve very high fault coverage with reasonable lengths of test sequences. The proposed TPG is comprised of two TPGs: seed selected random test pattern generator (RTPG) and 3-weight weighted random built-in-self test (WRBIST). Test pattern generated by seed selected RTPG detect easy-to-detect faults and test pattern generated by 3-weight WRBIST detect hard faults that remain undetected after seed selected RTPG patterns are applied. Experimental results show that the proposed TPG schemes can attain 100% fault coverage for all benchmark circuits with drastically reduced test sequence lengths. This reduction in test sequence length achieved at low hardware cost even for benchmark circuits that have large number of scan inputs.	benchmark (computing);built-in self-test;fault coverage;linear-feedback shift register;overhead (computing);test card	Syed Zahidul Islam;Mohd. Alauddin Mohd. Ali	2008	APCCAS 2008 - 2008 IEEE Asia Pacific Conference on Circuits and Systems	10.1109/APCCAS.2008.4746380	random testing;system on a chip;embedded system;electronic engineering;real-time computing;fault coverage;computer science;engineering;automatic test pattern generation;test compression;software testing	EDA	20.489791508188897	52.1962817175307	187228
19df95816bd0862789b4689c72e0791a4319b183	clock sequences for increasing the fault coverage of functional test sequences	clocks circuit faults logic gates computational modeling manufacturing compaction electronic mail;test generation clock sequence functional test sequence gate level fault coverage	A functional test sequence for a design may not be effective as a manufacturing test for a logic block in the design because it achieves a low gate-level fault coverage. This paper describes a procedure for selecting a clock sequence that increases the gate-level fault coverage of a functional test sequence when it is used for testing a subset of logic blocks. The procedure deactivates the clocks to the logic blocks in the subset when a primary input vector has a negative effect on their fault coverage. The procedure is different from earlier test generation and test compaction procedures in that it increases the fault coverage without modifying the functional test sequence. It thus preserves some of the functional characteristics and the test application process for the sequence. Experimental results for benchmark circuits are presented to demonstrate the effectiveness of the procedure.	benchmark (computing);clock signal;data compaction;fault coverage;functional testing;logic block;logic gate;stuck-at fault	Irith Pomeranz	2017	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2016.2622622	automatic test pattern generation;fault coverage;real-time computing;stuck-at fault;logic gate;electronic circuit;computer science;electronic engineering;logic block	EDA	21.107636406551624	51.1176242223209	187504
2660089e29b1446f98f8a3448d4caaf12b704656	exploiting symbolic techniques for partial scan flip flop selection	automatic testing;circuit analysis computing;flip-flops;graph theory;integrated circuit testing;integrated logic circuits;logic testing;sequential circuits;symbol manipulation;stg;circuit macros identification;large sequential circuits;partial scan flip flop selection;state transition graph;symbolic techniques;testability measure	Partial Scan techniques have been widely accepted as an effective solution to improve sequential ATPG performance while keeping acceptable area and performance overheads. Several techniques for flip-flop selection based on structural analysis have been presented in the literature. In this paper, we first propose a new testability measure based on the analysis of the circuit State Transition Graph through symbolic techniques. We then describe a scan flip flop selection algorithm exploiting this measure. We resort to the identification of several circuit macros to address large sequential circuits. When compared to other techniques, our approach shows good results, especially when it is used to optimize a set of flip-flops previously selected by means of structural analysis.	flops;selection algorithm;state diagram;state transition table;structural analysis	Fulvio Corno;Paolo Prinetto;Matteo Sonza Reorda;Massimo Violante	1998			routing;electronic engineering;real-time computing;computer science;graph theory;automatic test pattern generation;sequential analysis;design for testing;tellurium;sequential logic;structural analysis;algorithm	EDA	20.61874717916871	50.69917520846325	188103
16c4081d8500fe3a92d1d5709dc1e708525da59a	a scan-bist structure to test delay faults in sequential circuits	bist;circuit under test;sequential circuits;scan design;delay faults	Delay testing that requires the application of consecutive two-pattern tests is not an easy task in a scan-based environment. This paper proposes a novel approach to the delay fault testing problem in scan-based sequential circuits. This solution is based on the combination of a BIST structure with a scan-based design to apply delay test pairs to the circuit under test.	built-in self-test	Patrick Girard;Christian Landrault;V. Moreda;Serge Pravossoudovitch;Arnaud Virazel	1999	J. Electronic Testing	10.1023/A:1008305507376	embedded system;electronic engineering;scan chain;real-time computing;boundary scan;engineering;automatic test pattern generation;test compression;sequential logic	EDA	21.541033218429853	51.46254014060525	188201
72f3be1c38f8bbda46c3212a6adbdcdebe1cf17a	analogue fault modelling and simulation for supply current monitoring	fault free specifications;circuit faults;fault simulation;current supplies;externally observable behaviour;current supplies circuit faults circuit simulation operational amplifiers computational modeling bridge circuits computerized monitoring central processing unit circuit testing analog computers;testing;operational amplifiers;circuit analysis computing analogue integrated circuits integrated circuit modelling digital simulation operational amplifiers fault diagnosis;computerized monitoring;circuit simulation;analogue integrated circuits;computational modeling;operational amplifier;analogue fault modelling;integrated circuit modelling;faulty behaviour analogue fault modelling supply current monitoring fault simulation bridging faults operational amplifiers externally observable behaviour parameterisable macromodels fault free specifications;analog computers;parameterisable macromodels;analogue modelling;bridging faults;circuit testing;supply current monitoring;modelling and simulation;circuit analysis computing;spice;bridge circuits;central processing unit;digital simulation;faulty behaviour;fault diagnosis	Fault simulation of analogue circuits is a very CPU intensive task. This paper describes a technique to increase the speed of fault simulation. The effects of bridging faults within operational amplifiers have been classified according to the externally observable behaviour reducing the number of fault simulations by two thirds. Parameterisable macromodels have been written in which both fault-free specifications and faulty effects can be modelled. The supply current is also modelled. These macromodels have been verified by embedding within a larger circuit, and have been shown to accurately model fault-free and faulty behaviour, and to propagate faulty effects correctly. The macromodels simulate about 7.5 times faster than the full transistor model.	bridging (networking);central processing unit;fault tolerance;observable;operational amplifier;simulation;transistor model	Mark Zwolinski;Chris D. Chalk;Brian R. Wilkins	1996		10.1109/EDTC.1996.494354	embedded system;electronic engineering;real-time computing;engineering	EDA	23.435656993029365	52.37606973732387	188317
1510439bbc66924e56276bb5af2f0fd820b9076b	deterministic bist with partial scan	pattern generation;system performance;chip;partial scan;deterministic scan based bist	An efficiency deterministic BIST scheme based on partial scan chains together with a scan selection algorithm tailored for BIST is presented. The algorithm determines a minimum number of flip-flops to be scannable so that the remaining circuit has a pipeline-like structure. Experiments show that scanning less flip-flops may even decrease the hardware overhead for the on-chip pattern generator besides the classical advantages of partial scan such as less impact on the system performance and less hardware overhead.	benchmark (computing);built-in self-test;directed acyclic graph;evernote;flops;fault coverage;flip-flop (electronics);overhead (computing);selection algorithm	Gundolf Kiefer;Hans-Joachim Wunderlich	1999	European Test Workshop 1999 (Cat. No.PR00390)	10.1023/A:1008374811502	chip;electronic engineering;scan chain;parallel computing;real-time computing;telecommunications;computer science;engineering;computer performance	EDA	20.08596826336774	51.55599446045864	188382
7d1c4a66b80d1481df1f220041d504bc51ed2e99	soft-error tolerance and mitigation in asynchronous burst-mode circuits	digital circuit;tolerancia falta;detection erreur;evaluation performance;partial state output logic cones;soft error susceptibility;triple modular redundant;deteccion error;error correction codes;benchmark abmms;cmos technology;methode essai;performance evaluation;muller c elements;concurrent error detection;clocks;implementation;correction erreur;metodo descomposicion;testabilite;evaluacion prestacion;logic;error soft;methode decomposition;sistema n niveles;gate decomposition method;soft error tolerance asynchronous burst mode circuits soft errors soft error mitigation soft error susceptibility;error correction codes asynchronous circuits;testability;asynchronous circuit;erreur soft;circuit numerique;decomposition method;protection;redundancy;circuit asynchrone;benchmark abmms soft error tolerance asynchronous burst mode circuits muller c elements error mitigation approach soft error susceptibility assessment method complete state output logic cones partial state output logic cones gate decomposition method;systeme n niveaux;error correction;assessment methods;fault tolerance;soft error tolerance;multilevel system;circuito numerico;circuito asincrono;robustness;asynchronous circuits;circuits logic protection robustness redundancy error correction cmos technology clocks design methodology benchmark testing;testabilidad;circuits;correccion error;soft errors;soft error mitigation;error detection;test method;implementacion;soft error susceptibility assessment method;soft error;complete state output logic cones;tolerance faute;benchmark testing;error mitigation approach;asynchronous burst mode circuits;design methodology;metodo ensayo	We discuss the problem of soft errors in asynchronous burst-mode machines (ABMMs), and we propose two solutions. The first solution is an error tolerance approach, which leverages the inherent functionality of Muller C-elements, along with a variant of duplication, to suppress all transient errors. The proposed method is more robust and less expensive than the typical triple modular redundancy error tolerance method and often even less expensive than previously proposed concurrent error detection methods, which only provide detection but no correction. The second solution is an error mitigation approach, which leverages a newly devised soft-error susceptibility assessment method for ABMMs, along with partial duplication, to suppress a carefully chosen subset of transient errors. Three progressively more powerful options for partial duplication select among individual gates, complete state/output logic cones, or partial state/output logic cones and enable efficient exploration of the tradeoff between the achieved soft-error susceptibility reduction and the incurred area overhead. Furthermore, a gate-decomposition method is developed to leverage the additional soft-error susceptibility reduction opportunities arising during conversion of a two-level ABMM implementation into a multilevel one. Extensive experimental results on benchmark ABMMs assess the effectiveness of the proposed methods in reducing soft-error susceptibility, and their impact on area, performance, and offline testability.	benchmark (computing);error detection and correction;error-tolerant design;online and offline;overhead (computing);soft error;software testability;triple modular redundancy	Sobeeh Almukhaizim;Feng Shi;Eric Love;Yiorgos Makris	2009	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2009.2014381	electronic engineering;real-time computing;error detection and correction;computer science;electrical engineering;algorithm;statistics	EDA	22.271052123722818	49.659812626821434	188900
ee99d1acc3b13d2520b5f90002fd9d4c948427b6	dynamic testing of control units	current control;dynamic test control unit;control unit;test methods;dynamic test	"""The goal of the paper is to propose test methods for wired or microprogrammed control units without special test facilities: no special access path, i.e., no direct and exhaustive observation means. Consequently, the control unit will be tested through the current control algorithms under """"normal"""" sequencing facilities and through the controlled operative part; the proposed methodology consists of choosing an adequate set of algorithms and specific data, allowing an efficient test with respect to errors hypothesis."""	algorithm;control unit;dynamic testing;microcode	Chantal Robach;Gabriele Saucier	1978	IEEE Transactions on Computers	10.1109/TC.1978.1675161	real-time computing;computer hardware;computer science;operating system;dynamic testing;test method;control unit;algorithm;statistics	Visualization	23.87164963890426	49.766688484993935	189435
75e62a8dedc30d5cda3ce445263efec0e87415de	structural fsm traversal	existential quantification;state space methods;approximate algorithm;iterative algorithms;boolean functions;sequential circuits;state space traversal;automata;finite state machines;formal verification;binary decision diagrams;structural fsm;approximative algorithms;data structures;exact algorithm;state space;retiming structural fsm state space traversal finite state machine equivalence checking sequential circuits existential quantification approximative algorithms formal hardware verification reachability analysis;formal hardware verification;data structures boolean functions sequential circuits reachability analysis automata iterative algorithms binary decision diagrams formal verification state space methods algorithm design and analysis;equivalence checking;data structure;algorithm design and analysis;finite state machine;retiming;reachability analysis;state space methods finite state machines sequential circuits formal verification	"""This paper discusses a """"structural"""" technique for traversing the state space of a finite state machine (FSM) and its application to equivalence checking of sequential circuits. The key ingredient to a state-space traversal is a data structure to represent state sets. In structural FSM, traversal-state sets are represented noncanonically and implicitly as gate netlists. First, we present an exact algorithm, which is based on an iterative expansion of the FSM into time frames and a network-decomposition procedure serving the same purpose as an existential quantification operation. Then, we discuss approximative algorithms for the application of structural FSM traversal to sequential equivalence checking. We theoretically analyze the properties of the exact as well as the approximative algorithms. Finally, we give details on the implementation of a sequential equivalence checker and present experimental results that demonstrate the effectiveness of the proposed approach for equivalence checking of optimized and retimed circuits."""	data structure;exact algorithm;existential quantification;finite-state machine;formal equivalence checking;iterative method;state space;tree traversal;turing completeness	Dominik Stoffel;Markus Wedler;Peter Warkentin;Wolfgang Kunz	2004	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2004.826552	algorithm design;mathematical optimization;discrete mathematics;data structure;formal verification;computer science;state space;retiming;theoretical computer science;formal equivalence checking;mathematics;sequential logic;automaton;finite-state machine;boolean function;programming language;existential quantification;algorithm	EDA	18.287431092865013	47.592351804033996	189674
b44a6cf7542ab2cea64b5e486b19c61619aa981e	bddmap: a technology mapper based on a new covering algorithm	heuristic programming;knowledge based systems;logic design;logic testing;bddmap;algorithmic techniques;benchmark results;covering algorithm;functional matching;matching of patterns;multiple output gates;rule-based heuristics;technology mapper	We present a technology mapper which combines the strengths of rule-based heuristics and algorithmic techniques. Matching is mainly performed by rule-based heuristics which is complemented by functional matching based on OBDD's. The novel aspects of the covering algorithm includes using an anticipative cost function, global cost propagation and handling of multiple output technology gates. We obtain favorable results when BDDMAP is benchmarked against the mapper of MisII, release 3.5, using a complete set of recommended MCNC examples. Topic number 4.1	algorithm;binary decision diagram;heuristic (computer science);logic programming;loss function;mapper;software propagation	David S. Kung;Robert F. Damiano;Theresa A. Nix;David J. Geiger	1992			rule-based system;mathematical optimization;logic synthesis;data structure;computer science;theoretical computer science;knowledge-based systems;machine learning;dynamic programming;pattern matching;boolean function;programming language;algorithm	EDA	17.61250789479153	48.09346982570711	189732
2053b1b58d9538361482eb11a04134004315679f	an approach to the testing of microprocessors	single stuck-at fault;machine language instruction;4-bit microprocessor;reference output;simulated single stuck-at fault;functional testing technique;hardware redundancy;small number;redundancy;logic;hardware;algorithms;describing function;registers;fault detection;functional testing	In this paper, we describe functional testing techniques for detecting single stuck-at faults in a microprocessor. These techniques appear to be practical in that a relatively small number of machine language instructions is needed in the programs which implement them, the number of reference outputs which must be stored is small, and hardware redundancy for testing purposes is not needed. The efficacy of use of these functional testing techniques has been demonstrated by applying them to the testing of a simulated 4-bit microprocessor with simulated single stuck-at faults.	4-bit;functional testing;machine code;microprocessor;redundancy (engineering);sensor	Mark G. Karpovsky;Rodney Van Meter	1984	21st Design Automation Conference Proceedings		non-regression testing;embedded system;black-box testing;electronic engineering;orthogonal array testing;white-box testing;manual testing;integration testing;computer science;theoretical computer science;describing function;functional testing;redundancy;system testing;logic;algorithm	EDA	20.736272735861263	50.40291620451006	190392
6d54b43080a82837ceffaacb4ecfc409b01ab662	template-based circuit understanding	reverse engineering combinational circuits digital circuits hardware description languages;pruning technique circuit understanding reverse engineering control inputs template based approach smt solver signature computation;integrated circuits boolean functions combinational circuits hardware design languages libraries context wires	When verifying or reverse-engineering digital circuits, one often wants to identify and understand small components in a larger system. A possible approach is to show that the sub-circuit under investigation is functionally equivalent to a reference implementation. In many cases, this task is difficult as one may not have full information about the mapping between input and output of the two circuits, or because the equivalence depends on settings of control inputs. We propose a template-based approach that automates this process. It extracts a functional description for a low-level combinational circuit by showing it to be equivalent to a reference implementation, while synthesizing an appropriate mapping of input and output signals and setting of control signals. The method relies on solving an exists/forall problem using an SMT solver, and on a pruning technique based on signature computation.	algorithm;antivirus software;benchmark (computing);bit array;combinational logic;computation;digital electronics;encode;formal equivalence checking;high- and low-level;input/output;literal (mathematical logic);logic gate;reference implementation;reverse engineering;satisfiability modulo theories;solver;turing completeness;type signature;verification and validation	Adrià Gascón;Pramod Subramanyan;Bruno Dutertre;Ashish Tiwari;Dejan Jovanovic;Sharad Malik	2014	2014 Formal Methods in Computer-Aided Design (FMCAD)	10.1109/FMCAD.2014.6987599	real-time computing;computer science;theoretical computer science;programming language;algorithm	EDA	18.738479700956198	47.932575569863424	190578
b40398bf57df74dcad8e11db1e9bfa10844eb0b2	individual signal path calibration for maximum timing accuracy in a high pincount vlsi test system				Michael Catalano;Richard K. Feldman;Roberto Krutiansky;Richard Swan	1983			computer science;electronic engineering;calibration;real-time computing;very-large-scale integration	EDA	23.914775285933594	52.70909264233084	191338
de688a32fe6769c6e0406250422d248b88954c73	fault diagnosis and repair of cutpoint cellular arrays	cutpoint cellular array fault diagnosis procedure repair stuck at l stuck at 0;stuck at l;stuck at 0;fault diagnosis procedure;cutpoint cellular array;repair;fault diagnosis	A systematic fault-diagnosis procedure to locate all the faulty main-array columns and faulty rotated-array rows is presented. A simple method for repairing a cutpoint cellular array when the rotated array is not limited to being used as a collector array is given.	column (database);fault (technology)	Stephen S. Yau;M. Orsic	1970	IEEE Transactions on Computers	10.1109/T-C.1970.222906	computer science;parallel computing;row	Visualization	23.709938383323955	50.54508804069261	191401
d22c599852316c5c7ae135cb8e167d5fb14a3753	aquila: an equivalence verifier for large sequential circuits	verification;equivalence verifier;sequential circuits data structures boolean functions flip flops signal processing explosions power dissipation circuit testing combinational circuits automatic test pattern generation;boolean functions;automatic test pattern generation;sequential circuits;flip flops;aquila;atpg based;hybrid approach;formal verification;large sequential circuits;benchmark circuit equivalence verifier aquila large sequential circuits sequential circuits bdd based atpg based partial justification verification sequential equivalence;data structures;signal processing;power dissipation;equivalent circuits;logic testing;bdd based;explosions;circuit testing;sequential equivalence;benchmark circuit;logic cad;logic cad logic testing sequential circuits formal verification equivalent circuits;flip flop;partial justification;combinational circuits	In this paper, we address the problem of verifying the equivalence of two sequential circuits. A hybrid approach that combines the advantages of BDD-based and ATPG-based approaches is introduced. Furthermore, we incorporate a technique called partial justification to explore the sequential similarity between the two circuits under verification to speed up the verification process. Compared with existing approaches, our method is much less vulnerable to the memory explosion problem, and therefore can handle larger designs. The experimental results show that in a few minutes of CPU time, our tool can verify the sequential equivalence of an intensively optimized benchmark circuit with hundreds of flip-flops against its original version.	benchmark (computing);binary decision diagram;central processing unit;flops;flip-flop (electronics);formal equivalence checking;structural similarity;tree traversal;turing completeness;verification and validation	Shi-Yu Huang;Kwang-Ting Cheng;Kuang-Chien Chen	1997		10.1109/ASPDAC.1997.600302	equivalent circuit;electronic engineering;verification;formal verification;computer science;dissipation;theoretical computer science;automatic test pattern generation;signal processing;mathematics;sequential logic;combinational logic;boolean function;programming language;algorithm	EDA	18.688843640532006	48.195702916712655	191651
3ca631a4a33469afda2ec250e12c7544a18ff78a	false-noise analysis using resolution method	logical relation;cross coupled noise injection;false noise analysis;signal generators;circuit noise;boolean functions;high performance digital circuits;resolution method;exact solution;logic circuits;transistor level description;integrated logic circuits integrated circuit noise digital integrated circuits binary decision diagrams timing circuit analysis computing switching theory;np hard problem;binary decision diagrams;digital integrated circuits;clarinet noise analysis tool;data structures;maximum realizable noise reduced order bdd high performance digital circuits cross coupled noise injection false noise analysis false noise failures elimination np hard problem resolution method clarinet noise analysis tool multi variable logic relations transistor level description characteristic robdd;multi variable logic relations;character generation;switching theory;reduced order bdd;signal resolution;circuit testing;integrated logic circuits;digital circuits;noise analysis;switches;integrated circuit noise;circuit analysis computing;false noise failures elimination;high performance;circuit noise switches data structures boolean functions circuit testing digital circuits logic circuits signal resolution character generation signal generators;characteristic robdd;timing;maximum realizable noise	High-performance digital circuits are facing increasingly severe noise problems due to cross-coupled noise injection. Traditionally, noise analysis tools use the conservative assumption that all neighbors of a net can switch simultaneously, thereby producing the worst-case noise on a net. However, due to the logic correlations in the circuit, this worst-case noise may not be realizable, resulting in a so-called false noise failure. Since the problem has been shown to be NP-hard in general [2], exact solutions to this problem are not possible. In this paper, we therefore propose a new heuristic to eliminate false noise failures based on the resolution method [16]. It is shown that multi-variable logic relations can be computed directly from a transistor level description. Based on these generated logic relations, a characteristic ROBDD for a signal net and its neighboring nets is constructed. This ROBDD is then used to determine the set of neighboring nets that result in the maximum realizable noise on the net. The proposed approach was implemented and tested on industrial circuits. The results demonstrate the effectiveness of the approach to eliminate false noise failures.	best, worst and average case;binary decision diagram;digital electronics;heuristic;np-hardness;transistor	Alexey O. Glebov;Sergey Gavrilov;David Blaauw;Vladimir Zolotov;Rajendran Panda;Chanhee Oh	2002		10.1109/ISQED.2002.996785	electronic engineering;data structure;logic gate;network switch;computer science;theoretical computer science;np-hard;mathematics;boolean function;digital electronics;algorithm;signal generator	EDA	20.18047620881022	48.61216828193596	192269
7b298cdb8a668545cdf5524937ebde85ca8dc6de	a fast algorithm for finding common multiple-vertex dominators in circuit graphs	automatic test pattern generation;circuit cad;circuit optimisation;computability;equivalent circuits;atpg;boolean function decomposition;circuit graphs;common multiple-vertex dominators;equivalence checking;power optimization;satisfiability checking;technology mapping	In this paper we present a fast algorithm for computing common multiple-vertex dominators in circuit graphs. Dominators are widely used in CAD applications such as satisfiability checking, equivalence checking, ATPG, technology mapping, decomposition of Boolean functions and power optimization. State of the art algorithms compute single-vertex dominators in linear time. However, the rare appearance of single-vertex dominators in circuit graphs requires the investigation of a broader type of dominators and the development of algorithms to compute them. We show that our new technique is faster and computes more common multiple-vertex dominators than existing techniques.	algorithm	René Krenz;Elena Dubrova	2005		10.1109/ASPDAC.2005.1466220	transaction-level modeling;discrete mathematics;computer science;theoretical computer science;algorithm	Theory	18.09448359119333	48.01124222427584	192474
a4860735d3d3d5f664a2af933d97b819e720f863	on the minimal test set for single fault location	cardinality vlsi minimal test set single fault location heuristic algorithm fault dictionary transitive closure warshall s algorithm binary matrices space complexity time complexity;time complexity;automatic testing;computational complexity fault diagnosis logic testing integrated logic circuits automatic testing digital simulation fault location matrix algebra;matrix algebra;fault location circuit faults circuit testing dictionaries fault diagnosis electrical fault detection fault detection heuristic algorithms space technology computer science;computational complexity;logic testing;space complexity;transitive closure;integrated logic circuits;digital circuits;heuristic algorithm;digital simulation;fault diagnosis;fault location	A new heuristic algorithm (based on the fault dictionary approach) that finds the minimal test set for locating single faults (of the stuck-at type) in a digital circuit, thus reducing the size of the fault dictionary, is presented. The proposed algorithm is based on finding the transitive closure of the vectors in the test set with respect to the functional dominancies using Warshall's algorithm for binary matrices. The space complexity of the proposed algorithm is O(ma. >	test set	Xiao Sun;Fabrizio Lombardi;Donatella Sciuto	1993		10.1109/EURDAC.1993.410648	heuristic;time complexity;discrete mathematics;computer science;stuck-at fault;theoretical computer science;mathematics;dspace;computational complexity theory;transitive closure;digital electronics;algorithm	EDA	20.806948606817397	49.16858550592513	192685
1b42e192ff5626ee526532f30f69ca94bbc67d89	checking signal transition graph implementability by symbolic bdd traversal	symbolic bdd traversal;binary decision diagrams data structures boolean functions asynchronous circuits signal design state space methods circuit synthesis signal synthesis explosions councils;signal flow graph;state space methods;stg implementability;boolean functions;asynchronous circuit design signal transition graph symbolic bdd traversal implementability classes restricted input output interface stg implementability symbolic approach;signal design;sequential circuits;signal flow graphs;asynchronous circuit;input output;binary decision diagrams;data structures;signal transition graph;circuit cad signal flow graphs asynchronous circuits sequential circuits logic cad;councils;implementability classes;asynchronous circuits;explosions;circuit cad;signal synthesis;symbolic approach;asynchronous circuit design;logic cad;circuit synthesis;restricted input output interface	This paper defines conditions for a Signal Transition Graph to be implemented by an asynchronous circuit. A hierarchy of the implementability classes is presented. Our main concern is the implementability of the specification under the restricted input-output interface between the design and the environment, i.e., when no additional interface signals are allowed to be added to the design. We develop algorithms and present experimental results of using BDD-traversal for checking STG implementability. These results demonstrate efficiency of the symbolic approach and show a way of improving existing tools for STG-based asynchronous circuit design.	algorithm;asynchronous circuit;circuit design;signal transition;star trek generations;tree traversal	Alex Kondratyev;Jordi Cortadella;Michael Kishinevsky;Enric Pastor;Oriol Roig;Alexandre Yakovlev	1995		10.1109/EDTC.1995.470376	electronic engineering;computer science;theoretical computer science;algorithm	EDA	19.71184983358254	47.10072559475551	192846
0c5eb20cd6f6057ad5f188e7bc248309d4f96560	transition fault simulation by parallel pattern single fault propagation			simulation;software propagation	John A. Waicukauski;Eric Lindbloom;Vijay S. Iyengar;Barry K. Rosen	1986			real-time computing;electronic engineering;fault indicator;computer science;fault (power engineering)	HPC	23.043030571989025	51.823400109519	193282
4a042ec085a84446bbd0895b9d3d1816e85c4a5f	a novel technique to reduce the metastability of bang-bang phase frequency detectors	detectors;cmos integrated circuits;automated design;topology;process variation;topology integrated circuit modeling phase locked loops detectors clocks inverters;integrated circuit;clocks;phase difference;design flow;phase frequency detector;circuit stability;inverters;metastability failure;phase lock loop;cmos process;energy function;phase locked loops;phase detectors;mutual exclusion;bang bang phase frequency detectors;failure analysis;metastable state;system on chip;digital design;integrated circuit modeling;clock synchronization;phase detectors circuit stability cmos integrated circuits failure analysis;size 65 nm metastability reduction bang bang phase frequency detectors metastability failure cmos process;phase detector;digital circuits;timing jitter;size 65 nm;metastability reduction	This paper presents a new architecture of bang-bang phase frequency detector based on standard cells. The proposed architecture presents advantages in terms of compatibility with fully-automated design flow of digital circuitry compared with other architectures. The metastability failure is also studied. The reliability of this architecture is approved by simulation results in CMOS65 nm.	bang file;design flow (eda);digital electronics;electronic circuit;metastability in electronics;phase frequency detector;sensor;simulation;standard library;transistor	Mohammad Javidan;Eldar Zianbetov;François Anceau;Dimitri Galayko;Éric Colinet;Jérôme Juillard	2011	2011 IEEE International Symposium of Circuits and Systems (ISCAS)	10.1109/ISCAS.2011.5938131	electronic engineering;real-time computing;phase-locked loop;computer science;electrical engineering;control theory	Arch	23.181654376078036	53.04898886744152	193561
ddb54cb7ee081e704f54616abb930c6647629149	towards an automatic diagnosis for high-level design validation	fault detection circuit faults hardware circuit testing fault diagnosis system testing automatic control automatic testing control systems fault location;fault simulation;automatic test pattern generation;system under test;flow graphs;high level synthesis;flow graphs fault simulation automatic test pattern generation high level synthesis;atpgs automatic diagnosis high level design validation diagnosis strategy system under test detected faults fault simulation	In this paper, we focus on high level design diagnosis. A novel diagnosis strategy is presented which allows faults to be automatically located. Given a system under test, this method effectively restricts the suspected parts in order to correct the detected faults.	high- and low-level;level design	Maisaa Khalil;Yves Le Traon;Chantal Robach	1998		10.1109/TEST.1998.743298	reliability engineering;embedded system;electronic engineering;fault;real-time computing;fault coverage;fault indicator;computer science;engineering;stuck-at fault;automatic test pattern generation;system under test;high-level synthesis	EDA	20.42594478391775	50.07585864851826	193890
70466699dc116a7c8398e874ad6be0dc4b9b4f4a	high performance dummy fill insertion with coupling and uniformity constraints	iccad 2014 contest benchmarks dummy fill insertion uniformity constraints very large scale integration deep submicron vlsi manufacturing topographic variations layout pattern uniformity wire electrical properties coupling capacitance tile based method layout storage tile based dummy fill design;layout wires couplings planning capacitance upper bound optimization;dsa;multiple patterning;decomposition;technology;moore s law;wires electric electric properties filling integrated circuit layout vlsi;directed self assembly;mp	In deep-submicron VLSI manufacturing, dummy fills are widely applied to reduce topographic variations and improve layout pattern uniformity. However, the introduction of dummy fills may impact the wire electrical properties, such as coupling capacitance. Traditional tile-based method for fill insertion usually results in very large number of fills, which increases the cost of layout storage. In advanced technology nodes, solving the tile-based dummy fill design is more and more expensive. In this paper, we propose a high performance dummy fill insertion and sizing framework, where the coupling capacitance issues and density variations are considered simultaneously. The experimental results for ICCAD 2014 contest benchmarks demonstrate the effectiveness of our methods.	circuit complexity;coupling (electronics);dummy variable (statistics);insertion sort;international conference on computer-aided design;topography;very-large-scale integration	Yibo Lin;Bei Yu;David Z. Pan	2015	2015 52nd ACM/EDAC/IEEE Design Automation Conference (DAC)	10.1145/2744769.2744850	multiple patterning;electronic engineering;computer science;engineering;electrical engineering;decomposition;engineering drawing;technology	EDA	18.750107190217147	53.22140077424678	194490
85d56c7e0fb8d776c5708a161779a9464d4162c3	cellular automata-based test pattern generators with phase shifters	phase shifters;circuit faults;test pattern generators phase shifters circuit testing built in self test automatic testing automata linear feedback shift registers circuit synthesis system testing circuit faults;linear feedback shift registers;functional properties;automatic test pattern generation;logic testing cellular automata automatic test pattern generation built in self test shift registers finite state machines integrated circuit testing phase shifters;automatic testing;simulation framework;linear feedback shift register;indexing terms;satisfiability;system on a chip;circuit complexity;automata;finite state machines;built in self test applications;built in self test;test pattern generators;phase shifter;structural properties cellular automata based test pattern generators phase shifters simulation framework maximum length linear finite state machines linear feedback shift registers channel separation circuit complexity built in self test applications functional properties;structure and function;shift registers;maximum length linear finite state machines;logic testing;integrated circuit testing;system testing;circuit testing;test pattern generator;cellular automata;channel separation;cellular automata based test pattern generators;finite state machine;circuit synthesis;structural properties	The paper presents a novel, comprehensive and systematic methodology, which can be used to automate synthesis of cellular automata-based test pattern generators with phase shifters. First, a very fast and simple simulation framework is proposed to either verify or generate maximum-length linear finite state machines such as cellular automata or linear feedback shift registers. Subsequently, a new framework is presented for efficient selection of phase shifters that satisfy criteria of channel separation and circuit complexity. As shown in the paper, it is possible to synthesize, in a time-efficient manner, very large cellular automata and their corresponding fast phase shifters for built-in self-test applications with guaranteed structural and functional properties.	automata theory;cellular automaton;test card	Grzegorz Mrugalski;Janusz Rajski;Jerzy Tyszer	2000	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.856975	system on a chip;circuit complexity;electronic engineering;index term;computer science;phase shift module;theoretical computer science;automatic test pattern generation;shift register;automaton;linear feedback shift register;finite-state machine;system testing;algorithm;satisfiability	EDA	20.226519235314594	48.058476442252505	194561
de693efe5fdb59e24a11f9bf5e02bd719f6ef971	on the compaction of test sets produced by genetic optimization	genetic engineering;distributed power generation;embedding;test compaction;circuit faults;iterations;automatic test equipment;compaction circuit faults circuit testing fault detection electrical fault detection tin genetic engineering cities and towns distributed power generation benchmark testing;genetics;iterative methods;compaction;fault detection;fault coverage test sets compaction genetic optimization embedding test set sizes iterations test generation;test generation;test set sizes;cities and towns;fault coverage;genetic algorithms;test sets compaction;circuit testing;tin;n detection test sets;benchmark testing;genetic optimization;electrical fault detection;fault diagnosis	A previously proposed test generation procedure based on genetic optimization proved to have several advantages in terms of fault coverage; however, it produced large test set sizes. We investigate a way to generate compact test sets using this procedure by embedding it into a test compaction procedure. The compaction procedure constructs a compact test set out of the best tests contained in several test sets produced by the genetic optimization based test generation procedure. Using this approach, it is possible to significantly reduce the test set sizes obtained.	data compaction;fault coverage;genetic algorithm;mathematical optimization;test set	Irith Pomeranz;Sudhakar M. Reddy	1997		10.1109/ATS.1997.643906	structural engineering;genetic engineering;reliability engineering;compaction;automatic test equipment;benchmark;electronic engineering;genetic algorithm;iteration;fault coverage;tin;computer science;engineering;test compression;embedding;iterative method;fault detection and isolation	EDA	20.964469341368282	49.72773678961754	194648
8a1387ca852664c293d03a7d2cd9c54bde9fef0e	defect analysis and a new fault model for multi-port srams	fault simulation;multiport networks;dual port;multi port;multiport networks sram chips integrated circuit testing fault simulation failure analysis;electrical fault model;failure analysis;random access memory testing read write memory design for testability microelectronics electrical capacitance tomography fabrication decoding logic arrays fault detection;sddrf;defect analysis;pattern set failure analysis electrical fault model multi port sram semiconductor memory cell defect testing resistive short transistor level model;integrated circuit testing;sram;fault model;sram chips	Semiconductor memory failures depend on the behavior of its components. This paper deals with testing of defects occurring in the memory cells of a multi-port memory. We also consider the resistive shorts between word/bit lines of same and different ports of the memory. The memory is modeled at the transistor level and analyzed for electrical defects by applying a set of patterns. Not only have existing models been taken into account in our simulation but also a new fault model for the multi-port memory is introduced. The boundaries of failure for the proposed defects are identified.	electrical engineering;fault model;semiconductor memory;simulation;software bug;static random-access memory;transistor	Pradeep Nagaraj;Shambhu Upadhaya;Kamran Zarrineh;R. Dean Adams	2001		10.1109/DFTVS.2001.966790	reliability engineering;embedded system;failure analysis;electronic engineering;semiconductor memory;parallel computing;dynamic random-access memory;static random-access memory;memory refresh;computer science;engineering;stuck-at fault;operating system;fault model	EDA	22.38713168162816	53.25220177780745	194747
d4607968431e6c2e6d952c9fbe7e650b6fcefe6f	enabling testability of fault-tolerant circuits by means of iddq-checkable voters	digital circuit;design for testability techniques;tolerancia falta;multilevel fault tolerant circuits cmos circuits i sub ddq checkable voters maskable faults design for testability techniques on line testing;design for testability;evaluation performance;fiabilidad;reliability;multivalued logic cmos digital integrated circuits logic testing fault tolerance design for testability integrated circuit testing integrated circuit reliability;performance evaluation;circuit faults;fault tolerant;on line testing;etude experimentale;on line;en linea;testabilite;evaluacion prestacion;cmos circuits;nuclear magnetic resonance;i sub ddq checkable voters;tecnologia mos complementario;testability;i ddq testing;circuit numerique;fault tolerant system;masquage;cmos digital integrated circuits;voting;enmascaramiento;fiabilite;fault detection;fault tolerance;logic testing;circuito numerico;sistema tolerando faltas;integrated circuit testing;normal operator;system testing;masking;circuit testing fault tolerance circuit faults design for testability voting nuclear magnetic resonance electrical fault detection performance evaluation digital circuits system testing;systeme tolerant les pannes;testabilidad;en ligne;conception pour test;circuit testing;integrated circuit reliability;digital circuits;majority voting;maskable faults;technologie mos complementaire;multivalued logic;estudio experimental;tolerance faute;complementary mos technology;electrical fault detection;multilevel fault tolerant circuits	The reliability of a fault-tolerant circuit may be drastically impaired by the presence of maskable faults that never affect its functionality. Design for testability (DFT) techniques have to be applied to make maskable faults detectable. During the testing phase, traditional DFT schemes inhibit fault masking and/or activate additional observation/control paths through the circuit. Such schemes, however, do not enable on-line testing and cannot be applied to multilevel fault-tolerant circuits, where fault-masking is repeatedly performed inside the circuit. We propose a new approach to the design of testable fault-tolerant CMOS circuits that overcomes both limitations. Our approach is based on the use of -checkable voters(ICVs) that enable a complete test of maskable faults of any multiplicity during normal operations.	cmos;design for testing;fault tolerance;iddq testing;online and offline;probabilistically checkable proof	Alessandro Bogliolo;Michele Favalli;Maurizio Damiani	2000	IEEE Trans. VLSI Syst.	10.1109/92.863620	embedded system;fault tolerance;electronic engineering;real-time computing;engineering;electrical engineering	EDA	23.21441597704588	49.516107486868925	194829
2e229b1cc31ac1068e0a4a08e03ef50a4a85f2cb	compositional verification of retiming and sequential optimizations	sequential circuits circuit optimisation formal verification logic design;industrial designs compositional verification retiming optimization sequential optimization sequential equivalence verification temporal equivalence sequential equivalence checker;pediatrics;logic design;clocks;sequential circuits;sequential analysis;compositional verification;design optimization;retiming optimization;formal verification;conditional equivalence;permission;registers;moon;temporal equivalence;optimization;sequential equivalence;retime offset;circuit optimisation;sequential equivalence checker;industrial designs;design optimization algorithm design and analysis logic design sequential analysis permission moon design methodology;sequential equivalence verification;equivalence checking;sequential optimization;algorithm design and analysis;retiming;retime offset compositional verification sequential equivalence conditional equivalence retiming;industrial design;design methodology;timing	Once a design is both retimed and sequentially optimized, sequential equivalence verification becomes very hard since retiming breaks the equivalence of the retimed sub-blocks although the design equivalence is preserved.  This paper presents a novel compositional algorithm to verify sequential equivalence of large designs that are not only retimed but also optimized sequentially and combinationally. With a new notion of conditional equivalence in the presence of retiming, the proposed compositional algorithm performs hierarchical verification by checking whether each sub-block is conditionally equivalent, then checking whether the conditions are justified on their parent block by temporal equivalence. This is the first compositional algorithm handling both retiming and sequential optimizations hierarchically. The proposed approach is completely automatic and orthogonal to any existing sequential equivalence checker. The experimental results show that the proposed algorithm can handle large industrial designs that cannot be verified by the existing methods on sequential equivalence checking.	algorithm;formal equivalence checking;retiming;sequential consistency;turing completeness;verification and validation	In-Ho Moon	2008	2008 45th ACM/IEEE Design Automation Conference	10.1145/1391469.1391506	algorithm design;mathematical optimization;discrete mathematics;logic synthesis;multidisciplinary design optimization;industrial design;design methods;formal verification;computer science;natural satellite;equivalence partitioning;retiming;theoretical computer science;sequential analysis;formal equivalence checking;mathematics;sequential logic;processor register;algorithm	EDA	18.38337106796981	48.768794144297004	195078
3fffdc940fc373e44c822f74c7b2db4e0ac666c0	bist hardware synthesis for rtl data paths based on testcompatibility classes	design for testability;dft technique bist hardware synthesis rtl data paths test compatibility classes built in self test methodology bist methodology register transfer level test application time reduction compatible modules test pattern generators bist area overhead reduction fault escape probability reduction signature analysis register bist hardware synthesis algorithm tabu search based testable design space exploration test scheduling algorithm hls design flow;built in self test hardware testing scheduling algorithm test pattern generators lead time reduction degradation algorithm design and analysis space exploration resource management;hardware synthesis;scheduling built in self test logic testing integrated circuit testing design for testability circuit cad high level synthesis vlsi digital integrated circuits;high level synthesis;built in self test;digital integrated circuits;scheduling;logic testing;integrated circuit testing;vlsi;test pattern generator;circuit cad	New BIST methodologyfor RTL datapathsis presented. TheproposedBIST methodology takesadvantageof thestructuralinformationof RTL datapathandreducesthetestapplication time by groupingsame-typemodulesinto testcompatibility classes(TCCs). During testing, compatiblemodulesshareasmallnumberof testpatterngeneratorsatthesametesttimeleading to significantreductionsin BIST areaoverhead,performancedegradationandtestapplication time. Moduleoutputresponsesfrom eachTCCarecheckedby comparatorsleadingto substantial reductionin fault-escapeprobability. Only asinglesignatureanalysisregisteris requiredto compressthe responsesof eachTCC which leadsto high reductionsin volumeof outputdata andoverall testapplicationtime (thesumof testapplicationtime andshifting time requiredto shift out testresponses). This papershows how theproposedTCC groupingmethodologyis a generalcaseof thetraditionalBIST embeddingmethodologyfor RTL datapathswith bothuniform andvariablebit width. A new BIST hardwaresynthesisalgorithmemploysefficient tabu search-based testabledesignspaceexplorationwhichcombinestheaccuracy of incremental test schedulingalgorithmsandthe explorationspeedof testschedulingalgorithmsbasedon fixed test resourceallocation. To illustrateTCC groupingmethodologyefficiency, variousbenchmark andcomplex hypothetical datapathshave beenevaluatedandsignificantimprovements overBIST embeddingmethodologyareachieved.	built-in self-test;tabu search	Nicola Nicolici;Bashir M. Al-Hashimi;Andrew D. Brown;Alan Christopher Williams	2000	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.892861	electronic engineering;parallel computing;real-time computing;computer science;automatic test pattern generation;operating system;test compression;design for testing;very-large-scale integration;high-level synthesis;scheduling	EDA	19.713005332693978	51.68741849712561	195121
8bc819bd3fe725aa7f7972a794ee907b76e87131	a balanced decision tree based heuristic for linear decomposition of index generation functions		Index generation functions model content-addressable memory, and are useful in virus detectors and routers. Linear decompositions yield simpler circuits that realize index generation functions. This paper proposes a balanced decision tree based heuristic to efficiently design linear decompositions for index generation functions. The proposed heuristic finds a good linear decomposition of an index generation function by using appropriate cost functions and a constraint to construct a balanced tree. Since the proposed heuristic is fast and requires a small amount of memory, it is applicable even to large index generation functions that cannot be solved in a reasonable time by existing heuristics. This paper shows time and space complexities of the proposed heuristic, and experimental results using some large examples to show its efficiency. key words: index generation functions, linear decomposition, incompletely specified functions, balanced decision tree, content-addressable memory, logic design, heuristic	content-addressable memory;decision tree;heuristic (computer science);router (computing);self-balancing binary search tree;sensor	Shinobu Nagayama;Tsutomu Sasao;Jon T. Butler	2017	IEICE Transactions		content-addressable memory;logic synthesis;computer science;decision tree;theoretical computer science;heuristic	EDA	18.175863172863643	46.64144844347036	195135
6ef274eb5c86b11f0421b471b7c8862894d7c449	improvements to satisfiability-based boolean function bi-decomposition	boolean functions data structures central processing unit phasor measurement units input variables integrated circuit modeling;boolean functions;input variables;computability;bi decomposition;satisfiability;group oriented mus;logic synthesis;computability boolean functions;data structures;integrated circuit modeling;mus;group oriented muses satisfiability based boolean function bidecomposition logic synthesis boolean satisfiability minimally unsatisfiable subformula structural properties;phasor measurement units;central processing unit	Boolean function bi-decomposition is pervasive in logic synthesis. Bi-decomposition entails the decomposition of a Boolean function into two other functions connected by a simple two-input gate. Existing solutions are based on Binary Decision Diagrams (BDDs) and, more recently, on Boolean Satisfiability (SAT). Recent work exploited the identification of Minimally Unsatisfiable Subformulas (MUSes) for computing the sets of variables to use in Boolean function bi-decomposition. This paper develops new techniques for improving the use of MUSes in function bi-decomposition. The first technique exploits structural properties of the function being decomposed, whereas the second technique exploits group-oriented MUSes. Experimental results obtained on representative benchmarks from logic synthesis demonstrate significant improvements both in performance and in the quality of decompositions.	algorithm;binary decision diagram;boolean satisfiability problem;emoticon;functional testing;heuristic (computer science);logic synthesis;minimally invasive education;quality of results	Huan Chen;Joao Marques-Silva	2011		10.1109/VLSISoC.2011.6081636	boolean algebra;boolean circuit;and-inverter graph;circuit minimization for boolean functions;discrete mathematics;reed–muller expansion;boolean network;boolean domain;boolean expression;product term;standard boolean model;#sat;maximum satisfiability problem;theoretical computer science;karp–lipton theorem;mathematics;combinational logic;boolean function;boolean satisfiability problem;binary decision diagram;algorithm;two-element boolean algebra;parity function	EDA	17.896578892784323	47.92605336803996	195192
c452a2121279de48e6456f097a1c5562dffaae7f	scan cell ordering for low power bist	boundary scan testing;built in self test bist power dissipation transition frequency scan cell ordering pseudorandom scan;integrated circuit design;built in self test;low power;power dissipation;logic testing;low power electronics;built in self test very large scale integration computer society;low power electronics logic testing built in self test boundary scan testing integrated circuit design	Power dissipation during scan-based testing has gained significant importance in the past few years. In this work we examine the use of transition frequency based on scan cell ordering techniques in pseudorandom scan based BIST in order to reduce average power dissipation. We also propose the resetting of the input register of the circuit together with ordering of its elements to further reduce average power dissipation. Experimental results indicate that the proposed techniques can reduce average power dissipation up to 57.7%.	built-in self-test;cpu power dissipation;pseudorandomness	Maciej Bellos;Dimitris Bakalis;Dimitris Nikolos	2004	IEEE Computer Society Annual Symposium on VLSI	10.1109/ISVLSI.2004.1339558	electronic engineering;scan chain;real-time computing;boundary scan;engineering;electrical engineering	Arch	20.154384978208817	53.19993690282703	195576
433876036404baee61bbeb4a3eeefd5c1c5c791d	a new maximal diagnosis algorithm for bus-structured systems	decision support systems;system on a chip;system testing;integrable system;chip;fault detection	Complex interconnects in highly integrated system chips are implemented with the bus structure. From testing point of view, the bus structure system needs more complicated consideration than simple wiring networks since a bus line is received data from many drivers. Therefore, some faults are detected all the time and others are detected only at the particular time. We propose a new interconnect test algorithm for the bus structure. The MD+ algorithm supports maximal diagnosis for the busstructured system and its test period is shorter than the previous algorithms. Moreover, the MD+ algorithm is easy to apply since it is based on the complete diagnosis algorithm for wiring networks. The effectiveness of the MD+ algorithm is confirmed by comparing the test length with previous bus based interconnect test algorithms.	download;electrical connection;genetic algorithm;maximal set;medical algorithm;point of view (computer hardware company);wiring	YongJoon Kim;DongSub Song;YongSeung Shin;Sunghoon Chun;Sungho Kang	2003		10.1109/TEST.2003.1270857	chip;system on a chip;embedded system;integrable system;electronic engineering;real-time computing;decision support system;telecommunications;computer science;engineering;system testing;fault detection and isolation	EDA	21.864401849782617	51.76128363429293	195842
c22c528f06ba45ff56e7c6cff99fdf97726a774d	managing contamination delay to improve timing speculation architectures		Timing Speculation (TS) is a widely known method for realizing better-than-worst-case systems. Aggressive clocking, realizable by TS, enable systems to operate beyond specified safe frequency limits to effectively exploit the data dependent circuit delay. However, the range of aggressive clocking for performance enhancement under TS is restricted by short paths. In this paper, we show that increasing the lengths of short paths of the circuit increases the effectiveness of TS, leading to performance improvement. Also, we propose an algorithm to efficiently add delay buffers to selected short paths while keeping down the area penalty. We present our algorithm results for ISCAS-85 suite and show that it is possible to increase the circuit contamination delay by up to 30% without affecting the propagation delay. We also explore the possibility of increasing short path delays further by relaxing the constraint on propagation delay and analyze the performance impact.	contamination delay	Naga Durga Prasad Avirneni;Prem Kumar Ramesh;Arun K. Somani	2015	PeerJ PrePrints	10.7287/peerj.preprints.1412v1	speculation;overclocking;paleontology;control theory;propagation delay;performance improvement;elmore delay;real-time computing;contamination delay;exploit;biology	EDA	18.397378573743236	52.103702787486945	196037
d836a36a90af9dbeca1fefe4d3f147cd24bd229a	a new method to compute correlation functions (abstr.)	counting circuits correlators random processes computer networks concurrent computing writing bars sampling methods frequency logic circuits;concurrent computing;correlation functions;logic circuits;correlators;computer networks;counting circuits;random processes;correlation function;writing;sampling methods;frequency;bars			Paul G. A. Jespers;Pe Tsi Chu;Alfred Fettweis	1962	IRE Trans. Information Theory	10.1109/TIT.1962.1057768	sampling;discrete mathematics;concurrent computing;logic gate;computer science;theoretical computer science;frequency;mathematics;correlation function;writing	Crypto	22.29953822534709	48.268550971086384	196242
4fe5f4ab03b4e585081188281424cad148827983	scan-bist based on transition probabilities	circuit faults;fault tolerant;circuit testing circuit faults fault detection logic testing electrical fault detection benchmark testing flip flops automatic testing fault tolerance built in self test;transition probability;automatic testing;flip flops;pattern generation;scan design;built in self test;fault detection;fault tolerance;logic testing;built in test;circuit testing;benchmark testing;electrical fault detection	We demonstrate that it is possible to generate a deterministic test set that detects all the detectable single stuck-at faults in a full-scan circuit such that each test contains a small number of transitions from 0 to 1 or from 1 to 0 when considering consecutive input values. Using this result we show that built-in test-pattern generation for scan circuits can be based on transition probabilities instead of probabilities of specific bits in the test set being 0 or 1. The resulting approach associates only two parameters with every set of test vectors: an initial value and a transition probability. We demonstrate that this approach is effective in detecting all the detectable single stuck-at faults in benchmark circuits.	benchmark (computing);built-in self-test;markov chain;sensor;test set	Irith Pomeranz	2004	Proceedings. 41st Design Automation Conference, 2004.	10.1145/996566.996815	reliability engineering;fault tolerance;electronic engineering;real-time computing;computer science;engineering	EDA	21.53976259503013	51.369633072516066	196703
354a6132766717f0f5850f79b9ab109e979f0a15	intermittent scan chain fault diagnosis based on signal probability analysis	chain fault;scan-based design;signal probability analysis;fault site;large industrial design;new algorithm;intermittent scan chain fault;proposed diagnosis algorithm;industrial design;cores;bandwidth;probability;routing	A new algorithm to diagnose intermittent scan chain fault in scan-based designs is proposed in this paper. An intermittent scan chain fault sometimes is triggered and sometimes is not triggered during scan chain shifting, which makes it very difficult to locate the fault sites. In this paper, we provide answers to three questions:(1) Why intermittent scan chain faults happen?(2) Why diagnosis of this type of faults is necessary?(3) How to diagnose this type of faults?The experimental results presented demonstrate that the proposed diagnosis algorithm is effective for large industrial designs with multiple intermittent scan chain faults.	heuristic;medical algorithm	Yu Huang;Wu-Tung Cheng;Cheng-Ju Hsieh;Huan-Yung Tseng;Alou Huang;Yu-Ting Hung	2004	Proceedings Design, Automation and Test in Europe Conference and Exhibition		multi-core processor;embedded system;routing;electronic engineering;scan chain;real-time computing;industrial design;computer science;engineering;probability;bandwidth;statistics	EDA	21.397780923249197	51.736033717103226	196832
341709adf863ae4976d43bf2eeb3300f3b64fe41	multiple error diagnosis based on xlists	error location;analytical models;logic simulation;error models;large circuits;image processing;circuit faults;fpga;runtime;multiple error diagnosis algorithms;error analysis;circuit simulation;reconfigurable architecture;error location multiple error diagnosis algorithms xlists large circuits nonenumerative analysis technique logic simulation error models;model error;permission;error correction;logic testing;nonenumerative analysis technique;error diagnosis;computer science;circuit analysis computing;xlists;logic testing fault diagnosis logic simulation error analysis circuit analysis computing;computer errors;circuit synthesis;circuit simulation error correction computer errors analytical models runtime circuit synthesis permission circuit faults laboratories computer science;fault diagnosis	In this paper, we present multipleerror diagnosis algorithms to overcome two significant problems associated with current error diagnosis techniques targeting large circuits: their use of limited error models and a lack of solutions that scale well for multiple errors. Our solution is based on a nonenumerative analysis technique, based on logic simulation (3-valued and symbolic), for simultaneously analyzing all possible errors at setsof nodes in the circuit. Error models are introduced in order to address the “locality” aspect of error location and to identify sets of nodes that are “local” with respect to each other. Theoretical results are provided to guarantee the diagnosis of modeled errors and robust diagnosis approaches are shown to address the cases when errors do not correspond to the modeled types. Experimental results on benchmark circuits demonstrate accurate and extremely rapid location of errors of large multiplicity.	algorithm;benchmark (computing);locality of reference;logic simulation	Vamsi Boppana;Rajarshi Mukherjee;Jawahar Jain;Masahiro Fujita;Pradeep Bollineni	1999		10.1145/309847.310021	embedded system;electronic engineering;non-sampling error;real-time computing;error detection and correction;image processing;computer science;theoretical computer science;logic simulation;errors-in-variables models;algorithm;field-programmable gate array;statistics	EDA	20.334332951466912	49.55823555813175	197232
e3a7aafa0eac3530a68f47eb24b4ee86aec5efb3	a new method for partial scan design based on propagation and justification requirements of faults	design for testability;automatic testing;sequential circuits;flip flops;integrated circuit testing design for testability flip flops logic testing sequential circuits automatic testing;fault efficiency partial scan design propagation requirements justification requirements flip flops aborted faults combinational test generation optimal procedures heuristic procedures bellona program;logic testing;integrated circuit testing;test generation;flip flop;circuit faults circuit testing flip flops sequential analysis electrical fault detection feedback loop feedback circuits fault diagnosis fault detection system testing	Scan design can be viewed as scanning ,flip-flops, so that faults, otherwise aborted, are detected by meeting propagation and justification requirements. In this paper, we propose a new method which identifies justification and propagation requirements of aborted faults through combinational test generation and selects flip-flops to meet the requirements. Two procedures, optimal and heuristic, were considered in the process. We implemented the heuristic procedure in a program called BELLONA. BELLONA selects flip-flops progressively to lead to high fault efficiency. Our experimental results show that BELLONA achieves 100% fault efficiency for all circuits experimented with, on average, 19% offlip-jlops selected.	combinational logic;flops;flip-flop (electronics);heuristic;requirement;software propagation	Insung Park;Dong Sam Ha;Gyoochan Sim	1995		10.1109/TEST.1995.529867	reliability engineering;electronic engineering;real-time computing;engineering;design for testing;sequential logic	EDA	21.53608158790846	51.088697005029374	197269
6858e5133bbcce597a13632bfa7b5bba5e2ce029	capsule reviews	 control methods; and search;process management;problem solving;general	Analysis and Detection of Errors in Implementation of SHA-512 Algorithms on FPGAs. I. AHMAD AND A.S. DAS Hash functions have a number of useful applications and advantages. In particular, the secure Hash Algorithm SHA-512 is widely used in real applications and in essential security services, and makes concurrent error detection (CED) extremely important. This paper analyses the propagation of single and multiple errors occurring at different operations of a digest round in the hardware implementation of SHA-512. First, the SHA-512 algorithm is discussed in detail and so is the propagation of error in SHA-512 including the error analysis of a digest round and a block round and those representing single, transient and permanent faults at all stages of hash value computation. Then, the method of predicting and checking parity bits for each performed operation is discussed where the paper proposes a parity scheme and error detection techniques and carries out a number of experimental results testing different types of expected errors. These tests show good results for the fault coverage.	algorithm;computation;cryptographic hash function;error analysis (mathematics);error detection and correction;fault coverage;field-programmable gate array;parity bit;propagation of uncertainty;sha-2;software propagation	Fairouz Kamareddine	2005	Comput. J.	10.1093/comjnl/bxh137		PL	22.961199856990312	49.09622476328062	198159
1f95878b7b43749eb74ca509a1faddf9e591faaf	addressing useless test data in core-based system-on-a-chip test	system testing system on a chip circuit testing automatic testing costs computer science algorithm design and analysis partitioning algorithms test equipment memory management;memory management;test access mechanism;automatic testing;system on a chip;boundary scan testing;system on chip;logic testing;integrated circuit testing;automated test equipment;production testing;wrapper scan chains useless test data core based system on a chip test test memory requirements padding bits chains multiple scan chain designs test bus width multiple scan chain based cores test access mechanism test time test data test methodology;logic testing integrated circuit testing system on chip boundary scan testing production testing automatic testing	This paper analyzes the test memory requirements for core-based systems-on-a-chips and identifies useless test data as one of the contributors to the total amount of test data. The useless test data comprises the padding bits necessary to compensate for the difference between the lengths of different chains in multiple scan chains designs. Although useless test data does not represent any relevant test information, it is often unavoidable, and it leads to the trade-off between the test bus width and the volume of test data in multiple scan chains-based cores. Ultimately this trade-off influences the test access mechanism design algorithms leading to solutions that have either short test time or low volume of test data. Therefore, in this paper, a novel test methodology is proposed, which by dividing the wrapper scan chains into two or more partitions, and by exploiting automated test equipment memory management features reduces the useless memory. Extensive experimental results using ISCAS89 and ITC02 benchmark circuits are provided to analyze the implications of the number of wrapper scan chains in the partition, and the number of partitions on the proposed methodology.	algorithm;apple multiple scan 14 display;benchmark (computing);built-in test equipment;data compression;memory management;requirement;system on a chip;test automation;test data	Paul Theo Gonciari;Bashir M. Al-Hashimi;Nicola Nicolici	2003	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/TCAD.2003.818376	system on a chip;keyword-driven testing;embedded system;automatic test equipment;scan chain;parallel computing;real-time computing;model-based testing;boundary scan;white-box testing;computer hardware;integration testing;computer science;automatic test pattern generation;test compression;test harness	EDA	19.98066696916458	52.56706976362965	198204
f828261d2b8f9fa45baa4bb60b221caa4598e33d	a static noise impact analysis methodology for evaluating transient error effects in digital vlsi circuits	sequential elements;digital vlsi circuits;hspice simulation;very large scale integration;error resiliency;circuit design;circuit noise transient analysis very large scale integration semiconductor device noise protection circuit simulation circuit analysis electromagnetic transients working environment noise computer errors;matrix algebra;circuit noise interaction;transient noise;matrices;impact analysis;digital integrated circuits;circuit failure rate;fault tolerance;matrix transformations;vlsi;static noise impact analysis methodology;error resilience;cost effectiveness;failure rate;reliability analysis;vlsi digital integrated circuits fault tolerance integrated circuit noise integrated circuit reliability matrix algebra;nanometer circuit;circuit vulnerability;masking effects;single event upset;integrated circuit reliability;integrated circuit noise;nanometer circuit static noise impact analysis methodology transient error effects digital vlsi circuits circuit vulnerability circuit elements transient noise circuit noise interaction matrix transformations masking effects error resiliency sequential elements circuit failure rate hspice simulation;circuit elements;transient error effects	"""Single-event-upset (SEU) has become a great threat to the reliability of nanometer circuits. The need for cost-effective robust circuit design mandates the development of efficient reliability analysis. In this paper, a static """"noise impact analysis"""" methodology is developed to estimate the circuit vulnerability. First, both the circuit elements and the transient noise are abstracted in the format of matrices. Then the circuit-noise interaction is modeled by a series of matrix transformations, which jointly considers three masking effects that can potentially prevent transient noise from causing observable errors. Finally, the error-resiliency of the sequential elements is considered in determining the impact of transient noise on the circuit. Experiment results demonstrate that our technique can accurately yet quickly estimate the circuit failure rate by comparing with HSPICE simulation. The proposed methodology has greatly facilitate the economic design of robust nanometer circuit"""	circuit design;digital electronics;failure rate;observable;robustness (computer science);spice 2;sequential logic;simulation;single event upset;transformation matrix;transient noise	Chong Zhao;Xiaoliang Bai;Sujit Dey	2005	IEEE International Conference on Test, 2005.	10.1109/TEST.2005.1584071	equivalent circuit;electronic engineering;real-time computing;computer science;engineering;electrical engineering;very-large-scale integration;circuit extraction	EDA	23.981351904578222	52.359773022534576	198284
e9cd755b1f413c06f8b67c5c02685a37abf1b9ae	fault-diagnosis-based technique for establishing rtl and gate-levelcorrespondences	gate level synthesis;circuit diagnosis engine;circuit faults;rtl synthesis;signal design;indexing terms;fault diagnosis high level synthesis;signal correspondence;high level synthesis;incremental synthesis;signal correspondence fault diagnosis incremental synthesis rtl synthesis circuit diagnosis engine gate level synthesis hierarchical design flow mapping problem;formal verification;engines;signal processing;signal mapping;robustness;signal synthesis;hierarchical design;mapping problem;register transfer level;hierarchical design flow;signal synthesis circuit faults engines signal design signal mapping formal verification signal processing circuit synthesis robustness fault diagnosis;circuit synthesis;fault diagnosis;industrial design	In this paper, we address an important problem associated with hierarchical design flows (termed the mapping problem): identifying correspondences between a signal in a high-level specification and a net in its lower level implementation. Conventional techniques use shared names to associate a signal with a net whenever possible. However, given that a synthesis flow may not preserve names, such a solution is not universally applicable. This work provides a robust framework for establishing register-transfer level (RTL) signal to gate-level net correspondences for a given design. Our technique exploits the observation that circuit diagnosis provides a convenient means for locating faults in a gate-level network. Since our problem requires locating gate-level nets corresponding to RTL signals, we formulate the mapping problem as a query whose solution is provided by a circuit diagnosis engine. Our experimental work with industrial designs for many mapping cases shows that our solution to the mapping problem is 1) fast and 2) precise in identifying the gate-level equivalents (the number of nets returned by our mapping engine for a query is typically one or two even for designs with tens of thousands of VHDL lines).	and gate;high- and low-level;register-transfer level;vhdl	Srivaths Ravi;Indradeep Ghosh;Vamsi Boppana;Niraj K. Jha	2001	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.969435	embedded system;electronic engineering;real-time computing;industrial design;index term;formal verification;computer science;theoretical computer science;signal processing;high-level synthesis;programming language;register-transfer level;robustness	EDA	18.87841314774724	48.167253114513144	198671
253a91668ff0e5a8f6379e0e39ae828f98ebd97f	on the optimization power of retiming and resynthesis transformations	optimization power;resynthesis transformation;graph theory;sequential circuits;binary decision diagram	Retiming and resynthesis transformations can be used for op- timizing the area, power, and delay of sequential circuits. Even though this technique has been known for more than a decade, its exact optimization capability has not been for- mally established. We show that retiming and resynthe- sis can exactly implement 1-step equivalent state transition graph transformations. This result is the strongest to date. We also show how the notions of retiming and resynthe- sis can be moderately extended to achieve more powerful state transition graph transformations. Our work will provide theoretical foundation for practical retiming and resynthesis based optimization and verification.	mathematical optimization;retiming	Rajeev K. Ranjan;Vigyan Singhal;Fabio Somenzi;Robert K. Brayton	1998		10.1109/ICCAD.1998.742904	real-time computing;graph theory;retiming;theoretical computer science;mathematics;binary decision diagram;logic;algorithm;encoding	EDA	17.902573542877708	47.80749638111892	198792
74140904bcb82d182f45e71130711d73595df3bc	exhaustive simulation need not require an exponential number of tests	verification;concepcion asistida;digital simulation circuit analysis computing;computer aided design;conception ordinateur;integrated circuit;etude theorique;computational modeling circuit simulation hardware design automation circuit testing;analisis estructural;simulation;simulacion;circuito integrado;test;ensayo;concepcion ordenador;essai;test case generation;exhaustive simulation verification complete coverage test case generation structural analysis;estudio teorico;conception assistee;computer design;verificacion;theoretical study;analyse structurale;circuit analysis computing;structural analysis;circuit integre;digital simulation;structure analysis	Simulation is today the most common form of verification. One disadvantage of simulation is the excessive number of tests needed for complete coverage. However, as will be shown, the number of tests may be substantially reduced if test case generation is combined with a structural analysis. The resulting set of test cases for exhaustive simulation may be smaller than exponential, which might make exhaustive simulation feasible. Even if the set of test cases is still too large, choosing tests from this reduced set results in better coverage than otherwise. >	simulation;time complexity	Daniel Brand	1993	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.248074	simulation;engineering;computer aided design;structural analysis;algorithm	EDA	23.576652536518147	48.135737736678344	199004
4bc3a28b8abe19f4f0c545c2f87816c3a68de822	implementation by the special formula of an arbitrary subset of code words of (m, n)-code for designing a self-testing checker	computers;self checking circuit;field programmable gate array;circuit faults;integrated circuit;n code;circuit faults built in self test field programmable gate arrays single event upset computers integrated circuit reliability;m;built in self test;program testing;cardinal numbers special formula arbitrary subset code words self testing checker design number representation;self testing checker;self testing checker self checking circuit m n code;single event upset;field programmable gate arrays;integrated circuit reliability	The problem of synthesis of the self-testing checker for arbitrary l code words of (m, n)-code is considered. In particular, the problem of representation of number l by the sum of cardinal numbers of subsets of the code words corresponding to essential subtrees of the tree representing all code words of (m, n)-code is investigated. The properties such essential subtries are described.	code word;tree (data structure)	Natalia Butorina;Sergey Ostanin	2011	2011 9th East-West Design & Test Symposium (EWDTS)	10.1109/EWDTS.2011.6116599	polynomial code;electronic engineering;computer science;self-synchronizing code;theoretical computer science;algorithm	Logic	22.009827618570704	48.42635074328108	199053
