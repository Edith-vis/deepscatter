id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
31b9839a140a87ce930895c3debc346769c4c75d	a distributed agent-based approach for simulation-based optimization	computational steering;non standard optimization;agent based optimization;simulation based optimization	Structural design and optimization in engineering are increasingly addressing non-standard optimization problems (NSPs). These problems are characterized by a complex topology of the optimization space with respect to nonlinearity, multimodality, discontinuity, etc. By that, NSP can only be solved by means of computer simulations. In addition, the corresponding numerical approaches applied often tend to be noisy. Typical examples for NSP occur in robust optimization, where the solution has to be robust with respect to implementation errors, production tolerances or uncertain environmental conditions. However, a generally applicable strategy for solving such problem categories always equally efficiently is not yet available. To improve the situation, a distributed agent-based optimization approach for solving NSPs is introduced in this paper. The elaborated approach consists of a network of cooperating but also competing strategy agents that wrap various strategies, especially optimization methods (e.g. SQP, DE, ES, PSO, etc.) using different search characteristics. In particular, the strategy agents contain an expert system modeling their specific behavior in an optimization environment by means of rules and facts on a highly abstract level. Further, different common interaction patterns have been defined to describe the structure of a strategy network and its interactions. For managing the complexity of NSPs using multi-agent systems (MASs) efficiently, a simulation and experimentation platform has been developed. Serving as a computational steering tool, it applies MAS technology and accesses a network of various optimization strategies. As a consequence, an elegant interactive steering, a customized modeling and a powerful visualization of structural optimization processes are established. To demonstrate the far reaching applicability of the proposed approach, numerical examples are discussed, including nonlinear function and robust optimization problems. The results of the numerical experiments illustrate the potential of the agent-based strategy network approach for collaborative solving, where observed synergy effects lead to an effective and efficient solution finding.	agent-based model;mathematical optimization;simulation-based optimization	Van Vinh Nguyen;Dietrich Hartmann;Markus König	2012	Advanced Engineering Informatics	10.1016/j.aei.2012.06.001	stochastic programming;probabilistic-based design optimization;optimization problem;mathematical optimization;multi-swarm optimization;topology optimization;engineering optimization;simulation;test functions for optimization;meta-optimization;engineering;derivative-free optimization;artificial intelligence;stochastic optimization;multi-objective optimization;machine learning;management science;metaheuristic;global optimization	AI	21.81545515500815	-4.795359486610859	146569
8b41b5605453ca522e7caeccb0b83c5040bed8bf	two-b or not two-b?: design patterns for hybrid metaheuristics	metaheuristics;blackboard architecture;design patterns	Real world search problems, characterised by nonlinearity, noise and multidimensionality, are often best solved by hybrid algorithms. Techniques embodying different necessary features are triggered at specific iterations, in response to the current state of the problem space. In the existing literature, this alternation is managed either statically (through pre-programmed policies) or dynamically, at the cost of high coupling with algorithm inner representation. We extract two design patterns for hybrid metaheuristic search algorithms, the All-Seeing Eye and the Commentator patterns, which we argue should be replaced by the more flexible and loosely coupled Simple Black Box (Two-B) and Utility-based Black Box (Three-B) patterns that we propose here. We recommend the Two-B pattern for purely fitness based hybridisations and the Three-B pattern for more generic search quality evaluation based hybridisations.	black box;design pattern;hybrid algorithm;iteration;loose coupling;metaheuristic;nonlinear system;problem domain;search algorithm	Alina Patelli;Nelly Bencomo;Anikó Ekárt;Harry Goldingay;Peter R. Lewis	2015		10.1145/2739482.2768501	simulation;engineering;artificial intelligence;algorithm	ML	21.179864933515468	-5.387658081105728	146630
37fa64165a30e004cdcde43f7620a5842eeb4a0b	clustering based on sequential multi-objective games		We propose a novel approach for data clustering based on sequential multi-objective multi-act games (ClusSMOG). It automatically determines the number of clusters and optimises simultaneously the inertia and the connectivity objectives. The approach consists of three structured steps. The first step identifies initial clusters and calculates a set of conflict-clusters. In the second step, for each conflict-cluster, we construct a sequence of multi-objective multiact sequential two-player games. In the third step, we develop a sequential twoplayer game between each cluster representative and its nearest neighbour. For each game, payoff functions corresponding to the objectives were defined. We use a backward induction method to calculate Nash equilibrium for each game. Experimental results confirm the effectiveness of the proposed approach over state-of-the-art clustering algorithms.	algorithm;backward induction;benchmark (computing);cluster analysis;computer cluster;concurrent computing;experiment;fairness measure;game theory;nash equilibrium;parallel computing	Imen Heloulou;Mohammed Said Radjef;M. Tahar Kechadi	2014		10.1007/978-3-319-10160-6_33	brown clustering	AI	17.988761828056212	-8.463928400415716	146741
010a5eef34299122bc5002a6f02006cc2a98e658	cooperative and decomposable approaches on royal road functions: overcoming the random mutation hill-climber	royal road;gene fragment competition;parisian approach;hitchhiking	Traditionally, evolutionary algorithms (EAs) encode each individual as a possible solution to the whole problem. As a natural extension to standard EAs, problem decomposition emerged for addressing complex problems. Although many problem decomposition methods rely on dividing the main problem in several less complex sub-problems, launching independent populations (species) to solve each of them, there are also other problem decomposition approaches that require a single population. Parisian approach [1] (often called Individual Evolution) and Gene Fragment Competition (GFC) [5] are two single-population problem decomposition approaches, where the problem can be decomposed in smaller sub-problems, so that they can be evaluated individually reducing the size of the search space. In order to evaluate both Parisian approach and Gene Fragment Competion on problem solving, we aim to use the so called Royal Road functions [3]. We take advantage of the modular and hierarchical structure of the Royal Road test functions to adapt them to both Individual Evolution and Gene Fragment Competition. It is our claim that these functions may serve in the theoretical studies of singlepopulation problem decomposable approaches, such as the Parisian and Gene Fragment Competition, since the landscape can be varied in a number of ways, and the global optimum and all possible fitness values are known in advance. Besides presenting a comparison between a standard genetic algorithm and both Individual Evolution and Gene Fragment Competion on several instances of the Royal Road functions, it is also presented a comparison between these single-population problem decomposition approaches and the results of a previous study made by Ochoa et al. about multi-population co-evolutionary approaches to the same Royal Road functions [4]. One final comparison was	climber (beam);distribution (mathematics);encode;evolutionary algorithm;genetic algorithm;global optimization;population;problem solving	Gustavo Reis;Francisco Fernández;Gustavo Olague	2009		10.1145/1569901.1570211	mathematical optimization;geometry;hill climbing;computer science;rod	AI	24.273880739583557	-3.0575285003836736	147089
8b069a41bbd5c4bdb35b9154b54f73355739b373	a biologically inspired modified flower pollination algorithm for solving economic dispatch problems in modern power systems	modified flower pollination algorithm (mfpa);intensive exploitation phase;biologically inspired (bi) techniques;lévy flight;ramp rate limits (rrl);prohibited operating zones (poz);valve point loading (vpl) effects	Gradient-based traditional algorithms fail to locate optimal solutions for real-world problems with non-differentiable/discontinuous objective functions. But biologically inspired optimization algorithms, due to their unconventional random search capability, provide good solutions within finite time to multimodal and non-convex problems. The search capability of these methods largely depends on their exploration and exploitation potential. This paper presents a modified flower pollination algorithm (MFPA) in which (1) the local pollination of FPA is controlled by a scaling factor and (2) an intensive exploitation phase is added to tune the best solution. The effectiveness of MFPA is tested on some mathematical benchmarks and four large practical power system test cases.	algorithm;benchmark (computing);brute-force search;computation;cuckoo search;dynamic dispatch;global storage architecture;gradient;ibm power systems;image scaling;list of metaphor-based metaheuristics;mathematical optimization;microwave;multimodal interaction;random search;system testing;test case;time complexity	Hari Mohan Dubey;Manjaree Pandit;Bijaya Ketan Panigrahi	2015	Cognitive Computation	10.1007/s12559-015-9324-1	mathematical optimization;simulation;artificial intelligence	AI	19.546334916836308	-3.9803282253688215	147261
2b9bf8668a52be78a23b570a64fe9956819f8ba1	topologies and performance of intelligent algorithms: a comprehensive review	optimization;intelligent algorithms;review	Recently, optimization makes an important role in our day-to-day life. Evolutionary and population-based optimization algorithms are widely employed in several of engineering areas. The design of an optimization algorithm is a challenging endeavor caused of physical phenomena in order to obtain appropriate local and global search operators. Generally, local operators are fast. In contrast, global operators are used to find best solution in the search space; therefore they are slower compare to the local ones. The best review-knowledge of papers show that there are many optimization algorithms such as genetic algorithm, particle swarm optimization, artificial bee colony and etc in the engineering as a powerful tools. However, there is not a comprehensive review for theirs topologies and performance; therefore, the main goal of this paper is filling of this scientific gap. Moreover, several aspects of optimization heuristic designs and analysis are discussed in this paper. As a result, detailed explanation, comparison, and discussion on AI are achieved. Furthermore, some future research fields on AI are well summarized.	artificial bee colony algorithm;artificial neural network;chaos theory;computational complexity theory;computer performance;engineering design process;genetic algorithm;heuristic;mathematical optimization;optimization problem;particle swarm optimization;real-time clock;robust optimization;scheduling (computing)	Armin Nabaei;Melika Hamian;Mohammad Reza Parsaei;Reza Safdari;Taha Samad-Soltani;Houman Zarrabi;A. Ghassemi	2016	Artificial Intelligence Review	10.1007/s10462-016-9517-3	multi-swarm optimization;engineering optimization;simulation;test functions for optimization;meta-optimization;computer science;artificial intelligence;machine learning;management science;metaheuristic	AI	22.392378643192227	-5.118753762522254	147297
1ad44b17207b0fe446cdc4292ebf1f4639a87471	the challenge of irrationality: fractal protein recipes for pi	computational development;evolutionary computation;approximate algorithm;irrational numbers;pattern;data type;fractal proteins;pi;evolutionary computing	Computational development traditionally focuses on the use of an iterative, generative mapping process from genotype to phenotype in order to obtain complex phenotypes which comprise regularity, repetition and module reuse. This work examines whether an evolutionary computational developmental algorithm is capable of producing a phenotype with no known pattern at all: the irrational number PI. The paper summarizes the fractal protein algorithm, provides a new analysis of how fractals are exploited by the developmental process, then presents experiments, results and analysis showing that evolution is capable of producing an approximate algorithm for PI that goes beyond the limits of precision of the data types used.	approximation algorithm;computation;experiment;fractal;iteration	Jean Krohn;Peter J. Bentley;Hooman Shayani	2009		10.1145/1569901.1570000	mathematical optimization;combinatorics;data type;computer science;artificial intelligence;pi;machine learning;mathematics;pattern;algorithm;evolutionary computation	Comp.	23.094127998054937	-8.246406634106892	147464
8a9cf1cca7788f85cdec10f616ef17d5f9ba3676	mining probabilistic models learned by edas in the optimization of multi-objective problems	joomla;problem structure;satisfiability;data mining;probabilistic model;visualization;estimation of distribution algorithm;visualization technique;probabilistic modeling;estimation of distribution algorithms;multi objective optimization problem	One of the uses of the probabilistic models learned by estimation of distribution algorithms is to reveal previous unknown information about the problem structure. In this paper we investigate the mapping between the problem structure and the dependencies captured in the probabilistic models learned by EDAs for a set of multi-objective satisfiability problems. We present and discuss the application of different data mining and visualization techniques for processing and visualizing relevant information from the structure of the learned probabilistic models. We show that also in the case of multi-objective optimization problems, some features of the original problem structure can be translated to the probabilistic models and unveiled by using algorithms that mine the model structures.	data mining;estimation of distribution algorithm;mathematical optimization;multi-objective optimization	Roberto Santana;Concha Bielza;José Antonio Lozano;Pedro Larrañaga	2009		10.1145/1569901.1569963	probabilistic-based design optimization;mathematical optimization;probabilistic analysis of algorithms;probabilistic ctl;estimation of distribution algorithm;probabilistic relevance model;computer science;artificial intelligence;machine learning;data mining;divergence-from-randomness model	ML	22.693951827408718	-8.558550216973728	148112
346eb0974c11853f43bd72b27870446507b51dea	on integrating population-based metaheuristics with cooperative parallelism		Many real-life applications can be formulated as Combinatorial Optimization Problems, the solution of which is often challenging due to their intrinsic difficulty. At present, the most effective methods to address the hardest problems entail the hybridization of metaheuristics and cooperative parallelism. Recently, a framework called CPLS has been proposed, which eases the cooperative parallelization of local search solvers. Being able to run different heuristics in parallel, CPLS has opened a new way to hybridize metaheuristics, thanks to its cooperative parallelism mechanism. However, CPLS is mainly designed for local search methods. In this paper we seek to overcome the current CPLS limitation, extending it to enable population-based metaheuristics in the hybridization process. We discuss an initial prototype implementation for Quadratic Assignment Problem combining a Genetic Algorithm with two local search procedures. Our experiments on hard instances of QAP show that this hybrid solver performs competitively w.r.t. dedicated QAP parallel solvers.	color gradient;combinatorial optimization;computational resource;crossover (genetic algorithm);experiment;genetic algorithm;heuristic (computer science);local search (optimization);memetic algorithm;memetics;parallel computing;parallel metaheuristic;program optimization;prototype;quadratic assignment problem;real life;solver;speedup;test case	Jheisson López;Danny Múnera;Daniel Diaz;Salvador Abreu	2018	2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)	10.1109/IPDPSW.2018.00100	parallel computing;computer science;genetic algorithm;local search (optimization);quadratic assignment problem;combinatorial optimization;metaheuristic;population;heuristics;solver	AI	23.34178653247212	-3.313554128889277	149023
e9b31f1e93120b9078f091fb56e9a994a347c2e4	an intelligent method to reduce losses in distribution networks using self-adaptive harmony search algorithm		Loss reduction planning is considered one of the most significant and sensitive distribution designing system. The planning process to reduce losses along with distributed generation sources results in a non-convex, non-linear optimization problem, mixed with integer variables, which requires complicated calculations. To solve this problem, novel optimization algorithms such as harmony Search (HS) algorithm can be used for different optimization problems. This paper presents an effective intelligent optimization method to solve the network reconfiguration problem in the presence of distributed generation (DG) with an objective of minimizing real power loss and improving voltage profile in distribution system using new set of harmony search algorithms, called self-adaptive. To verify the efficiency of the algorithm the results have been analyzed in the IEEE standard system. The results show the strength, appropriate efficiency and superior performance of this algorithm in comparison to the original harmony Search algorithm and other optimization algorithms as well.	harmony search;search algorithm	Masoud Zahedi Vahid;Mahmoud Oukati Sadegh	2016	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-152052	optimization problem;mathematical optimization;artificial intelligence;machine learning;mathematics;metaheuristic;search algorithm	Robotics	17.361476661071578	-3.6709884547982967	149796
af8a02392c70f3bd3069f6cef9997aba5a3cd2ad	a fast objective reduction algorithm based on dominance structure for many objective optimization		The performance of the most existing classical evolutionary multiobjective optimization (EMO) algorithms, especially for Pareto-based EMO algorithms, generally deteriorates over the number of objectives in solving many-objective optimization problems (MaOPs), in which the number of objectives is greater than three. Objective reduction methods that transform an MaOP into the one with few objectives, are a promising way for solving MaOPs. The dominance-based objective reduction methods, e.g. k-EMOSS and (delta )-MOSS, omitting an objective while preserving the dominant structure of the individuals as much as possible, can achieve good performance. However, these algorithms have higher computational complexity. Therefore, this paper presents a novel measure for measuring the capacity of preserving the dominance structure of an objective set, i.e., the redundancy of an objective to an objective set. Subsequently, we propose a fast algorithm to find a minimum set of objectives preserving the dominance structure as much as possible. We compare the proposed algorithm with its counterparts on eleven test instances. Numerical studies show the effectiveness of the proposed algorithm.	algorithm;objective collapse theory;program optimization	Fangqing Gu;Hai-Lin Liu;Yiu-ming Cheung	2017		10.1007/978-3-319-68759-9_22	redundancy (engineering);machine learning;mathematical optimization;pareto principle;evolutionary algorithm;computational complexity theory;algorithm;multi-objective optimization;artificial intelligence;computer science;optimization problem	EDA	23.105390480634224	-3.929275948907976	150251
725c24159fa3934ac768717aa1a38658c997c714	evolution strategies: basic introduction	selection operator;basic introduction;strategy parameter;key feature;algorithmic concept;evolution strategy;evolution strategies;evolutionary algorithm;basic evolution strategy;application example	This tutorial gives a basic introduction to evolution strategies, a class of evolutionary algorithms. Key features such as mutation, recombination and selection operators are explained, and specifically the concept of self-adaptation of strategy parameters is introduced. All algorithmic concepts are explained to a level of detail such that an implementation of basic evolution strategies is possible. Some guidelines for utilization as well as some application examples are given.	evolution strategy;evolutionary algorithm;level of detail	Thomas Bäck	2011		10.1145/2001858.2002118	evolutionary computation;introduction to evolution;evolutionary programming;machine learning;artificial intelligence;management science;human-based evolutionary computation;evolutionary algorithm;computer science;java evolutionary computation toolkit;evolutionary acquisition of neural topologies;evolution strategy	AI	23.248090443893105	-6.396309768304531	150517
d29e8c7e1db6d08631333a4219f74f6c5248d7f0	hypervolume sharpe-ratio indicator: formalization and first theoretical results		Set-quality indicators have been used in Evolutionary Multiobjective Optimization Algorithms (EMOAs) to guide the search process. A new class of set-quality indicators, the Sharpe-Ratio Indicator, combining the selection of solutions with fitness assignment has been recently proposed. This class is based on a formulation of fitness assignment as a Portfolio Selection Problem which sees solutions as assets whose returns are random variables, and fitness as the investment in such assets/solutions. An instance of this class based on the Hypervolume Indicator has shown promising results when integrated in an EMOA called POSEA. The aim of this paper is to formalize the class of Sharpe-Ratio Indicators and to demonstrate some of the properties of that particular Sharpe-Ratio Indicator instance concerning monotonicity, sensitivity to scaling and parameter independence.	evolutionary algorithm;multi-objective optimization	Andreia P. Guerreiro;Carlos M. Fonseca	2016		10.1007/978-3-319-45823-6_76	artificial intelligence;computer science;mathematical optimization;machine learning;scaling;monotonic function;evolutionary algorithm;multi-objective optimization;sharpe ratio;random variable;portfolio	ML	20.66397545342398	-4.6598338912449595	150898
f503e43a53acf92bf12e7d1528f38358cb2ca49a	"""a """"non-model building"""" approach to solving hierarchical functions"""	genetic algorithms bayes methods;limiting factor;bayes methods;couplings testing problem solving bayesian methods decision making merging perturbation methods;model building;linkage detection nonmodel building hierarchical functions hierarchical bayesian optimization algorithm hboa operator development ga domain linkage learning diversity preservation selec to recombinative gas;genetic algorithms;bayesian optimization algorithm;hierarchical bayesian optimization algorithm;problem solving	The hierarchical Bayesian optimization algorithm (hBOA) by M. Pelikan and D.E. Goldberg (2001), used diversity preservation along with the original Bayesian optimization algorithm BOA by M. Pelikan et al. (1999) to tackle boundedly difficult hierarchical functions. However, model building can be an expensive process, and a pertinent question is the possibility of developing operators that can solve certain classes of hierarchical functions in the traditional GA domain. This study shows, that by following a three-step approach to hierarchical problem solving - effective linkage learning, merging of low-order BBs, and diversity preservation - it is possible to use competent (non-model building) selec-to-recombinative GAs to solve certain classes of hierarchical functions. Experimental bounds were found on the type of hierarchical problems that could be solved, and perturbation based linkage detection was found to be the limiting factor.		Felipe Padilla Diaz;Eunice Ponce de León;Alejandro Padilla;Marcelo Mejia	2003		10.1109/ENC.2003.1232896	mathematical optimization;model building;genetic algorithm;limiting factor;computer science;artificial intelligence;machine learning	Logic	22.061456315081358	-6.525717186582952	151651
0d701b8ad131775990a56c928cd3096bc9101607	a review of hybrid evolutionary multiple criteria decision making methods	pareto optimization decision making vectors evolutionary computation search problems approximation methods;interactive technique hybrid evolutionary multiple criteria decision making methods performance criteria multiobjective evolutionary algorithms multiple criteria decision making a posteriori technique a priori technique;evolutionary computation decision making	For real-world problems, the task of decision-makers is to identify a solution that can satisfy a set of performance criteria, which are often in conflict with each other. Multi-objective evolutionary algorithms tend to focus on obtaining a family of solutions that represent the trade-offs between the criteria; however ultimately a single solution must be selected. This need has driven a requirement to incorporate decision-maker preference models into such algorithms - a technique that is very common in the wider field of multiple criteria decision making. This paper reviews techniques which have combined evolutionary multi-objective optimization and multiple criteria decision making. Three classes of hybrid techniques are presented: a posteriori, a priori, and interactive, including methods used to model the decision-makers preferences and example algorithms for each category. To encourage future research directions, a commentary on the remaining issues within this research area is also provided.	evolutionary algorithm;mathematical optimization;multi-objective optimization	Robin C. Purshouse;Kalyanmoy Deb;Maszatul M. Mansor;Sanaz Mostaghim;Rui Wang	2014	2014 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2014.6900368	evolutionary programming;mathematical optimization;influence diagram;interactive evolutionary computation;multi-objective optimization;machine learning;mathematics;management science	AI	21.596674419332945	-4.633658562548612	151738
41dc11659a08a81e77b74989581464e9bfd12cda	error thresholds and optimal mutation rates in genetic algorithms		Academic Publications and Contributions CV summary · Google Scholar citations: 1160+, with an h-index of 20 and an i10-index of 31. · 16 journal papers, 36 refereed conference papers (including one best paper award and 2 other nominations) and 6 book chapters. · Lindenmayer systems as encodings in evolutionary algorithms, study of error thresholds and the roles of recombination and mate selection in evolutionary algorithms, hyper-heuristics and cross-domain optimisation, complex networks for the study of combinatorial landscapes.	complex network;evolutionary algorithm;genetic algorithm;google scholar;heuristic (computer science);hyper-heuristic;l-system;mathematical optimization	Gabriela Ochoa	2000				Metrics	23.688390918741725	-7.477482054069022	153041
d4ff91e9a7793f0a20b9b2733c2493d78a725228	evolutionary multi-objective optimization: current state and future challenges	optimisation evolutionary computation;optimisation;evolutionary computation;evolutionary multi objective optimization;heuristic search;natural selection;evolutionary computation genetic algorithms computer science usa councils books heuristic algorithms application software biographies civil engineering scholarships;genetic algorithm evolutionary multi objective optimization heuristic search algorithm problem solving evolutionary algorithm biologically inspired heuristics;genetic algorithm;evolutionary algorithm;multi objective optimization problem	"""During the last few years, there has been an increasing interest in using heuristic search algorithms based on natural selection (the so-called """"evolutionary algorithms"""") for solving a wide variety of problems. As in any other discipline, research on evolutionary algorithms has become more specialized over the years, giving rise to a number of sub-disciplines. This talk deals with one of the emerging sub-disciplines that has become very popular due to its wide applicability: evolutionary multi-objective optimization (EMO). EMO refers to the use of evolutionary algorithms (or even other biologically-inspired heuristics) to solve problems with two or more (often conflicting) objectives. Unlike traditional (single-objective) problems, multi-objective optimization problems normally have more than one possible solution. Thus, traditional evolutionary algorithms (e.g., genetic algorithms) need to be modified in order to deal with such problems. This talk will provide a general overview of this field, including its historical origins, its most significant developments, some of its most important application areas and its current challenges."""	evolutionary algorithm;genetic algorithm;heuristic (computer science);mathematical optimization;multi-objective optimization;program optimization;search algorithm	Carlos A. Coello Coello	2005		10.1109/ICHIS.2005.38	evolutionary programming;genetic programming;mathematical optimization;evolutionary music;genetic algorithm;interactive evolutionary computation;human-based evolutionary computation;cultural algorithm;java evolutionary computation toolkit;computer science;artificial intelligence;machine learning;evolutionary algorithm;evolutionary acquisition of neural topologies;genetic representation;evolution strategy;imperialist competitive algorithm;evolutionary robotics;metaheuristic;memetic algorithm;evolutionary computation	AI	22.39851425202589	-5.285492948003287	153553
6dd0da5110e7a1f5fea69c6324ae6e968d9b2f59	modified multiple search cooperative foraging strategy for improved artificial bee colony optimization with robustness analysis		Considering that extending the concept of bees partitioning into subgroups of foragers to the onlooker phase of the cooperative learning artificial bee colony (CLABC) strategy is not only feasible from algorithmic viewpoint but might reflect real behavioral foraging characteristics of bee swarms, this paper studies whether the performance of CLABC can be enhanced by developing a new model for the proposed cooperative foraging scheme. Relying on this idea, we design a modified cooperative learning artificial bee colony algorithm, referred to as mCLABC. The design procedure is built upon the definition of a partitioning scheme of onlookers allowing the generation of subgroups of foragers that might evolve differently by using specific solution search rules. In order to improve the involving of local and global search at both employed and onlooker levels, the multiple search mechanism is further tuned and scheduled according to a random selection strategy defined on the evolving parameters. Moreover, a detailed performance and robustness study of the proposed algorithm dealing with the analysis of the impact of different structural and parametric settings is conducted on benchmark optimization problems. Superior convergence performance, better solution quality, and strong robustness are the main features of the proposed strategy in comparison with recent ABC variants and advanced methods.	artificial bee colony algorithm;bees algorithm;mathematical optimization	Fatima Harfouchi;Hacene Habbi;Celal Ozturk;Dervis Karaboga	2018	Soft Comput.	10.1007/s00500-017-2689-1	robustness (computer science);artificial bee colony algorithm;machine learning;artificial intelligence;swarm intelligence;mathematical optimization;parametric statistics;computer science;cooperative learning;foraging;optimization problem;convergence (routing)	Robotics	24.329029014357463	-4.135415029901865	155474
ba57ab1554f0624d963398f89e5fac9287cf8493	a framework for genetic test-case generation for ws-bpel compositions		Search-based testing generates test cases by encoding an adequacy criterion as the fitness function that drives a search-based optimization algorithm. Genetic algorithms have been successfully applied in search-based testing: while most of them use adequacy criteria based on the structure of the program, some try to maximize the mutation score of the test suite. This work presents a genetic algorithm for generating a test suite for mutation testing. The algorithm adopts several features from existing bacteriological algorithms, using single test cases as individuals and keeping generated individuals in a memory. The algorithm can optionally use automated seeding when producing the first population, by taking into account interesting constants in the source code. We have implemented this algorithm in a framework and we have applied it to a WS-BPEL composition, measuring to which extent the genetic algorithm improves the initial random test suite. We compare our genetic algorithm, with and without automated seeding, to random testing.	business process execution language;fitness function;functional testing;genetic algorithm;mathematical optimization;mutation testing;random testing;software release life cycle;test case;test suite	Antonia Estero-Botaro;Antonio García-Domínguez;Juan José Domínguez-Jiménez;Francisco Palomo-Lozano;Inmaculada Medina-Bulo	2014		10.1007/978-3-662-44857-1_1	model-based testing;simulation;meta-optimization;computer science;machine learning;algorithm;population-based incremental learning	SE	21.489635732293124	-7.743313986963786	155872
3e79cf8c0803688d33372f8aea1e71416f34e729	correlation of job-shop scheduling problem features with scheduling efficiency	support vector machines;job shop scheduling;makespan prediction;machine learning;scheduling efficiency	In this paper, we conduct a statistical study of the relationship between Job-Shop Scheduling Problem (JSSP) features and optimal makespan. To this end, a set of 380 mostly novel features, each representing a certain problem characteristic, are manually developed for the JSSP. We then establish the correlation of these features with optimal makespan through statistical analysis measures commonly used in machine learning, such as the Pearson Correlation Coefficient, and as a way to verify that the features capture most of the existing correlation, we further use them to develop machine learning models that attempt to predict the optimal makespan without actually solving a given instance. The prediction is done as classification of instances into coarse lower or higher-than-average classes. The results, which constitute cross-validation and test accuracy measures of around 80% on a set of 15,0 0 0 randomly generated problem instances, are reported and discussed. We argue that given the obtained correlation information, a human expert can earn insight into the JSSP structure, and consequently design better instances, design better heuristic or hyper-heuristics, design better benchmark instances, and in general make better decisions and perform better-informed trade-offs in various stages of the scheduling process. To support this idea, we also demonstrate how useful the obtained insight can be through a real-world application. © 2016 Elsevier Ltd. All rights reserved.	benchmark (computing);coefficient;cross-validation (statistics);heuristic (computer science);hyper-heuristic;jssp;machine learning;makespan;procedural generation;scheduling (computing)	Sadegh Mirshekarian;Dusan N. Sormaz	2016	Expert Syst. Appl.	10.1016/j.eswa.2016.06.014	fair-share scheduling;job shop scheduling;support vector machine;mathematical optimization;dynamic priority scheduling;computer science;machine learning;data mining	AI	20.182928002052194	-6.458464986360686	156399
d531d19d89d327df0cb44bfa3b52f57ed304fc33	a cross entropy based algorithm for reliability problems	cross entropy;reliability;response surface methodology;metaheuristics;complex network;combinatorial optimization problem;software systems;large scale;complex system;budget constraint;cross entropy method	The Cross Entropy method has recently been applied to combinatorial optimization problems with promising results. This paper proposes a Cross Entropy based algorithm for reliability optimization of complex systems, where one wants to maximize the reliability of a system through optimal allocation of redundant components while respecting a set of budget constraints. We illustrate the effectiveness of the proposed algorithm on two classes of problems, software system reliability optimization and complex network reliability optimization, by testing it on instances from the literature as well as on randomly generated large scale instances. Furthermore, we show how a Cross Entropy-based algorithm can be fine-tuned by using a training scheme based upon the Response Surface Methodology. Computational results show the effectiveness as well as the robustness of the algorithm on different classes of problems.	algorithm;cross entropy	Marco Caserta;Marta Cabo Nodar	2009	J. Heuristics	10.1007/s10732-008-9074-2	mathematical optimization;budget constraint;complex systems;response surface methodology;cross-entropy method;entropy maximization;computer science;machine learning;data mining;reliability;mathematics;cross entropy;complex network;metaheuristic;software system	Theory	19.1569703999113	-4.849033166907107	156899
2010b2feb6cf288232101c5b60f178a7b10e7c3d	adapting to a realistic decision maker: experiments towards a reactive multi-objective optimizer	multi objective optimization;decision maker;multi objective genetic algorithm	The interactive decision making (IDM) methods exploit the preference information from the decision maker during the optimization task to guide the search towards favourite solutions. This work measures the impact of inaccurate and contradictory preference information on the quality of the solutions generated by the IDM methods. The investigation is done in the context of the BC-EMO algorithm, a recently proposed multi-objective genetic algorithm.	mathematical optimization	Paolo Campigotto;Andrea Passerini	2010		10.1007/978-3-642-13800-3_35	decision-making;mathematical optimization;computer science;artificial intelligence;multi-objective optimization;machine learning;data mining;mathematics	ECom	20.837602525423236	-4.828886770975009	157028
66fc53d13eea7b0a49c08e9ed0f7fac9b98327c7	community detection in weighted directed networks using nature-inspired heuristics.		Finding groups from a set of interconnected nodes is a recurrent paradigm in a variety of practical problems that can be modeled as a graph, as those emerging from Social Networks. However, finding an optimal partition of a graph is a computationally complex task, calling for the development of approximative heuristics. In this regard, the work presented in this paper tackles the optimal partitioning of graph instances whose connections among nodes are directed and weighted, a scenario significantly less addressed in the literature than their unweighted, undirected counterparts. To efficiently solve this problem, we design several heuristic solvers inspired by different processes and phenomena observed in Nature (namely, Water Cycle Algorithm, Firefly Algorithm, an Evolutionary Simulated Annealing and a Population based Variable Neighborhood Search), all resorting to a reformulated expression for the well-known modularity function to account for the direction and weight of edges within the graph. Extensive simulations are run over a set of synthetically generated graph instances, aimed at elucidating the comparative performance of the aforementioned solvers under different graph sizes and levels of intra- and inter-connectivity among node groups. We statistically verify that the approach relying on the Water Cycle Algorithm outperforms the rest of heuristic methods in terms of Normalized Mutual Information with respect to the true partition of the graph.		Eneko Osaba;Javier Del Ser;David Camacho;Akemi Gálvez;Andrés Iglesias;Iztok Fister;Iztok Fister	2018		10.1007/978-3-030-03496-2_36	machine learning;firefly algorithm;computer science;simulated annealing;artificial intelligence;mutual information;theoretical computer science;variable neighborhood search;modularity;heuristic;heuristics;population	AI	22.595124362077467	-7.762202618193649	157412
4f9b5740a53a19afaf43b4187f2d235c3e0cc86f	assessing solution quality of biobjective 0-1 knapsack problem using evolutionary and heuristic algorithms	multiobjective problem;pareto front;0 1 knapsack;local convergence;multiobjective evolutionary algorithm;linear functionals;np hard problem;knapsack problem;real world application;industrial application;profitability;heuristics;evolutionary algorithm;combinatorial optimization;heuristic algorithm	Multiobjective 0-1 knapsack problem involving multiple knapsacks is a widely studied problem. In this paper, we consider a formulation of the biobjective 0-1 knapsack problem which involves a single knapsack; this formulation is more realistic and has many industrial applications. Though it is formulated using simple linear functions, it is an NP-hard problem. We consider three different types of knapsack instances, where the weight and profit of an item is (i) uncorrelated, (ii) weakly correlated, and (iii) strongly correlated, to obtain generalized results. First, we solve this problem using three well-known multiobjective evolutionary algorithms (MOEAs) and quantify the obtained solution-fronts to observe that they show good diversity and (local) convergence. Then, we consider two heuristics and observe that the quality of solutions obtained by MOEAs is much inferior in terms of the extent of the solution space. Interestingly, none of the MOEAs could yield the entire coverage of the Pareto-front. Therefore, based on the knowledge of the Pareto-front obtained from the heuristics, we incorporate problemspecific knowledge in the initial population and obtain good quality solutions using MOEAs too. We quantify the obtained solution fronts for comparison. The main point we stress with this work is that, for real world applications of unknown nature, it is indeed difficult to realize how good/bad is the quality of the solutions obtained. Conversely, if we know the solution space, it is trivial to obtain the desired set of solutions using MOEAs, which is a paradox in itself. 2009 Elsevier B.V. All rights reserved. * Corresponding author. E-mail address: rkumar@cse.iitkgp.ernet.in (R. Kumar).	evolutionary algorithm;feasible region;heuristic (computer science);knapsack problem;linear function;local convergence;np-hardness;pareto efficiency;strongly correlated material	Rajeev Kumar;Pramod Kumar Singh	2010	Appl. Soft Comput.	10.1016/j.asoc.2009.08.037	local convergence;heuristic;continuous knapsack problem;mathematical optimization;combinatorics;combinatorial optimization;computer science;generalized assignment problem;cutting stock problem;change-making problem;multi-objective optimization;heuristics;evolutionary algorithm;np-hard;mathematics;mathematical economics;knapsack problem;profitability index	AI	20.746991343862273	-3.813873699822424	157676
8f5e4dc7721f7953019ab379b2de8dd63de0aa2c	applications of different metaheuristic techniques for finding optimal tst order during integration testing of object oriented systems and their comparative study		In recent past, a number of researchers have proposed genetic algorithm (GA) based strategies for finding optimal test order while minimizing the stub complexity during integration testing. Even though, metaheuristic algorithms have a wide variety of use in various medium to large size optimization problems [21], their application to solve the class integration test order (CITO) problem [12] has not been investigated. In this research paper, we propose to find a solution to CITO problem by the use of a GA based approach. We have proposed a class dependency graph (CDG) to model dependencies namely, association, aggregation, composition and inheritance between classes of unified modeling language (UML) class diagram. In our approach, weights are assigned to the edges connecting nodes of CDG and then these weights are used to model the cost of stubbing. Finally, we compare and discuss the empirical results of applying our approach with existing graph based and metaheuristic techniques to the CITO problem and highlight the relative merits and demerits of the various techniques.	class diagram;delay-gradient congestion control;genetic algorithm;integration testing;mathematical optimization;metaheuristic;software release life cycle;unified modeling language	Chayanika Sharma;Ritu Sibal	2014	CoRR	10.7321/jscse.v3n.12.1	mathematical optimization;computer science;artificial intelligence;algorithm	AI	19.64312292437711	-5.272160404553193	158766
c1d03f3e7d55a8ee71171dc044e34c3050eb77b8	evolving dynamic multi-objective optimization problems with objective replacement	multi objective optimization;multi objective genetic algorithm;dynamic environment;research paper;non stationary environment;multi objective optimization problem;multi objective genetic algorithms;pareto optimality;multi objective problems	This paper studies the strategies for multi-objective optimization in a dynamic environment. In particular, we focus on problems with objective replacement, where some objectives may be replaced with new objectives during evolution. It is shown that the Pareto-optimal sets before and after the objective replacement share some common members. Based on this observation, we suggest the inheritance strategy. When objective replacement occurs, this strategy selects good chromosomes according to the new objective set from the solutions found before objective replacement, and then continues to optimize them via evolution for the new objective set. The experiment results showed that this strategy can help MOGAs achieve better performance than MOGAs without using the inheritance strategy, where the evolution is restarted when objective replacement occurs. More solutions with better quality are found during the same time span.	algorithm;archive;mathematical optimization;multi-objective optimization;natural deduction;optimizing compiler;pareto efficiency	Steven Guan;Qian Chen;Wenting Mo	2004	Artificial Intelligence Review	10.1007/s10462-004-5900-6	mathematical optimization;multi-objective optimization;management science	AI	23.181119594991454	-6.31036254146244	160408
37e7ae796f63a16b79f745b9750105427cf9d68f	benchmarking the (1+1) evolution strategy with one-fifth success rule on the bbob-2009 function testbed	benchmarking;evolutionary computation;search space;one fifth success rule;search algorithm;adaptive search;evolution strategies;evolution strategy;black box optimization;evolutionary computing	In this paper, we benchmark the (1+1) Evolution Strategy (ES) with one-fifth success rule which is one of the first and simplest adaptive search algorithms proposed for optimization. The benchmarking is conducted on the noise-free BBOB-2009 testbed. We implement a restart version of the algorithm and conduct for each run 106 times the dimension of the search space function evaluations.	benchmark (computing);evolution strategy;like button;mathematical optimization;search algorithm;testbed	Anne Auger	2009		10.1145/1570256.1570342	mathematical optimization;simulation;computer science;artificial intelligence;machine learning;best-first search;evolution strategy;benchmarking;evolutionary computation;search algorithm	AI	24.371240650304983	-5.382788129374285	160473
1f652ab27ae98cd2004878551f1517922d2c7dfe	scalability of the bayesian optimization algorithm	bayesian network;computacion informatica;genetics;probabilistic model;ciencias basicas y experimentales;graphical model;genetic algorithm;bayesian optimization algorithm;grupo a;evolutionary computing	To solve a wide range of different problems, the research in black-box optimization faces several important challenges. One of the most important challenges is the design of methods capable of automatic discovery and exploitation of problem regularities to ensure efficient and reliable search for the optimum. This paper discusses the Bayesian optimization algorithm (BOA), which uses Bayesian networks to model promising solutions and sample new candidate solutions. Using Bayesian networks in combination with population-based genetic and evolutionary search allows BOA to discover and exploit regularities in the form of a problem decomposition. The paper analyzes the applicability of the methods for learning Bayesian networks in the context of genetic and evolutionary search and concludes that the combination of the two approaches yields robust, efficient, and accurate search. 2002 Elsevier Science Inc. All rights reserved.	authorization;bayesian network;bayesian optimization;black box;decision theory;evolutionary computation;genetic algorithm;image scaling;machine learning;mathematical optimization;scalability	Martin Pelikan;Kumara Sastry;David E. Goldberg	2002	Int. J. Approx. Reasoning	10.1016/S0888-613X(02)00095-6	statistical model;genetic algorithm;variable-order bayesian network;estimation of distribution algorithm;computer science;artificial intelligence;machine learning;bayesian network;data mining;graphical model;statistics;intelligent control;evolutionary computation	AI	23.583779834928368	-8.326066796098718	161288
d00e75a9cb8f0bd26cb4d60be4857000c7f2ecd7	when neural network computation meets evolutionary computation: a survey		Neural network (NN) and evolutionary computation (EC) are two of the most popular and important techniques in computational intelligence, which can be combined together to solve the complex real world problems. This paper represents a review of the researches that combined NN and EC. There are 3 main research focuses as follows. In the first research focus, EC algorithms have been widely used to optimize the structure and parameter of the NN, including weight, structure, learning rates, and others. In the second research focus, lots literatures have witnessed that EC based NNs are widespread in the applications such as classification, automatic control, prediction, and many other fields. These two kinds of researches into combining NN and EC are mainly focuses on using EC algorithms to optimize NN, to enhance the NN performance and the NN application ability. Our survey finds that particle swarm optimization is the most popular EC algorithm that the researchers choice to optimize NN in recent year, while genetic algorithm and differential evolution are also widely used. In the third research focus, there are also researches adopted NN as a tool to enhance the performance of EC algorithms. Although the literatures in this focus are not as many as the above two focuses, the existing results show that NN has great potential in enhancing EC algorithms. The survey shows that when NN and EC meet, combining them would result in an effective way to deal with the real world application. This interesting research topic has become more and more significant in the field of computer science and still has much room for development.	artificial neural network;evolutionary computation	Zong-Gan Chen;Zhi-hui Zhan;Wen Shi;Wei-neng Chen;Jun Zhang	2016		10.1007/978-3-319-40663-3_69	computational science;interactive evolutionary computation;human-based evolutionary computation;computer science;theoretical computer science;human-based computation	Logic	22.142235524080885	-5.780320433465628	161978
261141355e9b1371a3060d9eef172a7617bf415c	parameter setting in eas: a 30 year perspective		Parameterized evolutionary algorithms (EAs) have been a standard part of the Evolutionary Computation community from its inception. The widespread use and applicability of EAs is due in part to the ability to adapt an EA to a particular problem-solving context by tuning its parameters. However, tuning EA parameters can itself be a challenging task since EA parameters interact in highly non-linear ways. In this chapter we provide a historical overview of this issue, discussing both manual (human-in-the-loop) and automated approaches, and suggesting when a particular strategy might be appropriate.	evolutionary algorithm;evolutionary computation;fitness function;mathematical optimization;nonlinear system;performance tuning;problem solving	Kenneth DeJong	2007		10.1007/978-3-540-69432-8_1	simulation;engineering;artificial intelligence;algorithm	AI	21.699146858756595	-5.978087793890602	162025
2060793e14aa6bac3212f6620c7141bbb2a0129a	the composition of chaos hopfield neural network and gaussian machine to the traveling salesman problem	traveling salesman problem		hopfield network;travelling salesman problem	Nobuaki Ootake;Kenji Nagasaka	1998			artificial intelligence;machine learning;travelling salesman problem;bottleneck traveling salesman problem;computer science;artificial neural network;mathematical optimization;hopfield network;gaussian	ML	22.29279676408441	-9.804435446801053	162439
d2da888a16e5383dc46bd226fccda2cb236e71b3	cooperative co-evolution for large scale optimization with dynamic variable grouping via marginal product modeling		Cooperative co-evolution (CC) algorithm is a promising method to deal with large scale optimization (LSGO) problem. One major challenge in CC is to design a good decomposition strategy to decompose original problem into subproblems. Linkage learning is a technique to search the linkage betweens decision variables. In this paper, we proposed a dynamic online grouping CC algorithm which employ the linkage learning method of extended compact genetic algorithm (ECGA). This linkage learning method build marginal product models of population and search for models according to minimum description length (MDL) criterion. A discretization technique and normalization method of MDL value is used to make the linkage learning more adaptive in large scale optimization. The decision variables will be regrouped according to the linkage learned when the optimization procedure is considered as stagnant. Experiments are conduct on CEC'10 LSGO benchmark function. The test results confirm the validity of this method.	benchmark (computing);continuous optimization;database normalization;decision theory;discontinuous galerkin method;discretization;genetic algorithm;ieee congress on evolutionary computation;linkage (software);mdl (programming language);marginal model;material point method;mathematical optimization;minimum description length	Yapei Wu;Xingguang Peng;Demin Xu	2018	2018 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2018.8477740	computer science;genetic algorithm;mathematical optimization;normalization (statistics);minimum description length;marginal product;discretization;population	AI	23.876987054744788	-4.714891457277899	162768
0ad73fd6615ba09a63ca85c10ee498485664a262	evaluating the performance of an evolutionary tool for exploring solution fronts		EvoFilter is an evolutionary algorithm based tool for searching through large non-dominated fronts in order to find a subset of solutions that are of interest to the user. EvoFilter is designed to take the output of existing Multi Objective Evolutionary Algorithms and act as a decision support tool for users. Currently EvoFilter is available for all to use on-line [1]. This paper evaluates the performance of EvoFilter by creating a large number of randomised filter specifications which are then applied using EvoFilter and a simple filter to a range of non-dominated fronts created by a portfolio of Multi Objective Genetic Algorithms (MOGAs). The results show that EvoFilter is capable of finding sets of solutions that meet the users’ requirements more closely than those found using the simple filter. EvoFilter increases performance on some objectives by including relevant solutions event if these solutions slightly lessen performance on other objectives. The filter discussed in this paper may be accessed at [1].		Neil Urquhart	2018		10.1007/978-3-319-77538-8_36	genetic algorithm;evolutionary algorithm;decision support system;machine learning;scheduling (computing);portfolio;artificial intelligence;computer science	EDA	21.413581371338907	-4.085292693931279	163226
1dc576a3d9361057982e9e003449eaa5dff43c72	impact of sensor-based change detection schemes on the performance of evolutionary dynamic optimization techniques		Evolutionary algorithms are among the most common techniques developed to address dynamic optimization problems. They either assume that changes in the environment are known a priori, especially for some benchmark problems, or detect these changes. On the other hand, detecting the points in time where a change occurs in the landscape is a critical issue. In this paper, we investigate the performance evaluation of various sensor-based detection schemes on the moving peaks benchmark and the dynamic knapsack problem. Our empirical study validates the performance of the sensor-based detection schemes considered, by using the average rate of correctly identified changes and number of sensors invoked to detect a change. We also propose a new mechanism to evaluate the capability of the detection schemes for determining severity of changes. Additionally, a novel hybrid approach is proposed by integrating the change detection schemes with evolutionary dynamic optimization algorithms in order to set algorithm-specific parameters dynamically. The experimental evaluation validates that our extensions outperform the reference algorithms for various characteristics of dynamism.	dynamic programming;mathematical optimization	Lokman Altin;Haluk Topcuoglu	2018	Soft Comput.	10.1007/s00500-017-2660-1	machine learning;empirical research;mathematical optimization;artificial intelligence;evolutionary algorithm;knapsack problem;computer science;change detection;optimization problem	Embedded	23.5610832102639	-4.948469265486096	163684
81cb09cb69816a1189287304e9d6b06ba441dfa4	a skin membrane-driven membrane algorithm for many-objective optimization		Many-objective optimization problems refer to problems that hold more than three conflicting objectives, which are more challenging than those with two or three objectives. Membrane computing models, usually termed P systems, are a class of living cell-inspired computing models, which provide a rich framework for solving a variety of challenging problems. In this paper, a membrane computing model-based algorithm is proposed for many-objective optimization. Specifically, the population in the skin membrane is divided into two subpopulations, one used for guiding the convergence of populations in the internal membrane, while the other taking charge of the diversity of populations. Experimental results on benchmark test problems for many-objective optimization indicate the superiority of the developed algorithm over existing evolutionary many-objective optimization algorithms and P systems based multi-objective optimization algorithms.	algorithm;benchmark (computing);mathematical optimization;membrane computing;multi-objective optimization;p system;population	Zhangxiao Li;Lei Zhang;Yansen Su;Jun Li;Xun Wang	2016	Neural Computing and Applications	10.1007/s00521-016-2675-z	probabilistic-based design optimization;optimization problem;mathematical optimization;multi-swarm optimization;simulation;test functions for optimization;meta-optimization;derivative-free optimization;mathematics;management science;l-reduction	AI	24.46313352583316	-4.075017247333862	164043
a9b27fd37f739e69e5a8bbabef66a12c2792644b	ademo/d: an adaptive differential evolution for protein structure prediction problem		Protein Structure Prediction (PSP) is the process of determining three-dimensional structures of proteins based on their sequence of amino acids. PSP is of great importance to medicine and biotechnology, e.g., to novel enzymes and drugs design, and one of the most challenging problems in bioinformatics and theoretical chemistry. This paper models PSP as a multi-objective optimization problem and adopts ADEMO/D (Adaptive Differential Evolution for Multi-objective Problems based on Decomposition) on its optimizer platform. ADEMO/D has been previously applied to multi-objective optimization with a lot of success. It incorporates concepts of problem decomposition and mechanisms of mutation strategies adaptation. Decomposition-based multi-objective optimization tends to be more efficient than other techniques in complex problems. Adaptation is particularly important in bioinformatics because it can release practitioners, with a great expertise focused on the application, from tuning optimization algorithm’s parameters. ADEMO/D for PSP needs a decision maker and this work tests four different methods. Experiments consider off-lattice models and ab initio approaches for six real proteins. Results point ADEMO/D as a competitive approach for total energy and conformation similarity metrics. This work contributes to different areas ranging from evolutionary multi-objective optimization to bioinformatics as it extends the application universe of adaptive problem decomposition-based algorithms, which despite the success in various areas are practically unexplored in the PSP context.	differential evolution;protein structure prediction	Sandra M. Venske;Richard A. Gonçalves;Elaine M. Benelli;Myriam Regattieri Delgado	2016	Expert Syst. Appl.	10.1016/j.eswa.2016.03.009	simulation;computer science;bioinformatics;artificial intelligence;machine learning;mathematics	ML	22.690008284385517	-6.375510940415513	164359
ac30eab039228d554368b8af1c3a1f0738b40eff	solving multi-objective flowshop scheduling problem by taguchi-based particle swarm optimization	taguchi methods flow shop scheduling observers pareto optimisation particle swarm optimisation;particle swarm optimization sociology statistics optimization educational institutions scheduling genetic algorithms;taguchi based crossover flowshop scheduling problem particle swarm optimization;pareto best solutions multiobjective flowshop scheduling problem taguchi based particle swarm optimization tbpso algorithm fsp taguchi based crossover	A Taguchi-based particle swarm optimization (TBPSO) algorithm is proposed for solving multi-objective flowshop scheduling problems (FSPs). The proposed TBPSO integrates particle swarm optimization and Taguchi-based crossover. The proposed TBPSO is the use of a PSO to explore the optimal feasible region and the use of the Taguchi-based crossover to exploit the better solution. As a result, the TBPSO exhibits a significant improvement in Pareto best solutions of the FSP. By combining the advantages of exploration and exploitation, the TBPSO provides better results compared to the existing methods reported in the literature when solving multi-objective FSPs.	algorithm;feasible region;mathematical optimization;pareto efficiency;particle swarm optimization;phase-shift oscillator;scheduling (computing);taguchi methods	Jinn-Tsong Tsai;Ching-I Yang;Shang-Yuan Sun;Jyh-Horng Chou	2014	11th IEEE International Conference on Control & Automation (ICCA)	10.1109/ICCA.2014.6870988	mathematical optimization;multi-swarm optimization;machine learning;metaheuristic	Robotics	24.571121165997727	-3.5953069165601526	166129
f900aa0dbb04ed9402a28476bcad95f913f0e3c5	neighborhood knowledge-based evolutionary algorithm for multiobjective optimization problems	sorting genetic algorithms knowledge acquisition learning artificial intelligence search problems;convergence;evolutionary computation;knowledge based system;direction learning stage neighborhood knowledge based evolutionary algorithm multiobjective optimization problems neighborhood relationship nkea nsga ii jgga fast nondominated sorting algorithm information horizontal transmission knowledge acquisition pareto optimal solutions adaptive control functions mutual adaptation stage self adaptation stage coarse local search fine local search;measurement;sorting;adaptive control;indexing terms;knowledge acquisition;next generation;multiobjective optimization;genetic algorithms;optimization;search problems;evolutionary algorithm;learning artificial intelligence;pareto optimal solution;sorting algorithm;optimization evolutionary computation measurement sorting convergence knowledge based systems algorithm design and analysis;local search;algorithm design;algorithm design and analysis;knowledge based systems;multiobjective optimization evolutionary algorithm knowledge acquisition;horizontal transmission;evolutionary computing;knowledge base	Although there are a variety of approaches to solve multiobjective optimization problems, few of them makes systematic use of the neighborhood relationship between the candidate solutions observed during the search process to improve the final results. In this paper, a new evolutionary algorithm, referred to as the neighborhood knowledge-based evolutionary algorithm (NKEA), is proposed to solve the multiobjective optimization problem. NKEA not only takes into account the advantages of NSGA-II, and JGGA, such as the fast nondominated sorting algorithm and horizontal transmission of information in a candidate solution, but also exploits systematically the neighborhood knowledge acquired during the search process. Specifically, NKEA consists of three major stages: the direction learning stage, the mutual adaptation stage, and the self adaptation stage. NKEA not only uses the fast nondominated sorting algorithm to find the Pareto optimal solutions, but also adopts the elitist strategy to maintain the best individuals for the next generation based on this strategy. Two adaptive control functions in the mutual adaptation stage and the self adaptation stage are designed to adjust the respective contributions of coarse local search and fine local search, which allows NKEA to perform a more thorough local search. Finally, we introduce a new notion, known as the measure space, which integrates multiple measures, such as the convergence metric and the diversity metric, to evaluate the performance of the algorithm. The results of our experiments show that NKEA not only achieves good performance in a large number of multiobjective optimization problems, but also outperforms most of the state-of-the-art approaches in these problems.	benchmark (computing);control function (econometrics);data mining;drive letter assignment;evolutionary algorithm;experiment;iteration;iterative and incremental development;k-nearest neighbors algorithm;locus;local search (optimization);mathematical optimization;multi-objective optimization;optimization problem;pareto efficiency;population;pseudocode;randomness;sorting algorithm	Zhiwen Yu;Hau-San Wong;Dingwen Wang;Ming Wei	2011	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2010.2051444	algorithm design;mathematical optimization;computer science;artificial intelligence;local search;machine learning;evolutionary computation	Vision	24.254694218574098	-4.212391507452573	166213
bb38a844c976517a849e46b547d62b4ecb895331	a robust ant colony optimization for continuous functions		The robust ant colony algorithm for continuous optimization is very simple to use.It doesnu0027t make any major conceptual change to ant colony optimizationu0027s structure.It uses a broad-range search which enables ants to search in a new domain.It is robust to initial domainu0027s properties such as length, symmetry and border.It can find the correct result in given domains without optimal solution. Ant colony optimization (ACO) for continuous functions has been widely applied in recent years in different areas of expert and intelligent systems, such as steganography in medical systems, modelling signal strength distribution in communication systems, and water resources management systems. For these problems that have been addressed previously, the optimal solutions were known a priori and contained in the pre-specified initial domains. However, for practical problems in expert and intelligent systems, the optimal solutions are often not known beforehand. In this paper, we propose a robust ant colony optimization for continuous functions (RACO), which is robust to domains of variables. RACO applies self-adaptive approaches in terms of domain adjustment, pheromone increment, domain division, and ant size without any major conceptual change to ACOu0027s framework. These new characteristics make the search of ants not limited to the given initial domain, but extended to a completely different domain. In the case of initial domains without the optimal solution, RACO can still obtain the correct result no matter how the initial domains vary. In the case of initial domains with the optimal solution, we also show that RACO is a competitive algorithm. With the assistance of RACO, there is no need to estimate proper initial domains for practical continuous optimization problems in expert and intelligent systems.	algorithm;ant colony optimization algorithms;continuous optimization;mathematical optimization;steganography	Zhiming Chen;Shaorui Zhou;Jieting Luo	2017	Expert Syst. Appl.	10.1016/j.eswa.2017.03.036	robustness (computer science);artificial intelligence;continuous optimization;ant colony optimization algorithms;machine learning;signal strength;metaheuristic;intelligent decision support system;ant;mathematical optimization;computer science;continuous function	AI	19.039987848848643	-7.303997220543766	166340
3ec591dd287915fc03dc3fbbfa316e42eeb741e9	earl: an evolutionary algorithm for record linkage	evolutionary algorithm;multiobjective optimization;data integrity;record linkage;evolutionary computing	Record linkage is an important problem in all data integration contexts that assume to be valid the hypothesis of data sources affected by errors. In this paper we formulate the record linkage problem as a multiobjective optimization problem and we propose an algorithm for solving it based on evolutionary computation. This computational paradigm has a stochastic, adaptive and intrinsically parallel nature that makes it particularly suitable for on-the-fly data integration contexts. Experiments on real datasets proved the effectiveness and efficiency of this novel approach.	evolutionary algorithm;evolutionary computation;experiment;linkage (software);mathematical optimization;multi-objective optimization;optimization problem;programming paradigm	Francesco Cusmai;Carola Aiello;Monica Scannapieco;Tiziana Catarci	2008			evolutionary computation;record linkage;data integration;probabilistic logic;data mining;evolutionary algorithm;data set;data integrity;multi-objective optimization;computer science	AI	22.625818128156936	-8.40082722120636	166352
86f9a9a0501ad9b72fdca27de4d045be59b7dc40	solver tuning with genetic algorithms		Currently the parameters in a constraint solver are often selected by hand by experts in the field; these parameters might include the level of preprocessing to be used, the variable ordering heuristic or the suitable modelling approach. The efficient and automatic mechanism of parameters tuning for a constraint solver is a step towards making constraint programming a more widely accessible technology. Two types of tuning algorithms are discussed in this thesis: single instance tuning algorithms and instance-based tuning algorithms. A standard genetic based algorithm and a sexual genetic based algorithm are proposed and implemented to deal with the single instance tuning. As an instance-based tuning algorithm, the self-learning genetic algorithm, which suggests or predicts a suitable solver configuration for test instances by learning from train instances, is proposed in this thesis. To improve the efficiency of the instance-based tuning in further, a self-learning sexual genetic algorithm, which combines the self-learning mechanism with the sexual genetic algorithm, was discussed. The experiments in the thesis demonstrate how genetic algorithms are implemented and adapted to aid in parameter selection for constraint solvers. Genetic algorithms were implemented as the fundamental algorithm for tuning and the parameter sensitivity of genetic algorithms is also discussed in this thesis.	constraint programming;experiment;genetic algorithm;heuristic;performance tuning;preprocessor;single-instance storage;solver	Hu Xu	2015			mathematical optimization;genetic algorithm;solver;computer science	AI	22.514843639743763	-2.912151600362581	166559
0c4c2d8a2d7f1d5e65fcde8cd926c9008c8d4182	fitness landscapes and search in the evolutionary design of digital circuits			continuous design;digital electronics;fitness function	Vesselin K. Vassilev	2000				EDA	23.79518062897475	-8.68011976787664	167293
fb78bdbc6ee4170927bc9ce48c4248cd31958517	artificial evolution		This paper investigates the correlation between the characteristics extracted from the problem instance and the performance of a simple evolutionary multiobjective optimization algorithm. First, a number of features are identified and measured on a large set of enumerable multiobjective NK-landscapes with objective correlation. A correlation analysis is conducted between those attributes, including low-level features extracted from the problem input data as well as high-level features extracted from the Pareto set, the Pareto graph and the fitness landscape. Second, we experimentally analyze the (estimated) running time of the global SEMO algorithm to identify a (1+ ε)-approximation of the Pareto set. By putting this performance measure in relation with problem instance features, we are able to explain the difficulties encountered by the algorithm with respect to the main instance characteristics.	evolutionary algorithm;experiment;high- and low-level;mathematical optimization;multi-objective optimization;pareto efficiency;time complexity	Pierrick Legrand;Marc-Michel Corsini;Jin-Kao Hao;Nicolas Monmarché;Evelyne Lutton;Marc Schoenauer	2013		10.1007/978-3-319-11683-9	engineering;artificial intelligence;operations research;evolutionary computation	AI	21.2301022531364	-6.172992851334008	167502
153ea3537b0d35b2984b252e2f711619d463c32f	search space boundaries in neural network error landscape analysis	measurement;training;artificial neural networks;linear programming;optimization;search problems;biological neural networks	Fitness landscape analysis encompasses a selection of techniques designed to estimate the properties of a search landscape associated with an optimisation problem. Applied to neural network training, fitness landscape analysis can be used to establish the link between the shape of the objective function and various neural network design and architecture properties. However, most fitness landscape analysis metrics rely on search space sampling. Since neural network search space is unbounded, it is unclear what subset of the search space should be sampled to obtain representative measurements. This study analyses fitness landscape properties of neural networks under various search space boundaries, and proposes meaningful search space bounds for neural network fitness landscape analysis.	algorithm;artificial neural network;entropy (information theory);error message;gradient;loss function;mathematical optimization;network planning and design;optimization problem;particle swarm optimization;rugged computer;sampling (signal processing);μ operator	Anna Sergeevna Bosman;Andries Petrus Engelbrecht;Mardé Helbig	2016	2016 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2016.7850152	artificial intelligence;machine learning;data mining;mathematics;fitness approximation	SE	23.573164531357346	-9.002633025077127	168268
97a830ff6c3401959946e54a0260f5ebfea6c528	utilitarian distributed constraint optimization problems		Privacy has been a major motivation for distributed problem optimization. However, even though several methods have been proposed to evaluate it, none of them is widely used. The Distributed Constraint Optimization Problem (DCOP) is a fundamental model used to approach various families of distributed problems. As privacy loss does not occur when a solution is accepted, but when it is proposed, privacy requirements cannot be interpreted as a criteria of the objective function of the DCOP. Here we approach the problem by letting both the optimized costs found in DCOPs and the privacy requirements guide the agents' exploration of the search space. We introduce Utilitarian Distributed Constraint Optimization Problem (UDCOP) where the costs and the privacy requirements are used as parameters to a heuristic modifying the search process. Common stochastic algorithms for decentralized constraint optimization problems are evaluated here according to how well they preserve privacy. Further, we propose some extensions where these solvers modify their search process to take into account their privacy requirements, succeeding in significantly reducing their privacy loss without significant degradation of the solution quality.	distributed constraint optimization;program optimization	Julien Savaux;Julien Vion;Sylvain Piechowiak;René Mandiau;Toshihiro Matsui;Katsutoshi Hirayama;Makoto Yokoo;Shakre Elmane;Marius-Calin Silaghi	2016	CoRR		mathematical optimization;computer science;data mining;management science	Robotics	18.59126697419245	-8.667028289928616	168298
0b438a150ac8496c164d14ca50c79c980ed8d8d0	genetic programming for modelling of geotechnical engineering systems		Over the last decade or so, artificial intelligence (AI) has proved to provide a high level of competency in solving many geotechnical engineering problems that are beyond the computational capability of classical mathematics and traditional procedures. This chapter presents one of the most interesting AI techniques, i.e. genetic programming (GP), and its applications in geotechnical engineering. In the last few years, GP, which is inspired by natural evolution of the human being, has proved to be successful in modelling several geotechnical engineering problems and has demonstrated superior predictive ability compared to traditional methods. In this chapter, the modelling aspects and formulation of GP are described and explained in some detail and an overview of most successful GP applications in geotechnical engineering are presented and discussed.	genetic programming	Mohamed A. Shahin	2015		10.1007/978-3-319-20883-1_2	systems engineering;civil engineering;mechanical engineering	DB	21.347979547359554	-6.159592961388661	168977
22faa83571d2b9b61f9f96d998f3625d44e7e5fd	parallel hypervolume-guided hyperheuristic for adapting the multi-objective evolutionary island model	optimal method;parallel models;evolutionary algorithm;multi objective optimization problem;hybrid algorithm	This work presents a new parallel model for the solution of multi-objective optimization problems. The model is based on the  cooperation of a set of evolutionary algorithms. The main aim is to raise the level of generality at which most current evolutionary  algorithms operate. This way, a wider range of problems can be tackled since the strengths of one algorithm can compensate  for the weaknesses of another. The proposed model is a hybrid algorithm that combines a parallel island-based scheme with  a hyperheuristic approach. The hyperheuristic is guided by the measurement of the hypervolume achieved by different optimization  methods. The model grants more computational resources to those schemes that show a more promising behaviour. The computational  results obtained for some tests available in the literature demonstrate the validity of the proposed model.  	hyper-heuristic	Coromoto León;Gara Miranda;Eduardo Segredo;Carlos Segura	2008		10.1007/978-3-642-03211-0_22	evolutionary programming;mathematical optimization	Logic	23.3947006415918	-3.7758418360822885	169563
bf7b704656ab9c348af6e76af470e6977d63b5f7	a cost-based model and algorithms for interleaving solving and elicitation of csps	satisfiability;iterative algorithm;backtrack search;average cost;constraint satisfaction problem	In Constraint Satisfaction Problems it is usually assumed that the CSP is available before the solving process begins, that is, the elicitation of the problem is completed before we attempt to solve the problem. As discussed in the work on Open Constraints and Interactive CSPs, there are situations where it can be advantageous and natural to interleave the elicitation and the solving. In particular, it may be expensive, in terms of time or other costs, to elicit certain constraints or parts of the constraints, and, we may very well not need all the complete constraints to be available in order for us to find a solution. In this paper we consider algorithms which take these costs into account. Constraints may be initially incomplete: it may be unknown whether certain tuples satisfy the constraint or not. We assume that we can determine such an unknown tuple, i.e., find out whether this tuple is in the constraint or not, but doing so incurs a known cost, which may vary between tuples. We also assume that we know the probability of an unknown tuple satisfying a constraint. An optimal algorithm for this situation is defined to be one which incurs minimal expected cost in finding a solution. We define algorithms for this problem, based on backtracking search. Specifically, we consider a simple iterative algorithm based on a cost limit on which unknowns may be determined, and a more complex algorithm which delays determining an unknown in order to estimate better whether doing so is worthwhile. We show experimentally the benefit in terms of cost of using the more sophisticated algorithms.	algorithm;backtracking;constraint programming;constraint satisfaction;decision analysis;dynamic programming;experiment;forward error correction;hadamard transform;influence diagram;iterative method;john d. wiley;loss function;markov chain;markov decision process;optimization problem;stochastic programming	Nic Wilson;Diarmuid Grimes;Eugene C. Freuder	2007		10.1007/978-3-540-74970-7_47	mathematical optimization;discrete mathematics;constraint learning;mathematics;iterative method;constraint satisfaction problem;algorithm;difference-map algorithm;hybrid algorithm;satisfiability	AI	18.877119778331743	-9.587197272083714	170601
63e5779b0b977f1971dcd0d94528d19a51a70a0c	searching for agent coalition using particle swarm optimization and death penalty function	multi agent system;binary particle swarm optimization;inequality constraint;convergence rate;coalition formation;objective function;particle swarm optimizer;unconstrained optimization;particle swarm optimization algorithm;penalty function	The issue of coalition formation problem has been investigated from many aspects. However, all of the previous work just take the capability of agent into account, but not consider those factors, such as the time that agent takes to achieve a task, the cost of employing agent, the credit standing of agent, the risk that the task sponsor bears, and the bias of task sponsor and so on. So we originally take these factors into account. The coalition problem in this paper is a constrained problem including a great deal of equality constraints and inequality constraints. So we adopt the death penalty function to transform it to an unconstrained one. That is to say, it becomes a single objective function. Being an unconstrained optimization algorithm, the binary particle swarm optimization algorithm is adopted to address this problem. To improve the capability of global searching of our algorithm and convergent rate of the solutions, we divide the process of coalition formation into two stages to deal with respectively. Simulations show that our algorithm is effective and feasible.	particle swarm optimization;penalty method	Sheng-Fu Zheng;Shan-Li Hu;Xian-Wei Lai;Chao-Feng Lin;She-Xiong Su	2007		10.1007/978-3-540-74171-8_20	mathematical optimization;multi-swarm optimization;simulation;computer science;artificial intelligence;penalty method;multi-agent system;mathematics;rate of convergence;metaheuristic	AI	20.680639239481195	-3.3826405556781745	170720
b3a9390e464d78626dbc8bf117dd4c74322bdbd2	how to compare performance of robust design optimization algorithms, including a novel method		This paper proposes a method to compare the performances of different methods for robust design optimization of computationally demanding models. Its intended usage is to help the engineer to choose the optimization approach when faced with a robust optimization problem. This paper demonstrates the usage of the method to find the most appropriate robust design optimization method to solve an engineering problem. Five robust design optimization methods, including a novel method, are compared in the demonstration of the comparison method. Four of the five compared methods involves surrogate models to reduce the computational cost of performing robust design optimization. The five methods are used to optimize several mathematical functions that should be similar to the engineering problem. The methods are then used to optimize the engineering problem to confirm that the most suitable optimization method was identified. The performance metrics used are the mean value and standard deviation of the robust optimum as well as an index that combines the required number of simulations of the original model with the accuracy of the obtained solution. These measures represents the accuracy, robustness and efficiency of the compared methods. The results of the comparison shows that sequential robust optimization is the method with best balance between accuracy and number of function evaluations. This is confirmed by the optimizations of the engineering problem. The comparison also shows that the novel method is better than its predecessor is.	algorithm;algorithmic efficiency;computation;mathematical optimization;optimization problem;performance;robust optimization;robustness (computer science);simulation;surrogate model	Johan Persson;Johan Ölvander	2017	AI EDAM	10.1017/S089006041700018X	mathematical optimization;derivative-free optimization;systems engineering;engineering;meta-optimization;probabilistic-based design optimization;test functions for optimization	AI	18.50992845039502	-4.923297609026274	170751
7ebe250ef888686c0cfa9d11e1620b7f35950019	a parallel evolutionary algorithm for technical market indicators optimization	finance;technical trading rules;evolutionary algorithms;optimization;stock market data mining	This paper deals with the optimization of parameters of technical indicators for stock market investment. Price prediction is a problem of great complexity and, usually, some technical indicators are used to predict market trends. The main difficulty in using technical indicators lies in deciding a set of parameter values. We proposed the use of Multi-Objective Evolutionary Algorithms (MOEAs) to obtain the best parameter values belonging to a collection of indicators that will help in the buying and selling of shares. The experimental results indicate that our MOEA offers a solution to the problem by obtaining results that improve those obtained through technical indicators with standard parameters. In order to reduce execution time is necessary to parallelize the executions. Parallelization results show that distributing the workload of indicators in multiple processors to improve performance is recommended. This parallelization has been performed taking advantage of the idle time in a corporate technology infrastructure. We have configured a small parallel grid using the students Labs of a Computer Science University College.	automatic parallelization;central processing unit;complex system;complexity;computer science;continuous optimization;evolutionary algorithm;experiment;kullback–leibler divergence;moea framework;mathematical optimization;parallel computing;run time (program lifecycle phase);scalability;spatial variability;x86	Diego J. Bodas-Sagi;Pablo Fernández-Blanco;José Ignacio Hidalgo;Francisco José Soltero-Domingo	2012	Natural Computing	10.1007/s11047-012-9347-4	mathematical optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm;management science	HPC	19.54140753540998	-3.1765403402951944	173813
57f2b5fe4f694a2408c394a5f393e2df72ae2191	genetic doping algorithm (gend): theory and applications	genetics;evolutionary algorithms;genetic algorithms;biodiversity	This paper describes an evolutionary algorithm, GenD, conceived by Buscema in 1998 at the Centro Ricerche di Scienze della Comunicazione - Semeion in Rome, where it is still successfully used and has been further developed. Unlike classic genetic algorithms, the GenD system maintains an inner instability during evolution, presenting a continuous evolution of the evolution and a natural increase in biodiversity during the progress of the algorithm. The theory which leads to defining the GenD system is outlined. Specific characteristics of GenD, such as the definition of a species-health aware evolutionary law, the use of genetic operators and the adoption of a structured organization of individuals (tribes), are described. In order to measure GenD capabilities, we investigated also different problems, such as that known as the travelling sales person problem, which belongs to the class of full NP problems.	doping (semiconductor);genetic algorithm	Paolo Massimo Buscema	2004	Expert Systems	10.1111/j.1468-0394.2004.00264.x	biodiversity;genetic algorithm;computer science;artificial intelligence;evolutionary algorithm;algorithm	Theory	24.037305285164773	-7.973891534812912	174442
44a82819e4ffe9ff86fcb7338de6941b7a82848d	design of graph-based evolutionary algorithms: a case study for chemical process networks	genetic program;chemical process optimization;structure optimization;network representations;theory and practice;variable structure;distance measure;search space;process network;genetic programming;chemical engineering;stochastic optimization;metric based evolutionary algorithms;process optimization;graph representation;evolutionary algorithms;network optimization;evolutionary algorithm;process simulation;algorithm design;minimal moves	This paper describes the adaptation of evolutionary algorithms (EAs) to the structural optimization of chemical engineering plants, using rigorous process simulation combined with realistic costing procedures to calculate target function values. To represent chemical engineering plants, a network representation with typed vertices and variable structure will be introduced. For this representation, we introduce a technique on how to create problem specific search operators and apply them in stochastic optimization procedures. The applicability of the approach is demonstrated by a reference example. The design of the algorithms will be oriented at the systematic framework of metricbased evolutionary algorithms (MBEAs). MBEAs are a special class of evolutionary algorithms, fulfilling certain guidelines for the design of search operators, whose benefits have been proven in theory and practice. MBEAs rely upon a suitable definition of a metric on the search space. The definition of a metric for the graph representation will be one of the main issues discussed in this paper. Although this article deals with the problem domain of chemical plant optimization, the algorithmic design can be easily transferred to similar network optimization problems. A useful distance measure for variable dimensionality search spaces is suggested.	acclimatization;chemical engineering;each (qualifier value);evolutionary algorithm;evolutionary computation;genetic operator;graph (abstract data type);graph - visual representation;heat exchanger device component;integer (number);intel high definition audio;kahn process networks;knowledge integration;mathematical optimization;microsoft outlook for mac;mutation;population parameter;power plants;probability;problem domain;process optimization;shape optimization;simulation;stochastic optimization;test case;vertex (graph theory);benefit	Michael T. M. Emmerich;Monika Grötzner;Martin Schütz	2001	Evolutionary Computation	10.1162/106365601750406028	genetic programming;algorithm design;mathematical optimization;combinatorics;computer science;artificial intelligence;machine learning;process optimization;evolutionary algorithm;mathematics;graph;algorithm;metaheuristic	AI	22.607831941829485	-8.312496973241107	174513
aa3a54c3f0386b953c8f6f20a742dd854291ab53	genetic improvement using higher order mutation	higher order mutation;sbse;gi	This paper presents a brief outline of a higher-order mutation-based framework for Genetic Improvement (GI). We argue that search-based higher-order mutation testing can be used to implement a form of genetic programming (GP) to increase the search granularity and testability of GI.	genetic improvement (computer science);genetic programming;mutation testing	Yue Jia;Fan Wu;Mark Harman;Jens Krinke	2015		10.1145/2739482.2768417	bioinformatics;engineering;genetics;algorithm	PL	24.0118697606663	-9.531469990812663	174905
204cf5f6f679c837d3d5793ad0fd4f27f1408362	multi-objective optimization based on pareto optimum in secondary cooling and ems of continuous casting	pareto optimization;casting;slabs;steel;electromagnetics;cooling	The process of Continuous casting cooling is a nonlinear, strong coupling, multi-input multi-output (MIMO) system, in existing control system of continuous casting of secondary cooling control and the final electromagnetic stirring(F-EMS) control are two independent control system. The optimization of control parameter often use two independent model, without considering the coupling effect between them, led to the slab quality fluctuation with changes on process parameter or steel. In order to solve the parameter optimization problem of the secondary cooling and electromagnetic stirring, the particle swarm with Pareto frontier multi-objective coordinated optimization algorithm is employed, combined with the most concerned requirements in temperature field, liquid core, which includes the temperature of raising and dropping in each cooling zone, and the liquid core radius satisfied the best electromagnetic stirring condition as the objective functions. Adopt adaptive grid system to evaluate the diversity of population, and to improve the consistency of the optimal solution set, using multidimensional vector weighting to process weights parameters of candidate solution set to obtain the final Pareto optimal solutions, finally, applied the optimization algorithm to continuous casting process, and verify the effectiveness and feasibility.	adaptive mesh refinement;computer cooling;control system;mimo;mass effect trilogy;mathematical optimization;multi-objective optimization;nonlinear system;optimization problem;pareto efficiency;particle swarm optimization;population;quantum fluctuation;requirement;sbcl;search algorithm;slab allocation	Jie Yang;Zhenping Ji;Shuai Liu;Qiong Jia	2016	2016 International Conference on Advanced Robotics and Mechatronics (ICARM)	10.1109/ICARM.2016.7606933	mathematical optimization;engineering;operations management;continuous optimization;engineering drawing	Robotics	17.794713063359378	-3.7988835027436294	176007
18f2610a07d2c62a9d06b44eebe7c32e7d34018d	approaches based on genetic algorithms for multiobjective optimization problems	genetic algorithm;multiobjective optimization;vector optimization;3d reconstruction	In engineering, it is often necessary to formulate problems in which there are several criteria or objectives. It is unlikely that a solution that optimizes one of the objectives will be optimal for any of the others. Compromise solutions are therefore sought such that no other solutions are better in any one objective while remaining no worse in the others. These types of problems are known as either multiobjective, multicriteria, or vector optimization problems. The problem addressed in this paper concerns the proposition of different approaches based on Genetic Algorithms to solve multiobjective optimization problems. We use notions about population manipulation and Pareto theory to develop our approaches, and study the Left Ventricle 3D Reconstruction problem from two Angiographics Views to test them.	3d reconstruction;approximation algorithm;constraint (mathematics);genetic algorithm;mathematical optimization;multi-objective optimization;pareto efficiency;program optimization;tree traversal;vector optimization	José Aguilar;Pablo Miranda	1999				AI	21.800945068655427	-3.435417910258952	176069
b28abc70eee3a5b628d20ba7ffa96dd54c29beb6	many independent objective (mio) algorithm for test suite generation		Automatically generating test suites is intrinsically a multi-objective problem, as any of the testing targets (e.g, statements to execute or mutants to kill) is an objective on its own. Test suite generation has peculiarities that are quite different from other more regular optimisation problems. For example, given an existing test suite, one can add more tests to cover the remaining objectives. One would like the smallest number of small tests to cover as many objectives as possible, but that is a secondary goal compared to covering those targets in the first place. Furthermore, the amount of objectives in software testing can quickly become unmanageable, in the order of (tens/hundreds of) thousands, especially for system testing of industrial size systems. Traditional multi-objective optimisation algorithms can already start to struggle with just four or five objectives to optimize. To overcome these issues, different techniques have been proposed, like for example the Whole Test Suite (WTS) approach and the Many-Objective Sorting Algorithm (MOSA). However, those techniques might not scale well to very large numbers of objectives and limited search budgets (a typical case in system testing). In this paper, we propose a novel algorithm, called Many Independent Objective (MIO) algorithm. This algorithm is designed and tailored based on the specific properties of test suite generation. An empirical study, on a set of artificial and actual software, shows that the MIO algorithm can achieve higher coverage compared to WTS and MOSA, as it can better exploit the peculiarities of test suite generation.		Andrea Arcuri	2017		10.1007/978-3-319-66299-2_1	computer science;artificial intelligence;machine learning;empirical research;software;system testing;test suite;exploit;algorithm;sorting algorithm	SE	20.94462202144109	-7.606192119145687	176686
bbf5a575332b56c217db50e420a6ce73d235eeba	evolutionary optimization for multiobjective portfolio selection under markowitz's model with application to the caracas stock exchange	optimization technique;portfolio selection;stock exchange;portfolio optimization;indexation;measure of risk;profitability;evolutionary optimization;mutual fund	Several problems in the area of financial optimization can be naturally dealt with optimization techniques under multiobjective approaches, followed by a decision-making procedure on the resulting efficient solutions. The problem of portfolio optimization is one of them. This chapter studies the use of evolutionary multiobjective techniques to solve such problems, focusing on Venezuelan market mutual funds between years 1994 and 2002. We perform a comparison of different evolutionary multiobjective approaches, namely NSGA-II, SPEA2, and IBEA, and show how these algorithms provide different optimization profiles. The subsequent step of solution selection is done using Sharpe’s index as a measure of risk premium. We firstly show that NSGA-II provides similar results to SPEA2 on mixed and fixed funds, and better (according to Sharpe’s index) solutions than SPEA2 on variable funds, indicating that NSGA-II provides a better coverage of the region containing interesting solutions for Sharpe’s index. Furthermore, IBEA outperforms both NSGA-II and SPEA2 in terms of index value attained. Finally, we also show that this procedure results in a more profitable solution than an indexed portfolio by the Caracas Stock Exchange.	evolutionary algorithm;mathematical optimization;multi-objective optimization	Feijoo Colomine Duran;Carlos Cotta;Antonio J. Fernández	2009		10.1007/978-3-642-00267-0_18	financial economics;post-modern portfolio theory;economics;modern portfolio theory;multi-objective optimization;finance;portfolio optimization;microeconomics;black–litterman model	AI	20.25178872620659	-4.374948446673568	176886
7fd55376aeb45fc5d8e86a0517d96bd6c2745885	objective reduction in many-objective optimization: evolutionary multiobjective approaches and comprehensive analysis	objective reduction many objective optimization multiobjective optimization multiobjective evolutionary algorithms;optimization algorithm design and analysis visualization search problems evolutionary computation correlation decision making	Many-objective optimization problems bring great difficulties to the existing multiobjective evolutionary algorithms, in terms of selection operators, computational cost, visualization of the high-dimensional tradeoff front, and so on. Objective reduction can alleviate such difficulties by removing the redundant objectives in the original objective set, which has become one of the most important techniques in many-objective optimization. In this paper, we suggest to view objective reduction as a multiobjective search problem and introduce three multiobjective formulations of the problem, where the first two formulations are both based on preservation of the dominance structure and the third one utilizes the correlation between objectives. For each multiobjective formulation, a multiobjective objective reduction algorithm is proposed by employing the nondominated sorting genetic algorithm II to generate a Pareto front of nondominated objective subsets that can offer decision support to the user. Moreover, we conduct a comprehensive analysis of two major categories of objective reduction approaches based on several theorems, with the aim of revealing their strengths and limitations. Lastly, the performance of the proposed multiobjective algorithms is studied extensively on various benchmark problems and two real-world problems. Numerical results and comparisons are then shown to highlight the effectiveness and superiority of the proposed multiobjective algorithms over existing state-of-the-art approaches in the related field.	algorithmic efficiency;benchmark (computing);decision support system;evolutionary algorithm;genetic algorithm;mathematical optimization;numerical method;objective collapse theory;pareto efficiency;search problem;sorting	Yuan Yuan;Yew-Soon Ong;Abhishek Gupta;Hua Xu	2018	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2017.2672668	mathematical optimization;engineering optimization;interactive evolutionary computation;computer science;multi-objective optimization;metaheuristic;evolutionary computation	AI	22.8633960153967	-4.0670197573806535	176966
0e03e3d6b01d7ab693003f72c326f0de29b4244d	on the impact of mutation-selection balance on the runtime of evolutionary algorithms	optimal solution;runtime analysis;multi type branching process;mutation rate;self organizing system;branching process;polynomial time;evolutionary algorithms;evolutionary algorithm;branching processes;fitness function;evolutionary computing	The interplay between the mutation operator and the selection mechanism plays a fundamental role in the behaviour of evolutionary algorithms. However, this interplay is still not completely understood. This paper presents a rigorous runtime analysis of a non-elitistic population based evolutionary algorithm that uses the linear ranking selection mechanism. The analysis focuses on how the balance between parameter η controlling the selection pressure in linear ranking selection, and parameter χ controlling the bit-wise mutation rate impacts the expected runtime.  The results point out situations where a correct balance between selection pressure and mutation rate is essential for finding the optimal solution in polynomial time. In particular, it is shown that there exist fitness functions which under a certain assumption can be solved in polynomial time if the ratio between parameters η and χ is appropriately tuned to the problem instance class, but where a small change in this ratio can increase the runtime exponentially. Furthermore, it is shown that the appropriate parameter choice depends on the characteristics of the fitness function. Hence there does in general not exists a problem-independent optimal balance between mutation rate and selection pressure.  The results are obtained using new techniques based on branching processes.	analysis of algorithms;evolutionary algorithm;existential quantification;fitness function;norm (social);time complexity	Per Kristian Lehre;Xin Yao	2009	IEEE Transactions on Evolutionary Computation	10.1145/1527125.1527133	evolutionary programming;time complexity;mutation rate;branching process;mathematical optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm;fitness function;algorithm	Embedded	23.946971725939044	-6.811732733694427	177864
38cf52b105b9498b8b3e1688e47ee7dd2c707562	obesity heuristic, new way on artificial immune systems	data cleaning	There is a need for new metaphors from immunology to flourish the application areas of Artificial Immune Systems. A metaheuristic called Obesity Heuristic derived from advances in obesity treatment is proposed. The main forces of the algorithm are the generation omega-6 and omega-3 fatty acids. The algorithm works with Just-In-Time philosophy; by starting only when desired. A case study of data cleaning is provided. With experiments conducted on standard tables, results show that Obesity Heuristic outperforms other algorithms, with 100% recall. This is a great improvement over other algorithms.	algorithm;artificial immune system;experiment;heuristic;just-in-time compilation;metaheuristic;plasma cleaning	M. A. El-Dosuky;A. F. El-Bassiouny;T. T. Hamza;M. Z. Rashad	2012	CoRR		simulation;computer science;artificial intelligence;machine learning;operations research	SE	20.89007042628565	-5.429180918965025	178086
795b57a8d5d07c54c2eb450f06506ae055066381	a preference-based multi-objective evolutionary algorithm r-nsga-ii with stochastic local search	multi-objective optimization;preference-based evolutionary algorithms;memetic algorithm;stochastic local search	Incorporation of a decision maker’s preferences into multi-objective evolutionary algorithms has become a relevant trend during the last decade, and several preference-based evolutionary algorithms have been proposed in the literature. Our research is focused on improvement of a well-known preference-based evolutionary algorithm R-NSGA-II by incorporating a local search strategy based on a single agent stochastic approach. The proposed memetic algorithm has been experimentally evaluated by solving a set of well-known multi-objective optimization benchmark problems. It has been experimentally shown that incorporation of the local search strategy has a positive impact to the quality of the algorithm in the sense of the precision and distribution evenness of approximation.	evolutionary algorithm;local search (optimization);multi-objective optimization	Ernestas Filatovas;Algirdas Lancinskas;Olga Kurasova;Julius Zilinskas	2017	CEJOR	10.1007/s10100-016-0443-x	evolutionary programming;mathematical optimization;machine learning;mathematics;management science;memetic algorithm	AI	23.028242139260385	-4.368884134944916	178546
edf16fd0a4521a7b7132e6a0a89e4198bf100e7c	distributed optimization with information-constrained population dynamics				Andres Pantoja;German D. Obando;Nicanor Quijano	2019	J. Franklin Institute	10.1016/j.jfranklin.2018.10.016		ML	17.638628446824555	-9.213772687713474	178667
2c7d643fdaae5d744f79f0e09ee61c4585a7c6cc	distributed coevolutionary genetic algorithms for multi-criteria and multi-constraint optimisation	genetic algorithm	This paper explores the use of coevolutionary genetic algorithms to attack hard optimisation problems. It outlines classes of practical problems which are diicult to tackle with conventional techniques, and indeed with standard`single species' genetic algorithms, but which may be amenable tòmulti-species' coevolutionary genetic algorithms. It is argued that such algorithms are most coherent and eeective when implemented as distributed genetic algorithms with local selection operating. Examples of the successful use of such techniques are described, with particular emphasis given to new work on a highly generalised version of the job shop scheduling problem.	coherence (physics);distributed computing;genetic algorithm;job shop scheduling;mathematical optimization;network planning and design;scheduling (computing);selection rule;sorting network	Phil Husbands	1994		10.1007/3-540-58483-8_12	quality control and genetic algorithms;genetic algorithm;computer science;artificial intelligence;genetic representation	AI	22.497323578602092	-5.071104289926917	178799
9130b7c2d49ec467688aff8732af770ae8cb8afc	metaheuristic algorithms for detect communities in social networks: a comparative analysis study		This﻿article﻿presents﻿a﻿comparative﻿analysis﻿between﻿Cuckoo﻿Search﻿Optimization﻿Algorithm,﻿Lion﻿ Optimization﻿Algorithm﻿and﻿Ant-Lion﻿Optimization﻿Algorithm.﻿Zachary﻿karate﻿Club,﻿The﻿Bottlenose﻿ Dolphin﻿Network,﻿American﻿College﻿Football﻿Network,﻿and﻿Facebook﻿used﻿as﻿benchmark﻿datasets﻿for﻿ comparison,﻿the﻿results﻿proved﻿those﻿algorithms﻿can﻿define﻿the﻿structure﻿and﻿detect﻿communities﻿of﻿ complex﻿networks﻿with﻿high﻿accuracy﻿and﻿quality﻿based﻿on﻿different﻿method﻿that﻿it﻿used.﻿The﻿Cuckoo﻿ Search﻿Optimization﻿Algorithm﻿is﻿the﻿best﻿algorithm﻿compared﻿to﻿Ant-Lion﻿Optimization﻿Algorithm﻿ and﻿Lion﻿Optimization﻿Algorithm﻿as﻿it﻿got﻿greatest﻿number﻿of﻿communities,﻿detect﻿communities﻿in﻿ used﻿benchmark﻿datasets﻿with﻿average﻿accuracy﻿%69,﻿average﻿modularity﻿%62﻿and﻿average﻿fitness﻿%60. KeywoRDS Ant Lion Optimization Algorithm, Community Structure, Cuckoo Search, Lion Optimization Algorithm, Networks Community Detection, Social Networks Analysis, Social Networks	algorithm;cuckoo search;metaheuristic;program optimization;social network	Aboul Ella Hassanien;Ramadan Babers	2018	IJRSDA	10.4018/IJRSDA.2018040102	machine learning;metaheuristic;social network;computer science;artificial intelligence	ML	24.14844625340396	-6.097320335580613	178832
36f0a3611075559692af566403e6bed86d247221	automatic selection of gcc optimization options using a gene weighted genetic algorithm	organisms;gcc optimization;program compilers genetic algorithms;optimization options;evolution biology;optimization level;biological cells;genetic algorithm;genetic algorithms;optimization;source code;gene weighted genetic algorithm;program compilers;optimization biological cells genetic algorithms evolution biology organisms benchmark testing program processors;program processors;benchmark testing;optimization level automatic selection gcc optimization gene weighted genetic algorithm program compilers optimization options;automatic selection	Compilers usually provide a large number of optimization options for users to fine tune the performance of their programs. However, most users donpsilat have the capability to select suitable optimization options. Compilers hence usually provide a number of optimization levels. Each optimization level is a pre-selected group of optimization options and produces good efficiency for most programs. However, they exploit only a portion of the available optimization options. There is still a large potential that an even better efficiency can be gained for each specific source code by exploiting the rest of the available optimization options. We propose a gene weighted genetic algorithm to search for optimization options better than optimization levels for each specific source code. We also show that this new genetic algorithm is more effective than the basic genetic algorithm for a set of benchmarks.	benchmark (computing);gnu compiler collection;genetic algorithm;mathematical optimization	San-Chih Lin;Chi-Kuang Chang;Nai-Wei Lin	2008	2008 13th Asia-Pacific Computer Systems Architecture Conference	10.1109/APCSAC.2008.4625477	mathematical optimization;multi-swarm optimization;meta-optimization;genetic algorithm;computer science;bioinformatics;theoretical computer science;multi-objective optimization	EDA	21.64050809600364	-8.305694519268629	178850
5acc69006784c2cbda67abfff8a5c2599a29e8be	a semantic network-based evolutionary algorithm for modeling memetic evolution and creativity		We introduce a novel evolutionary algorithm (EA) with a semantic network-based representation. For enabling this, we establish new formulations of EA variation operators, crossover and mutation, that we adapt to work on semantic networks. The algorithm employs commonsense reasoning to ensure all operations preserve the meaningfulness of the networks, using ConceptNet and WordNet knowledge bases. The algorithm can be classified as a novel memetic algorithm (MA), given that (1) individuals represent pieces of information that undergo evolution, as in the original sense of memetics as it was introduced by Dawkins; and (2) this is different from existing MA, where the word “memetic” has been used as a synonym for local refinement after global optimization. For evaluating the approach, we introduce an analogical similarity-based fitness measure that is computed through structure mapping. This setup enables the open-ended generation of networks analogous to a given base network.	case-based reasoning;causal filter;clustering coefficient;commonsense knowledge (artificial intelligence);commonsense reasoning;computation;computational biology;computational creativity;crossover (genetic algorithm);directed graph;evolutionary algorithm;evolving networks;experiment;expressive power (computer science);first-order logic;fitness function;global optimization;knowledge base;mathematical optimization;memetic algorithm;memetics;mutation (genetic algorithm);nonlinear gameplay;open mind common sense;refinement (computing);semantic network;shortest path problem;simulation;stochastic process;theory;wordnet	Atilim Günes Baydin;Ramón López de Mántaras;Santiago Ontañón	2014	CoRR		computer science;artificial intelligence;machine learning;algorithm;memetic algorithm	AI	22.961821993503712	-8.980184792333244	179110
7cf267cca63399ce319ceacb8434beba3815d8da	population-based heuristic algorithms for continuous and mixed discrete-continuous optimization problems	期刊论文	Continuous optimization problems are optimization problems where all variableshave a domain that typically is a subset of the real numbers; mixed discrete-continuousoptimization problems have additionally other types of variables, sothat some variables are continuous and others are on an ordinal or categoricalscale. Continuous and mixed discrete-continuous problems have a wide rangeof applications in disciplines such as computer science, mechanical or electricalengineering, economics and bioinformatics. These problems are also often hard tosolve due to their inherent difficulties such as a large number of variables, manylocal optima or other factors making problems hard. Therefore, in this thesis ourfocus is on the design, engineering and configuration of high-performing heuristicoptimization algorithms.We tackle continuous and mixed discrete-continuous optimization problemswith two classes of population-based heuristic algorithms, ant colony optimization(ACO) algorithms and evolution strategies. In a nutshell, the main contributionsof this thesis are that (i) we advance the design and engineering of ACO algorithms to algorithms that are competitive or superior to recent state-of-the-artalgorithms for continuous and mixed discrete-continuous optimization problems,(ii) we improve upon a specific state-of-the-art evolution strategy, the covariancematrix adaptation evolution strategy (CMA-ES), and (iii) we extend CMA-ES totackle mixed discrete-continuous optimization problems.More in detail, we propose a unified ant colony optimization (ACO) frameworkfor continuous optimization (UACOR). This framework synthesizes algorithmiccomponents of two ACO algorithms that have been proposed in the literatureand an incremental ACO algorithm with local search for continuous optimization,which we have proposed during my doctoral research. The design of UACORallows the usage of automatic algorithm configuration techniques to automaticallyderive new, high-performing ACO algorithms for continuous optimization. We alsopropose iCMAES-ILS, a hybrid algorithm that loosely couples IPOP-CMA-ES, aCMA-ES variant that uses a restart schema coupled with an increasing populationsize, and a new iterated local search (ILS) algorithm for continuous optimization.The hybrid algorithm consists of an initial competition phase, in which IPOP-CMA-ES and the ILS algorithm compete for further deployment during a secondphase. A cooperative aspect of the hybrid algorithm is implemented in the formof some limited information exchange from IPOP-CMA-ES to the ILS algorithmduring the initial phase. Experimental studies on recent benchmark functionssuites show that UACOR and iCMAES-ILS are competitive or superior to otherstate-of-the-art algorithms.To tackle mixed discrete-continuous optimization problems, we extend ACOMV and propose CESMV, an ant colony optimization algorithm and a covariance matrix adaptation evolution strategy, respectively. In ACOMV and CESMV , the decision variables of an optimization problem can be declared as continuous, ordinal, or categorical, which allows the algorithm to treat them adequately. ACOMV andCESMV include three solution generation mechanisms: a continuous optimizationmechanism, a continuous relaxation mechanism for ordinal variables, and a categorical optimization mechanism for categorical variables. Together, these mechanisms allow ACOMV and CESMV to tackle mixed variable optimization problems.We also propose a set of artificial, mixed-variable benchmark functions, which cansimulate discrete variables as ordered or categorical. We use them to automatically tune ACOMV and CESMV's parameters and benchmark their performance.Finally we test ACOMV and CESMV on various real-world continuous and mixed-variable engineering optimization problems. Comparisons with results from theliterature demonstrate the effectiveness and robustness of ACOMV and CESMVon mixed-variable optimization problems.Apart from these main contributions, during my doctoral research I have accomplished a number of additional contributions, which concern (i) a note on thebound constraints handling for the CEC'05 benchmark set, (ii) computational results for an automatically tuned IPOP-CMA-ES on the CEC'05 benchmark set and(iii) a study of artificial bee colonies for continuous optimization. These additionalcontributions are to be found in the appendix to this thesis.	algorithm;continuous optimization;heuristic;mathematical optimization;population	Tianjun Liao	2015	4OR	10.1007/s10288-015-0285-8	probabilistic-based design optimization;discrete optimization;optimization problem;mathematical optimization;multi-swarm optimization;test functions for optimization;meta-optimization;special ordered set;computer science;derivative-free optimization;artificial intelligence;multi-objective optimization;machine learning;mathematics;continuous optimization;l-reduction;bilevel optimization;random optimization;metaheuristic	AI	23.465135237865315	-3.564307408815006	179867
48b06b51f0c670c5e1b618021c7b8b288ce73284	towards a better diversity of evolutionary multi-criterion optimization algorithms using local searches	extreme points;local search;multiobjective evolutionary optimization	In EMO diversity of the obtained solutions is an important factor, particularly for decision makers. NSGA-III is a recently proposed reference direction based algorithm that was shown to be successful up to as many as 15 objectives. In this study, we propose a diversity enhanced version of NSGA-III. Our algorithm augments NSGA-III with two types of local search. The first aims at finding the true extreme points of the Pareto front, while the second targets internal points. The two local search optimizers are carefully weaved into the fabric of NSGA-III niching procedure. The final algorithm maintains the total number of function evaluations to a minimum, enables using small population sizes, and achieves higher diversity without sacrificing convergence on a number of multi and many-objective problems.	algorithm;internet gateway device protocol;local search (optimization);mathematical optimization;maxima and minima;pareto efficiency;seamless3d;simulation;span and div;weatherstar	Haitham Ahmed Seada;Mohamed Abouhawwash;Kalyanmoy Deb	2016		10.1145/2908961.2908991	extreme point;mathematical optimization;computer science;local search;machine learning;mathematics;management science	ML	24.292386434518658	-3.4995522484438224	180315
ee6113900ed89ecde88e824835adebd61a3f9777	exploratory data analysis in a study of the performance of nonlinear optimization routines	nonlinear optimization;exploratory data analysis	Investigations into the comparative performance of mathematical software often involve collection and analysis of data under circumstances where the behavior of the software is not understood and unexpected results are likely to arise. The recently developed statistical techniques of exploratory data analysis are well suited to exposing important regularities of such data. Several of these techniques are explained and illustrated. Nonlinear optmuzation algorithms are comphcated by nature, and data on the performance of some of them provide an opportunity to apply exploratory techniques and other techniquos of modern data analysis. The focus of this study is on one relatively small body of data from selected measurements by K. E. Hillstrom on five nonlinear optimization routines in solving one test problem, starting from each of twenty randomly chosen starting points. The variability of performance across optimizers is described, and the effect of starting points is exposed. The concluding discussion examines some aspects of the design issues in studying behavior of mathematical software and related data analysis problems.	algorithm;exploratory testing;mathematical optimization;mathematical software;nonlinear programming;nonlinear system;optimizing compiler;randomness;spatial variability	David C. Hoaglin;Virginia Klema;Stephen C. Peters	1982	ACM Trans. Math. Softw.	10.1145/355993.355996	nonlinear programming;mathematics;exploratory data analysis	PL	22.357324821346936	-7.010423289664095	180496
c40c624b7841f7645918215bc601cffa732029e4	dynamic portfolio optimization in ultra-high frequency environment		This paper concerns the problem of portfolio optimization in the context of ultra-high frequency environment with dynamic and frequent changes in statistics of financial assets. It aims at providing Pareto fronts of optimal portfolios and updating them when estimated return rates or risks of financial assets change. The problem is defined in terms of dynamic optimization and solved online with a proposed evolutionary algorithm. Experiments concern ultra-high frequency time series coming from the London Stock Exchange Rebuilt Order Book database and the FTSE100 index.	ultra high frequency	Patryk Filipiak;Piotr Lipinski	2017		10.1007/978-3-319-55849-3_3	mathematical optimization;evolutionary algorithm;pareto principle;economics;stock exchange;portfolio optimization;multi-objective optimization;ultra high frequency;order book	EDA	18.67386538134051	-4.307117981042174	181846
5b9f74babb43485ac2b10a6819b79a4d06bd3cc8	differential evolution with improved individual-based parameter setting and selection strategy	differential evolution;selection strategy;global optimization;parameters setting;combined mutation strategy	In this paper, a novel differential evolution (DE) algorithm is designed to improve the search efficiency of DE by employing the information of individuals to adaptively set the parameters of DE and update population. Firstly, a combined mutation strategy is developed by using two mixed mutation strategies with a prescribed probability. Secondly, the fitness values of original and guiding individuals is used to guide the parameter setting. Finally, a diversity-based selection strategy is designed by assembling greedy selection strategy and defining a new weighted fitness value based on the fitness values and positions of target and trial individuals. The proposed algorithm compares with eight existing algorithms on CEC 2005 and 2014 contest test instances, and is applied to solve the Spread Spectrum Radar Polly Code Design. Experimental results show that the proposed algorithm is very competitive.	benchmark (computing);differential evolution;experiment;exploit (computer security);feature selection;greedy algorithm;numerical analysis;performance;polly (robot);radar;tournament selection	Mengnan Tian;Xingbao Gao;Cai Dai	2017	Appl. Soft Comput.	10.1016/j.asoc.2017.03.010	differential evolution;mathematical optimization;artificial intelligence;management science;global optimization	AI	24.20771241712647	-4.15225810247952	181946
2d1b0492e349201bdaf1c7cc8c4109174aa1c424	optimization algorithms for one-class classification ensemble pruning		One-class classification is considered as one of the most challenging topics in the contemporary machine learning. Creating Multiple Classifier Systems for this task has proven itself as a promising research direction. Here arises a problem on how to select valuable members to the committee - so far a largely unexplored area in one-class classification. Recently, a novel scheme utilizing a multi-objective ensemble pruning was proposed. It combines selecting best individual classifiers with maintaining the diversity of the committee pool. As it relies strongly on the search algorithm applied, we investigate here the performance of different methods. Five algorithms are examined - genetic algorithm, simulated annealing, tabu search and hybrid methods, combining the mentioned approaches in the form of memetic algorithms. Using compound optimization methods leads to a significant improvement over standard search methods. Experimental results carried on a number of benchmark datasets proves that careful examination of the search algorithms for one-class ensemble pruning may greatly contribute to the quality of the committee being formed.		Bartosz Krawczyk;Michal Wozniak	2014		10.1007/978-3-319-05458-2_14	ensemble learning;pruning	AI	20.883036932659863	-6.314060312673887	183065
af9d210289a419164d2bf628e685c57bdf90fe8d	an adaptive fitness function based on branch hardness for search based testing		Search based software testing has received great attention as a means of automating the test data generation, and the goal is to improve various criteria. There are different types of coverage criteria. In this paper, we deal with the path coverage. Concretely, we focus on the path that is the most difficult to cover. One major limitation of search based testing is the inefficient and insufficiently informed fitness function. To address this problem, we propose an adaptive fitness function based on branch hardness. The branch hardness is measured by the expected number of visits of each branch in the program, which is modeled by an absorbing discrete time Markov chain. By tuning the parameters of branch hardness heuristically, the search hardness, evaluated by the variation coefficient of the fitness function, of generating test data can be minimized. Therefore, this new fitness function is more flexible than the traditional counterparts. In addition, we point out that the present definition of branch distance and the use of normalizing functions are problematic, and propose some improvements. Finally, the empirical study reveals the promising result of our proposal in this paper.	code coverage;coefficient;experiment;fitness function;heuristic;hyper-heuristic;markov chain;mathematical optimization;naruto shippuden: clash of ninja revolution 3;numerical analysis;problem domain;search algorithm;software testing;test data generation;warez	Xiong Xu;Ziming Zhu;Li Jiao	2017		10.1145/3071178.3071184	discrete time and continuous time;computer science;machine learning;artificial intelligence;mathematical optimization;expected value;fitness approximation;test data generation;test data;heuristic;markov chain;fitness function	SE	20.95220752928323	-7.751859347492895	183425
4498ec14ef8a03c499b26195ae10dc96cc5249cb	evolutionary techniques versus swarm intelligences: application in reservoir release optimization	particle swarm optimization;genetic algorithms;artificial bee colony optimization;optimal reservoir release policy	In this paper, a nonlinear reservoir release optimization problem has been solved by using four optimization tools with various combinations of input parameters that are generally used in this research field. A comparison has been made between evolutionary methods [genetic algorithm (GA)] and swarm intelligences [particle swarm optimization (PSO) and artificial bee colony (ABC) optimization] in searching the optimum reservoir release policy. From the historical recorded data, the monthly inflow was categorized into three states: high, medium and low. As a guideline for the decision maker, an optimum release curve was generated for each month showing the release options with a variety of different storage conditions. GA (real and binary), ABC optimization and PSO algorithm have been used as optimization tools with the same formulation and objective function for all the methods. For verification of the models, a simulation is done by using 264 monthly historical inflow data. Different indices such as reliability, vulnerability and resiliency were calculated in order to check the performance and risk analysis purposes. The results show that the most recently developed ABC optimization technique provides the best results in meeting demands, avoiding wastage of water and in handling critical period of low flows.	artificial bee colony algorithm;categorization;evolutionary algorithm;genetic algorithm;it risk management;mathematical optimization;nonlinear system;optimization problem;particle swarm optimization;performance tuning;phase-shift oscillator;simulation;software release life cycle;systems management	Md S. Hossain;Ahmed El-Shafie	2013	Neural Computing and Applications	10.1007/s00521-013-1389-8	multi-swarm optimization;test functions for optimization;meta-optimization;genetic algorithm;computer science;derivative-free optimization;artificial intelligence;particle swarm optimization;operations research;metaheuristic	EDA	17.475454414323927	-3.1501558057692884	183570
6dc9654d2bc1514c96d3505f73c5b779d6b5e4b3	 r2-based multi/many-objective particle swarm optimization		We propose to couple the R2 performance measure and Particle Swarm Optimization in order to handle multi/many-objective problems. Our proposal shows that through a well-designed interaction process we could maintain the metaheuristic almost inalterable and through the R2 performance measure we did not use neither an external archive nor Pareto dominance to guide the search. The proposed approach is validated using several test problems and performance measures commonly adopted in the specialized literature. Results indicate that the proposed algorithm produces results that are competitive with respect to those obtained by four well-known MOEAs. Additionally, we validate our proposal in many-objective optimization problems. In these problems, our approach showed its main strength, since it could outperform another well-known indicator-based MOEA.	algorithm;archive;distribution (mathematics);entity name part qualifier - adopted;function problem;moea framework;mathematical optimization;metaheuristic;multi-objective optimization;numerous;optimization problem;pareto efficiency;particle swarm optimization;scalability;turing test;gallium (67)-dfo-sms;interest	Alan Díaz-Manríquez;Gregorio Toscano Pulido;Jose Hugo Barron-Zambrano;Edgar Tello-Leal	2016		10.1155/2016/1898527	mathematical optimization;multi-swarm optimization;simulation;artificial intelligence	Vision	23.611726346513752	-3.664564723795294	184109
d3300da06e40fd81ab5ed40a4ebd378ac7dc8e54	multi-objective inventory routing with uncertain demand using population-based metaheuristics		This article studies a tri-objective formulation of the inventory routing problem, extending the recently studied biobjective formulation. As compared to distance cost and inventory cost, which were discussed in previous work, it also considers stockout cost as a third objective. Demand is modeled as a Poisson random variable. State-of-the-art evolutionary multi-objective optimization algorithms and a new method based on swarm intelligence are used to compute approximation of the 3-D Pareto front. A bench-mark previously used in bi-objective inventory routing is extended by incorporating a uncertain demand model with an expected value that equals the average demand of the original benchmark. The results provide insights into the shape of the optimal trade-off surface. Based on this the dependences between different objectives are clarified and discussed. Moreover, the performances of the four different algorithmic methods are compared and due to the consistency in the results, it can be concluded that a near optimal approximation to the Pareto front can be found for problems of practically relevant size.	ant colony optimization algorithms;approximation;benchmark (computing);computation;desktop computer;evolutionary algorithm;experiment;genetic algorithm;loss function;mathematical optimization;metaheuristic;microsoft outlook for mac;multi-objective optimization;nl (complexity);optimization problem;parabolic antenna;pareto efficiency;performance;personal computer;real-time transcription;swarm intelligence;time complexity;triangular function;vehicle routing problem;yang	Zhiwei Yang;Michael T. M. Emmerich;Thomas Bäck;Joost N. Kok	2016	Integrated Computer-Aided Engineering	10.3233/ICA-160515	mathematical optimization	AI	21.311026512052244	-3.3809647601254835	184496
97ac1fecec1633871b7767775b372fb8867b56dd	optimal parameter choices through self-adjustment: applying the 1/5-th rule in discrete settings	runtime analysis;parameter control;adaptive parameter choice;theory;genetic algorithms	While evolutionary algorithms are known to be very successful for a broad range of applications, the algorithm designer is often left with many algorithmic choices, for example, the size of the population, the mutation rates, and the crossover rates of the algorithm. These parameters are known to have a crucial influence on the optimization time, and thus need to be chosen carefully, a task that often requires substantial efforts. Moreover, the optimal parameters can change during the optimization process. It is therefore of great interest to design mechanisms that dynamically choose best-possible parameters. An example for such an update mechanism is the one-fifth success rule for step-size adaption in evolutionary strategies. While in continuous domains this principle is well understood also from a mathematical point of view, no comparable theory is available for problems in discrete domains. In this work we show that the one-fifth success rule can be effective also in discrete settings. We regard the (1+(λ,λ)) GA proposed in [Doerr/Doerr/Ebel: From black-box complexity to designing new genetic algorithms, TCS 2015]. We prove that if its population size is chosen according to the one-fifth success rule then the expected optimization time on OneMax is linear. This is better than what any static population size λ can achieve and is asymptotically optimal also among all adaptive parameter choices.	asymptotically optimal algorithm;black box;evolutionary algorithm;genetic algorithm;mathematical optimization;software release life cycle	Benjamin Doerr;Carola Doerr	2015		10.1145/2739480.2754684	mathematical optimization;genetic algorithm;computer science;artificial intelligence;machine learning;theory;algorithm	Theory	23.983883940835796	-6.844852464324475	184787
65dbedcf77b4caf35fae7055615d0bfb20a6a3bc	mobile robot controller design by evolutionary multiobjective optimization in multiagent environments	evolutionary multiobjective optimization;mobile robots;behavior coordination;multiagent environments	Evolutionary computation has been often used for the design of mobile robot controllers thanks to its flexibility and global search ability. A lot of studies have been done based on single-objective functions including weighted-sum scalarizing objective functions. For an example of mobile robot navigation, at least the minimization of the arrival time to the target and the minimization of dangerous situations should be considered. In this case, a weighted-sum of two objectives is always minimized. It is, however, difficult to specify an appropriate weight vector beforehand. This paper demonstrates the application of evolutionary multiobjective optimization to mobile robot navigation in order to optimize the conflicting objective simultaneously. We analyze the obtained non-dominated controllers through simulation experiments in multiagent environments. We also show the utilization of the obtained non-dominated controllers for situation change.	agent-based model;mobile robot;multi-objective optimization	Yusuke Nojima;Hisao Ishibuchi	2011		10.1007/978-3-642-25489-5_50	control engineering;mobile robot;mathematical optimization;simulation;computer science;engineering;artificial intelligence;evolutionary robotics	Robotics	18.915958869913748	-4.746721805930301	185645
0a394201e766e00f51c0deee244fb7fa16c9bb9d	orthogonal learning competitive swarm optimizer for economic dispatch problems		Abstract Power system economic dispatch (ED), mathematically, is a typical complex nonlinear multivariable strongly coupled optimization problem with equality and inequality constraints, especially considering the valve-point effects. In this paper, a novel variant of competitive swarm optimizer (CSO) referred to as OLCSO is proposed to solve both convex and non-convex ED problems. In the canonical CSO, the loser particle in each pair updates its position by learning from the winner particle. Such a learning strategy is easy to implement, but is not efficient enough because even a bad particle can contain useful information while a good particle may have misleading features. To solve this issue, an orthogonal learning (OL) strategy based on orthogonal experimental design is developed for CSO to quickly discover more useful information that contained in the winner and the loser particles. The OL strategy can easily construct a more promising solution to provide a more systematic search strategy for OLCSO. A set of 24 numerical benchmark functions and three ED cases with diverse complexities and characteristics are used to comprehensively verify the performance of OLCSO. The experimental results and comparison results consistently indicate that OLCSO can be used as a competitive alternative for ED problems.	dynamic dispatch;mathematical optimization;swarm	Guojiang Xiong;Dongyuan Shi	2018	Appl. Soft Comput.	10.1016/j.asoc.2018.02.019	mathematical optimization;swarm behaviour;machine learning;inequality;artificial intelligence;mathematics;multivariable calculus;economic dispatch;nonlinear system;optimization problem	Theory	23.776862002240243	-4.396381860726294	185852
4b41da6dfaaa2590bc03dbb8b32197b81284361c	theoretical analysis of lexicase selection in multi-objective optimization		Lexicase selection is a parent selection mechanism originally introduced for genetic programming that has also been considered in the context of multi-objective optimization. This is the first theoretical runtime analysis of lexicase selection showing results for the bi-objective leading ones trailing zeroes benchmark problem. The lexicase selection operator is embedded into a simple hillclimbing algorithm and compared with different selection operators from the literature that are based on the classical dominance relationship. Strengths and weaknesses of the operators are demonstrated providing insights into their working principles. Results of experiments accompany the theoretical findings and point towards interesting questions for future research.	lexicase;mathematical optimization;multi-objective optimization	Thomas Jansen;Christine Zarges	2018		10.1007/978-3-319-99259-4_13	operator (computer programming);artificial intelligence;mathematical optimization;machine learning;computer science;genetic programming;multi-objective optimization;strengths and weaknesses	Logic	23.91947689473383	-6.025322229985242	186003
33556fefe796ee0afa318f048d9b81ae240e0ca0	applying a multiobjective metaheuristic inspired by honey bees to phylogenetic inference	swarm intelligence;bioinspired computation;phylogeny reconstruction;multiobjective optimization;computational biology	The development of increasingly popular multiobjective metaheuristics has allowed bioinformaticians to deal with optimization problems in computational biology where multiple objective functions must be taken into account. One of the most relevant research topics that can benefit from these techniques is phylogenetic inference. Throughout the years, different researchers have proposed their own view about the reconstruction of ancestral evolutionary relationships among species. As a result, biologists often report different phylogenetic trees from a same dataset when considering distinct optimality principles. In this work, we detail a multiobjective swarm intelligence approach based on the novel Artificial Bee Colony algorithm for inferring phylogenies. The aim of this paper is to propose a complementary view of phylogenetics according to the maximum parsimony and maximum likelihood criteria, in order to generate a set of phylogenetic trees that represent a compromise between these principles. Experimental results on a variety of nucleotide data sets and statistical studies highlight the relevance of the proposal with regard to other multiobjective algorithms and state-of-the-art biological methods.		Sergio Santander-Jiménez;Miguel A. Vega-Rodríguez	2013	Bio Systems	10.1016/j.biosystems.2013.07.001	biology;mathematical optimization;swarm intelligence;computer science;bioinformatics;multi-objective optimization;machine learning	Comp.	22.878696052734252	-7.9181620051993855	186505
cbdb123aa00ff90f892648a7c93b1c74640bb357	the influence of fitness caching on modern evolutionary methods and fair computation load measurement		Any evolutionary method may store the fitness values for the genotypes it has already rated. Any time the fitness is to be computed, the check may be made if the fitness for the same genotype was not computed earlier. If so, then instead of re-evaluating the same genotype, the stored value from the repository may be returned. Such technique will be denoted as fitness caching. It is easy to implement in any evolutionary method, and it minimizes the number of fitness function evaluations (FFE), which is desirable. Despite its simplicity fitness caching may significantly affect the computation load spent on fitness computation. Moreover, it may cause that the FFE will not be a reliable computation load measure.	cache (computing);computation;evolutionary algorithm;fitness function	Michal Witold Przewozniczek;Marcin M. Komarnicki	2018		10.1145/3205651.3205788	mathematical optimization;artificial intelligence;computer science;machine learning;genetic algorithm;computation;fitness function	Theory	23.989015354948773	-6.995287037735531	186949
9f8b8765ffae411485aec75fdc917d794604cd66	pareto-optimal search-based software engineering (posbse): a literature survey	meoa pareto optimal search based software engineering posbse multiobjectiveness multiobjective search software algorithms software tools software quality indicators multiobjective evolutionary optimization algorithms nsga ii spea2;pareto optimisation;evolutionary computation;software quality evolutionary computation genetic algorithms pareto optimisation search problems;pareto optimal solutions;search based software engineering;software software algorithms algorithm design and analysis software engineering search problems pareto optimization;search based software engineering multiobjective optimization pareto optimal solutions;multiobjective optimization;genetic algorithms;search problems;software quality	The Search-Based Software Engineering (SBSE) community is increasingly recognizing the inherit “multiobjectiveness” in Software Engineering problems. The old ways of aggregating all objectives into one may very well be behind us. We perform a well-deserved literature survey of SBSE papers that used multiobjective search to find Pareto-optimal solutions, and we pay special attention to the chosen algorithms, tools, and quality indicators, if any. We conclude that the SBSE field has seen a trend of adopting the Multiobjective Evolutionary Optimization Algorithms (MEOAs) that are widely used in other fields (such as NSGA-II and SPEA2) without much scrutiny into the reason why one algorithm should be preferred over the others. We also find that the majority of published work only tackled two-objective problems (or formulations of problems), leaving much to be desired in terms of exploiting the power of MEOAs to discover solutions to intractable problems characterized by many trade-offs and complex constraints.	evolutionary algorithm;multi-objective optimization;pareto efficiency;search-based software engineering	Abdel Salam Sayyad;Hany Ammar	2013	2013 2nd International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering (RAISE)	10.1109/RAISE.2013.6615200	mathematical optimization;search-based software engineering;computer science;machine learning;management science;software metric	SE	21.924633070971154	-4.649104947744029	187107
8de83cc2648bb86440f737f9d9d328f6384db2cd	an input adjustable tree algorithm for evolutionary testing	software testing;testing input variables gallium software testing genetics distance measurement evolutionary computation;evolutionary computation;flag variables;input variables;input adjustable tree algorithm;testing;genetics;distance measurement;structural testing;genetic algorithm;source code;structure testing;genetic algorithm structure testing evolutionary testing;evolutionary testing;source code input adjustable tree algorithm evolutionary testing flag variables;gallium	This paper proposes an Input Adjustable Tree Algorithm for the flag problems of evolutionary testing (ET). With the algorithm, the dependencies of input and internal/flag variables can be determined. Based on that, ET guides the search efficiently with the presence of flag variables in the source code.	algorithm;experiment;fitness function;population;software release life cycle;test case	Hsinyi Jiang;Katsunori Oyama;Carl K. Chang	2008	2008 32nd Annual IEEE International Computer Software and Applications Conference	10.1109/COMPSAC.2008.187	mathematical optimization;computer science;software engineering;software testing;algorithm;evolutionary computation	Robotics	21.319798948985564	-8.064337993786712	188393
3c6f75c1921fa55667b360ed3faa424ae0aa4697	multi-objective analysis of map-elites performance		In certain complex optimization tasks, it becomes necessary to use multiple measures to characterize the performance of different algorithms. This paper presents a method that combines ordinal effect sizes with Pareto dominance to analyze such cases. Since the method is ordinal, it can also generalize across different optimization tasks even when the performance measurements are differently scaled. Through a case study, we show that this method can discover and quantify relations that would be difficult to deduce using a conventional measure-bymeasure analysis. This case study applies the method to the evolution of robot controller repertoires using the MAP-Elites algorithm. Here, we analyze the search performance across a large set of parametrizations; varying mutation size and operator type, as well as map resolution, across four different robot morphologies. We show that the average magnitude of mutations has a bigger effect on outcomes than their precise distributions.		Eivind Samuelsen;Kyrre Glette	2018	CoRR		mathematical optimization;machine learning;control theory;ordinal number;magnitude (mathematics);artificial intelligence;pareto principle;computer science;bitwise operation	ML	19.66458900658925	-6.792525026910568	188480
718c5073ab3ecadd7ee926cd0fe3c9353a729313	a study on fuzzy cognitive map optimization using metaheuristics		Fuzzy Cognitive Maps (FCMs) are a framework based on weighted directed graphs which can be used for system modeling. The relationships between the concepts are stored in graph edges and they are expressed as real numbers from the ([-1,1]) interval (called weights). Our goal was to evaluate the effectiveness of non-deterministic optimization algorithms which can calculate weight matrices (i.e. collections of all weights) of FCMs for synthetic and real-world time series data sets. The best results were reported for Differential Evolution (DE) with recombination based on 3 random individuals, as well as Particle Swarm Optimization (PSO) where each particle is guided by its neighbors and the best particle. The choice of the algorithm was not crucial for maps of size roughly up to 10 nodes, however, the difference in performance was substantial (in the orders of magnitude) for bigger matrices.	fuzzy cognitive map;metaheuristic	Aleksander Cislak;Wladyslaw Homenda;Agnieszka Jastrzebska	2016		10.1007/978-3-319-45378-1_51	ant colony optimization algorithms;artificial intelligence	HCI	22.147512166777116	-7.903537235363627	188680
e514863419341c6b17c6b7fc513341579c28a89b	using omnidirectional bts and different evolutionary approaches to solve the rnd problem	radio networks;differential evolution;optimization technique;omnidirectional bts;population based incremental learning;multi objective optimization;de;sa;simulated annealing;sensor network;competitive learning;chc;optimization problem;np hard problem;mobile telecommunication;pbil;rnd;genetic algorithm;evolutionary algorithm;grid computing;neural network	RND (Radio Network Design) is an important problem in mobile telecommunications (for example in mobile/cellular telephony), being also relevant in the rising area of sensor networks. This problem consists in covering a certain geographical area by using the smallest number of radio antennas achieving the biggest cover rate. To date, several radio antenna models have been used: square coverage antennas, omnidirectional antennas that cover a circular area, etc. In this work we use omnidirectional antennas. On the other hand, RND is an NP-hard problem; therefore its solution by means of evolutionary algorithms is appropriate. In this work we study different evolutionary approaches to tackle this problem. PBIL (Population-Based Incremental Learning) is based on genetic algorithms and competitive learning (typical in neural networks). DE (Differential Evolution) is a very simple population-based stochastic function minimizer used in a wide range of optimization problems, including multi-objective optimization. SA (Simulated Annealing) is a classic trajectory descent optimization technique. Finally, CHC is a particular class of evolutionary algorithm which does not use mutation and relies instead on incest prevention and disruptive crossover. Due to the complexity of such a large analysis including so many techniques, we have used not only sequential algorithms, but also grid computing with BOINC in order to execute thousands of experiments in only several days using around 100 computers.	artificial neural network;boinc;broadcast television systems inc.;competitive learning;computer;differential evolution;evolutionary algorithm;experiment;fractal antenna;genetic algorithm;geographic coordinate system;gradient descent;grid computing;mathematical optimization;multi-objective optimization;np-hardness;optimization problem;population-based incremental learning;simulated annealing	Miguel A. Vega-Rodríguez;Juan Antonio Gómez Pulido;Enrique Alba;David Vega-Pérez;Silvio Priem-Mendes;Guillermo Molina	2007		10.1007/978-3-540-75867-9_107	differential evolution;optimization problem;mathematical optimization;simulation;genetic algorithm;wireless sensor network;simulated annealing;computer science;artificial intelligence;multi-objective optimization;machine learning;evolutionary algorithm;np-hard;competitive learning;artificial neural network;grid computing	AI	22.335575099380463	-5.6156220696901675	189644
e05030d12789a8c388fc2cd2f8c6ebd1537b0eb0	a broad and narrow approach to interactive evolutionary design - an aircraft design example	design process;evolutionary design;multi objective optimization;transport system;aircraft design;scientific communication;interactive evolutionary design;evolutionary process;fitness function;interactive evolutionary computation	While interactive evolutionary computation (IEC) is starting to penetrate a larger scientific community, only few researchers have applied IEC to the design of complicated artifacts like machines or transportation systems. The present paper introduces a specific approach to interactive evolutionary computation that breaches the two historical categories of user-defined fitness and selection in each generation (narrow) and occasional user-intervention of an automated evolutionary process to correct the fitness function used for (multi-objective) optimization (broad). To highlight the approach, a real world aircraft design problem is employed that demonstrates the relevance and importance of both features for an effective design process.	continuous design	Oliver Bandte	2009	Appl. Soft Comput.	10.1016/j.asoc.2007.11.007	evolutionary programming;evolutionary music;simulation;design process;interactive evolutionary computation;human-based evolutionary computation;computer science;computer-automated design;artificial intelligence;multi-objective optimization;machine learning;evolutionary algorithm;fitness function	Robotics	21.87118240950947	-5.741105810713106	189792
9a8f7482fc60c4f945bf3a1b3892cc67bccdd0a5	multidimensional scaling for evolutionary algorithms visualization of the path through search space and solution space using sammon mapping		Multidimensional scaling as a technique for the presentation of high-dimensional data with standard visualization techniques is presented. The technique used is often known as Sammon mapping. We explain the mathematical foundations of multidimensional scaling and its robust calculation. We also demonstrate the use of this technique in the area of evolutionary algorithms. First, we present the visualization of the path through the search space of the best individuals during an optimization run. We then apply multidimensional scaling to the comparison of multiple runs regarding the variables of individuals and multi-criteria objective values (path through the solution space).	evolutionary algorithm;feasible region;foundations;image scaling;imagery;mathematical optimization;mathematics;multidimensional scaling;numerous;sammon mapping;test scaling	Hartmut Pohlheim	2006	Artificial Life	10.1162/artl.2006.12.2.203		Visualization	22.198492244700304	-7.072702532257754	189900
563cf26e89b89e0e7cec0f20ef1d3af87dfc8f3b	automatic configuration of bi-objective optimisation algorithms: impact of correlation between objectives		Multi-objective optimisation algorithms expose various parameters that have to be tuned in order to be efficient. Moreover, in multi-objective optimisation, the correlation between objective functions is known to affect search space structure and algorithm performance. Considering the recent success of automatic algorithm configuration (AAC) techniques for the design of multi-objective optimisation algorithms, this raises two interesting questions: what is the impact of correlation between optimisation objectives on (1) the efficacy of different AAC approaches and (2) on the optimised algorithm designs obtained from these automated approaches? In this work, we study these questions for multi-objective local search algorithms (MOLS) for three well-known bi-objective permutation problems, using two single-objective AAC approaches and one multi-objective approach. Our empirical results clearly show that overall, multi-objective AAC is the most effective approach for the automatic configuration of the highly parametric MOLS framework, and that there is no systematic impact of the degree of correlation on the relative performance of the three AAC approaches. We also find that the best-performing configurations differ, depending on the correlation between objectives and the size of the problem instances to be solved, providing further evidence for the usefulness of automatic configuration of multi-objective optimisation algorithms.		Aymeric Blot;Holger H. Hoos;Marie-Eléonore Kessaci;Laetitia Vermeulen-Jourdan	2018	2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)	10.1109/ICTAI.2018.00093	machine learning;artificial intelligence;permutation;local search (optimization);correlation;algorithm;parametric statistics;computer science	SE	22.561458336762957	-4.047615011602259	189920
62380e010515b4363306378cb18261e462aa5068	knee point analysis of many-objective pareto fronts based on reeb graph		In many-objective optimization, the dimensionality of Pareto fronts becomes higher than three, and extracting preferable points for the decision maker is a key issue in the post-optimal analysis. The aim of this study is to develop a method to detect and visualize high-dimensional knee points. We propose a new definition of knee point and a graph-based approach to detect our knee points with a visualization of the geometry of the whole Pareto front. Our method is examined via Pareto front samples of synthetic problems and a real-world airplane design.	approximation algorithm;convex function;experiment;mapper;mathematical optimization;pareto efficiency;sensor;synthetic intelligence;utility	Naoki Hamada;Kazuhisa Chiba	2017	2017 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2017.7969494	machine learning;visualization;mathematical optimization;artificial intelligence;pareto principle;curse of dimensionality;multi-objective optimization;reeb graph;graph;mathematics	Vision	21.99716464060289	-7.1975111722769025	190130
83d9f675f9ae7bd3f3b04342c5c80bcb76efbb4c	an efficient scheme for candidate solutions of search-based multi-objective software remodularization		Multi-objective search-based software remodularization approaches are used to rearrange the software elements into modules by optimizing several quality criteria. These search-based approaches can find out better quality regrouping solutions compared to the traditional (analytical based) remodular- ization, if the suitable encoding for the candidate solutions is used. In this paper, we propose an efficient encoding scheme for candidate solutions and use this scheme to remodularize the object-oriented software using genetic based multi-objective evolutionary algorithm. This proposed representation helps in improving human-computer interaction, and semantic based, efficiently- designed and error-free information gets transferred to the computing system through it. To assess the effectiveness of the proposed approach, we evaluate it over six real-world software systems of different characteristics. Further, the approach is compared with the existing encoding scheme (i.e., GNE represen- tation scheme). Experiments show that the proposed approach produces better results in terms of quality, convergence speed and execution time compared to GNE representation scheme.		Amarjeet Prajapati;Jitender Kumar Chhabra	2016		10.1007/978-3-319-40349-6_28	mathematical optimization;computer science;theoretical computer science;data mining	SE	19.86414050568408	-5.3566318037240475	191485
4fa5ca8ea7d794ea1db2aea2f201589734860ff6	approximating the knee of an mop with stochastic search algorithms	search algorithm;decision maker;optimization problem;evolutionary algorithm;stochastic search	In this paper we address the problem of approximating the ’knee’ of a bi-objective optimization problem with stochastic search algorithms. Knees or entire knee-regions are of particular interest since such solutions are often preferred by the decision makers in many applications. Here we propose and investigate two update strategies which can be used in combination with stochastic multi-objective search algorithms (e.g., evolutionary algorithms) and aim for the computation of the knee and the knee-region, respectively. Finally, we demonstrate the applicability of the approach on two examples.	approximation algorithm;computation;evolutionary algorithm;mathematical optimization;optimization problem;search algorithm;stochastic optimization	Oliver Schütze;Marco Laumanns;Carlos A. Coello Coello	2008		10.1007/978-3-540-87700-4_79	beam search;optimization problem;decision-making;mathematical optimization;combinatorics;computer science;artificial intelligence;stochastic optimization;machine learning;evolutionary algorithm;mathematics;metaheuristic;evolutionary computation;search algorithm	AI	23.719275854233437	-3.2842645871273946	191594
effaec214b9144060e16653322079db41fee7722	evolutionary optimization on problems subject to changes of variables	ucl;discovery;theses;conference proceedings;digital web resources;ucl discovery;open access;ucl library;book chapters;open access repository;evolutionary algorithm;evolutionary optimization;dynamic optimization;ucl research	Motivated by an experimental problem involving the identification of effective drug combinations drawn from a non-static drug library, this paper examines evolutionary algorithm strategies for dealing with changes of variables. We consider four standard techniques from dynamic optimization, and propose one new technique. The results show that only little additional diversity needs to be introduced into the population when changing a small number of variables, while changing many variables or optimizing a rugged landscape requires often a restart of the optimization process.		Richard Allmendinger;Joshua D. Knowles	2010		10.1007/978-3-642-15871-1_16	computer science;artificial intelligence;data science;machine learning;evolutionary algorithm;operations research	Theory	22.555297528566108	-6.830096970001904	191950
5c31f5690d64ae6cedce68b1d1e3f49f2cc61ac7	evolutionary computing in manufacturing industry: an overview of recent applications	optimal solution;genetic program;theory and practice;search space;evolutionary programming;natural selection;industrial application;evolution strategy;genetic algorithm;genetic algorithms;global optimization;manufacturing industry;evolutionary computing	Traditional methods often employed to solve complex real world problems tend to inhibit elaborate exploration of the search space. They can be expensive and often results in sub-optimal solutions. Evolutionary computation (EC) is generating considerable interest for solving real world engineering problems. They are proving robust in delivering global optimal solutions and helping to resolve limitations encountered in traditional methods. EC harnesses the power of natural selection to turn computers into optimisation tools. The core methodologies of EC are genetic algorithms (GA), evolutionary programming (EP), evolution strategies (ES) and genetic programming (GP). This paper attempts to bridge the gap between theory and practice by exploring characteristics of real world problems and by surveying recent EC applications for solving real world problems in the manufacturing industry. The survey outlines the current status and trends of EC applications in manufacturing industry. For each application domain, the paper describes the general domain problem, common issues, current trends, and the improvements generated by adopting the GA strategy. The paper concludes with an outline of inhibitors to industrial applications of optimisation algorithms. # 2004 Elsevier B.V. All rights reserved.	application domain;computer;evolution strategy;evolutionary computation;evolutionary programming;expectation propagation;genetic algorithm;genetic programming;mathematical optimization;software release life cycle	Victor Oduguwa;Ashutosh Tiwari;Rajkumar Roy	2005	Appl. Soft Comput.	10.1016/j.asoc.2004.08.003	evolutionary programming;mathematical optimization;genetic algorithm;computer science;artificial intelligence;machine learning;management science;operations research;global optimization;evolutionary computation	AI	22.339407805512177	-5.031234661673751	192250
b937bbd0d0d70b7f871e6db5cf85b99c7629b128	a self-adaptive evolutionary approach to the evolution of aesthetic maps for a rts game	target maps self adaptive evolutionary approach aesthetic map evolution rts game procedural content generation pcg method automatic map generation planet wars real time strategy game aesthetic preferences training set a topological approach sphere of influence graph sig feature selection method multiobjective evolutionary algorithm kohonen network;planets games marine vehicles extraterrestrial measurements real time systems artificial intelligence vectors;graph theory computer games evolutionary computation feature selection	Procedural content generation (PCG) is a research field on the rise, with numerous papers devoted to this topic. This paper presents a PCG method based on a self-adaptive evolution strategy for the automatic generation of maps for the real-time strategy (RTS) game Planet Wars. These maps are generated in order to fulfill the aesthetic preferences of the user, as implied by her assessment of a collection of maps used as training set A topological approach is used for the characterization of the maps and their subsequent evaluation: the sphere-of-influence graph (SIG) of each map is built, several graph-theoretic measures are computed on it, and a feature selection method is utilized to determine adequate subsets of measures to capture the class of the map. A multiobjective evolutionary algorithm is subsequently employed to evolve maps, using these feature sets in order to measure distance to good (aesthetic) and bad (non-aesthetic) maps in the training set. The so-obtained results are visually analyzed and compared to the target maps using a Kohonen network.	evolution strategy;evolutionary algorithm;feature selection;graph theory;iterative and incremental development;procedural generation;real-time transcription;self-organizing map;test set	Raúl Lara-Cabrera;Carlos Cotta;Antonio J. Fernández	2014	2014 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2014.6900562	mathematical optimization;simulation;computer science;artificial intelligence;machine learning	AI	22.602766431821987	-9.158179665395258	192391
35bdf8dabf983c1639be96edb5869c4f60f96fb3	r2-emoa: focused multiobjective search using r2-indicator-based selection	emoa;r2 indicator;multiobjective optimization;preferences;performance assessment;indicator based selection	An indicator-based evolutionary multiobjective optimization algorithm (EMOA) is introduced which incorporates the contribution to the unary R2-indicator as the secondary selection criterion. First experiments indicate that the R2-EMOA accurately approximates the Pareto front of the considered continuous multiobjective optimization problems. Furthermore, decision makers’ preferences can be included by adjusting the weight vector distributions of the indicator which results in a focused search behavior.	algorithm;experiment;mathematical optimization;multi-objective optimization;pareto efficiency;unary operation	Heike Trautmann;Tobias Wagner;Dimo Brockhoff	2013		10.1007/978-3-642-44973-4_8	mathematical optimization;multi-objective optimization;machine learning;mathematics;management science	AI	20.702764016949743	-4.603617314002035	192406
cc8f677d8e342c99a680511bd8993db852cca57c	multi-objective mean-variance-skewness model for nonconvex and stochastic optimal power flow considering wind power and load uncertainties				J. J. Chen;Q. Henry Wu;L. L. Zhang;P. Z. Wu	2017	European Journal of Operational Research	10.1016/j.ejor.2017.06.018		Metrics	17.73714041227191	-3.9095835995063126	192422
70f1c715df7275c1e6ea053ecdafb4380f52e555	evolutionary synthesis of multi-agent systems for dynamic dial-a-ride problems	genetic program;multi agent system;dial a ride problems;genetic programming;automatic programming;dial a ride problem;multi agent systems;decentralized control	In dynamic dial-a-ride problems a fleet of vehicles need to handle transportation requests within time. We research how to create a decentralized multi-agent system that can solve the dynamic dial-a-ride problem. Normally multi-agent systems are hand designed for each specific application. In this paper we research the applicability of genetic programming to automatically program a multi-agent system that solves dial-a-ride problems. We evaluated the evolved system by running a number of simulations and compared it's performance to a selection hyper-heuristic. The results shows that genetic programming can be a viable alternative to hand constructing multi-agent systems.	genetic programming;heuristic;hyper-heuristic;multi-agent system;simulation	Rinde R. S. van Lon;Tom Holvoet;Greet Vanden Berghe;Tom Wenseleers;Juergen Branke	2012		10.1145/2330784.2330832	control engineering;simulation;engineering;operations management	AI	18.90833002301161	-4.749810721625875	192426
bd063354b1209ac527346c4b60dd93ea3662bf8f	design of an adaptive mutation operator in an electrical load management case study	occupation time;metodo adaptativo;multiobjective programming;programmation multiobjectif;optimisation;comparative analysis;optimizacion;reseau electrique;electrical network;red electrica;adaptive control;methode adaptative;space time;algoritmo genetico;dynamic behaviour;systeme adaptatif;espacio tiempo;time varying system;fonction objectif;objective function;management strategy;temps occupation;control adaptativo;systeme parametre variable;adaptive method;adaptive system;commande adaptative;tiempo ocupacion;algorithme genetique;sistema adaptativo;funcion objetivo;multiobjective optimization;genetic algorithm;genetic algorithms;optimization;sistema parametro variable;evolutionary process;espace temps;programacion multiobjetivo	An adequately designed and parameterized set of operators is crucial for an efficient behaviour of Genetic Algorithms (GAs). Several strategies have been adopted in order to better adapt parameters to the problem under resolution and to increase the algorithm's performance. One of these approaches consists in using operators presenting a dynamic behaviour, that is displaying a different qualitative behaviour in different stages of the evolutionary process. In this work a comparative analysis of the effects of using an adaptive mutation operator is presented in the operational framework of a multi-objective GA for the design and selection of electrical load management strategies. It is shown that the use of a time/space varying mutation operator depending on the values achieved for each objective function increases the performance of the algorithm.	electrical load;load management	Álvaro Gomes;Carlos Henggeler Antunes;Antonio Gomes Martins	2008	Computers & OR	10.1016/j.cor.2007.01.003	mathematical optimization;genetic algorithm;adaptive control;computer science;artificial intelligence;adaptive system;genetic operator;operations research;algorithm	DB	18.717532167616262	-2.863028644248788	193049
8d2e1d947628a82072c2dce8a4d1ec6ef668a511	multi-criteria optimization for parameter estimation of physical models in combustion engine calibration		In the automotive industry the calibration of the engine control unit is getting more and more complex because of many various boundary conditions, like the demand on CO 2 and fuel reduction. One important calibration problem is the parameter estimation for the model of the intake system of the combustion engine. This system is modeled by a physically motivated system, which can be parameterized by black-box models, like neural nets and characteristic diagrams, whose parameters must be set by an intelligent optimizer. Further, two contradictory aims must be considered and the engineer expects at the end of the optimization a pareto-front, where he can choose the best settings for the application from the pareto-optimal parameter estimations. To solve this multi-criteria optimization task an evolutionary algorithm is used, which is a combination of a genetic algorithm and an evolutionary strategy. This evolutionary algorithm is like all other stochastic searching methods leaned on the naturally biological evolution. It combines the well-known covariance matrix adaption for the mutation of the individuals with the S-metric selection for the multi-criteria fitness assignment of the individuals. It also improves these combination by the use of many subpopulations, which work parallel on various clusters, and by the use of an intelligent DoE-strategy for the initialization of the start individuals. With these improvements the developed evolutionary algorithm can easily fit the model of the intake system to test bed measurements and can provide the user a pareto-optimal set of parameters, on which he can choose on his own that ones, which he find most plausible.	estimation theory	Susanne Zaglauer;Michael Deflorian	2013		10.1007/978-3-642-37140-0_47	control engineering;automotive engineering;control theory	Vision	18.724528363476033	-5.064750969947826	193249
003782737cb18ed067f6f43aa492f67441a8534e	r2-bean: r2 indicator based evolutionary algorithm for noisy multiobjective optimization	statistical testing evolutionary computation nonparametric statistics;asymmetric noise distributions r2 bean noisy multiobjective optimization indicator based dominance operator evolutionary algorithms multiobjective optimization problems objective functions u r2 dominance operator quality indicator r2 indicator nonparametric statistical significance test mann whitney u test objective space noisy mop noise aware dominance operators;noise vectors linear programming sociology statistics noise measurement optimization	This paper proposes and evaluates an indicator-based and noise-aware dominance operator for evolutionary algorithms to solve the multiobjective optimization problems (MOPs) that contain noise in their objective functions. The proposed operator, UR2-dominance operator is designed with (1) a quality indicator, called R2 indicator, which quantifies the goodness of a given solution candidate (individual) and (2) a non-parametric (i.e., distribution-free) statistical significance test called the Mann-Whitney U-test. The UR2-dominance operator takes samples of given two individuals in the objective space, calculates the R2 indicator value for each sample, estimates the impacts of noise on the R2 values with a U-test, and determines which individual is statistically superior/inferior. Experimental results show that it operates reliably in noisy MOPs and outperforms existing noise-aware dominance operators particularly when many outliers exist under asymmetric noise distributions.	evolutionary algorithm;image noise;mathematical optimization;multi-objective optimization	Dung H. Phan;Junichi Suzuki	2014	the 2014 Seventh IEEE Symposium on Computational Intelligence for Security and Defense Applications (CISDA)	10.1109/CISDA.2014.7035637	mathematical optimization;machine learning;mathematics;statistics	AI	23.471383790556377	-5.372400026233711	193375
c3567384bbcbd86a35c63f2ea7120a0f2b43aca9	dominance for multi-objective robust optimization concepts		Abstract In robust optimization, the parameters of an optimization problem are not deterministic but uncertain. Their values depend on the scenarios which may occur. Single-objective robust optimization has been studied extensively. Since 2012, researchers have been looking at robustness concepts for multi-objective optimization problems as well. In another line of research, single-objective uncertain optimization problems are transformed to deterministic multi-objective problems by treating every scenario as an objective function. In this paper we combine these two points of view. We treat every scenario as an objective function also in uncertain multi-objective optimization, and we define a corresponding concept of dominance which we call multi-scenario efficiency . We sketch this idea for finite uncertainty sets and extend it to the general case of infinite uncertainty sets. We then investigate the relation between this dominance and the concepts of highly, locally highly, flimsily, and different versions of minmax robust efficiency. For all these concepts we prove that every strictly robust efficient solution is multi-scenario efficient. On the other hand, under a compactness condition, the set of multi-scenario efficient solutions contains a robust efficient solution for all these concepts which generalizes the Pareto robustly optimal (PRO) solutions from single-objective optimization to Pareto robust efficient (PRE) solutions in the multi-objective case. We furthermore present two results on reducing an infinite uncertainty set to a finite one which are a basis for computing multi-scenario efficient solutions.		Marco Botte;Anita Schöbel	2019	European Journal of Operational Research	10.1016/j.ejor.2018.08.020	mathematical optimization;robustness (computer science);mathematics;robust optimization;sketch;minimax;compact space;pareto principle;optimization problem	Theory	17.401588704470708	-6.416108828872621	194575
ca33b7f254de9ad4571c3cc534b57d40c207852a	a novel modified shuffled frog leaping algorithm to solve the optimal capacitor allocation problem in distribution system			algorithm;blue frog;list of metaphor-based metaheuristics	Mohammad-Reza Akbari-Zadeh;Mahdi Vosoogh;Mohammad Mirjavadi;Alireza Abbasi	2014	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-130997	mathematical optimization;algorithm	ECom	18.394532134594634	-3.534773788441853	194657
6cf0f5e971d568c57a60f1c6a1dfc39f6f401891	alternative voting systems in stock car racing	nascar;optimal method;genetic algorithm;genetic algorithms;voting theory;real coded genetic algorithm;scoring system	In this work, alternative voting methods are compared to determine NASCAR rankings for the Sprint Cup Series. All of these methods make use only of the final placement of each driver in each race. We then construct a set of metrics to determine the effectiveness of each of these voting methods when compared to one another and the actual NASCAR scoring system. Finally, we attempt to generate a more optimal method, as defined by those same metrics, using a real-coded genetic algorithm. Our results show that most of the alternative voting methods vastly outperform the actual NASCAR system. Likewise, the method produced by the genetic algorithm outperforms even the best of the alternative methods.	genetic algorithm;sprint (software development)	Aaron Garrett;Daniel Eric Smith	2009		10.1145/1569901.1570239	simulation;genetic algorithm;computer science;artificial intelligence;machine learning	AI	17.912311620015814	-6.5642871466387325	194840
c64adcc6f9efe47ac127978e6579e7d609a1eb7a	search-based multi-paths test data generation for structure-oriented testing	automated testing;software testing;path testing;test data generation;automation test;structure oriented;genetic algorithm;genetic algorithms;fitness function	This paper presents a new fitness function to generate test data for a specific single path, which is different from the predicate distance applied by most test data generators based on genetic algorithms (GAs). We define a similarity between the target path and execution path to evaluate the quality of the populations. The problem of the most existing generators is to search only one target data a time, wasting plenty of available interim data. We construct another fitness function combined with the single path function, which can drive GA to complete covering multi-paths to avoid the reduplicate searching and utilize the interim populations for different paths.  Several experiments are taken to examine the effectiveness of both the single path and multi-path fitness functions, which evaluate the functions' performance with the convergence ability and consumed time. Results show that the two functions perform well compared with other two typical path-oriented functions and the multi-paths approach retrenches the searching actually.	experiment;fitness function;genetic algorithm;population;software release life cycle;test data generation	Yang Cao;Chunhua Hu;Luming Li	2009		10.1145/1543834.1543839	basis path testing;test data generation;genetic algorithm;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;algorithm	SE	21.18637345711635	-7.773854471410803	194859
3f41c85fdea18760307f11773503a625c45c450f	a study of fitness distance correlation as a difficulty measure in genetic programming	fitness landscape;fitness distance correlation genetic programming problem difficulty program landscapes;genetic program;problem difficulty;fitness;genetic programming;study;fitness distance correlation;measure;correlation;difficulty;programming;distance;program landscapes;genetic	We present an approach to genetic programming difficulty based on a statistical study of program fitness landscapes. The fitness distance correlation is used as an indicator of problem hardness and we empirically show that such a statistic is adequate in nearly all cases studied here. However, fitness distance correlation has some known problems and these are investigated by constructing an artificial landscape for which the correlation gives contradictory indications. Although our results confirm the usefulness of fitness distance correlation, we point out its shortcomings and give some hints for improvement in assessing problem hardness in genetic programming.	algorithm;coherence (physics);data descriptor;evolutionary computation;fitness function;genetic programming;leucaena pulverulenta;markov chain monte carlo;mathematical optimization;mind;monte carlo method;quantity;random search;sampling (signal processing);sampling - surgical action;stationary process;statistical model	Marco Tomassini;Leonardo Vanneschi;Philippe Collard;Manuel Clergue	2005	Evolutionary Computation	10.1162/1063656054088549	genetic programming;programming;mathematical optimization;measure;fitness proportionate selection;fitness landscape;artificial intelligence;machine learning;mathematics;fitness approximation;distance;fitness function;correlation	AI	24.450223229724774	-7.723797150285311	195437
714da6a766ccef43b8b8d5baaceb438db5541a9a	solving multi-objective games using a-priori auxiliary criteria		This paper describes a method to support strategy selection in zero-sum Multi-Objective Games (MOGs). It follows a recent development concerning the solution of MOGs based on a novel non-utility approach. Such an approach commonly results with a large set of rationalizable strategies to choose from. Here, this approach is further developed to narrow down the set of rationalizable strategies into a set of preferable strategies using a-priori incorporation of decision-makers' preferences (auxiliary criteria). To search for the latter set a co-evolutionary algorithm is devised. The effectiveness of the algorithm is studied using an academic example of a zero-sum MOG involving two manipulators. To test the algorithm, a validation method is suggested using a discrete version of the example. The results substantiate the claim that the proposed algorithm finds a good approximation of the set of preferable strategies.	algorithmic efficiency;approximation;code coverage;computation;data validation;evolutionary algorithm	Meir Harel;Erella Eisenstadt;Amiram Moshaiov	2017	2017 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2017.7969471	artificial intelligence;game theory;mathematical optimization;machine learning;approximation algorithm;a priori and a posteriori;mathematics	Robotics	19.22031429925674	-8.283889194339844	195907
97238a7626cd8a938c6282f96919cff2c40fc6f7	effective vaccination policies	biological patents;biomedical journals;text mining;migration;agent based;europe pubmed central;citation search;influenza;citation networks;mathematical analysis;epidemiology;vaccines;viruses;evolution biology;development tool;vaccination;research articles;abstracts;open access;life sciences;clinical guidelines;pathogenic microorganisms;evolutionary algorithm;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	"""We present a framework for modeling the spread of pathogens throughout a population and generating policies that minimize the impact of those pathogens on the population. This framework is used to study the spread of human viruses between cities via airplane travel. It combines agent-based simulation, mathematical analysis, and an Evolutionary Algorithm (EA) optimizer. The goal of this study is to develop tools that determine the optimal distribution of a vaccine supply in the model. Using plausible benchmark vaccine allocation policies of uniform and proportional distribution, we compared their effectiveness to policies found by the EA. We then designed and tested a new, more effective policy which increased the importance of vaccinating smaller cities that are flown to more often. This """"importance factor"""" was validated using U.S. influenza data from the last four years."""	agent-based model;agent-based social simulation;allocation;benchmark (computing);each (qualifier value);evolutionary algorithm;mathematical optimization;mathematics;policy;population;small;virus	L. Shaw;W. Spears;L. Billings;P. Maxim	2010	Information sciences	10.1016/j.ins.2010.06.005	text mining;epidemiology;computer science;bioinformatics;human migration;artificial intelligence;evolutionary algorithm;data mining;vaccination;operations research	AI	19.279244549415825	-5.525887333943579	196040
b0c1c8f709da105b9108ce0db19dfc69e645f22c	community detection in complex networks: multi-objective enhanced firefly algorithm	community;complex network;multi objective;enhanced firefly algorithm;pareto optimal front;article	Studying the evolutionary community structure in complex networks is crucial for uncovering the links between structures and functions of a given community. Most contemporary community detection algorithms employs single optimization criteria (i.e.., modularity), which may not be adequate to represent the structures in complex networks. We suggest community detection process as a Multi-objective Optimization Problem (MOP) for investigating the community structures in complex networks. To overcome the limitations of the community detection problem, we propose a new multi-objective optimization algorithm based on enhanced firefly algorithm so that a set of non-dominated (Pareto-optimal) solutions can be achieved. In our proposed algorithm, a new tuning parameter based on a chaotic mechanism and novel self-adaptive probabilistic mutation strategies are used to improve the overall performance of the algorithm. The experimental results on synthetic and real world complex networks suggest that the multi-objective community detection algorithm provides useful paradigm for discovering overlapping community structures robustly.	firefly algorithm	Babak Amiri;Liaquat Hossain;John W. Crawford;Rolf T. Wigand	2013	Knowl.-Based Syst.	10.1016/j.knosys.2013.01.004	community;simulation;computer science;artificial intelligence;machine learning;complex network	DB	22.808425368431752	-7.637745694247111	196676
163384b9538882114dbea0884501c873d63bcbd4	uncertainty based hybrid particle swarm optimization techniques and their applications		In order to handle uncertainty in data, several uncertainty based models have been introduced. Perhaps the two most notable models among these are the fuzzy set introduced by Zadeh in 1965 and rough set introduced by Pawlak in 1982. These two models address two different aspects of uncertainty and these are complementary by nature. As a result their hybridization leads to better models. Particle Swarm Optimization (PSO) is an optimization technique that performs optimized search in the solution space for optimization by updation. In this chapter, we discuss on different types of PSOs and their application in classification, feature selection and rule generation. Further, we present several hybridization of PSO with fuzzy approach, rough approach and rough fuzzy approach in developing classification algorithms. Also, we discuss on a dynamic clustering algorithm which uses a rough fuzzy hybrid model embedded with PSO. We provide as an illustration the results of application of this algorithm on several real life data sets and provide its superiority through the computation of several index values for measuring classification accuracy like DB, D, ( alpha , rho , alpha ^* ) and ( gamma ). Also, we compile some other applications of PSO.	particle swarm optimization	J. Anuradha;B. K. Tripathy	2015		10.1007/978-3-662-46309-3_6	probabilistic-based design optimization;multi-swarm optimization;metaheuristic	EDA	19.69222518695735	-6.88072187619219	196803
8b420f9a66910cdb580eff11bbae542abba13297	multiobjective evolutionary algorithms to identify highly autocorrelated areas: the case of spatial distribution in financially compromised farms	fuzzy hot spots;financially compromised areas;local indicators of spatial aggregation;spatial analysis;multiobjective evolutionary algorithms	Local Indicators of Spatial Aggregation (LISA) can be used as objectives in a multicriteria framework when highly autocorrelated areas (hot-spots) must be identified and geographically located in complex areas. To do so, a Multi-Objective Evolutionary Algorithm (MOEA) based on SPEA2 (Strength Pareto Evolutionary Algorithm v.2) has been designed to evaluate three different fitness functions (fine-grained strength, the weighted sum of objectives and fuzzy evaluation of weighted objectives) and three LISA methods. MOEA makes it possible to achieve a compromise between spatial econometric methods as it highlights areas where a specific phenomenon shows significantly high autocorrelation. The spatial distribution of financially compromised olive-tree farms in Andalusia (Spain) was selected for analysis and two fuzzy hot-spots were statistically identified and spatially located. Hot-spots can be considered to be spatial fuzzy sets where the spatial units have a membership degree that can also be calculated.	autocorrelation;evolutionary algorithm;evolutionary computation;fitness function;fuzzy set;moea framework;pareto efficiency;weight function	Carlos R. García-Alonso;Leonor M. Pérez-Naranjo;Juan C. Fernández-Caballero	2014	Annals OR	10.1007/s10479-011-0841-3	mathematical optimization;operations management;data mining;mathematics;spatial analysis;statistics	Web+IR	20.069377022740536	-4.504979262290954	197182
fe576195211d430cfcad5d91427058166e5cb51d	constraints dependent t-way test suite generation using harmony search strategy	t way testing;artificial intelligent algorithms;constraints support;software and hardware testing	Recently, many new researchers have considered the adoption of Artificial Intelligence-based Algorithm for the construction of t-way test suite generation strategies (where t indicates the interaction strengths). Although useful, most existing AI-based strategies have not sufficiently dealt or even experimented with the problem of constraints. Here, it is desirable for a particular AI-based strategy of interest to be able to automatically exclude the set of impossible or forbidden combinations from the final t-way generated suite. This paper describes our experience dealing with constraints from within a Harmony Search Algorithm based strategy, called HSS. Our experience with HSS is encouraging as we have obtained competitive test size as overall.	harmony search;test suite	AbdulRahman A. Al-Sewari;Kamal Zuhairi Zamli	2012		10.1007/978-3-642-32541-0_1	simulation;artificial intelligence;algorithm	NLP	20.820121366971883	-7.064585020520779	197355
c6dc40d1015fe1fc8039703c26da37fbe721d244	quantified pareto-optimal front comparisons using attainment surfaces		Fonseca and Fleming introduced attainment surfaces over twenty years ago. It was shown that two algorithms could be compared using a grand attainment surface. Grand attainment surfaces show the regions in which one algorithm statistically outperforms another. Knowles and Corne extended the work done by Fonseca and Fleming by introducing a quantitative measure based on the concepts of the grand attainment surfaces. This paper presents an argument that the intersection line generation approach used to calculate the quantitative measure is not well suited for all Pareto-optimal front shapes. An alternative, the weighted POF shaped intersection line generation approach is presented. The new approach is tested along with the old approach against 30 test cases. The results show that the newly proposed weighted POF shaped intersection line generation approach is well suited for all the tested POF shapes and subsequently yield more accurate results.	algorithm;pareto efficiency;reliability engineering;test case	Christiaan Scheepers;Andries Petrus Engelbrecht	2017	2017 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2017.8280864	mathematical optimization;pareto principle;test case;mathematics	Vision	19.071722409189064	-7.068804908429632	197761
b561c02ff5acc9ab34247c5a7029ca056b078b47	a novel multiobjective optimization for cement stabilized soft soil based on artificial bee colony	swarm intelligence;multi objective optimization;artificial bee colony abc;cement stabilization;calibration charts;vector evaluated artificial bee colony veabc	Cement is the most widely used additive in soft soil stabilization due to its high strength and availability. The cement content and curing time have a direct influence on the stabilization cost and hence it is prudent to minimize these variables to achieve optimality. Thus, it is a classical multi-objective optimization problem to find the optimum combination of cement content used and the curing time provided to achieve the target strength. This paper brings out the use of Vector Evaluated Artificial Bee Colony VEABC algorithm, a multi-objective variant of Artificial Bee Colony ABC technique, for the problem on hand. VEABC is a swarm intelligence algorithm, which employs multiple swarms to handle the multiple objectives and the information migration between these swarms ensures a global optimum solution is reached. Due to the stochastic nature of ABC algorithm, the resulting Pareto Curve will cover a good range of data with smooth transition. The Pareto fronts obtained for target strength could be used as calibration charts for scheduling the soft soil stabilization activities.	artificial bee colony algorithm;multi-objective optimization	Rahul Khandelwal;J. Senthilnath;S. N. Omkar;Narendra Shivanath	2016	Int. J. of Applied Metaheuristic Computing	10.4018/IJAMC.2016100101	mathematical optimization;swarm intelligence;computer science;artificial intelligence;multi-objective optimization	HPC	24.22863018782113	-4.468637722114743	198262
225692f2da6f31ceda2142663ac2c902423246a5	modified symbiotic evolutionary learning for type-2 fuzzy system	road vehicles fuzzy reasoning fuzzy set theory genetic algorithms learning artificial intelligence road traffic control;symbiosis;type 2 fuzzy sets genetic algorithm symbiotic evolutionary computation traffic signal control;symbiosis genetic algorithms fuzzy systems sociology statistics delays biological cells;genetic algorithm modified symbiotic evolutionary learning type 2 fuzzy system fine tuned parameters group based symbiotic evolutionary approach fitness values membership function parameters solution space exploration improvement rule optimization base count optimization input parameter optimization similarity measure learning method simulated urban traffic network optimal signal timings set2 signal control traffic conditions central business district singapore average time delay vehicle speed distributed environment;biological cells;statistics;genetic algorithms;sociology;fuzzy systems;delays	This paper proposes a new modified symbiotic evolutionary learning method (SET2) for fine-tuning the parameters of a type-2 fuzzy system. The paper uses a group-based symbiotic evolutionary approach. Instead of evolving the individual rules and assigning the fitness values for each rule, the membership function parameters and the rules are evolved as individual groups. This method improves the exploration of the solution space, and optimizes the rule, base count and the most influencing input parameters in each rule which is difficult to obtain in conventional symbiotic evolutionary learning approach. The paper also proposes a method to obtain the similarity measure of the membership functions. In order to demonstrate the efficiency of the proposed learning method, it is deployed in a simulated urban traffic network to obtain the optimal signal timings in a distributed manner. The proposed SET2 signal control was tested for various traffic conditions experienced in a section of the Central Business District of Singapore. A comparison of the average time delay and speed of vehicles indicated that SET2 signal control performed significantly better than the benchmark signal controls such as GLIDE, hierarchical multiagent system, and geometric fuzzy multiagent system. The test bed also showcased the performance of the modified learning method in a distributed environment.	agent-based model;benchmark (computing);broadcast delay;feasible region;fuzzy control system;iterative and incremental development;mathematical optimization;membership function (mathematics);mike lesser;multi-agent system;optimization problem;rule-based system;similarity measure;software release life cycle;testbed	Balaji Parasumanna Gokulan;Dipti Srinivasan	2014	IEEE Systems Journal	10.1109/JSYST.2013.2247192	mathematical optimization;simulation;genetic algorithm;fuzzy classification;computer science;engineering;artificial intelligence;fuzzy number;machine learning;fuzzy control system;statistics;symbiosis	ML	20.07273675310281	-8.875288924026792	198585
43b731ab2ed08de4901edfb07ef6020f4a713ecf	evaluation of two-stage ensemble evolutionary algorithm for numerical optimization	challenging numerical optimization problem;exploration ability;engineering application;tsea framework;cec05 test function;two-stage ensemble;experimental study;evolutionary algorithm;application area;specific engineering problem;general numerical optimization problem	challenging numerical optimization problem;exploration ability;engineering application;tsea framework;cec05 test function;two-stage ensemble;experimental study;evolutionary algorithm;application area;specific engineering problem;general numerical optimization problem	evolutionary algorithm;mathematical optimization;numerical method;program optimization	Yu Wang;Bin Li;Kaibo Zhang;Zhen He	2011		10.1007/978-3-642-21515-5_64	mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;algorithm	EDA	23.872669373257885	-4.468783135149714	199002
