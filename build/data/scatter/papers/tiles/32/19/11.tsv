id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
183230e0eb5f3b8d4876cf3c31621959106846c0	competitive on-line linear regression	linear regression	We apply a general algorithm for merging prediction strategies (the Aggregating Algorithm) to the problem of linear regression with the square loss; our main assumption is that the response variable is bounded. It turns out that for this particular problem the Aggregating Algorithm resembles, but is slightly different from, the wellknown ridge estimation procedure. From general results about the Aggregating Algorithm we deduce a guaranteed bound on the difference between our algorithm's performance and the best, in some sense, linear regression function's performance. We show that the AA attains the optimal constant in our bound, whereas the constant attained by the ridge regression procedure in general can be 4 times worse.	algorithm	Vladimir Vovk	1997			econometrics;mathematical optimization;proper linear model;computer science;linear regression;machine learning;bayesian multivariate linear regression;polynomial regression;mathematics;statistics	ML	21.610444557969963	-30.37032655653707	158595
c31d4048265933bad9a6665840d2264a85cd4b82	adaptive importance sampling technique for neural detector training	probabilidad error;metodo adaptativo;communication system;error function;parabolic equation;probability density function;methode adaptative;algoritmo genetico;ecuacion parabolica;fonction objectif;objective function;captador medida;measurement sensor;equation parabolique;capteur mesure;adaptive method;echantillonnage importance;funcion error;algorithme genetique;funcion objetivo;genetic algorithm;error probability;fonction erreur;reseau neuronal;importance sampling;density functional;red neuronal;probabilite erreur;neural network	In this paper, we develop the use of an adaptive Importance Sampling (IS) technique in neural network training, for applications to detection in communication systems. Some topics are reconsidered, such as modifications of the error probability objective function (Pe), optimal and suboptimal IS probability density functions (biasing density functions), and adaptive importance sampling. A genetic algorithm was used for the neural network training, having utilized an adaptive IS technique for improving Pe estimations in each iteration of the training. Also, some simulation results of the training process are included in this paper.		José L. Sanz-González;Francisco Álvarez-Vaquero	2002		10.1007/3-540-46084-5_168	probability density function;genetic algorithm;importance sampling;parabola;artificial intelligence;probability of error;error function;mathematics;artificial neural network;algorithm;communications system;statistics	ML	17.378965426275947	-28.097677366919676	160249
4cfa990c53ecc6ae31db228fdc11f4729047bed5	modeling dynamic engineering processes using radial-gaussian neural networks	neural network	The paper proposes and evaluates an artificial neural network based method of modeling the dynamic behavior of continua. The technique is applicable to situations where the differential equations governing the behavior of a system are nonlinear and poorly understood, and the data available for training is noisy. A method of modeling the unknown component of governing differential equations using neural network technology, is first described. This includes a method for averaging out localized errors in the neural network function that results from noise in the training data. A description is then given of a radial-Gaussian neural network architecture and training algorithm adopted for this application. The construction of a complete simulation model of a specific system from the trained neural networks is demonstrated. The performance of the proposed approach is assessed in a series of experiments simulating the nonlinear thermal behavior of a translucent solid material. The system is proven to perform most effectively using the proposed error averaging technique, and to be capable of providing an accurate simulation of a system's behavior sustained over many thousands of simulation time steps.		Ian Flood	1999	Journal of Intelligent and Fuzzy Systems		stochastic neural network;nervous system network models;cellular neural network;types of artificial neural networks;computer science;machine learning;physical neural network;time delay neural network;artificial neural network	Robotics	17.882436583326218	-25.01016165851614	160366
68213f4ab10ee83f60f165233e848226f256f5f4	explicit computation of input weights in extreme learning machines		We present a closed form expression for initializing the input weights in a multilayer perceptron, which can be used as the first step in synthesis of an Extreme Learning Machine. The expression is based on the standard function for a separating hyperplane as computed in multilayer perceptrons and linear Support Vector Machines; that is, as a linear combination of input data samples. In the absence of supervised training for the input weights, random linear combinations of training data samples are used to project the input data to a higher dimensional hidden layer. The hidden layer weights are solved in the standard ELM fashion by computing the pseudoinverse of the hidden layer outputs and multiplying by the desired output values. All weights for this method can be computed in a single pass, and the resulting networks are more accurate and more consistent on some standard problems than regular ELM networks of the same size.	computation;moore–penrose pseudoinverse;multilayer perceptron;support vector machine	Jonathan Tapson;Philip de Chazal;André van Schaik	2014	CoRR		mathematical optimization;computer science;artificial intelligence;machine learning	ML	17.78704770154098	-30.65592003422561	160502
e03a0927c2e47b5d1e80f5165b13bb0580e23774	information-theory interpretation of the skip-gram negative-sampling objective function		In this paper, we define a measure of dependency between two random variables, based on the Jensen-Shannon (JS) divergence between their joint distribution and the product of their marginal distributions. Then, we show that word2vec’s skip-gram with negative sampling embedding algorithm finds the optimal low-dimensional approximation of this JS dependency measure between the words and their contexts. The gap between the optimal score and the low-dimensional approximation is demonstrated on a standard text corpus.	algorithm;approximation;haven (graph theory);information theory;jensen's inequality;kullback–leibler divergence;loss function;marginal model;mathematical optimization;mutual information;n-gram;sampling (signal processing);shannon (unit);text corpus;word2vec	Oren Melamud;Jacob Goldberger	2017		10.18653/v1/P17-2026	computer science;artificial intelligence;machine learning;information theory;sampling (statistics);gram	AI	23.42394977295911	-30.419380661853413	160529
7eb59395bd3e0048b4ef8126f5217ed6c1eaac17	deep learning with dynamic spiking neurons and fixed feedback weights		Recent work in computer science has shown the power of deep learning driven by the backpropagation algorithm in networks of artificial neurons. But real neurons in the brain are different from most of these artificial ones in at least three crucial ways: they emit spikes rather than graded outputs, their inputs and outputs are related dynamically rather than by piecewise-smooth functions, and they have no known way to coordinate arrays of synapses in separate forward and feedback pathways so that they change simultaneously and identically, as they do in backpropagation. Given these differences, it is unlikely that current deep learning algorithms can operate in the brain, but we that show these problems can be solved by two simple devices: learning rules can approximate dynamic input-output relations with piecewise-smooth functions, and a variation on the feedback alignment algorithm can train deep networks without having to coordinate forward and feedback synapses. Our results also show that deep spiking networks learn much better if each neuron computes an intracellular teaching signal that reflects that cell’s nonlinearity. With this mechanism, networks of spiking neurons show useful learning in synapses at least nine layers upstream from the output cells and perform well compared to other spiking networks in the literature on the MNIST digit recognition task.	approximation algorithm;artificial neural network;artificial neuron;backpropagation;computer science;deep learning;digit structure;feedback;mnist database;machine learning;neurons;nonlinear system;rule (guideline);spiking neural network;synapse;synapses;anatomical layer	Arash Samadi;Timothy P. Lillicrap;Douglas Blair Tweed	2017	Neural Computation	10.1162/NECO_a_00929	computer science;artificial intelligence;theoretical computer science;machine learning	ML	17.51081833325783	-30.582581416969848	160731
e8a51a396766de027915ac5ee4570b690cabbc19	weight configurations of trained perceptrons		We strive to predict the function mapping and rules performed by a trained perceptron from studying the weights. We derive a few properties of the trained weights and show how the perceptron's representation of knowledge, rules and functions depend on these properties. Two types of perceptrons are studied--one case with continuous inputs and one hidden layer, the other a simple binary classifier with boolean inputs and no hidden units.		H. S. Toh	1993	International journal of neural systems	10.1142/S0129065793000195	artificial intelligence;machine learning;pattern recognition;mathematics	ML	17.533755202062576	-29.799460365415037	160809
92519f20ffba7089531d8472bc111ddbaacafe00	radial basis function networks gpu-based implementation	algorithms computer simulation models theoretical neural networks computer pattern recognition automated;learning process;unite centrale;paper;markets;image processing;neural networks;carte graphique;mercado;computer graphics;central unit;fonction base radiale;acceleration;qa76 electronic computers computer science computer software;radial basis function networks;radial basis function;radial basis function network;marche;graphic processing unit gpu;pattern recognition;graphic processing unit;unidad central;unidad de proceso grafico;neural networks nns;computer science;radial basis function networks rbfns graphic processing unit gpu neural networks nns;reseau neuronal;radial basis function networks hardware neural networks computer graphics central processing unit acceleration costs computational efficiency image processing pattern recognition;computational efficiency;funcion radial base;radial basis function networks rbfns;red neuronal;central processing unit;tk electrical engineering electronics nuclear engineering;neural network;hardware	Neural networks (NNs) have been used in several areas, showing their potential but also their limitations. One of the main limitations is the long time required for the training process; this is not useful in the case of a fast training process being required to respond to changes in the application domain. A possible way to accelerate the learning process of an NN is to implement it in hardware, but due to the high cost and the reduced flexibility of the original central processing unit (CPU) implementation, this solution is often not chosen. Recently, the power of the graphic processing unit (GPU), on the market, has increased and it has started to be used in many applications. In particular, a kind of NN named radial basis function network (RBFN) has been used extensively, proving its power. However, their limiting time performances reduce their application in many areas. In this brief paper, we describe a GPU implementation of the entire learning process of an RBFN showing the ability to reduce the computational cost by about two orders of magnitude with respect to its CPU implementation.	algorithmic efficiency;application domain;approximation;artificial neural network;auditory perceptual disorders;central processing unit;computation;excretory function;float;graphics processing unit;linear model;name;neural network simulation;neural tube defects;nonlinear system;performance;radial (radio);radial basis function network;simulators;video card;orders - hl7publishingdomain	Andreas Brandstetter;Alessandro Artusi	2008	IEEE Transactions on Neural Networks	10.1109/TNN.2008.2003284	acceleration;radial basis function;simulation;computer science;artificial intelligence;central processing unit;machine learning;computer graphics;radial basis function network;artificial neural network	ML	17.750101705296032	-25.995185426916397	161003
0d9b6a918841dc361eb5dd28d358fb0f282888b9	sea surface temperature prediction and reconstruction using patch-level neural network representations		The forecasting and reconstruction of ocean and atmosphere dynamics from satellite observation time series are key challenges. While model-driven representations remain the classic approaches, data-driven representations become more and more appealing to benefit from available large-scale observation and simulation datasets. In this work we investigate the relevance of recently introduced bilinear residual neural network representations, which mimic numerical integration schemes such as Runge-Kutta, for the forecasting and assimilation of geophysical fields from satellite-derived remote sensing data. As a case-study, we consider satellite-derived Sea Surface Temperature time series off South Africa, which involves intense and complex upper ocean dynamics. Our numerical experiments demonstrate that the proposed patch-level neural-network-based representations outperform other data-driven models, including analog schemes, both in terms of forecasting and missing data interpolation.	artificial neural network;bilinear filtering;data assimilation;experiment;interpolation;missing data;model-driven integration;numerical analysis;numerical integration;patch (computing);relevance;runge–kutta methods;simulation;time series	Said Ouala;Cédric Herzet;Ronan Fablet	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8519345	numerical integration;artificial intelligence;algorithm;interpolation;machine learning;missing data;sea surface temperature;artificial neural network;computer science;hidden markov model;bilinear interpolation;ocean dynamics	Vision	18.300702117378794	-25.062758339642542	161129
76f027f31c2966eff56d83f7cef1ad1e6e27bf68	the high-order boltzmann machine: learned distribution and topology	topology;learning algorithm;convergence;probability;learning;statistical pattern recognition high order boltzmann machine neural networks topology convergence learning algorithm bahadur lazarsfeld expansion probability distribution stochastic network;aproximacion probabilista;probabilistic approach;systeme adaptatif;algorithme;aprendizaje;algorithm;apprentissage;probability distribution convergence stochastic processes temperature educational institutions network topology machine learning neural networks pattern recognition computer science education;approche probabiliste;probability distribution;adaptive system;pattern recognition;pattern recognition boltzmann machines learning artificial intelligence probability convergence topology;sistema adaptativo;boltzmann machine;learning artificial intelligence;boltzmann machines;machine boltzmann;algoritmo	In this paper we give a formal definition of the high-order Boltzmann machine (BM), and extend the well-known results on the convergence of the learning algorithm of the two-order BM. From the Bahadur-Lazarsfeld expansion we characterize the probability distribution learned by the high order BM. Likewise a criterion is given to establish the topology of the BM depending on the significant correlations of the particular probability distribution to be learned.	anatomy, regional;boltzmann machine;convergence (action);whole earth 'lectronic link;algorithm	F. Xabier Albizuri;Alicia D'Anjou;Manuel Graña;Francisco Javier Torrealdea;Carmen Hernández	1995	IEEE transactions on neural networks	10.1109/72.377984	boltzmann machine;probability distribution;convergence;computer science;artificial intelligence;theoretical computer science;adaptive system;machine learning;probability;statistics	ML	18.78910506168962	-27.793119554970446	161230
c4c55d72044bfd703c8d82be9e83f631c504a9c4	minimal training set size estimation for neural network-based function approximation	minimisation;neural nets;sampled data systems minimisation learning artificial intelligence neural nets function approximation;function approximation;sampled data systems;two dimensional data minimal training set size function approximation continuous data sampled data two layer neural network nyquist theorem learning time algorithm;neural networks function approximation sampling methods training data frequency estimation fourier transforms multi layer neural network multidimensional systems signal restoration electronic mail;learning artificial intelligence;neural network	A new approach to the problem of n-dimensional continuous and sampled-data function approximation using a two-layer neural network is presented. The generalized Nyquist theorem is introduced to solve for the optimum number of training examples in n-dimensional input space. Choosing the smallest but still sufficient set of training vectors results in a reduced learning time for the network. Analytical formulas and algorithm for training set size reduction are developed and illustrated by two-dimensional data examples. >		Aleksander Malinowski;Jacek M. Zurada;Peter B. Aronhime	1994		10.1109/ISCAS.1994.409611	sampled data systems;minimisation;feedforward neural network;mathematical optimization;types of artificial neural networks;function approximation;computer science;theoretical computer science;machine learning;time delay neural network;universal approximation theorem;deep learning;artificial neural network;statistics	ML	17.978196474429502	-29.32194432914931	162045
43d930f9b43f8d3948512581990a924d61163305	parallel tracing of multiple trajectories in gradient descent algorithm with cell broadband engine	multilayer perceptron;cell broadband engine;function approximation;gradient descent;function representation;multiple trajectories;generating function;back propagation;random set;gradient descent algorithm;saddle point	Explored here is the ability of Cell B.E. to efficiently reveal viable solutions of nonlinear function approximation with multilayer perceptron (MLP) employing gradient descent algorithm. The capacity of Cell BE to asynchronously trace several trajectories of implemented gradient descent algorithm from random set of starting points offers advantage of revealing statistical trends and classifying viable optimal approximations delivered by simulated function generator. Approximation conditions of surfaces of 2nd and 3rd order with saddle points, such as hyperbolic paraboloid z=x2-y2, and Monkey saddle z=x3-3xy2, are determined via implementation of gradient descent algorithm (its back propagation version) for 3 layers MPL. Demonstrated are conditions of generating function approximations with (1)highly irregular error distribution, (2)close to uniform error distribution as well as (3)enhanced approximation. In the last case the overall error is significantly smaller than that programmed in the algorithm to be attained via training patterns. Such enhanced solutions offer advantage of attaining highly accurate function representation within minimized resources of MLP (i.e. with minimized number of hidden neurons in the MLP).	algorithm;approximation;backpropagation;cell (microprocessor);function representation;gradient descent;memory-level parallelism;multilayer perceptron;multiphoton lithography;nonlinear system;quad flat no-leads package;software propagation	Yuri Boiko;Gabriel A. Wainer	2009			gradient descent;mathematical optimization;computer science;gradient method;backpropagation;neighbourhood components analysis;machine learning;descent direction;stochastic gradient descent	ML	18.437087845412226	-29.941980727438807	163173
9749989f83ef72ff8e9a716fde01427b7df3095d	bilinear residual neural network for the identification and forecasting of dynamical systems		Due to the increasing availability of large-scale observation and simulation datasets, data-driven representations arise as efficient and relevant computation representations of dynamical systems for a wide range of applications, where modeldriven models based on ordinary differential equation remain the state-of-the-art approaches. In this work, we investigate neural networks (NN) as physically-sound data-driven representations of such systems. Reinterpreting Runge-Kutta methods as graphical models, we consider a residual NN architecture and introduce bilinear layers to embed non-linearities which are intrinsic features of dynamical systems. From numerical experiments for classic dynamical systems, we demonstrate the relevance of the proposed NN-based architecture both in terms of forecasting performance and model identification.	artificial neural network;bilinear filtering;bilinear transform;computation;dynamical system;experiment;graphical model;numerical analysis;relevance;runge–kutta methods;simulation;system identification	Ronan Fablet;Said Ouala;Cédric Herzet	2017	CoRR		residual;mathematical optimization;dynamical systems theory;algorithm;artificial neural network;mathematics;ordinary differential equation;computation;bilinear interpolation;system identification;graphical model	ML	18.371560180927645	-25.129874224343563	165192
b0bd1c7953944dbcb52159e9f2431cab6b482324	statistical active learning in multilayer perceptrons	response surface methodology;redundant hidden units;multilayer perceptrons;active learning;parametric active learning;statistical variance;multilayer perceptron;fisher information matrix;backpropagation;learning systems;training data;pruning;nonhomogeneous media;statistical analysis;machine learning;design for experiments;covariance matrices;input locations;fisher information matrix statistical active learning input locations training data probabilistic active learning methods statistical variance parametric active learning multipoint search active learning pruning redundant hidden units;mean square error methods;statistical analysis multilayer perceptrons learning artificial intelligence information theory covariance matrices search problems;multilayer perceptrons learning systems training data backpropagation machine learning computer simulation response surface methodology mean square error methods nonhomogeneous media design for experiments;statistical active learning;search problems;learning artificial intelligence;multipoint search active learning;local minima;probabilistic active learning methods;computer simulation;information theory	This paper proposes new methods for generating input locations actively in gathering training data, aiming at solving problems unique to multilayer perceptrons. One of the problems is that optimum input locations, which are calculated deterministically, sometimes distribute densely around the same point and cause local minima in backpropagation training. Two probabilistic active learning methods, which utilize the statistical variance of locations, are proposed to solve this problem. One is parametric active learning and the other is multipoint-search active learning. Another serious problem in applying active learning to multilayer perceptrons is that a Fisher information matrix can be singular, while many methods, including the proposed ones, assume its regularity. A technique of pruning redundant hidden units is proposed to keep the Fisher information matrix regular. Combined with this technique, active learning can be applied stably to multilayer perceptrons. The effectiveness of the proposed methods is demonstrated through computer simulations on simple artificial problems and a real-world problem of color conversion.	active learning (machine learning);backpropagation;computer simulation;deterministic algorithm;fisher information;formation matrix;maxima and minima;multilayer perceptron;multipoint ground;sample variance;singular	Kenji Fukumizu	2000	IEEE transactions on neural networks	10.1109/72.822506	computer simulation;training set;response surface methodology;information theory;computer science;artificial intelligence;backpropagation;fisher information;pruning;machine learning;maxima and minima;pattern recognition;active learning;multilayer perceptron;active learning;statistics	ML	21.57191946085019	-29.344634588258533	167467
2e2824510a81aa276c080fa32d2f9b6802084970	lower bounds on individual sequence regret	regret minimization;online learning;online linear optimization;regularized follow the leader;regret lower bounds	In this work we lower bound the individual sequence anytime regret of a large family of online algorithms. This bound depends on the quadratic variation of the sequence, $$Q_T$$ Q T , and the learning rate. Nevertheless, we show that any learning rate that guarantees a regret upper bound of $$O(\sqrt{Q_T})$$ O ( Q T ) necessarily implies an $$\varOmega (\sqrt{Q_T})$$ Ω ( Q T ) anytime regret on any sequence with quadratic variation $$Q_T$$ Q T . The algorithms we consider are online linear optimization forecasters whose weight vector at time $$t+1$$ t + 1 is the gradient of a concave potential function of cumulative losses at time t. We show that these algorithms include all linear Regularized Follow the Leader algorithms. We prove our result for the case of potentials with negative definite Hessians, and potentials for the best expert setting satisfying some natural regularity conditions. In the best expert setting, we give our result in terms of the translation-invariant relative quadratic variation. We apply our lower bounds to Randomized Weighted Majority and to linear cost Online Gradient Descent. We show that our analysis can be generalized to accommodate diverse measures of variation beside quadratic variation. We apply this generalized analysis to Online Gradient Descent with a regret upper bound that depends on the variance of losses.	anytime algorithm;concave function;gradient descent;linear programming;mathematical optimization;online algorithm;randomized algorithm;randomized rounding;regret (decision theory)	Eyal Gofer;Yishay Mansour	2015	Machine Learning	10.1007/s10994-015-5531-y	mathematical optimization;combinatorics;machine learning;mathematics	ML	21.397099852078497	-30.86861984650766	168058
996aff391d80ae1e6ed3b98fb118d162690fc6cd	cortical circuitry implementing graphical models	graphic method;calcul neuronal;neural computation;basket cell;neurone impulsionnel;modele mathematique;51e24;maximal operator;building block;maximization;implementation;aproximacion;neurona pulsante;62e17;modele lineaire;cortical layer;modele calcul;leaky integrate and fire;fast spiking;modelo matematico;modelo lineal;anatomia;neural circuit;modele loglineaire;approximation;graph connectivity;large scale;loglinear model;spiking neurons;methode graphique;spiking neuron;linear model;conectividad grafo;62 09;mathematical model;graphical model;metodo grafico;layer 2;estimation statistique;reseau neuronal;escala grande;58a25;implementacion;anatomie;modele graphique;estimacion estadistica;connectivite graphe;statistical estimation;maximizacion;anatomy;red neuronal;computacion neuronal;modelo loglineal;maximisation;neural network;echelle grande;circuit neuronal	In this letter, we develop and simulate a large-scale network of spiking neurons that approximates the inference computations performed by graphical models. Unlike previous related schemes, which used sum and product operations in either the log or linear domains, the current model uses an inference scheme based on the sum and maximization operations in the log domain. Simulations show that using these operations, a large-scale circuit, which combines populations of spiking neurons as basic building blocks, is capable of finding close approximations to the full mathematical computations performed by graphical models within a few hundred milliseconds. The circuit is general in the sense that it can be wired for any graph structure, it supports multistate variables, and it uses standard leaky integrate-and-fire neuronal units. Following previous work, which proposed relations between graphical models and the large-scale cortical anatomy, we focus on the cortical microcircuitry and propose how anatomical and physiological aspects of the local circuitry may map onto elements of the graphical model implementation. We discuss in particular the roles of three major types of inhibitory neurons (small fast-spiking basket cells, large layer 2/3 basket cells, and double-bouquet neurons), subpopulations of strongly interconnected neurons with their unique connectivity patterns in different cortical layers, and the possible role of minicolumns in the realization of the population-based maximum operation.	anatomic structures;approximation;biological neuron model;computation;computer simulation;cortical implant;electronic circuit;expectation–maximization algorithm;graph - visual representation;graphical model;graphical user interface;hl7publishingsubsection <operations>;inference;mathematics;population;spiking neural network;anatomical layer;physiological aspects	Shai Litvak;Shimon Ullman	2009	Neural Computation	10.1162/neco.2009.05-08-783	data link layer;computer science;artificial intelligence;connectivity;machine learning;approximation;linear model;mathematical model;mathematics;graphical model;implementation;artificial neural network;algorithm;statistics;models of neural computation	ML	19.193965177382246	-27.451496737353523	169432
66e8c5682f08b49cad2a3e6c2955724ec98d8537	prediction algorithms and confidence measures based on algorithmic randomness theory	prediccion;confiance;learning algorithm;algorithmique;machine support vecteur;approximation numerique;confidence measure;machine;randomness;algorithme apprentissage;regresion;aproximacion numerica;transduction;aleatorizacion;confidence;maquina;regression;machine learning;confianza;algorithmics;algoritmica;randomisation;caractere aleatoire;numerical approximation;transduccion;learning artificial intelligence;randomization;algoritmo aprendizaje;prediction;apprentissage intelligence artificielle	This paper reviews some theoretical and experimental developments in building computable approximations of Kolmogorov's algorithmic notion of randomness. Based on these approximations a new set of machine learning algorithms have been developed that can be used not just to make predictions but also to estimate the confidence under the usual iid assumption.	algorithm;algorithmically random sequence;randomness	Alexander Gammerman;Vladimir Vovk	2002	Theor. Comput. Sci.	10.1016/S0304-3975(02)00100-7	randomization;transduction;machine;regression;prediction;artificial intelligence;machine learning;randomness tests;mathematics;confidence;algorithmics;randomness;algorithm;statistics	Theory	20.04992262221297	-30.766052996697777	169958
9cb7967c887d1a83aed5a9d7cc56360f67dd5900	helm: highly efficient learning of mixed copula networks		Learning the structure of probabilistic graphical models for complex real-valued domains is a formidable computational challenge. This inevitably leads to significant modelling compromises such as discretization or the use of a simplistic Gaussian representation. In this work we address the challenge of efficiently learning truly expressive copula-based networks that facilitate a mix of varied copula families within the same model. Our approach is based on a simple but powerful bivariate building block that is used to highly efficiently perform local model selection, thus bypassing much of computational burden involved in structure learning. We show how this building block can be used to learn general networks and demonstrate its effectiveness on varied and sizeable real-life domains. Importantly, favorable identification and generalization performance come with dramatic runtime improvements. Indeed, the benefits are such that they allow us to tackle domains that are prohibitive when using a standard learning approaches.	algorithm;bivariate data;computation;computational intelligence;discretization;fold (higher-order function);graphical model;ink serialized format;model selection;multinomial logistic regression;real life;standard operating procedure	Yaniv Tenzer;Gal Elidan	2014			machine learning;model selection;computer science;artificial intelligence;copula (linguistics);bivariate analysis;discretization;gaussian;graphical model	ML	24.483861214773352	-30.498279147543137	171755
d909e30da770eca14d069d966255bd1863edcd20	on exact learning from random walk	modelizacion;stochastic process;learning model;intelligence artificielle;modelisation;modele marche aleatoire;random walk;processus stochastique;artificial intelligence;inteligencia artificial;marcha aleatoria;proceso estocastico;modeling;modelo marcha aleatoria;random walk model;marche aleatoire	We consider a few particular exact learning models based on a random walk stochastic process, and thus more restricted than the well known general exact learning models. We give positive and negative results as to whether learning in these particular models is easier than in the general learning models.		Nader H. Bshouty;Iddo Bentov	2006		10.1007/11894841_17	stochastic process;artificial intelligence;machine learning;mathematics;random walk;statistics	NLP	20.594017605998946	-27.376546087979207	172377
6247202aeaf54b224eecc4d66134d0e60c2babf8	a learning rule for very simple universal approximators consisting of a single layer of perceptrons	contraste;modelizacion;fonction booleenne;continuous function;learning algorithm;puerta logica;reduced communication;regle;learning;metodo descenso;gradient method;implementation;multilayer perceptrons;pensee;fonction base radiale;competitive algorithms;boolean function;fonction continue;parallel perceptrons;intelligence artificielle;algorithme apprentissage;high precision;threshold logic;competitive learning;aprendizaje;porte logique;perceptron multicouche;modelisation;methode gradient;algorithme competitif;pensamiento;apprentissage;contrast;gradient bajada;regla;radial basis function;funcion continua;metodo gradiente;gradient descent;funcion booliana;logica umbral;committee machines;precision elevee;signal classification;descente gradient;precision elevada;parallel delta rule;classification signal;artificial intelligence;multi layer perceptron;inteligencia artificial;logique seuil;reseau neuronal;descent method;implementacion;funcion radial base;communication;algoritmo aprendizaje;modeling;logic gate;rule;comunicacion;red neuronal;thought;methode descente;neural network	"""One may argue that the simplest type of neural networks beyond a single perceptron is an array of several perceptrons in parallel. In spite of their simplicity, such circuits can compute any Boolean function if one views the majority of the binary perceptron outputs as the binary output of the parallel perceptron, and they are universal approximators for arbitrary continuous functions with values in [0,1] if one views the fraction of perceptrons that output 1 as the analog output of the parallel perceptron. Note that in contrast to the familiar model of a """"multi-layer perceptron"""" the parallel perceptron that we consider here has just binary values as outputs of gates on the hidden layer. For a long time one has thought that there exists no competitive learning algorithm for these extremely simple neural networks, which also came to be known as committee machines. It is commonly assumed that one has to replace the hard threshold gates on the hidden layer by sigmoidal gates (or RBF-gates) and that one has to tune the weights on at least two successive layers in order to achieve satisfactory learning results for any class of neural networks that yield universal approximators. We show that this assumption is not true, by exhibiting a simple learning algorithm for parallel perceptrons - the parallel delta rule (p-delta rule). In contrast to backprop for multi-layer perceptrons, the p-delta rule only has to tune a single layer of weights, and it does not require the computation and communication of analog values with high precision. Reduced communication also distinguishes our new learning rule from other learning rules for parallel perceptrons such as MADALINE. Obviously these features make the p-delta rule attractive as a biologically more realistic alternative to backprop in biological neural circuits, but also for implementations in special purpose hardware. We show that the p-delta rule also implements gradient descent-with regard to a suitable error measure-although it does not require to compute derivatives. Furthermore it is shown through experiments on common real-world benchmark datasets that its performance is competitive with that of other learning approaches from neural networks and machine learning. It has recently been shown [Anthony, M. (2007). On the generalization error of fixed combinations of classifiers. Journal of Computer and System Sciences 73(5), 725-734; Anthony, M. (2004). On learning a function of perceptrons. In Proceedings of the 2004 IEEE international joint conference on neural networks (pp. 967-972): Vol. 2] that one can also prove quite satisfactory bounds for the generalization error of this new learning rule."""	adaline;algorithm;analog;artificial neural network;assumed;backpropagation;benchmark (computing);boolean;committee machine;competitive learning;computation;delta rule;exhibits as topic;experiment;generalization (psychology);generalization error;gradient descent;journal of computer and system sciences;learning rule;machine learning;multilayer perceptron;numerous;radial basis function;rule (guideline);sigmoid function;weight;anatomical layer	Peter Auer;Harald Burgsteiner;Wolfgang Maass	2008	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2007.12.036	gradient descent;continuous function;radial basis function;systems modeling;delta rule;logic gate;contrast;computer science;gradient method;artificial intelligence;thought;perceptron;machine learning;mathematics;boolean function;multilayer perceptron;competitive learning;implementation;artificial neural network;algorithm	ML	17.592523980203318	-27.780447718921188	172561
01b7afd62e1e97dc2af7e30c42de3653773838ee	geometry of energy landscapes and the optimizability of deep neural networks		Deep neural networks are workhorse models in machine learning with multiple layers of nonlinear functions composed in series. Their loss function is highly non-convex, yet empirically even gradient descent minimisation is sufficient to arrive at accurate and predictive models. It is hitherto unknown why are deep neural networks easily optimizable. We analyze the energy landscape of a spin glass model of deep neural networks using random matrix theory and algebraic geometry. We analytically show that the multilayered structure holds the key to optimizability: Fixing the number of parameters and increasing network depth, the number of stationary points in the loss function decreases, minima become more clustered in parameter space, and the tradeoff between the depth and width of minima becomes less severe. Our analytical results are numerically verified through comparison with neural networks trained on a set of classical benchmark datasets. Our model uncovers generic design principles of machine learning models.	artificial neural network;benchmark (computing);convex function;deep learning;gradient descent;linear algebra;loss function;machine learning;maxima and minima;nonlinear system;numerical analysis;predictive modelling;series and parallel circuits;stationary process	Simon Becker;Yao Zhang;Alpha A. Lee	2018	CoRR		quantum mechanics;parameter space;mathematical optimization;energy landscape;mathematics;artificial neural network;algebraic geometry;spin glass;maxima and minima;gradient descent;stationary point	ML	18.729835359304737	-30.12066791360594	174447
64c4bccb1f08c617a221be3eb1ce6872f24f2fad	kernel methods on spike train space for neuroscience: a tutorial	biology computing;kernel;neural networks;hilbert spaces;tutorials machine learning learning systems kernel hilbert space neuroscience neural networks;neuroscience;hilbert space;learning systems;machine learning;tutorials;neurophysiology biological techniques biology computing hilbert spaces;neurophysiology;biological techniques;point processes kernel methods spike train space neuroscience tutorial positive definite kernels hilbert space computational neuroscientists signal processing experts mathematical analogies	Over the last decade, several positive-definite kernels have been proposed to treat spike trains as objects in Hilbert space. However, for the most part, such attempts still remain a mere curiosity for both computational neuroscientists and signal processing experts. This tutorial illustrates why kernel methods can, and have already started to, change the way spike trains are analyzed and processed. The presentation incorporates simple mathematical analogies and convincing practical examples in an attempt to show the yet unexplored potential of positive definite functions to quantify point processes. It also provides a detailed overview of the current state of the art and future challenges with the hope of engaging the readers in active participation.	action potential;computational neuroscience;hilbert space;kernel method;signal processing	Il Park;Sohan Seth;António R. C. Paiva;Lin Li;José Carlos Príncipe	2013	IEEE Signal Processing Magazine	10.1109/MSP.2013.2251072	computer science;electrical engineering;theoretical computer science;machine learning;mathematics;neurophysiology;hilbert space	ML	21.22159387016581	-28.658355031879783	174554
9c774e3a219d62072d5603fd74a33c6b4581d9b1	geometric upper bounds on rates of variable-basis approximation	rate of convergence;linear combination;fonction orthogonale;neural networks;approximation error;variable basis approximation;fonction base radiale;indexing terms;error aproximacion;orthonormal functions linear combinations variable basis approximation geometric upper bounds approximation errors;model complexity;upper bound;approximation theory;dictionnaire;radial basis function;combinacion lineal;dictionaries;orthogonal function;upper bound dictionaries computational modeling linear approximation neural networks polynomials pattern recognition optimization methods hilbert space convergence;combinatorial mathematics approximation theory;perceptron;reseau neuronal;borne superieure;funcion ortogonal;rates of approximation;funcion radial base;variable basis approximation approximation from a dictionary model complexity neural networks rates of approximation;combinatorial mathematics;approximation from a dictionary model complexity;diccionario;red neuronal;erreur approximation;combinaison lineaire;cota superior;neural network;approximation from a dictionary	In this paper, approximation by linear combinations of an increasing number n of computational units with adjustable parameters (such as perceptrons and radial basis functions) is investigated. Geometric upper bounds on rates of convergence of approximation errors are derived. The bounds depend on certain parameters specific for each function to be approximated. The results are illustrated by examples of values of such parameters in the case of approximation by linear combinations of orthonormal functions.	approximation algorithm;perceptron;radial (radio);radial basis function	Vera Kurková;Marcello Sanguineti	2008	IEEE Transactions on Information Theory	10.1109/TIT.2008.2006383	mathematical optimization;approximation error;radial basis function;combinatorics;index term;linear combination;computer science;perceptron;calculus;orthogonal functions;mathematics;rate of convergence;upper and lower bounds;artificial neural network;statistics;approximation theory	ML	18.960798747649612	-28.753385381034672	174561
0ba906e713e1a34eb68454b5cd355c8867251542	infinite-dimensional multilayer perceptrons	multilayer perceptrons kernel neurons integral equations constraint optimization discrete transforms lagrangian functions neural networks logic functions;learning;integro differential equations;multilayer perceptrons;aproximacion;variational techniques;difference equation;lagrange multiplier;multilayer perceptron;integration;approximation;algorithme;aprendizaje;function space;algorithm;apprentissage;integral transforms;difference equations;nonlinear transformation;multiplicateur lagrange;transforms;multiplicador lagrange;transformation non lineaire;transformacion no lineal;reseau neuronal;non linear transformation;red neuronal;steepest descent like algorithm infinite dimensional multilayer perceptrons nonlinear transformations integrations integral transforms variational technique lagrange multiplier technique integro difference equations;multilayer perceptrons variational techniques transforms integration difference equations integro differential equations;steepest descent;neural network;algoritmo	In this paper a new multilayer perceptron (MLP) structure is introduced to simulate nonlinear transformations on infinite-dimensional function spaces. This extension is achieved by replacing discrete neurons by a continuum of neurons, summations by integrations and weight matrices by kernels of integral transforms. Variational techniques have been employed for the analysis and training of the infinite-dimensional MLP (IDMLP). The training problem of IDMLP is solved by the Lagrange multiplier technique yielding the coupled state and adjoint state integro-difference equations. A steepest descent-like algorithm is used to construct the required kernel and threshold functions. Finally, some results are presented to show the performance of the new IDMLP.	algorithm;gradient descent;imaging, three-dimensional, computer assisted;lagrange multiplier;memory-level parallelism;multilayer perceptron;nonlinear system;quad flat no-leads package;recurrence relation;triune continuum paradigm;variational principle;cell transformation	Mustafa Kuzuoglu;Kemal Leblebicioglu	1996	IEEE transactions on neural networks	10.1109/72.508932	gradient descent;mathematical optimization;mathematical analysis;recurrence relation;function space;computer science;machine learning;approximation;calculus;mathematics;lagrange multiplier;multilayer perceptron;differential equation;artificial neural network;integral transform	Vision	17.67363694894696	-28.224831288126886	174861
d78b43847f19265cd759836bf791eb93ecefeb0c	function approximations by superimposing genetic programming trees: with applications to engineering problems	genetic program;non linear optimization;linear associative memory;genetic programming;function approximation;group of additive genetic programming tree;associative memory;value function approximation;fitness function;generalization capability	This paper concerns fundamental issues regarding genetic programming (GP) as a tool for real-valued function approximations. Standard GP suffers from the lack of estimation techniques for numerical parameters of a functional tree. Unlike other research activities, where non-linear optimization techniques are employed, we adopt the use of a linear associative memory for the estimation of these parameters under the GP algorithm. Instead of dealing with a large associative matrix, we present the method of building several associative matrices in small size, each of which is responsible for determining the value for different small portions of the whole parameter. This approach can significantly reduce computational cost, and a reasonably accurate value for parameters can be obtained. Due to the fact that the GP algorithm is likely to fall into a local minimum, the GP algorithm often fails to generate the functional tree with the desired accuracy. This motivates us to devise a group of additive genetic programming trees (GAGPT) which consists of a primary tree and a set of auxiliary trees. The output of the GAGPT is the summation of outputs of the primary tree and all auxiliary trees. The addition of auxiliary trees makes it possible to improve both the learning and generalization capability of the GAGPT, since the auxiliary tree evolves towards refining the quality of the GAGPT by optimizing its fitness function. The effectiveness of our approach is verified by applying the GAGPT to the estimation of the principal dimensions of a bulk cargo ship and engine torque of a passenger car.	approximation;genetic programming	Yun Seog Yeun;J. C. Suh;Young Soon Yang	2000	Inf. Sci.	10.1016/S0020-0255(99)00121-8	genetic programming;mathematical optimization;function approximation;computer science;artificial intelligence;machine learning;mathematics;fitness function;algorithm;statistics	DB	20.607558413468553	-24.451534017844544	175322
dbb4f19a39b023182338f69fdb04d9d834276c4f	recurrent correlation associative memories: a feature space perspective	modelizacion;exponential kernel;hopfield model;correlacion;modele hopfield;hebbian learning;dominance;kernel;memoire associative;saturacion;analisis estadistico;support vector machines;hopfield network;loi probabilite;ley probabilidad;modelo hopfield;methode noyau;support vector machine svm;distributed computing;hopfield neural nets;matrix algebra;probabilistic approach;feature space;polynomials;higher order;recurrence;modelisation;classification a vaste marge;statistical distributions;sinapsis;hamming distance;statistical analysis;dominancia;support vector machines content addressable storage hebbian learning hopfield neural nets matrix algebra polynomials statistical distributions;kernel associative memory;reseau neuronal hopfield;enfoque probabilista;approche probabiliste;recurrencia;error correction;statistical measure;probability distribution;exponential correlation associative memory ecam;metodo nucleo;support vector machine svm exponential correlation associative memory ecam feature space higher order hopfield network kernel associative memory recurrent correlation associative memory rcam;analyse statistique;distance hamming;dynamic range;recurrent correlation associative memory rcam;associative memory kernel neurons error correction support vector machines polynomials distributed computing probability distribution hamming distance dynamic range;associative memory;memoria asociativa;support vector machine recurrent correlation associative memory exponential kernel polynomial kernel higher order hopfield network hebbian weight kernel matrix statistical measure probability distribution interpattern hamming distance;kernel method;recurrent correlation associative memory;appariement chaine;modelo hebb;neurons;support vector machine;maquina ejemplo soporte;correlation;vector support machine;reseau neuronal;string matching;content addressable storage;hebb model;modeling	In this paper, we analyze a model of recurrent kernel associative memory (RKAM) recently proposed by Garcia and Moreno. We show that this model consists in a kernelization of the recurrent correlation associative memory (RCAM) of Chiueh and Goodman. In particular, using an exponential kernel, we obtain a generalization of the well-known exponential correlation associative memory (ECAM), while using a polynomial kernel, we obtain a generalization of higher order Hopfield networks with Hebbian weights. We show that the RKAM can outperform the aforementioned associative memory models, becoming equivalent to them when a dominance condition is fulfilled by the kernel matrix. To ascertain the dominance condition, we propose a statistical measure which can be easily computed from the probability distribution of the interpattern Hamming distance or directly estimated from the memory vectors. The RKAM can be used below saturation to realize associative memories with reduced dynamic range with respect to the ECAM and with reduced number of synaptic coefficients with respect to higher order Hopfield networks.	appendix;associative aphasia;coefficient;content-addressable memory;diagonally dominant matrix;dynamic range;electronic centralised aircraft monitor;feature vector;generalization (psychology);grayscale color map;hamming distance;hebbian theory;hopfield network;kernel method;kernelization;memory disorders;polynomial kernel;probability;sample variance;sensitivity and specificity;simulation;support vector machine;synaptic package manager;tacstd1 protein, human;weight;whole earth 'lectronic link;zero suppression;exponential	Renzo Perfetti;Elisa Ricci	2008	IEEE Transactions on Neural Networks	10.1109/TNN.2007.909528	probability distribution;support vector machine;kernel;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;bidirectional associative memory;hopfield network;artificial neural network	ML	21.08151232842095	-29.02700219443112	175801
d5988e21b7d5774f823e47547d8aa0cfcd5b98ca	multivariate anomaly detection in medicare using model residuals and probabilistic programming			anomaly detection	Richard A. Bauder;Taghi M. Khoshgoftaar	2017			artificial intelligence;anomaly detection;machine learning;probabilistic logic;computer science;multivariate statistics	ML	23.328493154374947	-25.17680367528191	176073
cbc0435dd5e664a62a73c22e18bf5cee86a224aa	artificial intelligence: learning to see and act	geociencias medio ambiente;ciencias biologicas generalidades;grupo de excelencia;abt scholkopf;ciencias basicas y experimentales generalidades;ciencias basicas y experimentales;geociencias medio ambiente generalidades;ciencias biologicas;grupo a	An artificial-intelligence system uses machine learning from massive training sets to teach itself to play 49 classic computer games, demonstrating that it can adapt to a variety of tasks. See Letter p.529 I mprovements in our ability to process large amounts of data have led to progress in many areas of science, not least artificial intelligence (AI). With advances in machine learning has come the development of machines that can learn intelligent behaviour directly from data, rather than being explicitly programmed to exhibit such behaviour. For instance, the advent of 'big data' has resulted in systems that can recognize objects or sounds with considerable precision. On page 529 of this issue, Mnih et al. 1 describe an agent that uses large data sets to teach itself how to play 49 classic Atari 2600 computer games by looking at the pixels and learning actions that increase the game score. It beat a professional games player in many instances — a remarkable example of the progress being made in AI. In machine learning, systems are trained to infer patterns from observational data. A particularly simple type of pattern, a mapping between input and output, can be learnt through a process called supervised learning. A supervised-learning system is given training data consisting of example inputs and the corresponding outputs, and comes up with a model to explain those data (a process called function approximation). It does this by choosing from a class of model specified by the system's designer. Designing this class is an art: its size and complexity should reflect the amount of training data available, and its content should reflect 'prior knowledge' that the designer of the system considers useful for the problem at hand. If all this is done well, the inferred model will then apply not only for the training set, but also for other data that adhere to the same underlying pattern. The rapid growth of data sets means that machine learning can now use complex model classes and tackle highly non-trivial inference problems. Such problems are usually characterized by several factors: the data are multi dimensional; the underlying pattern is complex (for instance, it might be nonlinear or changeable); and the designer has only weak prior knowledge about the problem — in particular , a mechanistic understanding is lacking. The human brain repeatedly solves non-trivial inference problems as we go about our daily lives, interpreting high-dimensional sensory …	approximation;artificial intelligence;atari;big data;choose (action);class;complexity;forty nine;inference;input/output;letter-quality printer;machine learning;nonlinear system;numerous;pc game;physical object;pixel;supervised learning;test set	Bernhard Schölkopf	2015	Nature	10.1038/518486a	reinforcement;artificial intelligence;computer science	AI	22.041489799144113	-29.547080156514216	176543
9b39b229d5ba8f193e7188bfbea2591199451688	a convergence result for learning in recurrent neural networks	convergence;stochastic process;learning;sistema;heuristic method;metodo heuristico;backpropagation;recurrence;algorithme;aprendizaje;algorithm;retropropagation;convergencia;apprentissage;recurrent network;recurrencia;backpropagation algorithm;system;processus stochastique;recurrent backpropagation;methode heuristique;systeme;recurrent neural network;reseau neuronal;proceso estocastico;retropropagacion;red neuronal;elman network;neural network;algoritmo	We give a rigorous analysis of the convergence properties of a backpropagation algorithm for recurrent networks containing either output or hidden layer recurrence. The conditions permit data generated by stochastic processes with considerable dependence. Restrictions are offered that may help assure convergence of the network parameters to a local optimum, as some simulations illustrate.	algorithm;backpropagation;local optimum;neural network software;recurrent neural network;simulation;stochastic process	Chung-Ming Kuan;Kurt Hornik;Halbert White	1994	Neural Computation	10.1162/neco.1994.6.3.420	stochastic process;computer science;artificial intelligence;backpropagation;machine learning;artificial neural network;algorithm	ML	17.912731847548375	-27.70433306788613	178199
0ece723b771f422c847ca34a2911b63b5355f3d0	efficient lifting for online probabilistic inference	structure learning;relational probabilistic models;efficient algorithm;video segmentation;probabilistic inference;probabilistic graphical model;utility maximization;graphical models;first order;viral marketing	Lifting can greatly reduce the cost of inference on firstorder probabilistic graphical models, but constructing the lifted network can itself be quite costly. In online applications (e.g., video segmentation) repeatedly constructing the lifted network for each new inference can be extremely wasteful, because the evidence typically changes little from one inference to the next. The same is true in many other problems that require repeated inference, like utility maximization, MAP inference, interactive inference, parameter and structure learning, etc. In this paper, we propose an efficient algorithm for updating the structure of an existing lifted network with incremental changes to the evidence. This allows us to construct the lifted network once for the initial inference problem, and amortize the cost over the subsequent problems. Experiments on video segmentation and viral marketing problems show that the algorithm greatly reduces the cost of inference without affecting the quality	amortized analysis;approximation algorithm;expectation–maximization algorithm;graphical model;ibm notes;lifting scheme;map;scalability	Aniruddh Nath;Pedro M. Domingos	2010			variable elimination;adaptive neuro fuzzy inference system;computer science;machine learning;pattern recognition;first-order logic;data mining;viral marketing;graphical model;probabilistic logic network;statistics	AI	24.24181769232204	-28.500603829271938	178327
f1abe9bd3aac07bb271281a9a08a721708ea9614	sparse recursive least mean p-power extreme learning machine for regression		Real industrial processes usually are equipped with onboard control or diagnostic systems and limit to store a complicated model. Also, measurement samples from real processes are contaminated with noises of different statistical characteristics and are produced by one-by-one way. In this case, learning algorithms with better learning performance and compact model for systems with noises of various statistics are necessary. This paper proposes a new online extreme learning machine (ELM) algorithm, namely, sparse recursive least mean p-power ELM (SRLMP-ELM). In SRLMP-ELM, a novel cost function, i.e., the sparse least mean p-power (SLMP) error criterion, provides a mechanism to update the output weights sequentially and automatically tune some parameters of the output weights to zeros. The SLMP error criterion aims to minimize the combination of the mean p-power of the errors and a sparsity penalty constraint of the output weights. For real industrial system requirements, the proposed on-line learning algorithm is able to provide more higher accuracy, compact model, and better generalization ability than ELM and online sequential ELM, whereas the non-Gaussian noises impact the processes, especially impulsive noises. Simulations are reported to demonstrate the performance and effectiveness of the proposed methods.	algorithm;computer simulation;elm;loss function;online and offline;online machine learning;recursion (computer science);requirement;sparse matrix;system requirements	Jing Yang;Yi Xu;Hai-Jun Rong;Shaoyi Du;Badong Chen	2018	IEEE Access	10.1109/ACCESS.2018.2815503	approximation algorithm;extreme learning machine;recursion;machine learning;computer science;distributed computing;control system;system requirements;artificial intelligence	ML	22.88717824025752	-27.9071084274014	178626
154d786a5e2f425ca585c0965618700c43a5ed45	permutation-based finite implicative fuzzy associative memories	fuzzy neural network;morphological neural networks;salt and pepper noise;implicative fuzzy learning;computer experiment;storage capacity;associative memory;fuzzy neural networks;pepper;finite chain;neural network;fuzzy associative memories	Implicative fuzzy associative memories (IFAMs) are single layer feedforward fuzzy neural networks whose synaptic weights and threshold values are given by implicative fuzzy learning. Despite an excellent tolerance with respect to either pasitive or negative noise, IFAMs are not suited for patterns corrupted by mixed noise. This paper presents a solution to this problem. Precisely, we first introduce the class of finite IFAMs by replacing the unit interval by a finite chain L. Then, we generalize both finite IFAMs and their dual versions by means of a permutation on L. The resulting models are referred to as permutationbased finite IFAMs (p-IFAMs). We show that a p-IFAM can be viewed as a finite IFAM, but defined on an alternative lattice structure ðL;^Þ. Thus, p-IFAMs also exhibit optimal absolute storage capacity and one step convergence in the autoassociative case. Furthermore, computational experiments revealed that a certain p-IFAM, called Lukasiewicz plIFAM, outperformed several other associative memory models for the reconstruction of gray-scale patterns corrupted by salt and pepper noise. 2010 Elsevier Inc. All rights reserved.	artificial neural network;computation;content-addressable memory;crystal structure;experiment;feedforward neural network;grayscale;salt-and-pepper noise;synaptic package manager	Marcos Eduardo Valle	2010	Inf. Sci.	10.1016/j.ins.2010.07.003	computer experiment;computer science;artificial intelligence;machine learning;mathematics;artificial neural network;algorithm;salt-and-pepper noise	AI	18.421143496241633	-28.864446777794175	179071
183c4993aa483d06c672a68ec289b37700b0d0aa	learning regression models with guaranteed error bounds		The combination of a symbolic regression model with a residual Gaussian Process is proposed for providing an interpretable model with improved accuracy. While the learned symbolic model is highly interpretable the residual model usually is not. However, by limiting the output of the residual model to a defined range a worst-case guarantee can be given in the sense that the maximal deviation from the symbolic model is always below a defined limit. When ranking the accuracy and interpretability of several different approaches on the SARCOS data benchmark the proposed combination yields the best result.	benchmark (computing);best, worst and average case;gaussian process;maximal set;symbolic regression	Clemens Otte	2013			econometrics;machine learning;mathematics;statistics	AI	22.92247439385921	-29.978182891121786	179144
a2729b6ca8d24bb806c168528eb81de950871446	a unified approach for mining outliers	electronic commerce;time complexity;large dataset;statistical distribution;credit cards	This paper deals with nding outliers (exceptions) in large datasets. The identiication of outliers can often lead to the discovery of truly unexpected knowledge in areas such as electronic commerce, credit card fraud, and even the analysis of performance statistics of professional athletes. One contribution of this paper is to show how our proposed, intuitive notion of outliers can unify or generalize many of the existing notions of outliers provided by discordancy tests for standard statistical distributions. Thus, when mining large datasets containing many attributes, a uniied approach can replace many statistical discordancy tests, regardless of any knowledge about the underlying distribution of the attributes. A second contribution of this paper is the development of an algorithm to nd all outliers in a dataset. An important advantage of this algorithm is that its time complexity is linear with respect to the number of objects in the dataset. We include preliminary performance results.	algorithm;credit card fraud;e-commerce;time complexity	Edwin M. Knorr;Raymond T. Ng	1997		10.1145/782010.782021	e-commerce;probability distribution;time complexity;computer science;data science;data mining;database	ML	23.722144015488432	-25.99693984375891	179369
36edc1a8558d1cb5285c325aeea5f0d5800d587b	embedding a grammatical description in deterministic chaos: an experiment in recurrent neural learning	stochastic process;dynamic system;self organization;recurrent neural network;evolutionary process;finite state machine;deterministic chaos	We consider the modeling process of a “biological” agent by combining the concepts of neuroinformatics and deterministic chaos. We assume that an agent observes a target process as a stochastic symbolic process, which is restricted by grammatical constraints. Our main hypothesis is that an agent would learn the target model by reconstructing an equivalent quasi-stochastic process on its deterministic neural dynamics. We employed a recurrent neural network (RNN), which is regarded as an adjustable deterministic dynamical system. Then, we conducted an experiment to observe how the RNN learns to reconstruct the target process, represented by a stochastic finite state machine in the simulation. The result revealed the capability of the RNN to evolve, by means of learning, toward chaos, which is able to mimic a target's stochastic process. We precisely analyzed the evolutionary process as well as the internal representation of the neural dynamics obtained. This analysis enabled us to clarify an interesting mechanism of the self-organization of chaos by means of neural learning, and also showed how grammar can be embedded in the evolved deterministic chaos.	artificial neural network;chaos theory;dynamical system;embedded system;finite-state machine;neuroinformatics;probabilistic automaton;random neural network;recurrent neural network;self-organization;simulation;stochastic process	Jun Tani;Naohiro Fukumura	1995	Biological Cybernetics	10.1007/BF00202792	stochastic process;self-organization;computer science;artificial intelligence;recurrent neural network;theoretical computer science;dynamical system;machine learning;mathematics;statistics	ML	18.681919995354804	-23.995399232995478	179602
bc4c605897132820ccbcf7bc18ac6770783898f2	multi-statistic approximate bayesian computation with multi-armed bandits		Approximate Bayesian computation is an established and popular method for likelihood-free inference with applications in many disciplines. The effectiveness of the method depends critically on the availability of well performing summary statistics. Summary statistic selection relies heavily on domain knowledge and carefully engineered features, and can be a laborious time consuming process. Since the method is sensitive to data dimensionality, the process of selecting summary statistics must balance the need to include informative statistics and the dimensionality of the feature vector. This paper proposes to treat the problem of dynamically selecting an appropriate summary statistic from a given pool of candidate summary statistics as a multi-armed bandit problem. This allows approximate Bayesian computation rejection sampling to dynamically focus on a distribution over well performing summary statistics as opposed to a fixed set of statistics. The proposed method is unique in that it does not require any pre-processing and is scalable to a large number of candidate statistics. This enables efficient use of a large library of possible time series summary statistics without prior feature engineering. The proposed approach is compared to state-of-the-art methods for summary statistics selection using a challenging test problem from the systems biology literature.	algorithmic efficiency;approximation algorithm;computation;feature engineering;feature vector;information;iteration;multi-armed bandit;preprocessor;rejection sampling;sampling (signal processing);scalability;systems biology;time series	Prashant Singh;Andreas Hellander	2018	CoRR		domain knowledge;mathematics;artificial intelligence;machine learning;feature vector;statistic;summary statistics;approximate bayesian computation;rejection sampling;inference;feature engineering	ML	23.4929343403314	-29.801935934374914	180382
05d68458ad785987e2eef62444cbf97ff3cd35c6	magnification control in winner relaxing neural gas	self organizing maps;probability density;data distribution;neural gas;vector quantization;magnification control;mutual information;self organized map;vector quantizer;disordered system;information theory;neural network	An important goal in neural map learning, which can conveniently be accomplished by magnification control, is to achieve information optimal coding in the sense of information theory. In the present contribution we consider the winner relaxing approach for the neural gas network. Originally, winner relaxing learning is a slight modification of the self-organizing map learning rule that allows for adjustment of the magnification behavior by an a priori chosen control parameter. We transfer this approach to the neural gas algorithm. The magnification exponent can be calculated analytically for arbitrary dimension from a continuum theory, and the entropy of the resulting map is studied numerically conf irming the theoretical prediction. The influence of a diagonal term, which can be added without impacting the magnification, is studied numerically. This approach to maps of maximal mutual information is interesting for applications as the winner relaxing term only adds computational cost of same order and is easy to implement. In particular, it is not necessary to estimate the generally unknown data probability density as in other magnification control approaches.	algorithm;algorithmic efficiency;computation;information theory;learning rule;maximal set;mutual information;neural gas;neuron;numerical analysis;numerical linear algebra;organizing (structure);self-organization;self-organizing map;simulation;triune continuum paradigm	Jens Christian Claussen;Thomas Villmann	2003	Neurocomputing	10.1016/j.neucom.2004.01.191	neural gas;probability density function;self-organizing map;information theory;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;mutual information;vector quantization;artificial neural network;statistics	ML	19.419047627658085	-27.968451844197343	180438
a780d5d36b4fc9909811bffe3667b03f0550e0ab	a tropical approach to neural networks with piecewise linear activations		We present a new, unifying approach following some recent developments on the complexity of neural networks with piecewise linear activations. We treat neural network layers with piecewise linear activations, such as Maxout or ReLU units, as polynomials in the (max,+) (or so-called tropical) algebra. Following up on the work of Montufar et al. [30], this approach enables us to improve their upper bound on linear regions of layers with ReLU or leaky ReLU activations to min { 2, 2 · ∑n j=0 ( m−1 j ) } , where n,m are the number of inputs and outputs, respectively. Additionally, we recover their upper bounds on maxout layers. Our work is parallel to the improvements reported in [3, 42], though exclusively under the lens of tropical geometry.	artificial neural network;deep learning;linear algebra;maxima and minima;max–min inequality;newton;piecewise linear continuation;polynomial;rectifier (neural networks)	Vasileios Charisopoulos;Petros Maragos	2018	CoRR		mathematical optimization;mathematics;discrete mathematics;artificial neural network;tropical geometry;piecewise linear function;polynomial;upper and lower bounds	ML	19.06996366088413	-29.79305755711864	181075
c9996b8d6d267cf10b67ff7e29ccbbe86740efba	research on algorithm of computer adaptive test using optimized mdpltm	innovation ability;computer adaptive testing;difficulty value;irt;optimized multi dimensional polytomous latent trait model omdpltm;adaptive test	On the basic of the modern education measure theory and computer adaptive test, the paper designed the algorithm of the adaptive test using the new model of item response theory: multi-dimensional polytomous latent trait model. Meanwhile, it tried on individual restrain parameters to optimize the algorithm in order to content the development of an individual's all-round way abilities.	algorithm	Jin-Ling Li;Feng-lin Wang;Wang-Xiu Li	2006			simulation;computerized adaptive testing;statistics	EDA	24.41732348526183	-24.886358568104747	183517
9c2c9e398c2f76940f40cfe072d3b10e63d065cc	approximate inference in bayesian networks using binary probability trees	bayes estimation;bayesian network;variable elimination;pruning tree;probability trees;indice aptitud;intelligence artificielle;algorithme deterministe;probabilistic approach;poda;context specific independence;indice aptitude;reseau bayes;deterministic algorithms;estimacion bayes;marginal distribution;red bayes;arbol binario;capability index;enfoque probabilista;approche probabiliste;arbre binaire;inferencia;bayes network;ley marginal;artificial intelligence;approximate inference;inteligencia artificial;elagage;variable elimination algorithm;bayesian networks inference;approximate computation;inference;loi marginale;estimation bayes;binary tree	The present paper introduces a new kind of representation for the potentials in a Bayesian network: binary probability trees. They enable the representation of context-specific independences in more detail than probability trees. This enhanced capability leads to more efficient inference algorithms for some types of Bayesian networks. This paper explains the procedure for building a binary probability tree from a given potential, which is similar to the one employed for building standard probability trees. It also offers a way of pruning a binary tree in order to reduce its size. This allows us to obtain exact or approximate results in inference depending on an input threshold. This paper also provides detailed algorithms for performing the basic operations on potentials (restriction, combination and marginalization) directly to binary trees. Finally, some experiments are described where binary trees are used with the variable elimination algorithm to compare the performance with that obtained for standard probability trees. 2010 Elsevier Inc. All rights reserved.	approximation algorithm;bayesian network;binary tree;decision tree;experiment;variable elimination	Andrés Cano;Manuel Gómez-Olmedo;Serafín Moral	2011	Int. J. Approx. Reasoning	10.1016/j.ijar.2010.05.006	random binary tree;binary search tree;binary expression tree;geometry of binary search trees;binary tree;computer science;machine learning;pattern recognition;bayesian network;mathematics;weight-balanced tree;ternary search tree;statistics	ML	24.561870097685144	-27.657211378534196	184855
d4eb0bb2dd3675b5675aef6f69e09b1f3ad04954	unsupervised learning in lstm recurrent neural networks	unsupervised learning;feedforward neural network;reseau information;optimisation;time varying;entropia;feedforward;optimizacion;apprentissage non supervise;long terme;boucle anticipation;information network;time varying system;long term;ciclo anticipacion;largo plazo;recurrent network;systeme parametre variable;entropie;court terme;optimization;entropy;sistema parametro variable;recurrent neural network;learning artificial intelligence;reseau neuronal;information gain;information theoretic;red neuronal;corto plazo;short term;long short term memory;red informacion;neural network;apprentissage intelligence artificielle	While much work has been done on unsupervised learning in feedforward neural network architectures, its potential with (theoretically more powerful) recurrent networks and time-varying inputs has rarely been explored. Here we train Long Short-Term Memory (LSTM) recurrent networks to maximize two information-theoretic objectives for unsupervised learning: Binary Information Gain Optimization (BINGO) and Nonparametric Entropy Optimization (NEO). LSTM learns to discriminate different types of temporal sequences and group them according to a variety of features.	long short-term memory;neural networks;recurrent neural network;unsupervised learning	Magdalena Klapper-Rybicka;Nicol N. Schraudolph;Jürgen Schmidhuber	2001		10.1007/3-540-44668-0_95	unsupervised learning;entropy;simulation;computer science;artificial intelligence;machine learning;deep learning;artificial neural network	ML	19.25804476527889	-28.83709045002725	185024
5b1bd8bbf73eee6d47b0d10a7c77cadb6df989b4	learning fixed point patterns by recurrent networks	reseau recurrent;convergence;learning;punto fijo;intelligence artificielle;fixed point;algorithme;aprendizaje;algorithm;convergencia;apprentissage;recurrent network;equilibre;point fixe;artificial intelligence;matrice poids connexion;inteligencia artificial;equilibrium;equilibrio;reseau neuronal;fix point;red neuronal;neural network;algorithme iteratif;algoritmo	Several learning algorithms have been derived for equilibrium points in recurrent neural networks. In this paper, we also consider learning the equilibrium points of such dynamical systems. We derive a structurally simple learning algorithm for recurrent networks which does not involve computing the trajectories of the system and we prove convergence and give examples. We also discuss solving for the connection weight matrix by iterative learning algorithms or direct solving.	fixed point (mathematics)	Leong Kwan Li	1994	J. Comput. Syst. Sci.	10.1016/S0022-0000(05)80001-7	instance-based learning;convergence;computer science;artificial intelligence;machine learning;calculus;mathematics;fixed point;stability;competitive learning;computational learning theory;active learning;artificial neural network;algorithm;generalization error	Theory	18.686924403940196	-27.25591820636427	186042
d9d652982ac862db3b093fd07ee1d67a919be01d	prediction with advice of unknown number of experts	prediction with expert advice;science learning;working paper;forecasting method	In the framework of prediction with expert advice, we consider a recently introduced kind of regret bounds: the bounds that depend on the effective instead of nominal number of experts. In contrast to the NormalHedge bound, which mainly depends on the effective number of experts but also weakly depends on the nominal one, we obtain a bound that does not contain the nominal number of experts at all. We use the defensive forecasting method and introduce an application of defensive forecasting to multivalued supermartingales.	regret (decision theory)	Alexey V. Chernov;Vladimir Vovk	2010			computer science;artificial intelligence;machine learning;data mining	ML	20.59868222567478	-30.910347136623326	186544
60a60ef3edfc5719fa1a9112868f7c893f231dd2	top-k rank aggregation from m-wise comparisons		Suppose one aims to identify only the top- $K$ among a large collection of $n$ items provided $M$ -wise comparison data, where a set of $M$ items in each data sample are ranked in order of individual preference. Natural questions that arise are as follows: 1) how one can reliably achieve the top- $K$ rank aggregation task; and 2) how many $M$ -wise samples one needs to achieve it. In this paper, we answer these two questions. First, we devise an algorithm that effectively converts $M$ -wise samples into pairwise ones and employs a spectral method using the refined data. Second, we consider the Plackett–Luce (PL) model, a well-established statistical model, and characterize the minimal number of $M$ -wise samples (i.e., sample complexity) required for reliable top- $K$ ranking. It turns out to be inversely proportional to $M$ . To characterize it, we derive a lower bound on the sample complexity and prove that our algorithm achieves the bound. Moreover, we conduct extensive numerical experiments to demonstrate that our algorithm not only attains the fundamental limit under the PL model but also provides robust ranking performance for a variety of applications that may not precisely fit the model. We corroborate our theoretical result using synthetic datasets, confirming that the sample complexity decreases at the rate of $frac{1}{M}$ . Also, we verify the applicability of our algorithm in practice, showing that it performs well on various real-world datasets.		Minje Jang;Sunghyun Kim;Changho Suh	2018	J. Sel. Topics Signal Processing	10.1109/JSTSP.2018.2834864	mathematical optimization;sample (statistics);noise measurement;computer science;pairwise comparison;proportionality (mathematics);spectral method;statistical model;ranking;upper and lower bounds	ML	23.45983753965765	-26.150803552252885	186627
be0a6f6340ac79c967b461e36c96b23ef3a9ba59	information-theoretic approach to blind separation of sources in non-linear mixture	gradient descent method;traitement signal;learning algorithm;signal estimation;metodo entropia maxima;gradient method;methode gradient;blind separation;metodo gradiente;signal processing;backpropagation algorithm;estimacion senal;algorithme retropropagation;mutual information;information back propagation;non linear mixture;theorie information;information entropy;reseau neuronal;methode entropie maximum;minimum mutual information;procesamiento senal;information theoretic;estimation signal;method of maximum entropy;back propagation;red neuronal;linear mixture model;maximum entropy;information theory;neural network;algoritmo retropropagacion;teoria informacion	The linear mixture model is assumed in most of the papers devoted to blind separation. A more realistic model for mixture should be non-linear. In this paper, a two-layer perceptron is used as a de-mixing system to separate sources in non-linear mixture. The learning algorithms for the de-mixing system are derived by two approaches: maximum entropy and minimum mutual information. The algorithms derived from the two approaches have a common structure. The new learning equations for the hidden layer are diierent from the learning equations for the output layer. The natural gradient descent method is applied in maximizing entropy and minimizing mutual information. The information (entropy or mutual information) back-propagation method is proposed to derive the learning equations for the hidden layer.	algorithm;backpropagation;blind signal separation;entropy (information theory);gradient descent;machine learning;mixing (mathematics);mixture model;mutual information;nonlinear system;perceptron;software propagation;theory	Howard Hua Yang;Shun-ichi Amari;Andrzej Cichocki	1998	Signal Processing	10.1016/S0165-1684(97)00196-5	information theory;computer science;backpropagation;calculus;signal processing;mathematics;algorithm;statistics	ML	19.56502721975327	-28.108276008298105	188662
01763f28d8f559b8bd1fbfdd7789563f976b03e7	loopy belief propagation in bayesian networks : origin and possibilistic perspectives		In this paper we present a synthesis of the work pe formed on two inference algorithms: the Pearl’s belief propagation (BP) algorithm applied t o Bayesian networks without loops (i.e. polytree) and the Loopy belief propagation (LBP) al gorithm (inspired from the BP) which is applied to networks containing undirected cycles. I t is known that the BP algorithm, applied to Bayesian networks with loops, gives incorrect numer ical results i.e. incorrect posterior probabilities. Murphy and al. [7] find that the LBP algorithm converges on several networks and when this occurs, LBP gives a good approximation of the exact posterior probabilities. However this algorithm presents an oscillatory behaviour wh en it is applied to QMR (Quick Medical Reference) network [15]. This phenomenon prevents t he LBP algorithm from converging towards a good approximation of posterior probabili ties. We believe that the translation of the inference computation problem from the probabilisti c framework to the possibilistic framework will allow performance improvement of LBP algorithm . We hope that an adaptation of this algorithm to a possibilistic causal network will sh ow an improvement of the convergence of LBP. 1. Review of Bayesian Networks Bayesian networks are powerful tools for modelling causes and effects in a wide variety of domains. They use graphs capturing causality notion between variables, and probability theory to express the causality power. Bayesian networks are very effective for modelling situations where some information is already known and incoming data is uncertain or partially unavailable. These networks also offer consistent semantics for representing causes and effects via an intuitive graphical representation. Because of all these capabilities, Bayesian networks are regarded as systems for uncertain knowledge representation and have a large number of applications with efficient algorithms and have strong theoretical foundations [9],[10],[11] and [12]. Theoretically, a Bayesian network is a directed acyclic graph (DAG) made up of nodes and causal edges. Each node has a probability of having a certain value. Nodes are often binary, though a Bayesian network may have n-ary nodes. Parent and child nodes are defined as follows: a directed edge exists from a parent to a child. Each child node will have a conditional probability table (CPT) based on parental values. There are no directed cycles in the graph, though there may be “loops”, or undirected cycles. An example network is shown in Figure 1, with parents Ui sharing a child X. The node X is a child of the Ui's as well as being a parent to the Yi's. TEGERA, The International Group of e-Systems Research and Applications. Hammamet, Tunisia, February 12-14, (2007). 2 Figure 1: A Bayesian Network (polytree) 2. Bayesian Network inference In bayesian network, the objective of inference is to compute P(X|E), the posterior probabilities of some “query” nodes (noted by X) given some observed value of evidence nodes (noted by E, E ⊄X) [13]. A simple form of it results when X is a single node, i.e., computing the posterior marginal probabilities of a single query node. With the constitution of a large Bayesian network, the feasibility of the probabilistic inference is tested: when the network is simple, the calculation of these probabilities is not very difficult. On the other hand, when the network becomes very large, several problems emerge: the inference requires an enormous memory size and calculation becomes very complex or even, in certain cases, can not be completed. The inference algorithms are classified in two groups [5]: Exact algorithms: these methods use the conditional independence contained in the networks and give, to each inference, the exact posterior probabilities. The exact probabilistic inference in general has been proven to be NP-hard by Cooper [4]. Approximate algorithms: they are the alternatives of the exact algorithms when the networks become very complex. They estimate the posterior probabilities in various ways. Approximating probabilistic inference was also shown to be NP-hard by Dagum and Luby [8]. 3. Pearl’s algorithm At the beginning of the 80s, Pearl published an efficient message propagation inference algorithm for polytrees [6] and [10]. This algorithm is an exact belief propagation procedure but works only for polytrees [12]. Consider the case of a general discrete node X having parents U1...Um and children Y1...Yn, as shown in Figure 1. Evidence will be represented by E, with evidence “above” X (evidence at ancestors of X) represented as e and evidence “below” X (evidence at descendants of X) as e . Knowledge of evidence can flow either down the network (from parent to child) or up the network (child to parent). We use the notation π(Ui) to represent a message from parent Ui to child and λ(Y j) for a message from child Yj to parent (see Figure 2) [13]. Figure 2: Messages propagation U1 U2 Um	approximation algorithm;backpropagation;bayesian network;belief propagation;cpt (file format);casio loopy;causal filter;causality;computation;computational problem;directed acyclic graph;directed graph;exact algorithm;graph (discrete mathematics);graphical user interface;knowledge representation and reasoning;local binary patterns;marginal model;michael luby;np-hardness;realization (probability);software propagation;tree (data structure);unified model;ipod;ical	Amen Ajroud;Mohamed Nazih Omri;Habib Youssef;Salem Benferhat	2012	CoRR		artificial intelligence;machine learning;mathematics;algorithm;statistics	ML	24.258206088545613	-26.96355526817605	188932
666ab73d8095710b2d377e129f5e7959fcf62a9f	varieties of helmholtz machine	minimisation;unsupervised learning;minimization;learning algorithm;architecture systeme;bottom up;probability density;learning;top down;funcion densidad probabilidad;probability density function;minimizacion;aprendizaje;feedback connections;fonction densite probabilite;apprentissage;expectation maximization;information processing;estimacion parametro;cat;model;arquitectura sistema;parameter estimation;estimation parametre;reseau neuronal;system architecture;em algorithm;expectation maximisation;visual cortex;red neuronal;neural network	The Helmholtz machine is a new unsupervised learning architecture that uses top-down connections to build probability density models of input and bottom-up connections to build inverses to those models. The wake-sleep learning algorithm for the machine involves just the purely local delta rule. This paper suggests a number of different varieties of Helmholtz machines, each with its own strengths and weaknesses, and relates them to cortical information processing. Copyright 1996 Elsevier Science Ltd.	algorithm;copyright;delta rule;helmholtz machine;information processing;probability density;top-down and bottom-up design;unsupervised learning;weakness	Peter Dayan;Geoffrey E. Hinton	1996	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(96)00009-3	unsupervised learning;probability density function;wake-sleep algorithm;expectation–maximization algorithm;information processing;computer science;artificial intelligence;machine learning;top-down and bottom-up design;mathematics;artificial neural network;algorithm;statistics	ML	19.680157954286067	-28.018050590518502	189347
2caf022389d2c2b8bf2cc08866031d9b30d71f52	private sequential learning		We formulate a private learning model to study an intrinsic tradeoff between privacy and query complexity in sequential learning. Our model involves a learner who aims to determine a scalar value, (v^*), by sequentially querying an external database with binary responses. In the meantime, an adversary observes the learneru0027s queries, though not the responses, and tries to infer from them the value of (v^*). The objective of the learner is to obtain an accurate estimate of (v^*) using only a small number of queries, while simultaneously protecting her privacy by making (v^*) provably difficult to learn for the adversary. Our main results provide tight upper and lower bounds on the learneru0027s query complexity as a function of desired levels of privacy and estimation accuracy. We also construct explicit query strategies whose complexity is optimal up to an additive constant.	adversary (cryptography);decision tree model;privacy;utility functions on indivisible goods	John N. Tsitsiklis;Kuang Xu;Zhi Xu	2018			instrumental and intrinsic value;mathematical optimization;computer science;adversary;theoretical computer science;small number;binary number;scalar value;sequence learning;upper and lower bounds	ML	24.46952330970667	-26.127087104242026	189983
57476501d07b60c5e1b8571a7a19be6c315b1950	manifold stochastic dynamics for bayesian learning	metrique riemann;hamilton equation;metropolis algorithm;fonction vraisemblance;sample size;chaine markov;cadena markov;metodo monte carlo;stochastic process;learning;tamano muestra;decision bayes;espace etat;methode monte carlo;taille echantillon;exploracion;variedad matematica;bayes decision;funcion verosimilitud;geometrie riemann;dynamical system;algorithme;aprendizaje;systeme dynamique;algorithm;apprentissage;markov chain monte carlo;bayesian learning;algorithme metropolis;monte carlo method;state space;ecuacion hamilton;processus stochastique;riemann geometry;exploration;stochastic dynamics;sistema dinamico;proceso estocastico;equation hamilton;espacio estado;riemann metric;likelihood function;metrico riemann;geometric structure;neural network;variete mathematique;algoritmo;manifold;markov chain	We propose a new Markov Chain Monte Carlo algorithm, which is a generalization of the stochastic dynamics method. The algorithm performs exploration of the state-space using its intrinsic geometric structure, which facilitates efficient sampling of complex distributions. Applied to Bayesian learning in neural networks, our algorithm was found to produce results comparable to the best state-of-the-art method while consuming considerably less time.	artificial neural network;computation;generalization (psychology);leucaena pulverulenta;markov chain monte carlo;monte carlo algorithm;monte carlo method;neural network simulation;nonlinear system;sampling (signal processing);sampling - surgical action;state space;stochastic process;time complexity;manifold	Mark Zlochin;Yoram Baram	1999	Neural Computation	10.1162/089976601753196021	sample size determination;stochastic process;riemannian geometry;metropolis–hastings algorithm;markov chain;wake-sleep algorithm;gibbs sampling;exploration;markov chain monte carlo;manifold;state space;dynamical system;calculus;mathematics;geometry;likelihood function;bayesian inference;artificial neural network;statistics;monte carlo method	ML	20.67468230901964	-27.575060582023163	190960
84361e67d5ac780d2c86c21c66c741f98867b2c8	machine learning [book review]	feedforward neural networks;optimisation;kernel;neural networks;support vector machines;neural nets;inference mechanisms;book reviews machine learning physics neural networks support vector machines kernel educational institutions feedforward neural networks information analysis intelligent networks;approximation theory;learning systems;physics;statistical analysis;machine learning;artificial intelligence;book reviews;intelligent networks;reviews;information analysis	95 Roughly speaking, machine learning is the problem of computing a mathematical rule that generalizes a relationship initially provided by a finite sample of real data. The problem of deducing a mathematical relationship between independent and dependent variables in an experiment is at the heart of both scientific research and much engineering practice. Machine learning is an area of statistics that when viewed in this light, is closely related to (but not contained in) the field of regression analysis. The two books reviewed here document many of the mathematical and algorithmic advances to date.	algorithm;book;here document;machine learning	George Cybenko	2001	Computing in Science & Engineering	10.1109/MCISE.2001.919274	support vector machine;intelligent network;kernel;computer science;artificial intelligence;machine learning;data mining;data analysis;artificial neural network;approximation theory	ML	21.193460811342895	-28.432533063425364	191277
0c6d1f0ea492a9c58cdecbe1f846ccf8f95c19ed	tractable learning and inference in high-treewidth graphical models	computer science tractable learning and inference in high treewidth graphical models university of maryland;college park yiannis aloimonos domke;justin;dissertation;statistics	Title of dissertation: TRACTABLE LEARNING AND INFERENCE IN HIGH-TREEWIDTH GRAPHICAL MODELS Justin Domke, Doctor of Philosophy, 2009 Dissertation directed by: Professor Yiannis Aloimonos Department of Computer Science Probabilistic graphical models, by making conditional independence assumptions, can represent complex joint distributions in a factorized form. However, in large problems graphical models often run into two issues. First, in non-treelike graphs, computational issues frustrate exact inference. There are several approximate inference algorithms that, while often working well, do not obey approximation bounds. Second, traditional learning methods are non-robust with respect to model errors– if the conditional independence assumptions of the model are violated, poor predictions can result. This thesis proposes two new methods for learning parameters of graphical models: implicit and procedural fitting. The goal of these methods is to improve the results of running a particular inference algorithm. Implicit fitting views inference as a large nonlinear energy function over predicted marginals. During learning, the parameters are adjusted to place the minima of this function close to the true marginals. Inspired by algorithms like loopy belief propagation, procedural fitting considers inference as a message passing procedure. Parameters are adjusted while learning so that this message-passing process gives the best results. These methods are robust to both model errors and approximate inference because learning is done directly in terms of predictive accuracy.	approximation algorithm;belief propagation;casio loopy;graphical model;justin (robot);justin frankel;mathematical optimization;maxima and minima;message passing;nonlinear system;software propagation;treewidth	Justin Domke	2009			computer science;artificial intelligence;data science	ML	24.363057185836656	-29.01599714207801	191303
e11eb7e775b0842009a3e59bf08b76eef29886b5	lifted meu by weighted model counting	influence diagrams;lifted inference	Recent work in the field of probabilistic inference demonstrated the efficiency of weighted model counting (WMC) engines for exact inference in propositional and, very recently, first order models. To date, these methods have not been applied to decision making models, propositional or first order, such as influence diagrams, and Markov decision networks (MDN). In this paper we show how this technique can be applied to such models. First, we show how WMC can be used to solve (propositional) MDNs. Then, we show how this can be extended to handle a first-order model – the Markov Logic Decision Network (MLDN). WMC offers two central benefits: it is a very simple and very efficient technique. This is particularly true for the firstorder case, where the WMC approach is simpler conceptually, and, in many cases, more effective computationally than the existing methods for solving MLDNs via first-order variable elimination, or via propositionalization. We demonstrate the above empirically.	computation;first-order predicate;influence diagram;markov chain;markov logic network;telephone number;variable elimination;windows media center	Udi Apsel;Ronen I. Brafman	2012			influence diagram;computer science;artificial intelligence;machine learning;algorithm;statistics	AI	24.252573346510168	-26.89790815110154	192641
2e7b6e73398af01bc975e9bf9374ee5f255252b3	vfunc: a deep generative model for functions		We introduce a deep generative model for functions. Our model provides a joint distribution p(f, z) over functions f and latent variables z which lets us efficiently sample from the marginal p(f) and maximize a variational lower bound on the entropy H(f). We can thus maximize objectives of the form Ef∼p(f)[R(f)] +λH(f), where R(f) denotes, e.g., a data log-likelihood term or an expected reward. Such objectives encompass Bayesian deep learning in function space, rather than parameter space, and Bayesian deep RL with representations of uncertainty that offer benefits over bootstrapping and parameter noise. In this short paper we describe our model, situate it in the context of prior work, and present proof-ofconcept experiments for regression and RL.	calculus of variations;data logger;deep learning;experiment;generative model;latent variable;marginal model;rl (complexity);situated cognition	Philip Bachman;Riashat Islam;Alessandro Sordoni;Zafarali Ahmed	2018	CoRR		deep learning;mathematics;parameter space;function space;mathematical optimization;generative model;joint probability distribution;latent variable;artificial intelligence;bayesian probability;upper and lower bounds	ML	23.457687262977156	-30.46745276817647	192674
26997f15bd140687a979cb299779ac628cff575d	minimizing regret with label efficient prediction	individual sequence;game theoretic prediction model;settore inf 01 informatica;regret minimization;sistema experto;prediction error;game theory;procesamiento informacion;learning;individual sequences;economic forecasting;predictive models game theory h infinity control economic forecasting pattern recognition statistical learning minimax techniques;prediction with expert advice individual sequences label efficient prediction on line learning;teoria juego;pregunta documental;theorie jeu;indexing terms;predictor;aprendizaje;repeated game;game theory prediction theory;funcion logaritmica;predicteur;optimal growth;minimax techniques;prediction with expert advice;apprentissage;logarithmic function;statistical learning;prediction theory;loss function;levels of abstraction;information processing;fonction logarithmique;pattern recognition;query;upper bound matching;lower bound matching;predictive models;upper and lower bounds;prediction model;systeme expert;cumulant;traitement information;h infinity control;hannan consistency;learning theory;label efficient prediction;regret minimization label efficient prediction upper bound matching lower bound matching hannan consistency game theoretic prediction model individual sequence on line learning prediction with expert advice;requete;on line learning;expert system	We investigate label efficient prediction, a variant, proposed by Helmbold and Panizza, of the problem of prediction with expert advice. In this variant, the forecaster, after guessing the next element of the sequence to be predicted, does not observe its true value unless he asks for it, which he cannot do too often. We determine matching upper and lower bounds for the best possible excess prediction error, with respect to the best possible constant predictor, when the number of allowed queries is fixed. We also prove that Hannan consistency, a fundamental property in game-theoretic prediction models, can be achieved by a forecaster issuing a number of queries growing to infinity at a rate just slightly faster than logarithmic in the number of prediction rounds.	consistency model;game theory;kerrison predictor;offset binary;regret (decision theory)	Nicolò Cesa-Bianchi;Gábor Lugosi;Gilles Stoltz	2005	IEEE Transactions on Information Theory	10.1109/TIT.2005.847729	game theory;information processing;computer science;artificial intelligence;machine learning;economic forecasting;mathematics;predictive modelling;expert system;algorithm;statistics	Theory	20.238789311701346	-30.61885056707053	195974
9ec8763f5c42a81418825306999a514bc7fe2ad1	basis function models of the cmac network	core storage;grnn;memory based networks;etude theorique;corteza cerebelar;circuito memoria;storage structure;simulation;memoria central;simulacion;cmac;rbf;memoire centrale;fonction articulaire;basicity function;circuit memoire;gmnn;estudio teorico;functional model;cerebellar cortex;estructura memoria;basic functions;structure memoire;funcion articular;fonction basicite;theoretical study;reseau neuronal;funcion basicidad;red neuronal;articular function;cerebellar model articulation controller;cortex cerebelleux;memory circuit;neural network;numerical simulation	An interpretation of the Cerebellar Model Articulation Controller (CMAC) network as a member of the General Memory Neural Network (GMNN) architecture is presented. The usefulness of this approach stems from the fact that, within the GMNN formalism, CMAC can be treated as a particular form of a basis function network, where the basis function is inherently dependent on the type of input quantization present in the network mapping. Furthermore, considering the relative regularity of input-space quantization performed by CMAC, we are able to derive an expected (or average) form of the basis function characteristic of this network. Using this basis form, it is possible to create basis-functions models of CMAC mapping, as well as to gain more insight into its performance. The developments are supported by numerical simulations.	approximation algorithm;artificial neural network;b-spline;basis function;benchmark (computing);biconnected component;cerebellar model articulation controller;collision (computer science);computer simulation;estimated;formal system;function model;memory disorders;network mapping;network planning and design;numerical analysis;one-key mac;quantization (signal processing);smoothing (statistical technique);test set;time series;turing completeness	Aleksander Kolcz;Nigel M. Allinson	1999	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(98)00113-0	computer simulation;computer science;function model;artificial intelligence;cmac;artificial neural network;algorithm	ML	18.888809638339012	-27.49494155844885	195985
ff7f269c8054a2b96d4574b14bdadd45d133e19a	dual extended kalman filtering in recurrent neural networks	metodo cuadrado menor;recursive least square;kalman filtering;eficacia sistema;methode moindre carre;filtrage kalman;least squares method;fonction poids;forme onde;complexite calcul;estimation etat;modelo determinista;algoritmo recursivo;simulacion numerica;performance systeme;calcul erreur;matrice covariance;kalman filter;matriz covariancia;modele deterministe;state estimation;system performance;experimental result;error analysis;complejidad computacion;forma onda;algorithme recursif;computational complexity;simulation numerique;estimacion parametro;funcion peso;resultado experimental;calculo error;recursive algorithm;reseau neuronal recurrent;waveform;recurrent neural networks;recurrent neural network;stochastic model;weight function;parameter estimation;estimation parametre;resultat experimental;extended kalman filter;deterministic model;estimacion estado;modelo estocastico;filtrado kalman;modele stochastique;covariance matrix;numerical simulation	In the classical deterministic Elman model, the estimation of parameters must be very accurate. Otherwise, the system performance is very poor. To improve the system performance, we can use a Kalman filtering algorithm to guide the operation of a trained recurrent neural network (RNN). In this case, during training, we need to estimate the state of hidden layer, as well as the weights of the RNN. This paper discusses how to use the dual extended Kalman filtering (DEKF) for this dual estimation and how to use our proposing DEKF for removing some unimportant weights from a trained RNN. In our approach, one Kalman algorithm is used for estimating the state of the hidden layer, and one recursive least square (RLS) algorithm is used for estimating the weights. After training, we use the error covariance matrix of the RLS algorithm to remove unimportant weights. Simulation showed that our approach is an effective joint-learning-pruning method for RNNs under the online operation.	biological neural networks;dual;estimated;least-squares analysis;neural network simulation;restless legs syndrome;weight;algorithm	Chi Sing Leung;Lai-Wan Chan	2003	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(02)00230-7	computer simulation;kalman filter;econometrics;computer science;artificial intelligence;recurrent neural network;machine learning;mathematics;computer performance;statistics	ML	19.419037371727235	-26.137111265362524	196474
3a9cfe063d28a8a325387553cfc736f0d576c015	on learning mean values in hopfield associative memories trained with noisy examples using the hebb rule	unsupervised learning;hebbian learning;neurons associative memory hopfield neural networks neural networks unsupervised learning nonlinear dynamical systems statistical distributions computer networks hebbian theory data mining;neural networks;hebbian theory;nonlinear dynamical systems;hopfield neural nets content addressable storage hebbian learning unsupervised learning;learning mean values;hopfield neural nets;data mining;classification;computer networks;hebb rule;statistical distributions;hopfield associative memories;hopfield neural networks;clustering;probability theory;associative memory;probability theory hopfield associative memories learning mean values hebb rule;neurons;content addressable storage;neural network	We study, using standard Probability Theory results, the ability of the Hopfield model of associative memory using the Hebb rule to learn mean values from examples in the presence of noise. We state and prove properties concerning this ability.	hebbian theory;hopfield network	Bruno Cernuschi-Frías;Enrique Carlos Segura	2000		10.1109/IJCNN.2000.860740	hebbian theory;computer science;artificial intelligence;machine learning;pattern recognition;bidirectional associative memory;hopfield network;artificial neural network	ML	18.47964433068489	-27.777364403997694	197908
c6ae059bfc2bb843f8f9ad338149808e3cf9b17e	the generation of animated motion by means of a recurrent neural network	learning algorithm;movimiento;algorithme apprentissage;motion;architecture reseau;arm movement;objective function;mouvement;network architecture;recurrent neural network;reseau neuronal;red neuronal;neural network	The possibility to use neural networks to guide animated motion sequences is investigated. The performance of two recurrent architectures, both derived from the cascade-correlation network, is compared. These architectures only differ in the objective function used to train the hidden units. Small differences in performance were observed, but both networks could successfully produce simple motion sequences. An animation environment was created to display arm movement and walking sequences.	artificial neural network;loss function;optimization problem;recurrent neural network	Marijke F. Augusteijn;Joseph M. Hill	1995	Neural Computing & Applications	10.1007/BF01414173	computer vision;simulation;network architecture;computer science;artificial intelligence;recurrent neural network;motion;machine learning;time delay neural network;echo state network;artificial neural network	ML	18.442789583642465	-24.361764469092442	197936
753ac88f46fe056db5b6a7d37014f95160873f42	diagnostic classifiers revealing how neural networks process hierarchical structure		We investigate how neural networks can be used for hierarchical, compositional semantics. To this end, we define the simple but nontrivial artificial task of processing nested arithmetic expressions and study whether different types of neural networks can learn to add and subtract. We find that recursive neural networks can implement a generalising solution, and we visualise the intermediate steps: projection, summation and squashing. We also show that gated recurrent neural networks, which process the expressions incrementally, perform surprisingly well on this task: they learn to predict the outcome of the arithmetic expressions with reasonable accuracy, although performance deteriorates with increasing length. To analyse what strategy the recurrent network applies, visualisation techniques are less insightful. Therefore, we develop an approach where we formulate and test hypotheses on what strategies these networks might be following. For each hypothesis, we derive predictions about features of the hidden state representations at each time step, and train ’diagnostic classifiers’ to test those predictions. Our results indicate the networks follow a strategy similar to our hypothesised ’incremental strategy’.	neural networks;recurrent neural network;recursion;recursive neural network	Sara Veldhoen;Dieuwke Hupkes;Willem H. Zuidema	2016			computer science;machine learning;artificial neural network;artificial intelligence;pattern recognition	ML	17.59252014991665	-29.724597513304264	198142
f008a41700a6303a819123645a31998c7e5d30a0	kernel function and parameters optimization in kica for rolling bearing fault diagnosis	kica;kernel parameters;kernel function;rolling bearing;fault diagnosis	Kernel independent component analysis (KICA) is a blind signal separation method which has a good effect for the treatment of non-linear signal. For introducing kernel techniques, the choices of kernel function and its kernel parameter have a great influence on the analytic results. A kernel function and its parameters optimization method is proposed on the basis of the similarity of source fault signals and kernel independent component. The similarity parameter is proposed to verify the merits or defects of KICA by using different kernel function and parameters. The simulation studies are processed, and the simulation conclusion is verified by the actual diagnostic case. These provide guidance for the application of the KICA method in the mechanical fault diagnosis.	blind signal separation;feature extraction;independent component analysis;kernel (operating system);mathematical optimization;nonlinear system;programmer;simulation	Lingli Jiang;Bo Zeng;Francis R. Jordan;Anhua Chen	2013	JNW	10.4304/jnw.8.8.1913-1919	kernel;kernel method;mathematical optimization;radial basis function kernel;kernel principal component analysis;computer science;machine learning;variable kernel density estimation;polynomial kernel;statistics;kernel smoother	ML	23.383779919087203	-24.16333037634478	198411
89f599f59c7c0de6610cec8a0aaf18ef63e47bf8	flexible prior distributions for deep generative models		We consider the problem of training generative models with deep neural networks as generators, i.e. to map latent codes to data points. Whereas the dominant paradigm combines simple priors over codes with complex deterministic models, we argue that it might be advantageous to use more flexible code distributions. We demonstrate how these distributions can be induced directly from the data. The benefits include: more powerful generative models, better modeling of latent structure and explicit control of the degree of generalization.	artificial neural network;code;data point;deep learning;generative model;programming paradigm	Yannic Kilcher;Aurélien Lucchi;Thomas Hofmann	2017	CoRR		machine learning;generative grammar;prior probability;data point;artificial neural network;generative model;generative topographic map;pattern recognition;artificial intelligence;computer science	ML	24.209885776011564	-30.64402674733148	198845
c77cdc421fbc6b61c2c08f547dd437fa5a63a21f	a volatility measure for annealing in feedback neural networks	spin glass;simulated annealing;specific heat;mean field;edwards anderson;neural network	In feedback neural networks, especially for static pattern learning, a reliable method of settling is required. Simulated annealing has been used but it is often difficult to determine how to set the annealing schedule. Often the specific heat is used as a measure of when to slow down the annealing process, but this is difficult to measure. We propose another measure, volatility, which is easy to measure and related to the Edwards-Anderson model in spin-glass physics. This paper presents the concept of volatility, an argument for its similarity to specific heat, simulations of dynamics in Boltzmann and mean-field networks, and a method of using it to speed up learning.	feedback;glass;neural networks;simulated annealing;simulation;volatility	Joshua Alspector;Torsten Zeppenfeld;Stephan Luna	1992	Neural Computation	10.1162/neco.1992.4.2.191	simulation;heat capacity;simulated annealing;spin glass;computer science;artificial intelligence;mean field theory;machine learning;adaptive simulated annealing;artificial neural network	ML	19.917271567195193	-26.45292618479627	199350
