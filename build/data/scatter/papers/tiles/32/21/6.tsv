id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
e6cc66f8d907b1975ddd4fb122f03407e6eb3fc9	a new moments based skew estimation technique using pixels in the word for binary document images	document analysis;boundary growing;optical character recognition;moments;words extraction skew estimation technique binary document images document analysis system optical character recognition;comparative study;skew detection;document image processing;pixel optical character recognition software character recognition optical devices educational institutions computer science text analysis performance analysis robustness computational efficiency;character sets document image processing optical character recognition word processing text editing;connected component;computational efficiency;character sets;optical character recognition connected component boundary growing moments skew detection;word processing;text editing	Accurate skew angle estimation is an essential component in document analysis system to enhance the performance of the optical character recognition (OCR). In this paper, a new and efficient moments based method to estimate skew angle of a pixels in the word in the scanned document image is proposed. The proposed technique has two stages. In the first stage, using boundary-growing method, pixels in the words of skewed text are extracted. The pixels in the words extracted are given as input to moments based method. It results in a skew angle in the second stage. Extensive experiments have been conducted on various types of documents such as documents containing different languages and different fonts to reveal the robustness of the proposed method. Comparative studies with the well-known methods are presented to show that the proposed method is superior in terms of accuracy and computational efficiency.	computation;experiment;optical character recognition;pixel;whole earth 'lectronic link	Palaiahnakote Shivakumara;G. Hemantha Kumar;H. S. Varsha;S. Rekha;M. R. Rashmi Nayaka	2005	Eighth International Conference on Document Analysis and Recognition (ICDAR'05)	10.1109/ICDAR.2005.24	computer vision;speech recognition;connected component;character encoding;computer science;comparative research;pattern recognition;moment;optical character recognition	Robotics	36.613514476185046	-65.99396008709964	153850
f9875874fdafa4b7c3428e94aa314aeeb7d50018	new tampered features for scene and caption text classification in video frame	linearity;image color analysis;discrete cosine transforms;mathematical model;text recognition;bars;character recognition	The presence of both caption/graphics/superimposed and scene texts in video frames is the major cause for the poor accuracy of text recognition methods. This paper proposes an approach for identifying tampered information by analyzing the spatial distribution of DCT coefficients in a new way for classifying caption and scene text. Since caption text is edited/superimposed, which results in artificially created texts comparing to scene texts that exist naturally in frames. We exploit this fact to identify the presence of caption and scene texts in video frames based on the advantage of DCT coefficients. The proposed method analyzes the distributions of both zero and non-zero coefficients (only positive values) locally by moving a window, and studies histogram operations over each input text line image. This generates line graphs for respective zero and non-zero coefficient coordinates. We further study the behavior of text lines, namely, linearity and smoothness based on centroid location analysis, and the principal axis direction of each text line for classification. Experimental results on standard datasets, namely, ICDAR 2013 video, 2015 video, YVT video and our own data, show that the performances of text recognition methods are improved significantly after-classification compared to before-classification.	apache axis;binary image;coefficient;crystal structure;deep learning;discrete cosine transform;document classification;experiment;framing (world wide web);graphics;international conference on document analysis and recognition;iterative method;line graph;line level;optic axis of a crystal;optical character recognition;performance	Sangheeta Roy;Palaiahnakote Shivakumara;Umapada Pal;Tong Lu;Chew Lim Tan	2016	2016 15th International Conference on Frontiers in Handwriting Recognition (ICFHR)	10.1109/ICFHR.2016.0020	computer vision;speech recognition;computer science;machine learning;pattern recognition;mathematical model;linearity;statistics	Vision	37.33943576792596	-64.18567967530295	154035
26422f7e84233bae1fffa567e001cecc058a886e	fuzzy graph modeling for text segmentation from land map images	fuzzy graph;similarity relation;political land map	Map image text segmentation has always been one of the difficult tasks because of its variety. The texts in a map may have the myriad background consists of various intensity values, different orientations, overlapping objects, intersected lines etc. Common problems for text extraction from map images are the lack of prior knowledge of text features such as color, font, size and orientation as well as the location of the probable text regions. Extracted texts can be used as an input to OCR for recognition. This paper presents an approach for text segmentation from map images using fuzzy graph analysis. Fuzzy graph is constructed from the map image. Fuzzy similarity value between two nodes within text region will be higher than other non-text regions. Seed points are selected through the fuzzy graph analysis. These seed points lie within texts in a map image. F* seed growing algorithm is used here for text localization.  The originality of this work lies in the fuzzy graph construction from map image and selection of seed points. The proposed text segmentation approach is tested on a collected dataset of paper map images (containing texts in Indian languages; like Bangla, Hindi etc.) and the results are encouraging.	algorithm;optical character recognition;text segmentation	Samit Biswas;Amit Kumar Das	2012		10.1145/2425333.2425408	computer vision;machine learning;pattern recognition;mathematics;map coloring	Vision	35.54328330529053	-65.78766682816405	154617
213fb3f0a8e515c703c2e24ec4a3d19cf442b9e7	on-line recognition of handwritten characters - alphanumerics, hiragana, katakana, kanji	bayesian decision rule;japanese characters;fourier coefficients;alphanumerics;on-line recognition	An on-line recognition system for handwritten characters is proposed. Fourier coefficients of pen-point movement loci relating to strokes are utilized as feature vectors of handwritten characters. A method based on a Bayesian decision rule tested with an experimental simulator. It is revealed that the method is effective for cursive handwritten characters, such as alphanumerics and Japanese characters.		Hiroki Arakawa	1983	Pattern Recognition	10.1016/0031-3203(83)90003-1	arithmetic;speech recognition;computer science;pattern recognition	Vision	32.51219644352708	-65.03523897787932	154931
eb09fc9f63eb01190dd17a4ae1e2b80258a67a68	medical content based image retrieval by using the hadoop framework	visual databases content based retrieval gaussian processes hilbert transforms image retrieval mammography medical image processing;medical image databases medical content based image retrieval hadoop framework medical images content based image retrieval system mapreduce distributed computing model hdfs storage model bemd ggd method bidimensional empirical mode decomposition generalized gaussian density functions bemd hht method bidi mensional empirical mode decomposition huang hilbert transform kullback leibler divergence euclidean distance ddsm mammography image database;biomedical imaging;feature extraction image retrieval computational modeling biomedical imaging vectors;computational modeling;vectors;feature extraction;image retrieval	Most medical images are now digitized and stored in large image databases. Retrieving the desired images becomes a challenge. In this paper, we address the challenge of content based image retrieval system by applying the MapReduce distributed computing model and the HDFS storage model. Two methods are used to characterize the content of images: the first is called the BEMD-GGD method (Bidimensional Empirical Mode Decomposition with Generalized Gaussian density functions) and the second is called the BEMD-HHT method (Bidi-mensional Empirical Mode Decomposition with Huang-Hilbert Transform HHT). To measure similarity between images we compute the distance between signatures of images, for that we use the Kullback-Leibler Divergence (KLD) to compare the BEMD-GGD signatures and the Euclidean distance to compare the HHT signatures. Through the experiments on the DDSM mammography image database, we confirm that the results are promising and this work has allowed us to verify the feasibility and efficiency of applying the CBIR in the large medical image databases.	antivirus software;apache hbase;apache hadoop;column-oriented dbms;content-based image retrieval;database;distributed computing environment;euclidean distance;experiment;file archiver;hilbert transform;hilbert–huang transform;kullback–leibler divergence;mapreduce;numerical analysis;physics and astronomy classification scheme;picture archiving and communication system;storage model;type signature	Said Jai-Andaloussi;Abdeljalil Elabdouli;Abdelmajid Chaffai;Nabil Madrane;Abderrahim Sekkaki	2013	ICT 2013	10.1109/ICTEL.2013.6632112	computer vision;visual word;feature extraction;image retrieval;computer science;data mining;computational model;automatic image annotation;information retrieval	Vision	38.37479362887057	-61.68756374085239	154995
171e3ba400eba136f6c6001e59446cd886d378ec	core points - a framework for structural parameterization	core points structural parameterization character recognition standard arclength parameterization handwritten sample knn template matching singular value decomposition;image segmentation;image matching;singular value decomposition;hidden markov models character recognition shape neural networks inspection singular value decomposition encoding handwriting recognition text analysis humans;image matching handwritten character recognition image segmentation singular value decomposition;visual inspection;linear transformation;matematik;template matching;character recognition;handwritten character recognition	Most implementations of single character recognition use standard arclength parameterization of the handwritten samples. A problem with the arclength approach is that points on curves of different samples from one character class may then actually correspond to parts of different structural significance. Many methods such as DTW and HMM have been successful partly because they are less sensitive to parameterizational differences. Given a sufficiently fine decomposition of a character sample into smaller segments, the complex non-linear variations of handwritten data can be viewed as a set of local linear transformations of the segments. In this paper we present a parameterization technique that implicitly defines such a structural decomposition. Experiments reveal that recognition rates for kNN template matching increase for reparameterized samples thus proving that the new parameterization removes redundance in a way that is genuinely beneficial for discrimination purposes. In addition to these quantitative results, visual inspection of the modes of singular value decomposition of reparameterized samples show that the new parameterization reduces the impact of parameterizational differences in shape variations of character samples.	hidden markov model;k-nearest neighbors algorithm;nonlinear system;optical character recognition;semantic parameterization;singular value decomposition;template matching;visual inspection	Jakob Sternby;Anders Ericsson	2005	Eighth International Conference on Document Analysis and Recognition (ICDAR'05)	10.1109/ICDAR.2005.81	computer vision;speech recognition;template matching;computer science;pattern recognition;linear map;image segmentation;singular value decomposition;visual inspection	Vision	34.01868940829033	-63.73893236339688	155008
b6d3c9735c59e802a67ee94132b569bdc983b827	an mlp using hough transform based fuzzy feature extraction for bengali script recognition	fuzzy set;multilayer perceptron;fuzzy sets;bengali script recognition;feature extraction;hough transform	We define fuzzy sets on the Hough transform of character pattern pixels from which additional fuzzy sets are synthesized using t-norms. A multilayer perceptron trained with a number of linguistic set memberships derived from these t-norms can recognize characters of Bengali scripts by their similarities to different fuzzy pattern classes.	feature extraction;fuzzy set;hough transform;multilayer perceptron;pixel;quad flat no-leads package;t-norm	Shamik Sural;P. K. Das	1999	Pattern Recognition Letters	10.1016/S0167-8655(99)00041-0	speech recognition;computer science;machine learning;pattern recognition;mathematics;fuzzy set	Vision	32.68948897210803	-65.46028591877305	155365
0bfd5eaa7f6af4166335678856dc2993c658e05d	an improved feature descriptor for recognition of handwritten bangla alphabet		Appropriate feature set for representation of pattern classes is one of the most important aspects of handwritten character recognition. The effectiveness of features depends on the discriminating power of the features chosen to represent patterns of different classes. However, discriminatory features are not easily measurable. Investigative experimentation is necessary for identifying discriminatory features. In the present work we have identified a new variation of feature set which significantly outperforms on handwritten Bangla alphabet from the previously used feature set. 132 number of features in all viz. modified shadow features, octant and centroid features, distance based features, quad tree based longest run features are used here. Using this feature set the recognition performance increases sharply from the 75.05% observed in our previous work [7], to 85.40% on 50 character classes with MLP based classifier on the same dataset.	experiment;feature model;handwriting recognition;memory-level parallelism;optical character recognition;quadtree;viz: the computer game	Nibaran Das;Subhadip Basu;Ram Sarkar;Mahantapas Kundu;Mita Nasipuri;Dipak Kumar Basu	2009	CoRR		speech recognition;feature;machine learning;pattern recognition;mathematics;feature	Vision	36.37752623322024	-59.75810273203962	155544
e4590ac027bc721683f6558a624fc3f78afea814	banknote recognition based on optimization of discriminative regions by genetic algorithm with one-dimensional visible-light line sensor		Banknote recognition is an important task in many automatic payment facilities and counting machines. The most popular approach is based on image processing methods in which banknote images are captured by visible light sensors and are classified by denominations and input orientations. There are regions on a banknote image that yield better recognition accuracy than the other areas. There have been few studies on optimal discriminative regions on a banknote image; therefore, we proposed a banknote recognition method to select the discriminative regions on the banknote image captured by a one-dimensional visible light sensor. The proposed method uses genetic algorithm to optimize the similarity mapping result for different classes of banknotes. Experimental results with banknote databases from various countries show that our proposed method results in better accuracies than previous methods with the average recognition accuracies of higher than 99% and small variance among five trials in each type of currency.	database;genetic algorithm;image processing;mathematical optimization;sensor	Tuyen Danh Pham;Ki-Wan Kim;Jeonggoo Kang;Kang Ryoung Park	2017	Pattern Recognition	10.1016/j.patcog.2017.06.027	genetic algorithm;banknote;discriminative model;visible spectrum;pattern recognition;image processing;artificial intelligence;computer vision;mathematics;payment	Vision	33.07607163069756	-60.664840246656475	155952
97b46fbfa7def763f71de05b869c303b902c02ef	face recognition scheme based on hsi-pcnn	hsi pcnn;ann;face recognition;pulse ignition rate sequence	By converting color face image into HSI color space from RGB color space, getting face image templates of H, S, I three channels, using HSI-PCNN algorithm extracts facial feature sequence of three channels, the feature sequence can be used for face recognition. Through experimental comparison, this method can distinguish facial features well and has Strong robustness. Compared to the original PCNN method as well as the others face recognition methods, the detection process of HSI-PCNN face recognition method is simple and the recognition rate is very high.At the same time, this method is easy to implement in embedded DSP system. This paper realizes face recognition using the method of HSI-PCNN which retains the color information of face skin, the innovation of this paper is to study the method of innovation.	algorithm;color space;digital signal processor;embedded system;facial recognition system;horizontal situation indicator;pulse-coupled networks	Xi Li;Hong Zheng;Cao Liu	2013	Journal of Multimedia	10.4304/jmm.8.5.573-579	facial recognition system;computer vision;speech recognition;computer science;pattern recognition;three-dimensional face recognition;face hallucination	Vision	32.83710794351185	-59.82252031411826	155959
cb6d3d5759405735c728e637647304cf657e3abf	consensus-based clustering for document image segmentation	document analysis;stroke width;segmentation;clustering;hypothesis testing	Segmentation of a document image plays an important role in automatic document processing. In this paper, we propose a consensus-based clustering approach for document image segmentation. In this method, the foreground regions of a document image are grouped into a set of primitive blocks, and a set of features is extracted from them. Similarities among the blocks are computed on each feature using a hypothesis test-based similarity measure. Based on the consensus of these similarities, clustering is performed on the primitive blocks. This clustering approach is used iteratively with a classifier to label each primitive block. Experimental results show the effectiveness of the proposed method. It is further shown in the experimental results that the dependency of classification performance on the training data is significantly reduced.	cluster analysis;document processing;image segmentation;similarity measure	Soumyadeep Dey;Jayanta Mukherjee;Shamik Sural	2016	International Journal on Document Analysis and Recognition (IJDAR)	10.1007/s10032-016-0275-1	correlation clustering;statistical hypothesis testing;document clustering;fuzzy clustering;computer science;machine learning;segmentation-based object categorization;consensus clustering;pattern recognition;data mining;cluster analysis;single-linkage clustering;scale-space segmentation;segmentation	Vision	36.685170577499306	-64.8950929289583	156300
2b66c7bd6585cd673017909acde90a991a6789e8	stable text line detection	knowledge free method;machine printed documents;handwriting recognition;document analysis;image segmentation;handwritten images;pixel image segmentation text analysis piecewise linear approximation cost function robustness testing image analysis character recognition shape;freestyle handwritten documents;text line segmentation;text analysis;curvilinear text lines;icdar 2009 handwriting segmentation competition;line detection;text analysis document image processing handwriting recognition image segmentation;artigo em livro de atas de conferencia internacional;hand printed documents;open document analysis problem;logic gates;automatic detection;icdar 2009 handwriting segmentation competition text line detection text line segmentation freestyle handwritten documents open document analysis problem curvilinear text lines machine printed documents hand printed documents knowledge free method automatic detection handwritten images;text line detection;pixel;document image processing;robustness;pattern analysis;region 1	Text line segmentation in freestyle handwritten documents remains an open document analysis problem. Curvilinear text lines and small gaps between neighbouring text lines present a challenge to algorithms developed for machine-printed or hand-printed documents. We investigate a general-purpose, knowledge-free method for the automatic detection of text lines based on a stable path approach. Lines affected by curvature and inclination are robustly detected. The proposed methodology was tested on a modern set of handwritten images made available on the ICDAR 2009 handwriting segmentation competition, with promissing results.	advanced chess;algorithm;edge detection;general-purpose modeling;historical document;international conference on document analysis and recognition;printing;robustness (computer science);video post-processing;weight function	Jaime S. Cardoso	2009	2009 Workshop on Applications of Computer Vision (WACV)	10.1109/WACV.2009.5403119	computer vision;speech recognition;logic gate;computer science;machine learning;pattern recognition;handwriting recognition;image segmentation;pixel;robustness	Vision	36.76076840934644	-66.12930060499012	156641
439af10ac2da193ddb7aa767f1dc56f7e09d62e6	robust color image retrieval for the www	digital signature;color image;image retrieval	The rapid growth of image archives increases the need for efficient and fast tools that can retrieve and search through large amount of visual data. In this paper an efficient method of extracting the image color content is proposed, which can serve as an image digital signature, allowing to efficiently index and retrieve large multimedia Internet based databases. The proposed method was applied using the images from the WEBMUSEUM Internet database containing the collection of images of fine arts. The results show that the new method of image color representation is robust to image resizing and compression and can be incorporated into existing web-based image retrieval systems.	archive;color image;color space;database;digital signature;experiment;image compression;image retrieval;image scaling;internet;thumbnail;www;web application	Bogdan Smolka	2004			visual word;digital image processing;image processing;binary image;automatic image annotation;information retrieval;image retrieval;computer vision;artificial intelligence;color image;image texture;computer science	Vision	39.118415184973614	-61.10339745558154	156804
6f2b4d77ce9afd37e5dcaea08bfadc56f9777e9e	face liveness detection with feature discrimination between sharpness and blurriness		Face recognition has been extensively used in a wide variety of security systems for identity authentication for years. However, many security systems are vulnerable to spoofing face attacks (e.g., 2D printed photo, replayed video). Consequently, a number of anti-spoofing approaches have been proposed. In this study, we introduce a new algorithm that addresses the face liveness detection based on the digital focus technique. The proposed algorithm relies on the property of digital focus with various depths of field (DOFs) while shooting. Two features of the blurriness level and the gradient magnitude threshold are computed on the nose and the cheek subimages. The differences of these two features between the nose and the cheek in real face images and spoofing face images are used to facilitate detection. A total of 75 subjects with both real and spoofing face images were used to evaluate the proposed framework. Preliminary experimental results indicated that this new face liveness detection system achieved a high recognition rate of 94.67% and outperformed many state-of-the-art methods. The computation speed of the proposed algorithm was the fastest among the tested methods.	algorithm;authentication;biometrics;computation;experiment;facial recognition system;fastest;gradient;liveness;printing;spoofing attack	Chun-Hsiao Yeh;Herng-Hua Chang	2017	2017 Fifteenth IAPR International Conference on Machine Vision Applications (MVA)	10.23919/MVA.2017.7986885	mathematics;face detection;artificial intelligence;computer vision;pattern recognition;facial recognition system;object-class detection;three-dimensional face recognition;magnitude (mathematics);spoofing attack;liveness;authentication	Vision	32.051827860822605	-61.79169265643998	157699
c0185180f2faac91ab4080ee5e69cfae228842f8	fractal dimension of maximum response filters applied to texture analysis	maximum response filters;fractal dimension;texture analysis	Texture provides fundamental features for several applications in computer vision and it is known to be an important cue for human vision. To improve the description of texture in different viewpoints (e.g., scale and orientation), we propose to extract fractal descriptors from invariant filter responses space. Experimental results on four well-known texture datasets show the effectiveness of the proposed method. In the experiments, our method has provided better results than relevant texture methods, including the standard fractal descriptors. In addition, experimental results have shown the robustness of our method in a dataset with high noise.	computer performance;computer vision;experiment;feature vector;filter bank;fractal dimension;image resolution	Lucas Correia Ribas;Diogo Nunes Gonçalves;Jonatan Patrick Margarido Oruê;Wesley Nunes Gonçalves	2015	Pattern Recognition Letters	10.1016/j.patrec.2015.07.030	image texture;computer vision;fractal analysis;machine learning;pattern recognition;mathematics;fractal dimension;texture compression;texture filtering	Vision	37.80291581369546	-59.600027812246175	157969
62597a6f62652ac29a1f72f03bdfc9fea7ac0eed	partitioned iterated function systems with division and a fractal dependence graph in recognition of 2d shapes	rozpoznawanie ksztaltu;dependence graph;shape recognition;graf zalezności;uklad funkcji iteracyjnej;fraktale;fractal;partitioned iterated function system	One of the approaches in pattern recognition is the use of fractal geometry. The property of self-similarity of fractals has been used as a feature in several pattern recognition methods. All fractal recognition methods use global analysis of the shape. In this paper we present some drawbacks of these methods and propose fractal local analysis using partitioned iterated function systems with division. Moreover, we introduce a new fractal recognition method based on a dependence graph obtained from the partitioned iterated function system. The proposed method uses local analysis of the shape, which improves the recognition rate. The effectiveness of our method is shown on two test databases. The first one was created by the authors and the second one is the MPEG7 CE-Shape-1PartB database. The obtained results show that the proposed methodology has led to a significant improvement in the recognition rate.	align (company);database;fastest;fractal;fractal compression;graphics hardware;image compression;iterated function system;iteration;mpeg-7;pattern recognition;self-similarity;similarity measure;the times;word lists by frequency	Krzysztof Gdawiec;Diana Domanska	2011	Applied Mathematics and Computer Science	10.2478/v10006-011-0060-8	combinatorics;discrete mathematics;fractal;fractal analysis;fractal landscape;mathematics;geometry;fractal compression	Vision	38.2416333705302	-64.00506716906487	158133
71b920f46d794fbdbb4736a08304065bea2b8508	document image segmentation using deep features		This paper explores the effectiveness of deep features for document image segmentation. The document image segmentation problem is modelled as a pixel labeling task where each pixel in the document image is classified into one of the predefined labels such as text, comments, decorations and background. Our method first extracts deep features from superpixels of the document image. Then we learn an svm classifier using these features, and segment the document image. Fisher vector encoded convolutional layer features (fv-cnn) and fully connected layer features (fc-cnn) are used in our study. Experiments validate that our method is effective and yields better results for segmenting document images in comparison to the popular approaches on benchmark handwritten datasets.	image segmentation	K. V. Jobin;C. V. Jawahar	2017		10.1007/978-981-13-0020-2_33	market segmentation;support vector machine;computer vision;image segmentation;artificial intelligence;pixel;pattern recognition;computer science	Vision	36.35479035595098	-64.75268643141396	158606
6a8348d45c6fd10c9c6200d8f07f5239e47417a8	fingerprint retrieval by complex filter responses	fingerprint recognition filters authentication information retrieval humans biometrics nist spatial databases forensics costs;image matching;image classification;feature vector;fingerprint retrieval;feature extraction;fingerprint local singularity fingerprint retrieval complex filter response feature vector;fingerprint local singularity;complex filter response;image retrieval feature extraction fingerprint identification image classification image matching;fingerprint identification;singular point;image retrieval	This paper proposes an approach of fingerprint retrieval based on the continuous classification of two complex filter responses. Two complex filters are introduced and applied on the fingerprint orientation field to extract the local singularities, the similarities to the singular points. A numerical feature vector from the aligned fingerprint local singularities is constructed as the global feature for fingerprint retrieval. The continuous classification is employed to retrieve a subset of fingerprints similar to the query fingerprint for the finer matching. Experimental results on NIST fingerprint database 4 (NIST-4) shows the effectiveness of the proposed fingerprint retrieval approach	feature vector;fingerprint;numerical analysis	Manhua Liu;Xudong Jiang;Alex ChiChung Kot	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.577	fingerprint;computer vision;singular point of a curve;contextual image classification;feature vector;feature extraction;image retrieval;computer science;machine learning;pattern recognition;information retrieval;fingerprint recognition	Vision	35.34595142781131	-61.30913453577888	159577
e67b3e09b8966ca4257e0e7eaf70dd10d692f2e2	embedding document structure to bag-of-words through pair-wise stable key-regions	pyramidal bow methods embedding document structure pairwise stable key regions layout analysis approaches distance transform based mser dtmser dendrogram structural elements characters words paragraphs bag of words framework structural document matching histogram document image retrieval typical bow methods;image retrieval document image processing image matching;feature extraction vectors histograms transforms indexing layout algorithm design and analysis	Since the document structure carries valuable discriminative information, plenty of efforts have been made for extracting and understanding document structure among which layout analysis approaches are the most commonly used. In this paper, Distance Transform based MSER (DTMSER) is employed to efficiently extract the document structure as a dendrogram of key-regions which roughly correspond to structural elements such as characters, words and paragraphs. Inspired by the Bag of Words (BoW) framework, we propose an efficient method for structural document matching by representing the document image as a histogram of key-region pairs encoding structural relationships. Applied to the scenario of document image retrieval, experimental results demonstrate a remarkable improvement when comparing the proposed method with typical BoW and pyramidal BoW methods.	bag-of-words model in computer vision;cluster analysis;codebook;computation;dendrogram;distance transform;goto;image retrieval;inverted index;maximally stable extremal regions;visual descriptor	Hongxing Gao;Marçal Rusiñol;Dimosthenis Karatzas;Josep Lladós	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.500	speech recognition;document clustering;computer science;document layout analysis;pattern recognition;information retrieval	Vision	36.9724291335359	-63.880437539383614	160146
0945e8f301cb5740b3efb233966ce9b989a63ca7	a novel feature extraction and classification methodology for the recognition of historical documents	databases;document handling;handwriting recognition;subpixel accuracy;support vector machines;optical character recognition;computational intelligence;granularity feature;training;optical character recognition feature extraction classification methodology historical document recognition subpixel accuracy confusion matrix granularity feature;text analysis;matrix algebra;feature extraction character recognition optical character recognition software support vector machines support vector machine classification text analysis computational intelligence laboratories informatics document handling;historical document recognition;optical character recognition software;hierarchical classification;pattern classification document image processing feature extraction handwritten character recognition matrix algebra optical character recognition;feature extraction;confusion matrix;pattern classification;document image processing;support vector machine classification;informatics;historical documents;centre of mass;character recognition;classification methodology;handwritten character recognition;historical documents feature extraction	In this paper, we present a methodology for off-line character recognition that mainly focuses on handling the difficult cases of historical fonts and styles. The proposed methodology relies on a new feature extraction technique based on recursive subdivisions of the image as well as on calculation of the centre of masses of each sub-image with sub-pixel accuracy. Feature extraction is followed by a hierarchical classification scheme based on the level of granularity of the feature extraction method. Pairs of classes with high values in the confusion matrix are merged at a certain level and higher level granularity features are employed for distinguishing them. Several historical documents were used in order to demonstrate the efficiency of the proposed technique.	comparison and contrast of classification schemes in linguistics and metadata;confusion matrix;feature extraction;historical document;online and offline;optical character recognition;pixel;recursion	Georgios Vamvakas;Basilios Gatos;Stavros J. Perantonis	2009	2009 10th International Conference on Document Analysis and Recognition	10.1109/ICDAR.2009.223	center of mass;support vector machine;computer vision;speech recognition;confusion matrix;feature extraction;computer science;machine learning;computational intelligence;pattern recognition;handwriting recognition;optical character recognition;informatics;feature	EDA	33.60242649249907	-65.46489639400475	161223
b1e7db9b46aaa0756926d88c68ec78512758aad6	a hybrid pso and svm algorithm for content based image retrieval		In order to improve the speed and accuracy of image retrieval, This paper presents a hybrid optimization algorithm which originates from Particle Swarm Optimization (PSO) and SVM (Support Vector Machine). Firstly, it use PSO algorithm, The image in the database image as a particle in PSO algorithm, After operation, return to the optimum position of the image. Secondly, use SVM to feedback the related images, Use the classification distance and nearest neighbor density to measure the most valuable image, After update classifier, choose the furthest point from the classification hyperplane as target image. Finally, the proposed method is verified by experiment, the experimental results show that this algorithm can effectively improve the image retrieval speed and accuracy.	algorithm;content-based image retrieval;phase-shift oscillator	Xinjian Wang;Guangchun Luo;Ke Qin;Aiguo Chen	2016		10.1007/978-3-319-42085-1_48	pattern recognition	Vision	37.90796208444472	-62.30487037737308	161268
a97d581cf441bac7c307d57fd00b7d9397459a95	3d-aided profile-based face recognition	databases;3d;feature space;face recognition;three dimensional displays;feature extraction;profile based face recognition;solid modeling;face recognition biometrics shape euclidean distance cameras robustness space exploration spatial databases face detection feature extraction;face modeling;facial data;face;humans;scale invariant features 3d aided profile based face recognition biometric face rotation profile silhouette rotation features feature extraction translation features;facial data profile based face recognition 3d;feature extraction face recognition;invariant feature	The silhouette of the face profile is a well-known biometric that is already in use in Face Recognition research. One of the challenges for successful employment of this biometric is the sensitivity of its geometry to face rotation. In this paper, we introduce a new method that improves robustness to rotation. We achieve this by exploring the feature space of profiles under various rotations with the aid of a 3D face model. Based on fiducial points on the profile silhouette, we extract a set of rotation-, translation- and scale-invariant features which are used to design and train a hierarchical pose-identity classifier. In our experiments the classifier is used for the identification of a driver using his/her side-view image. We present our results on a publicly available database.	biometrics;database;experiment;facial recognition system;feature vector;fiducial marker	Boris A. Efraty;Dat Chu;Emil Ismailov;Shishir K. Shah;Ioannis A. Kakadiaris	2009	2009 16th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2009.5413460	facial recognition system;face;computer vision;speech recognition;feature vector;feature extraction;computer science;machine learning;pattern recognition;three-dimensional face recognition;solid modeling;3d computer graphics	Vision	33.36063196136936	-60.6648742462123	161287
ac7de907abb0e1f3e8640a991e81a226e6ef8072	content based image retrieval on hadoop framework	histograms;cbir;distance measures content based image retrieval cbir hadoop mapreduce framework local tetra patterns ltrp feature vector computations;gray scale;sequencefiles cbir hadoop mapreduce local tetra patterns;pattern matching;feature extraction;image retrieval mathematical model feature extraction pattern matching gray scale histograms;mathematical model;local tetra patterns;sequencefiles;mapreduce;hadoop;parallel processing content based retrieval image retrieval;image retrieval	This paper presents an approach for implementing Content Based Image Retrieval (CBIR) on Hadoop MapReduce framework. Although any algorithm can be used for the actual retrieval (provided it can be parallelized), in this paper, we discuss the approach of Local Tetra Patterns (LTrPs). The MapReduce implementation details presented here can be used for most CBIR techniques that involve feature-vector computations and distance measures.	algorithm;apache hadoop;computation;content-based image retrieval;feature vector;mapreduce;parallel computing	U. S. N. Raju;Shibin George;V. Sairam Praneeth;Ranjeet Deo;Priyanka Jain	2015	2015 IEEE International Congress on Big Data	10.1109/BigDataCongress.2015.103	computer science;data mining;database;information retrieval	Vision	38.34373985540932	-61.288226575521506	161618
2b34c52faa701b354d2af4234527e1f6aac36159	an improved two-dimensional otsu segmentation method for nvshu character image	two dimensional histogram;otsu method;lateral inhibition network;nvshu character image	For the structural characteristics of Chinese NvShu character, this paper proposes an improved two-dimensional (2-D) OTSU segmentation method based on the lateral inhibition network for Nvshu character image. A 2-D histogram with the gray level and the lateral inhibition level of the image was established and the maximum between-cluster variance was chosen as the criterion to select the optimal threshold. Experimental results show that the proposed method not only successfully reduced the effect of background noise, but also improved the accuracy of the character image segmentation, especially for NvShu character images with low contrast, uneven gray level of character strokes and uneven background.	algorithm;grayscale;image processing;image segmentation;lateral thinking;otsu's method;software engineering	Que Dong;Jiangqing Wang;Yangguang Sun	2014	Journal of Multimedia	10.4304/jmm.9.9.1081-1088	computer vision;speech recognition;computer science;otsu's method;pattern recognition;balanced histogram thresholding;image segmentation	Vision	38.99891690434864	-65.96152185266428	161842
12b16044c8d6f65c26ce0803a497914208f9ba10	a novel approach of face detection based on skin color segmentation and pca	skin color segmentation;face detection skin principal component analysis image segmentation information filtering information filters face recognition information security image color analysis data mining;image segmentation;eye analogue segments;color space;color space face detection pca segmentation eigenface;skin;information access;segmentation;color model;skin color;face recognition;principal components analysis;image color analysis;image colour analysis;feature extraction;principal component analysis;relevant information extraction face detection skin color segmentation pca face recognition principal components analysis eye analogue segments;relevant information extraction;face;principal component analysis face recognition feature extraction image colour analysis image segmentation;face detection;eigenface;pca	Nowadays, face detection and recognition have gained importance in security and information access. In this paper, an efficient method of face detection based on skin color segmentation and principal components analysis(PCA) is proposed. Firstly, segmenting image using color model to filter candidate faces roughly; And then Eye-analogue segments at a given scale are discovered by finding regions which are darker than their neighborhoods to filter candidate faces farther; at the end, PCA method is used to extract the relevant information in human faces.	algorithm;face detection;image segmentation;information access;skin (computing)	Jing Zhang;Yang Liu;Seok-wun Ha	2008	2008 The 9th International Conference for Young Computer Scientists	10.1109/ICYCS.2008.79	facial recognition system;computer vision;speech recognition;computer science;machine learning;pattern recognition;principal component analysis	Vision	35.295500592930345	-62.63270592258438	162277
fc97fd0903e8de3b51657a62950f46758335a75f	palmprint recognition system using zernike moments feature extraction	image database;feature vector;image acquisition;pattern matching;feature extraction;zernike moment;distance metric;experimental evaluation;environmental factor	A major approach for palmprint recognition today is to extract feature vectors corresponding to individual palmprint images and to perform palmprint matching based on some distance metrics. One of the difficult problems in feature-based recognition is that the matching performance is significantly influenced by many parameters in feature extraction process, which may vary depending on environmental factors of image acquisition. This paper presents a palmprint recognition using Zernike moments feature extraction. Unsharp filtered palmprint images makes possible to achieve highly robust palmprint recognition. Experimental evaluation using a palmprint image database clearly demonstrates an efficient matching performance of the proposed system.	algorithm;feature extraction;fingerprint;region of interest	P. Esther Rani;R. Shanmuga Lakshmi	2010		10.1007/978-3-642-15766-0_72	computer vision;feature vector;metric;feature extraction;computer science;machine learning;pattern matching;pattern recognition;mathematics	Vision	34.768623363307505	-61.199894888064904	162403
6c9c830ebe7fa83c9bb3b78f6589efff21244c5a	local quadruple pattern: a novel descriptor for facial image recognition and retrieval			computer vision;quadruple-precision floating-point format	Soumendu Chakraborty;Satish Kumar Singh;Pavan Chakraborty	2017	Computers & Electrical Engineering	10.1016/j.compeleceng.2017.06.013		Vision	38.57639839782408	-60.09486769095891	162907
2d294935793b34d92abafca932a4035208661ec6	core point detection using improved segmentation and orientation	image segmentation;optimal core point detection;image matching;noisy background;fingerprint classification;fingerprint matching;image classification;fvc2004 database fingerprint classification fingerprint matching noisy background local orientation field optimal core point detection segmentation improvement fine orientation field estimation region of interest extraction;segmentation improvement;region of interest extraction;feature extraction;region of interest;fvc2004 database;image segmentation feature extraction fingerprint identification image classification image matching;local orientation field;fine orientation field estimation;fingerprint recognition image matching telecommunication computing educational institutions background noise geometry equations image segmentation image databases spatial databases;fingerprint identification;singular point	Core point detection is very important in fingerprint classification and matching process. Usually fingerprint images have noisy background and the local orientation field also changes very rapidly in the singular point area. It is difficult to locate the singular point precisely. In this paper, we present a new algorithm for optimal core point detection using improved segmentation and orientation. In our technique detects core point accurately by extracting best region of interest(ROI) from image and using fine orientation field estimation. We present a modified technique for extracting ROI and fine orientation field. The distinct feature of our technique is that it gives high detection percentage of core point even in case of low quality fingerprint images. The proposed algorithm is applied on FVC2004 database. Results of experiments demonstrate improved performance for detecting core point.	algorithm;computation;experiment;fingerprint;gradient;region of interest;sensor	Muhammad Usman Akram;Anam Tariq;Sarwat Nasir;Assia Khanam	2008	2008 IEEE/ACS International Conference on Computer Systems and Applications	10.1109/AICCSA.2008.4493597	fingerprint;computer vision;singular point of a curve;contextual image classification;feature extraction;computer science;machine learning;pattern recognition;image segmentation;region of interest	Vision	35.095028014342844	-62.58345289224559	162950
d140e121aa61897443ca681a62e5ac31c6cd31cc	similarity assessment with local binary patterns	histograms;social interaction;generic model;statistical analysis face recognition feature extraction;borda voting similarity assessment local binary patterns human face social interaction facial information processing pattern recognition intermediate face images model input images feature vectors euclidean distances manhattan distances chebyshev distances chi square statistic;face chebyshev approximation histograms face recognition vectors abstracts;local binary pattern;feature vector;face recognition;statistical analysis;vectors;abstracts;feature extraction;information processing;pattern recognition;face;chebyshev approximation	Identification from human face plays an important role in social interaction, such as recognition and security. Thus facial information processing is an active research area in pattern recognition. The similarity of a child's face to parent faces is evaluated in this paper. Intermediate face images are generated by morphing parents face images in specific proportions as model input images to the method. Then, feature vectors of the generated model images are obtained using the local binary patterns (LBP) and saved to a database. Euclidean, Manhattan, Chebyshev distances and Chi square statistic are used to measure the distance between given child's face and generated model faces using feature vectors and Borda voting is used to evaluate the similarity.	chi;computer security;feature vector;information processing;local binary patterns;morphing;pattern recognition	Vasif V. Nabiyev;Beste Gencturk	2012	2012 20th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2012.6204504	face;local binary patterns;speech recognition;feature vector;information processing;feature extraction;computer science;machine learning;pattern recognition;histogram;mathematics;statistics;approximation theory	Vision	35.90740478299961	-60.8278972596586	163162
3902ccd74848d33b6e1cbc0d13a1017481bceff0	a gender classification scheme based on multi-region feature extraction and information fusion for unconstrained images	bayesian classifier;gender classification;information fusion;support vector machine	Since gender classification has been interesting in many applications, we proposed a gender classification scheme based on multi-region feature extraction and information fusion in the paper. The proposed gender classification scheme is composed of three parts: pre-processing, multi-region feature extraction, and gender classifier. Before extracting useful information from multiple regions in a facial image, face detection and face orientation correction are performed in the pre-processing. Multi-region feature extraction measures three kinds of features from eyes, internal face, and hair. Since the three kinds of features have their particular properties, a classifier based on decision-level information fusion is utilized to combine these features for gender classification. To evaluate the proposed scheme, a large number of unconstrained images containing different-size faces are captured by using a low-cost webcam and digital cameras. Experimental results show that our proposed scheme can detect facial regions and the location of eyes well. Furthermore, the accuracy of the proposed gender classification scheme is higher than 96 %. These experimental results demonstrate that the proposed scheme can deal with unconstrained images for gender classification.	cellular automaton;comparison and contrast of classification schemes in linguistics and metadata;digital camera;face detection;feature extraction;preprocessor;statistical classification;webcam	Guo-Shiang Lin;Min-Kuan Chang;Yu-Jui Chang;Chia-Hung Yeh	2015	Multimedia Tools and Applications	10.1007/s11042-015-2797-9	support vector machine;computer vision;naive bayes classifier;computer science;machine learning;pattern recognition	Web+IR	32.13964277802267	-62.340800252699786	163286
831b49d00e50f356782889cbd7eb9525809c36ef	boosted geometric hashing based indexing technique for finger-knuckle-print database	finger knuckle print;geometric hashing;biometric;indexing;identification	Abstract This paper makes use of a boosted geometric hashing to propose an efficient indexing technique for finger-knuckle-print (FKP) images. Local feature extractors are used to extract features from each FKP image and each feature is inserted exactly once into the hash table which reduces memory and computational cost significantly. Features of all FKP images in the database are found to be well distributed in the hash table. It has been tested on publicly available PolyU FKP database [11] which consists of 7920 FKP images of 660 subjects. Further, the technique has been compared with a well known geometric hashing based indexing technique [6] and it is found to be better in terms of its performance.	brute-force search;euclidean distance;feature extraction;geometric hashing;hash table;image scaling;scale-invariant feature transform;speeded up robust features;viz: the computer game	Umarani Jayaraman;Aman K. Gupta;Phalguni Gupta	2014	Inf. Sci.	10.1016/j.ins.2014.02.032	identification;feature hashing;search engine indexing;hash table;dynamic perfect hashing;computer science;pattern recognition;data mining;database;information retrieval;biometrics	DB	35.64920413852065	-61.36812692424429	163545
a798352f64376f3436937c08d3892795ec6b8e5e	image hashing by log-qcslbp	verification;authentication;histogram;hashing;cslbp;lbp;algorithms;design;experimentation	This paper presents an image hashing algorithm for authentication and tampering based on texture features. Center Symmetric Local Binary Pattern (CSLBP) feature is computationally simple, rotation invariant which works in spatial domain. In CSLBP, number of histogram bin for each sub block of an image is 16, unlike 256 bin in Local Binary Pattern (LBP). In our proposed method, flipped difference is used to generate a histogram of only 8 bin, for each sub block. Resultant method with 8 bin histogram has less discrimination power. To enhance discrimination power, Laplacian of Gaussian (LoG) is used as a weight factor during histogram construction. LoG is used to find a characteristic scale for a given image location. LoG is a second order derivative edge detection operator which performs well in presence of noise. In our previous papers, we tried various local descriptors like magnitude of difference, standard deviation, coefficient correlation as a weight factor, to enhance the success rate of compressed CSLBP. Proposed LoG-QCSLBP gives good results for JPEG, salt & pepper noise, brightness plus, increase/decrease contrast. In the results section, we compared all variants of compressed CSLBP. Results clearly show that by incorporating the weight of a local descriptor, discrimination power of compressed CSLBP is enhanced.	adaptive histogram equalization;algorithm;authentication;blob detection;coefficient;edge detection;hash function;image histogram;jpeg;linear discriminant analysis;local binary patterns;resultant;salt (cryptography);salt-and-pepper noise	Varsha Patil;Tanuja K. Sarode	2016		10.1145/3018009.3018051	local binary patterns;histogram matching;theoretical computer science;machine learning;pattern recognition;mathematics;adaptive histogram equalization;image histogram	Vision	35.82474256530353	-60.68710858799579	163712
a5e5aaaca4cda51757ba897e21cbc4ca23c732d4	precise face segmentation for recognition	eye;wavelet transforms eye face recognition feature extraction filtering theory image classification image segmentation pose estimation support vector machines;image segmentation;support vector machines;face recognition face detection eyes mouth support vector machines support vector machine classification robustness filtering algorithms entropy layout;eye detection;efficient algorithm;image classification;wavelet transforms;t shape face region face segmentation face recognition facial component extraction eyes detection mouth width measuring pose estimation wavelet feature template support vector machine svm classifier wavelet entropy filtering;face recognition;feature extraction;support vector machine;filtering theory;pose estimation	In this paper, we present an efficient algorithm for facial component extractions, which are eyes detection and the mouth width measuring, and pose estimation. The algorithm is based on the novel overcomplete wavelet feature template, the support vector machine (SVM) classifier, and the wavelet entropy filtering to robustly detect and segment the T-shape face region. The segmented T-shape face region, which is the smallest area enclosed by the face ellipse including eyes and mouth, is used to select the corresponding view-based classifier for face recognition. The experimental results show that the proposed method is robust against the complex scenes.	algorithm;facial recognition system;robustness (computer science);support vector machine;wavelet	Jing-Wein Wang	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312859	facial recognition system;support vector machine;computer vision;computer science;machine learning;pattern recognition;three-dimensional face recognition;structured support vector machine	Vision	34.07161608127944	-60.69331859390505	164693
8b85ae014a4cfb38a018725da2f2f698cb1b2378	splicing forgeries localization through the use of first digit features	splicing;image coding;support vector machines;forgery;transform coding;svm forgery detection splicing attack localization;image coding support vector machines transform coding forgery discrete cosine transforms splicing q factor;support vector machines discrete cosine transforms feature extraction image classification image coding image forensics;discrete cosine transforms;discrete cosine transform forgeries localization image forensics image authentication image examination image area forensic instruments copy move manipulation localization map splicing operation jpeg compression dct coefficients digit features support vector machine classifier svm classifier forgery detection splicing attack;q factor	One of the principal problems in image forensics is determining if a particular image is authentic or not and, if manipulated, to localize which parts have been altered. In fact, localization is basic within the process of image examination because it permits to link the modified zone with the corresponding image area and, above all, with the meaning of it. Forensic instruments dealing with copy-move manipulation quite always provides a localization map, but, on the contrary, only a few tools, devised to detect a splicing operation, are able to give information about localization too. In this paper, a method to distinguish and then localize a single and a double JPEG compression in portions of an image through the use of the DCT coefficients first digit features and employing a Support Vector Machine (SVM) classifier is proposed. Experimental results and a comparison with a state-of-the-art technique are provided to witness the performances offered by the proposed method in terms of forgery localization.	algorithm;coefficient;discrete cosine transform;internationalization and localization;jpeg;performance;support vector machine;visual descriptor	Irene Amerini;Rudy Becarelli;Roberto Caldelli;Andrea Del Mastio	2014	2014 IEEE International Workshop on Information Forensics and Security (WIFS)	10.1109/WIFS.2014.7084318	computer vision;speech recognition;pattern recognition;mathematics	Vision	35.62655265184579	-62.139195155377166	165617
f9023c939c24bc905483e1b9b9f140dd1418caba	statistical property guided feature extraction for volume data		Feature visualization is of great significances in volume visualization, and feature extraction has been becoming extremely popular in feature visualization. While precise definition of features is usually absent which makes the extraction difficult. This paper employs probability density function (PDF) as statistical property, and proposes a statistical property guided approach to extract features for volume data. Basing on feature matching, it combines simple liner iterative cluster (SLIC) with Gaussian mixture model (GMM), and could do extraction without accurate feature definition. Further, GMM is paired with a normality test to reduce time cost and storage requirement. We demonstrate its applicability and superiority by successfully applying it on homogeneous and nonhomogeneous features. key words: feature extraction, probability density function (PDF), statistical property, simple liner iterative clustering (SLIC), Gaussian Mixture Model (GMM)	cluster analysis;feature extraction;google map maker;iterative method;mixture model;portable document format;scientific visualization	Li Wang;Xiaoan Tang;Junda Zhang;Dongdong Guan	2018	IEICE Transactions		computer vision;artificial intelligence;computer science;pattern recognition;feature extraction	DB	38.279025468635034	-63.684980437840004	165878
4397ee548c83fabfd4423228da61b46c15b76b03	palmprint authentication using fusion of wavelet and contourlet features	contourlets;fusion;biometrics;palmprint;feature extraction;wavelets	Abstract#R##N##R##N#Low resolution palmprint images consist of discriminative multisized and multidirectional principal lines and wrinkles. Intuitively, discrete wavelet transform (DWT) is a good choice to extract such patterns due to its space-frequency localization, multiresolution analysis (MRA) capability, and computational efficiency. However, most of the DWT-based palmprint recognition systems fail to report low equal error rate (EER) due to inherent limitations of DWT and shift-rotational variations in the intraclass palmprint images. This paper proposes the techniques for shift and rotation invariant feature extraction using DWT extension. The effectiveness of these techniques is tested on deliberately shifted and rotated palmprints. Further, limited directionality due to DWT is overcome by augmenting with features of contourlet transform. Contourlet transform can extract curve singularities effectively with multidirectional decomposition capability; wavelets are good in extracting point singularities. The different views of contourlet transform and DWT on palmprints motivate us to extract contourlet and wavelet features, and examine them for their individual and combined verification performances. The combined mode is found to perform well over their individual performances. The average EER (0.41%), obtained on PolyU-Online-Palmprint-Database-II (PolyU), is better than the existing wavelets/transform-based palmprint recognition approaches and comparable to the other state of the art palmprint recognition approaches. The computational burden on feature extraction and matching is substantially low thereby making the approach suitable for resource constrained environments. Copyright © 2010 John Wiley & Sons, Ltd.	authentication;contourlet;fingerprint;wavelet	S. M. Prasad;V. K. Govindan;P. S. Sathidevi	2011	Security and Communication Networks	10.1002/sec.234	wavelet;computer vision;speech recognition;fusion;feature extraction;computer science;pattern recognition;biometrics	Mobile	33.57541355670765	-61.1028071802784	166978
bda366ceaa2fe928abc17672630acba5ab8bf5c1	video segmentation utilized in visual data mining applications.	image database;video segmentation;texture segmentation;texture features;object segmentation;visual data mining;motion vector;image sequence;image search;video database;co occurrence matrix;color image segmentation	A novel approach utilized in video database objectbased queries is proposed. This new method segments an example video sequence into real world objects using a combination of color image segmentation techniques along with MPEG-1/2 motion vectors. First, the initial frame in the sequence undergoes a color/texture segmentation algorithm that divides the frame into homogenous regions of color and texture. Features extracted from the co-occurrence matrix provide the texture measurement utilized by this system. The MPEG-1/2 motion vectors are then exploited in predicting the objects of the next frame based on the initial frame’s segmentation. A robust technique for the identification of new objects as they enter the scene is proposed along with a measurement pertaining to the object segmentation accuracy is introduced. This new method has a host of visual data mining applications including image database retrieval and Internet image searches. This new algorithm is tested on various image sequences with segmentation results included.	algorithm;co-occurrence matrix;color image;data mining;document-term matrix;image segmentation;texture filtering	Mark Smith;Alireza Khotanzad	2006			image texture;computer vision;segmentation-based object categorization;pattern recognition;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation;computer graphics (images)	Vision	39.00332514155086	-61.33491444698512	167094
8164e07f3b451d4e8ab94d381e0b9fc2003065b4	compression of chinese document images by complex shape matching				Chwan-Yi Shiah;Yun-Sheng Yen	2013	Comput. J.	10.1093/comjnl/bxs100	computer vision;pattern recognition	Vision	37.68710517913635	-64.93421042427993	167763
7f40b89a4a1bfc467202e3c233ed24db51da5656	video-based face authentication using appearance models and hmms	iterative algorithm video based face authentication hmm active appearance model hidden markov model feature extraction image texture feature classification vector quantization;video signal processing face recognition feature extraction hidden markov models image classification image texture message authentication vector quantisation;authentication hidden markov models face recognition face detection active appearance model active shape model data mining feature extraction biometrics fingerprint recognition;video signal processing;hidden markov model;hmm;image classification;active appearance model;iterative algorithm;temporal information;image texture;feature vector;face recognition;hidden markov models;vector quantization;feature extraction;image texture analysis;vector quantizer;message authentication;video based face authentication;vector quantisation;feature classification;data security	In this paper, we propose a novel face authentication scheme using the active appearance model (AAM) and the hidden Markov model (HMM). The proposed face authentication system can be divided into two parts. First, the AAM is used to extract the low-dimensional feature vectors including combined texture and shape information of individual face images. The extracted feature vectors are further classified into several clusters using vector quantization. The clustered feature vectors are then characterized using HMMs to make full use of the temporal information across the face images. After all parameters in the HMMs are calculated, we can dynamically determine the thresholds for face authentication. An iterative algorithm is also proposed to automatically determine a suitable number of HMM states and a suitable number of observation classes to achieve good authentication accuracy. The experimental results show the efficacy of the proposed method	active appearance model;algorithm;authentication;feature vector;hidden markov model;iterative method;markov chain;vector quantization	Ke-Zhao Chen;Yao-Jen Chang;Chia-Wen Lin	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1692635	message authentication code;image texture;computer vision;contextual image classification;active appearance model;speech recognition;feature vector;feature extraction;computer science;machine learning;pattern recognition;iterative method;data security;vector quantization;hidden markov model	Vision	35.0949627099406	-60.85656860871012	167814
56546fa67c44459be30cf73bd739216e43504369	location extraction and discrimination of similar texture using gabor filter for donut recognition		This paper describes a machine vision system for recognition of bakery donut produce using Gabor filter that is capable of first locating and then analyzing regions of subtle texture differences. In the case when there is similar texture pattern, color analysis can then be used. Compared to conventional methods and applications, what newly presented are: Automatic location of small distinctive areas that characterizes the donut produce Identification of texture feature based on the spatial and orientation relationshp between coarse-to-fine frequency components of the image.	algorithm;gabor filter;machine vision;skin (computing)	Heng Cher Keng;Hidenobu Iida;Michio Miwa	2002			artificial intelligence;computer vision;pattern recognition;mathematics;machine vision;gabor filter;color analysis	Vision	35.097300393932926	-62.50598367411513	168198
6055d1873c558f8830e53105fa4d72a9489dac52	automatic character location and segmentation in color scene images	image segmentation layout colored noise histograms image color analysis gray scale digital cameras flowcharts image decomposition image analysis;image segmentation;grayscale based recognition automatic character location color scene images automatic text location natural scene images multi group decomposition scheme complexity color background connected component extraction block adjacency graph bag algorithm noise filtering runlength smearing heuristic features priority adaptive segmentation block candidate verification;optical character recognition;image colour analysis;feature extraction;filtering theory optical character recognition image colour analysis image segmentation natural scenes feature extraction;connected component;filtering theory;natural scenes	This paper describes a connected component (CC)based approach to automatic text location and segmentation in natural scene images. Multi-group decomposition scheme is used to deal with the complexity of the color background. Connected component extraction is implemented using block adjacency graph (BAG) algorithm after noise filtering and run length smearing (US) operation. Some heuristic features and priority adaptive segmentation (PAS) of characters are proposed in block candidate verification and grqscalebased recognition. A prototype system is completed and the experimental results prove the effectiveness of the proposed method	algorithm;connected component (graph theory);connected-component labeling;heuristic;prototype;run-length encoding	Hao Wang	2001		10.1109/ICIAP.2001.956977	computer vision;speech recognition;connected component;feature extraction;computer science;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;optical character recognition;scale-space segmentation;connected-component labeling	AI	37.720170156605164	-65.04095875980616	168482
347efd2b6f4d785c4b3062050f27316f4ae6e571	text detection system for the blind	histograms;image segmentation image color analysis histograms optical character recognition software shape signal processing conferences;image segmentation;bent text text detection system natural scene images blind persons visually impaired persons optical character recognition ocr programs text like image regions color image segmentation segment shape analysis text distortions slanted text tilted text;optical character recognition handicapped aids image colour analysis image segmentation medical computing;optical character recognition software;shape;image color analysis;signal processing;conferences	The system capable of localizing and reading aloud text embedded in natural scene images can be very helpful for blind and visually impaired persons - providing information useful in everyday life, it increases their confidence and autonomy. Even though the currently available optical character recognition (OCR) programs are fast and accurate, most of them fail to recognize text embedded in natural scene images. The goal of the algorithm described in this paper is to localize text-like image regions and pre-process them in a way that will make OCR work more reliably. The approach described in the paper is based on color image segmentation and segment shape analysis. Preliminary tests have shown that the proposed algorithm offers satisfactory detection rate and is pretty robust to typical text distortions, such as slant, tilt and bend.	algorithm;color image;distortion;embedded system;image segmentation;internationalization and localization;optical character recognition;preprocessor;shape analysis (digital geometry)	Marcin Pazio;Maciej Niedzwiecki;Ryszard Kowalik;Jacek Lebiedz	2007	2007 15th European Signal Processing Conference		computer vision;speech recognition;binary image;computer science;pattern recognition;image segmentation;scale-space segmentation	Robotics	35.53253776757089	-64.01224258929882	168540
673f826cdc8b33c2618aa158ea62058da78db35f	multispectral hand biometrics	sensors;biometrics access control;principal component analysis authorisation cameras feature extraction image classification image colour analysis object recognition;joints;personal computer secure access system multispectral hand biometrics contactless hand biometrics rgb depth camera red green blue depth camera near infrared spectra rgb spectra depth spectra palm print information hand shape information finger joint location information vein pattern information hand extraction palm recognition principle component analysis k nearest neighbors pattern classification multispectral analysis mass access control system;feature extraction vectors biometrics access control joints shape principal component analysis sensors;shape;vectors;feature extraction;principal component analysis	This paper reports on a feasibility study of contactless hand biometrics using an RGB-Depth (RGB-D) camera such as the Kinect v2 prototype. The RGB, depth, and near-infrared (near-IR) spectra provide access to information such as palm print, hand shape, finger joint location, and vein patterns. Extraction of the hand is first done using depth data. The frames with the best palm position are selected, and then correlated into the synchronized RGB and near-IR frames for further processing of the related information in each spectra. Using the hand location information the palm can be extracted in the RGB data for use in palm recognition. Recognition of the palm is performed using Principle Component Analysis and K-Nearest-Neighbors for the classification. This multi-spectral analysis is a pre-requisite for hand shape, palm, and vein recognition to be integrated into a mass access control system or a personal computer secure access system.	access control;biometrics;contactless smart card;control system;freedom of information laws by country;k-nearest neighbors algorithm;kinect;multispectral image;palm print;pattern recognition;personal computer;principal component analysis;prototype	Steven Samoil;Kenneth Lai;Svetlana N. Yanushkevich	2014	2014 Fifth International Conference on Emerging Security Technologies	10.1109/EST.2014.10	computer vision;speech recognition;engineering;remote sensing	Robotics	32.78295895035549	-62.03326289329044	168664
73cb272fc617124a2526e4963fab3882cf0aa525	target recognition in radar images using weighted statistical dictionary-based sparse representation		In this letter, we present a novel generic approach for radar automatic target recognition in either inverse synthetic aperture radar (ISAR) or synthetic aperture radar (SAR) images. For this purpose, the radar image is described by a statistical modeling in the complex wavelet domain. Thus, the radar image is transformed into a complex wavelet domain using the dual-tree complex wavelet transform. Afterward, the magnitudes of the complex sub-bands are modeled by Weibull or Gamma distributions. The estimated parameters of these models are stacked together to create a statistical dictionary in training step. For the recognition task, we use the weighted sparse representation-based classification method that captures the linearity and locality information of image features. In this context, we propose to use the Kullback–Leibler divergence between the parametric statistical models of training and test sets in order to assign a weight for each training sample. Experiments conducted on both ISAR and SAR images’ databases demonstrate that the proposed approach leads to an improvement in the recognition rate.	aperture (software);automatic target recognition;clutter;coefficient;complex wavelet transform;database;dictionary;gamma correction;kullback–leibler divergence;locality of reference;psi protein classifier;radar;sample rate conversion;sparse approximation;sparse matrix;statistical model;synthetic data;synthetic intelligence;test set	Ayoub Karine;Abdelmalek Toumi;Ali Khenchaf;Mohammed El Hassouni	2017	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2017.2766225	inverse synthetic aperture radar;radar imaging;wavelet;mathematics;computer vision;wavelet transform;synthetic aperture radar;radar;artificial intelligence;automatic target recognition;complex wavelet transform;pattern recognition	Vision	37.16681973602329	-61.62586889701535	169247
54809156dc221034b956432230a2f482984d9e5f	shape classification via image-based multiscale description	high pass;standard deviation;multiscale representation;low pass;computer vision;rotation invariance;fourier descriptors;wavelet transform;space use;shape classification;feature extraction;zernike moment;fourier based description;gaussian filter	We introduce a new multiscale Fourier-based object description in 2-D space using a low-pass Gaussian filter (LPGF) and a high-pass Gaussian filter (HPGF), separately. Using the LPGF at different scales (standard deviation) represents the inner and central part of an object more than the boundary. On the other hand using the HPGF at different scales represents the boundary and exterior parts of an object more than the central part. Our algorithms are also organized to achieve size, translation and rotation invariance. Evaluation indicates that representing the boundary and exterior parts more than the central part using the HPGF performs better than the LPGF-based multiscale representation, and in comparison to Zernike moments and elliptic Fourier descriptors with respect to increasing noise. Multiscale description using HPGF in 2-D also outperforms wavelet transform-based multiscale contour Fourier descriptors and performs similar to the perimeter descriptors without any noise. & 2011 Elsevier Ltd. All rights reserved.	euclidean distance;fourier analysis;linear discriminant analysis;low-pass filter;nearest neighbour algorithm;perimeter;persistence (computer science);quaternions and spatial rotation;salt-and-pepper noise;solid-state drive;wavelet transform;whole earth 'lectronic link	Cem Direkoglu;Mark S. Nixon	2011	Pattern Recognition	10.1016/j.patcog.2011.02.016	computer vision;topology;low-pass filter;feature extraction;computer science;mathematics;geometry;high-pass filter;standard deviation;gaussian filter;wavelet transform	Vision	38.1607024599164	-59.31059608823467	169283
fed5b44966c682bd9ad05f8cb531aeb0c7345ac6	a novel comprehensive database for offline persian handwriting recognition	digit recognition;check recognition;persian alphabet;numeral string;persian date;unconstrained persian handwriting recognition;persian handwriting recognition;persian handwriting database;persian offline recognition	Developing a standard database for offline handwriting recognition is an essential task. This paper offers a novel comprehensive database for conducting research on offline Persian handwriting recognition. Seven pages of forms were designed and completed by 500 native Persian writers, who were equally balanced in terms of gender and randomly selected from all over Iran. Then, the completed forms were scanned at a resolution of 300 DPI. Through several intensive processing steps, a huge number of isolated digits, numeral strings, touching digits, dates, words, names, alphabetical letters, free texts, arithmetic, and especial symbols from all these forms were extracted and organized as a standard database. All samples in this database were assigned with detailed ground truth and stored in three color formats: true color, gray level, and binary. Also, all subsets of this database were randomly partitioned into training, validation, and testing sets. We hope this comprehensive database will extend research in the pattern recognition community. & 2016 Elsevier Ltd. All rights reserved.	color depth;dots per inch;grayscale;ground truth;handwriting recognition;online and offline;pattern recognition;randomness	Javad Sadri;Mohammad Reza Yeganehzad;Javad Saghi	2016	Pattern Recognition	10.1016/j.patcog.2016.03.024	arithmetic;natural language processing;speech recognition;computer science	Vision	34.08886945424252	-65.82761191492197	169437
68194ada489bf8d296313aa38df26263f2bce1ae	skin detection from different color spaces for model-based face detection	skin detection;video surveillance;color space;boundary condition;human machine interface;face detection;human activity;electrical engineering electronics nuclear engineering;knowledge base	Skin and face detection has many important applications in intelligent human-machine interfaces, reliable video surveillance and visual understanding of human activities. In this paper, we propose an efficient and effective method for frontal-view face detection based on skin detection and knowledge-based modeling. Firstly, skin pixels are modeled by using supervised training, and boundary conditions are then extracted for skin segmentation. Faces are further detected by shape filtering and knowledge-based modeling. Skin results from different color spaces are compared. In addition, experimental results have demonstrated our method robust in successful detection of skin and face regions even with variant lighting conditions and poses.	face detection;spaces	Jinchang Ren;Jianmin Jiang;Stanley S. Ipson	2008		10.1007/978-3-540-85930-7_62	human–machine interface;computer vision;knowledge base;face detection;simulation;object-class detection;boundary value problem;computer science;color space;computer graphics (images)	Vision	32.85740338020394	-60.248644720710864	169642
5a1f5b3e2a52f5d4bd2f58ec7625e1b47ad1a601	a classification system for gray scale images by using combination of simple figures	face genetic algorithms euclidean distance shape support vector machines equations mathematical model;image classification;figure alphabet;gray scale image;face recognition;image colour analysis;pedestrian image gray scale images simple figures figure alphabet hypothesis pattern classification alphabet dot pattern adp genetic algorithm ga face image;gray scale image figure alphabet genetic algorithm;genetic algorithm;genetic algorithms;image colour analysis face recognition genetic algorithms image classification	"""It is thought that human being recognizes a complicated figure by combining simple figures. This is """"figure alphabet hypothesis"""" and these simple figures are called """"figure alphabet"""". We considered """"the mechanism in which a complicated figure is recognized with the combination of the figure chosen from comparatively simple figure groups"""", and applies it to a pattern classification. The proposed method assumes the figure alphabet to be the dot pattern (Alphabet Dot Pattern, ADP) of an N × N pixels. Because there are many kinds of ADP, ADP group is optimized by Genetic Algorithm (GA). And, the euclidean distance of an input figure and an ADP group is calculated, and classifies the figure. The proposal technique was previously applied to the classification problem of the binary multifont figure, and the validity was shown. In this research, the result applied to the gradation images. As a result, the classification of the face image and the pedestrian image obtained a high correct answer rate."""	euclidean distance;genetic algorithm;pixel;software release life cycle;usb on-the-go	Ryoji Ohira;Noriko Yata;Tomoharu Nagao	2013	2013 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/SMC.2013.206	facial recognition system;genetic algorithm;computer science;artificial intelligence;machine learning;pattern recognition;mathematics	Vision	33.59553404584857	-64.82280804311166	170224
70cec680ec33f86c154cf4f6bc02e304c1c3536c	steganalysis of lsb matching based on the sum features of average co-occurrence matrix using image estimation	steganalysis;lsb matching;image restoration;feature classify;co occurrence matrix	A new LSB matching steganalysis scheme for gray images is proposed in this paper. This method excavates the relevance between pixels in the LSB matching stego image from the co-occurrence matrix. This method can acquire high accuracy near to 100% at high embedding rate. In order to increase the accuracy at low embedding rate, we strengthen the differences between the cover image and the stego image to improve the performance of our scheme. Two 8 dimensional feature vectors are extracted separately from the test image and the restoration image, and then the combining 16 dimensional feature vector is used for steganalysis with the FISHER linear classification. Experimental results show that the detection accuracy of this method is above 90% with the embedding rate of 25%; even when the embedding rate is 10%, the detection accuracy reaches 80%.Experiments show that this method is more reliable than other state-of-art methods.	circuit restoration;co-occurrence matrix;document-term matrix;feature vector;least significant bit;linear classifier;major stationary source;pixel;relevance;standard test image;stationary process;steganalysis;steganography	Yanqing Guo;Xiangwei Kong;Bo Wang;Qian Xiao	2012		10.1007/978-3-642-40099-5_4	arithmetic;image restoration;computer vision;steganalysis;computer science;pattern recognition;mathematics;co-occurrence matrix	Vision	36.439160341921514	-61.586210862106604	170478
9d420ad78af7366384f77b29e62a93a0325ace77	a spectrogram-based audio fingerprinting system for content-based copy detection	spectrogram;feature parameters;content based copy detection;audio fingerprints;trecvid	This paper presents a novel audio fingerprinting method that is highly robust to a variety of audio distortions. It is based on an unconventional audio fingerprint generation scheme. The robustness is achieved by generating different versions of the spectrogram matrix of the audio signal by using a threshold based on the average of the spectral values to prune this matrix. We transform each version of this pruned spectrogram matrix into a 2-D binary image. Multiple versions of these 2-D images suppress noise to a varying degree. This varying degree of noise suppression improves likelihood of one of the images matching a reference image. To speed up matching, we convert each image into an n-dimensional vector, and perform a nearest neighbor search based on this n-dimensional vector. We give results with two different feature parameters and their combination. We test this method on TRECVID 2010 content-based copy detection evaluation dataset, and we validate the performance on TRECVID 2009 dataset also. Experimental results show the effectiveness of these features even when the audio is distorted. We compare the proposed method to two state-of-the-art audio copy detection systems, namely NN-based and Shazam systems. Our method by far outperforms Shazam system for all audio transformations (or distortions) in terms of detection performance, number of missed queries and localization accuracy. Compared to NN-based system, our approach reduces minimal Normalized Detection Cost Rate (min NDCR) by 23 % and improves localization accuracy by 24 %.	acoustic fingerprint;binary image;binary number;distortion;fingerprint (computing);maxima and minima;multistage interconnection networks;nearest neighbor search;reference frame (video);relevance;shazam;spectrogram;zero suppression	Chahid Ouali;Pierre Dumouchel;Vishwa Gupta	2015	Multimedia Tools and Applications	10.1007/s11042-015-3081-8	speech recognition;computer science;machine learning;spectrogram;pattern recognition	Vision	37.364376730307654	-61.77853398920914	170555
36d9f9d4e1acccdbb07c620703bf337eeee41468	visual data extraction from bi-level document images using a generalized kernel family with compact support, in scale-space	data mining kernel space technology testing image processing computational efficiency virtual colonoscopy read only memory image segmentation gaussian processes;information loss;handwritten data visual data extraction noisy bi level document images generalized kernel family compact support scale space information recovery information loss gaussian kernel processing time first derivative second derivative image processing;image processing;scale space;data extraction;feature extraction;gaussian kernel;document image processing;feature extraction document image processing handwritten character recognition;handwritten character recognition	Presents a generalization of a new kernel family with compact support in scale space which we recently published (Vision Interface, pp. 445-52, May 1999). We have shown that the proposed kernels are able to recover the information loss when using the Gaussian kernel, while they drastically reduce the processing time. Furthermore, the generalized kernel family preserves all the properties of the previous one and it offers other important properties, like the behavior of the first and second derivatives which are guaranteed to be the same as the Gaussian kernel one at any scale space. The latter property plays an important role in image processing, as we show in this paper. The construction and some properties shown in the previous version are recalled and some of the new properties of the new version are proven. An application of extracting handwritten data from noisy bi-level document images is presented to point out the practical impact of the improved version of the proposed kernels.		Lakhdar Remaki;Mohamed Cheriet	1999		10.1109/ICDAR.1999.791861	computer vision;kernel method;string kernel;scale space;speech recognition;kernel embedding of distributions;radial basis function kernel;mean-shift;image processing;feature extraction;computer science;machine learning;digital image processing;free boundary condition;pattern recognition;tree kernel;kernel;gaussian function;polynomial kernel	AI	37.90288523303052	-65.54841915154003	170758
5a290970384dfe7a57a5619b0588ac22b3451441	face segmentation based on skin color in complicated background and its sex recognition	2-d gabor-wavelet;combination of forecasts;gender classification;skin segmentation	Human skin color distribution is relatively compact in a color space, and it changes from frame to frame following illumination variations, also it is subject to camouflage interruption in complicated background for skin segmentation. This paper mainly talks about face detection based on skin color feature in complicated background. We assume that skin pixels in each frame are closed together as a “dot cloud” in a color space, its shape evolution from frame to frame is modeled as the mixture of translation, scaling and rotation. We introduce linear combination of forecasts to predict these parameters related to the above shape evolutions, so that skin distribution of next frame to be segmented can be predicted and skin segmentation for face detection can be improved against illumination variations. Additionally human skin biological feature is then introduced to remove camouflage noise. For face gender recognition we adopt 2-D Gabor transform for feature extraction and SVM for recognition. Extensive tests prove that this algorithm is quite sensitive to human color, and more accurate for human skin segmentation with Bayes classifier; Good performance of gender classification test is also achieved on a relative large scale and low-resolution video database.	algorithm;color space;face detection;feature extraction;gabor wavelet;gesture recognition;illumination (image);image scaling;image segmentation;informatics;interrupt;kerrison predictor;natural deduction;pattern recognition;pixel;signal processing;simulation;stochastic process;support vector machine;wavelet transform	Chuanxu Wang	2011	JSW		computer vision;speech recognition;pattern recognition	Vision	31.998743555348806	-59.45297876875914	171305
010d263cf72aec39c109427d0ae63c197b63e1b3	quantitative analysis of facial paralysis based on limited-orientation modified circular gabor filters	eyebrows;passband;two dimensional displays;gabor filters;statistical analysis;feature extraction;modulation	The diagnosis of disease with the aid of computer programs has been developing more and more in recent years. This paper presents an approach which is based on frequency technique for the objective quantitative analysis of facial paralysis. In this method, limited-orientation modified circular Gabor filters (LO-MCGFs) are used to enhance the desirable frequencies in images. Then, features are extracted from the filtered images for classification. The first advantage of the LO-MCGF is that its inner passbands are uniform, so it helps remove noise and control frequencies more effectively. The second benefit is that the LO-MCGF utilizes the existing robust characteristics of circular Gabor filter for rotation invariant texture regions. Hence, the LO-MCGF-based technique improves remarkably the accuracies of score estimation for some expressions whose local textures are invariant in rotation. Finally, the limited filtered regions, or limited propagation orientations, help the LO-MCGF focus on only some specific spaces. Therefore, the LO-MCGF can avoid the influences of irrelevant regions. In other words, it improves the spatial localization. For overall evaluation, experiments show that our proposed method is superior to other contemporary techniques tested on a dynamic facial expression database.	belief propagation;computer program;experiment;facial recognition system;feature extraction;gabor filter;pixel;preprocessor;relevance;software propagation	Truc Hung Ngo;Masataka Seo;Naoki Matsushiro;Wei Xiong;Yen-Wei Chen	2016	2016 23rd International Conference on Pattern Recognition (ICPR)	10.1109/ICPR.2016.7899658	computer vision;speech recognition;feature extraction;computer science;mathematics;passband;modulation	Vision	34.50143913058247	-62.12648427866251	171594
4e0eada4f243b1fb9f6e58cd4555daf90358c255	face recognition in unconstrained environments	eye;face recognition;face face recognition databases lighting image recognition feature extraction principal component analysis;lighting eye face recognition;lighting;yale and face recognition system face region detection unconstrained illumination environments eye detection rotated angle compensation face region cropping sequential steps cmu pie database	This paper proposes a novel face recognition system having good recognition performance through elaborate face region detection in unconstrained illumination environments. The proposed system consists of face and eyes detection, rotated-angle compensation, face region cropping, preprocessing, and classification modules as sequential steps. In particular, the elaborate face region is obtained from automatic face cropping procedure based on distance information between the eyes. The performance evaluation was carried out with various preprocessing images on the Yale B and the CMU-PIE databases. From the experimental results, we confirmed that the proposed method showed the best recognition accuracy compared to different approaches.	database;facial recognition system;illumination (image);performance evaluation;preprocessor	Dong-Ju Kim;Sang-Heon Lee;Myoung-Kyu Sohn;Byungmin Kim;Hyunduk Kim	2013	2013 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2013.6486832	facial recognition system;computer vision;face detection;speech recognition;object-class detection;computer science;engineering;three-dimensional face recognition;lighting	Vision	33.02356109349037	-59.14693418067115	171708
fb0ef680f1a2cbc48b438836e38557374ef34414	fuzzy color signatures	image retrieval information retrieval image databases histograms quantization humans indexing fuzzy logic earth cities and towns;earth mover s distance fuzzy color signatures digital libraries world wide web www image retrieval compact color descriptor efficient metric image adaptive color clustering method image colors peaks detection function color distribution image descriptors;pattern clustering;digital library;peak detection;fuzzy set theory;fuzzy logic;adaptive signal processing;pattern clustering image colour analysis image retrieval adaptive signal processing fuzzy set theory;image colour analysis;clustering method;earth mover s distance;image retrieval	With the large and increasing amount of visual information available in digital libraries and the Web, efficient and robust systems for image retrieval are urgently needed. In this paper a compact color descriptor scheme and an efficient metric to compare and retrieve images is presented. An image adaptive color clustering method, called fuzzy color signature, is proposed. The original image colors are mapped into a small number of representative colors using a peaks detection function derived from the color distribution. Fuzzy color signatures are then used as image descriptors. To compare image descriptors the Earth Mover’s Distance is used. The cost associated with the estimation of this metric was modified by applying fuzzy logic. Several experiments have been conducted to assess the performance of the proposed technique.	cluster analysis;color;digital library;experiment;fuzzy logic;image retrieval;library (computing);type signature;visual descriptor;world wide web	Andrés Dorado;Ebroul Izquierdo	2002		10.1109/ICIP.2002.1038053	fuzzy logic;demosaicing;adaptive filter;earth mover's distance;color histogram;image texture;computer vision;feature detection;visual word;digital library;color quantization;hsl and hsv;color image;image gradient;binary image;image processing;image retrieval;computer science;machine learning;digital image processing;pattern recognition;mathematics;fuzzy set;automatic image annotation;information retrieval	Vision	39.14145883043446	-60.903482369612256	171749
c2417707bcf6f02ef6811437a4502b5ccc9828d6	medical image retrieval based on latent semantic indexing	histograms;singular value decomposition medical image retrieval latent semantic indexing color histogram color autocorrelogram;medical image retrieval;singular value decomposition;singular value decomposition image retrieval medical image processing;color histogram;distance measurement;large scale integration;matrix decomposition;singular value decomposition color histogram color autocorrelogram latent semantic indexing;image color analysis;feature extraction;medical image processing;latent semantic indexing;term weighting;query by example;color autocorrelogram;biomedical imaging image retrieval indexing content based retrieval histograms medical diagnostic imaging information retrieval prototypes data mining singular value decomposition;image retrieval	To improve the performance of content-based medical image retrieval, herein an algorithm which makes use of latent semantic indexing (LSI) technology on gastroscopic image retrieval is proposed. First extract imagepsilas color histogram and color autocorrelogram of low-level features, and then use normalizing, term weighting and singular value decomposition to realize low-level features mapping into high-level semantic features. In this way, the retrieval results will be more in accordance with the query imagepsilas semantic content. Based on above idea, a prototype system which supports query by example image is designed and implemented. The experimental results according to the prototype system show that the approach proposed in the paper is effective to gastroscopic image retrieval.	algorithm;color histogram;high- and low-level;image retrieval;prototype;query by example;singular value decomposition	Qin Chen;Xiaoying Tai;Baochuan Jiang;Gang Li;Jieyu Zhao	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.1457	color histogram;computer vision;latent semantic indexing;visual word;feature extraction;image retrieval;computer science;query by example;pattern recognition;histogram;matrix decomposition;singular value decomposition;information retrieval;statistics	Vision	38.63876502267544	-61.392944840674126	172013
35118b69b493a2ef3864109c647e29667937da13	a method for the identification of noisy regions in normalized iris images	eye;biometric iris signatures;neural nets;biometrics access control;pixel classification;iris recognition;image classification;neural nets biometrics access control eye feature extraction image classification;iris recognition noisy image region identification normalized iris images polar coordinate system pixel classification posterior feature extraction feature comparison biometric iris signatures neural network;feature extraction;feature comparison;polar coordinate system;polar coordinate;normalized iris images;posterior feature extraction;noisy image region identification;optical reflection eyelashes pixel eyelids feature extraction biometrics iris recognition neural networks working environment noise focusing;neural network	"""In this paper we propose a new method for the identification of noisy regions in normalized iris images. Starting from a normalized and dimensionless iris image in the polar coordinate system, our goal consists in the classification of every pixel as """"noise"""" or """"not noise"""". This classification could be helpful in the posterior feature extraction or feature comparison stages regarding the construction of biometric iris signatures more robust to noise. We propose the extraction of 8 well known features for each pixel of the images followed by the classification through a neural network"""	artificial neural network;biometrics;computation;computer performance;digital signature;electronic signature;experiment;feature extraction;feedforward neural network;phase congruency;pixel;signal-to-noise ratio	Hugo Proença;Luís A. Alexandre	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.100	computer vision;polar coordinate system;speech recognition;computer science;machine learning;pattern recognition;artificial neural network	Vision	33.326435986554664	-63.168285712643275	172254
130b92ae135c70fc8bd758b390c86cc7d9684cb5	application of if-sets to modeling of lip shapes similarities	dissimilarity measure;shape similarity	This paper is an attempt to apply a similarity/disimilarity measure based on Atanassov IF-Sets to the comparison of lip shapes. A method of encoding lip shapes is presented and a comparison of numerical representations of lips based on the applied measure type is suggested.		Krzysztof Dyczkowski	2010		10.1007/978-3-642-14055-6_64	computer science;pattern recognition;mathematics	Vision	34.19141200881782	-63.61973042477047	173109
821cdda2ea8c48f603fa27e14280c158f873f4b1	local binary pattern and wavelet-based spoof fingerprint detection	texture;biometrics;spoof fingerprints;local binary pattern;fingerprint detection;real fingerprints;finger liveness;ridge frequency;spoofing;ridge orientation;lbp histograms;wavelets	Perspiration phenomenon is very significant to detect liveness of a finger. It requires two consecutive fingerprints to notice perspiration and therefore the method is slow. Some other methods in the literature need extra hardware to detect liveness. To alleviate these problems, in this paper, a new texture-based method which needs only one fingerprint is proposed. It is based on the observation that, real and spoof fingerprints exhibit different textural characteristics. Local binary pattern (LBP) histograms are used to capture these textural details. Wavelet energy features characterising ridge frequency and orientation information are also used for improving the efficiency of the proposed method. Dimensionalities of the feature sets are reduced by running sequential forward floating selection (SFFS). LBP features and wavelet energy features are independently tested on various classifiers: AdaBoost.M1, support vector machine and k-nearest neighbour. Features are also tested on a hybrid classifier formed by fusing all the mentioned earlier classifiers by the ‘majority voting rule’. Fingerprint databases consisting of 185 real, 90 fun-doh and 150 gummy fingerprints are created. Experimental results indicate that, the performance of new liveness detection approach is very promising, as it needs only one fingerprint and no extra hardware to detect vitality.	adaboost;authentication;autostereogram;basis function;belief propagation;binary pattern (image generation);biometrics;computation;database;fingerprint recognition;grayscale;image processing;k-nearest neighbors algorithm;liveness;local binary patterns;performance;spoofing attack;support vector machine;variable rules analysis;wavelet transform	Shankar Bhausaheb Nikam;Suneeta Agarwal	2008	IJBM	10.1504/IJBM.2008.020141	wavelet;computer vision;local binary patterns;speech recognition;computer science;archaeology;pattern recognition;texture;spoofing attack;biometrics	Vision	34.422213859116226	-60.2884411417436	173197
110bcd1e20760150eba866bca46500b883f00066	multiwavemed: a system for medical image retrieval through wavelets transformations	database indexing;biomedical imaging image retrieval feature extraction wavelet transforms image texture image databases spatial databases information retrieval focusing indexing;medical image retrieval;image colour analysis wavelet transforms image texture vectors database indexing image retrieval medical image processing;image indexing;texture features;indexing and retrieval;image texture;wavelet transforms;feature vector;wavelet transform;vectors;medical image;image colour analysis;medical image processing;query by content;software medical image retrieval wavelets transformations feature vectors image texture features query image database daubechies wavelets gabor wavelets query by content operations wavelet transforms medical image characterization image retrieval image indexing;access method;gabor wavelets;image retrieval	This paper presents the MultiWaveMed system, which is a new software allowing to index and retrieve medical images through the comparison of their texture features. The features are extracted by wavelet transforms, and are organized in feature vectors. The system extracts the image texture features, computes the distance between the query image to all images in the database, through the comparison of their features, and retrieve de n most similar images regarding this kind of feature. The proposed system has implemented both Daubechies and Gabor wavelets. The feature vectors extracted from the images are used to organize the images through access methods, which are the basis to perform the query-by-content operations over the images. The focus of this paper is to show the utility of the wavelet transforms on medical image characterization and their suitability for image indexing and retrieval.	content-based image retrieval;database;feature vector;gabor filter;image retrieval;image texture;wavelet transform	Agma J. M. Traina;César A. B. Castañón;Caetano Traina	2003	16th IEEE Symposium Computer-Based Medical Systems, 2003. Proceedings.	10.1109/CBMS.2003.1212781	image texture;computer vision;visual word;image retrieval;computer science;pattern recognition;automatic image annotation;gabor wavelet;information retrieval;wavelet transform	Vision	38.72943102069378	-61.17462909707664	173222
3607b26d59c9abef8dbd730627834cd44e989916	a study on the use of 8-directional features for online handwritten chinese character recognition	conference_paper;gaussian processes;gabor filters;gabor filter 8 directional feature extraction online handwritten chinese character recognition linear size normalization nonlinear shape normalization equidistance resampling directional pattern images gaussian envelope;handwritten chinese character recognition;gabor filter;gaussian processes handwritten character recognition feature extraction gabor filters;character recognition feature extraction shape gabor filters pattern recognition flowcharts computer science smoothing methods image generation text analysis;feature extraction;handwritten character recognition;level 1	This paper presents a study of using 8-directional features for online handwritten Chinese character recognition. Given an online handwritten character sample, a series of processing steps, including linear size normalization, adding imaginary strokes, nonlinear shape normalization, equidistance resampling, and smoothing, are performed to derive a 64/spl times/64 normalized online character sample. Then, 8-directional features are extracted from each online trajectory point, and 8 directional pattern images are generated accordingly, from which blurred directional features are extracted at 8/spl times/8 uniformly sampled locations using a filter derived from the Gaussian envelope of a Gabor filter. Finally, a 512-dimensional vector of raw features is formed. Extensive experiments on the task of recognizing 3755 level-1 Chinese characters in GB2312-80 standard are performed to compare and discern the best setting for several algorithmic choices and control parameters. The effectiveness of the studied approach is confirmed.		Zhen-Long Bai;Qiang Huo	2005	Eighth International Conference on Document Analysis and Recognition (ICDAR'05)	10.1109/ICDAR.2005.34	computer vision;speech recognition;feature extraction;computer science;machine learning;pattern recognition;gaussian process;statistics	Vision	33.96776296046413	-63.79866199106234	173421
d0ca8b2a855a54bf69e718f6415190eba8f076f9	a novel feature extraction method and hybrid tree classification for handwritten numeral recognition	decision tree classifier;learning algorithm;decision tree;feed forward neural network;neural networks;local features;feature extraction;classification system;handwritten numeral recognition;back propagation;geometric structure;artificial neural network;neural network	A hybrid classification system with neural network and decision tree as the classifiers for handwritten numeral recognition is proposed. Firstly a variety of stable and reliable global features are defined and extracted based on the character geometric structures, a novel floating detector is then proposed to detect segments along the left and right profiles of a character image used as local features. The recognition system consists of a hierarchical coarse classification and fine classification. For the coarse classifier: a three-layer feed forward neural network with back propagation learning algorithm is employed to distinguish six subsets {0}, {6}, {8}, {1,7}, {2, 3, 5}, {4, 9} based on the feature similarity of characters extracted. Three character classes namely {0}, {6} and {8} are directly recognized from artificial neural network (ANN). For each of characters in the latter three subsets, a decision tree classifier is built for further fine classification as follows: Firstly, the specific feature-class relationship is heuristically and empirically deduced between the feature primitives and corresponding semantic class. Then, an iterative growing and pruning algorithm is used to form a tree classifier. Experiments demonstrated that the proposed recognition system is robust and flexible and a high recognition rate is reported.	feature extraction	Ping Zhang;Lihui Chen	2002	Pattern Recognition Letters	10.1016/S0167-8655(01)00088-5	feedforward neural network;speech recognition;decision tree learning;feature extraction;computer science;backpropagation;machine learning;decision tree;pattern recognition;time delay neural network;artificial neural network	Vision	32.51111522095249	-65.18773573838845	173612
b2ce29e49e88fac5f7c075a9dfa839b72a1cb12c	fuzzy edge-symmetry features for improved intruder detection	image recognition;fuzzy neural nets;humans shape image edge detection object detection layout motion detection feature extraction robustness image segmentation neural networks;image segmentation;neural networks;multiscale wavelet feature system;improved intruder detection;safety systems;layout;system performance;fuzzy set theory;wavelet transforms;shape;image edge detection;wavelet transforms image recognition fuzzy set theory fuzzy neural nets safety systems;feature extraction;image recognition fuzzy edge symmetry feature improved intruder detection classifiers multiscale wavelet feature system;classifiers;robustness;humans;motion detection;fuzzy edge symmetry feature;object detection	The paper proposes a new set of fuzzy features based on symmetry of edges for improving the accuracy of detecting intruders. We show that the proposed fuzzy edge-symmetry feature-based classifier is comparable to the detection accuracy of a multi-scale wavelet feature system for intruder detection. We also present two approaches to fusing the results of classifiers trained independently on the edge-symmetry and wavelet features. Experimental results clearly indicate the improvement in system performance when the results of the two classifiers are fused.	intruder detection	Narayan Srinivasa;Swarup Medasani;Yuri Owechko;Deepak Khosla	2003		10.1109/FUZZ.2003.1206554	layout;computer vision;feature extraction;shape;computer science;machine learning;pattern recognition;mathematics;computer performance;fuzzy set;image segmentation;system safety;artificial neural network;robustness;wavelet transform	Logic	33.749902235981125	-63.03745656660858	174023
b7aa01a0af6d6b39fb02398f63403cfbc608b033	improving isolated digit recognition using a combination of multiple features	support vector machine isolated handwritten digits feature combination;visual databases feature extraction handwritten character recognition image classification statistical analysis support vector machines;cvl single digit database isolated digit recognition statistical feature structural feature isolated handwritten digit recognition classical pattern recognition problem nonnormalized handwritten digits global statistics moments profile based features projection based features digit contour digit skeleton feature extraction grid sampling image classification one against all svm;feature extraction handwriting recognition transforms support vector machines skeleton databases	This paper investigates the combination of different statistical and structural features for recognition of isolated handwritten digits, a classical pattern recognition problem. The objective of this study is to improve the recognition rates by combining different representations of non-normalized handwritten digits. These features include some global statistics, moments, profile and projection based features and features computed from the contour and skeleton of the digits. Some of these features are extracted from the complete image of digit while others are extracted from different regions of the image by first applying a uniform grid sampling to the image. Classification is carried out using one-against-all SVM. The experiments conducted on the CVL Single Digit Database realized high recognition rates which are comparable to state-of-the-art methods on this subject.	experiment;feature selection;grid computing;mnist database;pattern recognition;sampling (signal processing);statistical classification;support vector machine	Abdeljalil Gattal;Youcef Chibani;Chawki Djeddi;Imran Siddiqi	2014	2014 14th International Conference on Frontiers in Handwriting Recognition	10.1109/ICFHR.2014.81	speech recognition;feature vector;feature;feature extraction;machine learning;pattern recognition;feature	Vision	34.68028077009618	-59.33544661525094	174611
9d7052fa487943f5524e6a6d12f5e92cf24f9b87	a study on dct coefficients of time series pen position data for printed signature verification	handwriting recognition;image segmentation;time series	For the purpose of secure signature verification, it is preferable to use small sized feature data which is stable between genuine signatures and difficult to be mimicked by illegal transactions. Although the turning points extracted from XY position and pressure of pen is one of efficient feature data, they are not suitable for printed signatures written by Chinese or Japanese. This is because the signature consists of a number of segmented straight lines and has a fewer turning points than those of Western signatures. In order to reduce data size of printed signature, we have applied DCT (Discrete Cosine Transform) coefficients of time series XY position to signature verification. However, the DCT spectrum distance between genuine signatures acquired in different times is not small enough to accept. In this paper, we point out that the DCT spectrum distance of genuine signatures after DP matching becomes tremendously small and DCT spectra in low frequency domain has essential individuality. From experimental results using 20 Japanese persons, the 30 DCT spectra of Y position verifies the individuals with 1.7% EER(Equal Error Rate). This EER is similar with the results obtained by the signature verification system in which whole series data of XY position and pressure is used.	antivirus software;classical xy model;coefficient;discrete cosine transform;electronic signature;enhanced entity–relationship model;feature data;printing;time series;type signature	Takahiro Yoshida;Asami Hori;Seiichiro Hangai	2013	2013 8th International Symposium on Image and Signal Processing and Analysis (ISPA)		computer vision;speech recognition;computer science;pattern recognition	Mobile	33.28400527735452	-63.902363624169936	174765
515cd2180d680e70af10c1d6148d4e19d315611e	video forgery detection using correlation of noise residue	bayesian classifier;performance evaluation;video signal processing;gaussian processes;forgery processes video forgery detection noise residue correlation block level correlation values feature extraction gaussian mixture model bayesian classifier optimal threshold value parameter estimation video inpainting schemes;bayes methods;signal detection;image classification;noise correlation forgery streaming media cameras classification algorithms image coding;gaussian mixture model;feature extraction;video signal processing bayes methods feature extraction gaussian processes image classification signal detection	We propose a new approach for locating forged regions in a video using correlation of noise residue. In our method, block-level correlation values of noise residual are extracted as a feature for classification. We model the distribution of correlation of temporal noise residue in a forged video as a Gaussian mixture model (GMM). We propose a two-step scheme to estimate the model parameters. Consequently, a Bayesian classifier is used to find the optimal threshold value based on the estimated parameters. Two video inpainting schemes are used to simulate two different types of forgery processes for performance evaluation. Simulation results show that our method achieves promising accuracy in video forgery detection.	authentication;bayesian network;comparison and contrast of classification schemes in linguistics and metadata;data compression;digital signature;digital video;experiment;google map maker;inpainting;mixture model;naive bayes classifier;performance evaluation;simulation;statistical classification	Chih-Chung Hsu;Tzu-Yi Hung;Chia-Wen Lin;Chiou-Ting Hsu	2008	2008 IEEE 10th Workshop on Multimedia Signal Processing	10.1109/MMSP.2008.4665069	computer vision;contextual image classification;naive bayes classifier;speech recognition;feature extraction;computer science;machine learning;pattern recognition;mixture model;gaussian process;video denoising;detection theory	Vision	35.685606269939356	-61.18905142854276	174785
0ecbfceebcefb18c81b33508f0805c28cfa033d8	scene text extraction based on edges and support vector regression	scene text recognition;scene text segmentation;shape features;scene text detection	This paper presents a scene text extraction technique that automatically detects and segments texts from scene images. Three text-specific features are designed over image edges with which a set of candidate text boundaries is first detected. For each detected candidate text boundary, one or more candidate characters are then extracted by using a local threshold that is estimated based on the surrounding image pixels. The real characters and words are finally identified by a support vector regression model that is trained using bags-of-words representation. The proposed technique has been evaluated over the latest ICDAR-2013 Robust Reading Competition dataset. Experiments show that it obtains superior F-measures of 78.19 % and 75.24 % (on atom level), respectively, for the scene text detection and segmentation tasks.	experiment;pixel;support vector machine	Shijian Lu;Tao Chen;Shangxuan Tian;Joo-Hwee Lim;Chew Lim Tan	2015	International Journal on Document Analysis and Recognition (IJDAR)	10.1007/s10032-015-0237-z	computer vision;speech recognition;computer science;pattern recognition	Vision	36.51622091314606	-64.69699851341312	175465
8384094ce1b342da9eabd2ec939e9bb16ca7ff5c	new local edge binary patterns for image retrieval	image retrieval cs lbp d lbp lebp;image texture image retrieval;image texture;texture image retrieval local edge binary patterns lebp method center symmetric local binary pattern cs lbp direction local binary pattern d lbp texture databases;image retrieval	A new method, called local edge binary patterns (LEBP), is introduced in the paper, which takes the advantages of local binary patterns and local edges into account. Furthermore, several extensions to LEBP are also discussed in detail. Center-symmetric local binary pattern (CS-LBP) and direction local binary pattern (D-LBP) are chosen as examples to prove the performance of the new method on two commonly used texture databases. Experimental results show that LEBP can greatly improve the performance of the traditional local binary patterns in texture image retrieval.	binary pattern (image generation);database;image retrieval;local binary patterns	Junding Sun;Guoliang Fan;Xiaosheng Wu	2013	2013 IEEE International Conference on Image Processing	10.1109/ICIP.2013.6738827	image texture;computer vision;local binary patterns;binary image;image retrieval;computer science;machine learning;pattern recognition	Vision	37.42808094803381	-59.82286273186033	176111
384c2727b364ab27ca6d933302b2761913cbb35c	mouth covered detection for yawn	t technology general;edge detection;database yawn fatigue mouth covered destortion detection;distortion measurement;sleep;artificial neural networks;face recognition;sff database;distortion measurement artificial neural networks;lbp features;sleep edge detection face recognition;sleep deprivation experiments mouth covered detection fatigue sign phenomena yawn detection mouth opening measurement spontaneous human action local binary pattern features lbp features facial distortions wrinkles sobel edge detector strathclyde facial fatigue database sff database fatigue signs;sobel edge detector;electrical engineering electronics nuclear engineering	Yawn is one of the common fatigue sign phenomena. The common technique to detect yawn is based upon the measurement of mouth opening. However, the spontaneous human action to cover the mouth during yawn can prevent such measurements. This paper presents a new technique to detect the covered mouth by employing the Local Binary Pattern (LBP) features. Subsequently, the facial distortions during the yawn process are identified by measuring the changes of wrinkles using Sobel edges detector. In this research the Strathclyde Facial Fatigue (SFF) database that contains genuine fatigue signs is used for training, testing and evaluation of the developed algorithms. This database was created from sleep deprivation experiments that involved twenty participants.	algorithm;distortion;experiment;facial recognition system;learning classifier system;local binary patterns;opening (morphology);sobel operator;spontaneous order;statistical classification	Masrullizam Mat Ibrahim;John S. Soroghan;Lykourgos Petropoulakis	2013	2013 IEEE International Conference on Signal and Image Processing Applications	10.1109/ICSIPA.2013.6707983	facial recognition system;computer vision;speech recognition;edge detection;computer science;sleep;artificial neural network	Robotics	33.27159553137448	-62.187123768912166	176601
3cded5def4b669d84da3eed45708c94c2d5dab11	bird and whale species identification using sound images		Image identification of animals is mostly centred on identifying them based on their appearance, but there are other ways images can be used to identify animals, including by representing the sounds they make with images. In this study, the authors present a novel and effective approach for automated identification of birds and whales using some of the best texture descriptors in the computer vision literature. The visual features of sounds are built starting from the audio file and are taken from images constructed from different spectrograms and from harmonic and percussion images. These images are divided into sub-windows from which sets of texture descriptors are extracted. The experiments reported in this study using a dataset of Bird vocalisations targeted for species recognition and a dataset of right whale calls targeted for whale detection (as well as three well-known benchmarks for music genre classification) demonstrate that the fusion of different texture features enhances performance. The experiments also demonstrate that the fusion of different texture features with audio features is not only comparable with existing audio signal approaches but also statistically improves some of the stand-alone audio features. The code for the experiments will be publicly available at https://www.dropbox.com/s/bguw035yrqz0pwp/ElencoCode.docx?dl=0.		Loris Nanni;Rafael de Lima Aguiar;Yandre M. G. Costa;Sheryl Brahnam;Carlos Nascimento Silla;Ricky L. Brattin;Zhao Zhao	2018	IET Computer Vision	10.1049/iet-cvi.2017.0075	whale;audio signal;artificial intelligence;mathematics;software;pattern recognition;spectrogram;right whale	Vision	34.074849345515666	-61.45123429751995	176871
b81e1165a983ba8d45e26cb022dd7a1f8bb8c3f0	lbp-based ear recognition	object recognition;biometrics access control;recognition rate lbp based ear recognition biometrics fingerprint recognition face recognition iris recognition medical field local binary patterns principal components analysis pca global illumination changes indian institute of technology iit delhi ear image database;ear face face recognition principal component analysis fingerprint recognition histograms;principal component analysis biometrics access control feature extraction object recognition;feature extraction;principal component analysis	The ear, as a biometric, has been given less attention, compared to other biometrics such as fingerprint, face and iris. Since it is a relatively new biometric, no commercial applications involving ear recognition are available. Intensive research in this field is thus required to determine the feasibility of this biometric. In medical field, especially in case of accidents and death, where face of patients cannot be recognized, the use of ear can be helpful. In this work, yet another method of recognizing people through their ears is presented. Local Binary Patterns (LBP) is used as features and the results are compared with that of Principal Components Analysis (PCA). LBP has a high discriminative power, tolerance against global illumination changes and low computational load. Experiments were done on the Indian Institute of Technology (IIT) Delhi ear image database and results show that LBP yields a recognition rate of 93 % while PCA gives only 85 %.	belief propagation;biometrics;computation;experiment;fingerprint;global illumination;integrated information theory;local binary patterns;principal component analysis;yet another	N. B. Boodoo-Jahangeer;S. Baichoo	2013	13th IEEE International Conference on BioInformatics and BioEngineering	10.1109/BIBE.2013.6701687	computer vision;speech recognition;feature extraction;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;three-dimensional face recognition;principal component analysis	Vision	32.8229016478924	-59.342421136876624	176987
7d3f3e79ff4423e1d958ce0ae9bdb61bed5a287d	improved gabor filtering application in the identification of handwriting	feature extraction;multi-channel gabor wavelet transform;handwriting identification;texture analysis	In this paper, handwriting image will be regarded as a texture image,The textural features of it were extracted by Improved multi-channel 2-D Gabor filtering,and was added in the features database as the basis for the identification of handwriting after processed.This is a content independent method,with a broad applicability.the speed and accuracy of identification were increased after optimizing the parameters of Gabor filtering, the author also made a lot of experiments by the platform of vc++6.0, it proved the effectiveness of the algorithm.	algorithm;experiment;gabor filter	Yongping Liu;Xiaobo Guo	2008	Computer and Information Science		computer vision;speech recognition;computer science;pattern recognition;gabor wavelet	Vision	34.015967707368034	-62.84751932717502	176997
13c6ba987a5b97311fd6f18ba904514e8eb41f57	arabic handwriting recognition using projection profile and genetic approach	handwriting recognition;image segmentation;feature extraction algorithm offline arabic handwriting recognition projection profile genetic algorithm segmentation phases;segmentation;genetics;segmentation phases;biological cells;shape;natural language processing feature extraction genetic algorithms handwriting recognition image segmentation;feature extraction;pixel;thinning character recognition genetic algorithm feature extraction segmentation;projection profile;feature extraction algorithm;offline arabic handwriting recognition;genetic algorithm;genetic algorithms;shape feature extraction biological cells character recognition pixel handwriting recognition image segmentation;character recognition;natural language processing;thinning	This paper presents a complete system to recognize off-line Arabic handwriting. The proposed system starts from preprocessing and segmentation phases. It also includes thinning phase and finds vertical and horizontal projection profiles. The recognition phase is managed by genetic algorithm. The genetic algorithm stands on feature extraction algorithm that defines six features for each segment.	feature extraction;genetic algorithm;handwriting recognition;iteration;online and offline;preprocessor;thinning	Hanan Aljuaid;Dzulkifli Mohamad;Muhammad Sarfraz	2009	2009 Fifth International Conference on Signal Image Technology and Internet Based Systems	10.1109/SITIS.2009.29	computer vision;speech recognition;genetic algorithm;computer science;machine learning;pattern recognition;handwriting recognition	Robotics	33.24012115514383	-66.10972257503005	177292
af007e9a9b0d1d7a476ed8a6d6f2c6e18317d703	the problem of handwritten mathematical expression recognition evaluation	mathematical expressions;databases;benchmarking;grammar;handwriting recognition;database;dataset handwritten mathematical expression recognition evaluation benchmarking systems;layout;mathematical analysis;benchmarking systems;manganese;data structures;mathematical analysis handwriting recognition;pixel;handwritten mathematical expression recognition evaluation;evaluation;ground truth;layout handwriting recognition databases pixel manganese labeling grammar;evaluation online handwriting recognition mathematical expressions data structures benchmarking database;data structure;online;labeling;dataset	We discuss in this paper some issues related to the problem of mathematical expression recognition. The very first important issue is to define how to ground truth a dataset of handwritten mathematical expressions, and next we have to face the problem of benchmarking systems. We propose to define some indicators and the way to compute them so as they reflect the actual performances of a given system.	ground truth;performance	Ahmad-Montaser Awal;Harold Mouchère;Christian Viard-Gaudin	2010	2010 12th International Conference on Frontiers in Handwriting Recognition	10.1109/ICFHR.2010.106	layout;speech recognition;data structure;ground truth;computer science;manganese;evaluation;machine learning;pattern recognition;data mining;grammar;pixel;benchmarking	Vision	38.485240357132334	-63.44729843880826	178013
bb2aa463a5f112d286e57cc984eaf6196f205b74	robust palm print verification system based on evolution of kernel principal component analysis	kernel;smart phones;rsde robust palm print verification system biometric trait image quality fingerprint identification feature extraction evolution of kernel principal component analysis weighted gram matrix android mobile evo kpca region of interest roi genuine acceptance rate reduced set density estimate;fingerprint recognition;feature extraction;feature extraction principal component analysis kernel fingerprint recognition smart phones face equations;principal component analysis;palm print evo kpca rsde weighted gram matrix;face;principal component analysis feature extraction fingerprint identification matrix algebra palmprint recognition	Palm print is an emerging type of biometric that attracts researchers in biometrics area. As compared to the other biometric traits such as face, fingerprint and iris, the image quality of a fingerprint is robust with more information can be employed even though it is in low resolution. A new approach in feature extraction called evolution of kernel principal component analysis (Evo-KPCA) was proposed to speed up the processing time in the extraction stage. It used a reduced set density estimate (RSDE) to define a weighted gram matrix. As a result, the Evo-KPCA only extracted the most relevant and important information from a dataset. A total of 2400 palm print images was collected from three types of android mobiles. An experimental evaluation showed that the Evo-KPCA performed well in term of processing and accuracy compared to the region of interest (ROI), principle component analysis (PCA) and kernel principal component (KPCA) with the Genuine Acceptance Rates (GAR) of more than 98% and shorter processing time of less than 0.5s.	android;biometrics;compaq evo;feature extraction;fingerprint;gramian matrix;image quality;image resolution;kernel (operating system);kernel principal component analysis;palm print;region of interest	Salwani Ibrahim;Haryati Jaafar;Dzati Athiar Ramli	2014	2014 IEEE International Conference on Control System, Computing and Engineering (ICCSCE 2014)	10.1109/ICCSCE.2014.7072715	computer vision;speech recognition;engineering;pattern recognition	Vision	33.731228420528936	-60.301410233617744	179447
8799e545c7194f21cb239ee98c49bed16ccd442c	algorithm of traffic signs recognition based on the rapid transform		This paper presents a model of a system for invariant object recognition, which consists of five stages. The first stage shifts the object so that the centroid of the object coincides with the center of the image plane. The second stage is an application of the polar-coordinate transforms used to obtain N-dimensional vectors-representations of the input object. In this stage, any rotation of the input object becomes a cyclic shift of the output value of this stage. The third stage employs CT (Certain Transform), a class of shift-invariant transformations to provide invariant representations for cyclically shifted inputs. The next stage normalizes the outputs of the previous stage to obtain scale invariance. The final stage realizes a classification.	algorithm;binary image;circular shift;edge detection;emoticon;experiment;grayscale;image plane;outline of object recognition;parameter (computer programming);preprocessor;traffic sign recognition	Ján Gamec;Daniel Urdzik;Mária Gamcová	2012	Central European Journal of Computer Science	10.2478/s13537-012-0019-3	computer vision;control theory;mathematics;communication	Vision	35.10001257578919	-59.27642970346438	179552
6606802f2845014124cb6365d3b942c4e295f1ae	feature matching performance of compact descriptors for visual search	greedy rate allocation scheme;feature level roc;descriptor compression;image coding;feature matching performance;lattices;image matching;comprehensive patch level experiment;resource management;mpeg cdvs image level data sets;greedy algorithms;feature level roc feature matching performance compact descriptors for visual search descriptor extraction descriptor compression comprehensive patch level experiment image patch matching pairs mpeg cdvs image level data sets greedy rate allocation scheme bits distribution spatial bins sift descriptor entropy constrained vector quantization receiver operating characteristic;quantization signal;visual perception entropy feature extraction greedy algorithms image coding image matching image retrieval sensitivity analysis vector quantisation;transform coding;receiver operating characteristic;bit rate;descriptor extraction;resource management quantization signal transform coding image coding bit rate lattices encoding;entropy constrained vector quantization;sensitivity analysis;feature extraction;bits distribution;visual perception;entropy;spatial bins;vector quantisation;image patch matching pairs;encoding;compact descriptors for visual search;feature compression;sift descriptor;image retrieval	MPEG is currently developing a standard titled Compact Descriptors for Visual Search (CDVS) for descriptor extraction and compression. In this work, we report comprehensive patch-level experiments for a direct comparison of low bitrate descriptors for visual search. For evaluating different compression schemes, we propose a dataset of matching pairs of image patches from the MPEG-CDVS image-level data sets. We propose a greedy rate allocation scheme for distributing bits across different spatialbins of the SIFT descriptor. We study a scheme based on Entropy Constrained Vector Quantization and greedy rate allocation, which performs close to the performancebound for any compression scheme. Finally, we present extensive feature-level Receiver Operating Characteristic (ROC) comparisons for different compression schemes (VectorQuantization, Transform Coding, Lattice Coding) proposed during the MPEG-CDVS standardization process.	experiment;greedy algorithm;mpeg multichannel;moving picture experts group;receiver operating characteristic;transform coding;vector quantization	Vijay Chandrasekhar;Gabriel Takacs;David M. Chen;Sam S. Tsai;Mina Makar;Bernd Girod	2014	2014 Data Compression Conference	10.1109/DCC.2014.50	computer vision;entropy;greedy algorithm;transform coding;visual perception;feature extraction;image retrieval;computer science;resource management;machine learning;pattern recognition;lattice;mathematics;sensitivity analysis;receiver operating characteristic;encoding;statistics	ML	37.67151612868747	-60.5651169529888	179848
a7e218f4bab272ab30f7459c6338c2eea2715607	improved image retrieval using fast colour-texture features with varying weighted similarity measure and random forests		Content-based image retrieval (CBIR) retrieves images from image database based on the visual similarity of query image. For the implementation of CBIR, feature extraction plays a significant role, where colour feature is quite remarkable. But, due to achromatic surfaces or unevenly colored, the role of texture is also important. This paper introduced an efficient and fast CBIR system, which is based on the combination of computationally light weighted colour and texture features viz. chromaticity moment, colour percentile, and local binary pattern. For searching, this paper proposes inverse variance based varying weighted similarity measure (low for high variance feature and high for low variance feature), which reduces the effect of redundancy by assigning the priority to each feature, and effectively retrieves relevant images. In addition, this paper also proposes query image classification and retrieval model by filtering out irrelevant class images using Random Forests (RF) classifier, which recovers the class of a query image based on distinct learning (supervised) of various decision trees. This successful ensemble classification of query images reduces the semantic gap, searching space, and enhances the retrieval performance. Extensive experimental analyses on benchmark databases confirm the usefulness and effectiveness of this work.	benchmark (computing);binary pattern (image generation);computer vision;content-based image retrieval;database;decision tree;feature extraction;high- and low-level;local binary patterns;machine learning;radio frequency;random forest;redundancy (engineering);relevance;similarity measure;supervised learning;viz: the computer game	Vibhav Prakash Singh;Rajeev Srivastava	2017	Multimedia Tools and Applications	10.1007/s11042-017-5036-8	visual word;computer science;artificial intelligence;feature (computer vision);local binary patterns;computer vision;content-based image retrieval;similarity measure;pattern recognition;feature extraction;image retrieval;contextual image classification	Vision	36.93657573145524	-59.36138928542805	179917
57bfb4e78573d0ae856f5d3b48b317d5bda95280	an automated hierarchical framework for player recognition in sports image		The recognition of player in the soccer game is a challenging task due to the continuous variation in the position, view, orientation and distance of the players as well as the camera. In order to resolve this problem, the playeru0027s identification number (which is printed on their jersey) is recognized and based on the number, players are identified. This paper proposes a noble Optical Character Recognition (OCR) system that automatically extracts and recognizes the playeru0027s jersey number in the image. A hierarchical computational framework is introduced which uses high and low-level vision features of the image to identify the player. While following the hierarchical approach a parsing tree is constructed by segmenting the image into snippets based on different algorithms. The entire parsing tree is divided into 4 levels: Level 1 deals with the playfield detection and shot classification, Level 2 tackles the player localization and extraction, Level 3 covers the playeru0027s number extraction and shape restoration, and Level 4 recognizes the playeru0027s number. The proposed OCR system has consistently shown outstanding results in terms of efficiency, effectiveness, and robustness over a large soccer dataset.	algorithm;circuit restoration;high- and low-level;identifier;optical character recognition;parse tree;parsing;printing	Abhay Atrish;Navjot Singh;Krishan Kumar;Vinod Kumar	2017		10.1145/3177404.3177432	market segmentation;optical character recognition;robustness (computer science);parsing;artificial intelligence;computer science;pattern recognition	Vision	36.22948962905262	-64.43575565958108	180299
7ff970146fcdfddfe288ed31a96174de51a1cf80	detecting driver drowsiness using feature-level fusion and user-specific classification	fec;asm;eye state classification;nhtsa;perclos;esd value;cca;lda;drowsiness detection system;user specific classification;lbp;phogs;eer;svm;glcm;roi;feature level fusion;grbf;pca;blink detection;ecd	Accurate classification of eye state is a prerequisite for preventing automobile accidents due to driver drowsiness. Previous methods of classification, based on features extracted for a single eye, are vulnerable to eye localization errors and visual obstructions, and most use a fixed threshold for classification, irrespective of variations in the driver’s eye shape and texture. To address these deficiencies, we propose a new method for eye state classification that combines three innovations: (1) extraction and fusion of features from both eyes, (2) initialization of driver-specific thresholds to account for differences in eye shape and texture, and (3) modeling of driver-specific blinking patterns for normal (non-drowsy) driving. Experimental results show that the proposed method achieves significant improvements in detection accuracy. 2013 Elsevier Ltd. All rights reserved.	energy citations database;facial recognition system;online and offline;onset (audio);sensor	Jaeik Jo;Sung Joo Lee;Kang Ryoung Park;Ig-Jae Kim;Jaihie Kim	2014	Expert Syst. Appl.	10.1016/j.eswa.2013.07.108	support vector machine;computer vision;return on investment;speech recognition;computer science;machine learning;pattern recognition;assembly language;principal component analysis	AI	32.54340325298107	-59.54856947476548	180524
c87e73189ad00f72db30516d52930cd739745dff	using confusing characters to improve character recognition rate	optical character recognition;character recognition optical character recognition software vocabulary shape image recognition optical network units handwriting recognition computer science information analysis optical computing;proceedings paper;character recognition;reversed rank weight confusing characters character recognition rate confusion set analysis approach ocr system	This paper proposes a confusion set analysis approach to increasing character recognition rate. In the training phase, top five candidates are outputted from an OCR system. Each candidate is assigned a weight in reversed-rank. If the reversed-rank sum of an output candidate is greater than a threshold, the input character is stored in the confusion set of the output candidate. In the recognition phase, the characters in the confusion set with respect to the output character are recognized by another OCR system to find the final recognition result.	optical character recognition	Hsi-Jian Lee;Yeu-Chang Lin	1998		10.1109/ICSMC.1998.727503	arithmetic;speech recognition;document processing;intelligent character recognition;computer science;intelligent word recognition;optical character recognition	Robotics	33.510871479661446	-65.94571915207389	181207
738a0305faa7c220933cf2222e36e2c3c91534a1	accent detection in handwriting based on writing styles	handwriting recognition;support vector machines;writing feature extraction speech recognition fractals accuracy handwriting recognition conferences;support vector machines feature extraction handwriting recognition image classification learning artificial intelligence object detection;image classification;latent dirichlet allocation accent detection handwriting writing style multilingual writer english;latent dirichlet allocation;topic models accents in handwriting handwriting styles modeling;conference paper;feature extraction;topic models;accents in handwriting;learning artificial intelligence;handwriting styles modeling;object detection	Accent in handwriting can be defined as the influence of a writer's native script on his/her writing style in another script. In this paper, we approach the problem of detecting the existence of accents in handwriting. We approach this problem using two sets of writers, those who can write only in English, and the other set being multilingual writers who can also write in English. We learn the writing styles that are predominant in each set and use it as features in classification. Latent Dirichlet Allocation is used to learn the distribution over writing styles. Experimental results suggest the existence of accents in handwriting.	biometrics;document retrieval;handwriting recognition;heart rate variability;latent dirichlet allocation;optical character recognition;overwriting (computer science);sensor;speech recognition;statistical classification	Chetan Ramaiah;Utkarsh Porwal;Venu Govindaraju	2012	2012 10th IAPR International Workshop on Document Analysis Systems	10.1109/DAS.2012.13	latent dirichlet allocation;natural language processing;support vector machine;contextual image classification;speech recognition;feature extraction;intelligent character recognition;computer science;machine learning;pattern recognition;handwriting recognition;topic model	NLP	33.23746649329971	-64.69079035377911	181636
b41655a34686bf819bf83d3790b5005e253f4cb5	a comparison of wavelet transform features for texture image annotation	search and retrieval;content based search;texture image annotation;wavelet transforms gabor filters image retrieval indexing image texture analysis content based retrieval image processing information retrieval feature extraction image analysis;image processing;band pass filters;information retrieval;texture classification;wavelet transform features;image classification;gabor filters;image annotation;texture features;gabor wavelet transforms;orthogonal wavelet transforms;image texture;wavelet transforms;wavelet transform;filter banks wavelet transform features texture image annotation texture features content based search content retrieval biorthogonal wavelet transforms orthogonal wavelet transforms tree structured decompositions gabor wavelet transforms image processing complexity texture classification texture discrimination indexing techniques;indexing;biorthogonal wavelet transforms;feature extraction;indexation;tree structure;tree structured decompositions;image analysis;indexing techniques;image texture analysis;search problems;filter banks;texture discrimination;content retrieval;search problems image texture feature extraction wavelet transforms image classification indexing information retrieval band pass filters filtering theory;gabor wavelets;content based retrieval;image processing complexity;filtering theory;image retrieval	A comparison of different wavelet transform based texture features for content based search and retrieval is made. These include the conventional orthogonal and bi-orthogonal wavelet transforms, tree-structured decompositions, and the Gabor wavelet transforms. Issues discussed include image processing complexity, texture classification and discrimination, and suitability for developing indexing techniques.	automatic image annotation;wavelet transform	Wei-Ying Ma;B. S. Manjunath	1995		10.1109/ICIP.1995.537463	image texture;wavelet;computer vision;image analysis;second-generation wavelet transform;image processing;image retrieval;computer science;pattern recognition;wavelet packet decomposition;discrete wavelet transform;fast wavelet transform;lifting scheme;gabor wavelet;information retrieval;wavelet transform	Vision	38.97028581016428	-61.38120522762611	181854
09f92ef47db267ed1f78235e2dd11574fdc1bad1	hybrid off-line cursive handwriting word recognition	image recognition;handwriting recognition;character pixels;offline cursive handwriting word recognition;image recognition feature extraction handwritten character recognition;iam cursive handwriting database offline cursive handwriting word recognition word image normalization robust hybrid feature extraction character pixels;feature extraction;robust hybrid feature extraction;handwriting recognition image segmentation robustness feature extraction pixel image matching computational intelligence laboratories informatics testing;iam cursive handwriting database;word recognition;word image normalization;handwritten character recognition	In this paper, we present an off-line cursive word handwriting recognition methodology. This is based on an additive fusion resulted after a novel combination of two different modes of word image normalization and robust hybrid feature extraction. We employ two types of features in a hybrid fashion. The first one, divides the word image into a set of zones and calculates the density of the character pixels in each zone. In the second type of features, we calculate the area that is formed from the projections of the upper and lower profile of the word. The performance of the proposed methodology is demonstrated after testing with the reference IAM cursive handwriting database	feature extraction;handwriting recognition;identity management;online and offline;pixel;utility functions on indivisible goods	Basilios Gatos;Ioannis Pratikakis;Stavros J. Perantonis	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.644	natural language processing;computer vision;speech recognition;feature extraction;word recognition;intelligent character recognition;computer science;intelligent word recognition;machine learning;pattern recognition;handwriting recognition	Vision	33.123761591204385	-65.74278806524761	182099
8cdeb22da1ab67b6040f7f456f61ba15f33c4d58	letter recognition using holland-style adaptive classifiers	category learning;parallel rule-based systems;exemplar-based induction;apportionment of credit;fuzzy-match rule activation	Machine rule induction was examined on a difficult categorization problem by applying a Holland-style classifier system to a complex letter recognition task. A set of 20,000 unique letter images was generated by randomly distorting pixel images of the 26 uppercase letters from 20 different commercial fonts. The parent fonts represented a full range of character types including script, italic, serif, and Gothic. The features of each of the 20,000 characters were summarized in terms of 16 primitive numerical attributes. Our research focused on machine induction techniques for generating IF-THEN classifiers in which the IF part was a list of values for each of the 16 attributes and the THEN part was the correct category, i.e., one of the 26 letters of the alphabet. We examined the effects of different procedures for encoding attributes, deriving new rules, and apportioning credit among the rules. Binary and Gray-code attribute encodings that required exact matches for rule activation were compared with integer representations that employed fuzzy matching for rule activation. Random and genetic methods for rule creation were compared with instance-based generalization. The strength/specificity method for credit apportionment was compared with a procedure we call “accuracy/utility.“		Peter W. Frey;David J. Slate	1991	Machine Learning	10.1007/BF00114162	rule-based system;gray code;computer science;artificial intelligence;machine learning;pattern recognition	ML	33.78837085080493	-65.40848409536711	182220
c84065fe78ace456f79a493dfd022cc932729125	content-based image retrieval using moments of local ternary pattern	geometric moments;content based image retrieval;local ternary pattern;image retrieval	Due to the availability of large number of digital images, development of an efficient content-based indexing and retrieval method is required. Also, the emergence of smartphones and modern PDAs has further substantiated the need of such systems. This paper proposes a combination of Local Ternary Pattern (LTP) and moments for Content-Based Image Retrieval. Image is divided into blocks of equal size and LTP codes of each block are computed. Geometric moments of LTP codes of each block are computed followed by computation of distance between moments of LTP codes of query and database images. Then, the threshold using distance values is applied to retrieve images similar to the query image. Performance of the proposed method is compared with other state-of-the-art methods on the basis of results obtained on Corel-1,000 database. The comparison shows that the proposed method gives better results in terms of precision and recall as compared to other state-of-the-art image retrieval methods.	content-based image retrieval	Prashant Srivastava;Thanh Binh Nguyen;Ashish Khare	2014	MONET	10.1007/s11036-014-0526-7	computer vision;visual word;image retrieval;computer science;theoretical computer science;information retrieval	Vision	37.96397874351333	-59.860466300740626	182384
b5e426b081fb7f2b0761433a627a0903bd5a5478	a recognition system for online handwritten tibetan characters	de noising;pre processing;three stage classification;online handwritten tibetan character recognition	This paper describes a recognition system for online handwritten Tibetan characters using advanced techniques in character recognition. To eliminate noise points of handwriting trajectories, we introduce a de-noising approach by using dilation, erosion, thinning operators of the mathematical morphology. Selecting appropriate structuring elements, we can clear up large amounts of noises in the glyphs of the character. To enhance the recognition performance, we adopt three-stage classification strategy, where the top rank output classes by the baseline classifier are re-classified by similar character discrimination classifier. Experiments have been carried out on two databases MRG-OHTC and IIP-OHTC. Test results show the used recognition algorithm is effective and can be applied in pen-based mobile devices.		Long-Long Ma;Jian Wu	2011		10.1007/978-3-642-36824-0_10	speech recognition;intelligent character recognition;intelligent word recognition;pattern recognition	Theory	33.31014443943343	-65.39100834922505	182686
009480859dc865a19cc2ec37912f46fed3389e0f	a new method for arbitrarily-oriented text detection in video	gradient pixel direction;hua data;video text representative;text line direction;dominant text pixels;neighboring word patch grouping;arbitrarily oriented text detection video text frame gradient direction dominant text pixels video text representative angular region growing;sobel edge pixels;gradient direction;video retrieval edge detection feature extraction text detection;image resolution;cameras image edge detection feature extraction classification algorithms image resolution educational institutions pattern recognition;information extraction;edge detection;dominant text pixel selection;institute for integrated and intelligent systems;nonhorizontal data;conference output;faculty of science environment engineering and technology;video text frame;video retrieval;indexing and retrieval;f measure arbitrarily oriented text detection video frames information extraction system video indexing video retrieval dominant text pixel selection text representatives region growing gradient pixel direction sobel edge pixels edge components neighboring text component grouping sobel edge map extraction broken segments word patches text line direction neighboring word patch grouping missing text information restoration arbitrarily oriented data nonhorizontal data hua data icdar 2003 competition data camera images;computer vision;video indexing;camera images;arbitrarily oriented text detection;broken segments;word patches;image edge detection;feature extraction;neighboring text component grouping;classification algorithms;arbitrarily oriented data;pattern recognition;video frames;icdar 2003 competition data;f measure;text detection;sobel edge map extraction;missing text information restoration;region growing;text representatives;080104;information extraction system;cameras;angular region growing;edge components	Text detection in video frames plays a vital role in enhancing the performance of information extraction systems because the text in video frames helps in indexing and retrieving video efficiently and accurately. This paper presents a new method for arbitrarily-oriented text detection in video, based on dominant text pixel selection, text representatives and region growing. The method uses gradient pixel direction and magnitude corresponding to Sobel edge pixels of the input frame to obtain dominant text pixels. Edge components in the Sobel edge map corresponding to dominant text pixels are then extracted and we call them text representatives. We eliminate broken segments of each text representatives to get candidate text representatives. Then the perimeter of candidate text representatives grows along the text direction in the Sobel edge map to group the neighboring text components which we call word patches. The word patches are used for finding the direction of text lines and then the word patches are expanded in the same direction in the Sobel edge map to group the neighboring word patches and to restore missing text information. This results in extraction of arbitrarily-oriented text from the video frame. To evaluate the method, we considered arbitrarily-oriented data, non-horizontal data, horizontal data, Hua's data and ICDAR-2003 competition data (Camera images). The experimental results show that the proposed method outperforms the existing method in terms of recall and f-measure.	f1 score;frame (video);gradient;information extraction;perimeter;pixel;region growing;sobel operator	Nabin Sharma;Palaiahnakote Shivakumara;Umapada Pal;Michael Blumenstein;Chew Lim Tan	2012	2012 10th IAPR International Workshop on Document Analysis Systems	10.1109/DAS.2012.6	computer vision;speech recognition;edge detection;image resolution;feature extraction;computer science;machine learning;pattern recognition;region growing;f1 score;information extraction	NLP	37.070310201405945	-63.971896077236636	182727
9dba2379d16f82d52cab505a92ce646792fab994	application of pr techniques to mail sorting in china	pattern recognition technique;address recognition;mail sorting machine;near duplicate image matching;postcode recognition	Mail sorting machines play an important role in postal automation. In this paper, we give a brief overview of mail sorting machines in China Post from a pattern recognition point of view. OCR techniques such as postcode recognition and address recognition are essential for mail sorting machines, which are considered as class imbalance problems in our study. In addition to OCR that mainly focuses on the characters in the image, some image-level features are exploited for near-duplicate envelope image matching, which is helpful in tracking pieces of mail in the network environment.	image registration;optical character recognition;pattern recognition;point of view (computer hardware company);postal;sorting	Li Liu;Shujing Lu;Yue Lu;Ching Y. Suen	2014		10.1145/2641483.2641536	speech recognition;computer science;data mining;world wide web	AI	34.88387743134224	-65.15762659194456	183041
486204f56d1ba9be67b04bd998752d7c6d0942da	em-based layout analysis method for structured documents	image segmentation;training;semantics;text analysis;layout;computational modeling;covariance matrices;document analysis layout analysis em based algorithm gaussian mixtures logical distribution convergence record detection historical structured documents;gaussian processes convergence document image processing expectation maximisation algorithm;layout image segmentation training computational modeling semantics covariance matrices text analysis	In this paper we present a method to perform layout analysis in structured documents. We proposed an EM-based algorithm to fit a set of Gaussian mixtures to the different regions according to the logical distribution along the page. After the convergence, we estimate the final shape of the regions according to the parameters computed for each component of the mixture. We evaluated our method in the task of record detection in a collection of historical structured documents and performed a comparison with other previous works in this task.	algorithm;approximation algorithm;benchmark (computing);document layout analysis;expectation–maximization algorithm;fragmentation (computing);international conference on document analysis and recognition;iteration;linear separability;need to know;open research;pixel;sensor;speedup;test set	Francisco Cruz;Oriol Ramos Terrades	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.63	layout;computer vision;computer science;machine learning;document layout analysis;pattern recognition;data mining;semantics;image segmentation;computational model	Vision	36.020212581678784	-65.75172330629506	185263
0c6a566ebdac4bd14e80cd6bf4631bc7458e1595	local descriptors in application to the aging problem in face recognition	local descriptors;face recognition;aging process;local binary patterns;face detection;gabor wavelets	Local descriptors are widely used in face recognition due to their robustness to changes in expression or occlusion in facial images. In this paper, a comparison of local descriptors commonly used in face recognition methods is presented in the context of age changes of individuals. We quantify abilities of local descriptors used in face recognition in the context of age discrimination. The performance of the descriptors is evaluated by experimenting with the FG-NET database. We present the results for different age groups and for various age differences of individuals present in the training and testing images. The values of recognition accuracy are reported in combination with various similarity measures used for classification purposes. Moreover, the performance of the descriptors combined with Gabor wavelet images is tested. & 2013 Elsevier Ltd. All rights reserved.	color gradient;entity;experiment;facial recognition system;gabor filter;gabor wavelet;job control (unix);local binary patterns;statistical classification	Michal Bereta;Pawel Karczmarek;Witold Pedrycz;Marek Reformat	2013	Pattern Recognition	10.1016/j.patcog.2013.03.010	facial recognition system;computer vision;face detection;local binary patterns;computer science;machine learning;pattern recognition;three-dimensional face recognition	Vision	32.788637548365685	-59.25118632183839	185432
21cf4f227d2320abe12c289e6a0d3b636f57f076	an iris recognition method based on zigzag collarette area and asymmetrical support vector machines	asymmetrical support vector machines;mahalanobis distance;image recognition;personal identification pattern;image segmentation;mahalanobis distance iris recognition zigzag collarette area asymmetrical support vector machines iris segmentation chain code personal identification pattern feature extraction gabor wavelet backpropagation neural network k nearest neighbor hamming distance;backpropagation neural network;support vector machines;chain code;biometrics access control;iris recognition;iris recognition support vector machines support vector machine classification pattern recognition eyelids eyelashes feature extraction system performance backpropagation neural networks;backpropagation;satisfiability;support vector machines backpropagation biometrics access control feature extraction image recognition image segmentation pattern classification;iris segmentation;system performance;zigzag collarette area;gabor wavelet;hamming distance;security requirements;feature extraction;pattern classification;k nearest neighbor;support vector machine;gabor wavelets	We propose an improved iris recognition method for person identification using an iris segmentation approach based on chain code and zigzag collarette area with support vector machine (SVM). The zigzag collarette area is selected as a personal identification pattern which captures only the most important areas of iris complex pattern and better recognition accuracy is achieved. The idea to use the zigzag collarette area is that it is insensitive to the pupil dilation and usually not affected by eyelids or eyelashes. The deterministic feature sequence is extracted from iris images using Gabor wavelet technique and used to train SVM as iris classifiers. The traditional SVM is modified as asymmetrical SVM to treat False Accept and False Reject differently to satisfy several security requirements. The parameters of SVM are tuned to improve overall system performance. Our experimental results also indicate that the performance of SVM as a classifier is far better than the performance of backpropagation neural network (BPNN), K-nearest neighbor (KNN), Hamming and Mahalanobis distance. The proposed innovative technique is computationally effective as well as reliable in term of recognition rate of 99.56%.	artificial neural network;backpropagation;chain code;dilation (morphology);gabor wavelet;iris recognition;k-nearest neighbors algorithm;requirement;support vector machine;window function	Kaushik Roy;Prabir Bhattacharya	2006	2006 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2006.384497	support vector machine;computer vision;computer science;machine learning;pattern recognition;computer performance;gabor wavelet	ML	33.43211598017422	-63.00426785278192	185616
3b215b2d12616cf2209a31f9fc5890c36d3c19ae	conspicuous character patterns	character synthesis;detectors;histograms;conspicuous pattern character synthesis character detection;text analysis;conspicuous pattern;data mining;conspicuous character patterns;optical character recognition software;characters detection;shape;character detection;image edge detection;image color analysis;noncharacter pattern distribution;pixel;pattern recognition;character pattern distribution;pattern analysis;humans;character recognition detectors image edge detection optical character recognition software humans text analysis pattern analysis pattern recognition cameras design methodology;character recognition;scenery images;cameras;character pattern distribution conspicuous character patterns characters detection scenery images noncharacter pattern distribution;design methodology	Detection of characters in scenery images is often a very difficult problem. Although many researchers have tackled this difficult problem and achieved a good performance, it is still difficult to suppress many false alarms and although missings. This paper investigates a conspicuous character pattern, which is a special pattern designed for easier detection. In order to have an example of the conspicuous character pattern, we select a character font with a larger distance from a non-character pattern distribution and, simultaneously, with a smaller distance from a character pattern distribution. Experimental results showed that the character font selected by this method is actually more conspicuous (i.e., detected more easily) than other fonts.		Seiichi Uchida;Ryoji Hattori;Masakazu Iwamura;Shinichiro Omachi;Koichi Kise	2009	2009 10th International Conference on Document Analysis and Recognition	10.1109/ICDAR.2009.196	computer vision;detector;text mining;design methods;shape;computer science;pattern recognition;histogram;pixel	Vision	35.887411313350405	-64.9111372085632	185678
c38196b5e69fdee0d4969d40cfd486fb674fe22c	a lip localization algorithm under variant light conditions	lip localization;template matching;variant light;yiq	Lip-reading has potential attractive applications in information security, speech recognition, secret communication and so forth. To build an automatic lip-reading system, one key issue is how to locate the lip region, particularly under variant light condition. Therefore, a new lip localization algorithm is proposed in this paper, which contains three steps: face detection, rough lip localization and precise lip localization. Among them, the precise lip localization algorithm is the main point, which is based on the transformation of YIQ color model and template matching. Compared with the threshold segment based on the color space transformation, template matching is more robust to variant light conditions. Besides, Q component of YIQ color model can further increase the contrast of lip and skin and decrease the effect of illumination. Experimental results demonstrate that the proposed algorithm is efficient and robust in lip localization under variant light conditions.	algorithm;color space;face detection;information security;skin (computing);speech recognition;template matching	Xinjun Ma;Hongjun Zhang;Yuanyuan Li	2017		10.1145/3055635.3056587	color model;face detection;artificial intelligence;computer science;pattern recognition;template matching;computer vision;algorithm;color space	Vision	33.8996511555454	-62.29056696076997	185860
03616aa55076d21d0b04a0765fc258a814f5346d	scene classification based on rough set method features selection for outdoor images	databases;scene classification;image segmentation;k nearest neighbors classification model;support vector machines;rough set method feature selection;rough set theory;database browsing;image segmentation database;image classification;image segmentation database scene classification rough set method feature selection outdoor images image retrieval database organization database browsing k nearest neighbors classification model support vector machines university of massachusetts;visual databases feature extraction image classification image segmentation rough set theory support vector machines;classification algorithms databases feature extraction support vector machines image segmentation pattern recognition covariance matrix;feature extraction;classification algorithms;pattern recognition;university of massachusetts;k nearest neighbor;outdoor images;feature selection;support vector machine;rough set;database organization;covariance matrix;visual databases;image retrieval	Scene classification is valuable in image retrieval from databases because an understanding of the scene content can be used for efficient and effective database organization and browsing. a scene classification based on rough set method features selection for outdoor images is developed in this paper, support vector machines and k-nearest neighbors classification model are used, experiments on University of Massachusetts image segmentation database shows that based on rough set method features selection can improve the scene classification performance for outdoor images.	database;experiment;image retrieval;image segmentation;k-nearest neighbors algorithm;rough set;support vector machine	Qing-peng Zeng;Shuixiu Wu;Ming-Wen Wang	2008	2008 IEEE International Conference on Granular Computing	10.1109/GRC.2008.4664677	support vector machine;rough set;image retrieval;computer science;machine learning;pattern recognition;data mining;feature selection	Vision	37.808279778773276	-61.5092252294247	186019
b674de72c0a6efdf626e9b5138a8f7fd592242c5	extracting nonlinear features for multispectral images by fcmc and kpca	image features;kernel principal component analysis;kpca;fcmc;multispectral image;feature space;nonlinear feature;multispectral images;fuzzy c means clustering;classification accuracy	Classification is a very important task for scene interpretation and other applications of mul tral images. Feature extraction is a key step for classification. By extracting more nonlinear fe than corresponding number of linear features in original feature space, classification accur multispectral images can be improved greatly. Therefore, in this paper, an approach based fuzzy c-means clustering (FCMC) and kernel principal component analysis (KPCA) is propo resolve the problem of multispectral images. The main contribution of this paper is to provide a preprocessed method for classifying these images. Finally, some experimental results dem that our proposed method is effective and efficient for analyzing the multispectral images.  2004 Elsevier Inc. All rights reserved.	cluster analysis;data pre-processing;feature extraction;feature vector;field electron emission;kernel principal component analysis;multispectral image;nonlinear system;preprocessor	Zhan-Li Sun;De-shuang Huang;Yiu-ming Cheung	2005	Digital Signal Processing	10.1016/j.dsp.2004.12.004	multispectral image;computer vision;computer science;machine learning;pattern recognition;multispectral pattern recognition;mathematics	AI	35.437228634166516	-59.96987068884408	186144
e6b5212b24568a6b32b4f94fd9f96d7b456258e7	arabic handwriting texture analysis for writer identification using the dwt-lifting scheme	writer identification;arabic subword;dwt-lifting scheme;arabic handwriting texture analysis;off-line arabic handwriting;chosen text;discrete wavelet;handwriting texture analysis;text sample;best performance level;writer identification accuracy;average rate;wavelet transform;multilayer perceptron;discrete wavelet transform;handwriting recognition;lifting scheme	In this paper, we present an approach for writer identification using off-line Arabic handwriting. The proposed method explores the handwriting texture analysis by 2D discrete wavelet transforms using lifting scheme. A comparative evaluation between textural features extracted by 9 different wavelet transform functions was done. A modular multilayer perceptron classifier was used. Experiments have shown that writer identification accuracies reach best performance levels with an average rate of 95.68%. Experiments have been carried out using a database of 180 text samples. The chosen text was made to guarantee the involvement of the various internal shapes and letter locations within an Arabic subword.	database;discrete wavelet transform;lifting scheme;multilayer perceptron;online and offline;substring	Sami Gazzah;Najoua Essoukri Ben Amara	2007	Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)	10.1109/ICDAR.2007.62	speech recognition;computer science;machine learning;pattern recognition;handwriting recognition;multilayer perceptron;discrete wavelet transform;lifting scheme;wavelet transform	Robotics	32.3739505917339	-64.24885829185794	186943
e68b14207a7fc0fad2e388373d06b5c80e1a5cb7	recognition of similar patterns by mutilayer nets and detection of rotated angle and scale ratio	scale detection;mutilayer nets;pattern recognition;bp learning;rotated angle			Hiromu Gotanda;Kousaku Kawai;Tatsuya Yamaoka	1999	JRM	10.20965/jrm.1999.p0495	computer vision;speech recognition;pattern recognition	Robotics	32.297098514758275	-59.4694846067937	187603
1e61d183d6f9dad96e2cbcff06ed43df8e8111bd	delaunay triangulation-based features for camera-based document image retrieval system	delaunay triangulation;indexing camera based document image retrieval delaunay triangulation feature descriptors;hashing based indexing system delaunay triangulation feature camera document image retrieval system feature vector detrif geometrical constraint;camera based document image retrieval;indexing;mesh generation document image processing image retrieval indexing;feature descriptors;feature extraction indexing image retrieval cameras real time systems distortion	In this paper, we propose a new feature vector, named DElaunay TRIangulation-based Features (DETRIF), for real-time camera-based document image retrieval. DETRIF is computed based on the geometrical constraints from each pair of adjacency triangles in delaunay triangulation which is constructed from centroids of connected components. Besides, we employ a hashing-based indexing system in order to evaluate the performance of DETRIF and to compare it with other systems such as LLAH and SRIF. The experimentation is carried out on two datasets comprising of 400 heterogeneous-content complex linguistic map images (huge size, 9800 X 11768 pixels resolution) and 700 textual document images.	connected component (graph theory);cryptographic hash function;delaunay triangulation;distortion;feature vector;ground truth;image retrieval;pixel;point of view (computer hardware company);real-time clock;scale-invariant feature transform;virtual camera system	Quoc Bao Dang;Marçal Rusiñol;Mickaël Coustaty;Muhammad Muzzamil Luqman;De Cao Tran;Jean-Marc Ogier	2016	2016 12th IAPR Workshop on Document Analysis Systems (DAS)	10.1109/DAS.2016.66	computer vision;search engine indexing;visual word;delaunay triangulation;computer science;pattern recognition;information retrieval	Vision	39.05191340189033	-59.61472821471735	187652
58d496dc9bb5da25fab31099964147c81a1f144c	character-based car plate detection and localization	image recognition;pixel compactness character based car plate detection character based car plate localization malaysian car license plate black colored vehicles alphanumeric character extraction;alphanumeric character extraction;rule based;pixel compactness;traffic engineering computing character recognition image recognition;black colored vehicles;traffic engineering computing;character based car plate localization;malaysian car license plate;character recognition;character based car plate detection;tk electrical engineering electronics nuclear engineering	In this paper we address the issue of locating non-standard Malaysian car license plate. Instead of searching the region for the plate, we directly locate the alphanumeric characters of the car plate. In this manner, we remove issues such as plate size variations and plates on black colored vehicles. Our main goal is to locate and extract the alphanumeric characters of Malaysian special plates. These special plates do not follow the normal standard car plates' format as they may contain italic, cursive and connected letters, and of different fonts. Using several parameters such as pixel compactness, angles, and projection histogram, we use ruled-based technique to locate and detect these special characters of the car plates. The results have shown that we are able to automatically locate with an accuracy of 95%.	foreign key;internationalization and localization;pixel;sensor	Samsul Setumin;Usman Ullah Sheikh;Syed Abdul Rahman Abu-Bakar	2010	10th International Conference on Information Science, Signal Processing and their Applications (ISSPA 2010)	10.1109/ISSPA.2010.5605411	rule-based system;computer vision;speech recognition;computer science	Robotics	35.33004609038596	-64.29749638673967	187963
b99f48500f2392db463d73735aa35bd1a6d477f7	semi-local features for the classification of segmented objects		Image features are usually extracted globally from whole images or locally from regions-of-interest. We propose different approaches to extract semi-local features from segmented objects in the context of object detection. The focus lies on the transformation of arbitrarily shaped object segments to image regions that are suitable for the extraction of features like SIFT, Gabor wavelets, and MPEG-7 color features. In this region transformation step, decisions arise about the used region boundary size and about modifications of the object and its background. Amongst others, we compare uniformly colored, blurred and randomly sampled backgrounds versus simple bounding boxes without object-background modifications. An extensive evaluation on the Pascal VOC 2010 segmentation dataset indicates that semi-local features are suitable for this task and that a significant difference exists between different feature extraction methods.	chi;color;experiment;feature extraction;gabor filter;horst rittel;mpeg-7;nearest neighbor search;object detection;randomness;scale-invariant feature transform;semiconductor industry;wavelet	Robert Sorschag	2012			artificial intelligence;pattern recognition;computer science	Vision	36.75765405940761	-59.85080834573096	188988
00d59f1c41c060de6e8ef320122b62cfc4b9b215	flexible object recognition: a new approach toward increasing noise tolerance in contour pattern matching	object recognition;image object recognition;flexible object recognition method;for method;contour pattern matching;data mining;noise tolerance;accuracy;shape;pattern matching;feature extraction;pattern recognition;flexibility;noise	Pattern recognition with computer systems presents a great challenge to researchers in computer science. In some cases patterns can be differentiated by their silhouette and recognized through the contour around its shape. In this study, shape is deliberately examined in terms of its flexibility, a measure defined to be the extent to which curves could be deformed. The proposed flexible object recognition (FOR) method widely employs flexibility to find corners, to form segments, to match segment pairs, and eventually to calculate the dissimilarity of contour pairs. Further analysis on classification with such dissimilarities shows rather high accuracy rates across various application domains, which may provide an evidence of the robustness for the proposed FOR method.	computer science;contour line;outline of object recognition;pattern matching;pattern recognition	Chao-Yi Huang;Jong-Chen Chen	2009	2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2009.523	computer vision;state pattern;feature;feature extraction;shape;computer science;noise;cognitive neuroscience of visual object recognition;machine learning;pattern matching;pattern recognition;data mining;three-dimensional face recognition;accuracy and precision;3d single-object recognition	Vision	34.42677561909775	-62.34874052192444	189251
6bdcf7cbd8be2723d12e5716918ca9631c54d502	an efficient method for document image geometric layout analysis				S. Chi;Y. Chung;D.-G. Jang;W. Oh;Jason R. J. Lee	2003			computer vision;speech recognition;document processing;document layout analysis;pattern recognition	Vision	37.22554111785154	-65.5568858671122	189364
107d4547388945a4e41edc2c7db6755030de7a08	unsupervised refinement of color and stroke features for text binarization	gaussian mixture model;document image;conditional random field;binarization method;word image	Color and strokes are the salient features of text regions in an image. In this work, we use both these features as cues, and introduce a novel energy function to formulate the text binarization problem. The minimum of this energy function corresponds to the optimal binarization. We minimize the energy function with an iterative graph cut-based algorithm. Our model is robust to variations in foreground and background as we learn Gaussian mixture models for color and strokes in each iteration of the graph cut. We show results on word images from the challenging ICDAR 2003/2011, born-digital image and street view text datasets, as well as full scene images containing text from ICDAR 2013 datasets, and compare our performance with state-of-the-art methods. Our approach shows significant improvements in performance under a variety of performance measures commonly used to assess text binarization schemes. In addition, our method adapts to diverse document images, like text in videos, handwritten text images.	algorithm;benchmark (computing);binary image;cluster analysis;cut (graph theory);digital image;energy minimization;google street view;graph cuts in computer vision;image editing;image segmentation;international conference on document analysis and recognition;iteration;mathematical optimization;microsoft research;mixture model;open-source software;optical character recognition;pixel;refinement (computing);unsupervised learning	Anand Mishra;Karteek Alahari;C. V. Jawahar	2017	International Journal on Document Analysis and Recognition (IJDAR)	10.1007/s10032-017-0283-9	computer vision;computer science;machine learning;pattern recognition	Vision	36.689139452857226	-65.00102931748326	189569
36d3e96e2978b6f816b3a79b7348e7a7fb6cc8c9	multi-order standard deviation based distance metrics and its application in handwritten chinese character recognition	distance metrics;standard deviation;system performance;manhattan distance;handwritten chinese character recognition;hcl2004 handwritten chinese characters database multiorder standard deviation distance metrics handwritten chinese character recognition pattern recognition similarity measurement manhattan distance feature vector;similarity measurement;feature vector;vectors;distance metric;pattern recognition;multiorder standard deviation;experience base;hcl2004 handwritten chinese characters database;vectors handwritten character recognition;handwritten character recognition;character recognition pattern recognition statistics system testing gaussian distribution information science area measurement spatial databases handwriting recognition system performance	Distance metric is the most popular metrics in the area of pattern recognition, and it is always used as a measure of similarity between the test pattern and the reference patterns. In this paper, a new distance metric based on Manhattan distance is proposed. In the distance metric, not only the standard deviation but also the multi-order standard deviation of the reference patterns' feature vectors is involved. This paper develops this metric and the experiments based on the distance metric are discussed. According to our experiments on HCL2004 handwritten Chinese characters database, the proposed distance metric shows its efficiency by improving the recognition accuracy of the system 4.01% compared with the system performance based on the standard deviation weighted distance metric	experiment;feature vector;pattern recognition;taxicab geometry;test card	Ren junling	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.828	earth mover's distance;speech recognition;edit distance;feature vector;metric;computer science;machine learning;pattern recognition;euclidean distance;mathematics;computer performance;standard deviation;string metric;jaro–winkler distance	Vision	32.62099012365116	-64.41327544326788	189765
300a13b816a303ee0f498d702a4b997cb377d44a	effective video text detection using line features	computer vision image edge detection layout optical character recognition software detectors video sharing indexing character recognition text recognition computer science;video signal processing;edge detection;computational cost line features video text detection canny edge detector line feature vector graph stroke information edge map;feature vector;feature extraction;text detection;video signal processing edge detection feature extraction	Text superimposed on video frames provides synoptic or supplemental information on video semantics. In this paper, we propose a novel method to detect superimposed text effectively. First, we detect edges by an improved Canny edge detector. Then, a line-feature vector graph is generated based on the edge map and the stroke information is extracted. Finally text regions are generated and filtered according to line features. Experimental results show that, without much increasing the computational cost, our proposed method could suppress the false alarms notably. Furthermore, our method can be easily customized to applications with different tradeoffs in recall and precision.	algorithmic efficiency;canny edge detector;computation;edge detection;feature vector;precision and recall	Yang Liu;Hong Lu;Xiangyang Xue;Yap-Peng Tan	2004	ICARCV 2004 8th Control, Automation, Robotics and Vision Conference, 2004.	10.1109/ICARCV.2004.1469077	computer vision;speech recognition;edge detection;feature vector;feature extraction;computer science;machine learning;pattern recognition;feature	Robotics	36.80907386661765	-63.862829651709006	189973
55d5b24d3e7af8ebf0421f9cc709d35d7d9981d1	pores and ridges: fingerprint matching using level 3 features	level 2;gabor filters fingerprint matching fingerprint friction ridge details high resolution sensor automated fingerprint identification systems wavelet transform;fingerprint recognition feature extraction friction shape sensor phenomena and characterization sensor systems data mining wavelet transforms gabor filters iterative closest point algorithm;high resolution;image matching;gabor filters;wavelet transforms;gabor filter;wavelet transform;fingerprint identification;wavelet transforms fingerprint identification gabor filters image matching;level 1	Fingerprint friction ridge details are generally described in a hierarchical order at three levels, namely, Level 1 (pattern), Level 2 (minutiae points) and Level 3 (pores and ridge shape). Although high resolution sensors (~1000 dpi) have become commercially available and have made it possible to reliably extract Level 3 features, most automated fingerprint identification systems (AFIS) employ only Level 1 and Level 2 features. As a result, increasing the scan resolution does not provide any matching performance improvement (1998). We develop a matcher that utilizes Level 3 features, including pores and ridge contours, for 1000 dpi fingerprint matching. Level 3 features are automatically extracted using wavelet transform and Gabor filters and are locally matched using the ICP algorithm. Our experiments on a median-sized database show that Level 3 features carry significant discriminatory information. EER values are reduced (relatively ~20%) when Level 3 features are employed in combination with Level 1 and 2 features	algorithm;automated fingerprint identification;cpu cache;enhanced entity–relationship model;experiment;gabor filter;image resolution;minutiae;reduction (complexity);sensor;wavelet transform	Anil K. Jain;Yi Chen;Meltem Demirkus	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.938	computer vision;speech recognition;pattern recognition;mathematics;gabor wavelet;wavelet transform	Vision	32.840015021071025	-62.553498536534626	190046
48be17821ad12a65b7355b9e3e1cae442515a22b	a reduced reference image quality metric based on feature fusion and neural networks	degradation;networks;neural nets feature extraction image fusion;measurement;fusion;reduced;metric;image;transform coding;artificial neural networks;image edge detection;reference;quality;tid 2008 database reduced reference image quality metric feature fusion artificial neural network reduced reference degradation dependent iqm rriqm d feature extraction wavelet based edge map linear discriminant analysis lda ann;feature extraction image quality degradation transform coding image edge detection measurement artificial neural networks;feature extraction;image quality;feature;neural	A Global Reduced Reference Image Quality Metric (IQM) based on feature fusion using neural networks is proposed. The main idea is the introduction of a Reduced Reference degradation-dependent IQM (RRIQM/D) across a set of common distortions. The first stage consists of extracting a set of features from the wavelet-based edge map. Such features are then used to identify the type of degradation using Linear Discriminant Analysis (LDA). The second stage consists of fusing the extracted features into a single measure using Artificial Neural Networks (ANN). The result is a degradation-dependent IQM measure called the RRIQM/D. The performance of the proposed method is evaluated using the TID 2008 database and compared to some existing IQMs. The experimental results obtained using the proposed method demonstrate an improved performance even when compared to some Full Reference IQMs.	distortion;elegant degradation;feature extraction;feature vector;image quality;linear discriminant analysis;neural networks;real-time clock;visual descriptor;wavelet	Aladine Chetouani;Azeddine Beghdadi;Mohamed A. Deriche;Abdesselam Bouzerdoum	2011	2011 19th European Signal Processing Conference		computer vision;computer science;machine learning;pattern recognition	Vision	37.04461582595591	-60.169713859765686	190290
cc636d2e74ebc3143828c582ae81f64b00e998a0	handwritten kanji recognition using combined complementary classifiers in a cascade arrangement	classifier combination;image classification;handwriting recognition pattern recognition feature extraction design methodology laboratories electronic mail linear discriminant analysis shape;misrecognized pattern recognition handwritten kanji recognition combined complementary classifiers cascade arrangement recognition accuracy improvement common difference principal components difference principal components;combining classifier;handwritten kanji;principal component analysis;ocr;document image processing;character sets;character recognition;difference principal component;handwritten character recognition;principal component;character sets image classification document image processing handwritten character recognition principal component analysis	In classifier combination, the degree of recognition accuracy improvement depends not only on how classifiers are combined, but also on how much they complement each other. From this viewpoint, a complementary classifier that is combined with an existent classifier should use features that make it easy to recognize patterns misrecognized by the existing classifier. As such features, I propose using common difference principal components and difference principal components in a complementary classifier. I also propose combining complementary classifiers in cascade. In each complementary classifier, the common difference principal components and the difference principal components are obtained to make it easy to recognize patterns misrecognized in the preceding combined classifier. These ideas were applied to handwritten Kanji recognition. Experiments showed that the recognition rate increased from 97.35% to 98.00% after a single complementary classifier was combined and to 98.23% after four were combined.	statistical classification	Takahiko Kawatani	1999		10.1109/ICDAR.1999.791835	speech recognition;intelligent character recognition;computer science;intelligent word recognition;machine learning;pattern recognition;principal component analysis	HCI	32.226977875969226	-64.98933835174095	192224
8bcbf2bc771c4392f66ba503ff4d151f76fd29ae	detecting information-hiding in wav audios	second order;steganography audio coding learning artificial intelligence markov processes;distortion measurement steganography analysis of variance videos discrete cosine transforms histograms signal design detectors testing art;information hiding;testing;distortion measurement;transform coding;joints;audio coding;accuracy;least significant bit;steganography;feature extraction;audio stegograms information hiding wav audios steganalysis method neighboring joint distribution features markov features least significant bit learning machines;markov processes;computer science;learning artificial intelligence	In this article, we propose a steganalysis method for detecting the presence of information-hiding behavior in wav audios. We extract the neighboring joint distribution features and the Markov features of the second order derivative, and combine these features with the error response by randomly modifying the least significant bit, then apply learning machines to the features for distinguishing the stegoaudios from cover videos. Experimental results show that our method performs well in steganalysis of the audio stegograms that are produced by using Hide4PGP, Invisible Secrets and S-tools4.	least significant bit;markov chain;most significant bit;randomness;sensor;steganalysis	Qingzhong Liu;Andrew H. Sung;Mengyu Qiao	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761650	least significant bit;computer vision;transform coding;speech recognition;feature extraction;computer science;machine learning;pattern recognition;accuracy and precision;software testing;steganography;markov process;information hiding;second-order logic;statistics	Robotics	37.24952478249066	-62.29304013039645	192275
b95a18d64b437f30c887115825a24448c38874b6	a new keypoint-based copy-move forgery detection for small smooth regions	copy-move forgery detection;superpixel;adaptive feature points detector;exponent moments;reversed generalized 2 nearest-neighbor	Copy-move forgery is one of the most common types of image forgeries, where a region from one part of an image is copied and pasted onto another part, thereby concealing the image content in the latter region. Keypoint based copy-move forgery detection approaches extract image feature points and use local visual features, rather than image blocks, to identify duplicated regions. Keypoint based approaches exhibit remarkable performance with respect to computational cost, memory requirement, and robustness. But unfortunately, they usually do not work well if smooth background areas are used to hide small objects, as image keypoints cannot be extracted effectively from those areas. It is a challenging work to design a keypoint-based method for detecting forgeries involving small smooth regions. In this paper, we propose a new keypoint-based copy-move forgery detection for small smooth regions. Firstly, the original tampered image is segmented into nonoverlapping and irregular superpixels, and the superpixels are classified into smooth, texture and strong texture based on local information entropy. Secondly, the stable image keypoints are extracted from each superpixel, including smooth, texture and strong texture ones, by utilizing the superpixel content based adaptive feature points detector. Thirdly, the local visual features, namely exponent moments magnitudes, are constructed for each image keypoint, and the best bin first and reversed generalized 2 nearest-neighbor algorithm are utilized to find rapidly the matching image keypoints. Finally, the falsely matched image keypoints are removed by customizing the random sample consensus, and the duplicated regions are localized by using zero mean normalized cross-correlation measure. Extensive experimental results show that the newly proposed scheme can achieve much better detection results for copy-move forgery images under various challenging conditions, such as geometric transforms, JPEG compression, and additive white Gaussian noise, compared with the existing state-of-the-art copy-move forgery detection methods.	additive white gaussian noise;algorithmic efficiency;authentication;best bin first;computational complexity theory;copy-on-write;cross-correlation;entropy (information theory);experiment;feature (computer vision);jpeg;k-nearest neighbors algorithm;random sample consensus;real-time transcription;sensor;utility functions on indivisible goods	Xiang-Yang Wang;Shuwei Li;Yu-nan Liu;Ying Niu;Hong-Ying Yang;Zhi-li Zhou	2016	Multimedia Tools and Applications	10.1007/s11042-016-4140-5	computer vision;pattern recognition;data mining	Vision	36.600594474737136	-61.00575549808106	192296
069d5a78cca34151cec011aa150605aa006088dc	compact color features with bitwise quantization and reduced resolution for mobile processing	image resolution;quantisation signal feature extraction image colour analysis image resolution;quantisation signal;compact description image recognition;image colour analysis;feature extraction;image color analysis feature extraction image resolution quantization signal vectors mobile communication image recognition;mobile image application compact color features reduced resolution mobile processing computational cost power consumption feature extraction pixel depth resolution settings compact descriptors effective descriptors resolution parameters bitwise quantization algorithm	Color features for recognition are often extracted from 8-bit images. However, some studies recommended the use of an arbitrary number of colors, often less than 256 colors. Because the use of less colors can led to a lower computational cost and less power consumption, this paper investigates the extraction of features using images with different pixel depth, i.e., number of colors, and using two resolution settings. We show that it is possible to obtain compact and effective descriptors, by extracting features with images of lower quantization and resolution parameters. Also, we propose a bitwise quantization algorithm that codifies the most significant color features. While it reduces the number of colors, the distances between the feature vectors are kept similar, benefiting mobile image applications.	8-bit color;algorithm;algorithmic efficiency;bitwise operation;color depth;computation;feature vector;image resolution;quantization (signal processing)	Moacir P. Ponti;Luciana C. Escobar	2013	2013 IEEE Global Conference on Signal and Information Processing	10.1109/GlobalSIP.2013.6737000	color histogram;computer vision;feature detection;color quantization;image resolution;color image;binary image;feature extraction;pattern recognition;mathematics;sub-pixel resolution;feature;computer graphics (images)	Vision	37.71517437016069	-60.10892976581394	193180
2b3c1ceba350299e950fb900aba065fac4e91339	structural features by mcr expression for printed arabic character recognition	binary image;feature space;character recognition	This paper discribes how stroke features in document images are extracted and used for the recognition of printed Arabic characters. It is of importance to provide a good base representation that facilitate analysis and processing of document images. The strokes are extracted by a method called Minimum Covering Runs (MCR)[1]. This method of representing binary images by a minimum number of horizontal and vertical runs is used as a preprocessing step. The strokes are labeled and ordered, a feature space for the 100 shapes of the 28 Arabic characters is build. The system is under developement but the recognition rate obtained at this stage, 95.5% is encouraging.		Abdelmalek B. C. Zidouri;Supoj Chinveeraphan;Makoto Sato	1995		10.1007/3-540-60298-4_314	natural language processing;computer vision;speech recognition;feature vector;binary image;computer science;intelligent word recognition;pattern recognition	HCI	33.68423905870076	-65.90255301107433	193233
267db7764058495b83a278a75d0c1ab6a8a1d20e	3d steganalysis using the extended local feature set		3D steganalysis aims to find the changes embedded through steganographic or information hiding algorithms into 3D models. This research study proposes to use new 3D features, such as the edge vectors, represented in both Cartesian and Laplacian coordinate systems, together with other steganalytic features, for improving the results of 3D steganalysers. In this way the local feature vector used by the steganalyzer is extended to 124 dimensions. We test the performance of the extended local feature set, and compare it to four other steganalytic features, when detecting the stego-objects watermarked by six information hiding algorithms.		Zhenyu Li;Daofu Gong;Fenlin Liu;Adrian G. Bors	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451643	computer vision;information hiding;coordinate system;steganography;robustness (computer science);artificial intelligence;digital watermarking;feature vector;feature extraction;pattern recognition;steganalysis;computer science	Robotics	36.22662848034272	-59.77779010075552	194153
df799f79bd1197694dc8424974c23fe0f194e9fd	color space identification from single images	analytical models;software;support vector machines feature extraction image classification image colour analysis image segmentation regression analysis;photorgb rgb color space identification single image photography image production screen devices software applications multimedia unauthorized usage prevention exchangeable image file format color space information extraction two dimensional non causal regressive model image demosaicing properties discriminative feature extraction svm classifier image color space detection exif srgb adobergb;browsers;image color analysis;feature extraction;multimedia communication;image color analysis feature extraction cameras analytical models software multimedia communication browsers;cameras	In this paper, we focus on the problem of RGB color space identification from a single image. At the moment, RGB color spaces are widely adopted in photography for image producing. The problems with respect to color space identification, such as to get the consistent printing or displaying quality on screen devices and software applications and prevention of multimedia unauthorized usage(shown or printed by other device via gamut mapping), need to be concerned. Current techniques are all relying on EXchangeable Image File Format (EXIF) to extract color space information. In this paper, we use a two-dimensional non-causal regressive model to explore the image demosaicing properties in order to extract discriminative features and train them on SVM classifier for image color space detection without relying on EXIF. In our experiment, images in three different color spaces (sRGB, adobeRGB and pro PhotoRGB) are generated for color space identification task. The experimental results show that the proposed technique has an good performance on image color space identification.	adobe photoshop lightroom;algorithm;authorization;autostereogram;causal filter;color management;color space;demosaicing;exif;experiment;image file formats;jpeg;printing;raw image format;support vector machine;universal turing machine	Haoliang Li;Alex ChiChung Kot;Leida Li	2016	2016 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2016.7538912	demosaicing;color histogram;image texture;false color;rgb color model;computer vision;feature detection;color quantization;hsl and hsv;color normalization;color depth;color image;binary image;feature extraction;computer science;machine learning;multimedia;color space;computer graphics (images)	Robotics	32.120414726598064	-63.012236896665485	194171
420fd7d1219d2aa19b2edf616f0798c17aa99f44	fast extraction of 3d fourier moments via multiple integral images: an application to antitank mine detection in gpr c-scans		Automatic landmine detection is a challenging problem in post-conflict areas. This paper demonstrates experiments on antitank mine detection in subsurface 3D images generated by Ground Penetrating Radar. In the algorithmic part, we study piecewise Fourier approximations of low orders which are applied to successive 3D windows of an image. We take coefficients — moments — of these approximations as features for machine learning. The main contribution of the paper is a technique to calculate the moments fast. We construct a set of suitable integral images, which allows later to calculate each moment in constant time. The technique is akin to, but significantly different from the known idea of Viola and Jones, namely: we calculate Fourier moments rather than simple differential features; secondly, we use multiple integral images, not a single one; thirdly, our integral images are cumulative inner products between input image and suitable trigonometric terms. Conducted tests involve boosted decision trees as detectors.	kriging	Przemyslaw Klesk;Mariusz Kapruziak;Bogdan Olech	2016		10.1007/978-3-319-46418-3_19	computer vision	Vision	39.04663786775335	-64.09464597503741	194362
b25dd91f1e582645b2bf8683e55ec926e3ae4886	delta-n hinge: rotation-invariant features for writer identification	histograms;fasteners ink writing feature extraction probability distribution kernel histograms;kernel;text analysis feature extraction handwritten character recognition;feature extraction;probability distribution;iam datasets delta n hinge writer identification rotation invariant feature extraction hinge feature ink contours feature vector writing style characterization handwritten text firemaker datasets;writing;ink;fasteners	This paper presents a method for extracting rotation-invariant features from images of handwriting samples that can be used to perform writer identification. The proposed features are based on the Hinge feature [1], but incorporating the derivative between several points along the ink contours. Finally, we concatenate the proposed features into one feature vector to characterize the writing styles of the given handwritten text. The proposed method has been evaluated using Fire maker and IAM datasets in writer identification, showing promising performance gains.	benchmark (computing);biometrics;concatenation;feature vector;identity management;information	Sheng He;Lambert Schomaker	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.353	probability distribution;computer vision;kernel;speech recognition;feature extraction;computer science;pattern recognition;histogram;writing;feature;statistics	Robotics	33.89944323654746	-64.38095485790137	194854
e81e47627a8fa28e09c124972280fc44346fa783	effectively localize text in natural scene images	graph theory;image segmentation;会议论文;text detection feature extraction graph theory image segmentation;feature extraction image color analysis image edge detection robustness videos learning systems training;feature extraction;text detection;graph theory text localization natural scene images connected components analysis cca multiscale adaptive local thresholding operator complementary binary images stroke features spatial relation word level scene text regions collinear maximum group dataset icdar 2003 text lines	In this paper, we present an effective approach to locate scene text in images based on connected components analysis (CCA). Our approach first utilizes a multi-scale adaptive local thresholding operator to convert an image into two complementary binary images. Then, connected components (CCs) are extracted from both of them, which ensures that bright or dark text in contrast to background can be detected. Further, some rules are designed based on stroke features to verify whether a connected component belongs to characters, and the obtained candidate components are further checked on the word level by using a graph to represent spatial relation of different components. Finally, scene text regions are localized by searching the collinear maximum group over the graph. The comparison experiments of the proposed method with some representative state-of-the-art methods, on the challenging dataset ICDAR 2003, show that the proposed approach is very effective, and it is robust to text of different sizes, fonts, colors, as well as orientation of text lines.	binary image;color;connected component (graph theory);dark web;experiment;graph (discrete mathematics);graph theory;international conference on document analysis and recognition;thresholding (image processing)	Xiaoqian Liu;Ke Lu;Weiqiang Wang	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		computer vision;feature extraction;computer science;graph theory;machine learning;pattern recognition;mathematics;image segmentation	Vision	36.8467883277017	-64.19107134738407	195061
62dd49330a06b24df8e0352d7aa3793379e55f0e	face authentication using variants of elastic graph matching based on mathematical morphology that incorporate local discriminant coefficients	morphological dynamic link architecture;graph theory;face authentication;mathematical morphology;performance evaluation;receiver operating characteristics;image databases;receiver operator characteristic;image matching;authentication;elastic graph matching;gabor filters;testing;dynamic linking;graph matching;error analysis;morphology;face recognition;shape;dynamic link architecture;spatial databases;equal error rate;m2vts database face authentication elastic graph matching mathematical morphology local discriminant coefficients dynamic link architecture morphological dynamic link architecture morphological signal decomposition dynamic link architecture performance evaluation receiver operating characteristics equal error rate;morphological signal decomposition dynamic link architecture;error statistics;m2vts database;informatics;error statistics face recognition image matching graph theory mathematical morphology;local discriminant coefficients;authentication morphology testing error analysis face recognition shape gabor filters image databases spatial databases informatics	Two novel variants of Dynamic Link Architecture that are based on mathematical morphology and incorporate local coeecients which weigh the contribution of each node according to its discriminatory power in elastic graph matching are proposed, namely, the Morphological Dynamic Link Architecture and the Morphological Signal Decomposition-Dynamic Link Architecture. They are tested for face au-thentication in a cooperative scenario where the candidates claim an identity to be checked. Their performance is evaluated in terms of their receiver operating characteristic and the Equal Error Rate achieved in M2VTS database. An Equal Error Rate of 6.6%-6.8 % is reported. 1. INTRODUCTION Face recognition has exhibited a tremendous growth for more than two decades. A critical survey of the literature related to human and machine face recognition are found in 1]. An approach that exploits both sources of information, that is, the grey-level information and shape information, is the so-called Dynamic Link Architecture (DLA) 7]. The principles of this pattern recognition scheme can be traced back to the origins of self-organisation in neural networks. The algorithm is split in two phases, i.e., the training and the recall phase. In the training phase, the objective is to build a sparse grid for each person included in the reference set. Towards this goal a sparse grid is overlaid on the facial region of a person's digital image and the response of a set of 2D Gabor lters tuned to diierent orientations and scales is measured at the grid nodes. The responses of Gabor lters form a feature vector at each node. In the recall phase, the reference grid of each person is overlaid on the face image of a test person and is deformed so that a cost function is minimised. A problem in elastic graph matching that has received much attention is the weighting of graph nodes according to their discriminatory power. Several methods have been proposed in the literature. For example, a Bayesian approach yields the more reliable nodes for gender identiica-tion, beard and glass detection in bunch graphs 11]. An automatic weighting of the nodes according to their significance by employing local discriminants is proposed in 2].	algorithm;artificial neural network;authentication;coefficient;digital image;discriminant;drive letter assignment;facial recognition system;feature vector;gabor filter;loss function;matching (graph theory);mathematical morphology;pattern recognition;receiver operating characteristic;self-organization;sparse grid;sparse matrix	Constantine Kotropoulos;Anastasios Tefas;Ioannis Pitas	1998		10.1109/ICASSP.1998.679694	computer vision;morphology;computer science;graph theory;theoretical computer science;machine learning;pattern recognition;mathematics;receiver operating characteristic	Vision	39.102437804921664	-63.10608394172924	195306
dfe16796b869265e05b3d4cee17e28764164176c	blur insensitive texture classification using local phase quantization	low frequency;texture classification;gabor filter;classification accuracy	In this paper, we propose a new descriptor for texture classification that is robust to image blurring. The descriptor utilizes phase information computed locally in a window for every image position. The phases of the four low-frequency coefficients are decorrelated and uniformly quantized in an eight-dimensional space. A histogram of the resulting code words is created and used as a feature in texture classification. Ideally, the low-frequency phase components are shown to be invariant to centrally symmetric blur. Although this ideal invariance is not completely achieved due to the finite window size, the method is still highly insensitive to blur. Because only phase information is used, the method is also invariant to uniform illumination changes. According to our experiments, the classification accuracy of blurred texture images is much higher with the new method than with the well-known LBP or Gabor filter bank methods. Interestingly, it is also slightly better for textures that are not blurred.	8-bit;belief propagation;box blur;code word;coefficient;experiment;filter bank;gabor filter;gaussian blur;microsoft windows;pixel;whole earth 'lectronic link;window function	Ville Ojansivu;Janne Heikkilä	2008		10.1007/978-3-540-69905-7_27	computer vision;local binary patterns;speech recognition;pattern recognition;mathematics;low frequency	Vision	36.6541804757193	-60.57037953121	195613
e59bd47c0d0cc59b0cb4dadbb5a368df909dc5eb	spatial rich model steganalysis feature normalization on random feature-subsets		Spatial rich model (SRM) steganalysis feature is formed by high-order statistics collected from image noise residuals. These statistics are simply rescaled beforemachine learning. It is noted that SRM features of different cover images are very different. In this paper, we propose a feature normalization method based on random feature-subsets (NRS) for SRM. We randomly draw feature-subsets from SRM feature. Then these feature-subsets are normalized by using per-sample rescaling method to make the featuresubsets of different images have the same 1-norm (the sum of all elements). The proposed NRS method can adjust the feature distribution and increase the feature diversity. The normalized feature-subsets can achieve better detection performance and also can be used as a useful complement for the existing steganalysis features. Experimental results show that: (1) a small amount of normalized feature-subset supplement can obviously improve the detection performance of SRM feature; (2) under the same dimensionality, the proposed NRS version feature can achieve a better detection accuracy than that of original feature; (3) the proposed NRS method is applicable to projections of spatial rich model feature; (4) compared with steganalysis feature extraction, the computational time of NRS can be negligible. Communicated by V. Loia. B Pengfei Wang pengfeiw@163.com 1 School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China 2 Present Address: School of Computer Science and Technology, Anhui University of Technology, Maanshan 243002, China	computation;computer science;feature extraction;image noise;randomness;steganalysis;time complexity;wang b-machine	Pengfei Wang;Zhihui Wei;Liang Xiao	2018	Soft Comput.	10.1007/s00500-016-2459-5	speech recognition;pattern recognition;data mining;mathematics;feature	ML	35.32863283862196	-59.94890496193729	195864
4479669a1078863d2a7da09b9c21c31e2e40f7f1	text regions extracted from scene images by ultimate attribute opening and decision tree classification	decision tree classifier;connected component approach;scene text localization;decision tree;text analysis decision trees pattern classification;information extraction;icdar public dataset text regions extraction scene images ultimate attribute opening decision tree classification text region localization method;text analysis;residual operator scene text localization connected component approach text information extraction;residual operator;pattern classification;text information extraction;connected component;decision trees;decision trees data mining media feature extraction pixel buildings indexing	In this work we propose a method for localizing text regions within scene images consisting of two major stages. In the first stage, a set of potential text regions is extracted from the input image using residual operators (such as ultimate attribute opening and closing). In the second stage a set of features is obtained from each potential text region and this feature set will be later used as an input to a decision tree classifier in order to label these regions as text or non-text regions. Experiments performed using images from ICDAR public dataset show that this method is a good alternative for problems involving text location in scene images.	closing (morphology);decision tree;experiment;international conference on document analysis and recognition	Wonder Alexandre Luz Alves;Ronaldo Fumio Hashimoto	2010	2010 23rd SIBGRAPI Conference on Graphics, Patterns and Images	10.1109/SIBGRAPI.2010.55	computer science;machine learning;pattern recognition;incremental decision tree;data mining	Vision	35.912107859373776	-65.31710499262817	196312
456679cd54776937f1a52ea0b206d132ab160f4b	mri and ct image indexing and retrieval using local mesh peak valley edge patterns	texture;medical imaging;patterns;local binary patterns lbp;image retrieval	In this paper, a new pattern based feature, local mesh peak valley edge pattern (LMePVEP) is proposed for biomedical image indexing and retrieval. The standard LBP extracts the gray scale relationship between the center pixel and its surrounding neighbors in an image. Whereas the proposed method extracts the gray scale relationship among the neighbors for a given center pixel in an image. The relations among the neighbors are peak/valley edges which are obtained by performing the first-order derivative. The performance of the proposed method (LMePVEP) is tested by conducting two experiments on two benchmark biomedical databases. Further, it is mentioned that the databases used for experiments are OASIS-MRI database which is the magnetic resonance imaging (MRI) database and VIA/I-ELCAP-CT database which includes region of interest computer tomography (CT) images. The results after being investigated show a significant improvement in terms average retrieval precision (ARP) and average retrieval rate (ARR) as compared to LBP and LBP variant features.		Subrahmanyam Murala;Q. M. Jonathan Wu	2014	Sig. Proc.: Image Comm.	10.1016/j.image.2013.12.002	medical imaging;computer vision;local binary patterns;image retrieval;computer science;pattern recognition;data mining;pattern;texture	Vision	37.93611150787648	-60.34801812794442	196379
83cc8defc5da337ef3d76f1b11462d192b8563a4	character recognition based on dtw-radon	histograms;radon transforms;handwriting recognition;radon transform;dtw character recognition radon transform;training;shape descriptors character recognition dtw radon isolated offline character recognition radon features radon histograms compressing feature matrix;shape;vectors;transforms;document image processing;dtw;character recognition;radon transforms document image processing handwritten character recognition;handwritten character recognition;shape character recognition transforms histograms vectors handwriting recognition training	The paper presents a method for isolated off-line character recognition using radon features. The key characteristic of the method is to use DTW algorithm to match corresponding pairs of radon histograms at every projecting angle. Thanks to DTW, it avoids compressing feature matrix into a single vector which may miss information. Comparison has been made with the state-of-the-art of shape descriptors over several different character as well as numeral datasets from different scripts.	algorithm;dynamic programming;online and offline;optical character recognition;shape analysis (digital geometry);time complexity	K. C. Santosh	2011	2011 International Conference on Document Analysis and Recognition	10.1109/ICDAR.2011.61	radon transform;speech recognition;shape;pattern recognition;histogram;handwriting recognition	Vision	34.77340017111538	-60.509128386772375	196441
c65db868d7f50d6cfa38bad6b9a9331e583b681b	steganalysis for calibrated and lower embedded uncalibrated images	steganalysis;markov;support vector machine;calibration;dct	The objective of steganalysis is to detect messages hidden in a cover images, such as digital images. The ultimate goal of a steganalyst is to extract and decipher the secret message. In this paper, we present a powerful new blind steganalytic scheme that can reliably detect hidden data with a relatively small embedding rate in JPEG images as well as using a technique known as calibration. This would increase the success rate of steganalysis by detecting data in transform domain. This scheme is feature based in the sense that features that are sensitive to embedding changes are being employed as means of steganalysis. The features are extracted in DCT domain. DCT domain features have extended DCT features and Markovian features merged together in calibration technique to eliminate the drawbacks of both(inter and intra block dependency) respectively. For the lesser embedding rate, the features are considered separately to evolve a better classification rate. The blind steganalytic technique has a broad spectrum of analyzing different embedding techniques The feature set contains 274 features by merging both DCT features and Markovian features. The extracted features are being fed to a classifier which helps to distinguish between a cover and stego image. Support Vector Machine is used as classifier here.	steganalysis	Deepa D. Shankar;T. Gireesh Kumar;Hiran V. Nath	2011		10.1007/978-3-642-27242-4_34	support vector machine;computer vision;markov chain;calibration;steganalysis;computer science;machine learning;discrete cosine transform;pattern recognition;mathematics	Vision	36.05125869966143	-61.05846036578217	196590
9f858d73624226be5d1aa62021c1b1781c0aaa06	moving object detection and tracking based on improved surendra background updating algorithm	environmental influence;moving object;image features;background modeling;binary image;center of mass;detection and tracking of moving objects;background subtraction;moving object detection	Background subtraction method is usually used to detect the moving objects. But the establishment of the background model is vulnerable due to some external environmental influences, e.g. the noise, the brightness variations and so on. This paper presents a method based on three frame difference arithmetic of Surendra background updating algorithm to build the background model. By difference calculation of the current frame and background model, and deal with the binary images by applying the difference images, then make the morphology operation for removing the noises to get the smooth images, mark the different connected regions among binary images. According to different labels in connected regions, this paper defines different center of mass of moving objects, and analyzes the image features of moving object area, so as to achieve the detection and track of moving objects. Keyword: Surendra Background Updating; Background Subtraction; Moving Object Detection; Morphological Operations	algorithm;background subtraction;binary image;galaxy morphological classification;object detection	Chengliang Wang;Liangliang Jia;Juanjuan Chen	2011		10.1117/12.896113	computer vision;background subtraction;machine learning;physics;computer graphics (images)	Vision	38.711183911951	-65.87253625977954	196706
20b0d2ab3c5fdbe8a43f0c01a9856d6be7d797a9	combining fingerprint, palmprint and hand-shape for user authentication	feature vectors;fingerprint image matching;feature vectors user authentication personal authentication biometric features hand images fingerprint based verification system palmprint features hand shape features fingerprint image matching minutiae matching;fingerprint recognition authentication image matching biometrics shape nearest neighbor searches image databases spatial databases image resolution image sensors;image matching;hand images;feature vector;fingerprint based verification system;palmprint features;biometric features;feature extraction;image registration;minutiae matching;fusion rule;user authentication;hand shape features;image registration feature extraction fingerprint identification image matching;personal authentication;fingerprint identification	This paper investigates a new approach for personal authentication by combining unique biometric features which can be acquired from hand images alone. The proposed method attempts to improve the performance of fingerprint-based verification system by integrating palmprint and hand-shape features. The matching scores for the fingerprint images are computed using the number of matched minutiae on the overlapping areas while those for palmprint and hand-shape images are based on distance of feature vectors. These matching scores are combined using simple fusion rule which does not require any training. Our experimental results on the database of 100 users achieve promising results and therefore confirm the usefulness of proposed method	authentication;biometrics;feature vector;fingerprint;matched filter;minutiae	Ajay Kumar;David Zhang	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.383	fingerprint verification competition;computer vision;feature vector;computer science;machine learning;pattern recognition;data mining	Vision	33.074642836120056	-61.873632533731914	197242
c9182e12c1d8e19ad7b7b31a63cb8d5494b31a71	fast and simple 2d shape retrieval using discrete shock graph	computational complexity	In this letter, we propose an effective method to retrieve images from a 2D shape image database using discrete shock graphs combined with an adaptive selection algorithm. Experimental results show that our method is more accurate and fast than conventional approaches and reduces computational complexity.		Solima Khanam;Seok-Woo Jang;Woojin Paik	2011	IEICE Transactions		computer vision;computer science;theoretical computer science;machine learning;mathematics;computational complexity theory;algorithm	Vision	37.16720975948686	-61.49963919261311	197552
012efd93724908df66cc7cfa7d9ab8618cc36f67	scene text detection based on component-level fusion and region-level verification	text detection image filtering support vector machines;feature extraction support vector machines image color analysis aggregates standards histograms training;patch classification scene text detection adaptive local binarization maximally stable extremal region mser;component level fusion icdar2011 icdar2003 trained linear support vector machine classifier trained linear svm classifier word level classification character level filtering text region extraction region based method component based method scene text detection method region level verification	In this paper, we present a novel scene text detection method that combines the advantages of component-based methods and region-based methods, while overcoming their inherent limitations. We first extract text regions as candidates, and then aggregate these text components in these regions into words and text lines. To separate non-text components in the background from text components, we perform both character-level filtering and word-level classification with a trained linear SVM (support vector machine) classifier. Our extensive experiments on ICDAR2003 and ICDAR2011 datasets have shown that our method outperforms the state-of-the-art methods in text detection.	aggregate data;component-based software engineering;experiment;support vector machine	Guanghan Ning;Tony X. Han;Zhihai He	2015	2015 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2015.7350917	speech recognition;computer science;machine learning;pattern recognition	Robotics	36.48430704519365	-64.17904370307564	197823
5166fb80730f756ce276e1f0a6ea4cff1c08d0c5	descriptors for image-based fingerprint matchers	histogram of gradients;fingerprint matching;gabor filters;image based fingerprint verification;invariant local binary patterns	This paper focuses on the use of image-based techniques in fingerprint verification. A detailed review of the existing literature is provided by classifying existing methods on the basis of their alignment procedure and discussing the most salient approaches and their pros and cons. Even if, at present, the image-based techniques do not gain performance comparable with that obtained by the best minutiae-based approaches, several good reasons can be listed to support the research on image-based approaches: the possibility of using additional features in combination with minutiae to improve verification performance, the availability of a fixed length feature vector which makes these approaches suitable to be indexed, to be coupled with a learning system or to be combined with tokenised random number in a two factor authentication system (Biohashing). In this work we compare several texture-based descriptors for fingerprints and propose a novel image-based fingerprint matcher based on the minutiae alignment. In this approach, the feature extraction is performed locally on a decomposition of the fingerprint in several overlapping sub-windows considering the following measures: Gabor filters descriptors, invariant local binary patterns and histogram of gradients. Moreover, we propose to perform a supervised selection of a small subset of descriptors, in order to reduce the dimensionality of the feature set and discarding the less discriminative features. Extensive experiments conducted over the four FVC2002 fingerprint databases using a blind testing protocol show that the proposed system dramatically outperforms the other image-based fingerprint matchers proposed in the literature. Moreover, a further experiment conducted on a set of images reconstructed from ISO templates show that, differently to the minutiae-based approaches, our image-based matcher cannot be faked with the sole knowledge of the minutiae position and orientation, at least the original orientation image is required in order have a chance of performing a successful attack.	fingerprint	Loris Nanni;Alessandra Lumini	2009	Expert Syst. Appl.	10.1016/j.eswa.2009.04.041	computer vision;histogram of oriented gradients;computer science;machine learning;pattern recognition;data mining;mathematics	Crypto	32.0628034077295	-61.69860997287651	198790
