id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
05289c9609929a6995f0f44c48369183832ef68f	pattern analysis of dermoscopic images based on markov random fields	evaluation performance;performance evaluation;modelo markov;cancer;tumor maligno;asymmetry;color space;ley n variables;analisis forma;evaluacion prestacion;skin cancer;probabilistic approach;curva gauss;asymetrie;markov random field;conditional model;markov model;campo aleatorio;dermoscopic images;multivariate normal distribution;enfoque probabilista;approche probabiliste;pattern classification;pattern recognition;loi normale;asimetria;multivariate distribution;tumeur maligne;pattern analysis;espace chromatique;reconnaissance forme;espacio cromatico;modele markov;reconocimiento patron;imagen color;loi n variables;gaussian distribution;image couleur;analyse forme;champ aleatoire;malignant tumor;color image;random field;classification forme	In this paper a method for detecting different patterns in dermoscopic images is presented. In order to diagnose a possible skin cancer, physicians assess the lesion based on different rules. While the most famous one is the ABCD rule (asymmetry, border, colour, diameter), the new tendency in dermatology is to classify the lesion performing a pattern analysis. Due to the colour textured appearance of these patterns, this paper presents a novel method based on Markov random field (MRF) extended for colour images that classifies images representing different dermatologic patterns. First, each image plane in L^*a^*b^* colour space is modelled as a MRF following a finite symmetric conditional model (FSCM). Coupling of colour components is taken into account by supposing that features of the MRF in the three colour planes follow a multivariate Normal distribution. Performance is analysed in different colour spaces. The best classification rate is 86% on average.	markov chain;markov random field	Carmen Serrano;Begoña Acha	2009	Pattern Recognition	10.1016/j.patcog.2008.07.011	computer vision;multivariate normal distribution;computer science;artificial intelligence;mathematics;statistics;cancer	Vision	40.93892059812844	-64.06697636544142	158321
d2bf81eeb40a36769ab972a6d89c57648f47932e	automatic system for quality-based classification of marble textures	analisis de componentes principales;chaine fabrication;texture;analisis componente principal;learning algorithm;mecatronica;image processing;analisis textura;color space;algoritmo adaptativo;clasificacion de patrones;etat surface;multilayer perceptrons;real time;representation image;extraction forme;procesamiento imagen;algorithme apprentissage;product line;multilayer perceptron;backpropagation;texture analysis artificial neural networks marble surfaces pattern classification principal component analysis sum and difference histograms;traitement image;info eu repo semantics article;slabs image color analysis image texture analysis algorithm design and analysis backpropagation algorithms classification algorithms real time systems production systems mechatronics prototypes;textura analisis;image texture;production line;surface conditions;perceptron multicouche;backpropagation image texture slabs image colour analysis feature extraction pattern classification principal component analysis multilayer perceptrons;adaptive algorithm;artificial neural networks;histogram;texture analysis;suma y diferencia de histogramas;red multinivel;algorithme adaptatif;slabs;histogramme;electronica;extraccion forma;sum and difference histograms;image colour analysis;image representation;feature extraction;adaptive learning rate;estado superficie;principal component analysis;backpropagation algorithm;temps reel;textura;pattern classification;analyse composante principale;pattern recognition;algorithme retropropagation;tiempo real;mecatronique;image analysis;linea fabricacion;reconnaissance forme;multilayer network;reseau multicouche;mechatronics;reseau neuronal;reconocimiento patron;imagen color;histograma;algoritmo aprendizaje;high performance;marble surfaces;analyse texture;pattern extraction;red neuronal	In this paper, we present an automatic system and algorithms for the classification of marble slabs into different groups in real time in production line, according to slabs quality. The application of the system is aimed at the marble industry, in order to automate and improve the manual classification process of marble slabs carried out at present. The system consists of a mechatronic prototype, which houses all the required physical components for the acquisition of marble slabs images in suitable light conditions, and computational algorithms, which are used to analyze the color texture of the marble surfaces and classify them into their corresponding group. In order to evaluate the color representation influence on the image analysis, four color spaces have been tested: RGB, XYZ, YIQ, and K-L. After the texture analysis performed with the sum and difference histograms algorithm, a feature extraction process has been implemented with principal component analysis. Finally, a multilayer perceptron neural network trained with the backpropagation algorithm with adaptive learning rate is used to classify the marble slabs in three categories, according to their quality. The results (successful classification rate of 98.9%) show very high performance compared with the traditional (manual) system.	algorithm;artificial neural network;backpropagation;color space;computer vision;feature extraction;feature selection;grayscale;image analysis;image texture;marble;mechatronics;multilayer perceptron;pixel;principal component analysis;prototype;real-time locating system;xyz file format	J. Martinez-Alajarin;J. D. Luis-Delgado;Luis-Manuel Tomás-Balibrea	2005	IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)	10.1109/TSMCC.2004.843236	computer science;artificial intelligence;backpropagation;machine learning;artificial neural network	Robotics	45.57071937804554	-61.84357993300576	158508
daa97e0ce2fc1f786c50f8b5b3ff6ca18a6b3844	probabilistic shape-based image indexing and retrieval	gaussian processes;feature extraction;image retrieval;indexing;statistical analysis;visual databases;gaussian mixture modeling;edge-related noise;logo images;probabilistic framework;query image;shape-based image indexing;shape-based image retrieval;shape-based similarity;statistical model	In this paper we present a probabilistic framework for shape-based indexing and retrieval of images, in our framework shape-based features are extracted from each image and then a statistical model of the image is constructed using an effective deterministic method for Gaussian mixture modeling. In this way, each image is finally represented as a mixture of Gaussians and shape-based similarity between images is computed by measuring the distance between the corresponding mixture distributions. Several distance measures are presented and experimentally compared. Experimental results on the retrieval of logo images indicate that the method is very effective and exhibits robustness to the presence of various types of edge-related noise in the query image.	cluster analysis;experiment;logo;mixture model;relevance feedback;statistical classification;statistical model;wavelet	Konstantinos Valasoulis;Aristidis Likas	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1334420	active shape model;computer vision;visual word;image retrieval;computer science;pattern recognition;mixture model;information retrieval;statistics;divergence-from-randomness model	Vision	40.00173039971426	-62.08216659208545	158698
36e4bad3400ce11b64db43ed47d2844f47678c5a	analysis of human electrocardiogram for biometric recognition	signal image and speech processing;autocorrelacion;traitement signal;securite;biometrie;localization;transformation cosinus discrete;orientado aspecto;biometrics;biometria;localizacion;electrocardiographie;accuracy;electrocardiography;automatic recognition;electrocardiografia;precision;localisation;quantum information technology spintronics;discrete cosine transforms;signal processing;identification;safety;pattern recognition;identificacion;aspect oriented;reconnaissance forme;reconocimiento patron;seguridad;procesamiento senal;oriente aspect;reconocimiento automatico;electrocardiogram;autocorrelation;reconnaissance automatique	Security concerns increase as the technology for falsification advances. There are strong evidences that a difficult to falsify biometric trait, the human heartbeat, can be used for identity recognition. Existing solutions for biometric recognition from electrocardiogram (ECG) signals are based on temporal and amplitude distances between detected fiducial points. Such methods rely heavily on the accuracy of fiducial detection, which is still an open problem due to the difficulty in exact localization of wave boundaries. This paper presents a systematic analysis for human identification from ECG data. A fiducial-detection-based framework that incorporates analytic and appearance attributes is first introduced. The appearance-based approach needs detection of one fiducial point only. Further, to completely relax the detection of fiducial points, a new approach based on autocorrelation (AC) in conjunction with discrete cosine transform (DCT) is proposed. Experimentation demonstrates that the AC/DCT method produces comparable recognition accuracy with the fiducial-detection-based approach.	acoustic cryptanalysis;anomaly detection;autocorrelation;biometrics;coefficient;discrete cosine transform;feature extraction;fiducial marker;handwritten biometric recognition;hierarchical database model;holism;mathematical morphology;non-functional requirement;window function	Yongjin Wang;Foteini Agrafioti;Dimitrios Hatzinakos;Konstantinos N. Plataniotis	2008	EURASIP J. Adv. Sig. Proc.	10.1155/2008/148658	computer vision;speech recognition;telecommunications;computer science;artificial intelligence;signal processing;accuracy and precision;statistics	Vision	45.58345488821995	-60.34084711863603	158873
870e38120ea1c16c1bcd095da567199fff90f5e7	a survey of six international conferences on pattern recognition	image processing;analisis correspondencia;proceedings;traitement image;icpr proceedings;acte congres;correspondence analysis;pattern recognition;analyse correspondance;reconnaissance forme	In order to visualize the trends in pattern recognition during the past l0 years, the full papers contained in the Proceedings of the six International Conferences on Pattern Recognition held so far were categorized and indexed. In total, 40 index terms were used. The paper supplies information about participation by various countries. The continuous shift from pattern recognition towards image processing is substantiated. The general trends in emphasis are visualized in more detail on maps as obtained by the application of correspondence analysis. Some national differences are also indicated.	categorization;correspondence analysis;image processing;map;pattern recognition	Edzard S. Gelsema	1984	Pattern Recognition Letters	10.1016/0167-8655(84)90026-6	image processing;computer science;artificial intelligence;pattern recognition;correspondence analysis;operations research	Vision	46.357256196562346	-62.496994523991525	159840
7ac819478372b3362e6b5af57b3010ea9063945b	non-supervised classification of 2d color images using kohonen networks and a novel metric	topology;euclidean theory;image processing;surveillance;classification supervisee;topologie;supervised classification;procesamiento imagen;image classification;metric;1 dimensional;euclidean distance;traitement image;topologia;kohonen algorithm;algoritmo kohonen;vigilancia;algorithme kohonen;monitoring;classification image;theorie euclidienne;clasificacion supervisada;pattern recognition;metrico;monitorage;reconnaissance forme;reconocimiento patron;monitoreo;imagen color;image couleur;metrique;color image;teoria euclidiana	We describe the application of 1-Dimensional Kohonen Networks in the classification of color 2D images which has been evaluated in Popocatepetl Volcano’s images. The Popocatepetl, located in the limits of the State of Puebla in Mexico, is active and under monitoring since 1997. We will consider one of the problems related with the question if our application of the Kohonen Network classifies according to the total intensity color of an image or well, if it classifies according to the connectivity, i.e. the topology, between the pixels that compose an image. In order to give arguments that support our hypothesis that our procedures share the classification according to the topology of the pixels in the images, we will present two approaches based a) in the evaluation of the classification given by the network when the pixels in the images are permuted; and,b) when an additional metric to the Euclidean distance is introduced.	machine learning;teuvo kohonen	Ricardo Pérez-Aguila;Pilar Gómez-Gil;Fernando Antonio Aguilera Ramírez	2005		10.1007/11578079_29	computer vision;contextual image classification;color image;metric;image processing;computer science;artificial intelligence;euclidean distance;one-dimensional space;mathematics	ML	45.116132988629566	-62.55040152786371	160532
b79142d8721f391d5650bbe498e92178a1db0caa	boosted landmarks of contextual descriptors and forest-ecoc: a novel framework to detect and classify objects in cluttered scenes	teletrafic;object recognition;vision ordenador;clutter;base donnee;error correcting code;learning algorithm;deteccion blanco;codigo corrector error;structure arborescente;database;base dato;reconnaissance objet;algorithme apprentissage;computer vision;detection cible;detection objet;multiple classifiers;teletrafico;boosting;fouillis echo;embedding of dichotomies;estructura arborescente;multi class classification;confusion eco;tree structure;signal classification;teletraffic;pattern recognition;classification signal;correlogram;vision ordinateur;spatial relationships;reconnaissance forme;classification automatique;reconocimiento patron;code correcteur erreur;automatic classification;algoritmo aprendizaje;target detection;clasificacion automatica;object detection;error correcting output code	In this paper, we present a novel methodology to detect and recognize objects in cluttered scenes by proposing boosted contextual descriptors of landmarks in a framework of multi-class object recognition. To detect a sample of the object class, Boosted Landmarks identify landmark candidates in the image and define a constellation of contextual descriptors able to capture the spatial relationship among them. To classify the object, we consider the problem of multi-class classification with a battery of classifiers trained to share their knowledge among classes. For this purpose, we extend the Error Correcting Output Codes technique proposing a methodology based on embedding a forest of optimal tree structures. We validated our approach using public data-sets from the UCI and Caltech databases. Furthermore, we show results of the technique applied to a real computer vision problem: detection and categorization of traffic signs. 2007 Elsevier B.V. All rights reserved.	categorization;computer vision;database;information privacy;instance (computer science);multiclass classification;outline of object recognition;real computation	Sergio Escalera;Oriol Pujol;Petia Radeva	2007	Pattern Recognition Letters	10.1016/j.patrec.2007.05.007	spatial relation;computer vision;error detection and correction;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;machine learning;multiclass classification;pattern recognition;clutter;tree structure;boosting;correlogram	Vision	44.347669347940844	-59.34554504284297	161417
d0bdd7639aa62ccc6c664ab692beb4c05ecc28f7	human color perception in the hsv space and its application in histogram generation for image retrieval	busqueda informacion;saturacion;red www;color space;recherche image;information retrieval;reseau web;aplicacion espacial;color histogram;color perception;histogram;human vision and color perception;evaluation subjective;histogramme;percepcion visual;recherche information;human visual system;retina;imaging;retine;perception visuelle;web based system;formation image;world wide web;visual perception;formacion imagen;espace chromatique;espacio cromatico;content based image retrieval;subjective evaluation;histograma;content based retrieval;saturation;application spatiale;recherche par contenu;space application;evaluacion subjetiva;image retrieval	We have done a detailed analysis of the visual properties of the HSV (Hue, Saturation and Intensity Value) color space and Human visual system. Using the results of these analyses, we determine relative importance of hue and intensity based on the saturation of an image pixel with respect to rod and cone cells excitation of retina. We effectively apply this method to the generation of a color histogram and use it for content-based image retrieval applications. A web-based system has been developed for demonstrating our work.	color histogram;color space;color vision;content-based image retrieval;human visual system model;pixel;web application	A. Vadivel;Shamik Sural;Arun K. Majumdar	2005		10.1117/12.586823	color histogram;computer vision;hsl and hsv;color normalization;color image;chromaticity;visual perception;image retrieval;computer science;histogram;color vision;color space;human visual system model;histogram equalization;saturation;computer graphics (images)	Vision	43.211387469007136	-61.71673054840548	161729
c964494ac6b9767896ec44d8f984d8fd878cd8d9	stroke extraction method for offline recognition of chinese characters	structure methods;quantization;median filter;branch point;quantization noise;optical character recognition;extraction method;handwritten character recognition	A structural method for analysis of Chinese characters is presented, with the purpose ofhandwritten character recognition. Firstly, a line following and thinning process is used to obtain the thinned shape of the character. This process includes a specific treatment ofsingular regions allowing the detection ofthe branching points. In a second stage, an extended direction code is assigned to each point of the thinned line. Then, median filtering of extended codes eliminates much of the quantization noise, without altering significant direction changes. This leads to split up the character into a list of straight line segments, which are characterized by a main direction attribute. In a third stage, strokes are extracted by bringing together adjoining segments having neighboring directions. To compare two characters, firstly, we try to associate to each stroke of the first character the nearest stroke of the second one. Then, the distance between both characters is obtained from the sum of the distances between strokes, associated by pairs. This distance takes into account the possible presence ofnon-paired strokes in both characters.	code;median filter;online and offline;optical character recognition;quantization (signal processing);thinning	Jean-Pierre Larmagnac;Éric Dinet	2000		10.1117/12.373508	computer vision;speech recognition;quantization;computer science;pattern recognition;algorithm	Theory	43.03624574017136	-65.09660949912208	161804
3e0a3a2639987c3835299145c3fea2b04fdec9c0	dynamic bayesian networks for audio-visual speaker recognition	reconnaissance visage;modelizacion;distributed system;metodo caso peor;correlacion;topology;evaluation performance;image recognition;reconocimiento imagen;vision ordenador;base donnee;systeme reparti;performance evaluation;facies;biometrie;evaluacion prestacion;topologie;biometrics;database;biometria;base dato;topologia;computer vision;speaker recognition;modelisation;reseau bayes;sistema repartido;face recognition;reconocimiento voz;red bayes;dynamic bayesian network;reconnaissance image;methode cas pire;reconnaissance locuteur;bayes network;speech recognition;multimodal system;audio visual;vision ordinateur;reconnaissance parole;correlation;modeling;worst case method	Audio-Visual speaker recognition promises higher performance than any single modal biometric systems. This paper further improves the novel approach based on Dynamic Bayesian Networks (DBNs) to bimodal speaker recognition. In the present paper, we investigate five different topologies of feature-level fusion framework using DBNs. We demonstrate that the performance of multimodal systems can be further improved by modeling the correlation of between the speech features and the face features appropriately. The experiment conducted on a multi-modal database of 54 users indicates promising results, with an absolute improvement of about 7.44% in the best case and 3.13% in the worst case compared with single modal speaker recognition system.	dynamic bayesian network;speaker recognition	Dongdong Li;Yingchun Yang;Zhaohui Wu	2006		10.1007/11608288_72	facial recognition system;speaker recognition;computer vision;speech recognition;systems modeling;facies;computer science;artificial intelligence;bayesian network;correlation;dynamic bayesian network;biometrics	Vision	45.51940944393257	-59.74779726417073	161962
20c0100b434feb429d518dc32978424eb71a2656	fast retrieval methods for images with significant variations	diamond;image databases;image matching;image database;image classification;visual scenes;diamonds;image histograms;large image databases;wavelet transforms;precious stones matching;wavelet transform;database searching;fast imaging;precious stones identification;diamond image retrieval visual databases image classification image matching wavelet transforms;image histograms fast image retrieval methods large image databases visual scenes database searching precious stones matching precious stones identification diamonds classifiers hierarchy wavelet transform;image retrieval image databases histograms information retrieval visual databases data engineering design engineering systems engineering and theory layout testing;classifiers hierarchy;fast image retrieval methods;visual databases;image retrieval	Fastimageretrieval is thekey to successfor operationson large imagedatabases, and a greatmany techniqueshave beendevelopedfor efficient retrieval. However, most of thesemethodsare tailored to visual scenesor to images having limited variations. In this paperwe investigatethe searchingof enormousdatabases (of up to images)for the matchingandidentificationof preciousstones(principally diamonds).Becauseof the sizeof the database, we proposea hierarchyof classifiers,whichsuccessi vely prune candidateimagessuchthatthemorecomplex classifiersare requiredto test only tiny portionsof the data. The new classifierdevelopedhereappliesa wavelettransformto imagehistogramsand is capableof rejecting99.9% of bad matches.	sizeof	Paul W. Fieguth;Riyin Wan	2000		10.1109/ICIP.2000.899470	computer vision;visual word;image retrieval;computer science;pattern recognition;data mining;mathematics;wavelet transform	Vision	39.662845373918984	-60.42712759880184	162094
bf8a10e62273858ca0ff8a5d4d3069203a7e1d88	the image retrieval method using multiple features	color space;curvature scale space;information retrieval;hsi;css;histogram intersection;image retrieval	There are various kinds' methods to method that image retrieval based on shape feature. In this paper, an efficient content-based image information retrieval method which utilizes shape information and color information is proposed. CSS(Curvature Scale Space) space is used to extract shape information. HSI(Hue Saturation Intensity) space is used to extract color information. This method expresses contours of the object which is binarized through pre-processes in CSS space, then extract shape features of the object in this space. CSS space is a space that expresses curvatures of contours in multiple resolutions, which offers shape features invariant to shift, scale, and skew of the object. HSI color space offers hue and saturation information which is less affected by change of brightness of image. This method gets histogram of the object's color, and then applies histogram intersection degree to the matching metric in searching process. Show result that image object retrieval being based on process and this that draw CSS information from reflex because an experiment uses ICSS method, and estimate performance by comparing old method and method that propose. The results of experiments show that the proposed method is better in accuracy of searching than existing methods.	image retrieval	Jeung-Yo Ha;Hyung-Il Choi	2007		10.1007/978-3-540-74472-6_80	color histogram;computer vision;image retrieval;computer science;pattern recognition;mathematics;cascading style sheets;color space	Vision	39.336358970947835	-59.45295348593013	162633
4b961c716449e9cf21f69874e1ade100f5c6cf59	robust facial landmarking for registration	reconnaissance visage;mimica;traitement signal;3d face recognition;image recognition;reconocimiento imagen;transformation cosinus;transformacion discreta;analisis factorial;image processing;analisis estructural;biometrie;mimique;estudio comparativo;transformation cosinus discrete;biometrics;biometria;procesamiento imagen;codigo bloque;filtro gabor;traitement image;extraccion parametro;parameter extraction;experimental result;subsystem;etude comparative;gabor filter;automatic recognition;analyse factorielle;extraction parametre;face recognition;sous systeme;factor analysis;discrete cosine transforms;pattern matching;signal processing;transformacion coseno;comparative study;discrete transformation;reconnaissance image;filtre gabor;pattern recognition;addition;correspondencia bloque;block matching;facial features;code bloc;face;concordance forme;reconnaissance forme;facial expression;correspondance bloc;analyse structurale;cosine transform;reconocimiento patron;cosine transformation;structural analysis;procesamiento senal;template matching;subsistema;block code;transformation discrete;based discrete cosine transform;reconocimiento automatico;structure analysis;reconnaissance automatique;adiccion	Finding landmark positions on facial images is an important step in face registration and normalization, for both 2D and 3D face recognition. In this paper, we inspect shortcomings of existing approaches in the literature and compare several methods for performing automatic landmarking on near-frontal faces in different scales. Two novel methods have been employed to analyze facial features in coarse and fine scales successively. The first method uses a mixture of factor analyzers to learn Gabor filter outputs on a coarse scale. The second method is a template matching of block-based Discrete Cosine Transform (DCT) features. In addition, a structural analysis subsystem is proposed that can determine false matches, and correct their positions.	discrete cosine transform;facial recognition system;gabor filter;structural analysis;template matching;three-dimensional face recognition	Albert Ali Salah;Hatice Çinar Akakin;Lale Akarun;Bülent Sankur	2007	Annales des Télécommunications	10.1007/BF03253251	computer vision;speech recognition;image processing;computer science;signal processing;structural analysis	Vision	45.062366220238346	-59.86744100608746	162735
197de6ae9c1dd985f59db3b7d1d4ff957af690e9	intelligent face recognition using feature averaging	reconnaissance visage;complex objects;aplicacion militar;systeme intelligent;application militaire;image processing;guerra;facies;image databank;sistema inteligente;information technology;securite informatique;procesamiento imagen;technologie information;intelligence artificielle;system performance;traitement image;computer security;war;face recognition;seguridad informatica;banco imagen;banque image;intelligent system;methode moyenne;military application;pattern recognition;terrorisme;advanced technology;artificial intelligence;inteligencia artificial;reconnaissance forme;reseau neuronal;reconocimiento patron;technologie avancee;tecnologia informacion;terrorismo;averaging method;red neuronal;guerre;metodo medio;tecnologia avanzada;terrorism;neural network	Over the past four years there has been a marginal increase in research on developing advanced information technologies that can be efficiently used for national and international security in our war against terrorism. The list of wanted persons who are still free is getting larger, however, in most cases there is a database containing their face images and this can be used in the development of face recognition systems. A human face is an extremely complex object with features that can vary over time, sometimes very rapidly. This paper presents a fast intelligent face recognition system that uses essential face features averaging and a neural network to identify multi-expression faces. A real life application using this method is implemented on 180 images of 30 persons. Experimental results suggest that this simple but efficient system performs well, thus providing a fast intelligent system for recognizing faces with different expressions.		Adnan Khashman;Akram A. Garad	2006		10.1007/11760146_38	face detection;simulation;facies;image processing;computer science;artificial intelligence;three-dimensional face recognition;terrorism;war;law;information technology;computer security	Vision	44.782171510253285	-59.2019687489021	162836
8f342fbbf1ca14b2f5ec3a136fd368503693a539	fundamental region based indexing and classification of islamic star pattern images	analisis imagen;modelizacion;information structure;image recognition;reconocimiento imagen;classification algorithm;image processing;structure information;computer model;extraction forme;estructura informacion;procesamiento imagen;angulo rotacion;image classification;traitement image;modelisation;extraccion forma;indexing;feature extraction;indexation;rotation angle;classification image;reconnaissance image;indizacion;pattern classification;pattern recognition;image analysis;angle rotation;reconnaissance forme;extraction caracteristique;reconocimiento patron;modeling;analyse image;pattern extraction;classification forme	In this paper, we propose a new method for the indexing and classification of Islamic Stars Pattern (ISP) images based on rotational symmetry information. A computational model for the extraction of rotational symmetry features is proposed. This model is based on the three following steps. First, we detect the rotation center of the ISP image, then we complete the image structure by using symmetry information. Second, we compute the angle of rotation and number of folds. Finally, we extract the fundamental region, a representative region in the image from which the whole image can be regenerated. A method is also proposed for indexing and classifying ISP images on the basis of the extracted features. The classification algorithm is based on the number of folds. We characterize an image by its fundamental region and by its class which is defined in the classification step. Experiments show promising results either for ISP images classification or indexing. Efforts for the subsequent task of repeated pattern images classification can be significantly reduced.	fundamental domain	Mohamed Ould Djibril;Youssef Hadi;Rachid Oulad Haj Thami	2006		10.1007/11867661_78	computer vision;search engine indexing;contextual image classification;image analysis;systems modeling;image processing;feature extraction;computer science;pattern recognition	Vision	43.28224289141055	-60.156429152840055	163371
fff1daa1aa8fc2af037162e3f08d36f075b138a9	maximum entropy random fields for texture analysis	gibbs distribution;digital library;texture synthesis;random fields;texture features;computer vision;multi resolution filters;gabor filter;texture analysis;probability distribution;image analysis;multi resolution;potential function;maximum entropy;random field	Texture is often used as a region descriptor in image analysis and computer vision. Texture analysis is an important research area with important applications to digital libraries and multi-media databases. This paper will focus on a novel texture model named the maximum entropy random field (MERF). The MERF is a random field built upon multi-resolution filters with the maximum entropy (ME) method. Its joint probability distribution can be considered as a Gibbs distribution. The multi-resolution filters play a central role in the MERF: they define the potential function in the Gibbs distribution of the random field, and they can be used to extract texture features in various orientations and scales. The experiments of texture synthesis illustrate using the MERF to describe textures. The experiments of texture retrieval compare the MERF based feature with Gabor filters based feature and the multi-resolution autoregressive based feature using the Brodatz database, which indicates that the MERF features provide the best pattern retrieval accuracy.		Xiangyu Yang;Jun Liu	2002	Pattern Recognition Letters	10.1016/S0167-8655(01)00092-7	image texture;computer vision;random field;digital library;image analysis;computer science;machine learning;pattern recognition;mathematics;texture compression;texture filtering;statistics	Vision	40.08962042504452	-62.24139795758067	163592
0239896b7e1b4c88ce1e787e7fd19649f7bb5cbc	shape features based conic arcs for leaf recognition	image segmentation;fitting;feature vector contour meaningful point conic arcs;shape;vectors;signal processing;pattern recognition;shape signal processing conferences pattern recognition image segmentation fitting vectors;conferences	The most widely used in the field of visual object recognition descriptive features are shape based features. Identify objects in the image, contour and region shape descriptors based on two main topics to be examined. In order to describe objects with lesser number of descriptors, linear or cubic curves are fitted to the contours of the objects. The end points of these finite length curves are usually meaningful spots on the contours, where these fittings are needed for the start and end points. Curves are fitted to the sub-contours between successive such descriptive points on the object contour. After fitting conic arcs according to the type of the cone defining an object in the image feature vector is obtained. Thus the object is depicted with fitted to the contour of the conic arcs and the line pieces.	contour line;cubic function;curve fitting;data descriptor;feature (computer vision);feature vector;mike lesser;outline of object recognition	Tolga Avci;Gursel Kokdemir;Zuhal Kurt;Kemal Özkan	2014	2014 22nd Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2014.6830516	computer vision;shape;computer science;signal processing;pattern recognition;mathematics;geometry;image segmentation	Vision	41.92746209183421	-59.46586320366065	163662
2748defe179c4978a2a49e55695ba87f1b9dfa1e	stroke-based semi-automatic region of interest detection algorithm for in-situ painting recognition	semi automatic roi detection;planar object;local binary pattern;recognition;hough transform	In the case of illumination and view direction changes, the ability to accurately detect the Regions of Interest (ROI) is important for robust recognition. In this paper, we propose a stroke-based semi-automatic ROI detection algorithm using adaptive thresholding and a Hough-transform method for in-situ painting recognition. The proposed algorithm handles both simple and complicated texture painting cases by adaptively finding the threshold. It provides dominant edges by using the determined threshold, thereby enabling the Hough-transform method to succeed. Next, the proposed algorithm is easy to learn, as it only requires minimal participation from the user to draw a diagonal line from one end of the ROI to the other. Even though it requires a stroke to specify two vertex searching regions, it detects unspecified vertices by estimating probable vertex positions calculated by selecting appropriate lines comprising the predetected vertices. In this way, it accurately (1.16 error pixels) detects the painting region, even though a user sees the painting from the flank and gives inaccurate (4.53 error pixels) input points. Finally, the proposed algorithm provides for a fast processing time on mobile devices by adopting the Local Binary Pattern (LBP) method and normalizing the size of the detected ROI; the ROI image becomes smaller in terms of general code format for recognition, while preserving a high recognition accuracy (99.51%). As such, it is expected that this work can be used for a mobile gallery viewing system.1	algorithm;hough transform;local binary patterns;mobile device;pixel;region of interest;semiconductor industry;thresholding (image processing);vertex (geometry)	Youngkyoon Jang;Woontack Woo	2011		10.1007/978-3-642-22024-1_19	computer vision;computer science;artificial intelligence;computer graphics (images);region of interest	Vision	39.928704067730344	-65.80577918219596	163994
235414eb177ce3c70492e7e9ca39cd1b12c2e7bc	content-based 3-d model retrieval: a survey	content management;content based retrieval biological system modeling biology computing feature extraction shape computational biology solid modeling design automation user interfaces particle measurements;modelizacion;evaluation performance;object recognition;search engine;buscador;performance evaluation;image processing;user interface;search engines;information retrieval;3 d shape;evaluacion prestacion;search engine content based 3d model retrieval canonical coordinate normalization feature extraction query representation user interface performance evaluation machine learning method traditional shape matching technique;extraction forme;interrogation base donnee;apprentissage conceptuel;procesamiento imagen;interrogacion base datos;semantics;bibliografia;bibliography;metric;reconnaissance objet;intelligence artificielle;indexing and retrieval;semantica;semantique;traitement image;similitude;canonical coordinate normalization;modelisation;3d model retrieval;3d model;aprendizaje conceptual;traditional shape matching technique;machine learning;extraccion forma;busqueda por contenido;three dimensional displays;shape matching;3 d object;pattern matching;feature extraction;query representation;similarity match;bibliographie;similarity;security key;pattern recognition;concept learning;artificial intelligence;machine learning method;metrico;user interfaces content based retrieval feature extraction learning artificial intelligence pattern matching search engines;inteligencia artificial;concordance forme;reconnaissance forme;content based 3d model retrieval;similitud;extraction caracteristique;moteur recherche;learning artificial intelligence;reconocimiento patron;cle securite;modeling;similarity measure;content based retrieval;user interfaces;pattern extraction;database query;recherche par contenu;similarity match 3 d object 3 d shape content based retrieval feature extraction query interface;query interface;metrique;llave seguridad	As the number of available 3D models grows, there is an increasing need to index and retrieve them according to their contents. This paper provides a survey of the up-to-date methods for content-based 3D model retrieval. First, the new challenges encountered in 3D model retrieval are discussed. Then, the system framework and some key techniques of content-based 3D model retrieval are identified and explained, including canonical coordinate normalization and preprocessing, feature extraction, similarity match, query representation and user interface, and performance evaluation. In particular, similarity measures using semantic clues and machine learning methods, as well as retrieval approaches using nonshape features, are given adequate recognition as improvements and complements for traditional shape-matching techniques. Typical 3D model retrieval systems and search engines are also listed and compared. Finally, future research directions are indicated, and an extensive bibliography is provided.		Yao Yang;H. Lin;Yongzhi Zhang	2007	IEEE Trans. Systems, Man, and Cybernetics, Part C	10.1109/TSMCC.2007.905756	document retrieval;computer vision;query expansion;visual word;concept learning;image processing;computer science;artificial intelligence;machine learning;data mining;semantics;term discrimination;user interface;vector space model;data retrieval;information retrieval;search engine;human–computer information retrieval;divergence-from-randomness model	Embedded	40.88295781984005	-59.99184424548568	164666
d7ba1fa7c6e3b047b687d9edafa5538dfd2359d7	boosting saliency in color image features	salient point detection;detectors;phase detection;color saliency boosting color image features salient point detection image differential structure color distinctiveness;information systems;color saliency boosting;color image features;feature extraction image colour analysis;data mining;information content;computer vision;boosting;shape;general methods;image color analysis;image colour analysis;feature extraction;intelligent systems;color distinctiveness;image differential structure;intelligent sensors;color image;boosting detectors computer vision phase detection shape data mining image color analysis intelligent systems intelligent sensors information systems	The aim of salient point detection is to find distinctive events in images. Salient features are generally determined from the local differential structure of images. They focus on the shape saliency of the local neighborhood. The majority of these detectors is luminance based which has the disadvantage that the distinctiveness of the local color information is completely ignored. To fully exploit the possibilities of color image salient point detection, color distinctiveness should be taken into account next to shape distinctiveness. In this paper color distinctiveness is explicitly incorporated into the design of saliency detection. The algorithm, called color saliency boosting, is based on an analysis of the statistics of color image derivatives. Isosalient color derivatives can be closely approximated by ellipsoidal surfaces in color derivative space. Based on this remarkable statistical finding, isosalient derivatives are transformed by color boosting to have equal impact on the saliency. Color saliency boosting is designed as a generic method easily adaptable to existing feature detectors. Results show that substantial improvements in information content are acquired by targeting color salient features. Further, the generality of the method is illustrated by applying color boosting to multiple existing saliency methods.	approximation algorithm;boosting (machine learning);color image;experiment;image derivatives;self-information;sensor	Joost van de Weijer;Theo Gevers	2005	2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)	10.1109/CVPR.2005.93	phase detector;computer vision;detector;color quantization;color normalization;self-information;color image;intelligent decision support system;feature extraction;shape;computer science;machine learning;pattern recognition;mathematics;boosting;information system;intelligent sensor	Vision	41.081937444476765	-61.044330382897975	164895
b577398f07412a316f46891a8a3afc0836e3aaf7	fuzzy logic supported primary edge extraction in image understanding	fuzzy systems conferences;digital image processing;fuzzy logic supported primary edge extraction;edge detection;information retrieval;features enhancement;image understanding;edge extraction;fuzzy set theory;information enhancement methods;large databases;fuzzy logic;image enhancement;image retrieval algorithms;feature extraction;image retrieval algorithms fuzzy logic supported primary edge extraction image understanding information enhancement methods digital image processing information retrieval large databases features enhancement;very large databases;very large databases edge detection feature extraction fuzzy logic fuzzy set theory image enhancement image retrieval;fuzzy systems;conferences;image retrieval	Recently, the importance of information enhancement methods in digital image processing has increased significantly. A large amount of research has been focused on information retrieval and image understanding. Typical examples are searching for similar objects/images in large databases and understanding the objects in images. The main point of these tasks is to extract the most characteristic features of the objects in the images, like edges, corners, characteristic textures, etc. Another very important aspect can be the separation of the ldquosignificantrdquo and ldquounimportantrdquo parts of these features, i.e. the enhancement of those features which carry primary information and to filter out the part which represents information of minor importance. By this, the complexity of the searching and/or interpreting algorithms can be decreased while the performance increased. This paper describes a new edge processing method which is able to extract the ldquoprimaryrdquo, i.e. those edges which can advantageously be used in sketch based image retrieval algorithms.	algorithm;computer vision;database;digital image processing;edge detection;fuzzy logic;image retrieval;information retrieval;texture mapping	Annamária R. Várkonyi-Kóczy;András Rövid	2008	2008 IEEE International Conference on Fuzzy Systems (IEEE World Congress on Computational Intelligence)	10.1109/FUZZY.2008.4630671	fuzzy logic;computer vision;visual word;edge detection;feature extraction;image retrieval;computer science;artificial intelligence;digital image processing;pattern recognition;fuzzy set;information retrieval;fuzzy control system	Vision	39.55631290872756	-60.8390558291933	165297
4837b3051bc6cbf44386e4093fba3e116a375ef0	discrimination of facial regions based on dynamic grids of point representations	dynamic graph matching;acoplamiento grafo;image processing;simulated annealing;classification;graph matching;traitement image;computer vision;couplage graphe;recuit simule;vision ordinateur;discriminacion;clasificacion;discrimination	(1) the choice of the filter set, (2) the selection of the positions of the nodes of the graph to represent the characteristic image information, (3) the generation of a representative reference pattern needed for the calculation of the classifications, and (4) a new two-step graph-matching approach based on the simulated annealing technique. The approach was tested on facial regions taking the eye region as an example target. A classification performance for the verification of eye regions of more than 93% was achieved.	matching (graph theory);simulated annealing	Rainer Herpers;Gerald Sommer	1998	IJPRAI	10.1142/S0218001498000257	computer vision;discrimination;simulated annealing;image processing;biological classification;computer science;machine learning;pattern recognition;mathematics;matching	Vision	43.25291895027134	-60.38452629300104	165314
7c67cab152a109660b02d16c05d2b4ef4531f6db	a three-module strategy for edge detection	deteccion borde;contour following;image numerique;image processing;edge detection;image edge detection image resolution detectors concurrent computing nearest neighbor searches smoothing methods;procesamiento imagen;contextual information;computerised pattern recognition;imagen nivel gris;gray level images;traitement image;sequential process;three module strategy;parallel process;learning edges;gray level images computerized pattern recognition computerized picture processing three module strategy edge detection parallel process sequential process nonmaximum deletion algorithm contextual information contour following learning edges binary edge images;computerized picture processing;image niveau gris;imagen numerica;computerised picture processing;digital image;parallel processing computerised pattern recognition computerised picture processing modules;binary edge images;nonmaximum deletion algorithm;grey level image;detection bord;modules;computerized pattern recognition;parallel processing	This paper presents a three-module strategy for edge detection. The first and the last module involve well-known methods: the first module is a parallel process computing local edge strength and direction while the last module is a sequential process following edges. The originality of the overall method resides in the intermediate module, seen as a generalization of the nonmaximum deletion algorithm. The role of this module is twofold: it enables one to postpone some deletion to the last module where contextual information is available and it transmits the local edge direction in order to guide the contour following. In addition, a new postprocessing called learning edges is proposed as a refinement of the method. The binary edge images extracted from various gray-level images illustrate the power of the pro-	algorithm;edge detection;refinement (computing)	Vinciane Lacroix	1988	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.9103	parallel processing;computer vision;edge detection;computer science;artificial intelligence;machine learning;modular programming;digital image	Vision	45.62580124904106	-65.14755089925418	167537
8f10e77cb947504f356bb95ab2f64036542d1b62	retrieval of 3d polygonal objects based on multiresolution signatures	mesh smoothing;multiresolution signature;characteristic feature vector;mesh resolution;polygonal object;ranking rate;individual feature;complex object;feature vector;average ranking rate;successive mesh erosion	In this paper we present a method for retrieving 3D polygonal objects by using two sets of multiresolution signatures. Both sets are based on the progressive elimination of object’s details by iterative processing of the 3D meshes. The first set, with five parameters, is based on mesh smoothing. This mainly affects an object’s surface. The second set, with three parameters, is based on difference volumes after successive mesh erosions and dilations. Characteristic feature vectors are constructed by combining the features at three mesh resolutions of each object. In addition to being invariant to mesh resolution, the feature vectors are invariant to translation, rotation and size of the objects. The method was tested on a set of 40 complex objects with mesh resolutions different from those used in constructing the feature vectors. By using all eight features, the average ranking rate obtained was 1.075: 37 objects were ranked first and only 3 objects were ranked second. Additional tests were carried out to determine the significance of individual features and all combinations. The same ranking rate of 1.075 can be obtained by using some combinations of only three features.	3d computer graphics;3d printing;antivirus software;electronic signature;feature vector;information systems research;international symposium on fundamentals of computation theory;iterative method;meshlab;smoothing;type signature	Roberto Lam;J. M. Hans du Buf	2011		10.1007/978-3-642-24031-7_14	computer vision;machine learning;pattern recognition;mathematics	Visualization	41.88310549747246	-62.319795856260846	168013
2d8ec65336b4080c99a8f5eb0138da44ef00e486	gaussian mrf rotation-invariant features for image classification	classification markov random field mrf gaussian mrf gmrf model isotropic anisotropic least squares estimate lse discrete fourier transform dft rotational invariance texture analysis;least squares estimate lse;gray level cooccurrence probability features;normal distribution;rotational invariance;frequency domain analysis;gaussian mrf gmrf model;rotation invariant texture features;markov random fields;image classification;isotropic;least squares approximation;gabor filters;indexing terms;texture features;classification;markov random field;image texture;markov random field models;laplacian pyramid;laplace equations;image enhancement;rotation invariance;texture analysis;statistical improvement;image interpretation computer assisted;anisotropic;feature extraction;markov random field mrf;anisotropic circular gaussian mrf model;discrete fourier transform;anisotropic magnetoresistance;gaussian mrf rotation invariant features;least squares estimate;models statistical;discrete fourier transform dft;artificial intelligence;algorithms;pattern recognition automated;gray level cooccurrence probability features gaussian mrf rotation invariant features image classification markov random field models texture rotation anisotropic circular gaussian mrf model rotation invariant texture features discrete fourier transform statistical improvement laplacian pyramid;markov processes;image texture image classification markov processes discrete fourier transforms;texture rotation;rotation;discrete fourier transforms;image classification least squares approximation discrete fourier transforms feature extraction gabor filters markov random fields anisotropic magnetoresistance image texture laplace equations frequency domain analysis;computer simulation;markov chains;algorithms artificial intelligence computer simulation image enhancement image interpretation computer assisted markov chains models statistical normal distribution pattern recognition automated rotation	Features based on Markov random field (MRF) models are sensitive to texture rotation. This paper develops an anisotropic circular Gaussian MRF (ACGMRF) model for retrieving rotation-invariant texture features. To overcome the singularity problem of the least squares estimate method, an approximate least squares estimate method is designed and implemented. Rotation-invariant features are obtained from the ACGMRF model parameters using the discrete Fourier transform. The ACGMRF model is demonstrated to be a statistical improvement over three published methods. The three methods include a Laplacian pyramid, an isotropic circular GMRF (ICGMRF), and gray level cooccurrence probability features.	approximation algorithm;circular convolution;circular shift;computer vision;discrete fourier transform;feature extraction;gaussian blur;grayscale;laplacian matrix;least squares;markov chain;markov random field;normal statistical distribution;scientific publication;technological singularity	Huawu Deng;David A. Clausi	2004	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2004.30	normal distribution;computer simulation;magnetoresistance;image texture;computer vision;markov chain;contextual image classification;index term;feature extraction;biological classification;rotation;rotational invariance;computer science;machine learning;discrete fourier transform;pattern recognition;mathematics;markov process;least squares;anisotropy;frequency domain;isotropy;statistics	Vision	40.75242816100826	-63.767047271383305	168640
8beda12bf9fd67064fd988f18c26c2eba3c7dcd4	object recognition based on binary partition trees	object recognition partitioning algorithms image segmentation shape image recognition cost function image processing image databases object detection noise shaping;object recognition;full search;image segmentation;image matching;object recognition trees mathematics image matching image segmentation image colour analysis;euclidean distance;trees mathematics;object shape model object recognition bpt binary partition tree shape matching technique distance map euclidean distance measurement colour based image segmentation;shape matching;image colour analysis;shape modeling	This paper presents an object recognition method that exploits the representation of the images obtained by means of a binary partition tree (BPT). The shape matching technique in which it is based was first presented in F. Marques et al., (2002). This method compares a transformed version of an object shape model (reference contour) to the contours of a partition of the image. The comparison is based on a distance map that measures the Euclidean distance between any points in the image to the partition contours. In F. Marques et al., (2002), this algorithm was applied using a colour-based segmentation of the image and a full-search was performed to find the best match between the searched object and the contours of this segmentation. Here, the information of the binary partition tree is used both to obtain the segmentation and to guide and reduce the search for the optimum match between the shape and the objects of the image.	algorithm;distance transform;euclidean distance;outline of object recognition	Oreste Salerno;Montse Pardàs;Verónica Vilaplana;Ferran Marqués	2004	2004 International Conference on Image Processing, 2004. ICIP '04.	10.1109/ICIP.2004.1419452	active shape model;image texture;computer vision;scale space;binary image;u-matrix;computer science;cognitive neuroscience of visual object recognition;machine learning;segmentation-based object categorization;pattern recognition;euclidean distance;mathematics;3d single-object recognition;image segmentation;distance transform;minimum spanning tree-based segmentation;scale-space segmentation	Vision	43.60621982269694	-66.12821983536585	168653
50b402fac92b6dd515a53a5b0f9da4e9bc133403	fingerprint minutiae matching with orientation and ridge	verification;doigt;alignement;base donnee;image processing;alignment defect;technology;computer science artificial intelligence;database;procesamiento imagen;base dato;traitement image;identificacion sistema;empreinte digitale;defaut alignement;science technology;defecto alineacion;system identification;automatic fingerprint identification system;system;dactyloscopie;alineamiento;tâche appariement;tarea apareamiento;fingerprint;finger;imaging science photographic technology;huella digital;computer science;dedo;computer science theory methods;matching task;alignment;identification systeme;fingerprint identification	An important step in automatic fingerprint identification system (AFIS) is fingerprint matching. The task of fingerprint matching is to verify whether two fingerprints are coming from same finger. In this paper we detail and discuss the fingerprint matching algorithm. A minutia matching algorithm is proposed which modified the algorithm presented by Jain et al. In this algorithm, in order to reduce the effect of noise and false minutiae, block orientation and ridge information are introduced into the minutiae-based matching algorithm in a simple but reliable way. Ridge information which is some sampled points in the ridge are used to align two fingerprints, in order to avoid misalign two fingerprints, we use block orientation to correct the ridge alignment. Experiments on the database FVC2002 show the performance.	algorithm;align (company);automated fingerprint identification;experiment;fingerprint recognition;minutiae	Jiangang Cheng;Jie Tian;Hong Chen	2004		10.1007/978-3-540-25948-0_49	fingerprint;computer vision;speech recognition;image processing;computer science;artificial intelligence;database	Vision	45.84681700982428	-59.686753085957754	168656
89e080df62d31788c7eec46225edabc008dc26fa	hidden markov model-based weighted likelihood discriminant for 2-d shape classification	analisis imagen;polynome zernike;metodo momento;fonction vraisemblance;generalized probabilistic descent method;object recognition;zernike moments;zernike polynomial;moment method;cost function;support vector machines hidden markov models image classification maximum likelihood estimation;support vector machines;fonction poids;maximum likelihood;pattern classification hidden markov models hmms image shape analysis;metodo descenso;hidden markov model;analisis forma;algorithms artificial intelligence computer simulation discriminant analysis image enhancement image interpretation computer assisted markov chains models statistical pattern recognition automated reproducibility of results sensitivity and specificity;modele markov variable cachee;maquina vector soporte;maximum vraisemblance;image classification;probabilistic approach;fonction discriminante;maximum likelihood estimation;fourier descriptor;discriminant function;funcion verosimilitud;hidden markov model zernike moments support vector machine classification fourier descriptor generalized probabilistic descent method weighted likelihood discriminant function 2d shape descriptor shape curvature traditional maximum likelihood method minimum error shape classification;polinomio zernike;machine vecteur support;hidden markov models;shape;weighted likelihood discriminant function;shape classification;enfoque probabilista;approche probabiliste;methode moment;signal classification;hidden markov models hmms;funcion peso;pattern classification;funcion discriminante;pattern recognition;classification signal;support vector machine classification;2d shape descriptor;image analysis;shape curvature;pattern analysis;reconnaissance forme;support vector machine;weight function;minimum classification error;reconocimiento patron;descent method;analyse image;minimum error shape classification;traditional maximum likelihood method;image shape analysis;likelihood function;reflection;maxima verosimilitud;analyse forme	The goal of this paper is to present a weighted likelihood discriminant for minimum error shape classification. Different from traditional maximum likelihood (ML) methods, in which classification is based on probabilities from independent individual class models as is the case for general hidden Markov model (HMM) methods, proposed method utilizes information from all classes to minimize classification error. The proposed approach uses a HMM for shape curvature as its 2-D shape descriptor. We introduce a weighted likelihood discriminant function and present a minimum classification error strategy based on generalized probabilistic descent method. We show comparative results obtained with our approach and classic ML classification with various HMM topologies alongside Fourier descriptor and Zernike moments-based support vector machine classification for a variety of shapes.	algorithm;align (company);appendix;class;classification;comparison and contrast of classification schemes in linguistics and metadata;discriminant analysis;drug vehicle;eighty;emulator;ergodicity;experiment;feature selection;gradient descent;heuristic;hidden markov model;hidden surface determination;iso/iec 11404;loss function;mpeg-7;mandibular right second molar tooth;markov chain;microsoft windows;ninety nine;seventy nine;shape context;statistical classification;subgroup;support vector machine;weight;window function	Ninad Thakoor;Jean Gao;Sungyong Jung	2007	IEEE Transactions on Image Processing	10.1109/TIP.2007.908076	support vector machine;computer science;machine learning;pattern recognition;mathematics;maximum likelihood;hidden markov model;statistics	Vision	40.656493067275456	-63.930379120897044	168849
973db0c69d72e0dc7bbd4092bc56e7ff41a78f30	imagegrep: fast visual pattern matching in image databases	databases;image database;data storage;pattern matching;indexation;spatial configuration;domain specificity;material properties;image retrieval	Most current image retrieval systems use holistic comparison that require a global match between images or presegmented object in images. However, often the user of an image database system is interested in a local match between images. For example, `Find images from the database with something like this anywhere in the image,' or `Fine images with something like this in some region of any image in the database,' or `Find images with this spatial configuration of regions like this.' In this paper, we provide an overview of a new framework that should help to allow these types of queries to be answered efficiently. In order to illustrate the usefulness of our framework, we have developed a complete image retrieval system based on local color information. Our system features fully automatic insertion and very efficient query execution, rivaling the efficiency of systems that can only handle global image comparisons. The query execution engine, called the ImageGREP Engine, can process queries at a speed of approximately 3000 images per second (or better) on a standard workstation when the index can be stored in main memory. In the future, we believe our framework should be used in other domains and applications, to handle queries based on texture or other material properties and perhaps domain specific image properties.© (1997) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	database;pattern matching	David A. White;Ramesh Jain	1997		10.1117/12.263447	feature detection;visual word;image processing;image retrieval;computer science;data mining;database;automatic image annotation;information retrieval	Vision	39.70116367144479	-60.522860810637546	168966
0bbd926b20039a3067094fcdee159490cc170b97	gender recognition: a multiscale decision fusion approach	libre mercado;texture;procesamiento informacion;sex;methode echelle multiple;database;base dato;sexe;metodo escala multiple;histograms of oriented gradients;data fusion;local binary pattern;marche concurrentiel;algorithme;algorithm;accuracy;histogram;histogram of oriented gradients;precision;histogramme;fusion donnee;information processing;textura;decision fusion;base de donnees;gender recognition;multiscale method;local binary patterns;open market;traitement information;fusion datos;histograma;sexo;algoritmo	Gender recognition from face images has many applications and is thus an important research topic. This paper presents an approach to gender recognition based on shape, texture and plain intensity features gathered at different scales. We also propose a new dataset for gender evaluation based on images from the UND database. This allows for precise comparison of different algorithms over the same data. The experiments showed that information from different scales, even if just from a single feature, is more important than having information from different features at a single scale. The presented approach is quite competitive with above 90% accuracy in both evaluated datasets.		Luís A. Alexandre	2010	Pattern Recognition Letters	10.1016/j.patrec.2010.02.010	local binary patterns;speech recognition;information processing;computer science;artificial intelligence;machine learning;accuracy and precision;statistics	Vision	44.721078886312526	-61.25233282130942	169471
f9b8d64c80518890491b19fb9bae1d0b5e97ed75	on selecting an appropriate colour space for skin detection	skin detection;vision ordenador;systeme detection peau;piel;analisis datos;peau;attribute selection;skin;computer vision;data analysis;machine learning;analyse donnee;vision ordinateur;learning artificial intelligence;false positive;discriminacion;discrimination;apprentissage intelligence artificielle	We present a comprehensive and systematic approach for skin detection. We have evaluated each component of several colour models, and then we selected a suitable colour model for skin detection. Such approach is well-known in the machine learning community as attribute selection. After listing the top components, we exemplify that a mixure of colour components can discriminate very well skin in both indoor and outdoor scenes. The spawning space created by such componens is nearly convex, therefore it allow us to use even simple rules to discriminate skin to non-skin points. These simple rules can recognise 96% of skin points with just 11% of false positives. This is a data analysis approach that will help to many skin detection systems.	apache axis;color space;complementarity theory;exemplification;image noise;machine learning;pixel;time complexity	G. Gómez;M. Sanchez;Luis Enrique Sucar	2002		10.1007/3-540-46016-0_8	computer vision;discrimination;type i and type ii errors;computer science;artificial intelligence;machine learning;skin;data analysis;feature selection	Vision	46.26572018802806	-59.924241930454016	169861
d2e04c9625ca39901158e9dd0e277e02c010d2c4	image segmentation for the application of the neugebauer colour prediction model on inkjet printed ceramic tiles	printing;analisis imagen;modelizacion;image segmentation;image processing;ceramic color;cube;imagen medio tinte;image demi teinte;cubo;half tone image;procesamiento imagen;contextual information;traitement image;modelisation;contexto;couleur ceramique;segmentation image;pattern recognition;contexte;impression;image analysis;prediction model;reconnaissance forme;reconocimiento patron;imagen color;impresion;modeling;analyse image;color ceramica;context;image couleur;color image	Colour prediction models (CPM) can be used to analyze the printing quality of halftone-based color printing systems. In this paper, we consider the Neugebauer CPM which requires as input the fraction of occupation of each primary. To obtain these numbers, we apply several image segmentation algorithms, with and without contextual information. These segmentation algorithms are evaluated with respect to another technique based on mixtures of factor analyzers. More importantly, the segmentation results are evaluated with respect to the performance of the Neugebauer CPM when used with the obtained fractions of occupation. This evaluation is carried out by comparing the predicted color against that measured with a spectrophotometer, and testifies for the adequacy of the approach.	algorithm;cpm-goms;color;image segmentation;iterated conditional modes;printing;monotone	Pedro Latorre Carmona;Guillermo Peris-Fajarnés;Mário A. T. Figueiredo	2005		10.1007/11559573_2	computer vision;image analysis;systems modeling;color image;image processing;computer science;cube;predictive modelling;image segmentation	Vision	45.56395947613889	-61.75330181290024	170756
0f8b21e0701b49632a908f660e51020dfc6acae3	statistical fourier descriptors for defect image classification	object shape;support vector machines;grey level images;statistical fourier descriptors;welding;image classification;shape feature extraction welding inspection support vector machines correlation discrete fourier transforms;inspection;fourier descriptors;shape;statistical analysis;welding seams;welding seams statistical fourier descriptors defect image classification object shape shape statistics grey level images;machine vision;feature extraction;machine vision fourier descriptors feature extraction defect image classification;statistical analysis fourier transforms image classification;fourier transforms;industrial application;defect image classification;correlation;shape statistics;discrete fourier transforms	In many industrial applications, Fourier descriptors are commonly used when the description of the object shape is an important characteristic of the image. However, these descriptors are limited to single objects. We propose a general Fourier-based approach, called statistical Fourier descriptor (SFD), which computes shape statistics in grey level images. The SFD is computationally efficient and can be used for defect image classification. In a first example, we deployed the SFD to the inspection of welding seams with promising results.	algorithmic efficiency;computer vision;feature extraction;grayscale;software bug;statistical shape analysis	Fabian Timm;Thomas Martinetz	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.1018	fourier transform;support vector machine;computer vision;contextual image classification;inspection;machine vision;feature extraction;shape;computer science;machine learning;pattern recognition;mathematics;geometry;correlation;welding	Vision	41.0111636225115	-60.986228107706545	171845
e64ae712f5c50a571378efeb617d3f014d250672	deriving texture feature set for content-based retrieval of satellite image database	benchmark;performance;image database;euclidean distance;texture features;similarity retrieval;image texture;quadrature mirror filter;gabor filter;quadrature mirror filter deriving texture feature set content based retrieval satellite image database performance transformed based texture features spatial based texture features benchmark brodatz set normalized euclidean distance gabor filter transformed based feature sets;feature extraction;remote sensing;spatial based texture features;satellite image;difference set;normalized euclidean distance;transformed based feature sets;satellite image database;content based retrieval;deriving texture feature set;remote sensing visual databases image texture feature extraction;transformed based texture features;brodatz set;information retrieval image retrieval content based retrieval satellites image databases gabor filters videos euclidean distance indexing instruments;visual databases	In this paper, the performance of similarity retrieval from satellite image databases by using different sets of spatial and transformed-based texture features is evaluated and compared. A benchmark consisting of 37 satellite image clips from various satellite instruments is devised for the experiments. We show that although the proposed feature set perform only slightly better with the Brodatz set, its performance is far superior for the satellite images. The result indicates that more than 25% of the benchmark patterns can be retrieved with more than 80% accuracy by using normalized Euclidean distance. In contrast, less than 10% of the patterns are retrieved with more than 80% accuracy by using transformed-based feature sets (such as those based on Gabor filter or quadrature mirror filter (QMF)).		Chung-Sheng Li;Vittorio Castelli	1997		10.1109/ICIP.1997.647978	image texture;computer vision;benchmark;performance;feature extraction;computer science;quadrature mirror filter;pattern recognition;euclidean distance;mathematics;information retrieval;difference set	Vision	39.24173446891246	-60.70051398346729	172000
2e9c1868b22ccc201c6488a137b43d366e3536c7	quality-augmented fusion of level-2 and level-3 fingerprint information using dsm theory	discrete wavelet transforms;level 2;virtual memory;control de calidad;belief;belief function;dezert smarandache theory;computacion informatica;discrete wavelet transform;shared memory;image processing;redundancia;memoria compartida;biometrie;biometrics;redundant discrete wavelet transform;database;biometria;procesamiento imagen;base dato;transformation ondelette discrete;intelligence artificielle;aprendizaje probabilidades;data fusion;high precision;classification;qualite image;traitement image;empreinte digitale;quality assessment;croyance;redundancy;plausible and paradoxical reasoning;fingerprint recognition;ciencias basicas y experimentales;fusion donnee;precision elevee;image quality;dactyloscopie;memoire virtuelle;base de donnees;precision elevada;controle qualite;fonction generalisee;fingerprint;apprentissage probabilites;artificial intelligence;generalized function;calidad imagen;information fusion;huella digital;inteligencia artificial;theorie information;creencia;grupo a;fusion datos;quality control;funcion generalizada;clasificacion;memoria virtual;probability learning;information theory;fingerprint identification;redondance;memoire partagee;teoria informacion	Existing algorithms that fuse level-2 and level-3 fingerprint match scores perform well when the number of features are adequate and the quality of images are acceptable. In practice, fingerprints collected under unconstrained environment neither guarantee the requisite image quality nor the minimum number of features required. This paper presents a novel fusion algorithm that recognizes fingerprint images with high accuracy under these non-ideal conditions. The match scores obtained from level-2 and level-3 classifiers are first augmented with a quality score that is quantitatively determined by applying redundant discrete wavelet transform to a fingerprint image. We next apply generalized belief functions of Dezert Smarandache theory to effectively fuse the quality-augmented match scores obtained from level-2 and level-3 classifiers. Unlike statistical and learning based fusion techniques, the proposed plausible and paradoxical reasoning approach effectively mitigates conflicting decisions obtained from classifiers especially when the evidences are imprecise due to poor image quality or limited fingerprint features. The proposed quality-augmented fusion algorithm is validated using a comprehensive database which comprises of rolled and partial fingerprint images of varying quality with arbitrary number of features. The performance is compared with existing fusion approaches for different challenging realistic scenarios.	algorithm;discrete wavelet transform;experiment;fingerprint;image quality;machine learning;minutiae;uncontrolled format string	Mayank Vatsa;Richa Singh;Afzel Noore;Max M. Houck	2009	Int. J. Approx. Reasoning	10.1016/j.ijar.2008.01.009	fingerprint;speech recognition;image processing;information theory;computer science;artificial intelligence;algorithm	Vision	45.698927788930376	-60.63325438809879	172077
70ab5e6c531ea16ec2739cb11d90ead9c1c7168a	a region-based image retrieval system using salient point extraction and image segmentation	image features;image segmentation;image processing;recherche image;image databank;information retrieval;texture image;procesamiento imagen;image indexing;salient point extraction;systeme recuperation;texture features;traitement image;region based image retrieval;image texture;indexing;recherche information;banco imagen;indexation;banque image;segmentation image;image search;indizacion;recuperacion informacion;content based retrieval;recherche par contenu;image retrieval;retrieval systems	Although most image indexing schemes are based on global image features, they have limited capability because they cannot capture local variations of the image properly. In order to solve this problem, we propose a new region-based image retrieval system. Since objects are important for image search in a huge database, we first find the important region including an interesting object using image segmentation and salient point extraction. We then find color and texture features in each important region. We have demonstrated that the color and texture information in the important region is very useful for improving performance of the image retrieval system.	image retrieval;image segmentation	Heekyung Lee;Yo-Sung Ho	2002		10.1007/3-540-36228-2_27	image quality;image warping;image texture;computer vision;search engine indexing;feature detection;visual word;binary image;image processing;image retrieval;computer science;segmentation-based object categorization;digital image processing;pattern recognition;region growing;image segmentation;scale-space segmentation;automatic image annotation;feature;information retrieval	Vision	43.19422186591434	-61.45228804985225	172361
3a6b6847d8a1bcf8f1a86cce8f7252733f4b311c	boosting color saliency in image feature detection	analisis imagen;index terms image saliency;image saliency;image features;feature detection;detection forme;detecteur image;supervised learning;analisis forma;boosting computer vision detectors event detection shape image color analysis image analysis algorithm design and analysis statistical analysis statistics;image statistics;indexing terms;shape detection;classification;atencion visual;information content;color imaging index terms image saliency feature detection image statistics;color imaging image feature detection local color information salient point detection color saliency boosting statistical analysis color image derivatives;deteccion forma;algorithms artificial intelligence color colorimetry image enhancement image interpretation computer assisted information storage and retrieval pattern recognition automated reproducibility of results sensitivity and specificity;statistical analysis;statistique image;image colour analysis;feature extraction;color imaging;statistical analysis feature extraction image colour analysis;image analysis;pattern analysis;detector imagen;attention visuelle;apprentissage supervise;imagen color;visual attention;aprendizaje supervisado;analyse image;clasificacion;image couleur;image sensor;analyse forme;color image	The aim of salient feature detection is to find distinctive local events in images. Salient features are generally determined from the local differential structure of images. They focus on the shape-saliency of the local neighborhood. The majority of these detectors are luminance-based, which has the disadvantage that the distinctiveness of the local color information is completely ignored in determining salient image features. To fully exploit the possibilities of salient point detection in color images, color distinctiveness should be taken into account in addition to shape distinctiveness. In this paper, color distinctiveness is explicitly incorporated into the design of saliency detection. The algorithm, called color saliency boosting, is based on an analysis of the statistics of color image derivatives. Color saliency boosting is designed as a generic method easily adaptable to existing feature detectors. Results show that substantial improvements in information content are acquired by targeting color salient features.	algorithm;boosting (machine learning);color image;detectors;experiment;feature (computer vision);feature detection (computer vision);feature detection (web development);generic drugs;image derivatives;self-information	Joost van de Weijer;Theo Gevers;Andrew D. Bagdanov	2006	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2006.3	computer vision;image analysis;index term;self-information;color image;feature extraction;biological classification;computer science;pattern recognition;feature detection;image sensor;supervised learning;feature;computer graphics (images)	Vision	41.46299488081065	-61.18232248836329	173328
a63c4c82ebdf15b298cb29845aecac3865248f65	dimensionality reduction using multi-dimensional scaling for content-based retrieval	high dimensionality;neural networks;software libraries;image databases;query processing;multi dimensional scaling;image database accessing;iterative methods visual databases query processing feature extraction image texture computational complexity;information retrieval;nonlinear pca algorithm;digital library;digital libraries;image database;retrieval performance;aerial photo database;gabor filters;thesauri;image texture;feature vector;iterative methods;dimensionality reduction;computational complexity;feature extraction;principal component analysis;nonlinear principal components analysis;spatial databases;multidimensional scaling;pattern recognition;feature vector size reduction;tiles;experiment;image content based retrieval;database retrieval;iterative majorization;information retrieval spatial databases principal component analysis image retrieval image databases content based retrieval software libraries image texture pattern recognition;dimensional reduction;retrieval performance multidimensional scaling content based retrieval dimensionality reduction image content based retrieval digital libraries image database accessing computation time reduction image texture nonlinear principal components analysis feature vector size reduction nonlinear pca algorithm database retrieval experiment aerial photo database iterative majorization;content based retrieval;computation time reduction;visual databases;image retrieval	There has been much interest recently in image content based retrieval, with applications to digital libraries and image database accessing. One approach to this problem is to base retrieval from the database upon feature vectors which characterize the image texture. Since feature vectors are often high dimensional, multi-dimensional scaling, or non-linear principal components analysis (PCA) may be useful in reducing feature vector size, and therefore computation time. We have investigated a variant of the non-linear PCA algorithm described by Webb (see Pattern Recognition, vol.28, no.6, p.753-9, 1995) and its usefulness in the database retrieval problem. The results are quite impressive; in an experiment using an aerial photo database, the feature vector length was reduced by a factor of 10 without significantly reducing the retrieval performance.		Morris Beatty;B. S. Manjunath	1997		10.1109/ICIP.1997.638626	visual word;digital library;feature vector;multidimensional scaling;computer science;machine learning;pattern recognition;data mining;feature;information retrieval	Web+IR	39.57405096092433	-60.240465693089455	173787
c016930b8ff01b566233e686dd12daba26dd6edc	colour image skeletonisation	image recognition;image coding;standards;skeleton;morphological operations;vectors;image color analysis;image color analysis vectors skeleton morphological operations image recognition image coding standards	In this paper a new morphological technique suitable for colour image skeleton extraction is presented. Vector morphological operations are defined by means of a new ordering of vectors of the HSV colour space, which is a combination of conditional and partial sub-ordering. Then, these are used to extract skeletons of colour images in terms of erosions and openings. The proposed method was tested with a variety of images and such experimental results are provided. Its applications include image compression and recognition problems.	color image;color space;conditional (computer programming);image compression;mathematical morphology	Ioannis Andreadis;Maria I. Vardavoulia;Gerasimos Louverdis;Nikos Papamarkos	2000	2000 10th European Signal Processing Conference		arithmetic;image texture;computer vision;feature detection;morphological skeleton;color image;image gradient;binary image;u-matrix;image processing;mathematics;computer graphics (images)	Vision	43.08914269158713	-65.97532770077883	173919
605499ba0da99af7cf2e204ed0bfb16ac7ddce89	research on medical image retrieval based on arbitrary shape	mirror padding;content based;medical image retrieval;medical images;visual features extraction;medical image processing content based retrieval feature extraction;medical imaging technology;spurious high frequency component content based medical image retrieval arbitrary shape medical imaging technology information technology cbmir low level visual feature extraction mirror padding;会议论文;arbitrary shape medical image retrieval mirror padding;visualization;shape;feature extraction;medical image processing;high frequency components;feature extraction image retrieval shape medical diagnostic imaging visualization algorithm design and analysis;arbitrary shape;content based retrieval;algorithm design and analysis;medical diagnostic imaging;image retrieval	Nowadays, with the rapid development of medical imaging technology and information technology more and more medical images are available. Medical image retrieval plays increasingly important role in medical applications. Content-based medical image retrieval (CBMIR) poses unique challenges due to the unique characteristics of medical images. While current research of CBMIR focuses on low-level visual features extraction, we propose a novel medical image retrieval algorithm based on arbitrary shape by combining low-level visual features extraction and mirror-padding, which has the merit of relieving the spurious high frequency components as introduced by no-padding. The efficiency of the proposed algorithm for medical image retrieval is analyzed and verified through experimental results.	algorithm;feature extraction;high- and low-level;image retrieval;imaging technology;medical imaging;relevance feedback	Qimin Cheng;Yulan Shen;Zhenfeng Shao;Dongyang Li	2012	2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing	10.1109/IIH-MSP.2012.114	algorithm design;computer vision;visual word;visualization;feature extraction;image retrieval;shape;computer science;multimedia;information retrieval	Vision	39.35111373994429	-59.67952702240642	175200
a5e3bf27ed820fe286eab16cd2cd701835126e10	character image enhancement by selective region-growing	metodo adaptativo;hand writing;preprocesor;binary image;preprocesseur;preprocessor;caracter impreso;printed character;methode adaptative;image enhancement;reconnaissance caractere;escritura manual;adaptive method;image binaire;imagen binaria;region growing;article;caractere imprime;character recognition;reconocimiento caracter;ecriture	"""Preprocessing of character images is an important step in recognition. We describe a method of enhancing binary character images to assist the subsequent recognition process in both handwritten and machine-printed documents. The method performs selective and adaptive stroke """"filling"""" with a neighborhood operator which emphasizes stroke connectivity. An improvement of 7% points was realized in recognition of address fields."""	document;image editing;preprocessor;printing;region growing	Zhixin Shi;Venu Govindaraju	1996	Pattern Recognition Letters	10.1016/0167-8655(95)00126-3	computer vision;speech recognition;binary image;computer science;artificial intelligence;machine learning;region growing;preprocessor	Vision	46.21379975857059	-64.07721759761199	175906
0c8a80bfea4711e67df048b6d8d41d163551d62f	method for automatic karyotyping of human chromosomes based on the visual attention system	vision ordenador;image segmentation;image processing;texture image;biologia molecular;procesamiento imagen;neural net architecture;traitement image;image texture;computer vision;human visual system;molecular biology;region of interest;segmentation image;architecture reseau neuronal;vision ordinateur;visual attention;biologie moleculaire	The present article constitutes a contribution to the diagnosis attended by computer, concretely in the field of the chromosomes Classification. This task plays an important role in as otltstanding questions as the infantile prcdiagnosis aJ)d in the citogenetics of the cancer. The proposed architecture is biologically inspired on the behavior of tile human visual system. Thus, the operation in preattcntive way is modeled, by means of a module in charge to make the segregation figure-ground, using features of the visual attention system. Of the same lbrm, the attentive operation is modeled, by means of a module that takes care of the regions of interest sequentially (possible objects) secreted by the preattentive module. For each region it extracts the emergent features, and it adapts them before sending them to the recognition module. This last module as much receives the information of the preattentive module as of the attentive module, and makes the identification of the attended object. The attentive process is iterated until they are not left more interesting regions in the image. The proposed model is applied to the analysis of chromosomes, in an attempt to automate a tedious and expensive process in time. 1,1 addition, it is tried to avoid that the user must take part in some of the stages of the recognition.	care-of address;emergence;iteration;region of interest	José Fernando Díez Higuera;Francisco Javier Díaz Pernas	1999		10.1007/BFb0100507	image texture;computer vision;image processing;computer science;artificial intelligence;machine learning;image segmentation;human visual system model;region of interest	AI	45.516720565898616	-64.90810183244513	175953
4fe99a52d8964d234099466b866be2400a023f9a	correntropy based matched filtering for classification in sidescan sonar imagery	high order moments;correntropy based matched filtering;sidescan sonar imagery;nonlinear extension;cost function;image classification;sidescan sonar imagery correntropy matched filtering clssification;prior knowledge;template design;sonar imaging decision theory higher order statistics image classification matched filters object detection;matched filters filtering data mining shape sonar measurements object detection training data testing noise shaping image databases;data mining;sonar imaging;higher order statistics;clssification;high order moments correntropy based matched filtering sidescan sonar imagery mine classification nonlinear extension decision statistic shape variability template design;correntropy;shape;mine classification;feature extraction;decision theory;matched filters;correlation;matched filter;shape variability;matched filtering;object detection;noise;decision statistic;sonar	This paper presents an automated way of classifying mines in sidescan sonar imagery. A nonlinear extension to the matched filter is introduced using a new metric called correntropy. This method features high order moments in the decision statistic showing improvements in classification especially in the presence of noise. Templates have been designed using prior knowledge about the objects in the dataset. During classification, these templates are linearly transformed to accommodate for the shape variability in the observation. The template resulting in the largest correntropy cost function is chosen as the object category. The method is tested on real sonar images producing promising results considering the low number of images required to design the templates.	algorithm;correspondence problem;image fusion;kernel method;link/cut tree;loss function;matched filter;nonlinear system;sonar (symantec);spatial variability;template matching	Erion Hasanbelliu;José Carlos Príncipe;K. Clint Slatton	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346575	computer vision;speech recognition;computer science;pattern recognition;matched filter	Robotics	40.48731531789582	-61.493522255539304	176000
4ced397335977d29ddb1fa769ecf14353448fcfb	improving user control with minimum involvement in user-guided segmentation by image foresting transform	image foresting transform;user involvement	The image foresting transform (IFT) can divide an image into object and background, each represented by one optimum-path forest rooted at internal and external markers selected by the user. We have considerably reduced the number of markers (user involvement) by separating object enhancement from its extraction. However, the user had no guidance about effective marker location during extraction, losing segmentation control. Now, we pre-segment the image automatically into a few regions. The regions inside the object are selected and merged from internal markers. Regions with object and background pixels are further divided by IFT. This provides more user control with minimum involvement, as validated on two public datasets.		Thiago Vallin Spina;Javier A. Montoya-Zegarra;Paulo André Vechiatto Miranda;Alexandre X. Falcão	2009		10.1007/978-3-642-03767-2_118	computer vision;simulation;computer science;multimedia	Vision	42.80569166800395	-65.31684167940524	176213
ab6566378311a7640b364ba008ae9fbd3fd8c8d9	hierarchical partitions for content image retrieval from large-scale database	busqueda informacion;hierarchical clustering;analisis contenido;hierarchical partitioning;vision ordenador;contenu image;global solution;analyse amas;image content;raisonnement base sur cas;razonamiento fundado sobre caso;base donnee;multimedia;image processing;metadata;recherche image;information retrieval;base donnee tres grande;biometrie;biometrics;database;biometria;divertissement;procesamiento imagen;base dato;hombre;optimum global;multimedia application;intelligence artificielle;global optimum;data mining;traitement image;computer vision;objective function;very large database;large scale;content analysis;hierarchical classification;cluster analysis;proximite;proximidad;fouille donnee;recherche information;tratamiento digital;proximity;semantic gap;human;metadonnee;visual features;pattern recognition;classification hierarchique;aparato visual;artificial intelligence;appareil visuel;analisis cluster;vision ordinateur;digital processing;metadatos;solution globale;inteligencia artificial;reconnaissance forme;analyse contenu;very large databases;case based reasoning;analisis semantico;reconocimiento patron;analyse semantique;content based image retrieval;contenido imagen;visual system;clasificacion jerarquizada;content based retrieval;optimo global;busca dato;solucion global;entertainment;recherche par contenu;traitement numerique;semantic analysis;homme;image retrieval	Increasing of multimedia applications in commerce, biometrics, science, entertainments etc. leads to a great need of processing of digital visual content stored in very large databases. Many systems combine visual features and metadata analysis to solve the semantic gap between low-level visual features and high-level human concept, i.e. there arises a great interest in content-based image retrieval (CBIR) systems. As retrieval is computationally expensive, one of the most challenging moments in CBIR is minimizing of the retrieval process time. Widespread clustering techniques allow to group similar images in terms of their features proximity. The number of matches can be greatly reduced, but there is no guarantee that the global optimum solution is obtained. We propose a novel hierarchical clustering of image collections with objective function encompassing goals to number of matches at a search stage. Offered method enables construction of image retrieval systems with minimal query time.	analysis of algorithms;biometrics;cluster analysis;content-based image retrieval;database;global optimization;hierarchical clustering;high- and low-level;loss function;optimization problem	Dmitry Kinoshenko;Vladimir Mashtalir;Elena Yegorova;Vladimir Vinarsky	2005		10.1007/11510888_44	case-based reasoning;computer vision;entertainment;visual word;visual system;content analysis;image processing;image retrieval;computer science;artificial intelligence;data mining;database;hierarchical clustering;global optimum;cluster analysis;distance;metadata;automatic image annotation;semantic gap;biometrics;very large database	Vision	43.14972990180327	-61.05470896914823	176831
a95e770ad8e392dfd584a1063d9178ce3b70253a	detecting periodic structure	responsible features;dominant spectral frequencies;global threshold;electrical capacitance tomography;recursive implementation;conformity;periodic structures autocorrelation adaptive filters electrical capacitance tomography laboratories educational institutions read only memory layout convolution statistics;convolution;local neighbourhood;recursive implementation periodic structure global threshold responsible features autocorrelation adaptive filter conformity local neighbourhood dominant spectral frequencies local feature strength;periodic structure;layout;fourier transforms feature extraction image sequences adaptive filters;adaptive filters;local features;feature extraction;periodic structures;fourier transforms;statistics;local feature strength;read only memory;adaptive filter;autocorrelation;image sequences	We present a novel method for the detection of periodic structure in images. Finding a global threshold to detect a significant frequency component, and then associating it with responsible features, is fragile. The novel method extracts features from the original signal, and uses their autocorrelation as the basis for an adaptive filter, with which they are convolved. This convolution represents the conformity of a local neighbourhood to the dominant spectral frequencies: combined with the original feature signal, it effectively incorporates the property of periodicity into a local feature strength. A recursive implementation is suggested. This novel method avoids the fragility associated with global thresholds, and is shown to work on real data.	adaptive filter;autocorrelation;conformity;convolution;quasiperiodicity;recursion	James Orwell;James F. Boyce;John F. Haddon;Gregory H. Watson	1998		10.1109/ICPR.1998.711244	adaptive filter;computer vision;computer science;machine learning;pattern recognition;mathematics;statistics	Vision	39.50399426791758	-63.501273743947145	176914
41c26b39eb871069944ab3c756f34fa1c7275f73	skeletonization application: chinese calligraphy character representation and reconstruction		Chinese calligraphy is often used to perform the beauty of characters in Chinese culture and is quite suitable in the study of shape representation. The skeleton of a digital line pattern can be treated as the shape descriptor. However, the skeleton-biased and reconstruction-incomplete phenomena often exist in a skeletonization method, which results in the difficulty of using the skeleton to perform the beauty of Chinese calligraphy characters. To overcome this difficulty, skeletal line information derived from the skeletal points and indexed boundary points is defined, and its transformation is implemented by a procedure of two-phase skeletal line placement (SLP). Based on the SLP, an effective algorithm including the SLP-stroke for strokes, SLP-fork for forks, and SLP-end for the end parts of strokes is developed for constructing the skeletal line-based shape descriptor. Four indices of measurement of skeleton deviation, number of distorted forks, number of spurious strokes, and measurement of reconstructability are used to evaluate the performance of the proposed approach. Experimental results show that the skeleton-biased phenomenon can be greatly reduced and the pattern reconstructability close to 100% is achieved, thus confirming that the proposed skeletonization approach is suitable for the Chinese calligraphy character representation and reconstruction.	topological skeleton	Yung-Sheng Chen;Ming-Te Chao	2018	J. Electronic Imaging	10.1117/1.JEI.27.5.051202	computer vision;artificial intelligence;skeleton (computer programming);medial axis;computer science;pattern recognition;skeletonization;calligraphy;phenomenon	NLP	43.79735248005416	-64.9105856601231	177763
c3dac928bb7ecdd8e66fe08ad110ad76ba776f12	phase based 3d texture features	texturation;tissu;integrated approach;image tridimensionnelle;funcion haar;texture;laser sounding;invariance echelle;fonction haar;sondeo laser;convolution;spherical harmonic;haar function;extraction forme;database;base dato;convolucion;segmentation;imagen nivel gris;invarianza escala;harmonique spherique;texture features;classification;gray scale;voxel;tejido;extraccion forma;feature extraction;image niveau gris;textura;base de donnees;tissue;pattern recognition;texturacion;tridimensional image;invariante;armonica esferica;feature selection;sondage laser;reconnaissance forme;extraction caracteristique;3d laser scanning;reconocimiento patron;echelle gris;grey level image;pattern extraction;clasificacion;segmentacion;escala gris;invariant;scale invariance;invariant feature;imagen tridimensional;volume data	In this paper, we present a novel method for the voxel-wise extraction of rotation and gray-scale invariant features. These features are used for simultaneous segmentation and classification of anisotropic textured objects in 3D volume data. The proposed new class of phase based voxel-wise features achieves two major properties which can not be achieved by the previously known Haar-Integral based gray-scale features [1]: invariance towards non-linear gray-scale changes and a easy to handle data driven feature selection. In addition, the phase based features are specialized to encode 3D textures, while texture and shape information interfere in the Haar-Integral approach. Analog to the HaarIntegral features, the phase based approach uses convolution methods in the spherical harmonic domain in order to achieve a fast feature extraction. The proposed features were evaluated and compared to existing methods on a database of volumetric data sets containing cell nuclei recorded in tissue by use of a 3D laser scanning microscope.	3d computer graphics;convolution;encode;experiment;feature extraction;feature selection;grayscale;haar wavelet;microsoft outlook for mac;nonlinear system;texture mapping;voxel	Janis Fehr;Hans Burkhardt	2006		10.1007/11861898_27	computer vision;feature extraction;biological classification;computer science;machine learning;invariant;scale invariance;convolution;texture;voxel;feature selection;segmentation;grayscale;spherical harmonics	Vision	45.14732003108814	-60.75912946552666	178046
0ad66b77e61113a175c5ab0de8c869a49884b078	facial feature location with delaunay triangulation/voronoi diagram calculation	edge enhancement;delaunay triangulation;facial feature extraction;skeleton;point set cluster;video coding;face modeling;voronoi diagram delaunay triangulation;eyes mouth corners;facial features;voronoi diagram	Facial features determination is essential in many applications such as personal identification, 3D face modeling and model based video coding. Fast and accurate facial feature extraction is stil l a fi led to be explored. In this paper, an automatic extracting algorithm is developed to locate “key points” of facial features. The Delaunay Triangulation/Voronoi Diagram technique well known in computational geometric is applied on the edge enhanced binarized facial image. Facial features are classified and extracted in terms of various types of Delaunay triangles and the dual of a subset of the Delaunay triangles, Voronoi edges form the skeleton of facial skin. That is, facial feature's shape is described by Delaunay Triangulation/Voronoi Diagram. Furthermore, the facial features can be identified. The method succeeds in locating facial features in the facial region exactly and is insensitive to face deformation. The method is executable in a reasonably short time.	algorithm;data compression;delaunay triangulation;executable;feature extraction;voronoi diagram	Yi Xiao;Hong Yan	2001			computer vision;delaunay triangulation;voronoi diagram;pitteway triangulation;point set triangulation;mathematics;geometry;constrained delaunay triangulation;engineering drawing;bowyer–watson algorithm	Vision	44.45897329049768	-64.77496237753319	178153
0774099e8da99ad4ebc829c41c409f1016abbc2b	score level fusion of voting strategy of geometric hashing and surf for an efficient palmprint-based identification	palmprint;geometric hashing;voting score;indexing;identification;surf and fusion	This paper proposes an efficient indexing scheme for palmprint-based identification system. The proposed system uses geometric hashing of SURF key-points to index the palmprint into hash table and makes score level fusion of voting strategy based on geometric hashing and SURF score to identify the live palmprint. All ordered pairs of SURF key-points of the palmprint are scaled and mapped to a predefined coordinate system and all other points are similarity transformed. The new location after transformation serves as the index of the hash table. During identification, all ordered pairs of key-points of live palmprint are scaled and mapped to the coordinate system while remaining points are similarity transformed. A vote is casted to all images in the corresponding bins. Images having votes more than certain threshold are considered as candidate images of the live palmprint. SURF features of the live palmprint and the candidate images are compared for matching. Matching scores which are based on SURF key-points and vote of the corresponding candidate image are fused using weighted sum rule. The candidate image with the highest fused score is considered as the best match. The system is tested on IITK, CASIA and PolyU datasets. It has been observed that penetration rate of the proposed system is less than 30% for 0% bin miss rate (BMR) and has the identification accuracy of more than 97% for all three datasets. Further, the system is evaluated for robustness on downscaled and rotated. It has been found that the identification accuracy of the system for top best match is more than 90% for images downscaled up to 49% and accuracy is more than 85% when images are rotated at any angle.	fingerprint;geometric hashing;hash table;ordered pair;speeded up robust features;sum rule in quantum mechanics;weight function	G. S. Badrinath;Phalguni Gupta;Hunny Mehrotra	2011	Journal of Real-Time Image Processing	10.1007/s11554-011-0229-2	identification;computer vision;search engine indexing;computer science;pattern recognition;data mining	Vision	39.250638424822974	-59.16230788780954	178711
81f67ede979702fd7d0e723f398524cdfed47df6	a multiresolution color clustering approach to image indexing and retrieval	image resolution;query processing;image indexing;color histogram;pattern recognition image colour analysis image resolution feature extraction indexing query processing filtering theory octrees visual databases;indexing;image colour analysis;feature extraction;pattern recognition;performance multiresolution color clustering image indexing image retrieval color feature extraction octree data structure multiple color features dominant color color histogram distinctive colors selective filtering;image resolution indexing image retrieval color quantization feature extraction histograms filtering robustness information retrieval;data structure;filtering theory;octrees;visual databases;image retrieval	We propose a multiresolution color feature extraction scheme based on octree data structure to achieve efficient and robust image retrieval. With the proposed method, multiple color features, including the dominant color, the number of distinctive colors and the color histogram, can be naturally integrated into one framework. A selective filtering strategy is also described to speed up the retrieval process. Retrieval examples are given to illustrate the performance of the proposed approach.	cluster analysis;color histogram;data structure;feature extraction;image retrieval;octree	Xia Wan;C.-C. Jay Kuo	1998		10.1109/ICASSP.1998.679688	color histogram;computer vision;search engine indexing;visual word;color quantization;image resolution;color normalization;data structure;feature extraction;image retrieval;computer science;pattern recognition;information retrieval	Vision	39.301378184357205	-60.66289339837089	179391
bf96a33d63670d21dd362e8a0d6b92a1e76fec7d	the analysis method focusing on peaks of darkness for the impression evaluation method by space	impression space analysis method impression evaluation kansei vagueness;image colour analysis;color darkness darkness peaks impression evaluation method by space iems object impression impression words kansei space painting color am_pd characteristic impression analysis;focusing image color analysis color painting educational institutions algorithm design and analysis dispersion	This paper proposes an analysis method of the evaluation results obtained through the Impression Evaluation Method by Space (IEMS). The IEMS uses a plane containing impression words as the Kansei space. The impression of an object is specified by circling the areas matching the impression. The degree of matching the impression is expressed by painting color. As the impression words can be moved and/or added in the IEMS, it is difficult to analyze the evaluation results obtained from many subjects. The proposed analysis method focuses on the peaks of darkness. It is called the analysis method focusing on the peaks of darkness (abbr. AM_PD). By mapping the peaks of the darkness in each evaluation result to the same Kansei space, this method can analyze characteristic impressions. In this paper, the algorithm of extracting obvious peaks automatically is proposed toward realization of the AM_PD. The parameters of the AM_PD required to extract the obvious peaks are experimentally determined. This paper shows that the obvious peaks in the evaluation results can be extracted by using this algorithm.	algorithm;color;experiment	Shunsuke Akai;Teruhisa Hochin;Hiroki Nomiya	2014	15th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)	10.1109/SNPD.2014.6888721	computer vision	SE	43.113383358754774	-64.28548189810019	180005
cff315e2f10e7b651dce1239770513ca9e87134d	comparaison de deux familles complètes de descripteurs de formes pour l'indexation de bases d'objets 2d à niveaux de gris	image processing;fourier transform;image databank;numerical method;indexation automatique;information retrieval;representation image;extraction forme;image database;procesamiento imagen;invarianza;analytical continuation;imagen nivel gris;transformacion mellin;traitement image;similitude;experimental result;invariance;reconstruction image;metodo numerico;extraccion forma;reconstruccion imagen;recherche information;fourier transformation;image representation;image reconstruction;banco imagen;indexation;image niveau gris;banque image;similarity;transformation fourier;mellin transformation;prolongement analytique;automatic indexing;resultado experimental;pattern recognition;completitud;recuperacion informacion;reconnaissance forme;similitud;completeness;reconocimiento patron;resultat experimental;completude;grey level image;descriptor;pattern extraction;descripteur;methode numerique;transformation mellin;indizacion automatica;prolongamiento analitico;transformacion fourier	In this work, we propose the use o f two sets o f 2D shape descriptors for grey-level object content-based retrieval and image indexing. These families are invariant under planar similarities and complete. The completeness property ensures that an object is identified in a unique way up to a similarity transformation and guarantees a perfect discrimination between shapes. This reveals to be interesting when image databases are either homogeneous or large. The first set o f invariant descriptors is extracted from the analytical Fourier-Mellin transform, while the second one comes from the complex moment image representation. The similarity between shapes is estimated according to the distances induced by the two invariant descriptions. We tested and compared these families on two real grey-level object databases for content-based image retrieval. Retrieval results show that the invariant descriptors produce a reliable shape description, discriminating and stable to small shape variations. The completeness is an interesting feature that offers an extensive and flexible representation of shapes.	content-based image retrieval;database;shape analysis (digital geometry)	Stéphane Derrode;Rim Mezhoud;Faouzi Ghorbel	2000	Annales des Télécommunications	10.1007/BF03001911	fourier transform;image processing;computer science;calculus;mathematics;geometry;algorithm	Vision	43.40553560685666	-61.39164852703421	180312
d8762db8b8c1218061def32c56567db7f54889d3	on accurate orientation extraction and appropriate distance measure for low-resolution palmprint recognition	baja resolucion;traitement signal;look up table;palm print;distance measure;non linear filter;biometrie;biometrics;low resolution;database;mesure position;biometria;basse resolution;base dato;medicion posicion;etat actuel;tabla de consulta;accuracy;distance measurement;automatic recognition;precision;medicion distancia;feature extraction;signal processing;state of the art;position measurement;base de donnees;pattern recognition;estado actual;table conversion;filtro no lineal;reconnaissance forme;steerable filters;extraction caracteristique;reconocimiento patron;empreinte palmaire;procesamiento senal;filtre non lineaire;reconocimiento automatico;mesure de distance;palmprint verification;steerable filter;reconnaissance automatique	Orientation feature has been demonstrated to be one of the most effective features for low resolution palmprint recognition. In this paper, using steerable filter, we investigate the accurate orientation extraction and appropriate distance measure problems for effective palmprint recognition. First, we use high order steerable filter to extract accurate continuous orientation, and quantify it into discrete representation. Then, for effective matching of accurate orientations, we propose a generalized orientation distance measure. We further extend the distance measure for matching of discrete orientations, and show that several existing distance measures can be viewed as its special cases. Experimental results on both Hong Kong PolyU and CASIA palmprint databases show that the proposed method can obtain state-of-the-art verification accuracy. With the support of a look up table, the proposed method also enables small template size and satisfactory matching speed for practical applications.	fingerprint	Wangmeng Zuo;Feng Yue;David Zhang	2011	Pattern Recognition	10.1016/j.patcog.2010.09.017	computer vision;computer science;signal processing;accuracy and precision;statistics	Vision	45.552849335914374	-60.223870037111816	180540
5a3092b266ddf97ac9dc9a07a0ae7c40b54470cd	hsm: a new color space used in the processing of color images		Resumo: Inspired on the techniques used by painters to overlap layers of various hues of paint to create oil paintings, and also on observations of the the arrangement of Short-(S), Middle-(M), and Long-(L) wavelength-sensitive cones of the human retina for the interpretation of the colors, this paper proposes the use of the new color space called HSM to the processing of color images. To demonstrate the applicability of the HSM color space in the processing of color images, this paper proposes the pixelbased segmentation of a digital image of “human skin” or “non-skin”, the sketch of the face image and the pixel-based segmentation of the trumpet flowers tree (ype). The performance of the HSM color space in the pixel-based segmentation is compared with the HSV, YCbCr and TSL color spaces while the sketch of the face image is also compared with HSV, YCbCr and TSL colors spaces and the edge detectors of the Sobel, Prewitt, Roberts, Canny and Laplacian of Gaussian methods. The results demonstrate the potential of the proposed color space.	blob detection;canny edge detector;color space;digital image;edge detection;mdl (programming language);mixture model;pixel;prewitt operator;sensor;sobel operator	Osvaldo Severino;Adilson Gonzaga	2009	RITA		color histogram;false color;rgb color model;computer vision;color model;color quantization;hsl and hsv;color depth;color image;color balance;color space;computer graphics (images)	Vision	41.643281150828294	-65.64542343644113	180697
c895a4d9542e4da414d69dbca9109c33dbcd460e	new structured illumination technique for the inspection of high-reflective surfaces: application for the detection of structural defects without any calibration procedures	signal image and speech processing;biometrics;pattern recognition;image processing and computer vision	"""We present a novel solution for automatic surface inspection of metallic tubes by applying a structured illumination. The strength of the proposed approach is that both structural and textural surface defects can be visually enhanced, detected, and well separated from acceptable surfaces. We propose a machine vision approach and we demonstrate that this technique is applicable in an industrial setting. We show that recording artefacts drastically increases the complexity of the inspection task. The algorithm implemented in the industrial application and which permits the segmentation and classification of surface defects is briefly described. The suggested method uses """"perturbations from the stripe illumination"""" to detect, segment, and classify any defects. We emphasize the robustness of the algorithm against recording artefacts. Furthermore, this method is applied in 24 h/7 day real-time industrial surface inspection system."""		Yannick Caulier;Klaus Spinnler;Salah Bourennane;Thomas Wittenberg	2008	EURASIP J. Image and Video Processing	10.1155/2008/237459	computer vision;computer science;archaeology;pattern recognition;biometrics;computer graphics (images)	Vision	43.28321098892125	-64.08861068984373	180779
8f63efc95f0bea5b0987d978790dccea6210feb4	wrapping snakes for improved lip segmentation	speaker recognition image segmentation;mouth;wrapping;spline;active contour;image segmentation;energy method;active contours;force;speaker recognition;shape;ieee;lip segmentation;wrapping snakes;active contours speech recognition image segmentation;mathematical model;lips;speech recognition;robustness;wrapping shape speech recognition image segmentation lips mathematical model robustness active contours mouth spline;lip reading wrapping snakes lip segmentation;lip reading;noise	A key step in the process of lip-reading is determining the shape of the speaker's lips. This has previously been achieved through an energy method known as “snakes”, however this approach has some limitations. This paper presents an adapted approach called wrapping snakes, where the image forces are modified based on the snake's location and orientation. This modification encourages wrapping snakes to continue along features they have already partially found, overcoming one of the problems of traditional snakes. The use of wrapping snakes allows for more accurate and robust lip segmentation, as well as increasing the speed of the segmentation.	snakes and ladders;wrapping (graphics)	Matthew Ramage;Euan Lindsay	2009	2009 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2009.4959806	spline;speaker recognition;computer vision;speech recognition;shape;computer science;noise;mathematical model;active contour model;image segmentation;force;robustness	Robotics	43.918133363320585	-65.3039473216045	180809
6606b681f724355621abd1300547724198ef5924	fingerprint classification by directional image partitioning	topology;optimisation;image segmentation;fingerprint classification;search strategy;indexing terms;robustness automatic fingerprint classification directional image partitioning homogeneous connected regions fingerprint topology dynamic masks optimization criterion numerical vector multidimensional point search strategies continuous classification;fingerprint recognition topology multidimensional systems image databases information retrieval robustness classification algorithms partitioning algorithms biometrics image recognition;continuous classification;biometric systems;directional image;optimisation fingerprint identification image segmentation topology;fingerprint identification;partitioning algorithms	In this work, we introduce a new approach to automatic fingerprint classification. The directional image is partitioned into “homogeneous” connected regions according to the fingerprint topology, thus giving a synthetic representation which can be exploited as a basis for the classification. A set of dynamic masks, together with an optimization criterion, are used to guide the partitioning. The adaptation of the masks produces a numerical vector representing each fingerprint as a multidimensional point, which can be conceived as a continuous classification. Different search strategies are discussed to efficiently retrieve fingerprints both with continuous and exclusive classification. Experimental results have been given for the most commonly used fingerprint databases and the new method has been compared with other approaches known in the literature: As to fingerprint retrieval based on continuous classification, our method gives the best performance and exhibits a very high robustness.	database;fingerprint;mathematical optimization;numerical analysis;synthetic intelligence;variable shadowing	Raffaele Cappelli;Alessandra Lumini;Dario Maio;Davide Maltoni	1999	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.765653	fingerprint;computer vision;index term;computer science;machine learning;pattern recognition;mathematics;image segmentation	Vision	39.33257605148889	-61.83319031869118	180884
bd1d5eb7a3f34bdaebca994e34f289a8ae6daf3f	hierarchical classification of surface defects on dusty wood boards	defecto superficie;image processing;procesamiento imagen;surface defects;traitement image;hierarchical classification;pattern recognition;surface defect;reconnaissance forme;classification automatique;reconocimiento patron;automatic classification;clasificacion automatica;defaut surface	Abstract   Classification of surface defects on wood boards is one of the important steps towards a completely automated wood processing plant. This paper presents a hierarchical approach to classify sample boards of red oak into the nine classes, eight types of surface defects and clear wood. It utilizes a priori knowledge about surface defects and their texture properties. Since the boards in a wood processing plant are usually covered by dust, the feasibility of using the proposed approach in such an environment is investigated. Three types of image data including those of dusty board surfaces are generated and utilized in the classification experiments.		Choon-Woo Kim;Antti J. Koivo	1994	Pattern Recognition Letters	10.1016/0167-8655(94)90076-0	computer vision;image processing;computer science;pattern recognition	Vision	45.994048891932614	-61.77530614672133	181827
bc5fc18fd81be86a3ff83fe0f7d82726d2eebb3c	deformation similarity measurement in quasi-conformal shape space	shape deformation;riemannian metric;shape space	This paper presents a novel approach based on the shape space concept to classify deformations of 3D models. A new quasi-conformal metric is introduced which measures the curvature changes at each vertex of each pose during the deformation. The shapes with similar deformation patterns follow a similar deformation curve in shape space. Energy functional of the deformation curve is minimized to calculate the geodesic curve connecting two shapes on the shape space manifold. The geodesic distance illustrates the similarity between two shapes, which is used to compute the similarity between the deformations. We applied our method to classify the left ventricle deformations of myopathic and control subjects, and the sensitivity and specificity of our method were 88.8% and 85.7%, which are higher than other methods based on the left ventricle cavity, which shows our method can quantify the similarity and disparity of the left ventricle motion well. Published by Elsevier Inc.	3d modeling;binocular disparity;computational anatomy;distance (graph theory);sensitivity and specificity	Vahid Taimouri;Jing Hua	2014	Graphical Models	10.1016/j.gmod.2013.12.001	mathematical analysis;topology;mathematics;geometry	Vision	44.190334162849034	-64.07650883663875	182483
3f8926e2eaaa8f40a5756a5162f824728941221d	development of the software for images segmentation and objects detecting on video	software;image segmentation;algorithms;video	Features of program realization of algorithms of segmentation when developing the software for detecting and maintenance of objects on the stream video image are considered in this article. The special attention is paid to the choice of the using of algorithm of segmentation and realization of the qualifier which finds required object on the image, on the basis of Haar's cascades. The main algorithms which are basic when developing the software and examples of work of the program are given. © (2016) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	sensor	Kseniia Ezhova;Anton Chuhlamov;Dmitriy Fedorenko	2016		10.1117/12.2227927	computer vision;video;computer science;theoretical computer science;segmentation-based object categorization;image segmentation;scale-space segmentation;computer graphics (images)	Vision	41.3721838142009	-65.94691561728006	182888
5205c055c10cd4820b91132b5613ffa6ed88d75a	color co-occurence descriptors for querying-by-example	query processing;image database;indexing and retrieval;multimedia computing;information retrieval image segmentation image databases encoding indexing world wide web image retrieval layout frequency spatial databases;color segmentation;compact representation;indexing;very large databases visual databases multimedia computing query processing image colour analysis indexing;spatial distribution;image colour analysis;affine transformation;database descriptor color co occurrence descriptors querying by example multimedia documents indexing image retrieval large image database visual image content color segments spatial distribution color textures query descriptor;very large databases;similarity measure;high frequency;visual databases;image retrieval	Multimedia documents are different from traditional text documents, because they may contain encodings of raw sensorical data. This fact has severe consequences for the efficient indexing and retrieval of information from documents in large unstructured collections (e.g. WWW), because it is very difficult to automatically identify generic meanings from visual or audible objects. A novel method for image retrieval from large collections is proposed in this paper. The method is based on color co– occurrence descriptors that utilize compact representations of essential information of the visual image content. The set of descriptor elements represents ”elementary” color segments, their borders, and their mutual spatial distribution on the image frame. Such representation is flexible enough to describe image scenes ranging from simple combinations of color segments to high frequency color textures equally well. At the retrieval stage the comparison between a given query descriptor and the database descriptors is performed by a similarity measure. Image descriptors are robust versus affine transformations and several other image distortions. The consideration of the descriptors as sets of elements allows the combination of several images or subimages into a single query. Basic properties of the method are demonstrated experimentally on an image database containing 20000 images. The authors are grateful to the DAAD grant A/97/09313 and INTAS grant 96–785 that made this work possible.	database theory;distortion;experiment;grammar-based code;image retrieval;relevance;similarity measure;visual descriptor;www	Vassili Kovalev;Stephan Volmer	1998		10.1109/MULMM.1998.722972	computer vision;search engine indexing;visual word;image retrieval;computer science;high frequency;pattern recognition;data mining;affine transformation;information retrieval	Vision	39.74969492504075	-60.57775726864038	183144
0178d7bd2d8186cb732ff24c34a715ad44585313	spatial knowledge representation and retrieval in 3-d image databases	graph theory;architectural design;multimedia retrieval;3d imaging;query processing;time complexity;knowledge representation image retrieval image databases spatial databases testing multimedia databases information retrieval robustness image representation image recognition;real estate market;image database;interior design;multimedia computing;robustness 3d image databases spatial knowledge representation spatial retrieval multimedia retrieval applications architectural design interior design real estate marketing user queries image retrieval image representation scheme algorithm large image collections spatial similarity 3d spatial orientation graph graph edges time complexity translation scale variants testbed image collection image variants scale transformations;computational complexity;image representation;very large databases;knowledge representation;spatial orientation;very large databases visual databases multimedia computing knowledge representation image representation query processing graph theory computational complexity;visual databases	In multimedia retrieval applications such as architectural design, interior design, and real estate marketing, there exists a generic class of user queries that require retrieving images in the database that are spatially similar to the user query. We propose an image representation scheme (referred to as 3D spatial orientation graph or simply SOG) and an algorithm (referred to as SIM/sub 3D/) for retrieving 3D images of relevance (based on spatial similarity) to user queries from large image collections. Spatial similarity between a query and a database image is quantified based on the number as well as the extent to which the edges of SOG of the database image conform to the corresponding edges in the SOG of the query image. The time complexity of SIM/sub 3D/ is /spl Theta/(|E/sub q/|+|E/sub d/|) where |E/sub q/| and |E/sub d/| are the number of edges in the query and database images. SIM/sub 3D/ is robust in the sense that it can recognize translation and scale variants of apt image and these properties are shown formally. The effectiveness of SIM/sub 3D/ is evaluated using a testbed image collection. The testbed comprises 60 images and are produced by generating 3 variants of each of the 15 original images. Image variants are produced by translation and scale transformations, and an arbitrary composition of these two transformations. The variants are designed to examine the robustness of the proposed algorithm. The results produced by the algorithm on a set of test queries are in agreement with the intuitively expected results.	database;knowledge representation and reasoning	Venkat N. Gudivada;Gwang S. Jung	1995		10.1109/MMCS.1995.484912	time complexity;stereoscopy;computer vision;interior design;spatial disorientation;computer science;graph theory;theoretical computer science;data mining;computational complexity theory;world wide web;information retrieval	Vision	40.178671099450646	-60.32795492871373	183645
28fb8e74b6d05aa9b9513d16b1ec5e2633e2f7b3	the adaptive subspace map for image description and image database retrieval	image recognition;reconocimiento imagen;base donnee;high dimensionality;image databank;image database;database;base dato;imagen nivel gris;classification;recherche;descripcion;data extraction;banco imagen;image niveau gris;banque image;reconnaissance image;pattern recognition;autoorganizacion;self organization;reconnaissance forme;reconocimiento patron;description;investigacion;grey level image;clasificacion;autoorganisation	In this paper, a mixture-of-subspaces model is proposed to describe images. Images or image patches, when translated, rotated or scaled, lie in low-dimensional subspaces of the high-dimensional space spanned by the grey values. These manifolds can locally be approximated by a linear subspace. The adaptive subspace map is a method to learn such a mixture-of-subspaces from the data. Due to its general nature, various clustering and subspace-finding algorithms can be used. If the adaptive subspace map is trained on data extracted from images, a description of the image content is obtained, which can then be used for various classification and clustering problems. Here, the method is applied to an image database retrieval problem and an object image classification problem, and is shown to give promising results.	approximation algorithm;cluster analysis;computer vision;patch (computing)	Dick de Ridder;Olaf Lemmers;Robert P. W. Duin;Josef Kittler	2000		10.1007/3-540-44522-6_10	computer vision;self-organization;biological classification;computer science;artificial intelligence;database;automatic image annotation	Vision	43.75913514016582	-60.712380122578224	183748
93a600e632d030c92baa8aedacdd524aa410fc99	cognitive vision inspired contour and vertex detection	image contour detection;visual feature array;negative filtering;cognitive vision			Barna Reskó;Ádám B. Csapó;Péter Baranyi	2006	JACIII	10.20965/jaciii.2006.p0527	computer vision;feature detection;machine learning;pattern recognition;active contour model	Vision	41.80049042896449	-65.55421221509253	184117
744a78814d7b22a31ef3d694ed56da5c66cd8dc2	document image skew detection: survey and annotated bibliography	hough transform	Algorithms that estimate the angle at which a document image is rotated (called a document's skew) are surveyed. Four broad classes of technique are identified. These include methods that calculate skew from a horizontal projection profile, a distribution of feature locations, a Hough transform, or the distribution of responses from local, directionally sensitive masks. The basic method used by each class of technique is presented and the contributions of individual algorithms within each class are discussed.	algorithm;hough transform;variable shadowing	Jonathan J. Hull	1996		10.1142/9789812797704_0003	computer vision;real-time computing;bibliography;computer graphics (images);horizontal projection;skew;computer science;hough transform;artificial intelligence	Vision	39.31208647389926	-65.02703717986789	184319
dd24483b97dbc977c054f36665d1e088f8ea3618	computing curvilinear structure by token-based grouping	hardware design languages;token based grouping;grouping process;image processing;geometric entities;computational geometry;distributed computing;multiscale descriptions;curvilinear structure;layout;feature indexing;data mining;computer vision;multiple scales;edge data;shape;indexing;image processing computational geometry computer vision curve fitting feature extraction;organizing;feature extraction;indexation;military computing humans computer science indexing parallel processing layout organizing shape data mining hardware design languages;group process;humans;computer science;curve fitting;computational framework;parallel processing;military computing;grouping process token based grouping computational framework curvilinear structure edge data geometric entities multiscale descriptions feature indexing	This paper presents a computational framework for computing curvilinear structure on the edge data of images. The method is symbolic--operating on geometric entitiesltokens. It is also constructive, hierarchical, parallel, and locally distributed. Computation proceeds independently at at each token and at each stage interleaves the discovery of structure with its careful description. The process yields a hierarchy of descriptions at multiple scales. These multi-scale descriptions provide effiient feature indexing both for the grouping process itself as well as for subsequent recognition processes. Experimental results are presented to demonstrate the effectiveness of the approach with respect to curvilinear structure, and its application to more general grouping problems is discussed.	computation;parallel computing	John Dolan;Edward M. Riseman	1992		10.1109/CVPR.1992.223265	layout;parallel processing;computer vision;search engine indexing;image processing;feature extraction;computational geometry;shape;computer science;theoretical computer science;machine learning;geometry;group dynamics;curve fitting	Vision	41.70514841716541	-64.17100006551847	184489
ab619951bbede750d7ccbc24d4232ccf0b05291e	a method of style discrimination of oil painting based on 3d range data	databases;painting;art;range data;gaussian curvature;image processing;paints;testing;data mining;style discrimination;petroleum;shape;range image;feature extraction;information processing;3d range data;local mean curvature;humans;feature extraction image processing art;mean curvature;style discrimination method;gaussian curvature style discrimination oil painting 3d range data local mean curvature style discrimination method;petroleum painting data mining humans autocorrelation paints information processing testing databases shape;autocorrelation;oil painting	U’e conditried an experiment ahour “Kaiisei’: rvhirh is sensibility of each person. 00 goal was to extract an artist’s style in the oil painting. A style is determined 6)) CYIIOI; skill und other kry elrnirriis. Chr nirthods paid particrrlarattentioii to the characteristics of touch. one of the skills. ?extitre of the oil painting is very drperent from watercolor painting because paints harden, and it becomes a rrrgaedness that can easily be seen by the himian eye. We srrpposed ihat a iorich corrld he determined with in the local niean cr(rvatiire and the Gaiissian cim’atr(re e.rtracted j?oni the range image of the oil painting. In this puper w e proposed a s ~ l r disoiniirzation niethod rising these ciw’atirres. and reporied on /he experiment result.	hardening (computing);range imaging	Naoya Masuda;Kazuhiko Yamamoto;Kunihito Kato;Hideki Tanahashi	2001		10.1109/IM.2001.924470	gaussian curvature;computer vision;autocorrelation;information processing;image processing;feature extraction;painting;shape;computer science;mean curvature;geometry;petroleum;oil painting	ML	44.32738759449393	-63.71945624876475	185159
70af529c5e9c5d91476ee98fbf4c89419c570e2b	safe: a general framework for integrated spatial and feature image search	integrated spatial and feature image search;texture;image retrieval shape indexing pipelines color query processing content based retrieval prototypes feature extraction spatial resolution;query processing;color;query image;prototypes;motion;general framework;shape;indexing;feature extraction;pipelines;safe;image search;feature extraction query processing visual databases;content based image retrieval methods safe general framework integrated spatial and feature image search query image color texture shape motion image search capabilities;image search capabilities;content based image retrieval methods;content based image retrieval;content based retrieval;spatial information;visual databases;spatial resolution;image retrieval	"""We present a system for querying for images by the spatial and feature attributes of regions . The system enables the user to nd the images that contain an arrangement of regions similar to that diagrammed in a query image. We propose a general framework which allows for di erent types of features (e.g., color, texture, shape, motion) to be integrated with spatial information in the query process. We demonstrate that integrated spatial and feature querying improves image search capabilities over previous content-based image retrieval methods. INTRODUCTION In this paper, we present the general framework and a prototype system for querying for images by spatial and feature attributes. The spatial and feature (SaFe) system integrates content-based techniques with spatial query methods in order to search for images by arrangements of regions. SaFe has been deployed on-line in an application for querying in a large collection of unconstrained images (more than 650,000 images). Our contribution is the use of fully automated region and feature extraction and indexing, and the integration of spatial and feature image querying. These capabilities of SaFe distinguish it from other recent image retrieval systems (Virage [1], QBIC [2] and Photobook [3]) which do not provide this enhanced functionality. The spatial and feature image query paradigm provides a powerful method for image retrieval. However, it is extremely complex in that it requires that several disparate image query techniques be combined. First, the feature query component requires the assessment of the feature similarities of regions. Second, the spatial query component requires the assessment of the similarities in spatial locations and sizes of regions. Third, the system requires the comparison of images consisting of multiple regions. Last, the system requires that the spatial relationships, such as \above,"""" \below,"""" \near,"""" and so forth, be resolved. As depicted in Figure 1, the overall comparison of images for on-line demo see http://disney.ctr.columbia.edu/safe utilizes both the feature and spatial attributes of the regions in computing their similarity."""	content-based image retrieval;feature extraction;line level;online and offline;programming paradigm;prototype;spatial query	John R. Smith;Shih-Fu Chang	1997		10.1109/MMSP.1997.602652	image texture;computer vision;search engine indexing;feature detection;image resolution;feature extraction;image retrieval;shape;computer science;motion;pattern recognition;pipeline transport;spatial analysis;prototype;texture;feature;information retrieval;statistics	Vision	39.71696124799831	-60.585136404542155	185454
c0f449cbc01f71c17b90a1351340ecf73857d3bf	face retrieval by an adaptive mahalanobis distance using a confidence factor	eigenvalues and eigenfunctions;mahalanobis distance;video databases;face retrieval;eigenface techniques;neural networks;eigenface features;video signal processing;information retrieval;image matching;mpeg 7 standard training data gaussian distribution laboratories national electric code face recognition access control principal component analysis neural networks information retrieval;a posterior distribution;video retrieval;error variances;asymmetric components;standard mahalanobis distance;image contrast;training data;confidence;face recognition face retrieval adaptive mahalanobis distance confidence factor a posterior distribution observation errors face images error variances confidence error distribution standard mahalanobis distance eigenface techniques image contrast asymmetric components mpeg 7 face descriptors eigenface features match ratio weighted distance video retrieval;error distribution;face recognition;adaptive signal processing;posterior distribution;feature extraction;principal component analysis;mpeg 7 face descriptors;observation errors;national electric code;access control;face images;match ratio;mpeg 7 standard;adaptive mahalanobis distance;weighted distance;gaussian distribution;confidence factor;image matching face recognition image retrieval video databases video signal processing adaptive signal processing feature extraction eigenvalues and eigenfunctions;image retrieval	This paper proposes an adaptive Mahalanobis distance for face retrieval. The distance is derived from a posterior distribution of observation errors in features categorized by con dence of face images. Since the distance is calculated considering error variances of each dimension according to the con dence, it can re ect error distribution of each matching more precisely than a standard Mahalanobis distance. We apply this distance to eigenface techniques using image contrast and asymmetric components of face images as the con dence. To evaluate our proposed distance in face retrieval, we made experiments using MPEG-7 face descriptors as eigenface features. The best match ratio was improved from 93.5% to 97.6% compared with the weighted distance described in MPEG-7 by using the proposed distance.	categorization;eigenface;experiment;mpeg-7;naruto shippuden: clash of ninja revolution 3	Toshio Kamei	2002		10.1109/ICIP.2002.1037982	normal distribution;adaptive filter;computer vision;training set;national electrical code;feature extraction;image retrieval;computer science;access control;mahalanobis distance;machine learning;pattern recognition;confidence;posterior probability;principal component analysis	Vision	40.43405336547921	-62.00191295748154	185547
3f14c2f23cef37f1fd8fc67f3aa4f3be8f350708	face recognition by auto-associative radial basis function network	transformation ondelette;olivetti research laboratory;image processing;facies;biometrie;fonction base radiale;biometrics;biometria;procesamiento imagen;traitement image;wavelet transform;face recognition;radial basis function;radial basis function network;computational complexity;pattern recognition;facial features;transformacion ondita;reconnaissance forme;reseau neuronal;reconocimiento patron;rbf network;red neuronal;wavelet transformation;neural network	In this paper, we proposed an autoassociative Radial Basis Function (RBF) network and applied it with a modular structure to human face recognition. To capture the substantial facial features and reduce computational complexity, we propose to use wavelet transform (WT) to decompose face images and choose the lowest resoluation sub-band coefficients for face representation. Results indicate that out scheme yields accurate recognition on the widely use XM2VTS face database and Olivetti Research Laboratory (ORL) face database.	facial recognition system;radial (radio);radial basis function network	Bailing Zhang;Baoming Sun	2001		10.1007/3-540-45344-X_8	computer vision;radial basis function;facies;image processing;computer science;artificial intelligence;machine learning;computational complexity theory;radial basis function network;artificial neural network;biometrics;wavelet transform	Vision	44.10114735295771	-59.50429157408445	185788
b80cc377988d615871f059daa7a6618edfd92b32	a radial basis function for registration of local features in images	radial basis function;local features;image registration;compact support;landmarks;thin plate spline;global change	Image registration based on landmarks and radial basis functions (e.g. thin plate splines) results in global changes and deformation spreads over the entire resampled image. This paper presents a radial basis function for registration of local changes. The proposed research was based on study/analysis of profile for different radial basis functions, supporting local changes. The proposed function was designed to overcome the weaknesses, observed in other radial basis functions. The results are analyzed/compared on the basis of different properties and parameters discussed in this paper. Experimental results show that the proposed function improves the registration accuracy.	radial (radio);radial basis function	Asif Masood;Adil Masood Siddiqui;Muhammad Saleem	2007		10.1007/978-3-540-77129-6_56	computer vision;mathematical optimization;radial basis function;computer science;image registration;machine learning;mathematics;geometry;thin plate spline;global change	Vision	44.03588004665152	-63.911606221499724	186244
bcf72d95c1449e0d375bfa3b3d19dd557d51a8d9	a classification-matching combination for image retrieval	analisis contenido;m tree;imdex;high dimensionality;image processing;information extraction;information retrieval;element geometrique;k means;index documentation;procesamiento imagen;image;index;classification;traitement image;r tree;cbvq content based visual query;content analysis;imagen;recherche information;indice;feature extraction;indexation;tree structure;archives;elemento geometrico;recuperacion informacion;analyse contenu;geometric element;clasificacion;alogorithms;image retrieval	Nowadays, applications dealing with information extracted from images are commonplace. The widespread use of multimedia information (images, video, audio etc.) makes necessary applications capable of storing, and therefore retrieving, it. Information extracted from images is usually complex and high dimensional. The extraction of non‐textual low‐level indexing features from images is now a research field, and this process principally suffers because of the computational cost of the high dimensionality of those features. A new way to classify and match low‐level features extracted from images, for retrieval purposes, is presented in this paper. M‐tree and R‐tree structures are used, as well as an incremental version of the k‐means classification alogrithm. This set of alogrithms is used to solve the problem of low performance when retrieving previously catalogued images.	image retrieval	Julio Encinas;Juan Llorens Morillo;Adoración de Miguel Castaño	1999	Online Information Review	10.1108/14684529910334038	m-tree;r-tree;computer vision;content analysis;image processing;feature extraction;biological classification;image retrieval;computer science;image;data mining;tree structure;information extraction;information retrieval;k-means clustering	Vision	42.56373437836022	-61.077264612089905	186335
78acfb7ce48321e5c846be4b2608f9b4c0faae76	usefulness of boundary sequences in computing shape features for arbitrary shaped regions	binary image;holes boundary sequence arbitrary shaped regions shape feature computation area centroid orientation cross sections vertical line segments boundary sequence extraction method;shape image coding character recognition clocks encoding footwear multimedia computing computer science image segmentation image processing;feature extraction;cross section;feature extraction image sequences;extraction method;image sequences	A boundary sequence is a good representation of arbitrary shaped regions, but not directly used in computing shape features such as area, centroid, orientation, and so forth. In this paper, we show that the shape features can be easily computed by using cross-sections derived from a boundary sequence. The cross-sections are vertical line segments in the region and can be determined by tracing the boundary sequence once. Furthermore, a boundary sequence extraction method is also proposed, which generates a boundary sequence for each region in a binary image by scanning the image only once. The proposed method works well even if a region has holes.	binary image;connected component (graph theory);connected-component labeling;shape context;vertical bar	Seongok Kim;Sungyoung Kim;Jongmin Kim;Minhwan Kim	2002		10.1109/ICPR.2002.1047867	computer vision;feature detection;binary image;feature extraction;computer science;machine learning;pattern recognition;mathematics;cross section	Vision	43.0126213336775	-64.43128215908926	186794
6106fdcbdaceb7143744bdb71b1877a2b82d0bfc	a similarity measure for color image retrieval and indexing based on the multivariate two sample problem	trees mathematics feature extraction image colour analysis image retrieval indexing statistical analysis;indexing laboratories world wide web abstracts image edge detection;natural image collections similarity measure color image retrieval color image indexing multivariate two sample problem feature space color information image pixel random selection high density regions minimal spanning tree structure mst structure statistical measure	In this work, a similarity measure in the feature space is proposed for color retrieval and indexing based on the “Multivariate Two-Sample Problem”. Color information is extracted via random selection of image pixels from high-density regions. The proposed scheme has a global nature due to its randomness and is easy to implement. It makes uses of the minimal spanning tree (MST) structure and properties, providing the retrieval results with a statistical measure of their significance level. The main advantages of our proposal are its computational efficiency and the fact that it is generally applicable to natural image collections.	color image;computation;feature vector;file spanning;image retrieval;minimum spanning tree;pixel;randomness;similarity measure	Christos Theoharatos;Nikolaos A. Laskaris;George Economou;Spiros Fotopoulos	2004	2004 12th European Signal Processing Conference		color histogram;image texture;computer vision;feature detection;visual word;binary image;pattern recognition;mathematics;automatic image annotation;information retrieval	Vision	39.29802863598395	-60.46914320387664	187148
fa8dd31c3991ae4d039b1b1b299d52420a18df20	precise pupil contour detection based on minimizing the energy of pattern and edge	tecnologia electronica telecomunicaciones;edge detection;pupil contour detection;pattern recognition;energy minimization;tecnologias;grupo a	We propose a new method to precisely detect pupil contours in face images. Pupil contour detection is necessary for various applications using face images. It is, however, difficult to detect pupils precisely because of their weak edges or lack of edges. The proposed method is based on minimizing the energy of pattern and edge. The basic idea of this method is that the energy, which consists of the pattern and the edge energy, has to be minimized. An efficient search method is also introduced to overcome the underlying problem of efficiency in energy minimization methods. “Guide patterns” are introduced for this purpose. Moreover, to detect pupils more precisely we use an ellipse model as pupil shape in this paper. Experimental results show the effectiveness of the proposed method. key words: pupil contour detection, pattern recognition, edge detection, energy minimization	algorithm;contour line;design pattern;energy minimization;maxima and minima	Mayumi Yuasa;Osamu Yamaguchi;Kazuhiro Fukui	2002			computer vision;edge detection;computer science;energy minimization	Vision	44.45756748738477	-64.64403871920753	187230
ce5f39e44dd5a46e68376c462e6763787ba92990	classification of liquid and viscous inks using hsv colour space	saturation histograms liquid ink classification viscous ink classification hsv colour space document examination ink type recognition;human vision;color space;image classification ink image colour analysis document image processing gaussian distribution;ink printing infrared spectra printers forensics mass spectroscopy histograms writing instruments absorption;image classification;hsv color space;null;image colour analysis;document image processing;ink;gaussian distribution	Analysis of inks on questioned documents is often required in the field of document examination. This paper provides a novel approach for ink type recognition. Ink types liquid ink or viscous ink will be derived from the color properties of ink by extracting its HSV characteristics. This classification helps in distinguishing gel and roller pens versus ball pens, offset and ink jet printers versus laser printers. Different types of inks exhibit different absorption characteristics that causes color and distribution of color pixels to change. So we have done a detailed analysis of all color spaces and in particular HSV color space as it matches human vision. We observed that the saturation histograms of writings or printings reveals difference in absorption characteristics of ink, while hue histograms do not. We found that the saturation histograms can be modeled as Gaussian distribution that resembles process of diffusion of ink into paper. The measures like F ratio, /spl sigma/ ratio, saturation weighted hue variance (ANOVA) are used to classify inks.	color space;digital pen;f-ratio;image histogram;international conference on document analysis and recognition;light pen;pixel;saturation arithmetic	Chakravarthy Bhagvati;Haritha Dasari	2005	Eighth International Conference on Document Analysis and Recognition (ICDAR'05)	10.1109/ICDAR.2005.74	normal distribution;computer vision;contextual image classification;hsl and hsv;computer science;color space;computer graphics (images)	Vision	41.96253750216469	-63.27008078083284	187398
8e3c1d712b942707de63c03525465e8581403d5e	relaxed grey-world: computational colour constancy by surface matching	analisis imagen;utilisation information;contenu image;uso informacion;image content;analisis estadistico;image processing;information use;information source;source information;luminance;procesamiento imagen;partial information;probabilistic approach;traitement image;statistical analysis;surface matching;enfoque probabilista;approche probabiliste;analyse statistique;pattern recognition;image analysis;reconnaissance forme;reconocimiento patron;contenido imagen;colour constancy;analyse image;fuente informacion;luminancia	In this paper we present a new approach to computational colour constancy problem based on the process of surface matching. Classical colour constancy methods do not usually rely on this important source of information and they often use only partial information in the images. Our proposal is to introduce the use of a set of canonical surfaces and its matching versus the content of the image using a ‘relaxed’ grey-world assumption to perform colour constancy. Therefore, our approach takes into account information not considered in previous methods, which normally rely on statistical information in the image like highest luminance or image gamuts. Nevertheless the selection of the canonical surfaces is not a trivial process and should be studied deeply.	computation;information source	Francesc Tous;María Vanrell;Ramón Baldrich	2005		10.1007/11492429_24	computer vision;image analysis;image processing;computer science;mathematics;luminance;algorithm	Vision	43.15538240924845	-61.39198127798528	188025
4b6040c569b316ef47d0d9945fa84528baa43b79	hierarchical approximate matching for retrieval of chinese historical calligraphy character	shape matching;high dimensional data;chinese calligraphy;approximate matching;character recognition;character retrieval	As historical Chinese calligraphy works are being digitized, the problem of retrieval becomes a new challenge. But, currently no OCR technique can convert calligraphy character images into text, nor can the existing Handwriting Character Recognition approach does not work for it. This paper proposes a novel approach to efficiently retrieving Chinese calligraphy characters on the basis of similarity: calligraphy character image is represented by a collection of discriminative features, and high retrieval speed with reasonable effectiveness is achieved. First, calligraphy characters that have no possibility similar to the query are filtered out step by step by comparing the character complexity, stroke density and stroke protrusion. Then, similar calligraphy characters are retrieved and ranked according to their matching cost produced by approximate shape match. In order to speed up the retrieval, we employed high dimensional data structure — PK-tree. Finally, the efficiency of the algorithm is demonstrated by a preliminary experiment with 3012 calligraphy character images.	approximation algorithm;data structure;optical character recognition;public-key cryptography;regular expression	Xiafen Zhang;Yueting Zhuang;Jiangqin Wu;Fei Wu	2007	Journal of Computer Science and Technology	10.1007/s11390-007-9077-8	computer vision;speech recognition;computer science;clustering high-dimensional data	AI	39.22112117184767	-59.603179158428986	188050
ef57520e69e1d4a07c94674fd3966278567a50df	fast keyword searching using 'boostmap' based embedding	word searching;embedding;boostmap;shape vectors extraterrestrial measurements approximation methods feature extraction training;ifn enit database keyword search boost map based embedding dynamic time warping dtw technique sequence matching shape matching handwritten word document image analysis image retrieval linear searching constraint fast approximation algorithm triangle inequality boost map algorithm euclidean space local sensitivity hashing algorithm lsh algorithm k nearest neighbor query image;nearest neighbor word searching adaboost boostmap dynamic time warping embedding;image matching;image classification;approximation theory;visual databases approximation theory document image processing handwritten character recognition image classification image matching image retrieval learning artificial intelligence;nearest neighbor;adaboost;document image processing;learning artificial intelligence;dynamic time warping;handwritten character recognition;visual databases;image retrieval	Dynamic Time Warping (DTW), is a simple but efficient technique for matching sequences with rigid deformation. Therefore, it is frequently used for matching shapes in general, and shapes of handwritten words in Document Image Analysis tasks. As DTW is computationally expensive, efficient algorithms for fast computation are crucial. Retrieving images from large scale datasets using DTW, suffers from the constraint of linear searching of all sample in the datasets. Fast approximation algorithms for image retrieval are mostly based on normed spaces where the triangle inequality holds, which is unfortunately not the case with the DTW metric. In this paper we present a novel approach for fast search of handwritten words within large datasets of shapes. The presented approach is based on the Boost-Map [1] algorithm, for embedding the feature space with the DTW measurement to an euclidean space and use the Local Sensitivity Hashing algorithm (LSH) to rank the k-nearest neighbors of a query image. The algorithm, first, processes and embeds objects of the large data sets to a normed space. Fast approximation of k-nearest neighbors using LSH on the embedding space, generates the top kranked samples which are examined using the real DTW distance to give final accurate results. We demonstrate our method on a database of 45; 800 images of word-parts extracted from the IFN/ENIT database [11] and images collected from 51 different writers. Our method achieves a speedup of 4 orders of magnitude over the exact method, at the cost of only a 2:2% reduction in accuracy.	analysis of algorithms;approximation algorithm;british undergraduate degree classification;computation;cryptographic hash function;dynamic time warping;feature vector;image analysis;image retrieval;image warping;k-nearest neighbors algorithm;process (computing);social inequality;speedup;lsh	Raid Saabni;Alex Bronstein	2012	2012 International Conference on Frontiers in Handwriting Recognition	10.1109/ICFHR.2012.204	adaboost;contextual image classification;image retrieval;computer science;theoretical computer science;machine learning;dynamic time warping;pattern recognition;embedding;k-nearest neighbors algorithm;approximation theory	DB	39.441899217049404	-59.402349599064	188893
2d0285a600d744b7dd432875c02dbbe67678f6a7	workpiece recognition and inspection by a model-based scene analysis system	scene analysis	Abstract   A scene analysis system for the recognition and inspection of overlapping workpieces in visually noisy scenes is described. It consists of a preprocessing algorithm based on an edge-following operator and a model-based analysis algorithm. In the preprocessing stage, which is not described in detail, features such as corners, straight lines, circles and circular arcs are extracted and described by a few parameters. In the analysis stage, the pattern features extracted by the preprocessing algorithm are used to synthesize, in model-guided fashion, a prototype of the workpiece, which is continuously checked against the model. A similarity measure indicates the match between model and scene. Besides topographical features, the analysis makes use of grey levels, textural measures and values representing colors.  Results obtained with different, partly occluded workpieces are given.		P. Rummel;W. Beutel	1984	Pattern Recognition	10.1016/0031-3203(84)90041-4	computer vision;computer science;pattern recognition;computer graphics (images)	Vision	43.28697729448737	-64.12793532819886	188949
1e94b42ce626dc0bbf8ee317af9c082d7e3c8842	color image classification using tree classifiers	color image		color image	Raimondo Schettini;Carla Brambilla;Gianluigi Ciocca;Mauro De Ponti	1999			computer vision;computer science;artificial intelligence;binary image;color image;hsl and hsv;color quantization;color histogram;color normalization;image texture;histogram equalization	Vision	41.72791631951811	-65.64696331192255	189239
680bc34b805a606e2f761cbaeab33fb36381f8f7	texture classification using a novel, soft-set theory based classification algorithm	transformation ondelette;texture;vision ordenador;classification algorithm;image processing;complexite calcul;texture classification;extraction forme;teoria conjunto;database;procesamiento imagen;base dato;theorie ensemble;prise de decision;parameterization;classification theory;set theory;classification;calculo diadico;traitement image;parametrizacion;computer vision;feature vector;complejidad computacion;extraccion forma;computational complexity;calcul dyadique;feature extraction;real function;dyadic calculus;textura;fonction reelle;base de donnees;theorie classification;pattern recognition;vision ordinateur;transformacion ondita;reconnaissance forme;extraction caracteristique;reconocimiento patron;classification accuracy;toma decision;pattern extraction;clasificacion;funcion real;parametrisation;wavelet transformation;teoria clasificacion	In this paper, we have presented a new algorithm for classification of the natural textures. The proposed classification algorithm is based on the notions of soft set theory. The soft-set theory was proposed by D. Molodtsov which deals with the uncertainties. The choice of convenient parameterization strategies such as real numbers, functions, and mappings makes soft-set theory very convenient and practicable for decision making applications. This has motivated us to use soft set theory for classification of the textures. The proposed algorithm has very low computational complexity when compared with Bayes classification technique and also yields very good classification accuracy. For feature extraction, the textures are decomposed using standard dyadic wavelets. The feature vector is obtained by calculating averaged L1-norm energy of each decomposed channel. The database consists of 25 texture classes selected from Bordatz texture Album. Experimental results show the superiority of the proposed approach compared with some existing methods. . . .	algorithm;computation;computational complexity theory;dyadic transformation;euclidean distance;experiment;feature extraction;feature vector;set theory;taxicab geometry;time complexity;wavelet	Milind M. Mushrif;Somnath Sengupta;Ajoy Kumar Ray	2006		10.1007/11612032_26	parametrization;computer vision;feature vector;image processing;feature extraction;computer science;artificial intelligence;mathematics;texture;algorithm;set theory	AI	44.631379976900746	-61.6296233848997	189758
f570e77bc9a6e9362b7eec366e98448d96e4c5a4	face recognition using the nearest feature line method	face recognition face detection image databases spatial databases prototypes error analysis facial features neural networks principal component analysis lighting;linear combination;analisis componente principal;base donnee;reconnaissance face;modele lineaire;database;base dato;image classification;modelo lineal;indexing terms;classification;experimental result;prototipo;face recognition;combinacion lineal;principal component analysis;orl face database nearest feature line method classification method query feature point standard eigenface method;linear model;plus proche ligne caracteristique;resultado experimental;analyse composante principale;reseau neuronal;image classification face recognition principal component analysis;resultat experimental;prototype;clasificacion;red neuronal;nearest feature line;combinaison lineaire;neural network	In this paper, we propose a novel classification method, called the nearest feature line (NFL), for face recognition. Any two feature points of the same class (person) are generalized by the feature line (FL) passing through the two points. The derived FL can capture more variations of face images than the original points and thus expands the capacity of the available database. The classification is based on the nearest distance from the query feature point to each FL. With a combined face database, the NFL error rate is about 43.7-65.4% of that of the standard eigenface method. Moreover, the NFL achieves the lowest error rate reported to date for the ORL face database.	eigenface;facial recognition system;nfl;question (inquiry);return loss	Stan Z. Li;Juwei Lu	1999	IEEE transactions on neural networks	10.1109/72.750575	facial recognition system;contextual image classification;speech recognition;index term;linear combination;biological classification;computer science;machine learning;linear model;pattern recognition;prototype;artificial neural network;principal component analysis	Vision	43.79717421488002	-59.697843652682536	189799
ac8737548bc5ecd1912dc0627e20b5e2562d6540	colour image coding indexing and retrieval using binary space partition tree			binary space partitioning	S. Sudirman	2003				Vision	39.315457385935886	-63.3777306431846	190016
61cf539c740a6ec7fdd43e96649e0ee49ac5b4da	a fast retrieval algorithm for the earth mover's distance using emd lower bounds and the priority queue	histograms;cbir;pediatrics;fastemd library;content based image retrieval system;very large databases content based retrieval data structures feature extraction image colour analysis image retrieval image texture linear programming multimedia databases;query processing;distance measure;lower bounds;earth;multimedia information retrieval system;linear programming problem information retrieval algorithm earth mover distance measure emd lower bound priority queue multimedia information retrieval system content based image retrieval system image color image texture human perceptual similarity large scale multimedia database query processing fastemd library high speed feature based similarity retrieval cbir;earth mover distance measure;human perceptual similarity;similarity retrieval;image color;multimedia information retrieval;image texture;large scale;high speed feature based similarity retrieval;image color analysis;data structures;image colour analysis;feature extraction;priority queue;emd lower bound;transportation;multimedia databases;linear programming;mathematical model;large scale multimedia database;very large databases;information retrieval algorithm;earth mover s distance;content based image retrieval;content based retrieval;high speed;lower bounds earth mover s distance content based image retrieval;lower bound;linear programming problem;earth information retrieval image retrieval content based retrieval spatial databases multimedia systems multimedia databases humans large scale systems image databases;image retrieval	Earth Mover's Distance (EMD) is a distance measure between two distributions, and has been widely used in multimedia information retrieval systems, especially content-based image retrieval systems. When the EMD is applied to image problems based on color or texture, the EMD reflects the human perceptual similarities. Its computations, however, is too expensive to use in large-scale databases. In order to achieve the efficient computation of the EMD during query processing, we have developed “fastEMD”, a library for high-speed feature-based similarity retrievals in large databases. This paper introduces techniques that are used in the implementation of the fastEMD and demonstrates the efficiency in extensive experiments.	algorithm;priority queue	Masami Shishibori;Daichi Koizumi;Kenji Kita	2009		10.1109/NLPKE.2009.5313772	earth mover's distance;computer vision;computer science;pattern recognition;information retrieval	Theory	39.977627778457816	-60.186540395585936	191742
45a31e9b8a9500c5d6a1d370f4958777b737ef95	statistical approaches to material classification	statistical approach;bayesian classifier;bayesian classification;texture classification;nearest neighbour;statistical distribution	The objective of this paper is classification of materials from a single image obtained under unknown viewpoint and illumination conditions. Texture classification under such general conditions is an extremely challenging task. Our methods are based on the statistical distribution of rotationally invariant filter responses in a low dimensional space. There are two points of novelty: first, two representations of filter outputs, textons and binned histograms, are shown to be equivalent; second, two classification methodologies, nearest neighbour matching and Bayesian classification, are compared. In essence, given the equivalence of texton and bin representations, the paper carries out an exact comparison between the texton based distribution comparison classifiers of Leung and Malik [IJCV 2001], Cula and Dana [CVPR 2001], and Varma and Zisserman [ECCV 2002], and the Bayesian classification scheme of Konishi and Yuille [CVPR	autostereogram;bayesian network;cvpr;cellular automaton;european conference on computer vision;naive bayes classifier;normal (geometry);portable document format;statistical classification;texton;texture mapping;textures: a photographic album for artists and designers;turing completeness	Manik Varma;Andrew Zisserman	2002			bayes classifier;quadratic classifier;classification rule	Vision	40.166344334683345	-62.46725809818613	191808
4fccc80570e0c026ce1301af3dadf14bf01e024a	online finger-knuckle-print verification for personal authentication	finger knuckle print;traitement signal;on line systems;filtering;texture;filtrage;articulacion interfalangica dedo;algorithm performance;information extraction;biometric authentication;saisie donnee;biometrie;real time;authentication;filtrado;biometrics;finger interphalangeal joint;database;biometria;base dato;region interes;authentification;gabor filter;sistema coordenadas;automatic recognition;autenticacion;resultado algoritmo;toma dato;systeme en ligne;feature extraction;signal processing;region of interest;imaging;textura;performance algorithme;base de donnees;pattern recognition;formation image;formacion imagen;reconnaissance forme;systeme coordonnee;region interet;extraction caracteristique;reconocimiento patron;procesamiento senal;articulation interphalangienne doigt;personal authentication;data acquisition;reconocimiento automatico;reconnaissance automatique;interest region;coordinate system	Biometric based personal authentication is an effective method for automatically recognizing, with a high confidence, a person’s identity. By observing that the texture pattern produced by bending the finger knuckle is highly distinctive, in this paper we present a new biometric authentication system using finger-knuckle-print (FKP) imaging. A specific data acquisition device is constructed to capture the FKP images, and then an efficient FKP recognition algorithm is presented to process the acquired data in real time. The local convex direction map of the FKP image is extracted based on which a local coordinate system is established to align the images and a region of interest is cropped for feature extraction. For matching two FKPs, a feature extraction scheme, which combines orientation and magnitude information extracted by Gabor filtering is proposed. An FKP database, which consists of 7920 images from 660 different fingers, is established to verify the efficacy of the proposed system and promising results are obtained. Compared with the other existing finger-back surface based biometric systems, the proposed FKP system achieves much higher recognition rate and it works in real time. It provides a practical solution to finger-back surface based biometric systems and has great potentials for commercial applications. & 2010 Elsevier Ltd. All rights reserved.	algorithm;align (company);authentication;biometrics;data acquisition;effective method;experiment;feature extraction;gabor filter;region of interest	Lin Zhang;Lei Zhang;David Zhang;Hailong Zhu	2010	Pattern Recognition	10.1016/j.patcog.2010.01.020	computer vision;speech recognition;computer science;signal processing;authentication;information extraction;biometrics	Vision	45.145656623856716	-60.36295003159845	192154
3fa177064514311fd948716e0810fcd0e772f77f	the use of genetic algorithms in the morphological decomposition of translation invariant operators applied to digital images			digital image;genetic algorithm	João Ricardo de Freitas Oliveira	1998				Vision	41.960548796841955	-66.03686404443529	192780
4230de096b0d8d55f482bd3b3cbaebe2cbff8af4	wavelet-based texture image classification using vector quantization	transformation ondelette;teledetection;quantization;speckle;deteccion blanco;image segmentation;image processing;neural networks;0705p;data compression;analisis textura;0705m;0130c;texture classification;texture image;4230s;speckle noise;image classification;wavelet decomposition;wavelet packet;traitement image;image texture;detection cible;wavelet transforms;texture analysis;vector quantization;subbanda;target recognition;region of interest;remote sensing;subband;wavelet packet decomposition;segmentation image;pattern recognition;vector quantizer;optical sensors;reconnaissance forme;speckles;reseau neuronal;4230v;target detection;data structure;analyse texture;radar ouverture synthetique;sous bande;wavelets;radiometric corrections;image sensor;compression donnee;learning vector quantization;4230m;neural network;synthetic aperture radar;quantification vectorielle	Classification of image segments on textures can be helpful for target recognition. Sometimes target cueing is performed before target recognition. Textures are sometimes used to cue an image processor of a potential region of interest. In certain imaging sensors, such as those used in synthetic aperture radar, textures may be abundant. The textures may be caused by the object material or speckle noise. Even speckle noise can create the illusion of texture, which must be compensated in image pre-processing. In this paper, we will discuss how to perform texture classification but constrain the number of wavelet packet node decomposition. The new approach performs a two-channel wavelet decomposition. Comparing the strength of each new subband with others at the same level of the wavelet packet determines when to stop further decomposition. This type of decomposition is performed recursively. Once the decompositions stop, the structure of the packet is stored in a data structure. Using the information from the data structure, dominating channels are extracted. These are defined as paths from the root of the packet to the leaf with the highest strengths. The list of dominating channels are used to train a learning vector quantization neural network.	computer vision;vector quantization;wavelet	Eric P. Lam	2007		10.1117/12.704986	speckle pattern;computer vision;speech recognition;pattern recognition;wavelet packet decomposition;artificial neural network	Vision	44.46917604141955	-63.20038649078952	193033
52b01ebc56c030c321eecdbba2e98773da23ffe2	efficient fingerprint image enhancement for mobile embedded systems	interfase usuario;fiabilidad;reliability;mobile radiocommunication;informatique mobile;calculateur embarque;accentuation image;complexite calcul;user interface;biometrie;authentication;biometrics;biometria;punto fijo;filtro gabor;radiocommunication service mobile;arithmetique;embedded system;authentification;gabor filter;image enhancement;complejidad computacion;empreinte digitale;autenticacion;aritmetica;efficient implementation;parameter selection;arithmetics;computational complexity;point fixe;fiabilite;boarded computer;filtre gabor;fixed point arithmetic;fingerprint;interface utilisateur;floating point;coma flotante;huella digital;radiocomunicacion servicio movil;mobile computing;fix point;calculador embarque;embedded device;fingerprint verification;virgule flottante	Fingerprint image enhancement is an important step in a fingerprint verification system. The enhancement process, however, are often not applied to mobile embedded devices in which floating-point processing units (FPU) are absent. Earlier Hong and Jain reported a fingerprint enhancement algorithm based on the Gabor Filter. This algorithm and its derivatives have been proved to be quite effective in improving the fingerprint verification reliability. In this paper, we present an efficient implementation of this algorithm in an embedded system environment. In our implementation, fixed-point arithmetic is used to replace the floating-point operations. Moreover, a special Gabor filter parameter selection constraint is also proposed to reduce the computing complexity of the kernel generation step. Experimental results show that our new approach achieves significant speed improvement and is almost as effective as the traditional floating-point based implementation.	algorithm;algorithmic efficiency;biometrics;edge enhancement;embedded system;environment variable;fingerprint;fixed-point arithmetic;floating-point unit;gabor filter;image editing;interaction;linux;mobile device;singular value decomposition;dialog	Jiansheng Chen;Yiu Sang Moon;K. F. Fong	2004		10.1007/978-3-540-25976-3_14	embedded system;real-time computing;computer science;theoretical computer science;operating system;authentication;mobile computing;computer security	EDA	45.3749717459769	-60.820900985580174	193500
6e503672fb62221e23699fb0a2d6ee07ec7cfe22	exploiting evolutionary approaches for content-based medical image retrieval	user intention evolutionary approaches content based medical image retrieval semantic gap semantic interpretation user perception high dimensional feature vectors image representation feature selection techniques image descriptors optimization methods;distance function;feature extraction image retrieval biomedical imaging image color analysis semantics optimization methods genetic algorithms;feature extraction;distance function content based image retrieval evolutionary algorithms feature selection feature extraction;evolutionary algorithms;feature selection;content based image retrieval;semantic networks content based retrieval evolutionary computation feature selection image representation image retrieval medical image processing optimisation	Content-based image retrieval can be applied to assist radiologists to improve the efficiency and accuracy of interpreting the images. However, it presents some intrinsic problems. The two main problems are the so-called semantic gap that occurs due to the semantic interpretation of an image is still far to be reach, because it is based on the user's perception about the image. The other one is the dimensionality curse which leads to high dimensional feature vectors used to represent an image, where many of these features present some correlation. To mitigate these problems the paper presents a novel framework for content-based medical image retrieval joining feature selection techniques and image descriptors with optimization methods. It is capable to not only capture the user intention, but also to tune the feature selection process through the optimization method according to each user.	content-based image retrieval;curse of dimensionality;feature selection;mathematical optimization;radiology;semantic interpretation;visual descriptor	Reginaldo Rocha;Priscila T. M. Saito;Pedro Henrique Bugatti	2015	2015 IEEE 28th International Symposium on Computer-Based Medical Systems	10.1109/CBMS.2015.43	image texture;computer vision;feature detection;visual word;metric;feature extraction;image retrieval;computer science;machine learning;kanade–lucas–tomasi feature tracker;digital image processing;pattern recognition;feature selection;automatic image annotation;feature;information retrieval	Vision	39.27168730631461	-61.961742993107435	193542
c833c2fb73decde1ad5b5432d16af9c7bee1c165	homotopic image pseudo-invariants for openset object recognition and image retrieval	reconnaissance visage;algebraic topology;image recognition;topologie algebrique;object recognition;reconocimiento imagen;vision ordenador;image processing;image databases;facies;recherche image;image databank;topologia algebraica;analisis forma;face databases;homotopic image pseudo invariants;database;object recognition image retrieval face recognition image databases pixel internet image recognition independent component analysis image analysis testing;procesamiento imagen;base dato;reconnaissance objet;testing;intelligence artificielle;independent component analysis;traitement image;computer vision;invariants;face recognition;homotopic image pseudoinvariants;open set recognition;internet;recognition task;busqueda por contenido;banco imagen;pixel;banque image;reconnaissance image;base de donnees;internet homotopic image pseudoinvariants openset object recognition image retrieval face recognition pixelwise analysis recognition task face databases;pattern recognition;invariante;artificial intelligence;image analysis;vision ordinateur;pattern analysis;feature representation;inteligencia artificial;reconnaissance forme;pixelwise analysis;object recognition face recognition image retrieval;artificial intelligence biometry database management systems databases factual face humans image enhancement image interpretation computer assisted information storage and retrieval pattern recognition automated subtraction technique;reconocimiento patron;content based image retrieval;openset object recognition;content based retrieval;object recognition computer vision invariants feature representation;recherche par contenu;invariant;analyse forme;image retrieval	This paper presents novel homotopic image pseudo-invariants for face recognition based on pixelwise analysis. An exemplar face and test images are matched, and the most similar image is determined first. The homotopic image pseudo-invariants are calculated next to judge whether the most similar image is the same person as the exemplar. The proposed method can be applied to openset recognition. Recognition task can be performed with or without face databases, while the recognition rate is higher when a database is available. This fact facilitates the recognition of faces and various other objects on the Internet. We benchmark the method using FERET as well as the images downloaded from the Internet.	benchmark (computing);database;feret (facial recognition technology);face;facial recognition system;handwriting recognition;image retrieval;internet;invariant (computer science);outline of object recognition;physical object;pseudo brand of pseudoephedrine	Yoshihisa Shinagawa	2008	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2008.143	computer vision;image analysis;image processing;image retrieval;computer science;artificial intelligence;invariant;pattern recognition;three-dimensional face recognition;algebraic topology	Vision	44.314923565361504	-59.93282178858825	193607
dff09af92276bbdb48c02dd56101e421bf237073	a hybrid hmm/dpa adaptive gesture recognition method	dynamic programming;metodo adaptativo;modelo markov oculto;vision ordenador;programacion dinamica;alignement sequence;reconnaissance geste;modelo markov;modele markov cache;hidden markov model;gauchissement;gesture;edit distance;methode adaptative;dynamic program;alineacion secuencia;classification;computer vision;markov model;robustesse;adaptive method;programmation dynamique;torcimiento;distancia;robustness;vision ordinateur;appariement chaine;sequence alignment;modele markov;string matching;dynamic time warping;geste;clasificacion;gesture recognition;warping;distance;gesto;robustez	We present a hybrid classification method applicable to gesture recognition. The method combines elements of Hidden Markov Models (HMM) and various Dynamic Programming Alignment (DPA) methods, such as edit distance, sequence alignment, and dynamic time warping. As opposed to existing approaches which treat HMM and DPA as either competing or complementing methods, we provide a common framework which allows us to combine ideas from both HMM and DPA research. The combined approach takes on the robustness and effectiveness of HMMs and the simplicity of DPA approaches. We have implemented and successfully tested the proposed algorithm on various gesture data.	gesture recognition;hidden markov model	Stjepan Rajko;Gang Qian	2005		10.1007/11595755_28	image warping;computer vision;speech recognition;edit distance;biological classification;computer science;machine learning;dynamic programming;dynamic time warping;pattern recognition;sequence alignment;gesture recognition;markov model;programming language;gesture;distance;hidden markov model;robustness;string searching algorithm	Vision	45.636230959897006	-59.36791852186358	193980
13c02fde4a83527bb6244de53da50b2a98d5f19b	a vehicle occupant counting system based on near-infrared phenomenology and fuzzy neural classification	comptage;object recognition;counting function;fuzzy neural network;fuzzy neural nets;espectro ir proximo;near infrared spectrum;medicion automatica;automobiles;image processing;neural networks;object recognition vehicle occupant counting system fuzzy neural network near infrared imagery image classification sensor fusion road vehicles;logique floue;procesamiento imagen;passenger;logica difusa;image classification;transport routier;automatic measurement;data fusion;mesure automatique;indexing terms;contaje;traitement image;computer vision;infrared detection;fuzzy logic;near infrared;pasajero;monitoring;automatic detection;infrared imaging;detection ir;fusion donnee;counting;traffic engineering computing;spectre ir proche;monitorage;sensor fusion;reseau neuronal;road transportation;passager;fusion datos;monitoreo;deteccion ir;transporte por carretera;near infrared imaging;red neuronal;infrared detectors;fuzzy systems;fuzzy systems vehicle detection detectors counting circuits pattern recognition road vehicles sensor phenomena and characterization face detection road transportation licenses;traffic engineering computing automobiles computer vision object recognition sensor fusion image classification infrared imaging fuzzy neural nets;vehicle occupant detection;near infrared fusion;neural network	We undertook a study to determine if the automatic detection and counting of vehicle occupants is feasible. An automated vehicle occupant counting system would greatly facilitate the operation of freeway lanes reserved for buses, car-pools, and emergency vehicles (HOV lanes). In the present paper, we report our findings regarding the appropriate sensor phenomenology and arrangement for the task. We propose a novel system based on fusion of near-infrared imaging signals and we demonstrate its adequacy with theoretical and experimental arguments. We also propose a fuzzy neural network classifier to operate upon the fused near-infrared imagery and perform the occupant detection and counting function. We demonstrate experimentally that the combination of fused near-infrared phenomenology and fuzzy neural classification produces a robust solution to the problem of automatic vehicle occupant counting. We substantiate our argument by providing comparative experimental results for vehicle occupant counters based on visible, single near-infrared, and fused near-infrared bands. Interestingly, our proposed solution can find a more general applicability as the basis for a reliable face detector both indoors and outdoors.	artificial neural network;experiment;freeway;fuzzy set;neuro-fuzzy;phenomenological model	Ioannis T. Pavlidis;Vassilios Morellas;Nikolaos Papanikolopoulos	2000	IEEE Trans. Intelligent Transportation Systems	10.1109/TITS.2000.880964	computer vision;simulation;computer science;engineering;machine learning;sensor fusion;computer security;artificial neural network	AI	46.26794792160837	-61.281415304528835	194713
0f61414ce0ae3f81e2825760da101fa1d4114503	fingerprint recognition using model-based density map	sensitivity and specificity;evaluation performance;procesamiento informacion;performance evaluation;parametro s;diminution cout;parametre s;fingerprint recognition polynomials large scale systems costs biometrics spatial databases fingers performance analysis upper bound automation;image matching;algorithms artificial intelligence computer simulation dermatoglyphics fingers humans image enhancement image interpretation computer assisted information storage and retrieval models biological models statistical pattern recognition automated reproducibility of results sensitivity and specificity skin statistical distributions;evaluacion prestacion;skin;biometrics;models biological;density map matching;polynomial approximation image representation image matching;data fusion;polynomials;upper bound;decision level fusion scheme;large scale;statistical distributions;image enhancement;aproximacion polinomial;model based density map;minutiae based matching;polynomial approximation decision fusion density map fingerprint recognition;image interpretation computer assisted;fingerprint recognition;image representation;fusion donnee;spatial databases;information processing;approximation polynomiale;fingers;reproducibility of results;performance analysis;decision fusion;s parameter;polynomial model;models statistical;artificial intelligence;algorithms;minutiae based matching fingerprint recognition model based density map polynomial model decision level fusion scheme density map matching;pattern recognition automated;humans;reduccion costes;traitement information;fusion datos;density map;computer simulation;information storage and retrieval;dermatoglyphics;cost lowering;large scale systems;polynomial approximation;automation	Utilizing more information other than minutiae is much helpful for large-scale fingerprint recognition applications. In this paper, we proposed a polynomial model to approximate the density map of fingerprints and used the model's parameters as a novel kind of feature for fingerprint representation. Thus, the density information can be utilized into the matching stage with a low additional storage cost. A decision-level fusion scheme is further used to combine the density map matching with conventional minutiae-based matching and experimental results showed a much better performance than using single minutiae-based matching.	approximation algorithm;fingerprint recognition;map matching;minutiae;polynomial	Dingrui Wan;Jie Zhou	2006	IEEE Transactions on Image Processing	10.1109/TIP.2006.873442	computer simulation;probability distribution;computer vision;polynomial and rational function modeling;information processing;computer science;automation;machine learning;pattern recognition;mathematics;sensor fusion;skin;scattering parameters;upper and lower bounds;fingerprint recognition;biometrics;statistics;polynomial	Vision	41.167823766659744	-61.58661896001839	195041
f8c1bdc1a83ec678179df4830e5652493c59c8b5	the amplitude varying rate statistical approach for texture classification	statistical approach;analisis imagen;metodo estadistico;vision ordenador;analisis textura;texture classification;statistical method;classification;computer vision;texture analysis;methode statistique;image analysis;vision ordinateur;analyse image;analyse texture;clasificacion	We propose a new method for texture analysis, which is able to extract meaningful features of textures through a simple statistical approach. The method used is the Amplitude Varying Rate Statistics Method (AVRS). In this method, we will calculate the Amplitude Varying Rate Matrix (AVRM) through examining the profile of each scan line in a fixed direction and recording frequencies of baseline crossings		Chengsan Zhuang;Stanley M. Dunn	1990	Pattern Recognition Letters	10.1016/0167-8655(90)90124-K	computer vision;image analysis;biological classification;computer science;statistics	Vision	44.90574926621429	-62.437965932946895	195162
a65bb7502c798e252e98e930a3d41e2863bb73a9	fuzzy histogram for internal and external fuzzy directional relations	direction relations;spatial relations;medical images.;scale space;fuzzy internal cardinal directions;computer vision;image analysis;spatial relation;quantitative method	Spatial relations have key point importance in image analysis and computer vision. Numerous technics have been developed to study these relations especially directional relations. Modern digital computers give rise to quantitative methods and among them fuzzy methods have core importance due to handling imprecise knowledge information and vagueness. In most fuzzy methods external directional relations are considered which are useful for small scale space image analysis but in large scale space image analysis internal cardinal directions are also important. In this paper a new function is introduced which can be equally used for both internal and external fuzzy directional relations. Trigonometric function is used to determined the directions. This approach has core importance in medical images. A practical example in medical images is discussed.	computer vision;image analysis;medical imaging;object detection;scale space;vagueness	Nadeem Salamat;El-hadi Zahzah	2009			fuzzy logic;image histogram;scale space;spatial relation;machine learning;trigonometric functions;vagueness;artificial intelligence;mathematics;pattern recognition;histogram	Vision	41.451866211397785	-63.25967776403054	195678
88262ddc9a3a0954efa618711385f700f7fc2ade	regionboost learning for 2d+3d based face recognition	reconnaissance visage;3d face recognition;feed forward;learning algorithm;feedforward;image processing;learning;redundancia;biometrie;biometrics;biometria;procesamiento imagen;algorithme apprentissage;local binary pattern;boucle anticipation;classification;traitement image;aprendizaje;histogram;apprentissage;ciclo anticipacion;automatic recognition;sum rules;face recognition;redundancy;histogramme;machine learning;back propagation network;signal classification;pattern recognition;classification signal;reconnaissance forme;classification automatique;reconocimiento patron;automatic classification;histograma;algoritmo aprendizaje;clasificacion automatica;redondance;reconocimiento automatico;reconnaissance automatique	This paper describes an improved boosting algorithm, named RegionBoost, and its application in developing a fast and robust invariant Local Binary Pattern histogram based face recognition system. We propose to use a multi-classifier where each classifier, an AdaBoost of feed-forward back-propagation network, is trained using a single Sub-Window of the whole image, the classifiers are finally combined using the ‘‘Sum Rule’’. Only the best matchers, selected by running the Sequential Forward Floating Selection (SFFS), are exploited in the fusion step. In our opinion our method (based on local AdaBoost) partially solves the problem of redundancy among global AdaBoost selected features, with a manageable computational requirement. Finally, we propose a systematic framework for fusing 2D and 3D face recognition systems. 2007 Elsevier B.V. All rights reserved.	adaboost;algorithm;artificial neural network;authentication;backpropagation;biometrics;diffie–hellman key exchange;experiment;facial recognition system;neural networks;software propagation;three-dimensional face recognition	Loris Nanni;Alessandra Lumini	2007	Pattern Recognition Letters	10.1016/j.patrec.2007.06.003	image processing;computer science;artificial intelligence;machine learning;pattern recognition;feed forward	Vision	43.999417966807336	-59.421136884326934	195860
4367b1f10d63a42157e9a108fe72dfbc3da8fae6	nose tip detection and face localization from face range image based on multi-angle energy		In this paper, we propose a novel method to detect nose tip and localize face from face range image. The nose tip detection procedure of the method is based on the idea of Multi-angle Energy (ME) and works in scale-space. The face localization procedure of the method is based on the position of the nose tip and a modified version of Multi-angle Energy. The scale-space is established by robust smoothing the input face range image. In the nose tip detection procedure, for each scale of the scale-space, we compute the Multi-angle Energy for each point of the face range image. For the points whose values of ME are not equal to zero, hierarchical clustering method is used to cluster them into several clusters. In the obtained first h largest clusters, we can find a nose tip candidate by using a cascading scheme. For all scales of the scale-space, we get a series of nose tip candidates. We apply hierarchical clustering again for them. Nose tip can be found in the largest cluster. In the face localization procedure, we present a modified version of ME. With the modified ME, we use a similar cascading scheme to detect one endocanthion for the input face range image. Based on the distance between nose tip and endocanthion, face localization is achieved by using a sphere which is centered on the nose tip to crop the face region. We evaluate our method on two well-known 3D face databases, namely FRGC v2.0 and BOSPHORUS, and compare our method with other state-of-the-art methods. The experimental results show that the nose tip detection rates of our method are higher than those of the state-of-the-art methods. The face localization results are fine and can adapt to the face scale variance.	face detection;range imaging	Jian Liu;Quan Zhang;Chaojing Tang	2016		10.1007/978-3-319-40259-8_12	computer vision	Vision	44.74083104266035	-65.07884653719714	197896
ec8421084a190fab3c7e9590cd6367668a06b42d	classification and representation of networks from satellite images	satellite images;graph theory;hypothesis generation;graph building;satellites image texture analysis remote sensing cities and towns indexing image matching shape image sensors feature extraction roads;decision tree;image resolution;rivers;highways;image matching;heuristic programming;hypothesis generation propagation;image classification;image indexing;image resolution image classification image representation remote sensing indexing image matching feature extraction cartography graph theory heuristic programming;image sensors;curvilinear networks;texture analysis;a priori knowledge;shape;indexing;roads;image representation;feature extraction;remote sensing;satellites;satellite image;cities and towns;cartography;image analysis;image texture analysis;optical spot images image classification image representation satellite images image analysis remote sensing curvilinear networks image indexing image matching feature extraction roads highways rivers decision tree a priori knowledge graph building hypothesis generation propagation multi scale description network encoding;network encoding;point of view;multi scale description;optical spot images	Classification is one of the major issue in image analysis and processing for remote sensing applications. Though classification based on texture analysis —landuse, forests, cities, etc— is the purpose of numerous works, classification of curvilinear networks is hardly processed. However, it is of major interest, in particular for image indexing and images matching, because it is a main feature whose global shape does not change with sensors nor point of view. This paper introduces a new approach aiming at (i) building the networks from extracted curvilinear-like features and (ii) classifying them into roads, highways, rivers. The main idea is to use a decision tree taking into account a priori knowledge. Classification and graph building are achieved simultanously using a hypothesis generation/propagation scheme. The resulting network is encoded as a graph with a multi-scale description. Illustrations given on satellite optical SPOT images show encouraging results.	decision tree;graph (discrete mathematics);image analysis;schema (genetic algorithms);sensor	Véronique Prinet;Songde Ma;Olivier Monga	1999		10.1109/ICIAP.1999.797696	computer vision;search engine indexing;contextual image classification;image analysis;a priori and a posteriori;image resolution;feature extraction;shape;computer science;graph theory;machine learning;decision tree;pattern recognition;image sensor;satellite	Vision	42.27674381122974	-64.69421638316231	197990
c2fa80bf8ff641525ad3e62e619b3a4796dae69d	a cascade of unsupervised and supervised neural networks for natural image classification	busqueda informacion;transformation ondelette;unsupervised learning;modelizacion;image recognition;object recognition;reconocimiento imagen;vision ordenador;contenu image;image content;singularite;image processing;recherche image;information retrieval;interest points;multilayer perceptrons;distributed computing;procesamiento imagen;image classification;natural images;reconnaissance objet;apprentissage non supervise;multilayer perceptron;traitement image;computer vision;perceptron multicouche;modelisation;recherche information;classification image;reconnaissance image;singularidad;pattern recognition;autoorganizacion;calculo repartido;self organization;self organized map;vision ordinateur;transformacion ondita;reconnaissance forme;visual object recognition;reseau neuronal;reconocimiento patron;contenido imagen;modeling;calcul reparti;red neuronal;autoorganisation;wavelet transformation;neural network;singularity;image retrieval	This paper presents an architecture well suited for natural image classification or visual object recognition applications. The image content is described by a distribution of local prototype features obtained by projecting local signatures on a self-organizing map. The local signatures describe singularities around interest points detected by a wavelet-based salient points detector. Finally, images are classified by using a multilayer perceptron receiving local prototypes distribution as input. This architecture obtains good results both in terms of global classification rates and computing times on different well known datasets.	antivirus software;artificial neural network;codebook;computer vision;interest point detection;multilayer perceptron;network architecture;neural network software;organizing (structure);outline of object recognition;prototype;self-organization;self-organizing map;type signature;unsupervised learning;wavelet	Julien Ros;Christophe Laurent;Grégoire Lefebvre	2006		10.1007/11788034_10	unsupervised learning;computer vision;image processing;image retrieval;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;machine learning;artificial neural network	Vision	43.997599209053156	-60.4127541331512	199125
6f12ddf0970176c66e071c7cf48df72eabd3f9b5	color illumination models for image matching and indexing	image recognition;color;image matching;image indexing;computer vision;image representation image matching indexing lighting image colour analysis computer vision;indexing;photometry;image colour analysis;image representation;indexation;voltage;color illumination models;lighting image matching indexing photometry cameras power system modeling color image retrieval humans voltage;image normalization;humans;lighting;color invariants;power system modeling;color invariants color illumination models image matching image indexing color image photometry color representation image normalization;color representation;cameras;color image;image retrieval	Recent works have demonstrated that the direct use of grey levels for image matching and indexing allows one to build very powerful image recognition systems. The present paper attempts to enlarge these results to the case of color images. First, it presents a small abstract about photometry and cameras, which allows one to justify the choice of a color representation system. Then it presents, evaluates, and compares several illumination models, and discusses image normalization techniques. Finally, the paper presents a set of color invariants for image matching and indexing.	image registration	Pascal Gros	2000		10.1109/ICPR.2000.903611	computer vision;search engine indexing;voltage;color normalization;color image;photometry;image retrieval;computer science;lighting;mathematics;normalization;computer graphics (images)	Vision	40.12048599013598	-59.627432922008786	199334
33b1baf85f091a8bd6a99ac81055c87c2caa2b69	on a segmentation algorithm of lines of hough transform using discriminant analysis - on the enforcement of the platform of hough transform -		It is essential for edge detection of Hough transform to enforce the plaform of its availabilities. One of the most important subject of these enforcements is to prepare a robust method for segmenting line segments. We propose two kinds of algorithms: First one is a local algorithm, where a local area moves along the straight lines to judge locally whether the edge points should be on an edge segment or not. Another one is a global algorithm, where a histogram of the edge points along the straight line and the discriminant measure for it collaborate to judge globally whether the straight line should be deviated into some edge segments or not. We discussed also about the integration of these two algorithms to realize a practical line segmentation method.	edge detection;hough transform;linear discriminant analysis;local algorithm	Kunihito Kato;Kazuhito Murakami;Hiroyasu Koshimizu	1994			artificial intelligence;line (geometry);pattern recognition;mathematics;local algorithm;computer vision;edge detection;line segment;algorithm;scale-invariant feature transform;hough transform;linear discriminant analysis;histogram	Vision	44.6331819025023	-65.08867108588196	199506
b379f8efdd6ed377e2b170d8b3e3c6dff684b3d3	an efficient algorithm for fingerprint matching	interpolation;delaunay triangulation;image matching;efficient algorithm;computational geometry;spatial interpolation;fingerprint recognition deformable models fingers image matching computational geometry interpolation nonlinear distortion biometrics computer security data security;spatial interpolation fingerprint matching topology based algorithm fingerprint identification computational geometry delaunay triangulation;mesh generation;mesh generation computational geometry fingerprint identification image matching interpolation;fingerprint identification	This paper proposes novel topology-based algorithms for fingerprint matching. Three major aspects of fingerprint matching are considered: local matching, tolerance to deformation and global matching. The approach improves both the accuracy and the speed of fingerprint identification. Computational geometry methods including Delaunay triangulation and spatial interpolation are used. The proposed methods are able to efficiently deal with the distortions of fingerprints. Experimental results confirm that the algorithms presented are effective and more efficient compared to other fingerprint matching algorithms	algorithm;computation;computational geometry;delaunay triangulation;distortion;experiment;fingerprint recognition;matching (graph theory);multivariate interpolation;nonlinear system;radial basis function	Chengfeng Wang;Marina L. Gavrilova;Yuan Luo;Jon G. Rokne	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.236	mesh generation;fingerprint;computer vision;delaunay triangulation;computational geometry;interpolation;theoretical computer science;machine learning;mathematics;geometry;multivariate interpolation	Vision	41.69089561864324	-63.76320419814142	199550
0a8702df858a90638f2e36c89b136091fc106af1	art extension for description, indexing and retrieval of 3d objects	new three-dimensional shape descriptor;shape descriptor;art extension;angular radial transform;three dimensional;database indexing;indexation;image retrieval	This paper presents a new three-dimensional shape descriptor: 3D angular radial transform. It is an extension of the 2D region based shape descriptor proposed by MPEG-7, the angular radial transform (ART). We propose to generalize the ART to index 3D models.	3d modeling;angularjs;computation;distortion;image scaling;mpeg-7;radial (radio);requirement;shape analysis (digital geometry)	Julien Ricard;David Coeurjolly;Atilla Baskurt	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1334473	database index;three-dimensional space;computer vision;image retrieval;computer science;pattern recognition;information retrieval	Vision	40.76020055793214	-59.825773384462984	199954
