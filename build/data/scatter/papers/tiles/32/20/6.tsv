id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
79ffe075180abb5556347e329b1f63845beb390a	a supervised method to discriminate between impostors and genuine in biometry	supervised classification;score normalisation;unconstrained cohort normalisation;biometric identification	In this paper, we describe a supervised technique that allows to develop a more robust biometric system with respect to those based directly on the similarities of the biometric matchers or on the similarities normalised by the unconstrained cohort normalisation. In order to discriminate between genuine and impostors a quadratic discriminant classifier is trained using four features: the similarities of the biometric matcher; the similarities of the biometric matcher after the unconstrained cohort normalisation (UCN); the average scores among the test pattern and the users that belong to the background model; the difference between the user-specific threshold and the user-independent threshold. The proposed technique is validated by extensive experiments carried out on several biometric datasets (palm, finger, 2D and 3D faces, and ear). The experimental results demonstrate that the capabilities provided by our supervised method can significantly improve the performance of a standard biometric matcher or the performance of the standard UCN. 2009 Elsevier Ltd. All rights reserved.	biometrics;biostatistics;consistency model;discriminant;end-user computing;enhanced entity–relationship model;experiment;machine learning;statistical classification;supervised learning;test card;test set	Loris Nanni;Alessandra Lumini	2009	Expert Syst. Appl.	10.1016/j.eswa.2009.01.037	speech recognition;pattern recognition;data mining;biometrics	AI	29.36896239354164	-63.36584693187189	153677
f2a46904cd0f5ac652da43cd595aef25dcd558ae	improving the accuracy of a score fusion approach based on likelihood ratio in multimodal biometric systems	likelihood ratio;gaussian mixture model;sequential test;system integration;user experience;information fusion;classification accuracy	Multimodal biometric systems integrate information from multiple sources to improve the performance of a typical unimodal biometric system. Among the possible information fusion approaches, those based on fusion of match scores are the most commonly used. Recently, a framework for the optimal combination of match scores that is based on the likelihood ratio (LR) test has been presented. It is based on the modeling of the distributions of genuine and impostor match scores as a finite Gaussian mixture models. In this paper, we propose two strategies for improving the performance of the LR test. The first one employs a voting strategy to circumvent the need of huge datasets for training, while the second one uses a sequential test to improve the classification accuracy on genuine users.#R##N##R##N#Experiments on the NIST multimodal database confirmed that the proposed strategies can outperform the standard LR test, especially when there is the need of realizing a multibiometric system that must accept no impostors.	biometrics;multimodal interaction	Emanuela Marasco;Carlo Sansone	2009		10.1007/978-3-642-04146-4_55	user experience design;likelihood-ratio test;computer science;machine learning;pattern recognition;mixture model;data mining;statistics;system integration	Robotics	29.300230876331554	-63.47749776249244	154245
06c13716ad667cecf0c03c60c25ff11a8e2c8032	on filter banks of texture features for mobile food classification	software;human computer interaction;pose tracking;computer networks and communications;1707;handheld augmented reality;sensor fusion	Nowadays obesity has become one of the most common diseases in many countries. To face it, obese people should constantly monitor their daily meals both for self-limitation and to provide useful statistics for their dietitians. This has led to the recent rise in popularity of food diary applications on mobile devices, where the users can manually annotate their food intake. To overcome the tediousness of such a process, several works on automatic image food recognition have been proposed, typically based on texture features extraction and classification. In this work, we analyze different texture filter banks to evaluate their performances and propose a method to automatically aggregate the best features for food classification purposes. Particular emphasis is put in the computational burden of the system to match the limited capabilities of mobile devices.	aggregate data;filter bank;mobile device;performance	Niki Martinel;Claudio Piciarelli;Christian Micheloni;Gian Luca Foresti	2015		10.1145/2789116.2789132	embedded system;computer vision;simulation;computer science;sensor fusion;multimedia	AI	27.208980958038765	-59.240613704369146	154263
6d91735ab2af18a54a25d9d9e7abdeda0ab0d903	personal recognition using single-sensor multimodal hand biometrics	biometric authentication;performance improvement;error rate	Single-sensor approaches to multimodal biometric authentication targeting the human hand in multiple-matcher scenarios provide higher security in terms of accuracy and resistance to biometric system attacks than unimodal systems. This paper introduces a novel multimodal hand biometric system using palmar images acquired by a commercially available flatbed scanner. Hence, the presented approach to personal recognition is independent of specific biometric sensors, such as fingerprint readers or palmprint scanners. Experimental results with a minimum half total error rate of 0.003% using a database of 443 hand images will illustrate the performance improvement when hand-geometry, fingerprint and palmprint-based features are combined.	algorithm;authentication;biometrics;database;fingerprint recognition;hand geometry;image scanner;minutiae;multimodal interaction;sensor;transponder (aeronautics)	Andreas Uhl;Peter Wild	2008		10.1007/978-3-540-69905-7_45	computer vision;speech recognition;hand geometry;word error rate;computer science;computer security;biometrics	Vision	30.12229003323646	-62.587917166441116	154284
90e5e273560e02f75a215ded4244c9c578d037b2	on the security evaluation of a multibiometric system based on a voting strategy involving likelihood ratio statistic tests	databases;security evaluation;likelihood ratio;gaussian processes;biometrics access control;database management systems;training;biometrics;testing;set theory;biosecure multimodal database security evaluation voting strategy likelihood ratio statistic test multimodal biometric system multiple source unimodal biometric system biometric trait fused modality subset information fusion scheme optimal combination impostor match score finite gaussian mixture model standard lr test spoofing attacks;gaussian mixture model;likelihood ratio statistic;statistical analysis;estimation;statistical analysis biometrics access control database management systems gaussian processes government data processing security of data set theory;system integration;likelihood ratio test;robustness;training databases estimation robustness biometrics testing security;information fusion;security;government data processing;security of data	Multimodal biometric systems integrate information from multiple sources to improve the performance of a typical unimodal biometric system. The use of multimodal biometric systems has been encouraged by the threat of spoofing, where an impostor fakes a biometric trait. The reason lies on the assumption that, an impostor must fake all the fused modalities to be accepted. Recent studies showed that, there is a vulnerability of the existing fusion schemes in presence of attacks where only a subset of the fused modalities is spoofed. Among the possible information fusion approaches, recently, a framework for the optimal combination of match scores that is based on the likelihood ratio (LR) test has been presented. It is based on the modeling of the distributions of genuine and impostor match scores as a finite Gaussian mixture models. Since standard LR test demonstrated to be very sensitive to spoofing attacks, in this paper we analyze the robustness of a voting strategy based on likelihood ratio test in the presence of spoofing. The analysis has been carried out on the Biosecure multimodal database, demonstrating the advantages of a voting strategy with respect to the standard LR approach.	best, worst and average case;biometrics;experiment;fingerprint;lr parser;mixture model;multimodal interaction;spoofing attack	Emanuela Marasco;Carlo Sansone	2011	2011 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS)	10.1109/BIOMS.2011.6053683	computer science;pattern recognition;data mining;statistics	Mobile	29.08683066012509	-63.367826513991545	154509
0fbe38527279f49561c0e1c6ff4e8f733fb79bbe	integrating utility into face de-identification	k anonymity;video surveillance;privacy protection;de identification;face recognition;empirical validation;public space;microaggregation;privacy;privacy preserving data mining	With the proliferation of inexpensive video surveillance and face recognition technologies, it is increasingly possible to track and match people as they move through public spaces. To protect the privacy of subjects visible in video sequences, prior research suggests using ad hoc obfuscation methods, such as blurring or pixelation of the face. However, there has been little investigation into how obfuscation influences the usability of images, such as for classification tasks. In this paper, we demonstrate that at high obfuscation levels, ad hoc methods fail to preserve utility for various tasks, whereas at low obfuscation levels, they fail to prevent recognition. To overcome the implied tradeoff between privacy and utility, we introduce a new algorithm, k -Same-Select, which is a formal privacy protection schema based on k -anonymity that provably protects privacy and preserves data utility. We empirically validate our findings through evaluations on the FERET database, a large real world dataset of facial images.	algorithm;closed-circuit television;de-identification;feret (facial recognition technology);feret database;facial recognition system;hoc (programming language);pixelation;privacy;statistical classification;usability	Ralph Gross;Edoardo M. Airoldi;Bradley A Malin;Latanya Sweeney	2005		10.1007/11767831_15	facial recognition system;privacy software;computer science;data mining;internet privacy;privacy;computer security	HCI	29.819446782816105	-61.992214906692524	154733
3cf9156e725ebb91a896b4601e291d1da909aedb	on accuracy estimation and comparison of results in biometric research	databases;protocols;training;testing;face recognition;estimation;face	The estimated accuracy of an algorithm is the most important element of the typical biometrics research publication. Comparisons between algorithms are commonly made based on estimated accuracies reported in different publications. However, even when the same dataset is used in two publications, there is a very low frequency of the publications using the same protocol for estimating algorithm accuracy. Using the example problems of face recognition, expression recognition and gender classification, we show that the variation in estimated performance on the same dataset across different protocols can be enormous. Based on these results, we make recommendations for how to obtain performance estimates that allow reliable comparison between algorithms.	algorithm;biometrics;computation;cross-validation (statistics);epd;experiment;facial recognition system;statistical classification	Domingo Mery;Yuning Zhao;Kevin W. Bowyer	2016	2016 IEEE 8th International Conference on Biometrics Theory, Applications and Systems (BTAS)	10.1109/BTAS.2016.7791188	facial recognition system;face;communications protocol;estimation;speech recognition;computer science;pattern recognition;data mining;geometry;software testing;statistics	Vision	28.125318186578575	-63.75319533997946	156077
7a5308cbaaff4adeb48fd17107b7c282d5671d8c	symmetric sum-based biometric score fusion		Multimodal biometric systems, which combine information from multiple biometric sources, have shown to improve the identity recognition performance by overcoming the weaknesses and some inherent limitations of unimodal systems. A new framework for score level fusion based on symmetric sums (S-sums) has been presented. These S-sums are generated via triangular norms. The proposed framework has been tested on two publicly available benchmark databases. In particular, the authors used two partitions of NIST-BSSR1, i.e. NIST-multimodal database and NIST-fingerprint database. The experimental results show that the proposed method outperforms the existing approaches for the NIST-multimodal database and NIST-fingerprint database.	biometrics	Mohamed Cheniti;Naceur-Eddine Boukezzoula;Zahid Akhtar	2018	IET Biometrics	10.1049/iet-bmt.2017.0015	fusion;artificial intelligence;pattern recognition;computer science;biometrics	Vision	31.137709283832397	-61.351457408804166	156078
1e24280c580d69438ca0194a27639f8e2985113f	a lip geometry approach for feature-fusion based audio-visual speech recognition	feature extraction visualization speech recognition hidden markov models signal to noise ratio mouth;pca feature fusion based audio visual speech recognition lip geometry approach avsr system mouth region skin color filter border following convex hull hidden markov model hmm appearance based methods discrete cosine transform principal component analysis techniques simulated ambient noise conditions spoken phrases audio noise dct;speech recognition geometry hidden markov models;opencv lip geometry feature fusion audio visual speech recognition	This paper describes a feature-fusion audio-visual speech recognition (AVSR) system that extracts lip geometry from the mouth region using a combination of skin color filter, border following and convex hull, and classification using a Hidden Markov Model. By defining a small number of highly descriptive geometrical features relevant to the recognition task, the approach avoids the poor scalability (termed the `curse of dimensionality') that is often associated with featurefusion AVSR methods. The paper describes comparisons of the new approach with conventional appearance-based methods, namely the discrete cosine transform and the principal component analysis techniques, when operating under simulated ambient noise conditions that affect the spoken phrases. The experimental results demonstrate that, in the presence of audio noise, the geometrical method significantly improves speech recognition accuracy compared with appearance-based approaches, despite the new method requiring significantly fewer features.	audio-visual speech recognition;convex hull;curse of dimensionality;discrete cosine transform;hidden markov model;markov chain;principal component analysis;scalability	M. Z. Ibrahim;D. J. Mulvaney	2014	2014 6th International Symposium on Communications, Control and Signal Processing (ISCCSP)	10.1109/ISCCSP.2014.6877957	computer vision;speech recognition;computer science;pattern recognition	Vision	30.67640789992271	-60.694282061934885	156406
abb196b8ad23157eafdac02c52bb7c480362aa69	facial expression recognition using aam and local facial features	facial feature point extraction;facial expression recognition;feature extraction emotion recognition face recognition;face recognition active appearance model facial features principal component analysis shape control data mining active shape model psychology machine intelligence humans;emotion recognition;active appearance model;face recognition;feature extraction;adaboost;facial features;adaboost facial expression recognition local facial features active appearance model facial feature point extraction;local facial features	A new technique for facial expression recognition is proposed, which uses active appearance model (AAM) to extract facial feature points and combines useful local shape features to form a classifier. To enhance performance of AAM, we use Adaboost to locate eye position to initialize AAM. After extraction of facial feature points, we analyze local facial changes and use some simple features to form an effective classifier. At last, we demonstrate our approach by experiments.	active appearance model;adaboost;algorithm;automatic acoustic management;experiment;pattern recognition;simple features	Fangqi Tang;Benzai Deng	2007	Third International Conference on Natural Computation (ICNC 2007)	10.1109/ICNC.2007.373	computer vision;speech recognition;pattern recognition;three-dimensional face recognition;face hallucination	Vision	31.840001883647226	-59.56548102273494	157070
207fc52997daa5fdfb09f0f91cac2f62f28bb127	facial expression based music player	euclidean distance classifier;expression recognition;facial feature extraction;pca	Conventional method of playing music depending upon the mood of a person requires human interaction. Migrating to the computer vision technology will enable automation of such system. To achieve this goal, an algorithm is used to classify the human expressions and play a music track as according to the present emotion detected. It reduces the effort and time required in manually searching a song from the list based on the present state of mind of a person. The expressions of a person are detected by extracting the facial features using the PCA algorithm and Euclidean Distance classifier. An inbuilt camera is used to capture the facial expressions of a person which reduces the designing cost of the system as compared to other methods. The results show that the proposed system achieves upto 84.82% of accuracy level in recognizing the expressions.	algorithm;computer vision;euclidean distance;mind;principal component analysis	Sushmita G. Kamble;A. H. Kulkarni	2016	2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2016.7732105	computer vision;computer science;artificial intelligence;mathematics;principal component analysis	Robotics	30.13645664992327	-59.899823969071804	157429
bb37f7bd4a24e8b2174fdcdd028f50bd1c9383b4	fingerprint classification system with feedback mechanism based on genetic algorithm	feedback mechanism;image classification;fingerprint recognition feedback genetic algorithms image segmentation image databases image matching feature extraction system testing frequency phased arrays;method integration;image enhancement;feedback;fourier transforms;classification system;classification error;genetic algorithm;four class problem fingerprint classification system feedback mechanism genetic algorithm nist 14 database classification error five class problem;genetic algorithms;image enhancement feedback fourier transforms fingerprint identification image classification genetic algorithms;fingerprint identification	This paper presents a new method of fingerprint classification. The method integrates recognition system with feedback mechanism, based on genetic algorithm. The system was tested on 2000 images in NIST-14 database. For the five-class problem, classification error was 6.0% without any reject, and classification error approximated 1% with a 20% reject rate. For the fourclass problem(with two similar classes combined into the same class), classification error can be reduced to 5.2%. The results are better than those of the fingerprint classification systems created by K. Karu and A. Jian and by J. L. Blue et al.. Through the comparison experiments, it was illustrated that feedback mechanism can give recognition system the capability of adaptation to various inputs, and effectively improve its accuracy.	approximation algorithm;experiment;feedback;fingerprint;genetic algorithm;reduction (complexity)	Yuan Qi;Jie Tian;Ruwei Dai	1998		10.1109/ICPR.1998.711105	computer vision;genetic algorithm;computer science;machine learning;pattern recognition;feedback	AI	31.189254622907796	-64.78625491351701	159059
fd11acc18262431d999f5b8872111d7c57dcbb31	gait template protection using hmm-ubm		This paper presents a hidden Markov model-Universal background model gait authentication system, which is also incorporated into a template protection based on a fuzzy commitment scheme. We show that with limited enrollment data the HMM-UBM system achieves a very competitive equal error rate of$\approx \text{l}$% using one sensor. The proposed template protection scheme benefits from eigenfeatures coming from multiple Universal background model systems fused with a novel technique that minimizes the bit error rate for genuine attempts. This allows the protected system to achieve a false rejection rate below 5% with an effective key length of 64 bits.	64-bit computing;authentication;bit error rate;clinical use template;commitment scheme;deny (action);hidden markov model;key size;markov chain;rejection sampling;benefit	Tim Van hamme;Enrique Argones R&#x00FA;a;Davy Preuveneers;Wouter Joosen	2018	2018 International Conference of the Biometrics Special Interest Group (BIOSIG)	10.23919/BIOSIG.2018.8553315	fuzzy logic;rejection rate;pattern recognition;computer science;artificial intelligence;bit error rate;word error rate;commitment scheme;feature extraction;key size;hidden markov model	Mobile	29.59590447885681	-64.10384298496876	159240
e5bb6a133c794d9210f1793f2b42513a26a42b28	classification of facial expressions using k-nearest neighbor classifier	feature vector;action unit;facial features;k nearest neighbor;facial expression;point of interest	In this paper, we have presented a fully automatic technique for detection and classification of the six basic facial expressions from nearly frontal face images. Facial expressions are communicated by subtle changes in one or more discrete features such as tightening the lips, raising the eyebrows, opening and closing of eyes or certain combinations of them. These discrete features can be identified through monitoring the changes in muscles movement (Action Units) located near about the regions of mouth, eyes and eyebrows. In this work, we have used eleven feature points that represent and identify the principle muscle actions as well as provide measurements of the discrete features responsible for each of the six basic human emotions. A multi-detector approach of facial feature point localization has been utilized for identifying these points of interests from the contours of facial components such as eyes, eyebrows and mouth. Feature vector composed of eleven features is then obtained by calculating the degree of displacement of these eleven feature points from a nonchangeable rigid point. Finally, the obtained feature sets are used for training a K-Nearest Neighbor Classifier so that it can classify facial expressions when given to it in the form of a feature set. The developed Automatic Facial Expression Classifier has been tested on a publicly available facial expression database and on an average 90.76% successful classification rate has been achieved.	k-nearest neighbors algorithm;nearest neighbour algorithm	Abu Sayeed Md. Sohail;Prabir Bhattacharya	2007		10.1007/978-3-540-71457-6_51	computer vision;point of interest;speech recognition;feature vector;computer science;machine learning;pattern recognition;mathematics;k-nearest neighbors algorithm;facial expression	DB	31.22108787437031	-59.782538184091905	159309
044ca9f2194aca3cef7fbc6b94eb9857819a17be	synthetic on-line signature generation. part i: methodology and algorithms	synthetic generation;kinematic theory of rapid human movements;biometric recognition;sigma lognormal model;spectral analysis;on line signature	The theoretical framework and algorithms of a novel method for the generation of synthetic on-line signatures are presented. This model-based approach combines the spectral analysis of real signatures with the Kinematic Theory of rapid human movements in order to generate totally synthetic specimens. Two different algorithms are also described in order to produce duplicated samples from the synthetic master signatures, so that the generation scheme as a whole is able to produce in a complete automatic fashion huge synthetic databases. Typical examples of synthetic specimens are presented to highlight their human-like appearance. The validation protocol and the test results are presented and discussed in a companion paper. & 2011 Elsevier Ltd. All rights reserved.	algorithm;database;online and offline;spectrum analyzer;synthetic biology;synthetic data;type signature	Javier Galbally;Réjean Plamondon;Julian Fiérrez;Javier Ortega-Garcia	2012	Pattern Recognition	10.1016/j.patcog.2011.12.011	computer vision;speech recognition	Vision	28.201577704468445	-65.59902256457629	160372
183e028af0c03d96a2bb582637ed0e6c4485d464	facial video based response registration system	motor skills;feature extraction gesture recognition face support vector machine classification signal processing algorithms image color analysis;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;head gestures facial video response registration system real world scenarios motor skills speech based interfaces integrated video based system;video signal processing face recognition gesture recognition image registration	Today computers have become more accessible and easy to use for everyone, except the disabled. Though some progress has been made on this issue but still it has been focused on either a certain disability or is too expensive for real world scenarios. Major contributions have been made for people lacking fine motor skills and speech based interfaces, but what if they lack both. In this regard we have proposed an integrated video based system that enables the user to give commands by head gestures and enter text by lip-reading. Currently certain gestures and limited vocabulary is recognized by the system but this could be extended in the current framework.	algorithm;autostereogram;computer;face detection;feature vector;gesture recognition;high-level programming language;motion estimation;statistical classification;vocabulary;what if	Usman Saeed;Jean-Luc Dugelay	2008	2008 16th European Signal Processing Conference		computer vision;speech recognition;computer science;gesture recognition;communication	Vision	29.106970342682374	-59.9141013409791	160690
07cf7b0e7d882ef9bf79231773f99a6e23a0967a	a proposal for the management of the measurement uncertainty in classification and recognition problems	databases;probability computerised instrumentation face recognition measurement uncertainty;measurement uncertainty linear discrimination analysis face recognition classification algorithm effective probabilistic approach;uncertainty;measurement uncertainty;face recognition;uncertainty measurement uncertainty face recognition databases face proposals lighting;face;lighting;proposals;measurement uncertainty decision support systems face recognition measurement systems	This paper proposes a new approach to classification and recognition problems. It considers the measurement uncertainty affecting input data to improve the overall effectiveness of this type of process. The proposed method is based on an effective probabilistic approach for the evaluation of the confidence level of system outputs and the suitable use of related information to improve the performance in terms of the correct decision rate. As a case study, it is applied to a particular face recognition classification algorithm based on linear discrimination analysis. The performance comparison with a traditional approach has proven the value of the proposal.	algorithm;biostatistics;decision theory;feret (facial recognition technology);feret database;facial recognition system;fingerprint;linear discriminant analysis;local-density approximation;optical character recognition;performance evaluation;relevance;statistical classification;test case;verification and validation	Giovanni Betta;Domenico Capriglione;Mariella Corvino;Consolatina Liguori;Alfredo Paolillo	2015	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2014.2347218	facial recognition system;face;computer vision;uncertainty analysis;uncertainty;computer science;pattern recognition;data mining;lighting;mathematics;statistics;measurement uncertainty	Vision	28.702725536958535	-62.66940412708969	161212
90f035b4316a95d6a2fd14ba1e1990c9021cda32	face detection by aggregated bayesian network classifiers	optimum branching;bayesian network;bayesian network classifier;universiteitsbibliotheek;system performance;aggregated classifiers;face detection;forest structure	A face detection system is presented. A new classification method using forest-structured Bayesian networks is used. The method is used in an aggregated classifier to discriminate face from non-face patterns. The process of generating non-face patterns is integrated with the construction of the aggregated classifier. The face detection system performs well in comparison with other well-known methods. 2002 Elsevier Science B.V. All rights reserved.	bayesian network;face detection;statistical classification	Thang V. Pham;Marcel Worring;Arnold W. M. Smeulders	2002	Pattern Recognition Letters	10.1016/S0167-8655(01)00177-5	computer vision;face detection;computer science;machine learning;pattern recognition;bayesian network;data mining;computer performance	Vision	28.027718024280283	-59.53598388159846	161479
ec058c89aff17bc3f05c3600f685b8cad118f7be	vision-based classification of driving postures by efficient feature extraction and bayesian approach	tecnologia industrial tecnologia mecanica;tecnologia electronica telecomunicaciones;driving posture;feature extraction;driver behavior;tecnologias;grupo a;bayes classifier;driver assistance system	Reports of traffic accidents show that a considerable percentage of the accidents are caused by human factors. Human-centric driver assistance systems, with integrated sensing, processing and networking, aim to find solutions to this problem and other relevant issues. The key technology in such systems is the capability to automatically understand and characterize driver behaviors. In this paper, we propose a novel, efficient feature extraction approach for driving postures from a video camera, which consists of Homomorphic filter, skin-like regions segmentation, canny edge detection, connected regions The project is supported by National Natural Science Foundation of China (No. 51078087). C. Zhao (B) · J. He College of Transportation, Southeast University, Nanjing, 210096, People’s Republic of China e-mail: chihangzhao@seu.edu.cn J. He e-mail: hejie@seu.edu.cn B. Zhang Department of Computer Science and Software Engineering, Xi’an Jiaotong-Liverpool University, Suzhou, 215123, People’s Republic of China e-mail: Bailing.Zhang@xjtlu.edu.cn detection, small connected regions deletion and spatial scale ratio calculation. With features extracted from a driving posture dataset we created at Southeast University (SEU), holdout and crossvalidation experiments on driving posture classification are then conducted using Bayes classifier. Compared with a number of commonly used classification methods including naive Bayes classifier, subspace classifier, linear perception classifier and Parzen classifier, the holdout and crossvalidation experiments show that the Bayes classifier offers better classification performance than the other four classifiers. Among the four predefined classes, i.e., grasping the steering wheel, operating the shift gear, eating a cake and talking on a cellular phone, the class of talking on a cellular phone is the most difficult to classify. With Bayes classifier, the classification accuracies of talking on a cellular phone are over 90 % in holdout and cross-validation experiments, which shows the effectiveness of the proposed feature extraction method and the importance of Bayes classifier in automatically understanding and characterizing driver behaviors towards human-centric driver assistance systems.	canny edge detector;computer science;cross-validation (statistics);edge detection;email;experiment;feature extraction;human factors and ergonomics;learning classifier system;linear classifier;liverpool;mobile phone;naive bayes classifier;poor posture;probabilistic automaton;single event upset;software engineering;spatial scale;statistical classification;steering wheel;test set	Chihang Zhao;Bailing Zhang;Jie He	2013	Journal of Intelligent and Robotic Systems	10.1007/s10846-012-9797-z	margin classifier;computer vision;bayes classifier;quadratic classifier;feature extraction;computer science;engineering;artificial intelligence;machine learning;pattern recognition	ML	29.54382355071671	-60.056887247478315	162593
e3716760d4d4b9d5d22176ec46de9bb939445c4c	off-line handwritten numeral recognition using hybrid feature set - a comparative analysis		Abstract Handwritten numeral recognition has always been a very challenging task due to many variations in handwritten numerals with different writing styles. It is an active research area now a day. To tackle these variations and to get optimal recognition results, a hybrid feature set, which consists of multiple feature extraction approaches like Box Method, Mean, Standard Deviation and Centre of Gravity, has been used in this paper for recognizing the handwritten numerals. A Neural network has been used for successfully classifying 550 samples taken from “The Chars74” handwritten numerals dataset. The appropriate number of hidden neurons and different membership functions has been used to enhance the recognition results. The proposed recognition system is evaluated and compared with other methods.		Savita Ahlawat;Rahul Rishi	2017		10.1016/j.procs.2017.11.478	machine learning;writing style;artificial intelligence;artificial neural network;numeral system;computer science;standard deviation;feature extraction	Vision	30.80300427191833	-65.23892976285569	163027
6880e83831a294b4ee1a5b30867f3f566bf364e3	a comparative study on chrominance based methods in dorsal hand recognition: single image case		Dorsal hand recognition is a crucial topic in biometrics and human-machine interaction; however most of the identification systems identify and segment the hands from the images consisting of high contrast backgrounds. In other words, capturing and analyzing images of hands on a white or black or any colored background is way too easy to achieve high accuracy. On the contrary, in continuous authentication or in interactive human-machine systems, it can be not possible nor feasible to process high contrast images, like hands on computer keyboards which is not as simple as single color backgrounds even the feature to be extracted is solely the hand color. Therefore we deal with processing of the images consisting of hands on computer keyboards to compare various luminance and chrominance methods by YCbCr color space extraction and to find ways to achieve higher accuracy without any succeeding erosion, dilation or filtering. The methods focused on chromatic intervals could be summarized as: fixed intervals, covariance intervals and fuzzy 2-means. Our main contribution briefly is a necessary accuracy comparison and validation of the common methods on the single images. The highest accuracy is found as 96% by fuzzy 2-means applied to chrominance layers of the image.		Orcan Alpar;Ondrej Krejcar	2018		10.1007/978-3-319-92058-0_68	chromatic scale;chrominance;ycbcr;filter (signal processing);computer vision;luminance;biometrics;segmentation;artificial intelligence;color space;computer science	Robotics	31.215587908275314	-63.02993703045279	163836
5961a6982b69c5d814681cb4d3b6e4993ceee864	feasibility of principal component analysis in hand gesture recognition system		Nowadays actions are increasingly being handled in electronic ways, instead of physical interaction. From earlier times biometrics is used in the authentication of a person. It recognizes a person by using a human trait associated with it like eyes (by calculating the distance between the eyes) and using hand gestures, fingerprint detection, face detection etc. Advantages of using these traits for identification are that they uniquely identify a person and cannot be forgotten or lost. These are unique features of a human being which are being used widely to make the human life simpler. Hand gesture recognition system is a powerful tool that supports efficient interaction between the user and the computer. The main moto of hand gesture recognition research is to create a system which can recognise specific hand gestures and use them to convey useful information for device control. This paper presents an experimental study over the feasibility of principal component analysis in hand gesture recognition system. PCA is a powerful tool for analyzing data. The primary goal of PCA is dimensionality reduction. Frames are extracted from the Sheffield KInect Gesture (SKIG) dataset. The implementation is done by creating a training set and then training the recognizer. It uses Eigen space by processing the eigenvalues and eigenvectors of the images in training set. Euclidean distance with the threshold value is used as similarity metric to recognize the gestures. The experimental results show that PCA is feasible to be used for hand gesture recognition system. Keywords—Hand gesture recognition, Eigen values and Eigen vectors, Principal Component Analysis (PCA), Human Computer Interaction (HCI).	authentication;biometrics;dimensionality reduction;eigen (c++ library);euclidean distance;experiment;face detection;feature extraction;fingerprint;finite-state machine;gesture recognition;human computer;human–computer interaction;kinect;motorola moto;pixel;principal component analysis;test set;uncontrolled format string	Tanu Srivastava;Raj Shree Singh;Sunil Kumar;Pavan Chakraborty	2015	CoRR		face detection;computer science;artificial intelligence;gesture recognition;pattern recognition;euclidean distance;trait;dimensionality reduction;principal component analysis;biometrics;gesture	Vision	30.12988335143291	-59.9713279532275	164181
fbd163fd74abc9aa2f7939aaa7ce1833397c415d	on-line signature matching based on hilbert scanning patterns	hilbert scanning patterns;signature verification;gaussian mixture model;model building;hilbert scanning distance;similarity measure	Signature verification is a challenging task, because only a small set of genuine samples can be acquired and usually no forgeries are available in real application. In this paper, we propose a novel approach based on Hilbert scanning patterns and Gaussian mixture models for automatic on-line signature verification. Our system is composed of a similarity measure based on Hilbert scanning patterns and a simplified Gaussian mixture model for decision-level evaluation. To be practical, we introduce specific simplification strategies for model building and training. The system is compared to other state-of-the-art systems based on the results of the First International Signature Verification Competition (SVC 2004). Experiments are conducted to verify the effectiveness of our system.	hilbert system	Alireza Ahrary;Hui-ju Chiang;Sei-ichiro Kamata	2009		10.1007/978-3-642-01793-3_120	discrete mathematics;model building;machine learning;pattern recognition;mixture model;mathematics	Vision	30.509181043722485	-64.45116136072087	164191
5327241cdbfcfa39abadb4753c7f3706bc24f94a	face verification using local binary patterns generic histogram adaptation and chi-square based decision	authorisation;face authentication accuracy chi square based decision local binary pattern generic histogram adaptation face verification computational simplicity standard protocols feret xm2vts publically available databases claim verification chi square distance decision rule user specific lbp histogram map adaptation technique face images generic face model;face recognition;visual databases authorisation decision theory face recognition;decision theory;face adaptation models histograms databases training face recognition probes;visual databases;histogram adaptation face verification lbp	We propose a simple yet efficient approach to face authentication using local binary patterns (LBP) and histogram adaptation. First, a generic face model is constructed as the LBP histogram extracted from the face images of different users. Then, MAP adaptation technique is applied to obtain the user-specific LBP histogram using the generic model as a prior. We propose a decision rule based on Chi-square distance for claim verification. We extensively evaluate the proposed approach on two publically available databases (namely XM2VTS and FERET) using standard protocols, and compare the obtained results against those of two related works in the literature. The proposed approach yields in interesting results both in terms of authentication accuracy and computational simplicity.	authentication;chi;database;feret (facial recognition technology);local binary patterns	Elhocine Boutellaa;Messaoud Bengherabi;Zinelabidine Boulkenafet;Farid Harizi;Abdenour Hadid	2013	European Workshop on Visual Information Processing (EUVIP)		computer vision;local binary patterns;computer science;pattern recognition;data mining	Vision	29.443464272938886	-63.55349060278359	165778
f3ea062fe3c1222139ded4af4d1ea2b7cbb55be5	gas meter reading from real world images using a multi-net system	neural networks;object segmentation;ocr;text localization;multi net system;object detection	0167-8655/$ see front matter 2012 Elsevier B.V. A http://dx.doi.org/10.1016/j.patrec.2012.11.014 ⇑ Corresponding author. E-mail addresses: marco.vanetti@uninsubria.it ( uninsubria.it (I. Gallo), angelo.nodari@uninsubria.it (A We present a new approach for automatic gas meter reading from real world images. The gas meter reading is usually done on site by an operator and a picture is taken from a mobile device as proof of reading. Since the reading operation is prone to errors, the proof image is checked offline by another operator to confirm the reading. In this study, we present a method to support the validation process in order to reduce the human effort. Our approach is trained to detect and recognize the text of a particular area of interest. Firstly we detect the region of interest and segment the text contained using a method based on an ensemble of neural models. Then we perform an optical character recognition using a Support Vector Machine. We evaluated every step of our approach, as well as the overall assessment, showing that despite the complexity of the problem our method provide good results also when applied to degraded images and can therefore be used in real applications. 2012 Elsevier B.V. All rights reserved.	artificial neural network;context (computing);database;fourier analysis;minimum bounding box;mobile device;online and offline;optical character recognition;region of interest;support vector machine;unification (computer science)	Marco Vanetti;Ignazio Gallo;Angelo Nodari	2013	Pattern Recognition Letters	10.1016/j.patrec.2012.11.014	computer vision;speech recognition;computer science;artificial intelligence;machine learning;pattern recognition;artificial neural network	AI	30.234333340630375	-63.60987133620298	167486
b7c742ac8a18d1815437a041e1c6410712ab5043	comparative studies on multispectral palm image fusion for biometrics	image fusion;quality evaluation;comparative study	Hand biometrics, including fingerprint, palmprint, hand geometry and hand vein pattern, have obtained extensive attention in recent years. Physiologically, skin is a complex multi-layered tissue consisting of various types of components. Optical research suggests that different components appear when the skin is illuminated with light sources of different wavelengths. This motivates us to extend the capability of camera by integrating information from multispectral palm images to a composite representation that conveys richer and denser pattern for recognition. Besides, usability and security of the whole system might be boosted at the same time. In this paper, comparative study of several pixel level multispectral palm image fusion approaches is conducted and several well-established criteria are utilized as objective fusion quality evaluation measure. Among others, Curvelet transform is found to perform best in preserving discriminative patterns from multispectral palm images.	biometrics;curvelet;fingerprint;hand geometry;image fusion;multispectral image;pixel;usability	Ying Hao;Zhenan Sun;Tieniu Tan	2007		10.1007/978-3-540-76390-1_2	computer vision;comparative research;multispectral pattern recognition;image fusion	Vision	29.723321804135345	-61.79846089818854	167670
eafc61078d4a18d753b7cce5d0a83b8c548ded71	hierarchical neural network classifier for an efficient incident detection based on sound content analysis	signal classification acoustic signal detection feature extraction neural net architecture;field programmable gate array;hierarchical neural networks;accidents field programmable gate arrays transportation mel frequency cepstral coefficient safety neural networks;neural networks;neural net architecture;mel frequency cepstral coefficient;content analysis;accidents;feature extraction;transportation;safety;signal classification;acoustic signal detection;feature extraction algorithm hierarchical neural network classifier architecture incident detection sound content analysis fpga classification performance;parallel implementation;field programmable gate arrays;neural network	A sound content analysis is proposed to detect incident at intersections, which is suitable to implement on hardware such as FPGA. Due to confusion between the sound classes, an hierarchical classifier architecture is proposed to improve the classification performance. The proposed architecture and the feature extraction algorithm are suitable for parallel implementation.	algorithm;artificial neural network;feature extraction;field-programmable gate array;hierarchical classifier	Halis Altun	2012	2012 20th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2012.6204697	speech recognition;computer science;machine learning;pattern recognition;artificial neural network;field-programmable gate array	ML	25.660803250928666	-60.932869545139766	170884
266860beb30e13624ce45c66567d624ee659d152	online face recognition system for videos based on modified probabilistic neural networks	face recognition videos neural networks face detection surveillance image processing tv mobile handsets databases airports;probability;neural nets;video signal processing;video retrieval;image classification;face classifier modified probabilistic neural network video retrieval online learning face recognition system;closed system;online learning;probability neural nets face recognition image classification image retrieval video signal processing;mobile phone;face recognition;false positive rate;automatic detection;probabilistic neural network;on line learning;image retrieval	"""Video retrieval in consumer applications demands high level semantic descriptors such as people's identity. The problem is that in a variety of videos such as home videos, Hollywood content, TV broadcast content; mobile phone videos faces are not easy to recognize. Even more, a closed system trained to recognize only a predetermined number of faces become obsolete very easily. We developed an online-learning face recognition system for a variety of videos based on modified probabilistic neural networks (MPNN). This face recognition system can detect and recognize known faces, as well as automatically detect unknown faces and train the unknown faces online into new face classifiers such that this """"unknown face"""" can be recognized if it appears again. MPNN is a variant of the PNN with thresholding on the category (output) layer of a probabilistic neural network (PNN) in order to detect unknown categories of input data. The PNN training makes the online training very fast because adding new faces does not require retraining of the known categories. Our experimental results show that on-line learning gives somewhat lower hit rate, while at the same time reducing the false positive rate."""	artificial neural network;closed system;facial recognition system;high-level programming language;hollywood;mobile phone;online and offline;online machine learning;pattern recognition;probabilistic neural network;semantic data model;thresholding (image processing)	Jun Fan;Nevenka Dimitrova;Vasanth Philomin	2004	2004 International Conference on Image Processing, 2004. ICIP '04.	10.1109/ICIP.2004.1421479	computer vision;contextual image classification;probabilistic neural network;image retrieval;false positive rate;computer science;machine learning;pattern recognition;probability;closed system;statistics	Vision	26.579115066210274	-59.404234140652854	171317
33b6a440a3870fb56dc83ed89085780686bf7bf6	expression training for complex emotions using facial expressions and head movements	training;training emotion recognition real time systems face recognition autism face webcams;autism;emotion recognition;simple graphs expression training interface facial expressions head movements emotion recognition integrated emotion classifier exact expression imitation dynamic time warping action units intensity action units frequency;face recognition;webcams;face;emotion recognition affective computing;affective computing;image classification emotion recognition face recognition graph theory;real time systems	Imitation is an important aspect of emotion recognition. We present an expression training interface which evaluates the imitation of facial expressions and head movements. The system provides feedback on complex emotion expression, via an integrated emotion classifier which can recognize 18 complex emotions. Feedback is also provided for exact-expression imitation via dynamic time warping. Discrepancies in intensity and frequency of action units are communicated via simple graphs. This work has applications as a training tool for customer-facing professionals and people with Autism Spectrum Conditions.	dynamic time warping;emotion markup language;emotion recognition;image warping	Andra Adams;Peter Robinson	2015	2015 International Conference on Affective Computing and Intelligent Interaction (ACII)	10.1109/ACII.2015.7344660	psychology;face;computer vision;speech recognition;autism;computer science;artificial intelligence;affective computing;geometry;communication	Robotics	28.70908035162226	-59.893358107151194	171783
2733ad9fa3313e664144d981e02c9a1c29ea7bce	benchmarking quality-dependent and cost-sensitive score-level multimodal biometric fusion algorithms	automatic control;banking services;system reliability;banking;quality based fusion biometric database cost sensitive fusion multimodal biometric authentication;iris biometrics;performance evaluation;multimodal biometric authentication;biometric authentication;airports security control;quality dependent fusion algorithm;airports;image fusion;biometric database;biometrics;signalbehandling;cost sensitive fusion;biometric sensors;fingerprint biometrics;cost sensitive score level multimodal biometric fusion algorithm;biometrics costs performance evaluation fingerprint recognition access control hardware banking security automatic control airports;biometric devices;face recognition;person authentication;fingerprint recognition;biosecure ds2;image fusion face recognition fingerprint identification;signal processing;sequential fusion;sequential fusion cost sensitive score level multimodal biometric fusion algorithm quality dependent fusion algorithm banking services airports security control system reliability biometric devices biosecure ds2 access control iris biometrics fingerprint biometrics face biometrics person authentication biometric sensors;quality based fusion;access control;quality measures;security;article;face biometrics;fingerprint identification;hardware	Automatically verifying the identity of a person by means of biometrics (e.g., face and fingerprint) is an important application in our day-to-day activities such as accessing banking services and security control in airports. To increase the system reliability, several biometric devices are often used. Such a combined system is known as a multimodal biometric system. This paper reports a benchmarking study carried out within the framework of the BioSecure DS2 (Access Control) evaluation campaign organized by the University of Surrey, involving face, fingerprint, and iris biometrics for person authentication, targeting the application of physical access control in a medium-size establishment with some 500 persons. While multimodal biometrics is a well-investigated subject in the literature, there exists no benchmark for a fusion algorithm comparison. Working towards this goal, we designed two sets of experiments: quality-dependent and cost-sensitive evaluation. The quality-dependent evaluation aims at assessing how well fusion algorithms can perform under changing quality of raw biometric images principally due to change of devices. The cost-sensitive evaluation, on the other hand, investigates how well a fusion algorithm can perform given restricted computation and in the presence of software and hardware failures, resulting in errors such as failure-to-acquire and failure-to-match. Since multiple capturing devices are available, a fusion algorithm should be able to handle this nonideal but nevertheless realistic scenario. In both evaluations, each fusion algorithm is provided with scores from each biometric comparison subsystem as well as the quality measures of both the template and the query data. The response to the call of the evaluation campaign proved very encouraging, with the submission of 22 fusion systems. To the best of our knowledge, this campaign is the first attempt to benchmark quality-based multimodal fusion algorithms. In the presence of changing image quality which may be due to a change of acquisition devices and/or device capturing configurations, we observe that the top performing fusion algorithms are those that exploit automatically derived quality measurements. Our evaluation also suggests that while using all the available biometric sensors can definitely increase the fusion performance, this comes at the expense of increased cost in terms of acquisition time, computation time, the physical cost of hardware, and its maintenance cost. As demonstrated in our experiments, a promising solution which minimizes the composite cost is sequential fusion, where a fusion algorithm sequentially uses match scores until a desired confidence is reached, or until all the match scores are exhausted, before outputting the final combined score.	access control;algorithm;algorithmic efficiency;authentication;bayesian network;benchmark (computing);biometric device;biometrics;computation;computational resource;discriminative model;experiment;fingerprint;generative model;image fusion;image quality;logistic regression;multimodal interaction;naive bayes classifier;oracle fusion architecture;physical access;sensor;support vector machine;time complexity	Norman Poh;Thirimachos Bourlai;Josef Kittler;Lorène Allano;Fernando Alonso-Fernandez;Onkar Ambekar;John P. Baker;Bernadette Dorizzi;Omolara Fatukasi;Julian Fiérrez;Harald Ganster;Javier Ortega-Garcia;Donald E. Maurer;Albert Ali Salah;Tobias Scheidat;Claus Vielhauer	2009	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2009.2034885	computer vision;computer science;information security;signal processing;automatic control;data mining;computer security;biometrics	Mobile	29.409896284220828	-63.231674905794925	172942
fd0be5ed493d08f31475b4491d3807e34e1becd6	a pattern selection algorithm based on the generalized confidence	boundary patterns;training patterns;system performance;offline handwritten chinese character database pattern selection algorithm generalized confidence training patterns boundary patterns;pattern selection algorithm;pattern classification;subset selection;offline handwritten chinese character database;generalized confidence;system performance pattern recognition target recognition information science databases supervised learning character recognition pattern matching pattern analysis neural networks	In the process of training, some patterns are indispensable because they describe the characteristic of the class, but other patterns are dispensable. Sometimes, with these patterns the system performance even gets worse. So it is necessary to select the training patterns and find a more representative pattern subset. In this paper, a definition of the boundary patterns based on the generalized confidence is given, and a new algorithm of pattern selection is founded on this definition. According to the experiments on the offline handwritten Chinese character database HCL2004, the pattern subset selected by these algorithms have less patterns than the original set, but the system performance based on the subset is improved. Then the validity of the definition and these algorithms is approved	experiment;online and offline;selection algorithm	Junling Ren	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.148	computer science;machine learning;pattern recognition;data mining;computer performance	Vision	31.75423025470984	-65.84277000580597	173676
088820f939b5a43a9b77bd9207eb643dd987d524	pairwise coupling for machine recognition of hand-printed japanese characters	prediction accuracy machine recognition hand printed japanese character recognition classification computational costs pairwise coupling probabilistic two class kernel classifiers hiragana recognition;image classification character sets character recognition;image classification;character recognition kernel support vector machines computational efficiency costs biological system modeling large scale systems computer science accuracy computational biology;prediction accuracy;character sets;character recognition	Machine recognition of hand-printedJapanesecharacters hasbeenan areaof greatinterestfor manyyears. The majorproblemwith thisclassificationtaskis thehugenumber of different characters. Applying standard ”state-ofthe-art” techniques,such as theSVM,to multi-classproblemsof thiskindimposessevereproblems,bothof a conceptualanda technicalnature: (i) separatingoneclassfromall others maybe an unnecessarilyhard problem;(ii) solving thesesubproblemscan imposeunacceptablyhigh computational costs. In this paper, a new approach to Japanese character recognition is presentedthat successfullyovercomestheseshortcomings.It is basedon a pairwisecoupling procedure for probabilistic two-classkernel classifiers. Experimentalresultsfor Hiraganarecognition effectivelydemonstr atethatour methodattainsanexcellentlevel of predictionaccuracy while imposingvery low computational costs.	optical character recognition	Volker Roth;Koji Tsuda	2001		10.1109/CVPR.2001.990656	contextual image classification;speech recognition;character encoding;feature;computer science;machine learning;pattern recognition	AI	31.248116154232942	-65.06545355437885	174037
e420670d2a73822a802b75ded26812e9f0f62eae	discriminative projection selection based face image hashing	privacy	Face image hashing is an emerging method used in biometric verification systems. In this paper, we propose a novel f ace image hashing method based on a new technique called discriminative proj ction selection. We apply the Fisher criterion for selecting the r ows of a random projection matrix in a user-dependent fashion. Moreover, an other contribution of this paper is to employ a bimodal Gaussian mixture model at the quantization step. Our simulation results on three di fferent databases demonstrate that the proposed method has superior performance in comparison to previously proposed random projection based meth ods. key words: face image hashing, biometric security, privacy	automatic computing engine;biometrics;database;fisher–yates shuffle;hash function;mixture model;privacy;random projection;simulation	Cagatay Karabat;Hakan Erdogan	2012	IEICE Transactions		computer science;theoretical computer science;machine learning;universal hashing;pattern recognition;locality preserving hashing;privacy;computer security	Vision	31.25443395810275	-61.27180081000045	174969
49b4b6bb1635c8114dc068a6e9405170a8a50907	a study on emotion recognition method and its application using face image		In this paper, we introduce seven emotions and positive and negative emotion recognition methods using facial images and the development of apps based on the method. In previous researches, they used the deep-learning technology to generate models with emotion-based facial expressions to recognized emotions. There are existing apps that express six emotions, but not seven emotions and positive and negatives in graphs and percentages. Thus, we recognized seven emotions such as Angry, Disgust, Fear, Happy, Sad, Surprise, and Neutral and also classified the calculated emotion-recognition scores into positive, negative and neutral emotions. Then we implemented an app that provides the user with seven emotions scored and positive and negative emotions.	algorithm;database;emotion recognition;graph (discrete mathematics)	Hyeon-Jung Lee;Kwang-Seok Hong	2017	2017 International Conference on Information and Communication Technology Convergence (ICTC)	10.1109/ICTC.2017.8191005	support vector machine;surprise;emotion recognition;psychology;facial recognition system;disgust;pattern recognition;graph;facial expression;artificial intelligence	Robotics	28.85968787325767	-59.18271838732662	176116
7f78d48f9f3518a0134449b92fc22351267815c6	improved statistical steganalysis using models of heterogeneous cover signals			steganalysis	Rainer Böhme	2009				ML	27.123046264578868	-65.33370474427262	176627
614835e4d96244c58609756bfecadcb2cff68441	improving identification by pruning: a case study on face recognition and body soft biometric	databases;soft biometrics pruning anthropometric measurements face recognition;anthropometry;biometrics access control;anthropomeasure based system identification improvement face recognition algorithm body soft biometric capability biometrics database pruning preclassification step anthropometric measures large scale medical dataset chimera dataset;image classification;noise measurement;noise accuracy face recognition databases face noise measurement humans;accuracy;large scale;pruning;face recognition;soft biometrics pruning face recognition;visual databases anthropometry biometrics access control face recognition image classification;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;soft biometrics;face;humans;noise;face recognition soft biometrics pruning;visual databases	We investigate body soft biometrics capabilities to perform pruning of a hard biometrics database improving both retrieval speed and accuracy. Our pre-classification step based on anthropometric measures is elaborated on a large scale medical dataset to guarantee statistical meaning of the results, and tested in conjunction with a face recognition algorithm. Our assumptions are verified by testing our system on a chimera dataset. We clearly identify the trade off among pruning, accuracy, and mensuration error of an anthropomeasure based system. Even in the worst case of ±10% biased anthropometric measures, our approach improves the recognition accuracy guaranteeing that only half database has to be considered.	algorithm;anthropometry;best, worst and average case;cellular automaton;chimera (software library);continuation;facial recognition system;feature vector;mean squared error;soft biometrics	Carmelo Velardo;Jean-Luc Dugelay	2012	2012 13th International Workshop on Image Analysis for Multimedia Interactive Services	10.1109/WIAMIS.2012.6226747	face;computer vision;contextual image classification;speech recognition;computer science;noise measurement;noise;pruning;pattern recognition;anthropometry;accuracy and precision	Vision	28.11934242603079	-63.70679975755999	178554
ed73f33494f74f02537576c7c5bec92b9caad7cb	a calibration-free head gesture recognition system with online capability	ordered means model;calibration free head gesture recognition system;image motion analysis;head movement;magnetic heads;head shaking;sensors;tilting head gesture;signal processing systems and applications human body motion and gesture based interaction group interaction analysis of verbal and non verbal communication;motion sensor based approach;human body motion and gesture based interaction;training;group interaction analysis of verbal and non verbal communication;online recognition;time series;nodding;image sensors;classification;online capability;training data;signal processing systems and applications;hidden markov models;time series gesture recognition image motion analysis image sensors learning artificial intelligence;machine learning;signal processing;human body;magnetic heads hidden markov models sensors gesture recognition training data training lighting;systems and applications;lighting;learning artificial intelligence;online recognition calibration free head gesture recognition system online capability motion sensor based approach data acquisition head movement ordered means model classification machine learning time series nodding head shaking tilting head gesture;data acquisition;gesture recognition;group interaction;non verbal communication	In this paper, we present a calibration-free head gesture recognition system using a motion-sensor-based approach. For data acquisition we conducted a comprehensive study with 10 subjects. We analyzed the resulting head movement data with regard to separability and transferability to new subjects. Ordered means models (OMMs) were used for classification, since they provide an easy-to-use, fast, and stable approach to machine learning of time series. In result, we achieved classification rates of 85-95% for nodding, head shaking and tilting head gestures and good transferability. Finally, we show first promising attempts towards online recognition.	data acquisition;gesture recognition;linear separability;machine learning;motion detector;time series	Nils-Christian Wöhler;Ulf Großekathöfer;Angelika Dierker;Marc Hanheide;Stefan Kopp;Thomas Hermann	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.929	nonverbal communication;computer vision;training set;nod;human body;speech recognition;biological classification;computer science;sensor;machine learning;signal processing;time series;image sensor;gesture recognition;lighting;data acquisition	Robotics	27.38252171460809	-60.29863378646033	180201
b53be62c8d1ffc46bdb1b7781785bc238c105d72	eye state recognition algorithm gahmm of web-based learning fatigue	internet learning;hidden markov model;learning fatigue	With the increasingly deeper application of multimedia and network technology in education, the proportion of web-based learning presents a trend of continuous growth in people’s daily study, and the webbased learners tend to have learning fatigue during their learning process of distance education. Under the 4 learning states of normal study, fatigue and doubt, the eye opening degrees of web-based learner have certain difference. Through preprocessing of the color images of web-based learners’ eye state, the 2-dimensional kernel function is selected to build 48 optimal filters and obtain 48 eigenvalues, and then, through HMM, training is conducted to identify the eye state and feature classification. The experiment results show that this algorithm has very high identification ability of the web-based learning fatigue.	algorithm;closing (morphology);color image;hidden markov model;preprocessor;statistical classification;web application	Qiufen Yang;Zhenjun Li;Canjun Li;Xianlin Yang;Can Zhu	2014	Journal of Multimedia	10.4304/jmm.9.5.694-700	semi-supervised learning;unsupervised learning;computer vision;instance-based learning;error-driven learning;simulation;speech recognition;computer science;machine learning;world wide web;active learning;synchronous learning;hidden markov model	ML	26.29985231140934	-59.54946685449407	180899
dec059db0f0febacb496a99b1836bf201a469ae9	tracking and recognition of multiple human targets moving in a wireless pyroelectric infrared sensor network	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;feature extracting;uk phd theses thesis;期刊论文;life sciences;multiple human identification;distributed wireless pyroelectric sensor network;uk research reports;medical journals;europe pmc;biomedical research;empirical mode decomposition;bioinformatics	With characteristics of low-cost and easy deployment, the distributed wireless pyroelectric infrared sensor network has attracted extensive interest, which aims to make it an alternate infrared video sensor in thermal biometric applications for tracking and identifying human targets. In these applications, effectively processing signals collected from sensors and extracting the features of different human targets has become crucial. This paper proposes the application of empirical mode decomposition and the Hilbert-Huang transform to extract features of moving human targets both in the time domain and the frequency domain. Moreover, the support vector machine is selected as the classifier. The experimental results demonstrate that by using this method the identification rates of multiple moving human targets are around 90%.	algorithm;biometrics;deploy;experiment;feature extraction;hilbert–huang transform;host (network);patent ductus arteriosus 1;personal digital assistant;statistical classification;support vector machine;video sensor technology;wireless gateway;sensor (device)	Ji Xiong;Fangmin Li;Ning Zhao;Na Jiang	2014		10.3390/s140407209	speech recognition;telecommunications;bioinformatics;engineering;electrical engineering;data science;hilbert–huang transform;data mining	Mobile	25.786961344400016	-65.27415741199201	182078
afa2f05306028980f8dbd83ca2842de3bd663437	serial combination of multiple classifiers for automatic blue whale calls recognition	classifiers combination;blue whale calls;short time fourier transform;vector quantization;feature extraction;k nearest neighbour;chirplet transform;neural network	In this paper, we propose a serial combination architecture of classifiers for automatic blue whale calls recognition. Based on class's best selection operator, the proposed system uses a best classifier for D call class followed by another one that efficiently discriminate the A and B calls. The first classifier uses the short-time Fourier transform to characterize the patterns, while the second uses the chirplet transform. Both classifiers are based on multi-layer perceptron neural network. The classification performance (95.55%) of the proposed system outperforms all tested single classifiers. The other advantages of the system are no requirement for adjusting a series of parameters and simple feature extraction.		Mohammed Bahoura;Yvan Simard	2012	Expert Syst. Appl.	10.1016/j.eswa.2012.01.156	random subspace method;speech recognition;short-time fourier transform;feature extraction;computer science;machine learning;pattern recognition;chirplet transform;vector quantization;artificial neural network	Vision	27.025949433001966	-61.78292455616023	182691
045c7dbd264f78cf752eaef645a22f70395bb20d	fusion of face and gait for automatic human recognition	behavioral biometric automatic human recognition face fusion gait fusion physical biometric;focusing;image recognition;image resolution;legged locomotion;application software;biometrics access control;humans face recognition biometrics legged locomotion face detection application software image recognition image resolution focusing fingerprint recognition;image fusion;biometrics;gait recognition;human recognition;behavioral biometric;computer vision;image fusion biometrics access control face recognition gait analysis;face recognition;face gait integration human recognition computer vision face recognition gait recognition;automatic human recognition;fingerprint recognition;face gait integration;gait analysis;physical biometric;humans;gait fusion;face detection;face fusion	In recent years, several techniques have been proposed which integrate face, a physical biometric, with gait, a behavioral biometric, with the aim of investigating if such a combination will improve upon the performance of methods which exclusively employ only one of these biometrics. An overview of some of the well-known approaches in this area, along with a discussion of the advantages offered and the challenges faced by such systems, is provided in this paper and the potential of this technology for further research and application is explored.	biometrics;whole earth 'lectronic link	Rabia Jafri;Hamid R. Arabnia	2008	Fifth International Conference on Information Technology: New Generations (itng 2008)	10.1109/ITNG.2008.33	facial recognition system;computer vision;face detection;application software;speech recognition;gait analysis;image resolution;computer science;image fusion;fingerprint recognition;biometrics	EDA	28.840783732624185	-61.07865662392323	183871
070e09bd6d30c1dd8e114c11f1cab14548e2e05e	a fast cattle recognition system using smart devices	object recognition;cattle recognition;classification;computer vision;muzzle point pattern;machine learning;animal biometrics;feature extraction	A recognition system is very useful to recognize human, object, and animals. An animal recognition system plays an important role in livestock biometrics, that helps in recognition and verification of livestock in case of missed or swapped animals, false insurance claims, and reallocation of animals at slaughter houses. In this research, we propose a fast and cost-effective animal biometrics based cattle recognition system to quickly recognize and verify the false insurance claims of cattle using their primary muzzle point image pattern characteristics. To solve this major problem, users (owner, parentage, or other) have captured the images of cattle using their smart devices. The captured images are transferred to the server of the cattle recognition system using a wireless network or internet technology. The system performs pre-processing on the muzzle point image of cattle to remove and filter the noise, increases the quality, and enhance the contrast. The muzzle point features are extracted and supervised machine learning based multi-classifier pattern recognition techniques are applied for recognizing the cattle. The server has a database of cattle images which are provided by the owners. Finally, One-Shot-Similarity (OSS) matching and distance metric learning based techniques with ensemble of classifiers technique are used for matching the query muzzle image with the stored database.A prototype is also developed for evaluating the efficacy of the proposed system in term of recognition accuracy and end-to-end delay.	biometrics;database;end-to-end principle;internet protocol suite;machine learning;pattern recognition;preprocessor;prototype;semantic similarity;server (computing);smart device;supervised learning	Santosh Kumar;Sanjay Kumar Singh;Tanima Dutta;Hari Prabhat Gupta	2016		10.1145/2964284.2973829	computer vision;simulation;feature extraction;biological classification;computer science;cognitive neuroscience of visual object recognition;machine learning;computer security	Vision	31.055763370395145	-62.6894650652685	184362
642b0786bad7301c615b47257444ee16c60cc5f9	human identification using linear multiclass svm and eye movement biometrics	support vector machines biometrics access control image recognition;eye position;support vector machines;biometrics access control;identification linear multiclass svm eye position eye difference eye velocity biometric eye verification;training;biological system modeling;error analysis;support vector machines biometrics access control feature extraction training data models error analysis biological system modeling;feature extraction;identification;eye velocity;eye based biometric identification human identification linear multiclass svm eye movement biometrics linear multiclass svm model;eye difference;linear multiclass svm;data models;biometric eye verification	The paper presents a system to accurately differentiate between unique individuals by utilizing the various eye-movement biometric features. Eye Movements are highly resistant to forgery as the generation of eye movements occur due to the involvement of complex neurological interactions and extra ocular muscle properties. We have employed Linear Multiclass SVM model to classify the numerous eye movement features. These features were obtained by making a person fixate on a visual stimuli. The testing was performed using this model and a classification accuracy up to 91% to 100% is obtained on the dataset used. The results are a clear indication that eye-based biometric identification has the potential to become a leading behavioral technique in the future. Moreover, its fusion with different biometric processes such as EEG, Face Recognition etc., can also increase its classification accuracy.	biometrics;electroencephalography;embedded system;facial recognition system;interaction;velocity	Namrata Srivastava;Utkarsh Agrawal;Soumava Kumar Roy;U. S. Tiwary	2015	2015 Eighth International Conference on Contemporary Computing (IC3)	10.1109/IC3.2015.7346708	identification;data modeling;support vector machine;computer vision;speech recognition;feature extraction;computer science;machine learning;pattern recognition	Robotics	26.34038738539098	-63.95662619187506	184457
ccf723bd6d58b2f4e9600ffa1d3684cce7d1647a	a vision-based hybrid method for facial expression recognition	hybrid method;feature point;facial expression recognition;different facial expression;adaboost;whole facial expression recognition;vision-based hybrid method;facial expression;intelligent human computer communication;support vector machine;motion history image;optical flow;main contribution;skin color model;face region	Facial expression is a very useful channel for intelligent human computer communication. In this paper we propose a hybrid method to recognize facial expression. Our main contributions in this study are: first, face region is detected by combing Adaboost, Skin color model and motion history image; second, feature points representing different facial expressions are separated using optical flow; third, a support vector machine classifier is used to classify these feature point's info (location, distance, angle); last, tests to explore the whole facial expression recognition process are conducted and the results are satisfactory.	adaboost;human computer;optical flow;support vector machine	Xiuchang Huang;Yaping Lin	2008			three-dimensional face recognition	Vision	30.96616111163092	-59.165138689159214	184813
6d956d65a5fd5607abda6f9c99c6ce8a32cc2fac	3d caricature generation by manifold learning	3d;manifolds;training;regression model;manifold learning;artificial neural networks;elm 3d caricature manifold lle;3d model;face recognition;machine learning;lle manifold learning;extreme learning machine;three dimensional displays;three dimensional displays face manifolds solid modeling training machine learning artificial neural networks;solid modeling;solid modelling face recognition learning artificial intelligence regression analysis;caricature;2d facial photograph;regression analysis;face;learning artificial intelligence;elm;2d facial photograph caricature generation 3d model lle manifold learning regressive model extreme learning machine;caricature generation;regressive model;lle;solid modelling;manifold	3D caricature generation is becoming an interesting and important research program, but it is impossible for the computer to draw an elegant caricature without any background. In this paper, we build a training set which contains 110 true face photographs and corresponsive 3D caricature models. Based on that training set, the LLE manifold learning is performed to discover the low dimensional embeddings. Between the 2D true face embeddings and 3D caricature embeddings, a regressive model is learnt by the Extreme Learning Machine. Experiments show that, the regressive manifold model is effective to generate the final 3D caricature for a 2D facial photograph.	nonlinear dimensionality reduction;test set	Pengfei Li;Yiqiang Chen;Junfa Liu;Guanhua Fu	2008	2008 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2008.4607591	facial recognition system;speech recognition;manifold;computer science;artificial intelligence;machine learning;artificial neural network;regression analysis;3d computer graphics	Vision	25.831163773381686	-59.89613923084988	184817
b5210ce3d595107611a863a307fa96c4eb500d07	depth sensor based automatic hand region extraction by using time-series curve and its application to japanese finger-spelled sign language recognition		Abstract   Hand sign recognition is one of most challenging issues in computer vision and human computer interaction, and many researchers tackle this issue. In this research, we focus on JFSL (Japanese Finger-spelled Sign Language) which is one of hand signs. The tasks for achieving high performance of JFSL recognition as well as other hand signs are how to extract hand region precisely and how to recognize hand signs accurately. To deal with the former task, in this paper, we propose an automatic hand region extraction method with a depth sensor. The characteristic points of our proposed method are to utilize Time-Series Curve, which is one of contour features, and to extract hand region accurately without wearing landmark object such as a color wristband. On the other hand, to tackle the latter task, in this research, we focus on a deep neural network based recognition method since such a method is reported that it allows us to achieve high performance for various recognition tasks. Therefore, in this paper, we investigate JFSL recognition performance with a deep neural network approach compared to that with the conventional image recognition method (HOG+SVM). From the experimental results with 8 subjects, we have confirmed that our proposed method allows us to extract hand region accurately regardless of subjects and JFSL signs. In addition, from the experimental results with a deep neural network based recognition method for JFSL recognition, we have achieved at least average recognition rate over 88%.	language identification	Katsufumi Inoue;Takami Shiraishi;Michifumi Yoshioka;Hidekazu Yanagimoto	2015		10.1016/j.procs.2015.08.145	computer vision;speech recognition;gesture recognition;three-dimensional face recognition	NLP	31.156505880077525	-60.070645764850035	186989
326611cbfaea5a413c6f9496bf96b27267a7f273	“whitenedfaces” recognition with pca and ica	whitenedface recognition;whitening face recognition independent component analysis ica power spectrum principle component analysis pca;power law power face image spectrum;layout;independent component analysis;power spectrum;higher order statistics;independent component analysis whitenedface recognition power law power face image spectrum fast fourier transform algorithm principal component analysis;fast fourier transform;principal component analysis independent component analysis frequency layout low pass filters face recognition retina higher order statistics visual system power system modeling;face recognition;independent component analysis ica;retina;principal component analysis;principal component analysis face recognition fast fourier transforms independent component analysis;whitening;fast fourier transforms;fast fourier transform algorithm;principle component analysis;low pass filters;power law;power system modeling;frequency;visual system;principle component analysis pca	This letter develops a simple and effective whitening method for flattening the power-law power spectrum of face images and combines the whitening technique and PCA/ICA for face recognition. The whitening parameter in the whitening filter is adaptive to the input data so as to make the power spectrum of the whitened results as flat as possible. This proposed method is computationally saving for using fast Fourier transform algorithms. The transformed ldquowhitenedfacesrdquo are applied to face recognition with PCA and ICA coding strategies, respectively. The results show that the whitening processing will bring better recognition performances for both PCA and ICA representations.	algorithm;computation;decorrelation;facial recognition system;fast fourier transform;independent computing architecture;performance;pixel;principal component analysis;spectral density;whitening transformation	Lingzhi Liao;Siwei Luo;Mei Tian	2007	IEEE Signal Processing Letters	10.1109/LSP.2007.904704	facial recognition system;fast fourier transform;speech recognition;computer science;machine learning;pattern recognition;mathematics;statistics;principal component analysis	Vision	26.096056024741433	-62.578920138110234	187017
f0f8980d234e8c83136cbbc6a0deb09476c134d5	gait recognition for human identification using kinect		Gait is a pattern of biometric movement for human identification. Unlike other biometrics such as fingerprint, iris, face, and voice recognition, human gait can be captured with unobtrusive method. In this paper, several measurements are proposed which uses body frame information in 3D space. Body frame data is generated from depth images captured using Kinect camera. The generated body frames are used for human gait analysis. The angle of lower body parts is measured in a gait cycle. In addition, the length of body parts is measured as a feature for combination with the angle measurements. The measurements are compared to each other from 5 subjects who have similar body type. The difference from comparison of the measurements indicates that the human gait has a potential pattern for human identification.	biometrics;fingerprint;gait analysis;kinect	Wonjin Kim;Yanggon Kim	2017		10.1145/3129676.3129715	computer vision;artificial intelligence;gait;biometrics;computer science;gait (human)	Vision	26.502685976773165	-64.18127142361581	187375
eb48077757af9f98ecc89fd9f4866ce4897b5446	an hybrid mlp-svm handwritten digit recognizer	multilayer perceptrons;handwritten digit recognition;learning automata;postal services;pattern classification;postal services handwritten character recognition learning automata multilayer perceptrons pattern classification;ocr zip code digit recognition handwritten digits recognition support vector machines multilayer perceptron pattern classification mail sorting;support vector machine;handwritten character recognition;handwriting recognition character recognition optical character recognition software support vector machines error correction neural networks postal services training data support vector machine classification optical computing	This paper presents an original hybrid MLP-SVM method for unconstrained handwritten digits recognition. Specialized Support Vector Machines (SVMs) are introduced to improve significantly the MLP performances in local areas around the separation surfaces between each pair of digit classes, in the input pattern space. This hybrid architecture is based on the idea that the correct digit class almost systematically belongs to the two maximum MLP outputs and that some pairs of digit classes constitute the majority of MLP substitutions (errors). Specialized local SVMs are introduced to detect the correct class among these two classification hypotheses. The hybrid MLP-SVM recognizer achieves a recognition rate of 98:01%, for real mail zipcode digits recognition task, a performance better than several classifiers reported in recent researches.	best, worst and average case;finite-state machine;mnist database;memory-level parallelism;performance;quad flat no-leads package;sed;sion's minimax theorem;speech recognition;support vector machine	Abdel Bellili;Michel Gilloux;Patrick Gallinari	2001		10.1109/ICDAR.2001.953749	support vector machine;speech recognition;feature;intelligent character recognition;computer science;intelligent word recognition;machine learning;pattern recognition	ML	31.49257567408562	-65.15755946915158	188055
1e4ccb31ad6efdc5199b0b2567f0d64c03472d24	artificial finger detection by spectrum analysis	anti spoofing;spectrum analysis;fingerprint recognition;artificial finger	To prevent fingerprint spoofing attack, a simple, effective and low-cost approach for distinguishing artificial fingers from real ones based on spectrum analysis is presented in this paper. We measured the spectral features of both artificial and real fingers. The results show that near infrared images of fingers are sufficient to distinguish real fingers from artificial ones, while near ultraviolet images can be used to detect the surface details of fingers. We present a practical and simple algorithm based on these features that can successfully distinguish between real and artificial fingers regardless of the race of the test subject.		Shoude Chang;Jeff Secker;Qinghan Xiao;Brittany Reid;Alexander Bergeron;Wahab Almuhtadi	2011	IJBM	10.1504/IJBM.2011.042818	computer vision;spectrum analyzer;speech recognition;computer science;artificial intelligence;computer security;fingerprint recognition	Logic	30.63530859611291	-63.31774972450256	188179
b6c58c884185f531654774e6f170093e56ba0b50	comparing the performance of connectionist and statistical classifiers on an image segmentation problem	image segmentation	"""In the development of an image segmentation system for real time image processing applications, we apply the classical decision analysis paradigm by viewing image segmentation as a pixel classifica.tion task. We use supervised training to derive a classifier for our system from a set of examples of a particular pixel classification problem. In this study, we test the suitability of a connectionist method against two statistical methods, Gaussian maximum likelihood classifier and first, second, and third degree polynomial classifiers, for the solution of a """"real world"""" image segmentation problem taken from combustion research. Classifiers are derived using all three methods, and the performance of all of the classifiers on the training data set as well as on 3 separate entire test images is measured."""	connectionism;cubic function;decision analysis;image processing;image segmentation;pixel;polynomial;programming paradigm;statistical classification;test set	Sheri L. Gish;W. E. Blanz	1989			random subspace method;image texture;computer vision;computer science;machine learning;segmentation-based object categorization;pattern recognition;region growing;image segmentation;scale-space segmentation	ML	30.272667557715845	-65.32767126815156	188293
e2db15cefeddb717fd4f946b829597fb1bfd524e	biometrie identification from raw ecg signal using deep learning techniques		The paper presents and discusses a novel method of biometrie identification based on ECG data. The main idea of the study is to apply Deep Neural Networks (DNN) for human identification based on the raw ECG signal. To improve overall system accuracy various signal pre-processing and outlier detection techniques have been applied. Also, to make ECG identification approach more user friendly, three-finger measurement scheme has been proposed. All experiments have been made using self-collected Lviv Biometric Data Set.	anomaly detection;biometrics;deep learning;experiment;neural network software;preprocessor;usability	Lukasz Wieclaw;Yuriy Khoma;Pawel Falat;Dmytro Sabodashko;Veronika Herasymenko	2017	2017 9th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)	10.1109/IDAACS.2017.8095063	computer vision;anomaly detection;artificial intelligence;artificial neural network;feature extraction;deep learning;computer science;biometrics;data acquisition	Robotics	26.971785924326525	-63.50419082081453	189177
919a87ee1744533e1d38d3970c2b6a930d9a6fcc	robust scheme for iris presentation attack detection using multiscale binarized statistical image features	databases;image segmentation;support vector machines;pad scheme robust scheme iris presentation attack detection iris recognition systems diverse presentation attacks photo print attacks electronic display attack visible spectrum iris artefact database presentation attack detection scheme multiscale binarized statistical image features linear support vector machines iris artefact databases;visual databases iris recognition security of data support vector machines;iris recognition;tablet computers;presentation attacks biometrics iris recognition anti spoofing;feature extraction;iris recognition databases support vector machines image segmentation feature extraction hardware tablet computers;hardware	Vulnerability of iris recognition systems remains a challenge due to diverse presentation attacks that fail to assure the reliability when adopting these systems in real-life scenarios. In this paper, we present an in-depth analysis of presentation attacks on iris recognition systems especially focusing on the photo print attacks and the electronic display (or screen) attack. To this extent, we introduce a new relatively large scale visible spectrum iris artefact database comprised of 3300 iris normal and artefact samples that are captured by simulating five different attacks on iris recognition system. We also propose a novel presentation attack detection (PAD) scheme based on multiscale binarized statistical image features and linear support vector machines. Extensive experiments are carried out on four different publicly available iris artefact databases that have revealed the outstanding performance of the proposed PAD scheme when benchmarked with various well-established state-of-the-art schemes.	algorithm;baseline (configuration management);benchmark (computing);biometrics;database;display resolution;electronic visual display;experiment;iris recognition;real life;simulation;support vector machine;visual artifact	Ramachandra Raghavendra;Christoph Busch	2015	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2015.2400393	support vector machine;computer vision;feature extraction;computer science;machine learning;iris recognition;image segmentation;internet privacy;computer security	Vision	28.07147332787482	-62.719534903768825	190858
c8332fe2154569f9520ae96de5f71ff76e34e688	obtaining cryptographic keys using multi-biometrics		Multi-biometric systems have several advantages over uni-biometrics based systems, such as, better verification accuracy, larger feature space to accom- modate more subjects, and higher security against spoofing. Unfortunately, as in case of uni-biometric systems, multi-biometric systems also face the problems of nonrevocability, lack of template diversity, and possibility of privacy compromise. A combination of biometrics and cryptography is a good solution to eliminate these limitations. In this chapter we present a multi-biometric cryptosystem based on the fuzzy commitment scheme, in which, a crypto-biometric key is derived from multi- biometric data. An idea (recently proposed by the authors) denoted as FeaLingECc (Feature Level Fusion through Weighted Error Correction) is used for the multi- biometric fusion. The FeaLingECc allows fusion of different biometric modalities having different performances (e.g., face + iris). This scheme is adapted for a multi- unit system based on two-irises and a multi-modal system using a combination of iris and face. The difficulty in obtaining the crypto-biometric key locked in the sys- tem (and in turn the reference biometric data) is 189 bits for the two-iris system while 183 bits for the iris-face system using brute force attack. In addition to strong keys, these systems possess revocability and template diversity and protect user pri- vacy.	biometrics;key (cryptography)	Sanjay Ganesh Kanade;Dijana Petrovska-Delacrétaz;Bernadette Dorizzi	2013		10.1007/978-1-4471-5230-9_6	engineering;theoretical computer science;data mining;computer security	Crypto	30.982012382406797	-61.56757856832372	191149
813c93c54c19fd3ef850728e6d4a31d279d26021	emotion identification by facial landmarks dynamics analysis	databases;cohn kanade emotion database emotion identification facial landmarks dynamics analysis person facial landmarks trajectory neutral pose features extraction classification system emotion recognition robust estimation landmark accuracy complex emotion classes;emotion recognition;face recognition;emotion recognition face landmark temporal dynamics;image classification emotion recognition face recognition feature extraction;feature extraction;face databases emotion recognition face recognition feature extraction pain noise;pain;face;noise	In this paper we concentrate our efforts on the analysis of the facial landmarks dynamics as being a relevant method to access the subject's emotion. Given the person's facial landmarks we describe their trajectory with respect to the neutral pose and out of this trajectory we extract relevant features that are subsequently entered into a classification system for the actual recognition of emotion. This procedure provides a robust estimation, that has little sensibility with respect to landmark accuracy. Moreover it brings promising results for complex emotion classes. The approach is extensively tested on the facto emotion database, namely Cohn-Kanade+. The reached performance is comparable with state of the art, but on the complete palette of possible emotions.	algorithm;fiducial marker;palette (computing);vii	Alessandra Bandrabur;Laura Florea;Corneliu Florea;Matei Mancas	2015	2015 IEEE International Conference on Intelligent Computer Communication and Processing (ICCP)	10.1109/ICCP.2015.7312688	psychology;computer vision;speech recognition;three-dimensional face recognition;communication	Robotics	30.532606500249106	-59.26285203731961	191965
937ffb1c303e0595317873eda5ce85b1a17f9943	eyes do not lie: spontaneous versus posed smiles	universiteitsbibliotheek;eyelid movements;naive bayes classifier;automatic detection;spontaneous versus posed smile detection;facial features;facial expression	Automatic detection of spontaneous versus posed facial expressions received a lot of attention in recent years. However, almost all published work in this area use complex facial features or multiple modalities, such as head pose and body movements with facial features. Besides, the results of these studies are not given on public databases. In this paper, we focus on eyelid movements to classify spontaneous versus posed smiles and propose distance-based and angular features for eyelid movements. We assess the reliability of these features with continuous HMM, k-NN and naive Bayes classifiers on two different public datasets. Experimentation shows that our system provides classification rates up to 91 per cent for posed smiles and up to 80 per cent for spontaneous smiles by using only eyelid movements. We additionally compare the discrimination power of movement features from different facial regions for the same task.	angularjs;database;hidden markov model;k-nearest neighbors algorithm;linear discriminant analysis;naive bayes classifier;simplified molecular-input line-entry system;spontaneous order	Hamdi Dibeklioglu;Roberto Valenti;Albert Ali Salah;Theo Gevers	2010		10.1145/1873951.1874056	computer vision;naive bayes classifier;speech recognition;computer science;machine learning;facial expression	Vision	31.183024646790056	-59.49329800982199	192185
3e766d13b6e7ce1b395433e76a2448ba72876a79	fingerprint feature extraction via cnn with von neumann neighborhood	cellular neural networks cnn;feature extraction;cnn gene bank;fingerprint feature extraction;von neumann neighborhood	In this paper, we study fingerprint feature extraction via CNN with Von Neumann neighborhood. The extraction was implemented by using CNN with nine input variables, and we find that the process could also be implemented with only five variables, and an easier algorithm without compromising the effectiveness. According to the CNN model with five input variables and the corresponding CNN gene bank done by Chen et al. [2006, Http1], we can determine the CNN gene easily. Simultaneously, we also find some results in one of the references are incorrect.	algorithm;entity–relationship model;feature extraction;fingerprint;von neumann neighborhood	Yijun Lou;Fangyue Chen;Junbiao Guan	2007	I. J. Bifurcation and Chaos	10.1142/S0218127407019676	speech recognition;feature extraction;computer science;artificial intelligence;algorithm;von neumann neighborhood	NLP	29.76179339438896	-65.32982214060199	194890
d6ecaaf53cbacc62813a2b801d80d569b0b6c03d	improving biometric authentication performance from the user quality	finger knuckle;biometric quality;hand geometry;biometric authentication;biometrics access control;image matching;authentication;biometrics authentication geometry data mining fingers shape iris fingerprint recognition feature extraction rendering computer graphics;biometrics;geometry;palmprint;user quality;data mining;user templates;palmprint extraction;user quality biometrics biometric quality finger knuckle hand geometry palmprint personal authentication;performance improvement;shape;fingerprint recognition;user quality based fusion;feature extraction;fingers;biometric authentication performance;biometric measurement;image matching biometrics access control feature extraction;iris;rendering computer graphics;handshape images;personal authentication;user quality based fusion biometric authentication performance biometric measurement user templates handshape images palmprint extraction	The effectiveness of a biometric measurement and sensing system is directly related to the performance generated from sensed data. This paper investigates a new approach to quantify the quality of sensed data from the user templates. The objective is to incorporate the quality of sensed data to generate a reliable estimate on the matching scores. The proposed method of extracting user quality is based on the confidence of generating reliable matching scores from the user templates. We simultaneously extract the palmprint and hand-shape images from the single hand image and ascertain the performance improvement for the individual trait. The experimental results from the proposed approach are also presented when the biometric measurements from the finger knuckles are employed. The experimental results presented in this paper show significant improvement in performance while incorporating the proposed method of user quality in the matching stages. The proposed user-quality-based fusion of the two biometric modalities also achieves promising improvement in performance.	authentication;biometrics	Ajay Kumar;David Zhang	2010	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2009.2028773	computer vision;computer science;engineering;internet privacy;computer security;biometrics	EDA	31.109618375914774	-62.157579068892524	195308
054c5804b8904a67eb9951a06a37efcec2298fc1	recognizing surgically altered face images using multiobjective evolutionary algorithm	granular computing;granular computing face recognition plastic surgery genetic algorithm;image matching;face recognition;feature extractor surgically altered face image recognition biometrics person authentication facial appearance automatic face recognition nonlinear variations plastic surgery multiobjective evolutionary granular algorithm face image matching nondisjoint face granules multiobjective genetic approach;feature extraction;medical image processing;surgery;genetic algorithms;surgery face recognition feature extraction genetic algorithms granular computing image matching medical image processing;face feature extraction surgery face recognition biological cells data mining facial features	Widespread acceptability and use of biometrics for person authentication has instigated several techniques for evading identification. One such technique is altering facial appearance using surgical procedures that has raised a challenge for face recognition algorithms. Increasing popularity of plastic surgery and its effect on automatic face recognition has attracted attention from the research community. However, the nonlinear variations introduced by plastic surgery remain difficult to be modeled by existing face recognition systems. In this research, a multiobjective evolutionary granular algorithm is proposed to match face images before and after plastic surgery. The algorithm first generates non-disjoint face granules at multiple levels of granularity. The granular information is assimilated using a multiobjective genetic approach that simultaneously optimizes the selection of feature extractor for each face granule along with the weights of individual granules. On the plastic surgery face database, the proposed algorithm yields high identification accuracy as compared to existing algorithms and a commercial face recognition system.	authentication;biometrics;evolutionary algorithm;experiment;facial recognition system;feature selection;gaussian blur;genetic algorithm;granule (oracle dbms);laplacian matrix;mathematical optimization;mind;nonlinear system;randomness extractor;scale-invariant feature transform;self-information	Himanshu S. Bhatt;Samarth Bharadwaj;Richa Singh;Mayank Vatsa	2013	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2012.2223684	computer vision;face detection;genetic algorithm;granular computing;feature extraction;computer science;machine learning;pattern recognition;three-dimensional face recognition	Vision	30.187209173494136	-61.57018791477541	195980
2cf92ee60f719098acc3aae3981cedc47fa726b3	statistical performance evaluation of biometric authentication systems using random effects models	databases;bayes estimation;modelizacion;evaluation performance;interfase usuario;predictive distribution;base donnee;analisis estadistico;performance evaluation;biometrics authentication databases error analysis fingerprint recognition airports statistical analysis predictive models testing bayesian methods;estimacion densidad;asymmetry;biometric authentication;variable aleatoire;random effects;biometrics access control;user interface;bayes methods;biometrie;analisis forma;estimation densite;evaluacion prestacion;airports;bayesian inference;authentication;biometrics;database;biometria;variable aleatoria;base dato;bayesian methods;false alarm rate;statistical method;testing;intelligence artificielle;probabilistic approach;asymetrie;indexing terms;authentification;modelisation;error analysis;density estimation;facial asymmetry statistical performance evaluation biometric authentication systems hierarchical random effects models bayesian inference techniques posterior predictive distributions error rates false alarm probability face authentication systems filter based system gaussian mixture model based system frequency domain representation;estimacion bayes;statistical distributions;gaussian mixture model;statistical distributions bayes methods biometrics access control error statistics face recognition statistical analysis;autenticacion;watch list;watch list biometrics face authentication performance evaluation random effects model;face recognition;posterior distribution;statistical analysis;methode domaine frequence;fingerprint recognition;frequency domain method;enfoque probabilista;approche probabiliste;analyse statistique;random variable;ley a posteriori;error rate;asimetria;error statistics;artificial intelligence;interface utilisateur;predictive models;face;pattern analysis;random effects model;inteligencia artificial;information system;metodo dominio frecuencia;frequency domain	"""As biometric authentication systems become more prevalent, it is becoming increasingly important to evaluate their performance. This paper introduces a novel statistical method of performance evaluation for these systems. Given a database of authentication results from an existing system, the method uses a hierarchical random effects model, along with Bayesian inference techniques yielding posterior predictive distributions, to predict performance in terms of error rates using various explanatory variables. By incorporating explanatory variables as well as random effects, the method allows for prediction of error rates when the authentication system is applied to potentially larger and/or different groups of subjects than those originally documented in the database. We also extend the model to allow for prediction of the probability of a false alarm on a """"watch-list"""" as a function of the list size. We consider application of our methodology to three different face authentication systems: a filter-based system, a Gaussian mixture model (GMM)-based system, and a system based on frequency domain representation of facial asymmetry"""	authentication;biometrics;chamaecyparis lawsoniana;document completion status - documented;facial symmetry;inference;large;mixture model;normal statistical distribution;performance evaluation;random effects model;explanation	Sinjini Mitra;Marios Savvides;Anthony Brockwell	2007	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2007.1000	facial recognition system;computer science;machine learning;pattern recognition;data mining;authentication;biometrics;statistics;random effects model	Vision	28.462197320554647	-63.9179046899655	196651
74af2a5755160b7f8738013f9bb615afa5c35dfe	fingerprinting classification using fuzzy cerebellar model arithmetic computer neural networks	neural networks;feature vector;pattern classification;computing systems;neural network	We present some preliminary study results of an auto- mated fingerprint pattern classification approach based on a novel neural network structure called the fuzzy cerebellar model arithmetic computer (CMAC) neural network. The fingerprint images are first preprocessed to generate ridge flow, then the Karhunen-Loever (K-L) transform is used to extract the features from the ridge-flow images. The feature vector is then sent to a fuzzy CMAC neural network for classification. Excellent results were obtained through our preliminary experiments on the ''two classes'' problem. © 1997 SPIE and IS&T. (S1017-9909(97)00203-1)		Zheng J. Geng;Weicheng Shen	1997	J. Electronic Imaging	10.1117/12.269896	feature vector;computer science;artificial intelligence;neuro-fuzzy;machine learning;pattern recognition;time delay neural network;artificial neural network	ML	29.717744995628163	-65.47853291819389	197156
7fa52bb4f46a5ab661c11285ab2274c850e11e4f	towards a better understanding of the performance of latent fingerprint recognition in realistic forensic conditions	databases;manuals;fingerprint impressions latent fingerprint recognition realistic forensic conditions minutiae extraction;latent fingerprint recognition;forensic science fingerprint identification;image matching;biometrics;biometrics latent fingerprints feature extraction afis forensic identification;forensic identification;forensic science;conferenceobject;fingerprint recognition;minutiae extraction;feature extraction;fingerprint recognition feature extraction forensics databases manuals image matching fingers;fingers;latent fingerprints;afis;realistic forensic conditions;fingerprint impressions;high performance;bookpart;fingerprint identification;forensics	— This work studies the performance of a state-of-the-art fingerprint recognition technology, in several practical scenarios of interest in forensic casework. First, the differences in performance between manual and automatic minutiae extraction for latent fingerprints are presented. Then, automatic minutiae extraction is analyzed using three different types of fingerprints: latent, rolled and plain. The experiments are carried out using a database of latent finger marks and fingerprint impressions from real forensic cases. The results show high performance degradation in automatic minutiae extraction compared to manual extraction by human experts. Moreover, high degradation in performance on latent finger marks can be observed in comparison to fingerprint impressions.	acoustic fingerprint;database;elegant degradation;experiment;fingerprint recognition;information extraction;minutiae	Maria Puertas;Daniel Ramos-Castro;Julian Fiérrez;Javier Ortega-Garcia;Nicomedes Exposito	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.405	fingerprint;computer vision;speech recognition;feature extraction;computer science;internet privacy;forensic science;fingerprint recognition;biometrics	Vision	31.387096074448007	-63.31501816912439	197895
72345fed8d068229e50f9ea694c4babfd23244a0	comparative study: face recognition via the correlation filter technique	object recognition;conference;correlation filters;performance comparison;face recognition;internet;experiments	Face recognition attracts much attention in various applications due to its non-intrusive nature and the widespread availability of digital cameras. Recently, the benefits of using spatial frequency domain representations for face recognition have drawn great interests from the computer vision and pattern recognition community. In this paper, we present a comparative study by using the correlation filter (CF) technique in the application of face recognition. We overview some representative correlation filters (CFs) proposed recently and analyze their respective pros and cons. Experiments using different types of CFs with different training parameters are conducted on public face databases to investigate the overall performance of the CF-based face recognition methods. The observations based on these experiments are expected to provide widely applicable guidelines for designing the face recognition systems via the CF technique.	computer vision;database;digital camera;experiment;facial recognition system;pattern recognition	Riwei Chen;Yan Yan;Min Liu;Hanzi Wang	2014		10.1145/2632856.2632937	psychology;computer vision;speech recognition;three-dimensional face recognition;communication	Vision	28.307145301723978	-61.427350103517405	198592
37e1c2b7ae2690ebdfd69b2477fd8541297011a4	a new database of confusing characters for testing character recognition algorithms	databases;classification mechanisms;image classification handwritten character recognition optical character recognition visual databases;software tool;classification algorithm;algorithm testing;handwriting recognition;optical character recognition;automatic testing;performance;image database;image classification;mechanical factors;open database;confusing character generation;character generation;classification algorithms;human recognition processes image database algorithm testing software tool confusing character generation human knowledge open database automatic character recognisers performance handwritten character recognition human learning classification mechanisms;human recognition processes;software tools;humans;databases humans character recognition handwriting recognition software tools character generation automatic testing algorithm design and analysis classification algorithms mechanical factors;human learning;character recognition;automatic character recognisers;algorithm design and analysis;handwritten character recognition;human knowledge;visual databases	In this paper a new technique and software tool for the generation of systematically organised confusing characters is presented; by means of this tool it is possible to transfer human knowledge on character recognition into an open database in a systematic way. This base is useful to test automatic character recognisers by comparing their performance to human unchallenged ability in recognising handwritten characters. This base can be used also to accomplish experiments in the field of confusing character recognition, where the comparison with human knowledge is necessary. In fact the need to increase knowledge on human learning and classification mechanisms has been underlined, in order to design new and more efficient classification algorithms consistent with human recognition processes, also by studying the properties of confusing characters.		Vincenzo Di Lecce;Andrea Guerriero;Giovanni Dimauro;Sebastiano Impedovo;Giuseppe Pirlo;A. Salzo	1999		10.1109/ICIAP.1999.797716	algorithm design;computer vision;contextual image classification;speech recognition;performance;computer science;machine learning;pattern recognition;handwriting recognition;knowledge;optical character recognition	DB	31.70867448560901	-66.07395629387706	198685
6b0671d73433c7dff4ffff98a867145718128752	a novel multi-stage classifier for face recognition	olivetti research laboratory;random sampling;ransac;face recognition;minimum distance;decision process;svm;support vector machine;eigenface	A novel face recognition scheme based on multi-stages classifier, which includes methods of support vector machine (SVM), Eigenface, and random sample consensus (RANSAC), is proposed in this paper. The whole decision process is conducted cascade coarse-to-fine stages. The first stage adopts one-against-one-SVM (OAO-SVM) method to choose two possible classes best similar to the testing image. In the second stage, “Eigenface” method was employed to select one prototype image with the minimum distance to the testing image in each of the two classes chosen. Finally, the real class is determined by comparing the geometric similarity, as done by “RANSAC” method, between these prototype images and the testing images. This multi-stage face recognition system has been tested on Olivetti Research Laboratory (ORL) face databases, and its experimental results give evidence that the proposed approach outperforms the other approaches either based on the single classifier or multi-parallel classifier, it can even obtain a nearly 100 percent recognition accuracy.	database;eigenface;facial recognition system;oddworld: abe's oddysee;prototype;random sample consensus;return loss;support vector machine	Chen-Hui Kuo;Jiann-Der Lee;Tung-Jung Chan	2007		10.1007/978-3-540-76390-1_62	facial recognition system;support vector machine;computer vision;computer science;machine learning;pattern recognition	Vision	28.381673006578232	-59.134634399921765	199077
d8231e5000d764831d775a62eda49311a1e36173	behavioural pattern identification in a smart home using binary similarity and dissimilarity measures	binary similarity;disabled people;abnormal human behavioural patterns;door;frequent human behavioural patterns;smart home;sensors;elderly;fuzzy hamming distance;dissimilarity index;binary similarity measures;abnormal data;handicapped aids;hamming distance;vectors;monitoring;hamming distance intelligent sensors smart homes vectors educational institutions monitoring;dissimilarity measures;distance measures;abnormal data behavioural pattern identification smart home binary similarity measures dissimilarity measures frequent human behavioural patterns abnormal human behavioural patterns elderly disabled people pattern recognition tasks character recognition image retrieval binary similarity index dissimilarity index occupancy sensors door motion sensors distance measures unexpected data;pattern classification;unexpected data;behavioural sciences;abnormal behaviour detection;institutional repository research archive oaister;motion sensors;character recognition;intelligent sensors;sensors behavioural sciences handicapped aids home automation pattern classification;fuzzy hamming distance intelligent environemnt abnormal behaviour detection binary similarity dissimilarity measures;intelligent environemnt;smart homes;home automation;behavioural pattern identification;binary similarity index;occupancy sensors;pattern recognition tasks;image retrieval	The aim of this paper is to examine the suitability of binary similarity and dissimilarity measures in identifying frequent and abnormal human behavioural patterns in a smart home. There has been an increasing interest in this subject to help the elderly and disabled people to live alone in their own homes with little help and support from their carer. Similarity and dissimilarity measures have been applied for a wide range of pattern recognition tasks such as character recognition, image retrieval, etc. In this work, the binary similarity and dissimilarity indices are used on data generated from occupancy sensors including door and motion sensors in a smart home. These sensors indicate the presence and absence of the occupant in a specific area in the home. Many measures are introduced in the literature, the focus in this paper is on the measures that give credits to both the positive matches and the mismatching between two sensor values. This paper first gives an overview of the similarity measures to find the most common patterns and then dissimilarity or distance measures are used to identify unexpected or abnormal data. Data from two different case studies are used to validate the accuracy of these measurements.	behavioral pattern;bitstream;cluster analysis;experiment;futures studies;hamming distance;home automation;image retrieval;intelligent environment;optical character recognition;pattern recognition;sensor;statistical classification;window function	Sawsan M. Mahmoud;Ahmad Lotfi;Caroline S. Langensiepen	2011	2011 Seventh International Conference on Intelligent Environments	10.1109/IE.2011.53	engineering;machine learning;pattern recognition;data mining	HCI	27.44882553283535	-59.978144737612745	199347
