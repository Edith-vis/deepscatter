id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
46f71798e5e2534efbbaeb7e8366b4d21b73003b	semantic layering with magpie	smart browsing.;algorithms keywords semantic web;semantic services;ontology;semantic web;information retrieval;web pages	Browsing the web involves two main tasks: finding the right web page and then making sense of its content. A significant amount of research has gone into supporting the task of finding web resources through ‘standard’ information retrieval mechanisms, or semantics-enhanced search. Much less attention has been paid to the second problem. In this paper we describe Magpie, a tool which supports the interpretation of web pages. Magpie acts as a complementary knowledge source, which a reader can call upon to quickly gain access to any background knowledge relevant to a web resource. Magpie works by automatically associating an ontology based semantic layer to web resources, allowing relevant services to be directly invoked within a standard web browser. The functionality of Magpie is illustrated using examples of how it has been integrated with our lab’s web resources.	browsing;information retrieval;web page;web resource	John Domingue;Martin Dzbor;Enrico Motta	2004			semantic computing;semantic web rule language;data web;semantic search;semantic grid;web standards;computer science;semantic web;social semantic web;web page;semantic web stack;multimedia;web intelligence;semantic technology;world wide web;website parse template;information retrieval;semantic analytics	Web+IR	-41.17717192054957	8.198992868915616	158852
3c4cc5f69c6a58b158697be62cc336ffed399b2f	exploratory search upon semantically described web data sources		Exploratory search applications upon structured Web content is becoming one of the main information seeking paradigms for users. This is mainly due to the move towards mobile and pervasive Web access and to the more and more tight intertwining between everyday life and information seeking. Structured data is typically distributed on the Web and accessible through a service-oriented paradigm. This paper proposes a vision on: (1) a semantically-enabled service registration framework for describing in a Web data services in a convenient way; and (2) a design method for applications that exploit such model using a design pattern--based method.	exploratory search;information seeking;internet access;pervasive informatics;programming paradigm;semiconductor consolidation;service-orientation;service-oriented device architecture;software design pattern;user experience;web content;web data services;world wide web	Marco Brambilla	2012		10.1145/2494068.2494071	web service;web application security;web development;web modeling;data web;web analytics;web mapping;web design;web accessibility initiative;web standards;computer science;ws-policy;web navigation;social semantic web;data mining;multimedia;web intelligence;web engineering;web 2.0;world wide web;mashup	Web+IR	-43.54467403851027	11.035209679240175	159685
25d6d2bd02fda613cc39224513902c0e8626b3d5	a transport service ontology-based focused crawler	web pages transport service ontology focused crawler domain knowledge nonrelevant metadata filtering;web sites information filtering ontologies artificial intelligence;semantic crawler;transport service;web pages;focused crawler;information retrieval;information filtering;data mining;conceptual framework;ontologies artificial intelligence;computing and communication sciences;domain knowledge;conference paper;indexes;agent technology and semantic search;the australian standard research classification 280000 information;agent technology and semantic search ontology semantic crawler;transport service ontology;web sites;agent technology;ontologies crawlers semantic web web sites machine intelligence joining processes web services web and internet services resource management space technology;joining processes;semantic web;crawlers;ontologies;semantic search;ontology;nonrelevant metadata filtering	Ontology is a technology for conceptualizing specific domain knowledge, which can provide machine-readable definitions to the severed domain. Therefore, ontology can be utilized to enhance the performance of focused crawlers, by precisely defining the crawling boundary. In this paper, we will exhibit a conceptual framework of an ontology-based focused crawler serving in the domain of transport services. Here, a transport service ontology is designed for filtering non-relevant metadata, by means of logically linking the metadata with ontological concepts. In addition, we will provide the evaluation process in order to assess the power of ontology in the focused crawler. Conclusion and further works based on our current evaluation results will be made in the final section.	focused crawler;human-readable medium;web crawler	Hai Dong;Farookh Khadeer Hussain;Elizabeth Chang	2008	2008 Fourth International Conference on Semantics, Knowledge and Grid	10.1109/SKG.2008.56	upper ontology;database index;bibliographic ontology;semantic search;computer science;ontology;artificial intelligence;semantic web;ontology;web page;conceptual framework;database;focused crawler;ontology-based data integration;world wide web;information retrieval;process ontology;domain knowledge;suggested upper merged ontology	HPC	-42.18814027644731	7.58818363715294	160006
f93858ac9adeeeb23930b6f732355e6b319701e5	an orchestration framework for linguistic task ontologies		Ontologies provide knowledge representation formalism for expressing linguistic knowledge for computational tasks. However, natural language is complex and fluid, demanding fine-grained ontologies tailored to facilitate solving specific problems. Moreover, extant linguistic ontological resources ignore mechanisms for systematic modularisation to ensure semantic interoperability with task ontologies. We present an orchestration framework to organise and control the inheritance of ontological elements in the development of linguistic task ontologies. The framework is illustrated in the design of new task ontologies for Bantu noun classification system. Specific use is demonstrated with annotation of lexical items connected to ontology elements terms, and with the classification of nouns in the ABox into noun classes.	abox;knowledge representation and reasoning;natural language;ontology (information science);semantic interoperability;semantics (computer science);statistical classification	Catherine Chavula;C. Maria Keet	2015		10.1007/978-3-319-24129-6_1	natural language processing;computer science;database;linguistics	AI	-43.35157197022637	7.945208322210203	160026
5bc66f23ae0b581dc06e4508add176eafb76e6ae	a framework for applying the concept of significant properties to datasets	information science;significant properties;conceptual foundations;digital preservation;preservation models;data curation;ontology;dataset	The concept of signi cant properties, properties that must be identified and preserved in any successful digital object preservation, is now common in data curation. Although this notion has clearly demonstrated its usefulness in cultural heritage domains its application to the preservation of scientific datasets is not as well developed. One obstacle to this application is that the familiar preservation models are not sufficiently explicit to identify the relevant entities, properties, and relationships involved in dataset preservation. We present a logic-based formal framework of dataset concepts that provides the levels of abstraction necessary to identify and correctly assign significant properties to their appropriate entities. A unique feature of this model is that it recognizes that a typed symbol structure is a unique requirement for datasets, but not for other information objects.	case preservation;data curation;digital curation;entity;principle of abstraction;virtual artifact	Simone Sacchi;Karen M. Wickett;Allen H. Renear;David Dubin	2011		10.1002/meet.2011.14504801148	data curation;information science;computer science;ontology;data mining;database;information retrieval;data set	AI	-45.181442408783475	6.608246405411731	160902
9011d2275da5075e986bb361b86d2784198f54bf	process-oriented information logistics: aligning enterprise information with business processes	process oriented information logistics;drugs;logistics data processing;semantics;master and phd thesis;poil process oriented information logistics enterprise information business processes knowledge workers enterprise content management systems shared drives intranet portals organizing information management technology;logistics;logistics data processing business data processing enterprise resource planning;silicon compounds;business data processing;information management;enterprise resource planning;business process management;drugs context silicon compounds semantics logistics;context;business process management process oriented information logistics information management	Today, enterprises are confronted with a continuously increasing amount of data. Examples of such data include office files, e-mails, process descriptions, and data from process-aware information systems. This data overload makes it difficult for knowledge-workers to identify the information they need to perform their tasks in the best possible way. Particularly challenging is the alignment of process-related information with business processes. In fact, process-related information and business processes are usually managed separately. On the one hand, enterprise content management systems, shared drives, and Intranet portals are used for organizing information, on the other hand, process management technology is used to design and enact business processes. With process-oriented information logistics (POIL) this paper presents an approach for bridging this gap. POIL enables the process-oriented and context-aware delivery of process-related information to knowledge-workers. We also present a clinical use case and a proof-of-concept prototype to demonstrate the application and benefits of POIL.	bridging (networking);business process;content management system;email;enterprise content management;information logistics;information system;intranet portal;microsoft outlook for mac;organizing (structure);portals;process management (computing);prototype;scalability	Bernd Michelberger;Bela Mutschler;Manfred Reichert	2012	2012 IEEE 16th International Enterprise Distributed Object Computing Conference	10.1109/EDOC.2012.13	logistics;information technology management;information engineering;computer science;systems engineering;knowledge management;artifact-centric business process model;business process management;database;semantics;process management;information management;information system;enterprise information system	DB	-48.242232734878016	9.220452942180662	161410
ec5f3dd2094f24d369964ce7fce594cd4b780d67	use cases for linked data visualization model		There is a vast amount of Linked Data on the web spread across a large number of datasets. One of the visions behind Linked Data is that the published data is conveniently reusable by others. This, however, depends on many details such as conformance of the data with commonly used vocabularies and adherence to best practices for data modeling. Therefore, when an expert wants to reuse existing datasets, he still needs to analyze them to discover how the data is modeled and what it actually contains. This may include analysis of what entities are there, how are they linked to other entities, which properties from which vocabularies are used, etc. What is missing is a convenient and fast way of seeing what could be usable in the chosen unknown dataset without reading through its RDF serialization. In this paper we describe use cases based on this problem and their realization using our Linked Data Visualization Model (LDVM) and its new implementation. LDVM is a formal base that exploits the Linked Data principles to ensure interoperability and compatibility of compliant analytic and visualization components. We demonstrate the use cases on examples from the Czech Linked Open Data cloud.	best practice;conformance testing;data modeling;data visualization;distributed computing;entity;interoperability;linked data;load balancing (computing);population;requirement;resource description framework;sparql;serialization;tag cloud;transformers;usability;user requirements document;vocabulary;web service	Jakub Klímek;Jirí Helmich;Martin Necaský	2015			computer science;linked data;data mining;database;world wide web	Web+IR	-41.49768214096283	10.783733759092636	161420
ac10a0609d47fd183acff5a94ef300685f8ccefe	an integrated framework for securing semi-structured health records	role based access control;electronic health record;policy language;information structuring;ontology	"""In the last years, the adoption of Electronic Health Records (EHRs) have been widely promoted, with the final aim of improving care quality and patient safety. Yet, sharing patient data in a large distributed and heterogeneous context, such as the healthcare domain, has inherently introduced security and privacy risks, due to the great sensitivity and confidentiality of the patient data and the need of accessing such data by a large number of health care workers with various roles for the patient care. Even though various techniques have been developed to effectively implement fine-grained access control, which allows flexibility in specifying differential access rights of individual users, some unsolved problems can be pointed out with respect to the specification of complex policies over EHRs: (i) the difficulty of forcing narrative text to assume a semi-structured coded form into EHRs in order to build access control policies also working at a section-level; (ii) an overly high-level of theoretical ability required to practically use access control models and policy languages as a whole, due to a scarce integration among them; and (iii) the lack of tools for easily editing and upgrading access control policies over EHRs. In order to face all these open issues, this paper proposes a hybrid framework aimed at enabling and supporting the definition of fine-grained access control policies working on semi-structured EHRs. The key issues of the framework are: (i) a semantic-based method that hybridizes linguistic and statistical techniques in order to give a semi-structured form to a narrative text to be inserted into EHRs, by identifying its specific sections; (ii) a formal role-based authorization model, encoded as a couple of ontologies, to regulate the access to these semi-structured EHRs with respect to their sections; and (iii) a procedural policy language and a set of patterns to simply encode and update access control restrictions in the form of """"if-then rules"""" built on the top of the ontological model formalized. A prototype implementation of this framework is realized in the form of a system offering simple and intuitive interfaces to the security administrators. Finally, an experimental evaluation over real documents contained into EHRs, i.e. discharge summaries, is described, showing the feasibility of the proposed framework and suggesting that its application could simply and proficiently secure the access to healthcare information contained into semi-structured EHRs and, thus, face security and privacy risks in real healthcare scenarios."""		Flora Amato;Giuseppe De Pietro;Massimo Esposito;Nicola Mazzocca	2015	Knowl.-Based Syst.	10.1016/j.knosys.2015.02.004	computer science;knowledge management;artificial intelligence;ontology;role-based access control;data mining;computer security	ML	-47.93061168881627	4.729338889278937	161980
414b7e3ba54950986d76245efbd787a5f9ede4fd	callimachusdl: using semantics to enhance search and retrieval in a digital library	search and retrieval;digital library;faceted search;semantic web;ontologies	Among the challenges of classifying, locating and accessing knowledge in Digital Libraries tackling with the huge amount of resources the Web provides, improving Digital Libraries by means of different strategies, particularly, using semantics remains a promising and interesting approach. In this paper, we present CallimachusDL, a semantics-based Digital Library which provides faceted search, enhanced access possibilities and a proof-of-concept	data structure;database;digital library;faceted classification;image scaling;librarian;library (computing);pinakes;social network;web 2.0;world wide web	Juan Miguel Gómez-Berbís;Ricardo Colomo Palacios;Ángel García-Crespo	2008		10.1007/978-3-540-87781-3_58	digital library;semantic search;computer science;ontology;artificial intelligence;semantic web;data mining;world wide web;information retrieval	Web+IR	-41.17473011861903	6.972934318073915	162311
6cee4df103cadb733d8ec9eb6e9391022146f4cb	ferari: a prototype for complex event processing over streaming multi-cloud platforms	multi cloud platforms	In this demo, we present FERARI, a prototype that enables real-time Complex Event Processing (CEP) for large volume event data streams over distributed topologies. Our prototype constitutes, to our knowledge, the first complete, multi-cloud based end-to-end CEP solution incorporating: a) a user-friendly, web-based query authoring tool, (b) a powerful CEP engine implemented on top of a streaming cloud platform, (c) a CEP optimizer that chooses the best query execution plan with respect to low latency and/or reduced inter-cloud communication burden, and (d) a query analytics dashboard encompassing graph and map visualization tools to provide a holistic picture with respect to the detected complex events to final stakeholders. As a proof-of-concept, we apply FERARI to enable mobile fraud detection over real, properly anonymized, telecommunication data from T-Hrvatski Telekom network in Croatia.	cloud computing;complex event processing;emoticon;end-to-end principle;holism;mathematical optimization;prototype;query plan;real-time clock;usability;web application	Ioannis Flouris;Vasiliki Manikaki;Nikos Giatrakos;Antonios Deligiannakis;Minos N. Garofalakis;Michael Mock;Sebastian Bothe;Inna Skarbovsky;Fabiana Fournier;Marko Stajcer;Tomislav Krizan;Jonathan Yom-Tov;Taji Curin	2016		10.1145/2882903.2899395	real-time computing;computer science;database;world wide web	DB	-48.12475166494479	10.685916364296865	162504
f7c2c6ab82bfa31017bdde807251e0760450a64e	a multi-agent model for handling e-commerce activities	information management customer profiles;retail data processing;electronic commerce;retail data processing electronic commerce multi agent systems;agent modeling;e commerce;conceptual model;multi agent systems;network model;interest matching multi agent model e commerce activity handling customer profile handling b sdr network	In this paper we propose a multi-agent model for handling e-commerce activities. In our model, an agent is present in each e-commerce site, managing the information stor ed ther ein. In addition, another a gent is associated with each customer, handling her/his pro le . The pr oposed model is based on the exploitation of a particular conceptual model, called B-SDR network, capable of representing and handling both information stored in e-commerce sites and customer pro les. The capabilities of the B-SDR network model are exploited to let customer and site agents to cooperate in such a way to support a customer to detect, whenever she/he accesses an e-commerce site , those products and services present in the site itself and better matching her/his interests.	association rule learning;e-commerce;etsi satellite digital radio;information source;multi-agent system;network model;paintshop pro;prototype;xml	Domenico Rosaci;Giuseppe M. L. Sarnè;Domenico Ursino	2002		10.1109/IDEAS.2002.1029673	e-commerce;customer to customer;computer science;conceptual model;network model;customer intelligence	AI	-48.2490927066991	9.57181387143736	162646
598a6d1dd932162f7ee3c7950cca3be4454016d9	ontology-based semantic infrastructure for service interoperability		In this paper, we provide a general overview of our recent research contributions, with focus on the proposed approach for building service ontologies to serve as an interoperability semantic infrastructure in web information systems.	information system;interoperability;ontology (information science)	Devis Bianchini;Valeria De Antonellis;Michele Melchiori	2004			systems engineering;semantic interoperability;social semantic web;ontology inference layer;computer science;interoperability;semantic web stack;upper ontology;ws-i basic profile;cross-domain interoperability	Web+IR	-43.58029817077282	8.894995756649417	163101
cf3073415aedf21d42ecee175435bbb2eada7ec1	semantic interrelation of documents via an ontology	talk	This paper describes how to use an ontology for extensive semantic interrelation of documents in order to achieve sustainable development, i.e. continuous long-term usability of the contents. The ontology is structured via packages (corresponding to whole documents). Packages are related by import such that semantic interrelation becomes possible not only within a document but also between different documents. Coherence and consistency are enhanced by change management in a repository, including version control and configuration management. Semantic interrelation is realized by particular L TEX commands for the declaration and definition of classes, objects and relations, and references to them, such that they can be used in standard L TEX documents, in particular, with a new L TEX style for educational material (slides, handouts, annotated courses, assignments, and so on).	configuration management;declaration (computer programming);ontology (information science);open-source software;usability;version control	Bernd Krieg-Brückner;Arne Lindow;Christoph Lüth;Achim Mahnke;George Russell	2004			upper ontology;bibliographic ontology;ontology inference layer;ontology;ontology-based data integration	AI	-42.15679061850637	5.386500222099825	163252
5c9883c331db4564ebb6c74a5d28bc5275474978	semantic service matchmaking for digital health ecosystems	european commission;health service ontology;search engine;service evaluation and ranking;digital ecosystems;functional testing;ecosystem health;journal article;domain knowledge;large scale;information and communication technology;quality evaluation;small and medium enterprise;semantic service matchmaking;semantic search;health services;digital health ecosystems;sustainable development;health service metadata	The vision of Digital Ecosystems was initiated by the European Commission, with the purpose of constructing an information and communication technology environment to facilitate the sustainable development of small and medium enterprises. As a key subdomain of Digital Ecosystems, Digital Health Ecosystems provide crucial services to maintain the health of the main participants of Digital Ecosystems. We are concerned with the large-scale, ambiguous, heterogeneous, and untrustworthy health service information in Digital Health Ecosystems. An intensive survey found that current research cannot support accurate and trustworthy matchmaking between health service requests and health service advertisements in Digital Health Ecosystems. Therefore, in this paper, we propose a framework of a semantic service matchmaker, by taking into account the ambiguous, heterogeneous nature of service information in Digital Health Ecosystems. This framework is designed to make four major contributions, which are health service domain knowledge modeling, online health service information disambiguation, health service query disambiguation and health service quality evaluation and ranking. In order to thoroughly evaluate this framework, we implement a prototype – a Semantic Health Service Search Engine, and execute a series of experiments on the prototype using a functional testing and simulation approach.	algorithm;ambiguous grammar;ecosystem;experiment;focused crawler;functional testing;knowledge modeling;machine learning;prototype;quality of service;simulation;trust (emotion);web crawler;web design;web search engine;word-sense disambiguation	Hai Dong;Farookh Khadeer Hussain	2011	Knowl.-Based Syst.	10.1016/j.knosys.2011.02.005	ecosystem health;information and communications technology;semantic search;computer science;knowledge management;artificial intelligence;service delivery framework;service design;functional testing;data mining;world wide web;sustainable development;domain knowledge;search engine	HCI	-44.690358971666015	10.445621222506077	163454
40842ff12e2586cd7d86fec58b457695c83a1cbd	local ontologies for semantic interoperability in supply chain networks		Most of the issues of current supply chain management practices are related to the challenges of interoperability of relevant enterprise information systems (EIS). In this paper, we present the ontological framework for semantic interoperability of EISs in supply chain networks, based on Supply Chain Operations Reference (SCOR) model, its semantic enrichment and mappings with relevant enterprise conceptualizations. In order to introduce the realities of the enterprises into this framework, namely their models, we define and implement the approach to generation of local ontologies, based on the databases of their EISs. Also, we discuss on the translation between semantic and SQL queries, a process in which implicit semantics of the EIS’s databases and explicit semantics of the local ontologies become inter-related.	business logic;data model;database;database schema;enterprise information system;entity;entity–relationship model;erdős–rényi model;gene ontology term enrichment;hard coding;modular design;ontology (information science);ontology alignment;principle of abstraction;reference model;semantic integration;semantic interoperability;supply chain network;usability;virtual enterprise;web ontology language	Milan Zdravkovic;Miroslav Trajanovic;Hervé Panetto	2011			semantic interoperability	AI	-43.92461043984723	8.699973401343602	163709
1690c66a00037099aa8660f37d123d1cbe66642c	an ontological support for interactions with experience in designing the software intensive systems	precedent;automated designing;ontology;question answering;software intensive system	"""Nowadays, experience bases are widely used by project companies in designing the software intensive systems SIS. The efficiency of such informational sources is defined by """"nature"""" of modeled experience units and approaches that apply to their systematization. An orientation on a precedent model as a basic type of experience units and an ontological approach to their systematization are defined the specificity of the study described in this paper. Models of precedents are constructed in accordance with the normative schema when the occupational work is fulfilled by a team of designers. In creating the necessary ontology, the team should use a reflection of solved tasks on a specialized memory intended for simulating the applied reasoning of the question-answer type. The used realization of the approach facilitates increasing the efficiency of designing the SIS."""	interaction	Petr Sosnin	2015		10.1007/978-3-319-21410-8_30	question answering;computer science;knowledge management;artificial intelligence;common law;ontology;database;algorithm	SE	-46.78960449096138	6.321510520259065	163964
83160568827018d1b7acf47bf6181ff1e6eefb81	an ontology analysis tool	e commerce;protege plug in;information content;content analysis;ontology evaluation;empirical validation;semantic web;development methodology;tool evaluation;domain ontology;ontology re use;structure analysis	The success of the Semantic Web has been linked with the use of ontologies on the Semantic Web. Given the important role of ontologies on the Semantic Web, the need for domain ontology development and management are becoming more and more important to most kinds of knowledge-driven applications. Numerous proposed approaches to evaluating an ontology depend on the purpose of evaluation. Some tools evaluate ontologies for correctness, completeness and redundancy so that applications do not use poorly or incorrectly formulated ontologies; others have developed methodologies to ensure the consistency and completeness of an ontology throughout its entire lifetime. Recent proposals by researchers also suggest the importance of tools to help analyze ontologies for re-use by consumers. The scarcity of theoretically and empirically validated measures for consumer analysis of ontologies has motivated our research to develop an ontological analysis tool that can be used on both intensional and extensional ontologies...		Valerie V. Cross;Anindita Pal	2008	Int. J. General Systems	10.1080/03081070701499997	upper ontology;idef5;open biomedical ontologies;ontology alignment;ontology components;bibliographic ontology;self-information;content analysis;ontology inference layer;computer science;knowledge management;ontology;semantic web;data mining;semantic web stack;structural analysis;ontology-based data integration;web ontology language;owl-s;information retrieval;process ontology;semantic analytics;statistics;suggested upper merged ontology	Logic	-44.51001624140088	6.911047461452791	164309
3fde00d25b2fd02187c2020be323473a6d71cdef	infrastructures from the bottom-up and the top-down: can they meet in the middle?	text;bottom up;end user computing;top down;research collaboratories;web service;appropriation;cyberinfrastructure;participatory design;open source software	Based on a study of participatory design in the development of cyberinfrastructure involving the rapid composition of open source software and web services, we consider cases where researchers create their own ad hoc infrastructures out of available software. We compare „topdown‟ and „bottom-up‟ cyberinfrastructure development and speculate on whether the two approaches can be productively combined.	bottom-up parsing;bottom-up proteomics;cyberinfrastructure;development testing;hoc (programming language);open-source software;top-down and bottom-up design;web service	Michael Twidale;Ingbert R. Floyd	2008		10.1145/1795234.1795286	computer science;knowledge management;top-down and bottom-up design;database;law;world wide web	SE	-47.178973780244334	10.673094639675842	164668
333649aaaf3d4426352f49be35ea727d723bc213	middleware solutions for service-oriented remote laboratories: a review	web services cloud computing computer aided instruction laboratories middleware service oriented architecture;wot elearning 3 0 laas mashup service oriented remote laboratories;wot;elearning 3 0;service oriented remote laboratories;remote laboratories web services interoperability java standards;mashup;laas;service oriented remote laboratories middleware solutions web 3 0 elearning 3 0 laboratories as a service laas	The evolution of Web 3.0 and consequently eLearning 3.0 have demanded a major change of the way learning objects are provided and implemented. It is foreseen that learning objects in eLearning 3.0 should be interoperable and easily discovered, and will represent any kind of virtual or physical object. Several approaches attempted to implement remote Laboratories as a Service (LaaS) in order to achieve such interoperability and to allow their integration into heterogeneous educational systems for pedagogical purposes and for more convenience, as well as, their coupling and mashing up with other learning objects in order to yield a scaffold and rich educational environment. This paper provides a broad study on the available middleware solutions for service-oriented remote laboratories implementation, emphasizing the pros and cons of each and the upcoming challenges in developing service-oriented remote laboratories.	artificial intelligence;cooperative breeding;coupling (computer programming);ecosystem;habitat;high-level programming language;input/output;interoperability;middleware;rca connector;semantic web;service-oriented architecture;service-oriented device architecture;service-oriented software engineering;temporal logic;web 2.0;world wide web	Mohamed Tawfik;Elio San Cristóbal;Salvador Ros;Roberto Xander Hernandez;Antonio Robles-Gómez;Agustín C. Caminero;Llanos Tobarra;Miguel Latorre;Felix Garcia Loro;Germán Carro;Gabriel Díaz;Manuel Castro	2014	2014 IEEE Global Engineering Education Conference (EDUCON)	10.1109/EDUCON.2014.6826071	computer science;database;multimedia;world wide web	DB	-45.32878543248706	10.902980077228419	164747
1348e7e97c48c578c2644a7c25d96cb9bda37ff8	supporting database designers in entity-relationship modeling: an ontology- based approach	entity relationship model;database design	Database design has long been recognized as a difficult problem, requiring a great deal of skill on the part of the designer. Research has been carried out that provides methodologies and rules for creating good designs. There have even been attempts to automate the design process. However, before these can be truly successful, methodologies and tools are needed that can incorporate and use domain knowledge. In this research, a methodology for supporting database design is proposed that makes use of domain-specific knowledge about an application, which is stored in the form of ontologies. The ontologies provide information that is useful in both the creation of new designs and the verification of existing ones. They also capture the constraints of an application domain. A methodology for assisting database design that takes advantage of the ontologies has been implemented in a prototype system. Initial testing of the prototype illustrates that the incorporation and use of ontologies are effective in creating database design.	application domain;artificial intelligence;database design;entity–relationship model;icis;information systems;ontology (information science);prototype	Vijayan Sugumaran;Veda C. Storey	2003				DB	-44.26006459323292	5.627869542988582	165324
af4625d634c832992c6cf232413e3e9660f4e53f	a categorical knowledge management software platform for advanced areal surface texture specification and verification	areal surface texture;knowledge management;category theory;categorical model;geometrical product specification;surface textures;technical drawing;期刊论文;access facilities;functional requirement;management software	Geometrical product specification and verification (GPS) standard system defined by ISO/TC 213 is a universal language for expressing tolerances and communicating functional requirements for geometrical workpieces in technical drawings. GPS is developed through cooperation by more than 60 countries and documented in hundreds of paper files. Hence, the GPS world is very complex and difficult to be handled. To overcome current implementation problems, this paper presents recent developments in applications of ISO GPS areal surface texture knowledge, by describing a novel integrated categorical knowledge management software platform. This paper discusses a categorical model to retrieve and integrated manage complex knowledge of GPS areal surface texture. To ensure the integration and consistency, this categorical model is also used to design and construct the software architecture and formulate the inference engine. This paper selects five typical examples to illustrate the areal surface texture knowledge capture and representation, multi-level management, and knowledge access facilities. The platform focuses on solving the intrinsic product design, manufacture and metrology problems by acting as a virtual domain expert through translating ISO GPS standards into the form of computerized expert knowledge.	computer-aided design;documentation;functional requirement;global positioning system;inference engine;knowledge management;software architecture;subject-matter expert;technical drawing	Yuanping Xu;Jian Huang;Jun Lu	2013	JNW	10.4304/jnw.8.6.1395-1402	embedded system;technical drawing;computer science;machine learning;data mining;computer security;functional requirement;category theory	Robotics	-45.083266309606856	5.35954893457915	165964
bb2e5981c77c9cc2c6d82f9385ffd0a9e5243c40	a framework for data collection, transformation and processing in industrial systems		Data collection requires homogenization of the data prior to processing it. This can create a challenge to the companies since data have varicose formats and schemas. This paper discusses the implementation of data collection framework using the PLANTCockpit open source platform, which is an integration platform for business processes. The framework is extended to fetch data from heterogeneous sources and then, allow the user to select the relevant data that matches his/her needs. In addition to this, the extendable framework also makes it possible to select the output data structure based on the user’s requirements. Defining such a framework can reduce company’s efforts for reshaping and modifying their architectures to handle new challenges posed by the ever-changing data. The framework not only restricts one to collection and transformation, but also provides an option to perform available processing techniques on the transformed data structure. The proposed framework has been tested on a cloud-based platform provided by the Cloud Collaborative Manufacturing Networks (C2NET) project.	business process;c2net;cloud computing;data structure;extensibility;integration platform;open-source software;requirement;software architecture	Leila Sanipour;Wael M. Mohammed;Borja Ramis;José L. Martínez Lastra	2018	2018 IEEE 16th International Conference on Industrial Informatics (INDIN)	10.1109/INDIN.2018.8471996	data collection;data mining;business process;systems engineering;engineering;cloud computing;integration platform;schema (psychology);data structure;fetch	DB	-47.57617888477499	7.612821931580716	166571
512b653d4088ee1d670c2cb8dd4144b997e1f66c	managing multiple and distributed ontologies on the semantic web	ontology evolution;330 wirtschaft;software systems;multiple and distributed ontologies;semantic web	In traditional software systems, significant attention is devoted to keeping modules well separated and coherent with respect to functionality, thus ensuring that changes in the system are localized to a handful of modules. Reuse is seen as the key method in reaching that goal. Ontology-based systems on the Semantic Web are just a special class of software systems, so the same principles apply. In this article, we present an integrated framework for managing multiple and distributed ontologies on the Semant ic Web. It is based on the representation model for ontologies, trading off between expressivity and tractability. In our framework, we provide features for reusing existing ontologies and for evolving them while retaining the consistency. The approach is implemented within KAON, the Karlsruhe Ontology and Semantic Web tool suite.	coherence (physics);description logic;internationalization and localization;kaon;ontology (information science);requirement;scalability;semantic web;semantic integration;semantics (computer science);software system;user requirements document	Alexander Maedche;Boris Motik;Ljiljana Stojanovic	2003	The VLDB Journal	10.1007/s00778-003-0102-4	upper ontology;idef5;data web;ontology components;ontology inference layer;computer science;ontology;semantic web;social semantic web;data mining;semantic web stack;database;ontology-based data integration;web ontology language;world wide web;owl-s;process ontology;semantic analytics;software system	AI	-43.606207088988846	8.969904937893094	167035
c57275a4ce6b057cc2812f49fea74d8555aa6860	an automated information integration technique using an ontoly-based database approach	integrable system;information integration	Developing intelligent systems to integrate numerous heterogeneous data sources in order to give end users an uniform query interface is a great challenging issue. The process of constructing a global schema of the integrated system is usually done manually. This is because of the mechanisms of solving different conflicts existing in an heterogeneous context. Even more these data sources do not contain enough knowledge to help solving these conflicts and then generating the global schema. In this paper, we present a new approach to integrate heterogeneous sources based on a priori approach (ontology-based database). The originality of our approach is that each data source participating in the integration process contains an ontology that defines the meaning of its own data using an ontology model called PLIB. This approach ensures the automation of the integration process when (1) all data sources have the same ontology, and (2) all sources reference a shared ontology, and each one can extent this ontology by adding new concepts. Finally, we present integration algorithms for the previous cases.	algorithm;analysis of algorithms;artificial intelligence;database;global serializability;heterogeneous database system;mathematical optimization;plib;prototype;query optimization;schema evolution	Ladjel Bellatreche;Guy Pierra;Dung Nguyen Xuan;Hondjack Dehainsala	2003			process ontology;information integration;ontology-based data integration;ontology (information science);database;intelligent decision support system;data mining;ontology;suggested upper merged ontology;upper ontology;computer science	DB	-43.23645847617842	7.318557896664213	167245
776d978a96625bb2984fd4947e1b85266ae6624b	web services based framework for knowledge management in peer-to-peer environment	knowledge management;web service;peer to peer	The problem of Knowledge Management (KM) is eminent in the P2P area. This paper presents a general framework of knowledge management based on web services in peer-to-peer (P2P) environment. P2P knowledge management yields significant advantages when combined and applied as web services for KM. By adopting web services techniques and distributed approaches, we partition the knowledge network into numerous knowledge communities self-adaptively, and provide a mechanism for knowledge management in these knowledge communities with our framework. Our framework implements the integration of KM functions and autonomy of knowledge peers in knowledge network, and at the same time, the cost of building and maintaining KM systems is reduced.	backup;confidentiality;knowledge management;peer-to-peer;prototype;self-organization;semi-structured data;semiconductor industry;web service;xml	Zhengchuan Xu;Chenghong Zhang;Liang Dong	2004			web service;web application security;web development;data web;web standards;computer science;knowledge management;ws-policy;social semantic web;database;personal knowledge management;law;world wide web	DB	-47.87857281813231	8.693421292670807	167388
6819edcefc2479c9e7885c58c647fe09720e7cdb	managing modular ontology evolution under big data integration		Big Data integration frameworks provide unified view of the data available from heterogeneous data sources. These data sources are continuously evolving, forcing systems that integrate them to adapt their global schema after each change. This gets more challenging when aiming to maintain the global schema always reflecting data sources content. To cope with such complexity, in this paper we describe evolution scenarios and manage modular ontology evolution within Big Data integration framework in an a priori way according to changes performed against the data sources.	big data;coherence (physics);evolution;information system;new product development;ontology (information science);requirement;software propagation	Hanen Abbes;Faïez Gargouri	2017		10.1007/978-3-319-65930-5_2	process ontology;database;big data;ontology-based data integration;ontology;modular design;schema (psychology);data mining;ontology (information science);computer science	DB	-47.24949490918552	8.378512334586665	167739
0b3665182e90919f5a90f110b5053d7d4dfba59c	optimized data management for e-learning in the clouds towards cloodle	data management;big data;e learning;optimization;cloud computing	"""Cloud computing provides access to """"infinite"""" storage and computing resources, offering promising perspectives for many applications, particularly e-learning. However, this new paradigm requires rethinking of database management principles in order to allow deployment on scalable, easy to access infrastructures, applying a pay-as-you-go model in which failures are not exceptions but rather the norm. The GOD project aims to provide an optimized data management system for e-learning in the cloud by rethinking traditional database management techniques, extending them to consider the specificities of this paradigm."""	cloud computing;database;programming paradigm;scalability;software deployment	Mirna Adriani;Yeow Wei Choong;Ba Hung Ngo;Laurent d'Orazio;Dominique Laurent;Nicolas Spyratos	2013		10.1145/2542050.2542089	computer science;data mining;database;management science	DB	-46.58982634935211	9.629584747926828	167834
8f540fad15ff4529ea36727ed8f5f0d8a2c0c2de	matchbox: combined meta-model matching for semi-automatic mapping generation	data integrity;heterogeneous data;model transformation;tool interoperability;schema matching;meta model matching;model engineering;mapping generation;matching model;meta model	Data integration is a well-known challenge offering a common view on heterogeneous data, e. g. to ensure consistency or tool interoperability. To implement this integration MDE proposes to apply model transformations. A model transformation requires meta-model matching, i. e. the task of discovering semantic correspondences between elements. Recently, semi-automatic matching has been proposed to support transformation development by mapping generation.  However, current meta-model matching approaches concentrate on a fixed non-configurable set of matching algorithms and often miss a thorough evaluation, thus no estimate concerning their quality can be made. We tackle these issues by proposing MatchBox, an approach using a configurable combination of matchers in a common framework. Thereby, we adapt and extend established schema matching techniques for the purpose of meta-model matching.  Additionally, we present a benchmark for meta-model matching consisting of 23 real-world model transformations and mappings. This benchmark is used to comprehensively evaluate MatchBox. The results obtained lead to conclusions regarding our approach and the effectiveness of meta-model matching.	algorithm;benchmark (computing);interoperability;matchbox;metamodeling;model transformation;model-driven engineering;semi-supervised learning;semiconductor industry	Konrad Voigt;Petko Ivanov;Andreas Rummler	2010		10.1145/1774088.1774563	metamodeling;computer science;theoretical computer science;optimal matching;data integrity;data mining;database	AI	-44.00120957886959	7.462698141555645	168507
ed1a40f98d0880be010d01a0c37f51bad8afa41a	collaborative understanding of distributed ontologies in a multiagent framework: design and experiments	multiagent systems;dynamic profil- ing;distributed ontology learning;real time;work in progress	In this paper, we describe our work-in-progress with collaborative understanding of distributed ontologies in a multiagent framework. As reported earlier, the objective of this framework is to improve communication and understanding among the agents while preserving agent autonomy. Each agent maintains a dictionary for its own ontology and a translation table. Our current work has focused on how neighborhood profiling, the translation tables, and query experience influence the collaborative activities among the agents. We have built an infrastructure prototype and conducted a series of comprehensive experiments from the viewpoint of agent executions, query scenarios, and translation credibility values. The specific goals of our analyses are to investigate (a) the learning of useful neighbors for sharing queries, (b) the efficiency of query handling in different real-time scenarios and with different resource constraints (such as the number of threads and available translations), and (c) the effects of different concepts and query demands on collaborative understanding. This paper reports on the results that we have collected so far.	agent-based model;autonomy;dictionary;emoticon;experiment;ontology (information science);prototype;real-time clock	Leen-Kiat Soh	2003			ontology learning;work in process;credibility;ontology (information science);data mining;profiling (computer programming);autonomy;thread (computing);ontology;computer science;knowledge management	AI	-44.891654650952816	10.172580149185722	169287
7914044c21a1a66655e5bdfea07f5a29363b88f5	on designing an ehcr repository		In an ongoing project, a pilot study and implementation of repository design for electronic home care records (EHCR) is described. Electronic home care record is based on the idea of electronic health record, however it also satisfies additional information and functionality requirements specific for home care. The design is based on the home care data and service model (K4Care model). First we analyzed the problem and decided about the platform, storage technology, cooperation with other parts of the system being developed, and basic structure of the EHCR. Then we focused on the design of data storage and transformation of the K4Care model into a database structure. Finally cooperation between the database and multiagent system is proposed.	agent-based model;computer data storage;concurrency control;data mining;data storage tag;database engine;database schema;e-services;multi-agent system;query language;relational database;requirement;research data archiving;sql;select (sql);server (computing);software release life cycle;transport layer security	Petr Aubrecht;Kamil Matousek;Lenka Lhotská	2008			data mining;medical record;computer science;computer data storage	DB	-45.757226264295774	8.82519053669207	169606
173c482bab2b6541ba193ac050cee5b4fc4b0c0f	question answering based on pervasive agent ontology and semantic web	pervasive agent ontology;conceptual knowledge;semantic web technology;domain knowledge;user profile;question answering system;human machine interface;natural language;semantic web;semantic relations;domain specificity;question answering;www;knowledge base	Semantic Web technologies bring new benefits to knowledge-based question answering system. Especially, ontology is becoming the pivotal methodology to represent domain-specific conceptual knowledge in order to promote the semantic capability of a QA system. In this paper we present a QA system in which the domain knowledge is represented by means of ontology. In addition, personalized services are enabled through modeling users’ profiles in the form of pervasive agent ontology, and a Chinese Natural Language human–machine interface is implemented mainly through a NL parser in this system. An initial evaluation result shows the feasibility to build such a semantic QA system based on pervasive agent ontology, the effectivity of personalized semantic QA, the extensibility of pervasive agent ontology and knowledge base, and the possibility of self-produced knowledge-based on semantic relations in the pervasive agent ontology. 2009 Elsevier B.V. All rights reserved.	extensibility;knowledge base;nl (complexity);natural language;ontology (information science);personalization;pervasive informatics;question answering;semantic web;software quality assurance;user interface	Qinglin Guo;Ming Zhang	2009	Knowl.-Based Syst.	10.1016/j.knosys.2009.06.003	human–machine interface;upper ontology;ontology alignment;semantic computing;question answering;bibliographic ontology;ontology inference layer;computer science;ontology;artificial intelligence;knowledge-based systems;semantic web;social semantic web;semantic web stack;database;ontology-based data integration;natural language;world wide web;owl-s;information retrieval;process ontology;domain knowledge;suggested upper merged ontology	AI	-41.001620574498816	7.302452780207274	169979
b2e07989f863a3d9aeed9f9cf1a4903fa913c9e5	government ontology and thesaurus construction: a taiwanese experience	information management system;thesaurus;site web;gestion informacion;sistema multiple;administracion electronica;ontologie;ontology editor;ingenierie connaissances;government thesaurus;knowledge management;semantics;multiple system;administration publique;systeme information gestion;semantica;semantique;semantic interoperability;biblioteca electronica;tesaurus;government ontology;information management;administration electronique;electronic government;knowledge management system;management information systems;completitud;ontologia;civil service;electronic library;semantic search;information system;completeness;gestion information;sitio web;administracion publica;completude;ontology;systeme information;web site;bibliotheque electronique;sistema informacion;systeme multiple;knowledge engineering	Due to the quantity and the diversity involved in e-government presentations and operations, traditional approaches to web site information management have been found to be rather inefficient in time and cost. Consequently, the necessity of establishing a government knowledge management system, so as to speed up information lookups, sharing, and linkups, naturally arises. Moreover, this knowledge management system would in turn enhance e-government effectiveness as it helps to store and transmit information, be it explicit or implicit in nature. The first step in creating this knowledge management system is to build up the government ontology and thesaurus. Upon the completion of the ontology and thesaurus needed, semantic searching can be conducted, which in turn kickstarts other mechanisms required for effective information management. Our research team has been commissioned by the Executive Yuan of Taiwan to establish the draft of government ontology and thesaurus and to design a framework for multiple-layered information management systems upon which the ontology and thesaurus can be constructed. The goal of this paper is to present the government ontology and thesaurus which our research team has come up with as well as the related infrastructure and function of the multiplelayered information management system.	browsing;document classification;e-government;information management system (ims);knowledge management;ontology (information science);semantic search;terminology extraction;thesaurus	Chao-Chen Chen;Jian-Hua Yeh;Shun-hong Sie	2005		10.1007/11599517_30	upper ontology;semantic interoperability;bibliographic ontology;completeness;computer science;knowledge management;ontology;artificial intelligence;management information systems;data mining;database;ontology-based data integration;world wide web;information system;ontology editor	Web+IR	-42.694083416494614	6.985765906701423	170373
5702dc891e7db32438c9d917510d2c5fb44d6f54	evaluating software architectures using ontologies for storing and versioning of engineering data in heterogeneous systems engineering environments	databases;relational database software architecture evaluation ontologies engineering data storage engineering data versioning heterogeneous systems engineering environments large systems engineering projects project level concepts backtracking semantic data integration local tool concepts semantic storage industrial scenarios;ontolgoy;semantic integration;performance;semantics;resource description framework;computer architecture;ontologies semantics data models computer architecture databases resource description framework;ontologies;versioning;storage management backtracking manufacturing data processing ontologies artificial intelligence project management relational databases software architecture;performance ontolgoy semantic integration versioning;data models	Large systems engineering projects involve the cooperation of various stakeholders from different engineering disciplines. Individual stakeholders apply various tools and related data storage approaches that (a) might hinder seamless interoperability and (b) include limited capability to support data versioning. Project-level concepts enable the mapping of engineering data coming from different disciplines. However, it remains open how to store data on project level that enable flexible and efficient data access from different disciplines in different environments and enable backtracking to previous versions in case of defects and/or human errors. While semantic data integration provides fundamental solutions for bridging semantic gaps between common project-level concepts and the local tool concepts used by each discipline, semantic storages have been developed to query and reason over gathered data rather than versioning frequent instance changes inherent to such engineering projects in distributed and heterogeneous environments. In this paper we evaluate three software architectures using ontologies in different ways and compare selected quality attributes, i.e., performance and scalability, in the context of an industrial scenarios. Main results suggest that architectures relying on a relational database for versioning individuals still outperforms traditional ontology storages.	backtracking;bridging (networking);computer data storage;data access;emoticon;interoperability;list of system quality attributes;ontology (information science);relational database;scalability;seamless3d;software architecture;systems engineering	Richard Mordinyi;Estefanía Serral;Dietmar Winkler;Stefan Biffl	2014	Proceedings of the 2014 IEEE Emerging Technology and Factory Automation (ETFA)	10.1109/ETFA.2014.7005237	semantic data model;data modeling;semantic integration;performance;computer science;knowledge management;ontology;artificial intelligence;software versioning;rdf;data mining;database;semantics;programming language	SE	-46.47258130814445	7.009274198125309	171042
bb5e47155fc61cb1111510c6e67990971a40f448	voeditor: a visual environment for ontology construction and collaborative querying of semantic web resources	semantic web resources;multiagent system;ontologies collaboration semantic web collaborative tools service oriented architecture collaborative software software engineering computer architecture visualization internet;query processing;collaboration;software engineering;collaborative tools;tourism recommendation system voeditor ontology construction collaborative querying semantic web resources visual ontology modeling tool multiagent system;ontologies artificial intelligence;computer architecture;visualization;multi agent systems;recommender system;internet;ontology engineering;visual ontology modeling tool;tourism recommendation system;semantic web;semantic web multi agent systems ontologies artificial intelligence query processing;ontologies;collaborative querying;ontology construction;service oriented architecture;voeditor;domain ontology;modeling tool;collaborative software	In this paper, a visual ontology modeling tool called VOEditor and an architecture based on the tool aimed at collaborative querying of Semantic Web resources are presented. A visual environment for ontology construction is deployed, providing a convenient mechanism for ontology engineers to create and edit their ontologies in a graphical mode. Search and coordination activities are carried out by a system of multi-agent designed for such environments. Finally, the tool and the architecture are demonstrated in the Tourism Recommendation System which is based on a tourism domain ontology created by the VOEditor.	database storage structures;graphical user interface;infographic;information retrieval;multi-agent system;ontology (information science);recommender system;relational database;semantic web;web ontology language;web resource	Shengqun Tang;Lina Fang;Ruliang Xiao;Xinguo Deng;Youwei Xu	2007	31st Annual International Computer Software and Applications Conference (COMPSAC 2007)	10.1109/COMPSAC.2007.237	upper ontology;open biomedical ontologies;ontology alignment;the internet;visualization;bibliographic ontology;ontology inference layer;computer science;knowledge management;ontology;artificial intelligence;service-oriented architecture;semantic web;database;ontology-based data integration;world wide web;owl-s;process ontology;collaborative software;recommender system;suggested upper merged ontology;collaboration	AI	-42.68670467890759	9.849902660170583	171139
775c076aab84b61b73acfb741956342532cd0ba7	an extensible architecture for environmental scanning from web sources	software architecture;internet;information monitoring;competitive intelligence;web monitoring;environmental scanning	Most organisations respond to internal and external challenges with different degrees of effectiveness. One of their biggest challenges is the ability to identify and respond appropriately to changes in their external environments. How effective are the organisational responses depend on the scope, timeliness and quality of the information available. However, such attributes depend not only from the quality of the sources accessed but also from the availability of tools for information extraction in timeliness and with adequate presentation. Considering the web one of the most comprehensive sources of information currently available, it is proposed in this paper an extensible software architecture for the instantiation of web monitoring tools. Such architecture includes generic classes that allow its permanent extensibility, according to the necessity of including new functionalities. A prototype is presented and a case study is described to illustrate its applicability.	extensibility;information extraction;norm (social);prototype;software architecture;universal instantiation	Hércules Antonio do Prado;Edilson Ferneda;André Ribeiro Magalhães;Eduardo Amadeu Moresi	2011	IJRIS	10.1504/IJRIS.2011.037735	software architecture;the internet;simulation;competitive intelligence;environmental scanning;data mining;world wide web	DB	-45.838470718867526	10.996811375347422	173032
5ad0d801c14adae66cfbb8b0b075470b9afa37cc	ontology matching for socio-cyberphysical systems: an approach based on background knowledge		Nowadays there are exist many ontology matching methods mostly based on using context and content in various combinations. The accuracy of existing methods can be increased by using the background knowledge – an external reference knowledge that can facilitate the matching process. The paper proposes an approach for automated matching of elements (fragments) of the ontologies based on the combination of existed ontology matching methods (pattern and context-based), neural network matching and additional control by community-driven matching. All of them are using the background knowledge to get additional information that helps to find more precise correspondence between ontologies concepts. Also, the background knowledge helps to explain result of ontology matching to the user, which is going to check the correspondence manually. In addition, the paper proposes an architecture of ontology matching service that is built based on the presented approach. The service is used for providing semantic interoperability in socio-cyberphysical systems.	ontology alignment	Alexander V. Smirnov;Nikolay Teslya;Sergey Savosin;Nikolay Shilov	2017		10.1007/978-3-319-67380-6_3	ontology-based data integration;ontology alignment;process ontology;ontology (information science);data mining;information retrieval;knowledge-based systems;upper ontology;open knowledge base connectivity;suggested upper merged ontology;computer science	AI	-43.261739953351814	7.3671869480520105	173161
7ea4f9fae31edb1c779dc6d6ab830d6e31136dde	mapping ontologies by utilising their semantic structure		As a key factor to enable interoperability in the Semantic Web (Berners-Lee, Hendler & Lassila, 2001), ontologies are developed by different organisations at a large scale, also in overlapping areas. Therefore, ontology mapping has come into forth to achieve knowledge sharing and semantic integration in an environment where knowledge and information are represented by different underlying ontologies. The ontology mapping problem can be defined as acquiring the relationships that hold between the entities of two ontologies. Mapping results can be used for various purposes such as schema/ontology integration, information retrieval, query mediation, or web service mapping. In this article, a method to map concepts and properties between ontologies is presented. First, syntactic analysis is applied based on token strings, and then semantic analysis is executed according to WordNet (Fellbaum, 1999) and tree-like graphs representing the structures of ontologies. The experimental results exemplify that our algorithm finds mappings with high precision.	algorithm;database schema;entity;exemplification;information retrieval;interoperability;ora lassila;parsing;semantic web;semantic integration;web service;wordnet	Yi Zhao;Wolfgang A. Halang	2009			information retrieval;semantic integration;semantic computing;semantic web;ontology;ontology (information science);similarity measure;semantic analytics;recall;computer science	AI	-42.42433420164497	7.418406600555982	173189
7a7d290d2feda000027831cbba76b7e38bf18c90	multi-facet product information search and retrieval using semantically annotated product family ontology	busqueda informacion;search and retrieval;etude utilisation;gestion informacion;semantic annotation;decision support;ontologie;information retrieval;estudio utilizacion;information management and retrieval;digital camera;information search;ontology development;faceted search;multi facet;recherche information;information management;indexation;information processing;product family;semantic web;ontologia;product family design;gestion information;product design;ontology;information search and retrieval;use study;ta engineering general civil engineering general;new products	With the advent of various services and applications of Semantic Web, semantic annotation has emerged as an important research topic. The application of semantically annotated ontology had been evident in numerous information processing and retrieval tasks. One of such tasks is utilizing the semantically annotated ontology in product design which is able to suggest many important applications that are critical to aid various design related tasks. However, ontology development in design engineering remains a time consuming and tedious task that demands considerable human efforts. In the context of product family design, management of different product information that features efficient indexing, update, navigation, search and retrieval across product families is both desirable and challenging. For instance, an efficient way of retrieving timely information on product family can be useful for tasks such as product family redesign and new product variant derivation when requirements change. However, the current research and application of information search and navigation in product family is mostly limited to its structural aspect which is insufficient to handle advanced information search especially when the query targets at multiple aspects of a product. This paper attempts to address this problem by proposing an information search and retrieval framework based on the semantically annotated multi-facet product family ontology. Particularly, we propose a document profile (DP) model to suggest semantic tags for annotation purpose. Using a case study of digital camera families, we illustrate how the faceted search and retrieval of product information can be accomplished. We also exemplify how we can derive new product variants based on the designer's query of requirements via the faceted search and retrieval of product family information. Lastly, in order to highlight the value of our current work, we briefly discuss some further research and applications in design decision support, e.g. commonality analysis and variety comparison, based on the semantically annotated multi-facet product family ontology.		Soon Chong Johnson Lim;Ying Liu;W. B. Lee	2010	Inf. Process. Manage.	10.1016/j.ipm.2009.09.001	information processing;computer science;semantic web;ontology;data mining;database;information management;product design;world wide web;information retrieval;human–computer information retrieval	Web+IR	-42.588315024081986	7.3465115907549565	173516
669813b503bab353fbe145c61ceabc3363c2bb84	emotionsonto: an ontology for developing affective applications	info eu repo semantics article;design of affective interaction systems;multimodality;ontologies;context	EmotionsOnto is a generic ontology for describing emotions and their detection and expression systems taking contextual and multimodal elements into account. The ontology is proposed as a way to develop an easily computerizable and flexible formal model. Moreover, it is based on the Web Ontology Language (OWL) standard, which also makes ontologies easily shareable and extensible. Once formalized as an ontology, the knowledge about emotions can be used in order to make computers more personalised and adapted to users’ needs. The ontology has been validated and evaluated by means of an applications based on a emotionsaware Tangible User Interface (TUI). The TUI is guided by emotion knowledge previously gathered using the same TUI and modelled using EmotionsOnto.	computer;mathematical model;multimodal interaction;ontology (information science);tangible user interface;web ontology language;world wide web	Juan Miguel López;Rosa Gil;Roberto Barraza Garcia;César A. Collazos	2014	J. UCS	10.3217/jucs-020-13-1813	upper ontology;ontology components;bibliographic ontology;ontology inference layer;computer science;knowledge management;ontology;artificial intelligence;data mining;ontology-based data integration;world wide web;owl-s;process ontology;suggested upper merged ontology	Web+IR	-42.20089566939009	9.580759217079276	173671
48f776c36f6f623d6c7cc40f9c35a265d39ea3e5	ontology management system	management system	For linguistics we can envisage two kinds of interoperability. The first kind facilitates data sharing. The second, more ambitious, kind provides the basis for comparison and checking of theoretical claims about languages. Unfortunately, interoperability of the first kind does not guarantee interoperability of the second kind, because the intuitions of linguists, even when they have used an interoperable format to describe a language, may not be recoverable. If one wishes to take the more ambitious route and develop interoperability of the second kind, a major problem faced is that linguists often do not agree about the category or type to which a particular phenomenon belongs. The reasons for this are numerous, but often it has to do with choosing a particular characteristic or property as fundamental or defining. To illustrate with a concrete example from Russian, emphasis can be placed on a number of different properties when defining the notion ‘agreement’, including that the controller and target of agreement mark the same feature value. But this might lead one to exclude examples such as the following, when similar constructions in the language would fit:	interoperability;management system;ontology (information science);schedule (computer science)	Ahmad Kayed	2003			process ontology;ontology-based data integration;knowledge management;ontology;data management;management system;computer science	ML	-45.777964504858346	4.279028691485901	174259
603cfdc563205ef36b858e3c5820e2d99fdbc3b9	a grounded and participatory approach to collaborative information exploration and management	information exploration;groupware;bottom up;information sources;database management systems;user participation;information space;participatory approach;classification;term usages collaborative information exploration collaborative information management large information sources classification schemes group work user satisfaction bottom up approach information organisation group needs;standardisation;collaborative classification;information management;indexation;cscw;group work;classification groupware knowledge based systems database management systems;collaboration information management environmental management space exploration navigation proceedings editorial board containers broadband communication search engines books;user satisfaction;knowledge based systems	Classification of concepts and terms is an effective way of organising information for managing large information sources. In many cases, the classification schemes are devised through a painstakingly time-consuming process without user participation, and impose standardised terms as a result. However, in the context of group work in which individuals with diverse views and background work together, such an overhead and the inflexibility of term usage can undermine efficient information management and user satisfaction. Instead, a bottom-up approach can be combined in which users participate and construct such classification schemes as they explore the information space. The information organisation can hence be customised to the specific group needs and term usages are grounded in the information containers themselves allowing users to interpret the meaning of terms in context. In this paper, we describe a system that constructs concept indexes, which supports such a bottom-up process of information exploration and	bottom-up parsing;bottom-up proteomics;browsing;collaborative software;experiment;faceted classification;general material designation;information management;information source;input device;overhead (computing);prototype;tablet computer;top-down and bottom-up design	Keiichi Nakata	2001		10.1109/HICSS.2001.926216	biological classification;computer science;knowledge management;artificial intelligence;computer-supported cooperative work;top-down and bottom-up design;data mining;database;management science;information management;world wide web;standardization;collaborative software	DB	-42.723769617349696	8.001093277615308	174279
a391dd6dd3ab69c2b405dce1f1ff79b7187c75ff	a context model for collaborative environment	context awareness;groupware;memory service;context sharing;context aware;human computer interaction;collaborative work;context awareness cscw context model;context query;collaborative application;pervasive computing;conceptual model;hci;information space;ontologies artificial intelligence;context model;collaborative environment;collaboration control mechanism;computer supported collaborative work;human computer interaction context awareness context sharing context processing cscw computer supported collaborative work hci ubiquitous computing semantic rich context model conceptual model ontology context query memory service context matching service information space interaction space collaboration control mechanism;context modeling collaborative work context aware services context awareness ubiquitous computing human computer interaction middleware pervasive computing international collaboration computer science;entity relationship modelling;ubiquitous computing entity relationship modelling groupware human computer interaction ontologies artificial intelligence;cscw;ubiquitous computing;middleware;computer science;context matching service;interactive space;semantic rich context model;context modeling;interaction space;ontology;context processing;context aware services	Context awareness, context sharing and context processing are key requirements for the future CSCW, HCI and ubiquitous computing systems. Until now, the collaborative context factors have been seldom specifically addressed. This paper argues that a generic context model is very important for building context-aware collaborative applications. A new semantic rich context model for collaborative environment is proposed. The conceptual model for context is described as ontology for contextual collaborative applications (OCCA). The model for context query & memory service, context matching service and control policies is illustrated. Information space, interaction space and collaboration control mechanisms are built up or implemented based on this context model	computer-supported cooperative work;context awareness;control system;human–computer interaction;mysql;redland rdf application framework;requirement;response time (technology);sesame;specification language;ubiquitous computing	Guiling Wang;Jinlei Jiang;Meilin Shi	2006	2006 10th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2006.253138	computer science;knowledge management;database;context model;world wide web;ubiquitous computing	HCI	-43.182355993150914	11.034025728903485	175673
b0f998e36e59f922e5eae8e42dc33a4912a04f8f	creating & testing clarin metadata components		The CLARIN Metadata Infrastructure (CMDI) that is being developed in Common Language Resources and Technology Infrastructure (CLARIN) is a computer-supported framework that combines a flexible component approach with the explicit declaration of semantics. The goal of the Dutch CLARIN project ‘‘Creating & Testing CLARIN Metadata Components’’ was to create metadata components and profiles for a wide variety of existing resources housed at two data centres according to the CMDI specifications. In doing so the principles of the framework were tested. The results of the project are of benefit to other CLARINprojects that are expected to adhere to the CMDI framework and its accompanying tools.	declaration (computer programming)	Folkert de Vriend;Daan Broeder;Griet Depoorter;Laura van Eerten;Dieter Van Uytvanck	2013	Language Resources and Evaluation	10.1007/s10579-013-9231-6	computer science;data mining;database;world wide web	HPC	-42.152385439437126	4.615871228695218	175851
5bee1368d926cd9220fbc42b31db9e412e915471	efficient semantic event processing: lessons learned in user interface integration	user interface;integrable system;004 informatik;application integration;emergency management;domain knowledge;lessons learned	Most approaches to application integration require an unambiguous exchange of events. Ontologies can be used to annotate the events exchanged and thus ensure a common understanding of those events. The domain knowledge formalized in ontologies can also be employed to facilitate more intelligent, semantic event processing, but at the cost of higher processing efforts. When application integration and event processing are implemented on the user interface layer, performance is an important issue to ensure acceptable reactivity of the integrated system. In this paper, we analyze different architecture variants of implementing such an event exchange, and present an evaluation with regard to performance. An example of an integrated emergency management system is used to demonstrate those variants.	business rules engine;cache (computing);centralized computing;complex event processing;drag and drop;field (computer science);java;microsoft outlook for mac;ontology (information science);scalability;semantic reasoner;user interface	Heiko Paulheim	2010		10.1007/978-3-642-13489-0_5	computer science;systems engineering;knowledge management;database	DB	-44.029588797000365	10.027841602157043	176326
187e176bdafaf107edfcea93b5e0d8dad3f15ff5	ontology-centric, service-oriented enterprise campaign management system	intelligent campaign management system;owl;media information retrieval;ontology centric enterprise campaign management system;service oriented enterprise campaign management system;information retrieval;semantic service oriented approach;knowletracker;natural languages;commerce;data mining;ontologies artificial intelligence;navigation;marketing;ontologies artificial intelligence commerce information retrieval marketing;publicity tracking;cognition;semantic service oriented approach ontology centric enterprise campaign management system service oriented enterprise campaign management system media information retrieval publicity tracking intelligent campaign management system knowletracker;ontologies;automatic repeat request;ontologies conference management technology management power system management poles and towers public relations internet monitoring text mining industrial relations	Public relations is an important management staff function in this computer age, and accurate media information retrieval and appropriate measurement for publicity tracking in a campaign management system is of utmost importance. This paper proposes an intelligent campaign management system, called KnowleTracker, based on a semantic service-oriented approach. KnowleTracker has powerful deep mining functions to pull out news and other information that may lie several layers below the front page based on a semantic search for not only the specific keyword, but also the associated concepts that are not part of the keywords. The returned results are presented at different levels of detail and viewed from different angles, and show customers, detailed information of where their news releases are distributed. We demonstrate the utility of KnowleTracker in a real-world scenario through a case study on “A*STAR Event Campaign Management”, and argue that our system is an effective tool to tackle the complex task of campaign management and tracking. A Web Demo is available at: http://datam.i2r.a-star.edu.sg/est/demo/icsc2009/.	information retrieval;level of detail;management system;semantic search;service-oriented device architecture;service-oriented software engineering	Wee Tiong Ang;Wei-Peng Seeto;Francis Tan;Weng-Fai Tang;Kanagasabai Rajaraman	2009	2009 IEEE International Conference on Semantic Computing	10.1109/ICSC.2009.63	navigation;cognition;computer science;knowledge management;ontology;artificial intelligence;data mining;database;natural language;automatic repeat request;world wide web	DB	-46.68595803631739	8.958163579010883	177101
2e41cfe41bdc253a21d5608e14eb1db46e670a59	a tool for complete owl-s services annotation by means of concept networks		Current tools to create OWL-S annotations have been designed starting from the knowledge engineer’s point of view. Unfortunately, the formalisms underlying Semantic Web languages are often obscure to the developers of Web services. To bridge this gap, it is desirable that developers are provided with suitable tools that do not necessarily require knowledge of these languages in order to create annotations on Web services. With reference to some characteristics of the involved technologies, this work addresses these issues, proposing guidelines that can improve the annotation activity of Web service developers. Following these guidelines, we also designed a tool that allows a Web service developer to annotate Web services without requiring him to have a deep knowledge of Semantic Web languages. A prototype of such a tool is presented and discussed in this paper.	owl-s	Domenico Redavid;Stefano Ferilli;Berardina De Carolis;Floriana Esposito	2014		10.1007/978-3-319-25840-9_25	bioinformatics;data mining;world wide web	NLP	-44.12434913552398	7.464657491155276	177258
59c34a7222961873833928ffc63dfa10b7dbd1bb	context-based ontology matching: concept and application cases	software;context based semantic matching;project management;automatic ontology matching;semantics;materials;context based semantic matching context based ontology matching computer science context modeling automatic ontology matching;ontologies artificial intelligence;ontologies context semantics software materials project management context modeling;context model;datavetenskap datalogi;ontology matching context;ontologies;computer science;semantic matching;context modeling;use case;context;ontology matching;context based ontology matching	Work presented in this paper addresses the challenge of bringing together concepts and experiences from two different areas of computer science: context modeling and ontology matching. Current work in the field of automatic ontology matching does not take into account the context of the user during the matching process. This paper is organized as follows, (1) we introduce of the concept of “context” in the ontology matching process, (2) we introduce the use cases and motivation along with an example of the use of context and (3) an approach for context-based semantic matching, which builds on different (weighted) levels of overlap for a better ranking of alignment elements depending on user’s demand.	ontology alignment	Feiyu Lin;Jonathan Butters;Kurt Sandkuhl;Fabio Ciravegna	2010		10.1109/CIT.2010.233	upper ontology;project management;ontology alignment;computer science;ontology;data mining;database;semantics;linguistics;context model;ontology-based data integration;information retrieval;process ontology	Vision	-43.23778718615258	7.805544449974303	177601
f532c53c237091430f056fd6103ec9d991a8606d	concept as knowledge handles in collaborative document management	groupware;document handling;collaborative index construction knowledge handles collaborative document management electronic documents document spaces collaborative construction concept indexes arbitrary text piece software agents document collection document browsing;software agent;software agents groupware document handling indexing;collaboration knowledge management navigation information technology space technology identity based encryption read only memory knowledge based systems context information management;software agents;indexing;indexation;document management	With the increasing availability of electronic documents, it is essential that people can navigate through document spaces for information effectively through an index, in a collaborative manner. We describe a system that supports the collaborative construction of indexes of concepts rather than terms. In a concept index, a concept can be described by more than one term, phrase, arbitrary text piece, and other concepts. These concepts can be structured and associated with one another without strict restrictions. Software agents work in the background to find occurrences of concepts in a document collection, enabling users to navigate documents based on concepts. Users can extract concepts by simply highlighting pieces of text while browsing documents. Through collaborative index construction, a user benefits from contributions of other users, and the system enables a group of users to collaboratively manage information.		Angi Voß;Keiichi Nakata;Marcus Juhnke	1999		10.1109/ENABL.1999.805208	well-formed document;computer science;artificial intelligence;user requirements document;software agent;document management system;data mining;database;world wide web;design document listing	HCI	-42.794410171436716	8.127655575115009	178537
9c7e174005fded5716e8fd82698dde5300281a16	rimom2013 results for oaei 2013		This paper presents the results of RiMOM2013 in the Ontology Alignment Evaluation Initiative (OAEI) 2013. We participated in three tracks of the tasks: Benchmark, IM@OAEI2013 , and Multifarm. We first describe the basic framework of our matching System (RiMOM2013); then we describe the alignment process and alignment strategies of RiMOM2013, and then we present specific techniques used for different tracks. At last we give some comments on our results and discuss some future work on RiMOM2013. 1 Presentation of the system Recently, ontology is increasingly seen as an apocalyptic factor for enabling interoperability between heterogeneous systems and Semantic Web applications. Ontology Aligning is required for combining distributed and motley ontologies. Developing ontology alignment systems has become an essential issue of recent ontology research. RiMOM2013 is named after RiMOM(Risk Minimization based Ontology Mapping) which is a multi-strategy ontology alignment system and was firstly developed in 2007 [1][2]. RiMOM implements several different matching strategies that have been defined based on different ontological information. For different ontology mapping tasks, RiMOM can automatically select and combine multiple strategies to generate accurate alignment results. RiMOM has evolved all the time since 2007, and RiMOM2013 is developed based on RiMOM and has several new characteristics that will be described in following subsections. 1.1 State, purpose, general statement As shown in Fig. 1, the whole system is consists of three layers: User Interface layer, Control layer and Component layer. In the User Interface layer, RiMOM2013 provides an interface to allow customizing the matching procedure: including selecting preferred components, setting the parameters for the system, choosing to use translator tool or not. In semi-automatic ontology matching, the task layer stores parameters of the alignment tasks, and controls the execution process of components in the component layer. In component layer, we define six groups of executable components, including preprocessor, matcher, aggregator, evaluator, postprocessor and other utilities. In each group, there are several instantiated components. For a certain alignment task, user can select appropriate components and execute them in desired sequence.	benchmark (computing);executable;interoperability;interpreter (computing);ontology (information science);ontology alignment;preprocessor;semantic web;semantic integration;semiconductor industry;service layer;user interface	Qian Zheng;Chao Shao;Juan-Zi Li;Zhichun Wang;Linmei Hu	2013			simulation;computer science;data mining;management science	AI	-41.38768123308649	4.782296197969028	178693
42a42de11be21e1a26a27bc5906f19f2fd804cf8	building concept system from the perspective of development of the concept	concept system;knowledge;natural language processing;ontology;semantics	The concept system with rich content is the key to improve the performance of knowledge-based artificial intelligence knowledge system. And a sufficient number of concepts, rich in semantic association, to meet the multi-tasking and developed concept system are one of the major challenges of knowledge engineering. It is the fundamental goal of conceptualization of knowledge, too. In this paper, for the study of natural language processing, from the perspective of development of the concept, a framework is proposed to building concept system. © 2013 Springer-Verlag.		Cheng Xian-yi;Shen Xue-hua;Shi Quan	2012		10.1007/978-3-642-31552-7_7	conceptualization;knowledge management;knowledge engineering;ontology;semantics;computer science	Robotics	-43.99114658034835	6.095093704962455	178992
b7c37cce122152eda4cad0dca1c0e45c563690c9	an automatic database generation and ontology mapping from owl file		To promote ontology application development, some of the technical processes should be simplified with a supportive tool and an automatic method. This work presents a method to automatically generate a database schema from OWL file to prevent schema conflicts. Moreover, a mapping configuration can be created to associate an ontology and the generated data schema within the process. This method is designed to be compatible with an existing Ontology Application Management (OAM) Framework. With the proposed method, ontology labels are used to name data field name in database generation. The method allows any languages for ontology labels, but English ontology labels are recommended in this work since table names will be understandable. From testing, the produced mapping configuration to map ontology schema to database schema worked equivalently to human in terms of correctness but much faster in time consuming.	application lifecycle management;correctness (computer science);database schema;display resolution;object access method;ontology (information science);semantic integration;web ontology language	Jirapong Panawong;Taneth Ruangrajitpakorn;Marut Buranarach	2016			semantic integration;open biomedical ontologies;owl-s;information retrieval;database;suggested upper merged ontology;computer science	Web+IR	-40.99484405880691	4.850125181583242	180210
04081931a2c30792799edc14f64fce2736c3701b	use of ontology for solving interoperability problems between enterprises	collaborative process;interoperability process;transfor- mation.;ontology	When trying to solve interoperability problems between enterprises, the semantic issues are important. To date, they are more and more focused on ontology. This paper presents how to use ontology in the PBMEI method, aimed at solving enterprise interoperability problems in modelling environment. During the elaboration of PBMEI, the necessary ontology information is explicitly specified. Because of two different uses of ontologies, this paper proposes two variants of PBMEI. Finally, this paper concludes with the content of the ontologies required in PBMEI. The ontologies in the PBMEI method PBMEI for an application case are being studied.	enterprise interoperability;language-independent specification;model-driven architecture;ontology (information science)	Hui Liu;Anne-Françoise Cutting-Decelle;Jean Pierre Bourey	2010		10.1007/978-3-642-15961-9_86	upper ontology;semantic interoperability;knowledge management;data mining;database;ontology-based data integration;process ontology	AI	-43.63916394449077	8.490741566207623	180680
103ae79da45c082677cace4228bd2c7e4f9380b3	explication and semantic querying of enterprise information systems	database semantics;openerp;enterprise information system;ontology;systems interoperability	Many researches show that the ability of independent, heterogeneous enterprises’ information systems to interoperate is related to the challenges of making their semantics explicit and formal, so that the messages are not merely exchanged, but interpreted, without ambiguity. In this paper, we present an approach to overcome those challenges by developing a method for explication of the systems’ implicit semantics. We define and implement the method for the generation of local ontologies, based on the databases of their systems. In addition, we describe an associated method for the translation between semantic and SQL queries, a process in which implicit semantics of the EIS’s databases and explicit semantics of the local ontologies become interrelated. Both methods are demonstrated in the case of creating the local ontology and the semantic querying of OpenERP Enterprise Resource Planning system, for the benefit of the collaborative supply chain planning.	access control;application framework;business logic;conceptualization (information science);correctness (computer science);data model;database;database schema;enterprise information system;enterprise resource planning;erdős–rényi model;hard coding;interoperability;mighty no. 9;odoo;ontology (information science);ontology alignment;precondition;rewriting;sql;semantic web rule language;semantic integration;semantic interoperability;semantic query;semiconductor industry;supply chain network;virtual enterprise;web ontology language	Milan Zdravkovic;Hervé Panetto;Miroslav Trajanovic;Alexis Aubry	2013	Knowledge and Information Systems	10.1007/s10115-013-0650-x	semantic integration;computer science;knowledge management;ontology;data mining;database;enterprise information system	AI	-43.89129574408827	8.795630982420798	180745
5457f442184043483d324b4584d03430f991a0b1	research on semantic-based knowledge service for cluster supply chain	knowledge network;groupware;semantics adaptation models security collaboration ontologies knowledge based systems;knowledge based system;supply chain management authorisation groupware knowledge management;authorisation;knowledge management;collaboration;semantics;collaborative editing;visual navigation;visual navigation semantic based knowledge service cluster supply chain enterprise collaboration cluster enterprises knowledge sharing multilevel knowledge model cluster public knowledge enterprise private knowledge knowledge collaboration mechanism cooperative sharing knowledge access control scheme knowledge collaborative editing knowledge retrieval;cluster supply chain;knowledge service;knowledge sharing;semantic;collaboration cluster supply chain semantic knowledge service;ontologies;supply chain;access control;adaptation models;security;knowledge modeling;knowledge based systems;supply chain management	Knowledge service is critical to enterprise collaboration in cluster supply chain. However, current cluster enterprises have limited capabilities for knowledge sharing. In order to address the knowledge service needs of cluster supply chain, this paper proposes a novel semantic-based knowledge service approach. In the approach, a multi-level knowledge model is presented to achieve uniform and flexible representation for cluster public knowledge and enterprise private knowledge, which further forms complex knowledge network for cluster supply chain. Then the knowledge collaboration mechanism is utilized to support knowledge collaborative creating and enriching, and cooperative sharing. In addition, the knowledge access control scheme is employed to ensure high security. To demonstrate the practicality of the proposed approach, a knowledge service platform is implemented, including several core services such as knowledge collaborative editing, retrieval and visual navigation, etc. Applications show that this platform can support knowledge sharing between enterprises effectively and further promote the development of cluster supply chain efficiently.	access control;context (computing);knowledge base;knowledge management;knowledge representation and reasoning;machine vision	Feng Wang;Meng Wang;Shuai Yang;Lanfen Lin	2012	Proceedings of the 2012 IEEE 16th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2012.6221865	knowledge base;computer science;knowledge management;ontology;artificial intelligence;access control;knowledge-based systems;open knowledge base connectivity;data mining;supply chain;authorization;knowledge extraction;knowledge value chain;collaboration	Web+IR	-47.761357224276495	8.942781688408802	181002
ad74ee3e3073ceccdc9df1002d691bf61ffd1dd3	evolution of the metadata in the ontology-based knowledge management systems	dynamic change;semantic annotation;ontology evolution;business environment;knowledge management system;domain ontology	An ontology-based knowledge management system uses an ontology to represent explicit specification of a business domain and to serve as a backbone for providing and searching for knowledge sources. But, dynamically changing business environment implies changes in the conceptualisation of a business domain that are reflected on the underlying domain ontologies. Consequently, these changes have effects on the performances and validity of the KM system. In this paper we present an approach for enabling consistency of the description of knowledge sources in an ontology-based KM system in the case of changes in the domain ontology. This approach is based on our research in the ontology evolution and ontology-based annotation of documents. The proposed method is implemented in our semantic annotation framework so that efficient acquiring and maintaining of ontology-based metadata is supported.	business domain;internet backbone;knowledge management;management system;ontology (information science);performance	Ljiljana Stojanovic;Nenad Stojanovic;Siegfried Handschuh	2002			upper ontology;open biomedical ontologies;ontology alignment;ontology components;bibliographic ontology;ontology inference layer;knowledge management;ontology;knowledge-based systems;data mining;ontology-based data integration;owl-s;information retrieval;process ontology;suggested upper merged ontology	AI	-42.93604358005008	7.718292249307406	181432
1a48549992449fc02f6177a49812437c9a95fb21	pre-consensus ontologies and urban databases	urban planning	Facing the difficulties of interoperability and coo peration between several urban databases, a solution is based on ont logies which can help not only clarify the vocabulary used in urban planning, but also organize urban applications; indeed multiple definitions can be given to various urban objects. So this is the scope of the Towntology project which aims at defining on t logies for urban planning whose design is characterized by the multiplicity o f definitions. After having presented some ways of using ontologies for various actors in urban applications, a definition of pre-consensus ontologies is given, to ge her with some groupware tools to collect multiple textual and multimedia definitions in sub-ontologies, to check and consolidate the vocabulary in order to reach some c onsensus. We conclude this paper by giving some recommendations for the Towntology p roject for covering the whole urban field by integrating various sub-ontologies.	collaborative software;database;interoperability;ontology (information science);vocabulary	Robert Laurini	2007		10.1007/978-3-540-71976-2_3	computer science;knowledge management;data mining;management science	HCI	-44.23670730012267	5.6816947929093855	181761
b5914388095f9f45161070ac333eb1b23298c94f	research of model-driven interactive automatic / semi-automatic form building	event model;user interface;data model;form model;xforms;xml;use case	Forms are ubiquitous in today's software applications, so automation of form generation is highly desirable. In this paper, we provide improvements on Xforms model including data and event model. At the same time, we give a new method using use case for automatic form-building and the transformations from use case models to form user interfaces.	model-driven integration;semiconductor industry	Xiuyun Ding;Xueqing Li	2007		10.1007/978-3-540-73345-4_70	computer science;xforms;data mining;database;world wide web	NLP	-42.35672830196171	10.894493338162176	182175
4a5a3a48bf5001aa34da9580a1b795b8284d4e44	enhancing geo-service chaining through deep service descriptions		We demonstrate the integrated use of semantic and syntactic service descriptions, called deep service descriptions, for service chaining by combining two prototypes: one that deals with geoservice discovery abstract composition (called ‘GeoMatchMaker’), with one that supports concrete composition and execution of geoservices services (called ‘Integrated Component Designer’). Most other service chaining approaches confine themselves to handling either syntactic or semantic service descriptions. The proprietary formats of these descriptions hamper an effective integration of discovery, composition and execution of multiple services. In essence, service chaining should help a user by Address for correspondence: Rob Lemmens, Department of Geo-Information Processing, International Institute for Geo-Information Science and Earth Observation (ITC), P.O. Box 6, 7500 AA Enschede, The Netherlands. Email: lemmens@itc.nl 850 R Lemmens et al. © 2007 The Authors. Journal compilation © 2007 Blackwell Publishing Ltd Transactions in GIS , 2007, 11(6) providing an appropriate combination of executable services to solve a specified problem or query. Current XML-based service description languages, such as the Web Ontology Language-Services (OWL-S) and the Web Service Description Language-Semantics (WSDL-S), allow us to build a geoservice-reuse architecture based on common ontologies and shared service descriptions. Our approach uses annotation as a bridge between the syntax and semantics of services. This paper reports on its context and implementation issues. The target groups of this research are geo-information engineers who are confronted with information integration issues and service interoperability issues, and secondly, information engineers who in general are confronted with distributed information and with end users that need to access distributed services as one virtual application.	algorithm;blackwell (series);compiler;email;executable;geforce 7 series;geographic information system;graphical user interface;information processing;information science;internet;knowledge base;owl-s;ontology (information science);prototype;protégé;semantic interoperability;semantic query;semantic reasoner;service composability principle;service discovery;software deployment;software propagation;software repository;usability;user (computing);web ontology language;web services description language;web application;web search query;web service;xml	Rob Lemmens;Rolf A. de By;Michael Gould;Andreas Wytzisk;Carlos Granell;Peter van Oosterom	2007	Trans. GIS	10.1111/j.1467-9671.2007.01079.x	computer science;database;programming language;world wide web	Web+IR	-41.61801779368947	5.60131913532139	184353
2f5db06311ecdd18a082bb0ab0900ed4c5fe00c7	combining dialogue and semantics for learning and knowledge maturing: developing collaborative understanding in the web 2.0 workplace	software;vygotskian ideas;groupware;ontological semantics;computer aided instruction;collaboration;semantics;dialogue;web 2 0 workplace;ontologies artificial intelligence;ontologies games semantics collaboration communities software;ontologies knowledge maturing dialogue semantics;large scale;internet;large scale ec integrated project;integrated project;games;collaborative understanding;ontologies artificial intelligence computer aided instruction groupware internet;ontologies;vygotskian ideas knowledge maturing collaborative understanding web 2 0 workplace large scale ec integrated project ontological semantics;communities;knowledge maturing	This paper explores how we can support the development of collaborative understanding through a recent formulation of learning through knowledge maturing in the ‘Web 2.0 workplace’. Knowledge Maturing is a concept that is the subject of a large-scale EC Integrated Project, and in this paper we focus on, demonstrate and verify the conceptual and technical underpinnings that emphasise the role of dialogue and ontological semantics within the maturing process. So this paper: introduces the concept of knowledge maturing, describes a prototype application realising knowledge maturing through linking dialogue and semantics, examines this concept through re-thinking Vygotskian ideas, and, presents an initial evaluation along with a summary and some implications.	artificial intelligence;deep learning;endeavour (supercomputer);integrated project support environment;prototype;schmidt decomposition;semantic web;smarter planet;social media;web 2.0;world wide web	Andrew Ravenscroft;Simone Braun;Tobias Nelkner	2010	2010 10th IEEE International Conference on Advanced Learning Technologies	10.1109/ICALT.2010.55	games;the internet;computer science;knowledge management;ontology;data science;data mining;database;semantics;management;collaboration	Robotics	-46.4862736293312	4.578304182940206	185714
08a6c01a93e2aedcccf7ffbaf84f0b2d5d4250e2	a collaborative semantic web layer to enhance legacy systems	front end;text mining;expert finding;semantic web;legacy system;domain ontology;use case;national research council;semantic wiki;knowledge base	This paper introduces a framework to add a semantic web layer to legacy organizational information, and describes its application to the use case provided by the Italian National Research Council (CNR) intraweb. Building on a traditional web-based view of information from different legacy databases, we have performed a semantic porting of data into a knowledge base, dependent on an OWL domain ontology. We have enriched the knowledge base by means of text mining techniques, in order to discover on-topic relations. Several reasoning techniques have been applied, in order to infer relevant implicit relationships. Finally, the ontology and the knowledge base have been deployed on a semantic wiki by means of the WikiFactory tool, which allows users to browse the ontology and the knowledge base, to introduce new relations, to revise wrong assertions in a collaborative way, and to perform semantic queries. In our experiments, we have been able to easily implement several functionalities, such as expert finding, by simply formulating ad-hoc queries from either an ontology editor or the semantic wiki interface. The result is an intelligent and collaborative front end, which allow users to add information, fill gaps, or revise existing information on a semantic basis, while keeping the knowledge base automatically updated.	browsing;categorization;database;document classification;experiment;front and back ends;hoc (programming language);information;intraweb;knowledge base;knowledge management;legacy system;named-entity recognition;off topic;ontology (information science);plasma cleaning;sparql;semantic web;semantic similarity;text mining;web ontology language;web application;wiki	Alfio Massimiliano Gliozzo;Aldo Gangemi;Valentina Presutti;Elena Cardillo;Enrico Daga;Alberto Salvati;Gianluca Troiani	2007		10.1007/978-3-540-76298-0_55	use case;upper ontology;knowledge base;semantic computing;text mining;bibliographic ontology;semantic search;ontology inference layer;semantic grid;computer science;ontology;artificial intelligence;front and back ends;knowledge-based systems;semantic web;social semantic web;data mining;semantic web stack;database;semantic technology;world wide web;owl-s;legacy system;semantic analytics	Web+IR	-41.01946428443951	6.54151512664181	186574
7ed4626374bc1c8f84b4273e86d2ab19ccd1ab26	alocom: a generic content model for learning objects	comparative analysis;reusability;generic model;learning organization;learning system;content models;alocom;reusable learning object;learning object;learning object content model;ontologies;interoperability	e-Learning organizations are focusing heavily on learning content reusability. The ultimate objective is a learning object economy characterized by searchable digital libraries of reusable learning objects that can be exchanged and reused across various learning systems. To enable such approach, basic questions of learning content interoperability need to be addressed. This paper investigates the interoperation of learning content defined according to different specifications. A number of content models are reviewed that define learning objects and their components. On the basis of a comparative analysis, the content models are mapped to a generic model for learning objects to address interoperability questions and to enable share and reuse on a global scale.	align (company);content management system;digital library;interoperability;interoperation;library (computing);qualitative comparative analysis	Katrien Verbert;Erik Duval	2008	International Journal on Digital Libraries	10.1007/s00799-008-0039-8	qualitative comparative analysis;interoperability;multi-task learning;reusability;learning organization;computer science;knowledge management;ontology;multimedia;world wide web	Web+IR	-43.355530884940805	9.600507118122037	186703
4193473c67cc45ef9c8173c56fb33702964285c5	semantic interoperability of geospatial services	geographic information system;e government;semantic interoperability;multi agent;intelligent agents;gis;interoperability	This article proposes a multi-agent based framework that allows multiple data sources and models to be semantically integrated for spatial modeling in business processing. The paper reviews the feasibility of ontology-based spatial resource integration options to combine the core spatial reasoning with domainspecific application models. We propose an ontology-based framework for semantic level communication of spatial objects and application models. We then introduce a multi-agent system, ontology-based spatial information and resource integration services (OSIRIS), to semantically interoperate complex spatial services and integrate them in a meaningful composition. The advantage of using multi-agent collaboration in OSIRIS is that it obviates the need for end-user analysts to be able to decompose a problem domain to subproblems or to map different models according to what they actually mean. We also illustrate a multi-agent interaction scenario for collaborative modeling of spatial applications using the proposed custom feature of OSIRIS.	agent-based model;multi-agent system;problem domain;semantic interoperability;spatial–temporal reasoning	Iftikhar U. Sikder;Santosh K. Misra	2008	IJIIT	10.4018/jiit.2008010102	semantic interoperability;interoperability;e-government;computer science;knowledge management;artificial intelligence;data mining;database;geographic information system;ontology-based data integration;world wide web	AI	-44.34912113751253	9.389893696053546	186934
5d50e0e76c530c72da83bacf84d8261965524657	an interoperable web service architecture to provide base maps empowered by automated generalisation	web service;user profile	Producing customized base maps generated by automated generalisation on the web is an important issue in physical planning. In this web context an interoperable architecture is a key requirement. It integrates the necessary data and the functionality to finally perform the generation of the base map. Additionally, interoperability increases the reuse of the architecture for other domains. In this paper we will describe such an architecture. It has two key features: it supports the user profiles to specify the generalisation constraints and the generalisation-enabled WMS, which generates the base map according to the user profiles. The specialized WMS is especially able to access Web Service-based generalisation functionality. For the implementation of the architecture we used Geoserver, 1Spatial’s Clarity and 52° North WPS.	interoperability;user profile;wps office;web map service;web mapping;web service	Theodor Foerster;Jantien E. Stoter;Rob Lemmens	2008		10.1007/978-3-540-68566-1_15	web service;web modeling;web mapping;computer science;web page;data mining;database;web intelligence;world wide web;web coverage service	Web+IR	-43.28270674488179	10.609118702947425	187392
474125173c48344850f34da478cfc1ba7a9d709f	elmo: an interoperability ontology for the electricity market	electricity market	The liberalization of the electricity market in the European Union is a process of significant importance that aims at creating an efficient deregulated internal electricity market within the Union. An important challenge towards that end is definitely the development of effective market mechanisms and regulations that will comprise the operational framework of the market. Equally important, however, we consider the development of an interoperability framework that will enable the effective and unproblematic interaction between the market participants at both human and system level. Towards that direction we propose in this paper the Electricity Market Ontology (ELMO), an ontological model that provides a shared, common understanding of concepts and procedures regarding the electricity market operation. ELMO has been developed for the Hellenic Transmission System Operator (HTSO) and it is currently used by the organization for providing intelligent information access services to people interested in the market.	cyber-security regulation;extensibility;gene ontology term enrichment;information access;interoperability;ontology (information science);sysop;upper ontology	Panos Alexopoulos;Kostas Kafentzis;Christoforos Zoumas	2009			electricity market;computer science;marketing;electricity retailing;commerce	AI	-47.43042249934645	5.468421122156171	187532
afa413846ed35809e19bc3bc7ea5693d8b636dbf	elkar-cm: a multilingual collaborative concept map editor	multilingual collaborative concept map;main characteristic;paper elkar-cm;groupware;knowledge representation;concept map;visualization;kernel	Along this paper Elkar-CM, a multilingual collaborative concept map editor is presented. The paper starts explaining the main characteristics of CM-ED, the kernel in which Elkar-CM is based on. Next, the paper describes the main characteristics and functionalities offered by Elkar-CM. Finally some conclusions are pointed out	concept map;level editor	Cristóbal Arellano;Urko Rueda;Ianire Niebla;Mikel Larrañaga;Ana Arruarte Lasa;Jon A. Elorriaga	2006	Sixth IEEE International Conference on Advanced Learning Technologies (ICALT'06)	10.1109/ICALT.2006.158	concept map;knowledge representation and reasoning;human–computer interaction;computer science;knowledge management;artificial intelligence;data science;database;world wide web	Robotics	-46.009115971232944	4.7490958555093625	187543
46100481c5d861d6d032649dc0c0c529d2e9c491	taming the complexity of big data multi-cloud applications with models		Private and public clouds are getting more and more common. With them comes the need to analyze data stored by different applications in different clouds. Different clouds and applications tend to enforce the use of different data stores, which makes it even harder to aggregate information. The main outcome is that integrating different data sources requires deep knowledge on how data is stored on each solution and on the trade-offs involved in moving from one system to another. This paper is part of the ongoing work on the JUNIPER FP7 EU project (http://www.juniper-project.org/). In that project we explore the power of modelling tools to simplify the design of industrial big data applications. In the present work we present an overview of our approach and its application on a simple case study.	aggregate data;big data;cloud computing;data store;data structure;model-driven engineering;programming language;requirement;unified modeling language	Marcos Aurélio Almeida da Silva;Andrey Sadovykh;Alessandra Bagnato;Etienne Brosse	2014			data mining;andrey;cloud computing;big data;computer science	DB	-46.889318820634834	9.664497710850515	188361
82b852f568ead7aaa2a16391594901e932b8c72d	specification and design method for big data driven cyber physical systems		Cyber physical systems (CPS) such as automobile and intelligent transportation systems, aerospace systems, medical devices and health care systems are receiving a lot of attentions recently. Those systems contain a large network of sensors distributed across different components, which leads to a tremendous amount of measurement data available to system operators. Big data driven cyber physical systems are therefore specific. Their design needs appropriate concepts and tools which are not available under systemic or object oriented methods. UML, the most used nowadays, cannot, in its standard form, satisfy the requirements of such design. In this paper, we propose a big data driven cyber physical system design method based on AADL, which can specify and model the requirements of big data driven cyber physical systems, implement these requirements on big data platforms, guarantees QoS in a highly scalable manner, we present how to use AADL the extension mechanisms to model big data, especial spatial information and temporal information, we propose a scheduling algorithm to meet big data driven cyber physical system requirements.		Lichen Zhang	2014		10.1007/978-3-319-08422-0_124	systems engineering;database;computer security	EDA	-44.64691481685516	7.166826616625196	188398
d7f52a4b1820f7ce2273d2f3d0b9a0e4f5f13137	a workflow for generation of ldp		Linked Data Platform 1.0 (LDP) is the W3C Recommendation for exposing linked data in a RESTful manner. While several implementations of the LDP standard exist, deploying an LDP is still manual and tighly coupled to the chosen implementation. As a consequence, the same design (in terms of how the data is organised) is difficult to reuse in different LDP deployments. In this paper we propose a workflow for LDP generation to automatize the generation of LDPs from static, dynamic and heterogeneous data sources while keeping the design loosely coupled from the implementation.	linked data platform;loose coupling;representational state transfer	Noorani Bakerally;Antoine Zimmermann;Olivier Boissier	2018		10.1007/978-3-319-98192-5_27	linked data platform;rdf;implementation;data mining;linked data;reuse;workflow;computer science	AI	-42.47274641186129	11.21170812167361	188481
211f54d56182c561f225af76767e79c2b48b62ee	towards the automatic generation of web gis	design model;design models;web applications;automatic generation;visual language;web gis	In the present paper, we propose an approach for the development of Web GIS based on WebML, a high-level, formal visual language specifically conceived to design data-intensive Web applications. The proposal is motivated by the observation that Web GIS can be considered as a particular class of data-intensive Web applications. In the paper, we describe the extension of the visual formalism for modeling relevant interaction and navigation operations typical of Web GIS.	data-intensive computing;gis applications;geographic information system;high- and low-level;qualitative comparative analysis;semantics (computer science);visual language;web application;webml;world wide web	Sergio Di Martino;Filomena Ferrucci;Luca Paolino;Monica Sebillo;Genny Tortora;Giuliana Vitiello;Giuseppe Avagliano	2007		10.1145/1341012.1341081	web service;distributed gis;web development;web application;web modeling;data web;web mapping;web-based simulation;web design;web standards;computer science;semantic web;web navigation;social semantic web;data mining;semantic web stack;multimedia;web intelligence;programming language;world wide web	Web+IR	-42.307809744064976	10.614116221896143	188854
7037b06f978a21a636ae1caaa42daa76313fe885	thesauri and ontologies in digital libraries: 2. design, evaluation, and development	digital library;thesaurus development;classification;ontology development;design evaluation;conceptual structure;taxonomy;knowledge organization system standards;knowledge organization system;ontological engineering;ontology	This tutorial is intended for people who have a basic familiarity with the function and structure of thesauri and ontologies. It will introduce criteria for the design and evaluation of thesauri and ontologies and then deal with methods and tools for their development: Locating sources; collecting concepts, terms. and relationships to reuse existing knowledge; developing and refining thesaurus/ontology structure; software and database structure for the development and maintenance of thesauri and ontologies; collaborative development of thesauri and ontologies; developing crosswalks / mappings between thesauri/ontologies. In summing up, the tutorial will address the question of the amount of resources needed to develop and maintain a thesaurus or ontology.	digital library;library (computing);ontology (information science);thesaurus (information retrieval)	Dagobert Soergel	2002		10.1145/544220.544368	idef5;open biomedical ontologies;digital library;ontology components;biological classification;computer science;knowledge management;ontology;data mining;world wide web;information retrieval;process ontology;taxonomy	AI	-43.560419025878666	5.860901631068744	190190
eeaf7fbc71b49da6a9280b68ac4762431c1ce71f	provenance based diagnosis for scientific workflows	data provenance technology;groupware;provenance based diagnosis;scientific workflow;会议论文;workflow management software groupware scientific information systems;shared scientific workflow;workflow management software;kepler scientific workflow management system provenance based diagnosis scientific research collaborative activity shared scientific workflow data provenance technology integrated diagnosis information;kepler scientific workflow management system;diagnosis;scientific research;diagnosis scientific workflow data provenance;scientific information systems;collaborative activity;data provenance;integrated diagnosis information	Scientific research has become collaborative activities among scientists. Many scientists share data and scientific workflows with each other to facilitate scientific research. However, during using shared scientific workflows, it's hard for scientists to figure out suspicious data and processes, i.e., scientific workflow diagnosis. In this paper, we propose an approach for diagnosing scientific workflows based on the data provenance technology and reusing of diagnosis information. The main innovation of this paper is twofold: 1) By using data provenance technology, we deduce integrated diagnosis information of scientific workflows with the help of scientists' understanding of data; 2) We propose a novel model to preserve diagnosis information, and design a method to reuse the diagnosis information. We implement a prototype system based on the Kepler scientific workflow management system.	entity;kepler;prototype;real life	Jun Chen;Tun Lu;Guo Li;Tiejiang Liu;Xianghua Ding;Ning Gu	2015	2015 IEEE 19th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2015.7231018	scientific method;computer science;data science;medical diagnosis;database;world wide web;collaborative software	HPC	-45.26344920007004	7.5882946265930125	190218
616e3c503196098c1a5bbf595bec2308cd50d6bc	information product evaluation as asynchronous communication in context: a model for organizational research	map;digital library;image;satisfiability;knowledge worker;asynchronous communication;information system;information need;graphical;geographical;information search and retrieval;evaluation model;spatial	Knowledge workers are routinely engaged in information search and retrieval (ISR) tasks where they make evaluations of complex information products such as electronic documents or multi-media items. Information Systems (IS) organizations in business support the creation of these complex information products as well as providing tools and support for their acquisition and use. Some ISR assumptions, such as an information need exists independently of the ability of the repository to satisfy it, or an information need can be specified by objective terms, can be problematic for knowledge workers. An alternative approach considers information products as elements of an asynchronous communication; it explicitly considers evaluation after retrieval and the types of support provided by IS groups. General propositions about the task and context of information product evaluation are proposed and used to develop a new model (Information Product Evaluation Model) incorporating aspects of the user’s context, meta-information availability, and accessibility.	accessibility;information systems research;information needs	Lisa D. Murphy	1996		10.1145/226931.226958	cognitive models of information retrieval;computer science;knowledge management;theoretical computer science;information retrieval	Web+IR	-44.94684396949605	4.7234562056854035	190394
8e6918e2f09aa24dcc93c583a121f4f12f93aedc	anemone: an effective minimal ontology negotiation environment	multi agent system;semantic integration;semantic interoperability;ontology negotiation;ontology alignment	Communication in open heterogeneous multi agent systems is hampered by lack of shared ontologies. To overcome these problems, we propose a layered communication protocol which incorporates techniques for ontology exchange. Using this protocol, the agents gradually build towards a semantically integrated system by establishing minimal and effective shared ontologies. We tested our approach, called ANEMONE, on a number of heterogeneous news agents. We show how these agents successfully exchange information on news articles, despite initial difficulties raised by heterogeneous ontologies.	communications protocol;ontology (information science)	Jurriaan van Diggelen;Robbert-Jan Beun;Frank Dignum;Rogier M. van Eijk;John-Jules Ch. Meyer	2006		10.1145/1160633.1160794	upper ontology;semantic interoperability;ontology alignment;semantic integration;computer science;knowledge management;ontology;multi-agent system;data mining;database;ontology-based data integration;process ontology	AI	-43.79571922645389	9.275709270815598	190571
57afc010b4172a6697be09f247d42a7cf3c2b958	annotate! a tool for collaborative information retrieval	metadata clues;collaborative tools information retrieval search engines collaboration electronic switching systems xml timing reactive power hardware distributed computing;manually intensive document sifting;groupware;document handling;search session;document handling online front ends information retrieval groupware;search engines;information retrieval;user timings;collaboration;distributed computing;collaborative tools;interface layers;global usage history;online front ends;annotate;web based full text information retrieval;document annotations;search community;xml;discussion data;collaborative infrastructure;electronic switching systems;prototype implementation;spurious matches;data sets;session data;user annotations;search community annotate annotate collaborative information retrieval web based full text information retrieval spurious matches manually intensive document sifting document annotations global usage history metadata clues search session data sets xml discussion data user annotations session data user timings interface layers prototype implementation collaborative infrastructure;collaborative information retrieval;hardware;reactive power;timing	Difficulties with web-based full text information retrieval (IR) systems include spurious matches, manually intensive document sifting, and the absence of communication or coordination between users. To address these difficulties, we introduce the Annotate! system which enables document annotations, and captures global usage history. Annotate! provides improved data and metadata clues to guide the user in a search session. Two data sets, declared in XML, are at the core of Annotate! : discussiondata, a composite of documents and user annotations and sessiondata which captures user timings at the various interface layers. We discuss a prototype implementation, and show that the collaborative infrastructure enabled byAnnotate! can be predicted to improve the diffusion of ideas in the search community.	information retrieval;prototype;session (web analytics);web application;xml	Mark Ginsburg	1998		10.1109/ENABL.1998.725675	xml;computer science;database;ac power;management;world wide web;information retrieval;data set;collaboration	Web+IR	-47.69843141126244	10.630039754838116	190826
182df06cd3c911b38868d0eb1f75d5f705e584a3	layers of meaning: disentangling subject access interoperability		ieved. In order to facilitate subject access interoperability a mechanism must be built that allows the different controlled vocabularies to communicate meaning, relationships, and levels of extension and intension so that different user groups using different controlled vocabularies could access collections across the network. Switching languages, the tools of controlled vocabulary compatibility, consist of a single layer that does not allow for a flexible control of the semantic levels of meaning, relationships, and extension or intension. This paper proposes a multilayered conceptual framework wherein the levels of meaning, relationships and extension and intensio each controlled as individual parameters, rather than in a single switching langua	controlled vocabulary;documentation;game theory;information retrieval;intension;international society for knowledge organization;internet;interoperability;koch snowflake;library classification;neville's algorithm;rev;sbp;sensitivity and specificity;subject matter expert turing test;thesaurus (information retrieval)	Joseph T. Tennis	2001			database;world wide web;information retrieval	OS	-41.92962986748997	6.202440063711696	191408
a7ba69d5098903895b4a3ded5f7436077d4cea73	an experiment with ontology mapping using concept similarity	ontology mapping;information retrieval;concept mapping;indexation;ontologies;mapping;interoperability;electronic computers computer science	This paper describes a system for automatically mapping between concepts in different ontologies. The motivation for the research stems from the Diogene project, in which the project’s own ontology covering the ICT domain is mapped to external ontologies, in order that their associated content can automatically be included in the Diogene system. An approach involving measuring the similarity of concepts is introduced, in which standard Information Retrieval indexing techniques are applied to concept descriptions. A matrix representing the similarity of concepts in two ontologies is generated, and a mapping is performed based on two parameters: the domain coverage of the ontologies, and their levels of granularity. Finally, some initial experimentation is presented which suggests that our approach meets the project’s unique set of requirements.	information retrieval;ontology (information science);requirement;semantic integration	Robert Villa;Ruth Wilson;Fabio Crestani	2004			idef5;open biomedical ontologies;ontology components;computer science;data mining;database;information retrieval;process ontology	AI	-43.263984879694455	6.24056960987802	193004
928931c22dc00c7fdd2abd46fdb5da44cd72b714	ontology design approaches for development of an excise duty recommender system		Excise duty is a type of tax charged on certain products and services. Determining an excise product class can be a difficult task since the regulation written in legal language can be difficult for the users to interpret. Excise duty recommender system aims to simplify the users’ effort in product classification task and reduce errors in tax payment. This paper describes an initiative to develop excise product ontology to provide explicit and formal definitions of excise products and their classifications. It focuses on ontology design approaches for some excise products to support excise duty recommender system development. Two excise products were used as case studies: beverage and petroleum products. Steps in defining product mapping rules and developing the recommender system are described. A Semantic Web-based system architecture was adopted to enable future support for data sharing and reuse based on the Linked Data technology.	recommender system	Marut Buranarach;Taneth Ruangrajitpakorn;Chutiporn Anutariya;Vilas Wuwongse	2013		10.1007/978-3-319-08732-0_9	engineering;knowledge management;world wide web;computer security	HCI	-47.19798139350701	5.508525267777899	193230
f18db4b15682acd2fa1631b66c64918ea91dda18	information modeling	databases;application software;knowledge representation;standardization	"""Continuing the theme from the last column,1 this time I want to discuss information modeling in more detail. The central premise of the PDES/STEP exchange standardization effort is that the """"stuff"""" to be exchanged is information, but during the actual exchange the information is represented by data. The data forms used can differ according to the target computer exchange technology. The objectives of PDES can be summarized as"""	information model	Peter Wilson	1987	IEEE Computer Graphics and Applications	10.1109/MCG.1987.276941	knowledge representation and reasoning;application software;computer science;artificial intelligence;data science;operating system;open knowledge base connectivity;data mining;information retrieval;standardization	Visualization	-46.64401006723314	5.426451760472084	193478
4cfba0d12943d75272efbabd4614f38a85f1c1a8	squido, a saas web mining system for professionals	topical crawler;personalized information retrieval;competitive intelligence;web mining;information fusion;saas	Web information overload is a common issue for knowledge workers. In this application paper, we describe how Squido, a SaaS Web Mining system developed by IXXO, enables knowledge workers to get more value from their Web research.#R##N##R##N#We present Squido's main innovations, an overview of its features and market, as well as experimental results comparing the efficiency of the crawl strategies available in the product.	software as a service;web mining	François Pouilloux;Louis-Marc Perez	2010			web service;web application security;web mining;web development;web modeling;web mapping;web standards;engineering;knowledge management;web navigation;social semantic web;data mining;web intelligence;world wide web	ML	-46.722790919375775	9.016580750161618	194041
d9def2cba6a64b3307bc545e7033e41113c2ce68	ontology-based zika virus news authoring environment for the semantic web	content management system cms;semantic authoring;semantic web;authoring tool;ontology	This paper describes the experience of researching and teaching the conceptual and practical basis for the specification, modelling and design of an ontology-based news authoring environment for the Semantic Web, that takes into account the construction and use of an ontology of the Zika disease. Some CMSs are being adapted in order to receive semantic features, such as automatic generations of keywords, semantic annotation and tagging, content reviewing etc. We present here the infrastructure designed to foster research on semantic CMSs as well as semantic web technologies that can be integrated into an ontology-based news authoring environment.	semantic web	Edgard Costa Oliveira;Edison Ishikawa;Thabata Hellen Granja;Marcos Valério de Almeida Nunes;Lucas Hiroshi Hironouchi;Cristiano Costa de Souza;Rafael Batista Menegassi;Luciano Gois	2016		10.1145/3012071.3012093	upper ontology;semantic computing;bibliographic ontology;ontology inference layer;semantic grid;computer science;ontology;semantic web;ontology;social semantic web;semantic web stack;database;ontology-based data integration;semantic technology;world wide web;owl-s;information retrieval;semantic analytics	Web+IR	-41.60392635512399	6.443299714406884	194587
d286ab86e4cb9850081c219217b57880ff05ab74	service-oriented grids and problem solving environments	qa75 electronic computers computer science	The Internet’s continued rapid growth is creating an untapped environment containing a large quantity of highly competent computing resources suitable for exploitation in existing capacity-constrained and new innovative capability-driven distributed applications. The Grid is a new computing model that has emerged to harness these resources in a manner that fits the problem solving process needs of the computational engineering#N#design community. Their unique requirements have created specific challenges for Grid technologies to bring interoperability, stability, scalability and flexibility, in addition to, transparent integration and generic access to disparate computing resources within and across institutional boundaries. The emergence of maturing open standards based service-oriented (SO) technologies has fulfilled the fundamental requirements of interoperability, leaves a flexible framework onto which sophisticated system architectures may be built, and provides a suitable base for the development of future Grid technologies. The work presented in this thesis is motivated by the desire to identify, understand, and resolve important challenges#N#involved in the construction of Grid-enabled Problem Solving Environments (PSE) using SO technologies. The work explains why they are appropriate for Grid computing and successfully demonstrates the application and benefits of applying SO technologies in the scenarios of Computational Micromagnetics and Grid-enabled Engineering Optimisation and Design Search (Geodise) systems. Experiences achieved through the work can also be of referential value to future application of Grid computing in different areas.	problem solving;service-oriented architecture;service-oriented device architecture	Matthew J. Fairman	2004			simulation;computer science;theoretical computer science;management science;grid computing	AI	-45.681107210159645	10.612255305561193	195445
ca7f6b91ef1e8631bdf7679ed123847cbfb8f232	linguistically motivated ontology-based information retrieval		When Tim Berners-Lee proposed his vision of the Semantic Web in 2001, he thought of machines that automatically execute specific tasks based on available knowledge. The knowledge should be captured within ontologies which provide an unambiguous and semantically rich way to capture information. The information could further be used to enhance tasks like information retrieval, i.e., the retrieval of documents which match specific criteria. Over a decade later, technologies which are required for the Semantic Web have been established in several areas, e.g., the biological and medical domains. Both share a very constant pool of knowledge, which does not change as rapidly as in other domains, i.e., neither a lot of new knowledge must be added continuously nor the existing knowledge has to be updated very often. These circumstances make both domains suitable for manually creating ontologies. However, in case of a domain with constantly incoming new knowledge, it would be a great advantage if this knowledge could automatically be added or matched to an ontology. However, there is nearly no concept available on how ontological knowledge can be mapped to natural language precisely. We therefore developed the SE-DSNL approach. It provides experts with the ability to specify how ontological knowledge can be mapped to linguistic information of any known language. The concept provides a flexible and generic meta model which captures all the relevant information. In order to use this for parsing natural language text a prototypical implementation has been developed which takes the information of a SEDSNL model and applies it to a given input text. The result is a semantic interpretation of the input text which maps its lexical and syntactic elements to the ontology. The direct integration of semantic and linguistic information further allows using the semantic information at runtime. This yields certain advantages which are demonstrated by treating elaborate linguistic phenomena like pronominal anaphora resolution, word sense disambiguation, vagueness and reference transfer. To show the validity of the approach it has been evaluated using scenarios and two case studies.	anaphora (linguistics);information retrieval;java platform, standard edition;map;metamodeling;natural language;ontology (information science);parsing;run time (program lifecycle phase);semantic web;semantic interpretation;vagueness;word sense;word-sense disambiguation	Wolf Fischer	2013				AI	-41.154033453620045	7.933152238084887	195490
256428b06cde1b7c00a837a21d72968f617ab7a4	a step-by-step debugging technique to facilitate mashup development and maintenance	debugging;web documents;web pages;dependence graph;web data aggregation;data aggregation;mashup	"""With Web mashups, data from different Web documents and services are """"mashed"""" together to create a new functionality. The mashup developer usually has a clear vision of the desired output, i.e., the resulting Web page to present to the end user. Complex mashups require multiple processing steps, and become hard to debug if the delivered result is not as expected. In this paper we propose an approach that supports step-by-step debugging for declarative development of data mashups. A dependency graph is constructed from the mashup definition, and developers are able to define breakpoints to inspect a snapshot of the running mashup execution. A Web 2.0 application visualizes the intermediate results in each processing step. On top of that, it is possible to specify expected and unexpected result elements. If the result does not comply with the specifications, the platform helps to identify the processing step which caused the error."""	breakpoint;debugging;mashup (web application hybrid);snapshot (computer storage);web 2.0;web page	Waldemar Hummer;Philipp Leitner;Schahram Dustdar	2010		10.1145/1944999.1945006	web service;web modeling;computer science;web page;data mining;database;world wide web;mashup	DB	-41.59066802274001	10.82465120908877	195631
fef27a7b2b97d5e4a75768f6d8defa5f3dbe9a93	integrating domain ontologies into knowledge-based systems	knowledge based system;conceptual graph;knowledge representation;domain ontology	The work presented in this paper deals with the integration of heavyweight ontologies into Knowledge-Based Systems (KBS). We claim that such ontologies have to be built at the conceptual level, and that their use in a KBS requires an operationalization step, that consists in transcribing the ontology in an operational knowledge representation language according to a given scenario of use. For this purpose, we propose TooCoM, a tool based on the Conceptual Graphs model and dedicated to the edition and the operationalization of heavyweight ontologies.	conceptual graph;knowledge representation and reasoning;knowledge-based systems;ontology (information science)	Frédéric Fürst;Francky Trichet	2005			conceptual graph;knowledge representation and reasoning;idef5;computer science;knowledge management;artificial intelligence;knowledge-based systems;data mining	AI	-43.616538155827264	5.643047040363468	195779
54b76f7c249f56f3b17b8273a2d01903e19cb30c	extending webml towards semantic web	inf;web engineering;conceptual model;development process;design method;semantic web;ontology	Available methodologies for developing Sematic Web applications do not fully exploit the whole potential deriving from interaction with ontological data sources. Here we introduce an extension of the WebML modeling framework to fulfill most of the design requirements emerging for the new area of Semantic Web. We generalize the development process to support Semantic Web applications and we introduce a set of new primitives for ontology importing and querying.	requirement;semantic web;web application;webml	Federico Michele Facca;Marco Brambilla	2007		10.1145/1242572.1242783	web service;web modeling;semantic web rule language;data web;web design;design methods;ontology inference layer;web standards;computer science;conceptual model;semantic web;ontology;social semantic web;data mining;semantic web stack;database;web intelligence;web engineering;world wide web;owl-s;software development process;semantic analytics	Web+IR	-42.84068734798995	10.636418347577717	196201
3abb4e7464ddd409edff96dc72cf2abf30688082	semantic based support for visualisation in complex collaborative planning environments	thesis or dissertation;semantic web;informatics	Visualisation in intelligent planning systems [Ghallab et al., 2004] is a subject that has not been given much attention by researchers. Among the exis ting planning systems, some “well known planners” do not propose a solution for visu alisation at all, while others only consider a single approach when this solution so metimes is not appropriate for every situation. Thus, users cannot make the most of planning systems because they do not have appropriate support for interaction with them. This proble m is further enhanced when considering mixed-initiative planning systems, where age nts that are collaborating in the process have different backgrounds, are playing differ ent roles in the process, have different capabilities and responsibilities, or are using different devices to interact and collaborate in the process. To address this problem, we propose a general framework for v isualisation in planning systems that will give support for a more appropriate vi sualisation mechanism. This framework is divided into two main parts: a knowledge re presentation aspect and a reasoning mechanism for multi-modality visualisation. T he knowledge representation uses the concept of ontology to organise and model compl ex domain problems. The reasoning mechanism gives support to reasoning about th e visualisation problem based on the knowledge bases available for a realistic colla borative planning environment, including agent preferences, device features, plann ing i formation, visualisation modalities, etc. The main result of the reasoning mechanism is an appropriate visualisation modality for each specific situation, which provide s a better interaction among agents (software and human) in a collaborative planning env iro ment. The main contributions of this approach are: (1) it is a gener al and extensible framework for the problem of visualisation in planning syst ems, which enables the modelling of the domain from an information visualisation p erspective; (2) it allows a tailored approach for visualisation of information in an A I collaborative planning environment; (3) its models can be used separately in other p roblems and domains; (4) it is based on real standards that enable easy communication and interoperability with other systems and services; and (5) it has a broad potential f or its application on the Semantic Web.	enterprise resource planning;env;information visualization;interoperability;knowledge representation and reasoning;mathematical optimization;modality (human–computer interaction);semantic web	Natasha Correia Queiroz Lino	2007			semantic computing;semantic search;semantic grid;computer science;knowledge management;data science;semantic web;social semantic web;semantic web stack;world wide web;semantic analytics	AI	-44.38142671929266	9.398849230602004	196278
38102a982637e37e7a4667ca7ed980315b78de86	interoperability in data warehouses.	data warehouse	The term refers to the ability of combining the content of two or more heterogeneous data warehouses, for the purpose of cross-analysis. This need emerges in a variety of practical situations. For instance, when different designers of a large company develop their data marts independently, or when different organizations involved in the same project need to integrate their data warehouses. Data Warehouse interoperability is a special case of the general problem of database integration, but it can be tackled in a more systematic way because data warehouses are structured in a rather uniform way, along the widely accepted concepts of dimension and fact. As it happens in the general case, different degrees of interoperability can be pursued by adopting standards and/or by applying reconciliation techniques, likely specific for this context. The problem is becoming increasingly relevant with the spreading of federated architectures. Nevertheless, it has been the focus of a few systematic works and numerous open problems remain to be solved.	heterogeneous database system;interoperability	Riccardo Torlone	2009		10.1007/978-0-387-39940-9_207	systems engineering;interoperability;data integration;data warehouse;special case;computer science	DB	-46.501129484094626	6.758496838823805	196714
6f834aa475a4d7c208ad24dad253e3db67a376b7	grounding the foundations of ontology mapping on the neglected interoperability ambition		The problem of ontology mapping has attracted considerable attention over the last few years, as the usage of ontologies is increasing. In this paper, we revisit the fundamental assumptions that drive the mapping process. Based on real-world use cases, we identify two distinct goals for mapping, which are: (i) ontology development and (ii) facilitating interoperability. Most of current research on ontology mapping has been focused on ontology development and is rooted in the seminal work of McGuinness and Noy in 2000. For example, the well studied problem of ontology merging is an ontology development task. Note that with the increase in the number of information systems that utilize ontologies, facilitating interoperability between these systems is becoming more critical. We compare interoperability to the information integration problem in databases. As a result of this comparison, class matching is emphasized, as opposed to the matching of other entities in an ontology. To the best of our knowledge, this is the first work that distinguishes facilitating interoperability, from ontology development and merging.	autonomous robot;database;entity;information system;interoperability;ontology (information science);ontology merging;pattern matching;semantic integration;web ontology language;whole earth 'lectronic link	Hamid Haidarian Shahri;James A. Hendler;Donald Perlis	2008			information integration;semantic integration;ontology;information system;interoperability;ontology (information science);computer science;ontology merging;knowledge management;upper ontology	Web+IR	-43.69496170684391	5.093755684724399	196780
b6461b5cd1a0abc47369cfe2f74a8a0273223870	user-centric access to e-government information: e-citizen discovery of e-services		Effective and timely user access to public information is one of the most fundamental requirements for e-government and e-democracy. In this context, the discovery of e-services available to citizens plays a very important role, because it represents one of the most frequent points of contact between public administrations and citizens. We present a solution, based on dynamic taxonomies, to end-user discovery of e-services. Differently from mainstream research in semantic web, the solution we propose is intended for the direct use of end-users, rather than for programmatic or agent-mediated access.	e-government;e-services;requirement;semantic web	Giovanni Maria Sacco	2006			artificial intelligence;e-government;semantic web;e-services;knowledge management;machine learning;computer science;mainstream;user-centered design	AI	-46.245664792835555	10.0919827822762	197077
b4630e124d7853c8eef410c66c0dedf42d5f3784	structured feedback: a distributed protocol for feedback and patches on the web of data		The World Wide Web is an infrastructure to publish and retrieve information through web resources. It evolved from a static Web 1.0 to a multimodal and interactive communication and information space which is used to collaboratively contribute and discuss web resources, which is better known as Web 2.0. The evolution into a Semantic Web (Web 3.0) proceeds. One of its remarkable advantages is the decentralized and interlinked data composition. Hence, in contrast to its data distribution, workflows and technologies for decentralized collaborative contribution are missing. In this paper we propose the Structured Feedback protocol as an interactive addition to the Web of Data. It offers support for users to contribute to the evolution of web resources, by providing structured data artifacts as patches for web resources, as well as simple plain text comments. Based on this approach it enables crowd-supported quality assessment and web data cleansing processes in an ad-hoc fashion most web users are familiar with.	hoc (programming language);multimodal interaction;patch (computing);semantic web;web 2.0;web resource;world wide web	Natanael Arndt;Kurt Junghanns;Roy Meissner;Philipp Frischmuth;Norman Radtke;Marvin Frommhold;Michael Martin	2016			distributed computing;computer science	Web+IR	-41.20307553773435	9.993769366873432	197392
ac56eaad972c573760df6319afbc8e157ea16b1d	generic adaptation framework: a process-oriented perspective	informacion documentacion;ciencias sociales	Adaptive Hypermedia Systems (AHS) have long been mostly domainor application-specific systems. Existing reference models provide domain-independent high-level descriptions of AHS. They focus on abstract data structures and only briefly describe the adaptation process in a generic way. In this paper we consider the process aspects of AHS from the very first classical user modelling-adaptation loop to a generic detailed flowchart of the adaptation in AHS. We introduce a Generic Adaptation Process (GAP) and by aligning it with a layered (data-oriented) AHS architecture we show that it can serve as the process part of a new reference model for AHS.	abstract data type;adaptive hypermedia;adaptive system;data structure;flowchart;high- and low-level;interoperability;koch snowflake;ontology (information science);platoon (automobile);recommender system;reference model;systems design;systems engineering;web search engine;whole earth 'lectronic link	Evgeny Knutov;Paul De Bra;Mykola Pechenizkiy	2011	J. Digit. Inf.		simulation;computer science;distributed computing	NLP	-42.88359571704055	10.285988666321312	197560
207f8a045e9e06061cbe6be1002f005fbef0cd4f	realizing and maintaining aggregative digital library systems: d-net software toolkit and oaister system	digital library	"""Aggregative Digital Library Systems (ADLSs) provide end users with web portals to operate over an information space of descriptive metadata records, collected and aggregated from a pool of possibly heterogeneous repositories. Due to the costs of software realization and system maintenance, existing """"traditional"""" ADLS solutions are not easily sustainable over time for the supporting organizations. Recently, the DRIVER EC project proposed a new approach to ADLS construction, based on Service-Oriented Infrastructures. The resulting D-NET software toolkit enables a running, distributed system in which one or multiple organizations can collaboratively build and maintain their service-oriented ADLSs in a sustainable way. In this paper, we advocate that D-NET's """"infrastructural"""" approach to ADLS realization and maintenance proves to be generally more sustainable than """"traditional"""" ones. To demonstrate our thesis, we report on the sustainability of the """"traditional"""" OAIster System ADLS, based on DLXS software (University of Michigan), and those of the """"infrastructural"""" DRIVER ADLS, based on D-NET."""	digital library;distributed computing;oaister;portals;service-oriented device architecture;service-oriented software engineering	Paolo Manghi;Marko Mikulicic;Leonardo Candela;Donatella Castelli;Pasquale Pagano	2010	D-Lib Magazine	10.1045/march2010-manghi	digital library;computer science;world wide web	SE	-47.04663145805594	10.489623271645648	197861
bab85aa9731f5569f2b772464cbd9fb937c58559	a semantic web data retrieval implementation with an adaptive model for supporting agent decision structures	decision models;learning effectiveness;web pages;data distribution;agents;adaptive learning;data access;semantic web;data retrieval;ontology	This paper proposes an adaptive learning approach that yields decision models that can be applied by a transactions agent. This model can learn effectively with a variety of data distributions. This research uses the Semantic Web as a data access approach. The Semantic Web is a method that sellers can use to publish semantically meaningful information on Websites so automated applications can reliably access that information. We implemented a Semantic Web composed of 30 vendors' Web pages and a spider to search those pages to obtain product and vendor information. This information was used to train a learning agent, which then provided a decision model to a transaction agent.	data retrieval;semantic web	James V. Hansen;James B. McDonald;Conan C. Albrecht;Douglas L. Dean;Bonnie Brinton Anderson	2007	Electronic Commerce Research	10.1007/s10660-006-0060-1	web service;data access;decision model;semantic computing;web modeling;data web;web mapping;semantic search;semantic grid;web standards;computer science;software agent;semantic web;web navigation;ontology;social semantic web;web page;linked data;data mining;semantic web stack;web intelligence;world wide web;owl-s;website parse template;adaptive learning;data retrieval;information retrieval;semantic analytics;web server	Web+IR	-41.10496491195772	8.310274291403676	199882
