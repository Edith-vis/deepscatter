id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
0a8c824f749ab759c2e5462568deef72d2722126	an automatic assembling system for sealing rings based on machine vision		In order to grab and place the sealing rings of battery lid quickly and accurately, an automatic assembling system for sealing rings based on machine vision is developed in this paper. The whole system is composed of the light sources, cameras, industrial control units, and a 4-degree-of-freedom industrial robot. Specifically, the sealing rings are recognized and located automatically with the machine vision module. Then industrial robot is controlled for grabbing the sealing rings dynamically under the joint work of multiple control units and visual feedback. Furthermore, the coordinates of the fast-moving battery lid are tracked by the machine vision module. Finally the sealing rings are placed on the sealing ports of battery lid accurately and automatically. Experimental results demonstrate that the proposed system can grab the sealing rings and place them on the sealing port of the fast-moving battery lid successfully. More importantly, the proposed system can improve the efficiency of the battery production line obviously.	algorithm;assembly language;error detection and correction;image processing;industrial robot;machine vision;motion planning;record sealing;requirement;sorting	Mingyu Gao;Xiao Li;Zhiwei He;Yuxiang Yang	2017	J. Sensors	10.1155/2017/4207432	embedded system;computer hardware;engineering;engineering drawing	Robotics	60.5587105747557	-39.47663334200405	191065
6d61290d0473bdce1abc7de141894112a4e87ca0	improving the accuracy of ekf-based visual-inertial odometry	nonlinear filters;extended kalman filter accuracy improvement ekf based visual inertial odometry vio performance improvement jacobian matrices observability analysis ekf linearized system model yaw multistate constraint kalman filter algorithm msckf algorithm;ekf based visual inertial odometry;vio;kalman filters;transportation computer vision distance measurement inertial navigation jacobian matrices kalman filters nonlinear filters object tracking pose estimation;inertial navigation;kalman filter;ekf linearized system model;observability analysis;linear system;computer vision;accuracy improvement;distance measurement;performance improvement;msckf algorithm;state constraints;object tracking;transportation;multistate constraint kalman filter algorithm;extended kalman filter;jacobian matrices;yaw;pose estimation	In this paper, we perform a rigorous analysis of EKF-based visual-inertial odometry (VIO) and present a method for improving its performance. Specifically, we examine the properties of EKF-based VIO, and show that the standard way of computing Jacobians in the filter inevitably causes inconsistency and loss of accuracy. This result is derived based on an observability analysis of the EKF's linearized system model, which proves that the yaw erroneously appears to be observable. In order to address this problem, we propose modifications to the multi-state constraint Kalman filter (MSCKF) algorithm [1], which ensure the correct observability properties without incurring additional computational cost. Extensive simulation tests and real-world experiments demonstrate that the modified MSCKF algorithm outperforms competing methods, both in terms of consistency and accuracy.	algorithm;algorithmic efficiency;computation;computational complexity theory;experiment;extended kalman filter;iterative method;observable;odometry;simulation;smoothing;stochastic matrix;yaws	Mingyang Li;Anastasios I. Mourikis	2012	2012 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2012.6225229	kalman filter;control engineering;computer vision;computer science;control theory;mathematics	Robotics	54.71000147680154	-39.54748353626273	191382
83833a08000e77ad1253b629f67705e35236bfa8	coarse, inexpensive, infrared tracking for wearable computing	azimuth;tracking system;data integrity;user interface;wearable computers;kalman filter;testing;radio transmitters;indoor environment;taxonomy;wearable computer;computer science;augmented reality;infrared;user interfaces;optical receivers;wearable computers optical receivers testing computer science user interfaces azimuth augmented reality costs taxonomy radio transmitters	We present a novel, inexpensive, coarse tracking system that determines a person’s approximate 2D location and 1D head orientation in an indoor environment. While this coarse tracking cannot support precise registration of overlaid material, it can be used to drive user interfaces that can adapt to the quality of tracking available. Our approach uses a set of strong infrared beacons, each of which broadcasts a unique ID. The beacons are deployed in the environment such that their zones of influence strategically overlap, partitioning the area of coverage into a set of uniquely identifiable fragments. We use a compound, omnidirectional infrared receiver, composed of a set of individual, directional infrared receivers, to infer 2D position (parallel to the ground plane) and 1D orientation (azimuth), employing a Kalman-filter–based architecture for smoothing and data integration with other tracking systems available. To test our ideas, we have applied them to a prototype head tracker, and present results from our tests.	approximation algorithm;kalman filter;prototype;smoothing;tracking system;user interface;wearable computer	Drexel Hallaway;Tobias Höllerer;Steven K. Feiner	2003		10.1109/ISWC.2003.1241396	embedded system;computer vision;simulation;engineering	Robotics	57.6250221766762	-39.02961406118275	192643
a6e1ffa5860b17b578eed7552b02e9ada17eb16e	a dual source, parallel architecture for computer vision	cluster algorithm;data parallel;object recognition;occam2 pattern recognition systems pattern perception image processing artificial intelligence mathematics;edge detection;computer vision;thesis;multi source data;parallel vision;parallel architecture;cooperative processing;concurrent process	We present a parallel architecture for object recognition and location based on concurrent processing of depth and intensity image data. Parallel algorithms for curvature computation and segmentation of depth data into planar or curved surface patches, and edge detection and segmentation of intensity data into extended linear features, are described. Using this feature data in comparison with a CAD model, objects can be located in either depth or intensity images by a parallel pose clustering algorithm. The architecture is based on cooperating stages for low/intermediate level processing and for high level matching. Here, we discuss the use of individual components for depth and intensity data, and their realisation and integration within each parallel stage. We then present an analysis of the performance of each component, and of the system as a whole, demonstrating good parallel execution from raw image data to final pose.	3d modeling;central processing unit;clock rate;cluster analysis;computation;computer multitasking;computer vision;computer-aided design;data parallelism;data structure;dynamic data;dynamization;edge detection;feature data;generalised hough transform;high-level programming language;mimd;outline of object recognition;parallel algorithm;parallel computing;raw image format;region growing;rejection sampling;scalability;single-source data;source data;speedup;transputer;workstation	Andrew M. Wallace;Greg J. Michaelson;Norman Scaife;W. J. Austin	1998	The Journal of Supercomputing	10.1023/A:1007925309764	computer vision;parallel computing;edge detection;computer science;theoretical computer science;cognitive neuroscience of visual object recognition;machine learning	Robotics	57.91741691725458	-43.94618979179306	193200
6f3c9b80b658836b7b60b3f6842dc74aa659c8b2	an improved method for restoring the shape of 3d point cloud surfaces		Building﻿3D﻿objects﻿or﻿reconstructing﻿their﻿surfaces﻿from﻿3D﻿point﻿cloud﻿data﻿are﻿researched﻿activities﻿ in﻿the﻿field﻿of﻿geometric﻿modeling﻿and﻿computer﻿graphics.﻿In﻿the﻿recent﻿years,﻿they﻿are﻿also﻿studied﻿ and﻿used﻿in﻿some﻿fields﻿such﻿as:﻿graph﻿models﻿and﻿simulation;﻿image﻿processing﻿or﻿restoration﻿of﻿ digital﻿heritages.﻿This﻿article﻿presents﻿an﻿improved﻿method﻿for﻿restoring﻿the﻿shape﻿of﻿3D﻿point﻿cloud﻿ surfaces.﻿The﻿method﻿is﻿a﻿combination﻿of﻿creating﻿a﻿Bezier﻿surface﻿patch﻿and﻿computing﻿tangent﻿ plane﻿of﻿3D﻿points﻿to﻿fill﻿holes﻿on﻿a﻿surface﻿of﻿3D﻿point﻿clouds.﻿This﻿method﻿is﻿described﻿as﻿follows:﻿ at﻿first,﻿a﻿boundary﻿for﻿each﻿hole﻿on﻿the﻿surface﻿is﻿identified.﻿The﻿holes﻿are﻿then﻿filled﻿by﻿computing﻿ Bezier﻿curves﻿of﻿surface﻿patches﻿to﻿find﻿missing﻿points.﻿After﻿that,﻿the﻿holes﻿are﻿refined﻿based﻿on﻿ two﻿steps﻿(rough﻿and﻿elaborate)﻿to﻿adjust﻿the﻿inserted﻿points﻿and﻿preserve﻿the﻿local﻿curvature﻿of﻿the﻿ holes.﻿The﻿contribution﻿of﻿the﻿proposed﻿method﻿has﻿been﻿shown﻿in﻿processing﻿time﻿and﻿the﻿novelty﻿ of﻿combined﻿computation﻿in﻿this﻿method﻿has﻿preserved﻿the﻿initial﻿shape﻿of﻿the﻿surface KEywoRDS Bezier Surface, Hole Boundary, Hole Filling, Point Clouds, Shape Restoring, Tangent Plane		Sinh Van Nguyen;Ha Manh Tran;M. Tran	2018	IJSE	10.4018/IJSE.2018070103	psychology;point cloud;artificial intelligence;machine learning	Vision	59.949919583740545	-43.92263839934096	193458
848878b1b2f285d5f931c3205d083ac6d2dadbbd	design and implementation of low-cost lk optical flow computation for images of single and multiple levels		Lucas-Kanade (LK) optical flow algorithm is widely used for moving object detection and tracking by computing the motion vectors of pixels in image sequences. Due to the high computation complexity, optical flow computation is one of the crucial operations in many computer vision applications. This paper presents a low-cost hardware implementation of the LK optical flow algorithm. In particular, we design a low-cost divider used in the matrix inversion, leading to significant reduction in delay and area for calculation of small optical flow vectors. Furthermore, we also design a pyramidal LK optical flow computation unit that can process images of different sizes in order to increase the magnitude range of optical flow vectors.	algorithm;computation;computer vision;lucas–kanade method;maximum flow problem;object detection;optical flow;pixel;the matrix	Shen-Fu Hsiao;Chen-Yen Tsai	2018	2018 21st Euromicro Conference on Digital System Design (DSD)	10.1109/DSD.2018.00057	parallel computing;computation;optical filter;pixel;magnitude (mathematics);filter (signal processing);object detection;matrix (mathematics);electronic engineering;computer science;optical flow	Vision	57.49954307896275	-41.79362896075701	193629
19c20c22a33013f12c31614ff2541582ae50195e	nuts positioning system based on machine vision	binarization processing;canny edge extraction;gaussian filter;hough transform;machine vision	Aiming at the problems of high error ration,high labor intensity and low efficient for manual static adjustment of screws and nuts,an intelligent nut positioning system in the overload detection part of low-voltage circuit breaker production line was designed. Machine vision technology was taken into the detection unit of the production line. The images of hexagon nut were real-time captured by the CCD camera and processed with image processing technologies such as binarization processing,Gaussian filter,Canny edge extraction,Hough transform etc. Then the center point position of the hexagon nut was found,and was used to screws and nuts assembly. The system has already been qualified and accepted by factory's customer,and runs very well.		Rui Li	2013		10.1007/978-3-642-37502-6_129	embedded system;computer vision;engineering;engineering drawing	Robotics	60.34357221113934	-39.6794074608907	194118
9e2b9467bf8631fd924fd01c6cdfc0767493a88c	single-lens low-disparity stereo using microlenses	focusing;image processing;stereovision;microprisms;microlenses;technology and engineering;blur;calibration;parallel processing	In the framework of the 3-SIS project, we are designing a three-channel miniature camera using an integrated block-based processor and on-chip parallel (SIMD) image processing. This paper describes a single-lens stereo algorithm that we are planning to implement on the narrow-angle channel of the camera. Using microlenses on the sensor delivers a chessboard-like interlaced stereo pair exploiting opposite areas of the lens pupil. As the stereo base is limited by the lens aperture, disparities have very low values; choosing adequate focusing (depending on the scene) and prism deflection angles will give disparities between -1 and 1, which can be measured using local processing only involving directly neighbouring pixels, which is well adapted to the parallel image processing primitives. Subpixel correlation allows real-time, low precision but quasi-dense range information, which may be exploited as an extra clue into the image segmentation process.	binocular disparity	Jean Louchet;Peter Veelaert	2013	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2013.03.003	parallel processing;stereo camera;computer vision;calibration;image processing;computer science;stereopsis;computer graphics (images)	Embedded	57.71859615579944	-44.03698836540581	198325
d457f1d05b46da8f5b9842056a9e6a9577be9cfd	research on tool wear detection based on machine vision in end milling process	end milling;image processing;machine vision;tool wear measurement	This paper suggests a novel technique for the tool wear measurement based on machine vision. Tool images are captured between cutting operations using a machine vision system. The gray value difference threshold is determined from the tool image itself and the reference line is found to locate the tool in the image. The edges of the tool wear region are extracted by column scanning. A method of continuity testing is used to find the correct edge position in each wear column. To achieve a more accurate result, the sub-pixel edge detection technology is adopted to extract the edges. Finaly, the tool wear parameters can be obtained after rebuilding the top edge of the wear region and determining the bottom edge of the wear region. The measurement results gotten by the proposed method are compared with those gotten by measuring directly with a microscope. The proposed scheme is shown to be reliable and effective for the automated tool wear measurement.	algorithm;angularjs;edge detection;experiment;machine vision;online and offline;pixel;scott continuity;wear leveling	Jilin Zhang;Song Guo;Laishui Zhou	2012	Production Engineering	10.1007/s11740-012-0395-5	computer vision;engineering;forensic engineering;engineering drawing	Robotics	60.16655291941601	-41.01151860494443	198493
0a740dc92e0c53b7dc15a92a4bd8a9c85fe54f51	ambulatory measurement of three-dimensional foot displacement during treadmill walking using wearable wireless ultrasonic sensor network	drntu science medicine biomedical engineering;acoustics;ultrasonic devices biomedical equipment body sensor networks displacement measurement gait analysis image sensors mean square error methods motion measurement patient monitoring patient rehabilitation synchronisation;ultrasonic variables measurement;foot;journal article;mobile communication foot biomedical measurement acoustics tracking ultrasonic variables measurement cameras;mobile communication;camera based tracking system ambulatory measurement three dimensional foot displacement treadmill walking wearable wireless ultrasonic sensor network human motion monitoring rehabilitation gait analysis athletic performance analysis 3d foot trajectory measurements ultrasonic transmitter receivers fixed known positions radiofrequency module wireless data transmission rf module synchronization clock time of arrival ultrasonic signal anchor position signal travels mobile resides toa based tracking technique camera based motion capture system net root mean square error 3d displacement lightweight feature;biomedical measurement;cameras;tracking	Techniques that could be used to monitor human motion precisely are helpful in various applications such as rehabilitation, gait analysis, and athletic performance analysis. This paper focuses on the 3-D foot trajectory measurements based on a wearable wireless ultrasonic sensor network. The system consists of an ultrasonic transmitter (mobile) and several receivers (anchors) with fixed known positions. In order not to restrict the movement of subjects, a radio frequency (RF) module is used for wireless data transmission. The RF module also provides the synchronization clock between mobile and anchors. The proposed system measures the time-of-arrival (TOA) of the ultrasonic signal from mobile to anchors. Together with the knowledge of the anchor's position, the absolute distance that the signal travels can be computed. Then, the range information defines a circle centered at this anchor with radius equal to the measured distance, and the mobile resides within the intersections of several such circles. Based on the TOA-based tracking technique, the 3-D foot trajectories are validated against a camera-based motion capture system for ten healthy subjects walking on a treadmill at slow, normal, and fast speeds. The experimental results have shown that the ultrasonic system has sufficient accuracy of net root-mean-square error (4.2 cm) for 3-D displacement, especially for foot clearance with accuracy and standard deviation (0.62 ± 7.48 mm) compared to the camera-based motion capture system. The small form factor and lightweight feature of the proposed system make it easy to use. Such a system is also much lower in cost compared to the camera-based tracking system.	athletic performance;displacement mapping;ephrin type-b receptor 1, human;gait analysis;html element;information theory;kinesiology;motion capture;psychologic displacement;radio frequency;small form factor;speed (motion);standard deviation;time of arrival;tracking system;transmitter device component;treadmill, device;ultrasonics (sound);wearable computer;travel	Yongbin Qi;Cheong Boon Soh;Erry Gunawan;Kay Soon Low	2015	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2014.2316998	embedded system;simulation;mobile telephony;computer science;tracking;foot	Mobile	57.693874199451336	-38.30815927323392	198572
