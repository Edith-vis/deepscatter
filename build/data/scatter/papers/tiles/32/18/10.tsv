id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
2e33a1dfceb8c79c7aa97a975d7f2734a96baa83	microblog sentiment classification using parallel svm in apache spark		In the information age, sentiment classification of internet topics is of great significance. This paper proposes a microblog sentiment classification approach with parallel support vector machine (SVM). The proposed method integrates the features of microblog with preprocessing to ensure the data suitable for sentiment classification. After the preprocessing process, Apache Spark parallel SVM is used to execute the classification. SVM is one of the most popular algorithms in text classification. It fits small scale and nonlinear problems. However, SVM takes very long when dealing with big data. We apply Spark to parallelize SVM with Radial Basis Function (RBF) kernel function. The introduction of Apache Spark results in outstanding performance in machine learning compared to Hadoop. The experiments show that Spark increases the execution speed of SVM significantly. At the same time the classification accuracy is also increased by information gain (IG) approach in the preprocessing and kernel function parameter selection.	algorithm;apache hadoop;apache spark;big data;document classification;experiment;fits;feature vector;information gain in decision trees;kullback–leibler divergence;machine learning;nonlinear system;parameter (computer programming);preprocessor;radial basis function kernel;support vector machine	Bo Yan;Zijiang Yang;Yitian Ren;Xing Tan;Eric Liu	2017	2017 IEEE International Congress on Big Data (BigData Congress)	10.1109/BigDataCongress.2017.43	kernel (statistics);support vector machine;kernel (linear algebra);computer science;data mining;big data;feature extraction;preprocessor;spark (mathematics);artificial intelligence;machine learning;statistical classification;pattern recognition	ML	12.588923009612337	-36.484245314781504	159113
7f431e0c93d6707f690542bdb26f7a093eed127b	distributed adaptive importance sampling on graphical models using mapreduce	mapreduce adaptive importance sampling approximate inference;learning artificial intelligence importance sampling inference mechanisms;adaptive importance sampling;sequential method distributed adaptive importance sampling graphical models mapreduce machine learning algorithms approximate inference algorithms exact inference algorithms exponential time space complexity propagation based algorithms ais benchmark networks;inference algorithms approximation algorithms graphical models monte carlo methods proposals indexes accuracy;approximate inference;mapreduce	In the case of a graphical model, machine learning algorithms used to evaluate a query can be broadly classified into exact and approximate inference algorithms. Exact inference algorithms use only network parameters to evaluate a query. However, these algorithms are typically intractable on large networks due to exponential time and space complexity. Approximate inference algorithms are widely used in practice to overcome this constraint, with a trade-off in accuracy. It includes sampling and propagation-based algorithms. These approximate algorithms may also suffer from scalability issues if applied on large networks, for achieving higher accuracy. To address this challenge, we have designed and implemented several MapReduce-based distributed versions of a specific type of approximate inference algorithm called Adaptive Importance Sampling (AIS). We compare and evaluate the proposed approaches using benchmark networks. Experimental results show that our proposed approaches achieve significant scaleup and speedup compared to the sequential method, while achieving similar accuracy asymptotically.	apache hadoop;approximation algorithm;benchmark (computing);complex network;dspace;graphical model;importance sampling;machine learning;mapreduce;sampling (signal processing);scalability;software propagation;speedup;time complexity	Ahsanul Haque;Swarup Chandra;Latifur Khan;Charu C. Aggarwal	2014	2014 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2014.7004280	adaptive neuro fuzzy inference system;computer science;theoretical computer science;machine learning;data mining	ML	13.811092698385284	-36.675290590635875	159422
31765db61cc909da023916533718d0d05ed8347e	scaling up the accuracy of bayesian network classifiers by m-estimate	bayesian network classifier;laplace estimate;estimation method;naive bayes;m estimate;classification;scaling up;bayesian network classifiers;tree augmented naive bayes;probability estimation	In learning Bayesian network classifiers, estimating probabilities from a given set of training examples is crucial. In many cases, we can estimate probabilities by the fraction of times the events is observed to occur over the total number of opportunities. However, when the training examples are not enough, this probability estimation method inevitably suffers from the zero-frequency problem. To avoid this practical problem, Laplace estimate is usually used to estimate probabilities. Just as we all know, m-estimate is another probability estimation method. Thus, a natural question is whether a Bayesian network classifier with m-estimate can perform even better. Responding to this question, we single out a special m-estimate method and empirically investigate its effect on various Bayesian network classifiers, such as Naive Bayes (NB), Tree Augmented Naive Bayes (TAN), Averaged One-Dependence Estimators (AODE), and Hidden Naive Bayes (HNB). Our experiments show that the classifiers with our m-estimate perform better than the ones with Laplace estimate.	bayesian network	Liangxiao Jiang;Dianhong Wang;Zhihua Cai	2007		10.1007/978-3-540-74205-0_52	bayes' rule;bayes factor;naive bayes classifier;recursive bayesian estimation;bayesian programming;biological classification;computer science;maximum a posteriori estimation;machine learning;pattern recognition;mathematics;bayesian hierarchical modeling;bayesian statistics;bayes' theorem;bayesian inference;statistics	Vision	16.67236177072703	-37.34129178335005	161187
4fde5d8454fc6d24ac0ae4dcd526bca94c979602	learning algorithm selection for comprehensible regression analysis using datasetoids	statistical comparisons;meta learning;data mining;regression;multiple data sets;support;comprehensibility;classifiers;datasetoids;business and economics	Data mining tools often include a workbench of algorithms to model a given dataset but lack sufficient guidance to select the most accurate algorithm given a certain dataset. The best algorithm is not known in advance and no single model format is superior for all datasets. Evaluating a number of candidate algorithms on large datasets to determine the most accurate model is however a computational burden. An alternative and more time efficient way is to select the optimal algorithm based on the nature of the dataset. In this meta-learning study, it is explored to what degree dataset characteristics can help identify which regression/estimation algorithm will best fit a given dataset. We chose to focus on comprehensible `white-box' techniques in particular (i.e. linear, spline, tree, linear tree or spline tree) as those are of particular interest in many real-life estimation settings. A large scale experiment with more than thousand so called datasetoids representing various real-life dependencies is conducted to discover possible relations. It is found that algorithm based characteristics such as sampling landmarks are major drivers for successfully selecting the most accurate algorithm. Further, it is found that data based characteristics such as the length, dimensionality and composition of the independent variables, or the asymmetry and dispersion of the dependent variable appear to contribute little once landmarks are included in the meta-model.	algorithm selection;algorithmic learning theory	Gert Loterman;Christophe Mues	2015	Intell. Data Anal.	10.3233/IDA-150756	support;regression;computer science;machine learning;pattern recognition;data mining;statistics	NLP	11.76288651985458	-37.51159948149978	161864
8e973267b565d6e15d992d954de20872650ea7ac	optimal and suboptimal feature selection for classification of evoked brain potentials	bayes methods;selection caracteristique;brain models;classificateur bayes;classification;algorithm theory;classification algorithms algorithm design and analysis covariance matrix accuracy brain models error analysis;suboptimal algorithms statistical pattern recognition evoked brain potentials exhaustive search feature selection bayes gaussian statistics optimal algorithms forward sequential features selection stepwise linear discriminant analysis classification accuracy;pattern recognition;loi normale;reconnaissance forme;algorithme optimal;optimal algorithm;clasificacion;gaussian distribution;pattern recognition algorithm theory bayes methods brain models	Exhaustive feature selection algorithms are optimal because all possible combinations of features are tested against a predetermined criterion. Suboptimal algorithms that trade performance for speed by considering only a subset of all feature combinations are generally preferred. An implementation of the exhaustive search feature selection (ESFS) method is described for the Bayes Gaussian statistics. The algorithm significantly reduces the computational and time requirements normally associated with optimal algorithms. The performance of this algorithm is compared to that of two suboptimal algorithms-forward sequential features selection and stepwise linear discriminant analysis. Results show that this implementation provides a moderate improvement in classification accuracy and is well suited for evaluating the performance of suboptimal algorithms.	algorithm;brute-force search;computation;feature selection;linear discriminant analysis;requirement;stepwise regression;web search engine	D. L. Halliday;Clare D. McGillem;J. Westerkamp;Jorge I. Auñón	1985	IEEE Transactions on Systems, Man, and Cybernetics	10.1109/TSMC.1985.6313381	normal distribution;biological classification;computer science;machine learning;pattern recognition;mathematics;statistics	ML	15.53899900923738	-35.759856835475375	162067
fa58c20ac03aa1653044c8eaa116e7bcbdec2d6b	neural tree density estimation for novelty detection	unsupervised learning;time varying;maximum entropy neural tree density estimation competitive learning tree adaptive density estimation novelty detection learning rule equiprobable quantization time varying distributions adaptive multivariable histogram sequential detection tree data structure unsupervised learning;maximum entropy methods;estimacion densidad;learning;nouveaute;neural nets;deteccion;structure arborescente;estimation densite;novelty;novedad;novelty detection;detection;trees mathematics;indexing terms;competitive learning;algorithme;aprendizaje;quantisation signal;algorithm;density estimation;apprentissage;estructura arborescente;data structures;tree structure;partitioning algorithms clustering algorithms iterative algorithms quantization neurons histograms covariance matrix lattices convergence computational modeling;reseau neuronal;data structure;red neuronal;maximum entropy methods neural nets unsupervised learning trees mathematics quantisation signal adaptive estimation data structures;sequential detection;adaptive estimation;neural network;algoritmo	In this paper, a neural competitive learning tree is introduced as a computationally attractive scheme for adaptive density estimation and novelty detection. The learning rule yields equiprobable quantization of the input space and provides an adaptive focusing mechanism capable of tracking time-varying distributions. It is shown by simulation that the neural tree performs reasonably well while being much faster than any of the other competitive learning algorithms.	algorithm;competitive learning;learning rule;machine learning;novelty detection;simulation;vector quantization	D. Martinez	1998	IEEE transactions on neural networks	10.1109/72.661127	density estimation;index term;data structure;computer science;theoretical computer science;machine learning;pattern recognition;mathematics;tree structure;competitive learning;artificial neural network;statistics	ML	12.906204419381073	-32.01349440760272	162153
01b4101c36581f1d0fd760d995de715f13b066b6	incremental learning for multitask pattern recognition problems	incremental learning model;machine learning algorithms;incremental learning multitask learning neural network pattern recognition;learning model;long term memory;training;multitask pattern recognition;neural classifiers;pattern recognition machine learning humans detectors knowledge acquisition boosting predictive models resource management radio access networks face recognition;learning systems;accuracy;incremental learning;machine learning;multi class classification;knowledge acquisition;classification algorithms;pattern classification;pattern recognition;pattern classification learning artificial intelligence;knowledge acquisition incremental learning model multitask pattern recognition neural classifiers multiclass classification task;learning artificial intelligence;multiclass classification task;multitask learning;neural network	This paper presents a learning model of multitask pattern recognition (MTPR) which is constructed by several neural classifiers, long-term memories, and the detector of task changes. In the MTPR problem, several multi-class classification tasks are sequentially given to the learning model without notifying their task categories. This implies that the learning model is supposed to detect task changes by itself and to utilize the knowledge on the previous tasks for learning of new tasks. In addition, the learning model must acquire knowledge of multiple tasks incrementally without unexpected forgetting under the condition that not only tasks but also training samples are sequentially given. The proposed model is evaluated for two artificial MTPR problem. In the experiments, we verify that the proposed model can acquire and accumulate task knowledge very stably and the speed of knowledge acquisition for new tasks is enhanced by transferring knowledge.	algorithm;computer multitasking;emoticon;experiment;knowledge acquisition;machine learning;multiclass classification;pattern recognition	Seiichi Ozawa;Asim Roy	2008	2008 Seventh International Conference on Machine Learning and Applications	10.1109/ICMLA.2008.70	statistical classification;multi-task learning;long-term memory;computer science;artificial intelligence;machine learning;multiclass classification;pattern recognition;accuracy and precision;artificial neural network	ML	14.697188254677364	-34.26270770837779	162322
88cb222fba1757940105692cc01ee2cbabac0a60	naïve and robust: class-conditional independence in human classification learning	learning;naive bayes;classification;probabilistic inference;markov property;heuristics;bayesian model;class conditional independence	Humans excel in categorization. Yet from a computational standpoint, learning a novel probabilistic classification task involves severe computational challenges. The present paper investigates one way to address these challenges: assuming class-conditional independence of features. This feature independence assumption simplifies the inference problem, allows for informed inferences about novel feature combinations, and performs robustly across different statistical environments. We designed a new Bayesian classification learning model (the dependence-independence structure and category learning model, DISC-LM) that incorporates varying degrees of prior belief in class-conditional independence, learns whether or not independence holds, and adapts its behavior accordingly. Theoretical results from two simulation studies demonstrate that classification behavior can appear to start simple, yet adapt effectively to unexpected task structures. Two experiments-designed using optimal experimental design principles-were conducted with human learners. Classification decisions of the majority of participants were best accounted for by a version of the model with very high initial prior belief in class-conditional independence, before adapting to the true environmental structure. Class-conditional independence may be a strong and useful default assumption in category learning tasks.	concept learning;default;dependence;design of experiments;experiment;humans;inference;naive bayes classifier;nelson–aalen estimator;optimal design;programming paradigm;simulation;statistical classification	Jana Jarecki;Björn Meder;Jonathan D. Nelson	2018	Cognitive science	10.1111/cogs.12496	naive bayes classifier;categorization;conditional independence;machine learning;binary independence model;probabilistic classification;bayesian statistics;artificial intelligence;bayesian inference;computer science;pattern recognition;concept learning	AI	16.876481509185066	-37.24787619928027	162498
3445306ffeae0a089208238c61134cf65f7f1c12	active learning based on single-hidden layer feed-forward neural network	uncertainty active learning extreme learning machine inconsistency slfns;complexity theory;rough set theory entropy feedforward neural nets fuzzy set theory learning artificial intelligence;approximation algorithms;uncertainty;training;training uncertainty artificial neural networks approximation algorithms information entropy complexity theory;elm stream based active learning algorithms single hidden layer feed forward neural networks extreme learning machine information entropy gini index conditional features decision labels fuzzy rough sets inconsistency based strategy uncertainty based strategy slfn;artificial neural networks;information entropy	In this paper, we propose two stream-based active learning algorithms for single-hidden layer feed-forward neural networks (SLFNs) trained by extreme learning machine (ELM). Uncertainty and inconsistency are adopted as two sample selection criteria. Uncertainty reflects the nondeterminacy of a sample among different decision classes, which is calculated by information entropy or Gini-index. Inconsistency reflects the disagreement of the sample between its conditional features and decision labels, which is calculated by the lower approximations in fuzzy rough sets. Experimental results demonstrate that inconsistency-based strategy is more effective than uncertainty based strategy for SLFNs under stream-based environment.	active learning (machine learning);algorithm;approximation;artificial neural network;entropy (information theory);feedforward neural network;machine learning;rough set	Xizhao Wang;Sam Kwong;Qingshan Jiang;Ka-Chun Wong	2015	2015 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/SMC.2015.377	uncertainty;computer science;artificial intelligence;machine learning;pattern recognition;data mining;information fuzzy networks;approximation algorithm;artificial neural network;statistics;entropy	Robotics	14.642425968855104	-32.75391576260008	162734
3f9f0134dc8667d3ab43c15ac0231d0ff1e91252	mixture control chart patterns recognition using independent component analysis and support vector machine	control chart patterns;independent component analysis;control chart;pattern recognition;support vector machine;independent component	Effective recognition of control chart patterns (CCPs) is an important issue since abnormal patterns exhibited in control charts can be associated with certain assignable causes which affect the process. Most of the existing studies assume that the observed process data which needs to be recognized are basic types of abnormal CCPs. However, in practical situations, the observed process data could be mixture patterns, which consist of two basic CCPs combined together. In this study, a hybrid scheme using independent component analysis (ICA) and support vector machine (SVM) is proposed for CCPs recognition. The proposed hybrid ICA-SVM scheme initially applies an ICA to the mixture patterns in order to generate independent components (ICs). The hidden basic patterns of the mixture patterns can be discovered in these ICs. The ICs can then serve as the input variables of the SVM for building a CCP recognition model. Experimental results revealed that the proposed scheme is able to effectively recognize mixture control chart patterns and outperform the single SVM models, which did not use an ICA as a preprocessor. & 2011 Elsevier B.V. All rights reserved.	algorithm;chart;comparison and contrast of classification schemes in linguistics and metadata;independent computing architecture;independent component analysis;mixture model;national supercomputer centre in sweden;pattern recognition;preprocessor;support vector machine	Chi-Jie Lu;Yuehjen E. Shao;Po-Hsun Li	2011	Neurocomputing	10.1016/j.neucom.2010.06.036	independent component analysis;support vector machine;control chart;computer science;machine learning;pattern recognition;data mining	ML	10.438820623402775	-36.70573431343603	163525
df6ddb54db6216bdedbc0c9c2b06b3e702499133	an eager regression method based on best feature projections	proyeccion;prediccion;forma;learning;selection;projection method;linear regression;machine;regresion;aprendizaje;apprentissage;maquina;regression;shape;methode projection;machine learning;feature projection;projection;metodo proyeccion;regresion lineal;seleccion;forme;prediction;regression lineaire	This paper describes a machine learning method, called Regression by Selecting Best Feature Projections (RSBFP). In the training phase, RSBFP projects the training data on each feature dimension and aims to find the predictive power of each feature attribute by constructing simple li near regression lines, one per each continuous feature and number of categories per each categorical feature. Because, although the predictive power of a continuous feature is constant, it varies for each distinct value of categorical features. Then the simple linear regression lines are sorted according to their predictive power. In the querying phase of learning, the best linear regression line and thus the best feature projection are selected to make predictions.	machine learning	Tolga Aydin;H. Altay Güvenir	2001		10.1007/3-540-45517-5_25	principal component regression;selection;machine;regression;feature vector;feature;prediction;projection;shape;linear regression;machine learning;pattern recognition;mathematics;projection method;k-nearest neighbors algorithm;feature;statistics;dimensionality reduction	ML	10.514819264697657	-33.60687442751051	163746
742bf444c6a6ed52b477f380010f8b047ac5a7d3	estimation theory and neural networks revisited: rekf and rsvsf as optimization techniques for deep-learning	deep-learning;kalman filter;neural networks;rekf;rsvsf;smooth variable structure filter	Deep-Learning has become a leading strategy for artificial intelligence and is being applied in many fields due to its excellent performance that has surpassed human cognitive abilities in a number of classification and control problems (Ciregan, Meier, & Schmidhuber, 2012; Mnih et al., 2015). However, the training process of Deep-Learning is usually slow and requires high-performance computing, capable of handling large datasets. The optimization of the training method can improve the learning rate of the Deep-Learning networks and result in a higher performance while using the same number of training epochs (cycles). This paper considers the use of estimation theory for training of large neural networks and in particular Deep-Learning networks. Two estimation strategies namely the Extended Kalman Filter (EKF) and the Smooth Variable Structure Filter (SVSF) have been revised (subsequently referred to as RSVSF and REKF) and used for network training. They are applied to several benchmark datasets and comparatively evaluated.	artificial intelligence;artificial neural network;benchmark (computing);cognition;common variable immunodeficiency;computation (action);cycle (graph theory);deep learning;epoch (reference date);estimation theory;extended kalman filter;handling (psychology);learning disorders;mathematical optimization;neural network simulation;neural tube defects;revision procedure;supercomputer;teaching method	Mahmoud Ismail;Mina Attari;Saeid R. Habibi;Samir Ziada	2018	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2018.09.012	machine learning;mathematics;artificial neural network;deep learning;estimation theory;extended kalman filter;cognition;artificial intelligence	AI	17.048860164985545	-32.32100886244672	164369
4641910aed587bd6e9b456bfdb436fb5805006d4	a new generalized lvq algorithm via harmonic to minimum distance measure transition	prototypes cost function vector quantization convergence neural networks electric variables measurement design engineering unsupervised learning nearest neighbor searches error correction;harmonic average distance;multimodal datasets;cost function;distance measure;initialization sensitivity problem;generalized learning vector quantization;distance measure transition;average distance;learning systems;vector quantization;minimum distance;multimodal datasets generalized learning vector quantization distance measure transition harmonic average distance initialization sensitivity problem;pattern classification;artificial intelligence;vector quantisation generalisation artificial intelligence learning artificial intelligence pattern classification;generalisation artificial intelligence;learning artificial intelligence;vector quantisation;learning vector quantization	We present a novel generalized learning vector quantization (LVQ) framework called the harmonic to minimum generalized LVQ algorithm (H2M-GLVQ). Through incorporating the distance measure transition procedure from harmonic average distance to minimum distance, the H2M-GLVQ cost function is gradually changing from the soft model to the hard model. Our proposed method, at the early training stage, can effectively tackle the initialization sensitivity problem associated with the original generalized LVQ algorithm while the convergence of the algorithm can be ensured by the hard model in the later training stage. Experimental results have shown the superior performance of the H2M-GLVQ algorithm over the generalized LVQ and one of its variants on some artificial multi-modal datasets	algorithm;lga 1155;learning vector quantization;loss function;modal logic	A. Kai Qin;Ponnuthurai Nagaratnam Suganthan;Jing J. Liang	2004	2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)	10.1109/ICSMC.2004.1401294	learning vector quantization;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;vector quantization	Robotics	14.891058988524977	-32.77314102897167	164677
26004e75fd38a985d69ed042a15261f18dfc39e2	probabilistic ensemble simplified fuzzy artmap for sonar target differentiation	optimal solution;traitement signal;object recognition;calcul neuronal;solution optimale;neural computation;fuzzy artmap;t technology general;simplified fuzzy artmap;validacion cruzada;t technology;mobile robot;benchmark;relacion orden;artmap;ordering;clasificador;reconnaissance objet;sonar target differentiation;plurality voting;intelligent robot;relation ordre;classifier;signal processing;solucion optima;validation croisee;benchmarks;classificateur;target differentiation;cross validation;robot inteligente;reseau neuronal;classification accuracy;procesamiento senal;differenciation cible;red neuronal;computacion neuronal;robot intelligent;neural network;sonar	This study investigates the processing of sonar signals with ensemble neural networks for robust recognition of simple objects such as plane, corner and trapezium surface. The ensemble neural networks can differentiate the target objects with high accuracy. The simplified fuzzy ARTMAP (SFAM) and probabilistic ensemble simplified fuzzy ARTMAP (PESFAM) are compared in terms of classification accuracy. The PESFAM implements an accurate and effective probabilistic plurality voting method to combine outputs from multiple SFAM classifiers. Five benchmark data sets have been used to evaluate the applicability of the proposed ensemble SFAM network. The PESFAM achieves good accuracy based on the twofold cross-validation results. In addition, the effectiveness of the proposed ensemble SFAM is delineated in sonar target differentiation. The experiments demonstrate the potential of PESFAM classifiers in offering an optimal solution to the data-ordering problem of SFAM implementation and also as an intelligent classification tool in mobile robot application.	approximation error;artificial neural network;benchmark (computing);cross-validation (statistics);experiment;mobile robot;multicanonical ensemble;probabilistic database;sonar (symantec)	Chu Kiong Loo;Augustine Law;Way-Soong Lim;M. V. C. Rao	2005	Neural Computing & Applications	10.1007/s00521-005-0010-1	mobile robot;benchmark;classifier;order theory;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;machine learning;signal processing;data mining;artificial neural network;cross-validation;sonar;models of neural computation	AI	11.183069455791651	-33.81734131069763	165101
94df9eb807b33255cd695fb69cde14d2f7c2a248	using weighted networks to represent classification knowledge in noisy domains		Experience is not always a benign teacher. Examples often contain irrelevant features, the relevant features may be noisy, and the results may not be categorical. Most learning systems, however, assume that the teacher is benign, and in particular that the training cases are free of noise. This paper describes a system, IWN, which can learn classification knowledge from a relatively small number of training cases but whose performance does not rapidly deteriorate when the training cases contain noise. IWN uses a network of weighted links to represent classification knowledge. This use of a non-discrete knowledge representation enables IWN to be more robust in the face of noisy data. In this paper we describe IWNu0027s procedure for building its weighted networks and how IWNu0027s performance compares with other systems. A central focus will be on how several different evaluation functions for propagating values in the network affect the tradeoff between handling noisy data and handling exceptional cases.	weighted network	Ming Tan;Larry J. Eshelman	1988			computer science;artificial intelligence;machine learning;data mining;statistics	AI	15.862121384198167	-36.30806070796449	165223
24efe26317000e8e25151b5946c003787dc08abe	fine tuning method by using knowledge acquisition from deep belief network	fine tuning;adaptive structure learning;bigdata;knowledge acquisition;adaptive deep belief network	We developed an adaptive structure learning method of Restricted Boltzmann Machine (RBM) which can generate/annihilate neurons by self-organizing learning method according to input patterns. Moreover, the adaptive Deep Belief Network (DBN) in the assemble process of pre-trained RBM layer was developed. The proposed method presents to score a great success to the training data set for big data benchmark test such as CIFAR-10. However, the classification capability of the test data set, which are included unknown patterns, is high, but does not lead perfect correct solution. We investigated the wrong specified data and then some characteristic patterns were found. In this paper, the knowledge related to the patterns is embedded into the classification algorithm of trained DBN. As a result, the classification capability can achieve a great success (97.1% to unknown data set).	algorithm;benchmark (computing);big data;deep belief network;embedded system;fractal dimension;knowledge acquisition;organizing (structure);restricted boltzmann machine;self-organization;software design pattern;test data;test set	Shin Kamada;Takumi Ichimura	2016	2016 IEEE 9th International Workshop on Computational Intelligence and Applications (IWCIA)	10.1109/IWCIA.2016.7805759	big data;computer science;machine learning;pattern recognition;data mining;deep belief network;fine-tuned universe	AI	13.411190243437344	-35.422866522182545	165798
a4d46316ea1c2c56541835ee99309593f4fa37ea	discrimination of disease-related non-synonymous single nucleotide polymorphisms using multi-scale rbf kernel fuzzy support vector machine	evaluation performance;polymorphisms nssnps;performance evaluation;non synonymous single nucleotide polymorphisms nssnps;non synonymous single nucleotide;enfermedad;methode noyau;methode echelle multiple;disease;evaluacion prestacion;fonction base radiale;maquina vector soporte;multi scale rbf kernel;fuzzy support vector machine fsvm;metodo escala multiple;fuzzy support vector machine;machine vecteur support;radial basis function;fonction appartenance;metodo nucleo;signal classification;membership function;classification signal;kernel method;multiscale method;support vector machine;funcion pertenencia;classification automatique;automatic classification;funcion radial base;discriminacion;clasificacion automatica;discrimination;maladie;single nucleotide polymorphism	In this paper, we develop a multi-scale RBF kernel fuzzy support vector machine (MSKFSVM) and apply it to the identification of disease-associated non-synonymous single nucleotide polymorphisms (nsSNPs). The experimental results show that the proposed MSKFSVM outperforms the traditional SVM method.	radial basis function kernel;support vector machine	Wen Ju;Juan Shan;Changhui Yan;Heng-Da Cheng	2009	Pattern Recognition Letters	10.1016/j.patrec.2008.11.003	single-nucleotide polymorphism;support vector machine;kernel method;radial basis function;discrimination;radial basis function kernel;membership function;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;polynomial kernel	Vision	10.318043266001101	-34.51616777338524	166093
37059dcaa9634b6052aae2d0e280ac75669df55c	precision-recall-gain curves: pr analysis done right		Precision-Recall analysis abounds in applications of binary classification where true negatives do not add value and hence should not affect assessment of the classifier’s performance. Perhaps inspired by the many advantages of receiver operating characteristic (ROC) curves and the area under such curves for accuracybased performance assessment, many researchers have taken to report PrecisionRecall (PR) curves and associated areas as performance metric. We demonstrate in this paper that this practice is fraught with difficulties, mainly because of incoherent scale assumptions – e.g., the area under a PR curve takes the arithmetic mean of precision values whereas the Fβ score applies the harmonic mean. We show how to fix this by plotting PR curves in a different coordinate system, and demonstrate that the new Precision-Recall-Gain curves inherit all key advantages of ROC curves. In particular, the area under Precision-Recall-Gain curves conveys an expected F1 score on a harmonic scale, and the convex hull of a PrecisionRecall-Gain curve allows us to calibrate the classifier’s scores so as to determine, for each operating point on the convex hull, the interval of β values for which the point optimises Fβ . We demonstrate experimentally that the area under traditional PR curves can easily favour models with lower expected F1 score than others, and so the use of Precision-Recall-Gain curves will result in better model selection.	binary classification;convex hull;experiment;f1 score;model selection;numerical analysis;operating point;precision and recall;receiver operating characteristic	Peter A. Flach;Meelis Kull	2015			econometrics;mathematics;algorithm;statistics	ML	10.946239544077715	-36.48493502319931	167234
28fc744daa275a90dba7071b6fce43cabe218212	semantic supervised clustering to land classification in geo-images	analyse amas;deteccion multiespectral;image processing;detection multispectrale;supervised learning;maximum likelihood;analisis espacial;classification supervisee;supervised classification;maximum vraisemblance;procesamiento imagen;semantics;image classification;intelligence artificielle;semantica;semantique;traitement image;a priori knowledge;cluster analysis;multispectral images;classification image;clasificacion supervisada;artificial intelligence;analisis cluster;inteligencia artificial;apprentissage supervise;spatial analysis;analisis semantico;analyse semantique;aprendizaje supervisado;maximum likelihood method;analyse spatiale;maxima verosimilitud;semantic analysis;multispectral detection	In this paper, we propose a semantic supervised clustering approach to classify lands in geo-images. We use the Maximum Likelihood Method to generate the clustering. In addition, we complement the analysis applying spatial semantics to improve the classification. The approach considers the a priori knowledge of the multispectral image to define the training sites (classes) related to the geographic environment. In this case the spatial semantics is defined by the spatial properties, functions and relations that involve the geo-image. By using these characteristics, it is possible to determine the training data sites with a priori knowledge. This method attempts to improve the supervised clustering, adding the intrinsic semantics of the geo-images to determine the training sites that involve the analysis with more precision.		Miguel Torres Ruiz;Giovanni Guzmán;Rolando Quintero;Marco Moreno;Serguei Levachkine	2005		10.1007/11553939_36	fuzzy clustering;image processing;computer science;machine learning;pattern recognition;data mining;semantics;maximum likelihood;cluster analysis;supervised learning;statistics	ML	10.481097292950043	-32.79306454171819	167582
a743c2ded51c05f9a4c46a20cf2430ba73d166e4	construction of sequential classifier using confusion matrix		This paper presents the problem of building the decision scheme in the multistage pattern recognition task. This task can be pre- sented using a decision tree. This decision tree is built in the learning phase of classification. This paper proposes a split criterion based on the analysis of the confusion matrix. Specifically, we propose the divi- sion associated with an incorrect classification. The obtained results were verified on the data sets form UCI Machine Learning Repository and one real-life data set of the computer-aided medical diagnosis. - the choice of decision rules for performing the classification (14). In particular, this paper discuses a way to design a decision tree structure. The split criterion is based on the confusion matrix. The potential division of the node is associated with the analysis of misclassification in the learning process. In the experiment decision rules are chosen arbitrarily in the entire tree. The content of the work is as follows. Section 2 introduces the idea of the hierarchical (sequential) classifier. In Section 3 we describe the proposed split criterion. In the next section we present the results of the experiments verified on data sets form UCI repository and one real-life data set of the computer-aided medical diagnosis. The last section concludes the paper. K. Saeed et al. (Eds.): CISIM 2013, LNCS 8104, pp. 401-407, 2013.	confusion matrix	Robert Burduk;Pawel Trajdos	2013		10.1007/978-3-642-40925-7_37	decision tree learning;computer science;artificial intelligence;machine learning;incremental decision tree;data mining;statistics	ML	12.486018256927851	-37.741840863114604	167847
0a3df6702075a90a62349d9465a1c3c53b2a16b0	the mixture of k-optimal-spanning-trees based probability approximation: application to skin detection	skin detection;receiver operating characteristic curve;machine learning;dependency tree;optimal spanning tree;spanning tree;mixture of trees;probability mixture	This paper presents a new approach for machine learning to deal with the problem of classification and/or probability approximation. Our contribution is based on the Optimal-Spanning-Tree distributions that are widely used in many optimization areas. The rationale behind this study is that in some cases the approximation of true class probability given by an Optimal-Spanning-Tree is not unique and might be chosen randomly. Furthermore, the user can specify the error tolerance between the tree weights that he/she can accept to manage the information of these kinds of trees. Therefore, the main idea of this work consists in focusing and highlighting the performance of each possible K ðK 2 NÞ Optimal-Spanning-Tree and making some assumptions, to propose the mixture of the K-Optimal-SpanningTrees approximating the true class probability in a supervised algorithm. The theoretical proof of the K-Optimal-Spanning-Trees’ mixture is given. Furthermore, the performance of our method is assessed for Skin/Non-Skin classification in the Compaq database by measuring the Receiver Operating Characteristic curve and its under area. These measures have proved better results of the proposed model compared with a random Optimal-Spanning-Tree model and the baseline one. 2008 Elsevier B.V. All rights reserved.	algorithm;approximation;baseline (configuration management);design rationale;error-tolerant design;experiment;file spanning;machine learning;mathematical optimization;mixture model;pc bruno;pixel;randomness;receiver operating characteristic;spanning tree	Sanaa El Fkihi;Mohamed Daoudi;Driss Aboutajdine	2008	Image Vision Comput.	10.1016/j.imavis.2008.02.003	spanning tree;computer science;machine learning;pattern recognition;mathematics;receiver operating characteristic;statistics	AI	16.502891504457267	-38.01375500514311	167941
688cb5bdc3dd75c95fda517324d2222e049da8fc	novelty-organizing classifiers applied to classification and reinforcement learning: towards flexible algorithms	supervised learning;novelty map;reinforcement learning;novelty;novelty organizing classifiers;structured evolutionary algorithms;self organizing classifiers	It is widely known that reinforcement learning is a more general problem than supervised learning. In fact, supervised learning can be seen as a class of reinforcement learning problems. However, only a couple of papers tested reinforcement learning algorithms in supervised learning problems. Here we propose a new and simpler way to abstract supervised learning for any reinforcement learning algorithm. Moreover, a new algorithm called Novelty-Organizing Classifiers is developed based on a Novelty Map population that focuses more on the novelty of the inputs than their frequency. A comparison of the proposed method with Self-Organizing Classifiers and BioHel on some datasets is presented. Even though BioHel is specialized in solving supervised learning problems, the results showed only a trade-off between the algorithms. Lastly, results on a maze problem validate the flexibility of the proposed algorithm beyond supervised learning problems. Thus, Novelty-Organizing Classifiers is capable of solving many supervised learning problems as well as a maze problem without changing any parameter at all. Considering the fact that no adaptation of parameters was executed, the proposed algorithm's basis seems interestingly flexible.	algorithm;machine learning;organizing (structure);reinforcement learning;supervised learning	Danilo Vasconcellos Vargas;Hirotaka Takano;Junichi Murata	2014		10.1145/2598394.2598429	temporal difference learning;semi-supervised learning;unsupervised learning;instance-based learning;preference learning;error-driven learning;computer science;artificial intelligence;online machine learning;machine learning;linear classifier;pattern recognition;ensemble learning;learning classifier system;supervised learning;stability;reinforcement learning;active learning;learning to rank;generalization error	ML	14.627580226408318	-34.330470160842545	168065
99309212b9ec90115302725936bdd70e87b94013	an algorithm for a selective nearest neighbor decision rule (corresp.)	nearest neighbor;pattern classification;approximate nearest neighbor;decision rule	A procedure is introduced to approximate nearest neighbor (INN) decision boundaries. The algorithm produces a selective subset of the original data so that 1) the subset is consistent, 2) the distance between any sample and its nearest selective neighbor is less than the distance from the sample to any sample of the other class, and 3) the subset is the smallest possible.	algorithm	G. L. Ritter;Hugh B. Woodruff;Stephen R. Lowry;Thomas L. Isenhour	1975	IEEE Trans. Information Theory	10.1109/TIT.1975.1055464	nearest-neighbor chain algorithm;large margin nearest neighbor;r-tree;ball tree;nearest neighbor graph;best bin first;decision rule;mathematics;cover tree;nearest neighbor search;fixed-radius near neighbors;k-nearest neighbors algorithm;statistics	Theory	15.243313670639374	-35.33118677129186	168079
58bf60afec39260fc12ebecb7c62046212e3458f	a snccdbagg-based nn ensemble approach for quality prediction in injection molding process	neural network nn ensemble bagging generalization ability injection molding process;artificial neural networks training injection molding bagging prediction algorithms testing training data;neural nets;bagging;injection molding;training;prediction algorithms;testing;back propagation neural network;negative correlation learning;generalization ability;production engineering computing;injection moulding;training data;artificial neural networks;radial basis function;quality prediction;process parameters;network model;injection molding process;quality control injection moulding neural nets production engineering computing;snccdbagg based nn ensemble approach;neural network nn ensemble;prediction model;process improvement;product quality;negative correlation learning via correlation corrected data;quality control;negative correlation learning via correlation corrected data snccdbagg based nn ensemble approach quality prediction injection molding process neural network bagging;artificial neural network;heterogeneous network;neural network	This paper presents a SNCCDBAGG-based neural network (NN) ensemble approach for quality prediction in injection molding process. Bagging is used to create NNs for the ensemble by independently training these NNs on different training sets. Negative correlation learning via correlation-corrected data (NCCD) is used to achieve negative correlation of each network's error against errors for the rest of the ensemble by training transformed target data for NN in the ensemble as the desired network output for some epochs. A selection-based strategy is proposed to improve generalization ability when combining Bagging and NCCD. Experimental results show its good performance on quality predicting in injection molding process compared with single NN predictor and NCCD predictor.	algorithm;artificial neural network;bootstrap aggregating;kerrison predictor	Yang Liu;Fuli Wang;Yuqing Chang;Chuang Li	2011	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2010.2077279	training set;quality control;radial basis function;bootstrap aggregating;heterogeneous network;prediction;computer science;engineering;artificial intelligence;network model;machine learning;pattern recognition;predictive modelling;software testing;artificial neural network	AI	13.072733947393163	-34.73196258066446	168936
a493a87a7cd9750d23645d82b387482c3b95038b	using proximity and spatial homogeneity in neighbourhood-based classifiers	intelligence artificielle;classification;pattern recognition;artificial intelligence;inteligencia artificial;reconnaissance forme;reconocimiento patron;clasificacion	In this paper, a set of neighbourhood-based classifiers are jointly used in order to select a more reliable neighbourhood of a given sample and take an appropriate decision about its class membership. The approaches introduced here make use of two concepts: proximity and symmetric placement of the samples.	neighbourhood (graph theory)	José Salvador Sánchez;Filiberto Pla;Francesc J. Ferri	1997		10.1007/3-540-63507-6_203	biological classification;computer science;artificial intelligence;machine learning;data mining	Robotics	10.635686839288288	-33.5518829602359	169193
e79a3ad253c3c10100594472c5508277482bdf13	computational cost reduction by selective attention for fast speaker adaptation in multilayer perceptron	atencion selectiva;learning algorithm;diminution cout;multilayer perceptrons;cost reduction;algorithme apprentissage;multilayer perceptron;perceptron multicouche;backpropagation algorithm;word recognition;algorithme retropropagation;selective attention;learning artificial intelligence;algoritmo aprendizaje;speaker adaptation;cost lowering;reduccion costo;on line learning;attention selective;algoritmo retropropagacion;apprentissage intelligence artificielle	Selective attention learning is proposed to improve the speed of the error backpropagation algorithm of a multilayer Perceptron. Class-selective relevance for evaluating the importance of a hidden node in an off-line stage and a node attention technique for measuring the local errors appearing at the output and hidden nodes in an on-line learning process are employed to selectively update the weights of the network. The acceleration of learning time is then achieved by lowering the computational cost required for learning. By combining this method with other types of improved learning algorithms, further improvement in learning speed is also achieved. The effectiveness of the proposed method is demonstrated by the speaker adaptation task of an isolated word recognition system. The experimental results show that the proposed selective attention technique can reduce the adaptation time more than 65% in an average sense.	computation;multilayer perceptron	In Cheol Kim;Sung-Il Chien	2002		10.1007/3-540-48035-8_3	speech recognition;attention;word recognition;computer science;artificial intelligence;backpropagation;machine learning;multilayer perceptron	NLP	15.155588500031342	-31.0116621080525	169479
3fb5eb8a589c475dc15728ea7a887ec196e9bd6d	on the generalization ability of grlvq networks	dimensionalidad;metodo adaptativo;optimisation;tecnologia electronica telecomunicaciones;euclidean theory;computacion informatica;optimizacion;adaptive metric;pertinencia;margin optimization;dimensionality;metric;methode adaptative;lvq;classification;cuantificacion vectorial;vector quantization;ciencias basicas y experimentales;dimensionnalite;pertinence;adaptive method;theorie euclidienne;metrico;optimization;relevance;tecnologias;grupo a;relevance lvq;clasificacion;metrique;teoria euclidiana;learning vector quantization;generalization bounds;quantification vectorielle	We derive a generalization bound for prototype-based classifiers with adaptive metric. The bound depends on the margin of the classifier and is independent of the dimensionality of the data. It holds for classifiers based on the Euclidean metric extended by adaptive relevance terms. In particular, the result holds for relevance learning vector quantization (RLVQ) [4] and generalized relevance learning vector quantization (GRLVQ) [19].	euclidean distance;learning vector quantization;prototype;relevance	Barbara Hammer;Marc Strickert;Thomas Villmann	2004	Neural Processing Letters	10.1007/s11063-004-1547-1	learning vector quantization;computer science;artificial intelligence;machine learning;pattern recognition;mathematics	ML	10.296835536807755	-32.21199576930412	169481
e0c32a25879dce7c147054d588971ecc229b7b93	building ensembles of neural networks with class-switching	distributed system;switching networks;systeme reparti;modele agrege;modelo agregado;probabilistic approach;randomized experiment;classification;reseau commutation;sistema repartido;conferenceobject;enfoque probabilista;approche probabiliste;aggregate model;reseau neuronal;bookpart;clasificacion;red neuronal;neural network	This article investigates the properties of ensembles of neural networks, in which each network in the ensemble is constructed using a perturbed version of the training data. The perturbation consists in switching the class labels of a subset of training examples selected at random. Experiments on several UCI and synthetic datasets show that these class-switching ensembles can obtain improvements in classification performance over both individual networks and bagging ensembles.	experiment;neural networks;synthetic intelligence	Gonzalo Martínez-Muñoz;Aitor Sánchez-Martínez;Daniel Hernández-Lobato;Alberto Suárez	2006		10.1007/11840817_19	biological classification;computer science;artificial intelligence;randomized experiment;machine learning;distributed computing;artificial neural network	ML	10.392020612599577	-31.785986023788066	170208
fd74f6a234e6f4b1148d08be586bfbc1e33cd153	exploring the impact of different classification quality functions in an aco algorithm for learning neural network structures		Although artificial neural networks can be a very effective classification method, one of the drawbacks of their use is the need to manually prescribe the neural network topology. Recent work has introduced the ANN-Miner algorithm, an Ant Colony Optimization (ACO) technique for optimizing the topology of arbitrary FFNN’s, i.e. FFNN’s with multiple hidden layers, layer-skipping connections, and without the requirement of full-connectivity between successive layers. In this paper, we explore the use of several classification quality evaluation functions in ANN-Miner. Our experimental results, using 30 popular benchmark datasets, identify several quality functions that significantly improve on the simple Accuracy quality function that was previously used in ANN-Miner.	algorithm;ant colony optimization algorithms;artificial neural network;benchmark (computing);evaluation function;network topology	Khalid M. Salama;Ashraf M. Abdelbar	2014		10.5220/0005031301370144	artificial intelligence;machine learning;data mining	ML	14.047923176551642	-33.89957209687278	171982
8fb7e40c3e299a65ff8ffb887412330fd57aa5f9	towards self-tuning parameter servers		Recent years, many applications have been driven advances by the use of Machine Learning (ML). Nowadays, it is common to see industrial-strength machine learning jobs that involve millions of model parameters, terabytes of training data, and weeks of training. Good efficiency, i.e., fast completion time of running a specific ML job, therefore, is a key feature of a successful ML system. While the completion time of a longrunning ML job is determined by the time required to reach model convergence, practically that is also largely influenced by the values of various system settings. In this paper, we contribute techniques towards building self-tuning parameter servers. Parameter Server (PS) is a popular system architecture for large-scale machine learning systems; and by self-tuning we mean while a long-running ML job is iteratively training the expert-suggested model, the system is also iteratively learning which system setting is more efficient for that job and applies it online. While our techniques are general enough to various PSstyle ML systems, we have prototyped our techniques on top of TensorFlow. Experiments show that our techniques can reduce the completion times of a variety of long-running TensorFlow jobs from 1.4× to 18×. Paper #95	algorithm;apache hadoop;application programming interface;constructor (object-oriented programming);control knob;database;decibel;iterative method;machine learning;mathematical optimization;memory data register;online optimization;overhead (computing);parallel computing;peer-to-peer;performance;prototype;python;relocation (computing);self-tuning;server (computing);speedup;systems architecture;tensorflow;terabyte;time-domain reflectometer	Chris Liu;Pengfei Zhang;Bo Tang;Hang Shen;Lei Zhu;Ziliang Lai;Eric Lo	2018	CoRR		real-time computing;data mining;systems architecture;computer science;training set;convergence (routing);self-tuning;terabyte;server	Web+IR	13.213868030784782	-36.81503721335654	173009
bd6fb7ce5bc647e8c9a800aeba58b1a1031bf0bf	partial knowledge in embeddings		Representing domain knowledge is crucial for any task. There has been a wide range of techniques developed to represent this knowledge, from older logic based approaches to the more recent deep learning based techniques (i.e. embeddings). In this paper, we discuss some of these methods, focusing on the representational expressiveness tradeoffs that are often made. In particular, we focus on the the ability of various techniques to encode ‘partial knowledge’ a key component of successful knowledge systems. We introduce and describe the concepts of ensembles of embeddings and aggregate embeddings and demonstrate how they allow for partial knowledge.	aggregate data;aggregate function;deep learning;encode;knowledge representation and reasoning;knowledge-based systems;representational state transfer	R. V. Guha	2017	CoRR		domain knowledge;encode;computer science;machine learning;deep learning;knowledge-based systems;artificial intelligence;expressivity	AI	16.872149776535476	-34.554540048700495	173259
e746d0ac2d8c968826280e2a58f879790860b1cd	experimental study for the comparison of classifier combination methods	experimental design;evaluation performance;parametric fusion;classifier combination;performance evaluation;methode parametrique;logistique;learning;classifier selection;bagging;metodo parametrico;evaluacion prestacion;parametric method;methode taguchi;plan experiencia;logistic model;metodo subespacio;logistic regression;methode sous espace;algorithme;aprendizaje;algorithm;apprentissage;logistics;plan experience;random subspace method;signal classification;pattern recognition;subspace method;classification signal;classification automatique;automatic classification;clasificacion automatica;metodo taguchi;taguchi method;logistica;algoritmo	In this paper, we compare the performances of classifier combination methods (bagging, modified random subspace method, classifier selection, parametric fusion) to logistic regression in consideration of various characteristics of input data. Four factors used to simulate the logistic model are: (a) combination function among input variables, (b) correlation between input variables, (c) variance of observation, and (d) training data set size. In view of typically unknown combination function among input variables, we use a Taguchi design to improve the practicality of our study results by letting it as an uncontrollable factor. Our experimental study results indicate the following: when training set size is large, performances of logistic regression and bagging are not significantly different. However, when training set size is small, the performance of logistic regression is worse than bagging. When training data set size is small and correlation is strong, both modified random subspace method and bagging perform better than the other three methods. When correlation is weak and variance is small, both parametric fusion and classifier selection algorithm appear to be the worst at our disappointment. 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	emoticon;experiment;logistic regression;pattern recognition;performance;random subspace method;selection algorithm;simulation;taguchi methods;test set	S. Y. Sohn;Hye Won Shin	2007	Pattern Recognition	10.1016/j.patcog.2006.06.027	computer science;machine learning;pattern recognition;mathematics;logistic regression;statistics	AI	10.652573026033398	-34.568317813900784	173660
35f299c0fb579b33ac02b4f9364732f8f5d14bac	a statistical model selection strategy applied to neural networks	neural network;comparative study;multiple comparisons;feed forward neural network;statistical significance;statistical model	In statistical modelling, an investigator must often choose a suitable model among a collection of viable candidates. There is no consensus in the research community on how such a comparative study is performed in a methodologically sound way. The ranking of several methods is usually performed by the use of a selection criterion, which assigns a score to every model based on some underlying statistical principles. The fitted model that is favoured is the one corresponding to the minimum (or the maximum) score. Statistical significance testing can extend this method. However, when enough pairwise tests are performed the multiplicity effect appears which can be taken into account by considering multiple comparison procedures. The existing comparison procedures can roughly be categorized as analytical or resampling based. This paper describes a resampling based multiple comparison technique. This method is illustrated on the estimate of the number of hidden units for feed-forward neural networks.	artificial neural network;categorization;feedforward neural network;model selection;resampling (statistics);statistical model	Joaquín Pizarro Junquera;Elisa Guerrero Vázquez;Pedro L. Galindo	2000			multiple comparisons problem;probabilistic neural network;machine learning;artificial intelligence;artificial neural network;feedforward neural network;types of artificial neural networks;pattern recognition;resampling;statistical model;computer science;pairwise comparison	AI	11.433181841288647	-35.6285720752474	174362
04661567a7e1e59c8dee19dbafbe61902c6af5ec	comparison of data classification methods for predictive ranking of banks exposed to risk of failure	risk analysis machine learning supervised learning predictive models;machine learning algorithms;banking;supervised learning;risk analysis;training;decision trees machine learning algorithms machine learning training predictive models classification algorithms prediction algorithms;prediction algorithms;statistical algorithms data classification methods predictive ranking performance banks financial institution risk scoring capabilities risk exposure roc curves fdic call report data one year ahead ranking prediction schema inductive machine learning techniques;statistical analysis;machine learning;classification algorithms;pattern classification;statistical analysis banking learning artificial intelligence pattern classification risk analysis;predictive models;learning artificial intelligence;decision trees	The difficulty of understanding a financial institution's risk of default has been highlighted by multiple recent episodes in both the U.S. and in Europe. This paper describes a study on the empirical comparison of classification techniques for predictive ranking of the 12 month risk of default in banks. This work compares the scoring capabilities of different predictive models. The models compared were induced from past levels of risk exposure observed in historic data. The ranking performance of the models is compared by assessing the highest risk cases, using the left-hand side of the model's ROC curves (i.e., curves representing true positive to false positive rates). Empirical comparisons were performed using FDIC call report data and a one-year-ahead ranking prediction schema. This comparison demonstrates that inductive machine learning techniques can be successfully applied for predictive ranking of default risk. Observed results indicate better performance by symbolic rule or decision tree based models than by traditional modeling techniques based on statistical algorithms.	artificial neural network;c4.5 algorithm;data modeling;decision tree;elegant degradation;ensemble forecasting;interoperability;machine learning;multitier architecture;nonlinear system;predictive modelling;receiver operating characteristic;statistical model;tier 1 network	Charles A. Worrell;Shaun M. Brady;Jerzy W. Bala	2012	2012 IEEE Conference on Computational Intelligence for Financial Engineering & Economics (CIFEr)	10.1109/CIFEr.2012.6327823	computer science;machine learning;pattern recognition;data mining	ML	10.62128372452073	-37.901406185707735	174564
e33dacd5aec118c919e0b37472d26b095d6cbd9d	one-class classifiers with incremental learning and forgetting for data streams with concept drift	concept drift;one class classification;forgetting;incremental learning;pattern classification;data stream classification	One of the most important challenges for machine learning community is to develop efficient classifiers which are able to cope with data streams, especially with the presence of the so-called concept drift. This phenomenon is responsible for the change of classification task characteristics, and poses a challenge for the learning model to adapt itself to the current state of the environment. So there is a strong belief that one-class classification is a promising research direction for data stream analysis—it can be used for binary classification without an access to counterexamples, decomposing a multi-class data stream, outlier detection or novel class recognition. This paper reports a novel modification of weighted one-class support vector machine, adapted to the non-stationary streaming data analysis. Our proposition can deal with the gradual concept drift, as the introduced one-class classifier model can adapt its decision boundary to new, incoming data and additionally employs a forgetting mechanism which boosts the ability of the classifier to follow the model changes. In this work, we propose several different strategies for incremental learning and forgetting, and additionally we evaluate them on the basis of several real data streams. Obtained results confirmed the usability of proposed classifier to the problem of data stream classification with the presence of concept drift. Additionally, implemented Communicated by E. Lughofer. This work was supported by the Polish National Science Center under the Grant No. DEC-2013/09/B/ST6/02264. B. Krawczyk (B) ·M. Woźniak Department of Systems and Computer Networks, Wrocław University of Technology, Wybrzeże Wyspiańskiego 27, 50-370 Wrocław, Poland e-mail: bartosz.krawczyk@pwr.edu.pl M. Woźniak e-mail: michal.wozniak@pwr.edu.pl forgetting mechanism assures the limited memory consumption, because only quite new and valuable examples should be memorized.	active learning (machine learning);algorithm;anomaly detection;binary classification;circuit restoration;concept drift;decision boundary;email;machine learning;one-class classification;sigmoid function;stationary process;stream (computing);support vector machine;usability	Bartosz Krawczyk;Michal Wozniak	2015	Soft Comput.	10.1007/s00500-014-1492-5	computer science;artificial intelligence;concept drift;machine learning;pattern recognition;data mining;data stream mining;forgetting;one-class classification	ML	14.481681911033863	-37.64114190244313	174587
fdbeefc5fcc12e52c51254d098244209a360baee	a new approach to three ensemble neural network rule extraction using recursive-rule extraction algorithm	neural nets;classification algorithms biological neural networks data mining algorithm design and analysis radio frequency decision trees;neural nets data handling;data handling;data sets neural network rule extraction recursive rule extraction algorithm hayashi first question effective rule extraction algorithm e re rx algorithm ensemble recursive rule extraction	In this paper, we propose a Three Ensemble neural network rule extraction algorithm. Then we investigate Hayashi's first question, “Can the Ensemble-Recursive-Rule eXtraction (E-Re-RX) algorithm be extended to an ensemble neural network consisting of three or more MLPs and extract comprehensible rules?” The E-Re-RX algorithm is an effective rule extraction algorithm for dealing with data sets that mix discrete and continuous attributes. Using the experimental results, we consider the three MLP ensemble Re-RX algorithm from various points of view. Finally, we present provisional positive conclusions.	algorithm;artificial neural network;convolutional neural network;ensemble kalman filter;foremost;handwriting recognition;memory-level parallelism;multiclass classification;recursion (computer science);rule induction;test data	Yoichi Hayashi;Ryusuke Sato;Sushmita Mitra	2013	The 2013 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2013.6706823	delta rule;computer science;machine learning;group method of data handling;pattern recognition;data mining;fsa-red algorithm;artificial neural network	AI	13.343774410311978	-35.47419305726364	175432
7a28d3684e2e9a82a6a78242b14f391053a52964	inductive learning in a mixed paradigm setting	empirical study;classification algorithm;classification tree;decision tree;case base reasoning;rule based;rule learning;inductive learning	"""In a precedent-bused domain one appeals to previous cases to support a solution, decision, explanation, or an argument. Experts typically use care in choosing cases in precedent-based domains, and apply such criteria as case relevance, prototypicality, and importance. In domains where both cases and rules are used, experts use an additional case selection criterion: the generalizations that a particular group of cases support. Domain experts use their knowledge of cases to forge the rules learned from those cases.#R##N##R##N#In this paper, we explore inductive learning in a """"mixed paradigm"""" setting, where both rule-based and case-based reasoning methods are used. In particular, we consider how the techniques of casebased reasoning in an adversarial, precedent-based domain can be used to aid a decision-tree based classification algorithm for (1) training set selection, (2) branching feature choice, and (3) induction policy preference and deliberate exploitation of inductive bias. We focus on how precedentbased argumentation may inform the selection of training examples used to build classification trees. The resulting decision trees may then be reexpressed as rules and incorporated into the mixed paradigm system. We discuss the heuristic control problems involved in incorporating an inductive learner into CABARET, a mixed paradigm reasoner. Finally, we present an empirical study in a legal domain of the classification trees generated by various training sets constructed by a case-based reasoning module."""	inductive reasoning;programming paradigm	David B. Skalak;Edwina L. Rissland	1990			rule-based system;multi-task learning;decision tree learning;computer science;artificial intelligence;machine learning;decision tree;data mining;empirical research	ML	16.28782442989374	-35.229427275311096	176328
53cc0f023a2f0d63612ad84e96a3b08496fd5854	genetic programming with local improvement for visual learning from examples	vision ordenador;genetic program;learning algorithm;image processing;evolutionary programming;procesamiento imagen;intelligence artificielle;algorithme apprentissage;algoritmo genetico;traitement image;genetics;computer vision;reconnaissance caractere;learning from examples;visual learning;prediction accuracy;algorithme genetique;pattern recognition;artificial intelligence;algorithme evolutionniste;genetic algorithm;vision ordinateur;algoritmo evolucionista;inteligencia artificial;reconnaissance forme;evolutionary algorithm;reconocimiento patron;algoritmo aprendizaje;local search;character recognition;recherche locale;reconocimiento caracter	This paper investigates the use of evolutionary programming for the search of hypothesis space in visual learning tasks. The general goal of the project is to elaborate human-competitive procedures for pattern discrimination by means of learning based on the training data (set of images). In particular, the topic addressed here is the comparison between the ‘standard’ genetic programming (as defined by Koza [13]) and the genetic programming extended by local optimization of solutions, so-called genetic local search. The hypothesis formulated in the paper is that genetic local search provides better solutions (i.e. classifiers with higher predictive accuracy) than the genetic search without that extension. This supposition was positively verified in an extensive comparative experiment of visual learning concerning the recognition of handwritten characters.	evolutionary programming;genetic programming;local search (optimization);mathematical optimization;visual learning	Krzysztof Krawiec	2001		10.1007/3-540-44692-3_26	evolutionary programming;genetic programming;computer vision;genetic algorithm;image processing;computer science;artificial intelligence;local search;genetic operator;machine learning;evolutionary algorithm;genetic representation;algorithm	AI	10.48190857495156	-31.89348696937262	177557
983367f3e847a48315d83441eea1f8a2b78fcb6c	application of the evolutionary algorithms for classifier selection in multiple classifier systems with majority voting	sistema multiple;classifier combination;image processing;majority rule;caracter manuscrito;manuscript character;procesamiento imagen;multiple system;algoritmo genetico;classification;traitement image;regla mayoria;reconnaissance caractere;combining classifier;voting;algorithme genetique;pattern recognition;regle majorite;algorithme evolutionniste;genetic algorithm;tabu search;algoritmo evolucionista;voto;reconnaissance forme;evolutionary algorithm;vote;reconocimiento patron;majority voting;evolutionary optimization;multiple classifier system;caractere manuscrit;character recognition;clasificacion;reconocimiento caracter;busqueda tabu;recherche tabou;fitness function;systeme multiple	In many pattern recognition tasks, an approach based on combining classifiers has shown a significant potential gain in comparison to the performance of an individual best classifier. This improvement turned out to be subject to a sufficient level of diversity exhibited among classifiers, which in general can be assumed as a selective property of classifier subsets. Given a large number of classifiers, an intelligent classifier selection process becomes a crucial issue of multiple classifier system design. In this paper, we have investigated three evolutionary optimization methods for the classifier selection task. Based on our previous studies of various diversity measures and their correlation with majority voting error we have adopted majority voting performance computed for the validation set directly as a fitness function guiding the search. To prevent from training data overfitting we extracted a population of best unique classifier combinations, and used them for second stage majority voting. In this work we intend to show empirically, that using efficient evolutionary-based selection leads to the results comparable to absolutely best, found exhaustively. Moreover, as we showed for selected datasets, introducing a second stage combining by majority voting has the potential for both, further improvement of the recognition rate and increase of the reliability of combined outputs.	binary classification;brute-force search;computer performance;evolutionary algorithm;experiment;fitness function;genetic algorithm;learning classifier system;mathematical optimization;overfitting;pattern recognition;search algorithm;statistical classification;systems design;tabu search	Dymitr Ruta;Bogdan Gabrys	2001		10.1007/3-540-48219-9_40	margin classifier;majority rule;margin;image processing;quadratic classifier;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;algorithm	AI	10.688386740598604	-34.42395694064435	177961
a714bfd23e9a4c1b9c4b419b301d330e46c35f52	iblstreams: a system for instance-based classification and regression on data streams		This paper presents an approach to learning on data streams called IBLStreams. More specifically, we introduce the main methodological concepts underlying this approach and discuss its implementation under the MOA software framework. IBLStreams is an instance-based algorithm that can be applied to classification and regression problems. In comparison to model-based methods for learning on data streams, it is conceptually simple. Moreover, as an algorithm for learning in dynamically evolving environments, it has a number of desirable properties that are not, at least not as a whole, shared by currently existing alternatives. Our experimental validation provides evidence for its flexibility and ability to adapt to changes of the environment quickly, a point of utmost importance in the data stream context. At the same time, IBLStreams turns out to be competitive to state-of-the-art methods in terms of prediction accuracy. Moreover, due to its robustness, it is applicable to streams with different characteristics.	algorithm;moa;robustness (computer science);software framework	Ammar Shaker;Eyke Hüllermeier	2012	Evolving Systems	10.1007/s12530-012-9059-0	computer science;artificial intelligence;machine learning;data mining;statistics	ML	13.991813189430818	-37.81339877282358	178568
a2444f3f1c0640df4fd3f8858e6e352242196474	credal ensembles of classifiers	credal ensemble;credal classification;statistical modelling;classification;bayesian model averaging;imprecise probability;machine learning;compression based averaging;aode	It is studied how to aggregate the probabilistic predictions generated by different SPODE (Super-Parent-One-Dependence Estimators) classifiers. It is shown that aggregating such predictions via compression-based weights achieves a slight but consistent improvement of performance over previously existing aggregation methods, including Bayesian Model Averaging and simple average (the approach adopted by the AODE algorithm). Then, attention is given to the problem of choosing the prior probability distribution over the models; this is an important issue in any Bayesian ensemble of models. To robustly deal with the choice of the prior, the single prior over the models is substituted by a set of priors over themodels (credal set), thus obtaining a credal ensemble of Bayesian classifiers. The credal ensemble recognizes the prior-dependent instances, namely the instanceswhose most probable class varies when different prior over the models are considered. When faced with prior-dependent instances, the credal ensemble remains reliable by returning a set of classes rather than a single class. Two credal ensembles of SPODEs are developed; the first generalizes the Bayesian Model Averaging and the second the compression-based aggregation. Extensive experiments show that the novel ensembles compare favorably to traditional methods for aggregating SPODEs and also to previous credal classifiers. © 2012 Elsevier B.V. All rights reserved.	aggregate data;algorithm;averaged one-dependence estimators;bayesian network;block-matching algorithm;computation;ensemble kalman filter;ensemble forecasting;ensembles of classifiers;experiment;linear programming;naive bayes classifier;neural ensemble;yang	Giorgio Corani;Alessandro Antonucci	2014	Computational Statistics & Data Analysis	10.1016/j.csda.2012.11.010	statistical model;imprecise probability;biological classification;machine learning;pattern recognition;mathematics;statistics	AI	17.253837415805595	-37.600666420383824	179012
4d3a8874871dc8e9bce4fe776d42e52ffa9bff11	visualization using multi-layered u-matrix in growing tree-structured self-organizing feature map	unsupervised learning;pattern clustering;vector quantisation data visualisation matrix algebra pattern clustering self organising feature maps unsupervised learning;self organizing feature map;training;matrix algebra;neurons data visualization vectors training equations mathematical model unsupervised learning;u matrix;data visualisation;vectors;self organising feature maps;tree structure;data visualization;mathematical model;neurons;iris data multilayered u matrix tree structured self organizing feature map artificial neural network unsupervised learning data visualization vector quantization cluster analysis hierarchical neural network structure;vector quantisation;u matrix self organizing feature map tree structure data visualization	Self-organizing feature map (SOM) is well known artificial neural network using unsupervised learning for the data visualization and vector quantization. SOM has been used for cluster analysis. On the other hand, SOM cannot produce clarified clusters. And so SOM clustering capability is depends on visualization method. We proposed a variant of SOM that construct hierarchical neural network structure to clarify cluster boundaries in previous research. In this paper, we proposed a visualization method for this growing Tree-Structured SOM and discuss the computational result of Iris data.	artificial neural network;cluster analysis;data visualization;image resolution;interactivity;knowledge acquisition;organizing (structure);self-organization;self-organizing map;u-matrix;unsupervised learning;vector quantization	Takashi Yamaguchi;Takumi Ichimura	2011	2011 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/ICSMC.2011.6084224	u-matrix;computer science;machine learning;pattern recognition;mathematical model;data mining;tree structure;data visualization;statistics	Robotics	12.532713546485464	-34.74316475783238	179197
1dbc6ced5f5ddb9ad916bfd2bbbb77a60a5d8a90	using data mining to improve assessment of credit worthiness via credit scoring models	credit scoring;decision tree;predictive modeling;data mining;logistic regression;classification;financial data;qa75 electronic computers computer science;classification error;prediction model;statistical techniques;q science;logistic regression model;credit risk;historical data	Credit scoring model have been developed by banks and researchers to improve the process of assessing credit worthiness during the credit evaluation process. The objective of credit scoring models is to assign credit risk to either a ‘‘good risk’’ group that is likely to repay financial obligation or a ‘‘bad risk’’ group who has high possibility of defaulting on the financial obligation. Construction of credit scoring models requires data mining techniques. Using historical data on payments, demographic characteristics and statistical techniques, credit scoring models can help identify the important demographic characteristics related to credit risk and provide a score for each customer. This paper illustrates using data mining to improve assessment of credit worthiness using credit scoring models. Due to privacy concerns and unavailability of real financial data from banks this study applies the credit scoring techniques using data of payment history of members from a recreational club. The club has been facing a problem of rising number in defaulters in their monthly club subscription payments. The management would like to have a model which they can deploy to identify potential defaulters. The classification performance of credit scorecard model, logistic regression model and decision tree model were compared. The classification error rates for credit scorecard model, logistic regression and decision tree were 27.9%, 28.8% and 28.1%, respectively. Although no model outperforms the other, scorecards are relatively much easier to deploy in practical applications. 2011 Elsevier Ltd. All rights reserved.	data mining;decision tree model;logistic regression;privacy;risk aversion;unavailability	Bee Wah Yap;Seng-Huat Ong;Nor Huselina Mohamed Husain	2011	Expert Syst. Appl.	10.1016/j.eswa.2011.04.147	credit reference;actuarial science;computer science;machine learning;credit history;data mining;logistic regression	AI	10.728681676993737	-37.69217458964211	179441
e967b1c8b6cf5eab4bfe28893d49929682b02cd6	predicting number of unsupervised clusters by supervised function	pattern clustering;unsupervised clustering;manifolds;neural nets;real number system unsupervised cluster number prediction by supervised function supervised neural network zero gradient location similar data separation;training;similar data separation;predict the number of cluster;euclidean distance;data mining;zero gradient location;artificial neural networks;supervised function;clustering;pattern clustering data mining learning artificial intelligence neural nets;supervised function clustering predict the number of cluster;supervised neural network;number of clusters;real number system;clustering algorithms;neural networks clustering algorithms testing supervised learning distance measurement euclidean distance computational intelligence mathematics telecommunication traffic bayesian methods;neurons;learning artificial intelligence;high dimension;unsupervised cluster number prediction by supervised function;neural network	"""The clustering is one of popular technique for separating the similar data into the same group.The problem of this technique is """"How to find the real number of group in the data?"""". So, In this paper we try to find the solution that can guess the number of group by automatic. However, this number is very difficult to specify if the data space is in a very high dimension. Here, the problem of predicting number of clusters is transformed to the problem of constructing a function by using a supervised neural network and locating all zero gradients on this function. The number of locations having zero gradients is equal to the number of clusters. The proposed technique correctly predicts the number of clusters when it is tested with several testing sets."""	artificial neural network;cluster analysis;dataspaces;gradient;sql	Chouvanee Srivisal;Chidchanok Lursinsap	2009	2009 International Joint Conference on Computational Sciences and Optimization	10.1109/CSO.2009.132	computer science;machine learning;pattern recognition;data mining;mathematics;cluster analysis;artificial neural network	ML	14.492535122945341	-34.95891967884741	179898
36aca96f75dcd1588ed2985ea2ec3e1a2d31e47c	subsumption resolution: an efficient and effective technique for semi-naive bayesian learning	naive bayes;classification;feature selection;semi naive bayes;aode	Semi-naive Bayesian techniques seek to improve the accuracy of naive Bayes (NB) by relaxing the attribute independence assumption. We present a new type of semi-naive Bayesian operation, Subsumption Resolution (SR), which efficiently identifies occurrences of the specialization-generalization relationship and eliminates generalizations at classification time. We extend SR to Near-Subsumption Resolution (NSR) to delete near–generalizations in addition to generalizations. We develop two versions of SR: one that performs SR during training, called eager SR (ESR), and another that performs SR during testing, called lazy SR (LSR). We investigate the effect of ESR, LSR, NSR and conventional attribute elimination (BSE) on NB and Averaged One-Dependence Estimators (AODE), a powerful alternative to NB. BSE imposes very high training time overheads on NB and AODE accompanied by varying decreases in classification time overheads. ESR, LSR and NSR impose high training time and test time overheads on NB. However, LSR imposes no extra training time overheads and only modest test time overheads on AODE, while ESR and NSR impose modest training and test time overheads on AODE. Our extensive experimental comparison on sixty UCI data sets shows that applying BSE, LSR or NSR to NB significantly improves both zero-one loss and RMSE, while applying BSE, ESR or NSR to AODE significantly improves zero-one loss and RMSE and applying LSR to AODE significantly improves zero-one loss. The Friedman test and Nemenyi test show that AODE with ESR or NSR have a significant zero-one loss and RMSE advantage over Logistic Regression and a zero-one loss advantage over Weka’s LibSVM implementation with a grid parameter search on categorical data. AODE with LSR has a zero-one loss advantage over Logistic Regression and comparable zero-one loss with LibSVM. Finally, we examine the circumstances under which the elimination of near-generalizations proves beneficial.	a library for support vector machines;algorithm;algorithmic efficiency;averaged one-dependence estimators;biological systems engineering;categorical variable;computation;effective method;grid computing;lr parser;lazy evaluation;logistic regression;loss function;marginal model;missing data;naive bayes classifier;nat friedman;partial template specialization;random-access memory;requirement;semiconductor industry;subsumption architecture;the australian;weka;while	Fei Zheng;Geoffrey I. Webb;Pramuditha Suraweera;Liguang Zhu	2011	Machine Learning	10.1007/s10994-011-5275-2	naive bayes classifier;biological classification;computer science;artificial intelligence;machine learning;data mining;feature selection;statistics	AI	16.26017684711463	-36.97340371939272	181417
235abeeb2eca372e1c2b311ee208a3965f1e364e	optimizing student models for causality	student model;search algorithm;stepwise regression;intelligent tutoring;help seeking;cognitive model	Complex student models often include key parameters critical to their behavior and effectiveness. For example, one meta-cognitive model of student help-seeking in intelligent tutors includes 15 rules and 10 parameters. We explore whether or not this model can be improved both in accuracy and generalization by using a variety of techniques to select and tune parameters. We show that such techniques are important by demonstrating that the normal method of fitting parameters on an initial data set generalizes poorly to new test data sets. We then show that stepwise regression can improve generalization, but at a cost to initial performance. Finally, we show that causal search algorithms can yield simpler models that perform comparably on test data, but without the loss in training set performance. The resulting help-seeking model is easier to understand and classifies a more realistic number of student actions as help-seeking errors.	causality;cognitive model;optimizing compiler;search algorithm;stepwise regression;test data;test set	Benjamin Shih;Kenneth R. Koedinger;Richard Scheines	2007			cognitive model;simulation;computer science;artificial intelligence;machine learning;stepwise regression;statistics;search algorithm	ML	16.431130856182012	-34.266079456783196	182173
b605c7202ec235354d1b27aff62cad5a2021b9e8	the piecewise linear neural network: training and recognition	piecewise linear neural network;piecewise linear;neural nets;training;euclidean distance;backpropagation networks;backpropagation;learning systems;handwritten numerals;prototype patterns;recognition;neural nets character recognition learning systems;piecewise linear classifier;network structure;character recognition;training backpropagation networks handwritten numerals minimum euclidean distance network structure piecewise linear classifier piecewise linear neural network prototype patterns recognition;minimum euclidean distance;neural network	Consideration is given to the piecewise linear neural network (PLNN), a neural network form of a piecewise linear classifier. The weight vectors of the cells in the middle layer of the network represent prototype patterns of the various classes to be recognized. The PLNN classifies input patterns by the minimum Euclidean distance to the prototype cells. The network structure is defined during training. The training is controlled by parameters &#949; and d. If there is no cell of the correct class within distance &#949; of a training pattern, a new prototype cell is created. And all prototype cells within distance d of the training pattern have their weights adjusted, either towards or away from the training pattern, depending upon their class. Cells of the same class that are moved close together are merged. The dynamics of the PLNN training is shown by examples of the prototype cells adapting to statistically generated data. The results of training backpropagation networks of similar size are described. The PLNN is also trained for the recognition of handwritten numerals. The processing of the image data, training of the network, and recognition results for PLNNs of various sizes are described. The results of training backpropagation networks of comparable size on the same data are also shown. The PLNN performance is generally superior, with far less training time required	artificial neural network;piecewise linear continuation	Y. H. Kong;A. S. Noetzel	1990		10.1109/IJCNN.1990.137852	piecewise linear function;computer science;artificial intelligence;backpropagation;machine learning;pattern recognition;euclidean distance;mathematics;artificial neural network	ML	13.815385595671017	-32.5037585353946	184327
ed5ff963f862243d77de92c611f179760e3debb6	exploring pattern selection strategies for fast neural network training	training artificial neural networks support vector machines accuracy network topology satellite broadcasting pattern recognition;neural networks;support vector machines;training;uci machine learning repository pattern selection strategy fast neural network training pattern recognition mnist handwritten digit data bangla handwritten numerals shuttle data;satellite broadcasting;network topology;accuracy;artificial neural networks;fast neural network training;machine learning;bangla handwritten numerals;pattern recognition learning artificial intelligence;shuttle data;pattern recognition;pattern selection strategy;fast pattern selection;machine learning fast pattern selection neural networks;learning artificial intelligence;uci machine learning repository;mnist handwritten digit data;neural network	Nowadays, the usage of neural network strategies in pattern recognition is a widely considered solution. In this paper we propose three different strategies to select more efficiently the patterns for a fast learning in such a neural framework by reducing the number of available training patterns. All the strategies rely on the idea of dealing just with samples close to the decision boundaries of the classifiers. The effectiveness (accuracy, speed) of these methods is confirmed through different experiments on the MNIST handwritten digit data [1], Bangla handwritten numerals [2] and the Shuttle data from the UCI machine learning repository [3].	artificial neural network;direct-broadcast satellite;experiment;mnist database;machine learning;network topology;pattern recognition;selection bias	Szilárd Vajda;Gernot A. Fink	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.714	support vector machine;speech recognition;computer science;machine learning;pattern recognition;accuracy and precision;artificial neural network;network topology	ML	13.590931748973306	-32.87189411255181	184760
1c6df213b6e3f22e6f8dfeaa729aefe82e6a0813	towards scalable and accurate online feature selection for big data	pairwise correlation feature selection big data saola scalable and accurate online approach;extremely high dimensionality;training;correlation training markov processes redundancy accuracy big data search problems;data mining big data;extremely high dimensionality online feature selection feature redundancy;accuracy;redundancy;big data;feature redundancy;search problems;markov processes;correlation;online feature selection	Feature selection is important in many big data applications. Two critical challenges closely associate with big data. First, in many big data applications, the dimensionality is extremely high, in millions, and keeps growing. Second, big data applications call for highly scalable feature selection algorithms in an online manner such that each feature can be processed in a sequential scan. We present SAOLA, a <underline>S</underline>calable and <underline>A</underline>ccurate <underline>O</underline>n<underline>L</underline>ine <underline>A</underline>pproach for feature selection in this paper. With a theoretical analysis on bounds of the pairwise correlations between features, SAOLA employs novel pairwise comparison techniques and maintains a parsimonious model over time in an online manner. Furthermore, to deal with upcoming features that arrive by groups, we extend the SAOLA algorithm, and then propose a new group-SAOLA algorithm for online group feature selection. The group-SAOLA algorithm can online maintain a set of feature groups that is sparse at the levels of both groups and individual features simultaneously. An empirical study using a series of benchmark real datasets shows that our two algorithms, SAOLA and group-SAOLA, are scalable on datasets of extremely high dimensionality and have superior performance over the state-of-the-art feature selection methods.	algorithm;benchmark (computing);big data;feature selection;full table scan;interaction;occam's razor;online algorithm;opaque pointer;scalability;sparse matrix;telegraph key;time complexity	Kui Yu;Xindong Wu;Wei Ding;Jian Pei	2014	2014 IEEE International Conference on Data Mining	10.1109/ICDM.2014.63	big data;minimum redundancy feature selection;computer science;machine learning;pattern recognition;data mining;mathematics;accuracy and precision;markov process;redundancy;correlation;feature;statistics;dimensionality reduction	ML	13.708818562377056	-37.938164471763265	184963
7db9cdf6237607b6df9b7f1fad4388f53dbbabbb	learning deep representations : toward a better new understanding of the deep learning paradigm. (apprentissage de représentations profondes : vers une meilleure compréhension du paradigme d'apprentissage profond)		Deep Neural Networks (DNN) propose a new and efficient ML architecture based on the layer-wise building of several representation layers. A critical issue for DNNs remains model selection, e.g. selecting the number of neurons in each DNN layer. The hyper-parameter search space exponentially increases with the number of layers, making the popular grid searchbased approach used for finding good hyper-parameter values intractable. The question investigated in this paper is whether the unsupervised, layerwise methodology used to train a DNN can be extended to model selection as well. The proposed approach, considering an unsupervised criterion, empirically examines whether model selection is a modular optimization problem, and can be tackled in a layer-wise manner. Preliminary results on the MNIST data set suggest the answer is positive. Further, some unexpected results regarding the optimal size of layers depending on the training process, are reported and discussed.		Ludovic Arnold	2013				ML	15.89303604314936	-32.91514163870527	185045
a9d4bd5daa84ae79c986783393f1a540a9d40433	curiosity driven incremental lda agent active learning	eigenvalues and eigenfunctions;eigenspace;learning rate;multi agent system;active learning;linear discriminant analysis learning systems machine learning algorithms intelligent agent neural networks psychology mathematical model iterative algorithms machine learning knowledge engineering;multiple cilda agents cooperative learning;linear discriminate analysis;agent communication;data mining;error analysis;learning system;multi agent systems;learning methods;multi agent systems eigenvalues and eigenfunctions learning artificial intelligence;incremental learning;chromium;classification algorithms;multi agent system active linear discriminant analysis learning method curiosity driven incremental lda method multiple cilda agents cooperative learning eigenspace incremental learning processes;face;incremental learning processes;numerical models;learning artificial intelligence;classification accuracy;cooperative learning;curiosity driven incremental lda method;noise;active linear discriminant analysis learning method	This paper presented a novel active linear discriminant analysis (LDA) learning method in the form of curiosity-driven incremental LDA (cILDA) and multiple cILDA agents cooperative learning (mcILDA). The curiosity in psychology here is modelled mathematically as a discriminability residue in-between instance space and its corresponding eigenspace. As the learning proceeds, the curiosity of an individual agent updates over time by two incremental learning processes: One updates the characterization of eigenspace and another re-calculates the curiosity. In the multi-agent scenario, individual agent communicates and cooperates with each other at every learning stage to discover the discriminant characterization of the whole pattern. In the experiment, we described how the discriminative instances could be significantly selected based on the curiosity with, at most, minor sacrifices in learning rate and classification accuracy. The experimental results show that the proposed curiosity learning performs gracefully under different level of redundancy, and the proposed cILDA/mcILDA learning system is capable of learning less instances, but has more often an improved discrimination performance.	artificial neural network;authentication;c4.5 algorithm;decision tree;emoticon;k-nearest neighbors algorithm;linear discriminant analysis;mathematical model;multi-agent system;natural deduction;nn (newsreader);online machine learning;performance evaluation;prototype;radial (radio);radial basis function;support vector machine	Shaoning Pang;Seiichi Ozawa;Nikola K. Kasabov	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5178811	semi-supervised learning;face;instance-based learning;chromium;computer science;noise;artificial intelligence;machine learning;multi-agent system;pattern recognition;active learning;active learning	AI	12.5558309538823	-37.69815273528224	186523
5ee8a39f0291a159ade18b93c13e21877977d3dc	feature adaptive online sequential extreme learning machine for lifelong indoor localization	indoor localization;lifelong;feature adaptive;online sequential extreme learning machine os elm	Wi-Fi-based indoor localization with high capability and feasibility needs to implement lifelong online learning mechanism. However, the characteristic of Wi-Fi is wide variability, which lies in not only the fluctuation of signal strength value, but also the increase or decrease in the number of access points (APs). The traditional algorithms are effective for signal fluctuation, but cannot handle the dimension-changing problem of features caused by increase and decrease in APs’ number. To solve this problem, we propose a Feature Adaptive Online Sequential Extreme Learning Machine (FA-OSELM) algorithm. It can transfer the original model to a new one with a small number of data with new features, so as to make the new model suitable for the new feature dimension. The experiments show that the FA-OSELM can get higher accuracy with a small amount of new data, and it is an effective method to make lifelong indoor localization practical.	algorithm;effective method;error-tolerant design;euler characteristic;experiment;feature model;fractional anisotropy;money;quantum fluctuation;spatial variability;wireless access point	Xinlong Jiang;Junfa Liu;Yiqiang Chen;Dingjun Liu;Yang Gu;Zhenyu Chen	2014	Neural Computing and Applications	10.1007/s00521-014-1714-x	simulation;artificial intelligence;machine learning	AI	16.918016091324514	-33.11941564486664	186879
bdafff3d593ede58ed0dd1a452c4f5844ee453b2	byy harmony learning on finite mixture: adaptive gradient implementation and a floating rpcl mechanism	clustering analysis;metodo adaptativo;model selection;analyse amas;tecnologia electronica telecomunicaciones;gaussian mixture;learning algorithm;apprentissage competitif;computacion informatica;algoritmo adaptativo;model selection criteria;apprentissage harmonie;methode adaptative;algorithme apprentissage;bayesian ying yang system;harmony learning;adaptive algorithm;cluster analysis;algorithme adaptatif;theoretical analysis;ciencias basicas y experimentales;adaptive method;learning problems;analisis cluster;rival penalized competitive learning;systeme ying yang system;tecnologias;grupo a;finite mixture model;algoritmo aprendizaje;rival penalized;bayesian ying yang;color image segmentation;finite mixture	In tackling the learning problem on a set of finite samples, Bayesian Ying-Yang (BYY) harmony learning has developed a new learning mechanism that makes model selection implemented either automatically during parameter learning or in help of evaluating a new class of model selection criteria. In this paper, parameter learning with automated model selection has been studied for finite mixture model via an adaptive gradient learning algorithm for BYY harmony learning on a specific bidirectional architecture (BI-architecture). Via theoretical analysis, it has shown that the adaptive gradient learning implements a mechanism of floating rival penalized competitive learning (RPCL) among the components in the mixture. Also, the simulation results are demonstrated well for the adaptive gradient algorithm on the sample data sets from Gaussian mixtures with certain degree of overlap. Moreover, the adaptive gradient algorithm is applied to classification of the Iris data and unsupervised color image segmentation.	algorithm;bayesian network;color image;competitive learning;entropy (information theory);gradient;image segmentation;invariant (computer science);learning rule;mixture model;model selection;shannon (unit);simulation;theory;wang tile;yang	Jinwen Ma;Le Wang	2006	Neural Processing Letters	10.1007/s11063-006-9008-7	semi-supervised learning;unsupervised learning;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;mathematics;cluster analysis;competitive learning;active learning;generalization error	ML	11.867185986854384	-31.861835528467807	187400
d8cfae4a418ac4c95575dfe5b6f6ce34aeffe037	leveraging ontologies for lifted probabilistic inference and learning	coarse to fine inference and learning;approximate lifted inference;statistical relational models	Exploiting ontologies for efficient inference is one of the most widely studied topics in knowledge representation and reasoning. The use of ontologies for probabilistic inference, however, is much less developed. A number of algorithms for lifted inference in first-order probabilistic languages have been proposed, but their scalability is limited by the combinatorial explosion in the sets of objects that need to be considered. We propose a coarse-to-fine inference approach that leverages a class hierarchy to combat this problem. Starting at the highest level, our approach performs inference at successively finer grains, pruning low-probability atoms before refining. We provide bounds on the error incurred by this approach relative to full ground inference as a function of the pruning threshold. We also show how to learn parameters in a coarse-to-fine manner to maximize the opportunities for pruning during inference. Experiments on link prediction and biomolecular event prediction tasks show our method can greatly improve the scalability of lifted probabilistic infer-	algorithm;class hierarchy;first-order predicate;knowledge representation and reasoning;ontology (information science);scalability	Chloé Kiddon;Pedro M. Domingos	2010			backward chaining;adaptive neuro fuzzy inference system;computer science;semantic reasoner;artificial intelligence;machine learning;pattern recognition;data mining;algorithmic inference;probabilistic logic network;inference engine;statistics	AI	17.06930599982508	-34.78846069478237	187451
19303b656cb57c8cc8ab739b3c624d00c102264e	local-to-global bayesian network structure learning		We introduce a new local-to-global structure learning algorithm, called graph growing structure learning (GGSL), to learn Bayesian network (BN) structures. GGSL starts at a (random) node and then gradually expands the learned structure through a series of local learning steps. At each local learning step, the proposed algorithm only needs to revisit a subset of the learned nodes, consisting of the local neighborhood of a target, and therefore improves on both memory and time efficiency compared to traditional global structure learning approaches. GGSL also improves on the existing local-to-global learning approaches by removing the need for conflictresolving AND-rules, and achieves better learning accuracy. We provide theoretical analysis for the local learning step, and show that GGSL outperforms existing algorithms on benchmark datasets. Overall, GGSL demonstrates a novel direction to scale up BN structure learning while limiting accuracy loss.	algorithm;bayesian network;benchmark (computing)	Tian Gao;Kshitij P. Fadnis;Murray Campbell	2017			pattern recognition;machine learning;artificial intelligence;dynamic bayesian network;variable-order bayesian network;unsupervised learning;intelligent control;probabilistic neural network;bayesian network;wake-sleep algorithm;computer science;graphical model	ML	15.336227173877818	-31.540824008930155	188349
562c451dc9805eb090e4a97ccfaf6fb58818e182	identifying unknown unknowns in the open world: representations and policies for guided exploration		Predictive models deployed in the real world may assign incorrect labels to instances with high confidence. Such errors or unknown unknowns are rooted in model incompleteness, and typically arise because of the mismatch between training data and the cases encountered at test time. As the models are blind to such errors, input from an oracle is needed to identify these failures. In this paper, we formulate and address the problem of informed discovery of unknown unknowns of any given predictive model where unknown unknowns occur due to systematic biases in the training data. We propose a modelagnostic methodology which uses feedback from an oracle to both identify unknown unknowns and to intelligently guide the discovery. We employ a two-phase approach which first organizes the data into multiple partitions based on the feature similarity of instances and the confidence scores assigned by the predictive model, and then utilizes an explore-exploit strategy for discovering unknown unknowns across these partitions. We demonstrate the efficacy of our framework by varying the underlying causes of unknown unknowns across various applications. To the best of our knowledge, this paper presents the first algorithmic approach to the problem of discovering unknown unknowns of predictive models.	algorithm;open world;oracle database;predictive modelling;two-phase locking	Himabindu Lakkaraju;Ece Kamar;Rich Caruana;Eric Horvitz	2017			simulation;data mining	ML	16.50038403886485	-35.72903431378506	188957
2501d0bf0c2affe64afeefaf0be9defad29df040	evidence-based uncertainty sampling for active learning	active learning;uncertainty sampling;classification	Active learning methods select informative instances to effectively learn a suitable classifier. Uncertainty sampling, a frequently utilized active learning strategy, selects instances about which the model is uncertain but it does not consider the reasons for why the model is uncertain. In this article, we present an evidence-based framework that can uncover the reasons for why a model is uncertain on a given instance. Using the evidence-based framework, we discuss two reasons for uncertainty of a model: a model can be uncertain about an instance because it has strong, but conflicting evidence for both classes or it can be uncertain because it does not have enough evidence for either class. Our empirical evaluations on several real-world datasets show that distinguishing between these two types of uncertainties has a drastic impact on the learning efficiency. We further provide empirical and analytical justifications as to why distinguishing between the two uncertainties matters.	active learning (machine learning);information;sampling (signal processing);statistical classification	Manali Sharma;Mustafa Bilgic	2016	Data Mining and Knowledge Discovery	10.1007/s10618-016-0460-3	econometrics;machine learning;data mining;mathematics	ML	15.9463707996617	-37.93840235598019	189625
16ca5a516fa2c4696b9cb8f3c40ab6c25fd524f4	equivalent error bars for neural network classifiers trained by bayesian inference	bayesian inference	The topic of this paper is the problem of outlier detection for neural networks trained by Bayesian inference. I will show that marginalization is not a good method to get moderated probabilities for classes in outlying regions. The reason why marginalization fails to indicate outliers is analysed and an alternative measure, that is a more reliable indicator for outliers, is proposed. A simple artiicial classiication problem is used to visualize the diierences. Finally both methods are used to classify a real world problem, where outlier detection is mandatory.	analysis of algorithms;anomaly detection;artificial neural network;bayesian approaches to brain function;method of conditional probabilities	Peter Sykacek	1997			probabilistic neural network;artificial intelligence;adaptive neuro fuzzy inference system;machine learning;error bar;artificial neural network;time delay neural network;variable-order bayesian network;pattern recognition;dynamic bayesian network;computer science;bayesian inference	ML	16.189474944312238	-37.40999319067159	189680
e1caf0ed52ced0076dcf319d8021cc781692e45c	feature over-selection	genetic engineering;modelizacion;processus gauss;pulga de dna;high dimensionality;analisis estadistico;analisis estructural;puce a dna;loi conjointe;error sistematico;recherche aleatoire;bioinformatique;gene expression data;probabilistic approach;classification;gene expression;modelisation;expression genique;expected value;analyse syntaxique;statistical analysis;bias;analisis sintaxico;enfoque probabilista;approche probabiliste;syntactic analysis;analyse statistique;ingenieria genetica;genie genetique;dna chip;pattern recognition;classification error;ley conjunta;investigacion aleatoria;feature selection;reconnaissance forme;gaussian process;bioinformatica;analyse structurale;reconocimiento patron;proceso gauss;structural analysis;modeling;random search;expresion genetica;clasificacion;joint distribution;erreur systematique;bioinformatics	We propose probabilistic framework for analysis of inaccuracies due to feature selection (FS) when flawed estimates of performance of feature subsets are utilized. The approach is based on analysis of random search FS procedure and postulation that joint distribution of true and estimated classification errors is known a priori. We derive expected values for the FS bias, a difference between actual classification error after FS and classification error if ideal FS is performed according to exact estimates. The increase in true classification error due to inaccurate FS is comparable or even exceeds a training bias, a difference between generalization and Bayes errors. We have shown that there exists overfitting phenomenon in feature selection, entitled in this paper as feature over-selection. The effects of feature over-selection could be reduced if FS would be performed on basis of positional statistics. Theoretical results are supported by experiments carried out on simulated Gaussian data, as well as on high dimensional microarray gene expression data.	experiment;feature selection;microarray;overfitting;random search;stored procedure	Sarunas Raudys	2006		10.1007/11815921_68	genetic engineering;gene expression;random search;systems modeling;dna microarray;biological classification;computer science;artificial intelligence;parsing;bias;gaussian process;mathematics;structural analysis;joint probability distribution;feature selection;algorithm;expected value;statistics	ML	10.114705128406237	-35.08419008864465	189747
6cb72d96fb395f00b3523ce0f672cda0ba066a5f	speedup of color palette indexing in self-organization of kohonen feature map	learning process;sofm;color palette indexing;lookup table;speedup	Highlights? We point out two computational bottlenecks in the SOFM-based learning model. ? We propose a pruning-based search strategy for finding winning neurons. ? We propose a LUT-based lateral update interaction. ? Experimental results demonstrate that our proposed method have 35% execution-time improvement ratio in average. Based on the self-organization of Kohonen feature map (SOFM), recently, Pei et al. presented an efficient color palette indexing method to construct a color table for compression. Taking the palette indexing method as a representative, this paper presents two new strategies, the pruning-based search strategy and the lookup table (LUT)-based update strategy, to speed up the learning process in the SOFM. Based on four typical testing images, experimental results illustrate that our proposed two strategies have 35% execution-time improvement ratio in average. The practical improvement ratio is very close to that in the theoretical analysis.	palette (computing);self-organization;self-organizing map;speedup	Kuo-Liang Chung;Yong-Huai Huang;Jyun-Pin Wang;Ming-Shao Cheng	2012	Expert Syst. Appl.	10.1016/j.eswa.2011.08.092	computer vision;lookup table;speedup;computer science;artificial intelligence;machine learning	DB	14.092670812004215	-31.801203768359624	189918
f03ab93b840629137c9f2d01dbcf16d80facf9de	incremental knowledge acquisition in supervised learning networks	structure learning;information structure;empirical study;supervised learning;neural nets;rule based;neural net incremental knowledge acquisition incremental learning system supervised learning networks embedded incrementable information structure pattern recognition rule based connectionist technique domain knowledge case specific knowledge bounded weight modification structural learning overtraining;incremental learning;knowledge acquisition;pattern recognition;learning artificial intelligence;knowledge acquisition intelligent networks supervised learning learning systems fasteners pattern recognition subspace constraints real time systems monitoring process control;pattern recognition neural nets knowledge acquisition learning artificial intelligence	Acquiring new knowledge without interfering with old knowledge is a key issue in designing an incremental-learning system. The success of such a system hinges on an embedded incrementable information structure with improved performance over time. This paper describes an incremental-learning network for pattern recognition that uses a rule-based connectionist technique to represent general domain and case-specific knowledge, uses bounded weight modification to update its connection weights, and also performs strucdural learning. Specific strategies are developed for preventing overtraining and for incrementally growing and pruning the network. The soundness of this approach is demonstrated by empirical studies in two independent domains.	connectionism;embedded system;knowledge acquisition;logic programming;pattern recognition;supervised learning	LiMin Fu	1996	IEEE Trans. Systems, Man, and Cybernetics, Part A	10.1109/3468.541338	semi-supervised learning;unsupervised learning;instance-based learning;error-driven learning;computer science;artificial intelligence;machine learning;pattern recognition;learning classifier system;supervised learning;competitive learning;empirical research;active learning;artificial neural network;generalization error	AI	15.95359048899531	-33.47800888787133	191178
485a1be3f122f88fef25dc8d243fa23d3b715bb1	data description in subspaces	nearest neighbor searches object detection gaussian distribution covariance matrix pattern recognition extrapolation testing;sample size;probability density;normal distribution;extrapolation pattern classification data description probability density normal distribution nearest neighbor distances data boundary machine learning;extrapolation;extrapolation pattern classification learning systems normal distribution statistical analysis;learning systems;statistical analysis;nearest neighbor;pattern classification	In this paper we investigate how the boundary of a data set can be obtained in case of (very) low sample sizes. This boundary can be used to detect if new objects resemble the data set and therefore make the subsequent classification more confident. When a large number of training objects is available it is possible to directly estimate the density. After thresholding the probability density a boundary around the data is obtained. However in the case of very low sample sizes, extrapolations have to be performed. In this paper we propose a simple method based on nearest neighbor distances which is capable to find data boundaries in these low sample sizes. It appears to be especially useful when the data is distributed in subspaces.	k-nearest neighbors algorithm;thresholding (image processing)	David M. J. Tax;Robert P. W. Duin	2000		10.1109/ICPR.2000.906164	normal distribution;large margin nearest neighbor;sample size determination;probability density function;machine learning;pattern recognition;mathematics;extrapolation;k-nearest neighbors algorithm;statistics	ML	15.373256046432008	-35.67774474122702	191388
259a46a50d57723e4c06ba100c0da1a7810e61e9	a balanced neural tree for pattern classification	performance evaluation;decision trees dts;pattern classification;neural networks nns;perceptron;neural trees nts	This paper proposes a new neural tree (NT) architecture, balanced neural tree (BNT), to reduce tree size and improve classification with respect to classical NTs. To achieve this result, two main innovations have been introduced: (a) perceptron substitution and (b) pattern removal. The first innovation aims to balance the structure of the tree. If the last-trained perceptron largely misclassifies the given training set into a reduced number of classes, then this perceptron is substituted with a new perceptron. The second novelty consists of the introduction of a new criterion for the removal of tough training patterns that generate the problem of over-fitting. Finally, a new error function based on the depth of the tree is introduced to reduce perceptron training time. The proposed BNT has been tested on various synthetic and real datasets. The experimental results show that the proposed BNT leads to satisfactory results in terms of both tree depth reduction and classification accuracy.	algorithm;class;converge;emoticon;equilibrium;less than;memory-level parallelism;neural tube defects;overfitting;perceptron;synthetic intelligence;test set;trees (plant)	Christian Micheloni;Asha Rani;Sanjeev Kumar;Gian Luca Foresti	2012	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2011.10.007	computer science;artificial intelligence;perceptron;machine learning;pattern recognition;incremental decision tree	ML	14.18464642701495	-33.49838421145376	192165
70229207826cc4ad8c46bf3cde015b3e14f022cd	a practical view of suboptimal bayesian classification with radial gaussian kernels	institutional repositories;bayesian classification;fedora;vital;gaussian kernel;vector quantizer;vtls;ils	For pattern classi cation in a multi dimensional space the minimum misclassi cation rate is obtained by using the Bayes criterion Kernel estimators or probabilistic neural networks provide a good way to evaluate the probability densities of each class of data and are an interesting parallel implementation of the Bayesian classi er However their training procedure leads to a very high number of neurons when large datasets are available the classi er then becomes too complex and time consuming for on line operation Suboptimal Bayesian classi ers based on radial Gaussian kernels uses an iterative unsupervised learning method based on vector quantization to obtain a signi cant simpli cation of the network structure while keeping su ciently accurate estimations of probability densities In this paper we study the vector quantization problem and the e ects of codebook size and data space dimension on the optimal width factors of the radial Gaussian kernels used in the estimation	artificial neural network;bayesian network;codebook;dataspaces;iterative method;naive bayes classifier;radial (radio);radial basis function;unsupervised learning;variable kernel density estimation;vector quantization	Jean-Luc Voz;Michel Verleysen;Philippe Thissen;Jean-Didier Legat	1995		10.1007/3-540-59497-3_202	naive bayes classifier;computer science;machine learning;pattern recognition;mathematics;gaussian function;statistics	ML	15.793118676319596	-35.517201761122976	192321
195ff1b97d4ef7d494a235d957d9ab19924f7e78	design of fully and partially connected random neural networks for pattern completion	adaptive thresholding;learning algorithm;random neural network;gradient descent;local interaction	In previous works [1,2,3], the behavior of a fully-connected single-layer Random Neural Network (RN) [4,5] has been illustrated in a problem of pattern completion. We applied the gradient-descent learning algorithm which has been introduced by Gelenbe [6,7] for recurrent RN networks. The recall of any training pattern from a corrupted version consists in a progressive retrieval process with adaptive threshold. We have reduced the influence of the pattern geometry on the performance by modifying the computation of the network state. The experimental results are now compared to thoses obtained with Hopfield's network. As the learning times in such a model become rapidly prohibitive, we look into the use of a single-layer network with local interactions between neurons. The connectivity influence on the convergence of the learning algorithm and on the recognition rates is particularly examined.	neural networks	Christine Hubert	1993		10.1007/3-540-56798-4_137	gradient descent;stochastic neural network;feedforward neural network;mathematical optimization;types of artificial neural networks;random neural network;computer science;recurrent neural network;machine learning;pattern recognition;time delay neural network;mathematics;deep learning;thresholding;artificial neural network	AI	16.423468695595666	-31.525705165713195	194007
b2a99f34fb945d7ea843f859e840dfbd357401a8	fast incremental techniques for learning production rule probabilities in radar electronic support	performance measure;stochastic context free grammar;generalization error;stochastic context free grammars;radar electronic support;radar computing;incremental learning fast incremental techniques learning production rule probabilities radar electronic support stochastic context free grammars radar emitters graphical em tree scanning radar pulse data set computational complexity;fast incremental techniques;pulse measurements stochastic systems production systems tree graphs computer errors convergence computer simulation radar measurements time measurement computational complexity;radar equipment;trees mathematics;tree scanning;trees mathematics computational complexity expectation maximisation algorithm learning artificial intelligence radar computing radar equipment;support system;incremental learning;computational complexity;radar emitters;space complexity;learning artificial intelligence;graphical em;convergence time;radar pulse data set;computer simulation;learning production rule probabilities;production rule;expectation maximisation algorithm	Although Stochastic context-free grammars appear promising for recognition of radar emitters, and for estimation of their respective level of threat in radar electronic support systems, well-known techniques for learning their production rule probabilities are computationally demanding. In this paper, three fast incremental alternatives, called graphical EM (gEM), tree scanning (TS), and HOLA, are compared from several perspectives - perplexity, generalization error, time and space complexity, and convergence time. Estimation of the execution time and storage requirements allows for the assessment of complexity, while computer simulation using a radar pulse data set allows to asses the other performance measures. Results indicate that gEM and TS may provide a greater level of accuracy than HOLA, and that computational complexity may be orders of magnitude lower with HOLA. Furthermore, HOLA is an on-line technique that allows for incremental learning of probabilities to reflect changes in operational environments	computational complexity theory;computer simulation;context-free language;dspace;generalization error;online and offline;perplexity;production (computer science);radar;requirement;run time (program lifecycle phase);stochastic context-free grammar	Guillaume Latombe;Eric Granger;Fred A. Dilkes	2006	2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings	10.1109/ICASSP.2006.1661390	computer simulation;computer vision;speech recognition;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;dspace;computational complexity theory;stochastic context-free grammar;statistics;generalization error	Robotics	15.390974250307343	-36.587215557274064	194058
9cb37a92bc8734217a87c299a60e4348cf626ed2	timeliness online regularized extreme learning machine		To improve the learning performance, a novel online sequential extreme learning machine (ELM) algorithm for single-hidden layer feedforward networks is proposed with regularization mechanism in a unified framework. The proposed algorithm is called timeliness online regularized extreme learning machine (TORELM). Like the timeliness managing extreme learning machine which improves online sequential extreme learning machine by incorporating timeliness management scheme into ELM approach for the incremental training samples, TORELM also analyzes the training data one-by-one or chunk-by-chunk (a block of data) with fixed or varied chunk size under the similar framework. Meanwhile, the newly incremental training data could be prior to the historical data by maximizing the contribution of the newly increasing training data, since in some cases it may be more feasible that the incremental data can contribute reasonable weights to represent the current system situation in accordance with the practical analysis. Furthermore, in consideration of the disproportion between empirical risk and structural risk in some traditional learning methods, we add regularization technique to the timeliness scheme of TORELM through the use of a weight factor to balance them to achieve better generalization performance. Hence, TORELM has its unique feature of higher generalization capability in most cases with a small testing error while implementing online sequential learning. In addition, this algorithm is still competitive in training time compared with other schemes. Finally, the simulation results show that TORELM can achieve higher learning accuracy and better stability than other ELM-based machine learning methods.		Xiong Luo;Xiaona Yang;Changwei Jiang;Xiaojuan Ban	2018	Int. J. Machine Learning & Cybernetics	10.1007/s13042-016-0544-9	early stopping;semi-supervised learning;online machine learning;instance-based learning;active learning (machine learning);data mining;artificial intelligence;extreme learning machine;machine learning;multi-task learning;stability (learning theory);computer science	AI	14.940032700867803	-37.83845969127063	194643
53dbfd3bfdf271efe8acb35890b48728deeffe86	a comparative study on regularization strategies for embedding-based neural networks		This paper aims to compare different regularization strategies to address a common phenomenon, severe overfitting, in embedding-based neural networks for NLP. We chose two widely studied neural models and tasks as our testbed. We tried several frequently applied or newly proposed regularization strategies, including penalizing weights (embeddings excluded), penalizing embeddings, reembedding words, and dropout. We also emphasized on incremental hyperparameter tuning, and combining different regularizations. The results provide a picture on tuning hyperparameters for neural NLP models.	artificial neural network;dropout (neural networks);natural language processing;overfitting;testbed	Hao Peng;Lili Mou;Ge Li;Yunchuan Chen;Yangyang Lu;Zhi Jin	2015			mathematical optimization;computer science;artificial intelligence;machine learning;statistics	NLP	16.712600851395354	-32.43024234912083	194834
89d239cd19542b72818c8973b64dc5d578191ac9	growing a multi-class classifier with a reject option	reconnaissance visage;evaluation performance;densite probabilite;performance evaluation;image processing;probability density;biometrie;evaluacion prestacion;heuristic method;biometrics;biometria;procesamiento imagen;outlier;metodo heuristico;posterior probability;traitement image;densidad probabilidad;outlier detection;observacion aberrante;rejection;automatic recognition;face recognition;multi class classification;probabilite a posteriori;signal classification;probabilidad a posteriori;pattern recognition;classification signal;linear transformation;transformation non lineaire;transformacion no lineal;observation aberrante;methode heuristique;reconnaissance forme;classification automatique;reconocimiento patron;automatic classification;clasificacion automatica;non linear transformation;reconocimiento automatico;reconnaissance automatique	In many classification problems objects should be rejected when the confidence in their classification is too low. An example is a face recognition problem where the faces of a selected group of people have to be classified, but where all other faces and non-faces should be rejected. These problems are typically solved by estimating the class densities and assigning an object to the class with the highest posterior probability. The total probability density is thresholded to detect the outliers. Unfortunately, this procedure does not easily allow for class-dependent thresholds, or for class models that are not based on probability densities but on distances. In this paper we propose a new heuristic to combine any type of one-class models for solving the multi-class classification problem with outlier rejection. It normalizes the average model output per class, instead of the more common non-linear transformation of the distances. It creates the possibility to adjust the rejection threshold per class, and also to combine class models that are not (all) based on probability densities and to add class models without affecting the boundaries of existing models. Experiments show that for several classification problems using class-specific models significantly improves the performance. 2008 Elsevier B.V. All rights reserved.	experiment;facial recognition system;heuristic;multiclass classification;nonlinear system;rejection sampling	David M. J. Tax;Robert P. W. Duin	2008	Pattern Recognition Letters	10.1016/j.patrec.2008.03.010	probability density function;outlier;image processing;computer science;artificial intelligence;machine learning;multiclass classification;pattern recognition;mathematics;linear map;posterior probability;biometrics;statistics	Vision	10.863063626724825	-34.53304273229443	195484
8e620ddc0fd0c649891c19ad6884025b17bced20	the roc skeleton for multiclass roc estimation	grid generation;receiver operator characteristic;operating characteristics;computational complexity;roc analysis;operating characteristic;efficient estimation;multiclass roc;cost sensitive optimisation	Multiclass operating characteristics are a generalisation of the two-class receiver operator characteristic. A limitation regarding this generalisation is the computational complexity with increasing numbers of classes. In this paper, the ROC skeleton approach is proposed for efficiently estimating the operating characteristic. New operating points are computed from actual training samples, versus an alternative approach involving grid generation, that is prone to redundant calculations, and poor adaptation to certain classifier architectures. An extensive experimentation with a number of datasets and classifiers as a function of the number of calculations reveals the efficiency of this approach. Also notable is how in many cases good performance can be achieved with surprisingly few calculations, but the converse may also apply.	receiver operating characteristic	Thomas Landgrebe;Pavel Paclík	2010	Pattern Recognition Letters	10.1016/j.patrec.2009.12.037	computer science;machine learning;pattern recognition;mathematics;receiver operating characteristic;statistics	Vision	12.040097628623073	-36.92844653340134	196035
ba59fc10691c922d95c3b9b331254e910b3e281f	suboptimal bayesian classification by vector quantization with small clusters	institutional repositories;bayesian classification;fedora;probability density;vital;multi dimensional;vector quantizer;vtls;probabilistic neural network;ils	 Multi-dimensional classification based on the Bayes criterionminimizes the probability of misdassification. In order to apply thiscriterion, one has to know or to evaluate the probability densities ofeach class of data. Parzen windows or probabilistic neural networks maybe used to estimate these probability densities; however, the number ofoperations involved in such process is prohibitive for large databases. Theproposed algorithm shows how to apply vector quantization techniques... 	bayesian network;naive bayes classifier;vector quantization	Jean-Luc Voz;Michel Verleysen;Philippe Thissen;Jean-Didier Legat	1995			probability density function;probabilistic neural network;naive bayes classifier;learning vector quantization;computer science;machine learning;pattern recognition;data mining;relevance vector machine	ML	15.667162423468845	-35.64735592330252	196071
867827f0c823adb533f076f39838249a6719fea1	credit scoring models with auc maximization based on weighted svm	credit scoring;decision tree;kernel function;linear regression;auc;logistic regression;receiver operating characteristic curve;large scale;radial basis function;financial institutions;feature weighting;features weighting;k nearest neighbor;svm;cross validation;support vector machine;classification accuracy;quantitative method;neural network;least squares support vector machine	Credit scoring models are very important tools for financial institutions to make credit granting decisions. In the last few decades, many quantitative methods have been used for the development of credit scoring models with focus on maximizing classification accuracy. This paper proposes the credit scoring models with the area under receiver operating characteristics curve (AUC) maximization based on the new emerged support vector machines (SVM) techniques. Three main SVM models with different features weighted strategies are discussed. The weighted SVM credit scoring models are tested using 10-fold cross validation with two real world data sets and the experimental results are compared with other six traditional methods including linear regression, logistic regression, k nearest neighbor, decision tree, and neural network. Results demonstrate that weighted 2-norm SVM with radial basis function (RBF) kernel function and t-test feature weighting strategy has the overall better performance with very narrow margin than other SVM models. However, it also consumes more computational time. In considering the balance of performance and time, least squares support vector machines (LSSVM) with RBF kernel maybe a better choice for large scale credit scoring applications.	adaboost;artificial neural network;computation;decision tree;expectation–maximization algorithm;least squares support vector machine;logistic regression;radial (radio);radial basis function kernel;software release life cycle;time complexity	Ligang Zhou;Kin Keung Lai;Jerome Yen	2009	International Journal of Information Technology and Decision Making	10.1142/S0219622009003582	support vector machine;computer science;machine learning;pattern recognition;data mining;artificial neural network	AI	10.96232396548979	-37.839243002246135	196077
4d00b30a047e7a2a64c6759f31c371d8ff79891f	support vector machines and generalisation in hep		We review the concept of support vector machines (SVMs) and discuss examples of their use. One of the benefits of SVM algorithms, compared with neural networks and decision trees is that they can be less susceptible to over fitting than those other algorithms are to over training. This issue is related to the generalisation of a multivariate algorithm (MVA); a problem that has often been overlooked in particle physics. We discuss cross validation and how this can be used to improve the generalisation of a MVA in the context of High Energy Physics analyses. The examples presented use the Toolkit for Multivariate Analysis (TMVA) based on ROOT and describe our improvements to the SVM functionality and new tools introduced for cross validation within this framework.	algorithm;artificial neural network;black–derman–toy model;cross-validation (statistics);decision tree;heterogeneous element processor;model–view–adapter;multistage amplifier;overfitting;root;support vector machine	Adrian J. Bevan;Rodrigo Gamboa Goñi;Jon Hays;Tom J. Stevenson	2016	CoRR	10.1088/1742-6596/898/7/072021	physics	ML	11.33263623201647	-37.39474776903405	196585
dacaba137ba86be9dc655d80d5a074dea3731f36	generalization capability of artificial neural network incorporated with pruning method	rate of generalization;pruning;neural network;generalization capability	In any real world application, the performance of Artificial Neural Networks (ANN) is mostly depends upon its generalization capability. Generalization of the ANN is ability to handle unseen data. The generalization capability of the network is mostly determined by system complexity and training of the network. Poor generalization is observed when the network is over-trained or system complexity (or degree of freedom) is relatively more than the training data. A smaller network which can fit the data will have the k good generalization ability. Network parameter pruning is one of the promising methods to reduce the degree of freedom of a network and hence improve its generalization. In recent years various pruning methods have been developed and found effective in real world applications. Next, it is important to estimate the improvement in generalization and rate of improvement as pruning being incorporated in the network. A method is developed in this research to evaluate generalization capability and rate of convergence towards the generalization. Using the proposed method, experiments have been conducted to evaluate Multi-Layer Perceptron neural network with pruning being incorporated for handwritten numeral recognition.	artificial neural network	Siddhaling Urolagin;K. V. Prema;N. V. Subba Reddy	2011		10.1007/978-3-642-29280-4_19	computer science;artificial intelligence;machine learning;pattern recognition	ML	16.193581331229108	-32.19917098336965	196789
50a87c6ffce8bb04fd02153685195f718396e3a5	time series classification by imprecise hidden markov models		"""Hidden Markov models (HMMs) are powerful tools for modelling the generative and observational processes behind time series. For short sequences, the small amount of data can make unreliable the estimates returned by the EM algo- rithm, which is generally used to learn HMMs. To gain robustness in these cases, an imprecise version of the EM algorithm, achieving an interval-valued quantification of the model parameters can be considered instead. The bounds of the likelihood assigned to a particular sequence with respect to these intervals can be efficiently computed. Overall, this provides a time series classification algorithm. To classify a new sequence, the bounds of the likelihood associated to the HMMs learned from the supervised sequences are evaluated, and the returned class label is that of the highest-likelihood interval. If two or more of these intervals overlap and they are associated to different labels, the classifier returns multiple classes, this correspond- ing to a condition of partial indecision for the class of a particular sequence. An application to human action recognition shows the effectiveness of this approach in discriminating the hard-to-classify instances (those for which the classifier returns many classes) from the """"easy"""" ones (those for which a single class, which mostly is the correct one, is returned). This suggests the opportunity of an application of the proposed approach as an useful preprocessing tool for other time series classifiers."""	hidden markov model;markov chain;time series	Alessandro Antonucci;Rocco De Rosa	2011		10.3233/978-1-60750-972-1-195	machine learning;pattern recognition;mathematics;statistics	ML	15.766934273591009	-37.54056144559884	196817
48c817a54a977a74fb9b676f2b4d182bf7b7c176	deep learning for credit card data analysis	libraries;machine learning algorithms;gaussian kernel svm credit card data analysis advanced deep learning methods machine learnings;data mining;data analysis;machine learning;support vector machines credit transactions data analysis financial data processing learning artificial intelligence;sparks;machine learning credit cards machine learning algorithms sparks libraries data analysis data mining;credit cards	In this paper, two major applications are introduced to develop advanced deep learning methods for credit-card data analysis. The proposed methods are validated using benchmark experiments with other machine learnings. The experiments confirm that deep learning exhibits similar accuracy to the Gaussian kernel SVM.	benchmark (computing);deep learning;experiment;transaction data	Ayahiko Niimi	2015	2015 World Congress on Internet Security (WorldCIS)	10.1109/WorldCIS.2015.7359417	instance-based learning;computer science;data science;online machine learning;machine learning;data mining;stability;computational learning theory;active learning	ML	12.751935093590525	-36.54046342946249	197048
8b0df931155426bf331f38ce7b3a597f06e890d8	factorization ranking model for move prediction in the game of go		In this paper, we investigate the move prediction problem in the game of Go by proposing a new ranking model named Factorization Bradley Terry (FBT) model. This new model considers the move prediction problem as group competitions while also taking the interaction between features into account. A FBT model is able to provide a probability distribution that expresses a preference over moves. Therefore it can be easily compiled into an evaluation function and applied in a modern Go program. We propose a Stochastic Gradient Decent (SGD) algorithm to train a FBT model using expert game records, and provide two methods for fast computation of the gradient in order to speed up the training process. Experimental results show that our FBT model outperforms the state-of-the-art move prediction system of Latent Factor Ranking (LFR).	algorithm;bradley–terry model;compiler;computation;computer vision;convolutional neural network;david w. bradley;evaluation function;gradient;kerrison predictor;monte carlo tree search;object detection;speedup	Chenjun Xiao;Martin Müller	2016			simulation;computer science;artificial intelligence;machine learning;statistics	AI	13.771729943869474	-34.244317521590645	197201
517990eac49b325c7c7f08fd11058e64473ce42d	fast static available transfer capability determination using radial basis function neural network	competitive electricity market;available transfer capability;euclidean distance;electricity market;radial basis function;power system;radial basis function neural network;random forest;market participation;feature selection;euclidean distance based clustering technique;new england;neural network;random forest technique	In a competitive electricity market, available transfer capability information is required by market participants as well as the system operator for secure operation of the power system. The on-line updating of available transfer capability information requires a fast and accurate method for its determination. This paper proposes a radial basis function neural network based method for available transfer capability estimation in an electricity market having bilateral as well as multilateral transactions. Euclidean distance based clustering technique has been employed to select the number of hidden radial basis function units and unit centres for the radial basis function neural network. In order to reduce the number of inputs and the size of the neural network, a feature selection has been performed using two different methods based on Euclidean distance based clustering and random forest technique and the performance of the radial basis function neural network, trained with features selected using these two methods, has been compared. The effectiveness of the proposed method has been tested on 39-bus New England system and a practical 246-bus Indian system.	artificial neural network;radial (radio);radial basis function	T. Jain;Sri Niwas Singh;Suresh C. Srivastava	2011	Appl. Soft Comput.	10.1016/j.asoc.2010.11.006	random forest;mathematical optimization;radial basis function;electricity market;computer science;artificial intelligence;machine learning;euclidean distance;electric power system;feature selection;radial basis function network;artificial neural network	ML	13.105025798959192	-33.17701348824071	197449
2a4453cbe0586be60aaea79035d73e03fcfec967	using linear-threshold algorithms to combine multi-class sub-experts	linear functionals	We present a new type of multi-class learning algorithm called a linear-max algorithm. Linearmax algorithms learn with a special type of attribute called a sub-expert. A sub-expert is a vector attribute that has a value for each output class. The goal of the multi-class algorithm is to learn a linear function combining the sub-experts and to use this linear function to make correct class predictions. The main contribution of this work is to prove that, in the on-line mistake-bounded model of learning, a multi-class sub-expert learning algorithm has the same mistake bounds as a related two class linear-threshold algorithm. We apply these techniques to three linear-threshold algorithms: Perceptron, Winnow, and Romma. We show these algorithms give good performance on artificial and real datasets.	algorithm;experiment;linear function;machine learning;online and offline;perceptron;winnow (algorithm)	Chris Mesterharm	2003			winnow;mathematical optimization;weighted majority algorithm;cultural algorithm;computer science;machine learning;mathematics;algorithm;population-based incremental learning	ML	14.292290525940409	-34.70849681206883	197707
8c53aa5ec34135ec2a50dc431a5df03811018571	parallel implementation of neural networks training on graphic processing unit	belief networks;speech recognition gpu bp neural network acoustic model;neural nets;parallel programming;acoustic signal processing;speech recognition acoustic signal processing backpropagation belief networks graphics processing units neural nets parallel programming;backpropagation;dbn parallel implementation neural network training graphic processing unit artificial neural network deep belief network acoustic model training ann backpropagation neural network acoustic model speech recognition parallel reduction application asynchronous implementation cpu gpu;graphics processing units;speech recognition	Recently artificial neural network (ANN) especially the deep belief network (DBN) becomes more and more popular in the acoustic model training. In order to improve the speed of ANN, the Graphics Processing Unit (GPU) is used. This paper gives the training details of the Back-Propagation (BP) neural network acoustic model for speech recognition on GPU, including the parallel reduction application and asynchronous implementation between CPU and GPU. It is 26 times faster than using the single thread Intel® MKL(Math Kernel Library) implementation.	acoustic cryptanalysis;acoustic model;artificial neural network;backpropagation;bayesian network;central processing unit;deep belief network;graphics processing unit;math kernel library;software propagation;speech recognition	Yong Liu;Yeming Xiao;Li Wang;Jielin Pan;Yonghong Yan	2012	2012 5th International Conference on BioMedical Engineering and Informatics	10.1109/BMEI.2012.6513078	speech recognition;computer science;artificial intelligence;backpropagation;machine learning;time delay neural network;deep learning;artificial neural network	Robotics	12.435228312447213	-35.979320872104964	199031
99b2144a807f2e86a2bd08846d45a57afd1d3aa7	simple and stable internal representation by potential mutual information maximization		The present paper aims to interpret final representations obtained by neural networks by maximizing the mutual information between neurons and data sets. Because complex procedures are needed to maximize information, the computational procedures are simplified as much as possible using the present method. The simplification lies in realizing mutual information maximization indirectly by focusing on the potentiality of neurons. The method was applied to restaurant data for which the ordinary regression analysis could not show good performance. For this problem, we tried to interpret final representations and obtain improved generalization performance. The results revealed a simple configuration where just a single important feature was extracted to explicitly explain the motivation to visit the restaurant.	expectation–maximization algorithm;mutual information	Ryotaro Kamimura	2016		10.1007/978-3-319-44188-7_23	mathematical optimization;machine learning;welfare economics;interaction information;pointwise mutual information	ML	15.59711653124631	-32.39361614333401	199283
c2f536a43170a5f5141c6aa73d7808a41adcf9ff	training of cc4 neural network with spread unary coding		This paper adapts the corner classification algorithm (CC4) to train the neural networks using spread unary inputs. This is an important problem as spread unary appears to be at the basis of data representation in biological learning. The modified CC4 algorithm is tested using the pattern classification experiment and the results are found to be good. Specifically, we show that the number of misclassified points is not particularly sensitive to the chosen radius of generalization.	algorithm;artificial neural network;data (computing);unary coding;unary operation	Pushpa Sree Potluri	2015	CoRR		unary coding;theoretical computer science;machine learning;algorithm	ML	14.086278356582115	-34.10659900767838	199295
22a258852216dab4ac119528fa660d0a17258f0a	cloudsvm: training an svm classifier in cloud computing systems	support vector machines;distributed computing;mapreduce;cloud computing	In conventional method, distributed support vector machines (SVM) algorithms are trained over pre-configured intranet/internet environments to find out an optimal classifier. These methods are very complicated and costly for large datasets. Hence, we propose a method that is referred as the Cloud SVM training mechanism (CloudSVM) in a cloud computing environment with MapReduce technique for distributed machine learning applications. Accordingly, (i) SVM algorithm is trained in distributed cloud storage servers that work concurrently; (ii) merge all support vectors in every trained cloud node; and (iii) iterate these two steps until the SVM converges to the optimal classifier function. Large scale data sets are not possible to train using SVM algorithm on a single computer. The results of this study are important for training of large scale data sets for machine learning applications. We provided that iterative training of splitted data set in cloud computing environment using SVM will converge to a global optimal classifier in finite iteration size.	algorithm;apache hadoop;cloud computing;cloud storage;computer;converge;empirical risk minimization;intranet;iteration;machine learning;mapreduce;parallel computing;scalability;support vector machine	Ferhat Özgür Çatak;M. Erdal Balaban	2012		10.1007/978-3-642-37015-1_6	support vector machine;cloud computing;computer science;theoretical computer science;operating system;machine learning;data mining;ranking svm;structured support vector machine	ML	13.08803279129671	-36.83005682430056	199376
