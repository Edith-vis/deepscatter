id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
d8e527fcaea234f1fd24928551e1a36bd4984853	enabling peer-to-peer communication for hosts in private address realms using ipv4 lsrr option and ipv4+4 addresses	teletrafic;internet protocol;protocols;routeur;packet forwarding algorithm;end host protocol;protocolo internet;ipv4 lsrr option;ipv4 loose source record route option;routing;implementation;par a par;reseau ordinateur;protocole internet;routage;packet switching;conmutacion por paquete;private address realm;network address translation;approche deterministe;computer network;partage des ressources;algorithme;deterministic approach;linux based border router peer to peer communication private address realm ipv4 lsrr option ipv4 4 address network address translation ipv4 loose source record route option end host protocol internet router packet forwarding algorithm p2p traffic;algorithm;telecommunication traffic;teletrafico;telecommunication traffic internet ip networks peer to peer computing protocols telecommunication network routing;internet;telecommunication network routing;poste a poste;p2p traffic;internet router;resource sharing;enfoque determinista;particion recursos;teletraffic;linux based border router;router;red informatica;peer to peer communication;ip networks;ipv4 4 address;peer to peer computing;implementacion;peer to peer;commutation paquet;algoritmo;enrutamiento	Enabling peer-to-peer (P2P) communication for hosts behind network address translation (NAT) boxes is an important and difficult problem. Existing proposals, for example, UPnP, MIDCOM, TURN, STUN, STUNT, P2PNAT, NATBlaster among others, offer only partial, limited and non-deterministic solutions. A framework that offers a complete solution to the P2P communication problem is presented. The proposed framework is based on the use of IPv4þ4 addresses and the standard IPv4 Loose Source Record Route (LSRR) option and requires no changes whatsoever to end-host protocol stacks and Internet routers. The only requirement is a simple upgrade of border routers with a new LSRR-based packet-forwarding algorithm for the P2P traffic. The implementation of a Linux-based border router that runs the proposed forwarding algorithm is detailed, and how P2P applications can benefit from this framework is described.	algorithm;linux;network address translation;network packet;peer-to-peer;realms;router (computing);universal plug and play	Cihan Topal;Cuneyt Akinlar	2009	IET Communications	10.1049/iet-com.2008.0364	internet protocol;shared resource;communications protocol;routing;the internet;telecommunications;computer science;distributed computing;network address translation;deterministic system;implementation;computer security;packet switching;computer network	Networks	-5.335346422663176	76.23381290420751	191877
97c32bbb81806fc90077ede32716c2413a19ae59	comparative analysis of sdn and conventional networks using routing protocols		Conventional routing protocols such as RIP, OSPF, EIGRP and BGP have a very rigid and intricate system thus narrowing the adaptability of networks to the ever changing Internet. The emergence of Software Defined Networking (SDN) provides a solution for this problem. Due to the handiness of a centralized controller, SDN has provided an effective method in terms of routing computation and fine control over data packets. Due to the increase in unpredicted failures taking place the ability to predict/know the approximate maximum time it takes for these networks to converge in order to avoid and/or minimize loss of packets/data during these failures has become crucial in today's world. This time that the routers in the network take to converge via the implemented routing protocol and resume communication or transfer of information is called the routing convergence time. In this work, the performance is measured using routing convergence time during link failure with respect to the topology scale to show that SDN routing/forwarding is better compared to conventional routing. Further the results indicate that the routing convergence time is less in SDN networks on comparison with conventional networks when the topology scale is increased, indicating that SDN networks converge faster in comparison with Conventional networks and that routing convergence time is greatly influenced with the changing topological size.	approximation algorithm;border gateway protocol;centralized computing;computation;converge;effective method;emergence;like button;network packet;network switch;router (computing);routing table;software propagation;software-defined networking	Deepthi Gopi;Samuel Cheng;Robert C. Huck	2017	2017 International Conference on Computer, Information and Telecommunication Systems (CITS)	10.1109/CITS.2017.8035305	policy-based routing;routing information protocol;wireless routing protocol;dynamic source routing;link-state routing protocol;computer network;equal-cost multi-path routing;distance-vector routing protocol;static routing;distributed computing;computer science	Networks	-9.012586807407112	79.92376940690615	191899
341fd168d5ce2f776aaa27c19983dd6bf5ca14f7	reliable multiuser tree setup with local identifiers	transmision paquete;protocols;multicast communication;architecture systeme;protocole transmission;switch control subsystem tree connection setup protocol multiuser tree setup multicast communication high speed packet switched network local identifiers fast access routing tables routing space local label swapping data messages;high speed networks;trees mathematics packet switching protocols;packet switched;packet switching;red telefonica;trees mathematics;protocolo transmision;telecommunication network reliability routing switches multicast protocols access protocols multicast communication packet switching communication switching high speed networks multiprotocol label switching;identification;packet transmission;identificacion;arquitectura sistema;telephone network;system architecture;reseau telephonique;transmission paquet;multiutilisateur;switching control;transmission protocol	The authors present a reliable protocol for setting up a tree connection for the purpose of multicast communication over a high-speed packet switched network. The tree connection is based on the use of local identifiers that are swapped at every intermediate node of the tree. Local identifiers are simple to manage, provide fast access to the routing tables, and are very efficient in terms of the size of the resulting routing space. The context of the present work is a high-speed network in which the local label swapping on data messages is performed in hardware by the switching subsystem, while the connection setup is done in software by the switch control subsystem. The correctness of the protocol is formally proved. The protocol ensures the integrity of the tree, and, when failures occur, the tree is gracefully degraded into a smaller tree. >		Adrian Segall;Tsipora P. Barzilai;Yoram Ofek	1991	IEEE Journal on Selected Areas in Communications	10.1109/49.108680	identification;communications protocol;telephone network;telecommunications;computer science;distributed computing;fractal tree index;k-d-b-tree;tree traversal;packet switching;computer network;systems architecture	Vision	-5.846339691185643	79.2284194735306	191903
5523695fac7de6cd84bc933759d6e64fa83e1426	detector: a topology-aware monitoring system for data center networks		Troubleshooting network performance issues is a challenging task especially in large-scale data center networks. This paper presents deTector, a network monitoring system that is able to detect and localize network failures (manifested mainly by packet losses) accurately in near real time while minimizing the monitoring overhead. deTector achieves this goal by tightly coupling detection and localization and carefully selecting probe paths so that packet losses can be localized only according to end-to-end observations without the help of additional tools (e.g., tracert). In particular, we quantify the desirable properties of the matrix of probe paths, i.e., coverage and identifiability, and leverage an efficient greedy algorithm with a good approximation ratio and fast speed to select probe paths. We also propose a loss localization method according to loss patterns in a data center network. Our algorithm analysis, experimental evaluation on a Fattree testbed and supplementary large-scale simulation validate the scalability, feasibility and effectiveness of deTector.	analysis of algorithms;approximation algorithm;data center;end-to-end principle;greedy algorithm;network packet;network performance;overhead (computing);real-time computing;scalability;simulation;testbed;the matrix;traceroute	Yanghua Peng;Ji Yang;Chuan Wu;Chuanxiong Guo;Chengchen Hu;Zongpeng Li	2017			parallel computing;data center;detector;distributed computing;computer science	OS	-9.134565574363599	80.84787666639369	192633
98ebc617c095c23a96916734c0b0f55798e1d331	reliability evaluation of a computer network in cloud computing environment subject to maintenance budget	cloud computing environment;branch and bound approach;recursive sum of disjoint products rsdp;multiple minimal paths;maintenance budget	This paper measures the performance of a computer network in the cloud computing environment. To retain a good quality of service (QOS), the computer network is required to preserve a sufficient capacity level so that it can send d units of data from the source (a cloud computing center) to the sink (a set of clients) through multiple paths within time T. Thus, the maintenance action should be taken when the computer network falls to a specific state so that it cannot provide sufficient capacity to satisfy demand d. Given the maintenance budget B and time constraint T, we evaluate the probability that d units of data can be sent from the source to the sink, where the probability is referred to as the system reliability. A branch-and-bound approach including an adjusting procedure is proposed to obtain all minimal capacity vectors satisfying d, B, and T. Subsequently, the corresponding system reliability can be derived in terms of such vectors by applying the recursive sum of disjoint products algorithm. 2012 Elsevier Inc. All rights reserved.	algorithm;branch and bound;cloud computing;quality of service;recursion	Yi-Kuei Lin;Ping-Chen Chang	2012	Applied Mathematics and Computation	10.1016/j.amc.2012.10.024	mathematical optimization;real-time computing;computer science;distributed computing	Metrics	-6.277669860481804	77.94929075732345	192939
1544736e4744c972b96645393f80dcd98a8a64c8	a reconfigurable optical/electrical interconnect architecture for large-scale clusters and datacenters	optical switch;energy efficient;multi hop topologies;simulation framework;packet switched;interconnection network;scaling up;network topology;optical switching;large scale;data center;system design;high performance computer;interconnection networks;optical circuit switching;switching network	Hybrid optical/electrical interconnects, using commercially available optical circuit switches at the core part of the network, have been recently proposed as an attractive alternative to fully-connected electronically-switched networks in terms of port density, bandwidth/port, cabling and energy efficiency. Although the shift from a traditionally packet-switched core to switching between server aggregations (or servers) at circuit granularity requires system redesign, the approach has been shown to fit well to the traffic requirements of certain classes of high-performance computing applications, as well as to the traffic patterns exhibited by typical data center workloads. Recent proposals for such system designs have looked at small/medium scale hybrid interconnects. In this paper, we present a hybrid optical/electrical interconnect architecture intended for large-scale deployments of high-performance computing systems and server co-locations. To reduce complexity, our architecture employs a regular shuffle network topology that allows for simple management and cabling. Thanks to using a single-stage core interconnect and multiple optical planes, our design can be both incrementally scaled up (in capacity) and scaled out (in the number of racks) without requiring major re-cabling and network re-configuration. Also, we are the first to our knowledge to explore the benefit of using multi-hopping in the optical domain as a means to avoid constant reconfiguration of optical circuit switches. We have prototyped our architecture at packet-level detail in a simulation framework to evaluate this concept. Our results demonstrate that our hybrid interconnect, by adapting to the changing nature of application traffic, can significantly exceed the throughput of a static interconnect of equal degree, while at times attaining a throughput comparable to that of a costly fully-connected network. We also show a further benefit brought by multi-hopping, that it reduces the performance drops by reducing the frequency of reconfiguration.	computer cluster;computer port (hardware);data center;electrical connection;frequency-hopping spread spectrum;network packet;network switch;network topology;packet switching;requirement;server (computing);simulation;supercomputer;throughput	Diego Lugones;Kostas Katrinis;Martin Collier	2012		10.1145/2212908.2212913	embedded system;real-time computing;engineering;computer network	Arch	-10.877039488107433	80.15102722740191	193977
06e8632cc1714db56ffce853505ced64449fbca1	multicast protection scheme in survivable wdm optical networks	wdm;teletrafic;multiplexage longueur onde;protective device;simulation;wdm optical network;multidestinatario;telecommunication network;simulacion;endommagement;vulnerability;red fibra optica;deterioracion;dispositivo proteccion;shared protection;algorithme;algorithm;vulnerabilite;teletrafico;telecomunicacion optica;vulnerabilidad;telecommunication optique;dual link failures;diffusion information;red telecomunicacion;link failure;diffusion donnee;reseau fibre optique;information dissemination;defaillance;reseau telecommunication;difusion dato;teletraffic;optical telecommunication;optical fiber network;reprovisioning;difusion informacion;failures;data broadcast;damaging;optical fiber communication;fallo;multidestinataire;multiplaje longitud onda;dispositif protection;multicast;communication fibre optique;wavelength division multiplexing;algoritmo;wavelength division multiplex	The protection design is a key issue in survivable wavelength division multiplexing (WDM) optical networks. Most researches focused on protecting unicast traffic against the failure of a single network component such as a link or a node. In this paper, we investigate the protection scheme for multicast traffic in meshed WDM optical networks under dual-link failure consideration, and propose a novel protection algorithm called shared segment protection with reprovisioning (SSPR). Through dynamically adjusting link-cost according to the current network state, SSPR establishes a primary light-tree and corresponding link-disjoint backup segments for each multicast connection request. A backup segment can efficiently share wavelength capacity of its working tree or the common resource of other backup segments. Capacity reprovisioning establishes new segments for the vulnerable connections after a link failure and tolerates following link failures. The simulation results show that SSPR not only can make good use of wavelength resources and protect multicast sessions against any single-link failure, but also can greatly improve the traffic restorability in the event of dual-link breakdown.	multicast;wavelength-division multiplexing	Luhua Liao;Lemin Li;Sheng Wang	2008	J. Network and Computer Applications	10.1016/j.jnca.2006.11.001	telecommunications;computer science;computer security;wavelength-division multiplexing;computer network	Theory	-4.692235152381581	77.10472971225245	194801
170f8259e046533de5ef6e0c249165c69fbafe79	path trading: fast algorithms, smoothed analysis, and hardness results	border gateway protocol;dynamic program;smoothed analysis;autonomic system;computational complexity;fast algorithm;routing protocol;pareto optimality	The Border Gateway Protocol (BGP) serves as the main routing protocol of the Internet and ensures network reachability among autonomous systems (ASes). When traffic is forwarded between the many ASes on the Internet according to that protocol, each AS selfishly routes the traffic inside its own network according to some internal protocol that supports the local objectives of the AS. We consider possibilities of achieving higher global performance in such systems while maintaining the objectives and costs of the individual ASes. In particular, we consider how path trading, i.e. deviations from routing the traffic using individually optimal protocols, can lead to a better global performance. Shavitt and Singer (“Limitations and Possibilities of Path Trading between Autonomous Systems”, INFOCOM 2010) were the first to consider the computational complexity of finding such path trading solutions. They show that the problem is weakly NP-hard and provide a dynamic program to find path trades between pairs of ASes. In this paper we improve upon their results, both theoretically and practically. First, we show that finding path trades between sets of ASes is also strongly NP-hard. Moreover, we provide an algorithm that finds all Pareto-optimal path trades for a pair of two ASes. While in principal the number of Pareto-optimal path trades can be exponential, in our experiments this number was typically small. We use the framework of smoothed analysis to give theoretical evidence that this is a general phenomenon, and not only limited to the instances on which we performed experiments. The computational results show that our algorithm yields far superior running times and can solve considerably larger instances than the previous dynamic program.	algorithm;autonomous system (internet);border gateway protocol;computation;computational complexity theory;experiment;fast fourier transform;internet;np-hardness;pareto efficiency;reachability;routing;smoothed analysis;smoothing;time complexity	André Berger;Heiko Röglin;Ruben van der Zwaan	2011		10.1007/978-3-642-20662-7_4	smoothed analysis;mathematical optimization;border gateway protocol;computer science;theoretical computer science;distributed computing;routing protocol;computational complexity theory;path vector protocol;algorithm	Metrics	-7.135876993341094	78.64600562794463	195375
ab7bfc374b0a9b5ae7e9d5598c906aa5f81977a1	routing metric based on node degree for load-balancing in large-scale networks	telecommunication congestion control;routing network topology measurement topology stress internet routing protocols;large scale;telecommunication traffic;internet;routing metric traffic engineering load balancing large scale networks network topology network congestion;telecommunication network routing;load balance;telecommunication network topology;telecommunication traffic internet telecommunication congestion control telecommunication network routing telecommunication network topology	Traffic Engineering (TE) is required for reducing highly-loaded links/nodes in a part of networks, thereby reducing the traffic concentration in a part of network. For efficient use of network resources, it is important to efficiently map traffic demands to network resources. However, most of the existing TE schemes are not aware of underlying network topology, Indeed, they try to dynamically map traffic demands to network resources in response to traffic trends in a short period of time. The paper addresses the issue of network congestion due to inefficient mapping between traffic demand and network resources. We propose a new routing metric to allocate forwarding route from source node to its destinations for effective use of network resources in scale-free networks. We show that the best routing metric is $p$-norm based on node degrees along a path to destination node. Furthermore, we investigate the impact of the parameter, $p$, on congestion level of each link, and show the best parameter $p$ to minimize the maximum stress centrality in a network.	centrality;load balancing (computing);metrics (networking);network congestion;network topology;routing;test engineer	Hitomi Tamura;Masato Uchida;Masato Tsuru;Jun'ichi Shimada;Takeshi Ikenaga;Yuji Oie	2011	2011 IEEE/IPSJ International Symposium on Applications and the Internet	10.1109/SAINT.2011.96	traffic generation model;routing table;routing domain;routing;network planning and design;static routing;network traffic control;the internet;overlay network;network architecture;hierarchical routing;telecommunications;computer science;dynamic source routing;load balancing;multipath routing;ip forwarding;distributed computing;routing protocol;law;computer security;hazy sighted link state routing protocol;geographic routing;network topology;computer network;network traffic simulation	Networks	-9.238483361063741	78.99780308806474	195605
925de502878574bc4aab37a5c8c682d5018c54db	two-stage cut saturation algorithm for designing all-optical networks	optical fibre networks network topology telecommunication network routing optimisation optical wavelength conversion wavelength division multiplexing;wavelength di vision multiplexing;optimisation;electronic communication;efficient algorithm;all optical network;algorithm design and analysis costs network topology circuit topology wavelength routing wavelength assignment design optimization all optical networks communication networks optimization methods;wdm networks all optical network design two stage cut saturation algorithm physical topology design physical topology optimisation wavelength continuous constraint routing wavelength assignment lightpaths network node cost specification np hard problem efficient algorithm simulation results wavelength converters wavelength conversion link cost reduction;indexing terms;network simulator;network topology;optical fibre networks;telecommunication network routing;routing and wavelength assignment;optical wavelength conversion;wavelength conversion;wavelength division multiplexing	In this paper, we design and optimize the physical topology of all-optical networks. This problem is more challenging than the traditional one for electronic communication networks, because it has the wavelength-continuous constraint and it involves routing and wavelength assignment. In this problem, we are given the number of lightpaths required by every node pair and a cost specification, and our objective is to determine a physical topology of minimal cost. We formulate the problem, prove that it is NP-hard, and design an efficient algorithm called two-stage cut saturation algorithmfor it. In the first stage, we relax the wavelength-continuous constraint and apply the main idea of the cut saturation method to determine a good initial network. In the second stage, we impose the wavelength-continuous constraint and perform routing and wavelength assignment to establish the specified lightpaths on the initial network. When some lightpaths cannot be established, we apply the main idea of the cut saturation method to optimize the insertion of additional links into the network. Simulation results show the following: 1) the proposed algorithm can efficiently design networks with low costs and high utilization and 2) if wavelength converters are available to support full wavelength conversion, the total cost of the links can be significantly reduced.	algorithm;np-hardness;routing and wavelength assignment;saturation arithmetic;simulation;telecommunications network	Gaoxi Xiao;Yiu-Wing Leung;Kwok-Wah Hung	2001	IEEE Trans. Communications	10.1109/26.930640	electronic engineering;index term;telecommunications;computer science;engineering;network simulation;network topology;wavelength-division multiplexing;computer network	EDA	-5.137200225737131	81.48063803831283	196523
cccae59b306e245fdca7916374d932d3cc536a3a	limited-perimeter vector matching fault-localisation protocol for transparent all-optical communication networks	estensibilidad;teletrafic;complejidad espacio;evaluation performance;fault localisation protocol;protocols;congestion trafic;performance evaluation;time complexity;congestion trafico;complexite calcul;spectrum analysis;analyse spectre;localizacion imperfeccion;implementation;analisis espectro;evaluacion prestacion;signal analysis;gestion trafic;multidestinatario;telecommunication network;analisis de senal;traffic management;space time;espacio tiempo;red fibra optica;protocols computational complexity distributed control failure analysis fault location optical fibre networks;failure analysis;optical fibre networks;complejidad computacion;teletrafico;telecomunicacion optica;telecommunication optique;monitoring;traffic congestion;management mechanism;computational complexity;diffusion information;red telecomunicacion;diffusion donnee;reseau fibre optique;information dissemination;poursuite cible;defaillance;reseau telecommunication;difusion dato;teletraffic;space complexity;transparent all optical communication network;gestion trafico;optical telecommunication;optical communication;defect localization;space complexity limited perimeter vector matching fault localisation protocol transparent all optical communication network distributed control management mechanism computational complexity time complexity;optical fiber network;limited perimeter vector matching;extensibilite;scalability;monitorage;difusion informacion;failures;data broadcast;complexite espace;target tracking;localisation defaut;implementacion;monitoreo;distributed control;optical fiber communication;fallo;multidestinataire;analyse signal;espace temps;multicast;communication fibre optique;fault location	A novel fault-localisation protocol is constructed based on the principles of distributed control and management mechanisms. The proposed protocol has high scalability and speed, but at the cost of increased computational complexity. To provide the maximum level of transparency, the protocol skips any optical power monitoring or spectrum analysis at the intermediate nodes of established lightpaths. Moreover, to narrow down the associated time and space complexities, it restricts the fault-localisation area to a small area called limited-perimeter. These functions are implemented by means of five phases, namely pausing, flooding, multicasting, matching, and concluding. Although the protocol has been developed to pinpoint single failures, it could track down multiple failures that occur in nonoverlapped limited-perimeters. To evaluate the performance of the proposed method, time and space complexities are calculated and compared with a counterpart protocol that does not limit the fault-localisation area.	computational complexity theory;dspace;distributed control system;multicast;perimeter;scalability;telecommunications network	Atousa Vali Sichani;H. T. Mouftah	2007	IET Communications	10.1049/iet-com:20060082	simulation;two-phase commit protocol;telecommunications;computer science;signal processing;distributed computing;optical communication	HPC	-4.827879578807268	76.4993956887077	197103
ec653ff7ae809d80ff50bc123a1234ee21cdf7ac	minimizing bottleneck nodes of a substrate in virtual network embedding	virtual networks;topology;virtual network embedding;resource manager;simulation;resource management;network virtualization;substrates resource management network topology topology bandwidth internet simulation;virtualisation computational complexity embedded systems internet;network topology;scalability network virtualization virtual network embedding resource management;embedded systems;np hard problem;engineering and technology;teknik och teknologier;internet;computational complexity;bandwidth;scalability;substrates;bottleneck node reduced mapping approach virtual network embedding network virtualization internet virtual nodes np hard problem;virtualisation	Network virtualization has been proposed as a way to increase the flexibility of the Internet. This could enable the provisioning of many desired services in the current architecture and allow effective sharing and use of resources. Providing virtual networks (VNs) means that virtual nodes and links need to be embedded in the underlying shared infrastructure. This embedding process, where VNs with resource demands are mapped onto a substrate with finite resources is a challenging and NP-hard problem. In this paper the focus is on mapping the VNs in such a way that node resources in the substrate are not completely exhausted. To achieve this objective, an approach referred to as bottleneck node reduced mapping is presented. This method is evaluated and compared with an approach, where resource exhaustion is not considered.	artificial neural network;embedded system;internet;np-hardness;provisioning;resource exhaustion attack	Adil Razzaq;Peter Sjödin;Markus Hidell	2011	2011 International Conference on the Network of the Future	10.1109/NOF.2011.6126679	real-time computing;computer science;distributed computing;computer network	HPC	-11.683708418715781	81.45146660946646	198176
680cd0f32c7d900accb510d0fb4ff71628cd1c60	a research about redundant data packet in unstructured p2p network	p2p system;topology;optimisation;flooding;ttl;redundancy algorithm design and analysis topology network topology ip networks floods search problems;optimisation redundant data packet unstructured p2p network condensing forward list algorithm;unstructured p2p network;p2p;forward list p2p ttl cfl redundant data packet flooding;condensing forward list algorithm;peer to peer system;network topology;redundancy;redundancy optimisation peer to peer computing;redundant data packet;ip networks;search problems;floods;p2p networks;peer to peer computing;forward list;cfl;algorithm design and analysis	Peer-to-Peer systems depend on effective techniques to find and retrieve data; however, current techniques used in existing unstructured P2P system are often very inefficient because of the existence of large number of redundant messages. In this paper, we analyze the reason of engendering redundant data packet and put forward the Condensing Forward-List algorithm to reduce redundancy. Through experiments we find that it has good results. In addition, we design our algorithm to be simple, as a module that can be easily incorporated into existing unstructured P2P systems for immediate impact.	courant–friedrichs–lewy condition;experiment;flooding algorithm;moore's law;network packet;network topology;peer-to-peer;random graph;search algorithm;sequence container (c++)	Yuhua Liu;Longquan Zhu;Jingju Gao;Wenshan Cheng	2008	2008 10th IEEE International Conference on High Performance Computing and Communications	10.1109/HPCC.2008.75	algorithm design;time to live;computer science;theoretical computer science;flooding;peer-to-peer;distributed computing;redundancy;network topology;computer network	HPC	-8.332577693437791	76.85097526112871	198194
a2781f4b5d1dfdd8ff2d7d1bb0295f579c46d1d9	path-based multipath protection: resilience using multiple paths		The Multipath Protection (MPP) network resilience methods route and protect the upcoming demand over multiple paths. Although these schemes are able to allocate resources efficiently in the network, the length of the paths that the packets traverse cannot be controlled. Accordingly, to control the latency of the connections, we reuse the idea of MPP when we propose the Path-based Multipath Protection (PMPP) scheme. By controlling the maximal length of the paths, we increase the availability as well, because on shorter paths, fewer failures happen. The contribution of our work is threefold. First, we give the linear programming formulation of the PMPP method that does not have any integer variables resulting from polynomial runtime, similar to the former MPP methods. Second, we present extensive simulation results including the blocking ratios, the properties of the paths and the availabilities. Finally, we compare the PMPP resilience scheme with the original and improved versions of MPP method on the basis of several metrics. Copyright © 2012 John Wiley & Sons, Ltd. *Correspondence L. Gyarmati, Telefonica Research, Plaza de Ernest Lluch i Martín 5, Floor 15, 08019 Barcelona, Spain. E-mail: laszlo@tid.es This work was done while László Gyarmati was a graduate student at Telecommunications and Media Informatics, Budapest University of Technology and Economics Received 9 September 2010; Revised 16 January 2012; Accepted 30 January 2012	algorithm;blocking (computing);cyber resilience;emoticon;goodyear mpp;high availability;hypertext transfer protocol;informatics;john d. wiley;linear programming formulation;maxima and minima;maximal set;multipath propagation;polynomial;positive feedback;simulation;software propagation;traverse;time complexity	László Gyarmati;Tibor Cinkler;Tuan Anh Trinh	2012	Trans. Emerging Telecommunications Technologies	10.1002/ett.2522	telecommunications;computer science;theoretical computer science;distributed computing	Graphics	-6.728251389387841	79.57388552670967	198257
504fea47533a406034d287edf7f00fad5a7c8fb1	hierarchical design of an attractor structure for vnt control based on attractor selection	virtual network topology attractor structure attractor selection vnt control method dynamical system surrounding environments bottleneck links computational time large scaled networks heuristic algorithm internet services;topology;ip networks wdm networks adaptation models stochastic processes optical switches network topology topology;optical switches;network topology;stochastic processes;telecommunication traffic internet telecommunication network topology;ip networks;wdm networks;adaptation models	Our research group has proposed a VNT control method that is adaptive to traffic changes. The method is based on a dynamical system, called attractor selection, which models behavior where living organisms adapt to unknown changes in their surrounding environments and recover their conditions. One of important things of our VNT control method is how to determine attractors, i.e., VNT candidates, because a VNT configured by our VNT method finally converges on one of the VNT candidates. However, since the number of VNT candidates is limited, it is crucial that the limited number of attractors have diversity so that various kinds of VNTs are searched by attractor selection. In this paper, we propose a method to decide the VNT candidates. Our approach prepares the VNT candidates whose bottleneck links (lightpaths) are different to each other. However, this approach has a problem that it takes a heavy computational time for large-scaled networks. We therefore propose a method that divides a network into clusters for which our algorithm can be applied. Evaluation results show that the VNT candidates prepared by our method can suppress maximum link utilization than the ones prepared in a random manner or by an existing heuristic algorithm.	algorithm;computation;control theory;dynamical system;heuristic (computer science);network topology;time complexity	Toshihiko Ohba;Shin'ichi Arakawa;Yuki Koizumi;Masayuki Murata	2015	2015 12th Annual IEEE Consumer Communications and Networking Conference (CCNC)	10.1109/CCNC.2015.7157997	stochastic process;telecommunications;computer science;machine learning;distributed computing;optical switch;network topology;computer network	Robotics	-7.324789058984459	79.8924386556816	198515
7496b923aec81a4bb11c116e9397171a72d70121	gain equalization in metropolitan and wide area optical networks using optical amplifiers	optical attenuators;amplifier placement algorithm;semiconductor optical amplifiers;optical network;optical signals;receiver;spanning tree traversal;power equalization;metropolitan area networks;optical amplifier;optical amplifiers;optical fiber losses;optical fiber networks;trees mathematics;splitting loss;equalisers;network topology;gain equalization;wdma networks;trees mathematics metropolitan area networks wide area networks optical links equalisers multi access systems semiconductor lasers network topology;wide area optical networks;multi access systems;stimulated emission;semiconductor lasers;optical links;optical fiber amplifiers;fiber attenuation;spanning tree;optical fiber couplers;optical fiber networks optical attenuators optical receivers stimulated emission network topology optical fiber couplers wide area networks optical fiber amplifiers semiconductor optical amplifiers optical fiber losses;metropolitan area optical networks;star couplers;optical receivers;wide area network;wide area networks;wdma networks gain equalization wide area optical networks metropolitan area optical networks optical amplifiers network topology fiber attenuation splitting loss star couplers amplifier placement algorithm spanning tree traversal optical signals receiver power equalization	Optical metropolitan/wide area networks with arbitrary topology usually require optical amplifiers to compensate for the fiber attenuation and splitting loss introduced by the star couplers. An amplifier placement algorithm using spanning tree traversal is proposed. Using this algorithm, the authors show that it is possible to equalize the arriving optical signals at each receiver of the network. This technique enhances other static or dynamic gain equalization schemes and presents a more effective and robust solution to the power equalization problem for WDMA networks with arbitrary topology. >	optical amplifier	Chung-Sheng Li;Franklin Fuk-Kay Tong;Christos J. Georgiou;Monsong Chen	1994		10.1109/INFCOM.1994.337624	telecommunications;computer science;optical amplifier;computer network	Vision	-5.358733803291092	81.40422807446143	199299
