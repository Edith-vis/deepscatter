id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
32f9d5f70895a3e799c9c5758c1ac90efa7f68f4	simulating and visualizing real-time crowds on gpu clusters		We present a set of algorithms for simulating and visualizing real-time crowds in GPU (Graphics Processing Units) clusters. First we present crowd simulation and rendering techniques that take advantage of single GPU machines. Then, using as an example a wandering crowd behavior simulation algorithm, we explain how this kind of algorithms can be extended for their use in GPU cluster environments. We also present a visualization architecture that renders the simulation results using detailed 3D virtual characters. This architecture is adaptable in order to support the Barcelona Supercomputing Center (BSC) infrastructure. The results show that our algorithms are scalable in different hardware platforms including embedded systems, desktop GPUs, and GPU clusters, in particular, the BSC’s Minotauro cluster.	algorithm;binary symmetric channel;crowd simulation;desktop computer;embedded system;gpu cluster;graphics processing unit;real-time clock;rendering (computer graphics);scalability;supercomputer	Benjamín Hernández;Hugo Perez;Isaac Rudomín;Sergio Ruiz;Oriam de Gyves;Leonel Toledo	2014	Computación y Sistemas		computational science;supercomputer;parallel computing;visualization;rendering;computer science;message passing interface;crowd simulation;computer graphics (images)	HPC	-6.670999900074265	34.719020998591624	145379
f435d062bef1c080a92cab75f441032a309b892b	a general predictive performance model for wavefront algorithms on clusters of smps	parallel computing;distributed architectures;general and miscellaneous mathematics computing and information science;concurrent computing;performance evaluation;generic model;pervasive computing;los alamos national laboratory general predictive performance model wavefront algorithms clusters of smps parallel computing processor utilization communication requirements distributed architectures asci workload sgi origin 2000s;performance;los alamos national laboratory;model validation;computer architecture;wavefront algorithms;large scale;processor utilization;communication requirements;performance analysis;performance model;parallel computer;discrete ordinates;clustering algorithms;clusters of smps;asci workload;general predictive performance model;algorithms;parallel processing workstation clusters performance evaluation;predictive models;workstation clusters;predictive models clustering algorithms parallel processing pervasive computing performance analysis algorithm design and analysis concurrent computing computer architecture large scale systems laboratories;sgi origin 2000s;algorithm design and analysis;99 general and miscellaneous mathematics computing and information science;parallel processing;large scale systems;distributed architecture	"""We have recently been studying the performance of wavefront algorithms implemented using message passing on 2dimensional logical processor arrays [1,2]. Wavefront algorithms are ubiquitous in parallel computing, since they represent a means of enabling parallelism in computations that contain recurrences. Our particular interest in wavefront algorithms derives from their use in discrete ordinates neutral particle transport [3] computations, but other important uses are well known [4-7]. The basis of wavefront parallelism is the data dependence graph shown in Figure 1, in which the nodes may represent either physical grid points or logical processors. In the latter case, a computation progresses as a wavefront and """"scans"""" through a processor grid with pairs of processors sending and receiving boundary data required in order to update a portion of the physical mesh. Those processors within each wavefront, i.e., those on a diagonal, are algorithmically independent. Intuitively, then, the nominal benefit of wavefront parallelism is related to the (continuously-changing) length of a diagonal. However, additional concurrency can be achieved by """"blocking"""" the computation, resulting in more wavefront “sweeps” using smaller computational subgrids. This reduces processor idle time that accumulates as processors await their turn to compute, but requires that processors communicate more often. This tradeoff between processor utilization and communication requirements is characteristics of wavefront algorithms. An important task of performance models such as those described in [1,2] and the one proposed in this paper is to capture this tradeoff and the influence of the blocking parameters on the overall runtime of the application. Figure 1. Schematic of wavefront parallelism"""	algorithm;blocking (computing);central processing unit;computation;concurrency (computer science);data dependency;message passing;parallel computing;recurrence relation;requirement;schematic;wavefront technologies	Adolfy Hoisie;Olaf M. Lubeck;Harvey J. Wasserman;Fabrizio Petrini;Hank Alme	2000		10.1109/ICPP.2000.876127	parallel processing;algorithm design;parallel computing;concurrent computing;performance;computer science;theoretical computer science;operating system;distributed computing;predictive modelling;regression model validation;cluster analysis	HPC	-6.549151434503889	38.897955536913166	145981
8a1d827b26c48592746807275c886da3faaa2e9a	exploiting many-core architectures for dimensionally adaptive sparse grids			manycore processor;sparse grid;sparse matrix	Gerrit Buse	2014				HPC	-6.394547034211801	38.73658964235927	146066
d43acf1e28e0c291986213a4f81c6c84db9c22bb	umpal: an unstructured mesh partitioner and load balancer on world wide web	load balancer;world wide web;partitioner;internet;unstructured mesh;ease of use;prefix code;binomial tree;web interface;load balance;finite element method	The finite element method (FEM) has been widely used for the structural modeling of physical systems. Due to computation-intensiveness and computation-locality, it is attractive to implement the finite element method on distributed memory multicomputers. Many research efforts have already provided solid algorithms for mesh partitioning and load balancing. However, without proper support, mesh partitioning and load balancing are labor intensive and tedious. In this paper, we present an unstructured mesh partitioner and load balancer (UMPAL) on World Wide Web (WWW). UMPAL is an integrated tool that consists of five components, a partitioner, a load balancer, a simulator, a visualization tool, and a Web interface. In the partitioner, three partitioning methods, Jostle/DDM, Metis/DDM, and Party/DDM are provided. The load balancer provides two load-balancing methods, prefix code matching parallel load-balancing and binomial tree based parallel load-balancing. The simulator provides a performance simulation environment for a partitioned mesh. By inputting parameters of a target distributed memory multicomputer, one can get the execution result of a partitioned mesh from the simulator. The visualization tool provides a way for users to view a partitioned mesh. The Web interface provides a mean for users to use UMPAL via the Internet and integrates the other four parts. Through the Web interface, other four components can be operated independently or together. Additionally, UMPAL provides several demonstrations and their corresponding mesh models that allow beginners to download and experiment. The UMPAL is designed with ease of use, efficiency, and transparency in mind. The experimental results show the property being practical and usefulness of our UMPAL.	algorithm;binomial heap;class diagram;computation;distributed memory;download;finite element method;internet;load balancing (computing);locality of reference;metis;parallel computing;performance prediction;prefix code;simulation;unstructured grid;usability;www;world wide web	William C. Chu;Don-Lin Yang;Jen-Chih Yu;Yeh-Ching Chung	2001	J. Inf. Sci. Eng.		computer science;distributed computing;prefix code;parallel computing;world wide web;finite element method;load balancing (computing);usability;user interface	HPC	-9.142704428618213	37.07606535931496	146685
d22f65734556f7a1b8e2fd5410ee0131c2b33ad0	using gpus to enable simulation with computational gravitational dynamics in astrophysics	gpus;computing in astronomy;direct summation gpus supercomputing numeric accelerators computing in astronomy stellar dynamics galaxy dynamics black holes;n body technique gpu system simulation computational gravitational dynamics astrophysics;n body simulations astronomical graphics processing units;black holes;galaxy dynamics;numeric accelerators;computational modeling;direct summation;heuristic algorithms;graphics processing units;collision avoidance;graphics processing units computational modeling instruction sets algorithm design and analysis heuristic algorithms collision avoidance;stellar dynamics;algorithm design and analysis;instruction sets;supercomputing	Optimizations for individual N-body techniques allow the simulation of collisonal or collisionless systems, but not both together. Hybrid code running on GPUs meets this requirement, and enabled the efficient and accurate simulation of 11 interacting galaxies with a massive black hole in each of their nuclei.	black hole;graphics processing unit;interaction;simulation	Simon Portegies Zwart;Jeroen Bédorf	2015	Computer	10.1109/MC.2015.334	stellar dynamics;computational science;algorithm design;black hole;supercomputer;parallel computing;computer science;theoretical computer science;operating system;instruction set;computational model	Arch	-5.78850396763873	36.936921755237954	147973
c4a39e20beac5036e4dcbfc47837206745ddfcfd	climate data assimilation on a massively parallel supercomputer	distance education;climate;technical materials;high performance computing;earth;goddard space flight center;massively parallel processors;supercomputer;conjugate gradient method;packaging;assimilation;virtual classroom;data assimilation office;data assimilation supercomputers packaging earth algorithm design and analysis production propulsion laboratories high performance computing performance analysis;performance analysis;parallel processing computers;production;algorithms;reliability analysis;propulsion;data assimilation;preconditioned conjugate gradient;algorithms intel paragon psas data assimilation cray c90 massively parallel;algorithm design and analysis;supercomputers;cray computers	We have designed and implemented a set of highly efficient and highly scalable algorithms for an unstructured computational package, the PSAS data assimilation package, as demonstrated by detailed performance analysis of systematic runs on up to 512-nodes of an Intel Paragon. The preconditioned Conjugate Gradient solver achieves a sustained 18 Gflops performance. Consequently, we achieve an unprecedented 100-fold reduction in time to solution on the Intel Paragon over a single head of a Cray C90. This not only exceeds the daily performance requirement of the Data Assimilation Office at NASA's Goddard Space Flight Center, but also makes it possible to explore much larger and challenging data assimilation problems which are unthinkable on a traditional computer platform such as the Cray C90.	algorithm;computation;conjugate gradient method;convex conjugate;cray c90;data access object;data assimilation;distributed memory;flops;intel paragon;message passing;parallel computing;real-time clock;requirement;scalability;solver;supercomputer	Chris H. Q. Ding;Robert D. Ferraro	1996	Proceedings of the 1996 ACM/IEEE Conference on Supercomputing	10.1145/369028.369058	climate;distance education;computational science;algorithm design;packaging and labeling;supercomputer;parallel computing;data assimilation;propulsion;assimilation;computer science;earth;conjugate gradient method;algorithm;computer graphics (images)	HPC	-5.474791306272815	38.07625930308639	147997
4905fba2516b6ed1174c25bb36ace46f9da47f56	reducing the setup time of a one-step fdtd method		As society places greater demands on technology, it becomes in cr asingly important to be able to simulate that technology. While simulation tools can be very sophi sticated and capable of handling very complex devices and structures, the cost paid in computation time can be prohi bitive. To reduce this time, a number of one-step schemes ha v been developed, but these schemes suffer from a setup time tha t can outweigh the benefits of the scheme. We examine parallel processing is one means to reduce the setup time. B y approaching FDTD from the modal analysis perspective we offer an alternative to implement a one-step scheme for F DTD with coarse-grain parallelization.	computation;finite-difference time-domain method;flip-flop (electronics);modal logic;parallel computing;simulation;time complexity	Dmitry Gorodetsky;Philip Wilsey	2006			parallel computing;computer science;finite-difference time-domain method;theoretical computer science	EDA	-5.1329376455131	36.241141330106935	149421
de5a25c811211235667f945dff56a51196b42aee	parallel processing of spaceborne imaging radar data	x-band sar;intel paragon;sar data;synthetic aperture radar data;parallel processing;spaceborne imaging radar data;compute-intensive sar correlator phase;x-sar data;x-sar instrument;data decomposition;high volume;x-sar processing system;image processing;space technology;synthetic aperture radar;collaboration;near real time;propulsion;radar imaging	"""We discuss the results of a collaborative project on parallel processing of Synthetic Aperture Radar (SAR) data, carried out between the NASA/Jet Propulsion Laboratory (JPL), the California Institute of Technology (Caltech) and Intel Scalable Systems Division (SSD). Through this collaborative effort, we have successfully parallelized the most compute-intensive SAR correlator phase of the Spaceborne Shuttle Imaging Radar-C/X-Band SAR (SIR-C/X-SAR) code, for the Intel Paragon. We describe the data decomposition, the scalable high-performance I/O model, and the node-level optimizations which enable us to obtain efficient processing throughput. In particular, we point out an interesting double level of parallelization arising in the data decomposition which increases substantially our ability to support ''high volume'' SAR. Results are presented from this code running in parallel on the Intel Paragon. A representative set of SAR data, of size 800 Megabytes, which was collected by the SIR-C/X-SAR instrument aboard NASA's Space Shuttle in 15 seconds, is processed in 55 seconds on the Concurrent Supercomputing Consortium's Paragon XP/S 35+. This compares well with a time of 12 minutes for the current SIR-C/X-SAR processing system at JPL. For the first time, a commercial system can process SIR-C/X-SAR data at a rate which is approaching the rate at which the SIR-C/X-SAR instrument can collect the data. This work has successfully demonstrated the viability of the Intel Paragon supercomputer for processing ''high volume"""" Synthetic Aperture Radar data in near real-time."""		Craig Miller;David G. Payne;Thanh N. Phung;Herb Siegel;Roy Williams	1995		10.1109/SUPERC.1995.54	parallel processing;simulation;synthetic aperture radar;propulsion;image processing;computer science;an/apy-10;space technology;radar imaging;shuttle radar topography mission;computer graphics (images);collaboration	HPC	-5.226718833708512	33.88015785326158	149904
6226b55283e54663990479459dc330fbede433f9	hpc applications deployment on distributed heterogeneous computing platforms via omf, oml and p2pdc	planetlab;portals;multi threading;heterogeneous computing;component;asynchronous iterations component hpc heterogeneous computing peer to peer computing application deployment planetlab numerical simulation;portals multi threading;hpc;asynchronous iterations;portals peer to peer computing servers extraterrestrial measurements computer architecture volume measurement libraries;peer to peer computing;multithreaded control hpc applications deployment distributed heterogeneous computing platforms omf oml p2pdc web portal high performance computing applications;application deployment;numerical simulation	A new tool and web portal are presented for deployment of High Performance Computing applications on distributed heterogeneous computing platforms. This tool relies on the decentralized environment P2PDC and the OMF and OML multithreaded control, instrumentation and measurement libraries. Deployment on PlanetLab of a numerical simulation application is studied. A first series of computational results is displayed and analyzed.	ambiguous name resolution;central processing unit;communications protocol;computation;computer simulation;graphics processing unit;heterogeneous computing;infiniband;library (computing);multiple dispatch;numerical analysis;numerical partial differential equations;oml;obstacle problem;oracle database;overlay network;planetlab;software deployment;testbed;thread (computing)	Didier El Baz;The Tung Nguyen;Guillaume Jourjon;Thierry Rakotoarivelo	2014	2014 22nd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing	10.1109/PDP.2014.15	computer simulation;supercomputer;parallel computing;multithreading;computer science;operating system;component;distributed computing;software deployment;symmetric multiprocessor system	HPC	-9.378539887425587	38.18637224696283	149998
9773c40fe47bd28654eb5c2b9c74e41a09225a50	integration of computational fluid dynamics and computational aero acoustics on grid for dental applications	dental clinics;grid computing dentistry computational fluid dynamics aeroacoustics medical computing;dentistry;computer aided analysis;computational fluid dynamics grid computing acoustic applications dentistry computational modeling hospitals computer aided analysis costs distributed computing application software;application software;hybrid application;computation fluid dynamics;distributed computing;hospitals;dental application;dental clinics computational fluid dynamics computational aeroacoustics dental application grid computing hybrid application;null;medical computing;computational fluid dynamics;computational modeling;aeroacoustics;grid computing;computational aeroacoustics;physical simulation;acoustic applications	The hybrid applications are needed in dental research because the result of their operation could be predicted by both modeling of an oral truct and more than two kind of physical simulations. However, it takes long time to perform the hybrid applications, cost a lot of money and needs some experience to deal with them. This paper proposes a new execution procedure of two applications which can reduce the implementation time by considering parallel efficiency of those applications. It can determine which attitude should be taken, sequential or separate execution of two different applications related with each other. Following the execution procedure, the dental hybrid application was performed. As a result of that, desirable pairs of the number of CPUs allocated to each simulation could be found. This means that the adequate procedure should be considered before execution of the hybrid applications, in order to play a compute power producer for dental clinics and hospitals.	central processing unit;computational aeroacoustics;computational fluid dynamics;simulation;speedup;windows aero	Kazunori Nozaki;Toyokazu Akiyama;Shinji Shimojo;Shingo Maeda;Hiroo Tamagawa	2005	18th IEEE Symposium on Computer-Based Medical Systems (CBMS'05)	10.1109/CBMS.2005.70	computational science;application software;computational fluid dynamics;computer science;theoretical computer science;aeroacoustics;computational model;grid computing;computational aeroacoustics	Arch	-8.851887538844448	38.68926510545055	150369
7a694563c8f5c486d5551abc140b7b1146d05aef	methods for parallel computation of scf nmr chemical shifts by giao method: efficient integral calculation, multi-fock algorithm, and pseudodiagonalization	chemical shift;parallel computer;parallel computation	Ž . ABSTRACT: We implemented our gauge-including atomic orbital GIAO NMR chemical shielding program on a workstation cluster, using the parallel Ž . virtual machine PVM message-passing system. On a modest number of nodes, we achieved close to linear speedup. This program is characterized by several novel features. It uses the new integral program of Wolinski that calculates integrals in vectorized batches, increases efficiency, and simplifies parallelization. Ž . The self-consistent field SCF step includes a multi-Fock algorithm, i.e., the simultaneous calculation of several Fock matrices with the same integral set, increasing the efficiency of the direct SCF procedure. The SCF diagonalization step, which is difficult to parallelize, has been replaced by pseudodiagonalization. The latter, widely used in semiempirical programs, becomes important in ab initio type calculations above a certain size, because the ultimate scaling of the diagonalization step is steeper than that of integral computation. Examples of the calculation of the NMR shieldings in large systems at the SCF level are shown. Parallelization of the density functional code is underway. Q 1997 by John Wiley & Sons, Inc. J Comput Chem 18: 816]825, 1997	ab initio quantum chemistry methods;algorithm;automatic parallelization;computation;density functional theory;fock space;hartree–fock method;image scaling;john d. wiley;message passing;molecular orbital;parallel virtual machine;parallel computing;q-chem;semi-empirical quantum chemistry method;speedup;workstation	Krzysztof Wolinski;Robert Haacke;James F. Hinton;Peter Pulay	1997	Journal of Computational Chemistry	10.1002/(SICI)1096-987X(19970430)18:6%3C816::AID-JCC7%3E3.0.CO;2-V		HPC	-4.651513216676317	37.45207241974094	150701
5e6bacd14394fc2e87391623a778ef78c41b87c2	multi-modal traffic simulation platform on parallel and distributed systems	digital simulation;multi-threading;parallel machines;traffic engineering computing;transportation;disaster response;distributed environment;distributed manner;distributed system;many core machine;multicore machine;multimodal traffic simulation platform;multimodal transportation network;multinode cluster;multithreading environment;municipal planner;parallel environment;parallel manner;parallel system;supercomputer environment;traffic engineer;transportation company;what-if scenario	In this paper we describe a highly scalable multi-modal traffic simulation platform on parallel and distributed environments ranging from multi-core or many core machines to multi-node clusters or supercomputer environments. We evaluated our platform with multi-modal transportation networks from the capital city of Ireland, Dublin, and verified its high scalability and real-time performance on both a 1-node with 12 core machine for a multi-threading environment and a cluster of 12 nodes (with a total of 144 cores) for a distributed system. With this platform, municipal planners or traffic engineers at transportation companies can quickly conduct many series of simulations with various what-if scenarios in a parallel and distributed manner, allowing them to assess and select the best responses to sudden incidents, or plan for major events or disaster responses.	distributed computing;manycore processor;modal logic;multi-core processor;real-time transcription;scalability;simulation;supercomputer;thread (computing)	Toyotaro Suzumura;Hiroki Kanezashi	2014	Proceedings of the Winter Simulation Conference 2014		real-time computing;simulation;engineering;distributed computing;world wide web;advanced traffic management system	HPC	-6.914305412371189	33.90909448949361	151350
0ce4f5d92b09d0adc7929667fa70bbe568aef394	computing in high-energy physics: facing a new generation of experiments	high energy physics		experiment	Paolo Zanella	1983			microprocessor;particle;bibliography;computational science;computer science	ML	-7.637849280091845	37.50683612349939	151392
ea98afe47a1b21fde226f7a9918861c4c681968c	analysis of memory and time savings using ec/dsim	system monitoring parallel programming virtual machines computational complexity;system monitoring;parallel programming;linear equations time savings memory savings ec dsim ec frontend parallel program task step needs completion times parallel gaussian elimination fast fourier transform;fast fourier transform;virtual machines;computational complexity;parallel programs;computational modeling concurrent computing computer simulation computer networks computer science predictive models physics computing computer architecture communication system control control systems	This paper introduces the EC frontend and DSIM simulator. Given a pamllel program, they determine its ezecution time on huge networks of computers. EC eztmcts task step needs. DSIM predicts completion times rather than simulating each program step. This paper contains analyses of the memory savings and the ezecution time savings for simulations of one to 2,800 computers running parallel Gaussian elimination and fast Fourier transform. The time savings are 2O%(two days) for fifty runs of Gawsian reduction of a 400 x 401 mat& to solve 400 linear equations. Memory needs are reduced 99% (657 MBytes) per simulation run. The memory savings allow simulation of parallel programs running on thousands of processors. These huge network sizes are impractical with step-by-step simulations.	central processing unit;computer;fast fourier transform;gaussian elimination;linear equation;simulation	Gudjon Hermannsson;Ai Li;Larry D. Wittie	1994		10.1109/MASCOT.1994.284421	system monitoring;fast fourier transform;parallel computing;real-time computing;computer science;virtual machine;theoretical computer science;operating system;computational complexity theory	Arch	-9.008006256476198	39.05271389191447	152084
0b31ca1e23a5b6a7f2b1f35c4ce232beee5ac084	scalability analysis and domain decomposition of large eddy simulations of ship wakes	analytical models;execution time scalability analysis domain decomposition large eddy simulations turbulent fluctuations ship wake simulation computational fluid dynamics workstation clusters parallel processing;mechanical engineering computing;domain decomposition;execution time;scalability analysis;application software;navier stokes equations;computation fluid dynamics;cluster of workstations;aerospace simulation;large eddy simulation;scaling up;computational fluid dynamics;large eddy simulations;computational modeling;ships;marine vehicles;workstations;large eddy simulation les;cluster system;turbulent fluctuations;mechanical engineering computing computational fluid dynamics digital simulation ships wakes workstation clusters;scalability analytical models marine vehicles computational modeling workstations computer simulation navier stokes equations aerospace simulation supercomputers application software;parallel implementation;scalability;workstation clusters;computer simulation;supercomputers;parallel processing;wakes;digital simulation;ship wake simulation	Simulation of turbulent fluctuations in ship wakes is one of the complex applications of large eddy simulations in computational fluid dynamics (CFD). Ship wakes simulation requires extensive computations and large amounts of computer resources. The accuracy of ship wake prediction is limited by the memory of the workstation. In this paper we present the parallel implementation of large eddy simulations (LES) of a flat plane wake using a data domain decomposition technique for a cluster environment. We present the results of the implementation executed on a cluster of workstations. Also, we show how the implementation scales up with the number of workstations and that it is possible to obtain better accuracy by increasing the number of workstations in the cluster system. Moreover, we show how we can predict the number of workstations required to execute the simulation for a given accuracy level based on the number of grid nodes, or estimate the execution time for a certain cluster.	computation;computational fluid dynamics;computer cluster;computer simulation;data domain;domain decomposition methods;large eddy simulation;run time (program lifecycle phase);scalability;turbulence;workstation	A. Osman;H. Ammar;Andrei V. Smirnov;S. Shi;I. Celik	2001		10.1109/AICCSA.2001.933979	computer simulation;computational science;parallel processing;application software;parallel computing;scalability;simulation;workstation;computational fluid dynamics;computer science;operating system;domain decomposition methods;computational model;large eddy simulation	HPC	-5.980549284460284	38.645729571407806	152095
cbc8737feaf51332b89e11e9f8e1fd9d70abeacd	machines and algorithms	engineering;computational physics;paper;qcd;automatic keywords;performance;computer;cuda;quantum chromodynamics;hep;physics;nvidia;algorithms;high energy physics lattice;review;intel xeon phi	I discuss the evolution of computer architectures with a focus on QCD and with reference to the interplay between architecture, engineering, data motion and algorithms. New architectures are discussed and recent performance results are displayed. I also review recent progress in multilevel solver and integation algorithms. c Copyright owned by the author(s) under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike Licence.	algorithm;central processing unit;computation;computer architecture;design web format;electrical connection;ergodicity;graphics processing unit;hybrid memory cube;image scaling;knights;manycore processor;multigrid method;pascal;pin grid array;power supply unit (computer);preconditioner;rounding;scalability;single-precision floating-point format;skylake (microarchitecture);solver;transistor count;turing institute;twisted;variance reduction	Peter A. Boyle	2017	CoRR		performance;xeon phi;quantum chromodynamics;physics;quantum mechanics	ML	-7.456886755298244	37.582315796528164	152264
9abb51b149dd5c2a78d3ca8d52188c2571d702f3	solving a load balancing problem using boltzmann machines.	boltzmann machine;load balance			Injae Hwang;Ravi Varadarajan	1991			boltzmann machine;computational science;mathematical optimization;computer science;load balancing;theoretical computer science	Theory	-7.224366565530791	38.34346414017478	152635
b97e2739415f5b50fa79d5bb02fffc7013194ecb	computing climate change: can we beat nature?	oceans;concurrent computing;application software;loosely coupled computers;climate change;data mining;generate and test;computer architecture;sea surface;distributed computing system;process mapping;sequential selection;atmospheric modeling predictive models supercomputers concurrent computing oceans computer architecture application software chemistry land surface sea surface;chemistry;predictive models;land surface;heuristics;atmospheric modeling;supercomputers;time constraints	No abstract available		Robert C. Malone;Robert Chervin;Richard Smith;William P. Dannevik;John B. Drake	1991	Proceedings of the 1991 ACM/IEEE Conference on Supercomputing (Supercomputing '91)	10.1145/125826.126148	atmospheric model;application software;parallel computing;real-time computing;simulation;concurrent computing;computer science;theoretical computer science;operating system;heuristics;data mining;predictive modelling;programming language;climate change	HPC	-6.390869111068391	33.520086803714	153424
c2ed620f8c1ab25c34dd4c2c366227bb338a3bda	petascale tcl with namd, vmd, and swift/t	computers;molecular simulation;parallel rendering;rendering computer graphics authoring languages data flow computing data visualisation embedded systems;performance;biological system modeling;gpu;molecular visualization;computational modeling;computational modeling biological system modeling graphics processing units computers trajectory programming mathematical model;trajectory;graphics processing units;mathematical model;algorithms;design;programming;many core;scripting;high performance parallel scripting language petascale tcl namd vmd swift t embeddable dynamic language biomolecular visualization analysis program parallel trajectory analysis movie rendering blue waters	Tcl is the original embeddable dynamic language. Introduced in 1990, Tcl has been the foundation of the scripting interface of the popular biomolecular visualization and analysis program VMD since 1995 and was extended to the parallel molecular dynamics program NAMD in 1999. The two programs together have over 200,000 users who have enjoyed for nearly two decades the stability and flexibility provided by Tcl. VMD users can implement or extend parallel trajectory analysis and movie rendering on thousands of nodes of Blue Waters. NAMD users can implement or extend simulation protocols and multiple-copy algorithms that execute unmodified on any supercomputer without the need to recompile NAMD. We now demonstrate the integration of the Swift/T high-performance parallel scripting language to enable high-level data flow programming in NAMD and VMD. This integration is achieved without modifying or recompiling either program since the Turbine execution engine is itself based on Tcl and is dynamically loaded by the interpreter, as is the platform-specific MPI library on which it depends.	algorithm;blue waters;compiler;dataflow;high- and low-level;nanoscale molecular dynamics;petascale computing;platform-specific model;scripting language;simulation;supercomputer;swift (programming language);tcl;vmd	James C. Phillips;John E. Stone;Kirby L. Vandivort;Timothy G. Armstrong;Justin M. Wozniak;Michael Wilde;Klaus Schulten	2014	2014 First Workshop for High Performance Technical Computing in Dynamic Languages	10.1109/HPTCDL.2014.7	computational science;programming;design;parallel computing;performance;computer science;trajectory;operating system;parallel rendering;mathematical model;distributed computing;programming language;computer graphics (images)	HPC	-9.772556033240518	37.47044676800485	153837
25d3f6b404361358121c88f698df7ededaaefef8	on the parallelisation of bioinformatics applications	distributed memory architecture;computer architecture;phylogenetic tree;parallel computer;coarse grained;parallel programs;database search;machine model	This paper surveys the computational strategies followed to parallelise the most used software in the bioinformatics arena. The studied algorithms are computationally expensive and their computational patterns range from regular, such as database-searching applications, to very irregularly structured patterns (phylogenetic trees). Fine- and coarse-grained parallel strategies are discussed for these very diverse sets of applications. This overview outlines computational issues related to parallelism, physical machine models, parallel programming approaches and scheduling strategies for a broad range of computer architectures. In particular, it deals with shared, distributed and shared/distributed memory architectures.	algorithm;analysis of algorithms;architecture as topic;bioinformatics;computation;computer architecture;distributed memory;outlines (document);parallel computing;phylogenetic tree;phylogenetics;scheduling (computing);scheduling - hl7 publishing domain;trees (plant)	Oswaldo Trelles	2001	Briefings in bioinformatics	10.1093/bib/2.2.181	biology;parallel computing;phylogenetic tree;database search engine;computer science;bioinformatics;theoretical computer science;distributed computing	HPC	-9.054511334734121	38.92609578446682	154094
b0f47223a28a1e8b207e159f85bbca971055b8e8	multibillion-atom molecular dynamics simulation: design considerations for vector-parallel processing	processor architecture;performance evaluation;performance test;02 70 ns molecular dynamics simulation;supercomputer;molecular dynamics simulation;molecular dynamic simulation;particle method;algorithm;molecular dynamic;02 70 ns;vector processing;parallel processing	Progress in adapting molecular dynamics algorithms for systems with short-range interactions to utilize the features of modern supercomputers is described. Efficient utilization of the latest generation of processor architectures requires algorithms that can be both vectorized and parallelized. The approach adopted for vectorization involves combining the layer and neighbor-list methods, while parallelization employs spatial subdivision with explicit communication. The techniques presented here have been used in performance tests on the Cray X1 vector-parallel supercomputer with systems containing over 12 billion atoms.  2005 Elsevier B.V. All rights reserved.	algorithm;automatic vectorization;central processing unit;clock rate;computation;computer performance;cray x1;distributed memory;interaction;molecular dynamics;nichols plot;norm (social);parallel computing;parallel programming model;requirement;simulation;space partitioning;subdivision surface;supercomputer;transaction processing system;ut-vpn;verlet list	D. C. Rapaport	2006	Computer Physics Communications	10.1016/j.cpc.2005.11.008	computational science;molecular dynamics;computer architecture;vector processor;parallel computing;microarchitecture;computer science	HPC	-6.101026522259324	38.75598958959501	154465
89174f507071696ead2ed93da9fa750bc60def32	parallelizing evolutionary computation: a mobile agent-based approach	evolutionary computation;mobility;mobile agents;distributed computing;parallelism;parallel computer;middleware;evolutionary algorithm;mobile agent;evolutionary computing;java	Parallel computation models have been widely used to enhance the performance of traditional evolutionary algorithms, and they have been implemented on parallel computers to speed up the computation. Instead of using expensive parallel computing facilities, we propose to implement parallel evolutionary computation models on easily available networked PCs, and present a multi-agent framework to support parallelism. With the unique characteristics of agent autonomy and mobility, mobile agents can carry the EC-code and migrate from machine to machine to complete the computation dynamically. To evaluate the proposed approach we have developed a prototype system on a middleware platform JADE to solve a time-consuming task. Different kinds of experiments have been conducted to assess the developed system and the preliminary results show the promise and efficiency of our mobile agent-based approach. 2005 Elsevier Ltd. All rights reserved.	agent-based model;computer;computer hardware;evolutionary algorithm;evolutionary computation;experiment;fault tolerance;jade;machine to machine;middleware;mobile agent;multi-agent system;parallel computing;prototype;speedup	Wei-Po Lee	2007	Expert Syst. Appl.	10.1016/j.eswa.2005.11.034	parallel computing;computer science;theoretical computer science;machine learning;middleware;mobile agent;distributed computing;java;evolutionary computation	AI	-11.003764314670272	38.729254729350046	154579
5ae8c77f964b981688539343ad3f2e56494d473d	concurrent search structure algorithms	abstract data type;concurrent data structures;interconnection network;concurrency control;data structure	A dictionary is an abstract data type supporting the actions member, insert, and delete. A search structure is a data structure used to implement a dictionary. Examples include B trees, hash structures, and unordered lists. Concurrent algorithms on search structures can achieve more parallelism than standard concurrency control methods would suggest, by exploiting the fact that many different search structure states represent one dictionary state. We present a framework for verifying such algorithms and for inventing new ones. We give several examples, one of which exploits the structure of Banyan family interconnection networks. We also discuss the interaction between concurrency control and recovery as applied to search structures.	abstract data type;algorithm;computation;concurrency (computer science);concurrency control;data structure;dictionary;interconnection;parallel computing;verification and validation	Dennis Shasha;Nathan Goodman	1988	ACM Trans. Database Syst.	10.1145/42201.42204	data structure;computer science;theoretical computer science;concurrency control;database;distributed computing;concurrent data structure;non-lock concurrency control;programming language;abstract data type	DB	-10.220371356992283	32.70458670371191	154968
07bb9ccbffceb685ed2661a67ddd3666e80f4b7b	parallel discrete element simulation of poly-dispersed granular material	parallel computing;distributed memory;spatial domain decomposition;domain decomposition;distributed memory pc clusters;size distribution;particle compacting;pc cluster;parallel computer;poly dispersed granular material;discrete element method;granular material	The paper presents parallel 3D DEM simulation of poly-dispersed material described by the normal size distribution. Static domain decomposition and message passing inter-processor communication have been implemented in the DEM code. A novel algorithm for moving particles that exchange processors has been incorporated in the domain decomposition framework. Parallel performance of the developed algorithm and software has been investigated by a series of benchmark tests conducting tri-axial compaction of material with different numbers of particles, heterogeneity ratios and compaction durations. The speed-up equal to 8.81 has been obtained on 10 processors of the distributed memory PC cluster. It has been shown that a drastic increase of computational expenses of simulation for the poly-dispersed material in terms of CPU time is associated with the increase of its heterogeneity. A contribution of the temporal evolution of microscopic behaviour has also been illustrated. 2008 Civil-Comp Ltd. and Elsevier Ltd. All rights reserved.	3d printing;artificial cell;benchmark (computing);central processing unit;computation;computer cluster;data compaction;dispersive partial differential equation;distributed memory;domain decomposition methods;maximal set;message passing;numerical analysis;parallel algorithm;search algorithm;simulation;triangular function	Rimantas Kacianauskas;Algirdas Maknickas;Arnas Kaceniauskas;Darius Markauskas;Robertas Balevicius	2010	Advances in Engineering Software	10.1016/j.advengsoft.2008.12.004	parallel computing;real-time computing;granular material;distributed memory;computer science;theoretical computer science;domain decomposition methods;discrete element method	HPC	-5.778991469698186	36.56570422822788	155551
7330aafaea166a67fe6b28d1f718a055dbd4e376	a scalable approach for solving irregular sparse linear systems on the tera mta multithreaded parallel shared-memory computer	shared memory		cray mta-2;shared memory;sparse matrix;terabyte;thread (computing)	Leonid Y. Zaslavsky;Simon Kahan;Bracy H. Elton;Kristyn J. Maschhoff;Louis G. Stern	1999			parallel computing;scalability;tera-;linear system;computer science;shared memory;distributed computing	HPC	-6.459733760773545	39.10338726241822	156196
66759b9cc45f48619c0d28f1c3dcd7683da2f5ee	a distributed-memory implementation of the mchf atomic structure package	matrix eigenvalue problem;distributed memory;memoire;virtual memory;eigenvalue problem;schrodinger equation;algorithm performance;equation schrodinger;system performance;parallel computation;parallel atomic structure calculations;hartree fock;calculo paralelo;ecuacion schrodinger;atomic structure;memoria;resultado algoritmo;performance algorithme;distribution strategies and performance;multiconfiguration hartree fock;distribution strategies;calcul parallele;data structure;memory	The MCHF (Multiconfiguration Hartree-Fock) atomic structure package consists of a series of programs that predict a range of atomic properties and communicate information through files. Several of these have now been modified for the distributed-memory environment. On the Intel iPSC/860 the restricted amount of memory and the lack of virtual memory required a redesign of the data organization with large arrays residing on disk. The data structures also had to be modified. To a large extent, data could be distributed among the nodes, but crucial to the performance of the MCHF program was the global information that is needed for an even distribution of the workload. This paper outlines the computational problems that must be solved in an atomic structure calculation and describes the strategies used to distribute both the data and the workload on a distributed-memory system. Performance data are provided for some benchmark calculations on the Intel iPSC/860.	atom;benchmark (computing);computational problem;data structure;distributed memory;fock space;hartree–fock method;intel ipsc;multi-configurational self-consistent field	Charlotte Froese Fischer;Ming Tong;Murry Bentley;Zuchang Shen;C. Ravimohan	1994	The Journal of Supercomputing	10.1007/BF01204658	schrödinger equation;parallel computing;distributed memory;atom;data structure;computer science;virtual memory;theoretical computer science;operating system;memory;hartree–fock method	HPC	-4.563106437768812	37.25848352265607	156846
2adb76365ec8b07e37887bece92a249670c7b649	distributed and generic maximum likelihood evaluation	homogeneous environments;astroinformatics;generic maximum likelihood evaluation;maximum likelihood;scientific models;perforation;star streams;distributed executions;parallel executions;distributed evaluation frameworks;search methods;search method;high performance homogeneous computing clusters;generalized maximum likelihood;message passing astronomy astronomy computing grid computing internet;internet computing;astronomy computing;heterogeneous grid;internet;particle physics;scientific computing;message passing;complex distributed computing environments distributed maximum likelihood evaluation generic maximum likelihood evaluation astroinformatics star streams milky way galaxy particle physics sub atomic particles parallel executions distributed executions supercomputers high performance homogeneous computing clusters heterogeneous grid internet computing distributed evaluation frameworks scientific models search methods mpi homogeneous environments scientific computing;milky way;sub atomic particles;mpi;milky way galaxy;astronomy;grid computing;high performance;distributed maximum likelihood evaluation;supercomputers;complex distributed computing environments;evaluation framework;search methods maximum likelihood estimation distributed computing grid computing physics testing supercomputers concurrent computing information analysis performance evaluation	This paper presents GMLE 1, a generic and distributed framework for maximum likelihood evaluation. GMLE is currently being applied to astroinformatics for determining the shape of star streams in the Milky Way galaxy, and to particle physics in a search for theory-predicted but yet unobserved sub-atomic particles. GMLE is designed to enable parallel and distributed executions on platforms ranging from supercomputers and high-performance homogeneous computing clusters to more heterogeneous Grid and Internet computing environments. GMLE's modular implementation seperates concerns of developers into the distributed evaluation frameworks, scientific models, and search methods, which interact through a simple API. This allows us to compare the benefits and drawbacks of different scientific models using different search methods on different computing environments. We describe and compare the performance of two implementations of the GMLE framework: an MPI version that more effectively uses homogeneous environments such as IBM's BlueGene, and a SALSA version that more easily accommodates heterogeneous environments such as the Rensselaer Grid. We have shown GMLE to scale well in terms of computation as well as communication over a wide range of environments. We expect that scientific computing frameworks, such as GMLE, will help bridge the gap between scientists needing to analyze ever larger amounts of data and ever more complex distributed computing environments.	application programming interface;astroinformatics;boinc;blue gene;center for computational innovations;central processing unit;computation;computational science;computer cluster;distributed computing;folding@home;grid computing;internet;iterative method;message passing interface;salsa;seti@home;scalability;speedup;subatomic particle;supercomputer	Travis J. Desell;Nathan Cole;Malik Magdon-Ismail;Heidi Jo Newberg;Boleslaw K. Szymanski;Carlos A. Varela	2007	Third IEEE International Conference on e-Science and Grid Computing (e-Science 2007)	10.1109/E-SCIENCE.2007.30	parallel computing;computer science;theoretical computer science;operating system;database;distributed computing;milky way	HPC	-9.578744144438328	38.132589466549824	156870
e9a0ff5c73c7715b925a939c3203d6867fcec78d	the oklahoma advanced parallel processing research facility	parallel computer;parallel processing	An advanced research facility has been installed in the Norman campus of the University of Oklahoma. This facility will support innovative research in parallel processing, vectorization and supercomputing. In this talk the advanced nature of the configurations at the facility will be presented. The prominent parallel computing features available to researchers will be described in sufficient detail.	automatic vectorization;parallel computing;supercomputer	J. C. Diaz	1986		10.1145/800239.807168	human–computer interaction;computer science;computer graphics (images)	HPC	-8.303656257353497	39.200774059792046	158040
3b21b34d87b2492fe93e7c921431f5a6aec38518	parallel computation of smoke movement during a car park fire		In this paper the use of Fire Dynamics Simulator (FDS) for parallel computer simulation of the smoke movement during a fire of two passenger cars in an underground car park is investigated. The simulations were executed on a high-performance computer cluster. A specific problem of FDS parallel computation using Message-Passing Interface (MPI) is a separate solution of governing equations on computational subdomains causing a loss of accuracy. Therefore, the impact of parallelisation on simulation accuracy in the case of using a greater number of computational cores of the computer cluster is studied with the aim to increase the computational performance and enable practical application of such simulations for fire safety measures. The geometrical model and material properties of the cars used in the simulation have been verified by a full-scale fire experiment in open air. We describe the results of a series of simulations of several fire scenarios with different numbers of parked cars and ventilation configurations and determine times and locations at which conditions in the car park become untenable for human life. The simulation indicates that proper ventilation prolongs tenable conditions by several minutes.	computation;parallel computing	Peter Weisenpacher;Ján Glasa;Ladislav Halada	2016	Computing and Informatics		parallel computing;simulation;computer science;ventilation (architecture);computer cluster;fire dynamics simulator;smoke;supercomputer	Robotics	-6.243808364675619	35.72441754650447	158169
ee10ca175ca7f402ddbdec61a1933c0d0a9984c9	estimation of dynamical characteristics of a parallel program on a model	java programming;abstract syntax tree;distributed computing system;parallel computer;message passing;dynamic characteristic;parallel programs	This paper considers a model of a parallel program that can efficiently be interpreted on an instrumental computer, providing a means for a sufficiently accurate prediction of the actual time needed for execution of the parallel program on a given parallel computational system. The model is designed for parallel programs with explicit message passing written in Java with calls to the MPI library and is a part of the ParJava environment. The model is obtained by transforming the program control tree, which, for Java programs, can be constructed by modifying the abstract syntax tree. The communication functions are simulated on the basis of the LogGP model, which makes it possible to take into account specific features of the distributed computational system.	abstract syntax tree;computation;java;message passing;parallel computing;parse tree	Victor Ivannikov;Serguei Gaissaryan;Arutyun Avetisyan;Vartan A. Padaryan	2006	Programming and Computer Software	10.1134/S0361768806040037	message passing;computer science;theoretical computer science;database;distributed computing;programming language;algorithm;abstract syntax tree;parallel programming model	HPC	-10.589016121176096	37.86522491964301	158358
8c91fcce5b58fa4bc96458c2dc8f677be96e60dd	towards a computing model for open distributed systems	fault tolerant;programming language;computer model;model adaptation;distributed programs;parallel programming;efficient implementation;synchronization;approximate solution;distributed programming;fault tolerance;parallel computer;workqueue;open system;bag data structure;parallel programs;chemical reaction;data structure;open distributed system	"""This paper proposes an implementation of the data structure called bag or multiset used by descriptive programming languages (e.g. Gamma, Linda) over an open system. In this model, a succession of """"chemical reactions"""" consumes the elements of the bag and produces new elements according to specific rules. This approach is particularly interesting as it suppresses all unneeded synchronization and reveals all the potential parallelism of a program. An efficient implementation of a bag provides an efficient implementation of the subsequent program. This paper defines a new communication and synchronization model adapted from workqueues used in parallel computing. The proposed model allows to benefit from the potential parallelism offered by this style of programming when only an approximate solution is needed."""		Achour Mostéfaoui	2007		10.1007/978-3-540-73940-1_7	fault tolerance;parallel computing;real-time computing;data structure;computer science;theoretical computer science;operating system;distributed computing;programming language;algorithm	HPC	-11.716760485160266	39.15058355597235	158574
db2ed79b76ba2cc35bc256d77a8303f461de50e2	petapar: a scalable petascale framework for meshfree/particle simulation	dynamic load balancing;distributed processing;mpi pthreads;overlap of communication and compuation;computational modeling;scalability distributed processing abstracts computational modeling load modeling load management;abstracts;mpi pthreads petascale computing meshfree particle simulation scalability overlap of communication and compuation dynamic load balancing;load management;scalability;petascale computing;resource allocation grid computing message passing multi threading numerical analysis parallel processing physics computing;meshfree particle simulation;top500 supercomputer list petapar scalable petascale framework meshfree particle simulation high performance computing petaflops numerical simulation processor cores parallel computing petascale computing smoothed particle hydrodynamics sph material point method mpm regular grid based domain decomposition code scalability dynamic load balancing strategy flat mpi mpi pthreads hybrid parallelization titan;load modeling	Since high performance computing sustained petaflops in 2008, numerical simulation entered a new era to use 10K to 100K processor cores in one single run of parallel computing. In pursuit of petascale computing, the challenges of scalability must be addressed. Petapar is a highly scalable simulation framework which implements two popular meshfree/particle methods, the smoothed particle hydrodynamics (SPH) and the material point method (MPM). The parallelization starts from the regular-grid-based domain decomposition. The scalability of the code is assured by fully overlapping of communication and computation, and a dynamic load balancing strategy. Petapar supports both flat MPI and MPI+Pthreads hybrid parallelization. The code is tested on Titan, which ranked first on the Top500 supercomputer list when our research work has been done in November 2012. Experiment results show that petaPar linearly scales up to 260K CPU cores with an excellent parallel efficiency of 100% and 96% for the SPH and MPM, respectively.	central processing unit;computation;domain decomposition methods;flops;load balancing (computing);material point method;message passing interface;numerical analysis;numerical weather prediction;parallel computing;petascale computing;scalability;simulation;smoothed-particle hydrodynamics;smoothing;speedup;supercomputer;top500;titan	Leisheng Li;Yingrui Wang;Zhitao Ma;Rong Tian	2014	2014 IEEE International Symposium on Parallel and Distributed Processing with Applications	10.1109/ISPA.2014.16	computational science;parallel computing;petascale computing;scalability;computer science;theoretical computer science;distributed computing;computational model	HPC	-5.032694458949459	38.13106709487826	158799
551f4cec4ad45f9344d1ef1944b2ba6c145f1bdf	applied parallel computing industrial computation and optimization			computation;parallel computing;program optimization		1996		10.1007/3-540-62095-8	computational science;theoretical computer science;unconventional computing	HPC	-7.838024629135387	37.729535843975114	159180
5a7f4b11266dcb31bef6c004fca407fae5a55700	simulations of three-dimensional flows with the lattice boltzmann equation on the ibm 3090/vf	programming environments;pde software;three dimensional;finite difference scheme;specification languages;multigrid methods;parallel implementation;lattice boltzmann equation	We illustrate the basic features of the Lattice Boltzmann Equation (LBE), a new finite-difference scheme that arises from the microdynamics of the Frisch-Hasslacher-Pomcau cellular automation once, instead of tracking the individual history of each particle, one only solves for the mean values of the particle populations living in the lattice. Details on the actual coding of the LBE scheme are presented and discussed along with performance data pertaining to the vector and parallel implementation on the IBM 3090/600 vector multiprocessor. Finally, two applications in the field of two and three-dimensional hydrodynamics are briefly illustrated.	computer simulation;finite difference method;lattice boltzmann methods;multiprocessing;population;uriel frisch	Sauro Succi;F. Higuera;Ferenc Szelényi	1989		10.1145/318789.318804	three-dimensional space;mathematical optimization;parallel computing;computer science;theoretical computer science;lattice boltzmann methods	HPC	-7.7361886238101505	37.342992801183115	159226
3b07a5561a59289c5e7bad9a9bf216d60ecce5f6	using nested graphs to distribute parallel and distributed multi-agent systems	large complex multiscale multiagent models parallel and distributed multiagent system distribution pdmas nested graphs parallel resources modelling approach;nested graphs;distributed computing;multi agent;multi agent distributed computing pdmas nested graphs;multi agent systems;computational modeling;pdmas;computational modeling multi agent systems load modeling program processors adaptation models context context modeling;adaptation models;load modeling;context modeling;program processors;context;parallel processing graph theory large scale systems multi agent systems	Simulation has become an indispensable tool for researchers to explore systems without having recourse to real experiments. In this context multi-agent systems are often used to model and simulate complex systems. Depending on the characteristics of the modelled system, methods used to represent the system may vary. Whatever the modelling techniques used, increasing the size and the precision of a model increases the amount of computation needed, requiring the use of parallel systems when it becomes too large. Usually, to efficiently run on parallel resources, the model must be adapted to be distributed. In this paper, we propose a new modelling approach, based on nested graphs, that allows the design of large, complex and multi-scale multi-agent models which can be efficiently distributed on parallel resources. A PDMAS (Parallel and Distributed Multi-Agent Platform) that supports this approach and efficiently run parallel multi-agent models is introduced.	complex systems;computation;experiment;multi-agent system;simulation	Alban Rousset;Bénédicte Herrmann;Christophe Lang;Laurent Philippe;Hadrien Bride	2016	2016 24th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP)	10.1109/PDP.2016.91	parallel computing;real-time computing;computer science;theoretical computer science;multi-agent system;distributed computing;context model;computational model	HPC	-10.233938162931668	38.59230441253825	159257
cf43d27997802351a4258b67d95fda090abcf85b	a parallel code for time independent quantum reactive scattering on cpu-gpu platforms	detailed analysis;innovative feature;intensive usage;abc code;beams experiment simulation;different implementation strategy;computational engine;time independent quantum reactive;parallel code;gpu architecture;heavy usage;innovative architecture;cpu-gpu platform	The innovative architecture of GPUs has been exploited to the end of implementing an efficient version of the time independent quantum reactive scattering ABC code. The intensive usage of the code as a computational engine for several molecular calculations and crossed beams experiment simulations has prompted a detailed analysis of the utilization of the innovative features of the GPU architecture. ABC has shown to rely on a heavy usage of blocks of recursive sequences of linear algebra matrix operations whose performances vary significantly with the input and the section of the code. This has requested the evaluation of the suitability of different implementation strategies for the various parts of ABC. The outcomes of the related test runs are discussed in the paper.	central processing unit;code;computation;computational chemistry;computer program;fortran;graphics processing unit;hotspot (wi-fi);linear algebra;parallel computing;performance;programming language;quantum;recursion;run time (program lifecycle phase);simulation	Ranieri Baraglia;Malko Bravi;Gabriele Capannini;Antonio Laganà;Edoardo Zambonini	2011		10.1007/978-3-642-21931-3_32	real-time computing;simulation;computer science;theoretical computer science;operating system;database;programming language;computer security;algorithm	HPC	-6.117088945828358	38.3257160736836	159375
a5971d3225ce32732b71821ccd2e2f8ce52ea93d	virtual particles and search for global minimum	computational techniques;virtual particles;molecular dynamics;simulated annealing;multi dimensional;levels of abstraction;feature extraction;message passing;molecular dynamic;genetic algorithm;genetic algorithms;vehicle navigation;natural science;particle modeling;global minimum search;hopfield nets;predictive display;natural solvers	Abstract   The models and computational techniques stemming from natural sciences — so-called natural solvers — become more and more popular as the methods of  last resort  in investigations of irreducible problems of universal character. In the paper, the author uses the concept of a  virtual particle  (VIP) model. It covers the broad range of natural solvers, which use VIPs as basic objects. The main features of particles paradigm proposed: simplicity, decomposition ability, and built-in  message-passing  way of communication, make it attractive as a universal approach for mapping different problems on parallel platform. In course of the paper, molecular dynamics (MD) is proposed as a pure VIP model. In dependence of the level of abstraction the particle can be defined as atom, cluster of molecules, piece of matter, object or UNIX process. MD applications as a method of search for global minimum in multi-dimensional function domain is discussed. The features extraction problem considered, shows the advantages of this technique. It is also shown that Hopfield nets can be mapped onto a particle model. The locality of the particles paradigm is discussed on the base of the spatial genetic algorithm.	maxima and minima	Witold Dzwinel	1997	Future Generation Comp. Syst.	10.1016/S0167-739X(96)00024-6	molecular dynamics;parallel computing;simulation;genetic algorithm;computer science;artificial intelligence;theoretical computer science;database;distributed computing	Arch	-8.408681081241117	32.81450695780072	159552
c7a9e7e72d5bb1ba1ec14ac8a4a79d3a0cc7bb92	implementing a particle-fluid model of auroral electrons	dynamic model;physical sciences;fluid model;physical model;fysik	The particle-fluid model of auroral electrons that is presented in [1] is a major step forward within the field of dynamic models of the auroral generation mechanisms. The model is, however, also an example where the implementation of a physical model requires a lot of knowledge from the field of computer science. Therefore, this paper contains a detailed description of the implementation behind the particlefluid model. We present how the particles are implemented in doubly linked lists, how the fluid equations are solved in a time-efficient algorithm, and how these two parts are coupled into a single framework. We also describe how the code is parallelized with an efficiency of nearly 100%.	algorithm;aurora;computational fluid dynamics;computer science;doubly linked list;parallel computing	Jörgen Vedin;Kjell Rönnmark	2006		10.1007/978-3-540-75755-9_45	simulation;physical model;physical science	AI	-6.323525804145814	36.677290510670446	161301
74a1e7b3f13a4f9ab7041e0a4d74954d1ce12385	sedifoam: a general-purpose, open-source cfd-dem solver for particle-laden flow with emphasis on sediment transport	sediment transport;multi scale modeling;cfd dem;particle laden flow	With the growth of available computational resource, CFD–DEM (computational fluid dynamics–discrete element method) becomes an increasingly promising and feasible approach for the study of sediment transport. Several existing CFD–DEM solvers are applied in chemical engineering and mining industry. However, a robust CFD–DEM solver for the simulation of sediment transport is still desirable. In this work, the development of a threedimensional, massively parallel, and open-source CFD–DEM solver SediFoam is detailed. This solver is built based on open-source solvers OpenFOAM and LAMMPS. OpenFOAM is a CFD toolbox that can perform three-dimensional fluid flow simulations on unstructured meshes; LAMMPS is a massively parallel DEM solver for molecular dynamics. Several validation tests of SediFoam are performed using cases of a wide range of complexities. The results obtained in the present simulations are consistent with those in the literature, which demonstrates the capability of SediFoam for sediment transport applications. In addition to the validation test, the parallel efficiency of SediFoam is studied to test the performance of the code for large-scale and complex simulations. The parallel efficiency tests show that the scalability of SediFoam is satisfactory in the simulations using up to O(10) particles.	acceptance testing;cfd-dem;computational fluid dynamics;computational resource;computer simulation;discrete element method;general-purpose modeling;horner's method;large-scale atomic/molecular massively parallel simulator;molecular dynamics;numerical analysis;numerical method;open-source software;openfoam;parallel algorithm;parallel computing;scalability;solver;speedup	Rui Sun;Heng Xiao	2016	Computers & Geosciences	10.1016/j.cageo.2016.01.011	computational science;simulation;geology;computer science;theoretical computer science;sediment transport;cfd-dem	HPC	-5.85932675485707	36.764188523861414	161347
94818a2fa0448c17ee0d842422b4b3997cbc5fa8	predictive analysis and optimisation of pipelined wavefront computations	analytical models;optimisation;parallel algorithm;pipelined wavefront algorithm;ubiquitous class;maintenance cost;predictive analytic model;qa76 electronic computers computer science computer software;arrays;computational modeling;concurrent computing pervasive computing context modeling grid computing parallel algorithms algorithm design and analysis predictive models performance analysis defense industry weapons;loggp based analytic performance model;performance model;mathematical model;openmp;ubiquitous computing;optimization;tiles;ubiquitous computing optimisation pipeline processing;openmp pipelined wavefront algorithm ubiquitous class parallel algorithm predictive analytic model loggp based analytic performance model;data grid;analytical model;pipeline processing;qa76 computer software	Pipelined wavefront computations are a ubiquitous class of parallel algorithm used for the solution of a number of scientific and engineering applications. This paper investigates three optimisations to the generic pipelined wavefront algorithm, which are investigated through the use of predictive analytic models. The modelling of potential optimisations is supported by a recently developed reusable LogGP-based analytic performance model, which allows the speculative evaluation of each optimisation within the context of an industry-strength pipelined wavefront benchmark developed and maintained by the United Kingdom Atomic Weapons Establishment (AWE). The paper details the quantitative and qualitative benefits of: (1) parallelising computation blocks of the wavefront algorithm using OpenMP; (2) a novel restructuring/shifting of computation within the wavefront code and, (3) performing simultaneous multiple sweeps through the data grid.	alias systems corporation;benchmark (computing);computation;equation solving;erable;load balancing (computing);mathematical optimization;openmp;parallel algorithm;parallel computing;pipeline (computing);precomputation;speculative execution	Gihan R. Mudalige;Simon D. Hammond;J. A. Smith;Stephen A. Jarvis	2009	2009 IEEE International Symposium on Parallel & Distributed Processing	10.1109/IPDPS.2009.5160882	parallel computing;computer science;theoretical computer science;operating system;data grid;mathematical model;distributed computing;parallel algorithm;computational model;ubiquitous computing;computer network	HPC	-6.542573904320275	38.74565797845629	164585
07c387888f2e097b13d9e810fa4a625542ae16c6	parallelization of a multiconfigurational perturbation theory	high performance computing;naturvetenskap;natural sciences;high;teoretisk kemi;caspt2;parallellization;multiconfigurational perturbation theory;performance computing	In this work, we present a parallel approach to complete and restricted active space second-order perturbation theory, (CASPT2/RASPT2). We also make an assessment of the performance characteristics of its particular implementation in the Molcas quantum chemistry programming package. Parallel scaling is limited by memory and I/O bandwidth instead of available cores. Significant time savings for calculations on large and complex systems can be achieved by increasing the number of processes on a single machine, as long as memory bandwidth allows, or by using multiple nodes with a fast, low-latency interconnect. We found that parallel efficiency drops below 50% when using 8-16 cores on the shared-memory architecture, or 16-32 nodes on the distributed-memory architecture, depending on the calculation. This limits the scalability of the implementation to a moderate amount of processes. Nonetheless, calculations that took more than 3 days on a serial machine could be performed in less than 5 h on an InfiniBand cluster, where the individual nodes were not even capable of running the calculation because of memory and I/O requirements. This ensures the continuing study of larger molecular systems by means of CASPT2/RASPT2 through the use of the aggregated computational resources offered by distributed computing systems.	automatic parallelization;complex systems;computation (action);computational resource;distributed computing;greater than;infiniband;input/output;large;molcas;memory bandwidth;organic chemistry phenomena;parallel computing;perturbation theory;requirement;scalability;shared memory;speedup;test scaling	Steven Vancoillie;Mickaël G. Delcey;Roland Lindh;Victor Vysotskiy;Per-Åke Malmqvist;Valera Veryazov	2013	Journal of computational chemistry	10.1002/jcc.23342	supercomputer;natural science;theoretical computer science;computational chemistry;mathematics	HPC	-5.014386127843704	37.71362966587228	165597
e918df981809e36751061e03c1533cda676569b7	on the numerical sensitivity of computer simulations on hybrid and parallel computing systems	paper;computer graphic equipment;graphics processing units computer simulation hybrid computing system parallel computing system floating point arithmetic cell processor grape special purpose computer numerical sensitivity discrete stochastic arithmetic;cell processor;rounding errors;coprocessors;hybrid computing;nvidia geforce gtx 480;cuda;floating point error;performance improvement;parallel processing computer graphic equipment coprocessors digital simulation floating point arithmetic;graphics processing unit assembly;discrete stochastic arithmetic hybrid computing system simulation software rounding errors;parallel computer;nvidia;graphic processing unit;algorithms;floating point;source code;computer science;floating point arithmetic;system simulation;computer simulation;parallel processing;digital simulation	Simulation results depend not only on the precision of the floating point arithmetic with respect to the numerical accuracy of the results. They are also sensitive to differences of floating point arithmetic implementations of different hybrid and parallel computing systems such as CPUs, GPUs, dedicated processors like the Cell processor or the GRAPE special-purpose computer with the same precision. As floating point operations may not maintain basic properties like associative or distributive properties of the underlying mathematical operations, the numerical values computed by simulations may become dependent on the hardware platform and the specific run of the program. Numerical accuracy control of the simulation would identify significant variations of the simulation results due to these numerical effects. For this purpose, the numerical accuracy is controlled in this paper by a method for rounding error estimation based on the discrete stochastic arithmetic (DSA). This method, which is investigated on both CPUs and GPUs here, is generally applicable independent of the algorithm and can provide a tight estimation of the rounding errors while increasing the computational time only by a factor of approximately 3 in the ideal case. It is shown that the method can be applied automatically without modifying source code. Furthermore, performance improvements compared to the numerical accuracy control based on higher precision arithmetic can be obtained.	algorithm;cell (microprocessor);central processing unit;computation;computer simulation;embedded system;grape;graphics processing unit;numerical analysis;parallel computing;round-off error;rounding;time complexity	Wenbin Li;Sven Simon;Steffen Kieß	2011	2011 International Conference on High Performance Computing & Simulation	10.1109/HPCSim.2011.5999868	computer simulation;parallel processing;parallel computing;arbitrary-precision arithmetic;computer hardware;computer science;floating point;theoretical computer science;operating system;machine epsilon	HPC	-5.038778456382911	35.70649755781618	165766
7ef2d3a71115fe0ccf50dc236e01136679e9c2c5	solving biharmonic equation in a distributed computing environment using pvm	biharmonic equation;distributed computing environment		distributed computing environment;parallel virtual machine	Norhashidah Hj. Mohd. Ali;Tan Chun Shien;Chong Chee Hau	2004			biharmonic equation;distributed computing environment;computational science;computer science	HPC	-7.441135514261405	37.979173972589194	166443
f78fdf6da948317bcff2d7f88903450b7e6e0cf5	a parallel logic simulation algorithm based on query			algorithm;logic simulation	Tomohiro Kudoh;Tetsuro Kimura;Hideharu Amano;Takuya Terasawa	1992			logic optimization;parallel computing;logic simulation;theoretical computer science;parallel algorithm;query optimization;computer science;sargable	EDA	-10.2165383677806	34.01224386856136	166688
f09c38b80b8e32f9173e65c7287f1281b2015391	large scale parallel computing for fluid dynamics on unstructured grid	aerodynamics;computational fluid dynamics;mathematical model;face;program processors;parallel processing;partitioning algorithms	Massive parallel computational fluid dynamics is a vital tool for the modern aviation industry. The parallel aerodynamics numerical simulation software based on unstructured mixed grid and cell-centered finite volume method (FVM) was presented in this paper, which was developed for the complicated configurations of industrial grade. The algorithms for parallel implementation with message passing interface (MPI), including compact numerical discrete schemes, grid partition method for multi-processors and data transfer scheme, are discussed in detail. The validity of parallel computing is verified using a revolving model of relatively small grid. Then a large transport airplane configuration with hundred millions of grid elements is used for parallel testing, and the efficiency is preserved above 80% up to 18816 processors.	algorithm;central processing unit;computational fluid dynamics;computer simulation;finite volume method;message passing interface;numerical analysis;parallel computing;simulation software;unstructured grid	Jing Tang;Bin Li;Jiangtao Chen;Xiaoquan Gong	2016	2016 15th International Symposium on Parallel and Distributed Computing (ISPDC)	10.1109/ISPDC.2016.17	face;computational science;parallel processing;parallel computing;aerodynamics;computational fluid dynamics;computer science;theoretical computer science;massively parallel;mathematical model;distributed computing	HPC	-6.26170652964064	37.51851277800027	167872
d416b0c06b5ab63b30e50028c41c99111bec2794	strategies and tools for the exploitation of massively parallel computer systems	qa76 computer software computer software;qa76 computer software	The aim of this thesis is to develop software and strategies for the exploitation of parallel computer hardware, in particular distributed memory systems, and embedding these strategies within a parallelisation tool to allow the automatic generation of these strategies. The parallelisation of four structured mesh codes using the Computer Aided Parallelisation Tools provided a good initial parallelisation of the codes. However, investigation revealed that simple optimisation of the communications within these codes provided an even better improvement in performance. The dominant factor within the communications was the data transfer time with communication start-up latencies also significant. This was significant throughout the codes but especially in sections of pipelined code where there were large amounts of communication present. This thesis describes the development and testing of the methods used to increase the performance of these communications by overlapping them with unrelated calculation. This method of overlapping the communications was applied to the exchange of data communications as well as the pipelined communications. The successful application by hand provided the motivation for these methods to be incorporated and automatically generated within the Computer Aided Parallelisation Tools. These methods were integrated within these tools as an additional stage of the parallelisation. This required a generic algorithm that made use of many of the symbolic algebra tests and symbolic variable manipulation routines within the tools. The automatic generation of overlapped communications was applied to the four codes previously parallelised as well as a further three codes, one of which was a real world Computational Fluid Dynamics code. The methods to apply automatic generation of overlapped communications to unstructured mesh codes were also discussed. These methods are similar to those applied to the structured mesh codes and their automation is viewed to be of a similar fashion.	algorithm;code;computation;computational fluid dynamics;computer algebra system;computer hardware;distributed memory;generic programming;mathematical optimization;parallel computing;pipeline (computing);unstructured grid	Emyr Wyn Evans	2000			parallel computing;computer science;theoretical computer science;distributed computing	HPC	-11.667787888870329	37.95222624723137	167878
24a0f4ed81da907dfae36779932d8ae56710da01	quantum reactive scattering on innovative computing platforms	chebyshev;gpu;quantum time dependent;cuda;gpgpu;triatomic reactions	The possibility of implementing quantum reactive scattering programs on cheap platforms, originally used for graphic purposes only, has been investigated using a NVIDIA GPU. After a conversion of the code considered from Fortran to C and its deep restructuring for exploiting the GPU key features, significant speedups have been obtained for RWAVEPR, a time dependent quantum reactive scattering code propagating in time a complex wavepacket. As benchmark calculations those concerned with the evaluation of the reactive probabilities of the Cl+H 2  and the N+N 2  reactions have been considered.	quantum	Leonardo Pacifici;Danilo Nalli;Antonio Laganà	2013	Computer Physics Communications	10.1016/j.cpc.2013.01.002	parallel computing;simulation;computer science;chebyshev filter;theoretical computer science;general-purpose computing on graphics processing units	HPC	-5.8967286085637785	37.75578147989272	168147
edefb7d1da03c643688f607ed530cebbf02fead6	analyst: tool support for the migration of fortran applications to parallel systems	parallel systems		fortran	B. Chapman;M. Egg	1997			computer science;parallel computing;fortran;computational science	HPC	-9.395269558787902	36.97382639581881	168651
4db49b94c5b6274c55bd33226fa54842a01446ae	a software framework for mixed finite element programming	developpement logiciel;preconditionnement;matriz bloque;methode element fini;metodo elemento finito;numerical method;programming environment;preconditioning;finite element method;mixed finite element;medio ambiente programacion;metodo numerico;matrice bloc;mixed method;desarrollo logicial;software development;stabilized finite element method;software framework;unstructured mesh;block matrix;precondicionamiento;methode numerique;environnement programmation	Many code developers think the implementation of mixed finite elements on general unstructured meshes is challenging. This assertion is reflected in the many efforts on constructing stabilized finite element methods (e.g. for flow problems), where standard elements can be used, and the fact that there are very few libraries offering a mixed finite element programming environment. In this paper we described a software framework for mixed finite element programming, which makes the use of mixed methods as easy as standard finite element methods. The various abstractions used in this framework will be explained. The tools are made available in the generic Diffpack software.	software framework	Hans Petter Langtangen;Kent-André Mardal	2002		10.1007/3-540-47789-6_79	simulation;numerical analysis;computer science;software framework;software development;finite element method;preconditioner;programming language;block matrix;algorithm	HPC	-9.903572624953528	35.491983950311756	169639
fe579cab59248ba7be60e69f6b5799e3f581bc09	automatic parallel program generation for finite element analysis.	program generation;finite element analysis;automatic parallelization	The authors have been developing a finite element based simulation language system FEEL (Finite Element Equation Language). The current version of the system has the functionality to generate a portable message-passing parallel program from a user’s description of 2D partial differential equations. This paper introduces the FEEL system with an emphasis on its parallel program generation functionality. Discussion will be presented on how this tool can contribute to finite element programmers from several viewpoints. Since the development of efficient message-passing parallel programs requires a good knowledge of the target parallel computers, the functionality is expected to help numerical analysts who have need to develop finite element programs which require high-performance computing resources.		Shun Doi;Hidehiro Fujio;Kouta Sugihara	1996			computational science	HPC	-10.110889377269018	36.363599196727115	169777
a75d9b1c2a67f49edcc6f6c22da61488063d5af9	three-dimensional electromagnetic particle-in-cell with monte carlo collision simulations on three mimd parallel computers	parallel algorithm;domain decomposition;electromagnetic field;three dimensional;self consistent;large scale simulation;finite difference time domain method;parallel computer;message passing;monte carlo;particle in cell	A three-dimensional electromagnetic particle-in-cell code with Monte Carlo collision (PIC-MCC) is developed for MIMD parallel supercomputers. This code uses a standard relativistic leapfrog scheme incorporating Monte Carlo calculations to push plasma particles and to include collisional effects on particle orbits. A local finite-difference time-domain method is used to update the self-consistent electromagnetic fields. The code is implemented using the General Concurrent PIC (GCPIC) algorithm, which uses domain decomposition to divide the computation among the processors. Particles must be exchanged between processors as they move among subdomains. Message passing is implemented using the Express Cubix library and the PVM. We evaluate the performance of this code using a 512-processor Intel Touchstone Delta, a 512-processor Intel Paragon, and a 256-processor CRAY T3D. It is shown that a high parallel efficiency exceeding 95% has been achieved on all three machines for large problems. We have run PIC-MCC simulations using several hundred million particles with several million collisions per time step. For these large-scale simulations the particle push time achieved is in the range of 90–115 ns/particle/time step, and the collision calculation time in the range of a few hundred nanoseconds per collision.	algorithm;central processing unit;computation;computer;cray t3d;cubix;domain decomposition methods;finite-difference time-domain method;intel paragon;leapfrog integration;mimd;message passing;monte carlo method;pic microcontroller;parallel virtual machine;parallel computing;particle-in-cell;plasma active;simulation;speedup;supercomputer;touchstone file	Jun Wang;P. Liewer;E. Huang	1997	The Journal of Supercomputing	10.1007/BF00227862	three-dimensional space;computational science;particle-in-cell;parallel computing;message passing;electromagnetic field;computer science;theoretical computer science;domain decomposition methods;parallel algorithm;monte carlo method	HPC	-5.893116769597169	37.140097626693496	170964
00b5c57c9c3bf5e37b9f25c13cd23a1ea20a7ff8	implementing graph representation model for parallel and distributed systems using erlang	clusters;parallel systems;erlang;distributed systems;graphs representation	This paper describes a new model of graph representation using the Erlang actor model. Benefits of using lightweight processes instead of traditional passive data structures are given. Examples of using this model are shown. The experimental part gives two examples of using early implementations of the offered model. As a conclusion, an analysis of applicability for tasks from different branches of science is given.	actor model;beowulf cluster;computation;data structure;distributed computing;entity;erlang (programming language);experiment;fault tolerance;glossary;graph (abstract data type);graph (discrete mathematics);grid computing;guardian service processor;human–computer interaction;light-weight process;regular expression;scalability;server (computing);spawn (computing);topological graph theory;transaction processing system;vertex (graph theory);virtual machine	Iurii Petrov	2016	Computer Science (AGH)	10.7494/csci.2016.17.1.99	erlang;computer science;theoretical computer science;database;distributed computing;programming language	SE	-10.60250230942974	37.49185318925067	172963
70c607c0069f6d1ca80128c90d7f3dbdf97899e7	a hardware-accelerated quantum monte carlo framework (haqmc) for n-body systems	field programmable gate array;programming language;selected works;design and development;reconfigurable computing;modeling and simulation;distributed programs;cray xd1;hardware accelerator;fpga;fixed point;fpga implementation;07 05 tp;operating system;ground state;07 05 bx;bepress;ground state energy;utility computing;field programmable gate arrays;coarse grained;monte carlo;quantum monte carlo;high performance;reconfigurable hardware;02 70 ss;quantum monte carlo method	Interest in the study of structural and energetic properties of highly quantum clusters, such as inert gas clusters has motivated the development of a hardware-accelerated framework for Quantum Monte Carlo simulations. In the Quantum Monte Carlo method, the properties of a system of atoms, such as the ground-state energies, are averaged over a number of iterations. Our framework is aimed at accelerating the computations in each iteration of the QMC application by offloading the calculation of properties, namely energy and trial wave function, onto reconfigurable hardware. This gives a user the capability to run simulations for a large number of iterations, thereby reducing the statistical uncertainty in the properties, and for larger clusters. This framework is designed to run on the Cray XD1 high performance reconfigurable computing platform, which exploits the coarse-grained parallelism of the processor along with the fine-grained parallelism of the reconfigurable computing devices available in the form of field-programmable gate arrays. In this paper, we illustrate the functioning of the framework, which can be used to calculate the energies for a model cluster of helium atoms. In addition, we present the capabilities of the framework that allow the user to vary the chemical identities of the simulated atoms.	approximation algorithm;biological system;categorization;computation;cray xd1;field-programmability;field-programmable gate array;helium;ibm notes;instruction pipelining;monte carlo algorithm;monte carlo method;pipeline (computing);processor register;quantum monte carlo;reconfigurable computing;speedup;variational monte carlo	Akila Gothandaraman;Gregory D. Peterson;G. Lee Warren;Robert J. Hinde;Robert J. Harrison	2009	Computer Physics Communications	10.1016/j.cpc.2009.06.027	quantum monte carlo;parallel computing;real-time computing;reconfigurable computing;computer science;theoretical computer science;modeling and simulation;ground state;quantum mechanics;field-programmable gate array	ML	-5.173575059107809	38.83183626567395	173299
5e19f54e04b67fb6479dd4e7901a2d84aa9981d0	reproducible large-scale social simulations on various computing environment		In this paper, we propose parallel computing techniques for reproducible large-scale social simulations on various computing environments including CPU (Central Processing Unit) or GPU (Graphic Processing Unit). When we use computing resources for large-scale social simulations, the reproducibility of a simulation should be considered. “Reproducibility” means the same trial of a simulation can be repeated. If the same computing resources are available to repeat the trial, it is easy to reproduce the same simulation results. When not all the same computing resources are available, however, it becomes difficult to obtain the same trial since random number generators may become different from the original computation resources. In this study, we employ multi-thread computing on CPU or GPU. We propose two models to run reproducible social simulations on CPU or GPU. One is to parallelize trials (Trial Parallelization). The other is to parallelize agents of a single simulation (Agent Parallelization). These models can be ensured reproducibility even in different computing resources. Our experimental results show that the same computing processes are obtained on CPU or GPU. When we parallelize large-scale social simulation on CPU or GPU, we can accelerate the simulation as a secondary effect.	central processing unit;computation;general-purpose computing on graphics processing units;graphics processing unit;parallel computing;random number generation;social simulation	Takuya Harada;Tadahiko Murata	2017	2017 Joint 17th World Congress of International Fuzzy Systems Association and 9th International Conference on Soft Computing and Intelligent Systems (IFSA-SCIS)	10.1109/IFSA-SCIS.2017.8023303	parallel computing;theoretical computer science;computer science;computation;central processing unit;random number generation;social simulation	HPC	-5.951479805900231	34.943183158280064	173478
06120c626e36ffb7feee85b2f3a1dc20adc1b025	performance aspects of collocated and staggered grids for particle-in-cell plasma simulation		We present a computational comparison of collocated and staggered uniform grids for particle-in-cell plasma simulation. Both types of grids are widely used, and numerical properties of the corresponding solvers are well-studied. However, for large-scale simulations performance is also an important factor, which is the focus of this paper. We start with a baseline implementation, apply widely-used techniques for performance optimization and measure their efficacy for both grids on a high-end Xeon CPU and a second-generation Xeon Phi processor. For the optimized version the collocated grid outperforms the staggered one by about 1.5 x on both Xeon and Xeon Phi. The speedup on the Xeon Phi processor compared to Xeon is about 1.9 x.	particle-in-cell;pin grid array;simulation	Sergey Bastrakov;Igor Surmin;Evgeny Efimenko;Arkady Gonoskov;Iosif Meyerov	2017		10.1007/978-3-319-62932-2_8	grid;parallel computing;particle-in-cell;xeon;plasma;xeon phi;speedup;simd;computer science	HPC	-5.152004628734733	39.250568454762536	174381
8216227fc7b80528208bc75ae718ec49fefc9700	particle-in-cell laser-plasma simulation on xeon phi coprocessors	benchmarking;computational physics;physics plasm ph;plasma simulation;paper;plasma physics;physics;xeon phi;physics comp ph;particle in cell;intel xeon phi;particle in cell methods	This paper concerns the development of a high-performance implementation of the Particle-in-Cell method for plasma simulation on Intel Xeon Phi coprocessors. We discuss the suitability of the method for Xeon Phi architecture and present our experience in the porting and optimization of the existing parallel Particle-in-Cell code PICADOR. Direct porting without code modification gives performance on XeonPhi close to that of an8-core CPUonabenchmarkproblemwith 50particles per cell.Wedemonstrate step-by-step optimization techniques, such as improving data locality, enhancing parallelization efficiency and vectorization leading to an overall 4.2× speedup on CPU and 7.5× onXeon Phi compared to the baseline version. The optimized version achieves 16.9 ns per particle update on an Intel Xeon E5-2660 CPU and 9.3 ns per particle update on an Intel Xeon Phi 5110P. For a real problem of laser ion acceleration in targets with surface grating, where a large number of macroparticles per cell is required, the speedup of Xeon Phi compared to CPU is 1.6×. © 2016 Elsevier B.V. All rights reserved.	automatic vectorization;baseline (configuration management);central processing unit;coprocessor;locality of reference;mathematical optimization;parallel computing;particle-in-cell;plasma active;simulation;speedup;xeon phi	Igor Surmin;Sergey Bastrakov;Evgeny Efimenko;Arkady Gonoskov;A. V. Korzhimanov;Iosif Meyerov	2016	Computer Physics Communications	10.1016/j.cpc.2016.02.004	parallel computing;computer hardware;computer science;operating system;xeon phi;hyper-threading;physics	HPC	-5.16426350515639	38.7602595939847	174690
6ce4a27dead4f6681c0ad71989da8255260a1dcc	development and performance analysis of a parallel finite element application implemented in an object-oriented programming framework	finite element;object oriented programming		profiling (computer programming)	Brian J. Henz;Dale R. Shires	2003			inductive programming;computer science;reactive programming;finite element method;object-oriented programming;computational science	HPC	-9.735956186692185	37.29868297054604	175050
8c767f60727160d73d049c7488da80d8009fca76	performance prediction through simulation of a hybrid mpi/openmp application	heterogeneous systems;simulation;working conditions;hybrid;openmp;performance prediction;mpi;smp cluster;simulation environment;modeling and analysis	This paper deals with the performance prediction of hybrid MPI/OpenMP code. The use of HeSSE (Heterogeneous System Simulation Environment), along with an XML-based prototype language, MetaPL, makes it possible to predict hybrid application performance in many different working conditions, e.g., without the fully developed code or in an unavailable system. After a review of hybrid programming techniques and a brief overview of the HeSSE simulation environment, the problems related to the simulation of hybrid code and to its description through trace files are dealt with. The whole application modeling and analysis cycle is presented and validated, predicting the performance of a parallel N-body code on a SMP cluster and comparing it to the timings measured on the real system. 2005 Elsevier B.V. All rights reserved.	code;compiler;image scaling;message passing interface;openmp;parallel computing;performance prediction;prototype;simulation;symmetric multiprocessing;xml	Rocco Aversa;Beniamino Di Martino;Massimiliano Rak;Salvatore Venticinque;Umberto Villano	2005	Parallel Computing	10.1016/j.parco.2005.03.009	computational science;parallel computing;real-time computing;hybrid;computer science;message passing interface	HPC	-9.897166133818843	39.087141890623435	175054
479ccce1ccc8e6cff1adbc20dd81ad0e9c2f120f	dm-heom: a portable and scalable solver-framework for the hierarchical equations of motion		Computing the Hierarchical Equations of Motion (HEOM) is by itself a challenging problem, and so is writing portable production code that runs efficiently on a variety of architectures while scaling from PCs to supercomputers. We combined both challenges to push the boundaries of simulating quantum systems, and to evaluate and improve methodologies for scientific software engineering. Our contributions are threefold: We present the first distributed memory implementation of the HEOM method (DM-HEOM), we describe an interdisciplinary development workflow, and we provide guidelines and experiences for designing distributed, performance-portable HPC applications with MPI-3, OpenCL and other state-of-the-art programming models. We evaluated the resulting code on multi- and many-core CPUs as well as GPUs, and demonstrate scalability on a Cray XC40 supercomputer for the PS I molecular light harvesting complex.	algorithm;c++;cmake;central processing unit;compiler;computer scientist;cray xc40;density matrix;distributed memory;dm-crypt;graphics processing unit;high- and low-level;large hadron collider;machine code;manycore processor;message passing interface;multi-core processor;open-source software;opencl api;ps-algol;parallel computing;prototype;quantum information;quantum system;runtime system;scalability;simulation;software engineering;solver;supercomputer;wolfram mathematica	Matthias Noack;Alexander Reinefeld;Tobias Kramer;Thomas Steinke	2018	2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)	10.1109/IPDPSW.2018.00149	computer science;equations of motion;parallel computing;memory management;distributed memory;programming paradigm;scalability;workflow;supercomputer;solver	HPC	-7.6090634388040925	38.72481445367408	175198
fd2282d54bc647e2a68b8433c0f2521fe2dc330d	mra: a computational technique for security in high-performance systems	computational techniques;high performance		computation	Mahdi Abdelguerfi;Andrea Dunham;Wayne Patterson	1993			computer science	HPC	-8.282094579896452	35.008730170908585	177502
f071cedaf7568f42e175798ff1da4ff120df2d11	parallel clustering for visualizing large scientific line data	mathematical model vectors clustering algorithms data visualization data models graphics processing unit computational modeling;cluster algorithm;pattern clustering;salient feature capturing large scientific line data visualization line extraction dynamic structures dynamic interactions visual validation visual analysis process scientific simulation parallelization design regression model based clustering large line data categorization parallel clustering method expectation maximization algorithm iterative approximation optimal data partitioning sorted balance algorithm iterative clustering process regression model parameter recovery internode message exchanges;sorting;heterogeneous computing;computer model;regression model;data partitioning;data model;approximation theory;sorting approximation theory data visualisation expectation maximisation algorithm feature extraction message passing parallel processing pattern classification pattern clustering regression analysis;data visualisation;computational modeling;vectors;feature extraction;clustering method;data visualization;expectation maximization algorithm;pattern classification;message passing;mathematical model;graphic processing unit;clustering algorithms;regression analysis;graphics processing unit;parallel processing;data models;expectation maximisation algorithm	Scientists often need to extract, visualize and analyze lines from vast amounts of data to understand dynamic structures and interactions. The effectiveness of such a visual validation and analysis process mainly relies on a good strategy to categorize and visualize the lines. However, the sheer size of line data produced by state-of-the-art scientific simulations poses great challenges to preparing the data for visualization. In this paper, we present a parallelization design of regression model-based clustering to categorize large line data derived from detailed scientific simulations by leveraging the power of heterogeneous computers. This parallel clustering method employs the Expectation Maximization algorithm to iteratively approximate the optimal data partitioning. First, we use a sorted-balance algorithm to partition and distribute the lines with various lengths among multiple compute nodes. During the following iterative clustering process, regression model parameters are recovered based on the local lines on each individual node, with only a few inter-node message exchanges involved. Meanwhile, the workload of regression model computing is well balanced across the nodes. The experimental results demonstrate that our approach can effectively categorize large line data in a scalable manner to concisely convey dynamic structures and interactions, leading to a visualization that captures salient features and suppresses visual clutter to facilitate scientific exploration of large line data.	approximation algorithm;cuda;categorization;central processing unit;cluster analysis;clutter;computer multitasking;energy citations database;expectation–maximization algorithm;gpu cluster;graphics processing unit;interaction;interactive visualization;iterative method;message passing interface;parallel computing;petascale computing;plume (fluid dynamics);scalability;set packing;simulation;streaming media	Jishang Wei;Hongfeng Yu;Kwan-Liu Ma;Jackie H. Chen	2011	2011 IEEE Symposium on Large Data Analysis and Visualization	10.1109/LDAV.2011.6092316	computer science;theoretical computer science;machine learning;data mining	Visualization	-7.3558776980302305	33.13215492164692	177740
b38d6fa229c2fb70e2d8c918bc24b3c144984afc	hlogo: a parallel haskell variant of netlogo		Agent-based Modeling (ABM) has become quite popular to the simulation community for its usability and wide area of applicability. However, speed is not usually a trait that ABM tools are characterized of attaining. This paper presents HLogo, a parallel variant of the NetLogo ABM framework, that seeks to increase the performance of ABM by utilizing Software Transactional Memory and multi-core CPUs, all the while maintaining the user friendliness of NetLogo. HLogo is implemented as a Domain Specific Language embedded in the functional language Haskell, which means that it also inherits Haskell's features, such as its static typing.	agent-based model;central processing unit;domain-specific language;embedded system;functional programming;haskell;multi-core processor;netlogo;simulation;software transactional memory;type system;usability	Nikolaos Bezirgiannis;I. S. W. B. Prasetya;Ilias Sakellariou	2016	2016 6th International Conference on Simulation and Modeling Methodologies, Technologies and Applications (SIMULTECH)	10.5220/0005983501190128	simulation;object-oriented modeling;programming language;real-time computing;software transactional memory;trait;functional programming;haskell;netlogo;domain-specific language;usability;computer science	EDA	-10.985665938066044	39.11819971309145	178608
496948aa6ea820b82c1346dec955c4416fb8c8d9	circuit simulation code generation by computer algebra	computer algebra;circuit simulation code generation	CSCG (Circuit Simulation Code Generator) is a circuit simulator based on computer algebra system (REDUCE 3.0). Circuit specifications are given by commands which generate the Hamiltonian H and the dissipating function D of the circuit. Partial derivatives of H and D are computed symbolically by REDUCE so as to generate the equations of motion. CSCG is written in REDUCE and automatically generates FORTRAN code for numerical integration, either using Runge-Kutta or Gear's method. The partial derivatives needed in the latter method are also computed symbolically. In comparison with conventional table-driven simulators, the code generated by CSCG performs simulation much faster (similar to compiled versus interpreted code), and it is believed to be much easier to implement and to use. CSCG is now extensively used for simulations of Josephson junction circuitries.		Kia-Fock Loe;Noritaka Ohsawa;Eiichi Goto	1984		10.1007/3-540-16470-7_15	computational science;computer architecture;computer science;theoretical computer science;dual code;code generation	Arch	-11.770589318482887	34.859632113936094	180041
161d03430367a4d35629b48481e0497713a5f26e	introducing the semi-stencil algorithm	partial differential equation;code optimization;high performance computing;perforation;differential operators;finite difference;heterogeneous multi core;reverse time migration;memory access;cell b e;performance bounds;stencil computation	Finite Difference (FD) is a widely used method to solve Partial Differential Equations (PDE). PDEs are the core of many simulations in different scientific fields, e.g. geophysics, astrophysics, etc. The typical FD solver performs stencil computations for the entire 3D domain, thus solving the differential operator. This computation consists on accumulating the contribution of the neighbor points along the cartesian axis. It is performance-bound by two main problems: the memory access pattern and the inefficient re-utilization of the data. We propose a novel algorithm, named ”semi-stencil”, that tackle those two problems. Our first target architecture for testing is Cell/B.E., where the implementation reaches 12.4 GFlops (49% peak performance) per SPE, while the classical stencil computation only reaches 34%. Further, we successfully apply this code optimization to an industrial-strength application (Reverse-Time Migration). These results show that semi-stencil is useful stencil computation optimization.	algorithm;apache axis;cell (microprocessor);computation;finite difference;heterogeneous computing;locality of reference;mathematical optimization;memory access pattern;program optimization;regular expression;semiconductor industry;simulation;solver;stencil (numerical analysis);stencil buffer;super paper mario;working set	Raúl de la Cruz;Mauricio Araya-Polo;José María Cela	2009		10.1007/978-3-642-14390-8_52	differential operator;mathematical optimization;seismic migration;finite difference;supercomputer;parallel computing;stencil code;computer science;theoretical computer science;program optimization;stencil;distributed computing;five-point stencil;partial differential equation;algorithm	HPC	-5.674121662277354	39.09795461753824	180059
23c9abeb20cc552d40bbbdcc77c56f0ea5ae6451	accelerating computation of dna sequence alignment in distributed environment	sequence similarity;java programming;dynamic program;distributed environment;parallel computer;dna computing;computational biology;dna sequence	Sequence similarity and alignment are most important operations in computational biology. However, analyzing large sets of DNA sequence seems to be impractical on a regular PC. Using multiple threads with JavaParty mechanism, this project has successfully implemented in extending the capabilities of regular Java to a distributed environment for simulation of DNA computation. With the aid of JavaParty and the design of multiple threads, the results of this study demonstrated that the modified regular Java program could perform parallel computing without using RMI or socket communication. In this paper, an efficient method for modeling and comparing DNA sequences with dynamic programming and JavaParty was firstly proposed. Additionally, results of this method in distributed environment have been discussed.	computation;sequence alignment	Tao Guo;Guiyang Li;Russell J. Deaton	2008		10.1007/978-3-540-85930-7_30	computational science;dna sequencing;computer science;bioinformatics;theoretical computer science;dna computing;distributed computing environment	HPC	-9.361824352764318	37.989211074781245	180351
b79860aed2cbdca9c8de454ba1b4188adcfb5139	large-scale reservoir simulations on distributed-memory parallel computers		This paper presents our work on developing parallel reservoir simulators for modeling of fluid flows in porous media on distributed-memory parallel systems and studying the scalability of our reservoir simulators. These reservoir simulators are based on our in-house parallel platform, which provides grids, data, distributed-memory matrices and vectors, linear solvers, preconditioners, and well modeling. A standard black oil simulator, a two-phase oil-water simulator and simulators for extended models, such as polymer flooding and naturally fractured reservoirs, have been implemented. New preconditioners have been designed for the black oil and compositional models. Benchmarks show that the results from our parallel simulators match those from commercial simulators. Our parallel simulators are thousands of times faster than sequential simulators, and they have excellent scalability.	computer;distributed memory;parallel computing;simulation	Hui Liu;Kun Wang;Zhangxin Chen;Bo Yang;Ruijian He	2016			parallel computing;simulation;computer science;theoretical computer science	HPC	-6.306559623178551	36.866100580318644	181152
1d83997a1a9309de31f1704aad001ee178dd6b66	data reorganization in a dynamically reconfigurable environment	network servers file servers monitoring distributed databases network topology scheduling intelligent networks computer science data engineering database systems;file servers;dynamic reconfiguration;dynamic system;data engineering;dynamic system prototype;reallocation strategies;driftwood;network topology;distributed database system;network servers;fault tolerant computing;system recovery;monitoring;scheduling;database systems;distributed databases;nonblocking reorganization;system recovery fault tolerant computing parallel algorithms;dynamically reconfigurable distributed database;intelligent networks;computer science;transaction processing;parallel reorganization scheduler;system recovery time dynamically reconfigurable environment dynamically reconfigurable distributed database dynamic system prototype driftwood reallocation strategies nonblocking reorganization user transaction processing parallel reorganization scheduler;dynamically reconfigurable environment;system recovery time;user transaction processing;parallel algorithms	Poster Session A Précis Poster A.1 An Economical 40 MHz Universal Software Radio Using a Hybrid Approach Joseph Arrowood (Los Alamos National Laboratory) Poster A.2 Task-Level Energy Minimization for Reconfigurable Embedded Systems Hakan Aydin (University of Pittsburgh) Poster A.3 Implementation and Optimization of a Distributed Memory FFT Processor Robert Johnson (MathStar, Inc.) Poster A.4 A FPGA Implementation of an Adaptive Reconfigurable Image Encoder Sarin Mathen (ITTC) Poster A.5 SCALIP: Scalable IP for Systolic Applications Matthew Moe (Carnegie Mellon University) Poster A.6 Reconfigurable Video Processor Scott Morris (Raytheon Electronic Systems) Poster A.7 A Processor-In-Memory (PIM) Computing Architecture for Critical Navy Phased Array Radar Applications Stephen Shank (Lockheed Martin) Poster A.8 A Dynamically Reconfigurable Vision (DRV) System David Stack (Comptek Amherst Systems, Inc.) Poster A.9 A Hybrid FPGA/DSP/GPP Prototype Architecture for SAR and STAP Jack West (University of Oklahoma)	distributed memory;embedded system;encoder;energy minimization;fast fourier transform;field-programmable gate array;graph partition;prototype;reconfigurability;space-time adaptive processing	Xiaolin Du;Fred J. Maryanski	1988		10.1109/DCS.1988.12549	file server;intelligent network;parallel computing;real-time computing;information engineering;transaction processing;computer science;operating system;dynamical system;database;distributed computing;parallel algorithm;scheduling;distributed database;network topology	HPC	-7.979930293720852	33.79444146932094	181217
92829bbde8406d75b412c4373391fd2f9542f4b9	a distributed cellular automata simulation on cluster of pcs	modelizacion;parallelisme;algoritmo paralelo;parallel algorithm;performance test;rivers;hydrologie;distributed computing;algorithme parallele;modelisation;hidrologia;parallelism;paralelismo;rio;automate cellulaire;riviere;hydrology;calculo repartido;parallel implementation;cellular automata;modeling;calcul reparti;cellular automaton;automata celular	Inherent parallelism of Cellular Automata as well as large size of automata systems used for simulations makes their parallel implementation indispensable. The purpose of this paper is to present a parallel implementation of two sequential models introduced for modelling evolution of anastomosing river networks. Despite the both models exploit the Cellular Automata paradigm, the nontrivial application of this approach in the second model involves defining a mixed parallel-sequential algorithm. The detailed description of the two algorithms and the results of performance test are presented.		Pawel Topa	2002		10.1007/3-540-46043-8_79	stochastic cellular automaton;cellular automaton;systems modeling;continuous spatial automaton;computer science;theoretical computer science;distributed computing;parallel algorithm;mobile automaton;algorithm	Theory	-11.049636157535815	38.37254829154772	181387
ad0f444a9733f768391b763b916a87eace974b3e	scalable parallel computing at enea	parallel computer;intervento a convegno	"""A hardware and software environment with performance above 1 T eraaops (teracomputing) is presently required to face the leading computational challenges not only in fundamental sciences, but also in an increasing number of elds related to applied sciences and engineering. The technology options adopted for teracomputing are evaluated. In this perspective, a European line of supercomputers is described, which w as originated by the Italian Institute for Nuclear Physics and is now in use also in Germany and France: this line of massively parallel platforms is based on the use of CMOS VLSI custom chips, carefully designed to match the computing needs, so that only the silicon strictly necessary to the operations to be performed is used. 1 Teracomputing Computer simulation is becoming a powerful means of understanding the structure and behaviour of very complex systems (commonly called \grand chal-lenges""""): e.g., the \ab initio"""" solution of the fundamental equations of a system, to perform self-consistent \computer experiments"""" to be compared and eventually substituted to \physical experiments"""". Such a computational environment w as originally developed and exploited for speciic challenges of fundamental sciences, but is currently requested in an increasing number of elds related to applied sciences and engineering, as: climate and weather forecastingg air and water pollution managementt molecular design for new materials and new drugss biochemistry and bioengineeringg numerical wind tunnels for aerodynamics optimisation of cars and planess electromagnetic design for telecommunications and control systemss optimal design of engines (both for energy saving and pollution control)) etc. 1{3]. The \ab initio"""" solution of this kind of computational challenges typically requires limitless computing power: practically, with the present technology, t h e target is the availability of platforms oering a peak computing power above 1 Teraaops (i.e. 1000 billion oating point operations per second) and an almost perfect scalability."""	cmos;complex systems;computation;computer simulation;experiment;flops;mathematical optimization;numerical analysis;optimal design;parallel computing;scalability;supercomputer;very-large-scale integration	G. Bardotti;Silvio Migliori;Antonio Perozziello;Agostino Mathis;Paolo Novelli;M. A. Spano;Roberto Guadagni;A. M. Palumbo	1996		10.1007/3-540-61142-8_661	computational science;parallel computing;computer science;distributed computing	HPC	-6.62470475207282	35.897553725269454	181392
db6cf7263bf55b00177906d03b0b98e12cff0375	efficient parallel algorithm for statistical ion track simulations in crystalline materials	parallel computing;parallel algorithm;radiation effect;real time;29 25 t;molecular dynamics;molecular dynamic simulation;ion implantation;rare event;asynchronous communication;parallel computer;reed md;molecular dynamic;radiation range;host client algorithm;polling;cumulant;61 80 x	We present an efficient parallel algorithm for statistical Molecular Dynamics simulations of ion tracks in solids. The method is based on the Rare Event Enhanced Domain following Molecular Dynamics (REED-MD) algorithm, which has been successfully applied to studies of, e.g., ion implantation into crystalline semiconductor wafers. We discuss the strategies for parallelizing the method, and we settle on a host-client type polling scheme in which a multiple of asynchronous processors are continuously fed to the host, which, in turn, distributes the resulting feed-back information to the clients. This real-time feed-back consists of, e.g., cumulative damage information or statistics updates necessary for the cloning in the rare event algorithm. We finally demonstrate the algorithm for radiation effects in a nuclear oxide fuel, and we show the balanced parallel approach with high parallel efficiency in multiple processor configurations.	asynchronous circuit;automatic parallelization;central processing unit;extreme value theory;feedback;ion implantation;ionic;load balancing (computing);molecular dynamics;monte carlo method;parallel algorithm;parallel computing;real-time locating system;semiconductor;simulation;speedup	Byoungseon Jeon;Niels Grønbech-Jensen	2009	Computer Physics Communications	10.1016/j.cpc.2008.09.014	polling;molecular dynamics;parallel computing;real-time computing;computer science;theoretical computer science;asynchronous communication;ion implantation;parallel algorithm;cumulant	HPC	-4.829254950364887	33.29869551371682	181704
2cdec20fde81b6767e5b8a16ee7d1d35413ec65a	parallel & distributed simulation with deus	java api;peer to peer network;pdes tools;computer model;large scale systems application program interfaces digital simulation java;peer to peer networks pdes tools complex systems;deus;computational modeling;complex system;application program interfaces;peer to peer network parallel simulation distributed simulation deus complex systems analysis java api;complex systems;distributed simulation;peer to peer networks;complex systems analysis;parallel simulation;digital simulation;large scale systems;java	This paper illustrates how parallel & distributed simulation capabilities have been introduced in DEUS, our tool for the analysis of complex systems. Its essential Java API provides basic interfaces and classes for modeling nodes, events and processes that characterize the structure and dynamics of any complex system. By supporting parallel & distributed simulations across multiple computing nodes, DEUS enables the analysis of large-scale complex systems. Its experimental validation has been obtained by means of the distributed simulation of a significant complex system, i.e. a large peer-to-peer network.	application programming interface;complex system;complex systems;general-purpose modeling;java class library;list of java apis;load balancing (computing);open-source software;optimistic concurrency control;parsing;peer-to-peer;simulation	Michele Amoretti;Marco Picone;Stefano Bonelli;Francesco Zanichelli	2011	2011 International Conference on High Performance Computing & Simulation	10.1109/HPCSim.2011.5999880	computational science;complex systems;parallel computing;computer science;theoretical computer science;operating system;distributed computing;programming language;java;computational model	HPC	-9.991658699123324	37.96731244495296	182937
2029cba30e5a9fff0581a22ad04627b5ffe27cf6	interoperability parallel programs approach to simulate 3d frontal polymerization processes	spectral methods;communication scheduling;adi methods;communication schedule;heterogeneous computing;multigrid method;reaction diffusion system;navier stokes;domain decomposition methods;data representation;data distribution;finite difference method;large scale;parallelism;program and language inter operability;domain decomposition method;spectral method;scientific computing;finite differences methods;multigrid methods;physical model;parallel programs;data structure;combustion;navier stokes equation	The main object of this paper is to demonstrate the feasibility of coupling parallel codes in the framework of large scale scientific computing. The second aim is to provide a numerical tool to solve 3D frontal polymerization in liquid problems where the multiple physical scales require intensive computation on MIMD architecture. We extend our 2D modelization   [14]   of such phenomena by coupling a 3D reaction diffusion system well known in solid combustion   [22]   with the 3D Navier–Stokes equations written in Boussinesq approximation. We develop two separate parallel codes for each physical model, each code running on its own topological network of processors with its own data structures. The non-blocking communications, manage the interaction terms of the two physical models on each code, are performed through a Portable Inter Program Communication Library ( PIPCL ). This communication library computes array-based communication schedules creating a one-to-one implicit mapping between each data representation. The data distribution of each code is hidden to the others, allowing an easy parallel program inter-operability on heterogeneous computers.		Guy Edjlali;Marc Garbey;Damien Tromeur-Dervout	1999	Parallel Computing	10.1016/S0167-8191(99)00042-3	computational science;parallel computing;data structure;computer science;theoretical computer science;algorithm;spectral method	HPC	-8.328744812506844	36.99018927455436	182939
2fa2c20bf28fc123f8f5158d659538d9fd58bca4	a scalable three-dimensional domain decomposition mapping technique using mpi	domain decomposition;three dimensional		domain decomposition methods;message passing interface	Saleh H. Al-Sharaeh;B. Earl Wells	2003			parallel computing;computer science;scalability;domain decomposition methods	EDA	-6.521340790216475	38.02994880144747	182956
12be2fcc6e8a5837a386e8e9783bd6da91f81b0b	gpu-based parallel researches on rrtm module of grapes numerical prediction system	parallel computing;rrtm;gpu;cuda;grapes system	GRAPES (Global and Regional Assimilation and Prediction System) is a new generation of numerical weather prediction (NWP) system of China. As the system processes amount of data and requires high real-time,so it is always a hot research field of parallel computing.This is the first time that we use GPU (Graphics Processor Unit) general-purpose computing and CUDA technology on RRTM (Rapid Radiative transfer model) long-wave radiation module of GRAPES_Meso model for parallel processing, we rewrited the RRTM module with CUDA Fortran according to the characteristics of the GPU architecture.Enhancing the computational efficiency with optimization strategys such as the code tuning, asynchronous memory transfer,compiler option and etc. The optimization results indicate that a 14.3×speedup is obtained. Experiments are carried out on the multi-GPU platform,and can be easily extended to GPU clusters, the results show that the parallel computing algorithm is correct , stable and efficient.	algorithm;cuda;compiler;data assimilation;fortran;gpu cluster;graphics processing unit;lookup table;mathematical optimization;numerical analysis;numerical weather prediction;parallel computing;processor register;program optimization;real-time locating system;speedup;texture memory	Fang Zheng;Xianbin Xu;Dongdong Xiang;Zhuowei Wang;Ming Xu	2013	JCP	10.4304/jcp.8.3.550-558	computational science;parallel computing;computer science;theoretical computer science	HPC	-6.255080070362556	35.714706580437536	182987
0d55c2567e9a4c77155624a42cddbd7b9043af78	high resolution aerospace applications using the nasa columbia supercomputer	nasa columbia;high resolution;hybrid programming;reynolds average navier stokes;unstructured;computation fluid dynamics;computational fluid dynamics;openmp;parametric analysis;scalability;sgi altix;high performance	This paper focuses on the parallel performance of two high-performance aerodynamic simulation packages on the newly installed NASA Columbia supercomputer. These packages include both a high-fidelity, unstructured, Reynolds-averaged Navier-Stokes solver, and a fully-automated inviscid flow package for cut-cell Cartesian grids. The complementary combination of these two simulation codes enables high-fidelity characterization of aerospace vehicle design performance over the entire flight envelope through extensive parametric analysis and detailed simulation of critical regions of the flight envelope. Both packages are industrial-level codes designed for complex geometry and incorporate customized multigrid solution algorithms. The performance of these codes on Columbia is examined using both MPI and OpenMP and using both the NUMAlink and InfiniBand interconnect fabrics. Numerical results demonstrate good scalability on up to 2016 cpus using the NUMAlink4 interconnect, with measured computational rates in the vicinity of 3 TFLOP/s, while InfiniBand showed some performance degradation at high CPU counts, particularly with multigrid. Nonetheless, the results are encouraging enough to indicate that larger test cases using combined MPI/OpenMP communication should scale well on even more processors.	algorithm;central processing unit;code;computation;elegant degradation;flops;infiniband;message passing interface;multigrid method;numerical analysis;numerical linear algebra;openmp;reynolds-averaged navier–stokes equations;scalability;simulation;solver;supercomputer;test case	Dimitri J. Mavriplis;Michael J. Aftosmis;Marsha J. Berger	2007	IJHPCA	10.1177/1094342006074872	computational science;parallel computing;scalability;simulation;image resolution;computational fluid dynamics;computer science;operating system;parametric statistics	HPC	-5.235060990233798	38.997418492817594	183864
32521f46a28a1ec6f70c452a1c13caa381fabaab	toward gpu-accelerated traffic simulation and its real-time challenge	computational physics;paper;nvidia geforce gtx 560 ti;cuda;nvidia;computer science	Traffic simulation is a growing domain of computational physics. Many life and industrial applications would benefit from traffic simulation to establish reliable transportation systems. A core challenge of this science research, however , is its unbounded scale of computation. This paper explores an advantage of using the graphics processing unit (GPU) for this computational challenge. We study two schemes of maximizing GPU performance in the context of tra ffic simulation, and provide some basic experiments. The experimental results show that our GPU implementation improves simulation speed by five times over the traditional CPU implementation. We also discuss that additional orders-ofmagnitude improvements could be achieved by overcoming the current hardware limitation of the GPU.	central processing unit;computation;computational physics;computer graphics;decade (log scale);experiment;graphics processing unit;java caps;model of computation;real-time clock;real-time computing;real-time transcription;simulation;software deployment	Manato Hirabayashi;Shinpei Kato;Masato Edahiro;Yuki Sugiyama	2012			computational science;parallel computing;simulation;computer science	HPC	-6.425176765712414	36.11993926954491	184137
d833cbfa7ecc1d54041980c0bc29c609f6e9a2cd	acceleration of the discrete element method on a reconfigurable co-processor		Granular materials are important for many different disciplines, e.g. geomechanics, civil engineering and chemical engineering. Many approaches have been used to model their behaviour, but one of the best and most important is the Discrete Element Method (DEM). The DEM was first developed during the 70’s, but its widespread use has been hampered by its extremely computationally demanding nature. The DEM can be run on a parallel computer by farming out different sub-domains onto different processors. However, particles transiting from one sub-domain to another create communication and synchronisation overheads which limit the speed-up achieved by parallel processing. Also, if some cells become much more heavily populated than others, then there will be inefficiencies due to load imbalance between the processors. As a result of these effects, the speed-up achieved by running the DEM on parallel processor computers is far less than linear. This thesis describes work on the acceleration of the DEM using reconfigurable computing. A custom hardware architecture for the DEM has been designed and implemented on a Field Programmable Gate Array (FPGA) mounted on a reconfigurable computing card. The design exploits the low level parallelism of the DEM by using long, wide computational pipelines that compute many arithmetic operations concurrently. It also exploits the high level parallelism by overlapping the main computational tasks using domain decomposition techniques. Speed-ups of a factor of at least 30 per FPGA have been achieved for simulations involving 25,000 to 200,000 particles. A multi-FPGA system has been implemented that allows the full overlap of computation with communication, so that an almost linear speed-up can be achieved as the number of FPGAs is increased. The effect of the short wordlength arithmetic used in the FPGA has been investigated, and the accuracy of the simulations has been found to be acceptable. To my brother Norbert, Thank you very much for everything	central processing unit;computation;computer;coprocessor;discrete element method;domain decomposition methods;field-programmable gate array;high-level programming language;parallel computing;pipeline (computing);pipeline (software);population;reconfigurable computing;simulation	Benjamin Carrión Schäfer	2003				HPC	-5.311646085975987	36.290912644591636	185179
327e3653bb3d610bf1be786843fbfc450813d50a	enabling very-large scale earthquake simulations on parallel machines	parallel computing;southern california earthquake center;data management;scaling up;large scale;visualization;seismic waves;parallel computer;san andreas fault;parallel machines;scalability;earthquake simulation;terashake;data archive	The Southern California Earthquake Center initiated a major largescale earthquake simulation called TeraShake. The simulations propagated seismic waves across a domain of 600x300x80 km at 200 meter resolution, some of the largest and most detailed earthquake simulations of the southern San Andreas fault. The output from a single simulation may be as large as 47 terabytes of data and 400,000 files. The execution of these large simulations requires high levels of expertise and resource coordination. We describe how we performed single-processor optimization of the application, optimization of the I/O handling, and the optimization of execution initialization. We also look at the challenges presented by run-time data archive management and visualization. The improvements made to the application as it was recently scaled up to 40k BlueGene processors have created a community code that can be used by the wider SCEC community to perform large scale earthquake	archive;blue gene;central processing unit;computer simulation;input/output;mathematical optimization;research data archiving;run time (program lifecycle phase);terabyte	Yifeng Cui;Reagan Moore;Kim B. Olsen;Amit Chourasia;Philip Maechling;Bernard Minster;Steven M. Day;Yuanfang Hu;Jing Zhu;Amitava Majumdar;Thomas H. Jordan	2007		10.1007/978-3-540-72584-8_7	seismic wave;earthquake simulation;scalability;simulation;visualization;data management;computer science;data science	HPC	-7.389029371106222	36.19339899624471	185352
46ea6010e4fa0e603760338eda91c1825ecdd821	tree-based parallel algorithm design	algoritmo paralelo;program graph;parallel algorithm;code optimization;time complexity;funcion logica;program design;code generation;conception programme;ingenieria logiciel;software engineering;parallel random access machine;algebre;logical function;fonction logique;algorithme parallele;program optimization;complexite temps;algebra;graphe programme;numerical computation;genie logiciel;optimisation programme;complejidad tiempo;grafo programa;concepcion programa;optimizacion programa	In this paper a systematic method for the design of efficient parallel algorithms for the dynamic evaluation of computation trees and/or expressions is presented. This method involves the use of uniform closure properties of certain classes of unary functions. Using this method, optimal parallel algorithms are given for many computation tree problems which are important in parallel algebraic and numerical computation, and parallel code generation on exclusive read and exclusive write parallel random access machines. Our algorithmic result is complemented by a P-complete tree problem.	algorithm design;code generation (compiler);computation tree;exclusive or;linear algebra;numerical analysis;p-complete;parallel algorithm;parallel computing;random access;unary operation	Gary L. Miller;Shang-Hua Teng	1997	Algorithmica	10.1007/PL00009179	parallel computing;computer science;theoretical computer science;program optimization;analysis of parallel algorithms;programming language;algorithm;bulk synchronous parallel;cost efficiency	HPC	-11.425926941597307	33.27104566597091	185384
543203028b5655c4cebcbf76d02efbc008d3e203	dpf: a data parallel fortran benchmark suite	distributed memory;data parallel;software libraries;perforation;computer and information science;software performance evaluation;software libraries biological system modeling parallel architectures application software kernel biology computing physics computing fluid dynamics computational modeling chemistry;software performance evaluation parallel languages fortran program testing;memory access;evaluation metric;program testing;high performance fortran;fluid dynamics;fortran;data och informationsvetenskap;parallel languages;communication pattern;focal memory access data parallel fortran benchmark suite dpf data parallel fortran codes data parallel compilers parallel architecture library versions collective communication functions scientific software library functions application kernels communication patterns fluid dynamic simulations fundamental physics molecular studies chemistry biology high performance fortran flop rates flop count memory usage;language model;research paper or report	We present the Data Parallel Fortran (DPF) benchmark suite, a set of data parallel Fortran codes for evaluating data parallel compilers appropriate for any target parallel architecture, with shared or distributed memory. The codes are provided in basic, optimized and several library versions. The functionalityof thebenchmarks cover collectivecommunication functions, scientific software library functions, and application kernels that reflect the computational structure and communication patterns in fluid dynamic simulations, fundamental physics and molecular studies in chemistry or biology. The DPF benchmark suite assumes the language model of High Performance Fortran, and provides performance evaluation metrics of busy and elapsed times and FLOP rates, FLOP count, memory usage, communication patterns, local memory access, and arithmetic efficiency as well as operation and communication counts per iteration. An instance of the benchmark suite was fully implemented in CM–Fortran and tested on the CM–5.	benchmark (computing);code;compiler;data parallelism;digital photo frame;distributed memory;flip-flop (electronics);high performance fortran;iteration;language model;library (computing);parallel computing;performance evaluation;simulation	Y. Charlie Hu;S. Lennart Johnsson;Dimitris Kehagias;Nadia Shalaby	1997		10.1109/IPPS.1997.580896	computer architecture;parallel computing;computer science;theoretical computer science	HPC	-6.191198334306619	39.309794259882864	186125
a03fa8cf29e08ff3c9684ee4ea5685f7d5b971af	maintaining acyclicity of concurrent graphs	computer science	In this paper, we consider the problem of preserving acyclicity in a directed graph (for shared memory architecture) that is concurrently being updated by threads adding/deleting vertices and edges. To the best of our knowledge, no previous paper has presented a concurrent graph data structure. We implement the concurrent directed graph data-structure as a concurrent adjacency list representation. We extend the lazy list implementation of concurrent linked lists for maintaining concurrent adjacency lists. There exists a number of graph applications which require the acyclic invariant in a directed graph. One such example is Serialization Graph Testing Algorithm used in databases and transactional memory. We present two concurrent algorithms for maintaining acyclicity in a concurrent graph: (i) Based on obstruction-free snapshots (ii) Using wait-free reachability. We compare the performance of these algorithms against the coarse-grained locking strategy, commonly used technique for allowing concurrent updates. We present the speedup obtained by these algorithms over sequential execution. As a future direction, we plan to extend this data structure for other progress conditions.	adjacency list;concurrency (computer science);concurrent data structure;correctness (computer science);cycle detection;data structure;database;directed acyclic graph;directed graph;graph (abstract data type);lazy evaluation;lifting scheme;linearizability;linked list;lock (computer science);non-blocking algorithm;reachability;robertson–seymour theorem;serialization;shared memory;snapshot (computer storage);speedup;transactional memory;trusted timestamping	Sathya Peri;Muktikanta Sa;Nandini Singhal	2016	CoRR		implicit graph;transpose graph;adjacency list;parallel computing;wait-for graph;feedback arc set;directed graph;graph bandwidth;null graph;graph property;computer science;clique-width;theoretical computer science;comparability graph;voltage graph;distributed computing;graph;moral graph;complement graph;directed acyclic graph;algorithm	PL	-10.205878080552598	32.569751606005674	186253
97ec90320709461d0266c46f60ac2adb266f75f9	parallel afmpb solver with automatic surface meshing for calculation of molecular solvation free energy	boundary integral equation;computer and information science;solvation free energy;cilk plus;parallelization;fast multipole methods;automatic surface meshing;poisson boltzmann equation	We present PAFMPB, an updated and parallel version of the AFMPB software package for fast calculation of molecular solvation-free energy. The new version has the following new features: (1) The adaptive fast multipole method and the boundary element methods are parallelized; (2) A tool is embedded for automatic molecular VDW/SAS surface mesh generation, leaving the requirement for a mesh file at input optional; (3) The package provides fast calculation of the total solvation-free energy, including the PB electrostatic and nonpolar interaction contributions. PAFMPB is implemented in C and Fortran programming languages, with the Cilk Plus extension to harness the computing power of both multicore and vector processing. Computational experiments demonstrate the successful application of PAFMPB to the calculation of the PB potential on a dengue virus systemwithmore than onemillion atoms and amesh with approximately 20 million triangles.	boundary element method;cilk plus;computation;condition number;embedded system;experiment;fast fourier transform;fast multipole method;fortran;implicit solvation;mesh generation;multi-core processor;parallel computing;poisson–boltzmann equation;programming language;sas;scheduling (computing);solver;vector processor;whole earth 'lectronic link;workstation	Bo Zhang;Bo Peng;Jingfang Huang;Nikos Pitsianis;Xiaobai Sun;Benzhuo Lu	2015	Computer Physics Communications	10.1016/j.cpc.2014.12.022	computational science;parallel computing;computer science;theoretical computer science;physics;poisson–boltzmann equation	HPC	-5.294093363487353	37.5355542253114	186382
7b248325dae4c35a35fdb1478bdd23b71c9c87e6	gpu-accelerated vision modeling with the hpe cognitive computing toolkit			cognitive computing;graphics processing unit	Ben Chandler	2017		10.2352/ISSN.2470-1173.2017.14.HVEI-136	computational science;cognitive computing;computer science	HCI	-7.619310377656699	37.15295455641424	188595
74153fe5a120aab7fdeebaf616ff7c0cbf909ab0	parallel imperialist competitive algorithms		Correspondence Amin Majd, Åbo Akademi University, 20500 Turku, Finland. Email: amin.majd@abo.fi Summary The importance of optimization and NP-problem solving cannot be overemphasized. The usefulness and popularity of evolutionary computing methods are also well established. There are various types of evolutionary methods; they are mostly sequential but some of them have parallel implementations as well. We propose a multi-population method to parallelize the Imperialist Competitive Algorithm. The algorithm has been implemented with the Message Passing Interface on 2 computer platforms, and we have tested our method based on shared memory and message passing architectural models. An outstanding performance is obtained, demonstrating that the proposed method is very efficient concerning both speed and accuracy. In addition, compared with a set of existing well-known parallel algorithms, our approach obtains more accurate results within a shorter time period.	email;evolutionary algorithm;evolutionary computation;imperialist competitive algorithm;mathematical optimization;message passing interface;parallel algorithm;problem solving;shared memory	Amin Majd;Golnaz Sahebi;Masoud Daneshtalab;Juha Plosila;Shahriar Lotfi;Hannu Tenhunen	2018	Concurrency and Computation: Practice and Experience	10.1002/cpe.4393	distributed computing;computer science	ML	-9.632470739600754	39.228769556056754	190014
8d758352fb35feccbf71ca30bcf97ec9056b1cff	implementation of an air pollution transport model on parallel hardware	air pollution	Abstract The aim of this paper is to describe the basic modules of a simulation environment for air pollution analysis over conurbations and to present a strategy to implement the complex numerical models on a parallel computer. Therefore a new programming interface based on a large subset of PVM [1] was developed. The simulation system supports efficiently the forecasting of smog situations, the operational management, and the urban planning in reasonable simulation time. Results of the application in the area of Berlin and run-time measurements on the MANNA computer [2] are discussed.		Matthias Schmidt;R. Hänisch	1994			environmental engineering	ML	-7.005074974090908	34.964994509026	190153
ca8354ad15357a04a83cf60a7fa15bef715dd925	parallel sequence matching with taco's distributed object groups – a case study from molecular biology	data parallel;molecular sequence matching;template libraries;higher order;distributed objects;standard template library;molecular biology;data parallel programming;distributed object groups;workstation cluster	TACO is a template library that implements higher-order parallel operations on distributed object sets by means of reusable topology classes and C++ function templates. In this paper we discuss an experimental application that exploits TACO's distributed object groups and collective operations for computing the similarity between groups of molecular sequences, a computationally intensive core problem in molecular biology research. In particular we show how TACO's distributed collections can be conveniently combined with well known concepts found in the C++ standard template library (STL) to solve matching and sorting problems effectively on distributed hardware platforms. The resulting implementation is concise and gives excellent parallel performance on PC- and workstation clusters.	algorithm;c++;computation;data structure;distributed object;dynamic data;dynamization;high- and low-level;java remote method invocation;library (computing);message passing interface;multicast;parallel text;pattern matching;performance tuning;programmer;programming language;reachability;run time (program lifecycle phase);stl (file format);sorting;standard template library;subroutine;workstation;arts	Jörg Nolte;Paul Horton	2001	Cluster Computing	10.1023/A:1011468427597	parallel computing;standard template library;higher-order logic;computer science;bioinformatics;theoretical computer science;operating system;distributed computing;distributed object;programming language	HPC	-9.493317602047313	37.967145209271195	192536
321d8b8318cba6cb29ac5b607e8204b9740d0507	an object-oriented design for two-dimensional vortex particle methods	fluido incompresible;metodo sin malla;dimensionnement;software testing;methode particulaire;vortices;object oriented design;two dimensions;tourbillon;vortex flow;fast multipole method;lenguaje script;methode sans maille;dimensioning;abstraction;vortex method;vortex methods;metodo particula;viscous fluid;program verification;meshless method;abstraccion;fluide incompressible;incompressible fluid;particle method;algorithm;particle methods;ecoulement tourbillonnaire;object oriented;object orientation;oriente objet;algorithms;design;verification programme;dimensionamiento;orientado objeto;article;scripting language;langage script	Vortex methods offer a grid-free alternative to simulating incompressible, viscous, fluid flows. They require the use of fairly sophisticated algorithms and can be complicated to implement for general flows. This article describes an object-oriented design used to implement a vortex particle based flow solver in two dimensions. We provide an overview of the various abstractions that arose as a result of this design. Several of the algorithms have common components that may be abstracted and reused. We demonstrate how the design allowed us to derive the traditional benefits of OOD. In addition, we show how the design directly suggested elegant generalizations of existing algorithms. Finally, we show the benefits of using software testing techniques and building a powerful scripting layer for the library.	algorithm;simulation;software testing;solver;vortex	Prabhu Ramachandran;M. Ramakrishna	2009	ACM Trans. Math. Softw.	10.1145/1555386.1555387	design;simulation;fast multipole method;mathematics;scripting language;abstraction;software testing;programming language;dimensioning;algorithm;tourbillon	Graphics	-9.972580929892867	35.30436658053894	193071
41327c02c397d9088f277b5b39350e9017f04f5d	parallel and distributed implementation of large industrial applications	resource manager;computation fluid dynamics;resource management;object oriented programming;software engineering;object oriented;lessons learned;network of workstation;high performance computer;software package;scientific computing;industrial application;cfd;fortran;parallel processing;parallel scientific computing	Parallelization of high performance computing applicatio ns has been a field of active research for quite some time now. Most projects that have paral lelized industrial software packages have focused on the specific application and did not attempt to document and generalize their lessons learned. We report on results of a p roject that has parallelized a state of the art industrial computational fluid dynamics (CF D) packages and that explicitly aimed at establishing software engineering guidelines for future similar projects. Thanks to the consequent application of the software engineering gui delines defined for the project, the parallel CFD code has proven excellent efficiency and sca lability on a large number of parallel hardware platforms. The project also addressed software engineering issues suc h a object orientation and resource management. The CFD package has been redesigned as an object oriented program and implemented in C++ and Java. The object oriented CFD prog ram has shown reasonable efficiency in preliminary benchmark tests. We expect that fu rther optimizations to the OO code and advances in compiler technology will make the perfo rmance gap (relative to the FORTRAN version) almost disappear in the near future. A resource manager has been developed that allows productio n runs of parallel scientific computing software to execute in batch mode on networks of wo rkstations by dynamically allocating resources to parallel batch jobs that currently are not claimed by interactive users. The resource manager has been successfully tested with the p arallel CFD code as workload.	batch processing;benchmark (computing);c++;compiler;computation;computational fluid dynamics;computational science;computer programming;execution unit;fortran;graphical user interface;java;online and offline;parallel computing;random-access memory;software engineering;supercomputer;world wide web	Peter Luksch	2000	Future Generation Comp. Syst.	10.1016/S0167-739X(99)00077-1	computational science;computer architecture;parallel computing;computer science;resource management;operating system;database;distributed computing;programming language;object-oriented programming	SE	-8.968129591329705	37.64623335359251	193151
592f6f30409a46543cdf38319d55d17bd6afe0c2	speedup using flowpaths for a finite difference solution of a 3d parabolic pde	partial differential equation;mathematics computing;programming language;real time;convergence of numerical methods;high level programming language;partial differential equations convergence of numerical methods field programmable gate arrays finite difference methods java mathematics computing parabolic equations;convergent numerical algorithm;hardware circuit;finite difference;finite difference solution;fpga;null;contaminant transport process;field programmable gate arrays finite difference solution 3d parabolic pde partial differential equations convergent numerical algorithm computer simulation weather prediction contaminant transport process high level programming language java hardware circuit fpga;numerical calculation;large scale;partial differential equations;contaminant transport;numerical algorithm;finite difference methods hardware personal communication networks circuits partial differential equations computer simulation application software weather forecasting computational modeling predictive models;field programmable gate arrays;process simulation;weather prediction;computer simulation;parabolic equations;3d parabolic pde;finite difference methods;java	Partial differential equations (PDEs) are used to model physical phenomena and then appropriate convergent numerical algorithms are employed to solve them and create computer simulations. In many important applications, such as weather prediction and contaminant transport processes, simulation outputs are required in real time or even faster, yet the spatial component of the problem is very large, thereby increasing the computational time. In addition, often times numerical scientists work in groups to create a large-scale code, but they work individually on PCs to test components of the code, so that speedup of the computational algorithms on PCs is desirable. There is a benefit to creating and using custom hardware to perform the numerical calculations faster than commodity hardware. This work uses a high-level programming language (Java) to behaviorally describe, and then implement, a finite difference solution of a parabolic PDE as a custom hardware circuit targeted to an FPGA. The results show that the circuits can perform the calculations 1 to 2 orders of magnitude faster than commodity hardware.	algorithm;commodity computing;computation;computer simulation;electronic circuit;field-programmable gate array;finite difference;high- and low-level;high-level programming language;java;numerical analysis;numerical partial differential equations;parabolic antenna;speedup;time complexity	Darrin M. Hanna;Anna Maria Spagnuolo;Michael DuChene	2007	2007 IEEE International Parallel and Distributed Processing Symposium	10.1109/IPDPS.2007.370503	computer simulation;mathematical optimization;parallel computing;process simulation;computer science;theoretical computer science;programming language;partial differential equation;algorithm;field-programmable gate array	Arch	-5.759284617315025	35.960816712077786	193491
142aada1135231c1739304ffaa45a8e211d87d2a	parallel time-space processing model based fast n-body simulation on gpus	parallel computing;time space model;gpu;n body	The N-body problems simulate the evolution of a system of N bodies where the force exerted on each body arises due to its interaction with all the other bodies in the system. In this paper, we present a novel parallel implementation of N-body gravitational simulation on GPUs. We analyze the current implementation of GPU, and give our new method on implementing N-body algorithm on HD Radeon 5870 GPU of AMD. The experimental results show that this method achieves an acceleration of 413 compared with CPU, and an acceleration up to 5.5 times compared with other GPU based methods.	algorithm;central processing unit;graphics processing unit;radeon hd 5000 series;simulation	Wei Wang;Hanli Wang;Dong Guo;Haoyang Wei;Guosun Zeng	2013		10.1145/2442992.2442999	computational science;parallel computing;computer science;computer graphics (images)	HPC	-5.570374543647936	37.202645013364936	193539
25fd00d6b97675f75810472111d675cd7932c112	a method for accelerating flow-level network simulation with low-pass filtering of fluid models	accelerating simulation;flow level simulator;low pass filter;fluid flow model;large scale high speed network		low-pass filter;simulation	Yusuke Sakumoto;Hiroyuki Ohsaki;Makoto Imase	2013	JIP	10.2197/ipsjjip.21.481	parallel computing;simulation;low-pass filter;computer hardware;computer science;statistics	Metrics	-6.993353172140717	35.80313925067596	193783
b38354d4bbdffc038c3e89240d18e95888b5807d	scalable parallel computational geometry (summary)	scalable parallel computational geometry	Without Abstract	computation;computational geometry	Frank Dehne	1994		10.1007/3-540-58078-6_11	computational topology	NLP	-9.233546246389485	33.72947515049304	194760
532d7895a3f030718a60ccff9a3e2386a0cb8abc	brownian dynamics simulations on cpu and gpu with bd_box	paper;molecular dynamics;brownian dynamics;cuda;package;chemistry;nvidia;openmp;mpi;scalability;hydrodynamic interactions	There has been growing interest in simulating biological processes under in vivo conditions due to recent advances in experimental techniques dedicated to study single particle behavior in crowded environments. We have developed a software package, BD_BOX, for multiscale Brownian dynamics simulations. BD_BOX can simulate either single molecules or multicomponent systems of diverse, interacting molecular species using flexible, coarse-grained bead models. BD_BOX is written in C and employs modern computer architectures and technologies; these include MPI for distributed-memory architectures, OpenMP for shared-memory platforms, NVIDIA CUDA framework for GPGPU, and SSE vectorization for CPU.	algorithm;algorithmic efficiency;architecture as topic;automatic vectorization;biological system;blu-ray;box;brownian motion;cpu (central processing unit of computer system);cuda;central processing unit;chebyshev polynomials;cholesky decomposition;computer architecture;design of experiments;digital object identifier;distributed memory;ewald summation;extracellular matrix;forty nine;gnu;general-purpose computing on graphics processing units;graphics processing unit;hydrodynamic quantum analogs;hydrodynamics;interaction;journal of computational chemistry;libraries;library (computing);many-body problem;message passing interface;numerous;openmp;parallel computing;polynomial;scalability;shared memory;simulation;solutions;source code;streaming simd extensions;summation (document);video-in video-out;macromolecule	Maciej Dlugosz;Pawel Zielinski;Joanna Trylska	2011	Journal of computational chemistry	10.1002/jcc.21847	computational science;molecular dynamics;scalability;brownian dynamics;chemistry;message passing interface;theoretical computer science;package;quantum mechanics	HPC	-5.451041216927602	37.5052043593914	194782
48b2f5af0fb5f12fd4fcfd4f847d0031a91cb1f6	turbulence in cosmology: analysis of simulated and observational data using high performance computing			supercomputer;turbulence	Renata Sampaio da Rocha Ruiz	2011				HPC	-7.000082815191922	36.94058955351356	194878
582cd6ada6adc74d8f11a69b477bad506dbac228	architecture and performance of devito, a system for automated stencil computation		Stencil computations are a key part of many high-performance computing applications, such as image processing, convolutional neural networks, and finite-difference solvers for partial differential equations. Devito is a framework capable of generating highly-optimized code given symbolic equations expressed in Python, specialized in, but not limited to, affine (stencil) codes. The lowering process – from mathematical equations down to C++ code – is performed by the Devito compiler through a series of intermediate representations. Several performance optimizations are introduced, including advanced common sub-expressions elimination, tiling and parallelization. Some of these are obtained through well-established stencil optimizers, integrated in the back-end of the Devito compiler. The architecture of the Devito compiler, as well as the performance optimizations that are applied when generating code, are presented. The effectiveness of such performance optimizations is demonstrated using operators drawn from seismic imaging applications.	approximation;artificial neural network;c++;compiler;component-based software engineering;convolutional neural network;digital subscriber line;experiment;finite difference;image processing;intermediate representation;interpolation;linear algebra;numpy;parallel computing;python;stencil (numerical analysis);stencil buffer;stencil code;supercomputer;sympy;symbolic computation;tiling window manager	Fabio Luporini;Michael Lange;Mathias Louboutin;Navjot Kukreja;Jan Hückelheim;Charles Yount;Philipp A. Witte;Paul H. J. Kelly;Gerard Gorman;Felix J. Herrmann	2018	CoRR		compiler;architecture;convolutional neural network;theoretical computer science;operator (computer programming);stencil;computer science;stencil code;python (programming language);computation	HPC	-11.32667057174977	35.648800333767305	194969
d8fa4435986516ca7122f9cbf8624a7ea5e080b9	parallel systems: performance modeling and numerical algorithms-invited talk	parallel systems;numerical algorithm;performance model		algorithm	Daniel A. Reed	1987			parallel computing;theoretical computer science;distributed computing	HPC	-7.620685320420458	38.57727335184525	195686
9937f10bf506a274808d114f2f58471ee0d2cf61	shared-memory implementation of an irregular particle simulation method	shared memory;simulation methods;parallel implementation	 . We investigate a parallel implementation of an irregular particlesimulation algorithm. We concentrate on the issue which programmingand system support is needed to yield an efficient implementationfor a large number of processors. As execution platform we use the SBPRAM,a shared memory machine with up to 4096 processors.1 IntroductionMost investigations of irregular applications concentrate on implementations onshared-memory machines with a small or medium number of processors... 	shared memory;simulation	Thomas Rauber;Gudula Rünger;Carsten Scholtes	1996		10.1007/3-540-61626-8_108	shared memory;computer architecture;parallel computing;computer science;operating system;distributed computing	HPC	-6.2137377722662	37.52140934383816	195949
7ce78b22dcdf7d145058113fb181a5e07362f123	euro-par 2011: parallel processing workshops		This work concerns a general technique to enrich parallel version of stochastic simulators for biological systems with tools for online statistical analysis of the results. In particular, within the FastFlow parallel programming framework, we describe the methodology and the implementation of a parallel Monte Carlo simulation infrastructure extended with user-defined on-line data filtering and mining functions. The simulator and the on-line analysis were validated on large multi-core platforms and representative proof-of-concept biological systems.	biological system;euro-vo;monte carlo method;multi-core processor;online and offline;parallel computing;simulation	Josef Kittler;Alfred Kobsa;Moni Naor	2011		10.1007/978-3-642-29740-3		HPC	-8.939175327442081	38.48327247737031	196346
099f75d4ce86c97b048bcbfd06b3f1b8788a4df3	gpu based acceleration of telegraph equation	random access memory;paper;parallel algorithm;numerical solution;acceleration telegraphy taylor series wire graphics computational modeling random access memory differential equations arithmetic biological system modeling;biological system modeling;differential equation;graphics processor unit;gpu;telegraphy;acceleration;wire;cuda;telegraph equation;computational modeling;telegraph equation taylor series gpu accelleration parallel algorithm;nvidia;accelleration;arithmetic;algorithms;differential equations;computer science;memory bandwidth;graphics;taylor series	"""In a matter of just a few years, the programmable graphics processor unit has evolved into an absolute computing workhorse. With multiple cores driven by very high memory bandwidth, today's GPUs offer incredible resources for both graphics and non-graphics processing. An original mathematical method """"Modern Taylor Series Method'' (MTSM) which uses the Taylor series method for solving differential equations in a non-traditional way has been developed and implemented in TKSL software. Even though this method is not much preferred in the literature, experimental calculations have shown and theoretical analyses have verified that the accuracy and stability of the Taylor series method exceeds the currently used algorithms for numerically solving differential equations. It is the aim of the paper to illustrate GPU and MTSM for numerical solutions of a telegraph line."""	algorithm;computer graphics;graphics processing unit;high memory;memory bandwidth;numerical analysis;numerical integration;telegrapher's equations	Vaclav Simek;Michal Kraus;Jirí Kunovsky;Jirí Petrek	2008	Tenth International Conference on Computer Modeling and Simulation (uksim 2008)	10.1109/UKSIM.2008.47	acceleration;computational science;parallel computing;simulation;computer science;theoretical computer science;differential equation;quantum mechanics	Visualization	-5.270218107721159	35.88476218006102	197211
1292b00c69a4f2de8997efa76afcd3342399c364	exploiting the multilevel parallelism and the problem structure in the numerical solution of stiff odes	parallel processing concurrent computing differential equations software engineering power engineering and energy stability power engineering computing nonlinear equations distributed computing parallel algorithms;linear algebra;distributed memory systems;numerical solution;dense banded structures multilevel parallelism component based methodology parallel stiff ordinary differential equation solvers multicomputers numerical algorithms parallel linear algebra modules design specification reusability pc cluster narrow banded structures;parallel programming differential equations workstation clusters linear algebra numerical analysis parallel algorithms distributed memory systems;ordinary differential equation;parallel programming;numerical analysis;numerical scheme;pc cluster;differential equations;workstation clusters;parallel algorithms	A component-based methodology to derive parallel stiff Ordinary Differential Equation (ODE) solvers for multicomputers is presented. The methodology allows the exploitation of the multilevel parallelism of this kind of numerical algorithms and the particular structure of ODE systems by using parallel linear algebra modules. The approach furthers the reusability of the design specifications and a clear structuring of the derivation process. Two types of components are defined to enable the separate treatment of different aspects during the derivation of a parallel stiff ODE solver. The approach has been applied to the implementation of an advanced numerical stiff ODE solver on a PC cluster. Following the approach, the parallel numerical scheme has been optimized and adapted to the solution of two modelling problems which involve stiff ODE systems with dense and narrow banded structures respectively. Numerical experiments have been performed to compare the solver with the state-of-the-art sequential stiff ODE solver. The results show that the parallel solver performs specially well with dense ODE systems and reasonably well with narrow banded systems.	algorithm;component-based software engineering;computer cluster;emoticon;experiment;linear algebra;numerical analysis;numerical method;parallel computing;partial template specialization;solver;speedup;stiff equation;task parallelism	Jose M. Mantas Ruiz;Julio Ortega;José A. Carrillo	2002		10.1109/EMPDP.2002.994262	computational science;ordinary differential equation;mathematical optimization;parallel computing;numerical analysis;computer science;theoretical computer science;linear algebra;distributed computing;parallel algorithm;differential equation;numerical stability	HPC	-8.773786070356115	36.06645678889464	197367
2bab28e36b50452b75ac9014078e45b88f74cc0b	stencil computations for pde-based applications with examples from dune and hypre			computation;dune	Christian Engwer;Robert D. Falgout;Ulrike Meier Yang	2017	Concurrency and Computation: Practice and Experience	10.1002/cpe.4097	computer science;computational science;parallel computing;computer graphics (images);partial differential equation;computation;stencil	PL	-6.735365362998581	38.128815707775374	197973
32df32db56271e2f00323b707dd4bf6f7d3b54ec	porting and optimizing a quantum-chemistry fci algorithm on the cray t3d	quantum chemistry	A Full Configuration Interaction algorithm has been optimised for a Cray T3D massively parallel computer. A preliminary version of the code showed good scalability, but also load unbalancing problems and synchronisation overheads. In this paper are described several ways to overcome these problems. A optimal solution has been found to eliminate the need of synchronisation points while load unbalancing appears to depend on the theoretical formulation of the problem. Also in this case some hints are suggested for future works.		Roberto Ansaloni;Elda Rossi;Stefano Evangelisti	1995		10.1007/BFb0046671	computational science;parallel computing;computer science;theoretical computer science	EDA	-5.137706973401168	37.332978825470654	198964
60d94420fd92fe3d88306a6ca665e20520ed9e70	parallel simulation of liquid flow using lga model	libraries;rivers flow simulation parallel processing cellular automata message passing application program interfaces;fluid flow computational modeling automata lattices libraries concurrent computing workstations velocity measurement rivers application software;concurrent computing;rivers;lattices;application software;fluid flow;lattice gas automaton;river flow simulation parallel simulation liquid flow simulation lga model lattice gas automaton cellular automaton fhp iii mpi library parallel computer workstation cluster;mpi library;river flow simulation;automata;computational modeling;fhp iii;lga model;application program interfaces;workstations;liquid flow simulation;parallel computer;message passing;flow simulation;lattice gas;velocity measurement;cellular automata;cellular automaton;parallel processing;parallel simulation;workstation cluster	Lattice gas automaton, a type of cellular automaton for modeling liquid flow, was invented in 1976. Its improved version called FHP-III is presented with theoretical background. The model was implemented in a parallel way, using MPI library. The speedups on a parallel computer and on a workstation cluster have been measured. They are almost linear. A river flow simulation is presented as an application example.	lattice gas automaton;simulation	Janusz Borkowski;Marek Rulak	2002		10.1109/PCEE.2002.1115266	cellular automaton;computational science;application software;parallel computing;message passing;workstation;computer science;theoretical computer science;lattice;distributed computing;automaton;computational model;algorithm;lattice gas automaton	Robotics	-9.473421967333072	37.7981928856665	199558
395bc79d403e7f37fc5dacf1932060999bbeec51	the parallel computation of time-dependent monte carlo transport	concurrent computing monte carlo methods parallel processing conferences;time dependent;transportation problem;processor scheduling;input output programs;processor scheduling monte carlo methods parallel algorithms input output programs multiprocessing systems;sampling technique;monte carlo method;parallel computer;parallel i o;multiprocessing systems;monte carlo;scattering source communication monte carlo method multiple processors particle transport problem parallel computation i o models low cost communication;monte carlo methods;parallel algorithms	Parallel Monte Carlo methods are successful because particles are typically independent and easily distributed to multiple processors. For time-dependent Monte Carlo particle transport problem, due to the communication of each time-step about scattering source attribute and meshes, it reduces the parallel efficiency and limits enlarge of parallel scale. We research parallel computation of two types of time-dependent particle transport problems. Adaptive processor assignment in parallel computation and three parallel I/O models with low-cost communication are presented. The optimized processor choice is obtained. We propose a scheme that is based upon Monte Carlo layered sample technique. It is used to treat communication of scattering source. The parallel expandability is greatly improved. The large speedups over the basic methods are obtained.	monte carlo method	Li Deng;Jie Liu;Wenyong Zhang;Guoxing Yuan;Zhengfeng Huang;Haiyan Xu;Ruihong Wang;Shu Li	2003		10.1109/ICPPW.2003.1240374	quasi-monte carlo method;parallel computing;real-time computing;dynamic monte carlo method;hybrid monte carlo;particle filter;markov chain monte carlo;computer science;theoretical computer science;monte carlo integration;statistics;cost efficiency;monte carlo method;monte carlo method for photon transport	Vision	-6.17595250569558	37.2076144852505	199720
