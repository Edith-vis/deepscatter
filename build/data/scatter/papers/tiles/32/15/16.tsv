id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
74d5e9445c8154c8a77cc71487a4c5cfd9a9588c	the concept of a linguistic variable and its application to approximate reasoning - i	defence management;data journal;linguistic variable;universe of discourse;approximate reasoning;knowledge;it value;foresight innovation policy;it security;consult;risk architecture;process improvement;business intelligence	By a linguistic variable we mean a variable whose values are words or sentences in a natural or artificial language. I:or example, Age is a linguistic variable if its values are linguistic rather than numerical, i.e., young, not young, very young, quite young, old, not very oldand not very young, etc., rather than 20, 21, 22, 23, In more specific terms, a linguistic variable is characterized by a quintuple (&?, T(z), U, G,M) in which &? is the name of the variable; T(s) is the term-set of2 , that is, the collection of its linguistic values; U is a universe of discourse; G is a syntactic rule which generates the terms in T(z); and M is a semantic rule which associates with each linguistic value X its meaning, M(X), where M(X) denotes a fuzzy subset of U The meaning of a linguistic value X is characterized by a compatibility function, c : l/ + [0, I], which associates with each u in U its compatibility with X. Thus, the COItIpdtibiiity of age 27 with young might be 0.7, while that of 35 might be 0.2. The function of the semantic rule is to relate the compdtibihties of the socalled primary terms in a composite linguistic value-e.g.,.young and old in not very young and not very old-to the compatibility of the composite value. To this end, the hedges such as very, quite, extremely, etc., as well as the connectivesand and or are treated as nonlinear operators which modify the meaning of their operands in a specified fashion. The concept of a linguistic variable provides a means of approximate characterization of phenomena which are too complex or too ill-defined to be amenable to description in conventional quantitative terms. In particular, treating ZFuth as a linguistic variable with values such as true, very true, completely true, not very true, untrue, etc., leads to what is called fuzzy logic. By providing a basis for approximate reasoning, that is, a mode of reasoning which is not exact nor very inexact, such logic may offer a more realistic framework for human reasoning than the traditional two-valued logic. It is shown that probabilities, too, can be treated as linguistic variables with values such as likely, very likely, unlikely, etc. Computation with linguistic probabilities requires the solution of This work was supported in part by the Navy Electronic Systems Command under Contract N00039-71-C-0255, the Army Research Office, Durham, N.C., under Grant DA-ARO-D-31-124-7 l-G1 74, and the National Science Foundation under Grant GK-VP610656X3. The writing of the paper was completed while the author was participating in a Joint Study Program with the Systems Research Department, IBM Research Ldboratory, San Jose, California. Parts II and III of this paper will appear in forthcoming issues of Information Sciences. @American Elsevier Publishing Company, Inc., 1975	approximation algorithm;computation;domain of discourse;fuzzy logic;fuzzy set;ibm research;linguistic value;nonlinear system;numerical analysis;operand;pdf/a;phrase structure rules	Lotfi A. Zadeh	1975	Inf. Sci.	10.1016/0020-0255(75)90036-5	mathematical optimization;deep linguistic processing;computer science;artificial intelligence;machine learning;mathematics;knowledge;business intelligence;algorithm	AI	-10.848335691716601	9.259765691280476	133104
fff449b2b19db6d8968d01dad617172ec05f3f8b	pretopologies and completeness proofs		Pretopologies were introduced in [S] and there shown to give a complete semantics for a propositional sequent calculus BL here called basic linear logic, as well as for its extensions by structural rules, ex falso quodlibet or double negation. Immediately after the Logic Colloquium ’88, conversation with Per Martin-Löf helped me to see how the pretopology semantics should be extended to predicate logic; the result now is a simple and fully constructive completeness proof for first order BL and virtually all its extensions, including usual, or structured, intuitionistic and classical logic. Such a proof clearly illustrates the fact that stronger set-theoretic principles and classical metalogic are necessary only when completeness is sought with respect to a special class of models, such as usual two-valued models. To make the paper self-contained, I briefly review in section 1 the definition of pretopologies; section 2 deals with syntax and section 3 with semantics. The completeness proof in section 4, though similar in structure, is sensibly simpler than that in [S], and this is why it is given in detail. In section 5 it is shown how little is needed to obtain completeness for extensions of BL in the same language. Finally, in section 6 connections with proofs with respect to more traditional semantics are shortly investigated, and some open problems are put forward. The content of this paper, except the last section, was already contained in a lecture given in March 1989 at the Department of Mathematics of the University of Stockholm; I thank Prof. P. Martin-Löf for his kind invitation. Soon after, a first draft of this paper was read by Prof. H. Ono, whose answers [O1] and [O2] in turn influenced the chapter on algebraic semantics in Prof. A. S. Troelstra’s lectures [T]. So by now the completeness proof for BL has partly lost its originality; I will thus stress on the peculiarity of the approach via pretopologies. The main advantage of pretopologies seems to be that of having a middle position: so on one hand little effort is needed to show the completeness of the semantics of pretopologies, as usual with algebraic semantics to which it is closely connected, but	algebraic semantics (computer science);bl (logic);ex falso;first draft of a report on the edvac;graph coloring;intuitionistic logic;linear logic;sequent calculus;set theory	Giovanni Sambin	1995	J. Symb. Log.		discrete mathematics;algorithm;predicate logic;double negation;sequent calculus;principle of explosion;classical logic;metalogic;mathematical proof;mathematics;linear logic	Theory	-9.939547225688104	7.890730257494776	133364
dda69673b299f17fd3895ba58ecf7cc8bd04e5aa	characterizing the set of coherent lower previsions with a finite number of constraints or vertices	mathematics and statistics;vertices;lower previsions;extreme points;characterization;coherence;polytopes;constraints;computation	The standard coherence criterion for lower previsions is expressed using an infinite number of linear constraints. For lower previsions that are essentially defined on some finite set of gambles on a finite possibility space, we present a reformulation of this criterion that only uses a finite number of constraints. Any such lower prevision is coherent if it lies within the convex polytope defined by these constraints. The vertices of this polytope are the extreme coherent lower previsions for the given set of gambles. Our reformulation makes it possible to compute them. We show how this is done and illustrate the procedure and its results.	algorithm;approximation;coherent;computation;contingency (philosophy);fourier–motzkin elimination;minkowski addition;miranda;real life;taiwan fellowship editor;vertex enumeration problem	Erik Quaeghebeur	2010			polytope;vertex;extreme point;combinatorics;mathematical analysis;discrete mathematics;coherence;computation;mathematics	AI	-6.129445256738487	10.426214901511326	133366
56944698b4462dfe14d6585d05441f3706579c56	local and global metrics for the semantics of counterfactual conditionals	indexation;possible worlds	ABSTRACT The semantics for counterfactual conditionals employs indexed relations ⁢a between possible worlds, with x >a y read intuitively as «x is closer to a than is y». This paper considers the question how far these different «closeness» relations of a model may be derived from a common source. Despite some well-known negative observations, we show that there is also quite a strong positive answer. Our main result is that for any model equiped with modular relations derived from multiple metrics da via the equation x ⁢a y iff da(a, x) ⁢ da(a, y), there is a model that validates exactly the same formulae of the logic of counterfactuals, and whose relations ⁢a are determined by a common metric d, via the equation x ⁢a y iff da(a, x) ⁢da(a, y).	counterfactual conditional	Karl Schlechta;David Makinson	1994	Journal of Applied Non-Classical Logics	10.1080/11663081.1994.10510829	discrete mathematics;epistemology;computer science;mathematics;possible world;algorithm	Logic	-8.43267049802522	10.659259199425412	134841
c010c939461c731cd277afd5f336c60657c98f3b	fuzzifying modal algebra		Fuzzy relations are mappings from pairs of elements into the interval [0, 1]. As a replacement for the complement operation one can use the mapping that sends x to 1 − x. Together with the concepts of t-norm and t-conorm a weak form of Boolean algebra can be defined. However, to our knowledge so far no notion of domain or codomain has been investigated for fuzzy relations. These might, however, be useful, since fuzzy relations can, e.g., be used to model flow problems and many other things. We give a new axiomatisation of two variants of domain and codomain in the more general setting of idempotent left semirings that avoids complementation and hence is applicable to fuzzy relations. Some applications are sketched as well.	axiomatic system;boolean algebra;fuzzy logic;fuzzy set;idempotence;modal algebra;modal logic;t-norm	Jules Desharnais;Bernhard Möller	2014		10.1007/978-3-319-06251-8_24	discrete mathematics;image;codomain;mathematics;algebra	Logic	-7.413941198708066	10.756429979806118	135701
adb25af081a6fa274f1aa2ac6c543d26fc49e195	minimalism and paradoxes	truth;correspondance;correspondence;theorie des ensembles;prisoner s dilemma;deflationnisme;russell s paradox;verite;set theory;paradoxe de russell;division;stability;minimalisme;paradoxe du prisonnier;stabilite;minimalism	This paper argues against minimalism about truth. It does so by way of acomparison of the theory of truth with the theory of sets, and considerationof where paradoxes may arise in each. The paper proceeds by asking twoseemingly unrelated questions. First, what is the theory of truth about?Answering this question shows that minimalism bears important similaritiesto naive set theory. Second, why is there no strengthened version ofRussell's paradox, as there is a strengthened Liar paradox? Answering thisquestion shows that like naive set theory, minimalism is unable to makeadequate progress in resolving the paradoxes, and must be replaced by adrastically different sort of theory. Such a theory, it is shown, must befundamentally non-minimalist.	set theory	Michael Glanzberg	2003	Synthese	10.1023/A:1022999315312	stability;philosophy;epistemology;minimalism;division;mathematics;prisoner's dilemma;algorithm;semantic theory of truth;set theory	Theory	-11.070961923914435	4.556835363875901	136983
97655ba81db87af112e4ba6af6bb5bd1f5292056	two hypergraph theorems equivalent to bpi	hipergrafico;theoreme compacite;probleme np complet;logique mathematique;logica matematica;logique propositionnelle;mathematical logic;boolean algebra;theoreme ideal premier;propositional logic;algebre boole;problema np completo;hypergraph;logica proposicional;algebra boole;np complete problem;hypergraphe	Techniques originally developed for establishing NP-Completeness are adapted to prove that two compactness theorems concerning hypergraphs are equivalent to the Prime Ideal Theorem for Boolean algebras (BPI). In addition, some possible connections between NP-Completeness and BPI are explored	business process interoperability	Robert Cowen	1990	Notre Dame Journal of Formal Logic	10.1305/ndjfl/1093635418	boolean algebra;combinatorics;mathematical logic;discrete mathematics;np-complete;topology;mathematics;propositional calculus;algorithm;algebra	Logic	-10.303541651406915	10.82094453642296	137245
a9a6f2189deaa9b254d6d6b0e131bed233793390	post inequations				Dragic Bankovic	2013	Multiple-Valued Logic and Soft Computing			EDA	-7.716764203590281	7.5293042571503666	137731
3c8364f72e86a40c49d9c81e602540e163200d1c	a necessary and sufficient condition for lukasiewicz logic functions	multiple valued logic design;logic design;logic circuits;negation;sufficient conditions;charge coupled devices;fuzzy logic;sufficient conditions logic functions logic design multivalued logic fuzzy logic informatics charge coupled devices logic circuits;lukasiewicz multiple valued logic;multiple valued functions;lukasiewicz implication;lukasiewicz logic functions;necessary and sufficient condition;multivalued logic logic design;lukasiewicz implication lukasiewicz logic functions multiple valued logic design negation multiple valued functions lukasiewicz multiple valued logic;logic functions;informatics;multiple valued;multivalued logic;multiple valued logic	The literal, TSUM, min and max operations employed in multiple-valued logic design can be expressed in terms of the implication and the negation of Lukasiewicz logic. We can easily show that the set of multiple-valued functions composed of the above four operations and the negation is equivalent to the set of all multiple-valued functions composed of the Lukasiewicz implication and the negation. This implies that from the viewpoint of the multiple-valued logic design, Lukasiewicz multiple-valued logic is a fundamental system. In this paper, we clarify a necessary and sufficient condition for a multiple-valued function to be a Lukasiewicz logic function, which is defined as a function in terms of the Lukasiewicz implication and the negation.	łukasiewicz logic	Noboru Takagi;Kyoichi Nakashima;Masao Mukaidono	1996		10.1109/ISMVL.1996.508333	fuzzy logic;electronic engineering;discrete mathematics;logic synthesis;logic gate;computer science;negation as failure;artificial intelligence;negation;mathematics;informatics;algorithm	EDA	-10.797199972044275	11.075960397339603	139004
c1067c1c44e9aed67ad2bea345f79dc6ae2b747e	finding missing proofs with automated reasoning	general and miscellaneous mathematics computing and information science;mathematics;o codes;logic;automated reasoning;mathematical logic;mathematical methods and computing;mathematical logic and foundations;philosophy;computational linguistics;automation	This article features long-sought proofs with intriguing properties (such as the absence of double negation and the avoidance of lemmas that appeared to be indispensable), and it features the automated methods for nding them. The theorems of concern are taken from various areas of logic that include two-valued sentential (or propositional) calculus and in nite-valued sentential calculus. Many of the proofs (in e ect) answer questions that had remained open for decades, questions focusing on axiomatic proofs. The approaches we take are of added interest in that all rely heavily on the use of a single program that o ers logical reasoning, William McCune's automated reasoning program OTTER. The nature of the successes and approaches suggests that this program o ers researchers a valuable automated assistant. This article has three main components. First, in view of the interdisciplinary nature of the audience, we discuss the means for using the program in question (OTTER), which ags, parameters, and lists have which e ects, and how the proofs it nds are easily read. Second, because of the variety of proofs that we have found and their signi cance, we discuss them in a manner that permits comparison with the literature. Among those proofs, we o er a proof shorter than that given by Meredith and Prior in their treatment of ukasiewicz's shortest single axiom for the implicational fragment of two-valued sentential calculus, and we o er a proof for the ukasiewicz 23-letter single axiom for the full calculus. Third, with the intent of producing a fruitful dialogue, we pose questions concerning the properties of proofs and, even more pressing, invite questions similar to those this article answers.	applications of artificial intelligence;automated reasoning;propositional calculus	Branden Fitelson;Larry Wos	2001	Studia Logica	10.1023/A:1012486904520	mathematical logic;philosophy;epistemology;computer science;artificial intelligence;computational linguistics;automation;mathematics;linguistics;automated reasoning;proof assistant;programming language;logic;algorithm;algebra	Logic	-10.471401144600625	5.898311308580431	139965
228b82022776638e1d6e366d2f1cae966be3d63f	ill-known set approach to disjunctive variables: calculations of graded ill-known intervals		In this paper, we represent the possible ranges of unknown variables as graded ill-known sets and investigate the extension principle for graded ill-known sets. Because graded ill-known sets can be seen as fuzzy sets in the power set, calculations of function values with graded ill-known sets are generally complex. We show that lower and upper approximations of function values with graded ill-known sets can be obtained by calculations of two kinds of fuzzy sets in the universe under certain assumptions which are frequently satisfied.	disjunctive normal form	Masahiro Inuiguchi	2012		10.1007/978-3-642-31709-5_65	approximations of π;fuzzy set;discrete mathematics;power set;universe;mathematics;mathematical analysis	NLP	-5.662360756766682	10.654892501140907	141056
bbaa189496f43ac7c9c18b5506d9e187a3f0b781	deduction graphs with universal quantification	term graph rewriting;cut elimination;universal quantification;first order;propositional logic;directed graph;natural deduction;article in monograph or in proceedings	Deduction Graphs are meant to generalise both Gentzen-Prawitz style natural deductions and Fitch style flag deductions. They have the structure of acyclic directed graphs with boxes. In [Herman Geuvers and Iris Loeb. Natural Deduction via Graphs: Formal Definition and Computation Rules. Mathematical Structures in Computer Science (Special Issue on Theory and Applications of Term Graph Rewriting), Volume 17(03):485-526, 2007.] we have investigated the deduction graphs for minimal proposition logic. This paper studies the extension with first-order universal quantification, showing the robustness of the concept of deduction graphs.	natural deduction;universal quantification	Herman Geuvers;Iris Loeb	2008	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2008.03.036	judgment;discrete mathematics;universal graph;directed graph;graph product;universal quantification;computer science;first-order logic;mathematics;propositional calculus;programming language;sequent calculus;natural deduction;algorithm;graph rewriting	Theory	-11.588027532647924	10.629346679281683	141435
17c64e522392e362c6ceb9913c92c0d7c79416dd	robust diagnosis of discrete-event systems against permanent loss of observations	certain sensor;robust diagnosability;finite-state automaton;permanent loss;fault event;robust diagnosis;partial diagnosers;discrete-event system;diagnostic engine;certain unobservable event;observable event;online diagnosis;automaton	We consider the problem of diagnosing the occurrence of a certain unobservable event of interest, the fault event, in the operation of a partially-observed discrete-event system subject to permanent loss of observations modeled by a finite-state automaton. Specifically, it is assumed that certain sensors for events that would a priori be observable may fail at the outset, thereby resulting in a loss of observable events; the diagnostic engine is not directly aware of such sensor failures.We explore a previous definition of robust diagnosability of a given fault event despite the possibility of permanent (and unknown a priori) loss of observations and present a polynomial time verification algorithm to verify robust diagnosability and a methodology to perform online diagnosis in this scenario using a set of partial diagnosers. © 2012 Elsevier Ltd. All rights reserved.	algorithm;automaton;fault tolerance;finite-state machine;observable;redundancy (engineering);sensor;time complexity	Lilian Kawakami Carvalho;Marcos Vicente Moreira;João Carlos Basilio;Stéphane Lafortune	2013	Automatica	10.1016/j.automatica.2012.09.017		AI	-5.072811075109463	7.347361416176397	142896
918c94b745002aac5a2f2f8c0cc8b84fd95755b4	dynamic effect algebras and their representations	dynamic effect algebra;tense operators;effect algebra;lattice effect algebra	"""For lattice effect algebras, the so-called tense operators were already introduced by Chajda and Kolařik. Tense operators express the quantifiers """"it is always going to be the case that"""" and """"it has always been the case that"""" and hence enable us to express the dimension of time in the logic of quantum mechanics. We present an axiomatization of these tense operators and prove that in every effect algebra can be introduced tense operators which, for non-complete lattice effect algebras, can be only partial mappings. An effect algebra equipped with tense operators reflects changes of quantum events from past to future. A crucial problem concerning tense operators is their representation. Having an effect algebra with tense operators, we can ask if there exists a frame such that each of these operators can be obtained by our construction. We solve this problem for (strict) dynamic effect algebras having a full set of homorphisms into a complete lattice effect algebra."""	mcgurk effect	Ivan Chajda;Jan Paseka	2012	Soft Comput.	10.1007/s00500-012-0857-x	filtered algebra;spectral theorem;operator theory;discrete mathematics;universal enveloping algebra;pure mathematics;mathematics;algebra representation;cellular algebra;operator algebra;current algebra;algebra	ECom	-7.583565711152485	10.979454255884685	142967
7fc1742cbbea8795cf80e979faa60cf580a81d84	metal: a formalism to specify formalisms		syntax # end definition 15.5 In Appendix 1 we give the complete Metal program defining ASPLE. In Appendix 2 we give the Metal program that defines Metal itself. The reader who is curious about the complete structure of a Metal program is referred to these appendixes. In this first part we will now discuss the path that the user is encouraged to follow when defining a new language in Metal. We begin by defining the concrete syntax of ASPLE, then we define its abstract syntax. Finally we write the tree building functions associated with each production of that concrete syntax. 1.2. The concrete syntax of ASPLE The language ASPLE is a very small programming language entirely defined by its denotational semantics in [5]. (program) :: = begin (dcl-train)(stm_train) end (dcl_train) : : = (declaration) 1 (dcl_train)(declaration) (declaration) :: = (mode)(idlist); (mode) ::= boo1 int I ref (mode) (idlist) ::= (id) 1 (idlist), (id) (stm_train) : : = (statement) 1 (stm_train); (statement) (statement) : : = (asgt-stm) ( (cond-stm) 1 (loop-stm) 1 (transput-stm) (asgt-stm) ::= (id):= (exp) (cond-stm) :: = if (exp) then (stm-train) fi 1 if (exp) then (stm_train) else (stm-train) fi (loop-stm) : : = while (exp) do (stm_train) end (transput-stm) :: = input (id) I output (exp) (expu003e :: = (factor) 1 (exp)+ (factor) (factor) : : = (primary) ( (factor) * (primary)	semantics (computer science)	Gilles Kahn;Bernard Lang;Bertrand Melese;Elham Morcos	1983	Sci. Comput. Program.	10.1016/0167-6423(83)90009-6	declaration;programming language;syntax;abstract syntax;denotational semantics;rotation formalisms in three dimensions;int;formalism (philosophy);constructed language;computer science	Logic	-10.689231635574945	8.298067381318226	143677
a2d72fb4a587506e3de1a20e6c40662751cd1c8b	reference in arithmetic		Self-reference has played a prominent role in the development of metamathematics in the past century, starting with Gödel’s first incompleteness theorem. Given the nature of this and other results in the area, the informal understanding of self-reference in arithmetic has sufficed so far. Recently, however, it has been argued that for other related issues in metamathematics and philosophical logic a precise notion of self-reference and, more generally, reference, is actually required. These notions have been so far elusive and are surrounded by an aura of scepticism that has kept most philosophers away. In this paper I suggest we shouldn’t give up all hope. First, I introduce the reader to these issues. Second, I discuss the conditions a good notion of reference in arithmetic must satisfy. Accordingly, I then introduce adequate notions of reference for the language of first-order arithmetic, which I show to be fruitful for addressing the aforementioned issues	first-order predicate;gödel;peano axioms;self-reference	Isabel Arranz	2018	Rew. Symb. Logic	10.1017/S1755020317000351	algorithm;gödel;gödel's incompleteness theorems;skepticism;mathematics;philosophical logic;aura;arithmetic;metamathematics	PL	-11.77847744465753	5.422466373020256	143951
3dd3d1e8a1f4f8daf622c8b4dae683638983e85e	investigating production system representations for non-combinatorial match	arbre recherche;complexite;sistema experto;production engineering;expert systems;learning;rule based systems;production system;complejidad;systeme production;complexity;commerce;sistema produccion;aprendizaje;computer programming;apprentissage;arbol investigacion;eliminating combinatorics;cognition;instantiationless match;production;orid task;formulations;machines;systeme expert;trade off analysis;search tree;expert system	Eliminating combinatorics from the match in production systems (or rule-based systems) is important for expert systems, real-time performance, machine learning (particularly with respect to the utility issue), parallel implementations and cognitive modeling. In [71], the unique-attribute representation was introduced to eliminate combinatorics from the match. However, in so doing, unique-attributes engender a sufficiently negative set of trade-offs, so that investigating whether there are alternative representations that yield better trade-offs becomes of critical importance. This article identifies two promising spaces of such alternatives, and explores a number of the alternatives within these spaces. The first space is generated from local syntactic restrictions on working memory. Within this space, unique-attributes is shown to be the best alternative possible. The second space comes from restrictions on the search performed during the match of individual productions (match-search). In particular, this space is derived from the combination of a new, more relaxed, match formulation (instantiationless match) and a set of restrictions derived from the constraint-satisfaction literature. Within this space, new alternatives are found that outperform unique-attributes in some, but not yet all, domains.	cognitive model;constraint satisfaction;expert system;machine learning;match report;production system (computer science);real-time locating system;rule-based system	Milind Tambe;Paul S. Rosenbloom	1994	Artif. Intell.	10.1016/0004-3702(94)90097-3	complexity;simulation;cognition;computer science;artificial intelligence;computer programming;mathematics;production system;search tree;expert system;algorithm	ML	-5.87498786505194	6.406331611151284	144860
268787681c6b415332e28a240e3eef7a3ddee3cb	representation and inference for natural language: a first course in computational semantics	computacion informatica;filologias;grupo de excelencia;linguistica;ciencias basicas y experimentales;natural language;grupo a;computational semantics	"""Computational semantics is the study of how to represent meaning in a way that computers can use. For the authors of this textbook, this study includes the representation of the meaning of natural language in logic formalisms, the recognition of certain relations that hold within this formalization (such as synonymy, consistency, and implication), and the computational implementation of all this. I think that, while there probably are not many courses devoted to computational semantics, this book could profitably be incorporated into more traditional computational linguistics courses, especially when two courses are offered serially. The material here could be spread out and integrated into parts of a more standard pair of these courses, and it would result in a substantial widening of the knowledge that students come away with from these courses. The introduction of this book traces the history of computational semantics, with a goal of justifying the enterprise in the face of the modern emphasis on statistical natural language processing. Besides this introduction, the book contains six substantial chapters and four short appendices. There is also a very extensive suite of material on-line at a Web site maintained by the authors. Chapter 1 is an introduction to first-order logic, but with a twist that underscores the particular outlook taken in this book. There is a very short introduction to the notion of a model of a set of quantifier-free sentences, followed by an equally short discussion of the interpretation of quantifiers in a model. With respect to quantifier-free sentences, students are referred to the three-page Appendix B on propositional logic, where truth-tables are covered. The innovations start with the introduction of three """" inference tasks """" : querying, consistency checking, and informativity checking. These correspond to the logical concepts of satisfiability (of a given formula in a given model), consistency (whether there is a model that satisfies a given formula), and validity (whether a formula is true in all models, or, equivalently, whether a given argument is valid). Although the notions of querying, etc., are thus merely renamings of standard logical notions, it seems to me that the renaming is particularly apposite in the setting of a textbook for non-logicians, especially since much is to be done computationally with these notions in the enterprise of computational semantics. Much of the remainder of chapter 1 consists of a gentle introduction to Prolog and using it to check formulas for well-formedness …"""	boolean satisfiability problem;computation;computational linguistics;computational semantics;computer;first-order logic;first-order predicate;microsoft outlook for mac;model checking;natural language processing;online and offline;prolog;propositional calculus;quantifier (logic);stochastic grammar;term (logic);tracing (software)	Patrick Blackburn;Johan Bos	2005	Computational Linguistics	10.1162/coli.2006.32.2.283	natural language processing;computer science;linguistics;natural language;algorithm;computational semantics	AI	-11.205647794892132	6.843024036654525	146876
014c4594f638a13c9105c84b4e37166e3f5e14f3	relational hidden variables and non-locality	probabilistic models;possibilistic models;probabilistic model;foundations of quantum mechanics;quantum physics;quantum mechanics;hidden variables;probability distribution;non locality;logic in computer science	We use a simple relational framework to develop the key notions and results on hidden variables and non-locality. The extensive literature on these topics in the foundations of quantummechanics is couched in terms of probabilistic models, and properties such as locality and no-signalling are formulated probabilistically. We show that to a remarkable extent, the main structure of the theory, through the major No-Go theorems and beyond, survives intact under the replacement of probability distributions by mere relations.	hidden variable theory;locality of reference	Samson Abramsky	2013	Studia Logica	10.1007/s11225-013-9477-4	probability distribution;statistical model;combinatorics;discrete mathematics;quantum probability;quantum nonlocality;relational quantum mechanics;mathematics;quantum statistical mechanics;hidden variable theory	Theory	-10.66681854446727	4.230919720678656	147413
6a229d962c6d22b63a3e347daa96d07bcd07922c	formal metalanguage and formal theory as two aspects of generative grammar	formal theory;formal metalanguage;generative grammar	As is known, metalanguage is a language by means of which another language is described. The latter is called object-language. One and the same language may play the role of object-language and metalanguage. For example, the Russian language taken as an object of linguistic description is an object-language, the Russian language used for a linguistic description of Russian is a metalanguage. There are non-formal and formal metalanguages. For example, the Russian language used in ordinary grammars of Russian as a means of describing the Russian language is a non-formal metalanguage. Formal metalanguage is an artificial language, defined by deductive rules of construction, and used to describe natural languages. The problem of formal metalanguages for linguistic descriptions is a broad topic which we do not mean to-exhaust. We shall restrict ourselves to clarifying the role of formal metalanguages in constructing generative grammars. Every generative grammar is a formal theory. For example, a generative grammar of Russian is a formal theory of Russian, a generative grammar of English is a formal theory of English. We shall focus our attention on the question of correlation between formal metalanguages and formal linguistic theories understood as generative grammars. Let us take a concrete example: formal metalanguage and formal theory as two aspects of applicative generative grammar. This concrete example will make it possible, we hope, to draw certain general conclusions about the role of formal metalanguages in generative grammar. We shall start with formal metalanguage in applicative generative grammar. We call this metalanguage a universal operator language. The universal operator language is defined by the grammar which is an ordered quadruple	applicative programming language;generative grammar;natural language;object language;quadruple-precision floating-point format;theory (mathematical logic);universal quantification	Sebastian K. Saumjan;P. A. Soboleva	1973			grammar systems theory;formal system;generative grammar;formal semantics;object language;metalanguage;operator-precedence grammar;regular grammar;affix grammar;chomsky hierarchy;regular tree grammar;emergent grammar;formal grammar;attribute grammar;adaptive grammar	NLP	-10.325656737691277	8.227777892727026	149583
8d2eac2ce1baefeac48a0bd91fcc9b19451e3edc	a milestone reached and a secret revealed	general and miscellaneous mathematics computing and information science;logic;automated reasoning;mathematical methods and computing;anl;formal logic;artificial intelligence;elegant proofs;proof finding;automation	In this special issue of the Journal of Automated Reasoning, this article sets the stage for the succeeding articles, all of which focus on finding proofs of theorems of formal logic and on the various methodologies that were employed. The proofs that are offered mark an important milestone for automated reasoning and for logic, for each of them is indeed new. One key question this article answers is why an automated reasoning program was able to find proofs that had eluded some of the finest mathematicians and logicians for many, many decades.	journal of automated reasoning	Larry Wos	2001	Journal of Automated Reasoning	10.1023/A:1010650624155	computer science;artificial intelligence;theoretical computer science;automated proof checking;mathematics;automated reasoning;proof assistant;deductive reasoning;logic;algorithm	AI	-10.117231645631469	5.393559801115224	153772
0386f4e3fd0f7deedb2ac2329942b043370f0f80	connectivity spaces		Connectedness is a fundamental property of objects and systems. It is usually viewed as inherently topological, and hence treated as derived property of sets in (generalized) topological spaces. There have been several independent attempts, however, to axiomatize connectedness either directly or in the context of axiom systems describing separation. In this review-like contribution we attempt to link these theories together. We find that despite difference in formalism and language they are largely equivalent. Taken together the available literature provides a coherent mathematical framework that is not only interesting in its own right but may also be of use in several areas of computer science from image analysis to combinatorial optimization. Mathematics Subject Classification (2000). 54D05, 54E05.	coherence (physics);combinatorial optimization;computer science;image analysis;mathematical optimization;mathematics subject classification;semantics (computer science);spaces	Bärbel M. R. Stadler;Peter F. Stadler	2015	Mathematics in Computer Science	10.1007/s11786-015-0241-1		Theory	-7.04521904316501	8.415769531021603	154959
41c9532844a0a71624f2ef1dbf030bc979426053	languages of logic and their applications	syntax;semantics;first order languages;first order	Concerning the logical description languages, in the past 40–50 years many authors have introduced a number of structurally very different first-order languages. Some of these languages follow the structure of a given future model, other ones have been prepared for the description of an arbitrary model. Other variations of the first-order languages do not follow the whole structure of any model: they have been prepared only for the relations definable over the universe in order to be able to prove the generalizations of a number of difficult logical results. The semantics of the first-order languages is based on the interpretation of their extralogical symbols by a suitable model. In some cases, in the interpretation all possible models can be in focus, but there are cases when the models over a special universe are regarded. The naming problem of the universe element of the model arises at this stage. The efforts for solving this problem lead to different approaches. Here, we present the most important language definitions and some characteristic semantics. We investigate the different approaches and conclude that they do not indicate essential differences. In fact, they have been only motivated by seeking for an easier way to achieve the just fixed target. Moreover, we try to point out the suitability connections of languages and semantics definitions. c © 2007 Elsevier Ltd. All rights reserved.	description logic;first-order logic;first-order predicate;formal language;interface description language;interpreted language	Katalin Pásztor-Varga;Magda Várterész	2008	Computers & Mathematics with Applications	10.1016/j.camwa.2007.06.007	syntax;computer science;pure mathematics;formal semantics;first-order logic;mathematics;semantics;cone;ontology language;abstract family of languages;second-generation programming language;denotational semantics;algorithm;algebra	AI	-10.449281258001356	8.605580961313096	155131
597bcafe2b47d082311578398b1c414183b6c510	cohen and set theory	set theory	We discuss the work of Paul Cohen in set theory and its influence, especially the background, discovery, development of forcing. Paul Joseph Cohen (1934–2007) in 1963 established the independence of the Axiom of Choice (AC) fromZF and the independence of the Continuum Hypothesis (CH) from ZFC. That is, he established that Con(ZF) implies Con(ZF+¬AC) and Con(ZFC) implies Con(ZFC+¬CH). Already prominent as an analyst, Cohen had ventured into set theory with fresh eyes and an open-mindedness about possibilities. These results delimited ZF and ZFC in terms of the two fundamental issues at the beginnings of set theory. But beyond that, Cohen’s proofs were the inaugural examples of a new technique, forcing, which was to become a remarkably general and flexible method for extending models of set theory. Forcing has strong intuitive underpinnings and reinforces the notion of set as given by the first-order ZF axioms with conspicuous uses of Replacement and Foundation. If Gödel’s construction of L had launched set theory as a distinctive field of mathematics, then Cohen’s forcing began its transformation into a modern, sophisticated one. The extent and breadth of the expansion of set theory henceforth dwarfed all that came before, both in terms of the numbers of people involved and the results established. With clear intimations of a new and concrete way of building models, set theorists rushed in and with forcing were soon establishing a cornucopia of relative consistency results, truths in a wider sense, with some illuminating classical problems of mathematics. Soon, ZFC became quite unlike Euclidean geometry and much like group theory, with a wide range of models of set theory being investigated for their own sake. Set theory had undergone a sea-change, and with the subject so enriched, it is difficult to convey the strangeness of it. Received April 24, 2008. This is the full text of an invited address given at the annual meeting of the Association for Symbolic Logic held at Irvine in March 2008. My thanks to Juliet Floyd, and, for helpful communications, to Andreas Blass, Solomon Feferman, Alexander Kechris, Elliott Mendelson, and Dana Scott. c © 2008, Association for Symbolic Logic 1079-8986/08/1403-0003/$3.80	delimiter;first-order predicate;gödel;mind;peano axioms;triune continuum paradigm;zermelo–fraenkel set theory	Akihiro Kanamori	2008	Bulletin of Symbolic Logic		zermelo–fraenkel set theory;effective descriptive set theory;universal set;forcing;topology;scott–potter set theory;mathematics;set theory;algebra	Theory	-8.893579190271394	7.7838320635858755	156780
a280c94702efab9f6fa312386ef4ca783573285d	an algorithmic method supported by paraconsistent annotated logic applied to the determination of friction factors for turbulent flow in smooth pipes		The high complexity of the study of fluid flow is due to the existence of an excessive number of formulas to determine analytically the friction factor in pipelines. Currently, with more than a dozen formulas and the obligation of using graphics with readings on logarithmic scales for this purpose, the results are obtained with some degree of uncertainty. Recent work, with treatment of uncertainties, suggests that these complex calculations can be better performed with the basis of non-classical logic, such as the paraconsistent annotated logic (PAL) which has as a fundamental property the acceptance of contradictions. In this chapter we present a method that uses algorithms of PAL to make analysis in tests of fluid flow in smooth pipes. The PAL algorithms select and classify various results originating from the various equations for the obtaining of friction factor and, according to the Reynolds number, they optimize the calculation application of hydraulic projects in smooth pipes.	paraconsistent logic;turbulence	Maurício Conceição Mário;Marcílio Dias Lopes;Cláudio Luís Magalhães Fernandes;Dorotéa Vilanova Garcia;João Inácio da Silva Filho;José Carlos Morilla;Clóvis Misseno Da Cruz;Jair Minoro Abe;Cláudio Rodrigo Torres;Deovaldo de Moraes Júnior	2015		10.1007/978-3-319-19722-7_7	artificial intelligence;mathematics;algorithm	Vision	-9.509310900062285	6.292709778581277	158005
96b0cadfbad625fbddd55c4a1910df4e1f1b2905	the toffoli-hadamard gate system: an algebraic approach	quantum conputational logics;universal quantum gates;quantum computational structures;universality;quantum logic	Shi and Aharonov have shown that the Toffoli gate and the Hadamard gate give rise to an approximately universal set of quantum computational gates. The basic algebraic properties of this system have been studied in Dalla Chiara et al. (Foundations of Physics 39(6):559–572, 2009), where we have introduced the notion of Shi-Aharonov quantum computational structure. In this paper we propose an algebraic abstraction from the Hilbert-space quantum computational structures, by introducing the notion of Toffoli-Hadamard algebra. From an intuitive point of view, such abstract algebras represent a natural quantum generalization of both classical and fuzzy-like structures.	aharonov–bohm effect;hadamard transform;hilbert space;linear algebra;toffoli gate	Maria Luisa Dalla Chiara;Antonio Ledda;Giuseppe Sergioli;Roberto Giuntini	2013	J. Philosophical Logic	10.1007/s10992-013-9271-9	quantum simulator;quantum operation;quantum fourier transform;quantum logic;discrete mathematics;quantum information;quantum probability;toffoli gate;philosophy;epistemology;quantum network;quantum capacity;quantum technology;open quantum system;pure mathematics;universality;controlled not gate;quantum circuit;mathematics;quantum dissipation;quantum computer;quantum process;quantum dynamics;quantum algorithm;quantum turing machine;quantum gate;quantum error correction	Theory	-10.038532426336733	10.529426656144702	158016
07bcc41c7ad52cbac8b94f308d3311eec0d4a352	optimal planning in the presence of conditional effects: extending lm-cut with context splitting		The LM-Cut heuristic is currently the most successful heuristic in optimal STRIPS planning but it cannot be applied in the presence of conditional effects. Keyder, Hoffmann and Haslum recently showed that the obvious extensions to such effects ruin the nice theoretical properties of LM-Cut. We propose a new method based on context splitting that preserves these properties.	computation;heuristic;heuristic (computer science);overhead (computing);precondition;strips	Gabriele Röger;Florian Pommerening;Malte Helmert	2014		10.3233/978-1-61499-419-0-765	mathematical optimization;artificial intelligence;algorithm	AI	-7.810998583474998	6.126700567685901	158168
99a5841505fed763652f6bf6a6103d6316730e7e	a diagrammatic reasoning system for alc	selected works;first order;diagrammatic reasoning;bepress;description logic	Description logics (DLs) are a well-known family of knowledge representation (KR) languages. The notation of DLs has the style of a variable-free first order predicate logic. In this paper a diagrammatic representation of the DL ALC– based on Peirce’s existential graphs – is presented and a set of transformation rules on these graphs provided. As the transformation rules modify the diagrammatic representation of ALC this produces a diagrammatic calculus. Some examples present in the paper illustrate the use and properties of this calculus. Disciplines Physical Sciences and Mathematics Publication Details Dau, F. & Eklund, P. W. (2007). A diagrammatic reasoning system for ALC. In Z. Zhang (Eds.), International Conference on Knowledge Science, Engineering and Management (pp. 39-51). Heidelberg-Berlin: SpringerVerlag. This conference paper is available at Research Online: http://ro.uow.edu.au/infopapers/3048 A Diagrammatic Reasoning System for ALC Frithjof Dau, Peter Eklund Faculty of Informatics University of Wollongong Wollongong, NSW, 2522 Australia dau,peklund@uow.edu.au Abstract. Description logics (DLs) are a well-known family of knowledge representation (KR) languages. The notation of DLs has the style of a variable-free first order predicate logic. In this paper a diagrammatic representation of the DL ALC– based on Peirce’s existential graphs – is presented and a set of transformation rules on these graphs provided. As the transformation rules modify the diagrammatic representation of ALC this produces a diagrammatic calculus. Some examples present in the paper illustrate the use and properties of this calculus. Description logics (DLs) are a well-known family of knowledge representation (KR) languages. The notation of DLs has the style of a variable-free first order predicate logic. In this paper a diagrammatic representation of the DL ALC– based on Peirce’s existential graphs – is presented and a set of transformation rules on these graphs provided. As the transformation rules modify the diagrammatic representation of ALC this produces a diagrammatic calculus. Some examples present in the paper illustrate the use and properties of this calculus.	cognition;description logic;diagram;existential graph;experiment;first-order logic;knowledge representation and reasoning;mind;reasoning system;usability	Frithjof Dau;Peter W. Eklund	2007		10.1007/978-3-540-76719-0_8	diagrammatic reasoning;description logic;computer science;artificial intelligence;first-order logic;algorithm	AI	-11.759343623901984	9.851797413644592	158533
1e7ece17c8480ff5de36c0c49e9249276665dffc	coherent diagrammatic reasoning in compositional distributional semantics		The framework of Categorical Compositional Distributional models of meaning [3], inspired by category theory, allows one to compute the meaning of natural language phrases, given basic meaning entities assigned to words. Composing word meanings is the result of a functorial passage from syntax to semantics. To keep one from drowning in technical details, diagrammatic reasoning is used to represent the information flow of sentences that exists independently of the concrete instantiation of the model. Not only does this serve the purpose of clarification, it moreover offers computational benefits as complex diagrams can be transformed into simpler ones, which under coherence can simplify computation on the semantic side. Until now, diagrams for compact closed categories and monoidal closed categories have been used (see [2, 3]). These correspond to the use of pregroup grammar [12] and the Lambek calculus [9] for syntactic structure, respectively. Unfortunately, the diagrammatic language of Baez and Stay [1] has not been proven coherent. In this paper, we develop a graphical language for the (categorical formulation of) the nonassociative Lambek calculus [10]. This has the benefit of modularity where extension of the system are easily incorporated in the graphical language. Moreover, we show the language is coherent with monoidal closed categories without associativity, in the style of Selinger’s survey paper [17].		Gijs Jasper Wijnholds	2017		10.1007/978-3-662-55386-2_27	discrete mathematics;computer science;coherence theorem;diagrammatic reasoning;category theory;distributional semantics;natural language;semantics;associative property;syntax	NLP	-11.733613608671591	8.074793706151123	159384
e9a3378e7731f39093850fff6cb6bfe8a5af8771	diagnosis of probabilistic models using causality and regression		The counterexample in probabilistic model checking (PMC) is a set of paths in which a path formula holds, and their accumulated probability violates the probability bound. However, understanding the counterexample is not an easy task. In this paper we address the complementary task of counterexample generation, which is the counterexample analysis. We propose an aided-diagnostic method for probabilistic counterexamples based on the notions of causality and regression analysis. Given a counterexample for a Probabilistic CTL (PCTL)/Continuous Stochastic Logic (CSL) formula that does not hold over Discrete Time Markov Chain (DTMC)/Continuous Time Markov Logic (CTMC) model, this method generates the causes of the violation, and describes their contribution to the error in the form of a regression model.	algorithm;causal model;causal system;causality;fuzzy logic;markov chain;markov logic network;model checking;probabilistic ctl;statistical model	Hichem Debbi	2014			statistics;probabilistic logic;causality;mathematics	Logic	-6.431900629031001	5.529959918387189	160368
3766c317aae6da26786f964439fc1c877202b697	an epistemic logic for arbitration (extended abstract)	epistemic logic	Arbitration is the process of settling a conflict between two or more persons[Liberatore and Schaerf, 1995; Revesz, 1993; 1997]. The first version of the arbitration operator between knowledge bases is proposed in [Revesz, 1993] via the socalled model-fitting operators. The postulates for modelfitting operators and the corresponding semantic characterization are presented. Arbitration is defined as a special kind of model-fitting operators. In [Revesz, 1997], the arbitration operator is further generalized to make it applicable to weighted knowledge bases. A set of postulates is also directly used in characterizing the arbitration between a weighted knowledge base and a regular knowledge base. A weighted knowledge base in [Revesz, 1997] is defined as a mapping from model sets to nonnegative real numbers and a regular knowledge base is just a finite set of prepositional sentences. A generalized loyal assignment is then defined as a function that assigns to each weighted knowledge base a pre-order between prepositional sentences so that some conditions are satisfied for the pre-orders. Finally, the arbitration of a weighted knowledge base by a regular knowledge base is defined as	curve fitting;epistemic modal logic;knowledge base	Churn-Jung Liau	2003			philosophy of logic;multimodal logic;many-valued logic;dynamic logic (modal logic);predicate logic;normal modal logic;algorithm;computer science;higher-order logic;epistemic modal logic	AI	-10.963511556601338	10.214613067213216	160413
cd980f816af909e4669b901af44766bd48d197ee	factored arc consistency for rete match	automated programming;arc consistency;constraint satisfaction;factorization;matching;production systems	RETE match for production systems and Arc Consistency (AC) filtering are two efficient AI algorithms that are designed for particular constraint satisfaction problems (CSP). Interestingly, it is possible to integrate the two within a common framework, and provide RETE with the lookahead advantages of AC. Unfortunately, the resulting quadratic dependence of AC on working memory (WM) size precludes the application of AC to RETE, since RETE responds to incremental changes in WM. Recent results in AC graph factorization, however, reduce the quadratic dependence to just linear for certain classes of problems, including RETE. In this paper, we present RETE and AC within the unified framework of Call-Graph Caching (CGC) evaluation. We describe factored arc consistency (FAC) and its use in an integrated FAC/RETE algorithm that provides RETE match with AC lookahead. We discuss our implementations, promising initial empirical results, and explore FAC/RETE’s applicability conditions and extensions. We conclude that incorporating factored AC into RETE match is an interesting and potentially useful application of arc consistency methods to the RETE CSP.	local consistency;rete algorithm	Mark W. Perlin	1993	International Journal on Artificial Intelligence Tools	10.1142/S0218213093000151	matching;mathematical optimization;constraint satisfaction;computer science;artificial intelligence;theoretical computer science;machine learning;production system;factorization;algorithm;local consistency	Robotics	-5.8375536499253435	6.5533511651921925	162263
04f9e77fc3167d35add1acb143b2f427f78f00d3	algorithmic tolerances and semantics in data exchange	exact arithmetic;residue number systems;computational geometry;data exchange;single precision;robustness;modular computations;data transfer	Within industrial contexts, a common view of the level of confidence needed in CAD data transfer processes may be expressed as “1 don’t mind if the [CAD datatmnsfer] algorithm sometimes has difficulties, provided I get a warning message that tells me something has gone wrong. ” A particularly annoying, even mystifying, CAD data exchange problem occurs in the so-called ‘round-trip’ problem. There, an acceptable model is transferred from an originating system to a neutral format and then back to the original system, only to find that serious new flaws now appear in the model within the originating system.	algorithm;cad data exchange;computer-aided design	Thomas J. Peters;Neil F. Stewart;David R. Ferguson;P. S. Fussell	1997		10.1145/262839.263027	data exchange;discrete mathematics;computational geometry;computer science;theoretical computer science;geometry;programming language;single-precision floating-point format;algorithm;robustness	DB	-9.570013720312033	5.511833203348724	162969
a3da07c22f30a4424944b53824380f16282afbc8	graphical sequent calculi for modal logics		The syntax of modal graphs is defined in terms of the continuous cut and broken cut following Charles Peirce’s notation in the gamma part of his graphical logic of existential graphs. Graphical calculi for normal modal logics are developed based on a reformulation of the graphical calculus for classical propositional logic. These graphical calculi are of the nature of deep inference. The relationship between graphical calculi and sequent calculi for modal logics is shown by translations between graphs and modal formulas.	existential graph;graphical user interface;normal modal logic;propositional calculus;sequent calculus	Minghui Ma;Ahti-Veikko Pietarinen	2017		10.4204/EPTCS.243.7	normal modal logic;combinatorics;discrete mathematics;axiom s5;mathematics;accessibility relation;algorithm	Logic	-11.321339724225682	10.726248395634263	163316
f0df980913bb13920750a7bcec199c4f6c16778d	self-referencing as socio-scientific methodology in contrasting paradigms	cybernetics;mathematics;system theory;social system;islam;systems theory;system design;epistemology;formal logic	Purpose – The purpose of this paper is to critique Gödel’s and Tarski’s axiomatic approach in their theorems of incompleteness of the arithmetical system. Design/methodology/approach – Mathematical theory of self-referencing is contrasted and an original contribution made by an extension of the same theorem beyond Godel and Tarski, showing how the Islamic epistemology contributes to establishing new thought in mathematical logic with unity of the divine law. Findings – The paper finds that behind the critique of the axioms of provability and non-provability, decidability and undecidability, lies the morally valid episteme of all socio-scientific systems and that this is as true of social systems as it is of the hard-core sciences. Research limitations/implications – The paper has the potential for extension to applications, which has not been included. Originality/value – The paper contributes to new and original thinking in the area of mathematical logic of self-referencing theorem in the framework of unity of the divine law as the episteme of “everything”.	axiomatic system;gödel;social system	Masudul Alam Choudhury;S. I. Zaman	2009	Kybernetes	10.1108/03684920910973199	cybernetics;computer science;artificial intelligence;mathematics;systems theory;algorithm	Theory	-10.84516357211846	5.64853561215931	163502
c8ed24d86755095c263a2f031752f817e668da3e	experiments with a deductive question-answering program	question answering	"""As an investigation in artificial intelligence, computer experiments on deductive question-answering were run with a LISP program called DEDUCOM, an acronym for DEDUctive COMmunicator. When given 68 facts, DEDUCOM answered 10 questions answerable from the facts. A fact tells DEDUCOM either some specific information or a method of answering a general kind of question. Some conclusions drawn in the article are: (1) DEDUCOM can answer a wide variety of questions. (2) A human can increase the deductive power of DEDUCOM by telling it more facts. (3) DEDUCOM can write very simple programs (it is hoped that this ability is the forerunner of an ability to self-program, which is a way to learn). (4) DEDUCOM is very slow in answering questions. (5) DEDUCOM's search procedure at present has two bad defects: some questions answerable from the given facts cannot be answered and some other answerable questions can be answered only if the relevant facts are given in the """"right"""" order. (6) At present, DEDUCOM's method of making logical deductions in predicate calculus has two bad defects: some facts have to be changed to logically equivalent ones before being given to DEDUCOM, and some redundant facts have to be given to DEDUCOM."""	artificial intelligence;experiment;first-order logic;question answering	James R. Slagle	1965	Commun. ACM	10.1145/365691.365960	computer science	AI	-10.930548697483266	7.245018582288821	164141
9fe552356199f59e91c861bd588a82143892be30	epistemic equivalence of extended belief hierarchies	epistemic game theory;common assumption;common strong belief;type spaces;lexicographic belief hierarchies;conditional belief hierarchies;epistemic equivalence	In this paper, we introduce a notion of epistemic equivalence between hierarchies of conditional beliefs and hierarchies of lexicographic beliefs, thus extending the standard equivalence results of Halpern (2010) and Brandenburger et al. (2007) to an interactive setting, and we show that there is a Borel surjective function, mapping each conditional belief hierarchy to its epistemically equivalent lexicographic belief hierarchy. Then, using our equivalence result we construct a terminal type space model for lexicographic belief hierarchies. Finally, we show that whenever we restrict attention to full-support beliefs, epistemic equivalence between a lexicographic belief hierarchy and a conditional belief hierarchy implies that an arbitrary Borel event is commonly assumed under the lexicographic belief hierarchy if and only if it is commonly strongly believed under the conditional belief hierarchy. This is the first result in the literature directly linking common assumption in rationality (Brandenburger et al., 2008) with common strong belief in rationality (Battigalli and Siniscalchi, 2002).	lexicographical order;rationality;turing completeness	Elias Tsakas	2014	Games and Economic Behavior	10.1016/j.geb.2014.03.008	combinatorics;discrete mathematics;mathematics	AI	-8.061811362488424	10.008337699902972	164329
0078b8478086db18aab7cdbbb23eca13162a5664	deriving syntactic properties of arguments and adjuncts from neo-davidsonian semantics	logical form	This paper aims to show that certain syntactic differences between arguments and adjuncts can be thought of as a transparent reflection of differences between their contributions to neo-Davidsonian logical forms. Specifically, the crucial underlying distinction will be that between modifying an event variable directly, and modifying an event variable indirectly via a thematic relation. I note a convergence between the semantic composition of neo-Davidsonian logical forms and existing descriptions of the syntactic properties of adjunction, and then propose a novel integration of syntactic mechanisms with explicit neo-Davidsonian semantics which sheds light on the nature of the distinction between arguments and adjuncts. This paper aims to show that certain syntactic differences between arguments and adjuncts can be thought of as a transparent reflection of differences between their contributions to neo-Davidsonian logical forms. Specifically, the crucial underlying distinction will be that between modifying an event variable directly, as violently and yesterday do in (1), and modifying an event variable indirectly via a thematic relation, as b and c do in (1). (1) a. Brutus stabbed Caesar violently yesterday b. ∃e[stabbing(e) ∧ Stabber(e,b) ∧ Stabbee(e, c) ∧ violent(e) ∧ yesterday(e)] I note a convergence between the semantic composition of neo-Davidsonian logical forms and the mechanisms added by Frey and Gärtner [1] to Stabler’s Minimalist Grammar (MG) formalism [2] to allow adjunction phenomena. Frey and Gärtner provide an accurate formal encapsulation of what the distinctive syntactic properties of adjunction are. This paper contributes a novel integration of syntactic mechanisms with explicit neo-Davidsonian semantics which sheds light on why these properties cluster together. 1 Two Classes of Words Consider the sentence in (2) and the variants of it in (3–6). ⋆ Thanks to Norbert Hornstein, Greg Kobele, Paul Pietroski, Amy Weinberg and Alexander Williams for helpful discussions related to this paper. (2) Brutus stabbed Caesar (3) a. Brutus stabbed Caesar violently b. Brutus stabbed Caesar yesterday c. Brutus stabbed Caesar violently yesterday d. Brutus stabbed Caesar yesterday violently (4) a. * Brutus stabbed Caesar Cassius b. * Brutus stabbed Caesar Antony c. * Brutus stabbed Caesar Cassius Antony (5) a. Caesar stabbed Brutus b. Brutus stabbed Cassius c. Antony stabbed Caesar (6) a. * Brutus stabbed b. * stabbed Caesar c. * stabbed First, we can infer from (3) that there is some class of words, including ‘violently’ and ‘yesterday’, which can be boundlessly added to the sentence in (2) without affecting grammaticality, though no word of this class need be present. Let us call this class of words Class 1. We also note that each sentence in (3) implies the one in (2), and infer that any sentence including a word of Class 1 implies the sentence just like it but with that word removed; see Fig. 1. The data in (4) indicates that there is also some other class of words, including at least ‘Cassius’ and ‘Antony’, which can not be added to the sentence in (2) without affecting grammaticality. Let us call this class of words Class 2. Next, we can infer on the basis of (5) that ‘Brutus’ and ‘Caesar’ belong to a single class of words, since they can be interchanged without affecting grammaticality; and that this class must be Class 2, that of ‘Cassius’ and ‘Antony’. We also discover a difference between Class 1 and Class 2: while interchanging two Class 1 words does not produce any obvious difference in meaning (compare (3c) and (3d)), interchanging two Class 2 words does (compare (2) and (5a)). Finally, (6) shows that Class 2 words also can not be removed without affecting grammaticality, just as (4) shows that they can not be added. In sum we have discovered two classes of words with the following properties. (7) Distributional properties: a. Of Class 1 words, any number zero or greater can be present in a sentence constructed around ‘stabbed’. b. Of Class 2 words, exactly two must be present in a sentence constructed around ‘stabbed’. (8) Semantic properties: a. When two Class 1 words are interchanged, no obvious difference in meaning results.	caesar;emoticon;encapsulation (networking);gerald weinberg;mg (editor);minimalist grammar;semantics (computer science)	Tim Hunter	2009		10.1007/978-3-642-14322-9_9	natural language processing;logical form;computer science;mathematics;linguistics;algorithm	NLP	-11.235991718277335	7.5994547285198815	165809
da61686e8150fde5a4aa8d332d5039d1ad8e2db1	faults prognosis using partially observed stochastic petri nets		This article deals with the problem of fault prognosis in stochastic discrete event systems. For that purpose, partially observed stochastic Petri nets are considered to model the system with its sensors. The model represents both healthy and faulty behaviors of the system. Marking trajectories which are consistent with the measurements issued from the sensors are first obtained. Based on the events dates, the probabilities of the consistent trajectories are evaluated and a state estimation is obtained as a consequence. From the set of possible current states and their probabilities, a method to evaluate the probability of future fault is developed using a probabilistic model. An example is presented to illustrate the results.	item unique identification;sensor;statistical model;stochastic petri net	Rabah Ammour;Edouard Leclercq;Eric Sanlaville;Dimitri Lefebvre	2016	2016 13th International Workshop on Discrete Event Systems (WODES)	10.1109/WODES.2016.7497890	real-time computing;simulation;stochastic petri net;computer science;machine learning	Robotics	-5.0463416265406105	7.289374535349125	165979
6143476f1db52fe257cec307c05ce0e8ab66cd4e	the expressive power of memory logics		We investigate the expressive power of memory logics. These are modal logics extended with the possibility to store (or remove) the current node of evaluation in (or from) a memory, and to perform membership tests on the current memory. From this perspective, the hybrid logic HL(↓), for example, can be thought of as a particular case of a memory logic where the memory is an indexed list of elements of the domain. This work focuses in the case where the memory is a set, and we can test whether the current node belongs to the set or not. We prove that, in terms of expressive power, the memory logics we discuss here lie between the basic modal logic K and HL(↓). We show that the satisfiability problem of most of the logics we cover is undecidable. The only logic with a decidable satisfiability problem is obtained by imposing strong constraints on which elements can be memorized. 1 Modal Logics and Memory Logics Nowadays, the term modal logics loosely refers to an extremely wide variety of languages, which are used in many different applications (see, e.g., (Blackburn et al., 2006)). Actually, the fact that the number of members in this family keeps constantly increasing is one of the defining characteristic of the field. While most modal logics have certain general aspects in common (e.g., they are usually interpreted in terms of relational structures and they are computationally well behaved), there usually are as many modal logics satisfying any of these “characterizing properties” as there are modal logics not honoring them. As a result, it is very hard indeed to come up with a proper definition of what a modal logic is. Perhaps one of the few general traits of the field is the desire to investigate languages specially tailored for specific tasks. In this article we investigate the expressive power of a family of modal logics called memory logics, which extend both the semantics and the syntax of the classical modal logic. Many logical properties of memory logics have been investigated in recent articles. The original idea was introduced in (Areces, 2007). Areces, Figueira, Goŕın, & Mera (2009) investigate tableau algorithms and model checking for memory logics, while Areces,	algorithm;boolean satisfiability problem;classical modal logic;evert willem beth;expressive power (computer science);hybrid logic;interpolation;logical connective;mera 300;method of analytic tableaux;mind;model checking;pspace-complete;random access;turing completeness;undecidable problem;word lists by frequency	Carlos Areces;Diego Figueira;Santiago Figueira;Sergio Mera	2011	Rew. Symb. Logic	10.1017/S1755020310000389	t-norm fuzzy logics;discrete mathematics;mathematics;algorithm	Logic	-11.722926029845354	9.028211943209968	166403
ba70cf8bd2cfc8d7bd80a47a4ec189f82f048989	a conceptual analysis of early arabic algebra	languages and literatures	Center for Logic and Philosophy of Science, Ghent University, Belgium e-mail: albrecht.heeffer@ugent.be Abstract Arabic algebra derives its epistemic value not from proofs but from correctly performing calculations using coequal polynomials. This idea of ‘mathematics as calculation’ had an important influence on the epistemological status of European mathematics until the seventeenth century. We analyze the basic concepts of early Arabic algebra such as the unknown and the equation and their subsequent changes within the Italian abacus tradition. We demonstrate that the use of these concepts has been problematic in several aspects. Early Arabic algebra reveals anomalies which can be attributed to the diversity of influences in which the al-jabr practice flourished. We argue that the concept of a symbolic equation as it emerges in algebra textbooks around 1550 is fundamentally different from the ‘equation’ as known in Arabic algebra.	email;polynomial	Albrecht Heeffer	2008		10.1007/978-1-4020-8405-8_4	arithmetic;natural language processing;computer science;linguistics	Security	-10.529096297261015	7.049706234300286	167201
34301e2840ec9b5a598322282b88f656b0a97bf5	a proof-theoretic approach to scope ambiguity in compositional vector space models		We investigate the extent to which compositional vector space models can be used to account for scope ambiguity in quantified sentences (of the form Every man loves some woman). Such sentences containing two quantifiers introduce two readings, a direct scope reading and an inverse scope reading. This ambiguity has been treated in a vector space model using bialgebras by [8] and [19], though without an explanation of the mechanism by which the ambiguity arises. We combine a polarised focussed sequent calculus for the non-associative Lambek calculus NL, as described in [16], with the vector based approach to quantifier scope ambiguity. In particular, we establish a procedure for obtaining a vector space model for quantifier scope ambiguity in a derivational way. ∗This is a preprint of a paper to appear in: Journal of Language Modelling, 2018.	categorial grammar;language model;nl (complexity);quantifier (logic);sequent calculus	Gijs Jasper Wijnholds	2018	CoRR		natural language processing;principle of compositionality;ambiguity;of the form;artificial intelligence;calculus;semantics;vector space;sequent calculus;computer science	NLP	-10.408260831550853	8.110093596425282	167401
014c1791073a9512105e15c79ac32199a62e3604	a refinement of de bruijn's formal language of mathematics	mathematics;weak type theory;type checking;mathematical vernacular;abstract syntax;type theory;formal language	syntax for the category of statementsis: S = CS (! P )jBSZ(E)jVS : Examples ofCS (! P ) were given in Example 2.3. An example of BSZ(E) (with the8-binder forBS ) was given in Section 2.5. 2.7.1. Typings and declarations A typing statement or typing, expresses the relation between something and its type. In WTT we have five kinds of typings, depending on the nature of the type. This type can be: SET (the type of all sets),STAT (the type of all statements), a set, a noun or an adjective. Each of these typing statements relates asubject(the left hand side) with itstype/predicate(the right hand side). The abstract syntax for the set T of typing statements ( T S ) is: T = S : SET jS : STAT jT : SjT :N jT : A : Here,s : SET , S: STAT , t : s, t : n andt : a stand fors is a set , S is a statement , is an element of s , t is nand t is a. Examples of these cases include: S tn2N(n 2) : SET, p^q : STAT, 32 N,9 AB : an edge of 4ABC, λx2R(x2) : differentiable. Clearly,T is a subcollection of CS (! P ), the set of relational statements, with symbol “:” as special element in CS . See also Section 3.7. At its turn, a subcollection of the typings is formed by the declarations,Z, where the subject is a variable: 10 Z = VS : SET jVS : STAT jVT :SjVT :N . Here the variableVS, VS or VT is theintroducedor declaredvariable. Subscripts of binders (Section 2.5) can be taken from Z.	abstract syntax;de bruijn graph;formal language;h.264/mpeg-4 avc;jt (visualization format);stat (system call)	Fairouz Kamareddine;Rob Nederpelt	2004	Journal of Logic, Language and Information	10.1023/B:JLLI.0000028393.47593.b8	abstract syntax;formal language;epistemology;computer science;artificial intelligence;pure mathematics;mathematics;linguistics;programming language;type theory;algorithm	Logic	-10.729968194307126	8.477360903228991	169036
4c9673db25968087ad01010193e37fe0bf059bf7	computational philosophy: on fairness in automated decision making		As more and more of our lives are taken over by automated decision making systems (whether it be for hiring, college admissions, criminal justice or loans), we have begun to ask whether these systems are making decisions that humans would consider fair, or non-discriminatory. The problem is that notions of fairness, discrimination, transparency and accountability are concepts in society and the law that have no obvious formal analog. But our algorithms speak the language of mathematics. And so if we want to encode our beliefs into automated decision systems, we must formalize them precisely, while still capturing the natural imprecision and ambiguity in these ideas. In this talk, I’ll survey the new field of fairness, accountability and transparency in computer science. I’ll focus on how we formalize these notions, how they connect to traditional notions in theoretical computer science, and even describe some impossibility results that arise from this formalization. I’ll conclude with some open questions. 1998 ACM Subject Classification F.2.2 Nonnumerical Algorithms and Problems, J.4 Social and Behavioral Sciences	algorithm;computation;encode;fairness measure;humans;theoretical computer science;transparency (graphic)	Suresh Venkatasubramanian	2017		10.4230/LIPIcs.ISAAC.2017.2	computer science;applied mathematics;discrete mathematics	Theory	-10.64157071252206	4.903139883483832	169498
68b1a32adf1f8b047d7107087bd18ef1f6ac3e47	a new mdl measure for robust rule induction (extended abstract)	rule induction;decision tree;minimum description length;information theoretic	We present a generalization of a particular Minimum Description Length (MDL) measure that sofar has been used for pruning decision trees only. The generalized measure is applicable to (propositional) rule sets directly. Furthermore the new measure also does not suuer from problems reported for various MDL measures in the ML literature. The new measure is information-theoretically plausible and yet still simple and therefore ee-ciently computable. It is incorporated in a propositional Foil-like learner called Knopf. We report on favorable results in various purely symbolic propositional domains. Both rule quality in terms of simplicity (and syntactic closeness to the respective underlying theory where known) and pre-dictive accuracy of induced theories are convincing.	centrality;computable function;decision tree;mdl (programming language);minimum description length;rule induction;theory	Bernhard Pfahringer	1995		10.1007/3-540-59286-5_80	machine learning;pattern recognition;data mining;mathematics	ML	-7.4907335765492515	6.805249954161022	170314
8b7558ca6403fd4c1995ea78496ed5d1e942bed3	extending the power watershed framework thanks to γ-convergence		In this paper, we provide a formal proof of the power-watershed framework relying on the Γ4 convergence framework. The main ingredient for the proof is a concept of scale. The proof and 5 the formalism introduced in this paper have the added benefit to clarify the algorithm, and to allow 6 to extend the applicability of the power watershed algorithm to many other types of energy functions. 7 Several examples of applications are provided, including Total Variation and Spectral Clustering. 8		Laurent Najman	2017	SIAM J. Imaging Sciences	10.1137/17M1118580		Theory	-5.450228597289557	9.518478057924915	170351
25f3b6da72f963afd68aba592c77ca8fcb808b73	on the definition of the classical connectives and quantifiers		Classical logic is embedded into constructive logic, through a definition of the classical connectives and quantifiers in terms of the constructive ones. The history of the notion of constructivity started with a dispute on the deduction rules that one should or should not use to prove a theorem. Depending on the rules accepted by the ones and the others, the proposition P ∨ ¬P , for instance, had a proof or not. A less controversial situation was reached with a classification of proofs, and it became possible to agree that this proposition had a classical proof but no constructive proof. An alternative is to use the idea of Hilbert and Poincaré that axioms and deduction rules define the meaning of the symbols of the language and it is then possible to explain that some judge the proposition P ∨ ¬P true and others do not because they do not assign the same meaning to the symbols ∨, ¬, etc. The need to distinguish several meanings of a common word is usual in mathematics. For instance the proposition “there exists a number x such that 2x = 1” is true of false depending on whether the word “number” means “natural number” or “real number”. Even for logical connectives, the word “or” has to be disambiguated into inclusive and exclusive. Taking this idea seriously, we should not say that the proposition P ∨ ¬P has a classical proof but no constructive proof, but we should say that the proposition P ∨c ¬cP has a proof and the proposition P ∨ ¬P does not, that is we should introduce two symbols for each connective and quantifier, for instance a symbol ∨ for the constructive disjunction and a symbol ∨c for the classical one, instead of introducing two judgments: “has a classical proof” and “has a constructive proof”. We should also be able to address the question of the provability of mixed propositions and, for instance, express that the proposition (¬(P ∧Q)) ⇒ (¬P ∨c ¬Q) has a proof. The idea that the meaning of connectives and quantifiers is expressed by the deduction rules leads to propose a logic containing all the constructive and ∗INRIA, 23 avenue d’Italie, CS 81321, 75214 Paris Cedex 13, France. gilles.dowek@inria.fr. classical connectives and quantifiers and deduction rules such that a proposition containing only constructive connectives and quantifiers has a proof in this logic if and only if it has a proof in constructive logic and a proposition containing only classical connectives and quantifiers has a proof in this logic if and only if it has a proof in classical logic. Such a logic containing classical, constructive, and also linear, connectives and quantifiers has been proposed by J.-Y. Girard [3]. This logic is a sequent calculus with unified sequents that contain a linear zone and a classical zone and rules treating differently propositions depending on the zone they belong. Our goal in this paper is slightly different, as we want to define the meaning of a small set of primitive connectives and quantifiers with deduction rules and define the others explicitly, in the same way the exclusive or is explicitly defined in terms of conjunction, disjunction and negation: A⊕ B = (A ∧ ¬B) ∨ (¬A ∧ B). A first step in this direction has been made by Gödel [4] who defined a translation of constructive logic into classical logic, and Kolmogorov [7], Gödel [5], and Gentzen [2] who defined a translation of classical logic into constructive logic. As the first translation requires a modal operator, we shall focus on the second. This leads to consider constructive connectives and quantifiers as primitive and search for definitions of the classical ones. Thus, we want to define classical connectives and quantifiers ⊤c, ⊥c, ¬c, ∧c, ∨c, ⇒c, ∀c, and ∃c and embed classical propositions into constructive logic with a function ‖ ‖ defined as follows.	embedded system;exclusive or;gödel;hilbert space;intuitionistic logic;logical connective;modal operator;natural deduction;quantifier (logic);sequent calculus;term (logic)	Gilles Dowek	2013	CoRR		zeroth-order logic;discrete mathematics;mathematics;bounded quantifier;constructive analysis;atomic formula;algorithm;prenex normal form	Logic	-11.714840124189083	6.745421151633834	172416
150bcf6d538ae80b9c4cb06fbcce1d139ecc98e8	a lambda calculus for real analysis	lambda calculus	Abstract Stone Duality is a new paradigm for general topology in which computable continuous functions are described directly, without using set theory, infinitary lattice theory or a prior theory of discrete computation. Every expression in the calculus denotes both a continuous function and a program, and the reasoning looks remarkably like a sanitised form of that in classical topology. This is an introduction to ASD for the general mathematician, with application to elementary real analysis. This language is applied to the Intermediate Value Theorem: the solution of equations for continuous functions on the real line. As is well known from both numerical and constructive considerations, the equation cannot be solved if the function “hovers” near 0, whilst tangential solutions will never be found. In ASD, both of these failures, and the general method of finding solutions of the equation when they exist, are explained by the new concept of overtness. The zeroes are captured, not as a set, but by higher-type modal operators. Unlike the Brouwer degree of a mapping, these are naturally defined and (Scott) continuous across singularities of a parametric equation. Expressing topology in terms of continuous functions rather than using sets of points leads to treatments of open and closed concepts that are very closely lattice(or de Morgan-) dual, without the double negations that are found in intuitionistic approaches. In this, the dual of compactness is overtness. Whereas meets and joins in locale theory are asymmetrically finite and infinite, they have overt and compact indices in ASD. Overtness replaces metrical properties such as total boundedness, and cardinality conditions such as having a countable dense subset. It is also related to locatedness in constructive analysis and recursive enumerability in recursion theory. 2000 Mathematics Subject Classification 03F60 (primary); 54D05 03D45 68N18 68Q55 (secondary)	brouwer fixed-point theorem;computability theory;computable function;computation;de morgan's laws;lambda calculus;mathematics subject classification;modal operator;numerical analysis;programming paradigm;recursion (computer science);recursively enumerable set;scott continuity;set theory;while	Paul Taylor	2005	J. Logic & Analysis		system f;fixed-point combinator;typed lambda calculus;binary lambda calculus;lambda calculus;simply typed lambda calculus;mathematics;church encoding	Logic	-6.8100340488826	11.123943497323612	172422
e6ca54b62972da8c049b8ce6932bf4d958617f90	a simplified account of validity and implication for quantificational logic				Hugues Leblanc	1968	J. Symb. Log.		discrete mathematics;algorithm;mathematics	Logic	-11.015702370725494	10.633367152731639	172836
ceb90588b49f4af3b06af7edd7b81540ffd2ca99	formal languages and their relation to automata	turing machine;context-free grammar;automata theory;language theory;context-sensitive grammar;coherent theory;computer science;natural language;formal language;automata equivalent	New updated! The latest book from a very famous author finally comes out. Book of formal languages and their relation to automata, as an amazing reference becomes what you need to get. What's for is this book? Are you still thinking for what the book is? Well, this is what you probably will get. You should have made proper choices for your better life. Book, as a source that may involve the facts, opinion, literature, religion, and many others are the great friends to join with.	automata theory;automaton;formal language;introduction to automata theory, languages, and computation	John E. Hopcroft;Jeffrey D. Ullman	1969			formal language;nested word;chomsky hierarchy;formal semantics;automata theory;cone;ontology language;abstract family of languages;computability;second-generation programming language	PL	-10.293691851376554	8.223047127638765	173981
dadbf840df98d1e72964505b6c6ba7da876e937c		total order;fuzzy set;procesamiento informacion;conjunto difuso;ensemble flou;information processing;decidibilidad;theorie information;traitement information;decidabilite;information theory;decidability;teoria informacion	Abstract   For finite  L -fuzzy machines we develop behaviour, reduction and minimization theory. Here  L  stands for ( L ,∨,∧,0,1), where  L  is a totally ordered set with universal bounds 0 and 1 and the operations are join ∨ and meet ∧. The most essential results include investigating behaviour, equivalence, reduction and minimization problems and their algorithmical decidability.		Ketty Peeva	2004	Fuzzy Sets and Systems	10.1016/S0165-0114(02)00609-7	decidability;discrete mathematics;information processing;information theory;computer science;artificial intelligence;mathematics;fuzzy set;total order;algorithm;statistics	Robotics	-6.789822557266591	9.645014979439479	175177
112459b4c24fc20db8ce345f8a9f671937d76cf1	effective categoricity of injection structures	computable injection structure;computability theoretic property;effective categoricity	We study computability theoretic properties of computable injection structures and the complexity of isomorphisms between these structures.	computability;computable function;graph isomorphism;theory	Douglas A. Cenzer;Valentina S. Harizanov;Jeffrey B. Remmel	2011		10.1007/978-3-642-21875-0_6	theoretical computer science;algorithm	Logic	-6.709060792974144	10.109048148121031	176651
fa4d72d46aa294d6e0719a46f8cedc5b582c6004	jiha/tropos-mādda/hūlē distinction in arabic logic and its significance for avicenna's modals		The word, tropos, translated in Arabic as jiha, is understood in the field of logic as mode. Though investigations of modals in the medieval Arabo-Islamic logical tradition  trace their lineage back to Aristotle, the Greek word designating this concept was never used in this manner by the Stagirite.  The closest word that the Arabic jiha translates from Greek is tropos, which was a technical term that gradually developed with Aristotle’s commentators. The word came to be understood as part  of a dichotomy, tropos-hûlç, which was inherited by the Arabs as jiha-mādda This dichotomy seems to have become a determining factor for conversion rules of modal propositions and thus for modal syllogistic.  After an investigation outlining the evolution of the term tropos and the development of the dichotomy tropos-hûlç in the Commentary tradition of modal logic, the article presents philological evidence for their influence on Avicenna. It  then briefly discuss the ramifications of this influence for his modal conversion rules and syllogistic. In sum, the article  argues that the jiha-mādda (tropos-hûlç) division was part of a larger dichotomy that allowed Avicenna to construe propositions in various ways. How he understood  a given proposition determined the validity of its conversion and so of its place in his modal syllogistic.  		Asad Ahmed	2008		10.1007/978-1-4020-8405-8_8	humanities;philosophy;linguistics;literature	NLP	-11.245783615917569	6.113674924285929	176971
4264cef5840962bbf9086f2ac5610ce40a0f1b4c	fuzzy semantics for a natural-like language defined over a world of blocks	fuzzy set;natural language understanding	"""Winograd used a toy world called BLOCKS for his famous """"natural language understanding"""" system SHRDLU. In this world all distinct objects are equally distinct: a red-orange block is no closer to being a red block than to being a black block; and a rather large block is no closer to being a large block than to being a small block. This paper presents an APL package which gives a fuzzy set semantics for a limited English-like language (in which red-orange is near to red and so on), in a manner which is convenient for <u>reference</u>: the system accepts instructions in the form of simple indicative sentences, and demonstrates its """"understanding"""" by indicating the block which is the intended referent. The work is based on the principle of maximum meaningfulness"""" and is robust, in the sense that small changes in the instructions or in the state of the world do not disturb it."""	apl;coppersmith–winograd algorithm;fuzzy logic;fuzzy set;natural language understanding;shrdlu	Efraim Shaket	1977	SIGART Newsletter	10.1145/1045283.1045322	computer science;artificial intelligence;linguistics;fuzzy set;programming language;algorithm	NLP	-10.99433844501423	7.282219870152104	177236
034e226d6e15a4eae5759b2cabbda161257a5e76	on an axiomatic characterization of entropy of order α (theoretic measure)			theory	A. Basar Khan	1979	Kybernetika		discrete mathematics;mathematical optimization;mathematics;axiom	Vision	-6.797850456408551	10.045266058336141	177829
682efc58cba248f0f2c121f1c76454dbb783a6bc	probabilistic rule realization and selection		Abstraction and realization are bilateral processes that are key in deriving intelligence and creativity. In many domains, the two processes are approached through rules: high-level principles that reveal invariances within similar yet diverse examples. Under a probabilistic setting for discrete input spaces, we focus on the rule realization problem which generates input sample distributions that follow the given rules. More ambitiously, we go beyond a mechanical realization that takes whatever is given, but instead ask for proactively selecting reasonable rules to realize. This goal is demanding in practice, since the initial rule set may not always be consistent and thus intelligent compromises are needed. We formulate both rule realization and selection as two strongly connected components within a single and symmetric bi-convex problem, and derive an efficient algorithm that works at large scale. Taking music compositional rules as the main example throughout the paper, we demonstrate our model’s efficiency in not only music realization (composition) but also music interpretation and understanding (analysis).ion and realization are bilateral processes that are key in deriving intelligence and creativity. In many domains, the two processes are approached through rules: high-level principles that reveal invariances within similar yet diverse examples. Under a probabilistic setting for discrete input spaces, we focus on the rule realization problem which generates input sample distributions that follow the given rules. More ambitiously, we go beyond a mechanical realization that takes whatever is given, but instead ask for proactively selecting reasonable rules to realize. This goal is demanding in practice, since the initial rule set may not always be consistent and thus intelligent compromises are needed. We formulate both rule realization and selection as two strongly connected components within a single and symmetric bi-convex problem, and derive an efficient algorithm that works at large scale. Taking music compositional rules as the main example throughout the paper, we demonstrate our model’s efficiency in not only music realization (composition) but also music interpretation and understanding (analysis).	algorithm;bilateral filter;convex optimization;high- and low-level;strongly connected component	Haizi Yu;Tianxi Li;Lav R. Varshney	2017			machine learning;computer science;artificial intelligence;probabilistic logic;creativity;strongly connected component;abstraction;composition (visual arts);realization (systems)	ML	-6.285437480847337	4.946464971720266	177968
6066570f5a327dfbd461cb26937427cfbac1a460	mechanized reasoning for continuous problem domains (invited talk)		Specification and verification in continuous problem domains are key topics for the practical application of formal methods and mechanized reasoning. I discuss one approach to linear continuous control systems and consider the challenges and opportunities raised for mechanized reasoning. These include practical implementation and integration issues, algorithms in computational real algebraic geometry and hard open questions such as the Schanuel conjecture. I conclude with an overview of some recent new results on decidability and undecidability for vector spaces and related theories.	algorithm;control system;decision problem;formal methods;linear algebra;problem domain;theory;undecidable problem	Rob Arthan	2008			mechanics;algorithm;computer science;particulates;specific gravity	Logic	-7.799675348632295	8.670407089517212	178496
20db33dad6dfbbf356ac2b997b443639d5eac099	differential recursion and differentially algebraic functions	computational complexity;differential algebra	Moore introduced a class of real-valued “recursive” functions by analogy with Kleene’s formulation of the standard recursive functions. While his concise definition inspired a new line of research on analog computation, it contains some technical inaccuracies. Focusing on his “primitive recursive” functions, we pin down what is problematic and discuss possible attempts to remove the ambiguity regarding the behavior of the differential recursion operator on partial functions. It turns out that in any case the purported relation to differentially algebraic functions, and hence to Shannon’s model of analog computation, fails.	analog computer;computation;differential cryptanalysis;linear algebra;primitive recursive function;recursion (computer science);shannon (unit)	Akitoshi Kawamura	2007	CoRR			Theory	-10.01340007189211	6.490175855264143	180701
a0b926309c2192b158d5ab441d3b24df9abd04a0	the development and prospects for category theory	category theory	This paper is a formulation of my personal opinion of the historical development and the present prospects of category theory.	category theory	Saunders Lane	1996	Applied Categorical Structures	10.1007/BF00122247	calculus;pure mathematics;mathematics	Logic	-10.411044883306742	10.867451711500461	183546
0db264342277682b0e6dfc2b93a22f531f6b00c7	schemata: the concept of schema in the history of logic	number theory;string theory;complex system;set theory;propositional logic;first order;schemata;second order	Schemata have played important roles in logic since Aristotle’s Prior Analytics. The syllogistic figures and moods can be taken to be argument schemata as can the rules of the Stoic propositional logic. Sentence schemata have been used in axiomatizations of logic only since the landmark 1927 von Neumann paper [31]. Modern philosophers know the role of schemata in explications of the semantic conception of truth through Tarski’s 1933 Convention T [42]. Mathematical logicians recognize the role of schemata in first-order number theory where Peano’s second-order Induction Axiom is approximated by Herbrand’s Induction-Axiom Schema [23]. Similarly, in first-order set theory, Zermelo’s second-order SeparationAxiom is approximated by Fraenkel’s first-order Separation Schema [17]. In some of several closely related senses, a schema is a complex system having multiple components one of which is a template-text or scheme-template, a syntactic string composed of one or more “blanks” and also possibly significant words and/or symbols. In accordance with a side condition the template-text of a schema is used as a “template” to specify a multitude, often infinite, of linguistic expressions such as phrases, sentences, or argument-texts, called instances of the schema. The side condition is a second component. The collection of instances may but need not be regarded as a third component. The instances are almost always considered to come from a previously identified language (whether formal or natural), which is often considered to be another component. This article reviews the often-conflicting uses of the expressions ‘schema’ and ‘scheme’ in the literature of logic. It discusses the different definitions presupposed by those uses. And it examines the ontological and epistemic presuppositions circumvented or mooted by the use of schemata, as well as the ontological and epistemic presuppositions engendered by their use. In short, this paper is an introduction to the history and philosophy of schemata. §	approximation algorithm;complex system;database schema;first-order predicate;mathematical induction;propositional calculus;stoic;set theory	John Corcoran	2006	Bulletin of Symbolic Logic		axiom schema;number theory;logical schema;epistemology;computer science;artificial intelligence;first-order logic;schema;mathematics;linguistics;propositional calculus;string theory;programming language;second-order logic;algorithm;set theory;algebra	AI	-11.714063871411863	7.389855899765365	184247
631a3368ba95d0a9b5ef58a01b6a40c075dbd19a	language asp{f} with arithmetic expressions and consistency-restoring rules		In this paper we continue the work on our extension of Answer Set Programming by non-Herbrand functions and add to the language support for arithmetic expressions and various inequality relations over non-Herbrand functions, as well as consistency-restoring rules from CR-Prolog. We demonstrate the use of this latest version of the language in the representation of important kinds of knowledge.	answer set programming;computation;prolog;prototype;social inequality;solver;stable model semantics	Marcello Balduccini;Michael Gelfond	2012	CoRR		arithmetic;herbrand's theorem;ground expression;mathematics;algorithm	NLP	-11.63232897554214	11.031832499942485	184750
6414d5a63a5ecfaf65d77b905da19ebe9407c9a8	arbitrary truth-value functions and natural deduction	natural deduction;value function	ih t h Teaching student.: HENKIN’S completeness proof for first order predicate logic it helpful first, to deal with the simpler case of propositional logic. For most students tis is their first encounter with a non-trivial result in mathematical logic, and to make them appreciate the workings of this beautiful argument it is instructive to let them carry it out in a variety of settings: for different choices of primitive connectives, or for fregnients of the full logic. The reader who hah not thought about this for a ~ v h i l e may try his own hand a t one example: t o axiomatize the fragment of nonequivalence, + (exclusive disjunction). To be sure, this fragment is a logic without theorems, but a characterization in terms of Gentzen sequents or natural deduction i\ still possible.	exclusive or;first-order logic;logical connective;natural deduction;propositional calculus;sequent calculus	Krister Segerberg	1983	Math. Log. Q.	10.1002/malq.19830291102	deduction theorem;mathematics;bellman equation;sequent calculus;natural deduction	AI	-11.319995340762913	7.410584474121894	184841
f2063876aa7ed949356728247d70695e7370d31f	prudence in vacillatory language identification	natural language;language identification;learning theory;formal language	This paper settles a question about “prudent” “vacillatory” identification of languages. Consider a scenario in which an algorithmic deviceM is presented with all and only the elements of a languageL, andM conjectures a sequence, possibly infinite, of grammars. Three different criteria for success ofM onL have been extensively investigated in formal language learning theory. IfM converges to a single correct grammar forL, then the criterion of success is Gold's seminal notion ofTxtEx-identification. IfM converges to a finite number of correct grammars forL, then the criterion of success is calledTxtFex-identification. Further, ifM, after a finite number of incorrect guesses, outputs only correct grammars forL (possibly infinitely many distinct grammars), then the criterion of success is known asTxtBc-identification. A learning machine is said to beprudent according to a particular criterion of success just in case the only grammars it ever conjectures are for languages that it can learn according to that criterion. This notion was introduced by Osherson, Stob, and Weinstein with a view to investigating certain proposals for characterizing natural languages in linguistic theory. Fulk showed that prudence does not restrictTxtEx-identification, and later Kurtz and Royer showed that prudence does not restrictTxtBc-identification. This paper shows that prudence does not restrictTxtFex-identification.	formal language;language identification;natural language;royer oscillator	Sanjay Jain;Arun Sharma	1995	Mathematical systems theory	10.1007/BF01303059	natural language processing;language identification;combinatorics;formal language;computer science;artificial intelligence;learning theory;mathematics;natural language;algorithm	NLP	-9.64009385419209	6.9729164957554115	185227
1845b7006b9ecb80c505518ce7bc4a240c1a9c70	on the notion of universality of turing machine		Several years later, A. Minsky showed a simple example of UTM: (M5) There is a UTM having 6 states and 7 symbols. Recently, S. Watanabe (University of Tokyo) demonstrated an extremely simple machine which is also universal in a sense. (W6) There is a UTM having 3 states and 7 symbols.* It seems strange, however, that there is no general definition of the notion of universality: these scholars used implicitly their particular definitions which were quite different from each other at several points. In fact, there arise some delicate	universal transverse mercator coordinate system;universal turing machine;universality probability	Akihiro Nozaki	1969	Kybernetika		non-deterministic turing machine;mathematics;turing machine examples;probabilistic turing machine;nspace;turing machine;wolfram's 2-state 3-symbol turing machine;algorithm characterizations;universal turing machine;algorithm	Theory	-9.29579423458206	6.885940428825514	186909
46c37b2c89c5c9bd923b595091590a277af4b905	magidor-like and radin-like forcing	logique mathematique;theorie ensemble;theorie modeles;set theory;mathematical logic;forcing;forcage;model theory	We force over a model M of ZF+ K + (K)<? to obtain M[G] with cf(K) = y. The method is reminiscent of Magidor-forcing but uses no choice. Mimicing Radin-forcing, we generalize this for strong partition cardinals K to add a subset of K while preserving all cardinalities, cofinalities and K’S measurability. We apply these techniques to construct models of unusual partition properties, such as oa + [wJwl but 02w[oa]“‘.	model m keyboard	James M. Henle	1983	Ann. Pure Appl. Logic	10.1016/0168-0072(83)90054-4	combinatorics;mathematical logic;forcing;calculus;mathematics;model theory;set theory;algebra	Logic	-6.993654639989604	11.107441430373964	190573
847679c8e247258cb758537fe497dca7f62a34e7	some remarks on conservative extensions: a socratic dialogue				Paulo A. S. Veloso;Sheila R. M. Veloso	1991	Bulletin of the EATCS		theoretical computer science;mathematics education;mathematics;socratic dialogue	NLP	-8.83312366540147	7.995517538246415	190601
24e15ad340c53e8522af905c4f63db5dadb26b65	the loom-lag for syntax analysis : adding a language-independent level to lag	conference paper	The left-associative grammar model (LAG) has been applied successfully to the morphologic and syntactic analysis of various european and asian languages. The algebraic definition of the LAG is very well suited for the application to natural language processing as it inherently obeys de Saussure's second law (de Saussure, 1913, p. 103) on the linear nature of language, which phrase-structure grammar (PSG) and categorial grammar (CG) do not. This paper describes the so-called Loom-LAGs (LLAG) —a specialisation of LAGs for the analysis of natural language. Whereas the only means of language-independent abstraction in ordinary LAG is the principle of possible continuations, LLAGs introduce a set of more detailed language-independent generalisations that form the so-called loom of a Loom-LAG. Every LLAG uses the very same loom and adds the language-specific information in the form of a declarative description of the language —much like an ancient mechanised Jacquard-loom would take a program-card providing the specific pattern for the cloth to be woven. The linguistic information is formulated declaratively in so-called syntax plans that describe the sequential structure of clauses and phrases. This approach introduces the explicit notion of phrases and sentence structure to LAG without violating de Saussure's second law and without leaving the ground of the original algebraic definition of LAG. LLAGs can in fact be shown to be just a notational variant of LAG —but one that is much better suited for the manual development of syntax grammars for the robust analysis of free texts. 1 Background — The Left-Associative Grammar Model (LAG) As the reader may not be familiar with the model of left-associative grammar (LAG), this section starts with a brief introduction to LAG', which the reader familiar with LAG may well skip. Most attempts at grammar acquisition and grammar coding are based on variants of PSgrammar. For reasons of complexity, these PS-grammars must be context-free (CF). It is widely agreed, however, that the class of context-free languages is not sufficient for the description of natural language. Hence these approaches suffer from an inherent empirical restriction. The approach presented in this paper is based on the formalism of Left Associative Grammar (LAG, (Hausser, 1989)). While PS-grammar is based on the principle of possible substitutions, LA-grammar uses the principle of possible continuations. This difference results in a complexity hierarchy which is orthogonal to the well-known Chomsky hierarchy. 'For an in-depth discussion see (Hausser, 1989), and (Hausser, 2001).	categorial grammar;chomsky hierarchy;context-free language;continuation;formal system;indexed grammar;language-independent specification;linear algebra;loom;natural language processing;operator associativity;parsing;phrase structure grammar;whole earth 'lectronic link	Markus Schulze	2002			speech recognition;computer science;algorithm	NLP	-9.933983653526484	8.265052944564655	191034
1781f7ce9fbe8bbc1840b35d0754d8d225b1f54d	predictive combinators: a method for efficient processing of combinatory categorial grammars	predictive combinators;present work;functional composition;specialized combinators;efficient processing;node raising;semantically equivalent;forthcoming work;grammatical category;categorial grammar;combinatory categorial grammars;orginal basic combinators;combinatory categorial grammar	"""A B S T R A C T Steedman (1985, 1987) and others have proposed that Categorial Grammar, a theory of syntax in which grammatical categories are viewed as functions, be augmented with operators such as functional composition and type raising in order to analyze • noncanonical"""" syntactic constructions such as whextraction and node raising. A consequence of these augmentations is an explosion of semantically equivalent derivations admitted by the grammar. The present work proposes a method for circumventing this spurious ambiguity problem. It involves deriving new, specialized combinators and replacing the orginal basic combinators with these derived ones. In this paper, examples of these predictive combin~tor8 are offered and their effects illustrated. An algorithm for deriving them, as well as s discussion of their semantics, will be presented in forthcoming work."""	algorithm;combinatory categorial grammar;combinatory logic;mark steedman;theory	Kent Wittenburg	1987			natural language processing;generative grammar;categorial grammar;link grammar;computer science;linguistics;programming language;mildly context-sensitive grammar formalism;combinatory categorial grammar;algorithm	NLP	-9.841859977015247	8.401003573965554	191869
5fbde1ff3a5f9c526d3ee3246a244becdea7d5f0	the assimilation of aristotelian and arabic logic up to the later thirteenth century	aristotelian logic;bepress selected works;aristotelian logic arabic logic logic language;arabic logic		data assimilation	Henrik Lagerlund	2008		10.1016/S1874-5857(08)80026-X	philosophy;law of thought;linguistics;literature;logic;term logic;algorithm;philosophy of logic	Logic	-10.696769355611083	7.001163814902955	192501
318f45b9ab474bbd7f7120ee811ea249004eab5a	brouwer's weak counterexamples and testability: further remarks		Straightforwardly and strictly intuitionistic inferences show that the Brouwer– Heyting–Kolmogorov (BHK) interpretation, in the presence of a formulation of the recognition principle, entails the validity of the Law of Testability: that the form ¬ f V ¬¬ f is valid. Therefore, the BHK and recognition, as described here, are inconsistent with the axioms both of intuitionistic mathematics and of Markovian constructivism. This finding also implies that, if the BHK and recognition are suitably formulated, then Brouwer’s original weak counterexample reasoning was fallacious. The results of the present article extend and refine those of McCarty, C. (2012). Antirealism and Constructivism: Brouwer’s Weak Counterexamples. The Review of Symbolic Logic. First View. Cambridge University Press. §	brouwer fixed-point theorem;brouwer–heyting–kolmogorov interpretation;social constructivism;software testability	Charles McCarty	2013	Rew. Symb. Logic	10.1017/S1755020313000051		AI	-9.63110119429641	10.596634984562918	193876
13cdd05c04111578ad5bf286623dfdd9ccca1640	employee timetabling, constraint networks and knowledge-based rules: a mixed approach	knowledge based system;knowledge base	Employee Timetabling Problems (ETP) are all around us. One possible approach for solving ETPs is to use constraint processing techniques. Another approach that has been used many times in the past is to model human knowledge into knowledge-based systems for timetabling. It is diicult to represent the complex constraints of timetabling explicitly in constraint networks. On the other hand, knowledge-based representations of constraints are implicit and cannot support any of the heuristics of constraint based processing that have been developed over the last decade. The present report presents an apptoach to representing and processing employee timetabling problems (ETP) by a combination of explicit representations of some constraints in the network and rule-based processing in which spe-ciic heuristics for generic constraints of ETPs are embedded. The mixed-mode approach described above has been implemented in the form of a commercial software package for deening and solving real world ETPs. Examples of a family of real world ETPs are followed through the presentation and are quantitatively used to experimentally compare processing by standard CSP techniques and by the proposed mixed-mode approach.	commercial software;embedded system;experiment;heuristic (computer science);knowledge-based systems;logic programming;mixed-signal integrated circuit	Amnon Meisels;Ehud Gudes;Gadi Solotorevsky	1995		10.1007/3-540-61794-9_53	simulation;systems engineering;artificial intelligence;knowledge-based systems	AI	-5.498556939914905	6.315903927911399	194640
1d2682e1ee73f71ad21ab2dc05471ac8f4ab2b39	"""from """"illustration"""" to """"interpretation"""" - using concrete elements to represent abstract concepts in spatial design"""				Li-Yu Chen;Ya-Juan Gao	2016		10.1007/978-3-319-40093-8_16	structural engineering;pure mathematics;mathematics;engineering drawing	Logic	-6.3158252314169845	7.873601684201453	195432
ae16ab033bf0d1791602e3d9e929a167808658dc	on continuity of incomplete preferences		A weak (strict) preference relation is continuous if it has a closed (open) graph; it is hemicontinuous if its upper and lower contour sets are closed (open). If preferences are complete these four conditions are equivalent. Without completeness continuity in each case is stronger than hemicontinuity. This paper provides general characterizations of continuity in terms of hemicontinuity for weak preferences that are modeled as (possibly incomplete) preorders and for strict preferences that are modeled as strict partial orders. Some behavioral implications associated with the two approaches are also discussed.		Georgios Gerasimou	2013	Social Choice and Welfare	10.1007/s00355-012-0673-3	mathematical optimization;mathematical analysis;discrete mathematics;mathematics	AI	-7.6657419417490775	10.211803288910259	195681
142c7c8ad2e0c4d4e1a912003194f81dcb32b2b8	degrees of unsolvability		Modern computability theory began with Turing [Turing, 1936], where he introduced the notion of a function computable by a Turing machine. Soon after, it was shown that this definition was equivalent to several others that had been proposed previously and the Church-Turing thesis that Turing computability captured precisely the informal notion of computability was commonly accepted. This isolation of the concept of computable function was one of the greatest advances of twentieth century mathematics and gave rise to the field of computability theory. Among the first results in computability theory was Church and Turing’s work on the unsolvability of the decision problem for first-order logic. Computability theory to a great extent deals with noncomputable problems. Relativized computation, which also originated with Turing, in [Turing, 1939], allows the comparison of the complexity of unsolvable problems. Turing formalized relative computation with oracle Turing machines. If a set A is computable relative to a set B, we say that A is Turing reducible to B. By identifying sets that are reducible to each other, we are led to the notion of degree of unsolvability first introduced by Post in [Post, 1944]. The degrees form a partially ordered set whose study is called degree theory. Most of the unsolvable problems that have arisen outside of computability theory are computably enumerable (c.e.). The c.e. sets can intuitively be viewed as unbounded search problems, a typical example being those formulas provable in some effectively given formal system. Reducibility allows us to isolate the most difficult c.e. problems, the complete problems. The standard method for showing that a c.e. problem is undecidable is to show that it is complete. Post [Post, 1944] asked if this technique always works, i.e., whether there is a noncomputable, incomplete c.e. set. This problem came to be known as Post’s Problem and it was origin of degree theory. Degree theory became one of the core areas of computability theory and attracted some of the most brilliant logicians of the second half of the twentieth century. The fascination with the field stems from the quite sophisticated techniques needed to solve the problems that arose, many of which are quite easy to state. The hallmark of the field is the priority method introduced by	church–turing thesis;computability theory;computable function;computation;decision problem;embedded system;fascination;first-order logic;first-order predicate;formal system;google summer of code;graph coloring;handbook;provable security;recursion;recursively enumerable set;self-information;separable polynomial;simpson's rule;thomason collection of civil war tracts;turing degree;turing machine;turing reduction;undecidable problem;vhdl-ams;μ operator	Klaus Ambos-Spies;Peter A. Fejer	2014		10.1016/B978-0-444-51624-4.50010-1	turing;discrete mathematics;undecidable problem;computable function;decision problem;turing degree;computability theory;turing machine;computability;mathematics	Theory	-8.91321950522157	9.028592852169067	196168
0f0d52837bc18a1a01a6b25cbd64d7769651ad51	knowledge bases over algebraic models. some notes about informational equivalence	knowledge management;mathematical approach;informational equivalence;algebraic model;logic in computer science;knowledge base	This paper discusses the informational equivalence problem for knowledge bases. The authors show that using some mathematical approach it is possible to attack this problem and end up with an implementable algorithm. An essential part of the paper is devoted to the explanation of the mathematical idea which stands behind this algorithm. The authors try to do that in common terms or, at least, in less formal terms. In the second part of the paper mathematical methods are applied to study the properties of automorphic equivalence of knowledge bases multi-models and show that this notion is much wider than the total isomorphism identity of knowledge bases. In order to make the paper self-contained, the reader is provided with the formal definition of a knowledge base. Further development of the theoretical approach presented in the paper can lead to practical applications. For example, it can be used for preventing duplication of information in knowledge bases and in other tasks of improving knowledge management.	linear algebra;social proof;turing completeness	Marina Knyazhansky;Tatjana L. Plotkin	2012	IJKM	10.4018/jkm.2012010102	knowledge base;computer science;knowledge management;body of knowledge;mathematical knowledge management;knowledge-based systems;procedural knowledge;algorithm	Theory	-10.85865897616842	5.79456198388323	197739
0296197ec96651bed88d3d1c330a57441fb02033	boole's criteria for validity and invalidity	countermodel show invalidity;aristotle;existential import;boole s solutions fallacy;premise conclusion argument;george boole;deductions show validity;boolean logic;alfred tarski;solving versus deducing	It is one thing for a given proposition to follow or to not follow from a given set of propositions and it is quite another thing for it to be shown either that the given proposition follows or that it does not follow.* Using a formal deduction to show that a conclusion follows and using a countermodel to show that a conclusion does not follow are both traditional practices recognized by Aristotle and used down through the history of logic. These practices presuppose, respectively, a criterion of validity and a criterion of invalidity each of which has been extended and refined by modern logicians: deductions are studied in formal syntax (proof theory) and coun-termodels are studied in formal semantics (model theory).		John Corcoran;Susan Wood	1980	Notre Dame Journal of Formal Logic	10.1305/ndjfl/1093883246	boolean algebra;boole's syllogistic;philosophy;epistemology;syllogism;mathematics;algorithm;algebra	Logic	-11.549047902738446	7.771043742155653	198147
2c5b6186411cfa9dc9edd3d04072ab5a23e266e2	logical bell inequalities		Bell inequalities play a central rôle in the study of quantum non-locality and entanglement, with many applications in quantum information. Despite the huge literature on Bell inequalities, it is not easy to find a clear conceptual answer to what a Bell inequality is, or a clear guiding principle as to how they may be derived. In this paper, we introduce a notion of logical Bell inequality which can be used to systematically derive testable inequalities for a very wide variety of situations. There is a single clear conceptual principle, based on purely logical consistency conditions, which underlies our notion of logical Bell inequalities. We show that in a precise sense, all Bell inequalities can be taken to be of this form. Our approach is very general. It applies directly to any family of sets of commuting observables. Thus it covers not only the n-partite scenarios to which Bell inequalities are standardly applied, but also Kochen-Specker configurations, and many other examples. There is much current work on experimental tests for contextuality. Our approach directly yields, in a systematic fashion, testable inequalities for a very general notion of contextuality. There has been much work on obtaining proofs of Bell’s theorem ‘without inequalities’ or ‘without probabilities’. These proofs are seen as being in a sense more definitive and logically robust than the inequality-based proofs. On the hand, they lack the fault-tolerant aspect of inequalities. Our approach reconciles these aspects, and in fact shows how the logical robustness can be converted into systematic, general derivations of inequalities with provable violations. Moreover, the kind of strong non-locality or contextuality exhibited by the GHZ argument or by Kochen-Specker configurations can be shown to lead to maximal violations of the corresponding logical Bell inequalities. Thus the qualitative and the quantitative aspects are combined harmoniously.	bell state;bell's theorem;fault tolerance;kochen–specker theorem;locality of reference;logical connective;maximal set;observable;provable security;quantum entanglement;quantum information;social inequality	Samson Abramsky;Lucien Hardy	2012	CoRR	10.1103/PhysRevA.85.062114	counterfactual definiteness;chsh inequality;local hidden variable theory;principle of locality;quantum mechanics;bell test experiments	ML	-8.391430922363824	9.640615021969587	198150
31896024b91429b0fd514313449af18df3de052f	protection in operating systems	operating system	A model of protection mechanisms in computing systems is presented and its appropriateness is argued. The “safety” problem for protection systems under this model is to determine in a given situation whether a subject can acquire a particular right to an object. In restricted cases, it can be shown that this problem is decidable, i.e. there is an algorithm to determine whether a system in a particular configuration is safe. In general, and under surprisingly weak assumptions, it cannot be decided if a situation is safe. Various implications of this fact are discussed.		Dennis Tsichritzis	1972	Inf. Process. Lett.	10.1016/0020-0190(72)90044-0	computer science;mathematics	DB	-11.733658563078034	4.283690194992993	198304
e88c13e97ef049b42161d5a3f736f52b70315556	a theory of restricted quantification ii		In Part I of this paper no official significance was given to free occurrences of restricted-variables. Indeed doubt has been expressed as to the desirability or feasibility of such usage. Thus, to quote from Rosser [4], p. 146: “We now raise the question of the significance of F ( α ), in which the occurrences of α are free [ α a variable subject to the restriction K ( α )]. In deciding to take ( x ). K(x) ⊃ F(x) and (Ex) . K(x) . F(x) as the meanings of ( α ) F ( α ) and ( Eα ) F ( α ), we were guided by the intuitive meanings. In the case of F ( α ), the intuitive meaning does not furnish a satisfactory guide. In everyday mathematics, if it has been agreed that α stands for a quantity satisfying the restriction K ( α ), it is commonly the case that, if one is assuming F ( α ), then K ( α )u0026 F ( α ) is understood, but if one is trying to prove F ( α ), then K ( α ) ⊃ F ( α ) is understood. It seems that in symbolic logic perhaps it is best not to give any especial significance to α in F ( α ) when it occurs free.” Despite this anomalous behaviour we shall, in this Part, show how one can have unhampered use of free restricted-variables in appropriate contexts.		Theodore Hailperin	1957	J. Symb. Log.		mathematical logic;algebra;discrete mathematics;mathematics	Logic	-11.49476999874836	5.949841025997104	198693
7368a737fd8fd000126055c71326f42f03d7604e	every functionally complete m-valued logic has a post-complete axiomatization	complete axiomatization	Let f̂l be an m-valued functionally complete matrix with truth-values 1, 2, . . . ra, and let D be the class of designated values and U the class of undesignated values of β. We shall assume that β is Post-consistent, i.e. that U is not empty. Then the truth-functions definable using ϋ will include the functions Cpq, Np, and Fip, 1 < i < m, with the following properties, where ' | α | ' denotes the truth-value of a: (1) If, for all assignments of values to the variables of a and β, \a\ e D and I Caβ\ e D, then \ β\ e D for all similar assignments. (2) For all values of p and q, \ CpCNpq] e D. (3) For all values of the variables in a, if \a\ e U then \Na\ e D. (4) The Fip are constant functions such that, for all values of p, \Ftp\ = 1, \F2p\ = 2 , . . . , \Fmp\ =m. Consider now the deductive system M having as theses all β tautologies, and having among its rules of inference the rule of substitution of wffs for proposition variables and the rule of modus ponens for C in the sense that β is derivable from a and Caβ. We shall show that adding any nonβ -tautology γ to M as a thesis makes M Post-inconsistent. Since γ is not an β -tautology, there will be an assignment of values to its variables such that |y | e U. Let y be the result of substituting appropriate constant functions Fip for the variables of γ so that y is itself a constant function and |y τ | e U. We shall write t-a' to denote that a is a thesis of M. Since \-γ, we obtain hy f by substitution. Also, since | y r | e ( J , |Afy r |eD, and hence \-Nγ\ Using the appropriate substitution of \CpCNpq and two applications of the rule of modus ponens we obtain \-q. Hence M plus \-γ is Post-inconsistent, and M i s Post-complete.	axiomatic system;ccir system m;constant function;formal system;functional completeness;post-hartree–fock	Nuel Belnap;Storrs McCall	1970	Notre Dame Journal of Formal Logic	10.1305/ndjfl/1093893866	mathematics	Theory	-10.726195240347582	10.160422736116839	198719
421faf3b7142072746daed638e3bf18a3633b96d	valuations in nilpotent minimum logic	nm propositional logic finite distributive lattices nm algebras nilpotent minimum logic idempotent euler characteristics;settore inf 01 informatica;settore mat 01 logica matematica;formal logic boolean algebra;euler characteristic nm logic nm algebra nm logic valuation;algebra cost accounting lattices generators fuzzy logic electronic mail indexes;nm logic;euler characteristic;valuation;nm algebra	The Euler characteristic can be defined as a special kind of valuation on finite distributive lattices. This work begins with some brief consideration on the role of the Euler characteristic on NM algebras, the algebraic counterpart of Nilpotent Minimum logic. Then, we introduce a new valuation, a modified version of the Euler characteristic we call idempotent Euler characteristic. We show that the new valuation encodes information about the formulas in NM propositional logic.	euler characteristic;idempotence;irreducibility;linear algebra;ordinal data;propositional calculus;remote desktop protocol;value (ethics)	Pietro Codara;Diego Valota	2015	2015 IEEE International Symposium on Multiple-Valued Logic	10.1109/ISMVL.2015.19	zeroth-order logic;euler characteristic;boolean algebra;discrete mathematics;valuation;intuitionistic logic;intermediate logic;predicate functor logic;pure mathematics;mathematics;abstract algebraic logic;algorithm;algebra	Logic	-6.353473075636052	9.196745528190112	199201
3b5cb672b032556a1547b1fd8aaa90d2d8f4517b	harrington's conservation theorem redone	second order;cut elimination;second order arithmetic;conservativity;weak konig s lemma	Leo Harrington showed that the second-order theory of arithmetic WKL0 is Π 1 -conservative over the theory RCA0. Harrington’s proof is modeltheoretic, making use of a forcing argument. A purely proof-theoretic proof, avoiding forcing, has been eluding the efforts of researchers. In this short paper, we present a proof of Harrington’s result using a cut-elimination argument.	leo (computer);theory	Fernando Ferreira;Gilda Ferreira	2008	Arch. Math. Log.	10.1007/s00153-008-0080-8	calculus;pure mathematics;second-order arithmetic;mathematics;second-order logic	Theory	-9.104439711611697	11.08990675802458	199333
be2a219438d33eaf172eaed8ba97d66773c3bd23	shaken foundations or groundbreaking realignment? a centennial assessment of kurt gödel's impact on logic, mathematics, and computer science	history;centennial assessment;kurt godel incompleteness theorem;set theory computer science formal logic history;set theory;mathematical logic;set theory centennial assessment computer science kurt godel incompleteness theorem mathematical logic;formal logic;logic mathematics computer science set theory arithmetic artificial intelligence;computer science	"""The publication of Godels incompleteness theorems has frequently been portrayed as a devastating event, from which mathematics has not yet recovered. Yet those same theorems have also been hailed as proving that the powers of the human mind surpass those of any computer. Both those views, however, are caricatures. Godels impact on modern logic has been profound, but the incompleteness theorems did not cause widespread upset at the time of their publication, and subsequent mathematical work outside logic has hardly been affected by them. Nor is mathematics any less """"secure"""" than it was before Godels work."""	computer science;gödel	John W. Dawson	2006		10.1109/LICS.2006.47	predicate logic;mathematical logic;metamathematics;formal science;epistemology;many-valued logic;computer science;proof theory;computational logic;mathematics;automated reasoning;consistency;logic;term logic;algorithm;philosophy of logic;set theory	Theory	-10.570872612884548	5.1260236458316175	199689
