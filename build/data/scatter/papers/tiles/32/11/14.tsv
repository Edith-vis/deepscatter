id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
a8bd6b50d2403f04a950590c5aa232b9c42ab659	a big data-driven model for the optimization of healthcare processes		Healthcare organizations increasingly navigate a highly volatile, complex environment in which technological advancements and new healthcare delivery business models are the only constants. In their effort to out-perform in this environment, healthcare organizations need to be agile enough in order to become responsive to these increasingly changing conditions. To act with agility, healthcare organizations need to discover new ways to optimize their operations. To this end, they focus on healthcare processes that guide healthcare delivery and on the technologies that support them. Business process management (BPM) and Service-Oriented Architecture (SOA) can provide a flexible, dynamic, cloud-ready infrastructure where business process analytics can be utilized to extract useful insights from mountains of raw data, and make them work in ways beyond the abilities of human brains, or IT systems from just a year ago. This paper presents a framework which provides healthcare professionals gain better insight within and across your business processes. In particular, it performs real-time analysis on process-related data in order reveal areas of potential process improvement.	agile software development;assay of volatiles;big data;brain;business process;delivery of health care;hl7publishingsubsection <operations>;program optimization;real-time locating system;service-oriented architecture;service-oriented device architecture	Vassiliki Koufi;Flora Malamateniou;George Vassilacopoulos	2015	Studies in health technology and informatics	10.3233/978-1-61499-512-8-697	knowledge management;health care;data science;data mining;big data;medicine	ML	-38.66540781295252	-9.570408056901284	194001
4835dc9f600a27b520e28d7b7810fc5f0388424c	benefits of intersite pre-processing and clustering methods in e-commerce domain	e commerce;cluster analysis;statistical analysis;clustering method;data warehouse;data structure	This paper presents our preprocessing and clustering analysis on the clickstream dataset proposed for the ECML\PKDD 2005 Discovery Challenge. The main contributions of this article are double. First, after presenting the clickstream dataset, we show how we build a rich data warehouse based an advanced preprocesing. We take into account the intersite aspects in the given ecommerce domain, which offers an interesting data structuration. A preliminary statistical analysis based on time period clickstreams is given, emphasing the importance of intersite user visits in such a context. Secondly, we describe our crossed-clustering method which is applied on data generated from our data warehouse. Our preliminary results are interesting and promising illustrating the benefits of our WUM methods, even if more investigations are needed on the same dataset.	clickstream;cluster analysis;e-commerce;polish enigma double;preprocessor	Sergiu Theodor Chelcea;Alzennyr Da Silva;Yves Lechevallier;Doru Tanasa;Brigitte Trousse	2005	CoRR		data structure;computer science;data science;machine learning;data warehouse;data mining;database;cluster analysis;programming language	ML	-38.75079939099818	-8.471984616579682	194296
7770db8ab2135efef833b5bae3936840bb268b9b	classification extension based on iot-big data analytic for smart environment monitoring and analytic in real-time system		Monitoring water conditions in real-time is a critical mission to preserve the water ecosystem in maritime and archipelagic countries, such as Indonesia that is relying on the wealth of water resources. To integrate the water monitoring system into the big data technology for real-time analysis, we have engaged in the ongoing project named smart environment monitoring and analytic in real-time system (SEMAR), which provides the IoT-big data platform for water monitoring. However, SEMAR does not have an analytical system yet. This paper proposes the analytical system for water quality classification using Pollution Index method, which is an extension of SEMAR. Besides, the communication protocol is updated from REST to MQTT. Furthermore, the real-time user interface is implemented for visualisation. The evaluations confirmed that the data analytic function adopting the linear SVM and decision tree algorithms achieves more than 90% for the estimation accuracy with 0.019075 for the MSE.	big data;real-time clock;real-time computing;smart environment	Riyadh Arridha;Sritrusta Sukaridhoto;Dadet Pramadihanto;Nobuo Funabiki	2017	IJSSC	10.1504/IJSSC.2017.10008038	communications protocol;support vector machine;decision tree;analytic function;mqtt;big data;data mining;smart environment;computer science;user interface	Embedded	-35.21718737405439	-5.684204959056052	194736
9de7d0407b55171a1866787c788093522ea7c412	the use of charts, pivot tables, and array formulas in two popular spreadsheet corpora		The use of spreadsheets in industry is widespread. Companies base decisions on information coming from spreadsheets. Unfortunately, spreadsheets are error-prone and this increases the risk that companies base their decisions on inaccurate information, which can lead to incorrect decisions and loss of money. In general, spreadsheet research is aimed to reduce the error-proneness of spreadsheets. Most research is concentrated on the use of formulas. However, there are other constructions in spreadsheets, like charts, pivot tables, and array formulas, that are also used to present decision support information to the user. There is almost no research about how these constructions are used. To improve spreadsheet quality it is important to understand how spreadsheets are used and to obtain a complete understanding, the use of charts, pivot tables, and array formulas should be included in research. In this paper, we analyze two popular spreadsheet corpora: Enron and EUSES on the use of the aforementioned constructions.	chart;cognitive dimensions of notations;decision support system;money;pivot table;spreadsheet;text corpus	Bas Jansen;Felienne Hermans	2018	CoRR		computer science;theoretical computer science;data mining;decision support system;pivot table	SE	-35.191896919568684	-8.283611952974415	195380
b01b4155dc260a10be43a53c430cc4afe5288ad2	big data, big systems, big challenges: a personal experience - (extended abstract)			big data	Vadim E. Kotov	2014		10.1007/978-3-662-46823-4_3	data science;big data;computer science	Theory	-38.6655911161514	-6.730710967012199	195528
dfa8b3be166e0c4042f33c4d3c57c8cebe101871	mining dynamics: using data mining techniques to analyze multi-agent learning			data mining	Sherief Abdallah	2017	J. Intelligent Systems	10.1515/jisys-2016-0136	data science;data mining	ML	-39.05978567155581	-6.868761365301652	195799
0e9c41ebc5086b8b9d7004a68d6637e4940f03c9	research directions in data wrangling: visualizations and transformations for usable and credible data	uncertainty;qa75 electronic computers computer science;visualization;data transformation;data cleaning;data quality	In spite of advances in technologies for working with data, analysts still spend an inordinate amount of time diagnosing data quality issues and manipulating data into a usable form. This process of ‘data wrangling’ often constitutes the most tedious and time-consuming aspect of analysis. Though data cleaning and integration are longstanding issues in the database community, relatively little research has explored how interactive visualization can advance the state of the art. In this article, we review the challenges and opportunities associated with addressing data quality issues. We argue that analysts might more effectively wrangle data through new interactive systems that integrate data verification, transformation, and visualization. We identify a number of outstanding research questions, including how appropriate visual encodings can facilitate apprehension of missing data, discrepant values, and uncertainty; how interactive visualizations might facilitate data transform specification; and how recorded provenance and social interaction might enable wider reuse, verification, and modification of data transformations.	data quality;interactive visualization;missing data;plasma cleaning	Sean Kandel;Jeffrey Heer;Catherine Plaisant;Jessie Kennedy;Frank van Ham;Nathalie Henry Riche;Chris Weaver;Bongshin Lee;Dominique Brodbeck;Paolo Buono	2011	Information Visualization	10.1177/1473871611415994	visualization;data quality;uncertainty;computer science;artificial intelligence;data science;data mining;database;data transformation;statistics	HCI	-36.78447460960397	-8.700439147809693	195892
9c8f7cac886c31d288f553fa2ff983cb9bd05e29	big data analytics as a service for business intelligence		This paper proposes an ontology of big data analytics and examines how to enhance business intelligence through big data analytics as a service by presenting a big data analytics services-oriented architecture (BASOA), and applying BASOA to business intelligence, where our surveyed data analysis showed that the proposed BASOA is viable for developing business intelligence and enterprise information systems. This paper also discusses the interrelation- ship between business intelligence and big data analytics. The proposed approach in this paper might facilitate the research and development of business analytics, big data analytics, and business intelligence as well as intelligent agents.		Zhaohao Sun;Huasheng Zou;Kenneth D. Strang	2015		10.1007/978-3-319-25013-7_16	analytics;intelligence cycle;reactive search optimization;web analytics;engineering;artifact-centric business process model;data science;data mining;business analytics;business intelligence;web intelligence;cultural analytics;software analytics;world wide web;semantic analytics;business activity monitoring	DB	-38.89267296894302	-5.796781559723316	196339
a85e793954e2922cbb846a92a10f770f89d27ae1	advanced technology and social media influence on research, industry and community		The rapid development in technology and social media has gradually shifted the focus in research, industry and community from traditional into dynamic environments where creativity and innovation dominate various aspects of the daily life. This facilitated the automated collection and storage of huge amount of data which is necessary for effective decision making. Indeed, the value of data is increasingly realized and there is a tremendous need for effective techniques to maintain and handle the collected data starting from storage to processing and analysis leading to knowledge discovery. This chapter will cite our accomplished works which focus on techniques and structures which could maximize the benefit from data beyond what is traditionally supported. In the listed published work, we emphasized data intensive domains which require developing and utilizing advance computational techniques for informative discoveries. We described some of our accomplishments, ongoing research and future research plans. The notion of big data has been addressed to show how it is possible to process incrementally available big data using limited computing resources. The benefit of various data mining and network modeling mechanisms for data analysis and prediction has been addressed with emphasize on some practical applications ranging from forums and reviews to social media as effective means for communication, sharing and discussion leading to collaborative decision making and shaping of future plans.	social media	Reda Alhajj	2018		10.1007/978-3-319-89743-1_1	knowledge extraction;artificial intelligence;machine learning;computer science;management science;network model;cluster analysis;big data;group decision-making;social media;social network;ranging	HCI	-37.21845692735411	-7.7486388454106665	196818
da96b63465c3679894acba4295cfb838554e8bf2	the gold model: an oo multidimensional data model for multidimensional databases	multidimensional data;multidimensional database			Juan Trujillo	1999			data science;data mining;database	DB	-38.92217514777272	-5.0013453630562354	197509
449145a17113b3faff619ce53857b5342322ebac	distributed online temporal fuzzy concept analysis for stream processing in smart cities	parallel computation;online data streams;temporal fuzzy concept analysis;smart city;distributed architecture	Nowadays, one of the main challenges in the smart cities is mining high-level semantics from low-level activities. In this context, real-time data streams are continuously produced and analysed by efficient and effective algorithms, which are able to handle complexities related to big data, in order to enable the core functions of Decision Support Systems in the smart city. These algorithms should receive input data coming from different city domains (or pillars) and process, aggregate and reason over them in a way that it is possible to find hidden correlations among different and heterogeneous elements (e.g., traffic, weather, cultural events) along space and time dimensions. This paper proposes the online implementation and deployment of Temporal Fuzzy Concept Analysis on a distributed real-time computation system, based on Apache Storm, to face with big data stream analysis in the smart city context. Such online distributed algorithm is able to incrementally generate the timed fuzzy lattice that organizes the knowledge on several and cross-domain aspects of the city. Temporal patterns, of how situations evolve in the city, can be elicited by both exploring the lattice and observing its growth in order to obtain actionable knowledge to support smart city decision-making processes.	fuzzy concept;smart city;stream processing	Carmen De Maio;Giuseppe Fenza;Vincenzo Loia;Francesco Orciuoli	2017	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2017.02.002	distributed computing;smart city;distributed algorithm;software deployment;fuzzy concept;fuzzy logic;parallel computing;data stream mining;big data;data mining;computer science;decision support system	SE	-37.28918174597576	-5.244952996695113	198165
09a82d71943ff81cca754df2c3ae1f771c6faa7d	negative correlation discovery for big multimedia data semantic concept mining and retrieval	negative correlation;cluster computing engine negative correlation discovery big multimedia data semantic concept mining data processing techniques big data management big data retrieval multimedia high level semantic concept mining semantic gap high level concepts low level visual features hadoop mapreduce framework;semantics;data mining;information integration;big data;streaming media;multimedia communication;correlation multimedia communication data mining semantics big data streaming media videos;pattern clustering big data data mining information retrieval multimedia databases;spark;multimedia semantic mining and retrieval;mapreduce;correlation;hadoop;information integration big data negative correlation hadoop mapreduce spark multimedia semantic mining and retrieval;videos	With massive amounts of data producing each day in almost every field, traditional data processing techniques have become more and more inadequate. However, the research of effectively managing and retrieving these big data is still under development. Multimedia high-level semantic concept mining and retrieval in big data is one of the most challenging research topics, which requires joint efforts from researchers in both big data mining and multimedia domains. In order to bridge the semantic gap between high-level concepts and low-level visual features, correlation discovery in semantic concept mining is worth exploring. Meanwhile, correlation discovery is a computationally intensive task in the sense that it requires a deep analysis of very large and growing repositories. This paper presents a novel system of discovering negative correlation for semantic concept mining and retrieval. It is designed to adapt to Hadoop MapReduce framework, which is further extended to utilize Spark, a more efficient and general cluster computing engine. The experimental results demonstrate the feasibility of utilizing big data technologies in negative correlation discovery.	algorithm;apache hadoop;big data;cartesian closed category;coefficient;computer cluster;concept mining;data mining;high- and low-level;mapreduce;spark;ternary numeral system;windows firewall	Yilin Yan;Mei-Ling Shyu;Qiusha Zhu	2016	2016 IEEE Tenth International Conference on Semantic Computing (ICSC)	10.1109/ICSC.2016.73	concept mining;semantic computing;big data;spark;computer science;information integration;data mining;database;semantics;data stream mining;negative relationship;world wide web;correlation;information retrieval	DB	-36.70642329450516	-4.733640246108882	199821
