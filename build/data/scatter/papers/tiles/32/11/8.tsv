id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
d81c6811c93d2ad2a89cda72513da2a499c526d8	adaptive video content manipulation for oled display power management		Emerged as a choice of display for vivid colours and power efficiency in expensive Smartphones, in recent days Organic Light Emitting Diode (OLED) displays are increasingly replacing Liquid Crystal Displays (LCD) and Plasma in Smartphones and large screen Televisions. Yet, OLED displays are one of the most energy consuming modules in modern Smartphones. Power consumption of OLED displays have strong correlation with the colours illuminated by its pixels. Improvements in pixel density by manufacturers makes the displays more power hungry. In this paper, we present Human Visual System (HVS) aware adaptive colour transformation and darkening methods to create power-efficient videos for OLED displays while preserving visual fidelity of the videos. Our measurements and subjective evaluations show that we can save up to 60% of energy consumption with minimum distortion to visual quality of the video. As our colour transformation process uses pre-computed colour-map and the darkening process uses the gamma-correction function which is already implemented in most of the display hardware, runtime computation overheads are minimum and hence, our method can be used to manipulate realtime/live video streams as well.		Anand Bhojan	2018		10.1145/3286978.3287018	computer vision;pixel;video processing;energy consumption;power management;computer science;liquid-crystal display;electrical efficiency;human visual system model;distributed computing;pixel density;artificial intelligence	HCI	-37.81387087368745	-48.35309646674816	161742
72b9ec0007518fe8e0b8111b6b01c05503b77750	hierarchical faceted metadata in site search interfaces	user interface;usability study;iterative design;search user interfaces;www	One of the most pressing usability issues in the design of large web sites is that of the organization of search results. A previous study on a moderate-sized web site indicated that users understood and preferred dynamically organized faceted metadata over standard search. We are now examining how to scale this approach to very large collections, since it is difficult to present hierarchical faceted metadata in a manner appealing and understandable to general users. We have iteratively designed and tested interfaces that address these design challenges; the most recent version is receiving enthusiastic responses in ongoing usability studies.	faceted classification;usability;web search query	Jennifer English;Marti A. Hearst;Rashmi R. Sinha;Kirsten Swearingen;Ka-Ping Yee	2002		10.1145/506443.506517	iterative design;web usability;human–computer interaction;computer science;database;user interface;world wide web	HCI	-34.67017531352075	-50.68612417878177	162015
07a5fed824eda407b1be599c8fb0400c4438c6be	human multimedia display interface based on human activity recognition	interfaces;multimedia;human activity recognition	In this paper, we will propose a Human Multimedia Display Interface. The interface uses the tracking of human hand movements to control the IP-TV. This paper presents an improved CAMSHIFT algorithm to control an IP-TV system. The CAMSHIFT algorithm (Continuously Adaptive MeanShift) is a method of using color information[1]. It can do tracking with a specific color of the target. In some typical environmental constraints, it can obtain good tracking performance. However, as the question of noise, large area similar to the color interference and so on, only by CAM-SHIFT algorithm it is not competent. Against these issues we propose an improved CAMSHIFT algorithm[2].© (2011) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	activity recognition	Yiting Shang;Eung-Joo Lee	2011		10.1117/12.896400	computer vision;engineering;multimedia;communication	HCI	-40.142101285508105	-49.82607579044235	165411
b418311420e42bac11cdf2aacca62a2c0be35429	an effective design method for welfare robot and its application to the design of meal-assistance robot	design process;concept design;welfare robot;elderly society;meal assistance robot;design method;robots;elderly society welfare robot meal assistance robot;mechanism design	Recently, many welfare robots have been developed to solve problems in elderly society. However, very few welfare robots have been successfully commercialized. One of the reasons for the difficulty in commercializing them is the insufficient method of designing those kinds of robots. The present research aims to develop an effective design method for welfare robots. The author proposes a method focusing on the early stage of the mechanical design as the conceptual and basic design process: 1) prior research to investigate the conditions for evaluating the design, 2) arranging the goal for the evaluation items, 3) preliminary tests to investigate the standards of evaluation, 4) mock-up to determine the standards, and 5) specifications for detailed design. The proposed method concentrating on the concept design is applied to the design of a meal-assistance robot mechanism. The design derived by the proposed method is quite similar to the concept of the most recent version of the robot developed by the conventional design method as determined by interviewing medical staff.	mock object;robot	T. Sakaki	2008	RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2008.4600684	robot;mechanism design;simulation;design process;design methods;computer science;artificial intelligence;concept art;personal robot	Robotics	-39.029931170997386	-46.8629623078089	166739
cb30cea566404f400a31d159ba603327f3f36c45	a robot simulator classification system for hri	desktop computers;serious games;aircraft simulators;control algorithm;simulator rating;robot simulator classification system;training;simulation;desktop computers robot simulator classification system computer based robot simulators faa guidelines aircraft simulators computer simulation artificial intelligence;mobile robots;mobile robots learning artificial intelligence;artificial intelligent;computational modeling;games;robots;computer based robot simulators;classification system;artificial intelligence;faa;simulator rating serious games simulation training;robots atmospheric modeling computational modeling vehicles faa training games;vehicles;atmospheric modeling;learning artificial intelligence;computer simulation;serious game;faa guidelines	This paper presents a classification system for computer-based robot simulators that is based on the FAA guidelines for aircraft simulators. Low fidelity computer simulation has been used extensively for testing artificial intelligence and control algorithms for robotic systems. Until recently operator training using simulators has been impractical due to the cost of the computer systems necessary to simulate robot operation with high fidelity. The rapid increase in the power of desktop computers over the last decade has led to cheap, high fidelity vehicle simulation. A review of the literature shows that there are many robot simulators in use with a variety of features and fidelity levels. There has been no prior work attempting to classify the functionality of these robot simulators.	algorithm;artificial intelligence;authorization;compiler;computer simulation;desktop computer;human–robot interaction;microsoft windows;mobile robot;requirement;statistical classification;usability	Jeff Craighead;Robin R. Murphy;Jennifer L. Burke;Brian F. Goldiez	2007	2007 International Symposium on Collaborative Technologies and Systems	10.1109/CTS.2007.4621743	computer simulation;robot;mobile robot;games;atmospheric model;simulation;human–computer interaction;computer science;artificial intelligence;computational model;library classification	AI	-40.62991736207269	-47.148788037168416	167896
8b972031d4fc0248dd70868190267d3dcb652c45	gaze-contingent multiresolutional displays: an integrative review	gaze;gaze contingent multi resolutional displays;high resolution;position;realite virtuelle;ergonomia;image resolution;realidad virtual;pantalla;virtual reality;screen;imagerie;hombre;automatisation;posicion;gaze contingent displays;robotics;mirada;ergonomie;driving simulator;analyse multiresolution;automatizacion;remote operation;simulator;area of interest;fixations;regard;haute resolution;imagery;research and development;human factors;simulador;level of detail;image transmission;teleaccion;eye movements;human;alta resolucion;simulateur;robotica;article author version;saccades;robotique;imagineria;infrared;multi resolution;transmission image;artificial vision;multiresolution analysis;vision;ergonomics;ecran;analisis multiresolucion;teleoperation;transmision imagen;homme;automation	"""Gaze-contingent multiresolutional displays (GCMRDs) center high-resolution information on the user's gaze position, matching the user's area of interest (AOI). Image resolution and details outside the AOI are reduced, lowering the requirements for processing resources and transmission bandwidth in demanding display and imaging applications. This review provides a general framework within which GCMRD research can be integrated, evaluated, and guided. GCMRDs (or """"moving windows"""") are analyzed in terms of (a) the nature of their images (i.e., """"multiresolution,"""" """"variable resolution,"""" """"space variant,"""" or """"level of detail""""), and (b) the movement of the AOI (i.e., """"gaze contingent,"""" """"foveated,"""" or """"eye slaved""""). We also synthesize the known human factors research on GCMRDs and point out important questions for future research and development. Actual or potential applications of this research include flight, medical, and driving simulators; virtual reality; remote piloting and teleoperation; infrared and indirect vision; image transmission and retrieval; telemedicine; video teleconferencing; and artificial vision systems."""	computer vision;contingency (philosophy);driving simulator;emoticon;flight simulator;human factors and ergonomics;image resolution;level of detail;matching;microsoft windows;multiresolution analysis;requirement;simulators;telemedicine;virtual reality	Eyal M. Reingold;Lester C. Loschky;George W. McConkie;David M. Stampe	2003	Human factors	10.1518/hfes.45.2.307.27235	computer vision;simulation;image resolution;computer science;human factors and ergonomics;computer graphics (images);mechanical engineering	HCI	-40.81252777156278	-49.20834800715737	169274
d1d55dee144e5502fc11ec6ab7d0d95874bb7033	the effects of video image frame rate on the environmental hazards recognition performance in using remote vision to navigate visually impaired pedestrians	video image quality;user interface;blind people;navigation;gps;gis;image quality;visual impairment;environmental hazards;remote vision	This paper presents the results of a study to determine the effects of video image frame rate on the performance of the sighted human guide in recognizing static hazards in the travel environment - a basic activity in using remote vision to navigate visually impaired pedestrians. The results show that variations in the frame rate (25 fps and 2 fps) do not cause a significant difference in the ability to recognize static hazards in the travel environment based on video image. The study was conducted as a part of the process of development of a novel system for navigation of visually impaired people. The system, titled the System for Remote Sighted Guidance of Visually Impaired Pedestrians, is being developed by the Electronic Systems Research Group at the School of Engineering and Design, Brunel University.	computer stereo vision	Vanja Garaj;Ziad Hunaiti;Wamadeva Balachandran	2007		10.1145/1378063.1378098	image quality;computer vision;navigation;simulation;geomatics;global positioning system;computer science;operating system;multimedia;user interface	HCI	-40.31026181720261	-49.92409747237118	169672
6a9864e4bcae41ebfbb210d75977fbdb54b2ecca	towards a standardized test for intelligent wheelchairs	energy;mobility;task;performance;standard;metrics;test;radio communications;sensor;environment;hsi;measure;terminology;human system interaction;test method;test suite;robot;power;goal	Many people who have to rely on electric wheelchairs find it hard or even impossible to fulfill daily navigation tasks with their chairs. The SmartWheeler project aims at developing an intelligent wheelchair that minimizes the physical and cognitive load required in steering it. In this paper we briefly outline the SmartWheeler project and its goals. We then argue that it is important to have a standardized test to evaluate autonomous wheelchairs in terms of performance quality, safety, and usability. No such test exists as yet for intelligent wheelchairs, but there has been an effort in the clinical community to design tests for conventional wheelchair usage. We discuss the existing Wheelchair Skills Test (WST). We then suggest a paradigm that allows us to use this test to benchmark the quality of intelligent wheelchairs, and in particular their interface, in a task context that is relevant to clinical practice in rehabilitation.	autonomous robot;benchmark (computing);programming paradigm;usability	Joelle Pineau;Robert West;Amin Atrash;Julien Villemure;François Routhier	2010		10.1145/2377576.2377607	embedded system;simulation;engineering;artificial intelligence	HCI	-39.43034195604894	-46.926433470532956	170194
403ff89fd5d518f70851889b0f1fb473c07b14ff	unobtrusive gait verification for mobile phones	gait recognition;mobile phones;activity recognition	Continuously and unobtrusively identifying the phone's owner using accelerometer sensing and gait analysis has a great potential to improve user experience on the go. However, a number of challenges, including gait modeling and training data acquisition, must be addressed before unobtrusive gait verification is practical. In this paper, we describe a gait verification system for mobile phone without any assumption of body placement or device orientation. Our system uses a combination of supervised and unsupervised learning techniques to verify the user continuously and automatically learn unseen gait pattern from the user over time. We demonstrate that it is capable of recognizing the user in natural settings. We also investigated an unobtrusive training method that makes it feasible to acquire training data without explicit user annotation.	data acquisition;gait analysis;mobile phone;supervised learning;teaching method;usb on-the-go;unobtrusive javascript;unsupervised learning;user experience;verification and validation	Hong Lu;Jonathan Huang;Tanwistha Saha;Lama Nachman	2014		10.1145/2634317.2642868	computer vision;simulation;engineering;communication	AI	-37.93801312391776	-45.894941855138924	173278
d4d376e05549a7a803b2ff3fe76956442d85f9ab	a review of master-slave robotic systems for surgery	robotics;surgery;master slave	For decades, men have used robots to overcome their natural limitation in their dealing with the environment. In recent years, robots have been developed to assist surgeons in performing surgeries. Since these robots are meant for surgeons' use, the design and considerations for safety, reliability and human-robot interface become important. One of the most common modes of controlling surgery robots is using a master and slave layout. This paper explores the latest development in the area of master-slave robotic system for surgery.	master/slave (technology);robot	Soon Chiang Low;Louis Phee	2004	IEEE Conference on Robotics, Automation and Mechatronics, 2004.	10.1142/S0219843606000904	master/slave;simulation;computer science;artificial intelligence;robotics	Robotics	-39.58985425130245	-46.62642107860688	173989
e74fcde51d54046773b14c5452c0213b50746a09	on slide-based contextual cues for presentation reuse	online survey;contextual recommendation;knowledge worker;visual representation;local context;information management;slide based search	Reuse of existing presentation materials is prevalent among knowledge workers. However, finding the most appropriate material for reuse is challenging. Existing information management and search tools provide inadequate support for reuse due to their dependence on users' ability to effectively categorize, recall, and recognize existing materials. Based on our findings from an online survey and contextual interviews, we designed and implemented a slide-based contextual recommender, ConReP, for supporting reuse of presentation materials. ConReP utilizes a user-selected slide as a search-key, recommends materials based on similarity to the selected slide, and provides a local-context-based visual representation of the recommendations. Users input provides new insight into presentation reuse and reveals that slide-based search is more effective than keyword-based search, local-context-based visual representation helps in better recall and recognition, and shows the promise of this general approach of exploiting individual slides and local-context for better presentation reuse.	categorization;contextual inquiry;desktop computer;information management;personally identifiable information;recommender system;semiconductor industry	Moushumi Sharmin;Lawrence Bergman;Jie Lu;Ravi B. Konuru	2012		10.1145/2166966.2166992	computer science;knowledge management;data mining;multimedia;information management;world wide web	HCI	-35.16730853447733	-51.847672167747525	174258
6496d2abd1ba9550b552194769fa4c9c2e4b702e	interactive topic modeling for exploring asynchronous online conversations: design and evaluation of convisit	text visualization;interactive topic modeling;computer mediated communication;asynchronous conversation	Since the mid-2000s, there has been exponential growth of asynchronous online conversations, thanks to the rise of social media. Analyzing and gaining insights from such conversations can be quite challenging for a user, especially when the discussion becomes very long. A promising solution to this problem is topic modeling, since it may help the user to understand quickly what was discussed in a long conversation and to explore the comments of interest. However, the results of topic modeling can be noisy, and they may not match the user’s current information needs. To address this problem, we propose a novel topic modeling system for asynchronous conversations that revises the model on the fly on the basis of users’ feedback. We then integrate this system with interactive visualization techniques to support the user in exploring long conversations, as well as in revising the topic model when the current results are not adequate to fulfill the user’s information needs. Finally, we report on an evaluation with real users that compared the resulting system with both a traditional interface and an interactive visual interface that does not support human-in-the-loop topic modeling. Both the quantitative results and the subjective feedback from the participants illustrate the potential benefits of our interactive topic modeling approach for exploring conversations, relative to its counterparts.	blog;feedback;information needs;information overload;interactive visualization;jones calculus;massive open online course;multi-user;on the fly;online chat;slashdot;social media;text corpus;time complexity;topic model	Enamul Hoque;Giuseppe Carenini	2016	TiiS	10.1145/2854158	human–computer interaction;computer science;multimedia;computer-mediated communication	HCI	-33.77238174981665	-49.437510414101816	174680
2960231a92c5b8b394dd5d665ebf9ff3589ccb15	human-machine interface evaluation in a computer assisted surgical system	operating room;manipulators;speech based user interfaces;medical robotics;medical computing;man machine systems computer interfaces surges cameras robot vision systems minimally invasive surgery control systems laparoscopes application software abdomen;rating scale;human machine interface;tactile interface;telerobotics haptic interfaces speech based user interfaces medical robotics surgery medical computing manipulators;surgery;telerobotics;haptic interfaces;teleoperated system human machine interface evaluation computer assisted surgical system robotic surgical assistant voice command tactile interface manipulator	This work presents an approach to the evaluation of two interfaces for the control of a robotic surgical assistant. Each interface is associated to a different mode of controlling the system: by the surgeon (voice commands) or by the assistant (tactile interface). This two modes are allowed by the design of the manipulator, developed to occupy a small volume in the operating room. To evaluate the interfaces, a rating scale for teleoperated systems is proposed.	rating scale;robot	Jesús Fernández-Lozano;Jesús M. Gómez de Gabriel;Victor F. Muñoz;Isabel García-Morales;David Melgar;Carlos Vara-Thorbeck;Alfonso García-Cerezo	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1307156	human–machine interface;telerobotics;control engineering;computer vision;simulation;rating scale;computer science;engineering;artificial intelligence;user interface	Robotics	-40.379970311968705	-45.75890482658317	175095
bf5159d7ec7f2259e6aff1009be3afcf0305552d	senseflow: an experimental study of people tracking	people density;people tracking;smartphone;wi fi	"""Human detection and people tracking is one of the most important tasks in human sensing applications. The main challenges in large-scale people tracking are the recognition of people density in a specific area and tracking the people flow movement. To address these challenges, we present SenseFlow, a lightweight people tracking system. SenseFlow utilises off-the-shelf wireless sensing nodes which sniff probe requests periodically polled by user's mobile devices for Wi-Fi connection. We demonstrate the feasibility of the SenseFlow by building a proof-of-concept prototype and undertaking extensive evaluations in real-world settings. To study the people flow tracking performance, we evaluate SenseFlow with varying walking speeds and different models of smartphones on the SUTD University campus. Moreover, we also deploy SenseFlow in a crowded open area in city for 30 hours to evaluate the performance """"in the wild""""."""	mobile device;prototype;smartphone;tracking system	Kai Li;Chau Yuen;Salil S. Kanhere	2015		10.1145/2820990.2820994	simulation;telecommunications;engineering;multimedia	HCI	-37.224362273099686	-46.701574381203066	175513
0f02a6c0a91eead17059b900f95d1698efb527c8	soundslike: movies soundtrack browsing and labeling based on relevance feedback and gamification	engagement;audio;movies;bootstrapping;video;gamification;relevance feedback;music;entertainment;tagging	Movies and games are amongst the biggest sources of entertainment, in individual and social contexts. Increasingly, movies and videos are becoming accessible as enormous collections over the Internet, in social media and interactive TV, demanding for new and more powerful ways to search, browse and view them, that benefit from video content-based analysis and classification techniques. Game elements, in turn, can help in this often challenging process, e.g. in the audio, to obtain user feedback to improve the efficacy of classification, while maintaining or improving the entertaining quality of the user experience. In this paper, we present and discuss SoundsLike, a gamification approach to engage users in movies soundtrack labeling, based on relevance feedback and integrated in MovieClouds, an interactive web application designed to access, explore and visualize movies based on the information conveyed in the different tracks or perspectives of its content, especially audio and subtitles where most of the semantics is conveyed, and with a special focus on the emotional dimensions expressed in the movies or felt by the viewers.	browsing;digital video;gamification;internet;relevance feedback;social media;the movies;user experience;web application	Jorge M. A. Gomes;Teresa Chambel;Thibault Langlois	2013		10.1145/2465958.2465979	entertainment;video;computer science;music;multimedia;internet privacy;world wide web;bootstrapping	HCI	-33.970870315242436	-48.49009748120532	175918
47612cc60f0f8bd69cad139b9e181df6191413ba	enhanced exploration of oral history archives through processed video and synchronized text transcripts	exploratory search;user study;web interface;video retrieval;contextual inquiry;oral histories;oral history;mixed method;next generation;heuristic evaluation;digital video;digital video library	A digital video library of over 900 hours of video and 18000 stories from The HistoryMakers was used by 266 students, faculty, librarians, and life-long learners interacting with a system providing multiple search and viewing capabilities over a trial period of several months. User demographics and actions were logged with this multimedia collection, providing quantitative and qualitative metrics on system use. These transaction logs were complemented with heuristic evaluation, interviews, and contextual inquiry with representative users. Collectively, these mixed methods informed the development of the next generation web-based interface for the HistoryMakers video oral histories to improve access to and dissemination of this rich cultural resource. In particular, the feature of a synchronized text transcript in the video player for the narratives merited further investigation. Such an interface has not seen widespread use in digital video players available on the web, yet was valued highly by oral history archive viewers. A user study with 27 participants measured the utility of the HistoryMakers web interface incorporating the synchronized transcript video player for stated fact-finding and open-ended tasks. For life oral histories, an aligned text transcript is valued for both tasks, with the video rated significantly more useful for open-ended tasks over fact-finding. These results suggest a task-dependent role of modality in presentation of oral histories, with synchronized transcripts rated highly across tasks.	archive;contextual inquiry;digital video;heuristic evaluation;interaction;librarian;modality (human–computer interaction);next-generation network;nonlinear gameplay;usability testing;user interface;web application	Michael G. Christel;Scott M. Stevens;Bryan Maher;Julieanna Richardson	2010		10.1145/1873951.1874215	simulation;computer science;contextual inquiry;multimedia;user interface;heuristic evaluation;world wide web	HCI	-37.295706755595376	-50.17094715228079	176121
5819f22b0709e464821b9b0e1a16e4e869e2e2f0	control aspects of active-above-knee prosthesis	inference motor;sistema experto;movimiento;aplicacion medical;commande;relacion hombre maquina;base connaissance;man machine relation;locomotion;motion;motor inferencia;mouvement;base conocimiento;control;medical application;relation homme machine;systeme expert;moteur inference;application medicale;knowledge base;expert system	A methodology for control of an active above-knee prosthesis (AKP) is described. This approach is called Artificial Reflex Control (ARC), and depends on the use of production rules, so that the controller may be thought of as a leg movement expert. This control strategy is applicable to a variety of different gait modes. Automatic adaptation, according to the environment, and to the gait mode required, is based on heuristics related to human motor control.		Dejan B. Popovic;Rajko Tomovic;Dejan Tepavac;Laszlo Schwirtlich	1991	International Journal of Man-Machine Studies	10.1016/S0020-7373(05)80159-2	knowledge base;computer science;artificial intelligence;motion;expert system;algorithm;scientific control	Arch	-39.92967389356217	-45.73391193501335	177622
c34f05924bb6b08f56347864f6bfade8f376a369	cloth modeling and simulation: a literature survey	comfort;finite element method;cloth modeling and simulation	Cloth modeling and simulation has gained significant momentum in recent years due to advances in computational hardware and software. Cloth plays an important role not only in daily life, but also in special scenarios such as firefighter’s cloth and space suits. There are special requirements such as protection capability of the human body and mobility after the firefighters or astronauts wear the special cloth. Traditional assessment of cloth is to have prototypes first and have experiments by subjective rating. This is time consuming and expensive. Virtual cloth modeling and simulation provides a means to demonstrate and assess its performance before cloth is made. This paper attempts to give a literature review to summarize the state-of-the-art of cloth modeling and simulation.	cloth modeling;computation;experiment;nonlinear system;requirement;simulation;virtual reality	James Long;Katherine Burns;Jingzhou Yang	2011		10.1007/978-3-642-21799-9_35	simulation;engineering;computer graphics (images)	Graphics	-39.26596570563494	-46.77969108468255	178911
5bf9472bd84b33de1fa035dacf6a8f03e951f44a	search results pages and competition for attention theory: an exploratory eye-tracking study	viewing behavior;bepress selected works;search engine result pages serps;eye tracking search engine result pages serps viewing behavior fixation competition for attention;fixation;competition for attention;eye tracking	The World Wide Web plays a central role in many aspects of our modern life. In particular, using search engines to access information about products and services has become an integral part of our day-to-day activities. In this study we look at users’ viewing behavior on search engine results pages (SERPs) through the lens of competition for attention theory. While this theory has been used for examining consumer behavior on e-commerce websites, little work has been done to test this theory for viewing behavior on SERPs. We use eye tracking data to analyze viewing behavior. The results show that viewing behavior can have an impact on a user experience and effective search, providing theoretical direction for studying the viewing behavior of SERPs.	e-commerce;exploratory testing;eye tracking;floor and ceiling functions;search engine results page;user experience;web search engine;world wide web	Soussan Djamasbi;Adrienne Hall Phillips;Ruijiao Yang	2013		10.1007/978-3-642-39209-2_64	simulation;human–computer interaction;computer science;multimedia	Web+IR	-39.08456757480053	-51.677244164320584	179586
b8dba596f289c94e88c21fd0da727a0a9e8a4eee	a gamification framework for sensor data analytics		The Internet of Things (IoT) enables connected objects to capture, communicate, and collect information over the network through a multitude of sensors, setting the foundation for applications such as smart grids, smart cars, and smart cities. In this context, large scale analytics is needed to extract knowledge and value from the data produced by these sensors. The ability to perform analytics on these data, however, is highly limited by the difficulties of collecting labels. Indeed, the machine learning techniques used to perform analytics rely upon data labels to learn and to validate results. Historically, crowdsourcing platforms have been used to gather labels, yet they cannot be directly used in the IoT because of poor human readability of sensor data. To overcome these limitations, this paper proposes a framework for sensor data analytics which leverages the power of crowdsourcing through gamification to acquire sensor data labels. The framework uses gamification as a socially engaging vehicle and as a way to motivate users to participate in various labelling tasks. To demonstrate the framework proposed, a case study is also presented. Evaluation results show the framework can successfully translate gamification events into sensor data labels.		Alexandra L'Heureux;Katarina Grolinger;Wilson A. Higashino;Miriam A. M. Capretz	2017	2017 IEEE International Congress on Internet of Things (ICIOT)	10.1109/IEEE.ICIOT.2017.18	computer security;computer science;smart grid;data mining;data analysis;internet of things;analytics;crowdsourcing	Mobile	-36.29603629659396	-46.787260917641554	180225
c9622f163528c68faf5243eff586255424815dd4	using eye tracking for evaluating web search interfaces	web documents;information retrieval;user studies involving documents;eye tracking	Using eye tracking in the evaluation of web search interfaces can provide rich information on users' information search behaviour, particularly in the matter of user interaction with different informative components on a search results screen. One of the main issues affecting the use of eye tracking in research is the quality of captured eye movements (calibration), therefore, in this paper, we propose a method that allows us to determine the quality of calibration, since the existing eye tracking system (Tobii Studio) does not provide any criteria for this aspect. Another issue addressed in this paper is the adaptation of gaze direction. We use a black screen displaying for 3 seconds between screens to avoid the effect of the previous screen on user gaze direction on the coming screen. A further issue when employing eye tracking in the evaluation of web search interfaces is the selection of the appropriate filter for the raw gaze-points data. In our studies, we filtered this data by removing noise, identifying gaze points that occur in Area of Interests (AOIs), optimising gaze data and identifying viewed AOIs.	eye tracking;information;tracking system;web search engine	Hilal Al Maqbali;Falk Scholer;James A. Thom;Mingfang Wu	2013		10.1145/2537734.2537747	computer vision;eye tracking;computer science;multimedia;world wide web;information retrieval	HCI	-35.125863083471906	-50.226352808129924	182795
9670917535900dbd80c515516c036dc0d70b0709	on creating a 2d & 3d visual saliency dataset	personality;motion capture;biological motion;point light stimuli;action perception;trait judgments;thin slicing	Visual saliency (VS), which refers to the study of the behaviour or perception of the human vision system, is usually captured using eye tracking technologies on a (statistically) representative set of participants watching visual media on a screen. Using eye tracking technologies to capture the visual behaviour of a set of candidates is a long, expensive and tedious experiment to set. Artificial intelligence can be used to replicate this human behaviour and several 2D and 3D visual saliency algorithms (VSAs) have been proposed [Wang et al. 2013; Zdziarski and Dahyot 2013]. These algorithms attempt to reproduce human visual perception behaviour and have assisted in applications such as video content creation, retargetting and summarisation. Automatically replicating viewing behaviour is easier, less cumbersome and cheaper than the manual option presented by eye trackers.	algorithm;artificial intelligence;color vision;digital video;eye tracking;self-replicating machine	Zbigniew Zdziarski;Rozenn Dahyot	2013		10.1145/2492494.2501889	psychology;computer vision;simulation;communication	AI	-40.950551591628795	-51.91099906677397	182847
81822610067b25d12525daff64ef0ecf2eaed209	eyesense: towards information extraction on corneal images		Humans sense most of the environment through their eyes. Detecting people's activities and context from their visual behavior using mobile eye trackers is well studied. Typically, these systems require some kind of calibration prior to usage, unsuitable for the end user. Cameras that actively record the user's field of view became a valid alternative for lifelogging applications. But such approaches do not include gaze information and may cause privacy challenges. In this work we propose an in-depth analysis of the first long-term corneal imaging dataset (i.e., the reflection of the environment on the human eye). All data was manually labeled with information about the attended objects. This was compared to an automatic approach using a state-of-the art neural network.	artificial neural network;crowdsourcing;eye tracking;humans;image analysis;information extraction;lifelog;object detection;sensor	Christian Lander;Antonio Krüger	2018		10.1145/3267305.3274121	information extraction;lifelog;end user;human–computer interaction;gaze;artificial neural network;human eye;computer science;field of view;bittorrent tracker	HCI	-37.96825396285629	-47.194261696527214	183036
2728f936401176981ec6918f5d7729b0f7482dc0	"""""""learning to rank for information retrieval from user interactions"""" by k. hofmann, s. whiteson, a. schuth, and m. de rijke with martin vesely as coordinator"""	universiteitsbibliotheek	In this article we give an overview of our recent work on online learning to rank for information retrieval (IR). This work addresses IR from a reinforcement learning (RL) point of view, with the aim to enable systems that can learn directly from interactions with their users. Learning directly from user interactions is difficult for several reasons. First, user interactions are hard to interpret as feedback for learning because it is usually biased and noisy. Second, the system can only observe feedback on actions (e.g., rankers, documents) actually shown to users, which results in an exploration-exploitation challenge. Third, the amount of feedback and therefore the quality of learning is limited by the number of user interactions, so it is important to use the observed data as effectively as possible. Here, we discuss our work on interpreting user feedback using probabilistic interleaved comparisons, and on learning to rank from noisy, relative feedback.	feedback;information retrieval;interaction;learning to rank;reinforcement learning	Katja Hofmann;Shimon Whiteson;Anne Schuth;Maarten de Rijke	2014	SIGWEB Newsletter	10.1145/2591453.2591458	error-driven learning;simulation;computer science;artificial intelligence;machine learning;world wide web	Web+IR	-36.60699133204141	-50.92066027012558	183699
1a5b5b31ff886d9af0451b8d6c0536e925a79ef5	depth and motion cues with phosphene patterns for prosthetic vision		Recent research demonstrates that visual prostheses are able to provide visual perception to people with some kind of blindness. In visual prostheses, image information from the scene is transformed to a phosphene pattern to be sent to the implant. This is a complex problem where the main challenge is the very limited spatial and intensity resolution. Moreover, depth perception, which is relevant to perform agile navigation, is lost and codifying the semantic information to phosphene patterns remains an open problem. In this work, we consider the framework of perception for navigation where aspects such as obstacle avoidance are critical. We propose using a head-mounted RGB-D camera to detect free-space, obstacles and scene direction in front of the user. The main contribution is a new approach to represent depth information and provide motion cues by using particular phosphene patterns. The effectiveness of this approach is tested in simulation with real data from indoor environments.	agile software development;algorithm;computer vision;depth perception;expect;experiment;obstacle avoidance;simulation;transmitter;visual prosthesis	Alejandro Pérez-Yus;Jesus Bermudez-Cameo;Josechu J. Guerrero;Gonzalo López-Nicolás	2017	2017 IEEE International Conference on Computer Vision Workshops (ICCVW)	10.1109/ICCVW.2017.179	phosphene;artificial intelligence;computer vision;visualization;perception;visual perception;image resolution;depth perception;computer science;rgb color model;obstacle avoidance	Vision	-38.36151521188962	-47.08636128972082	186123
78d09e204bfc6cab81ed8e2e8fbe38d4c7532a82	eye tracking and eeg features for salient web object identification		We propose a biological-based feature comparison for identifying salient Web objects. We compare several features extracted from eye tracking and EEG data with a baseline given by mean fixation impact introduced by Buscher. For this, we performed an experiment with 20 healthy subjects in which gaze position, pupil size and brain activity were recorded while browsing in a Web site adaptation. Our results show that there are EEG features that could be related to Web user attention in objects. In particular the Gamma Band RMS and the EEG Variance indicate that the longer subjects view a web object (more attention), the less brain signal disturbance appears. We also discarded pupil size features due to low correlation with baseline. These results suggest that EEG features could be used to identify salient objects without using the time users spent on them as done in previous methodologies.	baseline (configuration management);electroencephalography;expect;eye tracking;gamma correction;iterated conditional modes;mean squared error	Gino Slanzi;Claudio Aracena;Juan D. Velásquez	2015		10.1007/978-3-319-23344-4_1	computer vision;geography;multimedia;communication	ML	-35.09000765255671	-50.56808339770047	186915
db768ae6de72a704b19f62b42666d213c1d81cb1	uav for everyone : an intuitive control alternative for drone racing competitions		As many technological innovations, the Unmanned Aerial Vehicles (UAV) were created for military purposes. However, these aircrafts are now a reality accessible for common civilians and are used to explore new possibilities in areas like cinema, photography or surveillance. The technology easily reached other application fields and turned into a new sports category as well, supported by many drone racing competitions that happen around the world. There are many alternatives to control a quadcopter, but the most accurate relies on a robust and heavy handheld remote controller that requires dexterity to be a good pilot. This limits the control of the UAV to users comfortable with this kind of interaction, discarding people with reduced fine motor skills, hand malformations or elders with low learning capacity from the possibility of piloting a quadcopter and participate in competition events. An alternative to these remote controllers should be developed to overpass the mentioned disadvantages. The solution proposed in this paper is an intuitive and accurate control system made of two small and lightweight wearable devices capable of detecting patterns based on motion events. These patterns are then sent to a mobile application responsible for controlling the drone. Wearing the described devices like a high-tech glove, the users can pilot the UAV through simple and intuitive upper limb movements, being the changes in the orientation of each device over time identified as a specific pattern. This solution presents a new approach to the control of UAV that improves the ease of piloting them and decreases the time that is required to learn how to handle them.		Roberto Ribeiro;J. Ramos;David Safadinho;Ant&#x00F3;nio Manuel de Jesus Pereira	2018	2018 2nd International Conference on Technology and Innovation in Sports, Health and Wellbeing (TISHW)	10.1109/TISHW.2018.8559538	simulation;control theory;wearable technology;drone;wearable computer;mobile device;control system;quadcopter;computer science;internet of things	Robotics	-40.191767493944994	-46.6536859114709	187938
1879384ff80710f81cc20144df731ad66b434a78	a subjunctive exploratory search interface to support media studies researchers	subjunctive interface;exploratory search;universiteitsbibliotheek;humanities	Media studies concerns the study of production, content, and/or reception of various types of media. Today's continuous production and storage of media is changing the way media studies researchers work and requires the development of new search models and tools.  We investigate the research cycle of media studies researchers and find that it is an iterative process consisting of several search processes in which data is gathered and the research question is refined. Changes in the research question, however, trigger new data gathering processes.  Based on these outcomes we propose a subjunctive exploratory search interface to support media studies researchers in refining their research question in an earlier stage of their research. To assess the subjunctive interface we conduct a user study and compare to a traditional exploratory search interface.  We find that with the subjunctive interface users explore more diverse topics than with the standard interface and that users formulate more specific research questions. Although the subjunctive interface is more complex, this does not decrease its usability.  These findings suggest that the subjunctive interface supports media studies researchers. The advantage of a subjunctive interface for exploration suggests a new direction for the development of exploratory search systems.	exploratory search;iteration;streaming media;usability testing	Marc Bron;Jasmijn van Gorp;Frank Nack;Maarten de Rijke;Andrei Vishneuski;Sonja de Leeuw	2012		10.1145/2348283.2348342	human–computer interaction;computer science;multimedia	Web+IR	-34.619834127131	-49.79346098116333	190221
3d9a05ec42a266c689eac634918d9e523d8f1689	an adaptive personality model for ecas	modelizacion;animacion por computador;metodo adaptativo;cabeza;interfase usuario;belief;theory and modeling;speech synthesis;personality;user interface;gesture;personnalite;base connaissance;methode adaptative;lenguaje marcacion;voice;voz;man machine system;modelisation;vie artificielle;croyance;texto hacia palabra;emotion emotionality;adaptive method;cognition;facial animation;personalidad;text to speech;cognicion;sistema hombre maquina;talking head;base conocimiento;emotion emotivite;interface utilisateur;sintesis palabra;head;texte a parole;emocion emotividad;tete;creencia;computer animation;modeling;markup language;geste;artificial life;dialogue manager;synthese parole;virtual human markup language;gesto;langage marquage;voix;systeme homme machine;knowledge base;animation par ordinateur	Curtin University’s Talking Heads (TH) combine an MPEG-4 compliant Facial Animation Engine (FAE), a Text To Emotional Speech Synthesiser (TTES), and a multi-modal Dialogue Manager (DM), that accesses a Knowledge Base (KB) and outputs Virtual Human Markup Language (VHML) text which drives the TTES and FAE. A user enters a question and an animated TH responds with a believable and affective voice and actions. However, this response to the user is normally marked up in VHML by the KB developer to produce the required facial gestures and emotional display. A real person does not react by fixed rules but on personality, beliefs, good and bad previous experiences, and training. This paper reviews personality theories and models relevant to THs, and then discusses the research at Curtin over the last five years in implementing and evaluating personality models. Finally the paper proposes an active, adaptive personality model to unify that work.	dialog system;experience;knowledge base;lazy evaluation;modal logic;speech synthesis;talking angela;theory;virtual human markup language	He Xiao;Donald Reid;Andrew Marriott;E. K. Gulland	2005		10.1007/11573548_82	speech recognition;systems modeling;cognition;computer facial animation;computer science;artificial intelligence;belief;computer animation;linguistics;markup language;personality;user interface;head;gesture;speech synthesis;voice;artificial life	NLP	-39.556190275653535	-48.839977332830266	190539
2ff398a1eb560ddca8e2dce5b5814b10a372a03d	multirobot internet-based architecture for telemanipulation: experimental validation	distributed system;manipulators;user interface;virtual interface;system performance;time delay;manipulators interactive programming internet industrial robots multi robot systems telerobotics user interfaces;internet service robots user interfaces delay effects bandwidth communication system control control systems joining processes service oriented architecture laboratories;internet;telemanipulation online robots system architecture user interface communications time delay limited bandwidth robot control management educational robots industrial robots web based system multirobot internet based architecture;industrial robots;multi robot systems;telerobotics;web based system;experimental validation;system architecture;user interfaces;interactive programming	The design of online robots is a difficult task that must take into account multiple aspects like for example: (1) The System Architecture, (2) The User Interface, (3) Communications, (4) Time delay, (5) Limited Bandwidth, etc. Besides this, taking into account that the web permits multiple people to easily access a single system, methods for managing the control o f a unique robot must be designed (e.g. off-line virtual interfaces, connecting several robots to the system, etc.). In this paper we present the system architecture that have been used in our laboratory to let users program remotely two educational and two industrial robots through the same web-based system. Experimental results show different alternatives to organize the architecture and focus on the system performance aspects.		Raúl Marín;Pedro J. Sanz;Patricio Nebot;Roger Esteller-Curto	2003		10.1109/ICSMC.2003.1244442	embedded system;simulation;computer science;artificial intelligence;computer performance;user interface;systems architecture	Robotics	-39.184908639659064	-45.664818860473154	192383
1af43b6a777e2d0d6ec9c0b74f9efa51e1c86a7e	cerebral and gaze data fusion for wheelchair navigation enhancement: case of distracted users				Hachem A. Lamti;Mohamed Moncef Ben Khelifa;Vincent Hugel	2019	Robotica	10.1017/S0263574718000991	gaze;control engineering;wheelchair;engineering;computer vision;sensor fusion;artificial intelligence	Robotics	-40.382685275668265	-45.12983194568319	193774
22a1c53994cc54df21428b2b5aab11d53c8597cd	why we filter our photos and how it impacts engagement		A variety of simple graphical filters are available to camera phone users to enhance their photos on the fly; these filters often stylize, saturate or age a photo. In this paper, we present a combination of large-scale data analysis and small scale in-depth interviews to understand filter-work. We look at producers’ practices of photo filtering and gain insights in the roles filters play in engaging photo consumers’ by driving their social interactions. We first interviewed 15 Flickr mobile app users (photo producers) to understand their use and perception of filters. Next, we analyzed how filters affect a photo’s engagement (consumers’ perspective) using a corpus of 7.6 million Flickr photos. We find two groups of serious and casual photographers among filter users. The serious see filters as correction tools and prefer milder effects. Casual photographers, by contrast, use filters to significantly transform their photos with bolder effects. We also find that filtered photos are 21% more likely to be viewed and 45% more likely to be commented on by consumers of photographs. Specifically, filters that increase warmth, exposure and contrast boost engagement the most. Towards the ongoing research in social engagement and photo-work, these findings suggest several practical implications such as designing filters for both serious and casual photographers or designing methods to prioritize and rank content in order to maximize engagement.	camera phone;flickr;graphical user interface;interaction;mobile app;on the fly;text corpus	Saeideh Bakhshi;David A. Shamma;Lyndon Kennedy;Eric Gilbert	2015			on the fly;internet privacy;social engagement;camera phone;multimedia;computer science;casual	HCI	-34.07753393350995	-48.41131613999119	193779
6aaa039beb09d77c1a9bb2b02d6fe7cb63dc5319	countering intrusiveness using new security-centric ranking algorithm built on top of elasticsearch		Mobile computing is dominating the technology market and it is expected to continue growing. Mobile thirdparty applications without any doubt contribute vastly to this growth. However, intrusive apps that tend to ask for plenty of permissions are becoming a common trend that influence the privacy of mobile users. Solutions have been proposed to detect and remove malicious apps from online markets or detect them after being installed. Yet, dealing with intrusive apps requires high user involvement and best judgment and comprehension. There have been a very few works that aim at helping mobile users make calculated decisions to avoid intrusive apps. In this paper, we are proposing and evaluating a new security-centric ranking algorithm built on top of the Elasticsearch engine to assist users evade installing intrusive apps. The algorithm calculates an intrusiveness score for an app based on its requested permissions, received system actions, and on the privacy preferences of users. In doing so, we are proposing a new approach to capture users' privacy preferences. The approach is evaluated through an online user study. The ranking algorithm is being evaluated on a large corpus of Android apps contextual data and APK files by conducting a pilot study and benchchmarking study. The results show that the scoring and reranking steps add very small overhead. Moreover, participants of the online and pilot studies gave positive feedback for the ranking algorithm and privacy preferences solicitation approach. The results suggest that our proposal would definitely protect the privacy of mobile users and pushes developers into requesting the minimum privileges that are required for their apps to function.	adobe flash player;algorithm;android;benchmark (computing);elasticsearch;malware;mobile app;mobile computing;mobile device;overhead (computing);positive feedback;principle of least privilege;privacy;relevance;server (computing);text corpus;usability testing;web search engine	Fadi Mohsen;Hamed Abdelhaq;Halil Bisgin;Andrew Jolly;Michael Szczepanski	2018	2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)	10.1109/TrustCom/BigDataSE.2018.00147	android (operating system);contextual design;comprehension;installation;mobile computing;algorithm;computer science;ranking;intrusiveness	SE	-37.88608630507345	-50.84798862312198	193837
86dd2cd2c6306d3409d4defc6775c73c948df0e5	user strategies for handling information tasks in webcasts	webcasting;real time;search strategy;table of contents;multimedia systems;search strategies;user interaction;information tasks;epresence	Webcast systems support real-time webcasting, and may also support access to the stored webcasts. Yet, research rarely examines issues concerning the interface to webcast systems, another form of multimedia system. This paper focuses specifically on how stored webcasts are re-used. Sixteen participants performed three typical information tasks using ePresence, a webcasting system that handles both live and stored video, and contains several tools: a video window, a timeline of the webcast, slides used by the presenter, and a moderator-generated table of contents, that facilitate user access to the intellectual content of a stored video. Use takes place at the level of the webcast, and our analysis assessed user interactivity. The results showed that different types of tasks need different strategies and tools.	google moderator;interactivity;real-time transcription;timeline;video	Christine Dufour;Elaine Toms;Jonathan Lewis;Ronald Baecker	2005		10.1145/1056808.1056912	simulation;human–computer interaction;table of contents;computer science;operating system;webcast;multimedia;world wide web	HCI	-37.1612096903312	-50.15549892735073	193970
dbde8b08a63e29a8fb4199451411a0cc2d1972bd	emphasis for highly customized documents	publishing;high customization;emphasis;aesthetic measure	Research and development of automatic layout engines for variable data printing raised an important question of automatically evaluating computer generated documents [1]. It is well-established that highly customized and personalized documents present better value. However, this is only true if the quality of personalized documents is compatible with the quality of documents manually created by professional designers. There are many important aesthetical principles that should be followed during document creation. One of them is an aesthetical principle of emphasis. This principle is based on findings by perceptual psychologists that an eye moves from big to small objects, from bright and intense to subdued and faded colors, from colors to black and white, from irregular to regular shapes and others. Emphasis is a very important aesthetic principle in publishing. It means something that stands out, dominates a design and becomes a centre of interest. It is used for creating a focal point and for drawing attention. Emphasis becomes even more important for highly customized publishing. This aspect is often overlooked even during manual catalogue creation. The result of obeying this principle converts just a good looking document into a valuable sales tool. Sale items that are the most appropriate or relevant for this particular customer are emphasized, thus increasing chances for the document to be looked at. Content selection for every individual copy is based on a relevancy score. However, not everything selected for a client is equally important. For example, there is a most relevant item, a special offer sale item, a least relevant and even optional content. Here we present a system for automatic prediction of a document’s fixation points and subsequent document improvement [2]. The former is based on the calculation of a bottom-up saliency map by applying center-surround operators at multiple spatial scales and multiple channels [3]. Responses are then combined with different weights according to their respective prominence. In our proposed framework, the original bottom-up method is used jointly with the document semantics and structure that are readily available during automatic document creation in publishing. The main steps of our approach are: I) generate a saliency map using a modified version of [3]; II) evaluate locations and distributions of fixation points: a) there should be a few, but not too many such points, and b) they should be well distributed across the page and not too close to each other; III) map fixation points to the underlying document structure to identify emphasized elements: the most important/relevant items should be emphasized while the least important items should not; and finally IV) perform improvement steps for de-emphasizing low-relevancy items, while re-emphasizing high relevancy ones. These steps may include changing adjustable parameters (like for example, colour, intensity, contrast with adjacent background, etc) for some elements, adding or deleting borders, and finally scaling up or down and repositioning items.	automatic layout;bottom-up parsing;color;emoticon;focal (programming language);image scaling;layout engine;obedience (human behavior);pay per sale;personalization;relevance;spatial scale;top-down and bottom-up design;variable data printing	Helen Balinsky;Maurizio Pilu	2005		10.1145/1096601.1096612	emphasis;computer science;publishing;multimedia;computer graphics (images)	Web+IR	-36.09809822226521	-48.932541427070696	195069
5617f46b362db1f968266f1c8097f956faef52c5	dynamic playlist generation: a case study		One of the central challenges in any music delivery system is that of playlist generation, or choosing which songs to play and in what order. Many existing studies of playlist generation consider the problem of constructing complete playlists from a finite library of songs subject to a given set of constraints. Such methods are not suitable for generating playlists on the fly, starting on demand and having unknown duration, or drawing from very large or infinite sets of songs. We present a practical implementation of generating playlists one song at a time as needed. The goal of finding globally optimal or foresighted playlists is set aside in favor of expediently selecting a single song to continue a given sequence. Song selection is based on a listener’s genre and mood choices in conjunction with history and preferences. We use standard metadata as well as our own custom subgenres and automated multidimensional mood estimations. Our method is compatible with collections of any size. It is currently in use by Sourcetone Interactive Radio (SIRTM), a mood-based streaming radio service.	algorithm;approximation;coherence (physics);database;maxima and minima;on the fly;personalization;real-time computing	Chad Wagner	2010			computer science	Web+IR	-34.68237986417719	-46.69496694908687	195215
db4abfb46608881b357ce7d007a1570b7570c108	improving website structure through reducing information overload		Abstract It is well known that website success relies heavily on its usability. Previous studies find that website usability depends greatly upon its visual complexity which has significant effects on usersu0027 psychological perception and cognitive load. In this study, we use a pageu0027s outdegree as one measurement for its visual complexity. In general, outdegrees should be kept not too high in page design as large outdegrees are often signs of high page complexity which can adversely affect user navigation. This is particularly desirable and critical for maintaining website structures, because as a website evolves over time, the need for information also changes. Website structures must be updated periodically to align with usersu0027 information needs. In this process, obsolete links should be removed to avoid clustering of links that could cause information overload to users. However, the need to slim down website structures is understudied in the literature. In this paper, we propose a mathematical programming model that reduces information load by removing links from highly clustered pages while minimizing the impact to users. Results from tests on a real dataset indicate that the model not only significantly reduces page complexity with little impact on user navigation, but also can be solved effectively. The model is also tested on large synthetic datasets to demonstrate its remarkable scalability.	information overload	Min Chen	2018	Decision Support Systems	10.1016/j.dss.2018.03.009	computer science;data mining;web usability;scalability;cluster analysis;information needs;information overload;usability;cognitive load	HCI	-35.14085260886784	-51.54104610130414	196295
4fa5437026f420a750be5c3cf0a91336dece3390	sam: a perceptive spoken language-understanding robot	lenguaje natural;description systeme;interfase usuario;error recovery;system description;systeme intelligent;english language;reconocimiento palabra;user interface;real time;relacion hombre maquina;sistema inteligente;distributed processing;langage naturel;manipulateur;planning artificial intelligence;man machine relation;real time operating system;natural languages;robotics;raisonnement;frame based knowledge system speech activated manipulator sam perceptive spoken language understanding robot english language sentences speech recognition natural language understanding robotic reasoning arm motion planning semantic analysis error recovery rules;natural language understanding;manipulador;natural language;knowledge systems;speech recognition natural languages planning artificial intelligence real time systems robots;robots;intelligent system;razonamiento;motion planning;robotica;speech recognition;speech understanding;interface utilisateur;descripcion sistema;robotique;relation homme machine;reconnaissance parole;reasoning;natural languages robot sensing systems speech recognition speech analysis manipulators human robot interaction vocabulary motion control communication system control control systems;traitement reparti;manipulator;semantic analysis;tratamiento repartido;spoken language understanding;real time systems	Speech activated manipulator (SAM), a reasoning robotic system with sensory capabilities that interacts with a human partner using natural language, is described. The robot understands, in real time, about 1041 semantically meaningful naturally spoken English language sentences using a vocabulary of about 200 words. SAM includes developments in mechanical control, real-time operating systems, multiprocessor communication and synchronization, kinematics, sensors and perception techniques, speech recognition and natural language understanding, robotic reasoning with gripper and arm motion planning. Speech recognition is augmented with semantic analysis and evaluation to form a complete speech understanding system. Used in conjunction with error recovery rules in the robot expert and frame-based knowledge system, SAM is robust and resistant to user errors. The most interesting aspects of the SAM system are described. Observations and experiences are discussed along with some advice for those interested in building similar systems. >	robot	Michael K. Brown;Bruce Buntschuh;Jay G. Wilpon	1992	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.199464	natural language processing;speech recognition;computer science;artificial intelligence;machine learning;natural language;robotics	Robotics	-39.4399630132759	-49.00308412481244	196991
c88f2b8984cd4d71ae5e8bbb4e921652d9884ef5	listening through a vibration motor	vibra motor;smartphone privacy;speech processing;smartphone security;vibratory communication;speech;vibration motor;sound recording;communication through physical vibration;vibration;nirupam roy;smartphone;ripple	This paper demonstrates the feasibility of using the vibration motor in mobile devices as a sound sensor, almost like a microphone. We show that the vibrating mass inside the motor -- designed to oscillate to changing magnetic fields -- also responds to air vibrations from nearby sounds. With appropriate processing, the responses become intelligible, to the extent that humans can understand the vibra-motor recorded words with greater than 80% average accuracy. Even off-the-shelf speech recognition softwares are able to decode at 60% accuracy, without any training or machine learning. We present our overall techniques and results through a system called VibraPhone, and discuss implications to both sensing and security.	machine learning;microphone;mobile device;speech recognition	Nirupam Roy;Romit Roy Choudhury	2016		10.1145/2906388.2906415	speech recognition;computer science;speech;vibration;speech processing	Mobile	-38.71280872185735	-45.488258221821646	198908
f766c9a4c6fed541254db4cf8abbcc682fb16f48	the developing market for medical robotics	telemedicina;aplicacion medical;telemedicine;robotics;telemedecine;telemedicine medical robotics remote presence robotically assisted surgery;medical robotics;medical computing;telemedicine medical robotics market drivers health care robotic systems remote presence robotically assisted surgery;medical robotics medical services medical diagnostic imaging costs medical treatment minimally invasive surgery commercialization aging robots prosthetics;estudio caso;etude cas;robotica;robotic systems;patient treatment;medical application;robotique;robotically assisted surgery;robot;remote presence;telemedicine health care medical computing medical robotics patient treatment;market drivers;application medicale;health care	This paper discusses the developing market for medical robotics. It first describes some of the dynamics and market drivers in health care, and then provides an outline of the areas of consideration when developing a commercial medical robot. The paper also offers three case studies of robotic systems that have been commercialized. Finally, it summarizes some of the key ingredients to be considered for the commercialization process	medical robot;robotics	Yulun Wang;Steven E. Butner;Ara Darzi	2006	Proceedings of the IEEE	10.1109/JPROC.2006.880711	robot;simulation;computer science;biological engineering;robotics;health care	Robotics	-39.04262443043998	-47.7059172880306	199044
448a2c95b9685193dfd339f3355766ff38d8197e	evaluating the performance of a face movement based wheelchair control interface in an indoor environment	geriatrics;human computer interaction;performance evaluation;hands free control;eye detection;intelligent wheelchairs;hci;hmi;wheelchairs electric vehicles face recognition geriatrics handicapped aids human computer interaction performance evaluation;system performance;hci intelligent wheelchairs eye detection hands free control face detection hmi;qa75 electronic computers computer science;electrodes;handicapped aids;face recognition;human machine interface;feature extraction;indoor environment;wheelchairs electromyography face humans feature extraction electrodes cameras;electric powered wheelchair performance evaluation face movement based wheelchair control interface indoor environment facial movement human machine interface intelligent wheelchair hands free control;electric vehicles;electromyography;face;humans;electric power;face detection;cameras;control strategy;wheelchairs	This paper presents a novel facial movement based human machine interface for an intelligent wheelchair to operate in an indoor environment. Five random selected intact subjects are designated to control a wheelchair by using the proposed control interface. The testing is carried out in a designed indoor environment. The system performance is evaluated by implementing same tasks ten times, with the criteria of control easiness and the time spent on each task. The experimental result shows that this new control strategy can assist disabled and elderly users for hands-free control of an electric powered wheelchair.	control theory;user interface	Lai Wei;Huosheng Hu;Tao Lu;Kui Yuan	2010	2010 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2010.5723358	human–machine interface;face;embedded system;computer vision;face detection;simulation;electric power;feature extraction;computer science;engineering;electrode;user interface;geriatrics	Robotics	-40.478513137632845	-45.28534606071986	199199
3cfaf0398106e91ac54663677008b42fbd7f9f1c	a mechanism for filtering distractors for doodle passwords	authentication;doodle;distractor;algorithm;qa75 electronic computers computer science	Graphical authentication holds some potential as an alternative to the ubiquitous password. Graphical authentication mechanisms typically present users with one or more challenge sets composed of a number of images: one target image surrounded by distractor images. Unfortunately, this means it tends to be more time-consuming than password entry and to alleviate this, we need to streamline the process as much as possible to maximize efficiency. The distractors must be chosen with care so as to ensure that users do not become confused by similarities with the target image. It is especially challenging to achieve this filtering with minimalist image types, such as hand-drawn doodles. This paper explores the issues related to filtering the distractor images used in graphical authentication mechanisms using minimalist images. We present an algorithm for automatically classifying minimalist images in terms of visual similarity. The principles outlined here can also be used to assess the similarity of other minimalist image types such as signatures and handwritten numerals.		Ron Poet;Karen Renaud	2009	IJPRAI	10.1142/S0218001409007430	computer vision;computer science;artificial intelligence;theoretical computer science;authentication	ECom	-34.42304712312549	-45.35616375384839	199330
