id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
291530f2893d40573ab968a467ff513790292125	visual model for one cad tool's algorithm representation	computer aided design;animation algorithm design and analysis design automation psychology software algorithms software tools application software test pattern generators automatic test pattern generation microprocessors;education computer aided design cad tools visual representation animation teaching human factors;cad;computer aided instruction;human factors computer aided instruction teaching data visualisation computer animation cad;data visualisation;human factors;visual modeling;visual representation;computer animation;algorithm design;teaching	"""Visual representation of one algorithm’s mathematical apparatus from the field of Computer Aided Design (CAD) Tools of computer hardware is suggested. Visual representation of the algorithm constitutes animation sound-film. The rich in the content of the paper is the verbal elucidation of visual representation forms, such as """"static images"""", """"dynamic images"""", """"moving"""", """"scenario"""", and so on, and also the comparison of these forms with the mathematical conceptions. The problem considered is an extraordinary way of learning of serious mathematical apparatus of algorithm designed for software realisation in CAD tools application. Really, it is needed in modern teaching process sometimes. It is supposed to accompany the report by animation fragment demonstration in variant of teacher's explanation of serious material. This fragment will present a little peace of algorithm working for a very simple example."""	algorithm;computer hardware;computer-aided design	Galina Yaitskova	2002		10.1109/IV.2002.1028806	computer vision;computer facial animation;computer science;theoretical computer science	HCI	-39.39746646967852	-31.535760125155868	175037
3225585697c428a083d3f51c36c8e4a96dfa6548	transforming your shadow into colorful visual media: multi-projection of complementary colors	historical sites;spatial narratives;virtual reality;media art;multimedia information system;audio tours;h 5 1 multimedia information systems artificial augmented and virtual realities;cemeteries;design;edutainment;j 5 arts and humanities architecture;mixed reality;real time systems;experience design	This paper proposes a real-time system that transforms your shadows on a floor into colorful visual media. This system is based on the effect of complementary color and multiprojection techniques. By exactly calibrating the system geometrically and photometrically, our system makes it possible to display various images such as texture animation, colorful picture, text and live videos in your shadows without any digitized artifact or latency. Since it can display any images you like, it is applicable for various purposes such as media art, entertainment, and advertisement.	color;computer animation;real-time clock;real-time computing	Yugo Minomo;Yasuaki Kakehi;Makoto Iida	2005		10.1145/1178477.1178485	visual arts;art;multimedia;computer graphics (images)	Graphics	-40.93491709546489	-36.49823338309225	175166
6f7ead750d30b06bdf4429bccdb93528dfa0dc83	an aid to hidden surface removal in real time cgi systems	real time;hidden surface removal	One of the limiting factors in the development of real-time Computer Generated Image systems for displaying perspective colour scenes is finding a suitable solution to the hidden surface problem. This paper presents a solution to this problem, whereby spatial properties of a three-dimensional 'model' held in the Computer Generated Image system database are utilized in order to minimize hidden surface computations for producing moving perspective scenes. This solution is particularly acceptable to situations involving a fixed model and moving eye point. Often Computer Generated Image systems resort to processing individual surfaces from objects in the model to obtain display priority levels; the solution presented is based upon the use of preprocessed relative priority levels which only require complete objects to be given priority levels thus reducing real-time computation. Once an absolute display priority level for an object is found it will be shown that all surfaces forming that object have known display priority levels. Techniques used to obtain object display priority levels are discussed, together with background information concerning the hidden surface problem.	common gateway interface;hidden surface determination	D. J. Tomlinson	1982	Comput. J.	10.1093/comjnl/25.4.429	computer vision;simulation;hidden surface determination;computer science;computer graphics (images)	Embedded	-35.594017771180745	-36.895593184970195	175412
56860581281a2c7f3bc1464950dc0e38e232d49b	style translation to create child-like motion		Animated child characters are increasingly important for educational and entertainment content geared towards younger users. While motion capture technology creates realistic and believable motion for adult characters, the same type of data is hard to collect for young children. We aim to algorithmically transform adult motion capture data to look child-like. We implemented a warping based style translation algorithm, and show the results when this algorithm is applied to adult to child transformation.	algorithm;image warping;motion capture	Yuzhu Dong;Aishat Aloba;Lisa Anthony;Eakta Jain	2018		10.2312/egp.20181023		HCI	-39.54371436652803	-36.00438725061705	175515
877dba432086b5b56d8078ac85269aa93fa5e6ac	thinking representation tools for science education with drawings	software;drawings;polka;image processing;galop thinking representation sceinece education drawings polka;computer aided instruction;galop;sceinece education;thinking representation;abstracts;image processing computer aided instruction computer animation;animation;animation abstracts educational institutions reflection predictive models software;predictive models;computer animation;reflection;galop thinking representation tools science education drawings polka figure objects science image animation making system	"""Drawings is a method of learning with expressing children's idea as pictures. We developed Polka for children to express their image by combining simple figure objects. Polka can easily show their drawing process for them to explain children's science image. We believe Polka is one of good drawing tools for expressing children's science idea and their thinking process. However, it is generally difficult for children to draw pictures including some movement. Therefore, as the next stage, we developed an animation making system called """"Galop"""" for science education with Drawings. Galop aims to deepen children's understandings by expressing objects and phenomenon with some moving as dynamic models. In the drawing environment provided by Galop, children express dynamic phenomenon as animation. Through the process of animation making, they get deep understanding about the dynamic phenomenon by checking objects moving on the drawing environment. This paper describes development of two thinking representation tools: Polka for drawing static images and Galop for expressing dynamic phenomenon based on Drawings."""	cut (graph theory);experience;image;vector graphics	Toshihiro Hayashi;Hayashi Nakayama;Hiroyuki Tarumi	2012	2012 Third International Conference on Emerging Intelligent Data and Web Technologies	10.1109/EIDWT.2012.34	computer vision;computer science;multimedia;computer graphics (images)	HCI	-39.43864160810448	-31.694473240229073	176070
4b73e53cf9a9cfafc1a19da496c0352c6305fd9b	simulation and modeling	orthopedic surgery;simulation and modeling;medical simulation;anthropologists using simulations evaluating judgments and decisions in sociocultural contexts;application software;prosthetics computational modeling shape computer graphics testing solar system orthopedic surgery data visualization medical simulation application software;computer graphics;kronenfeld and kaus s 1993 starling simulation of durkheimian emergent properties;distinguishing a simulation model from any other model forms;prosthetics;testing;computational modeling;shape;simulations never directly explaining any actual empirical phenomena;data visualization;solar system;bf psychology;evaluating theory by identifying its capacity reducing complexity of another description;approach cognitive in the important sense giving way exploring knowledge in action;gn anthropology;h social sciences;simulations being useful for many purposes;simulation alternative to simple speculation means for evaluating speculation;schank and abelson s 1977 simulation of restaurant conversations individuals in a simulation	A method for removing the discontinuity in G/sub ds/ going from the linear region to the saturation region in the MOS level 3 model of SPICE by modifying the channel length modulation expression is described. A detailed analysis of the problem and simulation results before and after the modification are presented. u003e	simulation	Michael L. Rhodes	1997	IEEE Computer Graphics and Applications	10.1109/MCG.1997.610197	medical simulation;computer vision;dynamic simulation;application software;simulation;orthopedic surgery;shape;computer science;artificial intelligence;operating system;data mining;mathematics;geometry;solar system;software testing;computer graphics;computational model;data visualization;algorithm;computer graphics (images);mechanical engineering	Visualization	-36.14566967744403	-36.51432039424268	176177
b3e1fe5539c16844349c9d78a7b18409eb2f5265	on improving urban environment representations	appearance;urban models;computer graphics;simulation;urban physics;aging;rendering	*Correspondence: Xavier Pueyo, Centre de Recerca ViRVIG-UdG, Universitat de Girona, Edifici P4, Campus de Montilivi, Girona E-17071, Spain e-mail: xavier.pueyo@udg.edu Computer graphics has evolved into a mature and powerful field that offers many opportunities to enhance different disciplines, adapting to the specific needs of each. One of these important fields is the design and analysis of Urban Environments. In this article, we try to offer a perspective of one of the sectors identified in Urban Environment studies: Urbanization. More precisely, we focus on geometric and appearance modeling, rendering, and simulation tools to help stakeholders in key decision stages of the process.	computer graphics;data visualization;email;geometric modeling;graphical user interface;rendering (computer graphics);simulation;usability	Xavier Pueyo;Carles Bosch;Gustavo Patow	2014	Front. Robotics and AI	10.3389/frobt.2014.00017	simulation;rendering;computer science;multimedia;computer graphics;computer graphics (images)	Graphics	-35.89654722984085	-31.846349951502052	176663
8e7c75db82ebdd663b9ff4f62fc176cbb7df0ccb	rapid prototyping for the substantiation of architectural design interaction	fabrication;design model;stress;architectural design;art;rapid prototyping industrial;content specific image rapid prototyping rp architectural design interaction 3d design visualization system design annotation substantiation 3d printer design model;printers;application software;content specific image;graphical user interfaces data visualisation solid modelling architectural cad rapid prototyping industrial virtual reality image texture printers;prototypes;3d printer;virtual reality;surface texture;image texture;data visualisation;rapid prototyping;graphical user interfaces;rp;data visualization;architectural design interaction;design annotation substantiation;architectural cad;physical model;visual system;3d design visualization system;architecture;graphics;prototypes data visualization printers graphics virtual reality fabrication surface texture art application software stress;solid modelling	We present a 3D design visualization system that is used for substantiating design annotation behavior in a 3D world through physical models. As an experiment and development work, the visualization of 3D data is conducted through the application of a commercially available 3D printer that outputs design models with graphic instruction notes left on surfaces. Content-specific images are also left on models as a kind of physical record in a construction case.	rapid prototyping	Naai-Jung Shih	2003		10.1109/IV.2003.1217968	computer vision;engineering;engineering drawing;computer graphics (images)	HCI	-39.3061078439165	-31.23507927833622	176776
6ae396e11661fc97093eebcc328e00ee324c9b5d	a streaming-based solution for remote visualization of 3d graphics on mobile devices	frames per second;video streaming;client server system;personal communication networks;multimedia;mobile device;personal digital assistant;application software;voxels;mpeg video;cluster based rendering remote visualization 3d graphics mobile devices personal digital assistants tablet pc cellular phones 3d model visualization graphics cards chromium software mpeg video streaming smart phones object visualization textured polygons voxels multimedia client server system;smart phone;smart phones;client server systems;acceleration;image texture;personal digital assistants;multimedia computing;chromium software;tablet pc;computer communication networks computer graphics computers handheld data compression echocardiography three dimensional equipment design equipment failure analysis signal processing computer assisted software;visualization;3d model;video streaming client server systems image texture mobile computing multimedia computing notebook computers solid modelling;streaming media;chromium;graphics cards;remote visualization;notebook computers;mpeg;cluster based rendering remote visualization chromium mpeg mobile devices;textured polygons;mpeg video streaming;mobile computing;cluster based rendering;3d graphics;mobile devices;3d model visualization;graphics;visualization graphics streaming media personal digital assistants personal communication networks hardware cellular phones application software acceleration chromium;cellular phones;object visualization;solid modelling;hardware	Mobile devices such as personal digital assistants, tablet PCs, and cellular phones have greatly enhanced user capability to connect to remote resources. Although a large set of applications is now available bridging the gap between desktop and mobile devices, visualization of complex 3D models is still a task hard to accomplish without specialized hardware. This paper proposes a system where a cluster of PCs, equipped with accelerated graphics cards managed by the Chromium software, is able to handle remote visualization sessions based on MPEG video streaming involving complex 3D models. The proposed framework allows mobile devices such as smart phones, personal digital assistants (PDAs), and tablet PCs to visualize objects consisting of millions of textured polygons and voxels at a frame rate of 30 fps or more depending on hardware resources at the server side and on multimedia capabilities at the client side. The server is able to concurrently manage multiple clients computing a video stream for each one; resolution and quality of each stream is tailored according to screen resolution and bandwidth of the client. The paper investigates in depth issues related to latency time, bit rate and quality of the generated stream, screen resolutions, as well as frames per second displayed	3d computer graphics;3d modeling;3d rendering;application framework;bridging (networking);cellular phone;chromium;client-side;clients;client–server model;codec;compression;desktop computer;devices;display resolution;embedding;frame (physical object);graphics hardware;graphics processing unit;hardware acceleration;imagery;interactive visualization;mpeg transport stream;mobile device;moving picture experts group;multimedia;opengl;performance;personal digital assistant;physical object;protocols documentation;server (computer);server (computing);server-side;smartphone;streaming media;tablet dosage form;tablet computer;video recording;video card;volume rendering;voxel	Fabrizio Lamberti;Andrea Sanna	2007	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2007.29	embedded system;computer science;mobile device;multimedia;mobile computing;computer graphics (images)	Visualization	-34.9207483139301	-34.24348847793425	177341
533280565012abb39fe1ca5d72b68d049c3d4435	intuitive and interactive modification of large finite element models	autostereoscopic display;automotive engineering;feedback mechanism;manipulators;automotive industry;engineering graphics;haptic device;interaction;cad;virtual reality;finite element;autostereoscopy finite element modeling interaction manipulators;finite element modeling;data visualisation;virtual prototyping;finite element methods design automation automotive engineering virtual prototyping product development analytical models safety vehicle crash testing assembly acceleration;visualization technique;structure and function;industrial production;finite element model;autostereoscopy finite element models virtual prototyping industrial product development automotive industry cad data visualization virtual reality interactive modification manipulators;finite element analysis;data visualisation cad automobile industry automotive engineering engineering graphics virtual prototyping virtual reality product development finite element analysis interactive systems;finite element analysis fea;interactive systems;simulation model;autostereoscopy;automobile industry;product development	Virtual prototyping is increasingly replacing real mock-ups and experiments in industrial product development. Part of this process is the simulation of structural and functional properties, which is in many cases based on Finite Element Analysis (FEA). One prominent example from the automotive industry is the safety improvement resulting from crash worthiness simulations. A simulation model for this purpose usually consists of up to one million finite elements and is assembled from many parts which are individually meshed out of their CAD representation. In order to accelerate the development cycle, simulation engineers want to be able to modify their FE models without going back to the CAD department. Furthermore, valid CAD models might even not be available in preliminary design stages. However, in contrast to CAD, there is a lack of tools that offer the possibility of modification and processing of finite element components while maintaining the properties relevant to the simulation. In this application paper we present interactive algorithms for intuitive and fast editing of FE models and appropriate visualization techniques to support engineers in understanding these models. This includes new kinds of manipulators, feedback mechanisms and facilities for virtual reality and immersion at the workplace, e.g. autostereoscopic displays and haptic devices.	algorithm;autostereoscopy;computer-aided design;experiment;finite element method;haptic technology;immersion (virtual reality);mock object;new product development;simulation;virtual reality	Dirc Rose;Katrin Bidmon;Thomas Ertl	2004	IEEE Visualization 2004	10.1109/VISUAL.2004.58	simulation;computer science;finite element method;virtual reality;data visualization;statistics	Visualization	-37.0984781167067	-31.604538320931784	178077
1cb9c30edfa4743029d2a18b692f5ac85a5b7a3f	analyzing interfaces and workflows for light field editing		With the increasing number of available consumer light field cameras, such as Lytro, Raytrix, or Pelican Imaging, this new form of photography is progressively becoming more common. However, there are still very few tools for light field editing, and the interfaces to create those edits remain largely unexplored. Given the extended dimensionality of light field data, it is not clear what the most intuitive interfaces and optimal workflows are, in contrast with well-studied two-dimensional (2-D) image manipulation software. In this work, we provide a detailed description of subjects’ performance and preferences for a number of simple editing tasks, which form the basis for more complex operations. We perform a detailed state sequence analysis and hidden Markov chain analysis based on the sequence of tools and interaction paradigms users employ while editing light fields. These insights can aid researchers and designers in creating new light field editing tools and interfaces, thus helping to close the gap between 4-D and 2-D image editing.	light field	Marta Ortín-Obón;Adrian Jarabo;Belén Masiá;Diego Gutierrez	2017		10.1145/3102163.3102190	human–computer interaction;sequence analysis;curse of dimensionality;software;signal processing;workflow;image editing;computer science;light field	HCI	-33.7575772619087	-33.81723664547111	178094
7db66fa33f34ae2c15e4effa1fcb228e8b44118f	an information theoretic approach to camera control for crowded scenes	interest points;crowd simulation;crowds;camera control;probabilistic model;virtual environment;automatic camera control;information theoretic;information theory;computer game;scene analysis	Navigation and monitoring of large and crowded virtual environments is a challenging task and requires intuitive camera control techniques to assist users. In this paper, we present a novel automatic camera control technique providing a scene analysis framework based on information theory. The developed framework contains a probabilistic model of the scene to build entropy and expectancy maps. These maps are utilized to find interest points which represent either characteristic behaviors of the crowd or novel events occurring in the scene. After an interest point is chosen, the camera is updated accordingly to display this point. We tested our model in a crowd simulation environment and it performed successfully. Our method can be integrated into existent camera control modules in computer games, crowd simulations and movie pre-visualization applications.	crowd simulation;image resolution;information theory;map;pc game;previsualization;statistical model;user experience;virtual reality	Cagatay Turkay;Emre Koc;Selim Balcisoy	2009	The Visual Computer	10.1007/s00371-009-0337-1	smart camera;statistical model;computer vision;camera auto-calibration;simulation;information theory;computer science;virtual machine;crowd simulation;mathematics;multimedia;statistics	Vision	-37.108108482189266	-37.773535351688245	178357
6bc51357470ace237cdc73fe1bca5fd49a00407c	a constraint-based methodology for product design with virtual reality	the australian standard research classification 210000 science general;constraint based manipulation;virtual reality;journal article;product design;allowable motions;model representation;constraint recognition and constraint solving	This paper presents a constraint-based methodology for product design with advanced virtual reality technologies. A hierarchically structured and constraintbased data model is developed to support product design from features to parts and further to assemblies in a VR environment. Product design in the VR environment is performed in an intuitive manner through precise constraint-based manipulations. Constraint-based manipulations are accompanied with automatic constraint recognition and precise constraint satisfaction to establish constraints between objects, and are further realized by allowable motions for precise 3D interactions in the VR environment. The allowable motions are represented as a mathematical matrix and derived from constraints between objects by constraint solving. A procedure-based degrees-of-freedom combination approach is presented for 3D constraint solving. A rule-based constraint recognition engine is developed for both constraint-based manipulations and implicitly incorporating constraints into the VR environment. An intuitive method is presented for recognizing pairs of mating features between assembly components. Examples are presented to demonstrate the efficacy of the proposed methodology.	constraint satisfaction problem;data model;interaction;logic programming;virtual reality	Yongmin Zhong;Xiaobu Yuan;Weiyin Ma;Bijan Shirinzadeh	2009	Intelligent Automation & Soft Computing	10.1080/10798587.2009.10643022	constraint logic programming;concurrent constraint logic programming;constraint programming;binary constraint;simulation;constraint satisfaction;constraint learning;computer science;artificial intelligence;constraint satisfaction dual problem;virtual reality;constraint;product design;constraint satisfaction problem;local consistency;backtracking	AI	-38.64530721488844	-33.15078497980999	178532
a91c239f16b6b38960b2a166f057f04fd565d8d5	virtual human representation and communication in vlnet	virtual environments virtual humans vlnet realism message types animate human body face;broadband networks;motion control;virtual reality;virtual human;humans virtual environment computer graphics facial animation face application software avatars intelligent networks biological system modeling laboratories;computer animation virtual reality;human body;avatars;computer animation;virtual humans;artificial life;networked virtual environments	Using virtual humans to represent participants promotes realism in networked VEs. Different message types used to animate the human body and face impose varying network requirements, as analyzed here.	virtual actor	Tolga K. Çapin;Hansrudi Noser;Daniel Thalmann;Igor S. Pandzic;Nadia Magnenat-Thalmann	1997	IEEE Computer Graphics and Applications	10.1109/38.574680	motion control;human body;simulation;computer facial animation;computer science;artificial intelligence;instructional simulation;metaverse;virtual reality;computer animation;multimedia;artificial life;immersion;broadband networks;computer graphics (images)	Visualization	-40.00675020635356	-36.780545634086586	178607
5f07c69fcf58a9a490174a4fd4ef4b85ea53ee9f	motion in games	user interface;artificial intelligent;pattern recognition;human computer interaction	Path planning technologies have rapidly improved over the last 10 years, but further integration is needed if pathfinding engines are to drive the behavior of even more realistic characters. This paper briefly outlines existing approaches for path planning and suggests scenarios where integration of information about character’s relationships could improve the quality of path planning in games.	motion planning;pathfinding	Josef Kittler	2012		10.1007/978-3-642-34710-8	turns, rounds and time-keeping systems in games	Robotics	-37.889149703313414	-37.960363773634725	179977
f498dc680dacad6a46fce203e3f5f95f58693882	body talk: crowdshaping realistic 3d avatars with words	3d shape;anthropometry;avatars;perception;crowdsourcing;body shape;human body modeling	"""Realistic, metrically accurate, 3D human avatars are useful for games, shopping, virtual reality, and health applications. Such avatars are not in wide use because solutions for creating them from high-end scanners, low-cost range cameras, and tailoring measurements all have limitations. Here we propose a simple solution and show that it is surprisingly accurate. We use crowdsourcing to generate attribute ratings of 3D body shapes corresponding to standard linguistic descriptions of 3D shape. We then learn a linear function relating these ratings to 3D human shape parameters. Given an image of a new body, we again turn to the crowd for ratings of the body shape. The collection of linguistic ratings of a photograph provides remarkably strong constraints on the metric 3D shape. We call the process crowdshaping and show that our Body Talk system produces shapes that are perceptually indistinguishable from bodies created from high-resolution scans and that the metric accuracy is sufficient for many tasks. This makes body """"scanning"""" practical without a scanner, opening up new applications including database search, visualization, and extracting avatars from books."""	3d printing;avatar (computing);book;crowdsourcing;image resolution;linear function;linear model;virtual reality	Stephan Streuber;Maria Alejandra Quiros-Ramirez;Matthew Q. Hill;Carina A. Hahn;Silvia Zuffi;Alice J. O'Toole;Michael J. Black	2016	ACM Trans. Graph.	10.1145/2897824.2925981	computer vision;body shape;computer science;anthropometry;multimedia;perception;crowdsourcing;computer graphics (images)	Graphics	-37.04181175241251	-36.170795339126926	180373
9fe38c96d4c5db682f382c9d7811f47e369f648d	a semantic environment model for crowd simulation in multilayered complex environment	urban space;crowd simulation;continuum crowd;semantic environment model;semantic model;semantic information;virtual environment;environment representation	Simulating crowds in complex environment is fascinating and challenging, however, modeling of the environment is always neglected in the past, which is one of the essential problems in crowd simulation especially for multilayered complex environment. This paper presents a semantic model for representing the complex environment, where the semantic information is described with a three-tier framework: a geometric level, a semantic level and an application level. Each level contains different maps for different purposes and our approach greatly facilitates the interactions between individuals and virtual environment. And then a modified continuum crowd method is designed to fit the proposed virtual environment model so that realistic behaviors of large dense crowds could be simulated in multilayered complex environments such as buildings and subway stations. Finally, we implement this method and test it in two complex synthetic urban spaces. The experiment results demonstrate that the semantic environment model can provide sufficient and accurate information for crowd simulation in multilayered complex environment.	apache continuum;crowd simulation;interaction;map;multitier architecture;synthetic intelligence;virtual reality	Hao Jiang;Wenbin Xu;Tianlu Mao;Chunpeng Li;Shihong Xia;Zhaoqi Wang	2009		10.1145/1643928.1643972	semantic data model;simulation;computer science;virtual machine;operating system;crowd simulation;multimedia	HPC	-37.369906433938695	-34.98536988722687	181344
3da9fef65f73eecd609ea2e6aec18e08ea517a70	optimized graph extraction and locomotion prediction for redirected walking		Redirected walking with advanced planners such as MPCRed or FORCE requires both knowledge about the virtual environment - mostly in the form of a skeleton graph representing the virtual environment - and a robust prediction of the user's actions. This paper presents methods for both parts and evaluates them with a number of test cases.	agent-based model;automated planning and scheduling;game engine;navigation mesh;online exhibition;redirected walking;test case;user experience;virtual reality;waypoint	Markus Zank;Andreas M. Kunz	2017	2017 IEEE Symposium on 3D User Interfaces (3DUI)	10.1109/3DUI.2017.7893328	simulation;computer science;multimedia;computer graphics (images)	Graphics	-37.738406256946995	-33.58984287452516	181831
98702c85472d54ff3b105d1b65123ad5a8fa15de	perception-motivated visualization for 3d city scenes	large scale;city scenes;expressive rendering;landmarks	Many approaches have been developed to visualize 3D city scenes, most of which exhibit the visualization results in a uniform rendering style. This paper presents an expressive rendering approach for visualizing large-scale 3D city scenes with various rendering styles integrated in a seamless way. Each view is actually a combination of the photorealistic rendering and the nonphotorealistic rendering to highlight the information that is interesting for the users and de-emphasize the other that is less important. At run-time, the users are allowed to specify their interested locations interactively. Our system automatically computes the salience of each location and illustrates the entire scene with emphasis in the area of interests. The GPU-based implementation enables interactive realtime performance. Our implementation of a system demonstrates benefits in many applications such as 3D GPS navigation, tourist information, etc. We have performed a pilot user evaluation of the effect for users to access information in 3D city.	gps navigation device;graphics processing unit;interactivity;run time (program lifecycle phase);seamless3d;unbiased rendering	Bin Pan;Yong Sheng Zhao;Xiaoming Guo;Xiang Chen;Wei Chen;Qunsheng Peng	2012	The Visual Computer	10.1007/s00371-012-0773-1	computer vision;tiled rendering;rendering;parallel rendering;multimedia;real-time rendering;software rendering;computer graphics (images)	Visualization	-33.795884321952165	-35.139447537300626	182347
1abe967916f8986ca019335070edbb11d4df9160	"""""""it's a uvn face rig, charlie brown"""": facial techniques for peanuts"""	rgb d;blendshapes;face animation;depth sensors	The Peanuts Movie presented a fantastic challenge for Blue Sky Studios: bring Charles Schulz's beloved and iconic characters into a 3D world while remaining faithful to the original comic's style and design. The characters' heads and faces posed unique problems that were difficult to solve with our existing technology. From tiny pinched mouths, to ear to ear smiles, their expressions stretched to great extremes without disturbing the clean profiles and smooth shading of their round heads. A new approach was developed to preserve and control the head shapes while allowing facial features to slide freely around those curved volumes. Additionally, Schulz removed 3 dimensional form where it diluted clarity and drew aspects of the character differently when it detracted from simple graphic appeal. Thus, their proportions and facial features change position and shape depending on their viewing angle. Due to the degree of change, a single standard three dimensional model would not suffice. To solve this issue we decided to make rig states which we called character views.	3d modeling;shading;simplified molecular-input line-entry system;viewing angle	Adam Burr;Steve Gressak;Matthew Doble;Christian Haniszewski;Ignacio Barrios;Brian Anderson;Ferris Webby	2015		10.1145/2775280.2792563	computer vision;artificial intelligence;computer graphics (images)	Graphics	-39.97089010175557	-35.56546952874719	182680
225d519b7bf48a98766faeebdde67a8a819bd018	markup upon video - towards dynamic and interactive video annotations		Interactive video is increasingly becoming a more and more dominant feature of our media platforms. Especially due to the popular YouTube annotations framework, integrating graphical annotations in a video has become very fashionable these days. However, the current options are limited to a few graphical shapes for which the user can define as good as no dynamic behaviour. Despite the enormous demand for easy-creatable, interactive video there are no such advanced tools available. In this article we describe an innovative approach, to realize dynamics and interactivity of video annotations. First we explain basic concepts of video-markup like the generic element model and visual descriptors. After that we introduce the event-tree model, which can be used to define event-handling in an interactive video formally as well as visually. By combining these basic concepts, we can give an effective tool to the video community for realizing interactive and dynamic video in a simple, intuitive and focused way.	event (computing);event tree;extensibility;graphical user interface;interactivity;markup language;requirement;usability;virtual community;visual descriptor	Peter Schultes;Franz Lehner;Harald Kosch	2011	J. UCS	10.3217/jucs-017-04-0605	computer science;video tracking;multimedia;world wide web;computer graphics (images)	HCI	-40.837891752453295	-33.49841075432838	182844
8a5ca4a0d84d355784c57dbe817b75da0acad58a	line-based drawing style description for manga classification	line features;statistical analysis;manga style classification	Diversity of drawing styles of mangas can be easily perceived by humans, but are hard to be described in text. We design computational features derived from line segments to describe drawing styles, enabling style classification such as discriminating mangas targeting youth boys and youth girls, and discriminating artworks produced by different artists. With statistical analysis, we found that drawing styles can be effectively characterized by the proposed features such that explicit (e.g., density of line segments) or implicit (e.g., included angles between lines) observations can be made to facilitate various manga style classification.	computation	Wei-Ta Chu;Ying-Chieh Chao	2014		10.1145/2647868.2654962	multimedia;statistics	HCI	-36.59142388619334	-36.162812546114644	183105
cedd32c7b2006609bb49a23d356ff6af48eac42f	high-level semantics representation for intelligent simulative environments	geometric node interrelations;virtual reality artificial intelligence knowledge representation computational modeling computer graphics data structures matrix decomposition layout chromium intelligent networks;intelligent virtual environment;knowledge based simulation;semantic representation;simulative virtual reality applications;computational geometry;virtual reality;abstract knowledge representation layer;high level semantic representation;simulation semantics;data structures;graph representation;data structures virtual reality knowledge representation digital simulation computational geometry;intelligent simulative environments;generalized scene graph representation;virtual construction;ive;knowledge representation;simulation environment;digital simulation;virtual construction high level semantic representation intelligent simulative environments simulative virtual reality applications abstract knowledge representation layer simulation semantics generalized scene graph representation geometric node interrelations intelligent virtual environment knowledge based simulation;knowledge base	This article describes an integration of knowledge based techniques into simulative virtual reality (VR) applications motivated using a virtual construction task. An abstract knowledge representation layer (KRL) provides a base formalism for the integration of simulation semantics. The KRL approach is demonstrated using a generalized scene graph representation which introduces an abstract definition and implementation of geometric node interrelations.	denotational semantics;graph (abstract data type);krl;knowledge representation and reasoning;scene graph;semantics (computer science);simulation;virtual reality	Marc Erich Latoschik;Peter Biermann;Ipke Wachsmuth	2005	IEEE Proceedings. VR 2005. Virtual Reality, 2005.	10.1109/VR.2005.38	computer vision;knowledge base;computational geometry;computer science;artificial intelligence;theoretical computer science;machine learning;virtual reality;graph	Visualization	-36.575549927761806	-31.81089057032871	183237
e8c98d3986aaa66d5060731c502bc635cd3aa254	web-based real-time ladar data visualization with multi-user collaboration support		In this paper we present a web-based visualization system developed for visualizing real-time point cloud data obtained from LADAR (or other) sensors. The system allows direct visualization of captured data, visualization of data from database or visualization of preprocessed data (e.g. labeled or classified data). The system allows the concurrent visualization from same or different data-sources on multiple clients in the web browser. Due to the use of modern web technologies the client can also be used on mobile devices. The system is developed using modern client- and server-side web technologies. The system allows connection with an existing LADAR sensor grabber applications through use of UDP sockets. Both server- and client-side parts of the system are modular and allow the integration of newly developed modules and designing a specific work-flow scenarios for target end-user groups. The system allows the interactive visualization of datasets with millions of points as well as streaming visualization with high throughput speeds.	data visualization;multi-user;real-time web	Ciril Bohak;Byeong Hak Kim;Min Young Kim	2018		10.1007/978-3-319-95270-3_17	data visualization;point cloud;web application;visualization;database;modular design;multi-user;interactive visualization;mobile device;computer science	Visualization	-35.167265254704205	-34.617728497908956	183359
10e11f2c1146f11f245ac4d624703b1d098331f1	engineering design of thermal quality clothing on a simulation-based and lifestyle-oriented cad system	cad system;thermal quality clothing;simulation capability;lifestyle oriented design	Engineering design of thermal quality clothing is a promising solution by applying multi-disciplinary knowledge to achieve the design and production of clothing with desirable thermal functions. In this paper, a special simulation-based and lifestyle-oriented CAD system is introduced to help the user in engineering design of thermal quality clothing. The engineering-oriented simulation models endowed with explicit data availability arose from the material parameters that are the key issue for engineering application. To offer an easy-to-use tool, this system is implemented with a lifestyle-oriented design procedure. It can facilitate the designers to quickly implement design and simulate on the wearing scenario, and evaluate and optimize their design. Due to the design of thermal quality clothing can be achieved without making physical prototypes, it is able to speed up the design cycle and reduce the design and development cost.	caddie;computer animation;computer-aided design;engineering design process;logic synthesis;simulation;virtual reality	Aihua Mao;Jie Luo;Yi Li;Ruomei Wang;Guiqing Li;Yueping Guo	2011	Engineering with Computers	10.1007/s00366-011-0224-z	simulation;systems engineering;engineering;engineering drawing	EDA	-37.09201786520244	-31.61300999858306	183489
50f8dfc437e22a70c78e72821f3332f0f822befa	a framework for recognition and animation of chess moves printed on a chess book		The work presented in this paper proposes a set of techniques to animate chess moves which are printed on a chess book. Those techniques include (1) extraction of chess moves from an image of printed page, (2) recognition of chess moves from the extracted image, and (3) displaying digitally encoded successive moves as an animation on a chessboard. Since all the moves are temporally related, temporal animations show change of spatial patterns in time. Moreover, it becomes easier to understand how the moves are played out and who leads the game. In this study, we animate chess moves printed in Figurine Algebraic Notation (FAN) notation. The proposed technique also eliminates false recognition by means of controlling possible moves in accordance with the rules of chess semantics.	algorithm;book;denotational semantics;image analysis;printing;robot;robotic arm;shape analysis (digital geometry)	Süleyman Eken;Abdülkadir Karabas;Hayrunnisa Sari;Ahmet Sayar	2018	Int. Arab J. Inf. Technol.		computer graphics (images);animation;false recognition;computer science;semantics;notation;artificial intelligence;pattern recognition	HCI	-38.549314226086494	-32.559226507607	184614
2f790b4c5d25a753b228d698ee718a9fcc4fafbe	creation of concept shape designs via a virtual reality interface	modelizacion;computer aided design;modele geometrique;architecture systeme;realite virtuelle;concept design;user interface;implementation;virtual reality;modelisation;ejecucion;conceptual design;hand tracking;conception assistee;arquitectura sistema;virtual reality environment;interface utilisateur;geometric model;shape description;system architecture;shape design;modeling;user interfaces;geometrical model;modelo geometrico	This paper describes an approach for creating concept shape designs in a virtual reality environment----~O~IRDS (Conceptual VIRtual Design System). Concept design refers to the clh irlitio design of a product or part. In concept design. the product details such as shape features and exact dimensions are not rigidly defined and the designer has some freedom in determining the shape and dimensions of the product. Current U\D require the designer to specify shape and dimensions to create (‘AI) models of products even though these are probably not necessary at the concept development stage. (OVIRDS overcomes these drawbacks by providing a bi-modal voice and hand-tracking based user interface to the VR-based CAlI modeling environment. This interface allows rapid concept design creation without requiring time consuming shape description and the tedious specifications of exact dimensions. (‘8 I997 Elsevier Science Ltd.	modal logic;software release life cycle;user interface;virtual reality	Tushar H. Dani;Rajit Gadh	1997	Computer-Aided Design	10.1016/S0010-4485(96)00091-7	simulation;human–computer interaction;computer science;engineering;computer aided design;virtual reality;user interface;engineering drawing	EDA	-37.546979620524866	-31.098160985945487	185301
1547f235b57c9cd74136d2b24f7470e2ccde70fc	video inlays: a system for user-friendly matchmove	matchmove;video editing;video representation	Digital editing technology is highly popular as it enables to easily change photos and add to them artificial objects. Conversely, video editing is still challenging and mainly left to the professionals. Even basic video manipulations involve complicated software tools that are typically not adopted by the amateur user. In this paper we propose a system that allows an amateur user to performs a basic matchmove by adding an inlay to a video. Our system does not require any previous experience and relies on a simple user interaction. We allow adding 3D objects and volumetric textures to virtually any video. We demonstrate the method's applicability on a variety of videos downloaded from the web.	digital media;usability;volumetric display	Dmitry Rudoy;Lihi Zelnik-Manor	2013		10.1145/2503713.2503741	computer vision;simulation;post-production;computer science;video tracking;multimedia;video processing;smacker video;computer graphics (images);non-linear editing system	HCI	-40.24780001615526	-33.71781365674508	185307
351346824b2b7e036009602e81630ef394f0bf99	graphical simulation a automatic verification of nc machining programs	automatic verification;machining;fixtures;testing;computational modeling;side effect;computer aided manufacturing;solid modeling;computer displays;dc motors;machining solid modeling computational modeling testing fixtures computer aided manufacturing computer displays graphics dc motors laboratories;graphics;solid modelling	A machining simulator seeks to display graphically the effects on the workpiece (and associated fixtures) of the cutter motions prescribed in an NC program. Simulators enable NC programmers and machine operators to detect visually potential collisions and gross programming errors. A machining verifier seeks to determine automatically, without recourse to human judgement, whether an NC program will produce a specified part without undesirable side effects (collisions, cutter breakage, etc.). Simulators and verifiers both require solid modelling facilities, but simulators need only fast display generators for Boolean combinations whereas verifiers require more varied and powerful facilities. This paper summarizes the issues underlying simulation and verification while describing a new simulator that is being converted into a verifier.		Ugur A. Sungurtekin;Herbert B. Voelcker	1986		10.1109/ROBOT.1986.1087729	simulation;machining;computer hardware;computer science;engineering;graphics;dc motor;software testing;solid modeling;computational model;engineering drawing;side effect;computer-aided manufacturing	Logic	-39.0012523967256	-31.485807278967325	185452
a4cfb747343a54e867bc47b79344b73c4825424b	gpu-accelerated attention map generation for dynamic 3d scenes	and texture;heating;i 3 7 computer graphics three dimensional graphics and realism virtual reality i 3 3 computer graphics picture image generation display algorithms i 3 7 computer graphics three dimensional graphics and realism color shading shadowing and texture;three dimensional displays visualization rendering computer graphics solid modeling real time systems heating data visualization;augmented reality gpu attention map generation dynamic 3d scene visual attention product development qualitative visualization on the fly visualization heat map texture offline high quality rendering selective rendering virtual reality;rendering computer graphics augmented reality data visualisation graphics processing units image texture;visualization;i 3 3 computer graphics picture image generation display algorithms;three dimensional displays;solid modeling;shadowing;data visualization;i 3 7 computer graphics three dimensional graphics and realism virtual reality;rendering computer graphics;i 3 7 computer graphics three dimensional graphics and realism color;real time systems;shading	Measuring visual attention has become an important tool during product development. Attention maps are important qualitative visualizations to communicate results within the team and to stakeholders. We have developed a GPU-accelerated approach which allows for real-time generation of attention maps for 3D models that can, e.g., be used for on-the-fly visualizations of visual attention distributions and for the generation of heat-map textures for offline high-quality renderings. The presented approach is unique in that it works with monocular and binocular data, respects the depth of focus, can handle moving objects and is ready to be used for selective rendering.	3d modeling;binocular vision;graphics processing unit;heat map;new product development;online and offline;real-time clock	Thies Pfeiffer;Cem Memili	2015	2015 IEEE Virtual Reality (VR)	10.1109/VR.2015.7223393	computer vision;shading;visualization;computer science;multimedia;solid modeling;data visualization;computer graphics (images);mechanical engineering	Visualization	-37.99842099519904	-35.07037821185739	185896
3bcc323f82fb1a668119c9500d56c40d7c2920b6	analysis of player actions in selected hockey game situations	forward backward;space time point sequences;id graphic animation;evaluation function;id graphic animation player action analysis hockey game situation proof of concept system player motion trajectory data game video hockey strategy player profiles space time point sequences backward skating forward skating finite state machine textual natural language description;image motion analysis;computer graphics;natural languages sport image motion analysis finite state machines image sequences computer animation;natural languages;space time;data mining;game video;books;proof of concept;player action analysis;games animation trajectory computer graphics data mining computer science tracking automata natural languages books;automata;hockey strategy;player profiles;finite state machines;player motion trajectory data;trajectory;natural language;games;animation;hockey game situation;computer science;forward skating;sport;computer animation;data consistency;backward skating;situation assessment;finite state machine;tracking;image sequences;proof of concept system;textual natural language description	We present a proof of concept system to represent and reason about hockey play. The system takes as input player motion trajectory data tracked from game video and supported by knowledge of hockey strategy, game situation and specific player profiles. The raw motion trajectory data consists of space-time point sequences of player position registered to rink coordinates. The raw data is augmented with knowledge of forward/backward skating, possession of the puck and specific player attributes (e.g., shoots left, shoots right). We use a finite state machine (FSM) model to represent our total knowledge of given situations and develop evaluation functions for primitive hockey behaviours (e.g., pass, shot). Based on the augmented trajectory data, the FSMs and the evaluation functions, we describe what happened in each identified situation, assess the outcome, estimate when and where key play choices were made, and attempt to predict whether better alternatives were available to achieve understood goals. A textual natural language description and a simple ID graphic animation of the analysis are produced as the output. The design is flexible to allow the substitution of different analysis modules and extensible to allow the inclusion of additional hockey situations.	evaluation function;finite-state machine;natural language	Fahong Li;Robert J. Woodham	2005	The 2nd Canadian Conference on Computer and Robot Vision (CRV'05)	10.1109/CRV.2005.17	computer vision;simulation;computer science;artificial intelligence;machine learning;multimedia;finite-state machine;natural language;computer graphics (images)	HCI	-34.68143154833087	-37.62403778102528	187221
4b933fd0bd6a091821bdd7909edd7cc3658bbe72	tanagra: reactive planning and constraint solving for mixed-initiative level design	computers;iterative refinement;generators;human computer interaction;mixed initiative;real time;software tools computational geometry computer games constraint handling human computer interaction;geometry;computational geometry;level design;reactive planning;procedural content generation;design environment;games;constraint programming;augmented design;augmented design tanagra reactive planning mixed initiative level design tool human computer interaction 2d platformer reactive level generator level geometry numerical constraint solving;constraint handling;constraint solving;planning;geometry generators human factors games planning computers;software tools;humans;tiles;computer games;physical properties;reactive planning augmented design constraint programming games level design mixed initiative procedural content generation	Tanagra is a mixed-initiative tool for level design, allowing a human and a computer to work together to produce a level for a 2-D platformer. An underlying, reactive level generator ensures that all levels created in the environment are playable, and provides the ability for a human designer to rapidly view many different levels that meet their specifications. The human designer can iteratively refine the level by placing and moving level geometry, as well as through directly manipulating the pacing of the level. This paper presents the design environment, its underlying architecture that integrates reactive planning and numerical constraint solving, and an evaluation of Tanagra's expressive range.	constraint satisfaction problem;level design;numerical analysis;procedural generation;reactive planning;tanagra	Gillian Smith;E. James Whitehead;Michael Mateas	2011	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2011.2159716	planning;games;constraint programming;simulation;level design;computational geometry;computer science;artificial intelligence;theoretical computer science;reactive planning;physical property	AI	-37.60115327795741	-34.23035796000961	189536
ce71ccf2c1cdb64b73ee05e57f74849b470d6552	a functional approach to animation	functional approach	We investigate the benefits of using a functional language to reason about and to implement animation. Since animation concerns pictures changing over time, we consider the manipulation of movies or picture sequences. A compact set of primitive operations over movies is introduced and its use as the basis for an animation system is illustrated. The notion of the behaviour of an animated character is formalised and we show how simple behaviours may be combined to create more complex behaviours. We then show how higher-order functions allow us to construct a variety of useful tools which lead to a highly concise functional script.	functional approach;functional programming;higher-order function;image	Kavi Arya	1986	Comput. Graph. Forum	10.1111/j.1467-8659.1986.tb00316.x	computer vision;simulation;computer facial animation;skeletal animation;computer science;artificial intelligence;multimedia;computer graphics (images)	Graphics	-39.35917310239488	-32.504963228448695	191641
84e577882ae54561674880eb2ddd8a90e52bceae	svg 3d graphical presentation for web-based applications	qa76 computer software	Due to the rapid developments in the field of computer graphics and computer hardware, web-based applications are becoming more and more powerful, and the performance distance between web-based applications and desktop applications is increasingly closer. The Internet and the WWW have been widely used for delivering, processing, and publishing 3D data. There is increasingly demand for more and easier access to 3D content on the web. The better the browser experience, the more potential revenue that web-based content can generate for providers and others. The main focus of this thesis is on the design, develop and implementation of a new 3D generic modelling method based on Scalable Vector Graphics (SVG) for web-based applications. While the model is initialized using classical 3D graphics, the scene model is extended using SVG. A new algorithm to present 3D graphics with SVG is proposed. This includes the definition of a 3D scene in the framework, integration of 3D objects, cameras, transformations, light models and textures in a 3D scene, and the rendering of 3D objects on the web page, allowing the end-user to interactively manipulate objects on the web page. A new 3D graphics library for 3D geometric transformation and projection in the SVG GL is design and develop.#R##N##R##N#A set of primitives in the SVG GL, including triangle, sphere, cylinder, cone, etc. are designed and developed. A set of complex 3D models in the SVG GL, including extrusion, revolution, Bezier surface, and point clouds are designed and developed. The new Gouraud shading algorithm and new Phong Shading algorithm in the SVG GL are proposed, designed and developed. The algorithms can be used to generate smooth shading and create highlight for 3D models. The new texture mapping algorithms for the SVG GL oriented toward web-based 3D modelling applications are proposed, designed and developed. Texture mapping algorithms for different 3D objects such as triangle, plane, sphere, cylinder, cone, etc. will also be proposed, designed and developed. This constitutes a unique and significant contribution to the disciplines of web-based 3D modelling, as well as to the process of 3D model popularization.	graphical user interface;scalable vector graphics;web application	Jisheng Lu	2015			web modeling;web mapping;computer science;theoretical computer science;multimedia;computer graphics (images)	HCI	-40.59102112496068	-33.50639127224191	192051
097df74f2540d0f52659ca748f7b4434e7d5a7b0	algorithms for the automatic generation of urban streets and buildings	3d graphics;procedural modeling;graphical model	We describe the algorithms we have developed to automatically generate street networks and building plots in the automatic procedural creation of a realistic city. Our system first sites the important regions of a city, such as the commercial center, historical center, and residential areas. Then, a network of freeway and main roads are built. Finally, a network of streets are built throughout the city. The main contribution described in this paper is the design of the freeways, main streets and minor streets, and the allocation of space for the roads and buildings in the city. Compared to existing methods, our system creates cities that more closely mimics real-world cities, and can also generate millions of streets in seconds.	algorithm;freeway	Soon Tee Teoh	2008			procedural modeling;simulation;drill;lock (computer science);rotation;3d computer graphics;axial symmetry;coupling;mechanical engineering;computer science	AI	-36.93842857194508	-32.52989755429151	192755
1fa8b938dec6642bf2b29546ed9f0e6cb38d134b	incorporating legal rules on procedural house generation	virtual environments;automatic generation;video game;3d model;house generation;procedural modelling;virtual environment;computer animation	The increasing demand for larger and more complex virtual models arising from different areas (e.g. design of virtual cities, video games and computer animated movies) creates the need for efficient computer algorithms able to generate them automatically. This paper presents a method for automatic generation of traversable houses, using architectural legal rules and an L-system to generate a list of interior rooms. The method is established with a framework specifically conceived to generate 2D floor plans and 3D models which allow the generation of multiple houses and interactive navigation.	3d floor plan;3d modeling;algorithm;computer animation;l-system	Nuno Rodrigues;M. Dionísio;Alexandrino Gonçalves;Luís Magalhães;João-Paulo Moura;Alan Chalmers	2008		10.1145/1921264.1921279	computer vision;simulation;computer science;virtual machine;operating system;computer animation;multimedia;computer graphics (images)	Graphics	-37.8214621631697	-33.16599216738831	193483
f29476094033d28e15891c7bfa0ba5e05e12d540	automated generation of intent-based 3d illustrations	non photorealistic rendering;rule based system;evaluation method;knowledge based graphics;individual object;illustrations;automated picture generation	This paper describes an automated intent-based approach to illustration. An illustrution is a picture that is designed to fulfill a communicative intent such as showing the location of an object or showing how an object is manipulated. An illustration is generated by implementing a set of stylistic decisions, ranging from determining the way in which an individual object is lit, to deciding the general composition of the illustration. The design of an illustration is treated as a goal-driven process within a system of constraints. The goal is to achieve communicative intent; the constraints are the illustrative techniques an illustrator can apply.We have developed IBIS (Intent-Based Illustration System), a system that puts these ideas into practice. IBIS designs illustrations using a generate-and-test approach, relying upon a rule-based system of methods and evaluators. Methods are rules that specify how to accomplish visual effects, while evaluators are rules that specify how to determine how well a visual effect is accomplished in an illustration. Examples of illustrations designed by IBIS are included.	adobe illustrator;constraint (mathematics);rule-based system;visual effects	Dorée D. Seligmann;Steven K. Feiner	1991		10.1145/122718.122732	technical illustration;rule-based system;computer vision;illustration;simulation;computer science;artificial intelligence;non-photorealistic rendering;computer graphics (images)	HCI	-38.41417982247424	-31.618362618250142	193943
3da1cb99017750adbdca739c0fd07baf55681aea	interactive video manipulation using object trajectories and scene backgrounds	high level video manipulation task interactive video manipulation object trajectories scene background video editing interfaces model object centric manipulation object centric navigation high level video semantics background mosaics object motions camera motions 3d space time trajectories camera operations intuitive curve manipulations video object temporal manipulation camera;object recognition;image motion analysis;object recognition cameras image motion analysis interactive video natural scenes;interactive video;cameras trajectory navigation visualization feature extraction estimation image reconstruction;video navigation interactive techniques object based video interaction video manipulation video mosaicing;cameras;natural scenes	Traditional video editing interfaces model and represent videos as a collection of frames against a timeline, which makes the object-centric manipulation of videos a laborious task. We enable a simple and meaningful interaction for object-centric navigation and manipulation of long shot videos by introducing operators on three high-level video semantics: background mosaics, object motions, and camera motions. We estimate the scene background and represent the object motion using 3-D space-time trajectories. We use the 3-D object trajectories as basic interaction elements, and define several object and camera operations as simple and intuitive curve manipulations. These allow users to perform various video object temporal manipulations by interactively manipulating the object trajectories. The camera operations model the camera as a movable and scalable aperture and allow the users to simulate pan, tilt, and zoom effects by creating new camera trajectories. With several example compositions, we demonstrate that our representation and operations allow users to simply and interactively perform numerous seemingly complex, high-level video manipulation tasks.	computer vision;high- and low-level;human–computer interaction;interactive media;pan–tilt–zoom camera;scalability;scene graph;simulation;timeline;usability;user interface;video processing	Rajvi Shah;P. J. Narayanan	2013	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2013.2248972	computer vision;computer science;cognitive neuroscience of visual object recognition;video tracking;multimedia;computer graphics (images)	Vision	-39.921155795155265	-36.74536802750379	194473
4845af63f46a76a4763cb6753e7be640b07c3d36	assistance for telepresence by stereovision-based augmented reality and interactivity in 3d space	vision system;sensory feedback;semantic model;image analysis;geometric model;augmented reality;mixed reality	In this paper, we describe some use of mixed reality as a new assistance for performing teleoperation tasks in remote scenes. We will start by a brief classification of augmented reality. This paper then describes the principle of our mixed reality system in teleoperation. It tackles the problem of scene registration using a manmachine cooperative and multisensory vision system. The system provides the operator with powerful sensorial feedback as well as appropriate tools to build (and update automatically) the geometric model of the perceived scene. We describe a new interactive approach combining image analysis and mixed reality techniques for assisted 3D geometric and semantic modeling. At the end of this paper, we describe applications in nuclear plants with results in 3D positioning.	algorithm;archicad library part;augmented reality;feedback;geometric modeling;image analysis;interactivity;mixed reality;real-time computing;real-time locating system;stereopsis;workstation	Philippe Fuchs;Fawzi Nashashibi;Didier Maman	2002	Presence: Teleoperators & Virtual Environments	10.1162/105474602320935856	semantic data model;computer vision;augmented reality;computer-mediated reality;image analysis;simulation;computer science;geometric modeling;mixed reality;multimedia	Visualization	-40.60465498321762	-37.812386266336965	194518
28c3f4e49ab34e05f03132be508c5e268f93b095	generating paths with wfc.		Motion plans are often randomly generated for minor game NPCs. Repetitive or regular movements, however, require non-trivial programming effort and/or integration with a pathing system. We here describe an example-based approach to path generation that requires little or no additional programming effort. Our work modifies the Wave Function Collapse (WFC) algorithm, adapting it to produce pathing plans similar to an input sketch. We show how simple sketch modifications control path characteristics, and demonstrate feasibility through a usable Unity implementation.	algorithm;heuristic (computer science);map;obstacle avoidance;pixel;uniform resource identifier;unity;variable shadowing;video post-processing;wave function collapse	Hugo Scurti;Clark Verbrugge	2018			artificial intelligence;machine learning;usable;sketch;computer science	NLP	-37.17660577442684	-36.979160487691054	194546
7372c1f981616d3ae42715e25a3699f0f1b2fed1	a novel virtual reality tool for teaching dynamic 3d anatomy	teaching tool;virtual reality;three dimensional;augmented reality	A Virtual-Reality-based tool for teaching dynamic three-dimensional anatomy may impart better understanding of bone dynamics during body movement. One application of this teaching tool is radiographic positioning instruction. We propose Augmented Reality, a technology that allows the overlay of graphically generated objects(bones in this case) on the real scenes(body in this case), as a means of visualization for such an application. In this paper we describe the design and the three stages of development of a prototype unit which demonstrates elbow movement. Preliminary results and problems encountered while developing the first stage, are also presented.	virtual reality	Anantha R. Kancherla;Jannick P. Rolland;Donna L. Wright;Grigore C. Burdea	1995		10.1007/978-3-540-49197-2_18	three-dimensional space;augmented reality;computer-mediated reality;computer science;virtual reality;mixed reality	Visualization	-37.15813596979713	-31.485392228287115	194663
e2c84314a09aa65b7aef1d6de02be545c15739c4	interactive virtual mummy dissections in a historical anatomic theatre	3d interaction;texture mapping;virtual reality;keystone correction;anthropology	This paper presents an interactive projection-based application for visual exploration of virtual mummies. It is part of an exposition on the Cultural Heritage of the Egyptian Mummies in the Museum Gustavianum, in Uppsala. We describe a general-purpose projection metaphor for correctly presenting virtual 3D images on the dissection table of a historical anatomic theatre. This method allows for dynamic offaxis perspective viewing situations as well as it provides keystone correction for excessive projection angles as necessitated by the specific installation environment. For the application to reach out beyond the scope of the exhibition, we developed an adaptive image-based rendering approach that scales with the performance of the rendering host. Based on dynamic mesh simplification of the 3D mummy model, it automatically performs re-projections of texture images in order to maintain correct visual results. For interaction purposes with a digitiser tablet we present a means of stroke-based input that provides ease of use to non-expert visitors of the exhibition.		Stefan Seipel;M. Lindkvist;Lars Winkler Pettersson	2003		10.2312/VAST/VAST03/101-110	texture mapping;computer vision;keystone effect;computer science;artificial intelligence;virtual reality;multimedia;computer graphics (images)	HPC	-36.92718232685356	-35.61676788449066	194964
e9ffb416488e8c13de489e08ef358faa67421a06	conceptual design and modification of freeform surfaces using dual shape representations in augmented reality environments	computer aided design;surface representations;gesture;3d sketching;conceptual design;augmented reality;hand motion;3d surface design	This paper enables the rapid creation and modification of freeform surfaces inside an augmented reality environment, and focuses on methods for enabling increased flexibility during exploratory, conceptual industrial product design through three-dimensional (3D) sketch-based user input. Specifically, we address the role of multiple shape representations with varying uncertainty levels during 3D conceptual sketching, along with methods to transform between those representations. The main contributions of this work are: (1) the formulation of virtual shape data in multiple, concurrent representations (points and surfaces), and a regressionmethod to transition fluidly back and forth between these representations during design, (2) methods for deforming and exploring the product shape using these multiple representations, and (3) representations of these forms such that designers can explore conceptual designs without the need for detailed surface operations such as trimming or continuity enforcement. Through incorporating these contributions, we introduce techniques that can be incorporated in future computer-aided conceptual design systems. These contributions are demonstrated for freeform surface design, with examples of computer mouse and car seat exterior surfaces. © 2011 Elsevier Ltd. All rights reserved.	ar (unix);augmented reality;computation;computer mouse;dos;freeform surface modelling;head-mounted display;interactivity;least squares;scott continuity;software propagation	Mark Fuge;Mehmet Ersin Yümer;Günay Orbay;Levent Burak Kara	2012	Computer-Aided Design	10.1016/j.cad.2011.05.009	computer vision;augmented reality;simulation;computer science;engineering;computer aided design;conceptual design;gesture;engineering drawing	HCI	-36.886924274800876	-33.46848801719317	194966
b6f8342c5a9f66ed72184c45b344680568a0afc1	augmenting 3d city models with visualization of real-time meteorological phenomena	3d city model;real time;user study;interactive environment;augmented reality;visual system	General interest in visualizations of digital 3D city models is growing rapidly, and several applications are already available that display such models very realistically. Many authors have emphasized the importance of the effects of realistic illumination for computer generated images, and this applies especially to the context of 3D city visualization. However, current 3D city visualization applications rarely implement techniques for achieving realistic illumination, in particular the effects caused by current weather-related phenomena. At most, some geospatial visualization systems render artificial skies—sometimes with a georeferenced determination of the sun position—to give the user the impression of a real sky. However, such artificial renderings are not sufficient for real simulation purposes. In this paper we present techniques to augment visualizations of digital 3D city models with real-time display of georeferenced meteorological phenomena. For this purpose we retrieve weather information from different sources, i. e., real-time images from cameras and radar data from web-based weather services, and we use this information in the rendering process for realistic visualization of different weather-related issues, such as clouds, rain, fog, etc. Our approach is not limited to a specific setup, and we have evaluated the results in a user study presented in this paper.	3d city models;digital 3d;illumination (image);real-time locating system;simulation;usability testing;web application	Frank Steinicke;Jörg Mensmann;Klaus H. Hinrichs;Jan de Buhr;Kai Rothaus;Antonio Krüger	2008			augmented reality;simulation;visual system;computer science;multimedia;computer graphics (images)	Visualization	-37.57635548239136	-35.72873817009595	195771
3d69a36b5e2a8e2a926bb6a1f3bdb71ac0e7b3c8	spatial awareness in full-body immersive interactions: where do we stand?	real time;experience;virtual reality;postural control;virtual prototyping;immersion;spatial awareness;consciousness;inverse kinematics;presence;collision avoidance;local minima;user interaction;real time application;literature survey;animated character	We are interested in developing real-time applications such as games or virtual prototyping that take advantage of the user full-body input to control a wide range of entities, from a self-similar avatar to any type of animated characters, including virtual humanoids with differing size and proportions. The key issue is, as always in real-time interactions, to identify the key factors that should get computational resources for ensuring the best user interaction efficiency. For this reason we first recall the definition and scope of such essential terms as immersion and presence, while clarifying the confusion existing in the fields of Virtual Reality and Games. This is done in conjunction with a short literature survey relating our interaction efficiency goal to key inspirations and findings from the field of Action Neuroscience. We then briefly describe our full-body real-time postural control with proactive local collision avoidance. The concept of obstacle spherification is introduced both to reduce local minima and to decrease the user cognitive task while interacting in complex environments. Finally we stress the interest of the egocentric environment scaling so that the user egocentric space matches the one of a height-differing controlled avatar.	computational resource;entity;image scaling;immersion (virtual reality);interaction;maxima and minima;real-time clock;real-time computing;real-time transcription;self-similarity;spatial–temporal reasoning;virtual reality	Ronan Boulic;Damien Maupu;Manuel Peinado;Daniel Raunhardt	2010		10.1007/978-3-642-16958-8_7	simulation;computer science;artificial intelligence;spatial contextual awareness;maxima and minima;inverse kinematics;consciousness;virtual reality;multimedia;immersion;computer graphics (images)	Graphics	-38.65904709182006	-37.217017259194634	196701
7647490937dc47eec0ba61535dad37b895e4cc7b	the effect of translational ego-motion on the perception of high fidelity animations	simulation;virtual reality;global illumination;motion simulators	The quality of the graphics displayed in motion simulators can play a signficant role in improving a user's training experience in such devices. However, the computation of high-fidelity graphics using traditional rendering approaches takes a substantial amount of time, precluding their use in such an interactive environment. This paper investigates exploiting how the human visual system deals with motion, to drive a selective rendering system. Such a selective renderer computes perceptually important parts of a scene in high quality and the remainder of the scene at a lower quality, and thus at a much reduced computational cost, without the user being aware of this quality difference. In this study we concentrate on translational motion and show, even for this less dramatic form of motion, a viewer's perception of a scene can be significantly effected.  A study was conducted involving 120 subjects in 8 conditions. An additional 'button-press' study of 26 subjects was also carried out. The results show that, for both studies, viewers could not notice a decrease in rendering quality when subjected to motion.	algorithmic efficiency;computation;display resolution;graphics;motion simulator;rendering (computer graphics);simulation	G. Ellis;Alan Chalmers	2006		10.1145/2602161.2602170	computer vision;simulation;rendering;computer science;virtual reality;global illumination;computer graphics (images)	HCI	-36.811480013226564	-37.10869542935586	196729
4e2494e811601c0d4bb80f94b6db94cb9368615a	musings on volumetric level of detail for virtual environments	visual acuity;three dimensions;real time;conceptual model;gaze tracking;three dimensional;level of detail;human visual system;cross section;eye tracking;virtual environment	This paper considers the extension of a real-time graphics renderer to support fovea enhancement — the technique of localising visual detail to the particular region of the display which the user is looking towards. This is performed by extending the standard notion of distance Level of Detail (LOD) into three dimensions to give volumetric LOD; whereby the LOD of an object is related to its presence within a three-dimensional volume which is aligned with the user's gaze. Before introducing this technique, some background details are discussed regarding the relevant characteristics of the human visual system and current solutions for effective gaze tracking. Subsequently, a brief cross-section of relevant research is presented and a conceptual model of volumetric LOD is formulated. Finally, implementation factors for such a system are considered and a theoretical evaluation is proffered.	eye tracking;graphics;level of detail;real-time transcription;rendering (computer graphics);virtual reality	Martin Reddy	1995	Virtual Reality	10.1007/BF02009713	three-dimensional space;computer vision;computer science;multimedia;computer graphics (images)	Visualization	-36.00123542421234	-35.73383951260078	197063
60b648388725f68491769e376f88faa5fab9bf86	design of mms (mobile mapping systems) applicable to lbs (local based services)	road facilities;landmark identification;ccd camera;image recognition;mobile mapping;geographic information;image recognition lbs local based services mobile mapping;web enabled phone;real time;mobile mapping system;packet radio networks;local based services;mobile mapping systems;web service;image recognition road vehicles global positioning system charge coupled devices digital cameras charge coupled image sensors real time systems prototypes cities and towns buildings;pda;geographic information systems;wireless internet;camera phone;web services geographic information systems image recognition mobile handsets notebook computers packet radio networks;wireless internet environment mobile mapping systems local based services geographic information road facilities digital map image recognition system landmark identification web service gprs web enabled phone pda;web services;mobile handsets;lbs local based services;notebook computers;digital map;point of view;gprs;wireless internet environment;digital mapping;image recognition system	The mobile mapping system using the vehicle equipped the GPS, IMU, CCD Camera is the effective system for the management of the road facilities, update of the digital map, and etc. If the geographic information which is acquired by the mobile mapping system can be transmitted in real-time, users can process what they want using latest data. We have developed a prototype image recognition system capable of identifying landmark (typically, city buildings and structures) from photographs captured on camera phones. The image recognition process runs server-side, as a Web service accessible over GPRS from a Web enabled phone or PDA. Photographs of landmarks are preloaded into a central database, which is then queried by users submitting images from their camera phones. The image recognition algorithm is robust to variations in both illumination and point of view. In this paper, the effective method was suggested for the transmission of the geographic information acquired by camera attached to a PDA such as position data, altitude data, and image data in the wireless Internet environment in real-time.	algorithm;camera phone;charge-coupled device;computer vision;effective method;global positioning system;location-based service;mobile mapping;personal digital assistant;prototype;real-time clock;real-time computing;real-time locating system;server (computing);server-side;web service	Jin-Suk Kang;Yonghee You;Mee Young Sung	2007	2007 2nd International Conference on Digital Information Management	10.1109/ICDIM.2007.4444270	web service;computer vision;digital mapping;computer science;multimedia;law;world wide web;computer security	Robotics	-34.01223600127138	-36.14197882447632	197380
717cb492b1edaf1a47a93c3f7950fcc689b89fea	specification by-example of virtual agents behavior	human computer interaction;spatial reasoning;interactive graphic environments;virtual reality;indexing terms;graphics animation virtual reality humans virtual environment virtual prototyping delay intrusion detection libraries shape;rapid prototyping;animation;temporal reasoning virtual reality interactive systems user interfaces computer animation spatial reasoning;virtual environment;interactive graphics;computer animation;specification by example;interactive systems;user interfaces;virtual agent;temporal reasoning;spatio temporal reasoning;spatio temporal reasoning specification by example virtual agents visual specification by example internal representation language automatic executability interaction rules behavioral training animation visual examples virtual reality	The development of virtual agents running within graphic environments which emulate real-life contexts may largely benefit from the use of visual specification by-example. To support this specification, the development system must be able to interpret the examples and cast their underlying rules into an internal representation language. This language must find a suitable trade-off among a number of contrasting requirements regarding expressiveness, automatic executability, and suitability to the automatic representation of rules deriving from the analysis of examples. A language is presented which attains this trade-off by combining together an operational and a declarative fragment to separately represent the autonomous execution of each individual agent and its interaction with the environment, respectively. While the declarative part permits to capture interaction rules emerging from specification examples, the operational part supports the automatic execution in the operation of the virtual environment. A system is presented which embeds this language within a visual shell to support a behavioral training in which the animation rules of virtual agents are defined through visual examples.	specification by example	Alberto Del Bimbo;Enrico Vicario	1995	IEEE Trans. Vis. Comput. Graph.	10.1109/2945.485622	anime;computer vision;simulation;index term;computer science;virtual machine;virtual reality;computer animation;multimedia;spatial intelligence;user interface	Visualization	-38.97633868441962	-32.51349859485651	197927
ad8e4a92c765d5f55505b3c49d4efe3329a7f31d	real time animation of virtual humans: a trade-off between naturalness and control	3d virtual environment;virtual human;interactive application;real time animation;naturalness;control;i 3 7 three dimensional graphics and realism animation;animation techniques;serious game	Virtual humans are employed in many interactive applications using 3D virtual environments, including (serious) games. The motion of such virtual humans should look realistic (or ‘natural’) and allow interaction with the surroundings and other (virtual) humans. Current animation techniques differ in the trade-off they offer between motion naturalness and the control that can be exerted over the motion. We show mechanisms to parametrize, combine (on different body parts) and concatenate motions generated by different animation techniques. We discuss several aspects of motion naturalness and show how it can be evaluated. We conclude by showing the promise of combinations of different animation paradigms to enhance both naturalness and control.		Herwin van Welbergen;Ben J. H. van Basten;Arjan Egges;Zsófia Ruttkay;Mark H. Overmars	2010	Comput. Graph. Forum	10.1111/j.1467-8659.2010.01822.x	simulation;naturalness;computer facial animation;skeletal animation;computer science;interactive skeleton-driven simulation;computer animation;multimedia;scientific control;computer graphics (images)	Graphics	-39.0802110828857	-37.00553045794346	197969
59b374f75c4de5e344205a4eb7737ec61c02a33e	wordseye: an automatic text-to-scene conversion system	multimedia;functional properties;information technology;hci;linguistic analysis;3d model;natural language;text to scene conversion;scene generation;computer science;applications;linguistics	Natural language is an easy and effective medium for describing visual ideas and mental images. Thus, we foresee the emergence of language-based 3D scene generation systems to let ordinary users quickly create 3D scenes without having to learn special software, acquire artistic skills, or even touch a desktop window-oriented interface. WordsEye is such a system for automatically converting text into representative 3D scenes. WordsEye relies on a large database of 3D models and poses to depict entities and actions. Every 3D model can have associated shape displacements, spatial tags, and functional properties to be used in the depiction process. We describe the linguistic analysis and depiction techniques used by WordsEye along with some general strategies by which more abstract concepts are made depictable.	3d modeling;desktop computer;emergence;entity;natural language	Robert Coyne;Richard Sproat	2001		10.1145/383259.383316	natural language processing;computer vision;computer science;multimedia;natural language;programming language;information technology;computer graphics (images)	Graphics	-39.08228814092103	-32.593272316782986	199043
188b80c250f194601126a43ef4d115da395da01c	remote high-performance visualization and collaboration	groupware;high resolution;image resolution;data compression;real time;visual communication;video compression;data communication;video coding;data visualisation;large scale simulation;commercial off the shelf;computer displays;network usage remote high performance visualization remote collaboration commercial off the shelf equipment system cost minimization real time full frame rate image transfer compressed high resolution images remotely distributed large format displays sandia national laboratories design centers virtual space large scale simulations video compression network equipment display quadrant technique distributed workgroups tera scale problem sets high resolution displays real time interactivity;high resolution imager;large screen displays;virtual space;high performance;large screen displays data visualisation groupware real time systems data compression video coding computer displays image resolution data communication visual communication;real time systems;visualization collaboration displays costs image coding space exploration laboratories design engineering virtual prototyping testing	Using commercial, off-the-shelf equipment minimizes costs yet supports real-time, full-frame-rate transfers of compressed, high-resolution images to remotely distributed large-format displays. Sandia National Laboratories' engineers and analysts regularly use design centers to design, prototype and test components in a virtual space, and to explore and examine the results of large-scale simulations. Using commercially available video, compression and network equipment and the display quadrant technique, distributed workgroups can now collaborate on tera-scale problem sets. They can take full advantage of high-resolution displays with real-time interactivity. In addition, the system cost and network usage scales linearly for larger resolution displays and/or the addition of new remote sites.		Jerrold A. Friesen;Thomas D. Tarman	2000	IEEE Computer Graphics and Applications	10.1109/38.851749	data compression;computer vision;simulation;image resolution;computer science;operating system;multimedia;data visualization;statistics;computer graphics (images)	Visualization	-34.4741096631007	-33.6330526254753	199140
aa4e7e70306e8a2910cb3fe59702a7e36a4d064d	marker hiding methods: applications in augmented reality	a general works	In augmented reality, the markers are noticeable by their simple design of a rectangular image with black and white areas that disturb the reality of the overall view. As the markerless techniques are not usually robust enough, hiding the markers has a valuable usage, which many researchers have focused on. Categorizing the marker hiding methods is the main motivation of this study, which explains each of them in detail and discusses the advantages and shortcomings of each. The main ideas, enhancements, and future works of the well-known techniques are also comprehensively summarized and analyzed in depth. The main goal of this study is to provide researchers who are interested in markerless or hiding-marker methods an easier approach for choosing the method that is best suited to their aims. This work reviews the different methods that hide the augmented reality marker by using information from its surrounding area. These methods have considerable differences in their smooth continuation of the textures that hide the marker area as well as their performance to hide the augmented reality marker in real time. It is also hoped that our analysis helps researchers find solutions to the drawbacks of each method.	augmented reality	Rania Mousa;Mohd Shahrizal Sunar;Hoshang Kolivand;Amjad Rehman;Abdullah Al-Dhelaan;Mznah Al-Rodhaan	2015	Applied Artificial Intelligence	10.1080/08839514.2015.993553	simulation;computer science;artificial intelligence;multimedia;computer graphics (images)	HCI	-36.681224221512345	-35.888282363276865	199335
11eed405422530c39d22cca28e1a3601794cfed6	vipr and the visual programming challenge	real time;contextual information;visual programming language;visual programming;pedagogical issues;visual features	The Visual Programming Challenge (VPC) provides a framework for exploring visual programming language issues in a quasi-real-time environment and for comparing competing languages. VIPR is an attempt to bring the traditional strengths of textual imperative languages to a visual programming language. It leverages these strengths to make use of well understood design and abstraction methodologies while providing additional visual features, such as explicit representations, contextual information, and execution animation. VIPR uses these strengths and features to address the quasi-real-time problem posed by the VPC, whose requirements include interaction with the low-level vehicle manipulation code, map exploration and display, as well as additional requirements such as flexibility of solution and performance demands. Our solution does not directly address pedagogical issues or the value of VIPR’s simple graphical semantics. It did point out weaknesses with VIPR’s approach to solving the scalability problem in visual programming languages. ∗This work was supported in part by a grant from the National Science Foundation: NSF CISE-IRI-9616242.	abstraction layer;debugging;diagram;distortion;extensibility;graphical user interface;handy board;high- and low-level;ibm notes;imperative programming;map projection;programmer;real-time clock;real-time transcription;requirement;scalability;tcl;top-down and bottom-up design;virtual private cloud;visual language;visual programming language	Wayne Citrin;Soraya Ghiasi;Benjamin G. Zorn	1998	J. Vis. Lang. Comput.	10.1006/jvlc.1998.0080	natural language processing;computer science;database;programming paradigm;fifth-generation programming language;visual programming language;programming language	Graphics	-40.24200403031719	-32.33212399675525	199392
4c01ee2ab8ff9aca4a6f878f8d01e29023fc798c	narrated animation: a case for generation	integrated systems;automatic;computer graphics;simulation;natural language;workplace layout	To date, our pr imary concern with Natural Language has been as input to the system, in line with the strong claim we make in [1] that moving task animation beyond direct graphical manipulat ion forces one to Natural Language as the only instruction source accessible to other users than the current community of manually skilled (or programming-wise) animators. (To this end, we have been analysing constructions commonly found in NL instructions, in terms of their representational requirements [3]. However here our point of discussion is NL Generation. Wha t makes us such eager consumers of advances and technology in this area is tha t animated simulations without narrat ion (ultimately, spoken narration) is only half the story. As researchers studying plan inference have shown [2], it may be well-nigh impossible to infer an agent 's intentions simply by observing his or her actions alone. 2 And we know that the ability to perform an action effectively in a range of environments requires understanding its intention, not just the physical motions used in some performance. Thus, communicating intentions is as impor tant to effective task instruction as demonstrat ing physical skills. Sharing the burden of communication between Natural Language and graphics, as Feiner and McKeown have noted [4], takes advantage of the best of both possible worlds. While some parts of our system are further along than others, no work at all has yet been done on generation. However, we have tried to take account of the needs of generation in designing the system, so that we will not have painted ourselves in a hole from the start . We clearly and hope to get further ideas and direction from this meeting. Basically, the sys tem has been designed so that the generator will receive information from three sources (see Figure 1.):	graphics;nl (complexity);natural language;nick mckeown;possible world;requirement;simulation	Norman I. Badler;Mark Steedman;Bonnie L. Webber	1990			simulation;computer science;multimedia;computer graphics (images)	AI	-38.846069669641416	-31.221824068933607	199482
d308f74297ca2eca288cf11074a7d584ed95c8e9	an algorithm for progressive raytracing	interfase usuario;user interface;representation image;base donnee visuelle;systeme recherche information;computer graphic;sintesis imagen;image synthesis;image interpretation;image generation;interpretacion imagen;progressive transmission;image representation;ray tracing;information retrieval systems;synthese image;interface utilisateur;interpretation image;visual databases	Progressive generation of images is one of the important research areas of computer graphics. Especially, when the image generation takes too much time the users want to see the progress in the rendering process. The user may decide either to continue the rendering process or stop the rendering according to the current view of the image. This may be due to the fact that either the image is produced to enough detail for the user or the user does not want to continue the rendering process for some reason. This is especially important for progressive transmission of images over the Internet. The images may be progressively transmitted and when the detail level of the image is enough for the user, the transmission process may stop. In this paper, we survey the progressive image generation techniques and present an algorithm for progressive generation of raytraced images. The algorithm utilizes a refinement technique that is similar to the one used in generating interlaced images in a progressive manner.	algorithm;glossary of computer graphics;interlaced video;internet;ray tracing (graphics);refinement (computing);rendering (computer graphics)	Okan Arikan;Ugur Güdükbay	2000		10.1007/3-540-40888-6_23	ray tracing;computer vision;rendering;computer science;multimedia;real-time rendering;user interface;computer graphics (images)	Graphics	-34.69698245349044	-35.13436544139315	199563
