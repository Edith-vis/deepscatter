id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
d1c042148b6bd2e85b694820f803484142a428fc	quality ensuring development of software processes	gestion integrada;developpement logiciel;gestion integree;gestion entreprise;modele entreprise;gestion qualite;norme iso;gestion calidad;certification;organisation entreprise;certificate authority;iso;processus metier;norma iso;firm management;integrated management;software development process;modelo empresa;software engineering;iso standard;production process;enterprise organization;business model;organizacion empresa;object oriented;desarrollo logicial;design pattern;software development;certificacion;processus fabrication;object oriented software engineering;software package;quality management system;genie logiciel;oriente objet;administracion empresa;progiciel;orientado objeto;ingenieria informatica;paquete programa;qualite logiciel;software quality;gestion developpement logiciel;software development management;business process;proceso fabricacion;software process;quality management	Software development is a complex process where many organizational units, persons, systems and artifacts are involved. In companies that exceed a certain size the business processes become difficult to handle and the quality of the product can decrease. A process-oriented view on software development is increasingly popular witnessed by current publications on the software development process and the application of modern quality management systems. The ISO 9000 norm describes a quality management system that provides a process oriented view on general production processes and is widely used in many industries. In this paper we suggest a systematic way of describing and developing software processes that contain certain desirable properties and fulfill quality management demands. Therefore, the design pattern approach known from object-oriented software engineering will be adapted to the modeling of business processes. Using this approach the requirements of the ISO 9000 norm can be translated to software development process patterns. These patterns can be used in modeling or reengineering the business processes of a software company in a way that the processes fulfill important properties of quality management systems and improve the overall quality of the resulting software product. Additionally, finding quality management patterns in software development processes can indicate the existence of a functioning quality management system to certification authorities and customers.	business process;certificate authority;code refactoring;communications of the acm;design pattern;ishikawa diagram;james rumbaugh;model-driven architecture;pattern language;pattern matching;process modeling;process patterns;requirement;sms language;software design;software design pattern;software development process;software engineering;unified modeling language;unified process	Alexander Förster;Gregor Engels	2003		10.1007/978-3-540-45189-1_6	quality management;verification and validation;team software process;software quality management;software engineering process group;software sizing;computer science;business process management;package development process;social software engineering;software development;software deployment;software quality control;business process modeling;goal-driven software development process;software development process;software quality;software metric;software quality analyst	SE	-56.46022694438093	20.746775323761	149283
d935125b811b7f32df8bff9376d1ba05191808fd	a legacy application meta-model for modernization		Cloud computing provides many advantages to enterprises such as rapid elasticity, reduced operational costs, no upfront investment, resource pooling, so on. To take advantage of cloud benefits, enterprise attempt to move their legacy application to the cloud environment. However, many factors influence this decision. First one involves a full understanding of the legacy application architectural model from different view models such as business (e.g., defining application functionalities), implementation and data (e.g., the architecture of the application, the language used) and infrastructure (e.g., Hardware resources). Second, it requires choosing, in an efficiently way, the most suitable cloud services responding to users' needs. Finally, each cloud service adopted defines a scenario modernization based on Architecture Driven Modernization (ADM) which support a transformation of the legacy application to a cloud environment to satisfy new users demands.  These concerns motivate the need for legacy application meta-model. This meta-model captures the high level of a legacy application regardless of technical details and represents three viewpoints (business viewpoints, implementation and data viewpoints and infrastructure viewpoints). Each viewpoint focuses on the application stakeholder perspectives. This meta-model helps also helps to make a decision about which view of the legacy application should be modernized and which cloud service (e.g., IaaS, PaaS, and SaaS) model is appropriate to be moved.	architecture-driven modernization;cloud computing;elasticity (cloud computing);high-level programming language;legacy system;metamodeling;model transformation;platform as a service;software as a service	K. Sabiri;F. Benabbou	2017		10.1145/3090354.3090385	data mining;metamodeling;cloud computing;viewpoints;legacy system;computer science;pooling;software as a service;architectural model;software modernization	HPC	-58.589740915764004	19.35977888684625	150786
1df96a9093404f4a5cc1fc81146d99694647effa	towards a lightweight model driven method for developing soa systems using existing assets	industrial project lightweight model driven method soa system legacy system migration system development meet in the middle approach asset reusing uml model business process;software maintenance;uml;unified modeling language business service oriented architecture humans aging transforms;aging;soa;uml precise style model driven soa;precise style;unified modeling language service oriented architecture software maintenance software reusability;software reusability;business;unified modeling language;transforms;model driven;humans;service oriented architecture	Developing SOA based systems and migrating legacy systems to SOA are difficult and error prone tasks, where approaches, methods and tools play a fundamental role. For this reason, several proposals have been brought forward in literature to help SOA developers. This paper sketches a novel method for the development of systems based on services, i.e., adhering to the SOA paradigm, which follows the model driven paradigm. Our method is based on a “meet-in-the-middle” approach that allows the reuse of existing assets (e.g., legacy systems). The starting point of this method is a UML model representing the target business process and the final result is a detailed design model of the SOA system. The method, explained in this paper using a simple running example, has been applied successfully within an industrial project.	business process execution language;business process;cognitive dimensions of notations;eclipse;legacy system;machine translation;meet-in-the-middle attack;plug-in (computing);postal;process modeling;programming paradigm;service-oriented architecture;unified modeling language;web service	Maurizio Leotta;Gianna Reggio;Filippo Ricca;Egidio Astesiano	2012	2012 14th IEEE International Symposium on Web Systems Evolution (WSE)	10.1109/WSE.2012.6320532	unified modeling language;real-time computing;computer science;software engineering;service-oriented architecture;law;oasis soa reference model	SE	-56.51878061810622	19.75252924880383	151056
827f60fa33cd55f2f632f514680f42c41443322c	using goal-oriented requirements engineering for improving the quality of iso/iec 15504 based compliance assessment frameworks	project management;goal orientation;compliance goal oriented requirements engineering business process iso iec 15504;iso standards;business process design;risk management;knowledge management;software systems;goal oriented requirements engineering;iso iec 15504;basel ii;operational risk;process design;requirements engineering;iec standards;business case;requirement engineering;business;taxonomy;compliance;goal oriented;context modeling;financial sector;business process;iso standards iec standards business risk management knowledge management project management context modeling software systems taxonomy process design	Within the context of business processes design and deployment we introduce and illustrate the use of goal models for capturing compliance requirements applicable over business processes configurations. More specifically we explain how a goal-oriented approach can be used together with the ISO/IEC 15504 standard in order to provide a formal framework according to which the compliance of business processes against regulations and their associated requirements can be assessed and measured. The overall approach is discussed and illustrated through the handling of a real business case related to the Basel II Accords on operational risk management in the financial sector.	business process;domain engineering;enterprise risk management;iso/iec 15504;itil;interoperability;requirement;requirements engineering;risk management;software deployment;software framework;spatial variability;traceability	André Rifaut;Eric Dubois	2008	2008 16th IEEE International Requirements Engineering Conference	10.1109/RE.2008.44	iso/iec 9126;reliability engineering;economics;iso/iec 12207;business requirements;systems engineering;knowledge management;goal orientation;requirements engineering;management	SE	-56.926766504030326	19.56471690665336	151863
a14e8f80f6e2ca3e7073e18c822f89c2caa37b8d	open-mentor: a third generation oo methodology-advanced tasks and techniques	object oriented modeling software engineering computer industry collaboration corporate acquisitions environmental management quality management project management software development management engineering management;object oriented methods;large scale;object oriented;large scale deployments;object technology open mentor full lifecycle object oriented methodology large scale deployments process focussed methodology;full lifecycle object oriented methodology;object technology;open mentor;process focussed methodology	The increased complexity associated with large-scale deployments requires an increase in the sophistication of the methodology used to manage these deployments. Tasks and techniques within the full lifecycle object-oriented methodology, OPEN-MeNtOR, are described in detail with emphasis on the more advanced contributions made by OPEN-MeNtOR to the state-of-the-art in object technology.		Paul A. Swatman	1997		10.1109/APSEC.1997.640222	simulation;computer science;systems engineering;engineering;knowledge management;software engineering;programming language;object-oriented programming	Visualization	-61.16490548747338	24.10302952641017	153544
4990132569304539bd08712503a687a04b30e591	a quality framework for agile requirements: a practitioner's perspective	verification;agile;invest;feature requests;smart;just in time requirements;quality;user stories;framework	Verification activities are necessary to ensure that the requirements are specified in a correct way. However, until now requirements verification research has focused on traditional up-front requirements. Agile or just-in-time requirements are by definition incomplete, not specific and might be ambiguous when initially specified, indicating a different notion of ‘correctness’. We analyze how verification of agile requirements quality should be performed, based on literature of traditional and agile requirements. This leads to an agile quality framework, instantiated for the specific requirement types of feature requests in open source projects and user stories in agile projects. We have performed an initial qualitative validation of our framework for feature requests with eight practitioners from the Dutch agile community, receiving overall positive feedback.	agile software development;just-in-time compilation;open-source software;positive feedback;requirement;user story	Petra Heck;Andy Zaidman	2014	CoRR		reliability engineering;requirements analysis;verification;agile unified process;agile usability engineering;computer science;systems engineering;engineering;knowledge management;software framework;requirement;agile software development;smart criteria;management;user story	SE	-58.67382709015955	23.97534038721504	153973
8864a234e7c1c34904de9502e7318fe873d6d011	a goal-driven project management framework for multi-agent software development : the case of i-tropos	institutional repositories;fedora;vital;vtls;ils	Today’s enterprise information systems have to match with their operational and organizational environment. Unfortunately, software project development method-ologies are traditionally inspired by programming concepts rather than by organiza-tional and enterprise ones. In order to reduce as much this distance, agent-orientation is emerging and has been subject to various researches over the last 10 years. Its suc-cess comes from the fact that it better meets the increasing complexity and flexibility required to develop software applications built in open-networked environments and deeply embedded into human activities. Thanks to benefits like efficient software project management, continuous organ-izational modeling and requirements acquisition, early implementation, continuous testing and modularity, iterative development is more and more used by software engineering professionals especially within object-oriented technologies through the Unified Process. Most multi-agent systems development methodologies only use a waterfall development life cycle or advice their users to proceed iteratively without offering a strong project management framework to support that way of proceeding. Consequently they are not suited for the development of huge and complex user-intensive applications. This dissertation presents a research aimed to build an original agent-oriented software development methodology using an iterative life cycle called I-Tropos. The method fills up the traditional Tropos life cycle gaps and offers a goal-oriented project management framework to support project stakeholders when apply-ing the method. The later covers several dimensions including risk, quality, time and process management. The methodology is validated on a real life case study in the steel industry and is supported by DesCARTES Architect, a CASE-Tool introduced in the dissertation.	multi-agent system;software development	Yves Wautelet	2008			project management;personal software process;verification and validation;extreme project management;software quality management;enterprise software;software project management;systems engineering;engineering;knowledge management;package development process;operations management;software framework;software development;iterative and incremental development;software construction;software as a service;systems development life cycle;project management 2.0;project management triangle;goal-driven software development process;software development process	SE	-60.74800813859102	22.930353982170985	154382
4411ecb175d6a0d7f4766179ed8a24816b9879aa	product line software engineering of embedded systems	assets engineering;analysing product assortment;embedded software area;engineering staff;product line;product line software engineering;product line approach;quality attributes;product features;product line architecture;business manner;domain engineering;evaluation criterion;business driver;embedded system;domain knowledge;embedded software;software engineering	In order to be able to determine whether the product line approach is suitable, a company needs to analyse its business drivers, commonality of existing products, domain knowledge owned by the engineering staff, and quality of the representations of existing software artefacts. In this paper we present evaluation criteria for the development of a product line and give an overview of the current state of practices in the embedded software area. Evaluation criteria are divided into three classes. Business drivers of a product line are defined by analysing product assortment and business manners. Domains and personnel are considered in the analysis of the preconditions and targets of a product line. In the development of core assets, elements that affect assets engineering are considered as well as the mechanisms needed in their maintenance. A product line architecture that brings about a balance between sub- domains and their most important properties is an investment that must be looked after. However, the subdomains need flexibility to use, change and manage their own technologies, and evolve separately, but in a controlled way.	embedded software;embedded system;precondition;software engineering	Eila Niemelä;Tuomas Ihme	2001		10.1145/375212.375271	domain analysis;reliability engineering;software quality management;embedded software;computer science;systems engineering;engineering;product lifecycle;product design specification;requirement;software engineering;domain engineering;product management;product design;domain knowledge;new product development;feature model;product engineering	SE	-62.31407866035002	22.309313687407897	154619
9dfdde6bf942bc2de441bc32b964a5a8ab699750	comprehensive variability analysis of requirements and testing artifacts		Analyzing variability of software artifacts is important for increasing reuse and improving development of similar software products, as is the case in the area of Software Product Line Engineering (SPLE). Current approaches suggest analyzing the variability of certain types of artifacts, most notably requirements. However, as the specification of requirements may be incomplete or generalized, capturing the differences between the intended software behaviors may be limited, neglecting essential parts, such as behavior preconditions. Thus, we suggest in this paper utilizing testing artifacts in order to comprehensively analyze the variability of the corresponding requirements. The suggested approach, named SOVA R-TC, which is based on Bunge’s ontological model, uses the information stored and managed in Application Lifecycle Management (ALM) environments. It extracts the behavior transformations from the requirements and the test cases and presents them in the form of initial states (preconditions) and final states (post-conditions or expected results). It further compares the behavior transformations of different software products and proposes how to analyze their variability based on cross-phase artifacts.	heart rate variability;requirement	Michal Steinberger;Iris Reinhartz-Berger	2016		10.1007/978-3-319-39696-5_28	systems engineering;computer science;software;test case;reuse;software product line;application lifecycle management	SE	-56.048215188635844	24.6048401758586	155066
e3c55ecb5304ac6b4b501f679f4bc0b73d50ee39	multi-objective resources allocation approaches for workflow applications in cloud environments		Resources allocation and scheduling has been recognised as an important topic for business process execution. However, despite the proven benefits of using Cloud to run business process, users lack guidance for choosing between multiple offering while taking into account several objectives which are often conflicting. Moreover, when running business processes it is difficult to automate all tasks. In this paper, we propose three complementary approaches for Cloud computing platform taking into account these specifications.	business process;cloud computing;scheduling (computing)	Kahina Bessai;Samir Youcef;Ammar Oulamara;Claude Godart;Selmin Nurcan	2012		10.1007/978-3-642-33618-8_86	simulation;engineering;knowledge management;operations management	Metrics	-59.76040297379527	19.02218053888656	155556
5c803681a65d883d241b56682aa3c4a1bad172b8	formal methods for the engineering and certification of safety-critical knowledge-based systems	formal methods;safety-critical knowledge-based systems;knowledge based system;formal method	The main aim of this work is positioning formal methods in the context of knowledge based software. Peculiar aspects of formal methods for knowledge-based systems and their role in knowledge engineering are summarised. Particular attention is posed on the verification and validation capabilities of formal methods as the actual added value substantiating the onerous effort required by their development and exploitation. This paper constitutes a result of the Safe-KBS Project1 whose basic aim was defining development and certification methodologies specifically oriented to the production of knowledge-based software embedded into safety critical systems.	formal methods;knowledge-based systems	Giovanna Dondossola	1999			reliability engineering;formal methods;systems engineering;knowledge management;knowledge engineering;formal specification;domain knowledge	Logic	-57.067238949832785	23.625442511619926	157279
22f24a42d50b3d0d0d84871b9c1b694da69b46e5	developing tools for reverse engineering in a software product-line architecture	reverse engineering software tools computer architecture programming computer science investments software systems time to market software engineering software quality;software systems;reverse engineering software reuse software development life cycle software architecture product line architecture;development tool;software architecture;software reusability;product line architecture;software development;organisational aspects software reusability software architecture reverse engineering systems re engineering software tools;software development life cycle;software tools;software product line;software reuse;reverse engineering;organisational aspects;systems re engineering	Software reuse should be engineered as early as possible in the software development life cycle. The earlier reusability considerations are put into software development, the larger the payoff can be obtained from reuse. Today, many organizations recognize that an architecture represent a significant investment of both time and effort of its design expertise. The organizations want to maximize this investment by reusing architecture on multiple systems. There are two settings in which architectures can be reused: within an organization and across organizations. This paper describes our work in creating and evolving product-line architecture for a family of software systems within an organization. The approach is illustrated with an industrial example of a commercial tool for reverse engineering. This paper also presents the problems with the solutions in reusing architecture in an industrial setting.	centralized computing;code refactoring;code reuse;computer architecture;distributed computing;distributed object;mit engineering systems division;mainframe computer;reverse engineering;rewrite (programming);server (computing);software development process;software product line;software system	Chia-Chu Chiang;Roger Y. Lee	2004	Proceedings of the 2004 IEEE International Conference on Information Reuse and Integration, 2004. IRI 2004.	10.1109/IRI.2004.1431434	enterprise architecture framework;functional software architecture;reference architecture;software architecture;space-based architecture;architecture tradeoff analysis method;database-centric architecture;applications architecture;social software engineering;component-based software engineering;software development;software design description;software engineering;domain engineering;software construction;service;solution architecture;software architecture description;systems development life cycle;resource-oriented architecture;reverse engineering;systems architecture;software system	SE	-62.122920657698494	23.266153403474537	157825
e042f1c8ed0b54dca3eb2f32b9051a2f21ca6d7e	multi-disciplinary engineering of production systems - challenges for quality of control software		Production systems and their inherent control systems are developed within an increasingly multi-disciplinary and increasingly complex engineering process which is, in addition, increasingly interlinked with the other life cycle phases of the production system. Surely this will have consequences for efficiency and correctness of the control system engineering.		Arndt Lüder;Johanna-Lisa Pauly;Konstantin Kirchheim	2019		10.1007/978-3-030-05767-1_1	engineering design process;systems engineering;correctness;software;discipline;control system;computer science	SE	-61.18434738749504	19.145972789501634	158512
19671abe7f43bfe298e0a6f982925b1e480f21d4	model-driven integration and management of data access objects in process-driven soas	software development;data access;database design;process engineering;service oriented architecture;software reuse;business process	In most process-driven and service oriented architectures (SOA), services need to access data stored in a database using database transactions. This is typically done using Data Access Objects (DAOs), but so far the integration of the business process, service, and DAO concepts is not well defined. As a consequence, when the number of services in a SOA grows, the number of DAOs can increase considerably and become hard to manage. In addition to this technical issue, business processes have to be highly adaptable to both functional and technical requirements. We propose a model-driven approach for integrating and managing DAOs in process-driven SOAs. We present a set of models providing different views tailored to the requirements of various stakeholders, such as business experts, database designers, database developers, etc. In process-driven SOAs, process activities running in a process-engine invoke services. We adapt these process flows to model a sequence of DAOs within a service. A DAO repository is used to manage DAOs more efficiently and to improve software reuse in database transaction development. The repository provides functionalities to create, update, retrieve, and delete database transactions. As our view-based models can flexibly be adapted to project requirements, our approach also aims at enhancing maintainability and increasing software development productivity.	business process execution language;business logic;code reuse;data access object;database transaction;model-driven architecture;model-driven integration;requirement;service-oriented architecture;software development;view model	Christine Mayr;Uwe Zdun;Schahram Dustdar	2008		10.1007/978-3-540-89897-9_6	computer science;systems engineering;data mining;database	DB	-55.93277451957326	19.281109565656795	158567
2ba7500d394bd7732f20fcd85bc81a7436da43de	predicting availability and response times of it services		When IT service providers adapt their IT system landscapes because of new technologies or changing business requirements, the effects of changes to the quality of service must be considered to fulfill service level agreements. Analytical prediction models can support this process in the service design stages, but dependencies between quality aspects are not taken into account. In this paper, a novel approach for predicting availability and response time of an IT service is developed, which is simulation-based to support dynamic analysis of service quality. The correctness of the model as well as its applicability in a real case can be evaluated. Therefore, this work presents a step towards an analytical framework for predicting IT service quality aspects.	benchmark (computing);business requirements;cognitive dimensions of notations;configuration management;correctness (computer science);database;european conference on information systems;holism;interdependence;list of system quality attributes;mathematical model;model-driven architecture;quality of service;requirement;response time (technology);service-level agreement;service-orientation;simulation;tracing (software);unavailability	Sascha Bosse;Christian Schulz;Klaus Turowski	2014			service level objective;service product management;operations management	Networks	-58.29690981344397	18.89696910329583	158734
556f1d91525c7513693b422a04529c8c38e43624	towards runtime model based integrated management of cloud resources	cloud management;models at runtime;software architecture	Although there are many management systems, Cloud management still faces with great challenges, due to the diversity of Cloud resources and ever-changing management requirements. Integration and adaptation become important for constructing a cloud management system, because a redevelopment solution based on existing systems is usually more practicable than developing the management system from scratch. However, the workload of redevelopment is also very high. As the runtime model is causally connected with the corresponding running system automatically, constructing an integrated Cloud management system based on runtime models can benefit from the model-specific natures to reduce the development workload. Therefore, in this paper, we present a runtime model based approach to constructing cloud management system. First, we construct the runtime model of each Cloud resource based on its own management interfaces. Second, we construct a composite model reflecting integration management requirements through merging the distributed runtime models. Third, we make Cloud management meet the adaptation requirements through model transformation from the composite model to the customized models specific to different administrators. Such architecture-level integrated management brings many advantages related to the interoperability, reusability and simplicity. The experiment on a real-world cloud demonstrates the feasibility, effectiveness and benefits of the new approach to integrated management of Cloud resources.	cloud management;interoperability;model transformation;requirement	Xing Chen;Ying Zhang;Xiaodong Zhang;Yihan Wu;Gang Huang;Hong Mei	2013		10.1145/2532443.2532444	real-time computing;simulation;systems engineering;engineering	DB	-55.97933345078788	19.70672998825755	159186
29f7fbecf78e9b4577c1b959cda095f5ce5a6387	a study of the relationship between usability and test cases precedence based on a formal model for activity diagrams	activity diagram	This paper is focused on the application of the well-known technique of use cases and especially on the activity diagrams used to represent them to enhance the IS requirements management. Based on previous work of the authors on test generation from use cases and recent studies about operation time measurement, this new form of addressing requirements management could offer significant benefits when compared with traditional practices: a) closer integration between functional requirements and usability constraints, b) easier and more profitable way to reuse the effort on the analysis phase and c) better relationship between analysts and users to derive a good quality specification. This paper shows how formal model for an extended activity diagram can be used for double purpose: A risk analysis on one hand and a usability analysis on the other one.	activity diagram;algorithm;assignment (computer science);emoticon;formal language;functional requirement;it risk management;mathematical model;operation time;point of view (computer hardware company);requirements management;semantics (computer science);software requirements;unified modeling language;usability;whole earth 'lectronic link	Pedro J. Lara Bercial;Juan José Escribano Otero;Luis Fernández Sanz;José Ramón Hilera	2005			requirements management;test case;reuse;functional requirement;usability;risk analysis (business);activity diagram;engineering;systems engineering;use case	SE	-55.77216075482127	24.52873899947869	159521
3ec9e80c40e0cea3752dbf63ea98f1981d9dc2e6	challenges in balancing the amount of solution information in requirement specifications for embedded products	requirements requirements specification;formal specification;complexity theory;standards;formal specification embedded systems;inverters;solutions;companies;computing and processing;assembly;embedded systems;engineering profession;embedded products requirements elicitation design activities requirements specifications design information;components circuits devices and systems;transportation;solutions requirements requirements specification;inverters companies standards transportation assembly complexity theory context;context	Requirements are traditionally viewed as being free of the details of an envisioned solution and specified using purely problem domain entities. Preventing premature design in the requirements permits the available design space not to be restricted too early which might inhibit innovative designs. In practice, on many industrial projects, separating the problem and solution domain entities can be difficult, and arguably there are benefits for not doing so. Many customers feel more confident describing their requirements, often as the difference between the existing products and their needs, some customers have such intimate knowledge of their products that their requirements tend to be very specific, and if the customer knows the exact solution needed that naturally will reduce the cost of the requirements elicitation as well as design activities. Practitioners are challenged to understand when having solution information in requirements is sensible and when it should be avoided. In this research challenge paper, we advocate that researchers should identify different contexts and corresponding criteria that practitioners can use to evaluate when requirements specifications may include design information. To understand the research challenge we present experiences from real projects and suggest possible factors that affect when design information may be viable in requirements specifications.	embedded system;entity;problem domain;requirement;requirements elicitation	Juha Savolainen;Dagny Hauksdottir;Mike Mannion	2013	2013 21st IEEE International Requirements Engineering Conference (RE)	10.1109/RE.2013.6636726	reliability engineering;transport;requirements management;computer science;systems engineering;engineering;operations management;software engineering;requirements elicitation;formal specification;assembly;non-functional requirement	SE	-61.69597482385913	22.249699191222167	159843
ea19629cc3c8c1e5756e4d8e2572e00f73408c02	rest client pattern	inheritance rest client pattern rest based design service oriented architecture soa web services it industry software design pattern software design reuse open source frameworks cxf resteasy jersey;software design reuse;soa;object oriented programming;companies;open source frameworks;public domain software;computer architecture;companies computer architecture service oriented architecture communities;cxf;resteasy;software reusability;web services;it industry;jersey;rest client pattern;software design pattern;communities;service oriented architecture;inheritance;rest based design;web services object oriented programming public domain software service oriented architecture software reusability	Service oriented architecture (SOA) is a common architectural practice in large enterprises. There are numerous technologies to support SOA including web services. The IT industry is moving toward REST based design for its simplicity and productivity. Apache CXF, Apache Axis, JBoss RestEasy, and Jersey frameworks support REST based services and client side implementation. Based on our observation in health care, manufacturing, and retail domains a reoccurring solution can be put into practice so as to minimize code duplication. This paper presents such a solution in the form of a design pattern that promotes design re-use. The REST client pattern houses common service operations in the top of class hierarchy so that re-use is promoted by inheritance. The service specific call preparations are implemented by sub-classes. This pattern is being used by three iconic companies in above mentioned domains using three different open source frameworks-CXF, RESTEasy, and Jersey.	apache axis;apache cxf;class hierarchy;client-side;duplicate code;enterprise architecture;enterprise integration;enterprise software;loose coupling;open-source software;representational state transfer;soap;service-oriented architecture;software design pattern;web service;wildfly	Bhim P. Upadhyaya	2014	2014 IEEE 23rd International Symposium on Industrial Electronics (ISIE)	10.1109/ISIE.2014.6864616	real-time computing;systems engineering;engineering;software engineering	SE	-58.46385560846583	19.497179821965485	160021
08e48e0e4e673f691e2baec1de4495e8ebda1191	development of a unified software quality platform in the szeged infopólus cluster	software metrics;goal question metric;quality attributes;measurement unified modeling language software quality data models monitoring servers;measurement;design and development;software quality assurance;software quality development;software infrastructure;unified software quality platform;metrics;small and middle sized enterprise;servers;szeged infopolus cluster;monitoring;unified modeling language;software industry;modeling software quality assurance metrics goal question metric quality model;industrial application;software infrastructure software quality assurance unified software quality platform szeged infopolus cluster software quality control software quality development szeged software innovation pole cluster small and middle sized enterprise;szeged software innovation pole cluster;quality model;software quality software metrics;modeling;software quality;software quality control;data models	In Software Quality Assurance, system status reports are key to the stakeholders for controlling software quality. Although we may rely on a large number of low level measurements to this end, their interpretation and the way of connecting them to high level quality attributes is always a challenge. In this paper we report on a complex project involving industrial partners whose aim is the development of a unified software quality platform that deals with and bridges these low and high level quality aspects, and provides a basis for the industrial applications of the approach. The project is implemented by a consortium of software industry members of the Szeged Software Innovation Pole Cluster and associated researchers with the support from the EU co-financed national grant promoting innovation clusters of small and middle-sized enterprises. The approach to the unified quality platform is based on the Goal-Question-Metric paradigm and a supporting software infrastructure, and its novelty lies in a unified representation of the low level metrics and the high level questions that evaluate them to address software quality assurance goals. It allows the definition of various complex questions involving different types of metrics, while the supporting framework enables the automatic collection of the metrics and the calculation of the answers to the questions. We present details about the design and development of the quality platform and its relation to the applications that are being developed by the industrial members of the consortium.	gqm;high-level programming language;list of system quality attributes;programming paradigm;software industry;software quality assurance	Árpád Beszédes;Lajos Schrettner;Tibor Gyimóthy	2012	2012 16th European Conference on Software Maintenance and Reengineering	10.1109/CSMR.2012.65	unified modeling language;data modeling;verification and validation;systems modeling;software sizing;software project management;computer science;systems engineering;social software engineering;software framework;software development;software design description;software engineering;software construction;gqm;data mining;software walkthrough;management;software deployment;software quality control;metrics;goal-driven software development process;software quality;software metric;server;measurement;software peer review	SE	-61.39344500455732	24.828625913658016	160577
99a3b358131a95b4c8baf9eedb152f9256adeea7	tracing the rationale behind uml model change through argumentation	quality system;design rationale	Neglecting traceability—i.e., the ability to describe and follow the life of a requirement—is known to entail misunderstanding and miscommunication, leading to the engineering of poor quality systems. Following the simple principles that (a) changes to UML model instances ought be justified to the stakeholders, (b) justification should proceed in a structured manner to ensure rigor in discussions, critique, and revisions of model instances, and (c) the concept of argument instantiated in a justification process ought to be well defined and understood, the present paper introduces the UML Traceability through Argumentation Method (UML-TAM) to enable the traceability of design rationale in UML while allowing the appropriateness of model changes to be checked by analysis of the structure of the arguments provided to justify such	design rationale;diagram;emoticon;ibm tivoli access manager;norm (social);requirements traceability;uml state machine;uml tool;unified modeling language;usability	Ivan Jureta;Stéphane Faulkner	2007		10.1007/978-3-540-75563-0_31	quality management system;idef6;computer science;knowledge management;software engineering;data mining;database;management science;design rationale	SE	-57.131738867353576	20.74439101023746	161026
710bef7cabf92c2428bf13e8b85c5f52b550ee0a	experiences during extraction of variability models for warehouse management systems	feature modeling;product derivation;warehouse management system feature modeling wms variability modeling technique warehouse automation supply chains variability models extraction;materials cranes software business unified modeling language sensors complexity theory;warehouse automation control engineering computing;control engineering computing;software product line;product derivation software product line feature modeling;warehouse automation	Warehouse management systems (WMS) play a critical role in supply chains and large production processes. WMS pose two crucial challenges for variability modeling and management: Firstly, the physical configuration of each warehouse differs significantly. Numerous different electronic devices like controllers, sensors, and motors are used to automate warehouses. Secondly, the processes running in a warehouse demand control and coordination of these various software and hardware components. These processes have different configurations according to customer requirements. This paper reports on our experiences when applying variability modeling techniques in WMS, in order to improve the degree of reuse and shorten the delivery time to customers. Feature modeling is used to extract commonalities and variability in WMS. More than 200 features were identified, and categorized into three hierarchical layers. Furthermore, we linked the feature models to assets, and utilize feature models to support product derivation. Then, the lessons learned from the experiences are discussed. Based on these experiences, we conclude that feature modeling can be applied nicely for scoping features and tracing features to assets, but is not comprehensive enough to support automated configuration during product derivation in WMS.	categorization;experience;feature model;heart rate variability;requirement;scope (computer science);sensor;spatial variability;warehouse management system	Miao Fang;Georg Leyh;Christoph Elsner;Jörg Dörr	2013	2013 20th Asia-Pacific Software Engineering Conference (APSEC)	10.1109/APSEC.2013.124	dimensional modeling;computer science;systems engineering;software engineering;data mining;database	SE	-56.354775652060724	25.258445466763913	161259
6811a2ff8c9cd603db0fb50f7f34e4bd17c824ea	visualization of variability in complex development structures	variability management;product line;complex development structures;feature diagram;visualization	Mass customization in modern industries leads to an increased complexity in product line engineering due to the high level of variability. Real-world industry-sized product lines can easily end up with thousands of features and constraints. Using sophisticated information visualization techniques is one important component in handling this complexity successfully as they provide a higher level of cognitive support and make the comprehension of the underlying structures easier and faster. However, it is still an unresolved problem to handle the occurring variability in a satisfactory way. This means that we need visualization mechanisms able to cope with the requirements of engineers as well as with the needs of the responsible managers. This paper addresses the issue of visualizing large product lines and discusses different techniques which can be used towards an efficient visualization of variability. Furthermore, it presents alternative methods to visualize complex constraints and group cardinalities. These techniques will then be illustrated with the help of a prototypical implementation.	cardinality (data modeling);heart rate variability;high-level programming language;information visualization;requirement;spatial variability	Jürgen Ommen;Georg Rock	2015		10.1145/2701319.2701324	simulation;visualization;computer science;systems engineering;engineering;operations management	SE	-56.10694080330815	25.25006086678653	161539
a1a9f6adb672bd6dbfb6c9a4440e3fc9dfa05a7b	optimal paths in business processes: framework and applications		We present an innovative framework for calculating optimal execution paths in business processes using the abstraction of workflow hypergraphs. We assume that information about the utility associated with the execution of activities in a process is available. Using the workflow hypergraph abstraction, finding a utility maximising path in a process becomes a generalised shortest hyperpath problem, which is NP-hard. We propose a solution that uses ant-colony optimisation customised to the case of hypergraph traversal. We discuss three possible applications of the proposed framework: process navigation, process simulation, and process analysis. We also present a brief performance evaluation of our solution and an example application.	business process	Marco Comuzzi	2017		10.1007/978-3-319-74030-0_7	theoretical computer science;business process;systems engineering;hypergraph;process simulation;tree traversal;constraint graph;workflow;computer science;abstraction	Theory	-56.671799022371175	18.702603555684792	161764
ff48eb699dd8a2d7b2513126c6285cb9ef327a65	architecting in software ecosystems: interface translucence as an enabler for scalable collaboration	interface translucence;open source development;collaboration;software systems;software ecosystems;software architecture;awareness;modular system;software development;modularity	Software ecosystems are emerging as an alternative approach for the development of complex software systems. The potentially transformational benefits of software ecosystems stems, primarily, from two basic principles that software ecosystems have embraced: transparency, a pillar in open source development, and modular system design. Despite the benefits associated with transparency and modularity, there are also important challenges that deserve attention. In this paper, we introduce the concept of interface translucence as an architectural mechanism that seeks to overcome challenges faced by transparency and modular system design. Interface translucence leverages the important technical role that interfaces play in software architectures to bridge the technical and socio-organizational dimensions of software development in ecosystems. We present an application of the concept of interface translucence in the context of architecting a software system as well as in the context of implementing it. We conclude with a discussion of future research work.	open-source software;scalability;software architecture;software development;software ecosystem;software system;systems design	Marcelo Cataldo;James D. Herbsleb	2010		10.1145/1842752.1842772	software architecture;awareness;systems engineering;engineering;knowledge management;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;modularity;software analytics;resource-oriented architecture;software deployment;software development process;software system;collaboration	SE	-61.35243446175424	21.506546433429662	161934
b4e1d9eb52eb33973086ade4979ca81086ff2e5e	enterprise and organizational modeling and simulation		Most of the current techniques and approaches for user requirements specification have problems with capturing the appropriate context for development of enterprise information systems. Primarily, they are designed to capture the functional aspects of software rather than its relevancy to an enterprise. Transactions defined in the DEMO (Design & Engineering Methodology for Organizations) represent business activities in their existential essence without implementation details. Therefore, they are great candidates to be utilized for the initial development phase of enterprise information systems. The paper exemplifies how to specify software specification the using the DEMO transaction pattern and BDD (Behaviour-Driven Development) technique. This proposal resulted from a significant lack of direct utilization of ontology for enterprise information systems development. The major part of the paper gives a step-by-step explanation of how to integrate DEMO transaction patterns into initial BDD scenarios for the development of enterprise information systems. Such created scenarios provide a perfect guideline in the initial phase of information system development for enterprises. The created scenarios were verified using the domain specific language Gherkin and BDD framework Behat.	behat;behavior-driven development;design & engineering methodology for organizations;domain-specific language;enterprise information system;relevance;requirement;simulation;software development process;software requirements specification;user requirements document	Robert Pergl	2018		10.1007/978-3-030-00787-4		SE	-55.88150694507215	22.791465380620522	162370
c96192a1f0d26b5d6a1722ff85a405715ce6b15b	gt4cci: an approach based on grounded theory for crosscutting concerns identification in requirements documents		When crosscutting concerns identification is perfo rmed on the activities involved in requirements engineering there are many gains in terms of quality, cost and efficiency throughout the lifecycle o f s ftware development. However, despite these gains, this identification face s several difficulties such as the lack of systematization and tools that support it a nd the difficult to justify why some concerns are identified as crosscutting or not , since this identification is often made without any methodology that systematize s and bases it. In this context, this paper proposes and evaluates an approach based on Grounded Theory, called GT4CCI, for systematizing the process of ident ifyi g crosscutting concerns in requirements document. Through the use of GT4CCI it is possible to better modularize the requirements document, make i t more consistent, detect possible failures and improve traceability among re quirements, adding significant gains in terms of quality and reliability to c rosscutting concerns identification and to requirements engineering.	correctness (computer science);cross-cutting concern;embedded system;experiment;ident protocol;precision and recall;requirement;requirements engineering;software development process;trac;traceability	Larissa de Alencar Sobral;Lyrene Fernandes da Silva	2013			traceability;process management;risk analysis (engineering);grounded theory;requirements engineering;software development;computer science;artificial intelligence	SE	-58.17082633234788	23.72078795957679	163438
f58c1019ca0da1135b4fcea942cf605c55fca378	investigating model slicing capabilities on integrated plant models with automationml	information filtering;unified modeling language;adaptation models;context modeling;data models;automation	Typical large-scale systems engineering projects depend on seamless cooperation and data exchange of experts from various engineering domains and organizations that work in a heterogeneous engineering environment. Available software tools support individual engineering disciplines quite well, but they only represent a discipline-specific view on the engineering plant. Consequently, a so-called integrated plant model captures and combines all different views into one representation in order to provide an overarching, discipline-independent view on the engineering plant. However, in order to support effective engineering processes, like change management, stakeholders need to be able to (a) define the scope of their changes they want to merge into the integrated plant model rather than the latest status of their view with various fragile adaptations, and (b) extract only engineering information from integrated plant model which is in the scope of the stakeholders's discipline and interest. In this paper, we describe requirements identified in industrial use cases regarding filtering capabilities on (integrated) engineering plant models and model-driven engineering techniques for model-slicing applied on AutomationML models. The approach contributes to quality assurance and fault-prevention in engineering data since it helps to focus on parts of the engineering plant model relevant in certain engineering processes.	change management (engineering);computer engineering;data model;emoticon;library (computing);model-driven engineering;performance evaluation;requirement;seamless3d;systems engineering	Richard Mordinyi;Dietmar Winkler;Fajar J. Ekaputra;Manuel Wimmer;Stefan Biffl	2016	2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA)	10.1109/ETFA.2016.7733556	unified modeling language;data modeling;mechanical engineering technology;information engineering;engineering informatics;system of systems engineering;computer science;systems engineering;engineering;knowledge management;electrical engineering;artificial intelligence;automation;data mining;requirements engineering;context model	SE	-58.14590172921152	18.91933946144267	165119
8c9aa538c83e0e979c8c7dda3182e87eaafa764a	architecture for embedded open software ecosystems	methods;technology;computer and information science;teknikvetenskap;consumer electronics;time;theory methods;software engineering;automotive software;natural sciences;software architecture;industry;theory;article peer reviewed scientific;actice;computer science;software ecosystem;embedded software	Software is prevalent in embedded products and may be critical for the success of the products, but manufacturers may view software as a necessary evil rather than as a key strategic opportunity and business differentiator. One of the reasons for this can be extensive supplier and subcontractor relationships and the cost, effort or unpredictability of the deliverables from the subcontractors are experienced as a major problem. The paper proposes open software ecosystem as an alternative approach to develop software for embedded systems, and elaborates on the necessary quality attributes of an embedded platform underlying such an ecosystem. The paper then defines a reference architecture consisting of 17 key decisions together with four architectural patterns, and provides the rationale why they are essential for an open software ecosystem platform for embedded systems in general and automotive systems in particular. The reference architecture is validated through a prototypical platform implementation in an industrial setting, providing a deeper understanding of how the architecture could be realised in the automotive domain. Four potential existing platforms, all targeted at the embedded domain (Android, OKL4, AUTOSAR and Robocop), are evaluated against the identified quality attributes to see how they could serve as a basis for an open software ecosystem platform with the conclusion that while none of them is a perfect fit they all have fundamental mechanisms necessary for an open software ecosystem approach.	ecosystem;embedded system;open-source software	Ulrik Eklund;Jan Bosch	2014	Journal of Systems and Software	10.1016/j.jss.2014.01.009	reference architecture;software architecture;verification and validation;simulation;embedded software;computer science;systems engineering;engineering;software framework;software development;software design description;operating system;software engineering;software construction;open platform;resource-oriented architecture;management;theory;avionics software;technology	Embedded	-60.499883534878265	20.874804812783655	165137
b89f5797c0d4b3f91dd013cd25ef35b1ebbf75a8	towards an ontology of software defects, errors and failures		The rational management of software defects is a fundamental requirement for a mature software industry. Standards, guides and capability models directly emphasize how important it is for an organization to know and to have a well-established history of failures, errors and defects as they occur in software activities. The problem is that each of these reference models employs its own vocabulary to deal with these phenomena, which can lead to a deficiency in the understanding of these notions by software engineers, potential interoperability problems between supporting tools, and, consequently, to a poorer adoption of these standards and tools in practice. We address this problem of the lack of a consensual conceptualization in this area by proposing a reference conceptual model (domain ontology) of Software Defects, Errors and Failures, which takes into account an ecosystem of software artifacts. The ontology is grounded on the Unified Foundational Ontology (UFO) and is based on well-known standards, guides and capability models. We demonstrate how this approach can suitably promote conceptual clarification and terminological harmonization in this area.	angular defect;conceptualization (information science);ecosystem;interoperability;ontology (information science);software bug;software engineer;software industry;vocabulary	Bruno Borlini Duarte;Ricardo de Almeida Falbo;Giancarlo Guizzardi;Renata S. S. Guizzardi;Vítor Estêvão Silva Souza	2018		10.1007/978-3-030-00847-5_25	data mining;conceptual model;conceptualization;computer science;interoperability;ontology;systems engineering;software;reference model;vocabulary	SE	-58.619822952167475	22.19078961820129	165714
6ba9780ea12a71954e1118ebc16bb1c2220edd2a	towards model-centric engineering of a dynamic access control product line	towards model centric engineering of a dynamic access control product line;product lines;info eu repo semantics conferenceobject;dynamic software;articulo;runtime models;role based access control;product line;access control systems;adaptive software;product line engineering;access control;software product line;dynamic software product lines	Access control systems are deployed in organizations to protect critical cyber-physical assets. These systems need to be adjustable to cope with different contextual factors like changes in resources or requirements. Still, adaptation is often performed manually. In addition, different product variants of access control systems need to developed together systematically. These characteristics demand a product line engineering approach for enhanced reuse. Moreover, to cope with uncertainty at runtime, adaptivity, i.e., switching between variations in a cyber-physical domain (reconfiguration) and adjusting access policies (behavior adaptation), needs to be supported.  In this position paper, we sketch an approach for engineering dynamic access control systems based on core concepts from dynamic software product lines and executable runtime models. The proposed solution is presented and first experiences are discussed along a sample dynamic software product line in the role-based access control domain.	control system;executable;line level;requirement;role-based access control;run time (program lifecycle phase);software product line	Mahdi Derakhshanmanesh;Mazeiar Salehie;Jürgen Ebert	2012		10.1145/2364412.2364437	domain analysis;real-time computing;computer science;systems engineering;engineering;access control;operations management;product design specification;operating system;software engineering;domain engineering;role-based access control;product engineering	SE	-55.93223002708875	20.665357531842492	167085
f6ce95ad8d6ac1d7d8eb5a6e51b7ba6b5ff49023	integration of user experiences to advancement of b2b-software-on-demand systems	small and medium sized companies b2b software on demand system business model user experience integration;electronic commerce;recommendations for visual representations;small to medium enterprises;b2b software on demand system;recommendation for improvements;companies;usability recommender system company modeling software on demand usability recommendations for visual representations recommendation for improvements swod maps recommendation for maps software maps data model;data model;business model;computer architecture;company modeling;visualization;software on demand;recommender system;internet;small to medium enterprises electronic commerce internet;visual representation;demand systems;user experience;swod maps;companies business computer architecture computer science application software recommender systems corporate acquisitions switches personal digital assistants information analysis;small and medium sized companies;usability;software maps;recommender systems;recommendation for maps;user experience integration	"""Software on Demand is the new way of ¿exible provide of software. Especially small and medium sized companies can benefit of this business model. A major problem of using this solution is that experience with users’ specific needs and common needs of the target groups cannot be clearly defined. For this reason it is essential to find a way to """"learn from the user"""". In this paper, I present the current project and a way how user experience can be integrated to improve the system."""	user experience	Eva-Maria Schwartz	2009	2009 International Conference on Computational Science and Engineering	10.1109/CSE.2009.79	business model;the internet;user modeling;visualization;usability;user journey;data model;computer science;knowledge management;data mining;database;world wide web;user story;recommender system	Robotics	-56.35132599327872	19.698986099649353	167595
dc4c1aeedc6d4877390ff090ebe4b77ee9f70ae1	a summary of domain analysis experience by way of heuristics	domain analysis experience;domain engineering;domain analysis;requirements reuse	Domain analysis is seen by wme in the reuse community to be a key process for achieving systematic, largescale, reuse. Howeverr the success of a domain analysis is largely dependent upon how well the domain analysis process is carried out. This paper describes a set of heuristics for domain analysis, which summari ses our experience of domain analysis in a palatable way for others. The aim of these heuristics is to provide an inexperienced domain analyst with practical advice about how to cope with problems during the domain analysis process. We explain when and how to apply each heuristic, illustrated with examples taken from the domain analysis case-studies we have performed at RoSEC, a company which manufactures electronic controllers for aircraft engines.	domain analysis;experience;heuristic (computer science);muse;windows aero	W. Lam;John A. McDermid	1997		10.1145/258366.258386	domain analysis;reliability engineering;domain;business domain;computer science;systems engineering;feature-oriented domain analysis;software engineering;domain engineering;domain model	SE	-60.40332068350854	24.050579896841754	167667
0d8736c565fe55555e85529ed5563354d000fe95	automating technical reviews in software forges and repositories based on linked data		Automating the evaluation of a software process is complex due to the absence of interoperability mechanisms between the tools that are used to manage, develop or maintain software projects. This work presents an approach to facilitate the construction of mechanisms to evaluate software projects. Based on information integration principles and Linked Open Data techniques, project management and development tools can expose their data using a set of shared models, thereby facilitating the development of integration solutions intended for software process evaluation. A practical application of the approach is here described in order to facilitate automated technical reviews of projects in software forges and repositories.		Juan Manuel Dodero;Ivan Ruiz-Rube;Ignacio Traverso Ribón	2014		10.1007/978-3-319-13674-5_4	database;world wide web	SE	-58.798555205734225	23.21700244314014	167735
0fd0dc97a1cf0d777daedf47d8aec0f337e426b2	integrating the concept of standard software into a certifiable development process	development process			Wolfgang Friess;Franz Duckstein	2006			engineering;systems engineering;software;goal-driven software development process;package development process;personal software process;software development process;design process;empirical process (process control model)	SE	-62.576632908606626	25.178649408194772	168093
f8f2ef16453e5d64038b5ef21b6c00f042170b08	semi-automated business process model matching and merging considering advanced modeling constraints		Model merging helps to manage the combination and coevolution of business processes. Combining models (semi-)automatically can be a helpful technique in manifold areas and has been investigated since decades by the scientific community. The rising complexity of (business-) processes in shifting environments demands for a more differentiated view on model matching and merging techniques. In this domain, we identified the problem of considering additional constraints in the matching and merging process and suggest an approach by adapting state of the art solutions correspondingly. In addition, we state necessary reduction rules and discuss their suitability. Moreover we provide a prototypical implementation of a matching and merging tool, which allows further investigations of the approach concerning quality, usefulness and efficiency.	business process;complexity;matching (graph theory);process modeling;semiconductor industry;utility	Markus C. Beutel;Vasil Borozanov;Sevket Gökay;Karl-Heinz Krempels	2017		10.5220/0006341603240331	artifact-centric business process model;process modeling;management science	SE	-57.058271443841896	18.958928228976607	168242
2b549136120bce887840e5e812d59c36168f18bc	applying mda to game software development	software development	Game software becomes more and more complex, according as the game platforms are improved or the requirements of game users become sophisticated, and so does the development of game software. However, there are few established development methodologies for game software development, and it decreases the productivity of the development. One of the solutions for this problem is to apply modeling technologies to it as we do to other application areas, and through modeling we can anticipate productivity improvement. This paper evaluates the applicability and suitability of MDA (Model driven Architecture) to game software development, along with establishing a UML modeling process for typical game categories.	activity diagram;business software;class diagram;model-driven architecture;polystation;rpg;requirement;sequence diagram;software deployment;software development;state diagram;uml state machine;uml tool;unified modeling language	Takashi Inoue;Yoshiyuki Shinkawa	2008			computer science;software development;software engineering;management	SE	-59.448966074574535	25.201946838268572	168301
49964770da1553ba8d40ad568095126b86c4192c	query-driven soft traceability links for models	incremental model queries;derived features;soft links;traceability	Model repositories play a central role in the model driven development of complex software-intensive systems by offering means to persist and manipulate models obtained from heterogeneous languages and tools. Complex models can be assembled by interconnecting model fragments by hard links, i.e., regular references, where the target end points to external resources using storage-specific identifiers. This approach, in certain application scenarios, may prove to be a too rigid and error prone way of interlinking models. As a flexible alternative, we propose to combine derived features with advanced incremental model queries as means for soft interlinking of model elements residing in different model resources. These soft links can be calculated on-demand with graceful handling for temporarily unresolved references. In the background, the links are maintained efficiently and flexibly by using incremental model query evaluation. The approach is applicable to modeling environments or even property graphs for representing query results as first-class relations, which also allows the chaining of soft links that is useful for modular applications. The approach is evaluated using the Eclipse Modeling Framework (EMF) and EMF-IncQuery in two complex industrial case studies. The first case study is motivated by a knowledge management project from the financial domain, involving a complex interlinked structure of concept and business process models. The second case study is set in the avionics domain with strict traceability requirements enforced by certification standards (DO-178b). It consists of multiple domain models describing the allocation scenario of software functions to hardware components.	avionics;business process;cognitive dimensions of notations;eclipse modeling framework;hard link;identifier;knowledge management;model-driven engineering;requirement;soft systems methodology;synapomorphy;traceability	Ábel Hegedüs;Ákos Horváth;István Ráth;Rodrigo Rizzi Starr;Dániel Varró	2014	Software & Systems Modeling	10.1007/s10270-014-0436-y	traceability;real-time computing;simulation;computer science;engineering;software engineering;data mining	SE	-55.701683340814945	20.138232442672418	168691
7b1e18688dae102b8702a074f71bbea8ba540998	automotive safety and security integration challenges		The ever increasing complexity of automotive vehicular systems, their connection to external networks, to the internet of things as well as their greater internal networking opens doors to hacking and malicious attacks. Security an d privacy risks in modern automotive vehicular systems are well publicized by now. That violation of securit y could lead to safety violations – is a well-argued and accepted argument. The safety discipline has matured over decades , but the security discipline is much younger . There are arguments and rightfully so, that the security engineering process is similar to the functional safety engineering process (formalized by the norm ISO 26262 ) and that they could be laid side -by-side and could be performed together but, by a different set of experts. There are moves to define a security engineering process along the lines of a functional safety engineering process for automotive vehicular systems . But, are these efforts at formalizing safety-security sufficient to produce safe and secure systems? When one sets out on this path with the idea of building safe and s ecure systems , one realizes that there are quite a few challenges, contradictions , dis imilarities, concerns to be addressed before safe and secure systems started coming out of production lines. The effort of this paper is to bring some such challeng e areas to the notice of the community and to suggest a way forward.	design pattern;internet of things;limbo;privacy;safety engineering;security engineering;type safety;vocabulary	Benjamin Glas;Carsten Gebauer;Jochen Hänger;Andreas Heyl;Jürgen Klarmann;Stefan Kriso;Priyamvadha Vembar;Philipp Wörz	2014				Security	-57.47433035154752	22.5669714884458	168727
6bd8942e98e6fcc3f3c34b3438c4d4fbc58f3e08	accommodating openness requirements in software platforms: a goal-oriented approach		Open innovation is becoming an important strategy in software development. Following this strategy, software companies ar increasingly opening up their platforms to third-party products. However, o pening up software platforms to third-party applications raises serious concerns about critical quality requirements, such as security, performance, privacy and p roprietary ownership. Adopting appropriate openness design strategies, which f ulfill open-innovation objectives while maintaining quality requirements, calls for deliberate analysis of openness requirements from early on in opening up s oftware platforms. We propose to treat openness as a distinct class of non-f unctional requirements, and to refine and analyze it in parallel with other design co cerns using a goal-oriented approach. We extend the Non-Functional Requirements (NFR) analysis method with a new set of catalogues for specifying and ref ining openness requirements in software platforms. We apply our approach to rev isit the design of data provision service in two real-world open software platfo rms and discuss the results.	non-functional requirement;open innovation;open-source software;openness;rev;software development;software industry	Mahsa Hasani Sadi;Eric Yu	2017		10.1007/978-3-319-59536-8_4	systems engineering;goal orientation;open innovation;software development;computer science;software;software design;openness to experience	SE	-59.519063662151275	20.421467257352155	169260
037a49e00df6e47b9d8f945536e298b11b159969	using technical-action-research to validate a framework for authoring software engineering methods	evidence based;case studies;software engineering;tar;omg;semat;validation	The validation of proposals has become a fundamental part of the creation of knowledge in Software Engineering. Initiatives like SEMAT have highlighted the need to base the correctness, usefulness and applicability of Software Engineering theories and practices on solid evidence. This paper presents the validation process used for KUALI-BEH, a proposal that became part of an OMG standard. The validation strategy applied was the result of integrating Technical-Action-Research and Case Study methods. After three years of work, we can conclude that TAR is a valuable research method, emphasizing that the main advantages of TechnicalAction-Research are continuous feedback and the validation of an artifact, in this case KUALI-BEH, in a real context.	correctness (computer science);semat;software engineering;theory	Miguel Morales Trujillo;Hanna Oktaba;Mario Piattini	2015		10.5220/0005338800150027	verification and validation;software engineering;tar;evidence-based practice	SE	-57.533422481792414	24.62637454206908	169468
c93389c6af8465358435663610de2b7d6e485633	legacy systems adaptation using the service oriented approach	service orientation;legacy system	Legacy systems are the core IT assets of the great majority of organisations that support their critical business processes. Integrating those existing legacy systems with the rest of IT infrastructure is a complex and difficult task. Legacy systems are often undocumented, inflexible and tightly coupled and imply high cost of maintenance. Many organisations are starting to look at Service Oriented Architectures (SOA) as a potential way to expose their existing legacy investment as functional units to be re-used and exploited externally. This paper is focused on providing guidance to those organisations which want to use SOA on legacy adaptation and transformation. For doing so, this paper defines a vision and a set of best practices that any organisation should follow in order to expose their useful legacy functionalities as part of a SOA environment, allowing the development of hybrid systems understood as compositions of new services as well as of legacy systems and existing components wrapped as services.	best practice;business process;extensibility;hybrid system;legacy system;multitier architecture;partial template specialization;smart;service-oriented architecture;undocumented feature	Francisco Javier Nieto;Iñigo Cañadas;Leire Bastida	2008			computer science;legacy system	SE	-58.64938853311665	20.08735773974038	169584
65af883aa7030702e63e0e0fcc4355cf713879f3	using patterns to empower end-users - the oregon software development process for groupware	software development process;end user participation;oregon;tailoring;design patterns;groupware development;oregon software development process osdp	Fostering interaction between end-users and developers is one of the most important issues when developing groupware. Insufficient interaction leads to groupware systems that do not fulfill the group's requirements and thus to low acceptance. Furthermore, as group processes change dynamically the requirements are not static as well. Groupware system development and use, therefore, have to address users' changing needs. Current design methodologies insufficiently focus on this aspect. Therefore, we propose the Oregon Software Development Process (OSDP) that fosters end-user participation throughout the whole groupware life cycle, structures the interaction between end-users and developers, and emphasizes the use of a shared language between users and developers. We illustrate the application of the process with experiences made in an interdisciplinary development project of a collaborative learning platform.	collaborative software;software development process	Till Schümmer;Stephan Lukosch;Robert Slagter	2006	Int. J. Cooperative Inf. Syst.	10.1142/S0218843006001360	software design pattern;simulation;human–computer interaction;computer science;software engineering;computer-supported cooperative work;software development process	SE	-62.26471827949358	19.369578135300777	170200
6ed50b66eff0cb3a0ca61091d1b830f648ddd552	issues encountered in building a flexible software development environment: lessons from the arcadia project	object management;key lesson;arcadia-1 architecture;arcadia project;flexible software development environment;heterogenous componentry;event-based control integration mechanism;effective software development environment;pervasive need;user interface development;language processing;principal component;user interface;software development environment	This paper presents some of the more significant technical lessons that the Arcadia project has learned about developing effective software development environments. The principal components of the Arcadia-1 architecture are capabilities for process definition and execution, object management, user interface development and management, measurement and evaluation, language processing, and analysis and testing. In simultaneously and cooperatively developing solutions in these areas we learned several key lessons. Among them: the need to combine and apply heterogenous componentry, multiple techniques for developing components, the pervasive need for rich type models, the need for supporting dynamism (and at what granularity), the role and value of concurrency, and the role and various forms of event-based control integration mechanisms. These lessons are explored in the paper.	concurrency (computer science);integrated development environment;pervasive informatics;software development;user interface	R. Kadia	1992		10.1145/142868.143768	simulation;human–computer interaction;computer science;systems engineering;engineering;software engineering;development environment;user interface;principal component analysis	SE	-61.24388225853531	21.794377844231498	170233
d5944458a2208bc4bf45a3b3f9d94c879ea3e3fa	tool support for analyzing the evolution of enterprise architecture metrics	metrics;enterprise architecture management;domain specific language	Managing the evolution of the Enterprise Architecture (EA) is a key challenge for modern enterprises. The EA metrics are instrumental in quantitatively measuring the progress of an enterprise towards its goals. Retrospective analysis of EA metrics empower business users to take informed decisions while planning and selecting efficient alternatives to achieve envisioned EA goals. Even though the current EA management tools support the definition and calculation of EA metrics, they do not capture the temporal aspects of EA metrics in their meta-model to enable retrospective analysis. In this paper, we first propose a model-based approach to capture the temporal aspects of EA metrics and then extend a domain specific language to compute EA metrics at any point of time in the past. This allows visualizing the evolution of EA metrics and as a consequence the evolution of the EA.	digital subscriber line;domain-specific language;embedded atom model;emoticon;enterprise architect;enterprise architecture;evolution;evolutionary algorithm;information model;metamodeling;microsoft outlook for mac;time series;usability	Manoj Bhat;Thomas Reschenhofer;Florian Matthes	2015		10.5220/0005370701540161	computer science;domain-specific language;knowledge management;enterprise architecture management;data mining;programming language;metrics	DB	-57.45247814238656	18.54682145919839	170391
1496a67c4fc77e0bdfda14e27c20d3e4f4f5aabc	functional matching in cots-based development context	requirements engineering;post-condition;pre-condition;matching;intention;component-based development.;map;strategy;section;requirement engineering;requirements elicitation;component based development	Requirements engineering in the context of off-the-shelf component-based system development is a difficult issue. Most actual approaches are not requirements-driven, which does not allow to gain a great customer acceptance. Otherwise, they have difficulties getting a natural matching between customer requirements and component features, which does not facilitate the user involvement. The paper extends our former thoughts on an approach that is requirements-driven and is featured by a systematic way-of-working for system requirements elicitation, COTS candidate products' features discovery, and last but not least, a rigorous reasoning on the matching matter. The overall process is helped with map usage, the new representation system that we believe useful for a natural reasoning.	component-based software engineering;requirement;requirements elicitation;requirements engineering;system requirements	Thanh Loan Le;Colette Rolland	2001			requirements elicitation;component-based software engineering;non-functional requirement;requirement;requirements engineering;system requirements;reliability engineering;systems engineering;engineering	SE	-55.998026787662226	24.851891218752876	171141
f2ef8b08a83601d07b059a0540f4af89893f8372	towards a holistic definition of system engineering: paradigm and modeling requirements		Current systems complexity has reached a degree that requires addressing conception and design issues while taking into account all the necessary aspects. Therefore, one of the main challenges is the way complex systems are specified and designed. The exponential growing effort, cost and time investment of complex systems in modeling phase emphasize the need for a paradigm, a framework and a environment to handle the system model complexity. For that, it is necessary to understand the expectations of the human user of the model and his limits. This paper presents a generic framework for designing complex systems, highlights the requirements a system model needs to fulfill to meet human user expectations, and defines the refined requirements modeling tools needs to meet to be useful in system engineering.	holism;programming paradigm;requirement;systems engineering	Hycham Aboutaleb;Bruno Monsuez	2014		10.1007/978-3-319-08422-0_85	systems engineering;requirements engineering	SE	-60.82056667292084	19.4248358071648	171410
6fd31b829eb3df97aefaced8100157df193b3597	towards a taxonomy of microservices architectures		The microservices architectural style is gaining more and more momentum for the development of applications as suites of small, autonomous, and conversational services, which are then easy to understand, deploy and scale. However, the proliferation of approaches leveraging microservices calls for a systematic way of analyzing and assessing them as a completely new ecosystem: the first cloud-native architectural style. This paper defines a preliminary analysis framework in the form of a taxonomy of concepts, encompassing the whole microservices lifecycle, as well as organizational aspects. This framework is necessary to enable effective exploration, understanding, assessing, comparing, and selecting microservice-based models, languages, techniques, platforms, and tools. Then, we analyze state of the art approaches related to microservices using this taxonomy to provide a holistic perspective of available solutions.	autonomous robot;ecosystem;event-driven programming;fault tolerance;holism;microservices;taxonomy (general)	Martin Garriga	2017		10.1007/978-3-319-74781-1_15	taxonomy (biology);systems engineering;computer science;microservices;architectural style	SE	-60.761505518698485	21.48924288592999	171888
27b579d8f15cf073a096b8573c4f4c9a64cccd83	early insight in systems design through modeling and simulation		In early design stages, system architects mostly rely on estimations to make design decisions. These are based on the available information at hand and their experience. Modeling and simulation is almost exclusively applied in more detailed stages of design. In this paper we present an approach aimed at making better informed design decisions, early in the design process.#R##N##R##N#Our approach focuses on giving insights in early design through simulations and models that are usually only provided in more detailed design stages. To do so, we propose a framework and address three conflicts that arise when connecting techniques from early and detailed design stages. These are dealing with uncertainty, accommodating multidisciplinary views and accounting for more divergent design space exploration strategies.#R##N##R##N#The approach has been applied to a medical imaging system, to analyze a possible latency reduction. The goal of this case study was to gain realistic insight in system latency using a highly abstracted system model and a generic simulation model. Insights gained with these models confirmed that a new design reduces system latency and deals better with large variations in latency. The underlying structure of the approach has proven itself to be feasible. Further research is necessary to determine whether the approach can cover a broader range of applications and to evaluate how the full approach can be implemented	simulation;systems design	Steven P. Haveman;G. Maarten Bonnema;Freek van den Berg	2014		10.1016/j.procs.2014.03.022	simulation;probabilistic design;management science	EDA	-60.91072146889182	19.19775458261591	172058
459cfd880efae8888fa19a9bf2474cd8f416c828	generality vs. reusability in architecture-based self-adaptation: the case for self-adaptive microservices		Why is it so difficult to build self-adaptive systems by reusing existing self-adaptation services and frameworks? In this paper, we argue that one possible explanation is that there is a fundamental mismatch between the adaptation needs of modern software systems, and the architectural models and adaptation mechanisms supported by current self-adaptation solutions. We identify and discuss the main reasons leading to this problem by looking into a number of representative self-adaptation solutions that have been proposed in recent years, including open source frameworks and cloud-based services, from two perspectives: generality, i.e., their ability to support a variety of architectural models and adaptation mechanisms, and reusability, i.e., their ability to be reused without requiring substantial effort from software developers. We then make the case that recent industry progress toward microservices and their enabling technologies can open the way to the development of more general and reusable self-adaptation solutions.	adaptive system;autonomous robot;cloud computing;general-purpose modeling;microservices;open-source software;software developer;software framework;software system	Nabor das Chagas Mendonça;David Garlan;Bradley R. Schmerl;Javier Cámara	2018		10.1145/3241403.3241423	systems engineering;architecture;software system;reuse;software;microservices;generality;computer science;reusability	SE	-60.096020945444714	21.866155134230958	172384
ae038d7a488f826ca3b39bac54c5fc21815bfd8e	the heat/act preliminary safety case: a case study in the use of goal structuring notation	argument structure;process management;safety critical system;flight control	The HEAT/ACT project consists of replacing the conventional mechanical flight control system of a helicopter with a fly-by-wire system. With such a project, the safety concerns are obvious, and therefore the development of a thorough and convincing Safety Case is paramount. The project therefore chose to adopt a phased approach to safety case development, beginning with a Preliminary Safety Case (PSC). Goal Structuring Notation (GSN) was chosen as the development method for the PSC, because of its perceived merits of ease of construction and clarity of review. This work was first reported in a presentation at the UK Safety Critical Systems Symposium (SSS’04), which described the initial development of the PSC argument structure, and investigated some of the practical issues identified in using GSN. This paper revisits the HEAT/ACT project. It reprises the original construction of the GSN argument, and goes on to show how the PSC has developed and evolved since that initial development phase. It examines how the GSN argument has been used in the interaction with other partners and sub-system suppliers involved in the HEAT/ACT project, and considers whether the effort expended in developing the PSC has lived up to expectations in its contribution to safety process management. 1 Background to the HEAT/ACT project The HEAT/ACT project consists of replacing the conventional mechanical flight control system on a medium-lift helicopter with a fly-by-wire system (Juggins et. al. 2004, Staple and Handcock 2002). It involves Copyright © 2004, Australian Computer Society, Inc. This paper appeared at the 9th Australian Workshop on Safety Related Programmable Systems (SCS'04), Brisbane. Conferences in Research and Practice in Information Technology, Vol. 38. Tony Cant, Ed. Reproduction for academic, not-for profit purposes permitted provided this text is included. extensive re-engineering of the aircraft systems, including: • removal of two out of three hydraulic systems • replacement of the main and tail rotor hydraulic actuators with electromechanical actuators • removal of mechanical flying controls. The major new items include: • adding another electrical generator • installing actuator control units • adding two new fly-by-wire (FBW) flight control computers. 2 Safety case approach With such a project, the safety concerns are obvious, and therefore a convincing and thorough Safety Case is paramount. UK Defence Standard 00-56 (UK Ministry of Defence 1996b), which defines the safety management requirements for defence projects “encourages the concept of an evolving Safety Case” in order to “[initiate the Safety Case] at the earliest possible stage...so that hazards are identified and dealt with while the opportunities for their exclusion exist.” The HEAT/ACT project recognised the benefit of constructing the safety argument as early as possible, for this precise reason. Any change to the architecture, for safety reasons or otherwise, becomes dramatically more difficult and expensive once designs are frozen and components are in manufacture. The project therefore chose to adopt a phased approach to safety case development, beginning with a Preliminary Safety Case (PSC). Through a process of review with airworthiness authorities, the PSC would provide initial confidence that the design of the HEAT/ACT system was such that acceptable safety could be demonstrated. It is of course of no benefit to show that the new system is acceptably safe without also considering the effects it has on the platform into which it is integrated, so the scope of the Safety Case was to include an assessment of the impact of the modification on the safety of the whole aircraft. System X is acceptably safe to deploy in the specified operational environment Quantified Fault Tree Analysis for hazard Y Argument by showing risk from all hazards has been reduced As Low As Reasonably Practicable Applicable standards: DEF-STAN 00-55 and DEF-STAN 00-56 Goal Solution Strategy Context Figure 1 – Notation for principal GSN elements, with text showing example instances of each Further safety case phases will follow to support major project milestones, such as hardware production and commissioning, and commencement of test flying (initially on a single aircraft). Each phase will use the preceding phase as a basis, refining and adapting the argument structure as the design evolves, and adding more complete evidence to support the argument. It was therefore vital that the safety argument presented in the PSC should be developed and presented in a way that would facilitate its future evolution. It must also support the engineering process by providing a structure in which to document safety activities and processes. Goal Structuring Notation (GSN) (Kelly 1999) was chosen as the method for representing this argument, on its perceived merits of ease of construction and clarity of review. GSN explicitly represents the individual elements of any safety argument (requirements, claims, evidence and context) and (perhaps more significantly) the relationships that exist between these elements (i.e. how individual requirements are supported by specific claims, how claims are supported by evidence and the assumed context that is defined for the argument). The principal symbols of the notation are shown in figure 1. When these elements are linked together in a network they are described as a ‘goal structure’. The principal purpose of any goal structure is to show how goals (claims about the system) are successively broken down into sub-goals until a point is reached where the claims can be supported by direct reference to available evidence (solutions). The notation is also used to make clear the argument strategies adopted (e.g. selecting a quantitative or qualitative approach), the rationale for the approach, and the context in which goals are stated (e.g. the system scope or the assumed operational role). Many different views exist on how (or even whether) GSN diagrams should be shown within delivered safety case documents. The approach chosen for HEAT/ACT was to present a small section of the argument in GSN on each page, followed by textual discussion. The text explains the intent of the argument fragment, with justification where necessary, and describes how it is intended that the fragment will be developed (including an outline of evidence requirements) in the subsequent phases of Safety Case development. As an aid to readers who are not familiar with the use of GSN, the PSC starts with an introduction to GSN notation, along with the more conventional description of the HEAT/ACT system. 3 Initiation and development of the Preliminary Safety Case When work on the PSC began, preliminary safety planning and preliminary hazard identification and risk assessment activities had been completed for the project, but detailed specification, design and analysis had not been commenced. The timing of PSC initiation was therefore ideal, meeting both guidance (e.g. Kelly 2003) and the project requirements. In the programme of a typical project, this would have allowed many months in which to draft, develop and finalise the PSC. However, the HEAT/ACT project has very challenging timescales, giving no more than two months for construction and initial issue of the PSC. The definition of the top goals of the GSN structure was relatively easy, building directly on commonly-described high-level arguments. However, developing the lowerlevel argument structures required to support these top goals initially proved problematic. Obstacles included concerns over how to manage the integration of existing safety evidence (e.g. for existing components being reused in the HEAT/ACT system), as well as simple lack of inspiration in identifying suitable strategies for developing the argument. These obstacles were largely overcome by a combination of the use of patterns (Kelly and McDermid 1997) – generic argument structures which must be instantiated for a specific system – and, even more effectively, by “borrowing and modifying” from a range of existing safety cases. The Pre-Implementation Safety Case for reduced vertical separation minima in European airspace (Eurocontrol 2001) was particularly useful for this activity. Ideas were also borrowed from an MSc thesis (Graham 2002), which developed a generic safety argument for modifications to existing aircraft; this provided some useful suggestions for how to tackle the arguments about integration of HEAT/ACT into the development helicopter. Examining how the authors of these and other safety arguments had solved the problems of instantiating patterns provided the inspiration to assist development of the argument, and also suggested “micropatterns” – often a very small number of GSN elements, or even just well-chosen wording of a goal or strategy – which could be adopted and adapted. The authors also found that reading and review of other safety cases were significant in building confidence in our own ability to recognise – and subsequently produce – well-structured and robust arguments.	computer;control system;design rationale;diagram;fault tree analysis;finalize (optical discs);fly-by-wire;generic programming;graham scan;hippi;hazard analysis;high- and low-level;instance (computer science);kelly criterion;maxima and minima;misuse case;multi-function printer;r.o.t.o.r.;requirement;risk assessment;system x (computing)	Paul Chinneck;David John Pumfrey;John McDermid	2004			simulation;systems engineering;engineering;operations management	SE	-58.198305099218636	25.122784598682248	172752
2ad8fb6a06d33692d944dc1c9d6ed6626d604b39	prototyping-oriented software development - concepts and tools	new prototyping-oriented software life-cycle;software development methodology;software development;prototyping-oriented development;various tool;software product;software development process;prototyping-oriented software development;classical software lifecycle model;integrated software development environment;various software development paradigm	It is often assumed—and current reports from research and industry confirm this assumption—that a prototyping-oriented development methodology can ameliorate some of the weaknesses of the life cycleoriented development approach. Specialists have not arrived at a consensus on what methods and tools are necessary for supporting prototyping-oriented software development. Based on the results of a several year long research project, this paper explains the authors’ concept of prototyping in the area of software development and what tools are necessary to support it.	iterative and incremental development;prolog;prototype;relational database management system;software development;software prototyping;software system	Gustav Pomberger;Walter R. Bischofberger;Dieter Kolb;Wolfgang Pree;Holger Schlemm	1991	Structured Programming			SE	-59.84002546841295	24.33306181312525	174702
1b0edeabce5e0f261edd1e52418dae1d0c67825a	fitting software to the organization: reducing time to value for new software systems		Most large and medium-sized organizations have shifted the focus of some or all of their organizational software development from tailored software, developed in object-oriented programming languages, to the use of configurable off-the-shelf packages or ERP systems. These systems offer a range of built-in functionality that can be adapted to specific requirements and offer opportunities for rapid system deployment and faster 'time-to-value', where the 'time-to-value' is the time after deployment when the system is fully operational and delivering value to the company.	built-in self-test;curve fitting;erp;enterprise resource planning;programming language;requirement;software deployment;software development;software system;system deployment	Ian Sommerville	2008	19th Australian Conference on Software Engineering (aswec 2008)	10.1109/ASWEC.2008.84	personal software process;verification and validation;team software process;software quality management;software engineering process group;software sizing;systems engineering;engineering;package development process;social software engineering;software development;software design description;software engineering;ultra-large-scale systems;software construction;systems development life cycle;software walkthrough;software analytics;software deployment;software quality control;goal-driven software development process;software requirements;software system;computer engineering	SE	-62.763115893676755	22.8711136329061	175137
52c6cd15e863cb6ee9ee75d5a9ba57dcfaa36f49	facilitating business improvement by information systems using model transformation and metrics		We propose a method to explore how to improve business by introducing information systems. We use a meta-modeling technique to specify the business itself and its metrics. The metrics are defined based on the structural information of the business model, so that they can help us to identify whether the business is good or not with respect to several different aspects. We also use a model transformation technique to specify an idea of the business improvement. The metrics help us to predict whether the improvement idea makes the business better or not. We use strategic dependency (SD) models in i* to specify the business, and attributed graph grammar (AGG) for the model transformation.	anti-grain geometry;attributed graph grammar;business process;graph rewriting;information system;metamodeling;model transformation;process architecture;tomotaka takahashi	Haruhiko Kaiya;Shunsuke Morita;Kenji Kaijiri;Shinpei Hayashi;Motoshi Saeki	2012			process management;information system;business model;business;model transformation;graph	NLP	-56.680924829533964	18.498730340696234	175151
27946c6499aa64be0b0f57504b9297a2a590cb27	an infrastructure for engineering cooperative agents	bottom up design infrastructure;virtual supply chain;multi agent systems;agent cooperation knowledge	Currently, systems of cooperative agents (multi-agent systems), possessing the capabilities of autonomy, adaptation, and cooperation, are being used in an increasingly wide variety of application areas, and the conversation-based multi-agent system design is the major design for those multi-agent systems. Supposedly, conversation-based multi-agent systems should have been prevailing enough for tackling dynamic aspects of problems in a variety of domains. However, for industries, multi-agent systems are still found to be in the birth stage where they only show their new values in anticipation for further explorations and improvements in order to attract critical mass of users of information executives or software developers. Nevertheless, what are the success factors that can result in a critical mass of multi-agent system designers? This paper shows one possible success factor — an infrastructure for the bottom-up design of multi-agent systems. The bottom-up design makes it possible for agents to be reassembled into multi-agent systems and reused as needed. However, what do we need to successfully support the bottom-up design? This paper is the first attempt to present a tool that fully supports the bottom-up design of multi-agent systems. The tool has three parts. The first part is a wrapper that wraps each agent so that it exempts the designers from the careful detailed deployment of the inter-relationships between cooperation knowledge and task knowledge inside the agent. This wrapper should be independent of the functions of agents. The second part is an environment that can support the wrapper to automate the cooperation process on behalf of agents. The third part is a graphical assembly panel for developers to visually configure wrapped agents residing at different places of the Internet into a working multi-agent system.		Soe-Tsyr Yuan;Zeng-Lung Wu	2000	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194000000377	simulation;computer science;systems engineering;engineering;artificial intelligence;software engineering;multi-agent system;management	SE	-58.9217788759777	20.26294975688668	175530
de6666fbcd4a407211d38c5ce088ab7b816b5f38	sm2pia: a model to support the development of pragmatic interoperability requirements	pragmatics;collaboration;pragmatic interoperability;business;web services;interoperability;context;interoperability model	Companies have increasingly distributed their teams to increase productivity and quality, and to reduce their costs in software development processes. This scenario has brought new challenges to effective collaboration and to enhance communication across peers. Pragmatic interoperability has been considered as one of the key requirements to tackle these challenges. However, there is lack of research investigating how to support development of pragmatic interoperability across globally dispersed groups. This paper proposes a model to support pragmatic interoperability in software projects to foster collaboration in distributed environments. The proposed model was implemented and evaluated in a collaborative architecture which supports collaborative scientific experiments development.	experiment;interoperability;requirement;software development process;web application	Frâncila Weidt Neiva;José Maria N. David;Regina M. M. Braga;Marcos R. S. Borges;Fernanda Campos	2016	2016 IEEE 11th International Conference on Global Software Engineering (ICGSE)	10.1109/ICGSE.2016.15	web service;semantic interoperability;interoperability;economics;computer science;systems engineering;knowledge management;data mining;ws-i basic profile;management;cross-domain interoperability;pragmatics;collaboration	SE	-59.51008126875502	20.830911475397805	175931
98a0614074ee081aedd2b19f1234aa4e3df475a7	processing requirements by software configuration management	automation software prototyping natural languages formal specifications data mining tree graphs;hierarchical structure;change management;version control requirements processing software configuration management requirements engineering process system design configuration management change management requirements specification;life cycle;software prototyping;formal specifications;natural languages;development process;data mining;software configuration management;tree graphs;requirements specification;systems analysis;system design;requirements engineering process;requirement engineering;requirements processing;change process;time to market;configuration management systems analysis;version control;requirement specification;configuration management;automation	Short development life cycles, the importance of timeto-market and fast changes in technology influence the requirements engineering process. Requirements are exposed to changes during the entire development life cycle, and decisions related to requirements and system design are moving toward developers. For this reason it is important to keep requirement changes under control during the entire development process. This control can be achieved by utilizing Configuration Management (CM) functions and in particular Change Management. This paper describes a model for managing requirements using CM functions. A requirements specification is defined as an hierarchic structure, in which elements of the structure are isolated requirements designated Requirements Specification Items. Having items under version control it is possible to get a better overview of the requirements change process. In the implementation phase, requirement items are associated with Change Requests which define implementations to be introduced in the system. When using Change Requests as links between requirements and the implemented functions we achieve a greater awareness of requirements and a better overview over the requirement process. Furthermore it provides a foundation for reuse of requirements when new systems are built.	requests;requirement;requirements engineering;software configuration management;software development process;software requirements specification;systems design;version control	Ivica Crnkovic;Peter Funk;Magnus Larsson	1999		10.1109/EURMIC.1999.794789	reliability engineering;requirements analysis;software requirements specification;requirements management;requirement prioritization;system requirements;business requirements;computer science;systems engineering;requirement;software engineering;needs analysis;system requirements specification;requirements elicitation;functional specification;non-functional testing;functional requirement;non-functional requirement;requirements traceability;vision document	SE	-57.1926420716447	24.007211059561588	176422
6dc341220ce90baea5801537e0287525afdd7879	cost benefits of ontologies	cost benefit	Given the state-of-the-art in ontological engineering, we still lack costing models for software projects that adopt reusable ontological libraries. However, we can find such costing models in the standard software engineering literature. The COCOMO-II software cost estimation model offers an estimate of the cost of adapting reusable sub-routines for a new project [Abts, Clark, Devnani-Chulani, Horowitz, Madachy, Reifer, Selby & Steece 1998, p21]. A learning curve must be traversed before a module can be adapted. By the time you know enough to change a little of that module, 0 0.2 0.4 0.6 0.8 1	cocomo;cost estimation in software engineering;library (computing);ontology (information science);ontology engineering;software development effort estimation	Tim Menzies	1999	Intelligence	10.1145/318964.318969	social psychology;ontology (information science);systems engineering;software;psychology;activity-based costing;ontology;cost estimate	SE	-60.02255987988549	22.389565298666696	176923
c019103188e7eac40b12543537fa1c583a3a0be3	reference architectures for self-managed software systems: a systematic literature review	software architecture;systematic literature review;systematic literature review self managed software systems reference architecture;reference architecture;self managed software systems;computer architecture databases software systems software architecture computational modeling;ra4smss reference architectures self managed software systems systematic literature review software systems design expertise ras for smss	Self-Managed Software Systems (SMSS) have emerged as an important type of software systems. However, the development of such systems is not a trivial task, as they constantly deal with adaptations at runtime so as to fulfill new needs of both users and execution environment. From another perspective, Reference Architectures (RAs) have been used for the aggregation of knowledge on specific domains, promoting the reuse of design expertise and facilitating the development, standardization, and evolution of software systems. Considering the relevance of such architectures, RAs for SMSS (RA4SMSS) have also been proposed. On the other hand, to the best of our knowledge, no study on a panorama or comparison on RA4SMSS has been published. This paper reports the results of a systematic literature review on RA4SMSS. They show that although relevant initiatives have been found, the SMSS area needs a broader contribution to boost the development of such systems. Moreover, research lines that must further investigated were also identified.	reference architecture;relevance;run time (program lifecycle phase);software system;systematic review	Frank José Affonso;Katia Romero Felizardo Scannavino;Lucas B. R. Oliveira;Elisa Yumi Nakagawa	2014	2014 Eighth Brazilian Symposium on Software Components, Architectures and Reuse	10.1109/SBCARS.2014.18	reference architecture;verification and validation;database-centric architecture;computer science;systems engineering;knowledge management;package development process;software design;social software engineering;component-based software engineering;software development;software design description;software engineering;software construction;software architecture description;software technical review;systems development life cycle;software walkthrough;software analytics;resource-oriented architecture;software deployment;software system;systems design;software peer review	SE	-60.048783571368226	21.510412557790595	176985
d13bb34f75856a90d7eb559c6e1a552f863e0852	application of an mbse approach for the integration of multidisciplinary design processes		In the current practices of system developments, there is a large gap between systems engineering activities and engineering analyses. In particular, there exists no practical link between architecture-level models, developed using languages such as SysML, and disciplinary models described in specialized tools. In order to close the gap, a capability was developed that integrates SysML models with analysis models. This work discusses application of the capability to the design of an aircraft propulsion system. System requirements and architecture were defined in a SysML model and analysis models were imported to the SysML model to set up parametric diagrams. Engineering analyses were performed from the SysML model to check requirements compliance of the system. When introduced to industry design processes, the technology can streamline requests for engineering analyses from system architecture models.		Nicolas Albarello;Hongman Kim	2013		10.1007/978-3-319-02812-5_7	architecture;multidisciplinary approach;systems architecture;engineering;systems modeling language;system requirements;systems engineering	Logic	-55.80407102157945	22.923162451665178	177047
228264e569286944d865eda1aa30e3cc5dd9c9c6	a linguistic-engineering approach to large-scale requirements management	engineering;developpement logiciel;customer communication software companies software product software quality linguistic engineering approach large scale requirements engineering management natural language;gestion exigence;linguistique;requirement duplicates;exigence;formal specification;customer relationship management;requirements management;dp industry;knowledge management;requirements similarity;large scale systems maintenance engineering computer architecture software maintenance software quality decision making information analysis couplings software architecture financial management;natural languages;requirement;software engineering;requirements engineering;ingenierie;large scale;software architecture;linguistica;redundancy;redundancy requirements engineering large scale requirements management natural language processing linguistic engineering requirement relationships requirements similarity requirement duplicates;linguistic engineering;desarrollo logicial;software development;exigencia;genie logiciel;datavetenskap datalogi;ingenieria;computational linguistics;software quality knowledge management customer relationship management computational linguistics dp industry natural languages formal specification;requirement relationships;ingenieria informatica;natural language processing;software quality;ingenierie linguistique;large scale requirements management;architecture logiciel;linguistics	For large software companies, the sheer number of textual requirements presents specific challenges. To find market opportunities, organizations must continuously elicit new requirements and reevaluate old ones as market needs evolve. Developing large, complex software products aimed at broad markets involves identifying and maintaining the link between product requirements and the massive inflow of customers' wishes. Automating this support through linguistic engineering could save considerable time and improve software quality.	requirement;requirements management;software industry;software quality	Johan Natt och Dag;Vincenzo Gervasi;Sjaak Brinkkemper;Björn Regnell	2005	IEEE Software	10.1109/MS.2005.1	software architecture;requirements analysis;requirements management;requirement prioritization;business requirements;computer science;systems engineering;engineering;software development;computational linguistics;requirement;software engineering;formal specification;database;requirements engineering;redundancy;natural language;programming language;software quality	SE	-59.07476068311976	23.51066339476647	177681
99aa4997df959fac9df5d8b957c16d05817632a7	introduction to the special issue on state of the art in engineering self-adaptive systems	computer and information science;computer and information sciences computer science;data och informationsvetenskap	Researchers and engineers have been studying self-adaptation for over a decade, which has resulted in a vast body of knowledge. Nevertheless, as technology progresses and software systems are increasingly integrated, new challenges emerge. Among these challenges are the need for new theoretical models for self-adaptation, methods to verify and validate self-adaptive systems, and disciplined engineering approaches to support decentralization of control in self-adaptive systems. Tackling these challenges requires a cross-disciplinary approach. The goal of this special issue is to provide an overview of the state of the art in the field of self-adaptive software systems. From 61 submission, 13 papers were selected for publication. These papers demonstrate that the integration of different research fields that is required to tackle the challenges in engineering self-adaptation is underway. We offer the papers of this special issue as a benchmark on the current state of the art, and an exposition of key ideas and directions for further work.	adaptive system	Danny Weyns;Sam Malek;Jesper Andersson;Bradley R. Schmerl	2012	Journal of Systems and Software	10.1016/j.jss.2012.07.045	computer science;engineering;management science;operations research;information and computer science	SE	-61.869308091161585	19.980328477376762	177872
5dacd86b7d9eabe1ab2dfcca2bc6a24d0bc4f81e	a cost-object model for activity based costing simulation of business processes	analytical models;cpnet activity based costing simulation market dynamism processe re design process re engineering cost refinement steps tuning processes regular business activities process performance simulation business process simulator cost object resource model abc analysis business process model and notation bpmn colored petri nets;bpmn;colored petri nets business process simulation activity based costing bpmn;context modeling business petri nets context analytical models unified modeling language logic gates;colored petri nets;activity based costing;business process simulation;logic gates;business;unified modeling language;petri nets business data processing costing;petri nets;context modeling;context	The achievement of business goals is heavily affected by the capability of enterprises to design, enforce and govern business processes. The dynamism of the market requires business goals to be constantly tuned, thus obliging the enterprise to continuously re-design processes. The cost for process re-engineering may be not negligible, if we consider that it may require several refinement steps and that tuning processes on-the-job may impair regular business activities. To this end, there is a growing interest towards tools that simulate the processes' performance before they get actually enforced. In this paper we propose a novel business process simulator which makes use of a cost-object resource model to allow for Activity Based Costing (ABC) analysis of the simulation results. The simulator works with business processes modelled in the Business Process Model and Notation (BPMN) and exploits the rigor of the Colored Petri Nets' (CPNets) formalism. A case study test has been conducted on a prototype implementation and related results are presented.	business process model and notation;formal system;petri net;process modeling;prototype;refinement (computing);simulation	Vincenzo Cartelli;Giuseppe Di Modica;Daniele Manni;Orazio Tomarchio	2014	2014 European Modelling Symposium	10.1109/EMS.2014.41	business domain;computer science;systems engineering;knowledge management;artifact-centric business process model;business process management;function model;operations management;process modeling;business process model and notation;process architecture;business process;process mining;business process discovery;business rule;business process modeling;petri net;business architecture	Logic	-55.57272545856815	18.740254193430772	178482
44d060e6a729f79cdcf96ee026f1a5752395bc26	validating documentation with domain ontologies	text mining;software maintenance;software engineering;domain knowledge;requirement engineering;domain ontology	Do we always use the same name for the same concept? Usually not. While misunderstandings are always troublesome, they pose particularly critical problems in software projects. Requirements engineering deals intensively with reducing the number and scope of misunderstandings between software engineers and customers. Software maintenance is another important task where proper understanding of the application domain is vital. In both cases it is necessary to gain (or regain) domain knowledge from existing documents that are usually inconsistent and imprecise. This paper proposes to reduce the risk of misunderstandings by unifying the terminology of the different stakeholders with the help of an ontology. The ontology is constructed by extracting terms and relations from existing documents. Applying text mining for ontology extraction has an unbeatable advantage compared to manual ontology extraction: Text mining detects terminology inconsistencies before they are absorbed in the ontology. In addition to this, the approach presented in this paper also introduces an explicit validation of ontology gained by text mining. 1. Documents are Always Inconsistent Usually, some kind of requirements document is written in the beginning of a software project. After requirements elicitation, one of the first tasks of the software developer is to understand the requirements document which includes trying to understand the terminology used. But practical experiences show that apart from being imprecise, requirements documents also use inconsistent terminology. A simple steam boiler specification [1], written for a formal methods contest, for example, looked extremely precise at first glance. However, the document called the same measuring unit in different places “water level measurement device”, “water level measuring unit”, “device to measure the quantity of water”, . . . . Obviously, this unwanted obfuscation hampers understanding of the domain. The reader can not be sure whether there is just one unit or two or three different devices. And of course, real life specifications, not written for an academic formal methods contest, are very likely even less consistent. Furthermore, real life documents are usually much longer rendering manual detection and resolution of such inconsistencies virtually impossible. 1Correspondence to: Leonid Kof, Fakultaet fuer Informatik, Technische Universitaet Muenchen, Boltzmannstr. 3, D-85748, Garching bei Muenchen, Germany Tel.: +49 89 289-17834; Fax: +49 89 289-17307; E-mail: kof@in.tum.de.	application domain;code refactoring;documentation;fax;formal methods;image resolution;in the beginning... was the command line;iterative method;ontology (information science);ontology learning;real life;requirement;requirements elicitation;requirements engineering;software developer;software development;software engineer;software maintenance;software project management;terminology extraction;text mining;web ontology language	Leonid Kof;Markus Pizka	2005			domain analysis;upper ontology;idef5;text mining;bibliographic ontology;software mining;computer science;knowledge management;ontology;software engineering;domain engineering;data mining;database;requirements engineering;ontology-based data integration;software maintenance;process ontology;domain knowledge;suggested upper merged ontology	SE	-56.801588203111194	23.178628892092494	179082
4ea6d09d69309e2dabe4e62294009bbc2445f812	a support system to cots-based software development for business services	knowledge based system;software maintenance and evolution;software systems;support system;software development;crosscutting concerns;modularisation;software design;logic metaprogramming;validation and verification	The work described in this paper deals with the problem of selecting, configuring, integrating and deploying COTS components to deliver tailored software systems. Since formal and precise description of components is not usually available, a reasonable approach is to augment the available documentation with the informal knowledge derived by practices and experience of experts. The development of a knowledge-based system is a way to organize this empirical knowledge and deliver a tool that can support software designers in the tough goal of COTS-based development.	documentation;knowledge-based systems;software development;software system	Stefania Bandini;Flavio De Paoli;Sara Manzoni;Paolo Mereghetti	2002		10.1145/568760.568815	reliability engineering;personal software process;long-term support;verification and validation;verification and validation;software verification;systems engineering;engineering;package development process;backporting;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;knowledge-based systems;software construction;software walkthrough;software analytics;resource-oriented architecture;software deployment;software development process;software system;software peer review	SE	-59.802418226632135	24.722008689107813	179134
475b167686ec4d2ba1d22d963d9c70a7a3ecadfe	software as a service: configuration and customization perspectives	analytical models;software;complexity theory;web based delivery model;biological system modeling;customization;software service;customization software as a service configuration;application software sun economies of scale software tools web and internet services computer architecture service oriented architecture subscriptions costs computer industry;web services economies of scale;multi tenancy based infrastructure;lead;configuration perspective;business;web services;application sharing;economy of scale configuration perspective customization perspective software service web based delivery model multi tenancy based infrastructure application sharing architecture;software as a service;source code;customization perspective;organizations;economies of scale;economy of scale;configuration;application sharing architecture	Software as a service (SaaS) provides software application vendors a Web based delivery model to serve big amount of clients with multi-tenancy based infrastructure and application sharing architecture so as to get great benefit from the economy of scale. Though SaaS application is usually developed with highly standardized software functionalities to serve as many clients as possible, many clients still ask for function variants according to their unique business needs through easy configuration and customization. Due to the subscription based model, SaaS vendors need take a well designed strategy to enable self serve configuration and customization by their customers without changing the SaaS application source code for any individual customer. In this paper, we will explore the configuration and customization issues and challenges to SaaS vendors, clarify the difference between configuration and customization. A competency model and a methodology framework have been developed to help SaaS vendors to plan and evaluate their capabilities and strategies for service configuration and customization.	application domain;business requirements;multitenancy;programming model;requirement;software as a service	Wei Sun;Xin Zhang;Changjie Guo;Pei Sun;Hui Su	2008	2008 IEEE Congress on Services Part II (services-2 2008)	10.1109/SERVICES-2.2008.29	mass customization;systems engineering;knowledge management;marketing;software as a service;business	Embedded	-62.3788885243178	22.473004121645975	179612
934f786720e0f52686c6d9a35c700bf7c04311a6	designing an architecture of sns platform by applying a product line engineering approach	software;architectural design;quality attributes;social networking service;instant messaging;client server architecture;social networking services;computer architecture software facebook business privacy data privacy;p2p;p2p approach sns platform architecture design social networking service software product line approach requirements engineering architecture definition facebook architecture architecture tradeoff analysis method atam spl practice product line uml based software engineering orthogonal variability model ovm file sharing instant messaging peer to peer approach;product line;software engineering;software product line architecture design architecture evaluation social networking service;computer architecture;software architecture;data privacy;software architecture social networking online;requirement engineering;business;architecture evaluation;social networking online;facebook;product line engineering;architecture design;file sharing;software product line;peer to peer;architecture tradeoff analysis method;privacy	The demand of new Social Networking Service (SNS) is high because the SNSs have been popular these days. In order to deliver various SNSs as early as possible, software product line (SPL) approach can be useful. By using the state of the practices of SPL, this paper shows how to manage commonalities and variabilities of SNS. Specifically, to make an architecture design, presented practices include: understanding relevant domains, requirements engineering, architecture definition. The strengths and weaknesses of Face book architecture are evaluated with the Architecture Tradeoff Analysis Method (ATAM). As a result of applying a framework for SPL practice, layered view and component-based view are illustrated along with variabilities represented by Product Line UML-based Software Engineering (PLUS) and Orthogonal Variability Model (OVM). Based on the analysis of requirements of SNS, additional services such as file sharing and instant messaging are represented as optional components. In case of Face book, three key quality attributes, i.e., availability, scalability, and privacy are analyzed by using quality attribute utility tree. We identified that Face book employs client-server architecture. Through ATAM, Peer-to-Peer (P2P) approach promoting privacy is explained.	architecture tradeoff analysis method;client–server model;component-based software engineering;file sharing;heart rate variability;instant messaging;list of system quality attributes;open verification methodology;peer-to-peer;requirement;requirements engineering;scalability;server (computing);software product line;unified modeling language	Duksan Ryu;Dan Lee;Jongmoon Baik	2012	2012 IEEE/ACIS 11th International Conference on Computer and Information Science	10.1109/ICIS.2012.43	computer science;software engineering;world wide web;computer engineering	SE	-57.77626013102202	25.231724637654462	179699
b4f6292bd3d51c291d1c044df0f54d08ef7fa7cc	the distributed co-simulation protocol for the integration of real-time systems and simulation environments		Virtual system development gets more and more important in many industrial domains. It is considered to reduce development times, lower computing costs, and shorten time-to-market. Co-simulation is a particularly promising approach for modular and interoperable development. In practice the integration and coupling of heterogeneous systems still require enormous efforts. The configuration and operation of distributed hardware-in-the-loop systems and simulations contribute to efficiency of testing. Currently no standardized interface or protocol specification is available, which allows the interaction of real-time and non-real-time systems of different vendors. This paper for the first time presents the Distributed Co-simulation Protocol (DCP) which is subject to proposal as a standard for real-time and non-real-time system integration and simulation. The DCP consists of a data model, a finite state machine, and a communication protocol including a set of protocol data units. It is designed as a tool independent standard. It was developed in context of the ACOSAR project and is subject to standardization as a Modelica Association Project (MAP). It enables the definition, configuration and execution of a wide range of different simulations and test scenarios. It supports a master-slave architecture for simulation setup and control. The specification defines the design of a slave only, the design of a master is not in scope of the specification. To highlight the industrial applicability of the DCP, three examples from the automotive domain are shown.	co-simulation;real-time clock;real-time computing;simulation	Martin Krammer;Martin Benedikt;Torsten Blochwitz;Khaled Alekeish;Nicolas Amringer;Christian Kater;Stefan Materne;Roberto Ruvalcaba;Klaus Schuch;Josef Zehetner;Micha Damm-Norwig;Viktor Schreiber;Natarajan Nagarajan;Isidro Corral;Tommy Sparber;Serge Klein;Jakob Andert	2018			system integration;architecture;communications protocol;real-time computing;standardization;finite-state machine;modelica;modular design;computer science;protocol data unit	Embedded	-56.10380907985211	22.001256148616964	179849
bd062e131c14623460f69b47cac854f2bf4660d4	supporting requirements change management in goal oriented analysis	control systems;goal orientation;history;change management;conference management;software development process;technology management;version control system;control systems conference management quality management software development management technology management engineering management information analysis history programming software quality;impact analysis;goal oriented analysis;engineering management;impact analysis goal oriented analysis version control;version control;programming;information analysis;software quality;software development management;quality management	Requirements changes frequently occur at any time of a software development process and their management is a crucial issue to develop software of high quality. Meanwhile, recently goal-oriented analysis techniques are being put into practice to elicit requirements. In this situation, the change management of goal graphs and its support is necessary. This paper presents two topics related to change management of goal graphs; 1) version control of goal graphs and 2) impact analysis on a goal graph when its modifications occur. In our version control system, we extract the differences between successive versions of a goal graph by means of monitoring modification operations performed through a goal graph editor, and store them in a repository. Our impact analysis detects conflicts that arise when a new goal is added, and investigates the achievability of the other goals when the existing goal is deleted.	change management (engineering);control system;diff utility;display resolution;requirement;sensor;series and parallel circuits;software development process;ternary numeral system;usability;version control	Daisuke Tanabe;Kohei Uno;Kinji Akemine;Takashi Yoshikawa;Haruhiko Kaiya;Motoshi Saeki	2008	2008 16th IEEE International Requirements Engineering Conference	10.1109/RE.2008.18	soft goal;quality management;economics;goal modeling;computer science;revision control;systems engineering;knowledge management;technology management;software engineering;change management;management science;management	SE	-57.70261762862119	23.86235790380401	180447
a847addaf1bc3942cafb12e7ef59358909802a07	using norm analysis patterns for automated requirements validation	formal specification;program verification;behavioral patterns norm analysis patterns automated requirements validation requirements engineering information system automated software validation;software information systems cognition libraries unified modeling language testing semantics;program verification formal specification;courteous logic requirements validation requirements engineering norms knowledge representation	Requirements validation is an integral activity of Requirements Engineering. An early detection of mismatch between the observable behavior of the real-world and the interpreted behavior of the information system after requirements analysis is essential to the success of the software developed. This paper presents how norm analysis patterns can be effectively utilized for automated software validation. Norms represent behavioral patterns in an organization. In this paper, we harness this fact to validate the elicited requirements.	behavioral pattern;information system;observable;requirement;requirements engineering;software verification and validation	Richa Sharma;Kanad K. Biswas	2012	2012 Second IEEE International Workshop on Requirements Patterns (RePa)	10.1109/RePa.2012.6359965	reliability engineering;requirements analysis;software requirements specification;verification and validation;requirements management;computerized system validation;software verification;computer science;systems engineering;software design;requirement;software engineering;needs analysis;system requirements specification;functional specification;non-functional testing;validation rule;non-functional requirement;software requirements;requirements traceability	SE	-58.09872243095277	23.767717720037727	180744
3d8264160c5aa73586f3b5fc82b9c9c7fc757731	modeling a complex global service delivery system	enterprise service provider;service level constraint;strict service level constraint;information technology;it service providers;complex service delivery system;quality of service;decision-making;complex global service delivery;service delivery;enterprise resource planning;experienced management team;skill level;dynamic customer workload;complex global service delivery system modeling;it service provider;diverse service personnel skill;large it services delivery;system design;service level;service provider	Enterprises and IT service providers are increasingly challenged with improving the quality of service while reducing the cost of service delivery. Effectively balancing dynamic customer workload, strict service level constraints, and diverse service personnel skills challenges the most experienced management teams. In this paper we describe a modeling framework for analyzing complex service delivery systems. The interaction among various key factors are included in the model to allow decision-making around staffing skill levels, scheduling, and service level constraints in system design. We demonstrate the applicability of the proposed approach in a large IT services delivery environment.	itil;quality of service;scheduling (computing);systems design	Yixin Diao;Aliza R. Heching;David M. Northcutt;George Stark	2011	Proceedings of the 2011 Winter Simulation Conference (WSC)		service provider;service level requirement;service level objective;quality of service;service level;service product management;application service provider;business service provider;differentiated service;computer science;systems engineering;knowledge management;service delivery framework;service design;service guarantee;service desk;data as a service;customer service assurance;information technology;service system;systems design	HPC	-59.79743677316306	18.865246464039483	182456
57da4afdd2c439356166210662cd28064786d498	software engineering for distributed autonomous real-time systems		We discuss key challenges of software engineering for distributed autonomous real-time systems and introduce a taxonomy for areas of interest with respect to the development of such systems.	autonomous robot;real-time computing;real-time transcription;software engineering	Lenz Belzner;Michael Till Beck;Thomas Gabor;Harald Roelle;Horst Sauer	2016		10.1109/SEsCPS.2016.017	verification and validation;computing;real-time computing;software engineering process group;information engineering;system of systems;system of systems engineering;software verification;search-based software engineering;computer science;systems engineering;social software engineering;component-based software engineering;software development;software construction;computer-aided engineering;requirements engineering;systems development life cycle;distributed design patterns;software requirements;software system;computer engineering;systems design	Embedded	-62.683444886671566	24.604097215069274	182542
65930ad111c802684f3edd4d068b1cf774f5cefb	process design for natural scientists		A major part of the scientific experiments that are carried out today requires thorough computational support. While database and algorithm providers face the problem of bundling resources to create and sustain powerful computation nodes, the users have to deal with combining sets of (remote) services into specific data analysis and transformation processes. Today’s attention to “big data” amplifies the issues of size, heterogeneity, and process-level diversity/integration. In the last decade, especially workflow-based approaches to deal with these processes have enjoyed great popularity. This book concerns a particularly agile and model-driven approach to manage scientific workflows that is based on the XMDD paradigm. In this chapter we explain the scope and purpose of the book, briefly describe the concepts and technologies of the XMDD paradigm, explain the principal differences to related approaches, and outline the structure of the book.	agile software development;algorithm;big data;computation;experiment;model-driven architecture;programming paradigm	Anna-Lena Lamprecht;Tiziana Margaria	2014		10.1007/978-3-662-45006-2	systems engineering;process design;computer science	AI	-59.94668672031836	20.076706077941143	182555
0f35459b671d332162e5ece1aff0f9c01c13cbb2	supporting distributed software development through context awareness on software artifacts: the disen-collaborar approach	collaborative software engineering;distributed software development;contextual information;artifacts;awareness	Source code and class diagram are artifacts produced or updated during software development. However, when the scenario in which teams are distributed is considered, the temporal and geographical distances among individuals affect communication, creating inconsistencies and ambiguities about the software artifacts. These problems can be minimized by sharing contextual information of actions that occur on cooperation objects. This paper presents the DiSEN-CollaborAR, an approach to deal with context awareness on software artifacts. It provides resources to communicate what individuals have done over the software artifacts. This is possible by capturing contextual information that is represented, stored, processed and displayed. So, awareness elements, artifact context and traceability among software artifacts contribute to increase the understanding of the software artifacts and also the collaboration among distributed teams.	class diagram;context awareness;distributed computing;geographical distance;software development;traceability	Rafael Leonardo Vivian;Elisa Hatsue Moriya Huzita;Gislaine Camila Lapasini Leal	2013		10.1145/2480362.2480509	awareness;software engineering process group;computer science;knowledge management;software design;software development;software design description;data mining;software walkthrough;software analytics;world wide web;goal-driven software development process	SE	-59.965856194464926	23.112974180844773	182651
d0949a446b79a98176162118d1798718280a7c6d	identifying top challenges for international research on requirements engineering for systems of systems engineering	systems engineering and theory communities collaboration security software systems industries complexity theory;systems of systems engineering;research agenda and roadmap systems of systems systems of systems engineering requirements engineering complexity panel discussion;formal specification;complexity theory;systems engineering;collaboration;software systems;industries;international re community large scale complex systems of systems sos systems of systems engineering sose public services requirements engineering conferences requirements engineering journals;complexity;systems engineering and theory;requirements engineering;systems of systems;formal verification;systems analysis;panel discussion;research agenda and roadmap;communities;security;systems engineering formal specification formal verification systems analysis	Due to an increasingly connected society and industry, our modern societal world and all industry sectors now increasingly depend on large-scale complex Systems of Systems (SoS). The emerging interdisciplinary area of SoS and Systems of Systems Engineering (SoSE) is largely driven by societal needs including public services such as health, transport, water, energy, food security, etc. The scale, complexities and challenges presented by SoS require us to go beyond traditional Requirements Engineering (RE) approaches. However, as is evident from publications in major Requirements Engineering conferences and journals, no significant effort has been expedited towards addressing specific RE issues for Systems of Systems Engineering. This panel explores key RE challenges in Systems of Systems Engineering, specifically, the areas in which the international RE community need to focus its research, and the approaches that are most likely to meet these challenges effectively. We first introduce Systems of Systems Engineering and outline key characteristics of SoS. We conclude by arguing that there is an urgent need for the global RE community to develop new ways of thinking, new capabilities and possibly a new science as a key mechanism for addressing requirements complexities posed by Systems of Systems.	apple sos;complex systems;requirement;requirements engineering;system of systems;systems engineering	Cornelius Ncube;Soo Ling Lim;Huseyin Dogan	2013	2013 21st IEEE International Requirements Engineering Conference (RE)	10.1109/RE.2013.6636746	biological systems engineering;systems analysis;complexity;health systems engineering;system of systems;system of systems engineering;formal verification;computer science;systems engineering;engineering;knowledge management;software engineering;formal specification;requirements engineering;management;software system;collaboration	SE	-62.396996247723976	20.79726988642209	182848
1fba25cd6d569291fbeaf5247a033738bac8ae1c	towards a comprehensive view of secure software engineering	software engineering laboratories computer security information security national security application software joining processes programming knowledge engineering bridges;software engineering security of data;software engineering;securing approaches secure software engineering security requirements;secure software engineering;security requirements;securing approaches;security of data	Secure software engineering is a big challenge. This is mainly due to the increasing complexity, openness and extensibility of modern applications, which make a complete analysis of security requirements very hard. The overall problem space is consequently no longer easily comprehensible for developers. This paper is an attempt to explore some of these issues underlying secure software engineering. We propose a secure software engineering framework, which suggests considering secure software engineering along four different, but complementary, views. Each view is capturing a particular relevant aspect of secure software engineering. Our motivations for developing this framework are to: (a) help understand and clarify the secure software engineering domain, (b) guide in classifying and comparing both secure software and securing approaches and (c) help researchers to identify new research axes.	emoticon;extensibility;openness;problem domain;requirement;software engineering	Mehrez Essafi;Lamia Labed Jilani;Henda Hajjami Ben Ghézala	2007	The International Conference on Emerging Security Information, Systems, and Technologies (SECUREWARE 2007)	10.1109/SECUREWARE.2007.4385331	domain analysis;software security assurance;personal software process;verification and validation;computing;software engineering process group;security engineering;software verification;computer science;social software engineering;component-based software engineering;software development;software engineering;software construction;software walkthrough;software deployment;computer security;software requirements;software system	SE	-58.2215899118746	22.286115646556	183030
ca088bec0c5c8302b889b915991689e9b901555f	a development process for mechatronic products: integrating software engineering and product engineering	rational unified process;mechanical engineering computing;unified process;development process;software engineering;software engineering mechanical engineering computing mechatronics product development production engineering computing;production engineering computing;mechanical engineering;product engineering;mechatronics software engineering unified modeling language product development time factors fault tolerance quality function deployment testing mechanical engineering electrical engineering;rational unified process mechatronic product development software engineering product engineering;mechatronics;mechatronic product development;product development;time constraint	Mechatronic products integrate electrical, software and mechanical engineering, allowing new possibilities in product development. This paper proposes a unified process to guide the development of mechatronic products which includes the rational unified process with some established methods and techniques from electrical and mechanical engineering. The approach focuses on the extensive exploration of multidisciplinary knowledge to develop an integrated solution. Time constraints and reliability issues are addressed. To illustrate the approach a simple case study is presented.	artifact (software development);cpu cache;capability maturity model integration;comparison of command shells;computation;data validation;dependability;diagram;documentation;electrical engineering;mechatronics;new product development;product engineering;prototype;rational unified process;reliability engineering;requirement;software engineering;unified modeling language	Ana Patrícia Fontes Magalhães;Aline Maria Santos Andrade;Leila Silva;Herman Lepikson	2007	2007 IEEE Conference on Emerging Technologies and Factory Automation (EFTA 2007)	10.1109/EFTA.2007.4416911	mechanical engineering technology;mechatronics;software engineering process group;information engineering;system of systems engineering;systems engineering;engineering;computer-automated design;methods engineering;unified process;social software engineering;requirement;requirements engineering;systems development life cycle;rational unified process;software development process;new product development;manufacturing engineering;product engineering;computer engineering;mechanical engineering	SE	-62.37722784006678	25.153859766842526	183671
db0ba8e2a6c1778d6444e3099e4022626a49df4b	on confusion between requirements and their representations	descriptive representation;model based representation;requirements representation oncology;requirement engineering;requirements representation ontology	Requirements representations are often confused with requirements. This confusion is not just widespread in practice, but it exists even in the latest requirements engineering research and theory, leading to a number of negative consequences. In this article, we discuss these negative consequences, and present a solution based on a strict distinction between requirements per se and requirements representations. We elaborate on this distinction and classify different forms of representations in a unified requirements representations ontology, including a refinement of descriptive and model-based requirements representations.	refinement (computing);requirement;requirements engineering;theory	Hermann Kaindl;Davor Svetinovic	2009	Requirements Engineering	10.1007/s00766-009-0095-7	economics;computer science;engineering;artificial intelligence;requirement;data mining;requirements engineering;management	SE	-56.641749634120465	22.33332553689689	183726
e9b59bb445f4e90b2cae62371f408aaa81762e6d	a comparison of two-level and multi-level modelling for cloud-based applications		The Cloud Modelling Framework (CloudMF) is an approach to apply model-driven engineering principles to the specification and execution of cloudbased applications. It comprises a domain-specific language to model the deployment topology of multi-cloud applications, along with a models@run-time environment to facilitate reasoning and adaptation of these applications at run-time. This paper reports on some challenges encountered during the design of CloudMF, related to the adoption of the two-level modelling approach and especially the type-instance pattern. Moreover, it proposes the adoption of an alternative, multi-level modelling approach to tackle these challenges, and provides a set of criteria to compare both approaches.		Alessandro Rossini;Juan de Lara;Esther Guerra;Nikolay Nikolov	2015		10.1007/978-3-319-21151-0_2	simulation;computer science;systems engineering;engineering;software engineering;data mining	SE	-58.91801693063442	21.102321108110157	183814
e8d6ca6c4215863a14ec6e562cce38b32f8e4b78	the methodology to integrate the information concerned about the safety between many kinds of materials about the space system		To assure that a system is safe, several tasks must be performed, resulting in the compilation of several safety-related documents. It is important that all the information related to safety is developed and maintained consistently. Because of retirements and changes to different department, it is difficult for engineers to pass on their knowledge. To ensure consistency throughout a project lifecycle notwithstanding program-level changes, a method to express the relationship between the safety information described in different documents is needed. Moreover, to address not only specifications but also bases for design formulated by a designer, design knowledge is accumulated together. We aim to improve the understanding of the safety design. In this study, we add two rules to the D-Case in order to achieve three goals. To verify the effectiveness of our method, these rules were applied to a rocket system.		Nasa Yoshioka;Nobuyuki Kobayashi;Seiko Shirasaka	2016		10.1007/978-3-319-29643-2_22	simulation;systems engineering;mathematics;management science	AI	-57.61121135313001	23.611956764159792	184209
3d19c3a96fac0585ed046435080cfe049314efc4	modelling requirements for self-integrating manufacturing systems	modelling requirements;self-integrating manufacturing systems	This paper discusses modeling requirements to support self-integrating manufacturing systems. Business process re-engineering, as it is currently performed, is driven by the same information as may drive the re-engineering process of future self-integrating systems. Unfortunately, today much of this information remains unexpressed. On-going research into enterprise representation may provide a foundation for self-integrating systems. However, the modeling solution must make apparent mismatch of goals, function, semantics and technology between the existing and future business processes and information infrastructure.	business process;requirement	Peter Denno	2000			integrated computer-aided manufacturing;process development execution system;computer-integrated manufacturing;manufacturing engineering;systems design	SE	-60.573729258470166	18.61923875692028	184504
51978952a89a16fa95770ccf97dae4f9fa186c1a	maintainability techniques in developing large expert systems	expert systems;expert systems telephony switches software prototyping laboratories production systems software engineering software maintenance artificial intelligence programming;telephone exchanges;software engineering;development tool;rapid prototyping;telecommunications computing;software problem areas large expert systems maintainable expert systems multiparadigm development tools complex expert system electronic telephone exchange maintainability traditional software engineering rapid prototyping approach expert system building compass project;telephone exchanges expert systems knowledge engineering software engineering telecommunications computing;expert system;knowledge engineering	The production of understandable and maintainable expert systems using the current generation of multiparadigm development tools is addressed. This issue is discussed in the context of COMPASS, a large and complex expert system that helps maintain an electronic telephone exchange. As part of the work on COMPASS, several techniques to aid maintainability were developed and successfully implemented. Some of the techniques were new, others were derived from traditional software engineering but modified to fit the rapid prototyping approach of expert system building. An overview of the COMPASS project is presented, software problem areas are identified, solutions adopted in the final system are described and how these solutions can be generalized is discussed.<<ETX>>	compass;expert system;programming tool;rapid prototyping;software engineering;telephone exchange	David S. Prerau;Alan Gunderson;Robert E. Reinke;Mark Adler	1990	IEEE Expert	10.1109/64.54675	telephone exchange;computer science;artificial intelligence;social software engineering;software development;systems development life cycle;subject-matter expert;expert system;software development process;software system	SE	-59.72649053126102	24.27477751945226	184592
7eac0627e5664200699c4b8dcb1fb0378dd38dad	a uml profile for privacy-aware data lifecycle models		Concerns over data-processing activities that may lead to privacy violations or harms have motivated the development of legal frameworks and standards to govern the processing of personal data. However, it is widely recognised that there is a disconnect between policy-makers’ intentions and software engineering reality. The Abstract Personal Data Lifecycle (APDL) model, which was proposed to serve as an abstract model for personal data life-cycles, distinguishes between the main operations that can be performed on personal data during its lifecycle by outlining the various distinct activities for each operation. We show how the APDL can be represented in terms of the Unified Modeling Language (UML). The profile is illustrated via a realistic case study.	profile (uml)	Majed Alshammari;Andrew C. Simpson	2017		10.1007/978-3-319-72817-9_13	systems engineering;applications of uml;uml tool;unified modeling language;computer science	NLP	-57.270505124037015	20.355112630800207	184913
de85e5400aee8c4cc78eaf6f941aa3167b98309e	change taxonomy and service importance factor for change analysis in composite service	service composition;atomic measurements;change management;service composition change management web service;会议论文;web service;stakeholders;web services decision making distributed processing fuzzy set theory management of change software management;web services;taxonomy;correlation;taxonomy web services decision making correlation stakeholders atomic measurements;service change management process change taxonomy service importance factor change analysis composite service distributed platform web service multicriteria decision making problem fuzzy synthetic evaluation technique	Service-based applications which increasingly rely on the distributed platform provided by the Web are subject to frequent changes due to changing business and technological requirements. Change impact analysis is an important activity of management for composite services consisting of services available through a marketplace of providers. This paper presents an approach to analyze component service changes in composite services and to evaluate the change effect levels. We first identify the various change types for composite services. Then, we focus on the analysis of service functional changes based on the proposed concept: service importance factor, which is used to measure change effect level. Determining service importance factor is a multi-criteria decision making problem and the fuzzy synthetic evaluation technique is applied to synthesize individual service importance factors related to a set of user-defined criteria. We have shown by the running example that the proposed change impact analysis approach is useful for subsequent tasks in the service change management processes.	categorization;change management (engineering);cognitive dimensions of notations;process modeling;requirement;service composability principle;service-oriented modeling;synthetic intelligence;world wide web	Yi Wang;Ying Wang	2015	2015 IEEE 12th International Conference on e-Business Engineering	10.1109/ICEBE.2015.30	web service;service level requirement;service level objective;service product management;differentiated service;knowledge management;service delivery framework;marketing;ws-policy;service design;change management;change management;database;management science;law;taxonomy;service system	SE	-56.01960507783759	20.583406722711644	185607
57c4d0859fa8cb4d1525a69312d594970ca4245d	special feature evolved software for the 80's	testing technological innovation maintenance engineering airplanes innovation management product design standards development software engineering software systems programming;technological innovation;software systems;maintenance engineering;testing;software engineering;standards development;innovation management;airplanes;product design;programming	To reach a better balance between free innovation and disciplined construction, we must bring an experimental element to software engineering, creating a modifiable and configurable software inventory composed of reusable and verified program parts.	software engineering	Laszlo A. Belady	1979	Computer	10.1109/MC.1979.1658621	maintenance engineering;programming;personal software process;verification and validation;software engineering process group;innovation management;search-based software engineering;package development process;software design;social software engineering;component-based software engineering;software development;software engineering;software construction;software testing;software walkthrough;product design;resource-oriented architecture;software maintenance;software deployment;software development process;software requirements;software system;software peer review	SE	-62.77996370122702	23.464238713209586	185850
e1f3ebe4968b71e45a09a1ed79560db9f79d891b	enhancing process models to improve business performance: a methodology and case studies		Process mining is not only about discovery and conformance checking of business processes. It is also focused on enhancing processes to improve the business performance. While from a business perspective this third main stream is definitely as important as the others if not even more, little research work has been conducted. The existing body of work on process enhancement mainly focuses on ensuring that the process model is adapted to incorporate behavior that is observed in reality. It is less focused on improving the performance of the process. This paper reports on a methodology that creates an enhanced model with an improved performance level. The enhancements of the model limit incorporated behavior to only those parts that do not violate any business rules. Finally, the enhanced model is kept as close to the original model as possible. The practical relevance and feasibility of the methodology is assessed through two case studies. The result shows that the process models improved through our methodology, in comparison with state-of the art techniques, have improved KPI levels while still adhering to the desired prescriptive model.		Marcus Dees;Massimiliano de Leoni;Felix Mannhardt	2017		10.1007/978-3-319-69462-7_15	conformance checking;business process;management science;process mining;process management;computer science;process modeling;business rule	Metrics	-57.36870506535185	19.645819064495047	186373
1bf9fa5bce4afc4044150626983f73d4c6fa3e4f	systems engineering for information fusion: towards enterprise multi-level fusion integration	fusion systems architecture systems enginnering information fusion multi level fusio;systems engineering;systems engineering sensor fusion software architecture;fusion system architecture systems engineering information fusion enterprise multilevel fusion integration systematic approach cohesive approach formal process;modeling aging organizations capability maturity model sensor fusion;software architecture;sensor fusion	Advances in both low-level and high-level fusion continue to be made at an increasingly accelerated pace. With the value of Information Fusion now being recognized as applicable to several domain problems, comes the need to develop a systematic and cohesive approach to address the Enterprise Multi-Level Fusion Lifecycle. It is no longer sufficient to advance fragmented capabilities without formal processes with which to deploy them in an integrated fashion. While the importance of Systems Engineering has been previously addressed by the Fusion Community of Interest, advances in technology and in the way that systems are deployed, e.g., Service Oriented Architecture, Distributed Systems, Information Assurance, and Real-Time/Mobile applications, and especially the complexity of Systems-of-Systems which characterize Multi-Level Fusion, warrant a fresh look at developing a lock-step approach. This paper draws from real-world projects and explores how Systems Engineering can be leveraged to deploy Enterprise Multi-Level Fusion applications and bridge the integration gap between Lower-Level and Higher-Level capabilities that continues to challenge the Fusion community.	airborne ranger;apple sos;autonomous robot;bridging (networking);causality;end-to-end encryption;heart rate variability;high- and low-level;information assurance;morphing;real-time computing;real-time transcription;semiconductor industry;sensor;service-oriented architecture;system of systems;systems engineering	Marco A. Solano;John Carbone	2013	Proceedings of the 16th International Conference on Information Fusion		systems engineering;engineering;transport engineering	SE	-61.68198395673622	21.17732023585872	186860
08e5c5392acaf77589b51536e131dbb8d9cd4964	conceptual map of software environmental impact		Nowadays, there is an increasing necessity for renewing hardware platforms, mainly because of the extended requirements of software products. On the other hand, pollution and health problems are being experienced by software users resulting from the replacement and use of computers. Taking into account the global concerns about damage to the ecosystem, enough arguments are found to develop a software quality model that includes the estimation of environmental impact. However, the fundamental concepts to be considered are not clear yet. This work is part of a research in progress; it proposes a map including concepts and relationships, which intends to establish the scope of a model (based on ISO/IEC 9126) for estimating system quality supported by a software eco-design. This set of concepts and relationships will increase conceptual maturity of the subject and the relevant relationships in it.	capability maturity model;computer;ecosystem;iso/iec 9126;requirement;software quality;user (computing)	J. Pinto;María A. Pérez;Luis Eduardo Mendoza;Anna Grimán;M. Kräuter	2006			software quality management;systems engineering;engineering;software design;social software engineering;operations management;software development;management science;software walkthrough;software quality control;software metric;software quality analyst	SE	-60.893164828812296	25.155220293108002	187222
cd49477ab1b5358076005af878f6869020f71f6c	two perspectives on reference architecture sustainability		In the context of software architectures, sustainability has been investigated as an important quality property to assess how well these architectures support changes over time. Several initiatives to achieve sustainable software architectures/systems can be already found. In parallel, reference architectures have served as an effective support to facilitate and standardize the development and evolution of software systems, including in complex, critical application domains. By encompassing valuable knowledge of specific domains, the reference architectures survival is considered of utmost importance, however, the most of such architectures have not been updated since their first version. Furthermore, there is a lack of works investigating how a reference architectures, by itself, can become sustainable and/or can contribute to develop sustainable systems in a domain. The main contribution of this paper is to provide a first view about sustainability on reference architectures. Resulting from our expertise on reference architectures, we bring out the two perspectives on their sustainability: (i) sustainability IN reference architectures; and (ii) sustainability OF reference architectures. In particular, for the perspective OF, we analyzed 20 existing reference architectures to assess their sustainability, and we found most of them were not updated over time. Hence, we also provide an initial set of aspects that could contribute to address sustainability of those architectures.	application domain;best practice;open research;reference architecture;software architecture;software system	Tiago Volpato;Brauner R. N. Oliveira;Lina Maria Garcés Rodriguez;Rafael Capilla;Elisa Yumi Nakagawa	2017		10.1145/3129790.3129815	computer science;software system;systems engineering;software;reference architecture;software architecture;database-centric architecture;sustainability	SE	-60.82738308545176	19.728889033365782	188395
e73614c4abe48e1762fed5c98b0c2835c63476e6	modelling of business processes for software as a service		The traditional approach to business process modelling frequently results in large models that are difficult to change and maintain. In cloud-based environment, business dynamics are mandating that business processes normally be increasingly responsive to changes. This demands business process should be highly modular, scalable and flexible for cloud-based applications. Further, in cloud-based business environments, besides describing new capabilities, process models should also define how those capabilities can be integrated with the existing systems. In this paper, a hierarchical graph-based specification called business component graph for SaaS (BCGS) has been proposed to address those issues. The proposed BCGS, formally, realises the business components for software as a service (SaaS)-based applications. BCGS represents the complex business logic design as a set of business components and their inter-relationships. Here, business component is defined as methodical integration of business processes an...	business process;software as a service	Amit Kr Mandal;Anirban Sarkar	2017	IJBPIM	10.1504/IJBPIM.2017.10004535	enterprise software;enterprise modelling;business requirements;systems engineering;artifact-centric business process model;business process management;function model;social software engineering;software development;software construction;software as a service;business process model and notation;process management;business system planning;business software;software deployment;business process modeling;business activity monitoring	SE	-56.07783313272114	18.453462413730247	188713
51a0324d242c1a86b4a436f092d698b410407bad	design guidelines for ambient software visualization in the workplace	employment;negative affect;project management;product specification;information sources;guidelines employment displays application software project management programming profession data visualization educational institutions processor scheduling information filtering;application software;processor scheduling;project manager;information filtering;working hours;development process;design guideline project status report development process product specification application domain customer requirements personal work flow project management software artifact software development ambient software visualization;software engineering;project status report;software artifact;information flow;application domain;guidelines;design guideline;programming profession;displays;software development;data visualization;personal work flow;prospective memory;software engineering program visualisation;ambient software visualization;program visualisation;software visualization;customer requirements	Success in software development dictates that the right information reaches the right people. In the development process, information flows among developers, managers, and customers. The information is represented in a multitude of sources: customer requirements, application domains, product specifications, development processes, schedules, budgets, project status reports, and task priorities. Unfortunately, in the transmission of information, vital tidbits are filtered away, made inaccessible, or withheld from the stakeholders. Software visualization systems have traditionally focused on the complexities of the relations and detailed structure of the software artifacts. Recently, attention has been given to visualizing software artifacts from the perspective of supporting teams in coordinating efforts. In this paper, we describe the nature of this information source and provide design guidelines for developing ambient software visualizations in the workplace. In particular, we describe how developers can better understand more about project management, recall and perform tasks in their personal work flow, and coordinate project state that is continually changing.	application domain;artifact (software development);gene ontology term enrichment;information flow (information theory);information source;integrated development environment;programming paradigm;requirement;scheduling (computing);software development process;software visualization	Chris Parnin;Carsten Görg	2007	2007 4th IEEE International Workshop on Visualizing Software for Understanding and Analysis	10.1109/VISSOF.2007.4290695	project management;software review;prospective memory;software visualization;personal software process;team software process;application software;application domain;information flow;software project management;computer science;systems engineering;engineering;knowledge management;package development process;software design;software development;software design description;product design specification;operating system;software engineering;data mining;systems development life cycle;software walkthrough;programming language;software analytics;goal-driven software development process;software development process;data visualization;affect;software peer review	SE	-60.4915354323004	24.07495724710244	189027
0b67650d6d0d6ce5173e70c1c2c6ca3512b7153b	spicy stonehenge: proposing a soa case study	benchmark testing;soa;public domain software;service oriented architecture;databases;business	Maintenance research in the context of Service Oriented Architecture (SOA) is currently lacking a suitable standard case study that can be used by scientists in order to (1) develop and assess their research ideas and (2) compare and benchmark their solution(s). It is also well established in different fields that having such a standard case study system brings many benefits, in that it helps determine which approaches work best for specific problems. For this reason, we decided to build upon an existing open-source system and make it available for other researchers to use. This system is Spicy Stonehenge.	benchmark (computing);open-source software;service-oriented architecture	Tiago Espinha;Cuiting Chen;Andy Zaidman;Hans-Gerhard Groß	2012	2012 4th International Workshop on Principles of Engineering Service-Oriented Systems (PESOS)		engineering;civil engineering;mechanical engineering	SE	-61.68993965419031	18.478168810365027	191175
cd04b623aec590cb6ae8c41c43768f8893681c2c	enterprise application deployment: a model driven approach		Today’s enterprise applications are based on numerous interrelated components that capture domain-specific, generic or infrastructural functionality. Each component is based on several constituting artifacts where a certain artifact is also needed by different components. The dependencies between components and artifacts become even more complex when versioning is required. Additionally, a software development process requires several runtime environments for development, testing, consolidation and production for which elements of artifacts need to be configured accordingly. For managing the deployment of enterprise applications throughout an application’s life cycle, a number of commercial tools are available. However, such tools often focus on specific technologies and require an integrated approach for build and deployment management. In this paper we present a different approach that allows for an agile model-driven deployment process that can be adapted to the desired level of detail. We propose the use of models to capture the complexity of interrelations between components, artifacts and their versions. By using either standard languages such as UML or domain-specific languages for the definition of system models, suitable tooling will be used to provide graphical user interfaces allowing for specifying required model elements and attributes.	agile software development;artifact (software development);domain-specific language;enterprise life cycle;enterprise software;graphical user interface;level of detail;model-driven architecture;runtime system;semiconductor consolidation;software deployment;software development process;unified modeling language	Peter Golibrzuch;Alexander Holbreich;Simon Zambrovski	2007			software deployment;enterprise system;enterprise information system;enterprise life cycle;process management;enterprise modelling;agile software development;software development process;enterprise integration;computer science	SE	-56.078404521765556	19.800211724456773	191217
2bdf17a258869accc982a0bad01c8e9591c7411f	applying a model-based methodology to develop web-based systems of systems.				M. A. Barcelona;Laura García-Borgoñón;Gonzalo Lopez-Nicolas;Isabel M. Ramos;María José Escalona Cuaresma	2017	J. Web Eng.		system of systems;systems design	DB	-60.61865971062025	18.604085179501098	191419
99fc7a6e1c60ef6ce06b852df821d913f1c0fb16	lessons learned on the development of an enterprise service management system using model-driven engineering	mde;report on experience.;code generation;enterprise systems	MDE (Model-Driven Engineering) techniques and tools promise to reduce the complexity and effort of software development. However, although this approach is widely known, there are few reports on its application to real enterprise developments. In this article we present our experience in the creation of an enterprise service management system using MDE. This is a complex system, as it must cope with the heterogeneity and distribution of both software services and their runtime infrastructure. Also, enterprise systems must support multiple non-functional requirements. These requirements are usually fulfilled by enterprise framework solutions, which require a steep learning curve. To overcome these problems we have applied the aforementioned MDE methodologies, starting from a generic information model and partially generating the system from it. We detail the pitfalls found and discuss the strong and weak points of the followed process.	code generation (compiler);complex system;efx factory;enterprise integration;enterprise system;functional requirement;information model;library (computing);management system;middleware;model transformation;model-driven engineering;model-driven integration;non-functional requirement;open-source software;package manager;persistence (computer science);run-time infrastructure (simulation);software development	Rodrigo García-Carmona;Juan C. Dueñas;Félix Cuadrado;José Luis Ruiz	2009		10.1007/978-3-642-20116-5_5	construction engineering;enterprise systems engineering;enterprise software;systems engineering;integrated enterprise modeling;enterprise architecture management;process management;enterprise integration;enterprise planning system;enterprise life cycle	SE	-59.273980409888324	21.920933443553814	192420
c4c0d0a881440dee0d313d46dc35b297b313fdf8	a research roadmap towards achieving scalability in model driven engineering	mde;bigmde;scalability	As Model-Driven Engineering (MDE) is increasingly applied to larger and more complex systems, the current generation of modelling and model management technologies are being pushed to their limits in terms of capacity and efficiency. Additional research and development is imperative in order to enable MDE to remain relevant with industrial practice and to continue delivering its widely recognised productivity, quality, and maintainability benefits. Achieving scalability in modelling and MDE involves being able to construct large models and domain-specific languages in a systematic manner, enabling teams of modellers to construct and refine large models in a collaborative manner, advancing the state of the art in model querying and transformations tools so that they can cope with large models (of the scale of millions of model elements), and providing an infrastructure for efficient storage, indexing and retrieval of large models. This paper attempts to provide a research roadmap for these aspects of scalability in MDE and outline directions for work in this emerging research area.	complex systems;domain-specific language;model-driven engineering;model-driven integration;scalability	Dimitrios S. Kolovos;Louis M. Rose;Nicholas Drivalos Matragkas;Richard F. Paige;Esther Guerra;Jesús Sánchez Cuadrado;Juan de Lara;István Ráth;Dániel Varró;Massimo Tisi;Jordi Cabot	2013		10.1145/2487766.2487768	systems engineering;engineering;knowledge management;data mining	SE	-60.96692805016799	20.294691105384178	192558
e312529189a0ffba4fb2e18e51c6e9a25b48034d	software migration and architecture evolution with industrial platforms: a multi-case study		The software industry increasingly needs to consider architecture evolution in the context of industrial ecosystem platforms. These environments feature a large number third-party offerings with a high variety and complexity of design and technology options. The software architects working on platform migration and in-platform evolution scenarios in such environments require support to find and utilize optimal offerings, ensure design compatibility with various technical and nontechnical constraints, and optimize architectures. Based on a multi-case study of three industrial cases, we have derived an architecture knowledge model that provides a basis for supporting software architects in platform migration and in-platform evolution scenarios.	evolution;knowledge representation and reasoning;software architect;software industry;software modernization	Konstantinos Plakidas;Daniel Schall;Uwe Zdun	2018		10.1007/978-3-030-00761-4_22	systems engineering;design and technology;computer science;architecture;software;software modernization	SE	-60.089733397525656	21.09149029913276	193523
6da7e15d4d5c2bffbe66e56e4619ec229b670c6d	a theory about the structure of gtses	general theory elements;project management;connector theories;components;connector theories gtse structure theory architecture component theories;connectors economics software engineering cognition project management software systems;software management;software systems;object oriented programming;software engineering;connectors;software architecture;interdependencies;gtse;cognition;software management object oriented programming software architecture;general theories of software engineering;theory architecture;architectural abstractions;economics;complexity management;interrelationships;component theories;gtse structure;interdependencies gtse general theories of software engineering complexity management architectural abstractions components connectors general theory elements interrelationships	Managing complexity is a fundamental goal of software engineering. One of the core techniques that has been successful in practice is that which separate concerns, especially variants of architectural abstractions called components and connectors. We present and illustrate a theory about the general structure of General Theories of Software Engineering (GTSE) - namely, that they should be organized as components and connectors to distinguish conceptually distinct general theory elements and their inter-relationships and interdependencies. Doing so, we argue, separates concerns that should be distinct and not conflated, thereby increasing the value of GTSE efforts.	interdependence;software engineering	Dewayne E. Perry;Don S. Batory	2015	2015 IEEE/ACM 4th SEMAT Workshop on a General Theory of Software Engineering	10.1109/GTSE.2015.13	reliability engineering;computer science;systems engineering	SE	-58.48411274490249	24.941712325061523	193595
05c455c5723bc3ce831933889cb6bcf71fd89038	model-driven self-management of legacy applications	management system;it management;feedback control;service level management	Increasing complexity of todays applications and services leads to the emerging trend of self-managing systems. Legacy applications often offer interfaces for manual management and very rarely do provide self-management features. Therefore it is very important to reuse existing management interfaces for achieving self-manageability. This paper presents our model-driven self-management approach of legacy applications. We introduce a framework for model-driven service level management which transforms abstract SLAs defined in UML into concrete SLA descriptions and deploys them for management. These SLAs are used to define the goals for our self-management agent which is responsible for providing feedback control. Its management knowledge is transformed from UML models using also a modeldriven approach.	feedback;itil;legacy system;management agent;model-driven architecture;model-driven integration;self-management (computer science);service-level agreement;unified modeling language	Markus Debusmann;Markus Schmid;Reinhold Kröger	2005		10.1007/11498094_6	information technology management;data management;knowledge management;feedback;management system;database;management science	SE	-58.07361209415682	19.00288368212651	194621
61b61d86ceeba1cde6185ac06161ecdc0156614e	an eclipse-based framework for supporting software development cooperative activities	software development	Software development is a cooperative activity, since it implies many actors. We focus on CSCW integrated global environments.  Many studies have already shown, for a long time, that a ‘good‘ cooperative environment should be able to take into account  the users’ emergent needs, and should be adaptable. Of course, such properties should also be found in environments supporting  software development. However, our study of some existing platforms points out their lacks in terms of tailorability and cooperative  support. Eclipse is one of these broadly used platforms. But even if it presents some shortcomings, its underlying framework  offers some features particularly interesting for our purpose. Upon results previously obtained in the CSCW field, we propose  to extend the Eclipse platform, in order to offer a new support for software development by creating a cooperative context  for the activities supported in Eclipse by each integrated plug-in.  	eclipse;software development	Arnaud Lewandowski;Grégory Bourguin	2006		10.1007/978-3-540-77581-2_17	personal software process;software engineering process group;crowdsourcing software development;software project management;computer science;social software engineering;software framework;software development;software engineering;software construction;software analytics;resource-oriented architecture;management;lean software development;software deployment;software development process;software peer review	SE	-61.207516038028686	21.830789684417653	195066
0d0e0e0e8e0162aacb17ca7ed93740f635d02f4b	language enrichment for resilient mde	composition;serveur institutionnel;enrichment;metamodel;resilience;archive institutionnelle;open access;archive ouverte unige;language;cybertheses;institutional repository	In Model-Driven Engineering, as in many engineering approaches, it is desireable to be able to assess the quality of a system or model as it evolves. A resilient engineering practice systematically assesses whether evolutions improve on the capabilities of a system. We argue that to achieve a systematic resilient model-driven engineering practice, resilience concepts should be first-class citizens in models. This article discusses how DREF, a formal framework defining resilience concepts, can be integrated with other modeling languages in order to pursue a resilient development process.	coexist (image);computer compatibility;digital subscriber line;download;entity;gene ontology term enrichment;list of toolkits;metamodeling;model-driven engineering;modeling language	Yasir Imtiaz Khan;Matteo Risoldi	2012		10.1007/978-3-642-33176-3_6	composition;systems engineering;engineering;knowledge management;language;world wide web;psychological resilience	SE	-58.793772951730226	21.380988528259902	196015
df1f4bfc230296190c76292cde5e281b6d2ca288	harnessing complexity in design	design team;effective solution;complex system;harnessing complexity;large scale design problem;design process;system behavior;personal characteristic;design effort	Large scale design problems involve complex systems. The complexity arises from the nature of the large interconnected systems and is escalated by the background, personal characteristics, and perspectives of the individuals working on the design team. It is important for designers to understand complexity and how complexity affects the understanding and prediction of system behavior. It is even more important to manage the complexity such that it does not overwhelm the design effort and prevent the development of effective solutions. This paper presents an overview of complexity, discusses how complexity can increase almost with out bound, and suggests ways to control the impact of complexity on design processes.	block cipher mode of operation;complex systems;complexity;integrated circuit;interaction;requirement	Timothy Maxwell;Atila Ertas;Murat M. Tanik	2002	Transactions of the SDPS		simulation;computer science;knowledge management;management science;complexity management	EDA	-61.39449811957639	19.077223279717092	196033
277d68a721476d79d09a980713515f1d962f6a0e	modeling knowledge intensive processes : concepts, methods, and applications	history;design engineering;risk management;knowledge management;contracts;maintenance engineering;companies;navigation;knowledge management contracts decision making educational institutions computational intelligence society companies problem solving organizing software design programming;knowledge management problem solving risk management workflow management software educational institutions computational intelligence society organizing guidelines navigation virtual environment;guidelines;history maintenance engineering design engineering knowledge engineering educational institutions computational intelligence society problem solving knowledge management software design software tools;organizing;workflow management software;software tools;virtual environment;software design;programming;problem solving;computational intelligence society;knowledge engineering	As we move further into the information age, knowledge is increasingly becoming a critical component in the competitive success of firms. As markets shift, technologies proliferate, competitors multiply and products acquire rapid obsolescence, successful companies rely on their ability to consistently create new knowledge, disseminate it quickly, and embody it in new products and services. As firms shift from a product centric form to a knowledge centric form, it becomes essential to support various dimensions of knowledge as a critical asset.		Kishore Sengupta;Balasubramaniam Ramesh	2000		10.1109/HICSS.2001.926334	maintenance engineering;programming;navigation;risk management;computer science;knowledge management;virtual machine;artificial intelligence;marketing;software design;software engineering;knowledge engineering;database;management science;knowledge value chain;management;world wide web	AI	-61.5203306076555	22.884195184433267	196120
a40fd4d4389f34b24a61695fcabdc4badf6afbb7	architectural knowledge in product line engineering: an industrial case stu	software product line infrastructure architectural knowledge software product line engineering software systems;architectural knowledge;dp industry;software systems;product line;software product line engineering;software houses;software architecture;lessons learned;product line engineering;software houses dp industry software architecture;knowledge engineering marketing and sales software engineering software quality costs time to market productivity computer industry laboratories software systems;software product line;software product line infrastructure	Capturing and sharing architectural knowledge is already a complex endeavor when dealing with conventional software systems for single customers. In product line engineering, however, the situation is even more difficult due to architectural variability and complex relationships between features and technical solution components. In this paper, we present our experiences and approaches taken in eliciting and sharing architectural knowledge for the software product line infrastructure of a company in the plant building domain. An important lesson learned is the necessity of capturing architectural knowledge and making this knowledge available appropriately to various stakeholders in the product line environment	heart rate variability;norm (social);software product line;software system	Deepak Dhungana;Rick Rabiser;Paul Grünbacher;Herbert Prähofer;Christian Federspiel;Klaus Lehner	2006	32nd EUROMICRO Conference on Software Engineering and Advanced Applications (EUROMICRO'06)	10.1109/EUROMICRO.2006.21	software architecture;personal software process;verification and validation;software quality management;software engineering process group;software sizing;architectural pattern;systems engineering;engineering;package development process;social software engineering;component-based software engineering;software development;software design description;software engineering;domain engineering;software construction;software walkthrough;resource-oriented architecture;software deployment;software requirements;software system;computer engineering;software peer review	SE	-62.098253055956484	22.851599030705458	196290
340e29c74ce262962075d02d8afa111843fa3868	a framework for the flexible instantiation of large scale software process tailoring	project manager;large scale;modelling language;software development;business process;software process	Due to the variety of concerns affecting software development in large organizations, generic software processes have to be adapted to project specific needs to be effectively applicable in individual projects. We describe the architecture of a tool aiming to provide support for tailoring and instantiation of reference processes. The goal is to minimize the effort for the individualisation of generic software processes to project specific needs. In contrast to existing approaches, our prototype provides flexible support for adaptation decisions made by project managers while adhering to modelling constraints stated by the used modelling language, enterprise policies or business process regulations.		Peter Killisperger;Markus Stumptner;Georg Peters;Georg Grossmann;Thomas Stückl	2010		10.1007/978-3-642-14347-2_10	personal software process;long-term support;verification and validation;team software process;enterprise software;software engineering process group;software sizing;software project management;computer science;systems engineering;knowledge management;package development process;software design;software framework;software development;software design description;software construction;management science;empirical process;software deployment;goal-driven software development process;software development process	SE	-56.59716149770654	20.00562073905855	196621
1af5c7cc5937ef894b31b8e056af4b43bac9e8cb	supporting assessment and improvement of software development processes using model transformations			software development	Daniel Feloni;Rosana T. V. Braga	2017			systems engineering;software development process;process management;computer science	SE	-62.52283258752822	24.849141100494812	196699
974c1a1720c11d9230894ee73cb961fd44695b5d	variability patterns for business processes in bpmn	variability pattern;business process improvement;bpmn;variability;business process	Many entities, both in academia and the business sector, urge an efficient improvement of business processes. However, when it comes to addressing this point, each slight disparity in the business rules and/or objectives translates into a separate model, which is neither practical nor acceptable as it burdens the host process-aware information system with repetitive and almost verbatim instances. To solve this issue, we propose considering variability. Variability will serve as a business process improvement technique to efficiently design and run a variable business process throughout different business situations that are similar to one another is some ways yet differ in others. First, we define variability within the context of business processes. Second, we present a set of variability patterns and explain how they are used. We validate our approach via the business process improvement patterns known and used by the community. The variability design patterns are a series of business process improvement patterns for building business process with variability and efficiently acting on the improved process performance metrics.	binocular disparity;business process model and notation;business process interoperability;business requirements;design pattern;diagram;entity;heart rate variability;information system;mutation (genetic algorithm);process patterns;requirement;semantics (computer science);sensitivity and specificity;software design pattern;spatial variability;text simplification	Alaaeddine Yousfi;Rajaa Saidi;Anind K. Dey	2016	Inf. Syst. E-Business Management	10.1007/s10257-015-0290-7	business domain;economics;systems engineering;knowledge management;artifact-centric business process model;business process management;operations management;business case;process modeling;management science;business process model and notation;business process;business process discovery;management;business rule;new business development;business process modeling	DB	-57.37127210083549	19.476772113800727	196899
60ffc4eeb76168dc7c0661c07f53898d195cee2f	model-driven engineering and software development		Safety case development is highly recommended by some safety standards to justify the safety of a system. The Goal Structuring Notation (GSN) is a popular approach to construct a safety case. However, the content of the safety case elements, such as safety claims, is in natural language. Therefore, a common understanding of the meaning of a safety claim may be difficult to reach. Consequently, the confidence of a safety claim can be misplaced. In this paper, we propose to use an SBVRbased controlled language to support safety case development. By using the controlled language, the ambiguities caused by natural language can be mitigated. Furthermore, an SBVR editor for building a vocabulary and a GSN editor with vocabulary support are developed. Finally, a case study has been carried out to show the benefits of using the controlled language for safety case construction.	controlled natural language;hippi;model-driven architecture;model-driven engineering;semantics of business vocabulary and business rules;software development	Philippe Desfray;Joaquim Filipe;Slimane Hammoudi;Luís Ferreira Pires	2015		10.1007/978-3-319-27869-8	civil engineering software;software engineering;resource-oriented architecture;systems engineering;software development;software development process;software peer review;software engineering process group;social software engineering;package development process;computer science	Mobile	-55.60516446222123	23.061536380501945	197287
6dc6b2c02e5d8d19c5bc7dc43795c9ebef2335fe	modelling automotive function nets with views for features, variants, and modes		Modelling the logical architecture of an automotive system as one central step in the development process leads to an early understanding of the fundamental functional properties of the system under design. This supports developers in making design decisions. However, due to the large size and complexity of the system and hence the logical architecture, a good notation, method and tooling is necessary. In this paper, we show how logical architectures can be modelled succinctly as function nets using a SysML-based notation. The usefulness for developers is increased by comprehensible views on the complete model that describe automotive features, variants, and modes.	systems modeling language	Hans Grönniger;Jochen Hartmann;Holger Krahn;Stefan Kriebel;Lutz Rothhardt;Bernhard Rumpe	2008	CoRR		simulation;systems engineering;engineering;engineering drawing	SE	-55.661787285108396	25.04947799959698	197492
6a6fa582f50e59e7cc308342c27fdc61be302c29	dynamic decision models for staged software product line configuration	feature models;utility elicitation;stakeholder preferences;software product lines	Software product line engineering practices offer desirable characteristics such as rapid product development, reduced time-to-market, and more affordable development costs as a result of systematic representation of the variabilities of a domain of discourse that leads to methodical reuse of software assets. The development lifecycle of a product line consists of two main phases: domain engineering, which deals with the understanding and formally modeling of the target domain, and application engineering that is concerned with the configuration of a product line into one concrete product based on the preferences and requirements of the stakeholders. The work presented in this paper focuses on the application engineering phase and builds both the theoretical and technological tools to assist the stakeholders in (a) understanding the complex interactions of the features of a product line; (b) eliciting the utility of each feature for the stakeholders and hence exposing the stakeholders’ otherwise implicit preferences in a way that they can more easily make decisions; and (c) dynamically building a decision model through interaction with the stakeholders and by considering the structural characteristics of software product line feature models, which will guide the stakeholders through the product configuration process. Initial exploratory empirical experiments that we have performed show that our proposed approach for helping stakeholders understand their feature preferences and its associated staged feature model configuration process is able to positively impact the quality of the end results of the application engineering process within the context of the limited number of participants. In addition, it has been observed that the offered tooling support is able to ease the staged feature model configuration process.	domain engineering;domain of discourse;emoticon;experiment;feature model;interaction;knowledge-based configuration;new product development;requirement;software product line	Ebrahim Bagheri;Faezeh Ensan	2013	Requirements Engineering	10.1007/s00766-013-0165-8	domain analysis;reliability engineering;systems engineering;engineering;operations management;product design specification;domain engineering;product design;new product development;product engineering	SE	-56.51529565000248	25.116982406864036	197649
248da321c443cd095e95ea13d977286ec5e2edd1	secure business process model specification through a uml 2.0 activity diagram profile	artefacto;gestion integrada;developpement logiciel;activity diagram;gestion integree;gestion entreprise;model specification;entreprise;language use;modele entreprise;hospital;uml 2 0;securite;notacion;competitividad;diagrama actividad;lenguaje uml;processus metier;empresa;firm management;integrated management;langage modelisation unifie;acceptance;security requirement;modelo empresa;aceptacion;artefact;business process model;business model;hopital;acceptation;specification modele;especificacion modelo;desarrollo logicial;security requirements;unified modelling language;business process modeling notation;firm;software development;safety;competitiveness;architecture basee modele;proceso oficio;administracion empresa;platform independent model;diagramme activite;competitivite;seguridad;activity diagrams;model driven architecture;business process;notation;arquitectura basada modelo;health care	Business processes have become important resources, both for an enterpriseu0027s performance and to enable it to maintain its competitiveness. The languages used for business process representation have, in recent years, been improved and new notations have appeared. However, despite the wide acceptance of the importance of business process security, to date the business analyst perspective in relation to security has hardly been dealt with. Moreover, security requirements cannot be represented in modern business process modeling notations. In this paper, we present an extension of UML 2.0 activity diagrams which will allow security requirements to be specified in business processes. Our proposal, denominated as BPSec (Business Process Security), is Model Driven Architecture compliant since it is possible to obtain a set of UML artifacts (Platform Independent Model-PIM) used in software development from a Secure Business Process model specification (Computation Independent Model-CIM). We also present the application of our approach to an example based on a typical health care institution, in which our M-BPSec method is employed as a framework for the use of our UML extension.	activity diagram;business process;process modeling;unified modeling language	Alfonso Rodríguez;Eduardo Fernández-Medina;Juan Trujillo;Mario Piattini	2011	Decision Support Systems	10.1016/j.dss.2011.01.018	simulation;business domain;activity diagram;business requirements;artifact-centric business process model;business process management;function model;operations management;applications of uml;process driven development;business case;process modeling;business process model and notation;process management;business process;business process discovery;business rule;new business development;business process modeling;business activity monitoring;business architecture	SE	-56.37715880227691	20.717096833386325	198754
1e410172a0fe1c4bf362c0825ba8e29ef63fd02c	a model introducing soas quality attributes decomposition		Recently, service oriented architecture (SOA) has been popularized with the emergence of standards like Web services. Nevertheless, the shift to this architectural paradigm could potentially involve significant risks including projects abandonments. With this in mind, the question of evaluating SOA quality arose. The appearance of methods like ATAM or SAAM propelled software architecture evaluation to a standard stage for any paradigm. However, there still are a number of concerns that have been raised with these methods; in particular their cost in terms of time and money, essentially because of the hand-operated nature of the evaluations conducted. The model proposed in this paper for evaluating SOAs takes as a starting point the McCall model; it allows the whole architecture to be decomposed in three types of quality attributes (factor, criterion and metric). KeywordsSOA; factor; criterion; metric	emergence;list of system quality attributes;money;non-functional requirement;programming paradigm;software architecture analysis method;web service	Riad Belkhatir;Mourad Oussalah;Arnaud Viguier	2012			systems engineering;computer science;management science	Web+IR	-59.86830726248927	20.21707434746312	199097
02c79a4d3297e62820a5e5d8aae48c693c99a064	applying a formal method in industry: a 15-year trajectory	deployment;b formal method;formal method;industry;smartcard	This article presents industrial experience of app lying the B formal method in the industry, on diverse application fiel ds (railways, automotive, smartcard, etc.). If the added value of such an app roach has been demonstrated over the year, using a formal method is not the pan acea and requires some precautions when introduced in an industrial develo pment cycle.	b-method;capability maturity model;formal methods;nintendo ds homebrew;smart card	Thierry Lecomte	2009		10.1007/978-3-642-04570-7_3	smart card;formal methods;computer science;software engineering;software deployment;computer security	Robotics	-62.807935663904026	24.469112554984186	199920
d92885fe7523b47e8e4cbf0deba8c8b2b2a7a216	scribbler: from collaborative sketching to formal domain specific models and back again	domain;collaborative	Most of the time developers make extensive use of software tools in a software development process to support them in their day-to-day work. One of the first and most important phases of this process is the design phase, but within this phase intuitive and easy to use tools, which support the creative but also collaborative workflow (parallel/distributed), are missing. At the moment, developers use whiteboards to express their ideas in team meetings. Subsequently a coworker takes a picture of the sketches and remodels them with a modeling tool. That procedure is very inconvenient, error-prone and hindering in a creative modeling cycle. For overcoming this ineffective process this paper shows a new software tool using digital whiteboards to transform free hand sketches in formal models and back again during modeling in a distributed team. The transformation is completely independent from a pre-defined modeling language. The tool provides also a training mode to learn new graphical syntax elements and map these to formal metamodel entities. Video: https://www.youtube.com/watch?v=0i3M9djPrRM [Mirror: http://sse-world.de/index.php?cID=3611]	cognitive dimensions of notations;entity;metamodeling;modeling language;programming tool;scribbler (robot);software development process	Martin Vogel;Tim Warnecke;Christian Bartelt	2013			software development process;metamodeling;modeling language;syntax;systems engineering;software;workflow;computer science	SE	-55.60623686414317	24.25790711175851	199999
