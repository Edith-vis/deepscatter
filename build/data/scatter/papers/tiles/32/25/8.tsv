id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
ee82d56237ecf6374ccb98f5684a660933def044	ray-traced collision detection for deformable bodies	distance field;collision detection;physics based animation;ray tracing	This paper presents a new approach to collision detection and modeling between deformable volumetric bodies. It allows deep intersections while alleviating the difficulties of distance field update. A ray is shot from each surface vertex in the direction of the inward normal. A collision is detected when the first intersection belongs to an inward surface triangle of another body. A contact force between the vertex and the matching point is then created. Experiments show that this approach is fast and more robust than traditional proximity-based	collision detection;computation;direct inward dial;distance transform;experiment;octree;ray tracing (graphics);robustness (computer science);volume	Everton Hermann;François Faure;Bruno Raffin	2008			ray tracing;computer vision;computer science;geometry;distance transform;collision detection;computer graphics (images)	Vision	62.61670683208726	-49.36591704958994	190774
602c78ddc608600aab42205a40090187a0df4137	near-instant capture of high-resolution facial geometry and reflectance	and texture;color;0801 artificial intelligence and image processing;software engineering;journal article;open world;picture image generation;digitizing and scanning;i 3 7 computer graphics;shadowing;i 3 3 computer graphics;lighting;three dimensional graphics and realism;shading	"""Modeling realistic human characters is frequently done using 3D recordings of the shape and appearance of real people, often across a set of different facial expressions to build blendshape facial models. Believable characters that cross the """"Uncanny Valley"""" require high-quality geometry, texture maps, reflectance properties, and surface detail at the level of skin pores and fine wrinkles. Unfortunately, there has not yet been a technique for recording such datasets that is near-instantaneous and low-cost. While some facial capture techniques are instantaneous and inexpensive [Beeler et al. 2010], these do not generally provide lighting-independent texture maps, specular reflectance information, or high-resolution surface normal detail for relighting. In contrast, techniques which use multiple photographs from spherical lighting setups [Ghosh et al. 2011] do capture such reflectance properties, at the expense of longer capture times and complicated custom equipment."""	facial motion capture;facial recognition system;image resolution;map;normal (geometry);surface detail;texture mapping;uncanny valley	Paul Graham;Graham Fyffe;Borom Tunwattanapong;Abhijeet Ghosh;Paul E. Debevec	2015		10.1145/2775280.2792561	computer vision;shading;computer science;lighting;multimedia;computer graphics (images)	Graphics	61.45075338996054	-50.92986837516365	190860
fe692583c1a02010bac29ab3ea3bce122152f35d	example-based rendering of eye movements	i 3 7 computer graphics animation;eye movement	This paper describes a model for example-based, photo-realistic rendering of eye movements in 3D facial animation. Based on 3D scans of a face with different gaze directions, the model captures the motion of the eyeball along with the deformation of the eyelids and the surrounding skin. These deformations are represented in a 3D morphable model. Unlike the standard procedure in facial animation, the eyeball is not modeled as a rotating 3D sphere located behind the skin surface. Instead, the visible region of the eyeball is part of a continuous face mesh, and displacements of the iris as well as occlusions by the lids are modeled in a texture mapping approach. The algorithm avoids artifacts that are widely encountered in 3D facial animation, and it presents a new concept of handling occlusions and discontinuities in morphing algorithms.	3d computer graphics;3d modeling;algorithm;artifact (software development);blackwell (series);compiler;computer animation;dilation (morphology);eurographics;global illumination;morphing;programming paradigm;reflections of signals on conducting lines;rendering (computer graphics);ringing artifacts;simulation;texture mapping;vertex (computer graphics)	Michael Banf;Volker Blanz	2009	Comput. Graph. Forum	10.1111/j.1467-8659.2009.01406.x	computer vision;simulation;computer science;eye movement;computer graphics (images)	Graphics	63.98333233976861	-47.57156166806466	191282
e750af2fbaa70c7254f2ec7d81ebded9d7980626	dynamic lod on gpu	paper;surface representation;adaptive mesh;computational geometry;computer graphic equipment;gpu quadtree structure geometry image atlas 3d surface representation geometry image features poly cube maps rendering pass lod algorithm fragment shaders resultant buffer vertex texturing node culling adaptive meshes;image texture;geometry rendering computer graphics graphics hardware pixel concurrent computing runtime mesh generation digital elevation models image converters;image representation;feature extraction;parameter space;algorithms;computer graphic equipment quadtrees computational geometry image representation image texture rendering computer graphics feature extraction;computer science;rendering computer graphics;3d graphics and realism;quadtrees;rendering	This paper presents a novel approach to implementing dynamic LOD on GPU. For our purpose, a quadtree structure is created based on seamless geometry image atlas, which is a 3D surface representation in parameter space by combining the features of geometry images and poly-cube maps. All the nodes in the quadtree are packed into the atlas textures. There are two rendering passes in our approach. In the first pass, the LOD selection is performed in the fragment shaders. The resultant buffer is taken as the input texture to the second rendering pass by vertex texturing, and thus the node culling and triangulation can be performed in the vertex shaders. Our LOD algorithm can generate adaptive meshes dynamically, and can be fully implemented on GPU. It improves the efficiency of LOD selection, and alleviates the computing load on CPU.	algorithm;central processing unit;cube mapping;glossary of computer graphics;graphics processing unit;map;quadtree;resultant;seamless3d;shader	Junfeng Ji;Enhua Wu;Sheng Li;Xuehui Liu	2005	International 2005 Computer Graphics	10.1109/CGI.2005.1500386	image texture;computer vision;rendering;feature extraction;computational geometry;computer science;theoretical computer science;geometry;parameter space;computer graphics (images)	Visualization	68.11919718743066	-50.92171318495793	191301
775fc1eea6b3b60f496cb8b3f46c4b502df500d7	progressive buffers: view-dependent geometry and texture lod rendering	human computer interaction;networked applications;texture mapping;virtual reality;digital geometry processing;multi user;haptics;willmore energy;high fidelity rendering;variational surface modeling;rendering system;level of detail;discrete differential geometry;perception;collaborative environments;geometric flow	We introduce a view-dependent level of detail rendering system designed with modern GPU architectures in mind. Our approach keeps the data in static buffers and geomorphs between different LODs using per-vertex weights for seamless transition. Our method is the first out-of-core system to support texture mapping, including a mechanism for texture LOD. This approach completely avoids LOD pops and boundary cracks while gracefully adapting to a specified frame rate or level of detail. Our method is suitable for all classes of GPUs that provide basic vertex shader programmability, and is applicable for both out-of-core or instanced geometry. The contributions of our work include a preprocessing and rendering system for view-dependent LOD rendering by geomorphing static buffers using per-vertex weights, a vertex buffer tree to minimize the number of API draw calls when rendering coarse-level geometry, and automatic methods for efficient, transparent LOD control.	application programming interface;glossary of computer graphics;graphics processing unit;level of detail;out-of-core algorithm;popping (computer graphics);preprocessor;rendering (computer graphics);seamless3d;shader;texture mapping	Pedro V. Sander;Jason L. Mitchell	2005		10.1145/1185657.1185826	willmore energy;texture mapping;computer vision;geometric flow;simulation;topology;rendering;computer science;level of detail;mathematics;geometry;virtual reality;haptic technology;perception;discrete differential geometry;computer graphics (images)	Graphics	65.19273957340742	-48.8299722345379	191435
f1b1194414a51e828006d7f7cdca0686ef405d28	a device independent graphics imaging model for use with raster devices	high resolution;device independence;graphics system;dither;image modeling	In building graphic systems for use with raster devices, it is difficult to develop an intuitive, device independent model of the imaging process, and to preserve that model over a variety of device implementations. This paper describes an imaging model and an associated implementation strategy that:  1. Integrates scanned images, text, and synthetically generated graphics into a uniform device independent metaphor;  2. Isolates the device dependent portions of the implementation to a small set of primitives, thereby minimizing the implementation cost for additional devices;  3. Has been implemented for binary, grey-scale, and full color raster display systems, and for high resolution black and white printers and color raster printers.	clipping (computer graphics);computer graphics;device independence;grayscale;high- and low-level;image resolution;image scanner;information processing letters;mathematical optimization;michael garey;planar straight-line graph;preparata code;programmer;raster graphics;reentrancy (computing);system integration;usability;warren abstract machine	John E. Warnock;Douglas K. Wyatt	1982		10.1145/800064.801297	computer vision;vector graphics;simulation;image resolution;raster graphics;scan line;computer science;output device;digital image;dither;computer graphics (images)	Graphics	65.48255194457639	-48.933558388360986	192019
05f0d5ca3e6cdeb4fae37102e939258691ab30e2	adaptive surface visualization of vessels with embedded blood flow based on the suggestive contour measure	picture image generation;line and curve generation;i 3 3 computer graphics	The investigation of hemodynamic information for the assessment of cardiovascular diseases (CVD) has increased in recent years. Improved flow measuring modalities and computational fluid dynamics (CFD) simulations are suitable to provide domain experts with reliable blood flow information. For a visual exploration of the flow information domain experts are used to investigate the flow information combined with its enclosed vessel anatomy. Since the flow is spatially embedded in the surrounding vessel surface, occlusion problems have to be resolved that include a meaningful visual reduction of the vessel surface but still provide important anatomical features. We accomplish this by applying an adaptive surface visualization inspired by the suggestive contour measure. Our approach combines several visualization techniques to improve the perception of surface shape and depth. Thereby, we ensure appropriate visibility of the embedded flow information, which can be depicted with established or advanced flow visualization techniques. We apply our approach to cerebral aneurysms and aortas with simulated and measured blood flow. In an informal user feedback with nine domain experts, we confirm the advantages of our approach compared with existent methods, e.g., semi-transparent surface rendering.	box counting;computational fluid dynamics;contour line;documentation;embedded system;experiment;hemodynamics;normal (geometry);response time (technology);semi-supervised learning;semiconductor industry;shading;simulation;thomas m. baer;usability testing;while	Kai Lawonn;Rocco Gasteiger;Bernhard Preim	2013		10.2312/PE.VMV.VMV13.113-120	computer vision;computer science;computer graphics (images)	Visualization	65.31452970455878	-46.735752741516286	192576
80e27e3d830648dd4245a5922218498a29164b67	facial type, expression, and viseme generation	computer model;facial modeling;geometric feature;hybrid approach;present day;pure data;sparse data;categorical data	The process of generating facial models and various poses of these models is a necessary part of most present-day movies, and usually required for any interactive game which features humans as a primary character. The generation of this face data can be approached in ways varying from pure computation to pure data acquisition. Computational models are flexible but can lack realism and intuitive or simple controls, while data-driven models produce realistic faces, but necessitate the often slow and cumbersome capture of new scan data for every desired set of face attributes. Our method is a hybrid approach, which combines a relatively small set of real world facial data with a computational algorithm that learns the underlying variations in this geometric information automatically. Given a sparse data set that spans variation in viseme, face type, and expression, we are able to generate new faces that exhibit combinations of these attributes, and were never part of the original data set. We rely on user-assisted categorization of our sparse data set to associate each piece of face data with a small set of attribute contributions, and then use this categorization data as a guide for binding abstract variation to concrete parameters. This process takes the complex, subtle, and often subjective qualities associated with visemes, expressions, and face types, and correlates them to known geometric features, in order to facilitate the creation of entirely new face poses.	algorithm;categorization;computation;computational model;data acquisition;humans;pure data;sparse matrix;type system	James Skorupski;Jerry Yee;Josh McCoy;James Davis	2007		10.1145/1280720.1280758	computer simulation;computer vision;categorical variable;sparse matrix;computer science;artificial intelligence;machine learning;pattern recognition;computer graphics (images)	Graphics	63.15312305829777	-46.34000511473062	192678
e309592ea21ec753f961069a276f10fbe17b6eba	fast approximations for global illumination on dynamic scenes	human computer interaction;networked applications;real time;virtual reality;multi user;haptics;high fidelity rendering;global illumination;perception;collaborative environments;dynamic scenes	An innovative lighting algorithm is presented that allows scenes to be displayed with approximate global illumination including ambient occlusion and sky-light effects at real-time rates. The method is scalable for high polygonal scenes and requires a small amount of pre-computation. The presented technique can be successfully applied to dynamic and animated sequences, and displays a striking aesthetic style by reducing traditional constraints of physical correctness and a standard lighting model.	3d computer graphics;acm siggraph;ambient occlusion;approximation algorithm;computation;computer vision;correctness (computer science);dead reckoning;digital imaging;direct3d;displacement mapping;distance transform;euclidean distance;game developers conference;general-purpose markup language;global illumination;glossary of computer graphics;graphics processing unit;high-dynamic-range rendering;illumination (image);interactivity;matt pharr;order-independent transparency;pixel;precomputation;real-time clock;real-time transcription;rendering (computer graphics);rendering equation;rubygems;scalability;scientific visualization;shading;shadow mapping;web page;windows 95	Alex Evans	2006		10.1145/1185657.1185834	computer vision;computer science;artificial intelligence;virtual reality;multimedia;haptic technology;perception;global illumination;computer graphics (images)	Graphics	64.66640867417114	-49.127039332345525	192750
d70e6206ed00e13aa95e8d258afd491b1b3f1c5d	half-precision floating-point ray traversal		Ray tracing is a memory-intensive application. This paper presents a new ray traversal algorithm for bounding volume hierarchies. The algorithm reduces the required memory bandwidth and energy usage, but requires extra computations. This is achieved with a new kind of utilization of half-precision floating-point numbers, which are used to store axis aligned bounding boxes in a hierarchical manner. In the traversal the ray origin is moved to the edges of the intersected nodes. Additionally, in order to retain high accuracy for the intersection tests the moved ray origin is converted to the child’s hierarchical coordinates, instead of converting the child’s bound coordinates into world coordinates. This means that both storage and the ray intersection tests with axis aligned bounding boxes can be done in half-precision. The algorithm has better results with wider vector instructions. The measurements show that on a Mali-T628 GPU the algorithm increases frame rate by 3% and decreases power consumption by 9% when wide vector instructions are used.	3d scanner;academy;algorithm;apache axis;bandwidth (signal processing);bounding volume hierarchy;computation;desktop computer;fastest;glossary of computer graphics;graphics processing unit;half-precision floating-point format;mali (gpu);memory bandwidth;ray tracing (graphics);single-precision floating-point format;tree traversal	Matias Koskela;Timo Viitanen;Pekka Jääskeläinen;Jarmo Takala	2016		10.5220/0005728001690176	bounding interval hierarchy;computer graphics (images);computer science;frame rate;bounding volume hierarchy;tree traversal;floating point;bounding volume;memory bandwidth;ray tracing (graphics)	Graphics	66.53686411853487	-50.954681382532584	193001
4896e59086691dd6c5355d12b908e4cfd447fbfc	multilevel representation and transmission of real objects with progressive octree particles	geometry data visualization decoding multimedia databases application software computer science education cultural differences medical services biomedical equipment automation;fast direct triangulation technique multilevel object representation real objects progressive octree particles multilevel representation scheme rendering dense data object attributes geometry attributes surface particles hierarchical space partitioning compact multilevel representation;octree;levels of detail;surface particles;direct triangulation;progressive representation;computational geometry;indexing terms;computational geometry octrees rendering computer graphics;3d model;level of detail;progressive transmission;compact representation;rendering computer graphics;triangle mesh;multiresolution 3d models;geometric structure;octrees	We present a multilevel representation scheme adapted to storage, progressive transmission, and rendering of dense data sampled on the surface of real objects. Geometry and object attributes, such as color and normal, are encoded in terms of surface particles associated to a hierarchical space partitioning based on an octree. Appropriate ordering of surface particles results in a compact multilevel representation without increasing the size of the uniresolution model corresponding to the highest level of detail. This compact representation can progressively be decoded by the viewer and transformed by a fast direct triangulation technique into a sequence of triangle meshes with increasing levels of detail. The representation requires approximately 5 bits per particle (2.5 bits per triangle) to encode the basic geometrical structure. The vertex positions can then be refined by means of additional precision bits, resulting in 5 to 9 bits per triangle for representing a 12-bit quantized geometry. The proposed representation scheme is demonstrated with the surface data of various real objects.	12-bit;encode;fast fourier transform;level of detail;octree;space partitioning;triangle mesh	Yücel Yemez;Francis J. M. Schmitt	2003	IEEE Trans. Vis. Comput. Graph.	10.1109/TVCG.2003.1260748	computer vision;index term;computational geometry;computer science;theoretical computer science;triangle mesh;level of detail;geometry;octree;computer graphics (images)	Visualization	67.62607570198114	-49.74671727682323	193057
82cdabd738989e914437eee003055442d9b51fd4	automatic fitting and control of complex freeform shapes in 3-d	computer aided design;feature recognition;distance measure;computer graphic;3 dimensional;deformable template;numerical experiment	In many computer graphics and computer-aided design problems, it is very common to find a smooth and well structured surface to fit a set of unstructured 3-dimensional data. Although general approaches of fitting give satisfactory results, the computation time and the complexity often prevent their further developments in more complex cases especially in reusing an existing design. In this paper, for a better control of existing freeform shapes, they are approximated by feature templates, with emphasis on extendable templates. By the advantage of the small number of intrinsic parameters in the feature based deformable templates, fitting procedures are faster and more robust. Three key types of simple freeform templates, the bump, the ridge and the hole, are introduced first. With distance measuring methods, a uniform optimization function is presented to achieve automatic feature recognition and fitting. By introducing the extendable template, the hole and the ridge template are further developed to match complex freeform shapes. Based on the approximated template, further shape manipulations can be conducted effectively using the shape intrinsic parameters. Numerical experiments are conducted in order to verify the proposed algorithms. It is also described how the matching technique can be applied in computer graphics and computer-aided design applications.	approximation algorithm;bump mapping;camera resectioning;computation;computer graphics;computer-aided design;curve fitting;experiment;extensibility;feature recognition;freeform surface modelling;mathematical optimization;robustness (computer science);shape context;time complexity	Yu Song;Joris S. M. Vergeest;Chensheng Wang	2004			feature recognition;three-dimensional space;computer vision;computer science;computer aided design;computer graphics (images)	Graphics	67.44274699901011	-45.175423861358674	193376
898ccd5c0c206ff1f16fa03c322c08e615f1c3d7	temporally coherent interactive ray tracing	large dataset;interactive application;interactive rendering;ray tracing;temporal coherence;image based rendering;interactive ray tracing	Ray tracing exhibits visible temporal aliasing artifacts in interactive viewing of complex datasets. We present a technique to reduce scintillation in point sampled imagery by targeting new rays to intersection points from previous frames. Remaining artifacts are abated by blending between successive frames. The algorithm achieves a reduction in scintillation comparable to that of supersampling, but at a significantly lower cost. Sample animations are available online.	algorithm;aliasing;alpha compositing;coherent;jumbo frame;ray tracing (graphics);supersampling	William Martin;Peter Shirley;Steven G. Parker;William B. Thompson;Erik Reinhard	2002	J. Graphics, GPU, & Game Tools	10.1080/10867651.2002.10487559	distributed ray tracing;ray tracing;computer vision;image-based modeling and rendering;computer science;multimedia;beam tracing;computer graphics (images)	Graphics	65.02913341431235	-51.810112245668336	193464
ec46ab01b364a2d87e160dbc4a19a209d71b5645	simplified tree lighting using aggregate normals	haptics;visual prosthetics;sensory substitution	Trees have earned a reputation among lighting artists for being difficult to light in an appealing way. A tree canopy is composed of a myriad of leaves facing random directions. Without shadows, standard diffuse lighting of a canopy yields unappealing visual noise.In Over the Hedge and Shrek III, we derive a set of aggregate normals that account for the shape of a leaf canopy. Combining this normal with the geometry normal of each leaf before shading yields a more appealing tree shape.	aggregate data;aggregate function;image noise;motorola canopy;shading	Scott Peterson;Lawrence Lee	2006		10.1145/1179849.1179908	computer vision;sensory substitution;simulation;computer science;haptic technology;computer graphics (images)	Graphics	63.02012247921346	-50.04532082265133	193516
c78eaa9992276467193e73deaab510d5b4062370	pde-based facial animation: making the complex simple	facial animation;face modeling	Direct parameterisation is among the most widely used facial animation techniques but requires complicated ways to animate face models which have complex topology. This paper develops a simple solution by introducing a PDE-based facial animation scheme. Using a PDE face model means we only needs to animate a group of boundary curves without using any other conventional surface interpolation algorithms. We describe the basis of the method and show results from a practical implementation.	algorithm;closing (morphology);control point (mathematics);experiment;facial recognition system;interpolation;simulation;uv mapping;vertex (geometry)	Yun Sheng;Philip J. Willis;Gabriela González Castro;Hassan Ugail	2008		10.1007/978-3-540-89646-3_71	computer vision;facial motion capture;simulation;computer facial animation;skeletal animation;computer science;computer graphics (images)	Graphics	65.96368717304956	-46.024624089339575	193769
f1b989bff42dddfaa21d606f5c3cc94a1d5cd377	hardware-accelerated real-time rendering for 3d sumi-e painting	3d imaging;real time;hardware accelerator;rendering system;graphics hardware;real time rendering	This paper presents a method for real-time 3D Sumi-e rendering using normal graphics hardware. Sumi-e is one of the traditional oriental painting styles. Most research on Sumi-e paintings has focused on 2D or 2.5D Sumi-e brushwork simulation. On these systems, complicated user's hand drawing is required to generate the image of Sumi-e effects, and it can render the 2D or 2.5D Sumi-e images only. We present an automated rendering system for 3D image of Sumi-e painting. It uses 3D common object as an input data and does not need any additional input of user brushwork. Especially for the real-time rendering, hardware-accelerated algorithm for Sumi-e rendering is newly suggested in our system. It is designed with efficiency for customer level graphics hardware. The results of this paper show that the features of traditional Sumi-e painting are successfully modeled and that 3D Sumi-e painting is rendered in real-time effectively.	3d computer graphics;iso/iec 9126;real-time transcription	Shin-Jin Kang;Sun-Jeong Kim;Chang-Hun Kim	2003		10.1007/3-540-44842-X_61	stereoscopy;hardware acceleration;computer science;multimedia;real-time rendering;graphics hardware;computer graphics (images)	Graphics	64.22363968419435	-48.00685098717146	194780
5185a920fce9c773c7cc40c8c9992083db595016	hand gesture recognition through on-line skeletonization - application of continuous skeleton to real-time shape analysis		New method for palm shape analysis and hand gesture recognition with help of continuous skeletons is presented in the paper. Continuous skeleton makes possible to develop fast and simple methods for palm shape analysis and measure a lot of its features. In particular it is possible to develop efficient methods for segmentation and analysis of the object topological structure, measuring relative location of object parts and measuring width of the object in arbitrary place. Applying to palm shape analysis skeleton provides a way to determine number of visible fingers, estimate their thickness and location, and perform efficient palm shape comparison with the sample. Moreover proposed approach allows measuring all mentioned features regardless of palm orientation in the frame. And efficient algorithms for skeleton construction allow performing shape analysis with high speed in real-time applications.	algorithm;gesture recognition;human–computer interaction;real-time transcription;shape analysis (digital geometry);thickness (graph theory);virtual reality	Alexey Kurakin;Leonid Mestetskiy	2011			computer vision;speech recognition	Vision	63.348628242701025	-46.13124639699073	194867
26041df60dae21ac3df2b69e6cf0978631ef247e	virtual brush: a model-based synthesis of chinese calligraphy	model based approach;level of detail;compact representation	This paper describes the Virtual Brush, a model-based approach to synthesizing realistically Chinese calligraphic writings. This approach simulates the physical process of brush stroke creation using a parameterized model which captures (a) the writing brush 3D geometric parameters, (b) the brush hair properties and (c) the variations of ink deposition along a stroke trajectory. An analysis of some well-known Chinese brush writing styles is given, with a view to establishing the relationship of these writing styles and the modeling process of simulating these different writing styles. We present here our model formulation and the implementation of a software which is capable of simulating some typical calligraphic writing styles on a PC platform. This parameterized model allows a compact representation for brush-written characters which can be used to synthesize characters at different levels of detail, with various brush effects. The result is applicable for very high-quality publishing purpose. Additionally, by appropriately transforming and scaling the stroke trajectories which define a virtual brush character, Purchase Export	emoticon;image scaling;norm (social);personal computer;physical vapor deposition;simulation	Helena T. F. Wong;Horace Ho-Shing Ip	2000	Computers & Graphics	10.1016/S0097-8493(99)00141-7	simulation;level of detail;computer graphics (images)	Graphics	64.81528133530685	-47.85923795489359	195073
60a65f716b2c179bddcf4dc3385ce290ecca9c10	resolution independent rendering of deformable vector objects using graphics hardware	expressive imagery;graphics hardware;non realistic modeling	Resolution independent rendering is important for many applications such as text rendering and rendering vector images. This area has received quite some interest in recent years due to the growing popularity of Flash and SVG-based applications. This sketch presents a new method for resolution independent rendering of vector images suitable for programmable graphics hardware. We have enhanced a previous method [Loop and Blinn 2005] by using a stencil buffer and transparency multisampling [ATI 2005; NVI 2004], so that our method has the following advantages:	adobe flash;blinn–phong shading model;graphics hardware;multisample anti-aliasing;rendering (computer graphics);resolution independence;scalable vector graphics;stencil buffer;subpixel rendering;nvi	Yoshiyuki Kokojima;Kaoru Sugita;Takahiro Saito;Takashi Takemoto	2006		10.1145/1179849.1179997	computer vision;tiled rendering;vector graphics;graphics pipeline;2d computer graphics;image-based modeling and rendering;computer hardware;rendering;computer science;real-time computer graphics;texture memory;computer graphics;alternate frame rendering;graphics hardware;software rendering;3d computer graphics;computer graphics (images)	Graphics	65.77178748002608	-51.32144933120946	195341
9f8505a814db07de04b3298cfc10cb21344952c8	painting with flowsnakes		Space filling curves, invented by mathematicians in the 19th century, have long been a fascination for artists, however there are no interactive tools to allow an artist to create and explore various levels of recursion of the curve in different parts of the artwork. In this work a new type of painting tool for artists is introduced, which gives the artist control over the very base of a space filling curve, i.e recursive subdivision. Although there are many such curves that would lend themselves to this treatment, the Flowsnake (Gosper) curve has been chosen in this work, mainly for its aesthetics. The curve is based on a hexagonal grid, and in our system hexagons are subdivided at the artist's touch in a non-homogeneous manner, leaving a trail that forms the space filling curve. Some tools are introduced for controlling the painting, such as limiting the depth of recursion, and the 'slow brush', which interpolates slowly between subdivisions to allow the artist to stop at a chosen level. A set of space filling curve brush types provide different shapes and profiles, for giving the artist control of the non-homogeneous subdivision, including the ability to un-subdivide the hexagons. An algorithm for drawing the curve non-recursively is introduced in order to produce a polyline suitable for processing on the GPU to make the system function at interactive rates. An animated version of the image can be made by replaying the subdivisions from the first level. Some examples made by art students and graduates are shown, along with the artist's comments on the system.	algorithm;fascination;glossary of computer graphics;gosper curve;graphics processing unit;interpolation;recursion;space-filling curve;subdivision surface	Brian Wyvill	2015			visual arts;engineering;cartography;computer graphics (images)	Graphics	67.63834120534358	-48.2567702650378	195716
3c48c70ddd514c7a821554184e74f7df1957f0fe	skinning cubic bézier splines and catmull-clark subdivision surfaces	spline;skeletal shape deformation;vector graphics;linear blend skinning;subdivision;image warping	"""Smooth space deformation has become a vital tool for the animation and design of 2D and 3D shapes. Linear methods, under the umbrella term of """"linear blend skinning"""", are the de facto standard for 3D animations. Unfortunately such approaches do not trivially extend to deforming vector graphics, such as the cubic Bézier splines prevalent in 2D or subdivision surfaces in 3D. We propose a variational approach to reposition the control points of cubic Bézier splines and Catmull-Clark subdivision surfaces---or any linear subdivision curves or surfaces---to produce curves or surfaces which match a linear blend skinning deformation as closely as possible. Exploiting the linearity of linear blend skinning, we show how this optimization collapses neatly into the repeated multiplication of a matrix per handle. We support C0, C1, G1, and fixed-angle continuity constraints between adjacent Bézier curves in a spline. Complexity scales linearly with respect to the number of input curves and run-time performance is fast enough for real-time editing and animation of high-resolution shapes."""	2d computer graphics;3d computer graphics;bézier curve;calculus of variations;catmull–clark subdivision surface;cubic function;image resolution;mathematical optimization;real-time clock;scott continuity;spline (mathematics);umbrella term;vector graphics	Alec Jacobson	2014	ACM Trans. Graph.	10.1145/2661229.2661270	image warping;spline;vector graphics;computer science;subdivision;mathematics;geometry;computer graphics (images)	Graphics	67.57700987496392	-45.97633206756429	195747
6d1b17affbf7db8e5c72eb2abc43da7e67ee46b6	boundary matching for interactive sprouts		The simplicity of the pen-and-paper game Sprouts hides a surprising combinatorial complexity. We describe an optimisation called boundary matching that accommodates this complexity to allow move generation for Sprouts games of arbitrary size at interactive speeds.	mathematical optimization;playout;time complexity	Cameron Browne	2015		10.1007/978-3-319-27992-3_14	artificial intelligence;machine learning;canonical form;computer science	Theory	64.0994226445702	-48.676571336111735	195818
d6442edeaafce8ec30d6674d34e54b3384195f20	pencilart: a chromatic penciling style generation framework				Chengying Gao;Mengyue Tang;Xiangguo Liang;Zhuo Su;Changqing Zou	2018	Comput. Graph. Forum	10.1111/cgf.13334	computer vision;image processing;chromatic scale;computer science;non-photorealistic rendering;artificial intelligence	NLP	63.165234297225666	-50.702088734597126	196619
f5264680a21c9f49b66dcd2b2e1a383dbd27564b	direct lighting on meso-structured surfaces with area light sources	会议论文;directional radiosity;meso structured surfaces;direct lighting	We present a novel direct lighting rendering method for static scenes with meso-structured surfaces and multiple area light sources. We use coarse geometry models with textures bound on them as inputs. The textures contain not only color maps, but also height field maps to represent the small concave and convex details for meso-structured surfaces. We explore traditional radiosity process as the main frame of our algorithm, and extend radiosity to directional radiosity for approximating light transportation on meso-structured surfaces. In pre-processing step, first, the form factors between the triangles of coarse models and the patches of area light sources are pre-computed. Then the directional radiosity of each triangle is computed by gathering irradiance according to directions sampled uniformly on the hemi-sphere of them. At last, directional radiosity of a vertex is estimated according to the directional radiosity of triangles passing through this vertex. For each frame, we combine relief texture mapping with directional radiosity to shade meso-structured surface. The experiment results show that our method has very similar quality and better time performance for rendering the scenes with meso-structured surfaces and multiple area light sources compared with SM+RTM method.	algorithm;computer form factor;concave function;heightmap;mainframe computer;map;mesoscopic physics;precomputation;preprocessor;radiosity (computer graphics);relief mapping (computer graphics);texture mapping	Lili Wang;Jun Wu	2015		10.1145/2821592.2821602	computer vision;radiosity;global illumination;computer graphics (images)	Graphics	66.09187609960733	-50.277216207258576	197110
7ee07d84ba835d93a3d016376106bf05d6c2a360	hair rendering by jittering and pseudo shadow	hair modeling;satisfiability;hair rendering;hair rendering computer graphics humans geometry information science computer graphics anisotropic magnetoresistance optical reflection computational modeling animation;jittering;pseudo shadow;realistic images rendering computer graphics jitter;realistic images;visible volume buffer;jitter;rendering computer graphics;natural hair images realistic hair rendering jittering pseudo hair model pseudo shadows shadow factor	In this paper, we first proposed two properties of hair that we believe are essential to realistic hair rendering. To satisfy these two properties of hair, we introduce the jittering and pseudo hair model. The jittering and pseudo shadow are achieved through the use of the shadow factor. The experimental results show that with the incorporation of the two properies, hair images look more natural than the images without these properties thus proving that these two properties do indeed improve the realism of hair images.		Waiming Kong;Masayuki Nakajima	2000		10.1109/CGI.2000.852344	computer vision;simulation;jitter;rendering;computer science;real-time rendering;satisfiability;computer graphics (images)	Graphics	63.33076487341927	-50.50803690585407	197809
4e796e04dfa083e068bc6c3600b8210c9cf6c23d	automatic impostor placement for guaranteed frame rates and low memory requirements	guaranteed frame rate;visibility culling;level of detail;human modeling and animation;image quality;simplification level of detail;image based rendering;acceleration techniques	Impostors are image-based primitives commonly used to replace complex geometry in order to reduce the rendering time needed for displaying complex scenes. However, a big problem is the huge amount of memory required for impostors. This paper presents an algorithm that automatically places impostors into a scene so that a desired frame rate and image quality is always met, while at the same time not requiring enormous amounts of impostor memory. The low memory requirements are provided by a new placement method and through the simultaneous use of other acceleration techniques like visibility culling and geometric levels of detail.	algorithm;image quality;requirement	Stefan Jeschke;Michael Wimmer;Heidrun Schumann;Werner Purgathofer	2005		10.1145/1053427.1053444	image quality;computer vision;simulation;image-based modeling and rendering;computer science;level of detail;computer graphics (images)	Graphics	65.87563638030113	-51.67809998059534	198041
99072714e55370a3fabde9daf8f4bd60ae5b98e9	user-defined texture synthesis	image processing;texture synthesis;area of interest;transfer function;force field;data visualization	Synthesis of textures is a very popular and active area of research; the applications and the areas of interest are various and significant. In the last years, much work has been done in order to optimize the synthesis process, speeding up the methods and minimizing the processing errors. Recent efforts in this area are concentrated in producing flexible algorithms and in introducing tools, which augment the texture with artistic effects. In this work we present a novel approach for flexible texture synthesis: starting from an input sample the process generates an arbitrary resolution output image; the characteristics of this output texture are user-defined, as the user can freely choose a force field, determine color variations and add further features. The synthesis process is fully automatic and does not require additional intervention. The resulting outputs can be interpreted as filtered versions of a texture or as being obtained through transfer functions.	algorithm;force field (chemistry);texture synthesis;transfer function	Francesca Taponecco	2004			computer vision;image processing;computer science;force field;transfer function;texture atlas;texture compression;texture synthesis;texture filtering;data visualization;computer graphics (images)	Graphics	66.27246503929643	-47.822050707941614	198541
10cc1621d6b228179eda173e111d071dab947c54	interactive clipping techniques for texture-based volume visualization and volume shading	rendering computer graphics data visualisation interactive systems;hardware acceleration;boundary representation;volume rendering;volume shading;data visualisation;graphics hardware;consistent shading interactive clipping techniques texture based volume visualization volume shading complex geometries per fragment operations graphics hardware texture based volume rendering interactive region selection interactive region exploration depth based clipping techniques voxelized clip object surface based illumination volume based illumination;clipping;volume visualization;rendering computer graphics;hardware transfer functions rendering computer graphics lighting testing data visualization computational geometry computer graphics geometrical optics biomedical optical imaging;interactive systems	We propose clipping methods that are capable of using complex geometries for volume clipping. The clipping tests exploit per-fragment operations on the graphics hardware to achieve high frame rates. In combination with texture-based volume rendering, these techniques enable the user to interactively select and explore regions of the data set. We present depth-based clipping techniques that analyze the depth structure of the boundary representation of the clip geometry to decide which parts of the volume have to be clipped. In another approach, a voxelized clip object is used to identify the clipped regions. Furthermore, the combination of volume clipping and volume shading is considered. An optical model is introduced to merge aspects of surface-based and volumebased illumination in order to achieve a consistent shading of the clipping surface. It is demonstrated how this model can be efficiently incorporated in the aforementioned clipping techniques.	boundary representation;clipping (computer graphics);global illumination;graphics hardware;graphics processing unit;identifier;interaction technique;interactivity;list of common shading algorithms;medical imaging;scientific visualization;shading;transfer function;user interface;volume rendering	Daniel Weiskopf;Klaus Engel;Thomas Ertl	2003	IEEE Trans. Vis. Comput. Graph.	10.1109/TVCG.2003.1207438	computer vision;scientific visualization;clipping;hidden surface determination;hardware acceleration;rendering;computer science;clipping;level of detail;multimedia;texture memory;graphics hardware;volume rendering;boundary representation;data visualization;software rendering;computer graphics (images)	Visualization	67.45527078562691	-50.718145802687175	198547
7a593bd6c2a3ef31c3f1456a4cc94d327f07e18a	flow volumes for interactive vector field visualization	data visualisation;flow visualisation;interactive systems;physics computing;rendering (computer graphics);user interfaces;vectors;artifacts;flow volumes;hardware compositing;hardware texturing;interactive system;interactive vector field visualization;rendering;smoke;sorting;subdivision;transparently rendered tetrahedra;user interaction	Flow volumes are the volumetric equivalent of stream lines. They provide more information about the vector field being visualized than do stream lines or ribbons. Presented is an efficient method for producing flow volumes, composed of transparently rendered tetrahedra, for use in an interactive system. The problems of rendering, subdivision, sorting, compositing artifacts, and user interaction are dealt with. Efficiency comes from rendering only the volume of the smoke, and using hardware texturing and compositing.	compositing;interactivity;rendering (computer graphics);sorting;subdivision surface;texture mapping	Nelson L. Max;Barry G. Becker;Roger Crawfis	1993			computer vision;flow visualization;computer science;theoretical computer science;mathematics;geometry;multimedia;computer graphics (images);fluid dynamics	Visualization	65.82300262820516	-49.10235906726972	199264
c8f89b887444b94ebb2f04adf776154bea82c380	a novel ray-shooting method to render night urban scenes a method based on polar diagrams	hard shadows;ray shooting;large 2 5d urban models;polar diagrams	Illumination and shadows are essential to obtain realistic virtual environments. Nevertheless, large scenes like urban cities demand a huge amount of geometry that must somehow be structured or reduced in order to be manageable. In this paper we propose a novel real-time method to determine the shadowed and illuminated areas in large scenes, specially suitable for urban environments. Our approach uses the polar diagram as a tessellation plane, and a ray-casting process to obtain the visible areas. This solution derives the exact illuminated area with a high performance. Moreover, our approach is also used to determine the visible portion of the scene from a pedestrian viewpoint. As a result, we only have to render the visible part of the scene, which is considerably lower than the global scene.	2.5d;algorithm;automatic parallelization;computation;diagram;display resolution;geometry processing;global illumination;graphics processing unit;illumination (image);map;opencl api;ray casting;real-time clock;real-time locating system;shadow mapping;shadow volume;shooting method;virtual reality;web application;webcl	María Dolores Robles-Ortega;J. R. Jiménez;Lidia M. Ortega	2014	2014 International Conference on Computer Graphics Theory and Applications (GRAPP)	10.5220/0004718800530063	computer vision;computer graphics (images)	Visualization	66.60759482202903	-51.650523003572744	199370
e786c684a8ef7e232a0917c35139031292248c60	explorations for real-time point cloud rendering of natural scenes in virtual reality	frustum culling;gpu rendering;level of detail;stereo vision;splatting;head mounted display	This work is a proof of concept, where we explore the possibility of rendering natural scenes in a head mounted display device without meshing. Real-time, stereoscopic full-HD rendering is obtained for a 14 million points scene, using a low end graphics card for virtual reality (Nvidia GeForce GTX 970), within an Oculus Rift DK2. High quality is achieved by using splatting, while real-time rendering is made possible by the means of a good data structure and a complexity reduction of the scene with techniques such as Optimized Sub-Sampling, Level of Detail and Frustum Culling. Altogether, those techniques lead to a good virtual reality immersion. Choices and limitations of the proposed techniques are discussed.	data structure;display device;geforce 600 series;geforce 900 series;graphics;head-mounted display;hidden surface determination;immersion (virtual reality);level of detail;oculus rift;point cloud;real-time clock;real-time locating system;real-time transcription;reduction (complexity);rendering (computer graphics);stereoscopy;video card;viewing frustum;virtual reality	Daniele Bonatto;Segolene Rogge;Arnaud Schenkel;Rudy Ercek;Gauthier Lafruit	2016	2016 International Conference on 3D Imaging (IC3D)	10.1109/IC3D.2016.7823453	computer vision;simulation;image-based modeling and rendering;viewing frustum;3d rendering;rendering;computer science;parallel rendering;real-time rendering;software rendering;computer graphics (images)	Visualization	67.32868415695096	-52.008461552202114	199455
642d9a3b6137ee22290ea828267ba515244aa22a	area-preserving parameterizations for spherical ellipses		We present new methods for uniformly sampling the solid angle subtended by a disk. To achieve this, we devise two novel area-preserving mappings from the unit square [0,1]2 to a spherical ellipse (i.e. the projection of the disk onto the unit sphere). These mappings allow for low-variance stratified sampling of direct illumination from disk-shaped light sources. We discuss how to efficiently incorporate our methods into a production renderer and demonstrate the quality of our maps, showing significantly lower variance than previous work. CCS Concepts •Computing methodologies → Rendering; Ray tracing; Visibility;		Ibón Guillén;Carlos Ureña;Alan King;Marcos Fajardo;Iliyan Georgiev;Jorge López-Moreno;Adrian Jarabo	2017	Comput. Graph. Forum	10.1111/cgf.13234	computer vision;artificial intelligence;computer science;rendering (computer graphics);ellipse;sampling (statistics);solid angle;ray tracing (graphics);unit sphere;distributed ray tracing;unit square	Graphics	66.4068024753424	-48.5210411318268	199713
26016cb43813fba3a8edcdf2ae8a49ab17fa8986	lod terrain rendering by local parallel processing on gpu	lod terrain rendering;hierarchical structure;paper;hardware tessellation;computer graphic equipment;terrain rendering;terrain mapping computer graphic equipment coprocessors parallel processing rendering computer graphics;gpu;tiles rendering computer graphics cameras graphics processing unit hardware acceleration data structures;coprocessors;acceleration;nvidia geforce gtx 480;visualization;level of detail;data structures;nvidia;tiles;terrain mapping;computer science;rendering computer graphics;graphics processing unit;hardware tessellation lod terrain rendering parallel processing gpu level of detail;3d graphics and realism;parallel processing;cameras;directx;hardware;rendering	In this paper, we present a new technique for highly efficient terrain rendering using continuous view-dependent Level-of-Detail based on hardware tessellation unit found in modern GPUs. Our technique is based on parallel local processing, in the sense that the results at each terrain patch do not depend on results already obtained at other patches. This patch-by-patch processing uses no hierarchical structure whatsoever, what makes it specifically tailored for GPU-based LOD terrain and is highly scalable.	graphics processing unit;parallel processing (dsp implementation);scalability;terrain rendering	Alexandre Valdetaro;Gustavo N. Nunes;Alberto Barbosa Raposo;Bruno Feijó;Rodrigo de Toledo	2010	2010 Brazilian Symposium on Games and Digital Entertainment	10.1109/SBGAMES.2010.30	computer vision;computer hardware;computer science;computer graphics (images)	Graphics	68.04796534046099	-51.78560506982416	199728
ebcf339a19ad2847d1794fa89b95d94953c2664b	real-time human vision rendering using blur distribution function	vision realistic;rendering	We propose a real-time rendering method which is based on the Blur Distribution Function(BDF) of human eye in order to achieve vision-realistic effect. In real-time rendering, a thin lens camera model is commonly adopted to simulate the effect of Depth of Field(DoF). Thin lens model is efficient to calculate but lacks vision-realistic effect. We consider the simulation of human vision an improvement in virtual reality. In this paper, we analysis and model the BDF of human eye. The BDF is calculated quickly by neural network to simulate blur size of each pixel. Based on a schematic eye model, which provides accurate optical properties of human eye, our method shows DoF effect simulating human vision. Evaluation results indicate that the rendering effect of our method conforms to human vision and extra computation cost is acceptable.	artificial neural network;backward differentiation formula;box blur;computation;gaussian blur;pixel;real-time clock;real-time locating system;real-time transcription;schematic;simulation;virtual reality	Ning Tang;Shuangjiu Xiao	2015		10.1145/2817675.2817686	computer vision;simulation;3d rendering;rendering;computer science;computer graphics (images)	Graphics	63.3238767520795	-51.340110938504665	199885
