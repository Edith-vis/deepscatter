id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
280173d29e682087596266c8d08e55b3d1c65ed1	automatic image registration by stochastic optimization of mutual information	optimisation;image resolution optimisation image registration stochastic processes search problems gradient methods wavelet transforms;affine transformation automatic image registration stochastic optimization mutual information search strategy stochastic gradient wavelet pyramid multiresolution pyramid fundus eye images;image resolution;search strategy;wavelet transforms;stochastic optimization;stochastic processes;affine transformation;image registration;stochastic gradient;gradient methods;mutual information;image registration stochastic processes mutual information histograms biomedical imaging optimization methods entropy probability distribution testing interpolation;search problems;multi resolution	Image registration is the process by which we determine a transformation that provides the most accurate match between two images. The search for the matching transformation can be automated with a suitable choice of metric, but can be very timeconsuming and tedious. In this paper, we consider a registration algorithm that combines a simple yet powerful search strategy based on optimization of mutual information using a stochastic gradient, together with a wavelet-based multi-resolution pyramid. It is tested using a pair of fundus eye images, which is matched using a six-parameter affine transformation. This extends previous work based on the three-parameter transformation [7]. The registration algorithm is implemented in a multiresolution manner using a wavelet pyramid.	algorithm;gradient;image registration;mathematical optimization;multiresolution analysis;mutual information;stochastic optimization;wavelet	Arlene A. Cole-Rhodes;Abake Adenle	2003		10.1109/ICASSP.2003.1199469	computer vision;mathematical optimization;image resolution;image registration;stochastic optimization;pattern recognition;affine transformation;mathematics;mutual information;statistics;wavelet transform	Vision	48.299835020516696	-71.86090805676535	178797
a6463533730c0d2c46e4a5a50f4415b6ef833e49	a priori information in image segmentation: energy functional based on shape statistical model and image information	minimisation;image segmentation shape biomedical imaging energy capture active contours level set equations signal processing steady state image analysis;lts5;image segmentation;statistical shape model;segmentation;pde;statistical analysis image segmentation gradient methods minimisation;statistical model;energy function;variational approach;statistical analysis;medical image;registration;variational model;gradient methods;a priori information;medical images a priori information image segmentation shape statistical model image information image gradients;lts2;steady state;statistical shape	In this paper, we propose an energy functional to segment objects whose global shape is a priori known thanks to a statistical model. Our work aims at extending the variational approach of Chen et al. [1] by integrating the statistical shape model of Leventon et al. [2]. The proposed energy functional allows us to capture an object that exhibits high image gradients and a shape compatible with the statistical model which best fits the segmented object. The minimization of the functional provides a system of coupled equations whose steady-state solution is the solution of the segmentation problem. Results are presented on synthetic and medical images.	entity–relationship model;fits;gradient;image segmentation;medical imaging;statistical model;statistical shape analysis;steady state;synthetic intelligence;variational principle	Xavier Bresson;Pierre Vandergheynst;Jean-Philippe Thiran	2003		10.1109/ICIP.2003.1247272	active shape model;statistical model;computer vision;minimisation;mathematical optimization;computer science;pattern recognition;mathematics;image segmentation;steady state;segmentation;statistics	Vision	50.27624545218779	-72.00786676296681	179011
bdc4d03fb248b9f3762d8b70747328fbd6a33e41	a seed expanding cluster algorithm for deriving upwelling areas on sea surface temperature images	homogeneity criterion;computer science and information systems;upwelling;seeded region growing;approximate clustering;sst images	In this paper a novel clustering algorithm is proposed as a version of the seeded region growing (SRG) approach for the automatic recognition of coastal upwelling from sea surface temperature (SST) images. The new algorithm, one seed expanding cluster (SEC), takes advantage of the concept of approximate clustering due to Mirkin (1996, 2013) to derive a homogeneity criterion in the format of a product rather than the conventional difference between a pixel value and the mean of values over the region of interest. It involves a boundary-oriented pixel labeling so that the cluster growing is performed by expanding its boundary iteratively. The starting point is a cluster consisting of just one seed, the pixel with the coldest temperature. The baseline version of the SEC algorithm uses Otsu's thresholding method to fine-tune the homogeneity threshold. Unfortunately, this method does not always lead to a satisfactory solution. Therefore, we introduce a self-tuning version of the algorithm in which the homogeneity threshold is locally derived from the approximation criterion over a window around the pixel under consideration. The window serves as a boundary regularizer. These two unsupervised versions of the algorithm have been applied to a set of 28 SST images of the western coast of mainland Portugal, and compared against a supervised version fine-tuned by maximizing the F-measure with respect to manually labeled ground-truth maps. The areas built by the unsupervised versions of the SEC algorithm are significantly coincident over the ground-truth regions in the cases at which the upwelling areas consist of a single continuous fragment of the SST map. & 2015 Elsevier Ltd. All rights reserved.	approximation algorithm;baseline (configuration management);cluster analysis;ground truth;map;otsu's method;pixel;region growing;region of interest;seed;self-tuning;strongly regular graph;thresholding (image processing);unsupervised learning	Susana Nascimento;Sérgio Casca;Boris G. Mirkin	2015	Computers & Geosciences	10.1016/j.cageo.2015.06.002	upwelling;geology;data mining;remote sensing	Vision	46.940937046015286	-68.92790846653841	179160
85e73930dee50b87c14732bb12db84c70d39a131	image filtering using morphological amoebas	morphological filters;image filtering;mathematical morphology;morphological operation;anisotropic filters;geodesic distance;3d image processing;color filters;noise reduction	This paper presents morphological operators with non-fixed shape kernels, or amoebas, which take into account the image contour variations to adapt their shape. Experiments on grayscale and color images demonstrate that these novel filters outperform classical morphological operations with a fixed, space-invariant structuring element for noise reduction applications. Tests on synthetic 3D images are then performed to show the high noise-reduction capacity of amoeba-based filters.	amoeba	Romain Lerallut;Etienne Decencière;Fernand Meyer	2007	Image Vision Comput.	10.1016/j.imavis.2006.04.018	computer vision;color filter array;geodesic;mathematical morphology;computer science;pattern recognition;noise reduction;mathematics	Vision	50.93586145659802	-66.93568289490817	179365
03c95e53f214952885fb04f6eb4feb02e0c8807e	adaptive regularization of ill-posed problems: application to non-rigid image registration	prior distribution;markov random field;non rigid image registration;ill posed problem;pattern recognition;variational method;tikhonov regularization;optimal algorithm	We introduce an adaptive regularization approach. In contrast to conventional Tikhonov regularization, which specifies a fixed regularization operator, we estimate it simultaneously with parameters. From a Bayesian perspective we estimate the prior distribution on parameters assuming that it is close to some given model distribution. We constrain the prior distribution to be a Gauss-Markov random field (GMRF), which allows us to solve for the prior distribution analytically and provides a fast optimization algorithm. We apply our approach to non-rigid image registration to estimate the spatial transformation between two images. Our evaluation shows that the adaptive regularization approach significantly outperforms standard variational methods.	algorithm;calculus of variations;image registration;markov chain;markov random field;mathematical optimization;matrix regularization	Andriy Myronenko;Xubo B. Song	2009	CoRR		regularization perspectives on support vector machines;backus–gilbert method;regularization;mathematical optimization;mathematical analysis;prior probability;computer science;variational method;maximum a posteriori estimation;pattern recognition;mathematics;tikhonov regularization;statistics	ML	52.0043896750166	-71.89287292264582	179582
10f7ce17ed1294cbe5d7b76adfaedc304ba992f7	occam filters for stochastic sources with application to digital images	gaussian noise;traitement signal;filtering;filtrage;digital filters stochastic processes digital images signal processing algorithms nonlinear filters wiener filter convergence adaptive signal processing signal processing predictive models;image numerique;senal estocastica;rate distortion theory occam filters stochastic sources digital images lossy data compression random noise filtering deterministic signals wavelet based denoising gaussian noise svd;image coding;data compression;stochastic signal;filtrado;transform coding;reduccion ruido;rate distortion theory;wavelet transforms;random noise;stochastic processes;signal processing;noise reduction;imagen numerica;reduction bruit;signal stochastique;compresion dato;digital image;procesamiento senal;gaussian noise filtering theory wavelet transforms transform coding image coding data compression stochastic processes rate distortion theory;filtering theory;compression donnee	An Occam filter employs lossy data compression to separate signal from noise. Previously, it was shown that Occam filters can filter random noise from deterministic signals. Here, we show that Occam filters can also separate two stochastic sources, depending on their relative compressibility. We also compare the performance of Occam filters and wavelet-based denoising on digital images.	digital image;occam	Balas K. Natarajan;Konstantinos Konstantinides;Cormac Herley	1998	IEEE Trans. Signal Processing	10.1109/78.668806	data compression;filter;gaussian noise;computer vision;transform coding;rate–distortion theory;computer science;theoretical computer science;signal processing;noise reduction;mathematics;digital image;statistics;wavelet transform	Embedded	53.63465110313469	-67.42980231141415	180209
54da733eb646e794e6ccf2141a07ce6f847339dd	a geometric active contour model using symmetrical kullback-leibler distance for sar image segmentation		This paper addresses the problem of SAR image segmentation by using a variational method. The resistor-average distance which is a symmetrical Kullback-Leibler distance is utilized to measure the discrepancy between the distributions of the classes to be segmented. The regional energy is derived by maximizing the discrepancy from the entire shapes of the distributions of the segmented classes. The gradient flow of the regional energy is derived accordingly. The heterogeneity indicator map, computed from the coefficient of variation, assists to locate the boundary of the segmented objects. The experimental results on SAR images confirm its effectiveness and flexibility.	active contour model;calculus of variations;coefficient;contour line;discrepancy function;gradient;image segmentation;kullback–leibler divergence	Na Li;Fang Liu;Lei Qiu;Xiangchenyang Su	2018	IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2018.8517380	variational method;artificial intelligence;kullback–leibler divergence;computer vision;image segmentation;synthetic aperture radar;coefficient of variation;computer science;active contour model	Vision	48.00339879022811	-69.12099341222041	180643
5f191957537a9ddae21eb59d0527b621ab49ce0e	an optimal segmentation method using jensen-shannon divergence via a multi-size sliding window technique	jensen shannon divergence;entropic edge detection;image segmentation;multi size window processing;entropy	In this paper we develop a new procedure for entropic image edge detection. The presented method computes the Jensen–Shannon divergence of the normalized grayscale histogram of a set of multi-sized double sliding windows over the entire image. The procedure presents a good performance in images with textures, contrast variations and noise. We illustrate our procedure in the edge detection of medical images.	canny edge detector;computation;edge detection;experiment;grayscale;image histogram;image noise;jensen's inequality;microsoft windows;pixel;sensor;shannon (unit);sobel operator	Qutaibeh D. Katatbeh;José Martínez-Aroza;Juan Francisco Gómez-Lopera;David Blanco-Navarro	2015	Entropy	10.3390/e17127858	computer vision;entropy;mathematical optimization;jensen–shannon divergence;pattern recognition;mathematics;image segmentation;physics;statistics	Vision	51.207784017072804	-67.15251197404739	181660
24e1bc7bdc6bfe15dc97de024005854c9e3cf923	introduction to the special issue on partial differential equations and geometry-driven diffusion in image processing and analysis	partial differential equation;image motion analysis;image processing;special issues and sections;integral equations;filters;image processing and analysis;shape;partial differential equations;special issues and sections partial differential equations image processing integral equations differential equations filters image analysis image motion analysis shape;image analysis;differential equations;article	where is the evolving image, is an operator that characterizes the given algorithm, and the image is the initial condition. 1 The solution of the differential equation gives the processed image at scale. In the case of vector-valued images, a system of coupled PDE’s of the form of (1) is obtained. The same formalism can be applied to planar curves (boundaries of planar shapes), whereis a function from to , or surfaces, functions from to . In this case, the operator must be restricted to the curve, and all isotropic motions can be described as a deformation of the curve or surface in its normal direction, with velocity related to its principal curvature(s). In more formal terms, a flow of the form	algorithm;image processing;initial condition;isotropic position;motion;normal (geometry);semantics (computer science);velocity (software development)	Vicent Caselles;Jean-Michel Morel	1998	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/TIP.1998.661176	computer vision;mathematical optimization;image analysis;image processing;computer science;theoretical computer science;calculus;mathematics;partial differential equation	Vision	49.9766123166466	-66.45369080442364	181686
cbd35ed17a8c6268c64db845cb7e99218d1e6144	an extension of the standard mixture model for image segmentation	modelizacion;standard gaussian mixture model gradient method image segmentation spatial constraints;processus gauss;ruido aleatorio;spatial constraints;representacion espacial;spatial dependence;image segmentation;image processing;standard gaussian mixture model;modelo markov;estimacion densidad;melange loi probabilite;markov random field model;gaussian processes;bruit aleatoire;segmentacion de imagenes;gradient method;estimation densite;markov random fields;procesamiento imagen;bayesian methods;mixed distribution;markov processes gaussian processes gradient methods image segmentation;traitement image;gray scale;markov random field;modelisation;methode gradient;density estimation;random noise;fichier log;gaussian mixture model;markov model;fichero actividad;data negative log likelihood;image segmentation pixel parameter estimation bayesian methods noise reduction markov random fields gradient methods gray scale robustness image processing;mixture model;metodo gradiente;gmm model image segmentation standard gaussian mixture modeling markov random field model image pixels data negative log likelihood gradient method grayscale images mrf models;noise reduction;robustesse;pixel;segmentation image;mrf models;grayscale images;algorithms animals artifacts computer simulation contrast sensitivity humans image processing computer assisted neural networks computer normal distribution pattern recognition automated space perception;spatial representation;gradient methods;mezcla ley probabilidad;robustness;representation spatiale;teoria mezcla;image pixels;spatial relationships;markov processes;gaussian process;parameter estimation;modele markov;classification automatique;reseau neuronal;proceso gauss;automatic classification;mixture theory;echelle gris;modeling;clasificacion automatica;theorie melange;red neuronal;escala gris;log file;gmm model;standard gaussian mixture modeling;neural network;robustez	Standard Gaussian mixture modeling (GMM) is a well-known method for image segmentation. However, the pixels themselves are considered independent of each other, making the segmentation result sensitive to noise. To reduce the sensitivity of the segmented result with respect to noise, Markov random field (MRF) models provide a powerful way to account for spatial dependences between image pixels. However, their main drawback is that they are computationally expensive to implement, and require large numbers of parameters. Based on these considerations, we propose an extension of the standard GMM for image segmentation, which utilizes a novel approach to incorporate the spatial relationships between neighboring pixels into the standard GMM. The proposed model is easy to implement and compared with MRF models, requires lesser number of parameters. We also propose a new method to estimate the model parameters in order to minimize the higher bound on the data negative log-likelihood, based on the gradient method. Experimental results obtained on noisy synthetic and real world grayscale images demonstrate the robustness, accuracy and effectiveness of the proposed model in image segmentation, as compared to other methods based on standard GMM and MRF models.	analysis of algorithms;exptime;google map maker;gradient descent;gradient method;grayscale color map;image segmentation;mbnl1 gene;markov chain;markov random field;mike lesser;mixture model;normal statistical distribution;pixel;racepinephrine;segmentation action;synthetic intelligence;urea 390 mg/ml topical cream [dermasorb xm];biologic segmentation	Thanh Minh Nguyen;Q. M. Jonathan Wu;Siddhant Ahuja	2010	IEEE Transactions on Neural Networks	10.1109/TNN.2010.2054109	computer vision;image processing;computer science;pattern recognition;mixture model;gaussian process;mathematics;image segmentation;scale-space segmentation;artificial neural network;grayscale;statistics	Vision	51.22132573330597	-68.80515629611502	182393
3af1e4958b6e1baa83fe8b33809944eba0818fe4	automatic image decomposition	texture;image segmentation;image processing;low frequency;inpainting image segmentation image representation automatic image decomposition image primitive components cartoon texture image structure critical decomposition control parameter selection bounded variation;image restoration;oscillation;image texture;image texture image segmentation image representation;image decomposition automatic control engineering profession low frequency noise image segmentation art tv image converters feedback equations;parameter selection;image representation;parameters;differential equations;image decomposition;high frequency;images;critical parameter	The decomposition of an image into its primitive components, such as cartoon plus texture, is a fundamental problem in image processing. In previous works, various authors have proposed a technique to achieve this decomposition into structure and texture. These two components are competing ones, and their proposed model has a critical parameter that controls this decomposition. In this paper, we show how to automatically select this parameter, and demonstrate with examples the importance of this optimal selection.	image processing	Kedar A. Patwardhan;Guillermo Sapiro	2004	2004 International Conference on Image Processing, 2004. ICIP '04.	10.1109/ICIP.2004.1418837	image texture;image restoration;computer vision;image processing;computer science;decomposition;machine learning;high frequency;pattern recognition;mathematics;image segmentation;low frequency;texture;oscillation;parameter;differential equation	Robotics	53.07118050505203	-68.96863005089779	182590
bcea9a2a4e17c462198ff9ddb770243fe515f10a	segmentation of vectorial image features using shape gradients and information measures	image features;video object;active contour;image segmentation;probability density function;shape gradient;image statistics;active contours;motion vector field;shape optimization;motion segmentation;joint probability density function;optical flow;entropy;vector field;information;information theory;color image;joint probability	In this paper, we propose to focus on the segmentation of vectorial features (e.g. vector fields or color intensity) using region-based active contours. We search for a domain that minimizes a criterion based on homogeneity measures of the vectorial features. We choose to evaluate, within each region to be segmented, the average quantity of information carried out by the vectorial features, namely the joint entropy of vector components. We do not make any assumption on the underlying distribution of joint probability density functions of vector components, and so we evaluate the entropy using non parametric probability density functions. A local shape minimizer is then obtained through the evolution of a deformable domain in the direction of the shape gradient. The first contribution of this paper lies in the methodological approach used to differentiate such a criterion. This approach is mainly based on shape optimization tools. The second one is the extension of this method to vectorial data. We apply this segmentation method on color images for the segmentation of color homogeneous regions. We then focus on the segmentation of synthetic vector fields and show interesting results where motion vector fields may be separated using both their length and their direction. Then, optical flow is estimated in real video sequences and segmented using the proposed technique. This leads to promising results for the segmentation of moving video objects.	color;image gradient;joint entropy;mathematical optimization;optical flow;shape optimization;synthetic intelligence	Ariane Herbulot;Stéphanie Jehan-Besson;Stefan Duffner;Michel Barlaud;Gilles Aubert	2006	Journal of Mathematical Imaging and Vision	10.1007/s10851-006-6898-y	computer vision;probability density function;information theory;computer science;machine learning;pattern recognition;mathematics;scale-space segmentation;statistics	Vision	49.29690223539251	-70.88697618948552	183244
29be4bda392d3313243ec6f15a212e04f00ad25d	bayesian vq image filtering design with fast adaption competitive neural networks	bayesian framework;analisis imagen;traitement signal;image filtering;image processing;compresion senal;procesamiento imagen;traitement image;compression signal;carte autoorganisatrice;cuantificacion vectorial;vector quantization;self organising feature maps;magnetic resonance;signal processing;signal compression;image analysis;vector quantizer;procesamiento senal;analyse image;noise removal;neural network;quantification vectorielle	Vector Quantization (VQ) is a well known technique for signal compression and codification. In this paper we propose the filtering of images based on the codebooks obtained from Vector Quantization design algorithms under a Bayesian framework. The Bayesian VQ filter consists in the substitution of the image pixel by the central pixel of the codevector that encodes the pixel and its neighborhood. This process can be interpreted as a Maximum A Posteriori restoration based on the codebook estimated from the image. We apply the VQ filter to noise removal in images from micromagnetic resonance. We compare our approach with the more conventional approach of applying VQ compression as a noise removal filter. Some visual results show the improvement introduced by our approach.	algorithm;artificial neural network;circuit restoration;codebook;pixel;signal compression;stochastic resonance;vector quantization	Ana Isabel González;Manuel Graña;Imanol Echave;Jesús Ruíz-Cabello	1999		10.1007/BFb0100501	computer vision;image analysis;image processing;computer science;machine learning;signal processing;pattern recognition;mathematics;vector quantization;artificial neural network	ML	52.73166572360281	-67.34445178021704	183310
a33808049d7636c030e14c68f5d22cdac9899f3a	sar image multiclass segmentation using a multiscale and multidirection triplet markov fields model in nonsubsampled contourlet transform domain	nsct hmt;nsct tmf model;nsct tmf energy function;sar image multiclass segmentation;multiscale information fusion	Triplet Markov fields (TMFs) model recently proposed is to deal with nonstationary image segmentation and has achieved promising results. In this paper, we propose a multiscale and multidirection TMF model for nonstationary synthetic aperture radar (SAR) image multiclass segmentation in nonsubsampled contourlet transform (NSCT) domain, named as NSCT-TMF model. NSCT-TMF model is capable of capturing the contextual information of image content in the spatial and scale spaces effectively by the construction of multiscale energy functions. And the derived multiscale and multidirection likelihoods of NSCT-TMF model can capture the dependencies of NSCT coefficients across scale and directions. In this way, the proposed model is able to achieve multiscale information fusion in terms of image configuration and features in underlying labeling process. Experimental results demonstrate that due to the effective propagation of the contextual information, NSCT-TMF model turns out to be more robust against speckle noise and improves the performance of nonstationary SAR image segmentation.	contourlet;markov chain;triplet state	Yan Wu;Peng Zhang;Ming Li;Qiang Zhang;Fan Wang;Lu Jia	2013	Information Fusion	10.1016/j.inffus.2012.12.001	computer vision;speech recognition;pattern recognition	Vision	50.46395952952409	-69.54842384880887	183488
552ab0b11360d050847e0d18d1a793c82d78ecd2	depth map estimation based on linear regression using image focus	depth map estimation;linear regression;shape from focus;3d shape recovery	This article presents a method for depth estimation using image focus based on the linear regression model. Two datasets are selected for each pixel based on the maximum value which is calculated using Laplacian operator. Then linear regression model is used to find lines that approximate these datasets. The best fit lines are found using least squares method. After approximating the two lines, their intersection point is calculated, and weights are assigned to calculate the new value for the depth map. The proposed method is compared with four depth estimation algorithms. Six different objects are selected for testing the proposed method. © 2011 Wiley Periodicals, Inc. Int J Imaging Syst Technol, 21, 241–246, 2011; © 2011 Wiley Periodicals, Inc.	depth map	Aamir Saeed Malik;Taek Lyul Song;Tae-Sun Choi	2011	Int. J. Imaging Systems and Technology	10.1002/ima.20274	econometrics;mathematical optimization;computer science;linear regression;machine learning;mathematics;statistics	EDA	47.941866452184065	-69.03443167164019	183820
8e468447fb8ff3e4dcaa3201df5b042d1de228ca	unsupervised change detection with expectation-maximization-based level set	unsupervised learning;geophysical image processing;landsat image;unsupervised learning expectation maximisation algorithm gaussian processes geophysical image processing remote sensing;multitempor;gaussian processes;journal;unsupervised change detection expectation maximization em level set method remote sensing;gaussian mixture model;quickbird image;emls;remote sensing;期刊论文;unsupervised change detection quickbird image landsat image pixel mean value estimation gaussian mixture model multitemporal image emls remote sensing image implicit handling expectation maximization based level set method;implicit handling;expectation maximization based level set method;expectation maximisation algorithm	The level set method, because of its implicit handling of topological changes and low sensitivity to noise, is one of the most effective unsupervised change detection techniques for remotely sensed images. In this letter, an expectation-maximization-based level set method (EMLS) is proposed to detect changes. First, the distribution of the difference image generated from multitemporal images is supposed to satisfy Gaussian mixture model, and expectation-maximization (EM) is then used to estimate the mean values of changed and unchanged pixels in the difference image. Second, two new energy terms, based on the estimated means, are defined and added into the level set method to detect those changes without initial contours and improve final accuracy. Finally, the improved level set method is implemented to partition pixels into changed and unchanged pixels. Landsat and QuickBird images were tested, and experimental results confirm the EMLS effectiveness when compared to state-of-the-art unsupervised change detection methods.	correctness (computer science);expectation–maximization algorithm;finite element method;map;mixture model;pixel;unsupervised learning	Ming Hao;Wenzhong Shi;Hua Zhang;Chang Li	2014	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2013.2252879	unsupervised learning;computer vision;computer science;machine learning;pattern recognition;mixture model;gaussian process;remote sensing	Vision	49.932206491773485	-68.30347875854717	183977
007b69136ce0d3f0d455ddc9ab2627f8dec66fe5	dynamic distance-based shape features for gait recognition	rough skeletons;gait recognition;smoothed distance function;skeleton variance image	We propose a novel skeleton-based approach to gait recognition using our Skeleton Variance Image. The core of our approach consists of employing the screened Poisson equation to construct a family of smooth distance functions associated with a given shape. The screened Poisson distance function approximation nicely absorbs and is relatively stable to shape boundary perturbations which allows us to define a rough shape skeleton. We demonstrate how our Skeleton Variance Image is a powerful gait cycle descriptor leading to a significant improvement over the existing state of the art gait recognition rate.	approximation;emoticon;gait analysis;poisson wavelet;projection screen;rough set;smoothing	Tenika P. Whytock;Alexander G. Belyaev;Neil M. Robertson	2014	Journal of Mathematical Imaging and Vision	10.1007/s10851-014-0501-8	computer vision;pattern recognition;mathematics;geometry;topological skeleton	Vision	48.40236396221271	-68.89057663897297	184640
f62e7db9e4ba90b7227c3ef8e92ab08467a4a72b	activity driven nonlinear diffusion for color image watershed segmentation	color space;diffusion;principal component analysis;color image;watershed segmentation;image segmentation	Nonlinear diffusion processes and watershed algorithms have been well studied for gray-scale image segmentation. In this paper we extend the use of these techniques to color or multichannel images. First, we formulate a general definition for a nonlinear diffusion process using the concept of an activity image that can be calculated for several image components. Then, we explain how the final activity image, obtained as a result of the nonlinear diffusion process, is fed through a watershed algorithm, yielding the segmentation of the image. The qualitative performance of the algorithm is illustrated with results for both gray-scale and color photographic images. Finally, we discuss the segmentation results obtained using a few well-known color spaces and demonstrate that a color principal component analysis gives the best results.	color image;nonlinear system;watershed (image processing)	Patrick de Smet;Rui Luís V. P. M. Pires;Danny De Vleeschauwer;Ignace Bruyland	2000	J. Electronic Imaging	10.1117/1.482728	image texture;computer vision;color image;watershed;computer science;segmentation-based object categorization;pattern recognition;diffusion;region growing;image segmentation;color space;scale-space segmentation;principal component analysis;computer graphics (images)	Vision	48.43071106305387	-68.43118033368113	186916
5862f72e65e044e3afc349902d746c0864fad91a	efficient active contour model based on vese-chan model and split bregman method	minimisation;piecewise constant techniques;image segmentation;mathematical model color numerical models level set computational modeling minimization active contours;image colour analysis;level set method active contour model multi phase image segmentation split bregman method;minimization problems active contour model split bregman method multiphase image segmentation color images piecewise constant multiphase vese chan model four phase level set formulation multiphase energy functional;piecewise constant techniques image colour analysis image segmentation minimisation	In this paper we propose an efficient multi-phase image segmentation for color images based on the piecewise constant multi-phase Vese-Chan model and the split Bregman method. The proposed model is first presented in a four-phase level set formulation and then extended to a multi-phase formulation. The four-phase and multi-phase energy functionals are defined and the corresponding minimization problems of the proposed active contour model are presented. The split Bregman method is applied to minimize the multi-phase energy functional efficiently. The proposed model has been applied to synthetic and real color images with promising results. The advantages of the proposed active contour model have been demonstrated by numerical results.	active contour model;bregman method;color depth;image segmentation;numerical analysis;synthetic intelligence	Yunyun Yang;Yi Zhao	2013	2013 Visual Communications and Image Processing (VCIP)	10.1109/VCIP.2013.6706370	computer vision;minimisation;mathematical optimization;computer science;pattern recognition;active contour model;mathematics;image segmentation;statistics	Vision	51.37766602615678	-71.25170664362513	187823
4ee8e22d7d6179a09451c8eb16ec5c4c3ae954b8	morphological component analysis: an adaptive thresholding strategy	algorithms artificial intelligence image enhancement image interpretation computer assisted principal component analysis reproducibility of results sensitivity and specificity;iterative method;traitement signal;morphological component analysis mca;metodo adaptativo;texture;adaptive thresholding;morphological component analysis;image segmentation;threshold detection;methode adaptative;image texture image segmentation;indexing terms;basis pursuit morphological component analysis adaptive thresholding strategy image texture;image texture;metodo iterativo;algorithme;algorithm;detection seuil;large scale;dictionnaire;deteccion umbral;sparse representations feature extraction morphological component analysis mca;analisis morfologico;iterative algorithms dictionaries morphology message oriented middleware pursuit algorithms image analysis image texture analysis large scale systems data mining harmonic analysis;methode iterative;feature extraction;signal processing;adaptive method;dictionaries;textura;morphological analysis;representacion parsimoniosa;analyse morphologique;basis pursuit;extraction caracteristique;sparse representation;procesamiento senal;diccionario;sparse representations;representation parcimonieuse;algoritmo	In a recent paper, a method called morphological component analysis (MCA) has been proposed to separate the texture from the natural part in images. MCA relies on an iterative thresholding algorithm, using a threshold which decreases linearly towards zero along the iterations. This paper shows how the MCA convergence can be drastically improved using the mutual incoherence of the dictionaries associated to the different components. This modified MCA algorithm is then compared to basis pursuit, and experiments show that MCA and BP solutions are similar in terms of sparsity, as measured by the lscr1 norm, but MCA is much faster and gives us the possibility of handling large scale data sets.	20-methylcholanthrene;adaptive grammar;algorithm;arabic numeral 0;basis pursuit;convergence (action);dictionary [publication type];experiment;handling (psychology);iteration;sparse matrix;thresholding (image processing)	Jérôme Bobin;Jean-Luc Starck;Mohamed-Jalal Fadili;Yassir Moudden;David L. Donoho	2007	IEEE Transactions on Image Processing	10.1109/TIP.2007.907073	image texture;computer vision;basis pursuit;index term;feature extraction;morphological analysis;computer science;machine learning;signal processing;pattern recognition;sparse approximation;mathematics;iterative method;thresholding;image segmentation;texture	Vision	52.794368697853656	-69.3348557309732	190688
96b8d408ce5053dfa3941b953cbb1ad6481e2364	erel: extremal regions of extremum levels	maximally stable extremal region mser;feature detection;extremal regions of extremum levels erel;stability criteria cleaning detectors benchmark testing feature extraction detection algorithms;feature detection erel extremal regions of extremum levels maximally stable extremal regions affine covariant region detector union find approach blur transformations maxima of gradient magnitudes;feature detection maxima of gradient magnitude mgm maximally stable extremal region mser extremal regions of extremum levels erel;maxima of gradient magnitude mgm;feature extraction computer vision	Extremal Regions of Extremum Levels (EREL) are regions detected from a set of all extremal regions of an image. Maximally Stable Extremal Regions (MSER) which is a novel affine covariant region detector, detects regions from a same set of extremal regions as well. Although MSER results in regions with almost high repeatability, it is heavily dependent on the union-find approach which is a fairly complicated algorithm, and should be completed sequentially. Furthermore, it detects regions with low repeatability under the blur transformations. The reason for the latter shortcoming is the absence of boundaries information in stability criterion. To tackle these problems we propose to employ prior information about boundaries of regions, which results in a novel region detector algorithm that not only outperforms MSER, but avoids the MSER's rather complicated steps of union-finding. To achieve that, we introduce Maxima of Gradient Magnitudes (MGMs) and use them to find handful of Extremum Levels (ELs). The chosen ELs are then scanned to detect their Extremal Regions (ER). The proposed algorithm which is called Extremal Regions of Extremum Levels (EREL) has been tested on the public benchmark dataset of Mikolajczyk [1]. Our experimental evaluations illustrate that, in many cases EREL achieves higher repeatability scores than MSER even for very low overlap errors.	algorithm;benchmark (computing);disjoint-set data structure;erdős–rényi model;gradient;maxima and minima;maximally stable extremal regions;repeatability;routh–hurwitz stability criterion	Mehdi Faraji;Jamshid Shanbehzadeh;Kamal Nasrollahi;Thomas B. Moeslund	2015	2015 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2015.7350885	computer vision;mathematical optimization;topology;computer science;machine learning;feature detection;mathematics;geometry	Vision	46.87042230340795	-66.39267941633977	190744
b9154a5f3b6b9ac01c722b7628471c7e3f9d48dd	automatic determination of the spread parameter in gaussian smoothing	filtering;filtrage;efficient algorithm;standard deviation;filtrado;methode gauss;scale space filtering;spread parameter;histogram;scale space;histogramme;gaussian smoothing;smoothing;gauss method;alisamiento;metodo gauss;histograma;lissage	The Gaussian filter is a very good filter for smoothing signals or images. The amount of smoothing depends on the value of the spread parameter (i.e., the standard deviation) of the Gaussian function. A heuristic and efficient algorithm to automatically determine the spread parameter for smoothing a given one-dimensional signal is proposed in this paper. The proposed algorithm uses an iterative process to compute a single spread parameter for smoothing the given signal. Only a small number of iterations are needed for smoothing most signals using the algorithm. Moreover, we extend the single-parameter Gaussian smoothing algorithm to multi-parameter smoothing for characterizing local variations of the signal. The algorithms are computationally fast and need no threshold. Experimental results show that the algorithms are indeed efficient and effective.	gaussian blur;smoothing	Hsin-Chih Lin;Ling-Ling Wang;Shi-Nine Yang	1996	Pattern Recognition Letters	10.1016/0167-8655(96)00082-7	filter;additive smoothing;computer vision;econometrics;mathematical optimization;scale space;computer science;gaussian blur;histogram;mathematics;standard deviation;statistics;smoothing;gauss–seidel method	Vision	53.13898031114604	-67.07342996508858	190808
ce7221ec9deb4d77e957247cf9b26dca1fbe94a7	image histogram thresholding using gaussian kernel density estimation (english)	silicon;kde;iterative method;probability gaussian processes image segmentation iterative methods pattern clustering;pattern clustering;kernel;otsu thresholding method image histogram thresholding gaussian mixture probability density function pdf gaussian kernel density estimation iterative method predecessor exhaustive search image segmentation;gaussian mixture;probability;image segmentation;image processing;gaussian processes;probability density function;silicon abstracts kernel;gaussian kernel image processing thresholding kde;iterative methods;abstracts;gaussian kernel;thresholding;pdf;predecessor;gaussian kernel density estimation;otsu thresholding method;image histogram thresholding;exhaustive search	In this article, image histogram thresholding is carried out using the likelihood of a mixture of Gaussians. In the proposed approach, a probability density function (PDF) of the histogram is computed using Gaussian kernel density estimation in an iterative manner. The threshold is found by iteratively computing a mixture of Gaussians for the two clusters. This process is aborted when the current bin is assigned to a different cluster than its predecessor. The method does not envolve an exhaustive search. Visual examples of our segmentation versus Otsu's thresholding method are presented.	brute-force search;image histogram;iterative method;kernel density estimation;mixture model;otsu's method;portable document format;thresholding (image processing)	Alexander Suhre;A. Enis Çetin	2013	2013 21st Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2013.6531341	image processing;histogram matching;machine learning;pattern recognition;balanced histogram thresholding;mathematics;iterative method;thresholding;statistics;image histogram	Vision	49.14207406131892	-68.42003666898005	190982
757c906204c0b9987d6931f92043a6076e2e6f8c	automatic target detection and tracking in flir image sequences using morphological connected operator	forward looking infrared image sequences;kernel;haar wavelet;wavelet transforms haar transforms image sequences infrared imaging object detection target tracking;mean shift;gray scale;wavelet transforms;adaptive double thresholding;infrared imaging;image reconstruction;pixel;image sequence;morphological connected operator;probabilistic density function automatic target detection target tracking forward looking infrared image sequences morphological connected operator airborne moving platform haar wavelet adaptive double thresholding;airborne moving platform;automatic target detection;target tracking;infrared;haar transforms;target tracking pixel image sequences gray scale image reconstruction kernel object detection;target detection;connected operator;density functional;probabilistic density function;object detection;image sequences	In this paper, we propose a method for detecting and tracking small targets in forward looking infrared (FLIR) image sequences taken from an airborne moving platform. Firstly, we adopt the morphological connected operator to remove the undesirable clutter in the background. Secondly, the image is decomposed by morphological Haar wavelet, and the wavelet energy image is computed from the horizontal and vertical detail images, and it is fused with the scaled image. Thirdly, the targets are extracted coarse-to-fine by adaptive double thresholding. Finally, targets are modeled by intensity probabilistic density function and tracked using mean shift algorithm. The experiments performed on the AMCOM FLIR data set verify the validity and robustness of the algorithm.	airborne ranger;algorithm;clutter;experiment;haar wavelet;mean shift;sensor;thresholding (image processing)	Chang'an Wei;Shouda Jiang	2008	2008 International Conference on Intelligent Information Hiding and Multimedia Signal Processing	10.1109/IIH-MSP.2008.193	iterative reconstruction;computer vision;kernel;speech recognition;infrared;mean-shift;pattern recognition;mathematics;pixel;grayscale;wavelet transform	Robotics	49.669998269972304	-67.70948587525606	192443
26d9725a27861274e50d1476d97ef0081868aa94	a robust algorithm for denoising meshes with high-resolution details	conference_paper;face neighborhood;high resolution details;mesh denoising;normal clustering;normal filtering	In this paper, we present a robust and efficient mesh denoising algorithm which preserves high-resolution details very well. Our method is a three-stage algorithm. Firstly, we modify a robust density-based clustering method and apply it to the face neighborhood of each triangular face to extract a subset of neighbors which belong to the same cluster as the central face. Because the faces within the extracted subset are not distributed across high-resolution details, we filter the central face normal iteratively within this subset to remove noise and preserve such details as much as possible. Finally, vertex positions are updated to be consistent with the filtered face normals using a least-squares formulation. Experiments on various types of meshes indicate that our method has advantages over previous surface denoising methods.	algorithm;cluster analysis;experiment;image resolution;least squares;noise reduction	Hanqi Fan;Qunsheng Peng;Yizhou Yu	2012		10.1007/978-3-642-34263-9_10	mathematical optimization;machine learning;data mining;mathematics	Graphics	46.91414007856969	-69.7358892748016	192492
0e3bca515b810939bc7a61b96dceb9a5fb93fda2	on bayes risk consistent pattern recognition procedures in a quasi-stationary environment	nearest neighbor searches;convergence;image segmentation;density measurement;probability density function;relaxation methods;random variables;layout;data mining;shape;pattern recognition image segmentation nearest neighbor searches random variables density measurement relaxation methods layout labeling probability density function;bayes risk;pattern recognition nonparametric procedures nonstationary environ ment orthogonal series;pattern recognition;asymptotic properties;nonparametric procedures;nonstationary environ ment;orthogonal series;labeling;random environment;reactive power	Van Ryzin and Greblicki showed that pattern recognition procedures derived from orthogonal series estimates of a probability density function are Bayes risk consistent. In this note it is proved that these procedures do not lose-under some additional conditions-their asymptotic properties even if the random environment is nonstationary.	estimated;pattern recognition;probability density;stationary process	Leszek Rutkowski	1982	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1982.4767201	layout;random variable;labeling theory;probability density function;convergence;shape;computer science;machine learning;pattern recognition;mathematics;ac power;image segmentation;statistics	Vision	48.97398453585386	-73.00009857007203	192575
1ceebded9e92c8c6a331eb3053b2428604ca917d	non-stationary fuzzy markov chain	modelizacion;markov chain model;chaine markov;cadena markov;deteccion multiespectral;image segmentation;image processing;detection multispectrale;modelo markov;classification non supervisee;triplet markov chain;bayes methods;methode bayes;procesamiento imagen;probabilistic approach;traitement image;statistical model;modelisation;markov model;triplet markov model;enfoque probabilista;approche probabiliste;multispectral images;clasificacion no supervisada;modele de markov triplet;segmentation image;signal classification;modele statistique;classification signal;unsupervised classification;modelo estadistico;fuzzy markov chain;modele markov;modeling;non stationary chain;multispectral image segmentation;multispectral detection;markov chain	This paper deals with a recent statistical model based on fuzzy Markov random chains for image segmentation, in the context of stationary and non-stationary data. On one hand, fuzzy scheme takes into account discrete and continuous classes through the modeling of hidden data imprecision and on the other hand, Markovian Bayesian scheme models the uncertainty on the observed data. A non-stationary fuzzy Markov chain model is proposed in an unsupervised way, based on a recent Markov triplet approach. The method is compared with the stationary fuzzy Markovian chain model. Both stationary and non-stationary methods are enriched with a parameterized joint density, which governs the attractiveness of the neighbored states. Segmentation task is processed with Bayesian tools, such as the well known MPM (Mode of Posterior Marginals) criterion. To validate both models, we perform and compare the segmentation on synthetic images and raw optical patterns which present diffuse structures. 2007 Elsevier B.V. All rights reserved.	image segmentation;markov chain;material point method;sensor;stationary process;statistical model;synthetic intelligence;triplet state;whole earth 'lectronic link	Fabien Salzenstein;Christophe Collet;Steven Le Cam;Mathieu Hatt	2007	Pattern Recognition Letters	10.1016/j.patrec.2007.07.002	markov chain;image processing;computer science;continuous-time markov chain;fuzzy number;machine learning;pattern recognition;mathematics;additive markov chain;markov model;statistics;variable-order markov model	AI	50.75796112349579	-69.6954177609944	192713
29ab2b8bd224b9c37f27218acce9f2b2434f55cf	markov random fields for pattern extraction in analog wafer test data		In semiconductor industry it is of paramount importance to check whether a manufactured device fulfills all quality specifications and is therefore suitable for being sold to the customer. The occurrence of specific spatial patterns within the so-called wafer test data, i.e. analog electric measurements, might point out on production issues. However, the shape of these critical patterns is unknown. In this paper different kinds of process patterns are extracted from wafer test data by an image processing approach using Markov Random Field models for image restoration. The goal is to develop an automated procedure to identify visible patterns in wafer test data to improve pattern matching. This step is a necessary precondition for a subsequent root-cause analysis of these patterns. The developed pattern extraction algorithm yields a more accurate discrimination between distinct patterns, resulting in an improved pattern comparison than in the original dataset. In a next step pattern classification will be applied to improve the production process control.	algorithm;circuit restoration;image processing;image restoration;map;markov chain;markov random field;pattern matching;pattern recognition;precondition;preprocessor;process patterns;semiconductor industry;test data;wafer testing	Stefan Schrunner;Olivia Bluder;Anja Zernig;Andre Kästner;Roman Kern	2017	2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)	10.1109/IPTA.2017.8310124	image restoration;artificial intelligence;precondition;markov random field;computer vision;image processing;random field;process patterns;pattern matching;pattern recognition;computer science;test data	Robotics	48.173688004343354	-66.49046946313668	192892
d754da802c7ca09736092147fadb21c33c27fdbc	multi-image morphing: summarizing visual information from similar ancient coin image regions	silicon;visualization integrated circuits training silicon mathematical model poisson equations optimization;ancient coin image classification task multi image morphing multiple source images automatic detection visual data summarization wear marks image registration sift flow functionalities markov random field visual content poisson equation smooths training image visual information ancient coin image regions;training;visualization;transforms data visualisation history image classification image morphing image registration markov processes poisson equation random processes;mathematical model;optimization;integrated circuits;poisson equations	The process of synthetically producing an image illustrating merged parts of multiple source images is usually known as image morphing. In this work a system is presented which morphs more than two source images to one output image. Its focus lies on using ancient coin images belonging to a common coin type. Nowadays, these coins can be worn or damaged. The goal of the presented morphing framework is the automatic detection and summarization of visual data of common regions by which outliers like wear marks of coins are removed. Since image registration forms the basis of the morphing system, SIFT flow functionalities are used. The selection of possible region-candidates is inferred by means of a Markov Random Field in order to find the best combination of visual content. Finally, solving the Poisson equation smooths the morphed image. An evaluation is carried out in which the system is applied to three different data sets in order to demonstrate visually aesthetic results. A second evaluation is done by investigating a classification task of ancient coin images. It is shown that substituting a morphed image as training image in the classification task improves the representation of a coin type compared to a single image.	autostereogram;image registration;markov chain;markov random field;morphing;scale-invariant feature transform	Stefan Hödlmoser;Sebastian Zambanini;Martin Kampel	2014	2014 International Conference on Virtual Systems & Multimedia (VSMM)	10.1109/VSMM.2014.7136662	computer vision;feature detection;visualization;image processing;computer science;artificial intelligence;machine learning;pattern recognition;mathematical model;silicon;automatic image annotation	Vision	48.239056855870224	-66.56054599433617	193493
326f8e3bc25a9dcedf7d998378f028b362064253	local log-euclidean covariance matrix (l2ecm) for image representation and its applications	covariance matrix;local image property;l2ecm image;local log-euclidean covariance matrix;spd matrix;various image cue;image gradient;multiple image cue;image representation;neighboring image property;diverse image;tensor-valued image	This paper presents Local Log-Euclidean Covariance Matrix (LECM) to represent neighboring image properties by capturing correlation of various image cues. Our work is inspired by the structure tensor which computes the second-order moment of image gradients for representing local image properties, and the Diffusion Tensor Imaging which produces tensor-valued image characterizing the local tissue structure. Our approach begins with extraction of raw features consisting of multiple image cues. For each pixel we compute a covariance matrix in its neighboring region, producing a tensor-valued image. The covariance matrices are symmetric and positive-definite (SPD) which forms a Riemannian manifold. In the Log-Euclidean framework, the SPD matrices form a Lie group equipped with Euclidean space structure, which enables common Euclidean operations in the logarithm domain. Hence, we compute the covariance matrix logarithm, obtaining the pixel-wise symmetric matrix. After half-vectorization we obtain the vector-valued LECM image, which can be flexibly handled with Euclidean operations while preserving the geometric structure of SPD matrices. The LECM features can be used in diverse image or vision tasks. We demonstrate some applications of its statistical modeling by simple second-order central moment and achieve promising performance.	automatic vectorization;image gradient;mixture model;pixel;statistical model;structure tensor	Peihua Li;Qilong Wang	2012		10.1007/978-3-642-33712-3_34	estimation of covariance matrices;computer vision;mathematical optimization;combinatorics;feature detection;u-matrix;image moment;mathematics;geometry	Vision	49.81284924771399	-70.49711311759567	194151
70e54a23e45a266b12614f8ca3a1cfe480e5fbac	pull-push level sets: a new term to encode prior knowledge for the segmentation of teeth images	relative position;level set;prior information;active region;individual object;prior knowledge;multiple objectives;teeth;level set method	This paper presents a novel level set method for contour detection in multiple-object scenarios applied to the segmentation of teeth images. Teeth segmentation from 2D images of dental plaster cast models is a difficult problem because it is necessary to independently segment several objects that have very badly defined borders between them. Current methods for contour detection which only employ image information cannot successfully segment such structures. Being therefore necessary to use prior knowledge about the problem domain, current approaches in the literature are limited to the extraction of shape information of individual objects, whereas the key factor in such a problem are the relative positions of the different objects composing the anatomical structure. Therefore, we propose a novel method for introducing such information into a level set framework. This results in a new energy term which can be explained as a regional term that takes into account the relative positions of the different objects, and consequently creates an attraction or repulsion force that favors a determined configuration. The proposed method is compared with balloon and GVF snakes, as well as with the Geodesic Active Regions model, showing accurate results.	active galactic nucleus;encode;problem domain	Rodrigo de Luis García;Raúl San José Estépar;Carlos Alberola-López	2005		10.1117/12.594060	computer vision;geography;artificial intelligence;communication	Vision	47.54731187167771	-70.97612499060199	194864
647871f28eca5485a7d24dd22917989ca2880f0a	bayesian tactile face	statistical sampling scheme;statistical sampling scheme bayesian tactile face graphical contents digital media tactile conversion human specialists human portrait image active shape model gradient profiles face images;bayes methods;training;bayesian inference;bayesian methods;human specialists;computational modeling;handicapped aids;face recognition;graphical contents;shape;digital media;image edge detection;bayesian tactile face;face modeling;haptic interfaces bayes methods face recognition handicapped aids;tactile conversion;human portrait image;visual impairment;face;bayesian methods image converters image edge detection humans active shape model computer graphics face detection deformable models image segmentation image sampling;face images;haptic interfaces;active shape model;graphics;gradient profiles	Computer users with visual impairment cannot access the rich graphical contents in print or digital media unless relying on visual-to-tactile conversion, which is done primarily by human specialists. Automated approaches to this conversion are an emerging research field, in which currently only simple graphics such as diagrams are handled. This paper proposes a systematic method for automatically converting a human portrait image into its tactile form. We model the face based on deformable active shape model (ASM) (Cootes et al., 1995), which is enriched by local appearance models in terms of gradient profiles along the shape. The generic face model including the appearance components is learnt from a set of training face images. Given a new portrait image, the prior model is updated through Bayesian inference. To facilitate the incorporation of a pose-dependent appearance model, we propose a statistical sampling scheme for the inference task. Furthermore, to compensate for the simplicity of the face model, edge segments of a given image are used to enrich the basic face model in generating the final tactile printout. Experiments are designed to evaluate the performance of the proposed method.	active shape model;algorithm;diagram;digital media;experiment;full scale;gradient;graphical user interface;graphics;information;maxima and minima;model-driven architecture;sampling (signal processing);user (computing)	Zheshen Wang;Xinyu Xu;Baoxin Li	2008	2008 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2008.4587374	active shape model;facial recognition system;face;computer vision;active appearance model;speech recognition;bayesian probability;shape;computer science;graphics;digital media;machine learning;mathematics;geometry;bayesian inference;computational model	Vision	49.73874406161854	-72.94735176260656	195726
ba6a9d567099892c08cd1fabd2c0c4f473b6e210	image modeling based on a 2-d stochastic subspace system identification algorithm	2-d roesser model;2-d stochastic realization theory;2-d subspace system identification;image modeling	Fitting a causal dynamic model to an image is a fundamental problem in image processing, pattern recognition, and computer vision. In image restoration, for instance, the goal is to recover an estimate of the true image, preferably in the form of a parametric model, given an image that has been degraded by a combination of blur and additive white Gaussian noise. In texture analysis, on the other hand, a model of a particular texture image can serve as a tool for simulating texture patterns. Finally, in image enhancement one computes a model of the true image and the residuals between the image and the modeled image can be interpreted as the result of applying a de-noising filter. There are numerous other applications within the field of image processing that require a causal dynamic model. Such is the case in scene analysis, machined parts inspection, and biometric analysis, to name only a few. There are many types of causal dynamic models that have been proposed in the literature, among which the autoregressive moving average and state-space models (i.e., Kalman filter) are the most commonly used. In this paper we introduce a 2-D stochastic state-space system identification algorithm for fitting a quarter plane causal dynamic Roesser model to an image. The algorithm constructs a causal, recursive, and separable-in-denominator 2-D Kalman filter model. The algorithm is tested with three real images and the quality of the estimated images are assessed.		José A. Ramos;Guillaume Mercère	2017	Multidim. Syst. Sign. Process.	10.1007/s11045-016-0385-4	image warping;computer vision;feature detection;binary image;machine learning;free boundary condition;pattern recognition;mathematics;anisotropic diffusion;top-hat transform;statistics	Vision	53.02092016044599	-66.39001752690727	195971
472753ea142b306bd339f5b6cb6728b00f579028	a variational level set method for multiple object detection	semi implicit scheme;distance function;image segmentation;level set;multiphase segmentation;energy function;multiple objectives;evolution equation;characteristic function;variational method;computational efficiency;level set method;object detection	A novel variational level set method for multiple object detection is presented, which uses  n  -1 level set functions for  n  -1 objects and the background without overlapping and vacuum problems. The energy functional includes three parts. The first part is a parametric region-based model via generic image noise distributions, the second part is the classic edge-based model, the third part is a term used to enforce the constraints of level set functions as signed distance functions. Characteristic functions for region partitioning are written in a unified form using Heaviside functions of level set functions. Some intermediate terms in evolution equations are extracted in a unified form for simplification of expressions and computation efficiency. The corresponding semi-implicit schemes are derived and used to some examples for segmentation of synthetic and real images to validate the method suggested in this paper.	object detection;variational principle	Zhenkuan Pan;Hua Li;Weibo Wei;Shuhua Xu	2008		10.1007/978-3-540-89646-3_72	computer vision;mathematical optimization;mathematical analysis;discrete mathematics;characteristic function;metric;computer science;variational method;level set;mathematics;image segmentation;level set method;statistics;level set	Vision	50.97708981957215	-71.06790747302935	196155
8abeab2ec3bb428c07daeaa5fe1199fdf2be9138	a new method for gaussian noise reduction in colour images by colour morphology			mathematical morphology;noise reduction	Francisco Ortiz	2006			gaussian noise;morphology (linguistics);physics;optics	Vision	51.221427114405216	-67.09183109593187	196196
5d1a0daa7e433a6461892f154729a32804b5cf24	large scale remote sensing image segmentation based on fuzzy region competition and gaussian mixture model		With the ever-increasing amount and complexity of remote sensing image data, the development of large-scale image segmentation analysis algorithms has not kept pace with the need for methods that improve the final accuracy of object recognition. In particular, the development of such methods for large-scale images poses a considerable challenge. Traditional image segmentation methods are of high time complexity and low segmentation accuracy. This paper presents a new large-scale remote sensing image segmentation method that combines fuzzy region competition and the Gaussian mixture model. The new algorithm defines a non-similarity measurement for the class attribute of pixels using the Gaussian mixture model. This algorithm has the ability to perform high precision fitting of data with a statistical distribution, thereby effectively eliminating the influence of noise on the segmentation result. Moreover, fuzzy region competition is introduced to define the prior probability of the neighborhood that will be regarded as the weight of the Gaussian component. This process enhances the robustness of large-scale image segmentation. Finally, we acquire the image data from Google Earth and conduct experiments; the experimental results show that this new method has the feasibility and effectiveness and can achieve highly accurate segmentation results compared with current state-of-the-art methods.	algorithm;experiment;google earth;html attribute;image segmentation;mixture model;outline of object recognition;pixel;time complexity	Shoulin Yin;Yingjie Zhang;Shahid Karim	2018	IEEE Access	10.1109/ACCESS.2018.2834960	mixture model;fuzzy logic;pixel;robustness (computer science);time complexity;prior probability;image segmentation;remote sensing;computer science;gaussian	Vision	46.84931733613807	-68.83575403691387	196259
46fa788c9eb9e7e31c8c16817e2f0b479154f14c	accurate image segmentation using gaussian mixture model with saliency map	image segmentation;gaussian mixture model;spatial information;saliency map;object recognition	Gaussian mixture model (GMM) is a flexible tool for image segmentation and image classification. However, one main limitation of GMM is that it does not consider spatial information. Some authors introduced global spatial information from neighbor pixels into GMM without taking the image content into account. The technique of saliency map, which is based on the human visual system, enhances the image regions with high perceptive information. In this paper, we propose a new model, which incorporates the image content-based spatial information extracted from saliency map into the conventional GMM. The proposed method has several advantages: It is easy to implement into the expectation–maximization algorithm for parameters estimation, and therefore, there is only little impact in computational cost. Experimental results performed on the public Berkeley database show that the proposed method outperforms the state-of-the-art methods in terms of accuracy and computational time.	algorithmic efficiency;berkeley db;computation;computer vision;estimation theory;expectation–maximization algorithm;experiment;google map maker;horner's method;image segmentation;mixture model;pixel;run time (program lifecycle phase);time complexity	Hui Bi;Hui Tang;Guanyu Yang;Huazhong Shu;Jean-Louis Dillenseger	2017	Pattern Analysis and Applications	10.1007/s10044-017-0672-1	artificial intelligence;mixture model;pattern recognition;pixel;human visual system model;image segmentation;mathematics;contextual image classification;saliency map;spatial analysis	Vision	50.418986326273284	-68.15551971602177	197051
1330cede3e7bf8d630d54c3f03c7e71b0a0dad7d	curvature estimation and curve inference with tensor voting: a new approach	perceptual grouping;computer vision;first order;stereo matching;image inpainting	Recently the tensor voting framework ( TVF  ), proposed by Medioni at al., has proved its effectiveness in perceptual grouping of arbitrary dimensional data. In the computer vision field, this algorithm has been applied to solve various problems as stereo-matching, boundary inference, and image inpainting. In the last decade the  TVF  was augmented with new saliency features, like curvature and first order tensors.#R##N##R##N#In this paper a new curvature estimation technique is described and its effectiveness, when used with the saliency functions proposed in [1], is demonstrated. Results are shown for synthetic datasets in spaces of different dimensionalities.		Gabriele Lombardi;Elena Casiraghi;Paola Campadelli	2008		10.1007/978-3-540-88458-3_55	computer vision;computer science;machine learning;pattern recognition;first-order logic;mathematics	Vision	53.06895616183053	-70.36581933939232	197054
6660f8fd34f775baf14d45cbb952645c97aa4d13	visibility-driven mesh analysis and visualization through graph cuts	sampling method;graph theory;visualization electronic mail face detection robustness sampling methods solid modeling geometry iterative algorithms algorithm design and analysis surface cracks;electronic mail;iterative algorithms;geometry;computational geometry;triangular mesh;index terms 8212;interior exterior classification;indexing terms;data visualisation;visualization;layer classification;sampling methods computational geometry data visualisation graph theory mesh generation;graph cut;solid modeling;sampling method visibility driven triangular mesh analysis data visualization graph cut computational geometry;data visualization;robustness;sampling methods;face detection;mesh generation;visibility driven triangular mesh analysis;algorithm design and analysis;index terms inside removal;index terms interior exterior classification;graph cut index terms 8212 interior exterior classification normal orientation layer classification inside removal;surface cracks;normal orientation;inside removal	In this paper we present an algorithm that operates on a triangular mesh and classifies each face of a triangle as either inside or outside. We present three example applications of this core algorithm: normal orientation, inside removal, and layer-based visualization. The distinguishing feature of our algorithm is its robustness even if a difficult input model that includes holes, coplanar triangles, intersecting triangles, and lost connectivity is given. Our algorithm works with the original triangles of the input model and uses sampling to construct a visibility graph that is then segmented using graph cut.	algorithm;cut (graph theory);graph - visual representation;graph cuts in computer vision;imagery;incised wound;mesh analysis;polygon mesh;sampling (signal processing);sampling - surgical action;visibility graph	Kaichi Zhou;Eugene Zhang;Jirí Bittner;Peter Wonka	2008	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2008.176	sampling;mathematical optimization;combinatorics;nested triangles graph;computer science;triangle mesh;mathematics;geometry;data visualization;statistics	Visualization	48.533547938991404	-67.24793485051633	197381
46e0b082bc47254071288c68148a49d21e7f45fb	a nonlinear multigrid diffusion model for efficient dense optical flow estimation	newton method image sequences image motion analysis;nonlinear optics image motion analysis nonlinear optical devices motion estimation relaxation methods acceleration optical coupling nonlinear equations optical devices gaussian processes;image motion analysis;gauss seidel newton method nonlinear multigrid diffusion model dense optical flow estimation multilevel nonlinear relaxation method nonlinear isotropic diffusion model optical flow coarse grid correction scheme;optical flow estimation;image sequence;diffusion equation;newton method;optical flow;is success;gauss seidel;diffusion model;image sequences	This paper presents a nonlinear multigrid isotropic diffusion model to estimate 2D dense motion. Multigrid provides an efficient multi-level nonlinear relaxation method that accelerates the evolution process of the nonlinear isotropic diffusion model. The resulting system of the two coupled nonlinear isotropic diffusion equations, for the two components of the optical flow, is successively transferred to coarser levels, and coarse-grid correction scheme is used to improve the performance. At each level, the Gauss-Seidel Newton method is used for nonlinear relaxation. Experimental results on both synthetic and real image sequences are reported to demonstrate the efficiency and accuracy of the proposed model.	multigrid method;nonlinear system;optical flow	Lixin Yang;Hichem Sahli	2005		10.1109/ICIP.2005.1529709	computer vision;diffusion equation;mathematical optimization;computer science;diffusion;optical flow;mathematics;geometry;newton's method;anisotropic diffusion;gauss–seidel method	Vision	52.952512554869045	-72.1581150736579	199832
