id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
7ae2806bac5e196752eb0eaaaa1a967cc6edc4c6	developing a new color model for image analysis and processing	communication system;image processing;real time;video processing;color model;time delay;image analysis;object identification	The theoretical outcomes and experimental results of new color model implemented in algorithms and software of image processing are presented in the paper. This model, as it will be shown below, may be used in modern real time video processing applications such as radar tracking and communication systems. The developed model allows carrying out the image process with the least time delays (i.e. it speeding up image processing). The proposed model can be used to solve the problem of true color object identification. Experimental results show that the time spent during RGI color model conversion may approximately four times less than the time spent during other similar models.	algorithm;color depth;color image;computer vision;digital image processing;fermat's principle;horizontal situation indicator;image analysis;image processing;radar;video processing	Rashad J. Rasras;Ibrahiem M. M. El Emary;Dimitri E. Skopin	2007	Comput. Sci. Inf. Syst.	10.2298/CSIS0701043R	computer vision;color model;image analysis;simulation;binary image;image processing;computer science;digital image processing;video processing;human visual system model;communications system;computer graphics (images)	Robotics	53.7382095383857	-60.08287309210367	158607
849676f5cab0c6378aff6f431ccf049200e7e9e5	part segmentation of slice data using regularity	objet;image processing;three dimensional shape;regularity;procesamiento imagen;object;segmentation;traitement image;forma tridimensional;slice data;image interpretation;interpretacion imagen;descripcion;forme tridimensionnelle;volumetric representations;interpretation image;description;objeto;segmentacion	This paper describes a two-stage technique for inferring part descriptions of articulated objects from parallel planar cross-sections or slices. First the data are segmented into significant components or parts, then sticks and blobs are fitted to the parts. We introduce a definition of ‘a part’ in the framework of regularity-based segmentation. The segmentation is completely model-independent. It exploits shape regularities to generate a set of perceptually plausible parts which can be described by any volumetric primitives. In contrast to several related approaches, bent parts can be successfully analyzed by our system. The volumetric primitives used in the modles are meant to be suggestive more than literal. An inferred model describes an object in terms of type, connectivity, position and orientation of its parts. Attractive features of the approach include simplicity, good generality and its treatment of bent parts. Experimental results are presented.		Emanuele Trucco	1993	Signal Processing	10.1016/0165-1684(93)90037-B	computer vision;image processing;computer science;object;mathematics;geometry;segmentation;engineering drawing	ML	50.62097205896528	-60.040814522426835	158616
71f5ab0a78890b6f3c3158cbe349e77626ae0a03	open curve segmentation via a two-phase scheme	curva;image processing;procesamiento imagen;courbe;courbure;segmentation;deux phases;curve;traitement image;accuracy;precision;wedge;pattern recognition;coin;curvatura;curvature;b spline;reconnaissance forme;reconocimiento patron;esquina;segmentacion	-A two-phase scheme is proposed for the segmentation of open curves. In the first phase, the curvature of each point of the curve is calculated based on the coordinates of five skipped points and the assumption that these five points form a B-spline curve. The points with significant curvatures are collected as candidate corners. During the second phase, the candidate comers are verified for deviations in the global trend of the curve. Those with small deviations are considered excessive and are removed. Application of the proposed method in the segmentation of a typical PCB (printed circuit board) curve, an aerial image of Medioni and Yasumoto (Comput. Vision Graphics Image Process. 39, 267-278 (1987)), and a multi-scale four-semicircle curve of Teh and Chin (IEEE Trans. Pattern Analysis Mach. Intell. PAMI-11, 859-872 (1989)) show that it is both minimal and accurate. Open curve Segmentation Corner Two-phase B-spline		Hsin-Teng Sheu;Hung-Zi Yang	1993	Pattern Recognition	10.1016/0031-3203(93)90180-5	computer vision;image processing;mathematics;geometry;accuracy and precision;statistics;curve fitting	Vision	47.050271250200296	-61.434366953975704	159164
730bfa20016b86f23986124dfe15c21f41b1983e	application of affine-invariant fourier descriptors to recognition of 3-d objects	transformation affine;affine invariant fourier descriptors;picture processing fourier analysis pattern recognition;espacio 3 dimensiones;picture processing;invarianza;boundary description;shearing robustness aircraft;3d object recognition;invariance;silhouettes 3d object recognition invariance affine invariant fourier descriptors boundary description affine transformation;fourier descriptors;robotersysteme;fourier transformation;espace 3 dimensions;affine transformation;silhouettes;three dimensional space;transformation fourier;estimacion parametro;pattern recognition;fourier analysis;reconnaissance forme;parameter estimation;estimation parametre;reconocimiento patron;transformacion afin;transformacion fourier	In this work, the method of Fourier descriptors has been extended to produce a set of normalized coefficients which are invariant under any affine transformation (translation, rotation, scaling, and shearing). The method is based on a parameterized boundary description which is transformed to the Fourier domain and normalized there to eliminate dependencies on the affine transformation and on the start-	coefficient;fast fourier transform;image scaling	Klaus Arbter;Wesley E. Snyder;Hans Burkhardt;Gerd Hirzinger	1990	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.56206	fourier transform;three-dimensional space;computer vision;topology;affine coordinate system;invariant;affine geometry of curves;affine hull;affine transformation;mathematics;geometry;fourier analysis;affine shape adaptation;estimation theory;affine combination	Vision	49.374734453799576	-60.4031371779624	159918
285b4b187aa40bae7e1630a61199956231206934	k × k thinning	iterative method;image processing;binary image;procesamiento imagen;segmentation;traitement image;metodo iterativo;algorithme;algorithm;afinamiento;automatic recognition;methode iterative;region;image binaire;pattern recognition;imagen binaria;amincissement;reconnaissance forme;reconocimiento patron;segmentacion;thinning;reconocimiento automatico;reconnaissance automatique;algoritmo	Abstract   A commonly used method for thinning regions in binary images consists of examining windows of 3 × 3 pixels throughout an image, and erasing the center pixel if the thinning criteria are met. The k × k  thinning method is a generalization of the 3 × 3 method, where k × k  sized windows are examined and a center core of (k − 2) × (k − 2)  pixels is erased if the criteria are met. The advantage of k × k  thinning is that, by peeling thicker layers from the boundaries of image regions, fewer iterations are required to reach the thinned result. For larger k , this is often at the cost of an increase in the coarseness of the result. Criteria are given by which the k × k  method thins to minimally 8-connected lines while retaining connectivity and endpoints. Sequential and parallel algorithms are given. A procedure to obtain line widths in the course of thinning is described. Examples are shown illustrating the reduction in iterations with increase of k , and the trade-off between size of k  and the coarseness of the result. Because of the highly repetitive, and local operations of the algorithm, it is straightforwardly mapped into VLSI hardware, and an example of this is given.	thinning	Lawrence O'Gorman	1990	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(90)90030-Y	computer vision;region;binary image;image processing;computer science;artificial intelligence;mathematics;iterative method;segmentation;algorithm	Vision	47.38818965493604	-64.03662988307867	160645
96a8779e66b67b22d2964f9fd87d244041d27e37	3-d multiview object representations for model-based object recognition	object representation;object recognition;modelo 3 dimensiones;propiedad;localizacion objeto;modele 3 dimensions;object location;three dimensional model;orientation;algorithme;sphere;modelisation;algorithm;algorritmo;pattern recognition;propriete;orientacion;identificateur;esfera;reconnaissance forme;properties;reconocimiento patron;modeling;localisation objet;identificador;modelaje;identifier	Abstract   3-D multiview object representations are presented as an alternative approach to traditional 3-D volumetric object representations. 3-D multiview models store features in a viewer-centered representation and thus can be immediately used to match features derived from 2-D images. Algorithms are presented that construct, search and perform region growing on 3-D multiview object models.	outline of object recognition	Matthew R. Korn;Charles R. Dyer	1987	Pattern Recognition	10.1016/0031-3203(87)90020-3	computer vision;systems modeling;object model;identifier;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;pattern recognition;mathematics;geometry;orientation;property;sphere	Vision	48.50199266990058	-59.121683651801966	161462
68aac357875662341dd804544a899d0935f3c76b	constant time joint bilateral filtering using joint integral histograms	histograms;psi_visics;joints;rm o 1 computational complexity;joint integral histograms jihs;image edge detection;computational complexity;data structures;ash;joint bilateral filtering;flash noflash images enhancement	In this brief, we present a constant time method for the joint bilateral filtering. First, we propose an image data structure, coined as joint integral histograms (JIHs). Extending the classic integral images and the integral histograms, it represents the global information of two correlated images. In a JIH, the value at each bin indicates an integral determined by the two images. Then, the joint bilateral filtering is transformed to computation and manipulation of histograms. Utilizing the JIHs, we are capable of joint bilateral filtering in constant time. Its performance is validated in a digital photography approach using Flash–noFlash image pairs. Compared with the brute-force method, the proposed method achieves a speedup factor of 2–3 orders of magnitude while producing similar filtering results.	bilateral filter;bin;brute-force search;computation;computer vision;data structure;digital photography;image editing;image processing;inspiration function;speedup;temporomandibular joint disorders;time complexity;orders - hl7publishingdomain	Ke Zhang;Gauthier Lafruit;Rudy Lauwereins;Luc Van Gool	2012	IEEE Transactions on Image Processing	10.1109/TIP.2012.2198220	computer vision;mathematical optimization;data structure;computer science;theoretical computer science;histogram;mathematics;computational complexity theory;algorithm;statistics	Vision	53.43163763760009	-64.06261954700557	161841
7bc790f9a8522349280b6436444e13c301529257	restoration of space-variant blurred image using a wavelet transform	transformation ondelette;restauration image;sous espace invariant;fonction etalement point;image restoration;multiresolution representation;analyse multiresolution;transformation orthogonale;restauracion imagen;transformacion ortogonal;wavelet transform;imagen borrosa;point spread function;blurred image;frequency data;invariant subspace;space variance;funcion distribucion punto;subespacio invariante;orthogonal transformation;transformacion ondita;image floue;multiresolution analysis;wavelet transformation;analisis multiresolucion	Abstract#R##N##R##N#This paper proposes a method to reconstruct a space-variant blurred image by using the wavelet transform, which is an orthogonal transform producing space-variant frequency data. A blurred image is divided into multiple resolutions by using a wavelet transform. As each resolution depends on the position of the image, this is corrected by applying a coefficient determined by a PSF parameter (the half-maximum width) so that the position-dependent frequency data are restored. The PSF in the blurred image is estimated to realize blind deconvolution. The method has been tested by a computer simulation and by a CCD camera using real images. The results show that the PSF in the blurred images can be estimated accurately when the images contain little noise. When the resolution of each blurred image is corrected by the estimated PSF parameter, it has been confirmed that the restoration was carried out depending on the degree of blurring.	circuit restoration;wavelet transform	Shoichi Hashimoto;Hideo Saito	1996	Systems and Computers in Japan	10.1002/scj.4690271409	multiresolution analysis;image restoration;computer vision;topology;computer science;difference of gaussians;point spread function;mathematics;geometry;algorithm;wavelet transform;orthogonal transformation	Robotics	53.0129085935324	-61.297617705567326	162098
351303ddf8c4fa57e43ca6bf2d6afe6b759a6a88	a normalized color difference edge detector based on quaternion representation	quaternion algebra;transforms edge detection convolution image colour analysis image representation;convolution;edge detection;normalized color difference edge detector;quaternion color difference edge detector;detectors quaternions image edge detection change detection algorithms convolution image representation filters image color analysis computer science algebra;quaternion representation;unit transform;color images;image colour analysis;image representation;transforms;unit transform normalized color difference edge detector quaternion representation quaternion color difference edge detector color images convolution color difference subspace quaternion algebra uniform transform image representation;color difference subspace;uniform transform;color image;image edge analysis	This paper presents the quaternion color difference edge detector, a new approach to detection of edges in color images. Based on a new type of convolution, the color difference subspace and the proposed edge detector are expressed analytically by using the algebra of the quaternion. The proposed color image edge detector generates edges only where sharp changes of color occur in the original image. The experimental results have verified the improved performance of the new edge detector compared to some well known methods.	edge detection	Canhui Cai;Sanjit K. Mitra	2000		10.1109/ICIP.2000.899834	color histogram;computer vision;edge detection;topology;color image;image gradient;computer science;deriche edge detector;quaternion algebra;mathematics;geometry;convolution;canny edge detector	Vision	52.21743211905915	-63.71857316555837	162344
3276b619c4a38981ff8aacbcb4e2111ecddc1b2b	spatial and temporal stability of hierarchically segmented regions for use as conjugate pairs in the estimation of depth and tracking				J. C. Woods	2003			conjugate;mathematics;mathematical optimization;artificial intelligence;pattern recognition	Vision	47.40156424367229	-66.13527474780115	162353
01c5266da1d379bafce5832787d1336db05b8a0f	n-dimensional skeletonization: a unified mathematical framework	electronic imaging	We present a skeletonization algorithm defined by ex- plicit Boolean conditions which are dimension independent. The pro- posed procedure leads to new thinning algorithms in two dimen- sions (2D) and three dimensions (3D). We establish the mathematical properties of the resulting skeleton referred to as the MB skeleton. From a topological point of view, we prove that the algorithm preserves connectivity in 2D and 3D. From a metric point of view, we show that the MB skeleton is located on a median hy- persurface (MHS) that we define. This MHS does not correspond to the standard notion of median axis/surface in 2D/3D, as it combines the various distances associated with the hypercubic grid. The MHS specificities prove to make the skeleton robust with respect to noise and rotation. Then we present the algorithmic properties of the MB skeleton: First, the algorithm is fully parallel, which means that no spatial subiterations are needed. This property, together with the symmetry of the Boolean n-dimensional patterns, leads to a per- fectly isotropic skeleton. Second, we emphasize the extreme con- ciseness of the Boolean expression, and derive the computational efficiency of the procedure. © 2002 SPIE and ISu0026T.	topological skeleton	Antoine Manzanera;Thierry M. Bernard;Françoise J. Prêteux;Bernard Longuet	2002	J. Electronic Imaging	10.1117/1.1506930	computer vision;computer science;data science	Theory	49.986965444222875	-62.75557949046871	162488
349f59075b2f38bfc3dfae7bd6a5c3f33275017e	using red-eye to improve face detection in low quality video images	gray image;image segmentation;image processing;optical reflection;edge detection;eye detection;infrared lighting;nonlinear image denoising;optical computing;gray image red eye effect face detection low quality video image infrared light image processing nonlinear image denoising image enhancement histogram stretch image thresholding edge detection;infrared imaging edge detection face recognition image denoising image enhancement image segmentation;image enhancement;eyes;face recognition;face detection lighting eyes infrared imaging infrared detectors optical reflection image analysis optical computing image processing image denoising;infrared imaging;low quality video image;image thresholding;image processing techniques;image analysis;red eye effect;image denoising;lighting;infrared;face detection;histogram stretch;infrared light;infrared detectors;infrared lighting red eye effect face detection	This paper presents a method to improve face detection by locating eyes in an image using infrared (IR) light, based on reflections due to the red-eye effect. The developed method analyzes two consecutive frames where the first one is taken under regular illumination with no IR and the second one using IR. The location of the eyes and the face contour are computed from the IR images using a collection of image processing techniques such as non-linear image denoising and enhancement, histogram stretch, image thresholding and edge detection. The algorithm operates successfully on low quality and low illumination gray images under a variety of skin tones, eye colors, angles, and illuminations, for subjects with and without glasses	algorithm;amiga reflections;color;edge detection;face detection;image processing;noise reduction;nonlinear system;reflection (computer graphics);thresholding (image processing)	Richard Youmaran;Andy Adler	2006	2006 Canadian Conference on Electrical and Computer Engineering	10.1109/CCECE.2006.277437	computer vision;image analysis;infrared;image processing;computer science;computer graphics (images)	Vision	53.57209591624919	-61.71973053995487	163498
502e79f5fcd05b46fa30f7e22b3b4082678a5658	cooperative vision integration through data-parallel neural computations	tratamiento paralelo;processing element;integrated approach;hopfield model;data parallel;modele hopfield;vision ordenador;regularisation;deterministic annealing;image segmentation;traitement parallele;neural nets;intensity contours;modelo hopfield;stereo disparity;coaccion;contrainte;neural network approach;optical computing neural networks optical coupling image motion analysis hopfield neural networks annealing computer vision concurrent computing robustness image segmentation;minimizacion funcion;methode calcul;energy function;regularization;computer vision;hopfield neural network;single instruction multiple data;algorithme;metodo calculo;calculating method;algorithm;hebbian adaptation;constraint;hopfield neural networks;function minimization;multiple early vision modules;massively parallel computer;single instruction multiple data mode;indexation;computerised picture processing;vision ordinateur;optical flow;regularizacion;data parallel neural computations;cooperative vision integration;reseau neuronal;local minima;image segmentation cooperative vision integration hopfield neural networks data parallel neural computations neural network approach multiple early vision modules intensity contours optical flow stereo disparity function minimization deterministic annealing hebbian adaptation massively parallel computer single instruction multiple data mode;red neuronal;parallel processing;neural nets computer vision computerised picture processing;minimisation fonction;neural network;algoritmo	The authors describe a neural network approach for combining processing of multiple early vision modules. Energy functions for coupling the computation of intensity contours, optical flow, and stereo disparity are defined. Hopfield neural networks are used for function minimization with deterministic annealing to avoid spurious local minima. Vision integration schemes are developed by extending the work of T.A. Poggio et al. (1988) to include cooperative interactions between different vision modules and the Hebbian adaptation of vision module coupling on a massively parallel computer consisting of 4096 processing elements operated in a single-instruction-multiple-data mode. Simple experiments assess the performance of various integration approaches. The resulting algorithms facilitate fast, robust image segmentation. >	computation;computational neuroscience	Scott T. Toborg;Kai Hwang	1991	IEEE Trans. Computers	10.1109/12.106222	regularization;computer vision;simd;computer science;artificial intelligence;machine learning;maxima and minima;optical flow;image segmentation;constraint;artificial neural network	Vision	47.35486600399128	-62.0577483832381	164150
b964a3ec330b7f9e3ec57251d51def557055a3e2	alternative strategies for irregular pyramid construction	edge detection;echantillonnage;deteccion contorno;sampling;forme pyramidale;detection contour;progressive edge formation;forma piramidal;imaging;specified rate sampling;pyramidal shape;formation image;formacion imagen;muestreo;prioritized sampling	In this paper, several alternative strategies for constructing irregular pyramids are proposed, namely, specified-rate sampling, prioritized sampling and progressive edge formation. When compared with the original scheme, these alternative strategies have shown to yield respectively pyramids in which the decimation ratio can be controlled by the application; with reduced height and pyramids which contains less nodes and edges in constructing the constituent graphs.		Horace Ho-Shing Ip;Stephen Wang-Cheung Lam	1996	Image Vision Comput.	10.1016/0262-8856(95)01050-5	medical imaging;sampling;computer vision;edge detection;topology;computer science;mathematics;geometry	Vision	47.447565082391954	-64.42842372619093	165054
4555fc9fa57e178776f0ea67e9a79b02fd831974	adjustment for discrepancies between als data strips using a contour tree algorithm	topology;airborne laser scanning;vision ordenador;laser sounding;image processing;sondeo laser;extraction forme;topologie;procesamiento imagen;intelligence artificielle;traitement image;topologia;computer vision;extraccion forma;courbe niveau;artificial intelligence;vision ordinateur;development methodology;sondage laser;inteligencia artificial;curva nivel;pattern extraction;contour line	In adjusting for discrepancies between adjacent airborne laser scanning (ALS) data strips, previous studies generally used conjugate features such as points, lines, and surface objects; however, irrespective of the types of features employed, the adjustment process relies upon the existence of suitable conjugate features within the overlapping area and the ability of the employed method to detect and extract the features. These limitations make the process complex and sometimes limit the applicability of developed methodologies because of a lack of suitable features in overlapping areas. To address these problems, this paper presents a methodology that uses the topological characteristics of the terrain itself, which is represented by a contour tree (CT). This approach provides a robust methodology without the restrictions involved in methods that employ conjugate features. Our method also makes the overall process of adjustment generally applicable and automated.	algorithm;contour line;strips	Dongyeob Han;Jaebin Lee;Yongil Kim;Kiyun Yu	2006		10.1007/11864349_93	computer vision;image processing;computer science;artificial intelligence;contour line	Robotics	48.41022287134032	-59.54220330967868	165200
01eee9e3c8d2856cab74fa8458fc1b004017d30a	computing the aspect graph for line drawings of polyhedral objects	analisis imagen;graph theory;proyeccion;geometry 3d object representation picture processing edge projection pattern recognition aspect graph line drawings polyhedral objects gaussian sphere accidental viewpoints vertex;imagen bidimensional;object recognition;vision ordenador;3d object representation;representation tridimensionnelle;polyedre;image segmentation;polyedron;poliedro;vertex;graphe aspect;geometry;computational geometry;picture processing;viewing data picture processing pattern recognition graph theory aspect graph line drawings polyhedral objects gaussian sphere;grafico aspecto;three dimensional;edge projection;computer vision;wire;algorithme;line drawings;aspect graph;algorithm;image interpretation;interpretacion imagen;shape;lisg;viewing data;projection;gaussian sphere;pattern recognition;image analysis;three dimensional representation;vision ordinateur;partitioning algorithms object recognition geometry shape computer science algorithm design and analysis;object recognition shape partitioning algorithms computer science computer vision wire image segmentation;accidental viewpoints;interpretation image;reconnaissance forme;computer science;reconocimiento patron;polyhedral objects;analyse image;image bidimensionnelle;representacion tridimensional;picture processing computational geometry graph theory pattern recognition;bidimensional image;partitioning algorithms;picture processing graph theory pattern recognition;algoritmo	An algorithm for computing the aspect graph for polyhedral objects is described. The aspects graph is a representation of three-dimensional objects by a set of two-dimensional views. The set of viewpoints on the Gaussian sphere is partitioned into regions such that in each region the qualitative structure of the line drawing remains the same. At the boundaries between adjacent regions are the accidental viewpoints where the structure for the line drawing changes. It is shown that for polyhedral objects there are two fundamental visual events: (1) the projections of an edge and a vertex coincide; and (2) the projections of three nonadjacent edges intersect at a point. The geometry of the object is reflected in the locus of the accidental viewpoints. The algorithm computes the partition together with a representative view for each region of the partition. >	polyhedral	Ziv Gigus;Jitendra Malik	1990	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.44399	three-dimensional space;vertex;computer vision;combinatorics;image analysis;projection;computational geometry;shape;computer science;graph partition;graph theory;cognitive neuroscience of visual object recognition;gaussian surface;machine learning;mathematics;geometry;image segmentation	Vision	49.16710798754801	-60.98601850295448	165496
b8cdcba726ef92ce2adf48a7f58832c37bdb11e5	matching for affine transformed pictures using hough planes	optimization problem;affine transformation	Considering the relationship between the deformation on Hough planes and the affine transformation on raw images, the authors have proposed a matching algorithm ; four-dimensional optimization problem to search rotation, scale, and two-translation parameters has been decomposed into two-stages of one-dimensional and one stage of twodimensional optimization problems. The algorithm achieves the reduction of calculating cost to search the four affine parameters. Furthermore, it works well on the images like human faces which are difficult to extract the feature points or segments since the Hough planes reflect global structure of straight lines on the raw images.	algorithm;hough transform;mathematical optimization;optimization problem	Atsushi Sakai;Yoshihiko Nomura;Yasunaga Mitsuya	1996			optimization problem;mathematical optimization;discrete mathematics;affine coordinate system;computer science;affine hull;affine transformation;harris affine region detector;mathematics;geometry;affine shape adaptation;affine combination	Vision	48.415910331466584	-62.37256829357416	165578
175c7bf16f895a3f80b914329b4d878156d38aa8	block matching integrating intensity, hue, and range	range data;image processing;procesamiento imagen;metric;satisfiability;traitement image;pattern matching;motion vector;correspondencia bloque;block matching;metrico;concordance forme;correspondance bloc;metrique;block matching algorithm	In this paper, we propose a new block matching algorithm that extracts motion vectors from consecutive range data. The proposed method defines a matching metric that integrates intensity, hue and range. Our algorithm begins matching with a small matching template. If the matching degree is not good enough, we slightly expand the size of a matching template and then repeat the matching process until our matching criterion is satisfied or the predetermined maximum size has been reached. As the iteration proceeds, we adaptively adjust weights of the matching metric by considering the importance of each feature.		Seok-Woo Jang;Marc Pomplun;Min C. Shin	2003		10.1007/978-3-540-45243-0_57	combinatorics;discrete mathematics;template matching;metric;image processing;computer science;pattern matching;pattern recognition;mathematics;block-matching algorithm;programming language;matching pursuit;satisfiability	Vision	47.319430447224036	-63.46749357842259	166217
c4a46fc9269f564a64173f5a8f5ea58fc5a618b6	junction and corner detection through the extraction and analysis of line segments	analisis imagen;graph theory;corner detection;teoria grafo;modele geometrique;image processing;metodo combinatorio;procesamiento imagen;internal structure;methode combinatoire;jambe;segmentation;classification;theorie graphe;traitement image;geometric approach;pierna;local structure;segment droite;analyse combinatoire;segmento recta;combinatorial method;image analysis;line segment;estructura local;structure locale;graph model;analyse image;clasificacion;segmentacion;leg;analisis combinatorio;combinatorial analysis;geometrical model;modelo geometrico	An algorithm is presented that analyzes the edge structure in images locally, using a geometric approach. A local edge structure that can be interpreted as a corner or a junction is assumed to be representable by a set of line segments. In a first step a segmentation of the local edge structure into line segments is evaluated. This leads to a graph model of the local edge structure, which can be analyzed further using a combinatorial method. The result is a classification as corner or junction together with the absolute orientation and internal structure, like the opening angle of a corner, or the angles between the legs of a junction. Results on synthetic and real data are given.	3d single-object recognition;algorithm;cvpr;cluster analysis;computer vision;corner detection;edge detection;gradient;lecture notes in computer science;outline of object recognition;pattern recognition;resultant;scale space;sensor;springer (tank);structure tensor;synthetic intelligence	Christian Perwass	2004		10.1007/978-3-540-30503-3_42	corner detection;computer vision;image analysis;topology;line segment;image processing;biological classification;computer science;graph theory;mathematics;geometry;segmentation	Vision	49.06439409674446	-60.04653266618663	166545
f3c9ac8cdeb0a7b147f4f2871ba0b53eec44ed42	recursive binary dilation and erosion using digital line structuring elements in arbitrary orientations	analisis imagen;methode recursive;maximum operation;evaluation performance;mathematical morphology;morfologia matematica;arbitrary orientations;probability;two pass algorithms;algorithm performance;performance evaluation;image processing;transformacion matematica;concepcion sistema;forme onde;complexite calcul;binary image;recursive binary erosion;salt and pepper noise images;morphology morphological operations shape discrete transforms pixel testing sun set theory image reconstruction acoustic noise;estudio comparativo;evaluacion prestacion;algoritmo recursivo;mathematical transformation;discrete line;speed up;experiment protocol;dilatacion;metodo recursivo;procesamiento imagen;recursive method;morphological operation;testing;orientation;set theory;indexing terms;traitement image;experimental result;etude comparative;complejidad computacion;morphology;erosion;estimation erreur;forma onda;morphological operations;algorithme recursif;shape;discrete transforms;error estimation;computational complexity;resultado algoritmo;system design;image reconstruction;dilation transform;acoustic noise;brute force;pixel;continuous line;dilatation;estimacion error;erosion transform;image binaire;transformation mathematique;comparative study;transforms;performance algorithme;sun;resultado experimental;brute force recursive binary dilation recursive binary erosion digital line structuring elements arbitrary orientations morphological operations binary images two pass algorithms constant time algorithms orientation error continuous line discrete line erosion transform dilation transform maximum operation thresholding sun sparc station 10 salt and pepper noise images probability pixel reflected structuring element speed up experiment protocol;reflected structuring element;imagen binaria;orientacion;binary images;image analysis;recursive binary dilation;recursive algorithm;thresholding;waveform;transforms image processing mathematical morphology;constant time algorithms	Performing morphological operations such as dilation and erosion of binary images, using very long line structuring elements is computationally expensive when performed brute-force following definitions. We present two-pass algorithms that run at constant time for obtaining binary dilations and erosions with all possible length line structuring elements, simultaneously. The algorithms run at constant time for any orientation of the line structuring element. Another contribution of this paper is the use of the concept of orientation error between a continuous line and its discrete counterpart. The orientation error is used in determining the minimum length of the basic digital line structuring element used in obtaining what we call dilation and erosion transforms. The transforms are then thresholded by the length of the desired structuring element to obtain the dilation and erosion results. The algorithms require only one maximum operation for erosion transform and only one minimum operation for dilation transform, and one thresholding step and one translation step per result pixel. We tested the algorithms on Sun Sparc Station 10, on a set of 240x250 salt and pepper noise images with probability of a pixel being a 1-pixel set to 0.25, for orientations of the normals of the structuring elements in the range [pi/2,3pi/2] and lengths, in pixels, in the range [5,145]. We achieved a speed up of about 50 (and for special orientations theta in {(pi/2), (3pi/4), pi, (5pi/4), (3pi/2)} a speed up of about 100) when the structuring elements had lengths of 145 pixels, over the brute-force methods in these experiments. We compared the results of our dilation algorithm with those of the algorithm discussed by Soille et al. (see IEEE Trans. Pattern Anal. Machine Intell., vol.18, p.562-67, 1996) and showed that for binary dilation (and erosion since it is just the dilation of the background with the reflected structuring element) our algorithm performed better and achieved a speed up of about four when dilation or erosion transform alone is obtained.	analysis of algorithms;approximation algorithm;binary image;comstock–needham system;dilate procedure;dilation (morphology);erosion (morphology);experiment;hl7publishingsubsection <operations>;long line (telecommunications);mathematical morphology;mental orientation;pathological dilatation;pixel;recursion (computer science);sparc;salt-and-pepper noise;structuring element;thresholding (image processing);time complexity	Desikachari Nadadur;Robert M. Haralick	2000	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.841511	computer vision;image analysis;morphology;binary image;image processing;computer science;mathematics;dilation;algorithm;statistics	Vision	47.79232455895319	-63.56849925977082	167093
370dc25286da39e3019808e876a83713c8d200b1	projective-space colour filters using quaternion algebra	image color analysis vectors quaternions europe signal processing geometry;vector filter projective space colour filters mapping colour image pixels euclidean vectors colour image processing projective space mapping colour space euclidean geometry operations colour image operations;image colour analysis algebra filtering theory	Instead of mapping colour image pixels into Euclidean vectors as is conventionally done in colour image processing, we present the idea of using projective space mapping based on homogeneous coordinates. This approach offers a much richer set of geometric operations in the colour space compared to the Euclidean geometry operations that exist in classical colour spaces. The projective geometry of points (pixel values) is described and compared to the classical Euclidean view of pixel values as vectors. The use of homogeneous coordinates is introduced and the geometric operations that are possible are outlined. Then it is shown how colour image pixel values may be transformed into and out of homogeneous coordinates, based on a representation in both cases using quaternions. We then show some examples of colour image operations that offer potential for new types of vector filter and we discuss the possibilities.	color image;color space;image processing;pixel;space mapping	Todd A. Ell;Stephen J. Sangwine	2008	2008 16th European Signal Processing Conference		homogeneous coordinates;computer vision;topology;mathematics;geometry	Vision	52.04322523384811	-63.94267737759963	167789
91ab1f08387e05068ab077b28d94b07cd2b84c2e	region merging in 3-d images using morphological operators	analisis imagen;mathematical morphology;vision ordenador;morfologia matematica;espacio 3 dimensiones;morphological operation;computer vision;enrejado;erosion;treillis;espace 3 dimensions;three dimensional space;pattern recognition;image analysis;vision ordinateur;reconnaissance forme;reconocimiento patron;analyse image;region merging;morphologie mathematique;lattice	Abstract   3-D image surfaces are characterized by their orientations using the concept of Neighborhood Plane Sets (NPS). Lattice based morphological operations are defined. A region merging scheme is proposed applying the morphological operators on the NPS images.	mathematical morphology	S. S. Biswas;A. K. Ray	1993	Pattern Recognition Letters	10.1016/0167-8655(93)90129-2	three-dimensional space;computer vision;image analysis;morphological skeleton;mathematical morphology;erosion;computer science;artificial intelligence;lattice	Vision	48.72982655426738	-61.37333499126508	168084
7f15b383073f13ef6bbb833b133f5fb941782a5d	projectively invariant decomposition and recognition of planar shapes	iterative method;decomposition;forma planaria;projective invariance;edge detection;forme convexe;convex shape;low complexity;imagen nivel gris;forma convexa;calculo automatico;computing;higher order;deteccion contorno;metodo iterativo;calcul automatique;detection contour;planar form;indexing;contact point ellipse;methode iterative;smoothing;indexation;image niveau gris;indizacion;alisamiento;pattern recognition;invariante;forme planaire;reconnaissance forme;descomposicion;reconocimiento patron;projective transformation;computational efficiency;grey level image;lissage;invariant	An algorithm is presented for computing a decomposition of planar shapes into convex subparts represented. by ellipses. The method is invariant to projective transformations of the shape, and thus the conic primitives can be used for matching and definition of invariants in the same way as points and lines. The method works for arbitrary planar shapes admitting at least four distinct tangents and it is based on finding ellipses with four points of contact to the given shape. The cross ratio computed from the four points on the ellipse can then be used as a projectively invariant index. It is demonstrated that a given shape has a unique parameter-free decomposition into a finite set of ellipses with unit cross ratio. For a given shape, each pair of ellipses can be used to compute two independent projective invariants. The set of invariants computed for each ellipse pair can be used as indexes to a hash table from which model hypothesis can be generated Examples of shape decomposition and recognition are given for synthetic shapes and shapes extracted from grey level images of real objects using edge detection.	algorithm;edge detection;graph (discrete mathematics);grayscale;hash table;planar (computer graphics);synthetic intelligence	Stefan Carlsson	1996	International Journal of Computer Vision	10.1007/BF00058751	computer vision;combinatorics;computing;edge detection;topology;computer science;invariant;shape analysis;mathematics;geometry;iterative method;decomposition;smoothing	Vision	49.27650068381602	-60.30870408915255	168447
9d4648358f5c070cf8412d92a6c7eedfe3f3ff96	contour estimation by array processing methods	signal image and speech processing;velocidad propagacion;array processing;high resolution;image processing;image resolution;signal distortion;procesamiento imagen;propagation velocity;array signal processing;metodo subespacio;distorsion signal;problema inverso;qualite image;transformacion hough;traitement image;methode sous espace;algorithme;algorithm;haute resolution;resolucion imagen;quantum information technology spintronics;varying speed;inverse problem;traitement signal reseau;image quality;velocidad variable;prediccion lineal;alta resolucion;subspace method;hough transformation;calidad imagen;transformation hough;linear prediction;vitesse variable;probleme inverse;resolution image;vitesse propagation;prediction lineaire;algoritmo;distorsion senal	This work is devoted to the estimation of rectilinear and distorted contours in images by high-resolution methods. In the case of rectilinear contours, it has been shown that it is possible to transpose this image processing problem to an array processing problem. The existing straight line characterization method called subspace-based line detection (SLIDE) leads to models with orientations and offsets of straight lines as the desired parameters. Firstly, a high-resolution method of array processing leads to the orientation of the lines. Secondly, their offset can be estimated by either the well-known method of extension of the Hough transform or another method, namely, the variable speed propagation scheme, that belongs to the array processing applications field. We associate it with the method called “modified forward-backward linear prediction” (MFBLP). The signal generation process devoted to straight lines retrieval is retained for the case of distorted contours estimation. This issue is handled for the first time thanks to an inverse problem formulation and a phase model determination. The proposed method is initialized by means of the SLIDE algorithm.	algorithm;array processing;computer simulation;contour line;edge detection;gradient method;hough transform;image processing;image resolution;mathematical optimization;numerical analysis;recursion (computer science);regular grid;software propagation;spectral density estimation;whole earth 'lectronic link	Salah Bourennane;Julien Marot	2006	EURASIP J. Adv. Sig. Proc.	10.1155/ASP/2006/95634	computer vision;image resolution;image processing;computer science;mathematics;geometry;algorithm	Vision	53.207265737884256	-61.00578248576415	169716
9369a713c8970aa711426eba2fb417c712404d87	an automatic focusing algorithm	article	A simple and effective automatic focusing algorithm is proposed in this article. The principle of the proposed automatic focusing algorithm is based on that, for the radial test pattern, a best-focused image should have the smallest blurred region in the middle of the acquired image, and hence, should have the smallest equivalent radius. The circular Hough transform has became a common method in numerous image-processing applications for circle detection. Various modifications to the basic circular Hough transform have been suggested, such as: the inclusion of edge orientation, simultaneous consideration of a range of circle radii, the use of a complex accumulator array with the phase proportional to the log of the radius, or for filter operations. The purpose of this work is to show that a radius of a circular region extracted by a normalized circular Hough transform is a possible solution for determining the sharpness of images. To acquire high quality images with a given CCD camera, it is crucial that the camera be located exactly at the back length of the lens, i.e., the focus position of the lens. In the best conditions, the contours of the acquired images are of the sharpest, with none of the blurring effects associated with unfocused images. Acquiring such high quality images by these means is the main goal of the automatic focusing algorithm proposed in this article. © 2003 Wiley Periodicals, Inc. Int J Imaging Syst Technol, 12, 235–238, 2002; Published online in Wiley InterScience (www.interscience.wiley.com). DOI 10.1002/ima.10029	accumulator (computing);algorithm;charge-coupled device;display resolution;hough transform;image processing;john d. wiley;radial (radio);test card	Sheng-Fuu Lin;You-Tasi Lin;Chien-Kun Su	2002	Int. J. Imaging Systems and Technology	10.1002/ima.10029	hough transform;computer vision;computer science;optics;computer graphics (images)	Vision	47.13815357760282	-64.66612354086456	169925
97224f92b11fa0332245e2dcfd3e38c694fea41b	compactly supported non-uniform spline wavelet for irregularly sub-sampled image representation	image sampling;spline image representation multiresolution analysis wavelet analysis signal resolution filter bank motion estimation polynomials tensile stress surface waves;filter bank;image resolution;two dimensional multiresolution;wavelet non uniform b spline two dimensional multiresolution;indexing terms;satisfiability;splines mathematics;wavelet transforms;channel bank filters;image representation;spline function;image grid spline wavelet image representation subsampling two dimensional multiresolution analysis b spline function orthonormalization orthogonal decomposition filter bank;wavelet transforms channel bank filters image representation image resolution image sampling splines mathematics;multiresolution analysis;wavelet;non uniform b spline	This paper investigates the mathematical framework of the two-dimensional multiresolution analysis adapted to irregularly spaced data. This two-dimensional multiresolution is related on separable multiresolution analysis using non-uniform B-spline functions. For any arbitrary degree of the spline function, we propose an orthonormalization procedure of the scaling and wavelet bases. These orthonormal basis functions satisfy the important features required by a traditional multiresolution analysis such as: (i) the continuity conditions of the scaling and wavelet functions and (ii) the compact support of the scaling and wavelets functions. We show that the orthogonal decomposition is implemented using filter banks where the coefficients depend on the location of the samples on the image grid.	b-spline;basis function;coefficient;data compression;filter bank;finite element method;image scaling;multiresolution analysis;scott continuity;spline (mathematics);spline wavelet	Anissa Zergaïnoh-Mokraoui;Pierre Duhamel	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312655	multiresolution analysis;spline;wavelet;computer vision;mathematical optimization;mathematical analysis;index term;image resolution;computer science;filter bank;mathematics;fast wavelet transform;algorithm;statistics;wavelet transform;satisfiability	Robotics	52.630833341464154	-65.83947568670607	170653
d5b7487eb98d3ddaddc7f29a444fc62d3398c0b2	a novel approach for detection of edges in range images using splines	three dimensional;smoothing spline;edge detection;region growing;second order;statistical test	In this paper we propose an approach for detection of edges of range images using a local statistics for detection of crease edges. The jump edges are first located using the ratio of the slopes as a measure. For the detection of crease edges, curvature is estimated a t all the data points using the first and second order derivatives of the smoothing spline. The local maximas of curvature are considered as the candidates for the crease edges. This condition is not a very strong constraint, as a result of which a large number of pixels are marked as crease edges. A statistical test is done over the image, and the distribution of the curvature values within a window is used for the detection of crease edges.	data point;pixel;smoothing spline;spline (mathematics)	Satish Kaveti;Eam Khwang Teoh;Han Wang	1994			three-dimensional space;computer vision;statistical hypothesis testing;edge detection;topology;smoothing spline;mathematics;geometry;region growing;marr–hildreth algorithm;second-order logic;statistics	Vision	47.98460223665555	-65.44520704161043	172084
e95b4d754ad53bf5ad6ce3ae1ad070e4503c4600	coarse to over-fine optical flow estimation	traitement signal;estimation mouvement;flux optique;methode echelle multiple;estimacion movimiento;simulation;optical flow estimation;simulacion;motion estimation;metodo escala multiple;optical o w;algorithme;algorithm;accuracy;precision;estimation erreur;campo flujo;flujo optico;theoretical analysis;error estimation;flow field;erreur estimation;signal processing;estimacion error;champ ecoulement;error estimacion;multiscale method;optical flow;estimation error;procesamiento senal;algoritmo	We present a readily applicable way to go beyond the accuracy limits of current optical flow estimators. Modern optical flow algorithms employ the coarse to fine approach. We suggest to upgrade this class of algorithms, by adding over-fine interpolated levels to the pyramid. Theoretical analysis of the coarse to over-fine approach explains its advantages in handling flow-field discontinuities and simulations show its benefit for sub-pixel motion. By applying the suggested technique to various multiscale optical flow algorithms, we reduced the estimation error by 10%-30% on the common test sequences. Using the coarse to over-fine technique, we obtain optical flow estimation results that are currently the best for benchmark sequences.	algorithm;benchmark (computing);interpolation;optical flow;pixel;simulation;way to go	Tomer Amiaz;Eyal Lubetzky;Nahum Kiryati	2007	Pattern Recognition	10.1016/j.patcog.2006.09.011	computer vision;econometrics;computer science;signal processing;accuracy and precision;statistics	Vision	51.751012079024136	-59.12516456973406	172656
f200920ecabcc8391c4fa34319e8d37450a41c19	scanning-curves representation for the coverage of surfaces using chain coding	chain code;surface representation;digital elevation model;three dimensional;digital image	We present a novel and interesting method for representing scanning curves for the coverage of surfaces by means of chain coding. We describe scanning curves for the coverage of surfaces using a chain code. Thus, scanning curves are composed of constant straight-line segments using only orthogonal directions and are represented by means of the orthogonal direction change chain code, which can describe three-dimensional curves. Surfaces which are represented using the orthogonal direction change chain code are called discrete surfaces. The chain elements represent the orthogonal direction changes of the constant straight-line segments of the scanning curve for the coverage of a surface. There are only five possible orthogonal direction changes for representing any scanning curve. This chain code only considers relative direction changes, which allows us to have a unique surface descriptor invariant under translation and rotation. Also, this surface descriptor may be invariant under starting point and mirroring transformations. Finally, in order to demonstrate the use of our proposed method, we present some results using surfaces from digital elevation model data and digital images. r 2002 Elsevier Science Ltd. All rights reserved.	chain code;computational anatomy;digital elevation model;digital image;disk mirroring;edge detection;erik proper;langrisser schwarz;numerical analysis	Ernesto Bribiesca	2003	Computers & Graphics	10.1016/S0097-8493(02)00250-9	three-dimensional space;computer vision;discrete mathematics;topology;digital elevation model;computer science;mathematics;geometry;chain code;digital image	Graphics	49.224533920752776	-61.6557491469922	172695
a87ae9cf3393ca561c307e878e6255afa6c37e0c	a split and merge procedure for polygonal border detection of dot pattern	image processing;capsula convexa;time complexity;edge detection;programme fusion;polygone;procesamiento imagen;punto;traitement image;programa fusion;deteccion contorno;enveloppe convexe;algorithme;polygon;algorithm;detection contour;point;complexite temps;dot;parallel systems;smoothing;alisamiento;poligono;complejidad tiempo;convex hull;lissage;merge routine;algoritmo	An approach to find the polygonal border of a dot pattern is proposed. The procedure starts with a convex hull of the dot pattern and obtains the final border by the process of splitting followed by merging. During splitting one or more sides of the convex hull are deleted and new sides are added to take care of the inherent concavity. To obtain a smooth polygonal border, two or more sides are merged into a single one. An advantage of the procedure is that the user can set a priori the number of sides of the polygon. Also, it works quite well if there is a gradual transition of dot density in the pattern. Given the convex hull, the procedure can be executed in O(nm) time for a pattern consisting of n dots and an m-sided polygonal border. Moreover, the procedure can be implemented in a parallel system as the operations on each side of the convex hull polygon are independent as well as localised.	edge detection	Gautam Garai;Bidyut Baran Chaudhuri	1999	Image Vision Comput.	10.1016/S0262-8856(98)00089-4	computer vision;image processing;computer science;convex hull;polygon;polygonal chain;mathematics;geometry;centered polygonal number;algorithm	Vision	47.51786341714542	-64.00310664429911	172875
acb83e11d0d983b3150795c271f4dcf90cedb9dd	implementation of a 3d vision system on dsps tms320c31	vision system;dynamic programming;metodo adaptativo;evaluation performance;programacion dinamica;image segmentation;performance evaluation;modelo 3 dimensiones;traitement image stereoscopique;systeme aide decision;vision estereoscopica;etude experimentale;modele 3 dimensions;evaluacion prestacion;vision stereoscopique;three dimensional model;dynamic method;methode adaptative;dynamic program;segmentation;sistema ayuda decision;algorithme;algorithm;decision support system;stereo matching;methode dynamique;adaptive method;stereo image processing;stereo vision;programmation dynamique;metodo dinamico;computer hardware;3d vision;stereopsis;real time application;estudio experimental;materiel informatique;material informatica;segmentacion;algoritmo	In this paper, the implementation of a new stereo vision process on a specialized architecture which comprises of three DSPs TMS320C31 is described. The first step of our stereo vision system is a self-adaptive image segmentation algorithm based on a new concept that we call declivity. The second step is a new and fast stereo matching algorithm based on dynamic programming and using self-adaptive decision parameters. The goal of our work is to develop a stereo vision system that achieves an acceptable level of performance using a modest amount of hardware. This implementation is organized as follows: declivity extraction from the two stereo images is performed in parallel on two DSPs, one for the right image and the other for the left one. Then, the last DSP computes the declivity matching based on our dynamic programming method as well as the 3D maps calculation. Finally, experimental results obtained using real pairs of stereo images on a VME 150/40 Imaging Technology Vision System are presented. They show the feasibility and the effectiveness of our system. These results can surely be improved by using a new generation of DSP in order to consider real-time applications.		Abdelaziz Bensrhair;N. Chafiqui;Pierre Miché	2000	Real-Time Imaging	10.1006/rtim.1998.0166	computer stereo vision;stereo cameras;computer vision;simulation;decision support system;computer science;stereopsis;artificial intelligence	Vision	47.081437414711466	-61.35595386036132	173016
726491110138619df83f977d813dd94fc6131d58	an optimal set of image segmentation rules	analyse scene;image segmentation;rule based systems;segmentation;computer vision;artificial intelligence;image analysis;vision ordinateur;systeme expert;systeme base regle;analyse image;scene analysis;symbolic representation;expert system	A set of rules for segmenting images was selected based on a quantitative evaluation of performance using a rule-based system. This note presents the rules and summarizes the results of their application.	image segmentation	Martin D. Levine;Ahmed M. Nazif	1984	Pattern Recognition Letters	10.1016/0167-8655(84)90032-1	computer vision;image analysis;computer science;artificial intelligence;machine learning;segmentation-based object categorization;image segmentation;scale-space segmentation;segmentation;expert system	Vision	46.91549932984509	-61.114639286216196	174649
d57cab890c5b66ad0d21aa0bbdcf5dd74b783610	new binary morphological operations for effective low-cost boundary detection	mathematical morphology;morfologia matematica;image segmentation;image processing;binary image;edge detection;conditional operation;low complexity operations;procesamiento imagen;morphological operation;low complexity;traitement image;deteccion contorno;detection contour;erosion;morphological operations;operation conditionnelle;segmentation image;image binaire;imagen binaria;dilation;boundary detection;hardware implementation;flip flop;morphologie mathematique	In this paper, new operational definitions of binary morphological, both conditional and non-conditional, operations are proposed. The new operations are applied to detect boundary points from binary images. Comparisons of boundary detection algorithms using proposed, standard morphological, and gradient-based operations, showing the effectiveness of the proposed operations, are given. Comparative hardware implementations of standard and proposed morphological operations are also given. Main distinguishing aspects of the new operations are: high efficiency and low hardware implementation (i.e., low number of buffers and D-Flip-Flops).	algorithm;binary image;computation;flops;flip-flop (electronics);gradient;mathematical morphology;operational definition;pixel;simulation;video post-processing	Aishy Amer	2003	IJPRAI	10.1142/S0218001403002307	computer vision;mathematical morphology;edge detection;binary image;erosion;image processing;computer science;theoretical computer science;mathematics;image segmentation;dilation;algorithm	Vision	47.71437570624323	-64.03163528946375	174942
7eca5789cf9588f4718fd01077e46ba2a972e6c5	fuzzy c-means classification for corrosion evolution of steel images	gaussian noise;evaluation performance;fuzzy c mean;desviacion tipica;revestimiento;methode semi automatique;degradation;theorie ensemble flou;performance evaluation;metals;semiautomatic method;standard deviation;evaluacion prestacion;degradacion;metodo semi automatico;ruido gaussiano;coatings;etude methode;estudio metodo;image bruitee;image clustering;fuzzy set theory;algorithme;imagen sonora;algorithm;minimizacion costo;perturbacion;minimisation cout;image simulation;cost minimization;noisy image;bruit gaussien;signal classification;ecart type;classification signal;method study;classification automatique;perturbation;automatic classification;revetement;clasificacion automatica;corrosion;radiometric corrections;optical coatings;algoritmo	An unavoidable problem of metal structures is their exposure to rust degradation during their operational life. Thus, the surfaces need to be assessed in order to avoid potential catastrophes. There is considerable interest in the use of patch repair strategies which minimize the project costs. However, to operate such strategies with confidence in the long useful life of the repair, it is essential that the condition of the existing coatings and the steel substrate can be accurately quantified and classified. This paper describes the application of fuzzy set theory for steel surfaces classification according to the steel rust time. We propose a semi-automatic technique to obtain image clustering using the Fuzzy C-means (FCM) algorithm and we analyze two kinds of data to study the classification performance. Firstly, we investigate the use of raw images' pixels without any pre-processing methods and neighborhood pixels. Secondly, we apply Gaussian noise to the images with different standard deviation to study the FCM method tolerance to Gaussian noise. The noisy images simulate the possible perturbations of the images due to the weather or rust deposits in the steel surfaces during typical on-site acquisition procedures.		Maite Trujillo San-Martin;Mustapha Sadki	2004		10.1117/12.527116	artificial intelligence;mathematics;algorithm;cartography	Vision	46.56078582845081	-64.89103322403344	174945
1ae425e1d91145e10216df11b153bc6973f0ffce	object recognition with shape prototypes in a 3d construction scenario	dynamic change;concepcion asistida;object recognition;computer aided design;forma geometrica;prototipo;comprension;modele cognitive;geometrical shape;pattern recognition;conception assistee;forme geometrique;construction virtuelle;reconnaissance forme;reconocimiento patron;prototype;comprehension	This paper is concerned with representations which enable a technical agent to recognize objects and aggregates from mechanical parts as they evolve in an ongoing construction task. The general goal is that the technical agent has a detailed understanding of the task situation such that it can execute instructions issued by a human user in a dynamically changing situation. A levelled approach for comprehensive shape representation is presented which is motivated by a cognitive model of pictorial shape representations (prototypes). In particular, our system is able to derive and represent spatial properties (such as orientation) and geometric features (e.g., axes or planes) that can be ascribed to the developing construct.	aggregate data;blue (queue management algorithm);cognition;cognitive model;expect;finite-state machine;image;intrinsic dimension;outline of object recognition;preprocessor;principle of abstraction;process modeling;prototype pattern;situated	Martin Hoffhenke;Ipke Wachsmuth	1999		10.1007/3-540-48238-5_19	computer vision;comprehension;simulation;computer science;artificial intelligence;computer aided design;cognitive neuroscience of visual object recognition;prototype	AI	47.961445008537076	-59.24034351587311	175108
0634974edd242897bb6aef73c5a6ee979d4cbf5f	the multiresolution gradient vector field skeleton	iterative method;invariance echelle;champ vectoriel;esqueleto;rotational invariance;gradient method;invarianza escala;analyse multiresolution;skeleton;metodo iterativo;algorithme;methode gradient;algorithm;campo vectorial;perturbacion;rotation invariance;metodo gradiente;shape matching;methode iterative;pattern matching;pattern recognition;squelette;multiresolution;concordance forme;reconnaissance forme;medial representation;invariance rotationnelle;perturbation;shape description;reconocimiento patron;vector field;multiresolution analysis;scale invariance;analisis multiresolucion;algoritmo	Many algorithms suppress skeleton associated with boundary perturbation by preventing their formation or by costly branch pruning. This work proposes a novel concept of structural and textural skeletons. The former is associated with the general shape structure and the latter with boundary perturbations. These skeletons remain disconnected to facilitate gross shape matching without the need for branch pruning. They are extracted from a multiresolution gradient vector field that is efficiently generated within a pyramidal framework. Experimental results show that these skeletons are scale and rotation invariant. They are less affected by boundary noise compared to skeletons extracted by popular iterative and non-iterative techniques.	algorithm;gradient;iterative method	Wooi-Boon Goh;Kai-Yun Chan	2007	Pattern Recognition	10.1016/j.patcog.2006.08.007	multiresolution analysis;combinatorics;vector field;topology;perturbation;rotational invariance;computer science;gradient method;scale invariance;pattern matching;mathematics;geometry;iterative method;topological skeleton;skeleton;algorithm	Vision	47.60820335375612	-61.24638774884912	175174
02f32c379b6f934fc0b191bd9479fa7842e19ea6	combinatorial ricci curvature and laplacians for image processing	laplace equations;combinatorial mathematics;image processing;laplacian operators;analogue formulae;combinatorial ricci curvature;grayscale images;voxels;pattern recognition;computational geometry;ricci curvature	A new Combinatorial Ricci curvature and Laplacian operators for grayscale images are introduced and tested on 2D synthetic, natural and medical images. Analogue formulae for voxels are also obtained. These notions are based upon more general concepts developed by R. Forman. Further applications, in particular a fitting Ricci flow, are discussed.	grayscale;image processing;synthetic intelligence;voxel	Emil Saucan;Eli Appleboim;Gershon Wolansky;Yehoshua Y. Zeevi	2009	2009 2nd International Congress on Image and Signal Processing		mathematical analysis;topology;image processing;computational geometry;computer science;mathematics;geometry;grayscale	Vision	50.75386126012818	-63.43982827879928	175276
80704b17f6b22b25658c66f865d1d87188590b8b	an optimal algorithm for computing fourier texture descriptors	texture description;primal sketch;fourier transform;two dimensional fourier transform;two dimensional fourier transform optimal algorithm primal sketch texture description picture preprocessing;computational complexity;timing optimization;discrete fourier transform;picture preprocessing;image analysis;optimal algorithm	"""The description of texture is an important problem in image analysis. Several methods in the literature require that local two-dimensional discrete Fourier transforms be computed as a first step in the texture description process. A chief limitation in these approaches has been the computational complexity of the transform calculation which has tended to limit the resolution of subsequent description and/or segmentation. It is shown here that through a suitable ordering of calculations, the transforms over a complete set of overlapping """"texture windows"""" can be obtained efficiently. An algorithm is given and is shown to be time-optimal to within a constant factor."""	algorithm;computational complexity theory;discrete fourier transform;image analysis;microsoft windows	Steven L. Tanimoto	1978	IEEE Transactions on Computers	10.1109/TC.1978.1674956	fourier transform;discrete hartley transform;fast fourier transform;mathematical optimization;discrete-time fourier transform;combinatorics;discrete mathematics;image analysis;hartley transform;harmonic wavelet transform;short-time fourier transform;computer science;fractional fourier transform;discrete sine transform;discrete fourier transform;mathematics;discrete fourier transform;fourier analysis;computational complexity theory;phase correlation;prime-factor fft algorithm;cyclotomic fast fourier transform	Vision	51.21208976029072	-62.449159267163765	175514
4b2f478ca7931d2ddd0939c991937a34b9216f38	efficient and accurate collision detection for granular flow simulation	frictional contact;octree;algorithm performance;image processing;octarbol;time complexity;edge detection;efficient algorithm;octarbre;procesamiento imagen;sphere detection;traitement image;colision;granular flow;deteccion contorno;algorithme;algorithm;detection contour;collision detection;resultado algoritmo;estructura datos;detection algorithm;performance algorithme;soybean;pattern recognition;contact mechanics;coherence;structure donnee;reconnaissance forme;coherencia;flow simulation;collision;reconocimiento patron;contact forces;data structure;octrees;bounding box;algoritmo	Abstract   In this paper, we present efficient algorithms for contact detection and accurate contact mechanics in granular flow simulations. The contact detection algorithms that we present are applicable to arbitrarily shaped rigid particles in a variety of environments including interactive as well as non-interactive. We present a very accurate force displacement model for characterizing the behavior of particles in contact. These algorithms are applied to granular flow simulations, in particular, soybean flow through an inclined chute. There are two phases of this research, namely, the development of contact detection algorithms and the development of accurate contact mechanics based force-displacement models. In the first phase, the algorithms consist of two stages. The first stage involves finding candidate particles for possible contacts. The second stage involves detecting precise contact between these candidates. In our application, the soybeans, which are approximately ellipsoidal in shape, are well approximated by a cluster of overlapping spheres. Detecting precise contact between spherical shapes is quite simple and hence, in this paper, we will focus only on the first stage of the first phase. The primary data structure used in the first stage is an octree. We build an octree for the enclosure/chute (containing the n particles) and use it in the algorithm for detecting possible contacts. The average time complexity of this stage of the first phase is O(n) and the worst case is O ( n log n ). In phase two, we develop a very accurate force-displacement model for dealing with the contact mechanics of soybean flow through an inclined chute. This model is a reasonably close approximation to the widely accepted Mindlin force-displacement model for elastic frictional contacts. Our force-displacement model accounts for normal and tangential direction contact forces acting between particles and/or particles and the chute walls. We also present examples of soybean flow simulations with fast contact detection and accurate contact mechanics.	collision detection;simulation	Baba C. Vemuri;Li Chen;Loc Vu-Quoc;Xiangrong Zhang;O. Walton	1998	Graphical Models and Image Processing	10.1006/gmip.1998.0479	time complexity;computer vision;simulation;edge detection;coherence;data structure;image processing;computer science;minimum bounding box;mathematics;geometry;contact force;contact mechanics;collision detection;algorithm;octree;collision	Robotics	50.802075582126996	-59.54770205678608	175710
426f2addde0246912b8cc90ef362927e194da0c4	recognition of occluded objects: a cluster-structure algorithm	analisis imagen;analyse amas;analisis escena;analyse scene;occlusion;disparity;matrice disparite;oclusion;segmentation;classification;disparidad;algorithme;algorithm;algorritmo;cluster analysis;approximation polygonale;disparity matrix;pattern recognition;image analysis;polygonal approximation;reconnaissance forme;reconocimiento patron;analyse image;disparite;clasificacion;segmentacion;scene analysis	-Clustering techniques have been used to perform image segmentation, to detect lines and curves in images and to solve several other problems in pattern recognition and image analysis. In this paper we apply clustering methods to a new problem domain and present a new method based on a cluster-structure approach for the recognition of 2-D partially occluded objects. Basically, the technique consists of three steps: clustering of border segment transformations; finding continuous sequences of segments in appropriately chosen clusters; and clustering of sequence average transformation values. As compared to some of the earlier methods, which identify an object based on only one sequence of matched segments, the new approach allows the identification of all parts of the model which match in the occluded scene. We also discuss the application of the clustering techniques to 3-D scene analysis. In both cases, the cluster-structure algorithm entails the application of clustering concepts in a hierarchical manner, resulting in a decrease in the computational effort as the recognition algorithm progresses. The implementation of the techniques discussed for the 2-D case has been completed and the algorithm has been evaluated with respect to a large number of examples where several objects partially occlude one another. The method is able to tolerate a moderate change in scale and a significant amount of shape distortion arising as a result of segmentation and/or the polygonal approximation of the boundary of the object. A summary of the results is presented. Clustering Occlusion Recognition Segment matching Sequencing Shape matching	algorithm;approximation;cluster analysis;computation;distortion;hidden surface determination;image analysis;image segmentation;machine vision;matched filter;norm (social);object-based language;pattern recognition;problem domain;segment tree	Bir Bhanu;John C. Ming	1987	Pattern Recognition	10.1016/0031-3203(87)90054-9	correlation clustering;constrained clustering;computer vision;data stream clustering;image analysis;fuzzy clustering;biological classification;flame clustering;computer science;canopy clustering algorithm;machine learning;consensus clustering;pattern recognition;cure data clustering algorithm;mathematics;cluster analysis;segmentation;algorithm;clustering high-dimensional data	Vision	47.198303352013966	-60.78049888303105	178026
6852ce5494ac94db48feb0ef0ebf1383f8981b4f	evolution equations for continuous-scale morphological filtering	equation derivee partielle;traitement signal;nonlinear filters;filtering;partial differential equation;mathematical morphology;filtrage;ecuacion derivada parcial;morfologia matematica;image processing;rate of change;signal analysis smoothing methods computer vision image edge detection filtering nonlinear filters motion detection nonlinear equations shape image analysis;nonlinear operator continuous scale morphological filtering multiscale signal analysis nonlinear multiscale operations signal features nonlinear partial differential equation scale evolution dilations opening closings erosion;methode echelle multiple;nonlinear partial differential equation;signal analysis;filtrado;procesamiento imagen;morphological operation;differential operators;analisis de senal;metodo escala multiple;traitement image;evolution equation;partial differential equations;signal processing;multiscale method;image processing partial differential equations mathematical morphology filtering theory nonlinear filters nonlinear differential equations;nonlinear differential equations;procesamiento senal;filtering theory;analyse signal;morphologie mathematique	Multiscale signal analysis has recently emerged as a useful framework for many computer vision and signal processing tasks. Morphological filters can be used to develop nonlinear multiscale operations that have certain advantages over linear multiscale approaches in that they preserve important signal features such as edges. In this paper, we discuss several nonlinear partial differential equations that model the scale evolution associated with continuous-space multiscale morphological erosions, dilations, openings, and closings. These equations relate the rate of change of the multiscale signal ensemble as scale increases to a nonlinear operator acting on the space of signals. The nonlinear operator is characterized by the shape and dimensionality of the structuring element used by the morphological operators, generally taking the form of a nonlinear function of certain partial differential operators.	computer vision;mathematical morphology;nonlinear system;signal processing;structuring element	Roger W. Brockett;Petros Maragos	1994	IEEE Trans. Signal Processing	10.1109/78.340774	computer vision;mathematical optimization;mathematical analysis;computer science;calculus;signal processing;mathematics;partial differential equation	Vision	50.8639381455603	-65.37991265361798	178564
5bdfb4fa606235d5fef642a6bec8d89a7722f9cf	density codes and shape spaces	jacobian matrix;image coding;funcion densidad probabilidad;probability density function;aproximacion;shape recognition;similitude;approximation;fonction densite probabilite;density functions;codage image;pattern encoding;shape similarity;similarity;pattern recognition;pattern analysis;similitud;reseau neuronal;sets of points;density functional;red neuronal;neural network;geometrical invariants	This paper presents an algorithm that allows for encoding probability density functions associated to samples of points of R(n). The resulting code is a sequence of points of R(n) whose density function approximates that of the set of data points. However, contrarily to sampled data points, code points associated to two different density functions can be matched, which allows to efficiently compare such functions. Moreover, the comparison of two codes can be made invariant to a wide variety of geometrical transformations of the support coordinates, provided that the Jacobian matrix of the transformation be everywhere triangular, with a strictly positive diagonal. Such invariances are commonly encountered in visual shape recognition, for example. Thus, using this tool, one can build spaces of shapes that are suitable input spaces for pattern recognition and pattern analysis neural networks. Moreover, a parallel neural implementation of the encoding algorithm is available for 2D image data.	algorithm;anatomy, regional;appendix;arabic numeral 0;code point;data point;dataspaces;distance;entry point;exclusion;jacobian matrix and determinant;matlab;neural network simulation;neural networks;normal statistical distribution;pattern recognition;polynomial;population parameter;reflection (computer graphics);sampling - surgical action;cell transformation	Pierre Courrieu	2006	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2005.10.006	jacobian matrix and determinant;probability density function;combinatorics;discrete mathematics;similarity;computer science;similitude;approximation;mathematics;geometry;artificial neural network	Vision	50.269178579367285	-63.72645843199842	179124
2617e8767229cbc27d7d303592b92a101fc7b225	a nonlinear image restoration framework using vector quantization	image coding image restoration vector quantisation;image coding;image processing;conference_paper;image restoration vector quantization degradation image coding signal restoration layout optical noise optical sensors image processing image classification;image classification;image restoration;power method;image compression;image compression nonlinear image restoration framework vector quantization image coding;vector quantizer;vector quantisation	Vector quantization (VQ) is a powerful method used primarily in signal and image compression. In recent years, it has also been applied to other various image processing tasks, including image classification, histogram modification, and restoration. In this paper, we focus our attention on image restoration using VQ. We present a general framework that incorporates two other methods in the literature, and discuss our method that follows more naturally from this framework. With appropriate training data for the VQ codebook, this method can restore images beyond its diffraction limit.	circuit restoration;codebook;computer vision;image compression;image processing;image restoration;nonlinear system;signal processing;vector quantization	Edmund Y. Lam	2004	Third International Conference on Image and Graphics (ICIG'04)	10.1109/ICIG.2004.15	image quality;image warping;image texture;image restoration;computer vision;contextual image classification;feature detection;speech recognition;binary image;u-matrix;power iteration;image processing;image compression;computer science;digital image processing;pattern recognition;mathematics;fractal transform;vector quantization;image histogram	Vision	50.839320533198666	-65.55080652202868	179456
8dc914d75a77babc8a71e84749787b60b0640c89	preprocessing phase in the pietsi project (prediction of time evolution images using intelligent systems)	systeme intelligent;image processing;sistema inteligente;procesamiento imagen;intelligence artificielle;traitement image;informational efficiency;intelligent system;artificial intelligence;inteligencia artificial	"""We outline the PIETSI project, the core of which is an image prediction strategy, and discuss common preliminary image processing tasks that are relevant when facing problems such as: useless background, information overlapping (solvable if dissimilar coding is being used) and memory usage, which can be described as """"marginal information efficiency""""."""	preprocessor	José Luis Crespo;Pilar Bernardos;Marta E. Zorrilla;Eduardo Mora	2003		10.1007/978-3-540-45210-2_59	simulation;image processing;computer science;artificial intelligence;machine learning	Robotics	47.27420226689073	-60.1152351234912	180818
ce68033a1f58678f7d8bf244f974adc3bfe82d9c	3-d object recognition and orientation from single noisy 2-d images	object recognition;metodo analitico;base donnee;estudio comparativo;database;base dato;ajustement;courbure;orientation;image bruitee;line fitting;fitting;imagen sonora;etude comparative;descripcion;object oriented;smoothing;analytical method;noisy image;points of maximum curvature;comparative study;alisamiento;pattern recognition;orientacion;curvatura;methode analytique;determinacion;curvature;determination;reconnaissance forme;rst transformation;reconocimiento patron;ajuste;description;lissage	Abstract   We have developed a method of recognising 3-D objects and determining their orientation from single 2-D images. These images may be noisy and contain partially occluded shapes.  The method combines both analytical and structural type techniques to build a description of the viewed object. This description is then compared to a database of 2-D model descriptions for various object orientations using 2-D pose-clustering techniques. Features derived from the local geometry of the object boundary are used in the matching process. This enables the object to be recognised and its orientation determined to within an average uncertainty of less than six degrees of arc, in both the major and minor axes of the object.	outline of object recognition	P. T. Fairney;D. P. Fairney	1996	Pattern Recognition Letters	10.1016/0167-8655(96)00012-8	computer vision;pose;object model;computer science;cognitive neuroscience of visual object recognition;comparative research;mathematics;geometry;curvature;orientation;object-oriented programming;smoothing	Vision	48.21351075483625	-59.7383626915528	181490
60c6f624ea77ac9b249c8913c33ba698de4efefa	scale space based grammar for hand detection	grammar;doigt;vision ordenador;base donnee;image processing;edge detection;analisis forma;database;procesamiento imagen;base dato;espacio escala;traitement image;computer vision;deteccion contorno;detection contour;detection objet;analyse syntaxique;scale space;analisis sintaxico;grammaire;syntactic analysis;invariante;finger;vision ordinateur;pattern analysis;dedo;gramatica;invariant;analyse forme;object detection;invariant feature;espace echelle	For detecting difficult objects, such as hands, an algorithm is presented that uses tokens and a grammar. Tokens are found by employing a new scale space edge detector that finds scale invariant features at object boundaries. First, the scale space is constructed. Then edges at each scale are found and the scale space is flattened into a single edge image. To detect a hand pattern, a grammar is defined using curve tokens for finger tips and wedges, and line tokens for finger sides. Curve tokens are found by superimposing a curve model on the scale space edge image and scoring its fit. Line tokens are found by using a modified Burns line finder. A hand pattern is identified by parsing these tokens using a graph based algorithm. On a database of 200 images of finger tips and wedges, finger tip curves are detected 85% of the time, and wedge curves are detected 70% of the time. On a database of 287 images of open hands against cluttered backgrounds, hands are correctly identified 70% of the time.	algorithm;computer vision;database;edge detection;formal language;object detection;parsing;scale space;sensor	Jan Prokaj;Niels da Vitoria Lobo	2006		10.1007/11821045_2	computer vision;scale space;speech recognition;edge detection;image processing;computer science;artificial intelligence;invariant;parsing;grammar	Vision	48.12286807397021	-59.88273604971144	181852
55ec1cafdfa273ea1b163a8cdba61dbe7fd1fa35	multi-scale spline-based contour data compression and reconstruction through curvature scale space	spline;splines mathematics data compression image reconstruction;image processing;data compression;curvature scale space;shape descriptor;reconstruction;speech processing;cascading style sheets;smoothed contours;consecutive curvature zero crossing points;splines mathematics;multiple scales;image processing multi scale spline based contour data compression reconstruction curvature scale space hermite curves 2 d contours multiple scales powerful contour shape descriptor mpeg 7 standard parametric representation input contour gaussian functions multi scale descriptions smoothed contours curvature zero crossing points tangent vectors hermite endpoints consecutive curvature zero crossing points hermite tangent vectors;parametric representation;2 d contours;multi scale descriptions;input contour;shape;hermite curves;image edge detection;tangent vectors;image reconstruction;signal processing;robustness;hermite tangent vectors;gaussian functions;hermite endpoints;powerful contour shape descriptor;curvature zero crossing points;mpeg 7 standard;spline data compression cascading style sheets image reconstruction shape robustness image edge detection speech processing signal processing mpeg 7 standard;multi scale spline based contour data compression	The curvature scale space (CSS) technique has been used in conjunction with Hermite curves for compression and robust reconstruction of 2-D contours at multiple scales. CSS is a powerful contour shape descriptor which is expected to be an MPEG-7 standard. A parametric representation of the input contour is convolved with Gaussian functions in order to obtain multi-scale descriptions of the contour. Curvature can be computed directly at each point of the smoothed contours. As a result, a set of curvature zero-crossing points can be extracted from each smoothed contour. Hermite curves were used since each Hermite curve is defined by two endpoints and the tangent vectors at those points. No points external to the input contour are required for Hermite curves. Hermite endpoints are defined as consecutive curvature zero-crossing points extracted at multiple scales using the CSS method. Hermite tangent vectors can also be determined using the CSS technique. The only data stored are the endpoints and the tangent vectors needed by the Hermite curves in order to arrive at an approximate reconstruction of the original contour.	data compression;scale space;spline (mathematics)	Yoke Khim Ung;Farzin Mokhtarian	2000		10.1109/ICASSP.2000.859255	data compression;iterative reconstruction;spline;computer vision;mathematical optimization;tangent vector;topology;image processing;shape;computer science;hermite interpolation;cubic hermite spline;signal processing;hermite spline;speech processing;mathematics;geometry;cascading style sheets;robustness	Vision	50.353320629513874	-63.819473792176396	183914
b5b19b28513acd0b471421ee7aee670897f044de	reduction of false positives in the detection of architectural distortion in mammograms by using a geometrically constrained phase portrait model	linear phase;phase portrait;symmetric matrix;image interpretation;gabor filter;false positive rate;condition number;false positive;breast cancer	Objective One of the commonly missed signs of breast cancer is architectural distortion. We have developed techniques for the detection of architectural distortion in mammograms, based on the analysis of oriented texture through the application of Gabor filters and a linear phase portrait model. In this paper, we propose constraining the shape of the general phase portrait model as a means to reduce the false-positive rate in the detection of architectural distortion. Material and methods The methods were tested with one set of 19 cases of architectural distortion and 41 normal mammograms, and with another set of 37 cases of architectural distortion. Results Sensitivity rates of 84% with 4.5 false positives per image and 81% with 10 false positives per image were obtained for the two sets of images. Conclusion The adoption of a constrained phase portrait model with a symmetric matrix and the incorporation of its condition number in the analysis resulted in a reduction in the false-positive rate in the detection of architectural distortion. The proposed techniques, dedicated for the detection and localization of architectural distortion, should lead to efficient detection of early signs of breast cancer.	condition number;distortion;gabor filter;internationalization and localization;linear phase	Fábio J. Ayres;Rangaraj M. Rangayyan	2007	International Journal of Computer Assisted Radiology and Surgery	10.1007/s11548-007-0072-x	computer vision;phase portrait;mathematical optimization;linear phase;type i and type ii errors;false positive rate;breast cancer;condition number;mathematics;geometry;symmetric matrix	Vision	49.81931119576879	-65.57436690974579	184395
ab19282d2aefd595c4bfc90e0ca064e10830e3a5	detection of piecewise-linear signals by the randomized hough transform	piecewise linear;piecewise linear functions;randomized hough transform;detection signal;edge detection;signal detection;piecewise linear function;line detection;image bruitee;transformacion hough;deteccion contorno;imagen sonora;detection contour;deteccion senal;noisy image;hough transformation;hough transform;transformation hough;random mapping	In this paper, a new application of the Hough transform is developed using fundamental ideas of the randomized Hough transform. The method detects and predicts piecewise-linear signals from serial samples with noise.	randomized hough transform	Atsushi Imiya	1996	Pattern Recognition Letters	10.1016/0167-8655(96)00005-0	hough transform;computer vision;speech recognition;piecewise linear function;computer science;mathematics;computer graphics (images)	Vision	47.21334841249194	-63.368636237305665	184441
0555c98d6d9b8c10109184008949885c08668a67	using eigenvectors of a vector field for deriving a second directional derivative operator for color images	image processing;edge detection;eigenvalues and eigenvectors;directional derivative;qualitative study;vector field;color image;eigenvectors	Edge detection in color images could be seen as detecting changes in a vector field.This paper presents a survey on existing methods and their difficulties. A second directional derivative approach is proposed, using eigenvalues and eigenvectors of a vector field for deriving a color edge detector and avoiding some ambiguities in the gradient direction estimation. Qualitative studies are presented by applying and comparing the different technics on a real image.	directional derivative	W. Alshatti;Patrick Lambert	1993		10.1007/3-540-57233-3_20	computer vision;topology;image gradient;image processing;eigenvalues and eigenvectors;computer science;mathematics;geometry;del;gradient	Robotics	51.337765525025674	-60.04883436685885	185158
5277f76140242680da17ae737da9b8c04812578f	multi-channel reconstruction of video sequences from low-resolution and compressed observations	baja resolucion;bayes estimation;marco;reconstruccion senal;canal multiple;high resolution;standards;image processing;data compression;bayesian approach;speech processing;low resolution;basse resolution;tratamiento palabra;standard;procesamiento imagen;traitement parole;traitement image;multiple channel;estimacion bayes;haute resolution;compression image;senal video;signal video;image compression;motion vector;interpolation method;image sequence;norma;alta resolucion;pattern recognition;video signal;signal reconstruction;secuencia imagen;compresion dato;reconnaissance forme;reconstruction signal;reconocimiento patron;etalon;norme;sequence image;compression donnee;estimation bayes;compresion imagen	A framework for recovering high-resolution video sequences from sub-sampled and compressed observations is presented. Compression schemes that describe a video sequence through a combination of motion vectors and transform coefficients, e.g. the MPEG and ITU family of standards, are the focus of this paper. A multichannel Bayesian approach is used to incorporate both the motion vectors and transform coefficients in it. Results show a discernable improvement in resolution in the whole sequence, as compared to standard interpolation methods.	coefficient;image resolution;interpolation;moving picture experts group	Luis D. Alvarez;Rafael Molina;Aggelos K. Katsaggelos	2003		10.1007/978-3-540-24586-5_5	computer vision;speech recognition;image resolution;image processing;quarter-pixel motion;computer science;motion estimation;speech processing;block-matching algorithm;motion compensation;algorithm	Vision	52.69086390236783	-61.70679346864594	187159
5895fca27741181f9dccff7bd537c30aa96eddcd	a new algorithm for local blur-scale computation and edge detection			algorithm;computation;edge detection;gaussian blur	Indranil Guha;Punam K. Saha	2018		10.1007/978-3-030-03801-4_52		Vision	51.08211594090428	-64.83460820503606	187296
c4dcd350f85b2efb17558f53aab961f8c5749b53	equi-affine invariant geometries of articulated objects	invariant laplacian;geodesic distance;proposed framework;global diffusion geometry;shear transformation;shape analysis;affine invariant geometric structure;existing set;articulated object;new form;affine invariant metric;equi-affine invariant geometries	We introduce an (equi-)affine invariant geometric structure by which surfaces that go through squeeze and shear transformations can still be properly analyzed. The definition of an affine invariant metric enables us to evaluate a new form of geodesic distances and to construct an invariant Laplacian from which local and global diffusion geometry is constructed. Applications of the proposed framework demonstrate its power in generalizing and enriching the existing set of tools for shape analysis.	gaussian blur;shape analysis (digital geometry);spectral density estimation;voronoi diagram	Dan Raviv;Alexander M. Bronstein;Michael M. Bronstein;Ron Kimmel;Nir A. Sochen	2011		10.1007/978-3-642-34091-8_8	discrete mathematics;topology;invariant;affine geometry of curves;mathematics;geometry;affine shape adaptation	Vision	50.198279663334596	-62.36138887364003	187707
da3dc2ce908dc65e5e64a812690037a1b2ed6e99	a two-subcycle thinning algorithm and its parallel implementation on simd machines	algoritmo paralelo;labeling computational efficiency pattern recognition supervised learning layout application software statistical distributions bayesian methods image restoration;parallel algorithm;algorithm performance;image processing;edge detection;procesamiento imagen;calculateur simd;image bruitee;traitement image;experimental result;algorithme parallele;deteccion contorno;imagen sonora;detection contour;tratamiento numerico;reconnaissance caractere;simd computer;resultado algoritmo;noisy image;performance algorithme;resultado experimental;pattern recognition;digital processing;parallel implementation;reconnaissance forme;parallel algorithms image thinning;reconocimiento patron;resultat experimental;image thinning;character recognition;traitement numerique;boundary noise sensitivity two subcycle thinning algorithm parallel implementation simd machines 8 connectedness degree erosion stability pattern rotation;reconocimiento caracter;parallel algorithms	A new parallel thinning algorithm with two subcycles is proposed and compared with other parallel thinning algorithms in terms of 8-connectedness degree, erosion, stability under pattern rotation, and boundary noise sensitivity. Computational issues are also reported based on the implementation of the thinning algorithm on the SIMD machines CM-200 and MasPar MPP-12000.	algorithm;computation;maspar;simd;thinning	Alfredo Petrosino;Giuseppe Salvi	2000	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.821742	computer vision;image processing;computer science;theoretical computer science;parallel algorithm;algorithm	Visualization	47.574748652436675	-64.098357469451	187709
0bdd4f7f7ad7e67d868630ce50ec3a4824fe3cd9	fast template matching by applying winner-update on walsh-hadamard domain	computervision;pattern matching walsh hadmard winner update template matching;pattern matching application software computer vision image processing video compression distortion measurement frequency computer science noise robustness noise level;walsh hadamard domain;hadamardtransforms;image processing;winner update strategy;application software;image matching;video compression;computer vision and image processing;imagematching;distortion measurement;noise robustness;computer vision;walsh hadamard transform;noise level;hadamard transforms;pattern matching;winner update;image matching computer vision hadamard transforms;template matching winner update strategy image processing computer vision walsh hadamard domain;computer science;frequency;template matching;walsh hadmard	Fast template matching is strongly demanded for many practical applications related to computer vision and image processing. In this paper, we propose a fast template matching method by applying the winner-update strategy on the Walsh-Hadamard domain. By taking advantage of the nice energy packing property of the Walsh-Hadamard transformation, we can just apply the winner-update process with a small number of Walsh-Hadamard coefficients to reduce the computational burden for template matching in an image. Experimental results demonstrate the efficiency and robustness of the proposed template matching algorithm under different noise levels.	algorithm;coefficient;computation;computer vision;emoticon;experiment;hadamard transform;image processing;kernel (operating system);mega city (the matrix);pattern search (optimization);set packing;template matching	Shou-Der Wei;Shao-Wei Liu;Shang-Hong Lai	2007	2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07	10.1109/ICASSP.2007.366086	data compression;computer vision;application software;template matching;image processing;template method pattern;computer science;theoretical computer science;machine learning;frequency;pattern matching	Robotics	51.96287326094491	-60.38265859978571	188121
41fbe1609b1d8c14b8dc292f801512c2ef7cc734	a lie group theoretic approach to the invariance problem in feature extraction and object recognition	invariance problem;object recognition;feature extraction;lie group;lie group generators	Cole, J.B., H. Murase and S. Naito, A Lie group theoretic approach to the invariance problem in feature extraction and object recognition, Pattern Recognition Letters 12 (1991) 519-523. We derive a formal solution to the invariance problem and construct it using Lie group generators. Representations of these generators with respect to image data are discussed. Group theoretical obstacles to three-dimensional invariant recognition and possible solutions are considered.	feature extraction;outline of object recognition;pattern recognition letters;theory	James B. Cole;Hiroshi Murase;Seiichiro Naito	1991	Pattern Recognition Letters	10.1016/0167-8655(91)90091-Y	combinatorics;discrete mathematics;topology;fundamental representation;representation theory of su;feature extraction;computer science;representation of a lie group;cognitive neuroscience of visual object recognition;machine learning;mathematics;lie group	Vision	49.76620589767155	-61.093640283428854	190805
6bf029d2ac4107b74d5a40e7a49dc414254619c2	geometric sampling of manifolds for image representation and processing	image processing;2 dimensional;computer vision;geometric approach;image representation	It is often advantageous in image processing and computer vision to consider images as surfaces imbedded in higher dimensional manifolds. It is therefore important to consider the theoretical and applied aspects of proper sampling of manifolds. We present a new sampling theorem for surfaces and higher dimensional manifolds. The core of the proof resides in triangulation results for manifolds with or without boundary, not necessarily compact. The proposed method adopts a geometric approach that is considered in the context of 2-dimensional manifolds (i.e surfaces), with direct applications in image processing. Implementations of these methods and theorems are illustrated and tested both on synthetic images and on real medical data.	computer vision;image processing;nyquist–shannon sampling theorem;sampling (signal processing);synthetic intelligence;triangulation (geometry)	Emil Saucan;Eli Appleboim;Yehoshua Y. Zeevi	2007		10.1007/978-3-540-72823-8_78	computer vision;topology;mathematics;geometry	Vision	51.47448334558515	-63.19527034423067	191801
0984ab0dc4bc46504445853d2b993d7caf0c2c5e	on-line graphics recognition: state-of-the-art	object recognition;vision ordenador;representation graphique;image processing;procesamiento imagen;shape recognition;sistema n niveles;reconnaissance objet;document graphique;grafismo;graphisme;traitement image;computer vision;scenario;image interpretation;documento grafico;interpretacion imagen;argumento;systeme n niveaux;reconocimiento grafico;script;multilevel system;pattern recognition;graphism;grafo curva;vision ordinateur;reconnaissance graphique;interpretation image;reconnaissance forme;reconocimiento patron;graphics recognition;graphic document;graphics;graphical recognition	A brief survey on on-line graphics recognition is presented. We first present some common scenarios and applications of on-line graphics recognition and then identify major problems and sub-problems at three levels: primitive shape recognition, composite graphic object recognition, and document recognition and understanding. Representative approaches to these problems are also presented. We also list several open problems at the end.		Wenyin Liu	2003		10.1007/978-3-540-25977-0_27	computer vision;image processing;intelligent character recognition;computer science;graphics;artificial intelligence;scenario;cognitive neuroscience of visual object recognition;computer graphics (images)	Vision	47.6650090305076	-60.0138710390504	192589
2a6e7a1386eef70595747c2cfed828381584fef4	image separation between natural and artificial objects using fractal dimension	lmage processing;artificial images;segmentation;fractal dimensions;natural images;fractal dimension	This paper describes the preliminary work of image separation between natural and artificial objects using fractal dimensions by noting that most of natural images have non-integer dimensions while artificial ones have integer dimensions.	fractal dimension	Shuichi Fukuda	1994			computer vision;fractal landscape;mathematics;fractal analysis;fractal dimension on networks;fractal transform;fractal dimension;artificial intelligence;integer	Vision	50.79041615353564	-63.28759842824669	192774
76ebe28725b086d96b090c5dbc939cd7b3325bbc	a one-pass two-operation process to detect the skeletal pixels on the 4-distance transform	skeletal pixels detection;image processing;binary image;one pass two operation process;procesamiento imagen;intelligence artificielle;computerised pattern recognition;traitement image;sequential raster scan distance transform skeletal pixels detection computerised picture processing pattern recognition one pass two operation process;algorithme;algorithm;afinamiento;sequential raster scan;computerised picture processing computerised pattern recognition;image binaire;pattern recognition;imagen binaria;computerised picture processing;skeleton shape inspection image processing algorithm design and analysis data processing computational efficiency topology;artificial intelligence;amincissement;inteligencia artificial;shape description;distance transform;thinning;algoritmo	A skeletonizing procedure is illustrated, based on the notion of multiple pixel as well as on the use of the 4-distance transform. The set of the skeletal pixels is identified within one sequential raster scan of the picture where the 4-distance transform is stored. To this purpose, two local conditions, recently introduced to characterize the multiple pixels, are employed. Since the set of the skeletal pixels is at most two pixels wide, the skeleton can be obtained on completion of an additional inspection of the picture, during which standard removal operations are applied. Besides being correct and computationally convenient, the procedure produces a labeled skeleton, i.e., a skeleton whose adequacy for shape description purposes is generally acknowl-	pixel;raster scan	Carlo Arcelli;Gabriella Sanniti di Baja	1989	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.19037	computer vision;binary image;image processing;computer science;artificial intelligence;distance transform;computer graphics (images)	Vision	47.81722996085334	-63.941783262295615	193849
cb4c379c8bebb688371e76e25f38e8c6236c8136	subband image coding using watershed and watercourse lines of the wavelet transform	transformation ondelette;image coding;image processing;arithmetic coding;data compression;gaussian processes;chain code;convolution;low frequency;low pass;procesamiento imagen;imagen nivel gris;image reconstruction image coding arithmetic codes wavelet transforms gaussian processes convolution data compression image representation prediction theory;traitement image;wavelet transforms;band pass;codificacion;arithmetic codes;wavelet transform;prediction theory;image representation;image reconstruction;image niveau gris;coding;lossless arithmetic coding subband image coding watershed lines watercourse lines wavelet transform primitive based image coding nonorthogonal dyadic wavelets 3d isotropic wavelet difference of gaussians operator convolution bandpass signals multiscale smoothed second derivatives gaussian shaped low pass wavelet low frequency information lowpass subband signal thresholding subsampling data reduction fidelity chain coding predictive coding amplitudes;data reduction;compresion dato;transformacion ondita;grey level image;predictive coding;image coding wavelet transforms filters shape humans convolution interpolation spatial resolution image resolution;wavelet transformation;compression donnee;codage	Reports progress in primitive-based image coding using nonorthogonal dyadic wavelets. A 3D isotropic wavelet is used to approximate the difference-of-Gaussians (D-o-G) operator. Convolution of the image with dilated versions of the wavelet produces three band-pass signals that approximate multiscale smoothed second derivatives. An additional convolution of the image with a Gaussian-shaped low-pass wavelet creates a fourth subband signal that preserves low-frequency information not described by the three band-pass signals. The authors show that the original image can be recovered from the watershed and watercourse lines of the three band-pass signals plus the lowpass subband signal. By thresholding the watershed/watercourse representation, subsampling the low-pass subband, and using edge post emphasis, the authors achieve data reduction with little loss of fidelity. Further compression of the watersheds and watercourses is achieved by chain coding their shapes and predictive coding their amplitudes prior to lossless arithmetic coding. Results are presented for grey-level test images at data rates between 0.1 and 0.3 b/pixel.		Lawrence H. Croft;John A. Robinson	1994	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.336246	computer vision;speech recognition;image processing;computer science;theoretical computer science;mathematics;statistics;wavelet transform	Vision	51.97141091480874	-62.837684864071186	194100
73fce67733cc1c13fec9f57fe9c92563548b4004	image analysis with legendre moment descriptors	legendre moments;image reconstruction;image analysis	Corresponding Author: Simon Liao The University of Winnipeg, Winnipeg, Manitoba, Canada, R3B 2E9, Canada Email: achiang0602@gmail.com Abstract: In this research, a numerical integration method is proposed to improve the computational accuracy of Legendre moments. To clarify the improved computation scheme, image reconstructions from higher order of Legendre moments, up to 240, are conducted. With the more accurately generated moments, the distributions of image information in a finite set of Legendre moments are investigated. We have concluded that each individual finite set of Legendre moments will represent the unique image features independently, while the even orders of Legendre moments describe most of the image characteristics.	computation;email;image analysis;numerical analysis;numerical integration	Amy Chiang;Simon X. Liao	2015	JCS	10.3844/jcssp.2015.127.136	iterative reconstruction;velocity moments;mathematical optimization;image analysis;method of moments;legendre polynomials;computer science;legendre wavelet	ML	50.452352855988785	-62.33094941730889	194515
f8167c618ccc4e6dfb58d55a829f61d6890db997	identification of blur parameters from motion blurred images	eficacia sistema;high resolution;estimation mouvement;restauration image;image processing;estimacion movimiento;performance systeme;procesamiento imagen;motion estimation;movie camera;image restoration;system performance;traitement image;algorithme;algorithm;restauracion imagen;camara;imaging system;motion blur;imagen borrosa;point spread function;blurred image;image floue;camera;algoritmo	the smear extent of the blurred image of a point object The problem of restoration of images blurred by relative in the original image. Extraction of the blur extent has motion between the camera and the object scene is important significant meaning in identification of the motion-blur in a large number of applications. The solution proposed here PSF. Cannon [1] dealt with the case of uniform linear identifies important parameters with which to characterize the motion blur that is described by a square pulse PSF and point spread function (PSF) of the blur, given only the blurred used its property of periodic zeros in the spectral domain image itself. This identification method is based on the concept of the blurred image. These zeros were emphasized in that image characteristics along the direction of motion are the cepstral domain and the blur extent was estimated by different from the characteristics in other directions. Depending measuring the separations between the zeros. The assumpon the PSF shape, the homogeneity and the smoothness of the tion of zeros in the spectral domain is not satisfied in blurred image in the motion direction are greater than in other directions. Furthermore, in this direction correlation exists bevarious cases of motion degradation such as accelerated tween the pixels forming the blur of the original unblurred motion [2, 3] and low frequency vibrations [4]. objects. By filtering the blurred image we emphasize the PSF Recent important developments in image restoration characteristics at the expense of the image characteristics. The are the maximum likelihood image and blur identification method proposed here identifies the direction and the extent methods [5–7]. These methods model the original image, of the PSF of the blur and evaluates its shape which depends on the blur, and the noise process. The original image is modthe type of motion during the exposure. Correct identification of eled as a two-dimensional autoregressive (AR) process, the PSF parameters permits fast high resolution restoration of and the blur is modeled by a two-dimensional linear system the blurred image.  1997 Academic Press with finite impulse response. A maximum likelihood estimation is used for identification of the image and blur parameters. The identification of the blur model parame	autoregressive model;box blur;cepstrum;circuit restoration;elegant degradation;finite impulse response;gaussian blur;image noise;image resolution;image restoration;linear system;pixel;smear campaign	Yitzhak Yitzhaky;Norman S. Kopeika	1997	CVGIP: Graphical Model and Image Processing	10.1006/gmip.1997.0435	image restoration;computer vision;image resolution;image processing;computer science;motion estimation;point spread function;computer graphics (images)	Vision	53.432836555191884	-60.925690089929425	194755
74ef972c2ba4a2394d0ad48a3596d42fb1c64fd8	optimal scale selection for circular edge extraction	cartesian coordinate;metodo analitico;coordenada polar;theoretical framework;image processing;validacion;methode echelle multiple;edge detection;image matching;extraction forme;analytical solution;procesamiento imagen;edge extraction;courbure;metodo escala multiple;classification;traitement image;deteccion contorno;solucion analitica;detection contour;optimal scaling;extraccion forma;analytical method;coordenadas cartesianas;curvatura;methode analytique;curvature;validation;polar coordinate;multiscale method;coordonnee cartesienne;solution analytique;coordonnee polaire;analytic solution;pattern extraction;clasificacion;validation studies	This paper addresses the issue of optimal scale selection for circular edge extraction in the context of higher dimensional multiscale edge extraction. Based on a classification of higher dimensional edges according to local curvature, we exemplarily establish a 2-D circular edge model. Through a careful mathematical derivation, we transform the circular edge model from Cartesian coordinates for which the analytical solution is unknown into polar coordinates. Utilizing this edge model we develop a novel theoretical framework for optimal scale selection for circular edge extraction through which the effects of curvature as related to scale can be analyzed. Moreover, we carry out a validation study in order to investigate on the level of principal performance how well the experimental results obtained from application of the developed framework to 2-D synthetic images match the theoretical results.	cartesian closed category;synthetic intelligence	Ji-Young Lim;H. Siegfried Stiehl	2003		10.1007/978-3-540-45243-0_6	closed-form expression;image processing;calculus;mathematics;geometry	Vision	49.238591918184866	-60.588293683126736	195447
4a8441c695d4e8626ff94f8e8cb231fdebc12545	on characterizing ribbons and finding skewed symmetries	computational geometry;computer vision;image segmentation shape robots laboratories computer science extremities contracts subcontracting testing;segmentation computer vision computational geometry blum ribbons skewed symmetries brady ribbons brook ribbons contour points local symmetry;computer vision computational geometry	Following Rosenfeld [14], we compare in this paper Blum, Brooks, and Brady ribbons. We prove that Blum and Brady ribbons are not, in general, Brooks ribbons. Conversely, we prove that Brooks ribbons are, in general, neither Blum nor Brady ribbons. For Blum and Brooks ribbons, it is in principle trivial to decide whether two contour points may form a ribbon pair: they have to form a local symmetry. This property is not true for Brooks ribbons. Is it possible to characterize locally the pairs of contour points which form a Brooks ribbon pair? Using the curvature of the contour of a Brooks ribbon, we show that the answer to this question is yes for some classes of Brooks ribbons, including skewed symmetries. This result is used in an implemented algorithm for finding skewed symmetries in an image, and examples of segmentation of real images are given.	algorithm;blum axioms;louis rosenfeld	Jean Ponce	1989		10.1109/ROBOT.1989.99966	computer vision;computational geometry;computer science;artificial intelligence;mathematics;engineering drawing;algorithm	Robotics	50.71193482622887	-60.426172330712106	196376
19540dd4aeabdbc537b9500580c44423970a3806	two new algorithms for efficient computation of legendre moments	legendre moments;hatamian s filter;computational complexity;fast algorithm;pattern recognition;image analysis	Orthogonal moments have been successfully used in the 1eld of pattern recognition and image analysis. However, the direct computation of orthogonal moments is very expensive. In this paper, we present two new algorithms for fast computing the two-dimensional (2D) Legendre moments. The 1rst algorithm consists of transforming the pixel-based calculation of Legendre moments into the line-segment-based calculation. After all line-segment moments have been calculated, Hatamian’s 1lter method is extended to calculate the one-dimensional Legendre moments. The second algorithm is directly based on the double integral formulation. The 2D shape is considered as a continuous region and the contribution of the boundary points is used for fast calculation of shape moments. The numerical results show that the new algorithms can decrease the computational complexity tremendously, furthermore, they can be used to treat any complicated objects. ? 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	algorithm;binary image;computation;computational complexity theory;image analysis;legendre transformation;numerical analysis;outline of object recognition;pattern recognition;pixel	Jindan Zhou;Huazhong Shu;Limin Luo;Wenxue Yu	2002	Pattern Recognition	10.1016/S0031-3203(01)00104-2	velocity moments;computer vision;mathematical optimization;combinatorics;image analysis;computer science;theoretical computer science;legendre wavelet;pattern recognition;mathematics;computational complexity theory	Vision	50.02070939253887	-62.02323378461455	197309
27cbf9a81665969d229bc4038ed77c1cdb9f4164	spatialboost: adding spatial reasoning to adaboost	vision ordenador;solucion debil;image segmentation;image processing;spatial reasoning;modele agrege;supervised learning;procesamiento imagen;modelo agregado;outlier;intelligence artificielle;classification;traitement image;spatial database;computer vision;weak solution;observacion aberrante;segmentation image;raisonnement spatial;aggregate model;observation aberrante;artificial intelligence;solution faible;interactive image segmentation;vision ordinateur;base dato especial;inteligencia artificial;apprentissage supervise;base de donnees spatiale;aprendizaje supervisado;clasificacion	SpatialBoost extends AdaBoost to incorporate spatial reasoning. We demonstrate the effectiveness of SpatialBoost on the problem of interactive image segmentation. Our application takes as input a trimap of the original image, trains SpatialBoost on the pixels of the object and the background and use the trained classifier to classify the unlabeled pixels. The spatial reasoning is introduced in the form of weak classifiers that attempt to infer pixel label from the pixel labels of surrounding pixels, after each boosting iteration. We call this variant of AdaBoost — SpatialBoost. We then extend the application to work with “GrabCut”. In GrabCut the user casually marks a rectangle around the object, instead of tediously marking a tri-map, and we pose the segmentation as the problem of learning with outliers, where we know that only positive pixels (i.e. pixels that are assumed to belong to the object) might be outliers and in fact should belong to the background.	adaboost;algorithm;data point;grabcut;image segmentation;item unique identification;iteration;pixel;spatial–temporal reasoning;synthetic intelligence;triangular function	Shai Avidan	2006		10.1007/11744085_30	computer vision;outlier;image processing;biological classification;computer science;artificial intelligence;weak solution;machine learning;spatial intelligence;image segmentation;supervised learning;spatial database	ML	46.5073175283535	-59.98216703656222	197721
b2311a7eb32b099dcb953d943d9df52414cead15	a fast snake segmentation method applied to histopathological sections	minimisation;algorithme rapide;marco;minimization;metodo analitico;fiabilidad;reliability;gradient vector flow;mise a jour;champ vectoriel;standards;fonction energie;convolution;edge detection;gradiente;standard;minimizacion;convolucion;segmentation;gradient;field experiment;algoritmo genetico;energy function;deteccion contorno;actualizacion;detection contour;campo vectorial;numerical scheme;mathematical programming;filter;fiabilite;analytical method;fast algorithm;norma;derivee;algorithme genetique;funcion energia;filtre;methode analytique;genetic algorithm;vector field;matematik;etalon;derivada;programmation mathematique;filtro;programacion matematica;norme;algoritmo rapido;segmentacion;updating;derivative	Using snakes to segment images has proven to be a powerful tool in many different applications. The snake is usually propagated by minimizing an energy function. The standard way of updating the snake from the energy function is time consuming. This paper presents a fast snake evolution algorithm, based on a more efficient numeric scheme for updating the snake. Instead of inverting a matrix derived from approximating derivatives in a sampled snake, an analytical expression is obtained. The expression takes the form of a convolution with a filter given by an explicit formula. The filter function can then be sampled and used to propagate snakes in a fast and straightforward manner. The proposed method is generally applicable to snakes and is here used for propagating snakes in a gradient vector flow field. Experiments are carried out on images of histopathological tissue sections and the results are very promising.		Adam Karlsson;Kent Stråhlén;Anders Heyden	2003		10.1007/978-3-540-45063-4_17	fabry–pérot interferometer;minimisation;vector field;genetic algorithm;field experiment;edge detection;filter;computer science;derivative;calculus;reliability;mathematics;convolution;gradient;segmentation;algorithm;statistics	Vision	47.95784599954072	-64.37228201497902	198101
bf9bca98969268e809451b97c8c41386d99a9d64	temporal structure tree in digital linear scale space	analisis imagen;time varying;image numerique;geometrie plane;plane geometry;methode echelle multiple;digital image analysis;geometrie algorithmique;espace lineaire;metodo arborescente;espacio lineal;computational geometry;aplicacion espacial;condicion estacionaria;metodo escala multiple;condition stationnaire;analyse temporelle;espacio escala;geometria discreta;analisis temporal;digital geometry;time varying system;time analysis;empreinte digitale;scale space;systeme parametre variable;geometrie discrete;discrete geometry;imagen numerica;stationary condition;fingerprint;tree structured method;image analysis;geometria computacional;multiscale method;methode arborescente;huella digital;digital image;sistema parametro variable;geometria plana;linear space;analyse image;application spatiale;space application;espace echelle	This paper focuses on the computation of stationary curves, which are sometimes called fingerprints for one dimensional real signals in the linear scale space. Images for the analysis in the linear scale space are expressed as digital images for each quantized scale. Therefore, we develop a discrete version of the linear scale space analysis, employing the results of digital image analysis. For the application of linear scale space analysis to the time-varying images and objects, our method has advantages, because our method is based on the digital geometry on a plane which is suitable for the computation in digital computers.	linear scale;scale space	Atsushi Imiya;Tateshi Sugiura;Tomoya Sakai;Yuichiro Kato	2003		10.1007/3-540-44935-3_25	discrete geometry;fingerprint;computer vision;scale space;image analysis;computational geometry;computer science;plane;calculus;mathematics;geometry;digital image;linear space;scale-space axioms;digital geometry	HCI	49.82386828494308	-61.495027351309766	199531
