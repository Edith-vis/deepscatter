id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
52e1991066e893fa79099c714be7480aa611dae3	new alternatives to the estimation problem in hardware-software codesign of complex embedded systems: the h.261 video co-dec case study	hardware software codesign;partitioning;macroscopic;embedded system;parallelism;sharing;estimation	As Codesign problems become larger and more realistic, the required time to estimate their solutions turns into an important bottleneck. This paper presents a new approach to improve the traditional estimation techniques, in order to avoid this drawback. The presented method has been successfully tested on a large experimental benchmark, attaining quality levels close to those provided by the Synopsys Behavioral Compiler. Finally, a case study based on the standard H.261 video co-dec is described, proving the convenience of the technique on real-life situations. The obtained results show a significant improvement in the process time, while keeping the good precision and fidelity levels that the traditional estimation models usually offer.	embedded system	Juan Antonio Maestro;Daniel Mozos;Raquel Dormido;Pedro Reviriego	2004	Design Autom. for Emb. Sys.	10.1007/s10617-005-1198-0	embedded system;estimation;real-time computing;simulation;computer science;operating system;macroscopic scale	EDA	0.2947716844929633	56.030956937180655	162878
78ed1217fdd46a3593a0b22e324fe584b17e5347	introducing preemptive scheduling in abstract rtos models using result oriented modeling	design model;preemptive scheduling;thermal aware design;system design flow;abstract rtos models;temperature control;communication model;soc design;integrated circuit design;integrated circuit modelling;system on chip;system design;hardware dependent software;result oriented modeling;static and dynamic optimization;dynamic frequency scaling;timing annotation;timing read only memory delay processor scheduling discrete event simulation dynamic scheduling embedded computing hardware embedded software clocks;system on chip dynamic scheduling integrated circuit design integrated circuit modelling;dynamic scheduling;model simulation;timing annotation preemptive scheduling abstract rtos models result oriented modeling soc design hardware dependent software dynamic scheduling system design flow	With the increasing SW content of modern SoC designs, modeling and development of Hardware Dependent Software (HDS) become critical. Previous work addressed this by introducing abstract RTOS modeling [6], which exposes dynamic scheduling effects early in the system design flow. However, such models insufficiently capture preemption. In particular, the accuracy of preemption depends on the granularity of the timing annotation. For an accurately modeled interrupt response time, very fine-grained timing annotation is necessary, which contradicts the RTOS abstraction idea and is detrimental to simulation performance.  In this paper, we eliminate the granularity dependency by applying the Result Oriented Modeling (ROM) technique previously used only for communication modeling. Our ROM approach allows precise preemptive scheduling, while retaining all the benefits of abstract RTOS modeling. Our experimental results demonstrate tremendous improvements. While the traditional model simulated an interrupt response time with a severe inaccuracy (12x longer in average and 40x longer for 96th percentile), our ROM-based model was accurate within 8% (average and 50th percentile) using identical timing annotations.	holographic data storage;preemption (computing);response time (technology);scheduling (computing);simulation;systems design	Gunar Schirner;Rainer Dömer	2008	2008 Design, Automation and Test in Europe	10.1145/1403375.1403408	system on a chip;embedded system;electronic engineering;parallel computing;real-time computing;models of communication;dynamic priority scheduling;computer science;operating system;temperature control;preemption;integrated circuit design;systems design	Embedded	-1.8508406968772002	56.21020389206986	163815
40206d06c9bdbe4b594de49feb940520d51d8e75	dynamic voltage scaling on mpeg decoding	energy efficiency;energy conservation;voltage control;activation energy;cmos technology;mobile device;motion pictures;decoding;energy efficient;predictor error rate;decoding time;movie stream;simulation;dynamic voltage scaling;video coding decoding energy conservation computer power supplies mobile computing portable computers;mobile computer;dvs with delay and drop rate minimizing algorithm;video coding;dvs with predicted decoding time;decoding time dynamic voltage scaling mpeg decoding processor energy consumption dvs with delay and drop rate minimizing algorithm dvs with predicted decoding time simulation energy efficiency movie stream predictor error rate;energy consumption;portable computers;dynamic voltage scaling decoding voltage control energy consumption delay energy efficiency mobile computing cmos technology motion pictures mobile communication;mobile communication;mpeg decoding;mobile computing;computer power supplies;processor energy consumption;energy saving	A number of research efforts have been devoted to reduce energy consumption of a processor without impacting the performance through the use of dynamic voltage scaling (DVS). This paper presents two DVS algorithms on MPEG decoding. One is DVS with delay and drop rate minimizing algorithm (DVS-DM) where voltage is determined based on previous workload only. Another algorithm scales the supply voltage according to the predicted MPEG decoding time and previous workload (DVS with predicted decoding time or DVS-PD). Simulation results show that DVS-PD improves energy eff iciency as much as 56% compared to the conventional shutdown algorithm. We also found that the amount of energy saving with DVS-PD is not affected by the fluctuation of the movie stream. But it is related with error rate of the predictor, which implies that if decoding time is predicted more accurately, DVS algorithm can be more efficient.	algorithm;descriptive video service;dynamic voltage scaling;image scaling;kerrison predictor;moving picture experts group;quantum fluctuation;shutdown (computing);simulation;spatial variability	Donghwan Son;Chansu Yu;Heung-Nam Kim	2001		10.1109/ICPADS.2001.934877	embedded system;parallel computing;real-time computing;computer hardware;computer science;operating system;efficient energy use;mobile computing	EDA	-4.093713698741362	59.418411076535875	163854
e8b20e99fb16fbab2a6462801448db4e5a4af313	improving the energy behavior of block buffering using compiler optimizations	integrated approach;embedded coding;embedded system;chip;embedded systems;energy optimizations;data cache;energy optimization;energy consumption;compiler optimization;compiler transformations;block buffering;energy saving	On-chip caches consume a significant fraction of the energy in current microprocessors. As a result, architectural/circuit-level techniques such as block buffering and sub-banking have been proposed and shown to be very effective in reducing the energy consumption of on-chip caches. While there has been some work on evaluating the energy and performance impact of different block buffering schemes, we are not aware of software solutions to take advantage of on-chip cache block buffers.This article presents a compiler-based approach that modifies code and variable layout to take better advantage of block buffering. The proposed technique is aimed at a class of embedded codes that make heavy use of scalar variables. Unlike previous work that uses only storage pattern optimization or only access pattern optimization, we propose an integrated approach that uses both code restructuring (which affects the access sequence) and storage pattern optimization (which determines the storage layout of variables). We use a graph-based formulation of the problem and present a solution for determining suitable variable placements and accompanying access pattern transformations. The proposed technique has been implemented using an experimental compiler and evaluated using a set of complete programs. The experimental results demonstrate that our approach leads to significant energy savings. Based on these results, we conclude that compiler support is complementary to architecture and circuit-based techniques to extract the best energy behavior from a cache subsystem that employs block buffering.	cpu cache;code;embedded system;graph (discrete mathematics);mathematical optimization;microprocessor;optimizing compiler	Mahmut T. Kandemir;J. Ramanujam;Ugur Sezer	2006	ACM Trans. Design Autom. Electr. Syst.	10.1145/1124713.1124727	chip;embedded system;computer architecture;parallel computing;real-time computing;computer science;loop optimization;operating system;optimizing compiler	EDA	-2.1125253439649656	53.563521066187604	164481
0f1dd10b5ca6f8206de270fe21f55b311df30f37	frequent value cache for low-power asynchronous dual-rail bus	switching activity;memoria tampon;evaluation performance;diseno circuito;performance evaluation;evaluacion prestacion;circuit design;circuit vlsi;data communication;system on a chip;asynchronous circuit;vlsi circuit;low power;circuit asynchrone;sistema sobre pastilla;puissance faible;circuito asincrono;conception circuit;floating point;systeme sur puce;power reduction;power consumption;circuito vlsi;memoire tampon;bus donnee;potencia debil;buffer memory	We study a power reduction method for the asynchronous dual-rail bus. A preliminary analysis of data communication patterns between a processor and a memory module reveals that many communications deliver a set of data items repeatedly. To exploit such communication characteristics, a frequent value cache(FVC) method is proposed that delivers not always data itself but sometimes an index of data item of FVC. Because of the lower switching activity, FVC reduces the power consumption of the asynchronous dual-rail bus. Simulation results illustrate that FVC reduces the power consumption of the normal asynchronous dual-rail bus by 25% and 30% at maximum for integer and floating-point benchmarks, respectively.		Byung-Soo Choi;Dong-Ik Lee	2003		10.1007/978-3-540-39762-5_58	system on a chip;embedded system;parallel computing;asynchronous circuit;computer science;floating point;operating system;circuit design;control bus	EDA	0.21569019865170258	57.87924974807575	164759
dae1b10a5ab5c1b32d6bf29ebf9973b7a1577fc6	optimization of timeout-based power management policies for network interfaces	network interfaces power demand cost function electronic mail power measurement switches;timeout based power management policy energy aware systems networkinterface;power saving dynamic power management policy battery powered consumer electronics device power consuming network interface timeout based power management policy policy parameter selection heuristic approach statistical data analysis optimization;telecommunication power management consumer electronics network interfaces optimisation power consumption statistical analysis	Dynamic power management policies are essential for battery-powered consumer electronics devices, which are mostly equipped with power consuming network interfaces. Timeout-based power management policies are implemented on most operating systems, but the selection of the policy parameters generally resort to heuristic approaches and there is lack of support for network interfaces dynamic power management. Therefore, this paper introduces an innovative solution for timeout-based power management policies for network interfaces. The presented policy exploits statistical data analysis and the optimization of both power savings and performance. The effectiveness of the introduced policy is demonstrated by experimental results1.	heuristic;mathematical optimization;network interface controller;operating system;power management;run time (program lifecycle phase);timeout (computing)	Saulo O. D. Luiz;Angelo Perkusich;Bruna M. J. Cruz;Breno H. M. Neves;Gabriela M. da S. Araujo	2013	IEEE Transactions on Consumer Electronics	10.1109/TCE.2013.6490247	real-time computing;engineering;computer network	EDA	-3.983333135510768	60.07235312126649	165965
98f873df22d59f90025b24033499ed31fd0b42e9	a framework for cosynthesis of memory and communication architectures for mpsoc	platform based design;cosmeca communication architectures memory architectures complex multiprocessor system on chip designs data traffic flow automated application specific cosynthesis framework;integrated memory circuits;traffic flow;satisfiability;system buses;high level synthesis;integrated circuit design;system on chip;memory architecture;digital systems;system on chip high level synthesis integrated circuit design integrated memory circuits memory architecture multiprocessing systems system buses;multiprocessor system on chip;memory architecture costs time to market multiprocessing systems bandwidth network synthesis libraries system performance digital systems high level synthesis;time to market;multiprocessing systems;memory architecture communication system performance digital systems high level synthesis;communication system performance	Memory and communication architectures have a significant impact on the cost, performance, and time-to-market of complex multiprocessor system-on-chip (MPSoC) designs. The memory architecture dictates most of the data traffic flow in a design, which in turn influences the design of the communication architecture. Thus, there is a need to cosynthesize the memory and communication architectures to avoid making suboptimal design decisions. This is in contrast to traditional platform-based design approaches where memory and communication architectures are synthesized separately. In this paper, the authors propose an automated application-specific cosynthesis framework for memory and communication architecture (COSMECA) in MPSoC designs. The primary objective is to design a communication architecture having the least number of buses, which satisfies performance and memory-area constraints, while the secondary objective is to reduce the memory-area cost. Results of applying COSMECA to several industrial strength MPSoC applications from the networking domain indicate a saving of as much as 40% in number of buses and 29% in memory area compared to the traditional approach	bus (computing);central processing unit;clock rate;cluster analysis;constraint graph;dataflow;direct memory access;dynamic random-access memory;eeprom;eprom;instruction set simulator;mpsoc;memory management unit;multiprocessing;network on a chip;overlap–add method;platform-based design;programmable read-only memory;random access;round-robin scheduling;semiconductor intellectual property core;simulation;static random-access memory;throughput;wireless access point	Sudeep Pasricha;Nikil D. Dutt	2007	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2006.884487	system on a chip;uniform memory access;embedded system;computer architecture;parallel computing;computer science;engineering;operating system;traffic flow;high-level synthesis;cache-only memory architecture;integrated circuit design;satisfiability	EDA	1.554731822587506	54.32571996466794	168405
c58b0389ff1a893381553a6a7281adb512f8bb75	a low-power image convolution algorithm for variable voltage processors	voltage control;kernels;kernel;image processing;application software;clocks;perforation;convolution;compaq;dynamic voltage scaling;digital signal processing chips convolution power consumption image processing;itsy;dvs research platform;low power;dvs research platform low power image convolution algorithm variable voltage processors kernels dynamic voltage scaling itsy energy saving compaq;energy consumption;threshold voltage;variable voltage processors;low power image convolution algorithm;digital signal processing chips;circuits;convolution operator;computer science;power consumption;common property;energy saving;convolution dynamic voltage scaling voltage control kernel energy consumption clocks computer science circuits threshold voltage application software	We describe a low-power image convolution algorithm for variable voltage processors. The algorithm takes advantages of common properties of popular kernels. Unlike a direct algorithm of convolution operation where the dynamic voltage scaling (DVS) feature of variable voltage processors cannot be used, our algorithm modifies the sequence of computing convolution sums so that DVS can be effectively utilized. Our implementation on Itsy, a DVS research platform from Compaq, shows the energy saving of up to 71% over that of the direct algorithm without any performance degradation.	buzen's algorithm;central processing unit;convolution;dynamic voltage scaling;elegant degradation;image scaling;low-power broadcasting	Hyugjin Kwon;Jihong Kim	2003		10.1109/ICASSP.2003.1202457	parallel computing;real-time computing;image processing;computer science;mathematics;convolution	EDA	-3.2857018172514425	54.790759307929896	168698
1a53375659520ffc260f62d83c36cc4f4e0827d4	adapting communication for adaptable processors: a multi-axis reconfiguration approach	network on chip;reconfigurable architectures;integrated circuit design;vliw processors communication adaptation adaptable processors multiaxis reconfiguration approach power density manufacturing technologies adaptable systems power consumption memory capacities communication infrastructure design space processing axes memory axes communication axes network on chip reconfigurable processor multiprocessor systems on chip mpsoc;multiprocessing systems;power consumption multiprocessor system on chip network on chip vliw processor;program processors power demand vliw memory management bandwidth cache memory throughput;reconfigurable architectures integrated circuit design multiprocessing systems network on chip	The increasing power density found in newer manufacturing technologies dictates that it is no longer possible for the whole chip to operate at full capacity the entire time. Adaptable systems must be devised to dynamically throttle their power consumption while maintaining the high performance expected by users. Furthermore, adapting processing and memory capacities leads to variable requirements of the communication infrastructure. Thus, in order to find the best solutions in the available design space, adaptability should be applied concordantly to three system axes: processing, memory and communication. In this work, we present the case for an architecture able to dynamically adapt its performance in all such layers. We focus on providing and adaptable Network-on-Chip able to dynamically meet the requirements of a reconfigurable processor.	algorithm;apache axis;central processing unit;digital signal processor;network on a chip;reconfigurable computing;requirement;router (computing);routing	Paulo C. Santos;Gabriel L. Nazar;Luigi Carro;Fakhar Anjam;Stephan Wong	2012	2012 International Conference on Reconfigurable Computing and FPGAs	10.1109/ReConFig.2012.6416726	embedded system;computer architecture;parallel computing;real-time computing;distributed memory;computer science;operating system;network on a chip;integrated circuit design	HPC	-1.3760364023632263	54.42364176180531	170403
fbbcea296d1214686f49d1cfc22d79527e610350	an energy management framework for energy harvesting embedded systems	reward maximization;solar energy;system performance;energy harvesting;wireless sensor node;embedded system;model predictive control;rate control;embedded systems;solar cell;real time scheduling;power management;general electric;kinetic energy;energy scavenging;energy source;energy management	Energy harvesting (also known as energy scavenging) is the process of generating electrical energy from environmental energy sources. There exists a variety of different energy sources such as solar energy, kinetic energy, or thermal energy. In recent years, this term has been frequently applied in the context of small autonomous devices such as wireless sensor nodes. In this article, a framework for energy management in energy harvesting embedded systems is presented. As a possible scenario, we focus on wireless sensor nodes that are powered by solar cells. We demonstrate that classical power management solutions have to be reconceived and/or new problems arise if perpetual operation of the system is required. In particular, we provide a set of algorithms and methods for various application scenarios, including real-time scheduling, application rate control, as well as reward maximization. The goal is to optimize the performance of the application subject to given energy constraints. Our methods optimize the system performance which, for example, allows the usage of smaller solar cells and smaller batteries. Furthermore, we show how to dimension important system parameters like the minimum battery capacity or a sufficient prediction horizon. Our theoretical results are supported by simulations using long-term measurements of solar energy in an outdoor environment. In contrast to previous works, we present a formal framework which is able to capture the performance, the parameters, and the energy model of various energy harvesting systems. We combine different viewpoints, include corresponding simulation results, and provide a thorough discussion of implementation aspects.	autonomous robot;embedded system;expectation–maximization algorithm;power management;real-time clock;scheduling (computing);simulation;solar cell	Clemens Moser;Jian-Jia Chen;Lothar Thiele	2008	JETC	10.1145/1773814.1773818	embedded system;real-time computing;simulation;computer science;engineering;computer performance;energy accounting;energy harvesting	Embedded	-3.639202774884828	59.574159317755324	171290
ac6d81c5ed23f2808e59da3d89b841f8ff7ee242	an energy efficient sensor network processor with latency-aware adaptive compression	energy efficient;sensor network;wireless sensor network;latency aware;compression accelerator;adaptive compression	This paper proposed a novel platform for sensor nodes to resolve the energy and latency challenges. It consists of a processor, an adaptive compressing module and several compression accelerators. We completed the proposed chip in a 0.18 μm HJTC CMOS technology. Compared to the software-based solution, the hardware-assisted compression reduces over 98% energy and 212% latency. Besides, we balanced the energy and latency metric using an adaptive module. According to the scheduling algorithm, the module tunes the state of the compression accelerator, as well as the sampling frequency of the online sensor. For example, given a 9 μs constraint for a 1-byte operation, it reduces 34% latency while the energy overheads are less than 5%. key words: wireless sensor network, compression accelerator, energy efficient, latency aware, adaptive compression	adaptive compression;algorithm;cmos;interrupt latency;network processor;sampling (signal processing);scheduling (computing);sensor	Yongpan Liu;Shuangchen Li;Jue Wang;Beihua Ying;Huazhong Yang	2011	IEICE Transactions	10.1587/transele.E94.C.1220	embedded system;parallel computing;real-time computing;wireless sensor network;computer science	Arch	-0.6306925878527108	58.94329776171237	171635
4b352c393405302e6bf440e952251e491ad24b10	improving energy efficiency for mobile platforms by exploiting low-power sleep states	energy efficiency;power saving;video streaming;energy efficient;reward based sleep state selection;idle duration prediction;form factor;system performance;low power sleep states;low power;mobile platform;energy consumption;power management;error probability;web browsing;power consumption	Reducing energy consumption is one of the most important design aspects for small form-factor mobile platforms, such as smartphones and tablets. Despite its potential for power savings, optimally leveraging system low-power sleep states during active mobile workloads, such as video streaming and web browsing, has not been fully explored. One major challenge is to make intelligent power management decisions based on, among other things, accurate system idle duration prediction, which is difficult due to the non-deterministic system interrupt behavior. In this paper, we propose a novel framework, called E2S3 (Energy Efficient Sleep-State Selection), that dynamically enters the optimal low-power sleep state to minimize the system power consumption. In particular, E2S3 detects and exploits short idle durations during active mobile workloads by, (i) finding optimal thresholds (i.e., energy break-even times) for multiple low-power sleep states, (ii) predicting the sleep-state selection error probabilities heuristically, and by (iii) selecting the optimal sleep state based on the expected reward, e.g., power consumption, which incorporates the risks of making a wrong decision We implemented and evaluated E2S3 on Android-based smartphones, demonstrating the effectiveness of the algorithm. The evaluation results show that E2S3 significantly reduces the platform energy consumption, by up to 50% (hence extending battery life), without compromising system performance.	algorithm;android;form factor (design);heuristic;low-power broadcasting;mobile device;power management;sleep mode;small form factor;smartphone;streaming media;tablet computer	Alexander W. Min;Ren Wang;James Tsai;Mesut A. Ergin;Tsung-Yuan Charlie Tai	2012		10.1145/2212908.2212928	embedded system;real-time computing;simulation;engineering	Mobile	-3.2167324069797316	59.659848242955256	171909
be36667dbb13d0e8fcaba7ce236dde3d8c6bb60d	energy modelling of embedded multimedia streaming applications with gstreamer on heterogeneous mpsoc	audio streaming;video streaming;streaming media energy consumption multimedia communication pipelines estimation power demand energy measurement;multimedia systems;embedded systems;estimation;energy measurement;streaming media;system on chip;energy consumption;computational complexity;pipelines;multimedia communication;video streams energy modelling embedded multimedia streaming applications gstreamer heterogeneous mpsoc embedded systems heterogeneous multicore architectures energy consumption power consumption hardware complexity multimedia streaming applications audio streams;multiprocessing systems;video streaming audio streaming computational complexity embedded systems multimedia systems multiprocessing systems system on chip;power demand	Embedded systems have to support more and more demanding multimedia applications. Heterogeneous multi-core architectures are now commonplace in mobile electronic devices. The impact on the power and energy consumption is tremendous; it has to be evaluated as soon as possible in the design process. Multimedia development frameworks are used to abstract the complexity of the hardware to the designer. In this paper, we propose a methodology to develop high-level performance and consumption models for multimedia streaming applications based on the GStreamer framework. Our approach is based on measurements of the power consumptions and execution times during the processing of combined video and audio streams. Performance and consumption models are build for various plugins instantiated in the corresponding GStreamer pipelines. The combination of estimations for all those plugins leads to a precise evaluation of the complete plugin performances. The precision of the models is evaluated against measurements for different real-life streaming applications.	embedded system;gstreamer;high- and low-level;mpsoc;multi-core processor;performance;pipeline (computing);plug-in (computing);real life	Mickael Lanoe;Eric Senn	2012	2012 IEEE 30th International Conference on Computer Design (ICCD)	10.1109/ICCD.2012.6378686	system on a chip;embedded system;estimation;parallel computing;real-time computing;computer science;pipeline transport;computational complexity theory	Embedded	2.2310407762208	54.75042450978671	171954
c56fadaedec249216e69fca16e3565266a38f2ef	optimize power for portable games on ultrabook	energy conservation;ultrabook power optimization pc game;power aware computing computer games energy conservation notebook computers;power aware computing;pc game power optimization power optimization portable games ultrabook power saving next generation mobile pc platform energy efficiency property strategy analysis;notebook computers;games optimization hardware graphics processing units batteries rendering computer graphics;computer games	Power saving is an important user experience for the applications running on Ultrabook, the next generation mobile PC platform with more portable features. However, traditional PC games, as one kind of the primary applications on Ultrabook, have few energy efficiency concern and practice so far. This paper analyzes the property & strategy of PC game power optimization, presents the practical optimization methods and the tools available for game developers. The Case study of a real game optimized with these methods and tools indicates the obvious power improvement.	mathematical optimization;next-generation network;pc game;personal computer;power optimization (eda);ultrabook;user experience	Guo Sheng;Zhang Yong;Song Zhikai;Shu Fan	2012	2012 International Conference on Energy Aware Computing	10.1109/ICEAC.2012.6471008	embedded system;simulation;computer hardware;computer science	EDA	-1.687417053001489	58.87492135245576	172339
2e923aed6d903f15ac2f09a0faccd7a357902a6f	system-level performance analysis of multiprocessor system-on-chips by combining analytical model and execution time variation	multiprocessor;queuing theory;communication architecture;system on chip;performance analysis	As the impact of the communication architecture on performance grows in a Multiprocessor Systemon-Chip (MPSoC) design, the need for performance analysis in the early stage in order to consider various communication architectures is also increasing. While a simulation is commonly performed for performance evaluation of an MPSoC, it often suffers from a lengthy run time as well as poor performance coverage due to limited input stimuli or their ad hoc applications. In this paper, we propose a novel system-level performance analysis method to estimate the performance distribution of an MPSoC. Our approach consists of two techniques: (1) analytical model of on-chip crossbar-based communication architectures and (2) enumeration of task-level execution time variations for a target application. The execution time variation of tasks is efficiently captured by a memory access workload model. Thus, the proposed approach leads to better performance coverage for an MPSoC application in a reasonable computation time than the simulation-based approach. The experimental results validate the accuracy, efficiency, and practical usage of the proposed approach. 2014 Published by Elsevier B.V.	computation;crossbar switch;hoc (programming language);mpsoc;multiprocessing;performance evaluation;profiling (computer programming);run time (program lifecycle phase);simulation;time complexity	Sungchan Kim;Soonhoi Ha	2014	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/j.micpro.2014.02.003	system on a chip;embedded system;parallel computing;real-time computing;multiprocessing;computer science;operating system;queueing theory	EDA	-0.37285954783512626	56.78258086227107	172871
2f675740dcf456219b9b04da935b5eb5a3351808	archexplorer for automatic design space exploration	time to market constraints;parametric exploration;architectural design;microprocessor chips electronic design automation memory architecture;archexplorer;microarchitecture;open design space exploration framework;multicore processor archexplorer automatic design space exploration architectural complexity time to market constraints architecture design parametric exploration structural exploration web based permanent open design space exploration framework on chip memory subsystem;prefetching;simulation;web based permanent;space exploration;structural exploration;design space;chip;methodology simulation design space exploration microarchitecture;computer architecture;computational modeling;adaptation model;technology and engineering;architectural complexity;memory architecture;automatic design space exploration;on chip memory subsystem;hardware adaptation model space exploration prefetching computational modeling computer architecture benchmark testing;multicore processors;multicore processor;architecture design;time to market;design space exploration;methodology;article;benchmark testing;microprocessor chips;hardware;electronic design automation	Growing architectural complexity and stringent time-to-market constraints suggest the need to move architecture design beyond parametric exploration to structural exploration. ArchExplorer is a Web-based permanent and open design-space exploration framework that lets researchers compare their designs against others. The authors demonstrate their approach by exploring the design space of an on-chip memory subsystem and a multicore processor.	design space exploration;multi-core processor;open design	Veerle Desmet;Sylvain Girbal;Alex Ramírez;Olivier Temam;Augusto Vega	2010	IEEE Micro	10.1109/MM.2010.76	multi-core processor;computer architecture;parallel computing;real-time computing;electronic design automation;computer science;operating system	EDA	2.1971793979340823	55.96736183227796	173100
624a6da6027f3759f3e3f5c4414111c777f1f71f	communication architectures for dynamically reconfigurable fpga designs	communication system;communication architectures;communication networks;logic design;dynamic reconfiguration;reconfigurable architectures field programmable gate arrays logic design;exchangeable hardware modules;reconfigurable architectures;reconfigurable fpga design;field programmable gate arrays communication architectures reconfigurable fpga design exchangeable hardware modules minimal communication system;runtime;computer architecture;joining processes;bandwidth;scalability;field programmable gate arrays;network on a chip;field programmable gate arrays hardware computer architecture bandwidth delay communication networks runtime scalability joining processes network on a chip;minimal communication system;hardware	This paper gives a survey of communication architectures which allow for dynamically exchangeable hardware modules. Four different architectures are compared in terms of reconfiguration capabilities, performance, flexibility and hardware requirements. A set of parameters for the classification of the different communication architectures is presented and the pro and cons of each architecture are elaborated. The analysis takes a minimal communication system for connecting four hardware modules as a common basis for the comparison of the diverse data given in the papers on the different architectures.	field-programmable gate array;interconnect bottleneck;interconnection;reconfigurability;reconfigurable computing;requirement	Thilo Pionteck;Carsten Albrecht;Roman Koch;Erik Maehle;Michael Hübner;Jürgen Becker	2007	2007 IEEE International Parallel and Distributed Processing Symposium	10.1109/IPDPS.2007.370364	embedded system;computer architecture;parallel computing;logic synthesis;scalability;computer science;network on a chip;bandwidth;communications system;field-programmable gate array	Arch	2.1040066702382796	59.94052156672665	174080
80318398ef4d85ca4bfebda19ac5c888a4a1a2d0	orchestrating the execution of stream programs on multicore platforms	conjunto independiente;modelizacion;parallelisme;lenguaje programacion;traitement signal;patron conception;unfolding;data parallel;representation graphique;streaming;programacion entera;compilateur;multimedia;streamit;programming language;stream programming;deploiement;independent set;performance;processeur multicoeur;patron concepcion;despliegue;code generation;cell processor;ejecucion programa;procesador multinucleo;compiler;programmation en nombres entiers;program execution;programming model;modelisation;planificacion;transmission en continu;parallelism;ensemble independant;multicore;programacion lineal;paralelismo;integer programming;execution programme;signal processing;design pattern;linear programming;langage programmation;programmation lineaire;grafo curva;algorithms;procesador oleoducto;coordinacion;planning;multicore processor;transmision fluyente;geometric mean;software pipelining;planification;parallel programming model;processeur pipeline;procesamiento senal;modeling;languages;graphics;integer linear program;compilador;pipeline processor;coordination	While multicore hardware has become ubiquitous, explicitly parallel programming models and compiler techniques for exploiting parallelism on these systems have noticeably lagged behind. Stream programming is one model that has wide applicability in the multimedia, graphics, and signal processing domains. Streaming models execute as a set of independent actors that explicitly communicate data through channels. This paper presents a compiler technique for planning and orchestrating the execution of streaming applications on multicore platforms. An integrated unfolding and partitioning step based on integer linear programming is presented that unfolds data parallel actors as needed and maximally packs actors onto cores. Next, the actors are assigned to pipeline stages in such a way that all communication is maximally overlapped with computation on the cores. To facilitate experimentation, a generalized code generation template for mapping the software pipeline onto the Cell architecture is presented. For a range of streaming applications, a geometric mean speedup of 14.7x is achieved on a 16-core Cell platform compared to a single core.	cell (microprocessor);code generation (compiler);compiler;computation;data parallelism;graphics;integer programming;linear programming;multi-core processor;parallel computing;pipeline (software);signal processing;speedup;stream processing;streaming media;unfolding (dsp implementation)	Manjunath Kudlur;Scott A. Mahlke	2008		10.1145/1375581.1375596	multi-core processor;parallel computing;real-time computing;integer programming;computer science;linear programming;theoretical computer science;signal processing;programming language	PL	-0.1924934975986481	53.98267406895856	174314
499466f099bf2b39b71a1d926a805803729e4b05	instantaneous current modeling in a complex vliw processor core	vliw processor;instruction level current model;low energy;mobile computer;wireless communication;embedded system design;energy consumption;current and power measurement in a processor;elementary functions;instantaneous current model;measurement technique;energy estimate;power and energy model;power measurement	Measuring and modeling instantaneous current consumption or current dynamics of a processor is important in embedded system designs, wireless communications, low-energy mobile computing, security of communications, and reliability. In this paper, we introduce a new instruction-level based macromodeling approach for instantaneous current consumption in a complex processor core along with new instantaneous current measurement techniques at the instruction and program level. Current consumption and voltage supply waveforms of a processor core were acquired by a sampling oscilloscope through an external interrupt-based setup. Accurate measurements of current, power and energy consumption at the instruction, block, or program level were obtained from analyzing the stored current and voltage waveforms. The current simulation methodology uses elementary functions called atomic functions to approximate the instantaneous current consumption at the instruction level. Based on these atomic functions, a simulated instantaneous current waveform at the program level was built. First, a base waveform of the current simulation was generated by the use of four basic current superposition principles. Secondly, a final waveform of the simulated current was generated from the base waveform by applying a factorial adjustment as a function of the instruction parallelism and sequencing. Step-by-step modeling procedures with numerical examples are presented. The model captured 98% of the variation of the instantaneous current for six complex applications, with an average RMS error of less than 2.2% of the average measured mean. Energy estimates obtained by the use of the simulated current waveforms were within 1.4% of the measured values. This research is important, since for the first time highly accurate instruction-based models of instantaneous current and power for complex processor cores have been developed.	approximation algorithm;computer program;elementary function;embedded system;interrupt;mobile computing;multi-core processor;numerical analysis;parallel computing;programme level;sampling (signal processing);simulation;waveform	Radu Muresan;Catherine H. Gebotys	2005	ACM Trans. Embedded Comput. Syst.	10.1145/1067915.1067923	embedded system;real-time computing;computer science;elementary function;operating system;mobile computing;wireless	Arch	-2.3870626700002378	57.83504407596789	175982
1a6a792424cbcb20c6e860532fa93239775a2c36	inter- rogram compilation for disk energy reduction.	gestion energia;compilacion;diseno circuito;circuit design;optimizacion compiladora;program verification;effet dimensionnel;analisis programa;program optimization;verificacion programa;gestion energie;programa aplicacion;application program;energy consumption;size effect;programme application;compiler optimization;consommation energie;compilation;conception circuit;optimisation programme;compilateur optimisation;program analysis;efecto dimensional;power consumption;analyse programme;consommation energie electrique;verification programme;optimizing compilers;optimisation compilateur;consumo energia;energy management;optimizacion programa	Compiler support for power and energy management has been shown to be effective in reducing overall power dissipation and energy consumption of individual programs, for instance through compilerdirected resource hibernation and dynamic frequency and voltage scaling (DVS). Typically, optimizing compilers perform intra-program analyses and optimizations, i.e., optimize the input program without the knowledge of other programs that may be running at the same time on the particular target machine. In this paper, we investigate the opportunities of compiling sets of programs together as a group with the goal of reducing overall disk energy. A preliminary study and simulation results for this inter-program compilation approach shows that significant disk energy can be saved (between 5% and 16%) over the individually, disk energy optimized programs for three benchmark applications.	benchmark (computing);computer;concurrency (computer science);distributed computing;dynamic voltage scaling;experiment;forward error correction;handheld game console;hardware description language;hibernation (computing);input/output;mathematical optimization;mobile computing;network packet;operating system;optimizing compiler;program analysis;program optimization;runtime system;scheduling (computing);simulation;very-large-scale integration	Jerry Hom;Ulrich Kremer	2003		10.1007/978-3-540-28641-7_2	real-time computing;simulation;engineering;algorithm	Arch	-2.436105941984834	54.41967360653445	176060
3e7bae8de3ad01f64f322f5734d444fd6a3d64c6	multi-objective exploration of compiler optimizations for real-time systems	optimising compilers;pareto optimisation;code transformations;evolutionary computation;multiobjective optimizer;pareto optimal solutions;approximation algorithms;compiler optimization sequences;real time;multi objective optimization;average case execution time;embedded systems software;spectrum;stochastic programming embedded systems evolutionary computation optimising compilers pareto optimisation;compiler;embedded system;objective function;embedded systems;worst case execution time;wcet;registers;statistical performance assessments;compiler optimization;pareto;optimizing compilers real time systems embedded system embedded software distributed computing software systems standards development timing aerospace electronics computer science;adaptive worst case execution time aware compiler framework;code size;optimization;approximation methods;search problems;pareto real time wcet compiler multi objective optimization;stochastic programming;performance degradation;pareto optimal solution;benchmark testing;performance assessment;multiobjective optimizer real time systems embedded systems software average case execution time code transformations performance degradation adaptive worst case execution time aware compiler framework compiler optimization sequences stochastic evolutionary multiobjective algorithms pareto optimal solutions statistical performance assessments;stochastic evolutionary multiobjective algorithms;real time systems	With the growing complexity of embedded systems software, high code quality can only be achieved using a compiler. Sophisticated compilers provide a vast spectrum of various optimizations to improve code aggressively w. r. t. different objective functions, e. g., average-case execution time (ACET) or code size. Due to the complex interactions between the optimizations, the choice for a promising sequence of code transformations is not trivial. Compiler developers address this problem by proposing standard optimization levels, e. g., O3 or Os. However, previous studies have shown that these standard levels often miss optimization potential or might even result in performance degradation. In this paper, we propose the first adaptive WCET-aware compiler framework for an automatic search of compiler optimization sequences which yield highly optimized code. Besides the objective functions ACET and code size, we consider the worst-case execution time (WCET) which is a crucial parameter for real-time systems. To find suitable trade-offs between these objectives, stochastic evolutionary multi-objective algorithms identifying Pareto optimal solutions are exploited. A comparison based on statistical performance assessments is performed which helps to determine the most suitable multi-objective optimizer. The effectiveness of our approach is demonstrated on real-life benchmarks showing that standard optimization levels can be significantly outperformed.	approximation;benchmark (computing);best, worst and average case;elegant degradation;embedded system;evolutionary algorithm;interaction;loss function;mathematical optimization;optimization problem;optimizing compiler;pareto efficiency;real life;real-time clock;real-time computing;real-time locating system;real-time operating system;real-time transcription;run time (program lifecycle phase);service-oriented software engineering;software quality;worst-case execution time	Paul Lokuciejewski;Sascha Plazar;Heiko Falk;Peter Marwedel;Lothar Thiele	2010	2010 13th IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing	10.1109/ISORC.2010.15	stochastic programming;pareto principle;spectrum;benchmark;compiler;parallel computing;real-time computing;profile-guided optimization;compiler correctness;interprocedural optimization;computer science;loop optimization;superoptimization;theoretical computer science;multi-objective optimization;dead code elimination;program optimization;optimizing compiler;processor register;compilation error;inline expansion;functional compiler;evolutionary computation;worst-case execution time	Embedded	0.36860516546653865	56.61654040094321	176325
adf211a17941962783a1d024faf8e5f6862f8c7b	a hardware/software partitioning and scheduling approach for embedded systems with low-power and high performance requirements	conception conjointe;diseno circuito;haute performance;systeme embarque;diseno conjunto;circuit design;circuit vlsi;multimedia application;embedded system;embedded systems;vlsi circuit;low power;codesign;hardware software partitioning;energy consumption;scheduling;puissance faible;consommation energie;alto rendimiento;conception circuit;power consumption;circuito vlsi;high performance;ordonnancement;reglamento;consumo energia;potencia debil	Hardware/software (hw/sw) partitioning largely affects the system cost, performance, and power consumption. Most of the previous hw/sw partitioning approaches are focused on either optimising the hw area, or the performance. Thus, they ignore the influence of the partitioning process on the energy consumption. However, during this process the designer still has the maximum flexibility, hence, it is clearly the best moment to analyse the energy consumption. We have developed a new hw/sw partitioning and scheduling tool that reduces the energy consumption of an embedded system while meeting high performance constraints. We have applied it to two current multimedia applications saving up to 30% of the system energy without reducing the performance.	central processing unit;computer performance;design space exploration;disk partitioning;embedded system;interconnection;real-time clock;real-time computing;requirement;run time (program lifecycle phase);scheduling (computing);system bus;transform, clipping, and lighting	Javier Resano;Daniel Mozos;Elena Pérez-Miñana;Hortensia Mecha;Julio Septién	2003		10.1007/978-3-540-39762-5_64	co-design;embedded system;parallel computing;real-time computing;computer science;circuit design;scheduling	EDA	-0.6648260720561754	54.44137667972111	177035
eae11e1e376fcca8ee0e25b52fd65a0a2f4aed18	estimating maximum error impact in dynamic data-driven applications for resource-aware adaption of software-based fault-tolerance		The rise of transient faults in modern hardware requires system designers to consider errors occurring at runtime. Both hardware- and software-based error handling must be deployed to meet application reliability requirements. The level of required reliability can vary for system components and depend on input and state, so that a selective use of resilience methods is advised, especially for resource-constrained platforms as found in embedded systems. If an error occurring at runtime can be classified as having negligible or tolerable impact, less effort can be spent on correcting it. As the actual impact of an error is often dependent on the state of a system at time of occurrence, it can not be determined precisely for highly dynamic workloads in data-driven applications. We present a concept to estimate error propagation in sets of tasks with variable data dependencies. This allows for a coarse grained analysis of the impact a failed task may have on the overall output. As an application example, we demonstrate our method for a typical dynamic embedded application, namely a decoder for the H.264 video format.	algorithm;dynamic data;fault tolerance	Björn Bönninghoff;Horst Schirmeier	2016	CoRR		embedded system;parallel computing;real-time computing;simulation;computer science;operating system;distributed computing	EDA	-1.6908684905908387	56.703821699771524	178613
2b3910fde67f74823d1d032124d43e21ce6cc681	energy- and area-efficient architectures through application clustering and architectural heterogeneity	multimedia application;embedded system;efficient custom architectures;energy efficient design;sensor nodes;heterogeneous isa processors;energy saving	Customizing architectures for particular applications is a promising approach to yield highly energy-efficient designs for embedded systems. This work explores the benefits of architectural customization for a class of embedded architectures typically used in energy- and area-constrained application domains, such as sensor nodes and multimedia processing. We implement a process flow that performs an automatic synthesis and evaluation of the different architectures based on runtime profiles of applications and determines an efficient architecture, with consideration for both energy and area constraints. An expressive architectural model, used by our engine, is introduced that takes advantage of efficient opcode allocation, several memory addressing modes, and operand types. By profiling embedded benchmarks from a variety of sensor and multimedia applications, we show that the energy savings resulting from various architectural optimizations relative to the base architectures (e.g., MIPS and MSP430) are significant and can reach 50p, depending on the application. We then identify the set of architectures that achieves near-optimal savings for a group of applications. Finally, we propose the use of heterogeneous ISA processors implementing those architectures as a solution to capitalize on energy savings provided by application customization while executing a range of applications efficiently.	cluster analysis	Lukasz Strozek;David M. Brooks	2009	TACO	10.1145/1509864.1509868	embedded system;parallel computing;real-time computing;computer science;operating system	EDA	-1.1875033476505406	53.61248760168996	179458
497afcc44810d922eb6012fff240d96b6e6784f6	scheduling power-constrained tests through the soc functional bus	functional bus;appareillage essai;tecnologia electronica telecomunicaciones;interconnection;integrated circuit;canal bus;test access mechanism;canal colector;simultaneidad informatica;circuito integrado;packet switching;packet based scheduling;conmutacion por paquete;buffer system;system on a chip;sistema amortiguador;functional tam;algorithme;interconexion;algorithm;scheduling algorithm;concurrency;sistema sobre pastilla;system on chip;scheduling;aparato ensayo;interconnexion;testing equipment;bus channel;systeme sur puce;power constrained;tecnologias;grupo a;systeme tampon;system on chip testing;simultaneite informatique;commutation paquet;ordonnancement;circuit integre;reglamento;algoritmo	This paper proposes a test methodology for core-based testing of System-on-Chips by utilizing the functional bus as a test access mechanism. The functional bus is used as a transportation channel for the test stimuli and responses from a tester to the cores under test (CUT). To enable test concurrency, local test buffers are added to all CUTs. In order to limit the buffer area overhead while minimizing the test application time, we propose a packet-based scheduling algorithm called PAcket Set Scheduling (PASS), which finds the complete packet delivery schedule under a given power constraint. The utilization of test packets, consisting of a small number of bits of test data, for test data delivery allow an efficient sharing of bus bandwidth with the help of an effective buffer-based test architecture. The experimental results show that the methodology is highly effective, especially for smaller bus widths, compared to previous approaches that do not use the functional bus.	scheduling (computing)	Fawnizu Azmadi Hussin;Tomokazu Yoneda;Alex Orailoglu;Hideo Fujiwara	2008	IEICE Transactions	10.1093/ietisy/e91-d.3.736	system on a chip;embedded system;parallel computing;real-time computing;computer science;local bus;automatic test pattern generation;operating system;scheduling	Vision	0.46186330211351123	58.249949231772874	179681
782f51234fd0464b9e213622ae149db670a41d28	a non-volatile microcontroller with integrated floating-gate transistors	processor architecture;microcontrollers;random access memory;word length 8 bit nonvolatile microcontroller nonvolatile processor architecture integrated floating gate transistors embedded devices mobile devices energy constrained environments microprocessor self powered devices volatile storage nonvolatile storage minimal latency energy consumption per cell integration volatile state elements system level optimizations;mobile device;floating gate;computer architecture;energy consumption;transistors;nonvolatile memory;normal operator;random access storage;power consumption;nonvolatile memory computer architecture microcontrollers random access memory energy consumption transistors;random access storage microcontrollers	We present a non-volatile processor architecture where its entire state can be almost instantly stored and restored in a non-volatile fashion. This capability is attractive for embedded or mobile devices in highly energy constrained environments. The non-volatile microprocessor can enable long computations to continue across power interruptions on self-powered devices or save idle power consumption without sacrificing responsiveness. To realize this vision, a microprocessor must be able to copy state between volatile and non-volatile storage with minimal latency and energy consumption. Our non-volatile architecture addresses this challenge through a per-cell integration of floating-gate non-volatile transistors into volatile state elements and careful system-level optimizations to hide expensive non-volatile operations. We evaluate this approach with a transistor-level prototype of an 8-bit nonvolatile microcontroller. Experiments indicate that the proposed architecture has minimal impact on normal operation while enabling all processor state to be preserved across an unexpected power interruption.	8-bit;computation;embedded system;interrupt;microcontroller;microprocessor;mobile device;non-volatile memory;prototype;responsiveness;transistor;volatile memory	Wing-Kei S. Yu;Shantanu Rajwade;Sung-En Wang;Bob Lian;G. Edward Suh;Edwin Kan	2011	2011 IEEE/IFIP 41st International Conference on Dependable Systems and Networks Workshops (DSN-W)	10.1109/DSNW.2011.5958839	microcontroller;embedded system;semiconductor memory;parallel computing;non-volatile memory;computer hardware;microarchitecture;computer science;operating system;mobile device;normal operator;transistor	EDA	-2.4968852820278213	57.49537739878104	179764
c6017b96eeef0e0626392f00641f970ecf35c39b	s/390 cmos server i/o: the continuing evolution	computadora;concepcion sistema;ordinateur;modelo entrada salida;implementation;serveur informatique;tecnologia mos complementario;computer;input output interface;ejecucion;input output model;modele entree sortie;interface entree sortie;system design;interfase entrada salida;servidor informatico;systeme parallele;parallel system;technologie mos complementaire;conception systeme;sistema paralelo;complementary mos technology;computer server	IBM has developed a strategy to achieve the high I/O demands of large servers. In a new environment of industry-standard peripheral component interconnect (PCI) attached adapters conforming to open I/O interfaces, S/390® has developed an efficient method of quickly integrating disk storage, communications, and future adapters. Preserving the S/390 I/O programming model and the high level of data integrity expected in S/390 products and reducing development cycle time and resources have further constrained design options. At the same time, S/390 developers have redesigned the traditional I/O components into the latest chip technologies. The developers have also designed a new internal link (STI) to meet the increased I/O bandwidth and connectivity required by the high processor performance of the third and fourth generations of S/390 CMOS servers. This paper describes this strategy and how it has led to systems that retain the differentiating features of S/390 products.		Thomas A. Gregg	1997	IBM Journal of Research and Development	10.1147/rd.414.0449	embedded system;electronic engineering;simulation;input–output model;channel i/o;telecommunications;computer science;engineering;electrical engineering;operating system;implementation;server;systems design	Robotics	0.6974678156704021	58.27944877085287	182887
0c48e026ffc7946d103a646721573b11080cbda9	dynamic power management of laptop hard disk	fault clustering;system modeling;continuous time models;defect clustering;reject ration;power management;fault coverage;user behavior;power consumption;defect level;dynamic power management;user interaction;high performance	Optimal power management policies for laptop hard disk are obtained with a system model that can handle non-exponential interarrival times in the idle and the sleep states. The measurement results on Sony Vaio laptop show that our policy has1:7 times less power consumption as compared to the default Windows timeout policy with still high performance. Battery-operated portable systems, such as laptops, demand tight constraints on energy consumption. In this paper we focus on power management for a hard disk on a laptop. The most common policy for hard disks is a timeout policy implemented in most operating systems. The policy optimization technique proposed in [2] solves the policy optimization problem using discrete-time Markov decision processes (DTMDP). All state transitions are assumed to follow stationary geometric distribution. The decision evaluation is repeated periodically, even when the system is idle, thus wasting power. Extensions to the DTMDP model are event-driven continuous-time (CTMDP) and semi-Markov (SMDP) decision process models [3, 4]. Both CTMDP and SMDP models assume exponential service request arrival times, and thus can have high energy costs and a large performance penalty. The power manager makes one decision as soon as the system is idle. If the decision is to stay awake, the system will wait until another arrival before revising the decision, possibly missing large idle times. Measurements show that the first arrival times are better modeled with a non-exponential distribution, such as Pareto. As a result, time-indexed semi-Markov decision process model (TISMDP) is then needed to obtain optimal policy. Policy decisions are still made in event-driven manner in low-power states thus saving power by not forcing policy re-evaluations. In the idle state, policy decision are re-evaluated until the transition is made into the sleep state, thus saving power during longer breaks. The policy optimization problem based on TISMDP model can be solved exactlyand in polynomial time (just under 1 minute on a 300MHz Pentium). Comparison of the measurement results for different policies implemented on the Sony Vaio laptop is shown in Table 1. TISMDP policy consumes 1:7 times less power than the default Windows timeout policy of 120s and 1:4 times less power than the 30s timeout policy. From our experience with the user interaction with the hard disk, the TISMDP algorithm performs well, thus giving us lowpower consumption with still good performance. The policy based on continuous-time model (CTMDP) performs worse then always-on policy, primarily due to the exponential interarrival request assumption. This policy both misses some long idle periods, and tends to shut-down too agressively, as can be seen from its very short average sleep time, Tas. Our policy also outperforms one based on the competitive algorithm (CA) [1] that is guaranted to yield a policy that consumes at worst twice the minimum amount of power consumed by the policy computed with perfect knowledge of the user behavior. Table 1. Measurement Comparison Algorithm Pwr (W) Tas (s) oracle policy 0.33 118 TISMDP 0.40 81 CA (5.43s timeout) 0.44 79 30s timeout 0.51 157 120s timeout 0.67 255	algorithm;event-driven architecture;event-driven programming;hard disk drive;high availability;laptop;low-power broadcasting;markov chain;markov decision process;mathematical optimization;microsoft windows;operating system;optimization problem;pareto efficiency;power management;process modeling;scale (map);semiconductor industry;stationary process;time complexity	Tajana Simunic;Luca Benini;Peter W. Glynn;Giovanni De Micheli	2000		10.1145/343647.344103	embedded system;real-time computing;simulation;systems modeling;fault coverage;engineering;operating system	Metrics	-3.9782234142042885	60.32004210602588	184281
08cfe650fdfa907764423958b1923e42ba945b7e	hybrid analytical-statistical modeling for efficiently exploring architecture and workload design spaces	architectural design;workload parameters hybrid analytical statistical modeling efficient architecture exploration workload design spaces microprocessor design time processor configurations early design stage methodology design space culling regions of interest analytical modeling statistical modeling register traffic characteristics power law properties;probability;performance evaluation;space exploration microprocessors design methodology traffic control performance analysis bridges information analysis information systems electronic mail electronic switching systems;virtual machines computer architecture performance evaluation microcomputers statistical analysis probability;performance;statistical method;design space;statistical model;computer architecture;statistical analysis;technology and engineering;virtual machines;region of interest;power law;microcomputers	Abstract: Microprocessor design time and effort are getting impractical due to the huge number of simulations that need to be done to evaluate various processor configurations for various workloads. An early design stage methodology could be useful to efficiently cull huge design spaces to identify regions of interest to be further explored using more accurate simulations. In this paper, we present an early design stage method that bridges the gap between analytical and statistical modeling. The hybrid analytical-statistical method presented here is based on the observation that register traffic characteristics exhibit power law properties which allows us to fully characterize a workload with just a few parameters which is much more efficient than the collection of distributions that need to be specified in classical statistical modeling. We evaluate the applicability and the usefulness of this hybrid analytical-statistical modeling technique to efficiently and accurately cull huge architectural design spaces. In addition, we demonstrate that this hybrid analytical-statistical modeling technique can be used to explore the entire workload space by varying just a few workload parameters.	microprocessor;region of interest;simulation;spaces;statistical model	Lieven Eeckhout;Koen De Bosschere	2001		10.1109/PACT.2001.953285	statistical model;power law;parallel computing;real-time computing;simulation;performance;computer science;virtual machine;theoretical computer science;operating system;probability;microcomputer;region of interest	EDA	1.6199362348112554	56.03515217613159	184908
0402cd19ab2a32219d2b3e65638db74acba9044f	studying the code compression design space - a synthesis approach	power estimation;embedded systems;high level synthesis;logic synthesis;code compression	Embedded domain has witnessed the application of different code compression methodologies on different architectures to bridge the gap between ever-increasing application size and scarce memory resources. Selection of a code compression technique for a target architecture requires a detailed study and analysis of the code compression design space. There are multiple design parameters affecting the space, time, cost and power dimensions. Standard approaches of exploring the code compression design space are tedious, time consuming, and almost impractical with the increasing number of proposed compression algorithms. This is one of the biggest challenges faced by an architect trying to adopt a code compression methodology for a target architecture. We propose a novel synthesis based tool-chain for fast and effective exploration of the code compression design space and for evaluation of the tradeoffs. The tool-chain consists of a frontend framework that works with different compression/decompression schemes and a backend with high-level-synthesis, logic-synthesis, and power estimation tools to output the critical design parameters. We use the tool-chain to effectively analyze different code compression/decompression schemes of varying complexities.		Sreejith K. Menon	2014	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2013.11.001	embedded system;parallel computing;logic synthesis;real-time computing;simulation;computer science;theoretical computer science;operating system;high-level synthesis;algorithm	EDA	1.1555530465862665	54.026151185328544	185403
61c642bd2867da47a2039e30f84a9e44e9b582ff	an intra-task dvfs technique based on statistical analysis of hardware events	generic model;optimization technique;performance estimation;satisfiability;dynamic information;statistical analysis;energy consumption;hardware performance counters;dvfs;dynamic voltage and frequency scaling;dynamic optimization;knowledge base;time constraint	The importance and demand for various types of optimization techniques for program execution is growing rapidly. In particular, dynamic optimization techniques are regarded as important. Although conventional techniques usually generated an execution model for dynamic optimization by qualitatively analyzing the behaviors of computer systems in a knowledge-based manner, the proposed technique generates models by statistically analyzing the behaviors from quantitative data of hardware events. In the present paper, a novel dynamic voltage and frequency scaling (DVFS) method based on statistical analysis is proposed. The proposed technique is a hybrid technique in which static information, such as the breakpoint of program phases and, dynamic information, such as the number of cache misses given by the performance counter, are used together. Relationships between the performance and values of performance counters are learned statistically in advance. The compiler then inserts a run-time code for predicting the performance and setting the appropriate frequency/voltage depending on the predicted performance. The proposed technique can greatly reduce the energy consumption while satisfying soft timing constraints.	breakpoint;cpu cache;compiler;dynamic frequency scaling;dynamic programming;dynamic voltage scaling;image scaling;mathematical optimization	Hiroshi Sasaki;Yoshimichi Ikeda;Masaaki Kondo;Hiroshi Nakamura	2007		10.1145/1242531.1242551	parallel computing;real-time computing;profile-guided optimization;computer science;theoretical computer science	EDA	-2.885618139961764	54.33507488772695	185550
d142c906ef7611911d39cdcc5d242b559441180d	methodology for power mode selection in fd-soi circuits with dvfs and dynamic body biasing	power supply circuits;oscillators;silicon on insulator;power aware computing;dynamic voltage and frequency scaling technique power mode selection fd soi circuits dvfs technique dynamic body biasing technique embedded system power consumption discretely convex subset ring oscillator;silicon on insulator microprocessor chips oscillators power aware computing power consumption power supply circuits;power consumption;power demand actuators clocks time frequency analysis threshold voltage ring oscillators context;microprocessor chips	Embedded systems need ever increasing computational performances. Since they have limited energy resources, power consumption has to be minimized. Dynamic Voltage and Frequency Scaling (DVFS) techniques combined with Body Biasing techniques decrease the power consumption of a chip by providing just enough computational performance to the chip so as to finish the task at its deadline. A Power Mode (PM) is defined with the clock frequency F applied to the chip and the power P consumed by the chip. Executing tasks with the 2 neighbor frequencies of the target frequency should minimize the power consumption. Unfortunately, this choice is not always optimal since the set of available PMs may not fulfil the convexity property anymore when 3 actuators are considered. Here, a method is proposed to tackle this issue. PMs are selected to form a discretely convex subset. Results for a ring oscillator in FD-SOI exemplify that the proposed approach can save power consumption.	biasing;clock rate;computation;convex set;dynamic frequency scaling;dynamic voltage scaling;embedded system;exemplification;performance;ring oscillator	Yeter Akgul;Diego Puschini;Suzanne Lesecq;Edith Beigné;Pascal Benoit;Lionel Torres	2013	2013 23rd International Workshop on Power and Timing Modeling, Optimization and Simulation (PATMOS)	10.1109/PATMOS.2013.6662174	power gain;embedded system;electronic engineering;real-time computing;power factor;engineering;silicon on insulator;switched-mode power supply;oscillation	EDA	-1.6340229033935754	57.22314875595405	185570
31eea7c3769b0255f8e183ef44749af6437ba153	embedded reconfigurable architectures	dynamic reconfiguration;embedded systems and applications;simulation;compilers;processor design;memory hierarchies;noc	In current-day embedded systems design, one is faced with cut-throat competition to deliver new functionalities in increasingly shorter time frames. This is now achieved by incorporating processor cores into embedded systems through (re-)programmability. However, this is not always beneficial for the performance or energy consumption. Therefore, adaptable embedded systems have been proposed to deal with these negative effects by reconfiguring the critical sections of an embedded system. In these proposals, we are clearly witnessing a trend that is moving from static configurations to dynamic (re)configurations.  Consequently, the proposed embedded systems can adapt their functionality at run-time to meet the application(s) requirements (e.g., performance) while operating in different environments (e.g., power and hardware resources). Besides processor cores, we have to deal with memory hierarchies and network-on-chips that should also be (dynamically) reconfigurable. Furthermore, the interplay of these components is increasing the design complexity that can be only alleviated if they can self-optimize.  In this tutorial, we will present and discuss several strategies to perform the mentioned dynamic reconfiguration of the processor, memory, and NoC components - together with their interaction. We will review and present the state-of-the-art for the design of each component that allows for a gradual selection of design points in the trade-off between performance and power. Finally, we will highlight an open-source project that incorporates many approaches for dynamic reconfiguration in both actual hardware and simulation accompanied by the necessary tools.	critical section;embedded system;memory hierarchy;network on a chip;open-source software;requirement;simulation;systems design	Stephan Wong;Luigi Carro;Stamatios Kavvadias;Georgios Keramidas;Francesco Papariello;Claudio Scordino;Roberto Giorgi;Stefanos Kaxiras	2012		10.1145/2380403.2380444	embedded system;computer architecture;compiler;parallel computing;real-time computing;processor design;computer science;operating system;network operations center;programming language	EDA	-0.011595035967262845	55.359375685581085	187750
582be29cf0c717f91c47bd467c9f719582c64888	fmrpu: design of fine-grain multi-context reconfigurable processing unit	data parallel;evaluation performance;communication system;architecture systeme;estimation mouvement;reconfigurable system;performance evaluation;routing;reconfigurable architectures;evaluacion prestacion;estimacion movimiento;reconfigurable logic;routage;motion estimation;circuito logico;computer architecture;architecture ordinateur;circuit logique;contexto;multimedia communication;contexte;system development;arquitectura sistema;arquitectura ordenador;high throughput;system architecture;communication multimedia;logic circuit;architecture reconfigurable;context;enrutamiento	At present the scale of multimedia and communication systems has become more and more complicated due to their fast developments. In order to handle diverse functions and shorten system development time, the ability to reconfigure system architecture becomes an important and flexible design consideration. In this paper, we propose a novel reconfigurable processing unit, FMRPU, which is a fine-grain with multi-context reconfigurable processing unit targeting at high-throughput and data-parallel applications. It contains 64 reconfigurable logic evel connectivity. According to the simulation results, the longest routing arrays, 16 switch boxes, and connects with each other via three hierarchical-lpath of FMRPU only takes 6.5 ns at 0.35 processes, which is able to construct the required logic circuit efficiently. To compare with same kind devices in dealing with Motion Estimation operations, the performance is raise to 17% and has excellent performance in executing DSP algorithms.		Jih-Ching Chiu;Ren-Bang Lin	2005		10.1007/11572961_15	high-throughput screening;embedded system;computer vision;routing;parallel computing;real-time computing;logic gate;computer science;operating system;motion estimation;distributed computing;communications system;systems architecture	EDA	1.924337854389752	56.889924538730625	188039
675a4af0403cf453f2607505c772178aaf6f205a	run-time minimization of reconfiguration overhead in dynamically reconfigurable systems	reconfiguration;dynamic programming;diseno circuito;reconfiguracion;programacion dinamica;multiprocessor;dynamic reconfiguration;reconfigurable architectures;circuit design;simultaneidad informatica;system performance;interconnection network;concurrency;energy consumption;scheduling;programmation dynamique;conception circuit;multiprocesador;simultaneite informatique;architecture reconfigurable;ordonnancement;reglamento;multiprocesseur	Dynamically Reconfigurable Hardware (DRHW) can take advantage of its reconfiguration capability to adapt at run-time its performance and its energy  consumption. However, due  to  the  lack of programming  support  for dynamic  task  placement  on  these  platforms,  little  previous work  has  been  presented studying these run-time performance/power trade-offs. To cope with the task  placement  problem  we  have  adopted  an  interconnection-network-based DRHW model with specific support  for  reallocating  tasks at run-time. On top of  it,  we  have  applied  an  emerging  task  concurrency  management  (TCM) methodology previously applied  to multiprocessor platforms. We have  identified that the reconfiguration overhead can drastically affect both the system performance and energy consumption. Hence, we have developed two new modules  for  the  TCM  run-time  scheduler  that minimize  these  effects.  The  first module reuses previously loaded configurations, whereas the second minimizes the impact of the reconfiguration latency by applying a configuration prefetching technique. With these techniques reconfiguration overhead is reduced by a factor of 4.	cpu cache;computer cooling;concurrency (computer science);interconnection;multiprocessing;overhead (computing);reconfigurability;reconfigurable computing;run time (program lifecycle phase);scheduling (computing)	Javier Resano;Daniel Mozos;Diederik Verkest;Serge Vernalde;Francky Catthoor	2003		10.1007/978-3-540-45234-8_57	embedded system;parallel computing;real-time computing;multiprocessing;concurrency;computer science;control reconfiguration;operating system;dynamic programming;circuit design;computer performance;scheduling	Embedded	-1.2559802185967903	54.17554900303685	188813
1ef7f7fccdbc8fafa23a77cf3a5eccd42b042ae6	a compiler assisted wear leveling for morphable pcm in embedded systems	wear leveling;embedded systems;phase change memory;endurance	Phase change memory (PCM) is considered as a promising alternative of DRAM-based main memory in embedded systems. A PCM cell can be dynamically programmed to be in either multiple-level cell (MLC) mode or single-level cell (SLC) mode. With this morphable feature, we can utilize the high-density of MLC and low-latency of SLC, to satisfy various memory requirements of specific applications in embedded systems. However, compared to its SLC counterpart, the lifetime of MLC is limited. To address this issue, this paper proposes a simple and effective wear-leveling technique, named Mixer , to enhance the lifetime of morphable PCM considering the program specific features. We first build an Integer Linear Programming (ILP) formulation to dynamically configure the optimal SLC/MLC partition in morphable PCM, and produce the best data allocation for each variable to achieve a balanced write distribution in morphable PCM with low memory access cost. The basic idea is to allocate low-latency SLC and high-density MLC cells for write intensive variables and other ordinary variables, respectively. We then propose a polynomial time algorithm to achieve near-optimal results. The evaluation results show that the proposed technique can effectively improve the lifetime of morphable PCM in embedded systems compared with previous work. © 2016 Published by Elsevier B.V.	algorithm;cell (microprocessor);compiler;computer data storage;dynamic random-access memory;embedded system;integer programming;linear programming;multi-level cell;p (complexity);phase-change memory;requirement;wear leveling	Linbo Long;Edwin Hsing-Mean Sha;Duo Liu;Liang Liang;Kan Zhong;Xiao Zhu	2016	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2016.06.007	embedded system;parallel computing;real-time computing;phase-change memory;computer hardware;computer science	EDA	-2.30548393961501	53.48347628874804	189447
19cf0df9aa0ceae377b279e667df6350e6e48c4e	power consumption estimation of a c program for data-intensive applications	digital circuit;traitement signal;concepcion asistida;digital signal processing;data intensive application;evaluation performance;computer aided design;diseno circuito;algorithm performance;performance evaluation;integrated circuit;langage c;code optimization;optimal code;code optimal;estudio comparativo;evaluacion prestacion;circuit design;optimization method;circuito integrado;metodo optimizacion;design space;experimental result;circuit numerique;texas instruments;etude comparative;tratamiento numerico;c language;assembly language;resultado algoritmo;signal processing;comparative study;circuito numerico;performance algorithme;estimacion parametro;methode optimisation;resultado experimental;conception assistee;digital signal processor;langage assemblage;digital processing;conception circuit;processeur signal numerique;parameter estimation;estimation parametre;power consumption;consommation energie electrique;codigo optimal;procesador senal numerica;resultat experimental;procesamiento senal;power modeling;traitement numerique;circuit integre;lenguaje c	A method for estimating the power consumption of an algorithm is presented. The estimation can be performed both from the C program and from the assembly code. It relies on a power model for the targeted processor. Without compilation, several targets can be compared at the C-level in order to rapidly explore the design space. The estimation can be refined afterwards at the assembly level to allow further code optimizations. The power model of the Texas Instrument TMS320C6201 is presented as a case study. Estimations are performed on real-life digital signal processing applications with average errors of 4.2 % at the C-level, and 1.8 % at the assembly level.	algorithm;assembly language;cpu cache;central processing unit;compiler;digital signal processing;instruction pipelining;map;online and offline;parallel computing;pipeline (computing);read-only memory;real life;run time (program lifecycle phase)	Eric Senn;Nathalie Julien;Johann Laurent;Eric Martin	2002		10.1007/3-540-45716-X_33	digital signal processor;simulation;telecommunications;computer science;electrical engineering;integrated circuit;digital signal processing;computer aided design;circuit design;comparative research;program optimization;signal processing;estimation theory;digital electronics;algorithm;assembly language	EDA	-1.8019247614179288	54.209628710602495	189700
9011f3c84e9a33ee64a2d95bd1b4f9681e4c04b9	reducing execution unit leakage power in embedded processors	utilisation information;salida;optimisation;uso informacion;calculateur embarque;optimizacion;execution time;information use;fuite;low power;temps inoccupation;leakage power;distribution temporelle;idle time;leak;boarded computer;power optimization;puissance faible;temps execution;optimization;tiempo ejecucion;embedded processor;calculador embarque;tiempo desocupacion;distribucion temporal;potencia debil;time distribution	We introduce low-overhead power optimization techniques to reduce leakage power in embedded processors. Our techniques improve previous work by a) taking into account idle time distribution for different execution units, and b) using instruction decode and control dependencies to wakeup the gated (but needed) units as soon as possible. We take into account idle time distribution per execution unit to detect an idle time period as soon as possible. This in turn results in increasing our leakage power savings. In addition, we use information already available in the processor to predict when a gated execution unit will be needed again. This results in early and less costly reactivation of gated execution units. We evaluate our techniques for a representative subset of MiBench benchmarks and for a processor using a configuration similar to Intels Xscale processor. We show that our techniques reduce leakage power considerably while maintaining performance.	central processing unit;dependence analysis;embedded system;emoticon;execution unit;mathematical optimization;overhead (computing);power gating;spectral leakage;xscale	Houman Homayoun;Amirali Baniasadi	2006		10.1007/11796435_31	embedded system;parallel computing;real-time computing;computer science;operating system;power optimization	Arch	-2.852420455539135	54.632015687665344	189944
074a4b3054b1f82b8e299748921c7753c2bd0803	robust control-theoretic thermal balancing for server clusters	clusters;file servers;compact server architectures;robust control thermal management energy consumption temperature control optimal control energy management thermal loading clustering algorithms heuristic algorithms difference equations;online measurements;optimal control theory;temperature control;temperature sensors;server clusters;feedback control clusters thermal balancing;robust control;indexing terms;workstation clusters computer centres file servers load distribution optimal control robust control temperature control;hot spot;ambient temperatures;computer centres;optimal control;servers;robust control theoretic thermal balancing;dynamic load distribution;heuristic algorithms;ambient temperatures robust control theoretic thermal balancing server clusters thermal management power consumption compact server architectures data centers dynamic load distribution online measurements optimal control theory control analysis cpu;thermal balancing;load distribution;temperature measurement;workstation clusters;power consumption;ambient temperature;cpu;power demand;thermal management;program processors;feedback control;algorithm design and analysis;dynamic loading;control analysis;data centers	Thermal management is critical for clusters because of the increasing power consumption of modern processors, compact server architectures and growing server density in data centers. Thermal balancing mitigates hot spots in a cluster through dynamic load distribution among servers. This paper presents two Control-theoretical Thermal Balancing (CTB) algorithms that dynamically balance the temperatures of different servers based on online measurements. CTB features controllers rigorously designed based on optimal control theory and a difference equation model that approximates the thermal dynamics of clusters. Control analysis and simulation results demonstrate that CTB achieves robust thermal balancing under a wide range of uncertainties: (1) when different tasks incur different power consumptions on the CPUs, (2) when servers experience different ambient temperatures, and (3) when servers experience thermal faults.	algorithm;central processing unit;coding tree unit;control theory;data center;load balancing (computing);optimal control;recurrence relation;robust control;server (computing);simulation;thermal management of high-power leds;ut-vpn	Yong Fu;Chenyang Lu;Hongan Wang	2010	2010 IEEE International Symposium on Parallel & Distributed Processing (IPDPS)	10.1109/IPDPS.2010.5470480	embedded system;parallel computing;real-time computing;optimal control;computer science;operating system;distributed computing	Arch	-4.430773264575142	56.79066222195932	190548
55512fc0be51166c06fbde0eda8c1e4cdccd298c	introducing firestarter: a processor stress test utility	firestarter;stress;prime95 firestarter linpack;power consumption patterns firestarter open source tool processor stress test utility cooling systems test system characterization energy efficiency research near peak power consumption high level language code assembly routines x86_64 processors;microarchitecture;performance evaluation;linpack;prime95;power demand registers stress bridges microarchitecture ports computers out of order;bridges;power aware computing microprocessor chips performance evaluation;out of order;power aware computing;registers;ports computers;power demand;microprocessor chips	Processor stress test utilities are important tools for a number of different use cases. In particular, cooling systems need to be tested at maximum load in order to ensure that they fulfill their specifications. Additionally, a test system characterization in terms of idle and maximum power consumption is often a prerequisite for energy efficiency research. This creates the need for a simple yet versatile tool that generates near-peak power consumption of compute nodes. While in different research areas tools such as LINPACK and Prime95 are commonly used, these tools are just highly optimized and compute intense routines that solve specific computational problems. As stress test utilities they are unnecessarily hard to use and in many cases unreliable in terms of power consumption maximization. We propose FIRESTARTER, an Open Source tool that is specifically designed to create near-peak power consumption. Our experiments show that this task cannot be achieved with generic high-level language code. We therefore use highly optimized assembly routines that take the specific properties of a given processor microarchitecture into account. A study on four compute nodes with current or last generation x86_64 processors shows that we reliably exceed the power consumption of other stress tests and create very steady power consumption patterns.	application domain;assembly language;benchmark (computing);central processing unit;code generation (compiler);computation;computational problem;computer cooling;computer scientist;error detection and correction;expectation–maximization algorithm;experiment;feedback;handy board;high- and low-level;high-level programming language;hyper-threading;image resolution;infiniband;intel quickpath interconnect;intel turbo boost;ivy bridge (microarchitecture);language code;load profile;lunpack;maximum power transfer theorem;memory hierarchy;microarchitecture;nehalem (microarchitecture);perf (linux);prime95;sandy bridge;software bug;static build;static library;stress testing (software);system administrator;thermal design power;throughput;westmere (microarchitecture)	Daniel Hackenberg;Roland Oldenburg;Daniel Molka;Robert Schöne	2013	2013 International Green Computing Conference Proceedings	10.1109/IGCC.2013.6604507	embedded system;parallel computing;real-time computing;computer science	HPC	-3.943431612142258	56.35596363974968	191551
b8c36b8d6f2d9e2809b9161ead092f3be8e5cd4a	design of memory subsystem for wide input data range in the salt asic		The paper presents the design and optimisation of memory buffer in the SALT (Silicon ASIC for LHCb Tracking) ASIC. The SALT is a new 128-channel readout ASIC for silicon strip detectors in the Large Hadron Collider beauty (LHCb) experiment at the Large Hadron Collider (LHC) in CERN. The stochastic nature of phenomena detected by the ASIC results in a very different amount of data after each collision of particles. The SALT generates a data packet which size may vary between one and 100 bytes in each clock cycle and which should be stored in a memory buffer regardless of its size. The memory buffer is based on a number of macro blocks. The input size of the macro block is a free parameter of the design so the optimization was performed taking into account occupied area and consumed power. A full 128-channel version, designed in CMOS 130 nm technology, together with implemented memory buffer, was submitted, produced and is being tested. The tests show full functionality of the ASIC and memory buffer.	12-bit;application-specific integrated circuit;byte;cmos;clock signal;data buffer;information;iteration;large hadron collider;mathematical optimization;network packet;salt (cryptography);sensor	Krzysztof Swientek;Magdalena Banachowicz	2017	"""2017 MIXDES - 24th International Conference """"Mixed Design of Integrated Circuits and Systems"""	10.23919/MIXDES.2017.8005192	memory buffer register;electronic engineering;application-specific integrated circuit;computer science;macro;cycles per instruction;computer hardware;byte;large hadron collider;integrated circuit design;cmos	EDA	-0.4741044777858831	57.92434390069894	191890
bfac2165cc81689656cdc2e76cdf275f241ca962	characterizing the impact of soft errors across microarchitectural structures and implications for predictability		The trends of transistor size and system complexity scaling continue. As a result, soft errors in the system, including the processor core, are predicted to become one of the major reliability challenges. A fraction of soft errors at the device level could become an unmasked error visible to the user. Unmasked soft errors may manifest as a detectable error, which could be recoverable (DRE) or unrecoverable (DUE), or a Silent Data Corruption (SDC). Detecting and recovering from an SDC is especially challenging since an explicit checker is needed to detect erroneous state. Predicting when SDCs are more likely could be valuable in designing resilient systems. To gain insight, we evaluate the Architectural Vulnerability Factor (AVF) of all major in-core memory structures of an out-of-order superscalar processor. In particular, we focus on the vulnerability factors for detectable and unrecoverable errors (DUE AVF ) and silent data corruptions (SDC AVF ) across windows of execution to study their characteristics, time-varying behavior, and their predictability using a linear regression trained offline. We perform more than 35 million microarchitectural fault injection simulations and, if necessary, run-to-completion using functional simulations to determine AVF, DUE AVF , and SDC AVF . Our study shows that, similar to AVF, DUE AVF and SDC AVF vary over time and across applications. We also find significant differences in DUE AVF and SDC AVF across the processor structures we studied. Furthermore, we find that DUE AVF can be predicted using a linear regression with similar accuracy as AVF estimation. However, SDC AVF could not be predicted with the same level of accuracy. As a remedy, we propose adding a software vulnerability factor, in the form of SDC PVF , to the linear regression model for estimating SDC AVF . We find that SDC PVF of the Architectural Register File explains most of the behavior of SDC AVF for the combined microarchitectural structures studied in this paper. Our evaluation shows that the addition of SDC PVF improves the accuracy by 5.19×, on average, to a level similar to DUE AVF and AVF estimates. We also evaluate the impact of limiting software-layer reliability information to only 5 basic blocks (16× cost reduction, on average), and observe that it increases error only by 18.7%, on average.	basic block;fault injection;image scaling;logic simulation;magnetic-core memory;microarchitecture;microsoft windows;multi-core processor;online and offline;register file;run to completion scheduling;schedule (computer science);smart data compression;soft error;superscalar processor;transistor;vulnerability (computing)	Bagus Wibowo;Abhinav Agrawal;James Tuck	2017	2017 IEEE International Symposium on Workload Characterization (IISWC)	10.1109/IISWC.2017.8167782	register file;fault injection;reliability engineering;real-time computing;linear regression;predictability;vulnerability (computing);computer science;data corruption;multi-core processor;microarchitecture	Arch	-2.7424988108646	56.67892289283169	192421
0899ada18135a588e85c55246ac6def683d06841	dora: optimizing smartphone energy efficiency and web browser performance under interference		This paper proposes DORA — a dynamic frequency controller that maximizes the energy efficiency of smartphones subject to user satisfaction demands in the presence of memory interference stemmed from background processes and coscheduled applications. The proposed algorithm predicts the optimal energy-efficient frequency setting at runtime using staticallytrained performance, dynamic power, and leakage power models. The parameters of the models represent web page characteristics and dynamically varying architecture and system conditions. The algorithm is designed, implemented and extensively evaluated on a Google Nexus 5 smartphone using a variety of mobile web browsing workloads. The results show high prediction accuracies for the performance and power models of 97.5% and 96%, respectively. Overall, DORA improves the smartphone's energy efficiency by an average of 16% compared to the default Android frequency governor, interactive, while maintaining the desired levels of user satisfaction (web page load time).	algorithm;android;background process;doraemon;embedded system;feedback;interference (communication);load (computing);loader (computing);microsoft customer care framework;mobile device;multi-core processor;online and offline;optimal control;optimizing compiler;profiling (computer programming);run time (program lifecycle phase);smartphone;spectral leakage;statistical interference;web page	Davesh Shingari;Akhil Arunkumar;Benjamin Gaudette;Sarma B. K. Vrudhula;Carole-Jean Wu	2018	2018 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)	10.1109/ISPASS.2018.00015	real-time computing;web page;computer science;android (operating system);architecture;quality of service;dynamic demand;mobile web;web navigation;nexus (standard)	Arch	-4.086087266355301	58.40576271580387	192761
17a66e0231c54da9d005f42d5db724f16fc2144d	a framework for evaluating promising power efficiency techniques in future gpus for hpc		Graphics Processing Units (GPUs) have been extensively used in high-performance computing (HPC) applications with superior power efficiency. Future high-performance GPUs will likely have hundreds of Compute Units (CUs) integrated on-die sharing the power and thermal envelopes. In this paper, we evaluate what we consider as three promising power efficiency techniques for future HPC systems equipped with GPUs, namely, low-voltage operation (e.g., near-threshold computing), runtime power management (e.g., power gating along with voltage and frequency scaling), and data compression during data transfer. In addition to providing the relative benefit of each technique, we also evaluate the combined potential of these techniques to improve the power efficiency of a future hypothetical GPU. This analysis is done based on a flexible framework that employs a combination of: (1) native hardware measurements, (2) analytical power projection to future GPUs, and (3) industrial technology scaling and per-component RTL-guided power models. We also provide insights into the dominant power components and the effectiveness of different low-power techniques for each application, aiding system architects and designers to make early yet critical decisions.	graphics processing unit;performance per watt	Kapil Dev;Indrani Paul;Wei Huang	2016			embedded system;parallel computing;computer hardware;computer science;operating system	HPC	-3.1565855606453646	55.39336589207586	192915
66e36790e17838607faf4ffc3033cae4813e106f	quality adapted backlight scaling (qabs) for video streaming to mobile handheld devices	algorithme rapide;distributed system;metodo adaptativo;negative affect;economies d energie;dispositivo potencia;streaming;systeme reparti;informatique mobile;video streaming;ahorros energia;transmision continua;real time;dispositif puissance;user perception;methode adaptative;satisfiability;effet dimensionnel;qualite service;energy use;transmission en continu;sistema repartido;low power;senal video;signal video;imagen borrosa;energy consumption;size effect;blurred image;fast algorithm;image quality;temps reel;adaptive method;puissance faible;consommation energie;power device;video signal;tiempo real;energy savings;handheld device;image floue;efecto dimensional;mobile computing;algoritmo rapido;service quality;energy saving;consumo energia;calidad servicio;potencia debil	For a typical portable handheld device, the backlight accounts for a significant percentage of the total energy consumption (e.g., around 30% for a Compaq iPAQ 3650). Substantial energy savings can be achieved by dynamically adapting backlight intensity levels on such low-power portable devices. In this paper, we analyze the characteristics of video streaming services and propose an adaptive scheme called Quality Adapted Backlight Scaling (QABS), to achieve backlight energy savings for video playback applications on handheld devices. Specifically, we present a fast algorithm to optimize backlight dimming while keeping the degradation in image quality to a minimum so that the overall service quality is close to a specified threshold. Additionally, we propose two effective techniques to prevent frequent backlight switching, which negatively affects user perception of video. Our initial experimental results indicate that the energy used for backlight is significantly reduced, while the desired quality is satisfied. The proposed algorithms can be realized in real time.	adaptive algorithm;algorithm;backlight;distortion;elegant degradation;enumerated type;heuristic;image quality;image scaling;low-pass filter;low-power broadcasting;mobile device;overhead (computing);peak signal-to-noise ratio;personal digital assistant;power management;prototype;streaming media;video decoder	Liang Cheng;Stefano Bossi;Shivajit Mohapatra;Magda El Zarki;Nalini Venkatasubramanian;Nikil D. Dutt	2005		10.1007/978-3-540-31956-6_78	image quality;embedded system;simulation;telecommunications;computer science;operating system;mobile device;mobile computing;service quality;affect;satisfiability	Mobile	-3.8822855691829075	60.23315281038107	192960
333511bb16d776e17b6f74d23092c51efe3b9c63	hierarchical memory size estimation for loop fusion and loop shifting in data-dominated applications	loop shifting;interpolation;off chip memories;data locality;hierarchical memory size estimation;chip;loop fusion;memory access;platform mapping;platform independent approach hierarchical memory size estimation loop fusion loop shifting data dominated applications data locality off chip memories platform mapping loop transformation incremental technique;leakage power;loop transformation;scratch pad memory;incremental technique;data structures;mtcmos;energy consumption solid modeling scanning probe microscopy phase estimation data analysis performance analysis testing real time systems multimedia communication multimedia systems;static timing analysis;digital storage data structures;selective mt;digital storage;data dominated applications;memories;pareto optimality;platform independent approach	Loop fusion and loop shifting are important transformations for improving data locality to reduce the number of costly accesses to off-chip memories. Since exploring the exact platform mapping for all the loop transformation alternatives is a time consuming process, heuristics steered by improved data locality are generally used. However, pure locality estimates do not sufficiently take into account the hierarchy of the memory platform. This paper presents a fast, incremental technique for hierarchical memory size requirement estimation for loop fusion and loop shifting at the early loop transformations design stage. As the exact memory platform is often not yet defined at this stage, we propose a platform-independent approach which reports the Pareto-optimal trade-off points for scratch-pad memory size and off-chip memory accesses. The estimation comes very close to the actual platform mapping. Experiments on realistic test-vehicles confirm that. It helps the designer or a tool to find the interesting loop transformations that should then be investigated in more depth afterward.	cache (computing);computer memory;for loop;heuristic (computer science);locality of reference;loop optimization;pareto efficiency	Qubo Hu;Arnout Vandecappelle;Martin Palkovic;Per Gunnar Kjeldsberg;Erik Brockmeyer;Francky Catthoor	2006	Asia and South Pacific Conference on Design Automation, 2006.	10.1145/1118299.1118442	loop tiling;chip;loop fusion;embedded system;loop inversion;electronic engineering;parallel computing;real-time computing;loop fission;data structure;loop interchange;telecommunications;interpolation;loop dependence analysis;computer science;loop nest optimization;operating system;memory;static timing analysis;loop splitting	EDA	-3.4973766346795703	54.0583736920041	193288
09ff5bd214346775016adbd9bb25063e318a2166	ecalogic: hardware-parametric energy-consumption analysis of algorithms	resource analysis;energy consumption;green computation;green software;static analysis;part of book or chapter of book	hile green software is a popular topic in computer science nowadays, the average programmer still has little options for analysis of the energy-efficiency of his/her software. Analysis is mostly done dynamically, for which a complex measurement set-up is needed. Using a static analysis which predicts the energy-consumption, would be more accessible and more cost-effective.  This paper presents ECAlogic, a tool that implements a static analysis that can bound the energy consumption of algorithms. The tool is parametric with respect to a set of hardware component models. Its results are symbolic over the program parameters.	algorithm;analysis of algorithms;computer science;programmer;static program analysis	Marc Schoolderman;Jascha Neutelings;Rody Kersten;Marko C. J. D. van Eekelen	2014		10.1145/2588548.2588553	simulation;computer science;theoretical computer science;static program analysis	PL	-2.220821681699558	55.27626251271266	193839
6f8e97761e7fc0a0002636343f8175846c6461b7	microprocessors in crt terminals	integrated circuit;data flow;read only memory	The recent introduction of integrated circuit microprocessors has produced a new variety of CRT terminal---the firmware terminal. The firmware terminal incorporates a microprocessor to control data flow, using a control program supplied by the terminal manufacturer in Read-Only-Memory. Priced only slightly above hardwired editing terminals, it can perform far more complex functions, assisting both the operator and the computer system into which it is connected. It is priced well below the userprogrammable terminal which requires magnetic storage for program and a much higher level of sophistication from both the sales force and users.	cathode ray tube;computer terminal;dataflow;firmware;integrated circuit;magnetic storage;microprocessor;terminal capabilities;throughput	John Whiting;Sandy Newman	1974	Computer	10.1145/1499949.1499960	embedded system;real-time computing;computer hardware;computer science	Arch	0.9398175375716494	58.2310904839641	193959
bba7c022a530137f5258557c3191ff99660b7aaf	adaptive mapping to resource availability for dynamic wavelet-based applications	wavelet transforms cache storage multimedia systems video signal processing;cache storage;optimal memory hierarchy;data dependent application behavior;partial reconfiguration;video signal processing;program compiler;cache storage resource availability adaptive mapping dynamic wavelet based video application optimal memory hierarchy data dependent application behavior motion triggered switching middleware program compiler;dynamic wavelet based video application;multimedia systems;motion triggered switching;memory access;wavelet transforms;memory optimization;data dependence;middleware;resource availability;memory hierarchy;availability runtime switches motion analysis energy efficiency energy consumption optimal control decoding video sequences testing;adaptive mapping	Platforms have to cope with unpredictably varying system resource requirements, because of inter-task level dynamism. To deal with this, they have to be at least partially reconfigurable. It is then important for applications to optimally exploit the memory hierarchy under varying memory availability. Moreover, in the case of intra-task dynamism, additional unpredictability is inserted and the exploration of the optimal memory hierarchy depends on data dependent application behavior. This paper presents a mapping strategy for a wavelet-based video application: depending on the encountered resource availability, switching to different memory optimized instantiations (i.e. localizations) of the application offers up to 25% energy gains in memory accesses, for a representative test sequence. We observe that it is possible to exploit the input motion characteristics in detail (that reflect the intra-task dynamism) by enabling motion-triggered switching, and further increase the achieved gains.	memory hierarchy;reconfigurable computing;requirement;wavelet	Vissarion Ferentinos;Bert Geelen;Francky Catthoor;Gauthier Lafruit;Thanos Stouraitis;Rudy Lauwereins;Diederik Verkest	2007	2007 IEEE/ACM/IFIP Workshop on Embedded Systems for Real-Time Multimedia	10.1109/ESTMED.2007.4375802	embedded system;parallel computing;real-time computing;computer science;operating system;middleware;wavelet transform	HPC	-2.5233775840352806	57.220733895914606	194085
b1d0f8ae8bbcc06bc7abb8a0b56bf04e51d41266	a power-aware reconfigurable rendering engine design with 453mpixels/s, 16.4mtriangles/s performance	processing element;precision aware shading scheme;engineering design;image quality change;dynamic reconfiguration;processor scheduling;reconfigurable architectures;power efficiency;fraction masking techniques;dispatching techniques;computer architecture;engines;image quality;dispatching techniques power aware reconfigurable rendering engine design image quality change precision aware shading scheme power efficiency fraction masking techniques processing element scalable architecture dynamic task scheduling;engines rendering computer graphics change detection algorithms computer architecture throughput image quality processor scheduling dynamic scheduling dispatching hardware;task scheduling;rendering computer graphics;power aware reconfigurable rendering engine design;rendering computer graphics reconfigurable architectures;dispatching;change detection algorithms;dynamic scheduling;throughput;hardware;processing element scalable architecture;dynamic task scheduling	This paper presents a power-aware dynamically reconfigurable rendering engine design, which changes power as rendering throughput and image quality change. At algorithm level, a precision-aware shading scheme is proposed to improve the power efficiency of the conventional shading algorithm through the combination of precision detection and fraction masking techniques. At architecture level, a processing element (PE) based scalable architecture is combined with dynamic task scheduling and dispatching techniques to raise hardware utilization rate and reduce computation latency. Finally a prototyping design which delivers 453MPixels/s, 16.4MTriangles/s, 2.24MPixel/mJ is presented	algorithm;computation;image quality;layout engine;level design;linear interpolation;mask (computing);overhead (computing);performance per watt;reconfigurability;reconfigurable computing;rendering (computer graphics);scalability;scheduling (computing);shading;systems architecture;throughput	Chih-Hao Chao;Yen-Lin Kuo;An-Yeu Wu;Weber Chien	2007	2007 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2007.378205	image quality;embedded system;throughput;parallel computing;real-time computing;electrical efficiency;dynamic priority scheduling;computer science;operating system;engineering design process	Arch	-2.869192427230079	58.5259340249831	194187
2acfe0e4a6ab5b623a1de8150d98f896af99e0f8	reconciling application power control and operating systems for optimal power and performance	hardware software codesign;application power control compiler automatic application level power control patch system level software application level information hardware level information power consumption reduction fine grained power control cloud computer system on chip embedded computer optimal power operating systems;embedded systems;integrated circuit design;power aware computing;system on chip;low power electronics;linux system on chip power control clocks kernel hardware libraries;system on chip embedded systems hardware software codesign integrated circuit design low power electronics power aware computing program compilers;program compilers	In the age of dark silicon on-chip power control is a necessity. Upcoming and state of the art embedded- and cloud computer system-on-chips (SoCs) already provide interfaces for fine grained power control. Sometimes both: core- and interconnect-voltage and frequency can be scaled for example. To further reduce power consumption SoCs often have specialized accelerators. Due to the rising specialization of hard- and software general purpose operating systems require changes to exploit the power saving opportunities provided by the hardware. However, they lack detailed hardware- and application-level-information. Application-level power control in turn is still very uncommon and difficult to realize. Now a days vendors of mobile devices are forced to tweak and patch system-level software to enhance the power efficiency of each individual product. This manual process is time consuming and must be re-iterated for each new product. In this paper we explore the opportunities and challenges of automatic application- level power control using compilers.	automatic parallelization;central processing unit;cloud computing;compiler;computer;dark silicon;dynamic voltage scaling;iteration;mobile device;operating system;partial template specialization;performance per watt;power gating;system on a chip	Dominic Hillenbrand;Yuuki Furuyama;Akihiro Hayashi;Hiroki Mikami;Keiji Kimura;Hironori Kasahara	2013	2013 8th International Workshop on Reconfigurable and Communication-Centric Systems-on-Chip (ReCoSoC)	10.1109/ReCoSoC.2013.6581539	system on a chip;embedded system;parallel computing;real-time computing;computer science;operating system;low-power electronics;integrated circuit design	Arch	-4.1267308219401855	55.600817847003725	194333
2c26ca8322f42118cea13c9ca94afd9423c4bdc1	vlsi implementation and evaluation of a real-time operating system	systeme temps reel;sistema operativo;eficacia sistema;hdl;haute performance;tron;gestion labor;implementation;performance systeme;circuit vlsi;real time operating system;pulga electronica;system performance;chip;ejecucion;vlsi circuit;gestion tâche;operating system;scheduling;vlsi technology;alto rendimiento;systeme exploitation;ordonamiento;real time system;hardware kernel;sistema tiempo real;computer hardware;circuito vlsi;task scheduling;puce electronique;high performance;materiel informatique;material informatica;ordonnancement	This paper proposed a new approach to create a very high performance real-time operating system (0s) using VLSI technology. In this method, a quick and steady response can be guaranteed by implementing basic operations of a real-time 0s as a peripheral chip (Silicon TRON) to be connected to general purpose microprocessors. To confirm the effectiveness of this method, most basic system calls of pITRON have been designed using an HDL. Synthesis results using a 0.8 pm CMOS technology show that the most important part of the system calls can be realized as a VLSI chip. According to the evaluation results based on an FPGA implementation, the hardware portion of these functionalities can be executed within 250 ns and task scheduling can be performed with 750 ns simultaneously, both of which are approximately 6 to 50 times faster than software implementation. Accordingly, very high performance real-time systems can be created by the proposed method.	cmos;field-programmable gate array;hardware description language;microprocessor;peripheral;real-time clock;real-time computing;real-time operating system;scheduling (computing);system call;tron project;very-large-scale integration	Takumi Nakano;Andy Utama;Akichika Shiomi;Masaharu Imai;Mitsuyoshi Itabashi	1996	Systems and Computers in Japan	10.1002/scj.4690270601	chip;embedded system;real-time computing;real-time operating system;computer science;operating system;implementation;scheduling	Embedded	0.32471305621974106	57.814223017330505	194412
2c8ebbcf81c0f0d2ac6ef2a30b99dbde59f385dd	bridging the gap between compilation and synthesis in the defacto system	langage description materiel informatique;field programmable gate array;compilacion;optimisation;oferta;memory protocols;storage access;behavioral synthesis;sistema temporizado;optimizacion;offer;behavioral analysis;parallelizing compilers;timed system;transformacion;langage evolue;red puerta programable;systeme adaptatif;reseau porte programmable;compilateur parallelisation;memory access;computer hardware description languages;system synthesis;design environment;scheduling;synthese systeme;analyse comportementale;protocole memoire;acces memoire;adaptive system;sintesis sistema;systeme temporise;adaptive computing;acceso memoria;compilation;sistema adaptativo;analisis conductual;lenguaje evolucionado;optimization;transformation;high level language;offre;ordonnancement;reglamento;time constraint	_____________ 1Funded by the Defense Advanced Research Project Agency under contract # F30602-98-2-0113 2Funded through a Boeing Satellite Systems Doctoral Scholars Fellowship Abstract. The DEFACTO project a Design Environment For Adaptive Computing TechnOlogy is a system that maps computations, expressed in high-level languages such as C, directly onto FPGA-based computing platforms. Major challenges are the inherent flexibility of FPGA hardware, capacity and timing constraints of the target FPGA devices, and accompanying speed-area trade-offs. To address these, DEFACTO combines parallelizing compiler technology with behavioral VHDL synthesis tools, obtaining the complementary advantages of the compiler’s high-level analyses and transformations and synthesis’ binding, allocation and scheduling of low-level hardware resources. To guide the compiler in the search of a g odsolution, we introduce the notion of balance between the rates at which data is fetched from memory and accessed by the computation, combined with estimation from behavioral synthesis. Since FPGA-based designs offer the potential for optimizing memory-related operations, we have also incorporated the ability to exploit parallel memory accesses andcustomize memory access protocols into the compiler analysis.	automatic parallelization;bridging (networking);computation;field-programmable gate array;high- and low-level;high-level synthesis;name binding;optimizing compiler;scheduling (computing);vhdl	Pedro C. Diniz;Mary W. Hall;Joonseok Park;Byoungro So;Heidi E. Ziegler	2001		10.1007/3-540-35767-X_4	transformation;parallel computing;real-time computing;compiler correctness;computer science;artificial intelligence;adaptive system;operating system;programming language;scheduling;high-level programming language;algorithm;field-programmable gate array	EDA	-0.293988878604685	53.82766488762661	194557
160216d550628c50b534e35c36abeefb2233b479	hardware/software partitioning for multifunction systems	system level design hardware software partitioning optimization multifunction embedded system multistandard video codec multisystem phone hardware software codesign hardware software mapping gclp algorithm;circuit decodeur;outil logiciel;hardware application software timing embedded system software tools partitioning algorithms design optimization video codecs constraint optimization concurrent computing;multistandard video codec;real time systems high level synthesis video codecs;circuit codeur;time dependent;software tool;transformation cosinus;architecture systeme;encoding decoding;concurrent computing;coding circuit;hardware software codesign;constraint optimization;filtre reponse impulsion finie;concepcion sistema;application software;multifunction embedded system;implementation;flot donnee;finite impulse response filter;audio video;flujo datos;indexing terms;design optimization;circuito desciframiento;embedded system;ejecucion;high level synthesis;decoding circuit;filtro respuesta impulsion acabada;code division multiple access;acces multiple code;codesign;hardware software partitioning;herramienta controlada por logicial;system design;mappage;multisystem phone;circuito codificacion;transformacion coseno;system level design;arquitectura sistema;video codecs;gclp algorithm;optimization;partitionnement;software tools;mapping;mpeg;computer hardware;cosine transform;data flow;system architecture;similarity function;acceso multiple codificado;materiel informatique;material informatica;conception systeme;software implementation;partitioning algorithms;hardware;real time systems;hardware software mapping;timing;time constraint	"""We are interested in optimizing the design of multifunction embedded systems such as multistandard audio/video codecs and multisystem phones. Such systems run a prespecified set of applications, and any """"one"""" of the applications is selected at a run time, depending on system parameters. Our goal is to develop a methodology for the efficient design of such systems. A key observation underlying our method is that it may not be efficient to design for each application separately. This is attributed to two factors. First, considering each application in isolation can lead to application-specific decisions that do not necessarily lead to the best overall system solution. Second, these applications typically tend to have several commonalities among them, and considering applications independently may lead to inconsistent mappings of common tasks in different applications. Our approach is to optimize jointly across the set of applications while ensuring that each application itself meets its timing constraints. Based on these guiding principles, we formulate, as a codesign problem, the design and synthesis of an efficient hardware-software implementation for a multifunction embedded system. The first step in our methodology is to identify nodes that represent similar functionality across different applications. Such """"common"""" nodes are characterized by several metrics such as their repetitions, urgency, concurrency, and performance/area tradeoff. These metrics are quantified and used by a hardware/software partitioning tool to influence hardware/software mapping decisions. The idea behind this is to bias common tasks toward the same resource as far as possible while also considering preferences and timing constraints local to each application. Further, relative criticality of applications is also considered, and the mapping decisions in more critical applications are allowed to influence those in less critical applications. We demonstrate how this is achieved by modifying an existing partitioning algorithm (GCLP) used to partition single-function systems. Our modified algorithm considers global preferences across the application set as well as the preference of each individual application to generate an efficient overall solution while ensuring that timing constraints of each application are met. The overall result of the system-level partitioning process is 1) a hardware or software mapping and 2) a schedule for execution for each node within the application set. On an example set consisting of three video applications, we show that the solution obtained by the use of our method is 38% smaller than that obtained when each application is considered independently."""	multi-function printer	Asawaree Kalavade;P. A. Subrahmanyam	1998	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.720318	co-design;embedded system;data flow diagram;code division multiple access;mathematical optimization;electronic engineering;application software;parallel computing;real-time computing;multidisciplinary design optimization;index term;concurrent computing;computer science;electrical engineering;operating system;finite impulse response;discrete cosine transform;electronic system-level design and verification;high-level synthesis;implementation;algorithm;systems design	EDA	1.4804357961887116	53.78789203362368	195265
0c735c8adf8defaefd70f5eddf143d67386750cf	context-aware performance analysis for efficient embedded system design	ideal target;performance analysis;system design;correlated load distribution;advanced performance analysis technique;complex embedded system;formal performance analysis;tight analysis bound;context-aware performance analysis;communication request;tighter analysis bound;large impact;routing;bandwidth;load distribution;embedded system;formal verification;embedded systems;cores	Performance analysis has many advantages in theory compared to simulation for the validation of complex embedded systems, but is rarely used in practice. To make analysis more attractive, it is critical to calculate tight analysis bounds. This paper shows that advanced performance analysis techniques taking correlations between successive computation or communication requests as well a correlated load distribution into account can yield much tighter analysis bounds. Cases where such correlations have a large impact on system timing are especially difficult to simulate and, hence, are an ideal target for formal performance analysis.	computation;corner case;cryptography;design space exploration;desktop computer;embedded system;load balancing (computing);profiling (computer programming);set-top box;simulation;system bus;systems design	Marek Jersak;Rafik Henia;Rolf Ernst	2004	Proceedings Design, Automation and Test in Europe Conference and Exhibition		multi-core processor;embedded system;routing;parallel computing;real-time computing;formal verification;computer science;weight distribution;operating system;distributed computing;bandwidth	EDA	-0.5768138470370175	56.06608350976767	196082
4416052fca95270b50a29e9e3cc245cca8962861	runtime power monitoring in high-end processors: methodology and empirical data	per-unitpower estimation;power dissipation;empirical application resultsthat;high-end processors;future power-aware research;example application;power breakdown;runtime power monitoring;estimation methodology andalso;empirical data;live power measurement;measuringpower dissipation;generatedcomponent power breakdown;software systems;thermal analysis	With power dissipation becoming an increasingly vexingproblem across many classes of computer systems, measuringpower dissipation of real, running systems has becomecrucial for hardware and software system research and design.Live power measurements are imperative for studiesrequiring execution times too long for simulation, such asthermal analysis. Furthermore, as processors become morecomplex and include a host of aggressive dynamic powermanagement techniques, per-component estimates of powerdissipation have become both more challenging as well asmore important.In this paper we describe our technique for a coordinatedmeasurement approach that combines real totalpower measurement with performance-counter-based, per-unitpower estimation. The resulting tool offers live totalpower measurements for Intel Pentium 4 processors, andalso provides power breakdowns for 22 of the major CPUsubunits over minutes of SPEC2000 and desktop workloadexecution. As an example application, we use the generatedcomponent power breakdowns to identify program powerphase behavior. Overall, this paper demonstrates a processorpower measurement and estimation methodology andalso gives experiences and empirical application resultsthat can provide a basis for future power-aware research.	cpu power dissipation;central processing unit;desktop computer;imperative programming;pentium 4;simulation;software system	Canturk Isci;Margaret Martonosi	2003		10.1145/956417.956567	embedded system;power-flow study;parallel computing;real-time computing;cpu power dissipation;computer science;dissipation;operating system;power optimization;low-power electronics;thermal analysis;software system	Arch	-3.176773275628477	56.05776498168084	196629
85d2b2a5e5d07e10ff4a26639d88a75b63edef91	a generic and high-level model of large unreliable nocs for fault tolerance and performance analysis	routing fault tolerance fault tolerant systems three dimensional displays graphical user interfaces throughput propagation losses;performance evaluation data visualisation electronic engineering computing fault tolerant computing graphical user interfaces integrated circuit interconnections network on chip;in depth interconnect visualization generic model high level model large unreliable noc network on chips fault tolerance technique performance analysis vocis 3d graphical user interface 3d gui	The integration of more and more computing cores into processors drives the adoption of larger and larger Network-on-Chips (NoCs). Concurrently, the decreasing reliability of 1 the latest technologies promotes the utilization of fault-tolerant techniques. Unfortunately, the understanding of fault-tolerant NoCs is increasingly difficult as interconnect scale up, because they require the combination of more and more complex and heterogeneous techniques. In this paper, an high-level model named VOCIS is presented, in order to ease the comprehension and analysis of large unreliable NoCs. This model features a 3D Graphical User Interface (GUI), that offers an effective and in-depth visualization of interconnects. A few analytical measurements provided directly by VOCIS are also presented, in order to assess quantitatively the impact of defects and corresponding fault-tolerant techniques.	central processing unit;electrical connection;fault tolerance;graphical user interface;high- and low-level;profiling (computer programming)	Fabien Chaix;Nacer-Eddine Zergainoh;Michael Nicolaidis	2014	2014 19th IEEE European Test Symposium (ETS)	10.1109/ETS.2014.6847827	embedded system;real-time computing;computer science;distributed computing;software fault tolerance	EDA	-0.38073113601978026	56.87837446298139	196940
c224a6d695b3ff96d83fd3021702a25818df21ce	guaranteeing real-time requirements with resource-based calibration of periodic processes	static priority;operating systems computers real time systems formal specification systems analysis scheduling;end to end constraint maintenance real time requirements resource based calibration periodic processes comprehensive design methodology end to end requirements guarantees real time systems process components asynchronous channels timing constraints end to end propagation delay temporal input sampling correlation allowable separation times updated output values automated design method optimization algorithm cpu utilization intermediate rate constraints restructuring tool assignment algorithm schedulable set fully periodic tasks;systeme temps reel;optimisation;entrada salida;formal specification;metodologia;optimizacion;gollete estrangulamiento;aproximacion no lineal;non linear optimization;real time;coaccion;contrainte;priorite;conception;indexing terms;methodologie;input output;non linear approximation;calibration timing real time systems design methodology constraint optimization design optimization temperature computer science usa councils performance analysis;goulot etranglement;static priority scheduling;approximation non lineaire;constraint;systems analysis;propagation delay;scheduling;diseno;end to end timing constraints;constraint solving;design;ordonamiento;real time system;optimization;sistema tiempo real;methodology;priority;prioridad;bottleneck;operating systems computers;ordonnancement;entree sortie;real time systems;design methodology;timing;time constraint	This paper presents a comprehensive design methodology for guaranteeing end-to-end requirements of real-time systems. Applications are structured as a set of process components connected by asynchronous channels, in which the endpoints are the system's external inputs and outputs. Timing constraints are then postulated between these inputs and outputs; they express properties such as end-to-end propagation delay, temporal input-sampling correlation, and allowable separation times between updated output values. The automated design method works as follows: First new tasks are created to correlate related inputs, and an optimization algorithm, whose objective is to minimize CPU utilization, transforms the end-to-end requirements into a set of intermediate rate constraints on the tasks. If the algorithm fails, a restructuring tool attempts to eliminate bottlenecks by transforming the application, which is then re-submitted into the assignment algorithm. The nal result is a schedulable set of fully periodic tasks, which collaboratively maintain the end-to-end constraints.	algorithm;approximation algorithm;avionics;blocking (computing);bottleneck (software);central processing unit;compiler;distributed computing;end-to-end principle;high- and low-level;mathematical optimization;michael j. fischer;nonlinear programming;nonlinear system;pentium 4;program slicing;propagation delay;real-time clock;real-time computing;real-time locating system;real-time transcription;replay attack;requirement;robotics;sampling (signal processing);scheduling (computing);search algorithm;software propagation;solver;streaming media	Richard Gerber;Seongsoo Hong;Manas Saksena	1995	IEEE Trans. Software Eng.	10.1109/32.392979	propagation delay;systems analysis;design;mathematical optimization;real-time computing;real-time operating system;computer science;operating system;methodology;formal specification;distributed computing;constraint;scheduling	Embedded	0.46585764587419337	53.66487958609979	197033
973202135cda2bb3edfb73ca7dedff09e627fd19	exploiting domain knowledge in system-level mpsoc design space exploration	universiteitsbibliotheek;design space pruning;system level design space exploration;genetic algorithms;mpsoc design	System-level design space exploration (DSE), which is performed early in the design process, is of eminent importance to the design of complex multi-processor embedded multimedia systems. During system-level DSE, system parameters like, e.g., the number and type of processors, and the mapping of application tasks to architectural resources, are considered. The number of design instances that need to be evaluated during such DSE to find good design candidates is large, making the DSE process time consuming. Therefore, pruning techniques are needed to optimize the DSE process, allowing the DSE search algorithms to either find the design candidates quicker or to spend the same amount of time to evaluate more design points and thus improve the chance of finding even better candidates. In this article, we study several novel approaches that exploit domain knowledge to optimize the DSE search process. To this end, we focus on DSE techniques based on genetic algorithms (GA) and introduce two new extensions to a GA to optimize its search behavior. Experimental results demonstrate that the extended GAs perform at least as well, but typically significantly better than a reference (non-optimized) GA. ! 2013 Elsevier B.V. All rights reserved.	central processing unit;design space exploration;electronic system-level design and verification;embedded system;extended precision;genetic algorithm;level design;mpsoc;multiprocessing;premature convergence;search algorithm;software release life cycle;systems design	Mark Thompson;Andy D. Pimentel	2013	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2013.05.023	embedded system;parallel computing;real-time computing;simulation;genetic algorithm;computer science;operating system	AI	0.8815707225916821	55.73329109503491	197396
0c1140e1cb605170545fc89c00a1f17a70ecd922	delay and power consumption estimation in embedded systems using hierarchical performance modeling	power consumption delay estimation embedded systems graphics processing units parallel processing power aware computing;gpu;flow graphs;embedded systems;message systems;graphics processing units;hardware architectures power consumption estimation delay estimation embedded systems hierarchical performance modeling performance metric estimation parallelization schemes hpm gpus software platforms;embedded systems hierarchical performance modeling hpm gpu parallelization delay power consumption estimate;parallelization;estimate;power consumption;hierarchical performance modeling hpm;delays power demand embedded systems graphics processing units message systems flow graphs;power demand;delays	Embedded systems have become very important in our life; they pervade all fields in today's advanced technology. With the increasing importance of these systems, designers need to estimate the performance metrics such as Delay which includes processing and communication and Power consumption. This procedure is very critical and even crucial at an early stage of design and implementation. Using GPUs and parallelization schemes together shows a promising sight to enhance the delay in a system under investigation with trade-off in power consumption and code size. In this paper, we will analyze that system using Hierarchical Performance Modeling (HPM) to estimate the improvement in the delay by using GPUs and parallelization methods on different hardware architectures and software platforms. The experimental results showed an improvement in the delay each time we used more threads and maximum reduction obtained when GPU was invoked to perform all graphical tasks.	embedded system;graphical user interface;graphics processing unit;parallel computing;performance prediction;principle of abstraction	Ahmed Alsheikhy;Song Han;Reda A. Ammar	2015	2015 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)	10.1109/ISSPIT.2015.7394356	embedded system;estimation;parallel computing;real-time computing;computer science	EDA	-0.7848723212561741	55.82478527616717	197488
6537abe79bfd6b25483524506198d25043a958e5	modeling and analysis of sldl-captured noc abstractions		With increasing number of IP cores, parallel communication architectures including NoCs have emerged for many-core systems. To efficiently architect NoCs, early analysis of crucial run-time metrics such as throughput, latency and saturation time is required. This requires abstract modeling of NoCs. Modeling abstraction, and consequently the modeling granularity impacts the accuracy and speed of simulation. While a fine-grained model will slowly lead more accurate information, a coarser model simulates faster and yields less accurate predictions. This paper first identifies possible levels of abstraction for NoC models and correlating captured features with the accuracy/speed trade-off. Second, this paper proposes two NoC models at different abstraction levels: a finer grained Bus-Functional Model (BFM), and a coarser Transaction-Level Model (TLM). The BFM updates the system status after any events happening during data unit transmission, while the TLM updates the system status at the end of data unit transmission. Our evaluation results show moving to higher abstraction (from BFM to TLM) gains at least 10x speedup at the cost of 10% 20% accuracy loss on average. Our analysis approach and results guide system architects in exploring NoC architectural alternatives and help identifying suitable abstract levels.	bus functional model;clock signal;manycore processor;network on a chip;principle of abstraction;simulation;specc;speedup;throughput	Ran Hao;Nasibeh Teimouri;Kasra Moazzemi;Gunar Schirner	2015		10.1007/978-3-319-90023-0_11	parallel computing;throughput;latency (engineering);granularity;computer science;abstraction;parallel communication	Metrics	-0.766775339441956	56.18520601676912	197543
034544d3d0cfaaea3bf0dac7ad2a399a9f454e4f	a constraint-based application model and scheduling techniques for power-aware systems	mars;power aware embedded systems;formal specification;application software;processor scheduling;impacct system level framework;constraint based application model;embedded systems software;power system modeling processor scheduling energy management power system management mars batteries thermal management application software embedded system timing;embedded system;embedded systems;low power;formal specification embedded systems processor scheduling;power system management;scheduling;constraint modeling;real time scheduling;batteries;power aware systems;min max power constraints;system level design;power management;min max timing;real mission critical applications;impacct system level framework constraint based application model scheduling power aware systems embedded systems performance constraints graph based model design space exploration power aware embedded systems min max timing min max power constraints constraint classification real mission critical applications;energy cost;design space exploration;power aware real time scheduling;power system modeling;performance constraints;thermal management;graph based model;energy management;timing;constraint classification	New embedded systems must be power-aware, not just low-power. That is, they must track their power sources and the changing power and performance constraints imposed by the environment. Moreover, they must fully explore and integrate many novel power management techniques. Unfortunately, these techniques are often incompatible with each other due to overspecialized formulations or they fail to consider system-wide issues. This paper proposes a new graph-based model to integrate novel power management techniques and facilitate design-space exploration of power-aware embedded systems. It captures min/max timing and min/max power constraints on computation and non-computation tasks through a new constraint classification and enables derivation of flexible system-level schedules. We demonstrate the effectiveness of this model with a power-aware scheduler on real mission-critical applications. Experimental results show that our automated techniques can improve performance and reduce energy cost simultaneously. The application model and scheduling tool presented in this paper form the basis of the IMPACCT system-level framework that will enable designers to aggressively explore many power-performance trade-offs with confidence.	computation;context-aware pervasive systems;embedded system;low-power broadcasting;maxima and minima;mission critical;power management;scheduling (computing)	Jinfeng Liu;Pai H. Chou;Nader Bagherzadeh;Fadi J. Kurdahi	2001		10.1145/371636.371707	embedded system;parallel computing;real-time computing;computer science	EDA	2.3796609432264404	54.827599825537625	198860
cfa2199f0fed0d53ef22c976a8d8276614c47382	compilation and simulation tool chain for memory aware energy optimizations	compilacion;economies d energie;optimisation;calculateur embarque;compilateur;ahorros energia;mobile device;optimizacion;code optimization;validacion;gollete estrangulamiento;simulation framework;digital camera;energy dissipation;compiler;video game;simulator;goulot etranglement;simulador;energy optimization;memory optimization;energy consumption;boarded computer;simulateur;consommation energie;hierarchie memoire;compilation;energy savings;validation;optimization;design space exploration;memory hierarchy;jerarquia memoria;simulation tool;system simulation;bottleneck;calculador embarque;compilador;consumo energia;embedded device	Memory hierarchies are known to be the energy bottleneck of portable embedded devices. Numerous memory aware energy optimizations have been proposed. However, both the optimization and the validation is performed in an ad-hoc manner as a coherent compilation and simulation framework does not exist as yet. In this paper, we present such a framework for performing memory hierarchy aware energy optimization. Both the compiler and the simulator are configured from a single memory hierarchy description. Significant savings of upto 50% in the total energy dissipation are reported.	arm architecture;coherence (physics);compiler;design space exploration;embedded system;hoc (programming language);mathematical optimization;memory hierarchy;simulation;system on a chip;toolchain;unicast	Manish Verma;Lars Wehmeyer;Robert Pyka;Peter Marwedel;Luca Benini	2006		10.1007/11796435_29	single compilation unit;compiler;parallel computing;real-time computing;simulation;computer science;dissipation;operating system;program optimization;mobile device;programming language	EDA	-2.3947421178380703	54.43009288752428	199240
0ef40799193c265c56b54ceebe93460fbb436b08	a hierarchical approach for energy efficient application design using heterogeneous embedded systems	energy efficiency;approximation error;energy efficient;performance estimation;simulation framework;design space;embedded system;low power;duty cycle;detection algorithm;heterogeneous embedded systems;design space exploration;hierarchical design	Several features such as reconfiguration, voltage and frequency scaling, low-power operating states, duty-cycling, etc. are exploited for latency and energy efficient application design using heterogeneous embedded systems. However, more choices during application design results in a large design space that must be traversed efficiently. In this paper, we propose a hierarchical methodology that integrates optimization heuristics, high-level performance estimators, and low-level simulators to enable efficient exploration of large design spaces. Our methodology is fast, robust against approximation errors due to high-level modeling, and can evaluate a much larger design space than an optimization heuristic only design space exploration technique. We have augmented MILAN, a model-based integrated simulation framework for embedded systems, to develop an environment to perform hierarchical design space exploration. Using our methodology for a beamforming application, we identify an energy-efficient mapping onto a heterogeneous embedded system while meeting a given latency constraint. We also demonstrate the use of our methodology in identifying an energy and latency efficient heterogeneous embedded system based on user-specified performance requirements for a personnel detection algorithm from a set of devices that includes FPGAs, DSPs, and traditional processors.	approximation;beamforming;central processing unit;compiler;design space exploration;digital signal processor;duty cycle;dynamic voltage scaling;embedded system;field-programmable gate array;frequency scaling;genetic algorithm;heuristic (computer science);high- and low-level;image scaling;low-power broadcasting;mathematical optimization;requirement;simulated annealing;simulation;tree traversal;usability	Sumit Mohanty;Viktor K. Prasanna	2003		10.1145/951710.951743	embedded system;parallel computing;real-time computing;simulation;computer science;operating system;efficient energy use	EDA	1.5210374968774263	54.77129579589433	199778
