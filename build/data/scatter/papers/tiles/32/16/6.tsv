id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
4189789fbe23355049ce67c5246defed7d09ff7a	pede (pig est data explorer) has been expanded into pig expression data explorer, including 10 147 porcine full-length cdna sequences	libraries;genes;animals;databases nucleic acid;family suidae;full length;internet;sequence homology nucleic acid;gene library;cdna sequence;dna complementary;molecular sequence data;data exploration;clone cells;user computer interface;base sequence;cdna cloning;swine;expressed sequence tags;cdna library	We formerly released the porcine expressed sequence tag (EST) database Pig EST Data Explorer (PEDE; http://pede.dna.affrc.go.jp/), which comprised 68,076 high-quality ESTs obtained by using full-length-enriched cDNA libraries derived from seven tissues. We have added eight tissues and cell types to the EST analysis and have integrated 94,555 additional high-quality ESTs into the database. We also fully sequenced the inserts of 10,147 of the cDNA clones that had undergone EST analysis; the sequences and annotation of the cDNA clones were stored in the database. Further, we constructed an interface that can be used to perform various searches in the database. The PEDE database is the primary resource of expressed pig genes that are supported by full-length cDNA sequences. This resource not only enables us to pick cDNA clones of interest for a particular analysis, but it also confirms and thus contributes to the sequencing integrity of the pig genome, which is now being compiled by an international consortium (http://www.piggenome.org/). PEDE has therefore evolved into what we now call 'Pig Expression Data Explorer'.	annotation;biopolymer sequencing;body tissue;compiler;dna, complementary;expressed sequence tags;libraries;pierre robin syndrome;porcine species	Hirohide Uenishi;Tomoko Eguchi-Ogawa;Hiroki Shinkai;Naohiko Okumura;Kohei Suzuki;Daisuke Toki;Noriyuki Hamasima;Takashi Awata	2007		10.1093/nar/gkl954	biology;molecular biology;the internet;cdna library;bioinformatics;genomic library;gene;genetics;expressed sequence tag	Comp.	-1.675329371656172	-60.31483805585655	117744
4c1a1f6db6211f70205d338f5d16096f6d136d2a	variation resources at uc santa cruz	animals;genomics;mice;alleles;rats;genome annotation;genotype;databases nucleic acid;allele frequency;university of california;internet;gene frequency;polymorphism;genome;non human primate;primates;humans;sequence alignment;user computer interface;recombination genetic;ucsc;linkage disequilibrium;polymorphism single nucleotide;single nucleotide polymorphism	The variation resources within the University of California Santa Cruz Genome Browser include polymorphism data drawn from public collections and analyses of these data, along with their display in the context of other genomic annotations. Primary data from dbSNP is included for many organisms, with added information including genomic alleles and orthologous alleles for closely related organisms. Display filtering and coloring is available by variant type, functional class or other annotations. Annotation of potential errors is highlighted and a genomic alignment of the variant's flanking sequence is displayed. HapMap allele frequencies and linkage disequilibrium (LD) are available for each HapMap population, along with non-human primate alleles. The browsing and analysis tools, downloadable data files and links to documentation and other information can be found at http://genome.ucsc.edu/.	alleles;collections (publication);documentation;flank (surface region);gene frequency;graph coloring;homology (biology);international hapmap project;linkage disequilibrium;primates;sequence homology;uc browser;university of california at santa cruz;dbsnp	Daryl J. Thomas;Heather Trumbower;Andrew D. Kern;Brooke L. Rhead;Robert M. Kuhn;David Haussler;W. James Kent	2007		10.1093/nar/gkl953	biology;genomics;bioinformatics;allele frequency;genetics	Comp.	-2.084594019388471	-60.203512422787554	117751
5db53121536296ee122bd08e857717aecb66d2e4	swiss-prot: juggling between evolution and stability	anotacion;functional annotation;secuencia aminoacido;base donnee;proteine;development;sequence aminoacide;aminoacid sequence;protein sequence;qualite;evolucion;database;ressource;desarrollo;base dato;bioinformatique;user feedback;annotation;serveur institutionnel;stability;archive institutionnelle;quality;developpement;automatic annotation;open access;focal point;life sciences;proteina;sequence analysis;archive ouverte unige;bioinformatica;stabilite;cybertheses;protein;recurso;institutional repository;estabilidad;calidad;bioinformatics;evolution;resource	We describe some of the aspects of Swiss-Prot that make it unique, explain what are the developments we believe to be necessary for the database to continue to play its role as a focal point of protein knowledge, and provide advice pertinent to the development of high-quality knowledge resources on one aspect or the other of the life sciences.	biological science disciplines;clinical trial protocol document;focal (programming language);relevance;swiss-model;switzerland	Amos Bairoch;Brigitte Boeckmann;Serenella Ferro;Elisabeth Gasteiger	2004	Briefings in bioinformatics	10.1093/bib/5.1.39	biology;stability;bioinformatics;artificial intelligence;sequence analysis;evolution;genetics;resource	Web+IR	-3.711212346121535	-60.69691363031671	118090
920d7bf3e61524e0b9cfcf19b96afd73bb2ac864	prime: a web site that assembles tools for metabolomics and transcriptomics		PRIMe (http://prime.psc.riken.jp/), the Platform for RIKEN Metabolomics, is a Web site that has been designed and implemented to support research and analysis workflows ranging from metabolome to transcriptome analysis. The site provides access to a growing collection of standardized measurements of metabolites obtained by using NMR, GC-MS, LC-MS, and CE-MS, and metabolomics tools that support related analyses (SpinAssign for the identification of metabolites by means of NMR, KNApSAcK for searches within metabolite databases). In addition, the transcriptomics tools provide Correlated Gene Search, and Cluster Cutting for the analysis of mRNA expression. Use of the tools and database can contribute to the analysis of biological events at the levels of metabolites and gene expression, and we describe one example of such an analysis for Arabidopsis thaliana using the batch-learning self-organizing map (BL-SOM), which is provided via the Web site.	bl (logic);database;gene expression profiling;metabolite;metabolome;metabolomics;organizing (structure);self-organization;self-organizing map;type iii site-specific deoxyribonuclease;world wide web	Kenji Akiyama;Eisuke Chikayama;Hiroaki Yuasa;Yukihisa Shimada;Takayuki Tohge;Kazuo Shinozaki;Masami Yokota Hirai;Tetsuya Sakurai;Jun Kikuchi;Kazuki Saito	2008	In silico biology		gene expression;metabolomics;metabolome;bioinformatics;transcriptome;metabolite;ranging;human metabolome database;biology	Comp.	-1.2010184529289352	-59.646418940775796	118442
1d402442f15a67f0f1c683bc8de21511e8f4169d	the sbase protein domain library, release 6.0: a collection of annotated protein sequence segments	proteins;structure function;ligand binding;protein conformation;amino acid sequence;protein sequence;internet;protein domains	The sixth release of the SBASE protein domain library sequences contains 130 703 annotated and crossreferenced entries corresponding to structural, functional, ligand-binding and topogenic segments of proteins. The entries were grouped based on standard names (2312 groups) and futher classified on the basis of the BLAST similarity (2463 clusters). Automated searching with BLAST and a new sequence-plot representation of local domain similarities are available at the WWW-server http://www.icgeb.trieste.it/sbase. A mirror site is at http://sbase.abc.hu/sbase. The database is freely available by anonymous 'ftp' file transfer from ftp.icgeb.trieste.it		János Murvai;Kristian Vlahovicek;Endre Barta;Csaba Szepesvári;Cristina Acatrinei;Sándor Pongor	1999	Nucleic acids research	10.1093/nar/27.1.257		Comp.	-1.9814459692531226	-60.19545402187007	118524
f23500ac9594a102f90da506368935bc8a769399	dgidb 2.0: mining clinically relevant drug-gene interactions	genes;drug delivery systems;drug discovery;mining;ligands;databases pharmaceutical;data mining;precision medicine;gene interaction;genome	The Drug-Gene Interaction Database (DGIdb, www.dgidb.org) is a web resource that consolidates disparate data sources describing drug-gene interactions and gene druggability. It provides an intuitive graphical user interface and a documented application programming interface (API) for querying these data. DGIdb was assembled through an extensive manual curation effort, reflecting the combined information of twenty-seven sources. For DGIdb 2.0, substantial updates have been made to increase content and improve its usefulness as a resource for mining clinically actionable drug targets. Specifically, nine new sources of drug-gene interactions have been added, including seven resources specifically focused on interactions linked to clinical trials. These additions have more than doubled the overall count of drug-gene interactions. The total number of druggable gene claims has also increased by 30%. Importantly, a majority of the unrestricted, publicly-accessible sources used in DGIdb are now automatically updated on a weekly basis, providing the most current information for these sources. Finally, a new web view and API have been developed to allow searching for interactions by drug identifiers to complement existing gene-based search functionality. With these updates, DGIdb represents a comprehensive and user friendly tool for mining the druggable genome for precision medicine hypothesis generation.	access network;add-ons for firefox;application programming interface;categories;clinical data;complement system proteins;digital curation;document completion status - documented;drug delivery systems;drug interactions;graphical user interface;identifier;informatics (discipline);interaction;nar 2;numerous;pipeline (computing);precision medicine;review [publication type];score;total number;twenty seven;usability;user interface device component;web application;web resource;whole earth 'lectronic link	Alex H. Wagner;Adam C. Coffman;Benjamin J. Ainscough;Nicholas C. Spies;Zachary L. Skidmore;Katie M. Campbell;Kilannin Krysiak;Deng Pan;Joshua F. McMichael;James M. Eldred;Jason R. Walker;Richard K. Wilson;Elaine R. Mardis;Malachi Griffith;Obi L. Griffith	2016	Nucleic acids research	10.1093/nar/gkv1165	biology;mining;bioinformatics;gene;precision medicine;ligand;genetics;drug discovery;genome	Comp.	-1.7209170453594163	-59.53114693748984	118645
dac89533c69df44f1565c7484d03d6ffa6d55484	fold-em: automated fold recognition in medium- and low-resolution (4-15 å) electron density maps	chaperonin 60;software;electrons;models molecular;cryoelectron microscopy;protein structure tertiary;structural homology protein;macromolecular substances;algorithms;protein folding;molecular docking simulation;databases protein	MOTIVATION Owing to the size and complexity of large multi-component biological assemblies, the most tractable approach to determining their atomic structure is often to fit high-resolution radiographic or nuclear magnetic resonance structures of isolated components into lower resolution electron density maps of the larger assembly obtained using cryo-electron microscopy (cryo-EM). This hybrid approach to structure determination requires that an atomic resolution structure of each component, or a suitable homolog, is available. If neither is available, then the amount of structural information regarding that component is limited by the resolution of the cryo-EM map. However, even if a suitable homolog cannot be identified using sequence analysis, a search for structural homologs should still be performed because structural homology often persists throughout evolution even when sequence homology is undetectable, As macromolecules can often be described as a collection of independently folded domains, one way of searching for structural homologs would be to systematically fit representative domain structures from a protein domain database into the medium/low resolution cryo-EM map and return the best fits. Taken together, the best fitting non-overlapping structures would constitute a 'mosaic' backbone model of the assembly that could aid map interpretation and illuminate biological function.   RESULT Using the computational principles of the Scale-Invariant Feature Transform (SIFT), we have developed FOLD-EM-a computational tool that can identify folded macromolecular domains in medium to low resolution (4-15 Å) electron density maps and return a model of the constituent polypeptides in a fully automated fashion. As a by-product, FOLD-EM can also do flexible multi-domain fitting that may provide insight into conformational changes that occur in macromolecular assemblies.	acclimatization;boat dock;cobham's thesis;cryoelectron microscopy;data table;docking (molecular);dolev–yao model;expectation–maximization algorithm;fits;fold (higher-order function);function (biology);graph - visual representation;graph theory;hash table;homologous gene;image resolution;inter-domain;internet backbone;large;matching;map;marijuana abuse;mosaic - computer software;motion;numerous;polypeptides;programming tool;protein domain;radiography;recursion;resonance;scale-invariant feature transform;scanning electron microscopy;scop;sequence analysis;sequence homology;small;staphylococcal protein a;structural analysis;threading (protein sequence);united states national institutes of health;vertebral column;yao graph;alpha-aminobutyric acid;cell transformation;electron density;macromolecule	Mitul Saha;Marc C. Morais	2012	Bioinformatics	10.1093/bioinformatics/bts616	protein folding;biology;bioinformatics;electron;structural bioinformatics;protein structure database	Comp.	1.4523899005180922	-61.08104843775769	118895
32dc2a2ea7d1735b3c0cf5f782200453215fe6cd	the embl-ebi bioinformatics web and programmatic tools framework		Since 2009 the EMBL-EBI Job Dispatcher framework has provided free access to a range of mainstream sequence analysis applications. These include sequence similarity search services (https://www.ebi.ac.uk/Tools/sss/) such as BLAST, FASTA and PSI-Search, multiple sequence alignment tools (https://www.ebi.ac.uk/Tools/msa/) such as Clustal Omega, MAFFT and T-Coffee, and other sequence analysis tools (https://www.ebi.ac.uk/Tools/pfa/) such as InterProScan. Through these services users can search mainstream sequence databases such as ENA, UniProt and Ensembl Genomes, utilising a uniform web interface or systematically through Web Services interfaces (https://www.ebi.ac.uk/Tools/webservices/) using common programming languages, and obtain enriched results with novel visualisations. Integration with EBI Search (https://www.ebi.ac.uk/ebisearch/) and the dbfetch retrieval service (https://www.ebi.ac.uk/Tools/dbfetch/) further expands the usefulness of the framework. New tools and updates such as NCBI BLAST+, InterProScan 5 and PfamScan, new categories such as RNA analysis tools (https://www.ebi.ac.uk/Tools/rna/), new databases such as ENA non-coding, WormBase ParaSite, Pfam and Rfam, and new workflow methods, together with the retirement of depreciated services, ensure that the framework remains relevant to today's biological community.	blast;bioinformatics;categories;databases;ensembl genomes;external bus interface;fasta;interproscan;interface device component;mafft;multiple sequence alignment;national center for biotechnology information;omega;pfam;programming languages;programming language;rfam;sequence analysis;similarity search;t-coffee;uniprot;user interface;web service;wormbase	Weizhong Li;Andrew Peter Cowley;Mahmut Uludag;Tamer Gur;Hamish McWilliam;Silvano Squizzato;Youngmi Park;Nicola Buso;Rodrigo Lopez	2015		10.1093/nar/gkv279	bioinformatics	Comp.	-2.3510161389694115	-59.994127044281235	119046
0fee8b5bde0f03b488f1f7ea7b8712ffbccde83a	the nanomaterial registry: opportunities and challenges in informatics	minimal information standards;data downstream analysis nanomaterial registry diverse test methods nanomaterial community standard protocols data formatting controlled vocabularies web based tool nanomaterial data environmental interaction biological interaction data driven content advance nanomaterial research stakeholder groups nanotechnology community industry regulatory government academia nr website features search browse data quality data quantity;web sites biochemistry bioinformatics nanobiotechnology nanostructured materials;nanomaterials standards data models nanobioscience communities protocols;nanotechnology;registry;nanomaterials;nanostructured materials;nanoinformatics;web sites;minimal information standards nanomaterials registry nanoinformatics nanotechnology;biochemistry;bioinformatics;nanobiotechnology	The quantity of publicly available literature on nanotechnology is staggering. The interpretation, sharing and downstream analysis of the data in this literature is both complex and rapidly evolving. The complexities surrounding the research and data are largely a result of the characteristics inherent to nanomaterials, as well as the diverse test methods, protocols, and assays used to evaluate these characteristics and interactions. The Nanomaterial Registry (NR) has been developed, through cooperation with the nanomaterial community, to address challenges, such as the needs for standard protocols, methods, data formatting, and controlled vocabularies. The NR is an authoritative, web-based tool whose purpose is to simplify the community's level of effort in assessing nanomaterial data from environmental and biological interaction studies. Because the NR is meant to be an authoritative resource, all data driven content is systematically curated and reviewed by subject matter experts. To support and advance nanomaterial research, a set of minimal information about nanomaterials (MIAN) has been developed and is foundational to the NR data model. The MIAN has been used to create evaluation and similarity criteria for nanomaterials that are curated into the NR. The NR is a publically available resource that is being built through collaborations with many stakeholder groups in the nanotechnology community, including industry, regulatory, government, and academia. Features of the NR website (www.nanomaterialregistry.org) currently include search, browse, side-by-side comparison of nanomaterials, compliance ratings based on the quality and quantity of data, and the ability to search for similar nanomaterials within the NR.	browsing;controlled vocabulary;data model;downstream (software development);informatics;interaction;noise reduction;subject matter expert turing test;subject-matter expert;web application	Michele L. Ostraat;Karmann C. Mills;Kimberly A. Guzan	2012	2012 IEEE International Conference on Bioinformatics and Biomedicine Workshops	10.1109/BIBMW.2012.6470258	nanomaterials;bioinformatics;data mining;nanobiotechnology	Visualization	-1.4625856739884213	-62.394631220732364	119261
1993fc16b31e047c9f4cda5d79f4275f4f1c8da3	entrezajax: direct web browser access to the entrez programming utilities	health research;uk clinical guidelines;biological patents;service provider;europe pubmed central;citation search;asynchronous javascript and xml;computational biology bioinformatics;qa76 electronic computers computer science computer software;uk phd theses thesis;life sciences;uk research reports;medical journals;computer appl in life sciences;r medicine general;europe pmc;national center for biotechnology information;biomedical research;bioinformatics	"""Web applications for biology and medicine often need to integrate data from Entrez services provided by the National Center for Biotechnology Information. However, direct access to Entrez from a web browser is not possible due to 'same-origin' security restrictions. The use of """"Asynchronous JavaScript and XML"""" (AJAX) to create rich, interactive web applications is now commonplace. The ability to access Entrez via AJAX would be advantageous in the creation of integrated biomedical web resources. We describe EntrezAJAX, which provides access to Entrez eUtils and is able to circumvent same-origin browser restrictions. EntrezAJAX is easily implemented by JavaScript developers and provides identical functionality as Entrez eUtils as well as enhanced functionality to ease development. We provide easy-to-understand developer examples written in JavaScript to illustrate potential uses of this service. For the purposes of speed, reliability and scalability, EntrezAJAX has been deployed on Google App Engine, a freely available cloud service. The EntrezAJAX webpage is located at http://entrezajax.appspot.com/"""	ajax (programming);cloud computing;entrez;google app engine;internet;javascript;laryngeal web;random access;same-origin policy;scalability;web application;web page;web resource;xml	Nicholas J. Loman;Mark J. Pallen	2010		10.1186/1751-0473-5-6	service provider;ajax;web application;computer science;bioinformatics;data mining;database;world wide web	Web+IR	-3.8532688631801193	-60.09170996973702	119970
e73771498450c1e7099b90993452d8b38f476104	automated gene-retrieval system for biological information needs	text mining;intelligent information system;information retrieval;gene ranking;drosophila melanogaster;biological systems;information need;fruit fly;querying non conventional data sources;biological process;bioinformatics;gene ontology	In this day and age, conducting a biological experiment is presumably a very expensive procedure largely owing to the highly sophisticated and expensive equipment necessitated by the process. Conceivably, being capable of isolating and focusing on a smaller set of imperative genes or gene products that are of high relevance to the experiment, pathway, or biological system under investigation is very desirable largely owing to the potential savings in experimental costs. In this work, we propose an intelligent information system capable of generating a ranked list of genes and gene products that are most pertinent to a given biological pathway, experiment or system (referred to as a biological context henceforth). We assume that the biological context of interest can be described by various textual query terms and phrases from the biological domain which, in turn, relate to various molecular functions, biological processes and cellular components of genes and their products. Intelligent text-based analyses and mining are utilised for this purpose by using the published literature, in the form of publication abstracts downloaded from PubMed, with the intention of ranking genes and gene products having identified relationships to the specified description terms based on the gene ontology (GO) standard. At this stage, our approach is capable of producing promising results given all surrounding restrictions, one of which is the lack of similar work in the literature. For demonstration purposes, we report experimental results on the molting regulation pathway in Drosophila melanogaster (fruit fly).	information needs	Imad Rahal;Baoying Wang;Riad Rahhal	2009	JIKM	10.1142/S0219649209002191	information needs;text mining;computer science;bioinformatics;data mining;biological process;information retrieval	HPC	-2.037925564780981	-63.51128271622498	120134
57469c74291233e78c343f629c7d2d6b11f0af8a	biosig: an imaging bioinformatics system for phenotypic analysis	graph theory;guided workflow access biosig imaging bioinformatics system phenotypic analysis cell specific expression cellular phenotypes cell phenome mapping data representation experimental protocols informatic protocols cellular response cataloging image collections tissues cells organelles light microscopy attributed graph cellular morphology protein localization cellular organization tissue culture cell culture web based multilayer informatics architecture;general and miscellaneous mathematics computing and information science;cell culture;information systems;light microscopy;indexing terms;lawrence berkeley laboratory;data model;protein localization;internet;medical image processing;bioinformatics image analysis organisms informatics data models genomics protocols cells biology microscopy morphology;internet medical image processing optical microscopy graph theory;phenotype;99 general and miscellaneous mathematics computing and information science;optical microscopy	Organisms express their genomes in a cell-specific manner, resulting in a variety of cellular phenotypes or phenomes. Mapping cell phenomes under a variety of experimental conditions is necessary in order to understand the responses of organisms to stimuli. Representing such data requires an integrated view of experimental and informatic protocols. The proposed system, named BioSig, provides the foundation for cataloging cellular responses as a function of specific conditioning, treatment, staining, etc., for either fixed tissue or living cell studies. A data model has been developed to capture experimental variables and map them to image collections and their computed representation. This representation is hierarchical and spans across sample tissues, cells, and organelles, which are imaged with light microscopy. At each layer, content is represented with an attributed graph, which contains information about cellular morphology, protein localization, and cellular organization in tissue or cell culture. The Web-based multilayer informatics architecture uses the data model to provide guided workflow access for content exploration.	attributed graph grammar;bioinformatics;body tissue;cell culture techniques;cellular organizational structure;collections (publication);conditioning (psychology);data model;galaxy morphological classification;genome;graph - visual representation;informatics (discipline);light microscopy;multilayer perceptron;name;organelles;phenotype;protocols documentation;staining method;world wide web;intracellular protein transport	Bahram Parvin;Gerald Fontenay;Mary Helen Barcellos-Hoff	2003	IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society	10.1109/TSMCB.2003.816929	the internet;index term;data model;computer science;bioinformatics;artificial intelligence;graph theory;theoretical computer science;phenotype;optical microscope;protein subcellular localization prediction;cell culture;information system	Visualization	-0.7142791021367764	-62.375561496221096	120216
485764f6ed5f26ce051ce6c1ddeeb03a2260e14f	sifts: structure integration with function, taxonomy and sequences resource	molecular sequence annotation;internet;proteins;protein conformation;systems integration;sequence analysis protein;databases protein	The Structure Integration with Function, Taxonomy and Sequences resource (SIFTS; http://pdbe.org/sifts) is a close collaboration between the Protein Data Bank in Europe (PDBe) and UniProt. The two teams have developed a semi-automated process for maintaining up-to-date cross-reference information to UniProt entries, for all protein chains in the PDB entries present in the UniProt database. This process is carried out for every weekly PDB release and the information is stored in the SIFTS database. The SIFTS process includes cross-references to other biological resources such as Pfam, SCOP, CATH, GO, InterPro and the NCBI taxonomy database. The information is exported in XML format, one file for each PDB entry, and is made available by FTP. Many bioinformatics resources use SIFTS data to obtain cross-references between the PDB and other biological databases so as to provide their users with up-to-date information.	bibliographic reference;bioinformatics;biological database;cath;cross-reference;evolutionary taxonomy;file transfer protocol;interpro;ncbi taxonomy;pfam;protein data bank (file format);scop;semiconductor industry;uniprot;xml;teams	Sameer Velankar;Jose M. Dana;Julius O. B. Jacobsen;Glen van Ginkel;Paul J. Gane;Jie Luo;Thomas J. Oldfield;Claire O'Donovan;Maria Jesus Martin;Gerard J. Kleywegt	2013		10.1093/nar/gks1258	protein structure;the internet;bioinformatics;uniprot;system integration	DB	-2.6099967681156095	-61.17252055669769	120681
5e5c9c5136edc29049514d20093bd1129f7b4a0e	extracting metadata from biological experimental data	biology computing;data mining bioinformatics databases information retrieval gene expression biological cells biology computing ontologies aging biotechnology;linked data;information retrieval;database;experiment dataset;data mining;metadata extraction;ontologies artificial intelligence;domain ontology automatic metadata extraction biological experimental data public bioinformatics data source experiment dataset database data extraction data retrieval data mining knowledge discovery;automatic metadata extraction;data extraction;biological experimental data;meta data;public bioinformatics data source;ontologies artificial intelligence biology computing data mining information retrieval meta data;domain ontology;data retrieval;knowledge discovery	The process of automatically extracting metadata from an experiment's dataset is an important stage in efficiently integrating this dataset with data available in public bioinformatics data sources. Metadata extracted from the experiment's dataset can be stored in databases and used to verify data extracted from other experiments' datasets. Moreover, the biologist can keep track of the dataset so that it can be easily retrieved next time. The extracted metadata can be mined to discover useful knowledge as well as integrated with other information using domain ontology to reveal hidden relationships. The experiment's dataset may contain several kinds of metadata that can be used to add semantic value to linked data. This paper describes an approach for extracting metadata from an experiment's dataset. This system has been used in a preliminary investigation of aging across species	bioinformatics;database;experiment;linked data;mined;ontology (information science)	Badr Al-Daihani;W. Alex Gray;Peter Kille	2006	17th International Workshop on Database and Expert Systems Applications (DEXA'06)	10.1109/DEXA.2006.58	computer science;data science;linked data;data mining;database;knowledge extraction;database catalog;metadata;data retrieval;data element;information retrieval;metadata repository	Web+IR	-3.112266879875015	-63.14406990710446	121243
31e08d8ee1a759a81b720c9920f85af46aed6c2b	rebase - restriction enzymes and methylases	hydrolysis;restriction enzyme;enzyme;protein conformation;amino acid sequence;internet	REBASE is a comprehensive database of information about restriction enzymes and their associated methylases, including their recognition and cleavage sites and their commercial availability. Information from REBASE is available via monthly electronic mailings as well as via WAIS and anonymous ftp. Specialized files are available that can be used directly by many software packages.	database;rebase;wechsler adult intelligence scale (assessment scale)	Richard J. Roberts;Dana Macelis	1994	Nucleic acids research	10.1093/nar/29.1.268		DB	-2.166141611455305	-60.65734184263049	121893
5e70a25875f3094d906c047e102510836816db64	motif scraper: a cross-platform, open-source tool for identifying degenerate nucleotide motif matches in fasta files		Summary Many genomic features are defined not by exact sequence matches, but by degenerate nucleotide motifs that represent multiple compatible matches. While there are databases cataloging genomic features, such as the location of transcription factor motifs, for commonly used model species, identifying the locations of novel motifs, known motifs in non-model genomes, or known motifs in personal whole-genomes is difficult. I designed motif scraper to overcome this limitation, allowing for efficient, multiprocessor motif searches in any FASTA file.   Availability and implementation The motif scraper package (MIT license) is available via PyPI, and the Python source is available on GitHub at https://github.com/RobersonLab/motif_scraper.		Elisha D. Roberson	2018	Bioinformatics	10.1093/bioinformatics/bty437	data mining;motif (music);computational biology;degenerate energy levels;genome;nucleotide motif;computer science;cross-platform;scraper site	Comp.	-2.8108437472583483	-59.25219523638764	122096
0ea968fc4b1587692e8522df4cf2823a782a93fc	mfold web server for nucleic acid folding and hybridization prediction	dna;community;software;protein structure secondary;databases nucleic acid;computer graphics;nucleic acid denaturation;nucleic acids;dna single stranded;nucleic acid hybridization;models molecular;single stranded;internet;rna;secondary structure;nucleic acid conformation;graphic user interface;thermodynamics;world wide web;scientific communication;user computer interface;base sequence;nucleic acid;free energy	The abbreviated name, 'mfold web server', describes a number of closely related software applications available on the World Wide Web (WWW) for the prediction of the secondary structure of single stranded nucleic acids. The objective of this web server is to provide easy access to RNA and DNA folding and hybridization software to the scientific community at large. By making use of universally available web GUIs (Graphical User Interfaces), the server circumvents the problem of portability of this software. Detailed output, in the form of structure plots with or without reliability information, single strand frequency plots and 'energy dot plots', are available for the folding of single sequences. A variety of 'bulk' servers give less information, but in a shorter time and for up to hundreds of sequences at once. The portal for the mfold web server is http://www.bioinfo.rpi.edu/applications/mfold. This URL will be referred to as 'MFOLDROOT'.	accessibility;crossbreeding;dot plot (bioinformatics);graphical user interface;nucleic acid hybridization;nucleic acids;salicylic acid 20 mg/ml medicated liquid soap;server (computer);server (computing);software portability;strand (programming language);uniform resource locator;www;web server;world wide web	Michael Zuker	2003	Nucleic acids research	10.1093/nar/gkg595	biology;nucleic acid;molecular biology;bioinformatics;genetics	Web+IR	-2.9824029432645776	-59.610643850582946	122859
861d12394fcca5f1718ee0b3d0abba375a7af94e	oncodb.hcc: an integrated oncogenomic database of hepatocellular carcinoma revealed aberrant cancer target genes and loci	dna;genes;maps;chromosome aberrations;quantitative trait loci;animals;genomics;carcinoma hepatocellular;mice;rats;cancer;databases genetic;comparative genomic hybridization;rodentia;physical chromosome mapping;liver neoplasms;internet;rna;genome human;genome;chromosomes;reverse transcriptase polymerase chain reaction;genes neoplasm;humans;user computer interface;candidate disease gene;neoplasms;loss of heterozygosity;diagnosis;systems integration;liver neoplasms experimental;gene expression profiling;positional cloning	The OncoDB.HCC (http://oncodb.hcc.ibms.sinica.edu.tw) is based on physical maps of rodent and human genomes containing quantitative trait loci of rodent HCC models and various human HCC somatic aberrations including chromosomal data from loss of heterozygosity and comparative genome hybridization analyses, altered expression of genes from microarray and proteomic studies, and finally experimental data of published HCC genes. Comprehensive integration of HCC genomic aberration data avoids potential pitfalls of data inconsistency from single genomic approach and provides lines of evidence to reveal somatic aberrations from levels of DNA, RNA to protein. Twenty-nine of 30 (96.7%) novel HCC genes with significant altered expressions in compared between tumor and adjacent normal tissues were validated by RT-PCR in 45 pairs of HCC tissues and by matching expression profiles in 57 HCC patients of re-analyzed Stanford HCC microarray data. Comparative mapping of HCC loci in between human aberrant chromosomal regions and QTLs of rodent HCC models revealed 12 syntenic HCC regions with 2 loci effectively narrowed down to 2 Mb. Together, OncoDB.HCC graphically presents comprehensive HCC data integration, reveals important HCC genes and loci for positional cloning and functional studies, and discloses potential molecular targets for improving HCC diagnosis and therapy.	body tissue;cloning vectors;cryofibrinogen:prthr:pt:plas:ord:3d rt incubation;diploid cell;heterozygote;human-centered computing;liver carcinoma;loss of heterozygosity;matching;microarray;neoplasms;nucleic acid hybridization;patients;physical map of the human genome;proteomics;quantitative trait loci;rna;scientific publication;synteny;windows rt;comparative genomic analysis	Wen-Hui Su;Chuan-Chuan Chao;Shiou-Hwei Yeh;Ding-Shinn Chen;Pei-Jer Chen;Yuh-Shan Jou	2007		10.1093/nar/gkl845	biology;genomics;molecular biology;the internet;rna;bioinformatics;gene;loss of heterozygosity;gene expression profiling;chromosome;comparative genomic hybridization;genetics;quantitative trait locus;dna;genome;cancer;system integration	Comp.	0.7581791711455034	-61.38060563077012	122961
b1567de8b7f9eb01dd59ad48dff41146b23a7989	ecome: a simple model for an evolving consumption web	graph theory;biology computing;bioenergy conversion;client server systems evolution biological bioenergy conversion predator prey systems ecology graph theory perturbation theory biology computing;normal distribution;perturbation theory;predator prey systems;evolution biological;client server systems;ecology;time use;trophic level;biomass biological system modeling evolution biology ecosystems atmosphere animals atmospheric modeling kernel computational biology biodiversity;mass extinction;mass extinction web ecome graph based model global ecosystem evolutionary principle biomass consumption rate predator prey relationship speciation rate biodiversity ecosystem hyper changing species perturbation	ECOME is an interactive, graph-based model for simulating an evolving, closed consumption web. It demonstrates the fundamental behavior of a global ecosystem over evolutionary time using well-established ecological/evolutionary principles. Nodes in the graph send biomass along weighted, directed edges. New nodes evolve by speciation and disappear when biomass (i.e. population) shrinks to zero. Consumption rates, predator/prey relationships, and speciation rates are user-defined, following theoretic-distributions. The output shows the biomass and biodiversity over time for up to five trophic levels. Using this simple system, we demonstrate that closed ecosystems are inherently unstable in the absence of evolution or in the presence of a single, hyper-changing species, but are dynamically stable and robust to perturbations when the evolution rates for all species follow a normal distribution. Our new application provides provocative lessons for biology students during a time of mass extinction.	control theory;directed graph;ecosystem;graph (discrete mathematics);population;prey;simulation;trophic function	Christopher Bystroff;Sam DeLuca;Carl N. McDaniel	2005	2005 IEEE Computational Systems Bioinformatics Conference - Workshops (CSBW'05)	10.1109/CSBW.2005.56	normal distribution;biology;botany;graph theory;perturbation theory;trophic level;ecology;extinction event	Visualization	2.362406252895905	-62.109003363668776	123652
149eddbfe45a41c7fb171a223380b9b8ebf1833b	pathway curation: application of text-mining tools egift and rlims-p	biology computing;text analysis biology computing data mining database management systems genetics molecular biophysics;database management systems;orthology prediction pathway curation computational linguistics;text analysis;data mining;genetics;molecular biophysics;humans proteins bioinformatics genomics biological cells databases substrates;computational linguistics;pathway curation;orthology prediction;chicken tgf beta signaling pathway pathway curation text mining egift tool rlims p tool manually curated reference database metabolic pathway orthology prediction computational linguistic tool information extraction protein information resource	Gallus Reactome provides a manually curated reference database for chicken signaling and metabolic pathways. Providing such a high-quality reference database requires significant time input from both curators and pathway experts. This paper describes the application of orthology prediction, computational linguistic tools including text mining and information extraction applications, along with resources available from the Protein Information Resource, to facilitate pathway curation. In this paper, we describe these methods in the context of curating the chicken TGF beta signaling pathway.	bibliographic database;chicken;digital curation;gene regulatory network;information extraction;protein information resource;reactome: a database of reactions, pathways and biological processes.;text mining;trivial graph format	Carl J. Schmidt;Liang Sun;Cecilia N. Arighi;Keith S. Decker;K. Vijay-Shanker;Manabu Torii;Catalina O. Tudor;Cathy H. Wu;Peter D'Eustachio	2012	2012 IEEE International Conference on Bioinformatics and Biomedicine Workshops	10.1109/BIBMW.2012.6470377	computer science;bioinformatics;data science;computational linguistics;data mining;genetics;molecular biophysics	Visualization	-1.80128378104774	-62.27428900324614	123786
216122a8e3423e7a9d0bb44b7d1b244caeab4dd1	the embrace web service collection	software;medical and health sciences;medicin och halsovetenskap;biological science disciplines;utopia;journal article;article letter to editor;registries;internet;information dissemination;computational biology;systems integration	The EMBRACE (European Model for Bioinformatics Research and Community Education) web service collection is the culmination of a 5-year project that set out to investigate issues involved in developing and deploying web services for use in the life sciences. The project concluded that in order for web services to achieve widespread adoption, standards must be defined for the choice of web service technology, for semantically annotating both service function and the data exchanged, and a mechanism for discovering services must be provided. Building on this, the project developed: EDAM, an ontology for describing life science web services; BioXSD, a schema for exchanging data between services; and a centralized registry (http://www.embraceregistry.net) that collects together around 1000 services developed by the consortium partners. This article presents the current status of the collection and its associated recommendations and standards definitions.	bioinformatics;biological science disciplines;centralized computing;embrace;ephrin type-b receptor 1, human;one thousand;ontology;registries;web service;edatrexate;standards characteristics	Steve Pettifer;Jon C. Ison;Matúš Kalaš;Dave Thorne;Philip McDermott;Inge Jonassen;Ali Liaquat;José María Fernández;Jose Manuel Rodriguez;David G. Pisano;Christophe Blanchet;Mahmut Uludag;Peter M. Rice;Edita Bartaseviciute;Kristoffer Rapacki;Maarten L. Hekkelman;Olivier Sand;Heinz Stockinger	2010		10.1093/nar/gkq297	web application security;web development;the internet;web standards;ws-policy;ws-addressing;services computing;ws-i basic profile;web 2.0;universal description discovery and integration;utopia;system integration	Web+IR	-3.128354060034818	-62.093615386010946	124424
0249dfb2a2bce743dece21ae5e9f2cf8c105af3a	estimating phylogenies from molecular data		Phylogenetic estimation from aligned DNA, RNA or amino acid sequences has attracted more and more attention in recent years due to its importance in analysis of many fine-scale genetic data. Nowadays, its application fields range from medical research to drug discovery, to epidemiology, to systematics and population dynamics. Estimating phylogenies involves solving an optimization problem, called the Phylogenetic Estimation Problem (PEP), whose versions depend on the criterion used to select a phylogeny among plausible alternatives. This chapter o↵ers an overview of PEP and discuss the most important versions that occur in the literature.	cellular automaton;estimation theory;least squares;mathematical optimization;maximum parsimony (phylogenetics);molecular phylogenetics;national fund for scientific research;open road tolling;optimization problem;phylogenesis;phylogenetics;population dynamics;programming paradigm;statistical classification	Daniele Catanzaro	2011		10.1007/978-1-4419-6800-5_8	biology;zoology;bioinformatics	ML	0.8913970369426016	-64.88672118295621	124648
5b2888b9921e9a6d679d7de079cfafe9208896b5	oncomirdbb: a comprehensive database of micrornas and their targets in breast cancer	breast neoplasms;animals;female;mice;databases nucleic acid;q science general;computational biology bioinformatics;3 untranslated regions;algorithms;humans;combinatorial libraries;computational biology;rc0254 neoplasms tumors oncology including cancer;micrornas;computer appl in life sciences;microarrays;bioinformatics	Given the estimate that 30% of our genes are controlled by microRNAs, it is essential that we understand the precise relationship between microRNAs and their targets. OncomiRs are microRNAs (miRNAs) that have been frequently shown to be deregulated in cancer. However, although several oncomiRs have been identified and characterized, there is as yet no comprehensive compilation of this data which has rendered it underutilized by cancer biologists. There is therefore an unmet need in generating bioinformatic platforms to speed the identification of novel therapeutic targets. We describe here OncomiRdbB, a comprehensive database of oncomiRs mined from different existing databases for mouse and humans along with novel oncomiRs that we have validated in human breast cancer samples. The database also lists their respective predicted targets, identified using miRanda, along with their IDs, sequences, chromosome location and detailed description. This database facilitates querying by search strings including microRNA name, sequence, accession number, target genes and organisms. The microRNA networks and their hubs with respective targets at 3'UTR, 5'UTR and exons of different pathway genes were also deciphered using the 'R' algorithm. OncomiRdbB is a comprehensive and integrated database of oncomiRs and their targets in breast cancer with multiple query options which will help enhance both understanding of the biology of breast cancer and the development of new and innovative microRNA based diagnostic tools and targets of therapeutic significance. OncomiRdbB is freely available for download through the URL link http://tdb.ccmb.res.in/OncomiRdbB/index.htm .	3' untranslated regions;5' untranslated regions;accession number (identifier);accession number (bioinformatics);bio-informatics;bioinformatics;compiler;database;deregulation;download;exons;gene regulatory network;mammary neoplasms;micrornas;mined;miranda;organism;pollard's rho algorithm for logarithms;question (inquiry);uniform resource locator	Rimpi Khurana;Vinod Kumar Verma;Abdul Rawoof;Shrish Tiwari;Rekha A. Nair;Ganesh Mahidhara;Mohammed M. Idris;Alan R. Clarke;Lekha Dinesh Kumar	2013		10.1186/1471-2105-15-15	biology;dna microarray;bioinformatics;genetics;microrna	Comp.	0.06576096823577236	-60.249540558198966	125502
31d4b122f211c9c580eb5227f69a0b2fa7df2687	mirnameconverter: an r/bioconductor package for translating mature mirna names to different mirbase versions		Summary The miRBase database is the central and official repository for miRNAs and the current release is miRBase version 21.0. Name changes in different miRBase releases cause inconsistencies in miRNA names from version to version. When working with only a small number of miRNAs the translation can be done manually. However, with large sets of miRNAs, the necessary correction of such inconsistencies becomes burdensome and error-prone. We developed miRNAmeConverter , available as a Bioconductor R package and web interface that addresses the challenges associated with mature miRNA name inconsistencies. The main algorithm implemented enables high-throughput automatic translation of species-independent mature miRNA names to user selected miRBase versions. The web interface enables users less familiar with R to translate miRNA names given in form of a list or embedded in text and download of the results.   Availability and Implementation The miRNAmeConverter R package is open source under the Artistic-2.0 license. It is freely available from Bioconductor ( http://bioconductor.org/packages/miRNAmeConverter ). The web interface is based on R Shiny and can be accessed under the URL http://www.systemsmedicineireland.ie/tools/mirna-name-converter/ . The database that miRNAmeConverter depends on is provided by the annotation package miRBaseVersions.db and can be downloaded from Bioconductor ( http://bioconductor.org/packages/miRBaseVersions.db ). Minimum R version 3.3.0 is required.   Contact stefanhaunsberger@rcsi.ie.   Supplementary information Supplementary data are available at Bioinformatics online.	addresses (publication format);algorithm;annotation;bioconductor;bioinformatics;cognitive dimensions of notations;download;embedded system;embedding;geographic information systems;high-throughput computing;interface device component;machine translation;micrornas;name;open-source software;throughput;uniform resource locator;user interface;version;world wide web;mirbase	Stefan J. Haunsberger;Niamh M. C. Connolly;Jochen H. M. Prehn	2017	Bioinformatics	10.1093/bioinformatics/btw660	bioinformatics;mirbase;database	Comp.	-3.4507569229315744	-59.742046357815646	125530
ad5f0c2aa29822997a0fc61a18fee559fe830775	identification of replication origins in prokaryotic genomes	replication;genomic composition asymmetry;composition;composicion;nucleotides;comparative genomics;origin;origin of replication;binding site;replicacion;statistical analysis;identification;genome;origine;genomique comparative;origen;identificacion;genoma;gc skew;bacterial genome;dnaa box;genome sequence	The availability of hundreds of complete bacterial genomes has created new challenges and simultaneously opportunities for bioinformatics. In the area of statistical analysis of genomic sequences, the studies of nucleotide compositional bias and gene bias between strands and replichores paved way to the development of tools for prediction of bacterial replication origins. Only a few (about 20) origin regions for eubacteria and archaea have been proven experimentally. One reason for that may be that this is now considered as an essentially bioinformatics problem, where predictions are sufficiently reliable not to run labor-intensive experiments, unless specifically needed. Here we describe the main existing approaches to the identification of replication origin (oriC) and termination (terC) loci in prokaryotic chromosomes and characterize a number of computational tools based on various skew types and other types of evidence. We also classify the eubacterial and archaeal chromosomes by predictability of their replication origins using skew plots. Finally, we discuss possible combined approaches to the identification of the oriC sites that may be used to improve the prediction tools, in particular, the analysis of DnaA binding sites using the comparative genomic methods.	academy;bacteria;binding sites;bioinformatics;box;briefings in bioinformatics;cosmo-rs;chromosomes;chromosomes, archaeal;classification;collections (publication);dna replication;dna sequence rearrangement;dna binding site;experiment;genome;genome, bacterial;jean;labor (childbirth);national origin;nucleotides;online and offline;perfectly matched layer;replication origin;science;substance withdrawal syndrome;synteny;tangerine computer systems;web site;funding grant	Natalia V. Sernova;Mikhail S. Gelfand	2008	Briefings in bioinformatics	10.1093/bib/bbn031	identification;biology;composition;replication;gc skew;bioinformatics;binding site;origin;comparative genomics;genetics;origin of replication;genome	Comp.	2.666993131362966	-59.91606182074186	126350
a77f464cac9de2e93d98b6cd84af6af11db32e0a	toxygates: interactive toxicity analysis on a hybrid microarray and linked data platform		MOTIVATION In early stage drug development, it is desirable to assess the toxicity of compounds as quickly as possible. Biomarker genes can help predict whether a candidate drug will adversely affect a given individual, but they are often difficult to discover. In addition, the mechanism of toxicity of many drugs and common compounds is not yet well understood. The Japanese Toxicogenomics Project provides a large database of systematically collected microarray samples from rats (liver, kidney and primary hepatocytes) and human cells (primary hepatocytes) after exposure to 170 different compounds in different dosages and at different time intervals. However, until now, no intuitive user interface has been publically available, making it time consuming and difficult for individual researchers to explore the data.   RESULTS We present Toxygates, a user-friendly integrated analysis platform for this database. Toxygates combines a large microarray dataset with the ability to fetch semantic linked data, such as pathways, compound-protein interactions and orthologs, on demand. It can also perform pattern-based compound ranking with respect to the expression values of a set of relevant candidate genes. By using Toxygates, users can freely interrogate the transcriptome's response to particular compounds and conditions, which enables deep exploration of toxicity mechanisms.	adverse reaction to drug;biological markers;candidate disease gene;chembl;column (database);communication endpoint;curation;data collection;data access;dosage;gene expression;hiroshi ishii (computer scientist);homology (biology);interaction;labor (childbirth);limited stage (cancer stage);linked data platform;microarray;question (inquiry);renal tissue;resource description framework;sparql;science;silo (dataset);toxicogenomics;usb on-the-go;united states national institutes of health;usability;user interface device component;drug development	Johan Nyström-Persson;Yoshinobu Igarashi;Maori Ito;Mizuki Morita;Noriyuki Nakatsu;Hiroshi Y Yamada;Kenji Mizuguchi	2013	Bioinformatics	10.1093/bioinformatics/btt531	pharmacology;biology;toxicology;bioinformatics	Comp.	-0.5384402205538092	-61.892422089152255	127016
a111043702e3caa97e8b10d23f1d72b18aa25fb7	the spectral game: leveraging open data and crowdsourcing for education	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;mass spectrometry;spectrum;infrared spectra;computer applications in chemistry;nmr spectroscopy;theoretical and computational chemistry;computational biology bioinformatics;3d environment;uk phd theses thesis;life sciences;second life;uk research reports;medical journals;europe pmc;documentation and information in chemistry;biomedical research;organic chemistry;open source;bioinformatics	We report on the implementation of the Spectral Game, a web-based game where players try to match molecules to various forms of interactive spectra including 1D/2D NMR, Mass Spectrometry and Infrared spectra. Each correct selection earns the player one point and play continues until the player supplies an incorrect answer. The game is usually played using a web browser interface, although a version has been developed in the virtual 3D environment of Second Life. Spectra uploaded as Open Data to ChemSpider in JCAMP-DX format are used for the problem sets together with structures extracted from the website. The spectra are displayed using JSpecView, an Open Source spectrum viewing applet which affords zooming and integration. The application of the game to the teaching of proton NMR spectroscopy in an undergraduate organic chemistry class and a 2D Spectrum Viewer are also presented.	applet;application program interface;chemspider;chemistry, organic;crowdsourcing;extraction;internet;joint committee on atomic and molecular physical data;manufactured supplies;protons;rca spectra 70;second life;web site;web application	Jean-Claude Bradley;Robert J. Lancashire;Andrew S. I. D. Lang;Antony J. Williams	2009		10.1186/1758-2946-1-9	spectrum;medicine;mass spectrometry;computer science;bioinformatics;data science;multimedia;world wide web	HCI	-3.5114848011346065	-59.529256886757686	127225
5177d248a36e06857e2ed4963002dd2c822b8312	puldb: the expanded database of polysaccharide utilization loci		The Polysaccharide Utilization Loci (PUL) database was launched in 2015 to present PUL predictions in ∼70 Bacteroidetes species isolated from the human gastrointestinal tract, as well as PULs derived from the experimental data reported in the literature. In 2018 PULDB offers access to 820 genomes, sampled from various environments and covering a much wider taxonomical range. A Krona dynamic chart was set up to facilitate browsing through taxonomy. Literature surveys now allows the presentation of the most recent (i) PUL repertoires deduced from RNAseq large-scale experiments, (ii) PULs that have been subjected to in-depth biochemical analysis and (iii) new Carbohydrate-Active enzyme (CAZyme) families that contributed to the refinement of PUL predictions. To improve PUL visualization and genome browsing, the previous annotation of genes encoding CAZymes, regulators, integrases and SusCD has now been expanded to include functionally relevant protein families whose genes are significantly found in the vicinity of PULs: sulfatases, proteases, ROK repressors, epimerases and ATP-Binding Cassette and Major Facilitator Superfamily transporters. To cope with cases where susCD may be absent due to incomplete assemblies/split PULs, we present 'CAZyme cluster' predictions. Finally, a PUL alignment tool, operating on the tagged families instead of amino-acid sequences, was integrated to retrieve PULs similar to a query of interest. The updated PULDB website is accessible at www.cazy.org/PULDB_new/.	annotation;automated theorem proving;compact cassette;experiment;gastrointestinal tract structure;gene prediction;integrase;membrane transport proteins;partial;preparation;protein family;question (inquiry);refinement (computing);superfamily;sampling - surgical action;taxonomy (general);tracer;tract (literature);web site	Nicolas Terrapon;Vincent Lombard;Elodie Drula;Pascal Lapébie;Saad Al-Masaudi;Harry J. Gilbert;Bernard Henrissat	2018		10.1093/nar/gkx1022	genetics;gastrointestinal tract;genome;locus (genetics);molecular biology;integrase;gene;membrane transport protein;polysaccharide;enzyme;biology	Comp.	-0.6237851494183766	-60.24470683153474	127271
20740b17fd91394cfdf17ebf1c227312d6bb56cb	the database of interacting proteins: 2004 update	databases;prediction method;animals;ucla;two hybrid system techniques;yeasts;datasets;precipitin tests;information services;models molecular;quality assessment;internet;proteins;macromolecular substances;reproducibility of results;healthcare quality assessment;protein protein interaction;protein binding;humans;actins;databases factual;protein interaction;high throughput;growth;computational biology;information storage and retrieval;databases protein;protein interaction network	The Database of Interacting Proteins (http://dip.doe-mbi.ucla.edu) aims to integrate the diverse body of experimental evidence on protein-protein interactions into a single, easily accessible online database. Because the reliability of experimental evidence varies widely, methods of quality assessment have been developed and utilized to identify the most reliable subset of the interactions. This CORE set can be used as a reference when evaluating the reliability of high-throughput protein-protein interaction data sets, for development of prediction methods, as well as in the studies of the properties of protein interaction networks.	database of interacting proteins (dip);high-throughput computing;subgroup;throughput;protein protein interaction	Lukasz Salwínski;Christopher S. Miller;Adam J. Smith;Frank K. Pettit;James U. Bowie;David S Eisenberg	2004	Nucleic acids research	10.1093/nar/gkh086	protein–protein interaction;actin;high-throughput screening;biology;plasma protein binding;the internet;bioinformatics;genetics;information system	Comp.	0.4184630579005824	-59.56718267325518	127574
1bbb62f5de2e7bb5e1644bff90fd9766d98ca9cf	reconstructing tumor genome architectures	genome organization	Although cancer progression is often associated with genome rearrangements, little is known about the detailed genomic architecture of tumor genomes. The attempt to reconstruct the genomic organization of a tumor genome recently resulted in the development of the End Sequence Profiling (ESP) technique, and the application of this technique to human MCF7 tumor cells. We formulate the ESP Genome Reconstruction Problem, and develop an algorithm to solve this problem in the case of sparse ESP data. We apply our algorithm to analyze human MCF7 tumor cells, and obtain the first reconstruction of the putative architecture of human MCF7 tumor genome. Our results assist in the ongoing ESP analysis of MCF7 tumors by suggesting additional ESP experiments for the completion of a reliable reconstruction of the MCF7 tumor genome, and by focusing BAC re-sequencing efforts.	architecture as topic;bacterial artificial chromosomes;batman: arkham city;biopolymer sequencing;chronic kidney disease stage 5;color gradient;dna sequence rearrangement;experiment;genome;mcf-7 cells;neoplasms;sparse matrix;algorithm	Benjamin J. Raphael;Stanislav Volik;Colin Collins;Pavel A. Pevzner	2003	Bioinformatics		biology;bioinformatics;genomic organization;genetics	Comp.	0.16131336833984958	-65.99917682470607	127778
2366d397ddbdd818276650f9576595281bc5e456	nematode.net update 2011: addition of data sets and tools featuring next-generation sequencing data	software;animals;genomics;metabolic networks and pathways;basic medicine;high throughput nucleotide sequencing;databases genetic;sequence analysis dna;data mining;genome helminth;nematoda;polymorphism single nucleotide	Nematode.net (http://nematode.net) has been a publicly available resource for studying nematodes for over a decade. In the past 3 years, we reorganized Nematode.net to provide more user-friendly navigation through the site, a necessity due to the explosion of data from next-generation sequencing platforms. Organism-centric portals containing dynamically generated data are available for over 56 different nematode species. Next-generation data has been added to the various data-mining portals hosted, including NemaBLAST and NemaBrowse. The NemaPath metabolic pathway viewer builds associations using KOs, rather than ECs to provide more accurate and fine-grained descriptions of proteins. Two new features for data analysis and comparative genomics have been added to the site. NemaSNP enables the user to perform population genetics studies in various nematode populations using next-generation sequencing data. HelmCoP (Helminth Control and Prevention) as an independent component of Nematode.net provides an integrated resource for storage, annotation and comparative genomics of helminth genomes to aid in learning more about nematode genomes, as well as drug, pesticide, vaccine and drug target discovery. With this update, Nematode.net will continue to realize its original goal to disseminate diverse bioinformatic data sets and provide analysis tools to the broad scientific community in a useful and user-friendly manner.	annotation;bio-informatics;bioinformatics;biopolymer sequencing;data mining;description;drug delivery systems;ephrin type-b receptor 1, human;gene regulatory network;genome;genome, helminth;genomics;helminths;massively-parallel sequencing;mental association;nematodes;pesticides;phylum nematoda;population;portals;usability	John C. Martin;Sahar Abubucker;Esley Heizer;Christina M. Taylor;Makedonka Dautova Mitreva	2012		10.1093/nar/gkr1194	biology;genomics;bioinformatics;genetics	Comp.	-1.6016483410802433	-60.44092020061621	128539
3dece7eed106bcca1fdb408737762b6ebd19d5df	extract: interactive extraction of environment metadata and term suggestion for metagenomic sample annotation	biological patents;biomedical journals;text mining;europe pubmed central;citation search;mathematics and computing;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;basic biological sciences;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	The microbial and molecular ecology research communities have made substantial progress on developing standards for annotating samples with environment metadata. However, sample manual annotation is a highly labor intensive process and requires familiarity with the terminologies used. We have therefore developed an interactive annotation tool, EXTRACT, which helps curators identify and extract standard-compliant terms for annotation of metagenomic records and other samples. Behind its web-based user interface, the system combines published methods for named entity recognition of environment, organism, tissue and disease terms. The evaluators in the BioCreative V Interactive Annotation Task found the system to be intuitive, useful, well documented and sufficiently accurate to be helpful in spotting relevant text passages and extracting organism and environment terms. Comparison of fully manual and text-mining-assisted curation revealed that EXTRACT speeds up annotation by 15-25% and helps curators to detect terms that would otherwise have been missed. Database URL: https://extract.hcmr.gr/.	accepting of extremity;annotation;biocreative;community;compliance behavior;customize;delimiter;digital curation;document completion status - documented;ecology;generic drugs;html;large;metagenomics;metrorrhagia;ninl gene;name;named-entity recognition;natural language processing;scientific publication;server (computer);server (computing);spreadsheet;tablet dosage form;text mining;uniform resource locator;user interface device component;web application;web service;benefit;standards characteristics	Evangelos Pafilis;Pier Luigi Buttigieg;Barbra Ferrell;Emiliano Pereira;Julia Schnetzer;Christos Arvanitidis;Lars Juhl Jensen	2016		10.1093/database/baw005	text mining;medical research;image retrieval;computer science;bioinformatics;data mining;database;world wide web;information retrieval	NLP	-3.442353198530722	-60.44542341237925	128693
1705f91036a9956c1edd70eb00cfb7516fcfa236	amod: a morpholino oligonucleotide selection tool	software;sequence comparison;genomics;base composition;translation initiation site;screen;site selection;embryos;nucleotide sequence;internet;rna;gene knockdown;antisense oligomers;translation;zebrafish;morpholines;dna primers;model;design;sequence alignment;oligonucleotides antisense;user computer interface;primer design	AMOD is a web-based program that aids in the functional evaluation of nucleotide sequences through sequence characterization and antisense morpholino oligonucleotide (target site) selection. Submitted sequences are analyzed by translation initiation site prediction algorithms and sequence-to-sequence comparisons; results are used to characterize sequence features required for morpholino design. Within a defined subsequence, base composition and homodimerization values are computed for all putative morpholino oligonucleotides. Using these properties, morpholino candidates are selected and compared with genomic and transcriptome databases with the goal to identify target-specific enriched morpholinos. AMOD has been used at the University of Minnesota to design approximately 200 morpholinos for a functional genomics screen in zebrafish. The AMOD web server and a tutorial are freely available to both academic and commercial users at http://www.secretomes.umn.edu/AMOD/.	acquired immunodeficiency syndrome;base composition;database;databases;functional genomics;morpholinos;nucleotides;oligonucleotides;server (computing);transcription initiation;transcriptome;translation initiation;web application;web server;zebrafish;algorithm;antisense therapy	Eric W. Klee;Kyong Jin Shim;Michael A. Pickart;Stephen C. Ekker;Lynda B. M. Ellis	2005	Nucleic Acids Research	10.1093/nar/gki453	translation;biology;design;gene knockdown;genomics;molecular biology;rna;bioinformatics;sequence alignment;genetics	Comp.	-1.2330737753961372	-59.558541373240075	129081
0c5006831094c9b5194e5dfa650cfb1830a19944	castp: computed atlas of surface topography of proteins with structural and topographical mapping of functionally annotated residues	software;functional annotation;protein function;computer graphics;my publications;amino acid;topographic map;physico chemical properties;surface topography;protein structure;internet;proteins;protein conformation;online mendelian inheritance in man;amino acids;sequence alignment;3d structure;protein data bank;polymorphism single nucleotide;sequence analysis protein;single nucleotide polymorphism;databases protein;knowledge base	Cavities on a proteins surface as well as specific amino acid positioning within it create the physicochemical properties needed for a protein to perform its function. CASTp (http://cast.engr.uic.edu) is an online tool that locates and measures pockets and voids on 3D protein structures. This new version of CASTp includes annotated functional information of specific residues on the protein structure. The annotations are derived from the Protein Data Bank (PDB), Swiss-Prot, as well as Online Mendelian Inheritance in Man (OMIM), the latter contains information on the variant single nucleotide polymorphisms (SNPs) that are known to cause disease. These annotated residues are mapped to surface pockets, interior voids or other regions of the PDB structures. We use a semi-global pair-wise sequence alignment method to obtain sequence mapping between entries in Swiss-Prot, OMIM and entries in PDB. The updated CASTp web server can be used to study surface features, functional regions and specific roles of key residues of proteins.	amino acids;cervical atlas;computer atlas of surface topology of proteins;dental caries;genetic polymorphism;nucleotides;online mendelian inheritance in man;protein data bank;swiss-prot;semiconductor industry;sequence alignment;server (computer);server (computing);single nucleotide polymorphism;staphylococcal protein a;switzerland;topography;web server	Joe Dundas;Zheng Ouyang;Jeffery Tseng;T. Andrew Binkowski;Yaron Turpaz;Jie Liang	2006	Nucleic Acids Research	10.1093/nar/gkl282	biology;protein structure;knowledge base;molecular biology;amino acid;bioinformatics;genetics	Comp.	-2.0627049806560502	-60.218483581638125	129331
e4f72a6774d6c449e8523c245bd5baf4f9485212	merops: the peptidase database		Peptidases (proteolytic enzymes) are of great relevance to biology, medicine and biotechnology. This practical importance creates a need for an integrated source of information about them, and also about their natural inhibitors. The MEROPS database (http://merops.sanger.ac.uk) aims to fill this need. The organizational principle of the database is a hierarchical classification in which homologous sets of the proteins of interest are grouped in families and the homologous families are grouped in clans. Each peptidase, family and clan has a unique identifier. The database has recently been expanded to include the protein inhibitors of peptidases, and these are classified in much the same way as the peptidases. Forms of information recently added include new links to other databases, summary alignments for peptidase clans, displays to show the distribution of peptidases and inhibitors among organisms, substrate cleavage sites and indexes for expressed sequence tag libraries containing peptidases. A new way of making hyperlinks to the database has been devised and a BlastP search of our library of peptidase and inhibitor sequences has been added.	annotation;blast;clans;classification;database;expressed sequence tags;fasta format;file transfer protocol;homology (biology);hyperlink;index;information source;interaction;library (computing);merops;mysql;peptide hydrolases;proteolytic enzyme;published database;relevance;sql;structured query language;unique identifier;version	Neil D. Rawlings;Fraser R. Morton;Chai Yin Kok;Jun Kong;Alan J. Barrett	2004	Nucleic acids research	10.1093/nar/gkm954		DB	-1.2662146981323361	-60.2181281472824	129340
1a2438fc87953d0c3a38ac985d62ac6273c14652	letter to the editor: seqxml and orthoxml: standards for sequence and orthology information	naturvetenskap;natural sciences	There is a great need for standards in the orthology field. Users must contend with different ortholog data representations from each provider, and the providers themselves must independently gather and parse the input sequence data. These burdensome and redundant procedures make data comparison and integration difficult. We have designed two XML-based formats, SeqXML and OrthoXML, to solve these problems. SeqXML is a lightweight format for sequence records-the input for orthology prediction. It stores the same sequence and metadata as typical FASTA format records, but overcomes common problems such as unstructured metadata in the header and erroneous sequence content. XML provides validation to prevent data integrity problems that are frequent in FASTA files. The range of applications for SeqXML is broad and not limited to ortholog prediction. We provide read/write functions for BioJava, BioPerl, and Biopython. OrthoXML was designed to represent ortholog assignments from any source in a consistent and structured way, yet cater to specific needs such as scoring schemes or meta-information. A unified format is particularly valuable for ortholog consumers that want to integrate data from numerous resources, e.g. for gene annotation projects. Reference proteomes for 61 organisms are already available in SeqXML, and 10 orthology databases have signed on to OrthoXML. Adoption by the entire field would substantially facilitate exchange and quality control of sequence and orthology information.	biojava;bioperl;biopython;data integrity;diff utility;fasta format;gene annotation;header of a document;homology (biology);orthologous gene;parsing;published database;read-write memory;score;signature;xml;standards characteristics	Thomas Schmitt;David N. Messina;Fabian Schreiber;Erik L. L. Sonnhammer	2011	Briefings in bioinformatics	10.1093/bib/bbr025	biology;natural science;computer science;bioinformatics;data mining;world wide web	DB	-3.166307169855727	-61.62158252169321	130228
3dc5ad13cb3a8140a2950bde081a5e22360ef304	text and data mining techniques in adverse drug reaction detection	drug side effect;drug safety;text mining;signal detection;data mining;statistical analysis;adverse drug reaction	We review data mining and related computer science techniques that have been studied in the area of drug safety to identify signals of adverse drug reactions from different data sources, such as spontaneous reporting databases, electronic health records, and medical literature. Development of such techniques has become more crucial for public heath, especially with the growth of data repositories that include either reports of adverse drug reactions, which require fast processing for discovering signals of adverse reactions, or data sources that may contain such signals but require data or text mining techniques to discover them. In order to highlight the importance of contributions made by computer scientists in this area so far, we categorize and review the existing approaches, and most importantly, we identify areas where more research should be undertaken.	categorization;computer science;computer scientist;data mining;database;spontaneous order;text mining	Sarvnaz Karimi;Chen Wang;Alejandro Metke-Jimenez;Raj Gaire;Cécile Paris	2015	ACM Comput. Surv.	10.1145/2719920	text mining;computer science;data science;data mining;pharmacovigilance;information retrieval;detection theory	ML	-2.887172492683802	-65.79596755340192	130555
1f6350631d09b355f5beea8c034a393306a5ff35	gif-db, a www database on gene interactions involved in drosophila melanogaster development	embl;animals;embryonics;computer communication networks;pattern formation;drosophila melanogaster;databases factual;gene regulatory network;molecular interactions;body patterning	GIF-DB (Gene Interactions in the Fly Database) is a new WWW database (http://www-biol.univ-mrs.fr/ approximately lgpd/GIFTS_home_page. html ) describing gene molecular interactions involved in the process of embryonic pattern formation in the flyDrosophila melanogaster. The detailed information is distributed in specific lines arranged into an EMBL- (or SWISS-PROT-) like format. GIF-DB achieves a high level of integration with other databases such as FlyBase, EMBL and SWISS-PROT through numerous hyperlinks. The original concept of interaction databases examplified by GIF-DB could be extended to other biological subjects and organisms so as to study gene regulatory networks in an evolutionary perspective.	gif;gene regulatory network;html;high-level programming language;hyperlink;interaction;pattern formation;published database;swiss-model;switzerland;www;if protein, drosophila	Bernard Jacq;Florence Horn;Florence Janody;Nicolas Gompel;Olivier Serralbo;Elodie Mohr;Christine Leroy;Bernard Bellon;Laurent Fasano;Patrick Laurenti;Laurence Röder	1997	Nucleic acids research	10.1093/nar/25.1.67	biology;gene regulatory network;bioinformatics;pattern formation;genetics	DB	-1.7008265750976121	-61.49902319566426	130882
8189e9c402a1773b76d1630ce64d785f27ea33e2	a factor analysis approach to transcription regulatory network reconstruction using gene expression data			factor analysis;transcription (software)	Wei Chen	2013			bioinformatics;data mining;genetics	Comp.	1.1838873854601923	-63.70823155861935	131726
cea3af8575dbff36ca29c6ef7da03c9ca67c0cd1	cancer odor database (cod): a critical databank for cancer diagnosis research		Database URL http://bioinf.modares.ac.ir/software/cod/.	databases;uniform resource locator	Sajjad Janfaza;Maryam Banan Nojavani;Babak Khorsand;Maryam Nikkhah;Javad Zahiri	2017		10.1093/database/bax055	cancer;data mining;odor;computer science	DB	0.3906778825178126	-63.27090212529945	131889
7a3dc752b36714b603179f849a6113a4880bc2d8	hindel, b. et al.basiswissen software-projektmanagement		Virginiamycin M1 having the Formula: and virginiamycin M1 analogs having the Formulae I-IV: (I) (II) (III) (IV) Virginiamycin M1 and the analogs I-IV are antagonists of cholecystokinin (CCK) and gastrin. Cholecystokinin antagonists are useful as analgesics and in the treatment and prevention of disorders of the gastrointestinal, central nervous and appetite regulatory systems in animals, especially humans. Gastrin antagonists are useful in blocking the receptors for gastrin in humans and may function as agents for the treatment of ulcers, tumors or other gastrointestinal disorders. The compounds of Formulae I-IV are also antibiotics and are useful as antimicrobial agents in animals including man and are useful as food additives to promote feed utilization in animals. Virginiamycin M1 and the analogs of Formula I, III and IV are produced by the controlled aerobic fermentation of a strain of Streptomyces olivaceus, ATCC No. 53527, while the analog of Formula II is produced by chemical synthesis.		Herrad Schmidt	2007	Wirtschaftsinformatik	10.1007/s11576-007-0020-y	appetite;data mining;chemical synthesis;antimicrobial;gastrin;pharmacology;computer science;cholecystokinin;virginiamycin;receptor;antibiotics	Robotics	2.658496458022281	-65.25524132016749	132103
a528837bac8c92f8e520fc458f09702f8df7e613	chemex: information extraction system for chemical data curation	software;information systems;data mining;computational biology bioinformatics;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics;small molecule libraries	Manual chemical data curation from publications is error-prone, time consuming, and hard to maintain up-to-date data sets. Automatic information extraction can be used as a tool to reduce these problems. Since chemical structures usually described in images, information extraction needs to combine structure image recognition and text mining together. We have developed ChemEx, a chemical information extraction system. ChemEx processes both text and images in publications. Text annotator is able to extract compound, organism, and assay entities from text content while structure image recognition enables translation of chemical raster images to machine readable format. A user can view annotated text along with summarized information of compounds, organism that produces those compounds, and assay tests. ChemEx facilitates and speeds up chemical data curation by extracting compounds, organisms, and assays from a large collection of publications. The software and corpus can be downloaded from http://www.biotec.or.th/isl/ChemEx .	body of uterus;cheminformatics;cognitive dimensions of notations;computer vision;data curation;digital curation;entity;human-readable medium;information extraction;raster graphics;text corpus;text mining	Atima Tharatipyakul;Somrak Numnark;Duangdao Wichadakul;Supawadee Ingsriswang	2012		10.1186/1471-2105-13-S17-S9	biology;dna microarray;computer science;bioinformatics;data science;information retrieval;information system	NLP	-2.846482985551152	-63.37297599262469	133151
1b7b2af74c043f564bd08d110a1769e11f6a5fc0	toppgene suite for gene list enrichment analysis and candidate gene prioritization	genes;software;animals;functional annotation;protein protein interaction network;mice;disease;random sampling;meta analysis;network analysis;internet;proteins;humans;candidate disease gene;protein interaction mapping;similarity measure;candidate gene	ToppGene Suite (http://toppgene.cchmc.org; this web site is free and open to all users and does not require a login to access) is a one-stop portal for (i) gene list functional enrichment, (ii) candidate gene prioritization using either functional annotations or network analysis and (iii) identification and prioritization of novel disease candidate genes in the interactome. Functional annotation-based disease candidate gene prioritization uses a fuzzy-based similarity measure to compute the similarity between any two genes based on semantic annotations. The similarity scores from individual features are combined into an overall score using statistical meta-analysis. A P-value of each annotation of a test gene is derived by random sampling of the whole genome. The protein-protein interaction network (PPIN)-based disease candidate gene prioritization uses social and Web networks analysis algorithms (extended versions of the PageRank and HITS algorithms, and the K-Step Markov method). We demonstrate the utility of ToppGene Suite using 20 recently reported GWAS-based gene-disease associations (including novel disease genes) representing five diseases. ToppGene ranked 19 of 20 (95%) candidate genes within the top 20%, while ToppNet ranked 12 of 16 (75%) candidate genes among the top 20%.	access network;algorithm;annotation;candidate disease gene;cardiac catheterization suite;complement system proteins;computation;experiment;gastrointestinal system;gene ontology term enrichment;genome-wide association study;high-throughput computing;informatics;interaction network;interactome;large;linkage (software);login;manuscripts;markov chain;mental association;microarray;monte carlo method;national institute of diabetes and digestive and kidney diseases (u.s.);pagerank;pallister-hall syndrome;personal handy-phone system;sampling (signal processing);sampling - surgical action;similarity measure;social network analysis;subgroup;throughput;version;web site;genetic linkage	Jing Chen;Eric E. Bardes;Bruce J. Aronow;Anil G. Jegga	2009		10.1093/nar/gkp427	biology;sampling;the internet;meta-analysis;network analysis;bioinformatics;gene;candidate gene;genetics	Comp.	-0.5672769025269724	-62.4197111623728	133395
aca83ac747fc549fc625820b5e4d10c975cab05f	picking cluster parts: cluster construction at the genome sequence centre				Martin Krzywinski	2001	;login:			ML	1.0192347973953744	-64.26247596561443	133502
b7563959dfffc750e58ec6d79ec73d764ab66e7f	methodology for computer-assisted prediction of growth hormone deficiency in children	biomedical research;bioinformatics		angular defect	Christine L. Tsien;Daniel J. Nigrin;Isaac S. Kohane	1998			data science;growth hormone deficiency;computer science;text mining	NLP	2.1726056474413857	-65.76623869445483	133541
53faa9b04eb426dd719b3c7af5f2daf98b076e45	computer aided hypotheses based drug discovery using catalystrtm and pc guha software systems		CATALYST [1] and PC-GUHA [2], [3] software systems have been used in computer aided hypotheses based drug discovery. They are based on quite different principles. CATALYST represents molecular simulation approach based on search for common structure parts of drug molecules responsible for the therapeutic activity (pharmacophores). CATALYST is distributed by Molecular Simulation, Inc . GUHA is acronym of General Unary Hypotheses Automaton. GUHA is academic software distributed by the Institute of Computer Science of the Academy of Sciences of Czech Republic where it is being developed since 1960’s. GUHA differs from various statistical packages enabling to test hypotheses that one has formulated, by its explorative character; it automatically generates hypotheses from empirical data by means of computer procedures. This is the first case when pharmacophoric hypotheses were generated by PC GUHA method on the basis of structure-activity data. The structures of 37 antimelanoma catechol analogs were encoded by unique ”fingerprint” descriptors in the same manner as fingerprints are encoded in dactyloscopy. This is the first successful use of fingerprint descriptors for pharmacophoric hypotheses generation. It was enabled by use of PC GUHA in Quantitative Structure-Activity Relationships. The compounds were classified into five classes according to their therapeutic activity. Quantitative Structure-Activity Relationships (QSAR) have been	academy;automaton;computer science;fingerprint;list of statistical packages;molecular dynamics;pharmacophore;quantitative structure–activity relationship;simulation;software system;unary operation	Jaroslava Halova;Oldrich Strouf;Premysl Zak;Anna Sochorova;Noritaka Uchida;Hiroshi Okimoto;Tomoaki Yuzuri;Kazuhisa Sakakibara;Minoru Hirota	1998		10.1007/3-540-49292-5_64	computer science;bioinformatics;data science	Graphics	-0.6860370510054948	-64.36909173130105	133691
205d5151172384cdea7c5611e06244d7010ab566	bio-ontology and text: bridging the modeling gap	vocabulary controlled;phylogeny;database management systems;knowledge management;databases genetic;periodicals as topic;information organization;genetics;confidence interval;models genetic;system biology;abstracting and indexing as topic;artificial intelligence;data structure;information storage and retrieval;natural language processing	MOTIVATION Natural language processing (NLP) techniques are increasingly being used in biology to automate the capture of new biological discoveries in text, which are being reported at a rapid rate. Yet, information represented in NLP data structures is classically very different from information organized with ontologies as found in model organisms or genetic databases. To facilitate the computational reuse and integration of information buried in unstructured text with that of genetic databases, we propose and evaluate a translational schema that represents a comprehensive set of phenotypic and genetic entities, as well as their closely related biomedical entities and relations as expressed in natural language. In addition, the schema connects different scales of biological information, and provides mappings from the textual information to existing ontologies, which are essential in biology for integration, organization, dissemination and knowledge management of heterogeneous phenotypic information. A common comprehensive representation for otherwise heterogeneous phenotypic and genetic datasets, such as the one proposed, is critical for advancing systems biology because it enables acquisition and reuse of unprecedented volumes of diverse types of knowledge and information from text.   RESULTS A novel representational schema, PGschema, was developed that enables translation of phenotypic, genetic and their closely related information found in textual narratives to a well-defined data structure comprising phenotypic and genetic concepts from established ontologies along with modifiers and relationships. Evaluation for coverage of a selected set of entities showed that 90% of the information could be represented (95% confidence interval: 86-93%; n = 268). Moreover, PGschema can be expressed automatically in an XML format using natural language techniques to process the text. To our knowledge, we are providing the first evaluation of a translational schema for NLP that contains declarative knowledge about genes and their associated biomedical data (e.g. phenotypes).   AVAILABILITY http://zellig.cpmc.columbia.edu/PGschema	bridging (networking);commonsense knowledge (artificial intelligence);computable function;computation;computational semantics;confidence intervals;data structure;database;databases;databases, genetic;declarative programming;entity;genetic heterogeneity;genetic phenomena;genetic translation process;genetic algorithm;genotype;information model;information schema;journal;knowledge management;knowledge representation and reasoning;linguistics;natural language processing;ontology (information science);organizing (structure);phenotype;programming paradigm;published database;representation (action);reuse (action);semantic web;systems biology;xml;funding grant;research grants	Carol Friedman;Tara B Borlawsky;Lyudmila Shagina;H. Rosie Xing;Yves A. Lussier	2006	Bioinformatics	10.1093/bioinformatics/btl405	natural language processing;confidence interval;data structure;computer science;bioinformatics;data mining;genetics;information retrieval	Web+IR	-4.521372961184887	-63.50483041716338	134685
cca60a36fc1fd941770b912e007e91fd1570c13d	web–enabled classification of snps for genome–wide association studies	databases;biology computing;genomics;program genenab web enabled classification genome association studies genetic underpinnings complex phenotypes human diseases polymorphic sites human genome single nucleotide polymorphism;complex phenotypes;human disease;dbsnp;genome wide association study;database;xml database;genetic underpinnings;polymorphic sites;classification;genetics;genetic variation;association study;kegg;genome association studies;internet biology computing classification diseases genetics;human diseases;internet;proteins;gwas;web enabled classification;human genome;polymorphism;clinical study;xml;diseases;xml genetic variation polymorphism gwas snp internet database kegg dbsnp;humans;genomics bioinformatics humans databases computer science biomedical engineering genetic engineering computer networks cardiac disease biology computing;program genenab;single nucleotide polymorphism;bioinformatics;snp	Whole genome association studies of the genetic underpinnings of complex phenotypes, and human diseases in particular, have been steadily gaining momentum over the past several years. Yet, the number of polymorphic sites in the human genome, including, but not limited to, single nucleotide polymorphisms (SNPs) is so large that identifying the combination of these few that have a significant effect on the condition of interest remains an overwhelming task. In this manuscript we present a new networked solution, and a program GeneNAB implementing it, to the computational identification and ranking of SNPs likely to be relevant for the phenotype of interest, genome-wide. We expect that the output of this program will be useful to guide further laboratory and clinical studies of these SNPs.	expect	Abhijit R. Tendulkar;Nikola Stojanovic;Robert Barber	2008	2008 International Conference on Information Technology	10.1109/ICIT.2008.65	genome-wide association study;genomics;computer science;bioinformatics	Comp.	-0.9755617828395596	-61.49173503047307	134846
378da1f50ceab33ed6da42e381196ff75a60d22b	aniseed 2015: a digital framework for the comparative developmental biology of ascidians	genes;urochordata;information systems;stem cells;embryologic development;gene annotation;vertebrates;schema;gene expression;genome;embryo;developmental biology;ciona intestinalis;basic local alignment search tool	Ascidians belong to the tunicates, the sister group of vertebrates and are recognized model organisms in the field of embryonic development, regeneration and stem cells. ANISEED is the main information system in the field of ascidian developmental biology. This article reports the development of the system since its initial publication in 2010. Over the past five years, we refactored the system from an initial custom schema to an extended version of the Chado schema and redesigned all user and back end interfaces. This new architecture was used to improve and enrich the description of Ciona intestinalis embryonic development, based on an improved genome assembly and gene model set, refined functional gene annotation, and anatomical ontologies, and a new collection of full ORF cDNAs. The genomes of nine ascidian species have been sequenced since the release of the C. intestinalis genome. In ANISEED 2015, all nine new ascidian species can be explored via dedicated genome browsers, and searched by Blast. In addition, ANISEED provides full functional gene annotation, anatomical ontologies and some gene expression data for the six species with highest quality genomes. ANISEED is publicly available at: http://www.aniseed.cnrs.fr.	anise;blast;ciona;code refactoring;ecthyma, contagious;embryonic development;gasterophilus intestinalis ab.ige:acnc:pt:ser:qn;gene annotation;gene expression;genome assembly sequence;information system;language development disorders;natural regeneration;ontology (information science);open reading frame;search - action;sister group;stem cells;urochordata;vertebrates	Matija Brozovic;Cyril Martin;Christelle Dantec;Delphine Dauga;Mickaël Mendez;Paul Simion;Madeline Percher;Baptiste Laporte;Céline Scornavacca;Anna Di Gregorio;Shigeki Fujiwara;Mathieu Gineste;Elijah K. Lowe;Jacques Piette;Claudia Racioppi;Filomena Ristoratore;Yasunori Sasakura;Naohito Takatori	2016		10.1093/nar/gkv966	biology;embryo;gene expression;bioinformatics;gene;schema;developmental biology;genetics;information system;anatomy;genome	Comp.	-1.0519932801986693	-61.74489287648618	135473
10330528ba3ea44662f1f7b668a5b38774ae595e	3pfdb+: improved search protocol and update for the identification of representatives of protein sequence domain families	software;animals;search engine;amino acid sequence;protein structure tertiary;humans;molecular sequence data;multigene family;databases protein	Protein domain families are usually classified on the basis of similarity of amino acid sequences. Selection of a single representative sequence for each family provides targets for structure determination or modeling and also enables fast sequence searches to associate new members to a family. Such a selection could be challenging since some of these domain families exhibit huge variation depending on the number of members in the family, the average family sequence length or the extent of sequence divergence within a family. We had earlier created 3PFDB database as a repository of best representative sequences, selected from each PFAM domain family on the basis of high coverage. In this study, we have improved the database using more efficient strategies for the initial generation of sequence profiles and implement two independent methods, FASSM and HMMER, for identifying family members. HMMER employs a global sequence similarity search, while FASSM relies on motif identification and matching. This improved and updated database, 3PFDB+ generated in this study, provides representative sequences and profiles for PFAM families, with 13 519 family representatives having more than 90% family coverage. The representative sequence is also highlighted in a two-dimensional plot, which reflects the relative divergence between family members. Representatives belonging to small families with short sequences are mainly associated with low coverage. The set of sequences not recognized by the family representative profiles, highlight several potential false or weak family associations in PFAM. Partial domains and fragments dominate such cases, along with sequences that are highly diverged or different from other family members. Some of these outliers were also predicted to have different secondary structure contents, which reflect different putative structure or functional roles for these domain sequences. Database URL: http://caps.ncbs.res.in/3pfdbplus/.	access network;amino acid sequence;amino acids;annotation;basal ganglia diseases;brooke-spiegler syndrome;classification;coverage level - family;emoticon;entity name part qualifier - adopted;erbb receptors;fo (complexity);folic acid;fragment (computer graphics);gnly wt allele;genetic selection;hmmer;homologous gene;homology (biology);immunoglobulins;lithium;matching;mental association;motif;pfam;pierre robin syndrome;plot (graphics);position weight matrix;protein domain;protein family;representative sequences;ss a antibodies;schilbach-rott syndrome;sequence homology;sequence alignment;similarity search;status epilepticus;tellurium;time complexity;trial elements domain;uniform resource locator;contents - htmllinktype;g/h;selenomethylselenocysteine	Agnel Praveen Joseph;Prashant Shingate;Atul K. Upadhyay;Ramanathan Sowdhamini	2014		10.1093/database/bau026	biology;computer science;bioinformatics;sequence analysis;peptide sequence;sequence logo;world wide web;genetics;search engine	Comp.	1.9838613677242953	-59.25962414595103	135530
3c9aa1867a6607ebd5dbd4dfa62a4deafd347bc6	pandit: an evolution-centric database of protein and associated nucleotide domains with inferred trees	evolution molecular;phylogeny;databases nucleic acid;nucleotides;protein sequence;protein domains;amino acid sequence;web interface;sequence analysis dna;genetics;internet;protein structure tertiary;phylogenetic tree;sequence homology nucleic acid;sequence homology amino acid;sequence alignment;user computer interface;multiple alignment;databases protein	PANDIT is a database of homologous sequence alignments accompanied by estimates of their corresponding phylogenetic trees. It provides a valuable resource to those studying phylogenetic methodology and the evolution of coding-DNA and protein sequences. Currently in version 17.0, PANDIT comprises 7738 families of homologous protein domains; for each family, DNA and corresponding amino acid sequence multiple alignments are available together with high quality phylogenetic tree estimates. Recent improvements include expanded methods for phylogenetic tree inference, assessment of alignment quality and a redesigned web interface, available at the URL http://www.ebi.ac.uk/goldman-srv/pandit.	amino acid sequence;amino acids;display resolution;estimated;inference;interface device component;phylogenetic tree;phylogenetics;protein domain;sequence alignment;trees (plant);uniform resource locator;user interface	Simon Whelan;Paul I. W. de Bakker;Emmanuel Quevillon;Nicolas Rodriguez;Nick Goldman	2006	Nucleic Acids Research	10.1093/nar/gkj087	biology;molecular biology;nucleotide;phylogenetic tree;the internet;multiple sequence alignment;bioinformatics;protein sequencing;sequence alignment;peptide sequence;protein domain;phylogenetic network;user interface;genetics;phylogenetics	Comp.	-1.1851903800209693	-59.45495536118609	136078
82df2a85a6c97eee81034f5f073c48d58957f474	case study: using sequence homology to identify putative phosphorylation sites in an evolutionarily distant species (honeybee)	apis mellifera;biological databases;homology;honeybee;phosphorylation;protein kinases	The majority of scientific resources are devoted to studying a relatively small number of model species, meaning that the ability to translate knowledge across species is of considerable importance. Obtaining species-specific knowledge enables targeted investigations of the biology and pathobiology of a particular species, and facilitates comparative analyses. Phosphorylation is the most widespread posttranslational modification in eukaryotes, and although many phosphorylation sites have been experimentally identified for some species, little or no data are available for others. Using the honeybee as a test organism, this case study illustrates the process of using protein sequence homology to identify putative phosphorylation sites in a species of interest using experimentally determined sites from other species. A number of issues associated with this process are examined and discussed. Several databases of experimentally determined phosphorylation sites exist; however, it can be difficult for the nonspecialist to ascertain how their contents compare. Thus, this case study assesses the content and comparability of several phosphorylation site databases. Additional issues examined include the efficacy of homology-based phosphorylation site prediction, the impact of the level of evolutionary relatedness between species in making these predictions, the ability to translate knowledge of phosphorylation sites across large evolutionary distances and the criteria that should be used in selecting probable phosphorylation sites in the species of interest. Although focusing on phosphorylation, the issues discussed here also apply to the homology-based cross-species prediction of other posttranslational modifications, as well as to sequence motifs in general.	amino acid sequence;apis mellifera;database;experiment;homologous gene;phosphorylation site;post-translational protein processing;probability;sequence homology, amino acid;sequence homology;sequence motif;contents - htmllinktype	Brett Trost;Scott Napper;Anthony J. Kusalik	2015	Briefings in bioinformatics	10.1093/bib/bbu040	biology;bioinformatics;genetics	Comp.	2.6462335507717016	-59.13136837647957	136101
24570d47cbcb06b142d6d9172be93abcf5a1e07e	accurate reconstruction of single individual haplotypes for personalized medicine	personalized medicine			Filippo Geraci;Marco O O Pellegrini	2010	ERCIM News		data mining;personalized medicine;haplotype;computer science;bioinformatics	Vision	1.118411035431521	-64.09934588542451	136148
1ef366e034d08317e9305bb390aed643459baba4	the digital ageing atlas: integrating the diversity of age-related changes into a unified resource	aging;internet;humans;databases factual	Multiple studies characterizing the human ageing phenotype have been conducted for decades. However, there is no centralized resource in which data on multiple age-related changes are collated. Currently, researchers must consult several sources, including primary publications, in order to obtain age-related data at various levels. To address this and facilitate integrative, system-level studies of ageing we developed the Digital Ageing Atlas (DAA). The DAA is a one-stop collection of human age-related data covering different biological levels (molecular, cellular, physiological, psychological and pathological) that is freely available online (http://ageing-map.org/). Each of the >3000 age-related changes is associated with a specific tissue and has its own page displaying a variety of information, including at least one reference. Age-related changes can also be linked to each other in hierarchical trees to represent different types of relationships. In addition, we developed an intuitive and user-friendly interface that allows searching, browsing and retrieving information in an integrated and interactive fashion. Overall, the DAA offers a new approach to systemizing ageing resources, providing a manually-curated and readily accessible source of age-related changes.	aging;ana (programming language);biological science disciplines;centralized computing;community-acquired infections;curie;gene duplication abnormality;hypertext transfer protocol;interface device component;rats, inbred bb;trees (plant);usability;web resource;benefit;kaufman syndrome	Thomas Craig;Chris Smelick;Robi Tacutu;Daniel Wuttke;Shona H. Wood;Henry Stanley;Georges Janssens;Ekaterina Savitskaya;Alexey Moskalev;Robert Arking;João Pedro de Magalhães	2015		10.1093/nar/gku843	the internet;bioinformatics	Graphics	-1.2803255590326108	-61.66837126263647	136808
bd0db4396a603dd05bcff98f8076f4f30e645f00	computer-assisted curation of a human regulatory core network from the biological literature		MOTIVATION A highly interlinked network of transcription factors (TFs) orchestrates the context-dependent expression of human genes. ChIP-chip experiments that interrogate the binding of particular TFs to genomic regions are used to reconstruct gene regulatory networks at genome-scale, but are plagued by high false-positive rates. Meanwhile, a large body of knowledge on high-quality regulatory interactions remains largely unexplored, as it is available only in natural language descriptions scattered over millions of scientific publications. Such data are hard to extract and regulatory data currently contain together only 503 regulatory relations between human TFs.   RESULTS We developed a text-mining-assisted workflow to systematically extract knowledge about regulatory interactions between human TFs from the biological literature. We applied this workflow to the entire Medline, which helped us to identify more than 45 000 sentences potentially describing such relationships. We ranked these sentences by a machine-learning approach. The top-2500 sentences contained ∼900 sentences that encompass relations already known in databases. By manually curating the remaining 1625 top-ranking sentences, we obtained more than 300 validated regulatory relationships that were not present in a regulatory database before. Full-text curation allowed us to obtain detailed information on the strength of experimental evidences supporting a relationship.   CONCLUSIONS We were able to increase curated information about the human core transcriptional network by >60% compared with the current content of regulatory databases. We observed improved performance when using the network for disease gene prioritization compared with the state-of-the-art.   AVAILABILITY AND IMPLEMENTATION Web-service is freely accessible at http://fastforward.sys-bio.net/.   CONTACT leser@informatik.hu-berlin.de or nils.bluethgen@charite.de   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	aquaporin 1;bioinformatics;chip-on-chip;contain (action);context-sensitive language;description;digital curation;ephrin type-b receptor 1, human;experiment;gene regulatory networks;gene regulatory network;interaction;list of code lyoko episodes;medline;machine learning;natural language;published database;scientific publication;transcription factor;text mining;transcription (software);transcription, genetic;web service;sentence	Philippe Thomas;Pawel Durek;Illés Solt;Bertram Klinger;Franziska Witzel;Pascal Schulthess;Yvonne Mayer;Domonkos Tikk;Nils Blüthgen;Ulf Leser	2015	Bioinformatics	10.1093/bioinformatics/btu795	computer science;bioinformatics;data science;data mining	Comp.	-1.684357167518831	-63.3959062214156	136824
54caf87b449c91bb3497d72d7f2c13c608952cc7	integration of open access literature into the rcsb protein data bank using biolit	software;web service;computational biology bioinformatics;proteins;open access;algorithms;biological data;user computer interface;combinatorial libraries;biological database;computer appl in life sciences;systems integration;pubmed;protein data bank;databases protein;microarrays;bioinformatics	Biological data have traditionally been stored and made publicly available through a variety of on-line databases, whereas biological knowledge has traditionally been found in the printed literature. With journals now on-line and providing an increasing amount of open access content, often free of copyright restriction, this distinction between database and literature is blurring. To exploit this opportunity we present the integration of open access literature with the RCSB Protein Data Bank (PDB). BioLit provides an enhanced view of articles with markup of semantic data and links to biological databases, based on the content of the article. For example, words matching to existing biological ontologies are highlighted and database identifiers are linked to their database of origin. Among other functions, it identifies PDB IDs that are mentioned in the open access literature, by parsing the full text for all research articles in PubMed Central (PMC) and exposing the results as simple XML Web Services. Here, we integrate BioLit results with the RCSB PDB website by using these services to find PDB IDs that are mentioned in research articles and subsequently retrieving abstract, figures, and text excerpts for those articles. A new RCSB PDB literature view permits browsing through the figures and abstracts of the articles that mention a given structure. The BioLit Web Services that are providing the underlying data are publicly accessible. A client library is provided that supports querying these services (Java). The integration between literature and websites, as demonstrated here with the RCSB PDB, provides a broader view for how a given structure has been analyzed and used. This approach detects the mention of a PDB structure even if it is not formally cited in the paper. Other structures related through the same literature references can also be identified, possibly providing new scientific insight. To our knowledge this is the first time that database and literature have been integrated in this way and it speaks to the opportunities afforded by open and free access to both database and literature content.	abstract summary;biological database;blurred vision;dna integration;excerpts;html link type - copyright;identifier;java programming language;journal;license;markup language;online and offline;ontology (information science);parsing;printing;protein data bank;pubmed central;published database;simple xml;web site;web service	Andreas Prlić;Marco A. Martinez;Dimitris Dimitropoulos;Bojan Beran;Benjamin T. Yukich;Philip E. Bourne;J. Lynn Fink	2009		10.1186/1471-2105-11-220	web service;biology;dna microarray;biological database;protein data bank;biological data;computer science;bioinformatics;data mining;world wide web;system integration	Web+IR	-2.3062134137416774	-61.45043998158943	137097
f15fba4e1edcb6d86616db6ca69e5bcaf3706577	seed-based intarna prediction combined with gfp-reporter system identifies mrna targets of the small rna yfr1	semilla;prediccion;rna mensajero;rna messenger;semence;mutation analysis;seeds;green fluorescent protein;green fluorescent proteins;binding sites;sistema combinado;genome size;rna messager;target;rna bacterial;prochlorococcus;combined system;identification;genome bacterial;messenger rna;gene targeting;blanco;cible;semillas;identificacion;seed;molecular sequence data;ribosome binding site;graine;sequence motif;sequence analysis rna;base sequence;small rna;prediction;systeme combine	MOTIVATION Prochlorococcus possesses the smallest genome of all sequenced photoautotrophs. Although the number of regulatory proteins in the genome is very small, the relative number of small regulatory RNAs is comparable with that of other bacteria. The compact genome size of Prochlorococcus offers an ideal system to search for targets of small RNAs (sRNAs) and to refine existing target prediction algorithms.   RESULTS Target predictions for the cyanobacterial sRNA Yfr1 were carried out with INTARNA in Prochlorococcus MED4. The ultraconserved Yfr1 sequence motif was defined as the putative interaction seed. To study the impact of Yfr1 on its predicted mRNA targets, a reporter system based on green fluorescent protein (GFP) was applied. We show that Yfr1 inhibits the translation of two predicted targets. We used mutation analysis to confirm that Yfr1 directly regulates its targets by an antisense interaction sequestering the ribosome binding site, and to assess the importance of interaction site accessibility.	accessibility;bacteria;gfp-cdna;genome size;green fluorescent proteins;least fixed point;mutation testing;prochlorococcus;rna;ribosomes;seed;sequence motif;algorithm;antisense therapy	Andreas S. Richter;Christian Schleberger;Rolf Backofen;Claudia Steglich	2010		10.1093/bioinformatics/btp609	identification;biology;molecular biology;ribosomal binding site;green fluorescent protein;prediction;bioinformatics;binding site;gene targeting;genome size;mutation testing;genetics;messenger rna;sequence motif	Comp.	2.600900729383395	-60.06986144048738	137417
fea291ffbf0e61a65f3a4010ae3781a0e73ee561	loftool: a gene intolerance score based on loss-of-function variants in 60 706 individuals	medicinsk genetik	Motivation Depletion of loss-of-function (LoF) mutations may provide a rank of genic functional intolerance and consequently susceptibility to disease.   Results Here we have studied LoF mutations in 60 706 unrelated individuals and show that the most intolerant quartile of ranked genes is enriched in rare and early onset diseases and explains 87% of de novo haploinsufficient OMIM mutations, 17% more than any other gene scoring tool. We detected particular enrichment in expression of the depleted LoF genes in brain (odds ratio = 1.5; P -value = 4.2e-07). By searching for de novo haploinsufficient mutations putatively associated with neurodevelopmental disorders in four recent studies, we were able to explain 81% of them. Taken together, this study provides a novel gene intolerance ranking system, called LoFtool, which may help in ranking genes of interest based on their LoF intolerance and tissue expression.   Availability and implementation The LoFtool gene scores are available in the Supplementary data .   Contact joaofadista@gmail.com.   Supplementary information Supplementary data are available at Bioinformatics online.	bioinformatics;de novo transcriptome assembly;depletion region;gene ontology term enrichment;genes, vif;geographic information systems;mutation;neurodevelopmental disorders;online mendelian inheritance in man;onset (audio);score	João Fadista;Nikolay Oskolkov;Ola Hansson;Leif Groop	2017	Bioinformatics	10.1093/bioinformatics/btv602	biology;bioinformatics;genetics	Comp.	2.71184311909797	-61.0152944419229	137750
2c8c736b50971e68c1216e99e6fe7edab1800471	interoperability between phenotype and anatomy ontologies	fenotipo;ontologie;dk atira pure researchoutput researchoutputtypes contributiontojournal article;vocabulary controlled;interoperabilite;interoperabilidad;disease;semantics;anatomia;ontologia;humans;interoperability;molecular mechanics;anatomie;phenotype;ontology;anatomy	MOTIVATION Phenotypic information is important for the analysis of the molecular mechanisms underlying disease. A formal ontological representation of phenotypic information can help to identify, interpret and infer phenotypic traits based on experimental findings. The methods that are currently used to represent data and information about phenotypes fail to make the semantics of the phenotypic trait explicit and do not interoperate with ontologies of anatomy and other domains. Therefore, valuable resources for the analysis of phenotype studies remain unconnected and inaccessible to automated analysis and reasoning.   RESULTS We provide a framework to formalize phenotypic descriptions and make their semantics explicit. Based on this formalization, we provide the means to integrate phenotypic descriptions with ontologies of other domains, in particular anatomy and physiology. We demonstrate how our framework leads to the capability to represent disease phenotypes, perform powerful queries that were not possible before and infer additional knowledge.   AVAILABILITY http://bioonto.de/pmwiki.php/Main/PheneOntology.	anatomic structures;bio-informatics;bioinformatics;description;entity;functional programming;functional testing;genetic translation process;inference;interoperability;knowledge-based systems;license;molecular biology;nico habermann;observable;ontology (information science);part dosing unit;participatory monitoring;phenes;phenotype;physical object;question (inquiry);reasoning;trait;physiological aspects	Robert Hoehndorf;Anika Oellrich;Dietrich Rebholz-Schuhmann	2010		10.1093/bioinformatics/btq578	biology;interoperability;molecular mechanics;computer science;bioinformatics;phenotype;ontology;data mining;semantics;genetics	AI	-4.381431727451187	-63.826418495707514	137799
eae2969e3dd8e3c777c69cf1d8c6fcb50f6f4bc8	comsin: database of protein structures in bound (complex) and unbound (single) states in relation to their intrinsic disorder	software;animals;databases genetic;molecular conformation;protein structure;models molecular;internet;protein conformation;protein structure tertiary;protein binding;humans;computational biology;information storage and retrieval;bacterial proteins;databases protein	Most of the proteins in a cell assemble into complexes to carry out their function. In this work, we have created a new database (named ComSin) of protein structures in bound (complex) and unbound (single) states to provide a researcher with exhaustive information on structures of the same or homologous proteins in bound and unbound states. From the complete Protein Data Bank (PDB), we selected 24 910 pairs of protein structures in bound and unbound states, and identified regions of intrinsic disorder. For 2448 pairs, the proteins in bound and unbound states are identical, while 7129 pairs have sequence identity 90% or larger. The developed server enables one to search for proteins in bound and unbound states with several options including sequence similarity between the corresponding proteins in bound and unbound states, and validation of interaction interfaces of protein complexes. Besides that, through our web server, one can obtain necessary information for studying disorder-to-order and order-to-disorder transitions upon complex formation, and analyze structural differences between proteins in bound and unbound states. The database is available at http://antares.protres.ru/comsin/.	access network;attention deficit hyperactivity disorder;automated planning and scheduling;bound state;epidemiologic research design;experiment;health services research;homology (biology);large;mood disorders;multiple personality disorder;name;protein data bank;science;sequence alignment;server (computing);staphylococcal protein a;united states national institutes of health;web server	Michail Yu. Lobanov;Benjamin A. Shoemaker;Sergiy O. Garbuzynskiy;Jessica H. Fong;Anna R. Panchenko;Oxana V. Galzitskaya	2010		10.1093/nar/gkp963	biology;protein structure;bioinformatics;genetics	Comp.	0.39159432720893406	-60.45772682113036	138222
a2f72717900df4360ab63010337a4461617b4819	grip: a web-based system for constructing gold standard datasets for protein-protein interaction prediction	biological patents;biomedical journals;protein function;protein complex;saccharomyces cerevisiae;text mining;computational techniques;europe pubmed central;drug targeting;citation search;gold standard;citation networks;genetics;computational biology bioinformatics;research articles;abstracts;interaction pattern;open access;life sciences;protein protein interaction;clinical guidelines;web based system;full text;computer appl in life sciences;rest apis;orcids;europe pmc;biomedical research;protein interaction network;bioinformatics;literature search	Information about protein interaction networks is fundamental to understanding protein function and cellular processes. Interaction patterns among proteins can suggest new drug targets and aid in the design of new therapeutic interventions. Efforts have been made to map interactions on a proteomic-wide scale using both experimental and computational techniques. Reference datasets that contain known interacting proteins (positive cases) and non-interacting proteins (negative cases) are essential to support computational prediction and validation of protein-protein interactions. Information on known interacting and non interacting proteins are usually stored within databases. Extraction of these data can be both complex and time consuming. Although, the automatic construction of reference datasets for classification is a useful resource for researchers no public resource currently exists to perform this task. GRIP (Gold Reference dataset constructor from Information on Protein complexes) is a web-based system that provides researchers with the functionality to create reference datasets for protein-protein interaction prediction in Saccharomyces cerevisiae. Both positive and negative cases for a reference dataset can be extracted, organised and downloaded by the user. GRIP also provides an upload facility whereby users can submit proteins to determine protein complex membership. A search facility is provided where a user can search for protein complex information in Saccharomyces cerevisiae. GRIP is developed to retrieve information on protein complex, cellular localisation, and physical and genetic interactions in Saccharomyces cerevisiae. Manual construction of reference datasets can be a time consuming process requiring programming knowledge. GRIP simplifies and speeds up this process by allowing users to automatically construct reference datasets. GRIP is free to access at http://rosalind.infj.ulst.ac.uk/GRIP/ .	drug delivery systems;extraction;influenza;pistol grip;proteomics;published database;reference implementation;silo (dataset);upload;web application;cellular localization;establishment and maintenance of localization;protein protein interaction	Fiona Browne;Haiying Wang;Huiru Zheng;Francisco Azuaje	2008	Source Code for Biology and Medicine	10.1186/1751-0473-4-2	protein–protein interaction;biology;text mining;targeted drug delivery;gold standard;computer science;bioinformatics;data science;data mining;multiprotein complex	Comp.	-0.4785167137079924	-60.91105770871356	138730
9e045e4ca9e6d9c08405848e4691d807c558048b	comparing mets and oai-ore for encapsulating scientific data products: a protein crystallography case study	x ray diffraction;x ray diffraction image archive;biology computing;protein crystallography;oai ore mets crystallography lims repositories;compounds;diffraction;distributed processing;scientific data;scientific workflow;mets;data capture;dimer mets oai ore scientific data product protein crystallography eresearch service secure web based laboratory information management x ray diffraction image archive timtam;web services biology computing crystallography distributed processing proteins;proteins;crystallography protein engineering laboratories genomics bioinformatics collaborative work information management x ray imaging x ray diffraction monitoring;structural genomics;structure determination;oai ore;web services;distributed databases;lims;crystal structure;scientific data product;high throughput;eresearch service;dimer;crystallography;repositories;laboratory information management system;protein data bank;secure web based laboratory information management;timtam	This paper describes the set of eResearch services developed by the eResearch Lab within the University of Queensland (UQ) for the Structural Genomics (SG) Group at UQ. The aim of these services is to enable collaborative teams of protein crystallographers in the SG group to track their experiments and to manage the plethora and diversity of data that they generate through distributed high-throughput approaches and complex scientific workflows. More specifically we describe: the secure Web-based laboratory information management system (TIMTAM) and the X-ray diffraction image archive (DIMER) used to monitor experiments and record data captured prior to structure determination and the publication of a new crystal structure in public repositories such as the Protein Data bank (PDB). We also describe the services that we have developed to relate the different products generated at each stage in the protein crystallography pipeline through OAI-ORE compound objects. We conclude by comparing the OAI-ORE approach for publishing and sharing related scientific outcomes with the METS-based approach employed by other scientific laboratories.	archive;crystal structure;experiment;high-throughput computing;information management system (ims);laboratory information management system;metadata encoding and transmission standard;protein data bank;suicidegirls;throughput	Charles Brooking;Stephen R. Shouldice;Gautier Robin;Bostjan Kobe;Jennifer L. Martin;Jane Hunter	2009	2009 Fifth IEEE International Conference on e-Science	10.1109/e-Science.2009.29	web service;high-throughput screening;structural genomics;protein data bank;computer science;bioinformatics;crystal structure;data science;database;automatic identification and data capture;diffraction;x-ray crystallography;data	Robotics	-3.068068930398501	-61.60979419939826	139594
c01eaa4221d59298bfd70d5ac36a929031be8d5c	a protein structure prediction service in the progengrid system		This paper describes a protein tertiary structure prediction service implemented in a Grid Environment. The service has been used for predicting the dicarboxylate carrier (DIC) of Saccharomyces cerevisiae by using the homology modelling approach. The visualization of the predicted model is made possible by using an interactive virtual reality environment based on X3D and Ajax3d technologies.	digital differential analyzer;homologous gene;homology (biology);homology modeling;imagery;protein structure prediction;staphylococcal protein a;virtual reality;x3d;dicarboxylate;dicarboxylate-binding protein;tertiary	Maria Mirto;Alessandra Ferramosca;Daniele Tartarini;Simone Romano;Alessandro Negro;Gianluca Tasco;Sandro Fiore;Vincenzo Zara;Rita Casadio;Giovanni Aloisio	2008	Studies in health technology and informatics		data mining;protein structure prediction;medicine	Visualization	0.3422540076320461	-62.729226590712386	139821
db4138f97889171b6e0fb54575fc052805b301de	ucbase 2.0: ultraconserved sequences database (2014 update)	software;animals;search engine;mice;rats;databases genetic;conserved sequence;humans;user computer interface;polymorphism single nucleotide	UCbase 2.0 (http://ucbase.unimore.it) is an update, extension and evolution of UCbase, a Web tool dedicated to the analysis of ultraconserved sequences (UCRs). UCRs are 481 sequences >200 bases sharing 100% identity among human, mouse and rat genomes. They are frequently located in genomic regions known to be involved in cancer or differentially expressed in human leukemias and carcinomas. UCbase 2.0 is a platform-independent Web resource that includes the updated version of the human genome annotation (hg19), information linking disorders to chromosomal coordinates based on the Systematized Nomenclature of Medicine classification, a query tool to search for Single Nucleotide Polymorphisms (SNPs) and a new text box to directly interrogate the database using a MySQL interface. To facilitate the interactive visual interpretation of UCR chromosomal positioning, UCbase 2.0 now includes a graph visualization interface directly linked to UCSC genome browser. Database URL: http://ucbase.unimore.it.	5' untranslated regions;annotation;base;carcinoma;genetic polymorphism;genome;graph drawing;information visualization;interface device component;mysql;rodent nomenclature name;single nucleotide polymorphism;single-chain antibodies;systematized nomenclature of medicine;uniform resource locator;university of california at santa cruz;web resource;leukemia	Vincenzo Lomonaco;Riccardo Martoglia;Federica Mandreoli;Laura Anderlucci;Warren Emmett;Silvio Bicciato;Cristian Taccioli	2014		10.1093/database/bau062	biology;computer science;bioinformatics;conserved sequence;world wide web;genetics;search engine	Comp.	-2.187731602449236	-60.30257816435478	140040
a8a2182e7329ba4d3b7b41d3c13fece78cb8f476	computer aided designing of juvenile hormone analogues as a potential pesticide based on ligand - receptor interaction - a docking study	juvenile hormone			Pamita Awasthi;Priyanka Sharma	2010			medicinal chemistry;juvenile hormone;pharmacology;receptor;biology;ligand	HCI	2.35694760680224	-64.63402564735527	140132
919acdd1d726d3f7ff16ddf98703c9d047b18526	mvp: a microbe–phage interaction database		Phages invade microbes, accomplish host lysis and are of vital importance in shaping the community structure of environmental microbiota. More importantly, most phages have very specific hosts; they are thus ideal tools to manipulate environmental microbiota at species-resolution. The main purpose of MVP (Microbe Versus Phage) is to provide a comprehensive catalog of phage-microbe interactions and assist users to select phage(s) that can target (and potentially to manipulate) specific microbes of interest. We first collected 50 782 viral sequences from various sources and clustered them into 33 097 unique viral clusters based on sequence similarity. We then identified 26 572 interactions between 18 608 viral clusters and 9245 prokaryotes (i.e. bacteria and archaea); we established these interactions based on 30 321 evidence entries that we collected from published datasets, public databases and re-analysis of genomic and metagenomic sequences. Based on these interactions, we calculated the host range for each of the phage clusters and accordingly grouped them into subgroups such as 'species-', 'genus-' and 'family-' specific phage clusters. MVP is equipped with a modern, responsive and intuitive interface, and is freely available at: http://mvp.medgenius.info.	archaea;bacteriophages;database;homology (biology);interaction;lysis;metagenomics;microbiota (plant);microorganism;noise shaping;pierre robin syndrome;prokaryote;scientific publication	Na L. Gao;Chengwei Zhang;Zhanbing Zhang;Songnian Hu;Martin J. Lercher;Xing-Ming Zhao;Peer Bork;Zhi Liu;Wei-Hua Chen	2018		10.1093/nar/gkx1124	genetics;database;archaea;bacteria;genome;metagenomics;host (biology);community structure;biology	Comp.	-0.05955668229587662	-59.78702969053962	140742
ead15f6cc1ec7290dc66c1462ef2d844a70bd009	interview with mit's robert langer	genetic engineering;music loop;materials science;genetic algorithms;music mixing	Dr. Robert Langers work is at the interface of biotechnology and materials science. A major focus is the study and development of polymers to deliver drugs, particularly genetically engineered proteins, DNA and RNAi, continuously at controlled rates for prolonged periods of time.	robert shaw (physicist)	Ubiquity Staff	2008	Ubiquity	10.1145/1366313.1366314	genetic engineering;genetic algorithm;telecommunications;computer science;artificial intelligence;management;audio mixing	HCI	1.9278445476670576	-65.14370340950005	140771
fedc62a0813abf7f0df5b45756ffece63f509e10	prin: a predicted rice interactome network	animals;escherichia coli;caenorhabditis elegans;saccharomyces cerevisiae;homo sapiens;network visualization;genome plant;signal transduction;mass spectrometry;web interface;molecular sequence annotation;gene expression data;oryza sativa;arabidopsis thaliana;computational biology bioinformatics;large scale;yeast two hybrid system;functional genomics;drosophila melanogaster;protein protein interaction;system biology;algorithms;subcellular localization;humans;metabolic pathway;combinatorial libraries;protein interaction;protein interaction mapping;high throughput;proteomics;molecular mechanics;quality control;database search;computer appl in life sciences;fruit fly;databases protein;microarrays;protein interaction network;bioinformatics	Protein-protein interactions play a fundamental role in elucidating the molecular mechanisms of biomolecular function, signal transductions and metabolic pathways of living organisms. Although high-throughput technologies such as yeast two-hybrid system and affinity purification followed by mass spectrometry are widely used in model organisms, the progress of protein-protein interactions detection in plants is rather slow. With this motivation, our work presents a computational approach to predict protein-protein interactions in Oryza sativa. To better understand the interactions of proteins in Oryza sativa, we have developed PRIN, a Predicted Rice Interactome Network. Protein-protein interaction data of PRIN are based on the interologs of six model organisms where large-scale protein-protein interaction experiments have been applied: yeast (Saccharomyces cerevisiae), worm (Caenorhabditis elegans), fruit fly (Drosophila melanogaster), human (Homo sapiens), Escherichia coli K12 and Arabidopsis thaliana. With certain quality controls, altogether we obtained 76,585 non-redundant rice protein interaction pairs among 5,049 rice proteins. Further analysis showed that the topology properties of predicted rice protein interaction network are more similar to yeast than to the other 5 organisms. This may not be surprising as the interologs based on yeast contribute nearly 74% of total interactions. In addition, GO annotation, subcellular localization information and gene expression data are also mapped to our network for validation. Finally, a user-friendly web interface was developed to offer convenient database search and network visualization. PRIN is the first well annotated protein interaction database for the important model plant Oryza sativa. It has greatly extended the current available protein-protein interaction data of rice with a computational approach, which will certainly provide further insights into rice functional genomics and systems biology. PRIN is available online at http://bis.zju.edu.cn/prin/ .	anatomy, regional;annotation;chromatography, affinity;drosophila <fruit fly, genus>;drosophila melanogaster;experiment;functional genomics;gene expression;graph drawing;high-throughput computing;hybrid system;imagery;interaction network;interactome;interface device component;interolog;organism;oryza (plant);oryza sativa antigen;primed in situ labeling;processor affinity;purification of quantum state;rafivirumab;saccharomyces cerevisiae;signal transduction;spectrometry;systems biology;throughput;two-hybrid screening;usability;user interface;yeast two-hybrid system techniques;protein protein interaction	Haibin Gu;Pengcheng Zhu;Yinming Jiao;Yijun Meng;Ming Chen	2010		10.1186/1471-2105-12-161	protein–protein interaction;functional genomics;high-throughput screening;biology;metabolic pathway;quality control;database search engine;dna microarray;mass spectrometry;molecular mechanics;computer science;bioinformatics;interactome;two-hybrid screening;proteomics;graph drawing;escherichia coli;user interface;genetics;signal transduction	Comp.	0.7816690167798288	-59.12501235630986	142479
877c4a39cd7acf5ef8029c829dbe77181d691d82	comparing metabolic pathways through potential fluxes: a selective opening approach	open closed net;petri nets;metabolic pathways	In our previous work we developed CoMeta, a tool for comparing metabolic pathways of different organisms, using the KEGG database as data source. The similarity measure adopted combines homology of reactions and functional aspects of the pathways. The latter are captured by T-invariants in the Petri net representation, which correspond to potential fluxes in the pathways. A Petri net can model a metabolic pathway of an organism either in isolation, focussing on its internal behaviour (isolated net), or as an interactive subsystem of the full metabolic network (open net). Modelling a pathway as an isolated net normally works fine for comparison purposes, but unsatisfactory results can arise as it supplies a partial view on internal fluxes. A representation as an open net makes additional information available, but the choice of the interactions of the pathway with the environment is non-trivial. Considering all possible interactions with the environment (an information automatically retrieved from KEGG) is not appropriate. Some interactions may add noise to the model, the size of invariants bases grows up to an order of magnitude and the comparison results might be less precise than with the isolated representation. Here we propose an extension of CoMeta which allows the user to select which metabolites should be considered as interactions of interest, discriminating between input and output metabolites. We illustrate some experiments which show the advantages of this more flexible approach. Our experience suggests that in general a good choice is to take as open metabolites those which are the input and output compounds for the pathway.	correctness (computer science);experiment;gene regulatory network;graph property;homology (biology);image noise;input/output;interaction;kegg;norm (social);petri net;similarity measure	Paolo Baldan;Martina Bocci;Nicoletta Cocco;Marta Simeoni	2013			bioinformatics;machine learning;distributed computing	Comp.	1.5737896574784058	-61.190694266922854	142648
e80dff977798b252ce381aa436d21e68eaaa390e	database of resistance related metabolites in wheat fusarium head blight disease (mwfd)		Database URL https://bioinfo.nrc.ca/mwfd/index.php.	antifungal agents;class;fusarium;homology (biology);joyce;metabolic process, cellular;metabolite;paget's disease, mammary;scientific publication;uniform resource locator;webserver directory index;eric	Anuradha Surendra;Miroslava Cuperlovic-Culf	2017		10.1093/database/bax076	fusarium;biotechnology;disease;bioinformatics;blight;computer science	ML	0.9827566125276437	-63.35240659104557	142916
0b086f3e3fcabfd403abf761ca96c4559c2e787e	improving bloom filter performance on sequence data using k -mer bloom filters			bloom filter	David Pellow;Darya Filippova;Carl Kingsford	2016		10.1007/978-3-319-31957-5_10		DB	0.6095593836032863	-63.638043484018425	142945
617180833d4ff139080a5ab9f14b00ad808f5b03	linkprot: a database collecting information about biological links		Protein chains are known to fold into topologically complex shapes, such as knots, slipknots or complex lassos. This complex topology of the chain can be considered as an additional feature of a protein, separate from secondary and tertiary structures. Moreover, the complex topology can be defined also as one additional structural level. The LinkProt database (http://linkprot.cent.uw.edu.pl) collects and displays information about protein links - topologically non-trivial structures made by up to four chains and complexes of chains (e.g. in capsids). The database presents deterministic links (with loops closed, e.g. by two disulfide bonds), links formed probabilistically and macromolecular links. The structures are classified according to their topology and presented using the minimal surface area method. The database is also equipped with basic tools which allow users to analyze the topology of arbitrary (bio)polymers.	access network;anatomy, regional;capsid;classification;database;display resolution;ions;knot (unit);numerical aperture;preparation;regulatory submission;server (computing);staphylococcal protein a;tertiary	Pawel Dabrowski-Tumanski;Aleksandra I. Jarmolinska;Wanda Niemyska;Eric J. Rawdon;Kenneth C. Millett;Joanna I. Sulkowska	2017		10.1093/nar/gkw976	bioinformatics	Comp.	-0.314767988403546	-60.87279550611748	143251
44d795cc6d5101bb2012542085cb88bcc1398056	flycop: metabolic modeling-based analysis and engineering microbial communities		Motivation Synthetic microbial communities begin to be considered as promising multicellular biocatalysts having a large potential to replace engineered single strains in biotechnology applications, in pharmaceutical, chemical and living architecture sectors. In contrast to single strain engineering, the effective and high-throughput analysis and engineering of microbial consortia face the lack of knowledge, tools and well-defined workflows. This manuscript contributes to fill this important gap with a framework, called FLYCOP (FLexible sYnthetic Consortium OPtimization), which contributes to microbial consortia modeling and engineering, while improving the knowledge about how these communities work. FLYCOP selects the best consortium configuration to optimize a given goal, among multiple and diverse configurations, in a flexible way, taking temporal changes in metabolite concentrations into account.   Results In contrast to previous systems optimizing microbial consortia, FLYCOP has novel characteristics to face up to new problems, to represent additional features and to analyze events influencing the consortia behavior. In this manuscript, FLYCOP optimizes a Synechococcus elongatus-Pseudomonas putida consortium to produce the maximum amount of bio-plastic (PHA, polyhydroxyalkanoate), and highlights the influence of metabolites exchange dynamics in a four auxotrophic Escherichia coli consortium with parallel growth. FLYCOP can also provide an explanation about biological evolution driving evolutionary engineering endeavors by describing why and how heterogeneous populations emerge from monoclonal ones.   Availability and implementation Code reproducing the study cases described in this manuscript are available on-line: https://github.com/beatrizgj/FLYCOP.   Supplementary information Supplementary data are available at Bioinformatics online.	bioinformatics;biological evolution;biotechnology;british informatics olympiad;community;competitive behavior, microbial;consortium;enzymes;genetic heterogeneity;geographic information systems;high-throughput computing;manuscripts;metabolic process, cellular;microbial consortia;online and offline;phytohemagglutinins;population;strain engineering;synechococcus;synthetic intelligence;throughput	Beatriz García Jiménez;José Luis García;Juan Nogales	2018		10.1093/bioinformatics/bty561	computer science;bioinformatics	DB	1.3853428407599595	-61.771571405318056	143929
dca990e5e43a202d0f5d5ddd0b7883eb9a8bc325	glycordf: an ontology to standardize glycomics data in rdf	journal article;glycomics based bioinformatics	MOTIVATION Over the last decades several glycomics-based bioinformatics resources and databases have been created and released to the public. Unfortunately, there is no common standard in the representation of the stored information or a common machine-readable interface allowing bioinformatics groups to easily extract and cross-reference the stored information.   RESULTS An international group of bioinformatics experts in the field of glycomics have worked together to create a standard Resource Description Framework (RDF) representation for glycomics data, focused on glycan sequences and related biological source, publications and experimental data. This RDF standard is defined by the GlycoRDF ontology and will be used by database providers to generate common machine-readable exports of the data stored in their databases.   AVAILABILITY AND IMPLEMENTATION The ontology, supporting documentation and source code used by database providers to generate standardized RDF are available online (http://www.glycoinfo.org/GlycoRDF/).	bioinformatics;cross-reference;documentation;glycomics;human-readable medium;ontology;polysaccharides;published database;resource description framework;source code	René Ranzinger;Kiyoko F. Aoki-Kinoshita;Matthew P. Campbell;Shin Kawano;Thomas Lütteke;Shujiro Okuda;Daisuke Shinmachi;Toshihide Shikanai;Hiromichi Sawaki;Philip V. Toukach;Masaaki Matsubara;Issaku Yamada;Hisashi Narimatsu	2015	Bioinformatics	10.1093/bioinformatics/btu732	biology;computer science;bioinformatics;data mining;world wide web	Web+IR	-3.2796047364142447	-61.57235270174247	143995
9a82bc32e2786503ed0a5cc470636d6575911280	plant pathogen interactions ontology (ppio)		Plant-pathogen interactions are an important knowledge domain within plant biotechnology, both scientifically and in economic terms. Unlike other knowledge domains within life sciences, however, semantic technologies have not been used extensively to codify it, therefore, there is a lack of axiomatic models amenable to automated integration and inference. We present the Plant-Pathogen Interactions Ontology (PPIO), a first step towards the axiomisation of plant-pathogen interactions that results in a model that encourages consistent annotation and supports both query and inference.	interaction	Alejandro Rodriguez Iglesias;Mikel Egaña Aranguren;Alejandro Rodríguez González;Mark D. Wilkinson	2013				AI	-4.475451298499888	-63.914366412799545	144290
0bdae299902778e3b87b5ba47a7587d8a747c802	towards automated metabolome assembly: application of text mining to correlate small molecules, targets and tissues	biological patents;biomedical journals;text mining;europe pubmed central;citation search;computer applications in chemistry;citation networks;theoretical and computational chemistry;computational biology bioinformatics;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics;literature search	How many species are there on Earth? Single celled organisms aside a few million are known. How many species had their genomes sequenced so far? Around two thousand. Approaching the era of a new genome sequence per week, it is fair to wonder: How many metabolomes have been compiled? The metabolome could be considered the ultimate phenotypic expression of the cell, and yet, we barely have one [1]. The metabolome refers to the complete set of small molecules (< 1500Da) present on a biological sample or organism [2]. Among all omics, metabolomics is probably the most unique to each individual in terms of the variation of its elements. Here we define Automated Metabolome Assembly (AMA) as a set of techniques to predict the metabolome of an organism based on the complete set of boundary information available (gene sequence, proteomics, bibliomics, etc.). As a first step towards Automated Metabolome Assembly we report the implementation of a text mining resource based on the existing EBI text mining infrastructure [3] to address the problem of finding co-occurrences of chemical entities, proteins, organisms, and tissues/cell types terms. We created a workflow based on a database holding 365 million of relations between these terms (proteins, metabolites, organisms and tissues) and PubMed citations, obtained from the whole PubMed collection up to September 2009. Dictionaries of terms for each kind of entity were generated from different ontologies. All known metabolites present in liver were obtained from the latest version of HMDB. The text mining results were compared to this reference set. Close to 90% of the reference set shows co-occurence of our liver-related tissue ontology terms with the respective metabolite names, demonstrating that this text-mining workflow can form an important building block for a comprehensive system for metabolome prediction.	compiler;dictionary;entity;external bus interface;human metabolome database;metabolomics;omics;ontology (information science);proteomics;pubmed;text mining	Pablo Moreno;Kalai Vanii Jayaseelan;Christoph Steinbeck	2011		10.1186/1758-2946-3-S1-P19	biology;e. coli metabolome database;text mining;medical research;computer science;bioinformatics;data science;data mining	ML	-1.1630821607578208	-60.77750032924499	144776
68e3b32b5ba0c371754aab819960a36750cc12aa	aniseed 2017: extending the integrated ascidian database to the exploration and evolutionary comparison of genome-scale datasets		ANISEED (www.aniseed.cnrs.fr) is the main model organism database for tunicates, the sister-group of vertebrates. This release gives access to annotated genomes, gene expression patterns, and anatomical descriptions for nine ascidian species. It provides increased integration with external molecular and taxonomy databases, better support for epigenomics datasets, in particular RNA-seq, ChIP-seq and SELEX-seq, and features novel interactive interfaces for existing and novel datatypes. In particular, the cross-species navigation and comparison is enhanced through a novel taxonomy section describing each represented species and through the implementation of interactive phylogenetic gene trees for 60% of tunicate genes. The gene expression section displays the results of RNA-seq experiments for the three major model species of solitary ascidians. Gene expression is controlled by the binding of transcription factors to cis-regulatory sequences. A high-resolution description of the DNA-binding specificity for 131 Ciona robusta (formerly C. intestinalis type A) transcription factors by SELEX-seq is provided and used to map candidate binding sites across the Ciona robusta and Phallusia mammillata genomes. Finally, use of a WashU Epigenome browser enhances genome navigation, while a Genomicus server was set up to explore microsynteny relationships within tunicates and with vertebrates, Amphioxus, echinoderms and hemichordates.	anise;base sequence;binding sites;ciona intestinalis;dna microarray chip;dna binding site;database;description;epigenomics;experiment;gene expression programming;genome;image resolution;lancelets;phylogenetics;rna;sensitivity and specificity;sequence number;server (computing);synteny;transcription factor;taxonomy;transcription (software);trees (plant);urochordata;vertebrates	Matija Brozovic;Christelle Dantec;Justine Dardaillon;Delphine Dauga;Emmanuel Faure;Mathieu Gineste;Alexandra Louis;Magali Naville;Kazuhiro R. Nitta;Jacques Piette;Wendy Reeves;Céline Scornavacca;Paul Simion;Renaud Vincentelli;Maelle Bellec;Sameh Ben Aicha;Marie Fagotto;Marion Guéroult-Bellone	2018		10.1093/nar/gkx1108	taxonomy (biology);epigenomics;phylogenetic tree;gene;database;genome;biology;epigenome;model organism;tunicate	Comp.	-1.1376159881601047	-59.324371841053114	144914
19b1570b440e54fc08967bbf41a2c1f9952106ea	erratum to: meta-analytic support vector machine for integrating multiple omics data	data mining and knowledge discovery;computational biology bioinformatics;algorithms;computer appl in life sciences;bioinformatics	[This corrects the article DOI: 10.1186/s13040-017-0126-8.].		Sunghwan Kim;Jae-Hwan Jhong;Jung-Jun Lee;Ja-Yong Koo	2017	BioData mining	10.1186/s13040-017-0128-6	support vector machine;computer science;bioinformatics;integrative bioinformatics;computational biology;omics	ML	0.6013918914468107	-63.503871555959336	145006
4a052764095c04972909ac6e3837969aaa184255	protein block expert (pbe): a web-based protein structure analysis server using a structural alphabet	software;performance comparison;dynamic program;protein structure;structure comparison;internet;protein conformation;protein folding;sequence alignment;user computer interface;3d structure;amino acid motifs;sequence analysis protein;databases protein	Encoding protein 3D structures into 1D string using short structural prototypes or structural alphabets opens a new front for structure comparison and analysis. Using the well-documented 16 motifs of Protein Blocks (PBs) as structural alphabet, we have developed a methodology to compare protein structures that are encoded as sequences of PBs by aligning them using dynamic programming which uses a substitution matrix for PBs. This methodology is implemented in the applications available in Protein Block Expert (PBE) server. PBE addresses common issues in the field of protein structure analysis such as comparison of proteins structures and identification of protein structures in structural databanks that resemble a given structure. PBE-T provides facility to transform any PDB file into sequences of PBs. PBE-ALIGNc performs comparison of two protein structures based on the alignment of their corresponding PB sequences. PBE-ALIGNm is a facility for mining SCOP database for similar structures based on the alignment of PBs. Besides, PBE provides an interface to a database (PBE-SAdb) of preprocessed PB sequences from SCOP culled at 95% and of all-against-all pairwise PB alignments at family and superfamily levels. PBE server is freely available at http://bioinformatics.univ-reunion.fr/PBE/.	addresses (publication format);alignment;alphabet;bioinformatics;document completion status - documented;dynamic programming;interface device component;protein data bank;protein family;protein, organized by structure;superfamily;scop;server (computer);server (computing);substitution matrix;web application;whole earth 'lectronic link	Manoj Tyagi;P. Sharma;C. S. Swamy;F. Cadet;Narayanaswamy Srinivasan;Alexandre G. de Brevern;Bernard O. Offmann	2006	Nucleic Acids Research	10.1093/nar/gkl199	biology;protein structure;structural alignment;bioinformatics;protein structure database	Comp.	-1.8917066475945614	-59.72515106326627	145298
f6288e679ec74d5e23218580ac9ee131c4b1e2e8	rnarchitecture: a database and a classification system of rna families, with a focus on structural information		RNArchitecture is a database that provides a comprehensive description of relationships between known families of structured non-coding RNAs, with a focus on structural similarities. The classification is hierarchical and similar to the system used in the SCOP and CATH databases of protein structures. Its central level is Family, which builds on the Rfam catalog and gathers closely related RNAs. Consensus structures of Families are described with a reduced secondary structure representation. Evolutionarily related Families are grouped into Superfamilies. Similar structures are further grouped into Architectures. The highest level, Class, organizes families into very broad structural categories, such as simple or complex structured RNAs. Some groups at different levels of the hierarchy are currently labeled as 'unclassified'. The classification is expected to evolve as new data become available. For each Family with an experimentally determined three-diemsional (3D) structure(s), a representative one is provided. RNArchitecture also presents theoretical models of RNA 3D structure and is open for submission of structural models by users. Compared to other databases, RNArchitecture is unique in its focus on structure-based RNA classification, and in providing a platform for storing RNA 3D structure predictions. RNArchitecture can be accessed at http://iimcb.genesilico.pl/RNArchitecture/.	architecture as topic;cath;categories;classification;database;experiment;rna;regulatory submission;rfam;scop;tracer	Pietro Boccaletto;Marcin Magnus;Catarina Almeida;Adriana Zyla;Astha Astha;Radoslaw Pluta;Blazej Baginski;Elżbieta Jankowska;Stanislaw Dunin-Horkawicz;Tomasz Wirecki;Michal Boniecki;Filip Stefaniak;Janusz M. Bujnicki	2018		10.1093/nar/gkx966	rna;biology;bioinformatics	ML	-0.43242417658810844	-60.43448314502279	145325
363055ac509bf392d89785889d534ab14e3ac2d7	modeling a microbial community and biodiversity assay with obo foundry ontologies: the interoperability gains of a modular approach	models biological;microbial consortia;rna ribosomal 16s;genes bacterial;biodiversity;genes rrna;gene ontology	The advent of affordable sequencing technology provides for a new generation of explorers who probe the world's microbial diversity. Projects such as Tara Oceans, Moorea Biocode Project and Gut Microbiome rely on sequencing technologies to probe community diversity. Either targeted gene surveys (also known as community surveys) or complete metagenomes are evaluated. The former, being the less costly of the two methods, relies on the identification of specific genomic regions, which can be used as a proxy to estimate genetic distance between related species in a Phylum. For instance, 16 S ribosomal RNA gene surveys are used to probe bacterial communities while internal transcribed spacer surveys, for example, can be used for probing fungal communities. With the explosion of projects and frenzy to explore new domains of life, scientists in the field have issued guidelines to report minimal information (following a checklist), ensuring that information is contextualized in a meaningful way. Yet the semantics of a checklist are not explicit. We demonstrate here how a tabular template can be used to collect information on microbial diversity using an explicit representation in the Resource Description Framework that is consistent with community agreed-upon knowledge representation patterns found in the Ontology for Biomedical Investigations.	biopolymer sequencing;clinical use template;community;genetic distance;internal transcribed spacer;interoperability;knowledge representation and reasoning;obo foundry;ontology (information science);ontology for biomedical investigations;phylum (taxon);rna;resource description framework;spacer device component;triobp gene;table (information);negative regulation of gut granule assembly	Philippe Rocca-Serra;Ramona L. Walls;Jacob Parnell;Rachel Gallery;Jie Zheng;Susanna-Assunta Sansone;Alejandra González Beltrán	2015		10.1093/database/bau132	biology;biodiversity;bioinformatics;ecology	AI	-3.8557495021691013	-63.24888955694518	145548
4d9f5cfad7cea944a35f75818fda903e0c92d807	wikipathways: a multifaceted pathway database bridging metabolomics to other omics research		WikiPathways (wikipathways.org) captures the collective knowledge represented in biological pathways. By providing a database in a curated, machine readable way, omics data analysis and visualization is enabled. WikiPathways and other pathway databases are used to analyze experimental data by research groups in many fields. Due to the open and collaborative nature of the WikiPathways platform, our content keeps growing and is getting more accurate, making WikiPathways a reliable and rich pathway database. Previously, however, the focus was primarily on genes and proteins, leaving many metabolites with only limited annotation. Recent curation efforts focused on improving the annotation of metabolism and metabolic pathways by associating unmapped metabolites with database identifiers and providing more detailed interaction knowledge. Here, we report the outcomes of the continued growth and curation efforts, such as a doubling of the number of annotated metabolite nodes in WikiPathways. Furthermore, we introduce an OpenAPI documentation of our web services and the FAIR (Findable, Accessible, Interoperable and Reusable) annotation of resources to increase the interoperability of the knowledge encoded in these pathways and experimental omics data. New search options, monthly downloads, more links to metabolite databases, and new portals make pathway knowledge more effortlessly accessible to individual researchers and research communities.	bridging (networking);community;database;departure - action;digital curation;documentation;doubling;findability;gene regulatory network;human-readable medium;identifier;interoperability;java annotation;konica minolta openapi;metabolite;metabolomics;omics;open api;portals;web service	Denise Slenter;Martina Kutmon;Kristina Hanspers;Anders Riutta;Jacob Windsor;Nuno Nunes;Jonathan Mélius;Elisa Cirillo;Susan L. Coort;Daniela Digles;Friederike Ehrhart;Pieter Giesbertz;Marianthi Kalafati;Marvin Martens;Ryan Miller;Kozo Nishida;Linda Rieswijk;Andra Waagmeester;Lars M. T. Eijssen	2018		10.1093/nar/gkx1064	genetics;metabolomics;computational biology;wikipathways : pathways for the people;bioinformatics;biology;omics	ML	-1.4985797234157514	-61.42770981987888	145652
2f72b9ea135055e8ba65732d1d27e1b8d58f0f7c	blast - an essential guide to the basic local alignment search tool	basic local alignment search tool		blast;smith–waterman algorithm	Ian Korf;Mark Yandell;Joseph A. Bedell	2003			simulation;bioinformatics;engineering drawing	AI	1.0521444699500337	-64.00211115828881	145899
14e05162e86aea806fb97f29be0ab5b2b70bd71d	supertarget and matador: resources for exploring drug-target relationships	embl;sequence comparison;drug effects;drug delivery systems;drug targeting;enzyme;pharmaceutical preparations;internet;proteins;drug design;pharmacology;indirect interaction;user computer interface;databases factual;data warehouse;drug screening;gene ontology	The molecular basis of drug action is often not well understood. This is partly because the very abundant and diverse information generated in the past decades on drugs is hidden in millions of medical articles or textbooks. Therefore, we developed a one-stop data warehouse, SuperTarget that integrates drug-related information about medical indication areas, adverse drug effects, drug metabolization, pathways and Gene Ontology terms of the target proteins. An easy-to-use query interface enables the user to pose complex queries, for example to find drugs that target a certain pathway, interacting drugs that are metabolized by the same cytochrome P450 or drugs that target the same protein but are metabolized by different enzymes. Furthermore, we provide tools for 2D drug screening and sequence comparison of the targets. The database contains more than 2500 target proteins, which are annotated with about 7300 relations to 1500 drugs; the vast majority of entries have pointers to the respective literature source. A subset of these drugs has been annotated with additional binding information and indirect interactions and is available as a separate resource called Matador. SuperTarget and Matador are available at http://insilico.charite.de/supertarget and http://matador.embl.de.	adverse reaction to drug;gene ontology;gene regulatory network;greater than;interaction;interface device component;metabolic process, cellular;pointer (computer programming);pointer <dog>;question (inquiry);subgroup;textbooks	Stefan Günther;Michael Kuhn;Mathias Dunkel;Monica Campillos;Christian Senger;Evangelia Petsalaki;Jessica Ahmed;Eduardo Garcia Urdiales;Andreas Gewiess;Lars Juhl Jensen;Reinhard Schneider;Roman Skoblo;Robert B. Russell;Philip E. Bourne;Peer Bork;Robert Preissner	2008		10.1093/nar/gkm862	pharmacology;biology;enzyme;targeted drug delivery;the internet;bioinformatics;data warehouse;drug design	Comp.	-0.39894313310975	-61.3332324727299	145992
38193972de0c87e12eddd94839840c0f902c0ec1	gpcrdb in 2018: adding gpcr structure models and ligands		G protein-coupled receptors are the most abundant mediators of both human signalling processes and therapeutic effects. Herein, we report GPCRome-wide homology models of unprecedented quality, and roughly 150 000 GPCR ligands with data on biological activities and commercial availability. Based on the strategy of 'Less model - more Xtal', each model exploits both a main template and alternative local templates. This achieved higher similarity to new structures than any of the existing resources, and refined crystal structures with missing or distorted regions. Models are provided for inactive, intermediate and active states-except for classes C and F that so far only have inactive templates. The ligand database has separate browsers for: (i) target selection by receptor, family or class, (ii) ligand filtering based on cross-experiment activities (min, max and mean) or chemical properties, (iii) ligand source data and (iv) commercial availability. SMILES structures and activity spreadsheets can be downloaded for further processing. Furthermore, three recent landmark publications on GPCR drugs, G protein selectivity and genetic variants have been accompanied with resources that now let readers view and analyse the findings themselves in GPCRdb. Altogether, this update will enable scientific investigation for the wider GPCR community. GPCRdb is available at http://www.gpcrdb.org.	class;clinical use template;crystal structure;gpcrdb;homologous gene;homology (biology);ligands;maxima and minima;physical inactivity;selectivity (electronic);simplified molecular input line entry specification;simplified molecular-input line-entry system;source data;spreadsheet;biological signaling;chemical properties	Gáspár Pándy-Szekeres;Christian Munk;Tsonko M. Tsonkov;Stefan Mordalski;Kasper Harpsøe;Alexander S. Hauser;Andrzej J. Bojarski;David E. Gloriam	2018		10.1093/nar/gkx1109	cell biology;molecular biology;gtp-binding protein regulators;ligand;biology;g protein-coupled receptor	Comp.	0.43292858808013607	-60.86396178963449	146105
a23493037780c309b96b93f9c31b5b94415af74d	applying content management to automated provenance capture	dynamic provenance;provenance challenge;provenance record;recording data provenance;workflow provenance system;data management;data pipeline;data service;content management software;content management technology;automated provenance	Workflows and data pipelines are becoming increasingly valuable to computational and experimental sciences. These automated systems are capable of generating significantly more data within the same amount of time compared to their manual counterparts. Automatically capturing and recording data provenance and annotation as part of these workflows are critical for data management, verification, and dissemination. We have been prototyping a workflow provenance system, targeted at biological workflows, that extends our content management technologies and other open source tools. We applied this prototype to the provenance challenge to demonstrate an end-to-end system that supports dynamic provenance capture, persistent content management, and dynamic searches of both provenance and metadata. We describe our prototype, which extends the Kepler system for the execution environment, the Scientific Annotation Middleware (SAM) content management software for data services, and an existing HTTP-based query protocol. Our implementation offers several unique capabilities, and through the use of standards, is able to provide access to the provenance record with a variety of commonly available client tools. Copyright © 2007 John Wiley & Sons, Ltd.	content management system	Karen Schuchardt;Tara Gibson;Eric G. Stephan;George Chin	2008	Concurrency and Computation: Practice and Experience	10.1002/cpe.1230	workflow;content management;data management;computer science;operating system;middleware;data mining;database;origin;metadata;world wide web;data	SE	-4.225452582247419	-60.786476671355146	146325
6437bf906883c7d8419870874ff38fa6a6929adf	onto2vec: joint vector-based representation of biological entities and their ontology-based annotations		Motivation Biological knowledge is widely represented in the form of ontology-based annotations: ontologies describe the phenomena assumed to exist within a domain, and the annotations associate a (kind of) biological entity with a set of phenomena within the domain. The structure and information contained in ontologies and their annotations make them valuable for developing machine learning, data analysis and knowledge extraction algorithms; notably, semantic similarity is widely used to identify relations between biological entities, and ontology-based annotations are frequently used as features in machine learning applications.   Results We propose the Onto2Vec method, an approach to learn feature vectors for biological entities based on their annotations to biomedical ontologies. Our method can be applied to a wide range of bioinformatics research problems such as similarity-based prediction of interactions between proteins, classification of interaction types using supervised learning, or clustering. To evaluate Onto2Vec, we use the gene ontology (GO) and jointly produce dense vector representations of proteins, the GO classes to which they are annotated, and the axioms in GO that constrain these classes. First, we demonstrate that Onto2Vec-generated feature vectors can significantly improve prediction of protein-protein interactions in human and yeast. We then illustrate how Onto2Vec representations provide the means for constructing data-driven, trainable semantic similarity measures that can be used to identify particular relations between proteins. Finally, we use an unsupervised clustering approach to identify protein families based on their Enzyme Commission numbers. Our results demonstrate that Onto2Vec can generate high quality feature vectors from biological entities and ontologies. Onto2Vec has the potential to significantly outperform the state-of-the-art in several predictive applications in which ontologies are involved.   Availability and implementation https://github.com/bio-ontology-research-group/onto2vec.   Supplementary information Supplementary data are available at Bioinformatics online.	algorithm;assumed;bioinformatics;caspase-1;class;cluster analysis;contain (action);display resolution;entity;enzyme commission number;feature vector;gene ontology;geographic information systems;machine learning;ontology (information science);protein family;semantic similarity;supervised learning;protein protein interaction;statistical cluster	Fatima Zohra Smaili;Xin Gao;Robert Hoehndorf	2018		10.1093/bioinformatics/bty259	natural language processing;artificial intelligence;supervised learning;knowledge extraction;machine learning;computer science;ontology;open biomedical ontologies;ontology (information science);feature vector;cluster analysis;semantic similarity	Comp.	-4.2490521029925485	-64.43888077441109	146335
dc6c5c06d2db797f76b4e2e1a5d8ebe1fdb1346f	codes, involutions, and dna encodings	dna;molecular computation;hybridation;codificacion;laboratory techniques;coding;hybridization;dna computing;hibridacion;calcul moleculaire;codage	DNA computing as a field started in 1994 when Leonard Adleman solved a hard computational problem entirely by manipulations of DNA molecules in a test tube [1]. The premise behind DNA computing is that DNA is capable of storing information, while various laboratory techniques that operate on and modify DNA strands (called bio-operations in the sequel) can be used to perform computational steps. Most DNA computations consists of three basic stages. The first is encoding the problem using single-stranded or double-stranded DNA. Then the actual computation is performed by employing a succession of bio-operations [14]. Finally, the DNA strands representing the solution to the problem are detected and decoded. Because of the nature of the substrate in which the data is encoded, namely DNA strands, problems can occur at the encoding stage which would not occur in an electronic medium. In order to describe these problems and our attempts at solutions, we now briefly present some basic molecular biology notions and notations. DNA (deoxyribonucleic acid) is found in every cellular organism as the storage medium for genetic information. It is composed of units called nucleotides, distinguished by the chemical group, or base, attached to them. The four bases, are adenine, guanine, cytosine and thymine, abbreviated as A, G, C, and T . The names of the bases are also commonly used to refer to the nucleotides that contain them. Single nucleotides are linked together end–to–end to form DNA strands. A short single-stranded polynucleotide chain, usually less than 30 nucleotides long, is called an oligonucleotide. The DNA sequence has a polarity: a sequence of DNA is distinct from its reverse. The two distinct ends of a DNA sequence are known under the name of the 5′ end and the 3′ end, respectively. Taken as pairs, the nucleotides A and T and the nucleotides C and G are said to be complementary. Two complementary single–stranded DNA sequences with	a.j. han vinck;british informatics olympiad;character encoding;code (cryptography);computation;computational problem;dna computing;dna database;evolutionary computation;genetic programming;handbook;john koza;john reif;morgan;philips nino;prefix code;springer (tank);stevens award;strand (programming language);succession;vii	Lila Kari;Rob Kitto;Gabriel Thierrin	2002		10.1007/3-540-45711-9_21	orbital hybridisation;computer science;bioinformatics;mathematics;coding;dna;dna computing;algorithm	Comp.	2.2400970203240202	-63.95066571163566	146554
180307b6508ab48b1ed31b72690ba8128fd9f7d5	the network library: a framework to rapidly integrate network biology resources	biology;elss earth life and social sciences;life;healthy living;biomedical innovation;msb microbiology and systems biology	MOTIVATION Much of the biological knowledge accumulated over the last decades is stored in different databases governed by various organizations and institutes. Integrating and connecting these vast knowledge repositories is an extremely useful method to support life sciences research and help formulate novel hypotheses.   RESULTS We developed the Network Library (NL), a framework and toolset to rapidly integrate different knowledge sources to build a network biology resource that matches a specific research question. As a use-case we explore the interactions of genes related to heart failure with miRNAs and diseases through the integration of 6 databases.   AVAILABILITY AND IMPLEMENTATION The NL is open-source, developed in Java and available on Github (https://github.com/gsummer).   CONTACT georg.summer@gmail.com.		Georg Summer;Thomas Kelder;Marijana Radonjic;Marc van Bilsen;Suzan Wopereis;Stephane Heymans	2016	Bioinformatics	10.1093/bioinformatics/btw436	biology;computer science;bioinformatics;data science	Comp.	-3.4405686724832245	-62.201414803973904	146811
160a5bef33048765c853fd849f049e1bd4a93fcd	zfin: enhancements and updates to the zebrafish model organism database	genes;community;software;animals;genomics;rna messenger;genotype;collaboration;databases genetic;models animal;genetics;gene expression;internet;zebrafish;genome;laboratory;phenotype;bioinformatics;antibodies	ZFIN, the Zebrafish Model Organism Database, http://zfin.org, serves as the central repository and web-based resource for zebrafish genetic, genomic, phenotypic and developmental data. ZFIN manually curates comprehensive data for zebrafish genes, phenotypes, genotypes, gene expression, antibodies, anatomical structures and publications. A wide-ranging collection of web-based search forms and tools facilitates access to integrated views of these data promoting analysis and scientific discovery. Data represented in ZFIN are derived from three primary sources: curation of zebrafish publications, individual research laboratories and collaborations with bioinformatics organizations. Data formats include text, images and graphical representations. ZFIN is a dynamic resource with data added daily as part of our ongoing curation process. Software updates are frequent. Here, we describe recent additions to ZFIN including (i) enhanced access to images, (ii) genomic features, (iii) genome browser, (iv) transcripts, (v) antibodies and (vi) a community wiki for protocols and antibodies.	anatomic structures;bioinformatics;digital curation;emoticon;gene expression;genotype;graphical user interface;image;laboratory;patch (computing);phenotype;primary source;promotion (action);protocols documentation;transcript;web application;wiki;zfin;zebrafish model organism database;format	Yvonne M. Bradford;Tom Conlin;Nathan A. Dunn;David Fashena;Ken Frazer;Douglas G. Howe;Jonathan Knight;Prita Mani;Ryan Martin;Sierra A. T. Moxon;Holly Paddock;Christian Pich;Sridhar Ramachandran;Barbara J. Ruef;Leyla Ruzicka;Holle Bauer Schaper;Kevin Schaper;Xiang Shao;Amy Singer;Judy Sprague	2011		10.1093/nar/gkq1077	biology;community;genomics;the internet;gene expression;zebrafish information network genome database;bioinformatics;phenotype;gene;genotype;antibody;genetics;laboratory;genome;collaboration	Comp.	-2.4975056156420923	-60.91568243006148	147596
68e5110ed22891eddaaec93bbb6c0d978e422080	the salami protein structure search server	software;amino acid sequence;protein structure;structural homology protein;sequence alignment;user computer interface;protein data bank;structural similarity;databases protein	Protein structures often show similarities to another which would not be seen at the sequence level. Given the coordinates of a protein chain, the SALAMI server at www.zbh.uni-hamburg.de/salami will search the protein data bank and return a set of similar structures without using sequence information. The results page lists the related proteins, details of the sequence and structure similarity and implied sequence alignments. Via a simple structure viewer, one can view superpositions of query and library structures and finally download superimposed coordinates. The alignment method is very tolerant of large gaps and insertions, and tends to produce slightly longer alignments than other similar programs.	clinical act of insertion;download;protein data bank;protein, organized by structure;quantum superposition;question (inquiry);sequence alignment;server (computer);server (computing)	Thomas Margraf;Gundolf Schenk;Andrew E. Torda	2009		10.1093/nar/gkp431	threading;biology;protein structure;structural alignment;protein data bank;multiple sequence alignment;bioinformatics;structural similarity;loop modeling;sequence alignment;peptide sequence;protein structure database	Comp.	-1.9037007975397342	-60.072007483543004	147955
e8c824adb41757a6145540fd4efca8a7509060ba	phylopro2.0: a database for the dynamic exploration of phylogenetically conserved proteins and their domain architectures across the eukarya		PhyloPro is a database and accompanying web-based application for the construction and exploration of phylogenetic profiles across the Eukarya. In this update article, we present six major new developments in PhyloPro: (i) integration of Pfam-A domain predictions for all proteins; (ii) new summary heatmaps and detailed level views of domain conservation; (iii) an interactive, network-based visualization tool for exploration of domain architectures and their conservation; (iv) ability to browse based on protein functional categories (GOSlim); (v) improvements to the web interface to enhance drill down capability from the heatmap view; and (vi) improved coverage including 164 eukaryotes and 12 reference species. In addition, we provide improved support for downloading data and images in a variety of formats. Among the existing tools available for phylogenetic profiles, PhyloPro provides several innovative domain-based features including a novel domain adjacency visualization tool. These are designed to allow the user to identify and compare proteins with similar domain architectures across species and thus develop hypotheses about the evolution of lineage-specific trajectories. Database URL: http://www.compsysbio.org/phylopro/.	architecture as topic;browsing;categories;download;emoticon;eukaryota;heatmap;imagery;interface device component;lineage (evolution);pfam;phylogenetics;uniform resource locator;user interface;web application;format	Graham L. Cromar;Anthony Zhao;Xuejian Xiong;Lakshmipuram S. Swapna;Noeleen Loughran;Hongyan Song;John Parkinson	2016		10.1093/database/baw013	biology;bioinformatics;data mining;world wide web	Comp.	-1.9818705341727614	-59.16092563679967	148230
4eec38d9b9d5a94a841913ea5a2e4f311fc61862	the candida genome database (cgd): incorporation of assembly 22, systematic identifiers and visualization of high throughput sequencing data		The Candida Genome Database (CGD, http://www.candidagenome.org/) is a freely available online resource that provides gene, protein and sequence information for multiple Candida species, along with web-based tools for accessing, analyzing and exploring these data. The mission of CGD is to facilitate and accelerate research into Candida pathogenesis and biology, by curating the scientific literature in real time, and connecting literature-derived annotations to the latest version of the genomic sequence and its annotations. Here, we report the incorporation into CGD of Assembly 22, the first chromosome-level, phased diploid assembly of the C. albicans genome, coupled with improvements that we have made to the assembly using additional available sequence data. We also report the creation of systematic identifiers for C. albicans genes and sequence features using a system similar to that adopted by the yeast community over two decades ago. Finally, we describe the incorporation of JBrowse into CGD, which allows online browsing of mapped high throughput sequencing data, and its implementation for several RNA-Seq data sets, as well as the whole genome sequencing data that was used in the construction of Assembly 22.	biopolymer sequencing;candida (fungus);candida albicans ag:titr:pt:ser:qn:la;candida sp identified:prid:pt:vag:nom:cyto stain;diploidy;entity name part qualifier - adopted;identifier;imagery;scientific literature;sequence number;throughput;web application;whole genome sequencing;positive regulation of reactive oxygen species biosynthetic process	Marek S. Skrzypek;Jonathan Binkley;Gail Binkley;Stuart R. Miyasato;Matt Simison;Gavin Sherlock	2017		10.1093/nar/gkw924	biology;bioinformatics;genetics	Comp.	-1.370087408086763	-59.60303135351247	148292
ff542a14c2500e33487f069e41451f2f24cf038e	homomint: an inferred human network based on orthology mapping of protein interactions discovered in model organisms	software;settore bio 18 genetica;proteome;computational biology bioinformatics;internet;gene ontology annotation;proteins;protein structure tertiary;genome;protein binding;models statistical;algorithms;pattern recognition automated;humans;sequence alignment;combinatorial libraries;protein interaction;string matching;high throughput;computational biology;computer appl in life sciences;information storage and retrieval;sequence analysis protein;microarrays;protein interaction network;bioinformatics	The application of high throughput approaches to the identification of protein interactions has offered for the first time a glimpse of the global interactome of some model organisms. Until now, however, such genome-wide approaches have not been applied to the human proteome. In order to fill this gap we have assembled an inferred human protein interaction network where interactions discovered in model organisms are mapped onto the corresponding human orthologs. In addition to a stringent assignment to orthology classes based on the InParanoid algorithm, we have implemented a string matching algorithm to filter out orthology assignments of proteins whose global domain organization is not conserved. Finally, we have assessed the accuracy of our own, and related, inferred networks by benchmarking them against i) an assembled experimental interactome, ii) a network derived by mining of the scientific literature and iii) by measuring the enrichment of interacting protein pairs sharing common Gene Ontology annotation. The resulting networks are named HomoMINT and HomoMINT_filtered, the latter being based on the orthology table filtered by the domain architecture matching algorithm. They contains 9749 and 5203 interactions respectively and can be analyzed and viewed in the context of the experimentally verified interactions between human proteins stored in the MINT database. HomoMINT is constantly updated to take into account the growing information in the MINT database.	annotation;class;experiment;gene ontology term enrichment;homology (biology);inference;inparanoid;interaction network;interactome;matching;mint;name;proteome;scientific literature;social network;string searching algorithm;throughput;mapped;protein protein interaction	Maria Persico;Arnaud Céol;Caius Gavrila;Robert Hoffmann;Arnaldo Florio;Gianni Cesareni	2005	BMC Bioinformatics	10.1186/1471-2105-6-S4-S21	computational biology;high-throughput screening;biology;plasma protein binding;the internet;dna microarray;computer science;bioinformatics;sequence alignment;proteome;genome;string searching algorithm	Comp.	-0.20458481334557163	-59.516618578912436	148293
9893c78c78ef1720cf8a069587bbccbe068f4074	the ebi search engine: ebi search as a service—making biological data accessible for all	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	We present an update of the EBI Search engine, an easy-to-use fast text search and indexing system with powerful data navigation and retrieval capabilities. The interconnectivity that exists between data resources at EMBL-EBI provides easy, quick and precise navigation and a better understanding of the relationship between different data types that include nucleotide and protein sequences, genes, gene products, proteins, protein domains, protein families, enzymes and macromolecular structures, as well as the life science literature. EBI Search provides a powerful RESTful API that enables its integration into third-party portals, thus providing 'Search as a Service' capabilities, which are the main topic of this article.	amino acid sequence;application programming interface;biological science disciplines;external bus interface;indexes;interconnectedness;peptide sequence;portals;protein domain;protein family;representational state transfer;search as a service;web search engine;search a word	Young Mi Park;Silvano Squizzato;Nicola Buso;Tamer Gur;Rodrigo Lopez	2017		10.1093/nar/gkx359	text mining;medical research	Comp.	-2.587396744054072	-60.02367177565758	148717
61c2336f86dab4509686a4781791ba396ac73d4d	flan: a web server for influenza virus genome annotation	software;influenza virus;genome annotation;genotype;genome viral;computer graphics;nucleotides;protein sequence;amino acid sequence;sequence analysis dna;influenza viruses;viruses;dna viral;internet;influenza a virus;genes viral;automatic annotation;open reading frame;algorithms;molecular sequence data;sequence alignment;short period;gene expression pattern;b virus;influenza b virus	FLAN (short for FLu ANnotation), the NCBI web server for genome annotation of influenza virus (http://www.ncbi.nlm.nih.gov/genomes/FLU/Database/annotation.cgi) is a tool for user-provided influenza A virus or influenza B virus sequences. It can validate and predict protein sequences encoded by an input flu sequence. The input sequence is BLASTed against a database containing influenza sequences to determine the virus type (A or B), segment (1 through 8) and subtype for the hemagglutinin and neuraminidase segments of influenza A virus. For each segment/subtype of the viruses, a set of sample protein sequences is maintained. The input sequence is then aligned against the corresponding protein set with a 'Protein to nucleotide alignment tool' (ProSplign). The translated product from the best alignment to the sample protein sequence is used as the predicted protein encoded by the input sequence. The output can be a feature table that can be used for sequence submission to GenBank (by Sequin or tbl2asn), a GenBank flat file, or the predicted protein sequences in FASTA format. A message showing the length of the input sequence, the predicted virus type, segment and subtype for the hemagglutinin and neuraminidase segments of Influenza A virus will also be displayed.	alignment;amino acid sequence;annotation;emoticon;fasta format;flat file database;genbank;herpesvirus 1, cercopithecine;influenza a virus;ncbi taxonomy;neuraminidase;nucleotides;orthomyxoviridae;peptide sequence;regulatory submission;server (computing);web server	Yīmíng Bào;Pavel Bolotov;Dmitry Dernovoy;Boris Kiryutin;Tatiana A. Tatusova	2007		10.1093/nar/gkm354	open reading frame;biology;nucleotide;the internet;bioinformatics;virology;protein sequencing;genotype;sequence alignment;sequence database;peptide sequence;computer graphics;genome project;genetics	Comp.	-1.7605872262022422	-59.90112619086137	148905
a5272d4862a124c617db067f36b75cc41476082a	large-scale analysis of conserved rare codon clusters suggests an involvement in co-translational molecular recognition events	software;codon;cluster analysis;proteins;bacteriophages;algorithms;bacteria;protein biosynthesis	MOTIVATION An increasing amount of evidence from experimental and computational analysis suggests that rare codon clusters are functionally important for protein activity. Most of the studies on rare codon clusters were performed on a limited number of proteins or protein families. In the present study, we present the Sherlocc program and how it can be used for large scale protein family analysis of evolutionarily conserved rare codon clusters and their relation to protein function and structure. This large-scale analysis was performed using the whole Pfam database covering over 70% of the known protein sequence universe. Our program Sherlocc, detects statistically relevant conserved rare codon clusters and produces a user-friendly HTML output.   RESULTS Statistically significant rare codon clusters were detected in a multitude of Pfam protein families. The most statistically significant rare codon clusters were predominantly identified in N-terminal Pfam families. Many of the longest rare codon clusters are found in membrane-related proteins which are required to interact with other proteins as part of their function, for example in targeting or insertion. We identified some cases where rare codon clusters can play a regulating role in the folding of catalytically important domains. Our results support the existence of a widespread functional role for rare codon clusters across species. Finally, we developed an online filter-based search interface that provides access to Sherlocc results for all Pfam families.   AVAILABILITY The Sherlocc program and search interface are open access and are available at http://bcb.med.usherbrooke.ca	amino acid sequence;clinical act of insertion;conserved sequence;genetic translation process;html;insertion mutation;interface device component;longest increasing subsequence;pfam;protein family;rare events;tissue membrane;usability	Matthieu Chartier;Francis Gaudreault;Rafael Najmanovich	2012	Bioinformatics	10.1093/bioinformatics/bts149	biology;molecular biology;codon usage bias;bacteria;bioinformatics;cluster analysis;genetic code;genetics;protein biosynthesis	Comp.	0.651764888130648	-59.23225699939248	148908
a78281f299555f69c1a1d1d487919572be33d489	molecular structure disassembly program (mosdap): a chemical information model to automate structure-based physical property estimation	information model;physical properties;molecular structure	Chemical information theory and molecular structure searching have long been used as computational aids to researchers in the pharmaceutical field to estimate molecular structure−property relationships and to assist in drug design. Tailored to these and other specific applications, such endeavors have been expensive to develop and typically are very specialized. Often, they are not readily available and are not a part of the open literature. Because the number of chemicals in commercial use is growing daily (with over 18 million molecular species now catalogued by Chemical Abstract Services), there is a need among engineers in the chemical process industries for predictive structure−property algorithms. The most common and useful methods are those based on group contribution that require only the chemical structure of interest. Unfortunately, each group contribution method typically has its own fragment library and specialized rules, making such models difficult to automate for general use by the engineer...	cheminformatics;disassembler;information model	John W. Raymond;Tony N. Rogers	1999	Journal of Chemical Information and Computer Sciences	10.1021/ci9803334	chemistry;molecule;information model;computer science;artificial intelligence;nanotechnology;physical property;algorithm;quantum mechanics	Theory	-1.5095780264715795	-62.245747077558995	149747
fd89d0969ed40a37e3de5dfae5c2a4c19170627b	flowcore: a bioconductor package for high throughput flow cytometry	software;drug discovery;database management systems;data management;clinical trial;data analysis methods;computational biology bioinformatics;high throughput screening;data analysis;complex data;analytical method;algorithms;user computer interface;combinatorial libraries;high throughput;computational biology;computer appl in life sciences;data structure;information storage and retrieval;flow cytometry;open source;microarrays;bioinformatics	Recent advances in automation technologies have enabled the use of flow cytometry for high throughput screening, generating large complex data sets often in clinical trials or drug discovery settings. However, data management and data analysis methods have not advanced sufficiently far from the initial small-scale studies to support modeling in the presence of multiple covariates. We developed a set of flexible open source computational tools in the R package flowCore to facilitate the analysis of these complex data. A key component of which is having suitable data structures that support the application of similar operations to a collection of samples or a clinical cohort. In addition, our software constitutes a shared and extensible research platform that enables collaboration between bioinformaticians, computer scientists, statisticians, biologists and clinicians. This platform will foster the development of novel analytic methods for flow cytometry. The software has been applied in the analysis of various data sets and its data structures have proven to be highly efficient in capturing and organizing the analytic work flow. Finally, a number of additional Bioconductor packages successfully build on the infrastructure provided by flowCore, open new avenues for flow data analysis.	bio-informatics;bioconductor;bioinformatics;bottleneck (software);compliance behavior;computation (action);computational biology;computational statistics;computer scientist;cytology;data structure;deploy;drug discovery;ferric carboxymaltose solution;flow cytometry;fuzzy cognitive map;hcs clustering algorithm;hl7publishingsubsection <operations>;home page;human placental lactogen;information sharing and analysis center;large;manuscripts;microsoft windows;national library of medicine (u.s.);netware loadable module;open-source software;operating system;organizing (structure);ph (complexity);programming languages;programming language;r language;requirement;residential gateway;revision procedure;software deployment;throughput;united states national institutes of health;unix;web site;web standards;research grants;standards characteristics	Florian Hahne;Nolwenn LeMeur;Ryan Remy Brinkman;Byron Ellis;Perry Haaland;Deepayan Sarkar;Josef Spidlen;Errol Strain;Robert Gentleman	2009	BMC Bioinformatics	10.1186/1471-2105-10-106	high-throughput screening;biology;data structure;data management;computer science;bioinformatics;data science;data mining;data analysis	SE	-4.395237826027623	-60.04392947262049	150286
71a55127438d3f80a836a78af2956d71943d2698	internet-based profiler system as integrative framework to support translational research	software;clinical data;database system;database management systems;databases genetic;relational database;image processing computer assisted;tumor markers biological;computational biology bioinformatics;internet;translational research;tissue microarray;algorithms;humans;molecular data;digital image;neoplasms;combinatorial libraries;biological markers;software design;computational biology;computer appl in life sciences;gene expression profiling;oligonucleotide array sequence analysis;programming languages;structure analysis;microarrays;bioinformatics;automation	Translational research requires taking basic science observations and developing them into clinically useful tests and therapeutics. We have developed a process to develop molecular biomarkers for diagnosis and prognosis by integrating tissue microarray (TMA) technology and an internet-database tool, Profiler. TMA technology allows investigators to study hundreds of patient samples on a single glass slide resulting in the conservation of tissue and the reduction in inter-experimental variability. The Profiler system allows investigator to reliably track, store, and evaluate TMA experiments. Here within we describe the process that has evolved through an empirical basis over the past 5 years at two academic institutions. The generic design of this system makes it compatible with multiple organ system (e.g., prostate, breast, lung, renal, and hematopoietic system,). Studies and folders are restricted to authorized users as required. Over the past 5 years, investigators at 2 academic institutions have scanned 656 TMA experiments and collected 63,311 digital images of these tissue samples. 68 pathologists from 12 major user groups have accessed the system. Two groups directly link clinical data from over 500 patients for immediate access and the remaining groups choose to maintain clinical and pathology data on separate systems. Profiler currently has 170 K data points such as staining intensity, tumor grade, and nuclear size. Due to the relational database structure, analysis can be easily performed on single or multiple TMA experimental results. The TMA module of Profiler can maintain images acquired from multiple systems. We have developed a robust process to develop molecular biomarkers using TMA technology and an internet-based database system to track all steps of this process. This system is extendable to other types of molecular data as separate modules and is freely available to academic institutions for licensing.	authorization documentation;biological markers;biological system;data point;digital image;experiment;extensibility;heart rate variability;hematopoietic system;internet;neoplasms;patients;profiling (computer programming);relational database;scanning;staining intensity;structure of parenchyma of lung;structured product labeling licensing terminology;therapeutic procedure;thrombotic microangiopathies;tissue microarray;tower mounted amplifier;translational research;body system	Robert Kim;Francesca Demichelis;Jeffery Tang;Alberto Riva;Ronglai Shen;Doug F. Gibbs;Vasudeva Mahavishno;Arul M. Chinnaiyan;Mark A. Rubin	2005	BMC Bioinformatics	10.1186/1471-2105-6-304	tissue microarray;the internet;dna microarray;relational database;computer science;bioinformatics;data science;software design;automation;data mining;structural analysis;gene expression profiling;translational research;digital image	Comp.	-2.0696072147891944	-62.54673863548788	150566
23fa4ec550878416e6be6d20dfdda5469954fa49	ytrp: a repository for yeast transcriptional regulatory pathways	transcription genetic;search engine;saccharomyces cerevisiae;databases genetic;genes fungal;internet;gene expression regulation fungal;user computer interface;nitrogen	Regulatory targets of transcription factors (TFs) can be identified by the TF perturbation experiments, which reveal the expression changes owing to the perturbation (deletion or overexpression) of TFs. But the identified targets of a given TF consist of both direct and indirect regulatory targets. It has been shown that most of the TFPE-identified regulatory targets are indirect, indicating that TF-gene regulation is mainly through transcriptional regulatory pathways (TRPs) consisting of intermediate TFs. Without identification of these TRPs, it is not easy to understand how a TF regulates its indirect targets. Because there is no such database depositing the potential TRPs for Saccharomyces cerevisiae now, this motivates us to construct the YTRP (Yeast Transcriptional Regulatory Pathway) database. For each TF-gene regulatory pair under different experimental conditions, all possible TRPs in two underlying networks (constructed using experimentally verified TF-gene binding pairs and TF-gene regulatory pairs from the literature) for the specified experimental conditions were automatically enumerated by TRP mining procedures developed from the graph theory. The enumerated TRPs of a TF-gene regulatory pair provide experimentally testable hypotheses for the molecular mechanisms behind a TF and its regulatory target. YTRP is available online at http://cosbi3.ee.ncku.edu.tw/YTRP/. We believe that the TRPs deposited in this database will greatly improve the usefulness of TFPE data for yeast biologists to study the regulatory mechanisms between a TF and its knocked-out targets. Database URL: http://cosbi3.ee.ncku.edu.tw/YTRP/.	access network;browsing;deletion mutation;experiment;gene expression regulation;gene regulatory network;graph theory;inference;national supercomputer centre in sweden;pik3r3 protein;scientific publication;transcription factor;transcription (software);transcription, genetic;transcriptional regulation;tryptophan;uniform resource locator;yeastract	Tzu-Hsien Yang;Chung-Ching Wang;Yu-Chao Wang;Wei-Sheng Wu	2014		10.1093/database/bau014	biology;the internet;computer science;bioinformatics;data mining;nitrogen;genetics;search engine	Comp.	-0.13689825813587395	-60.115745052986824	151558
a7d0610665b8c1040642f58b0599f395541884f5	anatomy ontologies and potential users: bridging the gap	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;data mining and knowledge discovery;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;bioinformatics	MOTIVATION To evaluate how well current anatomical ontologies fit the way real-world users apply anatomy terms in their data annotations.   METHODS Annotations from three diverse multi-species public-domain datasets provided a set of use cases for matching anatomical terms in two major anatomical ontologies (the Foundational Model of Anatomy and Uberon), using two lexical-matching applications (Zooma and Ontology Mapper).   RESULTS Approximately 1500 terms were identified; Uberon/Zooma mappings provided 286 matches, compared to the control and Ontology Mapper returned 319 matches. For the Foundational Model of Anatomy, Zooma returned 312 matches, and Ontology Mapper returned 397.   CONCLUSIONS Our results indicate that for our datasets the anatomical entities or concepts are embedded in user-generated complex terms, and while lexical mapping works, anatomy ontologies do not provide the majority of terms users supply when annotating data. Provision of searchable cross-products for compositional terms is a key requirement for using ontologies.	anatomic structures;bridging (networking);domain specific term;embedded system;embedding;entity;foundational model of anatomy;matching;numerous;ontology (information science);uberon;user-generated content	Ravensara S. Travillian;Tomasz Adamusiak;Tony Burdett;Michael Gruenberger;John M. Hancock;Ann-Marie Mallon;James Malone;Paul N. Schofield;Helen E. Parkinson	2011		10.1186/2041-1480-2-S4-S3	medical research;computer science;bioinformatics;data science;data mining;algorithm	Web+IR	-4.309686593314686	-63.852842985970234	151896
bcd8326dfa858cea7b42be5c39e1744b03fec2de	poster: distinguishing scientific abbreviations and genes in bio-medical literature mining	molecular biophysics biology computing cellular biophysics data mining dictionaries genetics;biology computing;electronic mail;gene recognition;text mining;false positive rates;gene identification;usa councils;data mining;genetics;scientific abbreviations;text mining text recognition humans electronic mail usa councils dictionaries natural language processing;gene identification text mining natural language processing abbreviation;official gene symbols;dictionaries;molecular biophysics;dictionary;false positive rates scientific abbreviations gene recognition biomedical literature mining text mining official gene symbols dictionary;humans;abbreviation;biomedical literature mining;text recognition;cellular biophysics;natural language processing	The accumulation of biomedical literature makes it increasingly difficult for scientists to keep up with scientific advancements, requiring the development of text mining tools to collect and integrate data in a high-throughput fashion. A major challenge in biomedical text mining is how to recognize genes sensitively and accurately, and translate them to their official gene symbols. Gene symbols and their commonly used aliases and synonyms usually derive from an abbreviation of the gene's description. However, many gene symbols and alias exactly match other abbreviations commonly used in scientific literature that do not refer to genes. A systematic study on the abbreviations used in biomedical literatures should help improve the accuracy of gene recognition during text mining.	biomedical text mining;british informatics olympiad;high-throughput computing;scientific literature;throughput;tree accumulation	Guozhen Liu;Han Zhang;George Quellhorst	2011	2011 IEEE 1st International Conference on Computational Advances in Bio and Medical Sciences (ICCABS)	10.1109/ICCABS.2011.5729906	natural language processing;text mining;computer science;bioinformatics;data science;data mining;rule-based machine translation;associative array;molecular biophysics	Visualization	-2.489015260775898	-64.06807654400485	152584
eb80b6f2df3bda7c34e9ef3bdfe05ba8af44ba0d	a snpshot of pubmed to associate genetic variants with drugs, diseases, and adverse reactions	databases;information extraction;text mining;pharmacogenomics	"""MOTIVATION Genetic factors determine differences in pharmacokinetics, drug efficacy, and drug responses between individuals and sub-populations. Wrong dosages of drugs can lead to severe adverse drug reactions in individuals whose drug metabolism drastically differs from the """"assumed average"""". Databases such as PharmGKB are excellent sources of pharmacogenetic information on enzymes, genetic variants, and drug response affected by changes in enzymatic activity. Here, we seek to aid researchers, database curators, and clinicians in their search for relevant information by automatically extracting these data from literature.   APPROACH We automatically populate a repository of information on genetic variants, relations to drugs, occurrence in sub-populations, and associations with disease. We mine textual data from PubMed abstracts to discover such genotype-phenotype associations, focusing on SNPs that can be associated with variations in drug response. The overall repository covers relations found between genes, variants, alleles, drugs, diseases, adverse drug reactions, populations, and allele frequencies. We cross-reference these data to EntrezGene, PharmGKB, PubChem, and others.   RESULTS The performance regarding entity recognition and relation extraction yields a precision of 90-92% for the major entity types (gene, drug, disease), and 76-84% for relations involving these types. Comparison of our repository to PharmGKB reveals a coverage of 93% of gene-drug associations in PharmGKB and 97% of the gene-variant mappings based on 180,000 PubMed abstracts.   AVAILABILITY http://bioai4core.fulton.asu.edu/snpshot."""	abstract summary;adverse reaction to drug;assumed;biocurator;cross-reference;database;dosage;gene frequency;mental association;parkinson disease;pharmgkb;pharmacogenomic analysis;population;pubchem;pubmed;relationship extraction;single nucleotide polymorphism;text corpus;drug metabolism;drug response	Jörg Hakenberg;Dmitry Voronov;Nguyen Ha Vo;Shanshan Liang;Saadat Anwar;Barry Lumpkin;Robert Leaman;Luis Tari;Chitta Baral	2012	Journal of biomedical informatics	10.1016/j.jbi.2012.04.006	natural language processing;text mining;medicine;computer science;bioinformatics;pharmacogenomics;data mining;information extraction	Comp.	-2.0779227526792754	-64.5401193096687	152663
23edb25cd54bddcdc9ee72135a664725802ec85a	immunogenetics sequence annotation: the strategy of imgt based on imgt-ontology	immunoglobulin;database;t cell receptor;antibody;sequence annotation;imgt;immunoinformatics;immunogenetics	IMGT, the international ImMunoGeneTics information system((R))(http://imgt.cines.fr) created in 1989, by the Laboratoire d'ImmunoGénétique Moléculaire (LIGM), Université Montpellier II and CNRS, Montpellier, France, is a high quality integrated information system, secialized in immunoglobulins (IG), T cell receptors (TR), major histocompatibility complex of human and other vertebrates and related proteins of the immune system that belong to the IgSF and Mhc superfamilies. IMGT/LIGM-DB, the first and the largest IMGT database, manages more than 92,000 IG and TR nucleotide sequences from human and 150 other vertebrate species in May 2005. IMGT/LIGM-DB provides expertly annotated sequences and standardized knowledge based on IMGT-ONTOLOGY, the first ontology for immunogenetics and immunoinformatics. The strategy developed by IMGT, for the IG and TR nucleotide sequence annotation, involves two different approaches that depend on the nature of the sequences, genomic DNA (gDNA) or complementary DNA (cDNA).	annotation;base sequence;cell signaling;computational immunology;dna, complementary;display resolution;genomic dna;ibm system r;immune system;immunogenetics;immunoglobulins;information system;ontology;t-cell receptor;transistor	Véronique Giudicelli;Denys Chaume;Joumana Jabado-Michaloud;Marie-Paule Lefranc	2005	Studies in health technology and informatics		data mining;immunogenetics;ontology;medicine;annotation;bioinformatics	Comp.	-1.8695274943506621	-61.852569211373364	153123
5793035a0357a784096b5bb981cef5d9b13ece71	spdbs: an sbml-based biochemical pathway database system	database system;visual simulation;signal transduction pathway;systems biology markup language;system biology;metabolic pathway;genome sequence	Biochemical pathways such as metabolic, regulatory, or signal transduction pathways can be viewed as a complicated network of interactions among molecular species in the cell. As the amount of pathway information for various organisms is increasing very rapidly, performing various analyses on the full network of pathways for even multiple organisms can be possible and therefore developing an integrated database for storing and analyzing pathway information is becoming a critical issue. However, analyzing these networks is not easy because of the nature of the existing pathway databases, which are often heterogeneous, incomplete, and/or inconsistent. To solve this problem, SBML(Systems Biology Markup Language) – a computer-readable format for representing various biochemical pathways – has been adopted by the most of the SW packages in systems biology. We developed an SBML-based Biochemical Pathway Database System (SPDBS) that supports (1) efficient integration of the heterogeneous and distributed pathway databases, (2) prediction of the metabolic pathways for a given (non-annotated) genome sequence, (3) dynamic visualization/ simulation of the pathways, (4) starting from the detailed pathway graph, build networks at different levels of representation, (5) imports/exports of SBML documents for the simulation and/or exchange of the biochemical pathways in various applications. To evaluate the system, we applied the system to the construction of pathways from its genome sequences. For the E. coli genome sequence, SPDBS estimates the same metabolic pathways as the original well-known E. coli pathway. We are applying our system to the pathway prediction of S. chungbukensis DJ77 and Vibrio vulnificus CMCP6.	database;gene regulatory network;sbml	Tae-Sung Jung;Kyoung-Ran Kim;Seung-Hyun Jung;Tae-Kyung Kim;Myung-Sang Ahn;Jong-Hak Lee;Wan-Sup Cho	2006		10.1007/11816102_58	biopax : biological pathways exchange;metabolic pathway;whole genome sequencing;small molecule pathway database;bioinformatics;data mining;systems biology;signal transduction	DB	-3.9505900075537066	-62.40225222214823	153279
a0d2fe8015d2821923391c72e7f682e85054096e	the naked mole rat genome resource: facilitating analyses of cancer and longevity-related adaptations	evolution molecular;genes;animals;genomics;female;mice;guinea pigs;longevity;medical biotechnology with a focus on cell biology including stem cell biology molecular biology microbiology biochemistry or biopharmacy;medicinsk bioteknologi med inriktning mot cellbiologi inklusive stamcellsbiologi molekylarbiologi mikrobiologi biokemi eller biofarmaci;journal article;genome;humans;sequence alignment;neoplasms;mole rats	MOTIVATION The naked mole rat (Heterocephalus glaber) is an exceptionally long-lived and cancer-resistant rodent native to East Africa. Although its genome was previously sequenced, here we report a new assembly sequenced by us with substantially higher N50 values for scaffolds and contigs.   RESULTS We analyzed the annotation of this new improved assembly and identified candidate genomic adaptations which may have contributed to the evolution of the naked mole rat's extraordinary traits, including in regions of p53, and the hyaluronan receptors CD44 and HMMR (RHAMM). Furthermore, we developed a freely available web portal, the Naked Mole Rat Genome Resource (http://www.naked-mole-rat.org), featuring the data and results of our analysis, to assist researchers interested in the genome and genes of the naked mole rat, and also to facilitate further studies on this fascinating species.	acclimatization;adaptation;annotation;cd44 antigens;eaf2 gene;hmmr wt allele;hyaluronan;mole rats;nevus	Michael Keane;Thomas Craig;Jessica Alföldi;Aaron M. Berlin;Jeremy Johnson;Andrei Seluanov;Vera Gorbunova;Federica Di Palma;Kerstin Lindblad-Toh;George M. Church;João Pedro de Magalhães	2014		10.1093/bioinformatics/btu579	biology;genomics;bioinformatics;gene;sequence alignment;genetics;genome	Comp.	1.1713917627318131	-61.59822653159558	153577
db2c13b9773b2196d0e6ac3c4955bb8aed9aedbb	cisred: a database system for genome-scale computational discovery of regulatory elements	animals;genomics;database system;response elements;databases nucleic acid;web accessibility;regulatory element;internet;promoter regions genetic;random sequence;user computer interface;high throughput;computational biology	We describe cisRED, a database for conserved regulatory elements that are identified and ranked by a genome-scale computational system (www.cisred.org). The database and high-throughput predictive pipeline are designed to address diverse target genomes in the context of rapidly evolving data resources and tools. Motifs are predicted in promoter regions using multiple discovery methods applied to sequence sets that include corresponding sequence regions from vertebrates. We estimate motif significance by applying discovery and post-processing methods to randomized sequence sets that are adaptively derived from target sequence sets, retain motifs with p-values below a threshold and identify groups of similar motifs and co-occurring motif patterns. The database offers information on atomic motifs, motif groups and patterns. It is web-accessible, and can be queried directly, downloaded or installed locally.	database;genome;high-throughput computing;motif;promoter regions, genetic;randomized algorithm;throughput;vertebrates;video post-processing	Gordon Robertson;Misha Bilenky;Keven Lin;An He;W. Yuen;M. Dagpinar;Richard Varhol;Kevin Teague;Obi L. Griffith;Xiangrong Zhang;Yu Pan;Maik Hassel;Monica C. Sleumer;W. Pan;Erin Pleasance;M. Chuang;H. Hao;Yvonne Y. Li;Neil Robertson;C. Fjell;Bernard Li;Stephen B. Montgomery;Tamara Astakhova	2006	Nucleic Acids Research	10.1093/nar/gkj075	high-throughput screening;biology;genomics;the internet;bioinformatics;random sequence;web accessibility;response element;genetics	DB	-0.8717480176678665	-59.13153645743591	153693
8ba91d866ac6e57c9cb853c27d4e056ce6ef484e	asap: automated sequence annotation pipeline for web-based updating of sequence information with a local dynamic database		The automated sequence annotation pipeline (ASAP) is designed to ease routine investigation of new functional annotations on unknown sequences, such as expressed sequence tags (ESTs), through querying of web-accessible resources and maintenance of a local database. The system allows easy use of the output from one search as the input for a new search, as well as the filtering of results. The database is used to store formats and parameters and information for parsing data from web sites. The database permits easy updating of format information should a site modify the format of a query or of a returned web page.	annotation;expressed sequence tags;license;parsing;web application;web page;format	Andrew V. Kossenkov;Frank J. Manion;Eugene V. Korotkov;Thomas D. Moloshok;Michael F. Ochs	2003	Bioinformatics	10.1093/bioinformatics/btg056	computer science;bioinformatics;data mining;database;world wide web	DB	-3.660402869273453	-59.42665241490202	154081
8a05a8a7ccaed0f6b19e530c1ab8c80a9ba05c08	improving the performance of domaindiscovery of protein domain boundary assignment using inter-domain linker index	software;protein function;position specific scoring matrix;protein domains;amino acid sequence;computational biology bioinformatics;protein structure;protein structure tertiary;multi domain;structural homology protein;secondary structure;indexation;background knowledge;algorithms;solvent accessibility;molecular sequence data;sequence alignment;support vector machine;combinatorial libraries;computer appl in life sciences;amino acid motifs;sequence analysis protein;databases protein;microarrays;bioinformatics	Knowledge of protein domain boundaries is critical for the characterisation and understanding of protein function. The ability to identify domains without the knowledge of the structure – by using sequence information only – is an essential step in many types of protein analyses. In this present study, we demonstrate that the performance of DomainDiscovery is improved significantly by including the inter-domain linker index value for domain identification from sequence-based information. Improved DomainDiscovery uses a Support Vector Machine (SVM) approach and a unique training dataset built on the principle of consensus among experts in defining domains in protein structure. The SVM was trained using a PSSM (Position Specific Scoring Matrix), secondary structure, solvent accessibility information and inter-domain linker index to detect possible domain boundaries for a target sequence. Improved DomainDiscovery is compared with other methods by benchmarking against a structurally non-redundant dataset and also CASP5 targets. Improved DomainDiscovery achieves 70% accuracy for domain boundary identification in multi-domains proteins. Improved DomainDiscovery compares favourably to the performance of other methods and excels in the identification of domain boundaries for multi-domain proteins as a result of introducing support vector machine with benchmark_2 dataset.	accessibility;algorithm;archive;bmc bioinformatics;bio-informatics;bourne shell;c shell;c++;casp5 gene;citrus junos;dppa3 wt allele;encephalitis virus, california;html link type - copyright;information and computer science;inter-domain;international conference on bioinformatics;linker (computing);manuscripts;neoplasms;numerous;paper;peer review;perl;philip bourne;position weight matrix;protein domain;pubmed central;stella;scientific publication;silo (dataset);support vector machine;citation;contents - htmllinktype;mecarzole	Abdur R. Sikder;Albert Y. Zomaya	2006	BMC Bioinformatics	10.1186/1471-2105-7-S5-S6	biology;support vector machine;protein structure;dna microarray;computer science;bioinformatics;sequence alignment;data mining;peptide sequence;protein domain;protein secondary structure	ML	-0.8057876883458345	-62.71599090500306	154276
006aad94c780ce88d48d556ae7e1f81cabcdea1d	event extraction for dna methylation	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;data mining and knowledge discovery;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;dna methylation;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;bioinformatics	BACKGROUND We consider the task of automatically extracting DNA methylation events from the biomedical domain literature. DNA methylation is a key mechanism of epigenetic control of gene expression and implicated in many cancers, but there has been little study of automatic information extraction for DNA methylation.   RESULTS We present an annotation scheme for DNA methylation following the representation of the BioNLP shared task on event extraction, select a set of 200 abstracts including a representative sample of all PubMed citations relevant to DNA methylation, and introduce manual annotation for this corpus marking nearly 3000 gene/protein mentions and 1500 DNA methylation and demethylation events. We retrain a state-of-the-art event extraction system on the corpus and find that automatic extraction of DNA methylation events, the methylated genes, and their methylation sites can be performed at 78% precision and 76% recall.   CONCLUSIONS Our results demonstrate that reliable extraction methods for DNA methylation events can be created through corpus annotation and straightforward retraining of a general event extraction system. The introduced resources are freely available for use in research from the GENIA project homepage http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA.	abstract summary;annotation;biomedical text mining;body of uterus;dna methylation [pe];gene expression;home page;information extraction;item unique identification;malignant neoplasms;pubmed;text corpus;citation;study of epigenetics	Tomoko Ohta;Sampo Pyysalo;Makoto Miwa;Jun'ichi Tsujii	2010		10.1186/2041-1480-2-S5-S2	bioinformatics;data science;rna-directed dna methylation;dna methylation;data mining;algorithm	NLP	-2.34423227734157	-64.03617226765493	156297
3163662297d50acb204c59dbdddbd37edd3c3211	the swiss-prot protein sequence data bank and its new supplement trembl	post translational modification;embl;animals;computer communication networks;genome fungal;protein sequence;genome plant;amino acid sequence;serveur institutionnel;nucleotide sequence;redundancy;proteins;archive institutionnelle;protein processing post translational;open access;genome bacterial;humans;archive ouverte unige;databases factual;cd rom;cybertheses;base sequence;systems integration;institutional repository;domain structure	SWISS-PROT is a curated protein sequence database which strives to provide a high level of annotation (such as the description of the function of a protein, its domain structure, post-translational modifications, variants, etc), a minimal level of redundancy and a high level of integration with other databases. Recent developments of the database include: an increase in the number and scope of model organisms; cross-references to seven additional databases; a variety of new documentation files; the creation of TREMBL, and unannotated supplement to SWISS-PROT. This supplement consists of entries in SWISS-PROT-like format derived from the translation of all coding sequences (CDS) in the EMBL nucleotide sequence database, except CDS already included in SWISS-PROT.	amino acid sequence;annotation;base sequence;clinical trial protocol document;cross-reference;documentation;genetic translation process;high-level programming language;nucleotides;open reading frames;peptide sequence;post-translational protein processing;published database;swiss-prot;sequence database;staphylococcal protein a;switzerland;uniprot	Amos Bairoch;Rolf Apweiler	1996	Nucleic acids research	10.1093/nar/24.1.21	biology;cd-rom;nucleic acid sequence;bioinformatics;protein sequencing;posttranslational modification;peptide sequence;redundancy;protein structure database;genetics;system integration	DB	-1.9062890878228236	-60.99909399136501	156548
768d7cf853f4508307444178f514d898dbda0931	designing and implementing chemoinformatic approaches in tdr targets database: linking genes to chemical compounds in tropical disease causing pathogens	computational biology bioinformatics;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	Background Information about chemical compounds and their activity against whole organisms or specific molecular targets is available from the literature or from specialized databases. However, there are few resources that effectively integrate such large chemical datasets with genome data and provide a mechanism to link active compounds to potential target genes. Here, we showcase the integration of chemoinformatic tools for querying chemical datasets and linking chemicals to genes in TDR Targets database (tdrtargets.org), a web accessible resource that integrates a wide range of functional genomic datasets from tropical disease pathogens and provides a ranking mechanism for identifying and prioritising novel therapeutic targets [1].	cheminformatics;database;information retrieval;tdr targets;time-domain reflectometer	María P. Magariños;John P. Overington;Santiago J. Carmona;Dhanasekaran Shanmugam;Maria A. Doyle;Stuart A. Ralph;Gregory J. Crowther;Christiane Hertz-Fowler;Solomon Nwaka;Matthew Berriman;David S. Roos;Wesley C. Van Voorhis;Fernán Agüero	2010	BMC Bioinformatics	10.1186/1471-2105-11-S10-O10	computational biology;biology;dna microarray;computer science;bioinformatics	Comp.	-1.8232130273573335	-62.21645052054764	156681
b867f6d80f3dfcc9266e3395939a637749de3fa6	using biobin to explore rare variant population stratification		Rare variants (RVs) will likely explain additional heritability of many common complex diseases; however, the natural frequencies of rare variation across and between human populations are largely unknown. We have developed a powerful, flexible collapsing method called BioBin that utilizes prior biological knowledge using multiple publicly available database sources to direct analyses. Variants can be collapsed according to functional regions, evolutionary conserved regions, regulatory regions, genes, and/or pathways without the need for external files. We conducted an extensive comparison of rare variant burden differences (MAF < 0.03) between two ancestry groups from 1000 Genomes Project data, Yoruba (YRI) and European descent (CEU) individuals. We found that 56.86% of gene bins, 72.73% of intergenic bins, 69.45% of pathway bins, 32.36% of ORegAnno annotated bins, and 9.10% of evolutionary conserved regions (shared with primates) have statistically significant differences in RV burden. Ongoing efforts include examining additional regional characteristics using regulatory regions and protein binding domains. Our results show interesting variant differences between two ancestral populations and demonstrate that population stratification is a pervasive concern for sequence analyses.	aggregate data;bin;cab direct (database);document completion status - documented;feature selection;gene frequency;gene regulatory network;genetic polymorphism;global health;imperative programming;interaction;large;nucleotides;one thousand;open regulatory annotation database;pervasive informatics;pierre robin syndrome;population;primates;regulatory sequences, nucleic acid;scientific publication;sequence analysis;single nucleotide polymorphism;statistical test;stratification	Carrie Moore;John R. Wallace;Alex T. Frase;Sarah A. Pendergrass;Marylyn DeRiggi Ritchie	2013	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		population stratification;heritability;genetic variation;bioinformatics;genomics;genetics;gene;allele frequency;intergenic region;1000 genomes project;biology	Comp.	2.0944772008060664	-61.49397827743644	156956
df212d5f814a75346ab54d72d58b4716c84ee13f	bioinformatics prediction and experimental validation of micrornas involved in cross-kingdom interaction	computational molecular biology;sequence analysis;microrna	MicroRNAs (miRNAs) are a class of small noncoding RNAs that act as efficient post-transcriptional regulators of gene expression. In 2012, the first cross-kingdom miRNA-based interaction had been evidenced, demonstrating that exogenous miRNAs act in a manner of mammalian functional miRNAs. Starting from this evidence, we defined the concept of cross-kingdom functional homology between plant and mammalian miRNAs as a needful requirement for vegetal miRNA to explicit a regulation mechanism into the host mammalian cell, comparable to the endogenous one. Then, we proposed a new dedicated algorithm to compare plant and mammalian miRNAs, searching for functional sequence homologies between them, and we developed a web software called MirCompare. We also predicted human genes regulated by the selected plant miRNAs, and we determined the role of exogenous miRNAs in the perturbation of intracellular interaction networks. Finally, as already performed by Pirrò and coworkers, the ability of MirCompare to select plant miRNAs with functional homologies with mammalian ones has been experimentally confirmed by evaluating the ability of mol-miR168a to downregulate the protein expression of SIRT1, when its mimic is transfected into human hepatoma cell line G2 (HEPG2) cells. This tool is implemented into a user-friendly web interface, and the access is free to public through the website http://160.80.35.140/MirCompare.	bioinformatics;cell (microprocessor);duoxa1 gene;experiment;gene expression;homologous gene;homology (biology);interface device component;leukemia, b-cell;mammals;micrornas;sequence homology;transcription, genetic;usability;user interface;web site;algorithm;protein expression	Stefano Pirrò;Antonella Minutolo;Andrea Galgani;Marina Potestà;Vittorio Colizzi;Carla Montesano	2016	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2016.0059	biology;molecular biology;bioinformatics;sequence analysis;genetics;microrna	Comp.	0.5875184787664197	-59.39413144040956	157344
312479e0886fd124148d164cc939759c6716bd43	large-scale extraction of gene interactions from full-text literature using deepdive	software;epistasis genetic;databases genetic;data mining;humans;data curation;information storage and retrieval	MOTIVATION A complete repository of gene-gene interactions is key for understanding cellular processes, human disease and drug response. These gene-gene interactions include both protein-protein interactions and transcription factor interactions. The majority of known interactions are found in the biomedical literature. Interaction databases, such as BioGRID and ChEA, annotate these gene-gene interactions; however, curation becomes difficult as the literature grows exponentially. DeepDive is a trained system for extracting information from a variety of sources, including text. In this work, we used DeepDive to extract both protein-protein and transcription factor interactions from over 100,000 full-text PLOS articles.   METHODS We built an extractor for gene-gene interactions that identified candidate gene-gene relations within an input sentence. For each candidate relation, DeepDive computed a probability that the relation was a correct interaction. We evaluated this system against the Database of Interacting Proteins and against randomly curated extractions.   RESULTS Our system achieved 76% precision and 49% recall in extracting direct and indirect interactions involving gene symbols co-occurring in a sentence. For randomly curated extractions, the system achieved between 62% and 83% precision based on direct or indirect interactions, as well as sentence-level and document-level precision. Overall, our system extracted 3356 unique gene pairs using 724 features from over 100,000 full-text articles.   AVAILABILITY AND IMPLEMENTATION Application source code is publicly available at https://github.com/edoughty/deepdive_genegene_app   CONTACT russ.altman@stanford.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	biogrid;bioinformatics;database;digital curation;extraction;extractors;forty nine;randomness extractor;source code;transcription factor;transcription (software);drug response;protein protein interaction	Emily K. Mallory;Ce Zhang;Christopher Ré;Russ B. Altman	2016		10.1093/bioinformatics/btv476	data curation;computer science;bioinformatics;data mining;information retrieval	Comp.	-2.25296636278115	-63.827465848446984	157417
007eb732972e68a0c1fcc8cb4c505ad9d589b185	parameciumdb in 2011: new tools and new data for functional and comparative genomics of the model ciliate paramecium tetraurelia	software;genomics;paramecium tetraurelia;databases genetic;proteomics;genome protozoan	ParameciumDB is a community model organism database built with the GMOD toolkit to integrate the genome and biology of the ciliate Paramecium tetraurelia. Over the last four years, post-genomic data from proteome and transcriptome studies has been incorporated along with predicted orthologs in 33 species, annotations from the community and publications from the scientific literature. Available tools include BioMart for complex queries, GBrowse2 for genome browsing, the Apollo genome editor for expert curation of gene models, a Blast server, a motif finder, and a wiki for protocols, nomenclature guidelines and other documentation. In-house tools have been developed for ontology browsing and evaluation of off-target RNAi matches. Now ready for next-generation deep sequencing data and the genomes of other Paramecium species, this open-access resource is available at http://paramecium.cgm.cnrs-gif.fr.	a51 antigen, paramecium tetraurelia;blast;biomart;deep sequencing;digital curation;genome;genomics;homology (biology);motif;ontology;protocols documentation;rodent nomenclature name;scientific literature;server (computing);transcriptome;wiki	Olivier Arnaiz;Linda Sperling	2011		10.1093/nar/gkq918	biology;genomics;bioinformatics;proteomics;genetics	Comp.	-1.5352635447456489	-59.75669781497697	157564
4cc9911b4cd34d53f0e558a2f42931a790223873	locomotif: a graphical programming system for rna motif search		"""Acknowledgments I thank my supervisor, Robert Giegerich, for providing me with an interesting research topic and for his support throughout the years, both scientifically, as well as by offering me the chance to continue my work while taking care of my daughter. Thanks also to Jens Stoye for appraising this thesis. I thank Peter Steffen who developed the ADP compiler that is an integral part of the Locomotif system and adapted it for my needs. I thank Jan Krüger for help in installing the system on the webserver and for guidance in XML and Java questions. Nan Zhang gave me a headstart on the XML schema. I appreciate the financial support from the DFG. I enjoyed being part of the GK Bioin-formatik and value travel opportunities and scientific merit of the BREW workshops in Helsinki and Berlin. I thank Jens Reeder for many ideas, discussions, hours spent debugging the Locomotif system and proofreading this thesis, but most of all for his enduring emotional support over all these years. I am deeply grateful for my daughter Emma. Finally, I thank my parents for all their support and patience. Gedruckt auf alterungsbeständigem Papier • • ISO 9706 Parts of this thesis are taken from an earlier work [RG06]: A graphical programming system for molecular motif search. Introduction The field of computational biology is characterized by the need to combine substantial knowledge from computer science and molecular biology. Sophisticated algorithmics are required to handle the large data volume and the elaborated biological models e. g. in whole genome comparison, gene structure prediction or simulation of metabolic processes. Deep knowledge from domain experts is required to choose the right questions to ask and to interpret the results. There has been a paradigm shift in molecular biology recently. Three types of chain molecules form the basis of life: deoxy-ribonucleic acid (DNA), ribonucleic acid (RNA), and proteins. The long-lasting """" dogma """" of molecular biology saw DNA as the prime source of genetic information, stored in the well-known double helix. RNA was mainly seen as an intermediate carrier, a single stranded molecule bringing genetic information from the DNA to the cell's translational machinery. There, the proteins are synthesized as chains of amino acids, according to the universal genetic code. Proteins were seen as the exclusive actors in both the cell metabolism and its regulation. Recent findings have overturned this view. It has become apparent that RNA …"""	acid;admissible numbering;algorithmics;care-of address;compiler;computation;computational biology;computer science;debugging;emma;floor and ceiling functions;jan bergstra;java;motif;nan;programming paradigm;simulation;subject-matter expert;usb on-the-go;visual programming language;web server;whole earth 'lectronic link;xml schema	Janina Reeder	2006				Comp.	-0.03878953617585546	-65.42426101149712	158234
f83ae97c32fbca52a16a111b62c0588c73f7add2	integrating protein structures and precomputed genealogies in the magnum database: examples with cellular retinoid binding proteins	evolution molecular;retinol binding proteins;protein family;retinol binding proteins cellular;database management systems;protein sequence;amino acid sequence;ligand binding;binding sites;models chemical;structural bioinformatics;computational biology bioinformatics;full length;protein structure;large scale;amino acid replacement;protein conformation;phylogenetic tree;protein binding;algorithms;crystal structure;molecular sequence data;sequence alignment;multiple sequence alignment;binding protein;experimental research;nucleotide substitution;combinatorial libraries;pedigree;computer appl in life sciences;computer simulation;information storage and retrieval;sequence analysis protein;cellular retinol binding protein;structured data;databases protein;microarrays;bioinformatics	When accurate models for the divergent evolution of protein sequences are integrated with complementary biological information, such as folded protein structures, analyses of the combined data often lead to new hypotheses about molecular physiology. This represents an excellent example of how bioinformatics can be used to guide experimental research. However, progress in this direction has been slowed by the lack of a publicly available resource suitable for general use. The precomputed Magnum database offers a solution to this problem for ca. 1,800 full-length protein families with at least one crystal structure. The Magnum deliverables include 1) multiple sequence alignments, 2) mapping of alignment sites to crystal structure sites, 3) phylogenetic trees, 4) inferred ancestral sequences at internal tree nodes, and 5) amino acid replacements along tree branches. Comprehensive evaluations revealed that the automated procedures used to construct Magnum produced accurate models of how proteins divergently evolve, or genealogies, and correctly integrated these with the structural data. To demonstrate Magnum's capabilities, we asked for amino acid replacements requiring three nucleotide substitutions, located at internal protein structure sites, and occurring on short phylogenetic tree branches. In the cellular retinoid binding protein family a site that potentially modulates ligand binding affinity was discovered. Recruitment of cellular retinol binding protein to function as a lens crystallin in the diurnal gecko afforded another opportunity to showcase the predictive value of a browsable database containing branch replacement patterns integrated with protein structures. We integrated two areas of protein science, evolution and structure, on a large scale and created a precomputed database, known as Magnum, which is the first freely available resource of its kind. Magnum provides evolutionary and structural bioinformatics resources that are useful for identifying experimentally testable hypotheses about the molecular basis of protein behaviors and functions, as illustrated with the examples from the cellular retinoid binding proteins.	amino acid sequence;amino acids;behavior;circa;crystal structure;evaluation;experiment;gecko;inference;ligand binding;ligands;mips magnum;modulation;nucleotides;peptide sequence;phylogenetic tree;phylogenetics;precomputation;processor affinity;protein data bank;protein family;retinoids;retinol binding proteins;retinol-binding proteins, cellular;sequence alignment;structural bioinformatics;surgical replantation;systems biology;trees (plant);vitamin a;physiological aspects;retinoid binding	Michael E. Bradley;Steven A. Benner	2005	BMC Bioinformatics	10.1186/1471-2105-7-89	computer simulation;biology;protein structure;molecular biology;computer science;bioinformatics;genetics	Comp.	1.758678507865427	-59.7379243017186	158394
8c260c98598ffbe78a11c82730c179a056673ac2	visualisation of influenza a protein segments in distance invariant self-organising map	influenza a;avian influenza;phylogenetic tree;distance invariant manifold;lateral gene transfer;h1n1;tree of life;h5n1;mutation;information visualisation;self organising map	Due to the lateral gene transfer, the phylogenetic tree could be inadequate for representing the evolution of virus. This paper employs the distance invariant manifold (Cheng and Liou, 2009) to display the collection of influenza A in a cubic space. This space provides a global view of the evolution of the whole family vividly.		Wei-Chen Cheng;Cheng-Yuan Liou	2012	IJIIDS	10.1504/IJIIDS.2012.045116	mutation;phylogenetic tree;information visualization;influenza a virus subtype h5n1;bioinformatics;horizontal gene transfer;tree of life	Robotics	1.538625552666364	-63.37214833870288	159537
1a0e2e9440e55c01c71ff4c5fb6b3dda59f23282	the curation of genetic variants: difficulties and possible solutions	automated curation;manual curation;difficulties in curation;interpretation of variants	The curation of genetic variants from biomedical articles is required for various clinical and research purposes. Nowadays, establishment of variant databases that include overall information about variants is becoming quite popular. These databases have immense utility, serving as a user-friendly information storehouse of variants for information seekers. While manual curation is the gold standard method for curation of variants, it can turn out to be time-consuming on a large scale thus necessitating the need for automation. Curation of variants described in biomedical literature may not be straightforward mainly due to various nomenclature and expression issues. Though current trends in paper writing on variants is inclined to the standard nomenclature such that variants can easily be retrieved, we have a massive store of variants in the literature that are present as non-standard names and the online search engines that are predominantly used may not be capable of finding them. For effective curation of variants, knowledge about the overall process of curation, nature and types of difficulties in curation, and ways to tackle the difficulties during the task are crucial. Only by effective curation, can variants be correctly interpreted. This paper presents the process and difficulties of curation of genetic variants with possible solutions and suggestions from our work experience in the field including literature support. The paper also highlights aspects of interpretation of genetic variants and the importance of writing papers on variants following standard and retrievable methods.	amino acids;bio-informatics;bioinformatics;circuit complexity;database;databases;digital curation;genetic screening method;hgnc;hugo gene nomenclature committee;imperative programming;journal;online search;paper;prospective search;rodent nomenclature name;sensitivity and specificity;solutions;usability;web search engine;interest	Kapil Raj Pandey;Narendra Maden;Barsha Poudel;Sailendra Pradhananga;Amit Kumar Sharma	2012		10.1016/j.gpb.2012.06.006	data curation;bioinformatics;data science;data mining	SE	-2.3098085272482787	-64.01361748150026	159614
4a72c6e9d068d08898db8c4195846d858d43281c	geference: reference database for construing personal genome expression		With the lowering cost and the increasing discoveries, genomics research filed has materialized personal genome era. Especially, microarray gene expression platform has already made several success stories for prognosis/diagnosis in medical contexts. However, the genome expression profiles, although having extensive information, still not be used in usual clinical context due to its complexity. In this study, we developed a reference database system, GEFERENCE, a searchable space for personal genome expression profiles by reorganizing patient centric genome expression and clinical information extracted from public data repository, GEO. We assembled total 34,745 patient’s gene expression data from the 28 different tissue types with corresponding clinical information. And we manually curate the relation of information among individual patient, gene expression data, and clinical information by tight collaboration with clinicians. With GEFERENCE, clinician or medical service provider could search genome expression profiles of patients and get insight for relevant decision making.	bibliographic database;information privacy;microarray;research data archiving	Changwon Keum;Ju Han Kim;Young Soo Song;Kyoung Tai No;Jung Hoon Woo	2009			genomics;service provider;gene expression;genome;database;information repository;personal genomics;biology;microarray;bioinformatics	Comp.	-3.3196658363763234	-63.91075482051208	159757
54c65d1cb01e6c0eabc785d6111a49db8992f51e	dbtbs: a database of transcriptional regulation in bacillus subtilis containing upstream intergenic conservation information	genes;genomics;gram positive bacteria;dna bacterial;oncogenes;dna intergenic;databases genetic;transcription factors;binding sites;bacillus subtilis;conserved sequence;transcription regulation;internet;promoter regions genetic;gene expression regulation bacterial;transcription factor;genome bacterial;experimental validation;operon;regulatory elements transcriptional;sequence alignment;bacterial genome;transcriptional control;base sequence;gram positive	DBTBS, first released in 1999, is a reference database on transcriptional regulation in Bacillus subtilis, summarizing the experimentally characterized transcription factors, their recognition sequences and the genes they regulate. Since the previous release, the original content was extended by the addition of the data contained in 569 new publications, the total of which now reaches 947. The number of B. subtilis promoters annotated in the database was more than doubled to 1475. In addition, 463 experimentally validated B. subtilis operons and their terminators have been included. Given the increase in the number of fully sequenced bacterial genomes, we decided to extend the usability of DBTBS in comparative regulatory genomics. We therefore created a new section on the conservation of the upstream regulatory sequences between homologous genes in 40 Gram-positive bacterial species, as well as on the presence of overrepresented hexameric motifs that may have regulatory functions. DBTBS can be accessed at: http://dbtbs.hgc.jp.	bibliographic database;contain (action);ethanol 0.62 ml/ml topical gel;experiment;genome;operon;sequence motif;transcription factor;transcription (software);transcription, genetic;transcriptional regulation;usability;user-generated content;promoter	Nicolas Sierro;Yuko Makita;Michiel J. L. de Hoon;Kenta Nakai	2008		10.1093/nar/gkm910	biology;genomics;molecular biology;bioinformatics;genetics;transcriptional regulation;transcription factor	Comp.	-0.0716794149727276	-60.05365271636937	159894
b697b39e96cf679c4019ebe2ee456d36adfb82e1	the nih bd2k center for big data in translational genomics	genomics;computational genomics;genome informatics;big data;apis	The world's genomics data will never be stored in a single repository - rather, it will be distributed among many sites in many countries. No one site will have enough data to explain genotype to phenotype relationships in rare diseases; therefore, sites must share data. To accomplish this, the genetics community must forge common standards and protocols to make sharing and computing data among many sites a seamless activity. Through the Global Alliance for Genomics and Health, we are pioneering the development of shared application programming interfaces (APIs) to connect the world's genome repositories. In parallel, we are developing an open source software stack (ADAM) that uses these APIs. This combination will create a cohesive genome informatics ecosystem. Using containers, we are facilitating the deployment of this software in a diverse array of environments. Through benchmarking efforts and big data driver projects, we are ensuring ADAM's performance and utility.		Benedict Paten;Mark Diekhans;Brian J. Druker;Stephen H. Friend;Justin Guinney;Nadine Gassner;Mitchell Guttman;W. James Kent;Patrick Mantey;Adam A. Margolin;Matt Massie;Adam M. Novak;Frank A. Nothaft;Lior Pachter;David A. Patterson;Maciej Smuga-Otto;Joshua M. Stuart;Laura J. van't Veer	2015	Journal of the American Medical Informatics Association : JAMIA	10.1093/jamia/ocv047	genomics;big data;application programming interface;computer science;bioinformatics;data science;data mining;database;computational genomics	HCI	-4.169014322727674	-60.5543092192083	160015
8140badfa4644fcb946cc44c2dcaff49ff0238ed	bbp: brucella genome annotation with literature mining and curation	software;genomics;management system;genome annotation;databases bibliographic;gene mutation;virulence;brucella;databases genetic;genetics;computational biology bioinformatics;keyword search;genome;genome bacterial;discussion forum;gram negative;algorithms;experimental validation;computer analysis;combinatorial libraries;computational biology;genes bacterial;computer appl in life sciences;natural language processing;mutation;programming languages;microarrays;bioinformatics	Brucella species are Gram-negative, facultative intracellular bacteria that cause brucellosis in humans and animals. Sequences of four Brucella genomes have been published, and various Brucella gene and genome data and analysis resources exist. A web gateway to integrate these resources will greatly facilitate Brucella research. Brucella genome data in current databases is largely derived from computational analysis without experimental validation typically found in peer-reviewed publications. It is partially due to the lack of a literature mining and curation system able to efficiently incorporate the large amount of literature data into genome annotation. It is further hypothesized that literature-based Brucella gene annotation would increase understanding of complicated Brucella pathogenesis mechanisms. The Brucella Bioinformatics Portal (BBP) is developed to integrate existing Brucella genome data and analysis tools with literature mining and curation. The BBP InterBru database and Brucella Genome Browser allow users to search and analyze genes of 4 currently available Brucella genomes and link to more than 20 existing databases and analysis programs. Brucella literature publications in PubMed are extracted and can be searched by a TextPresso-powered natural language processing method, a MeSH browser, a keywords search, and an automatic literature update service. To efficiently annotate Brucella genes using the large amount of literature publications, a literature mining and curation system coined Limix is developed to integrate computational literature mining methods with a PubSearch-powered manual curation and management system. The Limix system is used to quickly find and confirm 107 Brucella gene mutations including 75 genes shown to be essential for Brucella virulence. The 75 genes are further clustered using COG. In addition, 62 Brucella genetic interactions are extracted from literature publications. These results make possible more comprehensive investigation of Brucella pathogenesis. Other BBP features include publication email alert service, Brucella researchers' contact database, and discussion forum. BBP is a gateway for Brucella researchers to search, analyze, and curate Brucella genome data originated from public databases and literature. Brucella gene mutations and genetic interactions are annotated using Limix leading to better understanding of Brucella pathogenesis.	best practice;bioinformatics;brucella abortus;brucellosis;cog (project);database;databases;digital curation;email;extraction;gene annotation;gene ontology;genome;how true feel alert right now;interaction;natural language processing;power (psychology);pubmed;scientific publication;virulence	Zuoshuang Xiang;Wenjie Zheng;Yongqun He	2006	BMC Bioinformatics	10.1186/1471-2105-7-347	mutation;biology;genomics;dna microarray;bioinformatics;virulence;management system;genome project;genetics;genome	Comp.	-2.176192088049825	-63.58086274471695	161601
e9aa73e88af0e2d8b8aff0f5efc3af4aa13df826	prgdb 2.0: towards a community-based database model for the analysis of r-genes in plants	genes;community;pathogenic organism;host organism;plants;resistance genes;technology;genome plant;semantics;databases genetic;immunity natural;models genetic;internet;genes vpr;genes plant;disease resistance	The Plant Resistance Genes database (PRGdb; http://prgdb.org) is a comprehensive resource on resistance genes (R-genes), a major class of genes in plant genomes that convey disease resistance against pathogens. Initiated in 2009, the database has grown more than 6-fold to recently include annotation derived from recent plant genome sequencing projects. Release 2.0 currently hosts useful biological information on a set of 112 known and 104 310 putative R-genes present in 233 plant species and conferring resistance to 122 different pathogens. Moreover, the website has been completely redesigned with the implementation of Semantic MediaWiki technologies, which makes our repository freely accessed and easily edited by any scientists. To this purpose, we encourage plant biologist experts to join our annotation effort and share their knowledge on resistance-gene biology with the rest of the scientific community.	annotation;database model;disease resistance;genome, plant;mediawiki;plant physiological phenomena;web site;whole genome sequencing	Walter Sanseverino;Antonio Hermoso;Raffaella D'Alessandro;Anna V. Vlasova;Giuseppe Andolfo;Luigi Frusciante;Ernesto Lowy;Guglielmo Roma;Maria Raffaella Ercolano	2013		10.1093/nar/gks1183	biology;community;biotechnology;bioinformatics;semantics;genetics;technology	Comp.	-1.800365544927858	-61.56398469607331	161780
ef59ef847e2cdbfcdd0ab798c6cd911546b4facb	gtc: a web server for integrating systems biology data with web tools and desktop applications	health research;uk clinical guidelines;biological patents;europe pubmed central;integrable system;citation search;computational biology bioinformatics;uk phd theses thesis;life sciences;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;bioinformatics	Gaggle Tool Creator (GTC) is a web application which provides access to public annotation, interaction, orthology, and genomic data for hundreds of organisms, and enables instant analysis of the data using many popular web-based and desktop applications.	annotation;creator report number:id:pt:form:nom:vaers;desktop computer;extensible authentication protocol;server (computer);server (computing);systems biology;web application;web server	Dan Tenenbaum;J. Christopher Bare;Nitin S. Baliga	2010		10.1186/1751-0473-5-7	biology;integrable system;computer science;bioinformatics;data science;world wide web	Web+IR	-3.675617032235171	-59.784057402470026	162131
0502bfb3e1af7b15525ae6771781a1d6cbc70d2e	genomic variability within an organism exposes its cell lineage tree	animals;genomics;caenorhabditis elegans;somatic mutation;models theoretical;mutation rate;mathematical analysis;embryos;genetics;genetic variation;stem cell;models genetic;microsatellite repeats;infant newborn;genome;cell lineage;developmental biology;genes plant;humans;proteomics;computational biology;mutation;cell line	"""What is the lineage relation among the cells of an organism? The answer is sought by developmental biology, immunology, stem cell research, brain research, and cancer research, yet complete cell lineage trees have been reconstructed only for simple organisms such as Caenorhabditis elegans. We discovered that somatic mutations accumulated during normal development of a higher organism implicitly encode its entire cell lineage tree with very high precision. Our mathematical analysis of known mutation rates in microsatellites (MSs) shows that the entire cell lineage tree of a human embryo, or a mouse, in which no cell is a descendent of more than 40 divisions, can be reconstructed from information on somatic MS mutations alone with no errors, with probability greater than 99.95%. Analyzing all approximately 1.5 million MSs of each cell of an organism may not be practical at present, but we also show that in a genetically unstable organism, analyzing only a few hundred MSs may suffice to reconstruct portions of its cell lineage tree. We demonstrate the utility of the approach by reconstructing cell lineage trees from DNA samples of a human cell line displaying MS instability. Our discovery and its associated procedure, which we have automated, may point the way to a future """"Human Cell Lineage Project"""" that would aim to resolve fundamental open questions in biology and medicine by reconstructing ever larger portions of the human cell lineage tree."""	control theory;diploid cell;encode (action);heart rate variability;immunology;instability;language development disorders;large;lineage (evolution);mathematics;short tandem repeat;somatic mutation;stem cell research;stem cells;trees (plant);unstable medical device problem	Dan Frumkin;Adam Wasserstrom;Shai Kaplan;Uriel Feige;Ehud Shapiro	2005	PLoS Computational Biology	10.1371/journal.pcbi.0010050	mutation;biology;mutation rate;embryo;genomics;stem cell;germline mutation;bioinformatics;genetic variation;developmental biology;proteomics;genetics;cell culture;genome	Comp.	2.5889389880341884	-61.958155886010175	162348
0b4931aa352c228f1549e8791e18a534d1b8f8c8	issues in developing integrated genomic databases and application to the human x chromosome	base integrada dato;computerized processing;tratamiento informatico;mapa fisico;hombre;human;carte physique;integrated database;x chromosome;traitement informatique;cromosoma x;chromosome x;physical map;homme;base donnee integree	MOTIVATION In the past decade, a vast amount of mapping data has been generated on the human X chromosome, without a mechanism which would provide a global view of exactly what has been achieved. Large datasets are available electronically, but in heterogeneous formats and with incompatible access modes. In addition, relationships between objects in different datasets are often not specified.   RESULTS We discuss the problem of integrating these data into one database and define a number of requirements that are vital for any integration approach. We have developed IXDB, the Integrated X chromosome database, which fulfils those requirements and aims at providing a global view on genomic data at a chromosomal level. IXDB represents a conceptual framework based on identifying, storing and analysing relationships between biological objects, and includes a series of tools to automate the integration of such information. It currently focuses on physical mapping data, as a starting point towards a map of the human X chromosome that should provide a uniform and global research resource for ongoing and future sequencing and functional studies.   AVAILABILITY IXDB is available at http://ixdb.mpimg-berlin-dahlem.mpg.de. The iace2ixdb software and a description of the Iace data format are available from the authors.   CONTACT hrc@genoscope.cns.fr	biopolymer sequencing;congenital chromosomal disease;database;genetic heterogeneity;requirement;format;negative regulation of nms complex assembly involved in kinetochore assembly	Ulf Leser;Hans Lehrach;Hugues Roest Crollius	1998	Bioinformatics	10.1093/bioinformatics/14.7.583	biology;bioinformatics;data mining;genetics;x chromosome	DB	-4.4334478130404165	-61.1800308578248	162448
6333f40294ec04ed00f49eab00246cf1f25292f1	yapoptosis: yeast apoptosis database	apoptosis;saccharomyces cerevisiae;systems biology;gene regulatory networks;complexes;genes fungal;internet;genome;atlas;databases as topic;humans;user computer interface;programmed cell death;protein interaction networks	In the past few years, programmed cell death (PCD) has become a popular research area due to its fundamental aspects and its links to human diseases. Yeast has been used as a model for studying PCD, since the discovery of morphological markers of apoptotic cell death in yeast in 1997. Increasing knowledge in identification of components and molecular pathways created a need for organization of information. To meet the demands from the research community, we have developed a curated yeast apoptosis database, yApoptosis. The database structurally collects an extensively curated set of apoptosis, PCD and related genes, their genomic information, supporting literature and relevant external links. A web interface including necessary functions is provided to access and download the data. In addition, we included several networks where the apoptosis genes or proteins are involved, and present them graphically and interactively to facilitate rapid visualization. We also promote continuous inputs and curation by experts. yApoptosis is a highly specific resource for sharing information online, which supports researches and studies in the field of yeast apoptosis and cell death. DATABASE URL: http://www.ycelldeath.com/yapoptosis/.	access network;aging;apoptosis;autophagy;bio-informatics;bioinformatics;cell (microprocessor);cell death;cessation of life;channel (communications);communications media;computation;database;digital curation;download;dynamic programming;imagery;interactivity;interface device component;kartagener syndrome;knowledge organization;necrosis;process-centered design;protocols documentation;uniform resource locator;usability;user interface	Kwanjeera Wanichthanarak;Marija Cvijovic;Andrea Molt;Dina Petranovic	2013		10.1093/database/bat068	programmed cell death;biology;gene regulatory network;the internet;bioinformatics;apoptosis;atlas;data mining;world wide web;genetics;systems biology;genome	Comp.	-1.259273912431585	-61.448706399070055	162726
57db9cc0ab228ab055351f92a06cb6adfe7c1c69	comppi: a cellular compartment-specific database for protein–protein interaction network analysis	animals;cell compartmentation;internet;proteins;humans;protein interaction mapping;databases protein	Here we present ComPPI, a cellular compartment-specific database of proteins and their interactions enabling an extensive, compartmentalized protein-protein interaction network analysis (URL: http://ComPPI.LinkGroup.hu). ComPPI enables the user to filter biologically unlikely interactions, where the two interacting proteins have no common subcellular localizations and to predict novel properties, such as compartment-specific biological functions. ComPPI is an integrated database covering four species (S. cerevisiae, C. elegans, D. melanogaster and H. sapiens). The compilation of nine protein-protein interaction and eight subcellular localization data sets had four curation steps including a manually built, comprehensive hierarchical structure of >1600 subcellular localizations. ComPPI provides confidence scores for protein subcellular localizations and protein-protein interactions. ComPPI has user-friendly search options for individual proteins giving their subcellular localization, their interactions and the likelihood of their interactions considering the subcellular localization of their interacting partners. Download options of search results, whole-proteomes, organelle-specific interactomes and subcellular localization data are available on its website. Due to its novel features, ComPPI is useful for the analysis of experimental results in biochemistry and molecular biology, as well as for proteome-wide studies in bioinformatics and network science helping cellular biology, medicine and drug design.	anatomical compartments;bioinformatics;compiler;cytology;digital curation;download;interaction network;interactome;molecular biology;multi-compartment model;network science;proteome;saccharomyces cerevisiae;uniform resource locator;usability;web site;protein protein interaction	Daniel V. Veres;Dávid M. Gyurkó;Benedek Thaler;Kristof Z. Szalay;Dávid Fazekas;Tamás Korcsmáros;Péter Csermely	2015		10.1093/nar/gku1007	biology;the internet;cell biology;bioinformatics	Comp.	0.3008356117306695	-60.05836181058745	162811
8ae7993aa7d0328d06ec47eda0180b566fdb07ff	opengenemed: a portable, flexible and customizable informatics hub for the coordination of next-generation sequencing studies in support of precision medicine trials	clinical trial management system;genomics;next-generation sequencing;open source software;precision medicine	Trials involving genomic-driven treatment selection require the coordination of many teams interacting with a great variety of information. The need of better informatics support to manage this complex set of operations motivated the creation of OpenGeneMed. OpenGeneMed is a stand-alone and customizable version of GeneMed (Zhao et al. GeneMed: an informatics hub for the coordination of next-generation sequencing studies that support precision oncology clinical trials. Cancer Inform 2015;14(Suppl 2):45), a web-based interface developed for the National Cancer Institute Molecular Profiling-based Assignment of Cancer Therapy (NCI-MPACT) clinical trial coordinated by the NIH. OpenGeneMed streamlines clinical trial management and it can be used by clinicians, lab personnel, statisticians and researchers as a communication hub. It automates the annotation of genomic variants identified by sequencing tumor DNA, classifies the actionable mutations according to customizable rules and facilitates quality control in reviewing variants. The system generates summarized reports with detected genomic alterations that a treatment review team can use for treatment assignment. OpenGeneMed allows collaboration to happen seamlessly along the clinical pipeline; it helps reduce errors made transferring data between groups and facilitates clear documentation along the pipeline. OpenGeneMed is distributed as a stand-alone virtual machine, ready for deployment and use from a web browser; its code is customizable to address specific needs of different clinical trials and research teams. Examples on how to change the code are provided in the technical documentation distributed with the virtual machine. In summary, OpenGeneMed offers an initial set of features inspired by our experience with GeneMed, a system that has been proven to be efficient and successful for coordinating the application of next-generation sequencing in the NCI-MPACT trial.	annotation;biopolymer sequencing;deploy;hl7publishingsubsection <operations>;heparin, low-molecular-weight;informatics (discipline);interaction;internet;massively-parallel sequencing;mutation;nc (complexity);nci thesaurus;neoplasms;precision medicine;review [publication type];rule (guideline);technical documentation;usb hub;virtual machine;web application;teams	Alida Palmisano;Yingdong Zhao;Ming-Chung Li;Eric C. Polley;Richard M. Simon	2017	Briefings in bioinformatics	10.1093/bib/bbw059	bioinformatics;data mining	HCI	-4.212297673025127	-60.416617733758066	163156
c91aff2a3ad6a1f560ce3f21838eced2df408c53	biddsat: visualizing the content of biodiversity data publishers in the global biodiversity information facility network	materias investigacion ciencias medioambientales biodiversidad;info eu repo semantics article	UNLABELLED In any data quality workflow, data publishers must become aware of issues in their data so these can be corrected. User feedback mechanisms provide one avenue, while global assessments of datasets provide another. To date, there is no publicly available tool to allow both biodiversity data institutions sharing their data through the Global Biodiversity Information Facility network and its potential users to assess datasets as a whole. Contributing to bridge this gap both for publishers and users, we introduce BIoDiversity DataSets Assessment Tool, an online tool that enables selected diagnostic visualizations on the content of data publishers and/or their individual collections.   AVAILABILITY AND IMPLEMENTATION The online application is accessible at http://www.unav.es/unzyec/mzna/biddsat/ and is supported by all major browsers. The source code is licensed under the GNU GPLv3 license (http://www.gnu.org/licenses/gpl-3.0.txt) and is available at https://github.com/jotegui/BIDDSAT.	biodiversity informatics;collections (publication);data quality;evaluation procedure;gnu;source code;web application	Javier Otegui;Arturo H. Ariño	2012	Bioinformatics	10.1093/bioinformatics/bts359	biology;computer science;bioinformatics;data mining;database;world wide web	HPC	-3.199153058827765	-60.94372749370732	163870
4eef11a839f88ec2792351b5d9a0c430c0c1496e	weblab: a data-centric, knowledge-sharing bioinformatic platform	software;cooperative behavior;internet;knowledge sharing;user computer interface;databases factual;computational biology	With the rapid progress of biological research, great demands are proposed for integrative knowledge-sharing systems to efficiently support collaboration of biological researchers from various fields. To fulfill such requirements, we have developed a data-centric knowledge-sharing platform WebLab for biologists to fetch, analyze, manipulate and share data under an intuitive web interface. Dedicated space is provided for users to store their input data and analysis results. Users can upload local data or fetch public data from remote databases, and then perform analysis using more than 260 integrated bioinformatic tools. These tools can be further organized as customized analysis workflows to accomplish complex tasks automatically. In addition to conventional biological data, WebLab also provides rich supports for scientific literatures, such as searching against full text of uploaded literatures and exporting citations into various well-known citation managers such as EndNote and BibTex. To facilitate team work among colleagues, WebLab provides a powerful and flexible sharing mechanism, which allows users to share input data, analysis results, scientific literatures and customized workflows to specified users or groups with sophisticated privilege settings. WebLab is publicly available at http://weblab.cbi.pku.edu.cn, with all source code released as Free Software.	bio-informatics;bioinformatics;customize;database;databases;greater than;information privacy;interface device component;literature;requirement;source code;upload;user interface;citation	Xiao-Qiao Liu;Jianmin Wu;Xiao-Chuan Liu;Shuqi Zhao;Zhe Li;Lei Kong;Xiaocheng Gu;Jingchu Luo;Ge Gao	2009		10.1093/nar/gkp428	the internet	HPC	-4.534154295076364	-60.64920663229789	164211
cb82829f1f88b2e48e7eba625b1cfd23effee22d	improved ontology for eukaryotic single-exon coding sequences in biological databases		Efficient extraction of knowledge from biological data requires the development of structured vocabularies to unambiguously define biological terms. This paper proposes descriptions and definitions to disambiguate the term 'single-exon gene'. Eukaryotic Single-Exon Genes (SEGs) have been defined as genes that do not have introns in their protein coding sequences. They have been studied not only to determine their origin and evolution but also because their expression has been linked to several types of human cancer and neurological/developmental disorders and many exhibit tissue-specific transcription. Unfortunately, the term 'SEGs' is rife with ambiguity, leading to biological misinterpretations. In the classic definition, no distinction is made between SEGs that harbor introns in their untranslated regions (UTRs) versus those without. This distinction is important to make because the presence of introns in UTRs affects transcriptional regulation and post-transcriptional processing of the mRNA. In addition, recent whole-transcriptome shotgun sequencing has led to the discovery of many examples of single-exon mRNAs that arise from alternative splicing of multi-exon genes, these single-exon isoforms are being confused with SEGs despite their clearly different origin. The increasing expansion of RNA-seq datasets makes it imperative to distinguish the different SEG types before annotation errors become indelibly propagated in biological databases. This paper develops a structured vocabulary for their disambiguation, allowing a major reassessment of their evolutionary trajectories, regulation, RNA processing and transport, and provides the opportunity to improve the detection of gene associations with disorders including cancers, neurological and developmental diseases.	alternative splicing;biological database;confusion;databases;description;developmental disabilities;exons;imperative programming;introns;mental association;neoplasms;numerous;ontology;open reading frames;published database;rife;rna processing;rna splicing;sequence number;shotgun sequencing;transcription (software);transcription, genetic;transcriptional regulation;transcriptome;untranslated regions;vocabulary;word-sense disambiguation	Roddy Jorquera;Carolina González;Philip Clausen;Bent Petersen;David S. Holmes	2018		10.1093/database/bay089	exon;coding (social sciences);ontology;bioinformatics;biological database;computer science	Comp.	-2.012610998723354	-63.994720839161346	165176
e1a209d80a4e76902e5681942c639b57aa20e79e	mhcpred: a server for quantitative prediction of peptide-mhc binding	hla dr antigens;least squares analysis;ひらめく;software;peptides;研究開発;専門;cellular immunity;特許;機関;検索;科学技術;研究者;産学連携;横断検索;hla a antigens;multivariate analysis;jst;学術;独立行政法人;partial least square;検索エンジン;科学技術振興機構;robust statistics;antigen presentation;リンクセンター;binding sites;関連検索;論文;ひろがる;j global;遺伝子;internet;データベース;ｊｇｌｏｂａｌ;研究資源;研究課題;jglobal;国立研究開発法人;jdream;mhcpred ペプチド mhc結合の定量的予測のためのサーバー;ｊ ｇｌｏｂａｌ;アイディア;資料;models statistical;world wide web;技術動向;multivariate statistics;書誌情報;文献;発想;化学物質;epitopes t lymphocyte;統合検索;ｊｓｔ;科学技術用語;sequence analysis protein;つながる	Accurate T-cell epitope prediction is a principal objective of computational vaccinology. As a service to the immunology and vaccinology communities at large, we have implemented, as a server on the World Wide Web, a partial least squares-based multivariate statistical approach to the quantitative prediction of peptide binding to major histocom- patibility complexes (MHC), the key checkpoint on the antigen presentation pathway within adaptive cellular immunity. MHCPred implements robust statistical models for both Class I alleles (HLA-A*0101, HLA-A*0201, HLA-A*0202, HLA-A*0203, HLA-A*0206, HLA-A*0301, HLA-A*1101, HLA-A*3301, HLA-A*6801, HLA-A*6802 and HLA-B*3501) and Class II alleles (HLA-DRB*0401, HLA-DRB*0401 and HLA-DRB*0701). MHCPred is available from the URL: http://www.jenner.ac.uk/MHCPred.	alleles;antigen presentation pathway;cell cycle checkpoints;cellular immunity;community;computational technique;dosage forms;epitopes;gene regulatory network;hla class i histocompatibility antigen, a-0301 alpha chain;hla-dq antigens;immunology;informatics (discipline);major histocompatibility complex;model of hierarchical complexity;partial least squares regression;server (computer);server (computing);statistical model;transaction processing system;uniform resource locator;world wide web	Pingping Guan;Irini A. Doytchinova;Christianna Zygouri;Darren R. Flower	2003	Nucleic acids research	10.1093/nar/gkg510	biology;robust statistics;multivariate statistics;the internet;antigen presentation;bioinformatics;binding site;immunology;multivariate analysis;least squares	ML	0.5957159787437043	-63.087737660179975	165900
4c0992d515932a7380132d5eadce2df15e3b11ba	foundation: a program to retrieve all possible structures containing a user-defined minimum number of matching query elements from three-dimensional databases	three dimensional;drug design;three dimensional structure;database search;active site	A program is described that searches three-dimensional, structural databases, given a user-defined query, in order to retrieve all structures that contain any combination of a user-specified minimum number of matching elements. Queries consist of three-dimensional coordinates of atoms and/or bonds. Numerous query constraints are described which allow the investigator to define the chemical nature of the desired structures as well as the environment within which these structures must reside. They include: (1) Bonded vs. isolated atom distinction; (2) Atom type designation; (3) Definition of subsets with occupancy specification (>, =, < X atoms); (4) RMS-fit; (5) Active site volume accessibility of atoms linking query elements; (6) Number, atom type, and cyclic structure constraints for atoms linking pharmacophoric elements; (7) Automatic error boundary adjustment--ad infinitum constraint. To illustrate the capabilities of this program, queries based on the crystal structure of a thermolysin-inhibitor complex were tested against a subset of the Cambridge Crystallographic Database. Several compounds were returned which satisfied various aspects of the query, including fitting within the active site. Combination of segments of compounds which satisfy partial queries should provide a method for generating unique compounds with affinity for sites of known three-dimensional structure.	accessibility;atom (standard);cambridge structural database;crystal structure;identifier;matching;processor affinity;published database;question (inquiry);reside;specification;subgroup;thermolysin	Chris M. W. Ho;Garland R. Marshall	1993	Journal of computer-aided molecular design	10.1007/BF00141572	three-dimensional space;biochemistry;database search engine;chemistry;theoretical computer science;active site;computational chemistry;data mining;information retrieval;drug design	DB	-1.740715870857734	-60.759686675953574	166675
8735ddb6bc61a2e56e162678fa521c21ba1330a5	the research on the osmotic stress gene mining model based on the arabidopsis genome				Xiao Yu;Xiang Li;Huihui Deng;Yuchen Tang;Mukul Maiti;Qingming Kong	2019	JITR	10.4018/JITR.2019010109	data mining;genome;gene;osmotic shock;arabidopsis;computer science;bioinformatics	ML	1.7706271517868317	-63.37823257188492	166800
7d541c64ac477593f3d297f1faba838e0d056156	identification of the idiosyncratic bacterial protein tyrosine kinase (by-kinase) family signature	proteine;bacterie;protein tyrosine kinase;transferases;enzyme;bioinformatique;enzima;non specific serine threonine protein kinase;identification;identificacion;proteina;bacteria;bioinformatica;protein;bioinformatics	MOTIVATION Most of the protein tyrosine kinases found in bacteria have been recently classified in a new family, termed BY-kinase. Indeed, they share no sequence homology with their eukaryotic counterparts and have no known eukaryotic homologues. They are involved in several biological functions (e.g. capsule biosynthesis, antibiotic resistance, virulence mechanism). Thus, they can be considered interesting therapeutic targets to develop new drugs to treat infectious diseases. However, their identification is rendered difficult due to slow progress in their structural characterization and comes most often from biochemical experiments. Moreover BY-kinase sequences are related to many other bacterial proteins involved in several biological functions (e.g. ParA family proteins). Accordingly, their annotations in generalist databases, sequence analysis and classification remain partial and inhomogeneous and there is no bioinformatics resource dedicated to these proteins.   RESULTS The combination of similarity search with sequence-profile alignment, pattern matching and sliding window computation to detect the tyrosine cluster was used to identify BY-kinase sequences in UniProt Knowledgebase. Cross-validations with keywords searches, pattern matching with several patterns and checking of motifs conservation in multiple sequence alignments were performed. Our pipeline identified 640 sequences as BY-kinases and allowed the definition of a PROSITE pattern that is the signature of the BY-kinases. The sequences identified by our pipeline as BY-kinases share a good sequence similarity with BY-kinases that have already been biochemically characterized, and they all bear the characteristic motifs of the catalytic domain, including the three Walker-like motifs followed by a tyrosine cluster.   AVAILABILITY http://bykdb.ibcp.fr	ambiguous name resolution;amiga walker;antibiotic resistance, microbial;bacterial proteins;bioinformatics;checking (action);classification;communicable diseases;computation;computer cluster;database;databases;experiment;hidden markov model;homologous gene;internet;jeune thoracic dystrophy;knowledge bases;knowledge base;linear algebra;multiple sequence alignment;prosite;pattern matching;phosphotransferases;protein tyrosine kinase;protein family;sequence analysis;sequence homology;similarity search;uniprot;virulence;walkers;anthocyanidin reductase activity	Fanny Jadeau;Emmanuelle Bechet;Alain J. Cozzone;Gilbert Deléage;Christophe Grangeasse;Christophe Combet	2008	Bioinformatics	10.1093/bioinformatics/btn462	sh3 domain;identification;biology;biochemistry;enzyme;bacteria;computer science;bioinformatics;genetics	Comp.	1.774454583259932	-59.16627795685629	168365
4eb8cc420bb2b304f0358d6299f37eb7dc46a34d	the encode project at uc santa cruz	software;genomics;interaction analysis;encode consortium;databases nucleic acid;replication origin;origin of replication;pseudogenes;datasets;immunoprecipitation;laboratory techniques and procedures;internet;chromatin immunoprecipitation;chromatin;genome human;human genome;laboratory test finding;gene organization;humans;sequence alignment;multiple sequence alignment;user computer interface;base sequence;ucsc;deoxyribonuclease i;hypersensitivity	The goal of the Encyclopedia Of DNA Elements (ENCODE) Project is to identify all functional elements in the human genome. The pilot phase is for comparison of existing methods and for the development of new methods to rigorously analyze a defined 1% of the human genome sequence. Experimental datasets are focused on the origin of replication, DNase I hypersensitivity, chromatin immunoprecipitation, promoter function, gene structure, pseudogenes, non-protein-coding RNAs, transcribed RNAs, multiple sequence alignment and evolutionarily constrained elements. The ENCODE project at UCSC website (http://genome.ucsc.edu/ENCODE) is the primary portal for the sequence-based data produced as part of the ENCODE project. In the pilot phase of the project, over 30 labs provided experimental results for a total of 56 browser tracks supported by 385 database tables. The site provides researchers with a number of tools that allow them to visualize and analyze the data as well as download data for local analyses. This paper describes the portal to the data, highlights the data that has been made available, and presents the tools that have been developed within the ENCODE project. Access to the data and types of interactive analysis that are possible are illustrated through supplemental examples.	data table;deoxyribonuclease i;download;drug allergy;encode;encyclopedias;gene feature;multiple sequence alignment;pseudogenes;replication origin;table (database);track (course);uc browser;web site;chromatin immunoprecipitation	Daryl J. Thomas;Kate R. Rosenbloom;Hiram Clawson;Angie S. Hinrichs;Heather Trumbower;Brian J. Raney;Donna Karolchik;Galt P. Barber;Rachel A. Harte;Jennifer Hillman-Jackson;Robert M. Kuhn;Brooke L. Rhead;Kayla E. Smith;Archana Thakkapallayil;Ann S. Zweig;David Haussler;W. James Kent	2007		10.1093/nar/gkl1017	biology;genomics;human genome;molecular biology;chromatin immunoprecipitation;the internet;immunoprecipitation;chromatin;multiple sequence alignment;bioinformatics;sequence alignment;genetics;origin of replication;pseudogene	Comp.	-2.820912113503997	-60.01581472258916	168389
756aae95b3ccc3d5e5a8fd8d319b0f9501db6e91	transfac: an integrated system for gene expression regulation	genes;motor agitation and retardation scale;database management systems;nucleotides;integrable system;signal transduction;dna binding;transcription factors;binding site;matrix attachment region;internet;transcription factor;genome;gene expression regulation;protein binding;databases factual;regulatory sequences nucleic acid	TRANSFAC is a database on transcription factors, their genomic binding sites and DNA-binding profiles (http://transfac.gbf.de/TRANSFAC/). Its content has been enhanced, in particular by information about training sequences used for the construction of nucleotide matrices as well as by data on plant sites and factors. Moreover, TRANSFAC has been extended by two new modules: PathoDB provides data on pathologically relevant mutations in regulatory regions and transcription factor genes, whereas S/MARt DB compiles features of scaffold/matrix attached regions (S/MARs) and the proteins binding to them. Additionally, the databases TRANSPATH, about signal transduction, and CYTOMER, about organs and cell types, have been extended and are increasingly integrated with the TRANSFAC data sources.	binding sites;data sources;database;databases;gene expression regulation;matrix attachment regions;mutation;nucleotides;organ;regulatory sequences, nucleic acid;signal transduction;transcription factor;transcription (software);transduction (machine learning)	Edgar Wingender;Xin Chen;Reinhard Hehl;Holger Karas;Ines Liebich;V. Matys;T. Meinhardt;M. Prüß;Ingmar Reuter;Frank Schacherer	2000	Nucleic acids research	10.1093/nar/28.1.316	biology;molecular biology;bioinformatics;genetics;transfac;transcription factor	Comp.	-0.03372721018901897	-60.201906061865316	168662
69193b398e07c701b542130359e26a2a9e9a6793	imageplane: an automated image analysis pipeline for high-throughput screens using the planarian schmidtea mediterranea	animals;genomics;stem cells;biology;image processing computer assisted;functional genomics;planarians;cell proliferation;rna small interfering;algorithms;computational biology;helminth proteins;high throughput screening assays;automation	ImagePlane is a modular pipeline for automated, high-throughput image analysis and information extraction. Designed to support planarian research, ImagePlane offers a self-parameterizing adaptive thresholding algorithm; an algorithm that can automatically segment animals into anterior-posterior/left-right quadrants for automated identification of region-specific differences in gene and protein expression; and a novel algorithm for quantification of morphology of animals, independent of their orientations and sizes. ImagePlane also provides methods for automatic report generation, and its outputs can be easily imported into third-party tools such as R and Excel. Here we demonstrate the pipeline's utility for identification of genes involved in stem cell proliferation in the planarian Schmidtea mediterranea. Although designed to support planarian studies, ImagePlane will prove useful for cell-based studies as well.	algorithm;autostereogram;bioimage informatics;collections (publication);high-throughput computing;image analysis;image processing;informatics (discipline);information extraction;mathematical morphology;outlines (document);pipeline (computing);pipeline pilot;planarians;population;quantitation;r language;stem cells;thresholding (image processing);throughput;tracer;basic research;protein expression;stem cell proliferation	Steven Flygare;Michael Campbell;Robert Mars Ross;Barry Moore;Mark Yandell	2013	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2013.0025	functional genomics;biology;genomics;molecular biology;bioinformatics;automation;cell growth	Comp.	-1.3318623206876106	-63.0119092859281	169328
529be75960d02c23d8c3650ee39191a34e1c5727	development of detection method for novel fusion gene using genechip exon array	biological patents;health informatics;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;biomedicine general;bioinformatics;literature search	Fusion genes have been recognized to play key roles in oncogenesis. Though, many techniques have been developed for genome-wide analysis of fusion genes, a more efficient method is desired. We introduced a new method of detecting the novel fusion gene by using GeneChip Exon Array that enables exon expression analysis on a whole-genome scale and TAIL-PCR. To screen genes with abnormal exon expression profiles, we developed computational program, and confirmed that the program was able to search the fusion partner gene using Exon Array data of T-cell acute lymphocytic leukemia (T-ALL) cell lines. It was reported that the T-ALL cell lines, ALL-SIL, BE13 and LOUCY, harbored the fusion gene NUP214-ABL1, NUP214-ABL1 and SET-NUP214, respectively. The program extracted the candidate genes with abnormal exon expression profiles: 1 gene in ALL-SIL, 1 gene in BE13, and 2 genes in LOUCY. The known fusion partner gene NUP214 was included in the genes in ALL-SIL and LOUCY. Thus, we applied the proposed program to the detection of fusion partner genes in other tumors. To discover novel fusion genes, we examined 24 breast cancer cell lines and 20 pancreatic cancer cell lines by using the program. As a result, 20 and 23 candidate genes were obtained for the breast and pancreatic cancer cell lines respectively, and seven genes were selected as the final candidate gene based on information of the EST data base, comparison with normal cell samples and visual inspection of Exon expression profile. Finding of fusion partners for the final candidate genes was tried by TAIL-PCR, and three novel fusion genes were identified. The usefulness of our detection method was confirmed. Using this method for more samples, it is thought that fusion genes can be identified.	acute lymphocytic leukemia;candidate disease gene;chronic lymphocytic leukemia;cultured cell line;database;databases;exons;extraction;gene expression profiling;genes, vif;leukemia, b-cell;lymphoid leukemia;mammary neoplasms;nup214 gene;pancreatic carcinoma;sensor;visual inspection;cancer cell	Yusaku Wada;Masaaki Matsuura;Minoru Sugawara;Masaru Ushijima;Satoshi Miyata;Koichi Nagasaki;Tetsuo Noda;Yoshio Miki	2013		10.1186/2043-9113-4-3	health informatics;text mining;medical research;medicine;computer science;bioinformatics;data science;nursing;data mining	Comp.	0.4150455173485	-61.9848861478515	169483
86e6424c0744306dd5e3467c0fbfed32c294fd90	the hssp database of protein structure-sequence alignments and family profiles	embl;computer communication networks;protein structure;proteins;protein conformation;sequence alignment;multiple sequence alignment;databases factual;information storage and retrieval;protein data bank	HSSP (http: //www.sander.embl-ebi.ac.uk/hssp/) is a derived database merging structure (3-D) and sequence (1-D) information. For each protein of known 3D structure from the Protein Data Bank (PDB), we provide a multiple sequence alignment of putative homologues and a sequence profile characteristic of the protein family, centered on the known structure. The list of homologues is the result of an iterative database search in SWISS-PROT using a position-weighted dynamic programming method for sequence profile alignment (MaxHom). The database is updated frequently. The listed putative homologues are very likely to have the same 3D structure as the PDB protein to which they have been aligned. As a result, the database not only provides aligned sequence families, but also implies secondary and tertiary structures covering 33% of all sequences in SWISS-PROT.		Chris Dodge;Reinhard Schneider;Chris Sander	1998	Nucleic acids research	10.1093/nar/26.1.313	biology;protein structure;structural alignment;homology modeling;multiple sequence alignment;bioinformatics;sequence analysis;sequence alignment;sequence database;conserved domain database;protein structure database;alignment-free sequence analysis	Comp.	-1.9499163063342129	-60.15252471528867	169612
624435495656a7c01225f13844637ba5f43d141a	pubangiogen: a database and knowledge for angiogenesis and related diseases	animals;angiogenesis modulating agents;disease;signal transduction;neovascularization pathologic;internet;protein interaction mapping;databases chemical	Angiogenesis is the process of generating new blood vessels based on existing ones, which is involved in many diseases including cancers, cardiovascular diseases and diabetes mellitus. Recently, great efforts have been made to explore the mechanisms of angiogenesis in various diseases and many angiogenic factors have been discovered as therapeutic targets in anti- or pro-angiogenic drug development. However, the resulted information is sparsely distributed and no systematical summarization has been made. In order to integrate these related results and facilitate the researches for the community, we conducted manual text-mining from published literature and built a database named as PubAngioGen (http://www.megabionet.org/aspd/). Our online application displays a comprehensive network for exploring the connection between angiogenesis and diseases at multilevels including protein-protein interaction, drug-target, disease-gene and signaling pathways among various cells and animal models recorded through text-mining. To enlarge the scope of the PubAngioGen application, our database also links to other common resources including STRING, DrugBank and OMIM databases, which will facilitate understanding the underlying molecular mechanisms of angiogenesis and drug development in clinical therapy.	angiogenic process;animal model;blood vessel;cardiovascular diseases;database;diabetes mellitus;drug interactions;drugbank;malignant neoplasms;name;online mendelian inheritance in man;string;scientific publication;text mining;tumor angiogenesis;web application;drug development;protein protein interaction	Peng Li;Yongrui Liu;Huan Wang;Yuan He;Xue Wang;Yundong He;Fang Lv;Huaqing Chen;Xiufeng Pang;Mingyao Liu;Tieliu Shi;Zhengfang Yi	2015		10.1093/nar/gku1139	biology;the internet;bioinformatics;signal transduction	Comp.	-0.3903601344069245	-62.22776766046847	170489
9f0deb8eea001e7c1fed24708ce8572675e5ff65	exploitation des algorithmes génétiques pour la prédiction de structure de complexe protéine-protéine. (using genetic algorithms to predict structural protein-protein interactions)			genetic algorithm;interaction;linear algebra	Thomas Bourquard	2009				NLP	1.012897971403402	-65.4770740362485	170764
8a399f15c663144dfbab5ddf45bd6f44c5035059	geno3d: automatic comparative molecular modelling of protein	molecular modelling	Geno3D (http://geno3d-pbil.ibcp.fr) is an automatic web server for protein molecular modelling. Starting with a query protein sequence, the server performs the homology modelling in six successive steps: (i) identify homologous proteins with known 3D structures by using PSI-BLAST; (ii) provide the user all potential templates through a very convenient user interface for target selection; (iii) perform the alignment of both query and subject sequences; (iv) extract geometrical restraints (dihedral angles and distances) for corresponding atoms between the query and the template; (v) perform the 3D construction of the protein by using a distance geometry approach and (vi) finally send the results by e-mail to the user.	amino acid sequence;blast;clinical use template;distance;email;emoticon;homologous gene;homology (biology);homology modeling;molecular modelling;physical restraint equipment (device);question (inquiry);server (computing);user interface device component;web server	Christophe Combet;Martin Jambon;Gilbert Deléage;Christophe Geourjon	2002	Bioinformatics	10.1093/bioinformatics/18.1.213	molecular modelling;biology;computer science;bioinformatics;theoretical computer science;data mining	Comp.	-1.8620842579296317	-59.964927574954736	170788
1823026160626ed2cd47de840d3829a7bb2ebb38	ncbi geo: archive for functional genomics data sets—update	community;genomics;metadata;high throughput nucleotide sequencing;databases genetic;national library of medicine u s;datasets;gene expression;internet;functional genomics;genome;united states national institutes of health;gene expression profiling;oligonucleotide array sequence analysis	The Gene Expression Omnibus (GEO, http://www.ncbi.nlm.nih.gov/geo/) is an international public repository for high-throughput microarray and next-generation sequence functional genomic data sets submitted by the research community. The resource supports archiving of raw data, processed data and metadata which are indexed, cross-linked and searchable. All data are freely available for download in a variety of formats. GEO also provides several web-based tools and strategies to assist users to query, analyse and visualize data. This article reports current status and recent database developments, including the release of GEO2R, an R-based web application that helps users analyse GEO data.	access network;annotation;digital archive;download;epidemiologic research design;functional genomics;high-throughput computing;index;microarray;national center for biotechnology information;r language;throughput;web application;format	Tanya Barrett;Stephen E. Wilhite;Pierre Ledoux;Carlos Evangelista;Irene F. Kim;Maxim Tomashevsky;Kimberly A. Marshall;Katherine H. Phillippy;Patti M. Sherman;Michelle Holko;Andrey Yefanov;Hyeseung Lee;Naigong Zhang;Cynthia L. Robertson;Nadezhda Serova;Sean R. Davis;Alexandra Soboleva	2013		10.1093/nar/gks1193	functional genomics;biology;community;genomics;the internet;gene expression;bioinformatics;gene expression profiling;metadata;genetics;genome	Comp.	-2.77591535943855	-60.62664424222234	171254
8a130766a4aad79575a20f78f95039ebbe0f2213	membrane computing	membrane computing	We recall several elements of molecular biology of bacteria, also discussing their (possible) relevance for the membrane computing area.	membrane computing;relevance	Jan van Leeuwen	2003		10.1007/3-540-36490-0	computer science	Theory	1.4150077196157047	-64.03231210319179	172796
45bde160dd29066ad0f649270ebdee86f31c7164	improvement in protein-coding region identification based on sliding window trigonometric fast transforms using singular value decomposition	decomposition valeur singuliere;st dht;proteine;improvement;singular value decomposition;bioinformatique;short time discrete hartley transform;time;mejora;protein coding regions;codificacion;temps;svd;sliding window trigonometric fast transforms;short time discrete fourier transform;identification;amelioration;st dft;short time discrete sine transform;coding;identificacion;st dst;short time discrete cosine transform;decomposicion valor singular;proteina;period 3 property;bioinformatica;st dct;protein;sliding window;codage;tiempo;bioinformatics	In this paper, the performance of various sliding window trigonometric fast transforms for identification of protein coding regions has been analysed at the nucleotide level. It is found that, Short-Time Discrete Fourier Transform (ST-DFT) gives better identification accuracy in comparison with Short-Time Discrete Cosine Transform (ST-DCT), Short-Time Discrete Sine Transform (ST-DST) and Short-Time Discrete Hartley Transform (ST-DHT). In the proposed method, identification accuracy of protein coding regions has been improved by applying Singular Value Decomposition (SVD) on the DNA spectrum obtained using sliding window trigonometric fast transforms. The results show that, in proposed method all trigonometric fast transforms gives almost similar results in terms of area under ROC curve for GENSCAN test set.	area under curve;dht brand of dihydrotachyesterol;dst gene;dihydrotestosterone;discrete fourier transform;discrete hartley transform;discrete cosine transform;discrete sine transform;distributed hash table;fast fourier transform;genscan;hartley (unit);hartley guinea pig;nucleotides;open reading frames;receiver operator characteristics;receiver operating characteristic;select (sql);short-time fourier transform;singular value decomposition;slide (glass microscope);tapering - action;test set;window function	Malaya Kumar Hota;Vinay Kumar Srivastava	2011	International journal of data mining and bioinformatics	10.1504/IJDMB.2011.038580	arithmetic;discrete hartley transform;speech recognition;hartley transform;trigonometric interpolation;modified discrete cosine transform;computer science;bioinformatics;discrete sine transform;calculus;discrete fourier transform;discrete cosine transform;mathematics;discrete fourier transform;singular value decomposition;statistics	Vision	2.219636392991639	-63.56494978057978	173242
fa783af4fcd876f30cc8eae2e54682492acedb4b	ncdr: a comprehensive resource of non-coding rnas involved in drug resistance		Summary As a promising field of individualized therapy, non-coding RNA pharmacogenomics promotes the understanding of different individual responses to certain drugs and acts as a reasonable reference for clinical treatment. However, relevant information is scattered across the published literature, which is inconvenient for researchers to explore non-coding RNAs that are involved in drug resistance. To address this, we systemically identified validated and predicted drug resistance-associated microRNAs and long non-coding RNAs through manual curation and computational analysis. Subsequently, we constructed an omnibus repository named ncDR, which furnishes a user-friendly interface that allows for convenient browsing, visualization, querying and downloading of data. Given the rapidly increasing interest in precision medicine, ncDR will significantly improve our understanding of the roles of regulatory non-coding RNAs in drug resistance and has the potential to be a timely and valuable resource.   Availability and implementation http://www.jianglab.cn/ncDR/.   Contact jiangwei@hrbmu.edu.cn or lw2247@yeah.net.   Supplementary information Supplementary data are available at Bioinformatics online.	bioinformatics;digital curation;download;ephrin type-b receptor 1, human;geographic information systems;imagery;interface device component;name;precision medicine;scientific publication;usability	Enyu Dai;Feng Yang;Jing Wang;Xu Zhou;Qian Song;Weiwei An;Lihong Wang;Wei Jiang	2017	Bioinformatics	10.1093/bioinformatics/btx523	coding (social sciences);computer science;drug resistance;bioinformatics	Comp.	-1.478291989742926	-61.23226919404599	174215
3f94ea52a39fe81826bd2332666ee32406dcfee8	informatics center for mouse genomics	quantitative trait loci;universal access;automatic segmentation;streaming video;image database;complex traits;genetics;tools and techniques;central nervous system;qtl analysis	In recent years, there has been an explosion in the number of tools and techniques available to researchers interested in exploring the genetic basis of all aspects of central nervous system (CNS) development and function. Here, we exploit a powerful new reductionist approach to explore the genetic basis of the very significant structural and molecular differences between the brains of different strains of mice, called either complex trait or quantitative trait loci (QTL) analysis. Our specific focus has been to provide universal access over the web to tools for the genetic dissection of complex traits of the CNS—tools that allow researchers to map genes that modulate phenotypes at a variety of levels ranging from the molecular all the way to the anatomy of the entire brain. Our website, The Mouse Brain Library (MBL; http://mbl.org) is comprised of four interrelated components that are designed to support this goal: The Brain Library, iScope, Neurocartographer, and WebQTL. The centerpiece of the MBL is an image database of histologically prepared museum-quality slides representing nearly 2000 mice from over 120 strains—a library suitable for stereologic analysis of regional volume. The iScope provides fast access to the entire slide collection using streaming video technology, enabling neuroscientists to acquire high-magnification images of any CNS region for any of the mice in the MBL. Neurocartographer provides automatic segmentation of images from the MBL by warping precisely delineated boundaries from a 3D atlas of the mouse brain. Finally, WebQTL provides statistical and graphical analysis of linkage between phenotypes and genotypes.	alleles;anatomic structures;brain;cns disorder;cell proliferation;cervical atlas;collections (publication);genomics;genotype;genotype determination;graphical user interface;informatics (discipline);linkage (software);neuroanatomy;neuroinformatics;phenotype;quantitative trait loci;reductionism;slide (glass microscope);streaming media;thoracic surgery, video-assisted;web site;genetic linkage	Glenn D. Rosen;Nathan T. La Porte;Boris Diechtiareff;Christopher J. Pung;Jonathan Nissanov;Carl Gustafson;Louise Bertrand;Smadar Gefen;Yingli Fan;Oleh J. Tretiak;Kenneth F. Manly;Melburn R. Park;Alexander G. Williams;Michael T. Connolly;John A. Capra;Robert W. Williams	2003	Neuroinformatics	10.1385/NI:1:4:327	universal design;bioinformatics;central nervous system;genetics;quantitative trait locus	Comp.	-1.112650190679408	-61.88795811125488	174226
9a78ae74da916bb10ac24fa407cb642e4f1bde2f	aleaves facilitates on-demand exploration of metazoan gene family trees on mafft sequence alignment server with enhanced interactivity	genes;software;animals;phylogeny;genes homeobox;vertebrates;wnt proteins;internet;proteins;genome;humans;sequence alignment;repressor proteins;sequence analysis protein	We report a new web server, aLeaves (http://aleaves.cdb.riken.jp/), for homologue collection from diverse animal genomes. In molecular comparative studies involving multiple species, orthology identification is the basis on which most subsequent biological analyses rely. It can be achieved most accurately by explicit phylogenetic inference. More and more species are subjected to large-scale sequencing, but the resultant resources are scattered in independent project-based, and multi-species, but separate, web sites. This complicates data access and is becoming a serious barrier to the comprehensiveness of molecular phylogenetic analysis. aLeaves, launched to overcome this difficulty, collects sequences similar to an input query sequence from various data sources. The collected sequences can be passed on to the MAFFT sequence alignment server (http://mafft.cbrc.jp/alignment/server/), which has been significantly improved in interactivity. This update enables to switch between (i) sequence selection using the Archaeopteryx tree viewer, (ii) multiple sequence alignment and (iii) tree inference. This can be performed as a loop until one reaches a sensible data set, which minimizes redundancy for better visibility and handling in phylogenetic inference while covering relevant taxa. The work flow achieved by the seamless link between aLeaves and MAFFT provides a convenient online platform to address various questions in zoology and evolutionary biology.	access network;archaeopteryx;biological science disciplines;computational phylogenetics;data sources;data access;family tree;gins complex location;gene family;genome;handling (psychology);homologous gene;hyperbolic absolute risk aversion;inference;informatics (discipline);interactivity;kuma;language development disorders;mafft;metazoa;molecular phylogenetics;multiple sequence alignment;numerous;phylogenetic analysis;question (inquiry);resultant;seamless3d;search engine optimization;server (computer);server (computing);silo (dataset);trees (plant);version;web server;women's health services;zoology	Shigehiro Kuraku;Christian M. Zmasek;Osamu Nishimura;Kazutaka Katoh	2013		10.1093/nar/gkt389	biology;the internet;repressor;multiple sequence alignment;bioinformatics;sequence analysis;gene;sequence alignment;genetics;alignment-free sequence analysis;phylogenetics;genome	Comp.	-1.4219921268288171	-59.11803189370802	175293
18f7ccd89445b16292a7a5ac5dc5b47221526fa7	memo: a hybrid sql/xml approach to metabolomic data management for functional genomics	genomics;text;dk atira pure researchoutput researchoutputtypes contributiontojournal article;data integrity;formal model;proteome;database management systems;metabolism physiology;semantic integration;signal transduction;data management;data processing;models biological;proteome metabolism;relational database;data format;computational biology bioinformatics;qa75 electronic computers computer science;genomics methods;large scale;hybrid approach;information storage and retrieval methods;signal transduction physiology;functional genomics;system biology;algorithms;user computer interface;combinatorial libraries;gene function;computer appl in life sciences;systems integration;computer simulation;information storage and retrieval;metabolism;qh301 biology;genome sequence;microarrays;bioinformatics	The genome sequencing projects have shown our limited knowledge regarding gene function, e.g. S. cerevisiae has 5–6,000 genes of which nearly 1,000 have an uncertain function. Their gross influence on the behaviour of the cell can be observed using large-scale metabolomic studies. The metabolomic data produced need to be structured and annotated in a machine-usable form to facilitate the exploration of the hidden links between the genes and their functions. MeMo is a formal model for representing metabolomic data and the associated metadata. Two predominant platforms (SQL and XML) are used to encode the model. MeMo has been implemented as a relational database using a hybrid approach combining the advantages of the two technologies. It represents a practical solution for handling the sheer volume and complexity of the metabolomic data effectively and efficiently. The MeMo model and the associated software are available at http://dbkgroup.org/memo/ . The maturity of relational database technology is used to support efficient data processing. The scalability and self-descriptiveness of XML are used to simplify the relational schema and facilitate the extensibility of the model necessitated by the creation of new experimental techniques. Special consideration is given to data integration issues as part of the systems biology agenda. MeMo has been physically integrated and cross-linked to related metabolomic and genomic databases. Semantic integration with other relevant databases has been supported through ontological annotation. Compatibility with other data formats is supported by automatic conversion.	academia (organization);annotation;capability maturity model;complexity;databases;design of experiments;encode (action);extensibility;formal language;functional genomics;handling (psychology);home page;instrument - device;memo model;memorandum;metabolomics;microsoft sql server;omics;operating system;programming languages;programming language;relational database;requirement;sql;sql/xml;scalability;semantic integration;systems biology;whole genome sequencing;xml;format	Irena Spasić;Warwick B. Dunn;Giles Velarde;Andy Tseng;Helen Jenkins;Nigel Hardy;Stephen G. Oliver;Douglas B. Kell	2005	BMC Bioinformatics	10.1186/1471-2105-7-281	computer simulation;computational biology;functional genomics;biology;genomics;whole genome sequencing;semantic integration;dna microarray;data processing;data management;relational database;computer science;bioinformatics;proteome;data integrity;data mining;metabolism;signal transduction;system integration	DB	-4.473634131034587	-61.807953521692184	175565
740f494727384d36bbcfaadbe5354a83d80d6340	semantic web integration of cheminformatics resources with the sadi framework	semantic web service;health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computer applications in chemistry;chemistry development kit;theoretical and computational chemistry;computational biology bioinformatics;paradigm shift;uk phd theses thesis;computer experiment;life sciences;formal logic;semantic web;uk research reports;access method;medical journals;formal ontology;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics	BACKGROUND The diversity and the largely independent nature of chemical research efforts over the past half century are, most likely, the major contributors to the current poor state of chemical computational resource and database interoperability. While open software for chemical format interconversion and database entry cross-linking have partially addressed database interoperability, computational resource integration is hindered by the great diversity of software interfaces, languages, access methods, and platforms, among others. This has, in turn, translated into limited reproducibility of computational experiments and the need for application-specific computational workflow construction and semi-automated enactment by human experts, especially where emerging interdisciplinary fields, such as systems chemistry, are pursued. Fortunately, the advent of the Semantic Web, and the very recent introduction of RESTful Semantic Web Services (SWS) may present an opportunity to integrate all of the existing computational and database resources in chemistry into a machine-understandable, unified system that draws on the entirety of the Semantic Web.   RESULTS We have created a prototype framework of Semantic Automated Discovery and Integration (SADI) framework SWS that exposes the QSAR descriptor functionality of the Chemistry Development Kit. Since each of these services has formal ontology-defined input and output classes, and each service consumes and produces RDF graphs, clients can automatically reason about the services and available reference information necessary to complete a given overall computational task specified through a simple SPARQL query. We demonstrate this capability by carrying out QSAR analysis backed by a simple formal ontology to determine whether a given molecule is drug-like. Further, we discuss parameter-based control over the execution of SADI SWS. Finally, we demonstrate the value of computational resource envelopment as SADI services through service reuse and ease of integration of computational functionality into formal ontologies.   CONCLUSIONS The work we present here may trigger a major paradigm shift in the distribution of computational resources in chemistry. We conclude that envelopment of chemical computational resources as SADI SWS facilitates interdisciplinary research by enabling the definition of computational problems in terms of ontologies and formal logical statements instead of cumbersome and application-specific tasks and workflows.	cheminformatics;chemistry development kit;class;clients;computation;computational problem;computational resource;dna integration;experiment;formal ontology;graphical user interface;hl7publishingsubsection <query>;input/output;interoperability;mast/stem cell growth factor receptor kit, human;ontology (information science);open-source software;population parameter;programming languages;programming paradigm;prototype;quantitative structure-activity relationship;quantitative structure–activity relationship;representational state transfer;resource description framework;reuse (action);sadi;sparql;stuve-wiedemann syndrome;semantic web service;semiconductor industry;sinewave synthesis	Leonid L. Chepelev;Michel Dumontier	2011		10.1186/1758-2946-3-16	paradigm shift;semantic interoperability;data web;computer experiment;computer science;bioinformatics;data science;semantic web;social semantic web;data mining;semantic web stack;access method;logic	Web+IR	-4.432588826194092	-63.787784434236066	175751
7640fec060b522d5b279b9fefac7e1490c0df3cc	the embl nucleotide sequence database		The EMBL Nucleotide Sequence Database (http://www.ebi.ac.uk/embl/), maintained at the European Bioinformatics Institute (EBI), incorporates, organizes and distributes nucleotide sequences from public sources. The database is a part of an international collaboration with DDBJ (Japan) and GenBank (USA). Data are exchanged between the collaborating databases on a daily basis to achieve optimal synchrony. The web-based tool, Webin, is the preferred system for individual submission of nucleotide sequences, including Third Party Annotation (TPA) and alignment data. Automatic submission procedures are used for submission of data from large-scale genome sequencing centres and from the European Patent Office. Database releases are produced quarterly. The latest data collection can be accessed via FTP, email and WWW interfaces. The EBI's Sequence Retrieval System (SRS) integrates and links the main nucleotide and protein databases as well as many other specialist molecular biology databases. For sequence similarity searching, a variety of tools (e.g. FASTA and BLAST) are available that allow external users to compare their own sequences against the data in the EMBL Nucleotide Sequence Database, the complete genomic component subsection of the database, the WGS data sets and other databases. All available resources can be accessed via the EBI home page at http://www.ebi.ac.uk.		Guenter Stoesser;Wendy Baker;Alexandra van den Broek;Evelyn Camon;Maria Garcia-Pastor;Carola Kanz;Tamara Kulikova;Vincent Lombard;Rodrigo Lopez;Helen E. Parkinson;Nicole Redaschi;Peter Sterk;Peter Stoehr;Mary Ann Tuli	2001	Nucleic acids research	10.1093/nar/29.1.17		Comp.	-2.861186369355611	-61.29403364213532	175857
8fbf814987e462f0058749056109fb21184ae845	collection of mutant trna sequences	purines;mutation;escherichia coli			J. E. Celis	1979	Nucleic acids research	10.1093/nar/8.1.197-b	mutation;biology;purine metabolism;molecular biology;bioinformatics;escherichia coli;genetics	Crypto	2.168283450633807	-63.519040957173196	175951
1862c17719f2014dcef5a780a964ec532912a8ae	a metadata-aware application for remote scoring and exchange of tissue microarray images	software;breast neoplasms;female;image processing computer assisted;computational biology bioinformatics;tissue array analysis;internet;algorithms;humans;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	The use of tissue microarrays (TMA) and advances in digital scanning microscopy has enabled the collection of thousands of tissue images. There is a need for software tools to annotate, query and share this data amongst researchers in different physical locations. We have developed an open source web-based application for remote scoring of TMA images, which exploits the value of Microsoft Silverlight Deep Zoom to provide a intuitive interface for zooming and panning around digital images. We use and extend existing XML-based standards to ensure that the data collected can be archived and that our system is interoperable with other standards-compliant systems. The application has been used for multi-centre scoring of TMA slides composed of tissues from several Phase III breast cancer trials and ten different studies participating in the International Breast Cancer Association Consortium (BCAC). The system has enabled researchers to simultaneously score large collections of TMA and export the standardised data to integrate with pathological and clinical outcome data, thereby facilitating biomarker discovery.	application program interface;archive;biological markers;body tissue;breast carcinoma;collections (publication);compliance behavior;consortium;deep zoom;digital image;interoperability;mammary neoplasms;microsoft silverlight;numerous;open-source software;question (inquiry);score;slide (glass microscope);stage iii breast cancer ajcc v7;standards-compliant;thrombotic microangiopathies;tissue microarray;web application;xml;standards characteristics	Lorna Morris;Andrew Tsui;Charles Crichton;Steve Harris;Peter Maccallum;William J. Howat;Jim Davies;James D. Brenton;Carlos Caldas	2013		10.1186/1471-2105-14-147	biology;the internet;dna microarray;computer science;bioinformatics;data science	HCI	-3.26586505278523	-60.4911608274895	176221
17a5b615984ca5de8b46fb18cf1b52ba1129fe2f	analysis of equine protein-coding gene structure and expression by rna-sequencing	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;gene structure;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics	Background RNA-sequencing (RNA-seq) data from eight equine tissue samples (34-day whole embryo, full term placental villous, adult testes, adult cerebellum, adult articular cartilage, adult LPS-stimulated articular cartilage, adult synovial membrane, and adult LPS-stimulated synovial membrane) were used to refine the structural annotation of protein-coding genes in the horse and for a preliminary assessment of tissue-specific expression patterns.	lightweight portable security	Stephen J. Coleman;Zheng Zeng;Jinze Liu;James N. MacLeod	2010		10.1186/1471-2105-11-S4-O8	biology;dna microarray;bioinformatics;data science;gene	Comp.	0.971069163693728	-62.14150467117484	176881
76f11e439d170faac55f4ae8ba90f6d2117cd0de	multinomial modeling and an evaluation of common data-mining algorithms for identifying signals of disproportionate reporting in pharmacovigilance databases	adverse drug reaction;problematic decs;multinomial modeling;adverse effect;disproportionate reporting;low-frequency decs;underexpected decs;common data-mining algorithm;drug safety professional;pharmacovigilance databases;low-frequency combination;large databases	MOTIVATION A principal objective of pharmacovigilance is to detect adverse drug reactions that are unknown or novel in terms of their clinical severity or frequency. One method is through inspection of spontaneous reporting system databases, which consist of millions of reports of patients experiencing adverse effects while taking one or more drugs. For such large databases, there is an increasing need for quantitative and automated screening tools to assist drug safety professionals in identifying drug-event combinations (DECs) worthy of further investigation. Existing algorithms can effectively identify problematic DECs when the frequencies are high. However these algorithms perform differently for low-frequency DECs.   RESULTS In this work, we provide a method based on the multinomial distribution that identifies signals of disproportionate reporting, especially for low-frequency combinations. In addition, we comprehensively compare the performance of commonly used algorithms with the new approach. Simulation results demonstrate the advantages of the proposed method, and analysis of the Adverse Event Reporting System data shows that the proposed method can help detect interesting signals. Furthermore, we suggest that these methods be used to identify DECs that occur significantly less frequently than expected, thus identifying potential alternative indications for these drugs. We provide an empirical example that demonstrates the importance of exploring underexpected DECs.   AVAILABILITY Code to implement the proposed method is available in R on request from the corresponding authors.   CONTACT kjell@arboranalytics.com or Mark.M.Gosink@Pfizer.com   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	adverse reaction to drug;algorithm;bioinformatics;data mining;global variable;multinomial logistic regression;patients;pharmacovigilance;published database;sql server reporting services;simulation;spontaneous order;substance abuse detection	Kjell Johnson;Cen Guo;Mark Gosink;Vicky Wang;Manfred Hauben	2012	Bioinformatics	10.1093/bioinformatics/bts576	econometrics;data science;data mining	Comp.	-2.713474760216499	-65.67400153390875	177152
843ec2436a8296430c9463adb9277d34f4ab61cd	human genome variation: haplotypes, linkage disequilibrium, and populations - session introduction	linkage disequilibrium;human genome	"""The working draft of a reference sequence of the human genome is nearing completion and is providing a basis for studies in a variety of domains. Computational challenges exist in all of these domains because of the massive amounts of data, the multiple often complex relationships among the types of relevant data, and the need to make the data accessible to researchers approaching the data from different perspectives. One aspect of genomic data of broad relevance is the variation in the DNA sequence among the billions of separate copies existing in the several billion living humans. Some of that variation is """"abnormal"""" and the basis for inherited diseases. However, most of the variation is normal and simply makes each of us unique. Yet this common, normal variation is of great biomedical relevance because it can alter disease susceptibility, physiologic reactions to drugs, and response to environmental stimulus. The variation is also relevant to anthropology and understanding human evolution. In fact, several aspects of DNA sequence variation are consequences of recent human evolution: the amount of variation, the distribution of variation among human populations, and the organization of variation along the DNA sequence. This last issue has become increasingly interesting as millions of single nucleotide polymorphisms (SNPs) have been identified and mapped. With multiple SNPs mapped to every small segment of DNA the focus has shifted from the individual SNP to considering groups of SNPs as haplotypes (haploid genotypes) with the common finding that for n SNPs in a small segment of DNA there are usually far fewer than the 2 n haplotypes expected by chance. This non-randomness, commonly referred to as linkage disequilibrium (LD), is adding an additional level of complexity to genetic databases and analytic programs."""	common normal (robotics);computation;database;genetic algorithm;linkage (software);population;randomness;relevance	Francisco M. de la Vega;Kenneth K. Kidd;Isaac S. Kohane	2003			genetics;complete linkage;human genome;bioinformatics;association mapping;tag snp;haplotype;linkage disequilibrium;genetic association;biology	Comp.	2.5731527767356392	-61.63942664270564	177538
ef5b739d965af6f49ef044d7c3381fedbe1527d5	an object-oriented data model for the dynamic modelling of metabolic pathways	metabolic pathway		data model	Gabi Kastenmüller;Hans-Werner Mewes	1999			bioinformatics;metabolic pathway;data model;object-oriented programming;biology	SE	-0.4772047328779358	-64.86028989903552	177673
01b2b1939000d54824d35afbcec793e1423c9eb8	the genome sequence database: towards an integrated functional genomics resource	databases;whole genome sequencing;animals;consensus sequence;gene expression;genome human;genome;integral functional;humans;sequence alignment;databases factual;base sequence;computational biology;information storage and retrieval;genome sequence	During 1998 the primary focus of the Genome Sequence DataBase (GSDB; http://www.ncgr.org/gsdb ) located at the National Center for Genome Resources (NCGR) has been to improve data quality, improve data collections, and provide new methods and tools to access and analyze data. Data quality has been improved by extensive curation of certain data fields necessary for maintaining data collections and for using certain tools. Data quality has also been increased by improvements to the suite of programs that import data from the International Nucleotide Sequence Database Collaboration (IC). The Sequence Tag Alignment and Consensus Knowledgebase (STACK), a database of human expressed gene sequences developed by the South African National Bioinformatics Institute (SANBI), became available within the last year, allowing public access to this valuable resource of expressed sequences. Data access was improved by the addition of the Sequence Viewer, a platform-independent graphical viewer for GSDB sequence data. This tool has also been integrated with other searching and data retrieval tools. A BLAST homology search service was also made available, allowing researchers to search all of the data, including the unique data, that are available from GSDB. These improvements are designed to make GSDB more accessible to users, extend the rich searching capability already present in GSDB, and to facilitate the transition to an integrated system containing many different types of biological data.	blast;collections (publication);data access;data quality;data retrieval;digital curation;functional genomics;graphical user interface;homologous gene;homology (biology);international nucleotide sequence database collaboration;knowledge bases;knowledge base;south african national bioinformatics institute;web search engine	M. P. Skupski;M. Booker;Andrew D. Farmer;M. Harpold;Wen Huang;Jeff T. Inman;Donald Kiphart;C. Kodira;S. Root;Faye D. Schilkey;Jolene Schwertfeger;Adam C. Siepel;D. Stamper;Nina Thayer;R. Thompson;Jennifer R. Wortman;J. J. Zhuang;Carol Harger	1999	Nucleic acids research	10.1093/nar/27.1.35	biology;whole genome sequencing;bioinformatics;genetics;alignment-free sequence analysis	Comp.	-2.376093059215526	-60.77575913023667	177699
1cf28698c762461f101aaf2753a5adb621b24e92	asgard: an open-access database of annotated transcriptomes for emerging model arthropod species	genes;animals;molecular sequence annotation;databases genetic;arthropods;models animal;journal article;access to information;transcriptome;user computer interface;base sequence;species specificity	The increased throughput and decreased cost of next-generation sequencing (NGS) have shifted the bottleneck genomic research from sequencing to annotation, analysis and accessibility. This is particularly challenging for research communities working on organisms that lack the basic infrastructure of a sequenced genome, or an efficient way to utilize whatever sequence data may be available. Here we present a new database, the Assembled Searchable Giant Arthropod Read Database (ASGARD). This database is a repository and search engine for transcriptomic data from arthropods that are of high interest to multiple research communities but currently lack sequenced genomes. We demonstrate the functionality and utility of ASGARD using de novo assembled transcriptomes from the milkweed bug Oncopeltus fasciatus, the cricket Gryllus bimaculatus and the amphipod crustacean Parhyale hawaiensis. We have annotated these transcriptomes to assign putative orthology, coding region determination, protein domain identification and Gene Ontology (GO) term annotation to all possible assembly products. ASGARD allows users to search all assemblies by orthology annotation, GO term annotation or Basic Local Alignment Search Tool. User-friendly features of ASGARD include search term auto-completion suggestions based on database content, the ability to download assembly product sequences in FASTA format, direct links to NCBI data for predicted orthologs and graphical representation of the location of protein domains and matches to similar sequences from the NCBI non-redundant database. ASGARD will be a useful repository for transcriptome data from future NGS studies on these and other emerging model arthropods, regardless of sequencing platform, assembly or annotation status. This database thus provides easy, one-stop access to multi-species annotated transcriptome information. We anticipate that this database will be useful for members of multiple research communities, including developmental biology, physiology, evolutionary biology, ecology, comparative genomics and phylogenomics. Database URL: asgard.rc.fas.harvard.edu.	101 mouse;accessibility;accession number (identifier);accession number (bioinformatics);amphipoda;annotation;arbovirus encephalitis;arthropods;base excision repair;baseline (configuration management);bedbugs;biopolymer sequencing;cellular phone;communications satellite;community;database;de novo transcriptome assembly;description;developmental biology;download;ecology;experiment;fasta format;gene ontology;genetic screening method;genomics;graphical user interface;homology (biology);information retrieval;interface device component;interference (communication);massively-parallel sequencing;ncbi taxonomy;national center for biotechnology information;ninety nine;numerous;open reading frames;physical vapor deposition;protein domain;rna interference;science;sequence read archive;simoselaps bimaculatus;software testing;subphylum crustacea;throughput;uniform resource locator;upload;vectorbase;version;web search engine;whole genome sequencing;negative regulation of reactive oxygen species biosynthetic process;physiological aspects	Victor Zeng;Cassandra G. Extavour	2012		10.1093/database/bas048	biology;transcriptome;bioinformatics;gene;world wide web	Comp.	-1.1528569269994282	-59.961891918615905	177884
1f4ff7fc37d9fc321d96c0cbcaf662a555abd475	a parallel algorithm for de novo peptide sequencing	simulation and modeling;parallel algorithm;systems biology;physiological cellular and medical topics;computational biology bioinformatics;algorithms;bioinformatics	Introduction Protein identification is a main problem in proteomics, the large-scale analysis of proteins. Tandem mass spectrometry (MS/MS) provides an important tool to handle protein identification problem. Indeed the spectrometer is capable of ionizing a mixture of peptides, essentially several copies of the same unknown peptide, dissociating every molecule into two fragments called complementary ions, and measuring the mass/charge ratios of the peptides and of their fragments. These measures are visualized as mass peaks in a mass spectrum.	de novo protein structure prediction;parallel algorithm;proteomics	Elisa Mori;Sara Brunetti;Sonia Campa;Elena Lodi	2007	BMC Systems Biology	10.1186/1752-0509-1-S1-P61	computational biology;computational science;computer science;bioinformatics;parallel algorithm;systems biology	Comp.	1.7115533208943665	-62.77370105563692	177978
1f48f1020bd8e0aafb151eb97b05e46977bf73f0	frequent subsequence-based protein localization	amino acid;amino acid composition;protein localization;environmental stress;toxic metals;support vector machine	Extracellular plant proteins are involved in numerous processes including nutrient acquisition, communication with other soil organisms, protection from pathogens, and resistance to disease and toxic metals. Insofar as these proteins are strategically positioned to play a role in resistance to environmental stress, biologists are interested in proteomic tools in analyzing extracellular proteins. In this paper, we present three methods using frequent subsequences of amino acids: one based on support vector machines (SVM), one based on boosting and FSP, a new frequent subsequence pattern method. We test our methods on a plant dataset and the experimental results show that our methods perform better than the existing approaches based on amino acid composition.	algorithm;boosting (machine learning);extensibility;human-readable medium;in the beginning... was the command line;kerrison predictor;proteomics;support vector machine	Osmar R. Zaïane;Yang Wang;Randy Goebel;Gregory J. Taylor	2006		10.1007/11691730_5	support vector machine;amino acid;computer science;bioinformatics;machine learning;protein subcellular localization prediction	Comp.	2.0724886721766067	-63.01377182599624	178130
b4a9d6d14285a285dbe3dbdcfed20fe9aa050de3	fastalert - an automatic search system to alert about new entries in biological sequence databanks	dna;computer program;secuencia aminoacido;base donnee;proteine;sequence aminoacide;aminoacid sequence;interrogation base donnee;database;interrogacion base datos;base dato;systeme recherche;secuencia nucleotido;nucleotide sequence;sequence nucleotide;search system;proteins;sistema investigacion;proteina;programa computador;database query;programme ordinateur	This paper describes a new tool enabling awareness of new sequence databank entries of interest. The FastAlert system relieves the researcher from the burden of repeating FASTA searches in order to keep up with the rapidly growing amount of information found in biological sequence databanks. The query sequence can be submitted from any computer connected to the Internet. Upon registration, the databank, including the updates, is scanned at periodic intervals with the sequence provided. The results, so-called FastAlert reports, are delivered via electronic mail. The reports contain the FASTA best-scores list and the similarity statistics for each entry listed.	alert:type:point in time:^patient:nominal;databases;email;fasta;internet;question (inquiry);scanning;registration - actclass	F. Eggenberger;Nicole Redaschi;Reinhard Dölz	1996	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/12.2.129	biology;nucleic acid sequence;bioinformatics;data mining;genetics;dna	Comp.	-2.545632284390712	-59.94206450940463	178362
4c987ffb492e44acc010cbeb2347b92e257d7b59	hmdb: the human metabolome database	genes;community;metabolic diseases;metabolomics;metabolic networks and pathways;mass spectra;mass spectrometry;hematuria;enzyme;nuclear magnetic resonance;metabolites;information gathering;internet;enzymes;disease association;nuclear magnetic resonance biomolecular;humans;user computer interface;databases factual;quality control;mutation;metabolism;single nucleotide polymorphism;cerebrospinal fluid	The Human Metabolome Database (HMDB) is currently the most complete and comprehensive curated collection of human metabolite and human metabolism data in the world. It contains records for more than 2180 endogenous metabolites with information gathered from thousands of books, journal articles and electronic databases. In addition to its comprehensive literature-derived data, the HMDB also contains an extensive collection of experimental metabolite concentration data compiled from hundreds of mass spectra (MS) and Nuclear Magnetic resonance (NMR) metabolomic analyses performed on urine, blood and cerebrospinal fluid samples. This is further supplemented with thousands of NMR and MS spectra collected on purified, reference metabolites. Each metabolite entry in the HMDB contains an average of 90 separate data fields including a comprehensive compound description, names and synonyms, structural information, physico-chemical data, reference NMR and MS spectra, biofluid concentrations, disease associations, pathway information, enzyme data, gene sequence data, SNP and mutation data as well as extensive links to images, references and other public databases. Extensive searching, relational querying and data browsing tools are also provided. The HMDB is designed to address the broad needs of biochemists, clinical chemists, physicians, medical geneticists, nutritionists and members of the metabolomics community. The HMDB is available at: www.hmdb.ca.	bibliographic reference;book;cerebrospinal fluid;chemical vapor deposition;compiler;database model;genbank;gene regulatory network;human metabolome database;mental association;metabolomics;metabolomics;mutation;name;nuclear magnetic resonance;published database	David S. Wishart;Dan Tzur;Craig Knox;Roman Eisner;Anchi Guo;Nelson Young;Dean Cheng;Kevin Jewell;David Arndt;Summit Sawhney;Chris Fung;Lisa Nikolai;Mike Lewis;Marie-Aude Coutouly;Ian J. Forsythe;Peter Tang;Savita Shrivastava;Kevin Jeroncic;Paul Stothard;Godwin Amegbey;David Block;David D. Hau	2007		10.1093/nar/gkl923	biology;biochemistry;enzyme;e. coli metabolome database;mass spectrometry;bioinformatics;metabolomics;human metabolome database;genetics	Comp.	-1.2837926855464836	-61.36926050163936	178409
d81668aee471a7318686b148ba942c13e57c2350	from data repositories to submission portals: rethinking the role of domain-specific databases in collectf	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Domain-specific databases are essential resources for the biomedical community, leveraging expert knowledge to curate published literature and provide access to referenced data and knowledge. The limited scope of these databases, however, poses important challenges on their infrastructure, visibility, funding and usefulness to the broader scientific community. CollecTF is a community-oriented database documenting experimentally validated transcription factor (TF)-binding sites in the Bacteria domain. In its quest to become a community resource for the annotation of transcriptional regulatory elements in bacterial genomes, CollecTF aims to move away from the conventional data-repository paradigm of domain-specific databases. Through the adoption of well-established ontologies, identifiers and collaborations, CollecTF has progressively become also a portal for the annotation and submission of information on transcriptional regulatory elements to major biological sequence resources (RefSeq, UniProtKB and the Gene Ontology Consortium). This fundamental change in database conception capitalizes on the domain-specific knowledge of contributing communities to provide high-quality annotations, while leveraging the availability of stable information hubs to promote long-term access and provide high-visibility to the data. As a submission portal, CollecTF generates TF-binding site information through direct annotation of RefSeq genome records, definition of TF-based regulatory networks in UniProtKB entries and submission of functional annotations to the Gene Ontology. As a database, CollecTF provides enhanced search and browsing, targeted data exports, binding motif analysis tools and integration with motif discovery and search platforms. This innovative approach will allow CollecTF to focus its limited resources on the generation of high-quality information and the provision of specialized access to the data.Database URL: http://www.collectf.org/.	annotation;binding sites;collectf;community;consortium;contribution;curation;databases;documented;domain-specific language;experiment;gene ontology;genome;genome, bacterial;identifier;motif;ontology (information science);portals;programming paradigm;published database;refseq;regulatory elements, transcriptional;regulatory submission;repository;scientific publication;software documentation;transcription factor;transcription (software);transcription, genetic;url data type;uniprot;uniprotkb	Sefa Kiliç;Dinara M. Sagitova;Shoshannah Wolfish;Benoit Bely;Mélanie Courtot;Stacy Ciufo;Tatiana A. Tatusova;Claire O'Donovan;Marcus C. Chibucos;Maria Jesus Martin;Ivan Erill	2016	Database : the journal of biological databases and curation	10.1093/database/baw055	text mining;medical research;computer science;bioinformatics;data mining;database;world wide web;information retrieval	Comp.	-2.371981737636243	-61.5945291028134	178895
cc9acd8e1ed4b33f192f0b212bd919c7c445f66a	david-ws: a stateful web service to facilitate gene/protein list analysis	genes;software;molecular sequence annotation;databases genetic;internet;proteins;computational biology	SUMMARY The database for annotation, visualization and integrated discovery (DAVID), which can be freely accessed at http://david.abcc.ncifcrf.gov/, is a web-based online bioinformatics resource that aims to provide tools for the functional interpretation of large lists of genes/proteins. It has been used by researchers from more than 5000 institutes worldwide, with a daily submission rate of ∼1200 gene lists from ∼400 unique researchers, and has been cited by more than 6000 scientific publications. However, the current web interface does not support programmatic access to DAVID, and the uniform resource locator (URL)-based application programming interface (API) has a limit on URL size and is stateless in nature as it uses URL request and response messages to communicate with the server, without keeping any state-related details. DAVID-WS (web service) has been developed to automate user tasks by providing stateful web services to access DAVID programmatically without the need for human interactions.   AVAILABILITY The web service and sample clients (written in Java, Perl, Python and Matlab) are made freely available under the DAVID License at http://david.abcc.ncifcrf.gov/content.jsp?file=WS.html.	annotation;application programming interface;clients;david bioinformatics resources;imagery;interaction;interface device component;java programming language;matlab;online locator service;perl;python;regulatory submission;scientific publication;server (computing);state (computer science);stateful firewall;stateless protocol;uniform resource locator;user interface;web application;web service;message	Xiaoli Jiao;Brad T. Sherman;Da Wei Huang;Robert M. Stephens;Michael W. Baseler;H. Clifford Lane;Richard A. Lempicki	2012		10.1093/bioinformatics/bts251	web service;biology;url redirection;the internet;server-side redirect;computer science;bioinformatics;web api;gene;data mining;database;world wide web;genetics	Web+IR	-3.6513599161465407	-59.79934384291975	178912
23f7358be502145df61cd99ea682feef2004c560	protein-chemical evidence for the signal sequence of the pro-ompa protein			signal peptides	K. Gamon;W. Schmidmayr;U. Henning	1980	Nucleic acids research		ompa protein;genetics;signal peptide;biology	Logic	2.21102625319875	-63.77435015142778	179045
07003ffdfa874c448c7d5a8c6fb979155017f13b	mirex: a platform for comparative exploration of plant pri-mirna expression data	software;databases nucleic acid;rna plant;data mining;internet;arabidopsis;user computer interface;micrornas;gene expression profiling	mirEX is a comprehensive platform for comparative analysis of primary microRNA expression data. RT-qPCR-based gene expression profiles are stored in a universal and expandable database scheme and wrapped by an intuitive user-friendly interface. A new way of accessing gene expression data in mirEX includes a simple mouse operated querying system and dynamic graphs for data mining analyses. In contrast to other publicly available databases, the mirEX interface allows a simultaneous comparison of expression levels between various microRNA genes in diverse organs and developmental stages. Currently, mirEX integrates information about the expression profile of 190 Arabidopsis thaliana pri-miRNAs in seven different developmental stages: seeds, seedlings and various organs of mature plants. Additionally, by providing RNA structural models, publicly available deep sequencing results, experimental procedure details and careful selection of auxiliary data in the form of web links, mirEX can function as a one-stop solution for Arabidopsis microRNA information. A web-based mirEX interface can be accessed at http://bioinfo.amu.edu.pl/mirex.	data mining;database;databases;deep sequencing;gene expression profiling;interface device component;micrornas;mirex;organ;plant seeds;qualitative comparative analysis;seedlings;usability;web application;windows rt;negative regulation of pri-mirna transcription from rna polymerase ii promoter	Dawid Bielewicz;Jakub Dolata;Andrzej Zielezinski;Sylwia Alaba;Bogna Szarzynska;Michal W. Szczesniak;Artur Jarmolowski;Zofia Szweykowska-Kulinska;Wojciech M. Karlowski	2012		10.1093/nar/gkr878	biology;the internet;bioinformatics;gene expression profiling;genetics;microrna	Comp.	-1.0523009473040874	-59.40928366463585	179337
869e7ea465b0856b9ce31a05f1210cef5e5ea506	the sumo server: 3d search for protein functional sites	protein function;amino acid;ligand binding;large scale;drug design;scientific communication;3d structure;protein data bank	UNLABELLED We provide the scientific community with a web server which gives access to SuMo, a bioinformatic system for finding similarities in arbitrary 3D structures or substructures of proteins. SuMo is based on a unique representation of macromolecules using selected triplets of chemical groups having their own geometry and symmetry, regardless of the restrictive notions of main chain and lateral chains of amino acids. The heuristic for extracting similar sites was used to drive two major large-scale approaches. First, searching for ligand binding sites onto a query structure has been made possible by comparing the structure against each of the ligand binding sites found in the Protein Data Bank (PDB). Second, the reciprocal process, i.e. searching for a given 3D site of interest among the structures of the PDB is also possible and helps detect cross-reacting targets in drug design projects.   AVAILABILITY The web server is freely accessible to academia through http://sumo-pbil.ibcp.fr and full support is available from MEDIT (http://www.medit.fr).   CONTACT mjambon@burnham.org.	academia (organization);amino acids;binding sites;bio-informatics;bioinformatics;drug design;heuristic;lateral thinking;ligands;markov chain;protein data bank;query language;question (inquiry);server (computing);web server;world wide web;macromolecule	Martin Jambon;Olivier Andrieu;Christophe Combet;Gilbert Deléage;François Delfaud;Christophe Geourjon	2005	Bioinformatics	10.1093/bioinformatics/bti645	amino acid;protein data bank;computer science;bioinformatics;data mining;ligand;world wide web;drug design	Comp.	-0.745903439264256	-60.594358447815054	179449
26239dc6b7f9a2dc48a4c345dd2762fe44b4f46b	the intact molecular interaction database in 2012	genes;software;animals;controlled vocabulary;vocabulary controlled;computer graphics;molecular sequence annotation;databases genetic;internet;proteins;level of detail;false positive reactions;protein structure tertiary;directional data;source code;humans;user computer interface;protein interaction mapping;computational biology;molecular interactions;information storage and retrieval;sequence analysis protein;programming languages;open source;databases protein	IntAct is an open-source, open data molecular interaction database populated by data either curated from the literature or from direct data depositions. Two levels of curation are now available within the database, with both IMEx-level annotation and less detailed MIMIx-compatible entries currently supported. As from September 2011, IntAct contains approximately 275,000 curated binary interaction evidences from over 5000 publications. The IntAct website has been improved to enhance the search process and in particular the graphical display of the results. New data download formats are also available, which will facilitate the inclusion of IntAct's data in the Semantic Web. IntAct is an active contributor to the IMEx consortium (http://www.imexconsortium.org). IntAct source code and data are freely available at http://www.ebi.ac.uk/intact.	annotation;binding (molecular function);digital curation;download;infographic;interactome;open-source software;population;semantic web;source code;format	Samuel Kerrien;Bruno Aranda;Lionel Breuza;Alan Bridge;Fiona Broackes-Carter;Carol Chen;Margaret Duesbury;Marine Dumousseau;Marc Feuermann;Ursula Hinz;Christine Jandrasits;Rafael C. Jimenez;Jyoti Khadake;Usha Mahadevan;Patrick Masson;Ivo Pedruzzi;Eric Pfeiffenberger;Pablo Porras;Arathi Raghunath	2010		10.1093/nar/gkr1088	controlled vocabulary;the internet;bioinformatics;level of detail;gene;computer graphics;source code	Comp.	-1.9934628395216094	-60.74303630580896	179623
240b66faee512523b8acf83eb804623166e9c8a2	apidb: integrated resources for the apicomplexan bioinformatics resource center	animals;cryptosporidium;databases genetic;data type;apicomplexa;toxoplasma;internet;plasmodium;user computer interface;genome protozoan;computational biology;systems integration	ApiDB (http://ApiDB.org) represents a unified entry point for the NIH-funded Apicomplexan Bioinformatics Resource Center (BRC) that integrates numerous database resources and multiple data types. The phylum Apicomplexa comprises numerous veterinary and medically important parasitic protozoa including human pathogenic species of the genera Cryptosporidium, Plasmodium and Toxoplasma. ApiDB serves not only as a database in its own right, but as a single web-based point of entry that unifies access to three major existing individual organism databases (PlasmoDB.org, ToxoDB.org and CryptoDB.org), and integrates these databases with data available from additional sources. Through the ApiDB site, users may pose queries and search all available apicomplexan data and tools, or they may visit individual component organism databases.	academic medical centers;apicomplexa;bioinformatics resource centers;database;databases;entry point;genera;parasites;parasitic element (electrical networks);phylum (taxon);plasmodium <genus>;resource identifier:uri:pt:clinical document:nom;toxoplasma;united states national institutes of health;web application	Cristina Aurrecoechea;Mark Heiges;Haiming Wang;Zhiming Wang;Steve Fischer;Philippa Rhodes;John A. Miller;Eileen Kraemer;Christian J. Stoeckert;David S. Roos;Jessica C. Kissinger	2007		10.1093/nar/gkl880	biology;the internet;data type;bioinformatics;ecology;system integration	DB	-1.8030939336731155	-61.66100630323978	179858
c1b691ec7b8e74acfd32a5ae92ba397533f7f37b	biomart as an integration solution for the international knockout mouse consortium	international cooperation;animals;mice;embryonic stem cells;gene knockout techniques;mice knockout;database management systems;molecular sequence annotation;databases genetic;internet;humans;societies;user computer interface;phenotype;biomedical research	In this article, we describe the use of the BioMart data management system to provide integrated access to International Knockout Mouse Consortium (IKMC) data and other related mouse resources. The IKMC is currently mutating all mouse protein-coding genes in embryonic stem (ES) cells using gene targeting and gene trapping approaches. The BioMart portal allows researchers to identify and obtain IKMC knockout vectors, ES cells and mice for genes of interest. Gene annotation, expression, phenotype and disease data is also integrated from external BioMarts, allowing selection of IKMC products by a wide variety of criteria. These products are invaluable for researchers involved in the elucidation of gene function and the role of individual genes in human disease. Here, we describe these datasets in more detail and illustrate the functionality of the portal using several examples.	biomart;consortium;crown group;dna integration;database;gene annotation;gene targeting;hepatic;knockout;cellular targeting;recurrent childhood brain stem glioma	Darren J. Oakley;Vivek Iyer;William C. Skarnes;Damian Smedley	2011		10.1093/database/bar028	international knockout mouse consortium;biology;the internet;biotechnology;bioinformatics;phenotype;data mining;genetics;embryonic stem cell	Comp.	-1.2803123744030014	-61.4139613057334	180151
7fe03654e6aae7c13a1bb3efde389731e11ad8c6	tops: an enhanced database of protein structural topology	animals;hydrogen bond;protein structure secondary;pattern search;protein structure;hydrogen bonding;structure comparison;internet;proteins;secondary structure;protein folding;humans;user computer interface;computational biology;information storage and retrieval;databases protein	The TOPS database holds topological descriptions of protein structures. These compact and highly abstract descriptions reduce the protein fold to a sequence of Secondary Structure Elements (SSEs) and three sets of pairwise relationships between them, hydrogen bonds relating parallel and anti- parallel beta strands, spatial adjacencies relating neighbouring SSEs, and the chiralities of selected supersecondary structures, including connections in betaalphabeta units and between parallel alpha helices. The database is used as a resource for visualizing folding topologies, fast topological pattern searching and structure comparison. Here, significant enhancements to the TOPS database are described. The topological description has been enhanced to include packing relationships between helices, which significantly improves the description of protein folds with little beta strand content. Further, the topological description has been annotated with sequence information. The query interfaces to the database have been improved and the new version can be found at http://www.tops.leeds.ac.uk/.	anatomy, regional;description;hydrogen;question (inquiry);sequence alignment;set packing;strand (programming language);tops	Ioannis Michalopoulos;Gilleain M. Torrance;David R. Gilbert;David R. Westhead	2004	Nucleic acids research	10.1093/nar/gkh060	bioinformatics;hydrogen bond	Comp.	1.5122790540667943	-60.386782355704035	180207
3cc8d9468baae247ca1fbff892a8cf0d5d470021	secret4: a web-based bacterial type iv secretion system resource	dna;genes;community;software;host organism;leptocyte;databases genetic;agrobacterium tumefaciens;translocation genetics;genetics;bodily secretions;bacterial secretion systems;internet;genome;genome bacterial;sequence alignment;bacteria;genes bacterial;infection;bacterial proteins	SecReT4 (http://db-mml.sjtu.edu.cn/SecReT4/) is an integrated database providing comprehensive information of type IV secretion systems (T4SSs) in bacteria. T4SSs are versatile assemblages that promote genetic exchange and/or effector translocation with consequent impacts on pathogenesis and genome plasticity. T4SSs have been implicated in conjugation, DNA uptake and release and effector translocation. The effectors injected into eukaryotic target cells can lead to alteration of host cellular processes during infection. SecReT4 offers a unique, highly organized, readily exploreable archive of known and putative T4SSs and cognate effectors in bacteria. It currently contains details of 10 752 core components mapping to 808 T4SSs and 1884 T4SS effectors found in representatives of 289 bacterial species, as well as a collection of more than 900 directly related references. A broad range of similarity search, sequence alignment, phylogenetic, primer design and other functional analysis tools are readily accessible via SecReT4. We propose that SecReT4 will facilitate efficient investigation of large numbers of these systems, recognition of diverse patterns of sequence-, gene- and/or functional conservation and an improved understanding of the biological roles and significance of these versatile molecular machines. SecReT4 will be regularly updated to ensure its ongoing maximum utility to the research community.	archive;bacteria;bibliographic reference;greater than;primer;phylogenetics;quaternions and spatial rotation;sequence alignment;similarity search;web application	Dexi Bi;Linmeng Liu;Cui Tai;Zixin Deng;Kumar Rajakumar;Hong-Yu Ou	2013		10.1093/nar/gks1248	biology;community;the internet;chromosomal translocation;bacteria;bioinformatics;gene;sequence alignment;genetics;dna;genome	Comp.	-0.019841157287444212	-60.23440114363807	180294
c221c54b61d59d3f48f0815f52b784d9c07fd805	livercancermarkerrif: a liver cancer biomarker interactive curation system combining text mining and expert annotations	database management systems;data mining;tumor markers biological;liver neoplasms;internet;humans;data curation;user computer interface;computational biology	UNLABELLED Biomarkers are biomolecules in the human body that can indicate disease states and abnormal biological processes. Biomarkers are often used during clinical trials to identify patients with cancers. Although biomedical research related to biomarkers has increased over the years and substantial effort has been expended to obtain results in these studies, the specific results obtained often contain ambiguities, and the results might contradict each other. Therefore, the information gathered from these studies must be appropriately integrated and organized to facilitate experimentation on biomarkers. In this study, we used liver cancer as the target and developed a text-mining-based curation system named LiverCancerMarkerRIF, which allows users to retrieve biomarker-related narrations and curators to curate supporting evidence on liver cancer biomarkers directly while browsing PubMed. In contrast to most of the other curation tools that require curators to navigate away from PubMed and accommodate distinct user interfaces or Web sites to complete the curation process, our system provides a user-friendly method for accessing text-mining-aided information and a concise interface to assist curators while they remain at the PubMed Web site. Biomedical text-mining techniques are applied to automatically recognize biomedical concepts such as genes, microRNA, diseases and investigative technologies, which can be used to evaluate the potential of a certain gene as a biomarker. Through the participation in the BioCreative IV user-interactive task, we examined the feasibility of using this novel type of augmented browsing-based curation method, and collaborated with curators to curate biomarker evidential sentences related to liver cancer. The positive feedback received from curators indicates that the proposed method can be effectively used for curation. A publicly available online database containing all the aforementioned information has been constructed at http://btm.tmu.edu.tw/livercancermarkerrif in an attempt to facilitate biomarker-related studies.   DATABASE URL http://btm.tmu.edu.tw/LiverCancerMarkerRIF/	augmented browsing;biocreative;biological markers;biomedical text mining;digital curation;experiment;interface device component;liver and intrahepatic biliary tract carcinoma;liver diseases;malignant neoplasms;malignant neoplasm of liver;name;norm (social);patients;positive feedback;pubmed;tumor markers;uniform resource locator;usability;user interface;sentence	Hong-Jie Dai;Johnny Chi-Yang Wu;Wei-San Lin;Aaron James F. Reyes;Mira Anne C. dela Rosa;Syed Abdul Shabbir;Richard Tzong-Han Tsai;Wen-Lian Hsu	2014		10.1093/database/bau085	the internet;data curation;computer science;bioinformatics;data mining;database;world wide web;information retrieval	HCI	-1.8463064469470498	-63.24719399082936	181356
eb251b4051782d8f8033bba7c754c1ac54fd920e	development of a workflow for protein sequence analysis based on the taverna workbench software	homology search;web service;taverna workbench;web services;protein sequence analysis;workflow;multiple sequence alignment;article	A workflow based on the Taverna Workbench® software and tentatively named WPSA was developed to perform a generic protein sequence analysis eliminating the need to cut and paste data throughout web applications. The program performs a homology search, a multiple sequence alignment and a phylogeny analysis using PHYLogeny Interface Package (PHYLIP). The workflow designed gives a fast and significant answer to the user about the input sequence entered taking between 5 to 10 minutes to run depending on the Internet connection and web services.	mysql workbench;sequence analysis	Mariana B. Monteiro;Manuela E. Pintado;Francisco X. Malcata;Conrad Bessant;Patrícia R. Moreira	2009		10.1007/978-3-642-02481-8_169	web service;computer science;bioinformatics;database;world wide web;workflow engine	Comp.	-4.133067251366196	-59.14182488993055	181364
cba4023ff2dec610d899b998d2492bc41c296a7a	the metacyc database of metabolic pathways and enzymes and the biocyc collection of pathway/genome databases		The MetaCyc database (MetaCyc.org) is a freely accessible comprehensive database describing metabolic pathways and enzymes from all domains of life. The majority of MetaCyc pathways are small-molecule metabolic pathways that have been experimentally determined. MetaCyc contains more than 2400 pathways derived from >46,000 publications, and is the largest curated collection of metabolic pathways. BioCyc (BioCyc.org) is a collection of 5700 organism-specific Pathway/Genome Databases (PGDBs), each containing the full genome and predicted metabolic network of one organism, including metabolites, enzymes, reactions, metabolic pathways, predicted operons, transport systems, and pathway-hole fillers. The BioCyc website offers a variety of tools for querying and analyzing PGDBs, including Omics Viewers and tools for comparative analysis. This article provides an update of new developments in MetaCyc and BioCyc during the last two years, including addition of Gibbs free energy values for compounds and reactions; redesign of the primary gene/protein page; addition of a tool for creating diagrams containing multiple linked pathways; several new search capabilities, including searching for genes based on sequence patterns, searching for databases based on an organism's phenotypes, and a cross-organism search; and a metabolite identifier translation service.		Ron Caspi;Richard Billington;Luciana Ferrer;Hartmut Foerster;Carol A. Fulcher;Ingrid M. Keseler;Anamika Kothari;Markus Krummenacker;Mario Latendresse;Lukas A. Mueller;Quang Ong;Suzanne M. Paley;Pallavi Subhraveti;Daniel S. Weaver;Peter D. Karp	2016	Nucleic acids research	10.1093/nar/gkv1164	genomics;genetics;biopax : biological pathways exchange;metabolic network;database;genome;ecocyc;human microbiome project;metabolic pathway;metacyc;biology	Comp.	-0.9854047153148533	-60.485109731235966	181805
4d2890af1906f06997fdd3290e674e436b28eb5a	sdrf2graph – a visualization tool of a spreadsheet-based description of experimental processes	directed acyclic graph;software;computer graphics;databases genetic;computational biology bioinformatics;internet;information dissemination;algorithms;visual feedback;user computer interface;combinatorial libraries;next generation sequencing;computational biology;computer appl in life sciences;information storage and retrieval;microarrays;bioinformatics	As larger datasets are produced with the development of genome-scale experimental techniques, it has become essential to explicitly describe the meta-data (information describing the data) generated by an experiment. The experimental process is a part of the meta-data required to interpret the produced data, and SDRF (Sample and Data Relationship Format) supports its description in a spreadsheet or tab-delimited file. This format was primarily developed to describe microarray studies in MAGE-tab, and it is being applied in a broader context in ISA-tab. While the format provides an explicit framework to describe experiments, increase of experimental steps makes it less obvious to understand the content of the SDRF files. Here, we describe a new tool, SDRF2GRAPH, for displaying experimental steps described in an SDRF file as an investigation design graph, a directed acyclic graph representing experimental steps. A spreadsheet, in Microsoft Excel for example, which is used to edit and inspect the descriptions, can be directly input via a web-based interface without converting to tab-delimited text. This makes it much easier to organize large contents of SDRF described in multiple spreadsheets. SDRF2GRAPH is applicable for a wide range of SDRF files for not only microarray-based analysis but also other genome-scale technologies, such as next generation sequencers. Visualization of the Investigation Design Graph (IDG) structure leads to an easy understanding of the experimental process described in the SDRF files even if the experiment is complicated, and such visualization also encourages the creation of SDRF files by providing prompt visual feedback.	abbreviations;acquired immunodeficiency syndrome;cd151 wt allele;cns disorder;clinical use template;delimiter;description;design of experiments;directed acyclic graph;experiment;fantom;gnu;gene expression profiling;graph - visual representation;graphviz;home page;imagery;large;linux;manuscripts;microarray;minimum information about a microarray experiment;omics;operating system;programming languages;protocols documentation;r programming language;regulatory submission;repository;requirement;ruby;sample and data relationship format;spreadsheet;spreadsheet;tablet dosage form;transcriptome;unix;visual feedback;web application;contents - htmllinktype	Hideya Kawaji;Yoshihide Hayashizaki;Carsten O. Daub	2008	BMC Bioinformatics	10.1186/1471-2105-10-133	biology;dna sequencing;the internet;dna microarray;computer science;bioinformatics;theoretical computer science;computer graphics;directed acyclic graph;algorithm	Visualization	-3.568479348776262	-59.72729656666942	182282
01b79ed49ddd7f6b28fde46e7d02a61ac8db376b	obtaining relevant genes by analysis of expression arrays with a multi-agent system		Expression Arrays; Multiagent System; CBR System; Pathway  Triple negative breast cancer (TNBC) is an aggressive form of breast cancer. Despite treatment with chemotherapy, relapses are frequent and response to these treatments is not the same in younger women as in older women. Therefore, the identification of genes that provoke this disease is required, as well as the identification of therapeutic targets. There are currently different hybridization techniques, such as expression arrays, which measure the signal expression of both the genomic and transcriptomic levels of thousands of genes of a given sample. Probesets of Gene 1.0 ST GeneChip arrays provide the ultimate genome transcript coverage, providing a measurement of the expression level of the sample. This paper proposes a multi-agent system to manage information of expres-sion arrays, with the goal of providing an intuitive system that is also extensible to analyze and interpret the results. The roles of agent integrate different types of techniques, from statistical and data mining techniques that select a set of genes, to search techniques that find pathways in which such genes participate, and information extraction techniques that apply a CBR system to check if these genes are involved in the disease.		Alfonso González-Briones;Juan Ramos;Juan Francisco de Paz;Juan Manuel Corchado	2015		10.1007/978-3-319-19776-0_15	computer science;bioinformatics;artificial intelligence;multi-agent system;data mining	Comp.	-1.6895981281767383	-64.22180721762555	182545
89f78fecc10d6c0a4a43d5d86987ad82ad2fbaf3	a systems biology approach to modelling tea (camellia sinensis)	simulation and modeling;systems biology;physiological cellular and medical topics;computational biology bioinformatics;system biology;algorithms;camellia sinensis;bioinformatics	"""Tea manufacture induces a variety of stresses that affect tea quality. We are using microarray data to track transcriptional changes occurring during wounding and withering of the leaves to identify metabolic pathways that could influence tea aroma and flavour. Current transcriptomic approaches include the use of a partial, tea-specific array. In order to monitor a larger number of genes we have performed cross-species analyses using Affymetrix Arabidopsis genome arrays [1]. Arabidopsis metabolic SBML [2] network data from AraCyc [3], KEGG and Reactome were collated and merged, then subsequently overlaid with the tea expression data. Subnetworks were constructed by connecting the shortest paths between the differentially expressed genes and the downstream aroma-related compounds, therefore identifying the pathways involved in aroma. from BioSysBio 2007: Systems Biology, Bioinformatics and Synthetic Biology Manchester, UK. 11–13 January 2007 Published: 8 May 2007 BMC Systems Biology 2007, 1(Suppl 1):P13 doi:10.1186/1752-0509-1-S1-P13 <supplement> <title> <p>BioSysBio 2007: Systems Biology, Bioinformatics, Synthetic Biology</p> </title> <editor>John Cumbers, Xu Gu, Jong Sze Wong</editor> <note>Meeting abstracts – A single PDF containing all abstracts in this Supplement is available <a href=""""www.biomedcentral.com/content/files/pdf/1752-0509-1-S1-full.pdf"""">here</a>.</note> <url>http://www.biomedcentral.com/content/pdf/1752-0509-1-S1-info.pdf</url> </supplement> This abstract is available from: http://www.biomedcentral.com/1752-0509/1?issue=S1 © 2007 Marshall et al; licensee BioMed Central Ltd. This figure shows Cytoscape [4] layouts of (a) the merged AraCyc, KEGG and Reactome network, (b) the AraCyc metabolic network wit gene identifiers, (c) the subgraph extracted based on the tea wounding and withering expression data [identified by green nodes] connected to tea aroma rel ted compound [ide tifi d by re odes]. Figur 1 This figure shows Cytoscape [4] layouts of (a) the merged AraCyc, KEGG and Reactome network, (b) the AraCyc metabolic network with gene identifiers, (c) the subgraph extracted based on the tea wounding and withering expression data [identified by green nodes] connected to tea aroma related compounds [identified by red nodes]. (a) (b) (c) Page 1 of 2 (page number not for citation purposes) BMC Systems Biology 2007, 1(Suppl 1):P13 http://www.biomedcentral.com/1752-0509/1?issue=S1 Publish with BioMed Central  and every scientist can read your work free of charge """"BioMed Central will be the most significant development for disseminating the results of biomedical research in our lifetime."""" Sir Paul Nurse, Cancer Research UK Your research papers will be: available free of charge to the entire biomedical community peer reviewed and published immediately upon acceptance cited in PubMed and archived on PubMed Central yours — you keep the copyright Submit your manuscript here: http://www.biomedcentral.com/info/publishing_adv.asp BioMedcentral Conclusion We present the initial output of this project and address how cross-species expression data can be used to colour a network and analysed using a variety of subgraph analyses. Acknowledgements Many thanks to the NASC Arrays X-species Service, Peter Clarke, Shao Chih Kuo and Thomas Spriggs for their help throughout the project. References 1. Hammond JP, Broadley MR, Craigon DJ, Higgins J, Emmerson ZF, Townsend HJ, White PJ, May ST: Using genomic DNA-based probe-selection to improve the sensitivity of high-density oligonucleotide arrays when applied to heterologous species. Plant Methods 2005, 1:. 2. Hucka M, Finney A, Sauro HM, Bolouri H, Doyle JC, Kitano H, Arkin AP, Bornstein BJ, Bray D, Cornish-Bowden A, et al.: The Systems Biology Markup Language (SBML): A medium for the representation and exchange of biochemical network models. Bioinformatics 2003, 19:524-531. 3. Mueller LA, Zhang P, Rhee SY: AraCyc: A Biochemical Pathway Database for Arabidopsis. Plant Physiology 2003, 132:453-460. 4. Shannon P, Markiel A, Ozier O, Baliga NS, Wang JT, Ramage D, Amin N, Schwikowski B, Ideker T: Cytoscape: A Software Environment for Integrated Models of Biomolecular Interaction Networks. Genome Research 2003, 13:2498-2504. Page 2 of 2 (page number not for citation purposes)"""	archive;b. j. fogg;bmc systems biology;bioinformatics;cytoscape;dhrystone;downstream (software development);edmund m. clarke;emoticon;gene regulatory network;heterojunction;higgins;identifier;intelligent platform management interface;jt (visualization format);kegg;markup language;microarray;nsb/appstudio;portable document format;pubmed central;sbml;sy telecom;scratch: the ultimate dj;shannon (unit);shortest path problem;synthetic biology;synthetic intelligence;wang tile;zermelo–fraenkel set theory	Alex Marshall;Sirisha Gollapudi;Jacquie de Silva;Charlie Hodgman	2007	BMC Systems Biology	10.1186/1752-0509-1-S1-P13	biology;botany;computer science;bioinformatics;systems biology	Comp.	-0.6370887908150155	-63.23479713240905	182908
09731313e3583ffaedd0e958b5b772f3e8bc7e8e	a computational tool for the simulation and optimization of microbial strains accounting integrated metabolic/regulatory information	software tool;integrable model;metabolic engineering;metabolic models;integrated models;regulatory models;open source software;open source	BACKGROUND AND SCOPE Recently, a number of methods and tools have been proposed to allow the use of genome-scale metabolic models for the phenotype simulation and optimization of microbial strains, within the field of Metabolic Engineering (ME). One of the limitations of most of these algorithms and tools is the fact that only metabolic information is taken into account, disregarding knowledge on regulatory events.   IMPLEMENTATION AND PERFORMANCES This work proposes a novel software tool that implements methods for the phenotype simulation and optimization of microbial strains using integrated models, encompassing both metabolic and regulatory information. This tool is developed as a plug-in that runs over OptFlux, a computational platform that aims to be a reference tool for the ME community.   AVAILABILITY The plug-in is made available in the OptFlux web site (www.optflux.org) together with examples and documentation.	algorithm;documentation;mathematical optimization;metabolic engineering;metabolic process, cellular;performance;plug (physical object);plug-in (computing);programming tool;simulation;web site	Paulo Vilaça;Isabel Rocha;Miguel Rocha	2011	Bio Systems	10.1016/j.biosystems.2010.11.012	biology;simulation;bioinformatics;metabolic engineering	Logic	-4.489183531127395	-60.27780842829852	183012
6685cfaac90b1ab3b615d9be09d1a0b49d4eec8f	rice proteome database based on two-dimensional polyacrylamide gel electrophoresis: its status in 2003	electrophoresis gel two dimensional;proteome;oryza sativa;internet;polyacrylamide gel electrophoresis;proteomics;computational biology;information storage and retrieval;databases protein	The Rice Proteome Database is the first detailed database to describe the proteome of rice. The current release contains 21 reference maps based on two-dimensional polyacrylamide gel electrophoresis (2D-PAGE) of proteins from rice tissues and subcellular compartments. These reference maps comprise 11 941 identified proteins showing tissue and subcellular localization, corresponding to 4180 separate protein entries in the database. The Rice Proteome Database contains the calculated properties of each protein such as molecular weight, isoelectric point and expression; experimentally determined properties such as amino acid sequences obtained using protein sequencers and mass spectrometry; and the results of database searches such as sequence homologies. The database is searchable by keyword, accession number, protein name, isoelectric point, molecular weight and amino acid sequence, or by selection of a spot on one of the 2D-PAGE reference maps. Cross-references are provided to tools for proteomics and to other 2D-PAGE databases, which in turn provide many links to other molecular databases. The information in the Rice Proteome Database is updated weekly, and is available on the World Wide Web at http://gene64.dna.affrc.go.jp/RPD/.	accession number (identifier);accession number (bioinformatics);amino acid sequence;amino acids;anatomical compartments;bibliographic reference;body tissue;database;experiment;gel electrophoresis (lab technique);homology (biology);isoelectric point;keyword;map;molecular weight;pierre robin syndrome;polyacrylamide gel electrophoresis;proteome;proteomics;spectrometry;world wide web;polyacrylamide gels	Setsuko Komatsu;Keiichi Kojima;Kouji Suzuki;Kazuo Ozaki;Kenichi Higo	2004	Nucleic acids research	10.1093/nar/gkh020	biology;molecular biology;the internet;bioinformatics;proteome;proteomics;genetics;polyacrylamide gel electrophoresis	Comp.	-1.5600744536520996	-60.406440274199234	183184
ad0782eda8db0b276e772744d78e4c1d8567adb7	the comptox chemistry dashboard: a community data resource for environmental chemistry	bioassay data;compound database;computational toxicology;data curation;edsp21;environmental chemistry;environmental fate and transport data;non-targeted analysis;open data;physicochemical properties;toxcast;toxrefdb;toxic substances control act (tsca);toxicity data	Despite an abundance of online databases providing access to chemical data, there is increasing demand for high-quality, structure-curated, open data to meet the various needs of the environmental sciences and computational toxicology communities. The U.S. Environmental Protection Agency’s (EPA) web-based CompTox Chemistry Dashboard is addressing these needs by integrating diverse types of relevant domain data through a cheminformatics layer, built upon a database of curated substances linked to chemical structures. These data include physicochemical, environmental fate and transport, exposure, usage, in vivo toxicity, and in vitro bioassay data, surfaced through an integration hub with link-outs to additional EPA data and public domain online resources. Batch searching allows for direct chemical identifier (ID) mapping and downloading of multiple data streams in several different formats. This facilitates fast access to available structure, property, toxicity, and bioassay data for collections of chemicals (hundreds to thousands at a time). Advanced search capabilities are available to support, for example, non-targeted analysis and identification of chemicals using mass spectrometry. The contents of the chemistry database, presently containing ~ 760,000 substances, are available as public domain data for download. The chemistry content underpinning the Dashboard has been aggregated over the past 15 years by both manual and auto-curation techniques within EPA’s DSSTox project. DSSTox chemical content is subject to strict quality controls to enforce consistency among chemical substance-structure identifiers, as well as list curation review to ensure accurate linkages of DSSTox substances to chemical lists and associated data. The Dashboard, publicly launched in April 2016, has expanded considerably in content and user traffic over the past year. It is continuously evolving with the growth of DSSTox into high-interest or data-rich domains of interest to EPA, such as chemicals on the Toxic Substances Control Act listing, while providing the user community with a flexible and dynamic web-based platform for integration, processing, visualization and delivery of data and resources. The Dashboard provides support for a broad array of research and regulatory programs across the worldwide community of toxicologists and environmental scientists.rnOpen image in new window	adverse reaction to drug;biological assay;chemical substance excluding protein or nucleic acid;cheminformatics;collections (publication);computation;dashboard;digital curation;download;ecology;environmental illness;identifier;poisons;published database;science;toxicologists;usb hub;united states environmental protection agency;video-in video-out;virtual community;web application;contents - htmllinktype;format	Antony J. Williams;Christopher M. Grulke;Jeff Edwards;Andrew D. McEachran;Kamel Mansouri;Nancy C. Baker;Grace Patlewicz;Imran Shah;John Wambaugh;Richard S. Judson;Ann M. Richard	2017		10.1186/s13321-017-0247-6	public domain;cheminformatics;open data;world wide web;data mining;bioinformatics;dynamic web page;computer science;data stream mining;identifier;data curation;upload	DB	-1.7871171840311537	-61.06789572081252	183191
61252ad10cec3e6535cd8c0678c8bf5aee4ecc15	epimodel: a system to build automatically systems of differential equations of compartmental type-epidemiological models	mathematica;computer program;type epidemiological model;mathematical parameters;disease transmission;convalescence;articulo;models biological;text file;epidemiological model;quadratic models;systems of differential equations;epidemiologic methods;human;mathematical model;priority journal;compartment model;differential equations;automatic building of systems of differential equations;article;computer simulation;building codes;programming languages;disease predisposition	In this paper we describe epiModel, a code developed in Mathematica that facilitates the building of systems of differential equations corresponding to type-epidemiological linear or quadratic models whose characteristics are defined in text files following an easy syntax. It includes the possibility of obtaining the equations of models involving age and/or sex groups.	appl1 gene;arabic numeral 100;epidemiology;limbo;mathematics;meningococcal infections;multi-compartment model;natural history;note (document);olami–feder–christensen model;orally disintegrating tablet dosage form;papillomaviridae;serial ata;simulation;springer (tank);wolfram mathematica;wolfram systemmodeler;biomathematics;meningococcal polysaccharide vaccine (mpsv4)	Juan Carlos Cortés;Almudena Sánchez-Sánchez;Francisco-José Santonja;Rafael J. Villanueva	2011	Computers in biology and medicine	10.1016/j.compbiomed.2011.06.018	computer simulation;computer science;theoretical computer science;machine learning;mathematical model;mathematics;multi-compartment model;differential equation;algorithm;statistics	Logic	0.6586231914776068	-65.32499877024942	183541
594d121c71a6e952be14da9f43ef2ac5f2d15373	i-tasser server: new development for protein structure and function predictions	software;ligands;binding sites;models molecular;internet;proteins;protein conformation;structural homology protein;algorithms;sequence analysis protein	The I-TASSER server (http://zhanglab.ccmb.med.umich.edu/I-TASSER) is an online resource for automated protein structure prediction and structure-based function annotation. In I-TASSER, structural templates are first recognized from the PDB using multiple threading alignment approaches. Full-length structure models are then constructed by iterative fragment assembly simulations. The functional insights are finally derived by matching the predicted structure models with known proteins in the function databases. Although the server has been widely used for various biological and biomedical investigations, numerous comments and suggestions have been reported from the user community. In this article, we summarize recent developments on the I-TASSER server, which were designed to address the requirements from the user community and to increase the accuracy of modeling predictions. Focuses have been made on the introduction of new methods for atomic-level structure refinement, local structure quality estimation and biological function annotations. We expect that these new developments will improve the quality of the I-TASSER server and further facilitate its use by the community for high-resolution structure and function prediction.	access network;algorithm;annotation;chris wallace (computer scientist);clinical use template;database;databases;download;experiment;function (biology);home page;i-tasser;image resolution;iterative method;level structure;libraries;library (computing);matching;manuscripts;medicine;nar 2;protein data bank;protein structure prediction;protein, organized by structure;refinement (computing);requirement;science;server (computer);server (computing);simulation;thread (computing);user interface device component;virtual community;wallace tree;method development	Jianyi Yang;Yonghui Zhang	2015		10.1093/nar/gkv342	protein structure;the internet;bioinformatics;binding site;protein structure database;ligand	Comp.	-1.3493274265655195	-59.631147833375074	183777
f8d0ab18c91e0239d488ab11b5d4d52087b843aa	a robust method for finding the automated best matched genes based on grouping similar fragments of large-scale references for genome assembly		Big data research on genomic sequence analysis has accelerated considerably with the development of next-generation sequencing. Currently, research on genomic sequencing has been conducted using various methods, ranging from the assembly of reads consisting of fragments to the annotation of genetic information using a database that contains known genome information. According to the development, most tools to analyze the new organelles’ genetic information requires different input formats such as FASTA, GeneBank (GB) and tab separated files. The various data formats should be modified to satisfy the requirements of the gene annotation system after genome assembly. In addition, the currently available tools for the analysis of organelles are usually developed only for specific organisms, thus the need for gene prediction tools, which are useful for any organism, has been increased. The proposed method—termed the genome_search_plotter—is designed for the easy analysis of genome information from the related references without any file format modification. Anyone who is interested in intracellular organelles such as the nucleus, chloroplast, and mitochondria can analyze the genetic information using the assembled contig of an unknown genome and a reference model without any modification of the data from the assembled contig.	big data;database;fasta;gene prediction;reference model;requirement;sequence analysis;xslt/muenchian grouping	Jaehee Jung;Jong Soo Kim;Young-Sik Jeong;Gangman Yi	2017	Symmetry	10.3390/sym9090192	computational biology;gene annotation;mathematics;combinatorics;genome;gene prediction;hybrid genome assembly;genome project;sequence assembly;reference genome;contig;bioinformatics	Comp.	-1.4417020319314378	-59.370252473749815	184098
cbb31fc44e68d415c19c229ec6db9c6a2fc2662e	epigenet: a graph database of interdependencies between genetic and epigenetic events in colorectal cancer	networks;graph database;computational molecular biology;molecular interdependencies;colorectal cancer;epigenetics	The development of colorectal cancer (CRC)-the third most common cancer type-has been associated with deregulations of cellular mechanisms stimulated by both genetic and epigenetic events. StatEpigen is a manually curated and annotated database, containing information on interdependencies between genetic and epigenetic signals, and specialized currently for CRC research. Although StatEpigen provides a well-developed graphical user interface for information retrieval, advanced queries involving associations between multiple concepts can benefit from more detailed graph representation of the integrated data. This can be achieved by using a graph database (NoSQL) approach. Data were extracted from StatEpigen and imported to our newly developed EpiGeNet, a graph database for storage and querying of conditional relationships between molecular (genetic and epigenetic) events observed at different stages of colorectal oncogenesis. We illustrate the enhanced capability of EpiGeNet for exploration of different queries related to colorectal tumor progression; specifically, we demonstrate the query process for (i) stage-specific molecular events, (ii) most frequently observed genetic and epigenetic interdependencies in colon adenoma, and (iii) paths connecting key genes reported in CRC and associated events. The EpiGeNet framework offers improved capability for management and visualization of data on molecular events specific to CRC initiation and progression.		Irina Balaur;Mansoor Saqi;Ana Barat;Artem Lysenko;Alexander Mazein;Christopher J. Rawlings;Heather J. Ruskin;Charles Auffray	2017	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2016.0095	nosql;cancer;bioinformatics;graph (abstract data type);graph database;interdependence;colorectal cancer;epigenetics;graphical user interface;computer science	Comp.	0.00019750058137727155	-62.06361867952121	184197
bcb7d7ab2d4bf0687ea50b08b62687ebab373e64	rnasoft: a suite of rna secondary structure prediction and design software tools	dna;software;software tool;rna secondary structure;internet;rna;thermodynamic model;secondary structure;nucleic acid conformation;rna secondary structure prediction;user computer interface;base sequence;molecular structure	DNA and RNA strands are employed in novel ways in the construction of nanostructures, as molecular tags in libraries of polymers and in therapeutics. New software tools for prediction and design of molecular structure will be needed in these applications. The RNAsoft suite of programs provides tools for predicting the secondary structure of a pair of DNA or RNA molecules, testing that combinatorial tag sets of DNA and RNA molecules have no unwanted secondary structure and designing RNA strands that fold to a given input secondary structure. The tools are based on standard thermodynamic models of RNA secondary structure formation. RNAsoft can be found online at http://www.RNAsoft.ca.	libraries;nanostructured materials;protein structure prediction;rna;software design;therapeutic procedure;thermodynamics	Mirela Andronescu;Rosalía Aguirre-Hernández;Anne Condon;Holger H. Hoos	2003	Nucleic acids research	10.1093/nar/gkg612	biology;the internet;rna;molecule;bioinformatics;nucleic acid secondary structure;genetics;dna;protein secondary structure	Comp.	0.4110292621957472	-60.67777602153669	184465
4ca24fed9cf926c6cf63c804f33d2b7e9298d524	shared genomics: high performance computing for distributed insights in genomic medical research	genome wide association study;hpc;statistical genetics	The study of the genetics of diseases is entering a new era. Increasingly, genome-wide association studies are being used to identify positions within the human genome that have a link with a disease condition. The number of genomic locations studied means that High Performance Computing (HPC) solutions will have to increasingly be used in the statistical analysis of these data sets. Understanding the biomedical implications of the statistical analysis will also require heavy use of bioinformatics annotation tools. In this paper we report the outcome of developing HPC statistical genetics analysis codes for use by clinical researchers. Statistical results are automatically annotated with relevant biological information by calling multiple web-services orchestrated via pre-existing scientific workflows. Access to the HPC codes and bioinformatics annotation processes is via a client Workbench which hides as much as possible from the user the HPC infrastructure and bioinformatics annotation processes, whilst aiding the exchange of ideas and results between stakeholders.	annotation;bioinformatics;code;computation (action);knowledge spillover;solutions;supercomputer;web service;while;workbench	David C. Hoyle;Mark Delderfield;Lee Kitching;Gareth Smith;Iain E. Buchan	2009	Studies in health technology and informatics	10.3233/978-1-60750-027-8-232	computational biology;bioinformatics;genetics	HPC	1.3563640251688127	-60.65469432634046	184601
4801034f75ab3e5a19b1af9db261ec13a77037e4	the personal genome browser: visualizing functions of genetic variants	software;genomics;computer graphics;genetic variation;internet;genome human;humans	Advances in high-throughput sequencing technologies have brought us into the individual genome era. Projects such as the 1000 Genomes Project have led the individual genome sequencing to become more and more popular. How to visualize, analyse and annotate individual genomes with knowledge bases to support genome studies and personalized healthcare is still a big challenge. The Personal Genome Browser (PGB) is developed to provide comprehensive functional annotation and visualization for individual genomes based on the genetic-molecular-phenotypic model. Investigators can easily view individual genetic variants, such as single nucleotide variants (SNVs), INDELs and structural variations (SVs), as well as genomic features and phenotypes associated to the individual genetic variants. The PGB especially highlights potential functional variants using the PGB built-in method or SIFT/PolyPhen2 scores. Moreover, the functional risks of genes could be evaluated by scanning individual genetic variants on the whole genome, a chromosome, or a cytoband based on functional implications of the variants. Investigators can then navigate to high risk genes on the scanned individual genome. The PGB accepts Variant Call Format (VCF) and Genetic Variation Format (GVF) files as the input. The functional annotation of input individual genome variants can be visualized in real time by well-defined symbols and shapes. The PGB is available at http://www.pgbrowser.org/.	annotation;biopolymer sequencing;built-in self-test;crew resource management, healthcare;heterozygote detection;high-throughput computing;knowledge bases;knowledge base;nucleotides;one thousand;personalization;petrolatum 1 mg/mg topical ointment;phenotype;prostaglandins b;scale-invariant feature transform;scanning;throughput;variant call format;whole genome sequencing	Liran Juan;Mingxiang Teng;Tianyi Zang;Yafeng Hao;Zhenxing Wang;Chengwu Yan;Yongzhuang Liu;Jie Li;Tianjiao Zhang;Yadong Wang	2014		10.1093/nar/gku361	biology;personal genomics;genomics;the internet;bioinformatics;genetic variation;computer graphics;genetics	Comp.	-2.256870624570024	-60.07897993301031	185335
7efd35eb509190bf1d006d4a28b1bf89b812241a	activities at the universal protein resource (uniprot)	community;representation;annotation;science technology;family;system;life sciences biomedicine;proteomics data;genome database;biochemistry molecular biology;ontology	The mission of the Universal Protein Resource (UniProt) (http://www.uniprot.org) is to provide the scientific community with a comprehensive, high-quality and freely accessible resource of protein sequences and functional annotation. It integrates, interprets and standardizes data from literature and numerous resources to achieve the most comprehensive catalog possible of protein information. The central activities are the biocuration of the UniProt Knowledgebase and the dissemination of these data through our Web site and web services. UniProt is produced by the UniProt Consortium, which consists of groups from the European Bioinformatics Institute (EBI), the SIB Swiss Institute of Bioinformatics (SIB) and the Protein Information Resource (PIR). UniProt is updated and distributed every 4 weeks and can be accessed online for searches or downloads.	amino acid sequence;annotation;biocurator;bioinformatics;consortium;external bus interface;geographic information systems;knowledge bases;knowledge base;peptide sequence;protein information resource;service implementation bean;uniprot;universal protein resource;web site;web service	The Uniprot Consortium	2014		10.1093/nar/gkt1140	computational biology;biology;community;bioinformatics;uniprot;ontology;system;representation	Comp.	-2.6822941748190328	-61.34504457581021	185340
c851dc7307c4e5c88a791662e114e3dadc7d0f67	pdbsum new things	models structural;protein structure secondary;anatomy regional;protein interaction domains and motifs;models molecular;protein conformation;protein structure tertiary;protein data bank;databases protein	PDBsum (http://www.ebi.ac.uk/pdbsum) provides summary information about each experimentally determined structural model in the Protein Data Bank (PDB). Here we describe some of its most recent features, including figures from the structure's key reference, citation data, Pfam domain diagrams, topology diagrams and protein-protein interactions. Furthermore, it now accepts users' own PDB format files and generates a private set of analyses for each uploaded structure.	accepting of extremity;anatomy, regional;diagram;experiment;pdbsum;pfam;protein data bank;citation;protein protein interaction	Roman A. Laskowski	2009		10.1093/nar/gkn860	biology;protein structure;protein data bank;bioinformatics;protein structure database	Comp.	-0.9224396299282485	-60.572983111184506	185427
d8d17f65d65cc4158740c222aec991a025d84fd8	semantic analysis of thyroid cancer cell proteins obtained from rare research opportunities	cellular proteins;countermeasures;disease impact;graphical queries;semantic knowledgebase;space research	Research in natural sciences is mainly done by means of experiments. Some of those experiments such as spaceflight-dependent experiments are extremely laborious, complex and expensive. Hence, they often remain rare events with little chances of statistical tests and possibilities of repetition. In order to make each single event as valuable as possible, a sophisticated comparison of experimental data received with the hundreds of millions of computer-stored documents appears necessary. We used results of an earlier study on proteome analysis of microgravity-exposed human thyroid cancer cells, selected twenty proteins which appeared gravity sensitive and investigated whether their change observed in cells under the loss of gravity could cause health problems in astronauts. Using network analysis via Knowledge Explorer (KE) we searched the literature for diseases related to one or more of the selected proteins. After using Linked Open Data (LOD) and other public resources to establish a comprehensive semantic knowledgebase around functional properties of the selected proteins, the collection's network was used to query a set of databases for the proteins' involvement in biosystems and human diseases. Finally, possible countermeasures could be proposed.		Johann Bauer;Daniela Grimm;Erich Alfred Gombocz	2017	Journal of biomedical informatics	10.1016/j.jbi.2017.10.011	data mining;linked data;experimental data;computer science;thyroid cancer;proteome;rare events;bioinformatics	Web+IR	-1.4767029962053915	-63.918092124769	185451
77d52f4e696e7064dbd3c2f075ed98aecc0133ee	the viroid and viroid-like rna database	databases;arn;genero humano;banque de donnees;computer communication networks;expert systems;sistemas expertos;phylogeny;viroides;hepatitis;viroide;bases de datos;hepatitis delta virus;information technology;rna satellite;virus;genre humain;information services;terminology as topic;viruses;internet;rna;service d information;technologie de l information;viroids;servicios de informacion;world wide web;humans;sequence alignment;mankind;rna viral;systeme expert;databases factual;tecnologia de la informacion;information storage and retrieval;hepatite;rna catalytic	The viroid and viroid-like RNA database is a compilation of all natural sequences published in journals or available from the GenBank and EMBL nucleotide sequence libraries. Several information regarding these RNA species such as the position of their self-catalytic domains and the open reading frame of the human hepatitits delta virus are provided. The database also includes a determination of the likely ancestral sequence of most species and a prediction of the most stable secondary structures of these sequences. This online database is available on the World Wide Web (http://www.callisto.si.usherb.ca/[symbol: see text]jpperra ). It should provide an excellent reference point for further phylogenetic and structure-function studies of these RNA species.	base sequence;catalytic domain;compiler;genbank;hepatitis delta virus;journal;libraries;nucleotides;open reading frame;phylogenetics;rna;reading frames (nucleotide sequence);scientific publication;viroids;world wide web;gamma-delta t-cell receptor	Daniel A. Lafontaine;Patrick Deschênes;Frédéric Bussière;Véronique Poisson;Jean-Pierre Perreault	1998	Nucleic acids research	10.1093/nar/27.1.186	biology;the internet;rna;virus;bioinformatics;sequence alignment;sequence database;refseq;information technology;genetics;information system	Comp.	-2.9026590556538956	-60.59819799027365	186043
a976aa04a14b416b8bece15848e685cf52a607c9	visualization of tuberculosis patient and mycobacterium tuberculosis complex genotype data via host-pathogen maps	dna;new york state;dna fingerprinting;tree maps;data mining;genetics;medical computing;data visualisation;visualization;spoligotypes tuberculosis visualization host pathogen maps tree maps;new york city;phylogenetic tree;new york city tb patient data tuberculosis patient mycobacterium tuberculosis genotype data visualization host pathogen maps mtbc dna fingerprints host pathogen relationship visualisation host pathogen relationship discovery mtbc strains multiple dna fingerprinting methods spoligotyping restriction fragment length polymorphisms rflp patient surveillance data spoligoforests phylogenetic tree pathogen genotyping space new york state tb patient data;restriction fragment length polymorphism;strain biomarkers data visualization asia pathogens genetics;diseases;host pathogen maps;spoligotypes;microorganisms bioinformatics biological techniques data mining data visualisation diseases dna genetics medical computing;biological techniques;mycobacterium tuberculosis complex;microorganisms;tuberculosis;bioinformatics	DNA fingerprints of Mycobacterium tuberculosis complex bacteria (MTBC) are routinely gathered from tuberculosis (TB) patient isolates for all TB patients in the United States to support TB tracking and control efforts, but few tools are available for visualizing and discovering host-pathogen relationships. We present a new visualization approach, host-pathogen maps, for simultaneously examining MTBC strains genotyped by multiple DNA fingerprinting methods such as spoligotyping and restriction fragment length polymorphisms (RFLP) typing along with associated patient surveillance data. The host-pathogen maps are dynamically coupled with spoligoforests or other phylogenetic tree approaches to allow easy navigation within the pathogen genotyping space. Visualization of New York State and New York City (NYC) TB patient data from 2001–2007 is used to illustrate how host-pathogen maps can be used to rapidly identify potential instances of uncontrolled spread of tuberculosis versus disease resulting from latent reactivation of prior infection, a critical distinction in tuberculosis control. Host-pathogen maps also reveal trends and anomalies in the relationships between patient groups and MTBC genetic lineages which can provide critical clues in epidemiology and contact investigations of TB.	chromosome (genetic algorithm);dna microarray;dna profiling;fingerprint (computing);latent dirichlet allocation;map;phylogenetic tree;phylogenetics;risk factor (computing);terabyte;the new york times;treemapping;uncontrolled format string;variable-length code	Kristin P. Bennett;Cagri Ozcaglar;Janani Ranganathan;Srivatsan Raghavan;Jacob Katz;Dan Croft;Bülent Yener;Amina Shabbeer	2011	2011 IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW)	10.1109/BIBMW.2011.6112364	biology;dna profiling;phylogenetic tree;visualization;bioinformatics;virology;microorganism;restriction fragment length polymorphism;genetics;dna;data visualization	Visualization	0.6471892099676194	-62.06869014411342	186400
47f57080bd252ff9da13caf22897613dc6bd976c	estuber db: an online database for tuber borchii est sequences	software integration;filamentous fungi;database management systems;web interface;databases genetic;chromosome mapping;sequence analysis dna;computational biology bioinformatics;ascomycota;internet;online systems;dna fungal;tandem repeat;algorithms;sequence alignment;user computer interface;combinatorial libraries;computer appl in life sciences;information storage and retrieval;expressed sequence tag;genome sequence;cdna library;microarrays;bioinformatics;gene ontology	The ESTuber database ( http://www.itb.cnr.it/estuber ) includes 3,271 Tuber borchii expressed sequence tags (EST). The dataset consists of 2,389 sequences from an in-house prepared cDNA library from truffle vegetative hyphae, and 882 sequences downloaded from GenBank and representing four libraries from white truffle mycelia and ascocarps at different developmental stages. An automated pipeline was prepared to process EST sequences using public software integrated by in-house developed Perl scripts. Data were collected in a MySQL database, which can be queried via a php-based web interface. Sequences included in the ESTuber db were clustered and annotated against three databases: the GenBank nr database, the UniProtKB database and a third in-house prepared database of fungi genomic sequences. An algorithm was implemented to infer statistical classification among Gene Ontology categories from the ontology occurrences deduced from the annotation procedure against the UniProtKB database. Ontologies were also deduced from the annotation of more than 130,000 EST sequences from five filamentous fungi, for intra-species comparison purposes. Further analyses were performed on the ESTuber db dataset, including tandem repeats search and comparison of the putative protein dataset inferred from the EST sequences to the PROSITE database for protein patterns identification. All the analyses were performed both on the complete sequence dataset and on the contig consensus sequences generated by the EST assembly procedure. The resulting web site is a resource of data and links related to truffle expressed genes. The Sequence Report and Contig Report pages are the web interface core structures which, together with the Text search utility and the Blast utility, allow easy access to the data stored in the database.	accessibility;annotation;anteroventral thalamic nucleus;bl (logic);blast;bmc bioinformatics;base excision repair;bio-informatics;categories;clone;concentrate dosage form;consensus sequence;dna, complementary;database;decibel;diabetes insipidus;estdomains;expressed sequence tags;francis;filamentous fungus;functional genomics;fungi;genbank;gene ontology;greater than;hyphae;inference;interface device component;libraries;manuscripts;multiprocessing;mysql;niche blogging;numerous;ontology (information science);php;prosite;page (document);perl;persistent vegetative state;proteome;requirement;revision procedure;scientific publication;silo (dataset);statistical classification;symbiosis;tandem repeat sequences;uniprot;uniprotkb;user interface;wdfy2 wt allele;web site;web search engine;algorithm;contents - htmllinktype;mecarzole	Barbara Lazzari;Andrea Caprera;Cristian Cosentino;Alessandra Stella;Luciano Milanesi;Angelo Viotti	2007	BMC Bioinformatics	10.1186/1471-2105-8-S1-S13	biology;whole genome sequencing;the internet;cdna library;dna microarray;computer science;bioinformatics;sequence alignment;user interface;world wide web;genetics;tandem repeat;expressed sequence tag;system integration	Comp.	-1.5548907953565883	-60.2805864806281	186429
2e5d6c91c2137dead26be29b64ab8e4706f25374	customizable generation of synthetically accessible, local chemical subspaces		Screening large libraries of chemicals has been an efficient strategy to discover bioactive compounds; however a portion of the potential for success is limited to the available libraries. Synergizing combinatorial and computational chemistries has emerged as a time-efficient strategy to explore the chemical space more widely. Ideally, streamlining the evaluation process for larger, feasible chemical libraries would become commonplace. Thus, combinatorial tools and, for example, docking methods would be integrated to identify novel bioactive entities. The idea is simple in nature, but much more complex in practice; combinatorial chemistry is more than the coupling of chemicals into products: synthetic feasibility includes chemoselectivity, stereoselectivity, protecting group chemistry, and chemical availability which must all be considered for combinatorial library design. In addition, intuitive interfaces and simple user manipulation is key for optimal use of such tools by organic chemists-crucial for the integration of such software in medicinal chemistry laboratories. We present herein Finders and React2D-integrated into the Virtual Chemist platform, a modular software suite. This approach enhances virtual combinatorial chemistry by identifying available chemicals compatible with a user-defined chemical transformation and by carrying out the reaction leading to libraries of realistic, synthetically accessible chemicals-all with a completely automated, black-box, and efficient design. We demonstrate its utility by generating ∼40 million synthetically accessible, stereochemically accurate compounds from a single library of 100 000 purchasable molecules and 56 well-characterized chemical reactions.		Joshua Pottel;Nicolas Moitessier	2017	Journal of chemical information and modeling	10.1021/acs.jcim.6b00648	bioinformatics;combinatorial chemistry;nanotechnology	Comp.	-1.3278209986100937	-65.38396061567805	186640
2a9196408537bb2cbc72e02def75f5122666f50a	trest, trgen and hits: access to databases of predicted protein sequences	animals;protein sequence;amino acid sequence;search method;information services;nucleotide sequence;internet;proteins;sequence homology amino acid;gene structure;humans;molecular sequence data;sequence alignment;databases factual;high throughput;data retrieval;expressed sequence tag;expressed sequence tags;markov chains	High throughput genome (HTG) and expressed sequence tag (EST) sequences are currently the most abundant nucleotide sequence classes in the public database. The large volume, high degree of fragmentation and lack of gene structure annotations prevent efficient and effective searches of HTG and EST data for protein sequence homologies by standard search methods. Here, we briefly describe three newly developed resources that should make discovery of interesting genes in these sequence classes easier in the future, especially to biologists not having access to a powerful local bioinformatics environment. trEST and trGEN are regularly regenerated databases of hypothetical protein sequences predicted from EST and HTG sequences, respectively. Hits is a web-based data retrieval and analysis system providing access to precomputed matches between protein sequences (including sequences from trEST and trGEN) and patterns and profiles from Prosite and Pfam. The three resources can be accessed via the Hits home page (http://hits. isb-sib.ch).	amino acid sequence;base sequence;bioinformatics;class;data retrieval;databases;expressed sequence tags;fragmentation (computing);home page;homology (biology);hypothetical protein;nucleotides;prosite;peptide sequence;pfam;pierre robin syndrome;precomputation;throughput;web application	Marco Pagni;Christian Iseli;Thomas Junier;Laurent Falquet;C. Victor Jongeneel;Philipp Bucher	2001	Nucleic acids research	10.1093/nar/29.1.148	biology;bioinformatics;genetics;expressed sequence tag	Comp.	-1.4734175869966795	-59.94239423191471	186917
791281f148784fd29be105f8d88e163d27be092b	hierarchical classification of hydrolases catalytic sites	protein family;enzyme;hierarchical classification;protein folding;chemical reaction	UNLABELLED Universal ontology of catalytic sites is required to systematize enzyme catalytic sites, their evolution as well as relations between catalytic sites and protein families, organisms and chemical reactions. Here we present a classification of hydrolases catalytic sites based on hierarchical organization. The web-accessible database provides information on the catalytic sites, protein folds, EC numbers and source organisms of the enzymes and includes software allowing for analysis and visualization of the relations between them.   AVAILABILITY http://www.enzyme.chem.msu.ru/hcs/	enzyme commission number;hydrolase;ontology;protein family;world wide web	Igor A. Gariev;Sergey D. Varfolomeev	2006	Bioinformatics	10.1093/bioinformatics/btl413	protein folding;biology;biochemistry;enzyme;molecular biology;chemical reaction;bioinformatics;protein family	Comp.	-0.36541594836788105	-61.181680211608864	186959
f1ccf57e94aaa3b58db1e4a48de90f8b7282ab3f	chilodb: a genomic and transcriptome database for an important rice insect pest chilo suppressalis	animals;genomics;database management systems;moths;databases genetic;oryza sativa;期刊论文;user computer interface;gene expression profiling	ChiloDB is an integrated resource that will be of use to the rice stem borer research community. The rice striped stem borer (SSB), Chilo suppressalis Walker, is a major rice pest that causes severe yield losses in most rice-producing countries. A draft genome of this insect is available. The aims of ChiloDB are (i) to store recently acquired genomic sequence and transcriptome data and integrate them with protein-coding genes, microRNAs, piwi-interacting RNAs (piRNAs) and RNA sequencing (RNA-Seq) data and (ii) to provide comprehensive search tools and downloadable data sets for comparative genomics and gene annotation of this important rice pest. ChiloDB contains the first version of the official SSB gene set, comprising 80,479 scaffolds and 10 221 annotated protein-coding genes. Additionally, 262 SSB microRNA genes predicted from a small RNA library, 82 639 piRNAs identified using the piRNApredictor software, 37,040 transcripts from a midgut transcriptome and 69 977 transcripts from a mixed sample have all been integrated into ChiloDB. ChiloDB was constructed using a data structure that is compatible with data resources, which will be incorporated into the database in the future. This resource will serve as a long-term and open-access database for research on the biology, evolution and pest control of SSB. To the best of our knowledge, ChiloDB is one of the first genomic and transcriptome database for rice insect pests. Database URL: http://ento.njau.edu.cn/ChiloDB.	amiga walker;crown group;data structure;gene annotation;genomics;interaction;invertebrate iridescent virus 6;micrornas;midgut;piwi-interacting rna;plague;stem of plant;super smash bros.;transcript;transcriptome;uniform resource locator	Chuanlin Yin;Ying Liu;Jinding Liu;Huamei Xiao;Shuiqing Huang;Yongjun Lin;Zhaojun Han;Fei Li	2014		10.1093/database/bau065	biology;genomics;botany;biotechnology;bioinformatics;gene expression profiling	Comp.	-1.4896982546762687	-60.96004331200543	187568
d7b5a2c340ed59e55934ef3b664f094f5b004c75	an ontology to integrate transcriptomics and interatomics data involved in gene pathways of genome stability	architectural design;complex network;relational database;cell cycle checkpoint;genomic instability;dna repair;information system;database design	Disruption of the mechanisms that regulate cell-cycle checkpoints, DNA repair, and apoptosis results in genomic instability and the development of cancer. The description of the complex network of these pathways requires news tools to integrate large quantities of experimental data in the design of biological information systems. In this context we present Ontocancro an extensible ontology and an architecture designed to facilitate the integration of data originating from different public databases in a singleand well-documented relational database. Ontocancro is an Ontology stored in a knowledge database designed to be a source of information to integrate transcriptomics and interatomics data involved in gene pathways of Genome Maintenance Mechanisms (GMM).	complex network;google map maker;information source;information system;instability;relational database	Giovani Rubert Librelotto;José Carlos M Mombach;Marialva Sinigaglia;Éder Simão;Heleno Borges Cabral;Mauro A. A. Castro	2009		10.1007/978-3-642-03223-3_18	biology;dna repair;genome instability;relational database;computer science;bioinformatics;data mining;database;genetics;information system;complex network;database design;cell cycle checkpoint	Comp.	-4.378898642087383	-63.37785917226981	188225
30d321d3efe43243176dbf3610ee17a20bc09083	rescue-ese identifies candidate exonic splicing enhancers in vertebrate exons	software;animals;mice;rna messenger;rna splicing;amino acid sequence;regulatory sequences ribonucleic acid;sequence analysis dna;internet;rna precursors;zebrafish;exonic splicing enhancer;experimental validation;humans;sequence analysis rna;tetraodontiformes;gene function;exons	A typical gene contains two levels of information: a sequence that encodes a particular protein and a host of other signals that are necessary for the correct expression of the transcript. While much attention has been focused on the effects of sequence variation on the amino acid sequence, variations that disrupt gene processing signals can dramatically impact gene function. A variation that disrupts an exonic splicing enhancer (ESE), for example, could cause exon skipping which would result in the exclusion of an entire exon from the mRNA transcript. RESCUE-ESE, a computational approach used in conjunction with experimental validation, previously identified 238 candidate ESE hexamers in human genes. The RESCUE-ESE method has recently been implemented in three additional species: mouse, zebrafish and pufferfish. Here we describe an online ESE analysis tool (http://genes.mit.edu/burgelab/rescue-ese/) that annotates RESCUE-ESE hexamers in vertebrate exons and can be used to predict splicing phenotypes by identifying sequence changes that disrupt or alter predicted ESEs.	amino acid sequence;amino acids;enhancer of transcription;exons;extensible storage engine;information;ptb-associated splicing factor;phenotype;protein sequence determination;pufferfish;rna splicing;splicing rule;transcript;trinity rescue kit;zebrafish;extra sheep e antigen, mouse;spinal cord stimulators	William G. Fairbrother;Gene W. Yeo;Rufang Yeh;Paul Goldstein;Matthew Mawson;Phillip A. Sharp;Christopher B. Burge	2004	Nucleic acids research	10.1093/nar/gkh393	biology;molecular biology;the internet;zebrafish information network genome database;exon;bioinformatics;peptide sequence;genetics;exonic splicing enhancer;rna splicing	Comp.	1.2787111293728988	-60.16589180192694	188468
c0a69d167aac0e346a8a0b5170a73b75bdca816a	discovery of complex genomic rearrangements in cancer using high-throughput sequencing	complex genomic rearrangement;closed chain breakage;larger scale rearrangement;high-throughput sequencing;breast cancer genomes;genomic shard;tumour genomes;complex genomic rearrangements;prostate cancer;balanced rearrangement;n locus	complex genomic rearrangement;closed chain breakage;larger scale rearrangement;high-throughput sequencing;breast cancer genomes;genomic shard;tumour genomes;complex genomic rearrangements;prostate cancer;balanced rearrangement;n locus	throughput	Andrew W McPherson;Chunxiao Wu;Alexander W Wyatt;Sohrab P. Shah;Colin Collins;Süleyman Cenk Sahinalp	2012		10.1007/978-3-642-29627-7_17	biology;molecular biology;bioinformatics;genetics	NLP	1.6648564110926165	-63.05603215348419	188573
7e7794f626d7f4d7bed77585c0950fa3035e27a1	searchpks: a program for detection and analysis of polyketide synthase domains	substrate specificity;software;computer graphics;natural product;multienzyme complexes;models molecular;internet;protein structure tertiary;multi domain;sequence homology amino acid;polyketide synthase;chemical structure;sequence analysis protein	SEARCHPKS is a software for detection and analysis of polyketide synthase (PKS) domains in a polypeptide sequence. Modular polyketide synthases are unusually large multi-enzymatic multi-domain megasynthases, which are involved in the biosynthesis of pharmaceutically important natural products using an assembly-line mechanism. This program facilitates easy identification of various PKS domains and modules from a given polypeptide sequence. In addition, it also predicts the specificity of the potential acyltransferase domains for various starter and extender precursor units. SEARCHPKS is a user-friendly tool for correlating polyketide chemical structures with the organization of domains and modules in the corresponding modular polyketide synthases. This program also allows the user to extensively analyze and assess the sequence homology of various polyketide synthase domains, thus providing guidelines for carrying out domain and module swapping experiments. SEARCHPKS can also aid in identification of polyketide products made by PKS clusters found in newly sequenced genomes. The computational approach used in SEARCHPKS is based on a comprehensive analysis of various characterized clusters of modular polyketide synthases compiled in PKSDB, a database of modular polyketide synthases. SEARCHPKS can be accessed at http://www.nii.res.in/searchpks.html.	acyltransferase;anabolism;compiler;digital media player;experiment;extender device component;genome;homologous gene;natural products;numerous;paging;polypeptides;sensitivity and specificity;sequence homology;usability;polyketide synthase	Gitanjali Yadav;Rajesh S. Gokhale;Debasisa Mohanty	2003	Nucleic acids research	10.1093/nar/gkg607	biology;biochemistry;the internet;bioinformatics;chemical structure;computer graphics	SE	-0.09942582221345872	-59.50401336241787	188650
1d1d9642a8f9b10bfc39128b3a14b0d33fe4623a	representing default knowledge in biomedical ontologies: application to the integration of anatomy and phenotype ontologies	software;animals;dk atira pure researchoutput researchoutputtypes contributiontojournal article;vocabulary controlled;information science;semantics;computational biology bioinformatics;knowledge;reproducibility of results;artificial intelligence;algorithms;humans;combinatorial libraries;computational biology;phenotype;computer appl in life sciences;domain ontology;anatomy;natural language processing;microarrays;bioinformatics;knowledge base	Current efforts within the biomedical ontology community focus on achieving interoperability between various biomedical ontologies that cover a range of diverse domains. Achieving this interoperability will contribute to the creation of a rich knowledge base that can be used for querying, as well as generating and testing novel hypotheses. The OBO Foundry principles, as applied to a number of biomedical ontologies, are designed to facilitate this interoperability. However, semantic extensions are required to meet the OBO Foundry interoperability goals. Inconsistencies may arise when ontologies of properties – mostly phenotype ontologies – are combined with ontologies taking a canonical view of a domain – such as many anatomical ontologies. Currently, there is no support for a correct and consistent integration of such ontologies. We have developed a methodology for accurately representing canonical domain ontologies within the OBO Foundry. This is achieved by adding an extension to the semantics for relationships in the biomedical ontologies that allows for treating canonical information as default. Conclusions drawn from default knowledge may be revoked when additional information becomes available. We show how this extension can be used to achieve interoperability between ontologies, and further allows for the inclusion of more knowledge within them. We apply the formalism to ontologies of mouse anatomy and mammalian phenotypes in order to demonstrate the approach. Biomedical ontologies require a new class of relations that can be used in conjunction with default knowledge, thereby extending those currently in use. The inclusion of default knowledge is necessary in order to ensure interoperability between ontologies.	addresses (publication format);anatomic structures;axiomatic system;bsd;british informatics olympiad;categories;computational anatomy;core ontology;dlv;dna integration;datalog;default;description;digital curation;epidemiology;faceted classification;flip-flop (electronics);flumazenil;formal system;gnu;general formal ontology;home page;informatics (discipline);information system;internet;interoperability;java programming language;knowledge base;knowledge representation and reasoning;linux;manuscripts;mouse anatomy concepts;no support needed;non-monotonic logic;obo foundry;ontology (information science);open biomedical ontologies;operating system;phenotype;poly a;preparation;programming languages;relevance;requirement;roberto busa;semantic web rule language;semantics (computer science);strigiformes;web ontology language;interest;omacetaxine mepesuccinate	Robert Hoehndorf;Frank Loebe;Janet Kelso;Heinrich Herre	2007	BMC Bioinformatics	10.1186/1471-2105-8-377	biology;idef5;open biomedical ontologies;knowledge base;ontology components;information science;computer science;bioinformatics;data science;phenotype;data mining;semantics;knowledge;web ontology language	AI	-4.448302070498736	-63.8871854775754	188708
bc5f2ab5d52a61a844374c38c58695d712471324	sbr-blood: systems biology repository for hematopoietic cells	genes;hematopoiesis;reproductive physiological process;animals;mice;systems biology;databases genetic;datasets;hematopoietic system;histones;transcription factor;united states national institutes of health;epigenesis genetic;workflow;dna methylation;humans;hematopoietic stem cells;blood cells;epigenetics;gene expression profiling	Extensive research into hematopoiesis (the development of blood cells) over several decades has generated large sets of expression and epigenetic profiles in multiple human and mouse blood cell types. However, there is no single location to analyze how gene regulatory processes lead to different mature blood cells. We have developed a new database framework called hematopoietic Systems Biology Repository (SBR-Blood), available online at http://sbrblood.nhgri.nih.gov, which allows user-initiated analyses for cell type correlations or gene-specific behavior during differentiation using publicly available datasets for array- and sequencing-based platforms from mouse hematopoietic cells. SBR-Blood organizes information by both cell identity and by hematopoietic lineage. The validity and usability of SBR-Blood has been established through the reproduction of workflows relevant to expression data, DNA methylation, histone modifications and transcription factor occupancy profiles.	biopolymer sequencing;blood cells;central nervous system hematopoietic neoplasm;hematological disease;hematopoiesis;histone code;histones;lineage (evolution);standard business reporting;systems biology;transcription factor;transcription (software);usability;cell type;study of epigenetics	Jens Lichtenberg;Elisabeth F. Heuston;Tejaswini Mishra;Cheryl A. Keller;Ross C. Hardison;David M. Bodine	2016	Nucleic acids research	10.1093/nar/gkv1263	biology;bioinformatics;epigenetics;haematopoiesis;genetics;systems biology	Comp.	0.1576052104409216	-61.19000105965124	188757
46698bd353920b5410ec1e8fd83e2f0e4f55a2d5	transcriptome profile of ovcar3 cisplatin-resistant ovarian cancer cell line	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics	Background The NIH:OVCAR-3 is a cisplatin refractory cell line established from malignant ascites of a patient with progressive adenocarcinoma of the ovary after combination chemotherapy with cyclophosphamide, Adriamycin, and cisplatin [1]. Thus, OVCAR3 serves as a model cell line for drug resistance in ovarian cancer. Here, we perform a comparative transcriptome analysis from the US National Cancer Institute human tumor cell line anticancer drug screen (NCI60) dataset [2]. Our results indicate a specific gene transcription profile of OVCAR3 genes relative to non-cancerous Human Ovarian Surface Epithelial cells (HOSE) and drug sensitive Serous Ovarian Cancer Epithelial Samples (CEPI) and SKOV3 cell lines. Pathway enrichment analysis from OVCAR3 unique transcripts was conducted using KEGG; Disease and Drug term enrichment used the PharmGKB [3] databases.	database;gene ontology term enrichment;gene regulatory network;kegg;pharmgkb;transcription (software)	Shruti S. Sakhare;Gautam G. Rao;Sammed N. Mandape;Siddharth Pratap	2014		10.1186/1471-2105-15-S10-P21	biology;dna microarray;computer science;bioinformatics;data science	Comp.	0.01116447016308935	-61.959521476986	189013
ecc6baacb6dd77987aa6d0b65093d94a07befb81	the seed: a peer-to-peer environment for genome annotation	genome annotation;peer to peer;open source	This open source toolkit will help scientists interpret the vast body of genomic data now publicly available.	open-source software;peer-to-peer	Ross A. Overbeek;Terry Disz;Rick L. Stevens	2004	Commun. ACM	10.1145/1029496.1029525	computer science;bioinformatics;data mining;vertebrate and genome annotation project;genome project;world wide web	Comp.	-3.907138298457082	-60.70618444243929	189067
4ee370eee987926e799b1e67626b76f02acbb04f	gopubmed: exploring pubmed with the gene ontology	ひらめく;software;研究開発;専門;特許;機関;検索;科学技術;研究者;vocabulary controlled;産学連携;横断検索;jst;学術;独立行政法人;検索エンジン;科学技術振興機構;databases genetic;リンクセンター;関連検索;論文;ひろがる;j global;遺伝子;levamisole;internet;データベース;ｊｇｌｏｂａｌ;研究資源;研究課題;jglobal;国立研究開発法人;jdream;ｊ ｇｌｏｂａｌ;アイディア;資料;abstracting and indexing as topic;技術動向;書誌情報;文献;発想;user computer interface;化学物質;enzyme inhibitors;統合検索;ｊｓｔ;subject headings;pubmed;科学技術用語;gopubmed gene ontologyを使ったpubmed探索;つながる;gene ontology	The biomedical literature grows at a tremendous rate and PubMed comprises already over 15 000 000 abstracts. Finding relevant literature is an important and difficult problem. We introduce GoPubMed, a web server which allows users to explore PubMed search results with the Gene Ontology (GO), a hierarchically structured vocabulary for molecular biology. GoPubMed provides the following benefits: first, it gives an overview of the literature abstracts by categorizing abstracts according to the GO and thus allowing users to quickly navigate through the abstracts by category. Second, it automatically shows general ontology terms related to the original query, which often do not even appear directly in the abstract. Third, it enables users to verify its classification because GO terms are highlighted in the abstracts and as each term is labelled with an accuracy percentage. Fourth, exploring PubMed abstracts with GoPubMed is useful as it shows definitions of GO terms without the need for further look up. GoPubMed is online at www.gopubmed.org. Querying is currently limited to 100 papers per query.	abstract summary;categorization;gene ontology;gopubmed;molecular biology;paper;pubmed;question (inquiry);server (computing);vocabulary;web server;benefit	Andreas Doms;Michael Schroeder	2005	Nucleic Acids Research	10.1093/nar/gki470	controlled vocabulary;the internet	Comp.	-1.7545107715414534	-62.48051140606836	189084
3c4a7f1fd47e9a48b4f6d6b8ba14e3fcde445fd4	mpromdb: an integrated resource for annotation and visualization of mammalian gene promoters and chip-chip experimental data	animals;genomics;mice;rats;databases nucleic acid;computer graphics;transcription factors;binding sites;chip;internet;chromatin immunoprecipitation;promoter regions genetic;humans;user computer interface;computational biology;systems integration;exons;oligonucleotide array sequence analysis;transcription initiation site	We have developed Mammalian Promoter Database (MPromDb), a novel database that integrates gene promoters with experimentally supported annotation of transcription start sites, cis-regulatory elements, CpG islands and chromatin immunoprecipitation microarray (ChIP-chip) experimental results with intuitively designed presentation. Release 1.0 of MPromDb currently contains 36,407 promoters and first exons (19,170 from human, 15,953 from mouse and 1284 from rat), 3739 transcription factor (TF)-binding sites (2027 from human, 1181 mouse and 531 rat) and 224 TFs with links to PubMed and GenBank references. Target promoters of TFs that have been identified by ChIP-chip assay are integrated into the database. MPromDb serves as a portal for genome-wide promoter analysis of data generated by ChIP-chip experimental studies. MPromDb can be accessed from http://bioinformatics.med.ohio-state.edu/MPromDb.	annotation;aquaporin 1;bibliographic reference;binding sites;bioinformatics;chip-on-chip;cpg islands;exons;experiment;genbank;imagery;mammals;microarray;pubmed;transcription factor;transcription (software);transcription initiation site;chromatin immunoprecipitation;promoter	Hao Sun;Saranyan K. Palaniswamy;Twyla T. Pohar;Victor X. Jin;Tim Hui-Ming Huang;Ramana V. Davuluri	2006	Nucleic Acids Research	10.1093/nar/gkj096	chip;biology;genomics;molecular biology;chromatin immunoprecipitation;the internet;exon;bioinformatics;binding site;mammalian promoter database;computer graphics;genetics;system integration;transcription factor	Comp.	-1.4323368847237046	-59.78071318343143	189125
28dced8346b869cc5f4b8ee6c3da9e1b9d77aa66	guidelines for managing data and processes in bone and cartilage tissue engineering	animals;cell differentiation;computational biology bioinformatics;cartilage;guidelines as topic;algorithms;humans;biocompatible materials;bone and bones;combinatorial libraries;computer appl in life sciences;tissue engineering;microarrays;bioinformatics	In the last decades, a wide number of researchers/clinicians involved in tissue engineering field published several works about the possibility to induce a tissue regeneration guided by the use of biomaterials. To this aim, different scaffolds have been proposed, and their effectiveness tested through in vitro and/or in vivo experiments. In this context, integration and meta-analysis approaches are gaining importance for analyses and reuse of data as, for example, those concerning the bone and cartilage biomarkers, the biomolecular factors intervening in cell differentiation and growth, the morphology and the biomechanical performance of a neo-formed tissue, and, in general, the scaffolds' ability to promote tissue regeneration. Therefore standards and ontologies are becoming crucial, to provide a unifying knowledge framework for annotating data and supporting the semantic integration and the unambiguous interpretation of novel experimental results. In this paper a conceptual framework has been designed for bone/cartilage tissue engineering domain, by now completely lacking standardized methods. A set of guidelines has been provided, defining the minimum information set necessary for describing an experimental study involved in bone and cartilage regenerative medicine field. In addition, a Bone/Cartilage Tissue Engineering Ontology (BCTEO) has been developed to provide a representation of the domain's concepts, specifically oriented to cells, and chemical composition, morphology, physical characterization of biomaterials involved in bone/cartilage tissue engineering research. Considering that tissue engineering is a discipline that traverses different semantic fields and employs many data types, the proposed instruments represent a first attempt to standardize the domain knowledge and can provide a suitable means to integrate data across the field.	biomaterials;bone tissue;cartilage;cell differentiation process;experiment;in vitro [publication type];instrument - device;mathematical morphology;natural regeneration;ontology (information science);regenerative medicine;reuse (action);scientific publication;semantic integration;tissue engineering;video-in video-out;standards characteristics;tissue regeneration	Federica Viti;Silvia Scaglione;Alessandro Orro;Luciano Milanesi	2014		10.1186/1471-2105-15-S1-S14	biology;dna microarray;biocompatible material;bioinformatics;tissue engineering;cellular differentiation	DB	-3.797502621451545	-64.24122491163878	189370
211944d9300f9dbddba392e717f1eef345f36688	prototype intelligent information system for disease diagnosis in crops.	intelligent information system	Novel vasopressin analogs having the general schematic formula: wherein X is selected from the group consisting of H and NH2 and Y is selected from the group consisting of -S-S-, -CH2S- and -SCH2- and A=L when B=D and A=D when B=L and a method of treatment using these compounds to increase the level of Factor VIII and plasminogen activator in a subjectu0027s blood.		Savita Kolhe;Raj Kamal;Harvinder S. Saini;Girish Kumar Gupta	2007			computer science;information retrieval	Robotics	2.232096842257504	-65.88795258240673	190166
f2e0cfafdbba841b41e5fb1ff99972424be876ba	05471 abstract collection - computational proteomics			computation;proteomics	Christian G. Huber;Oliver Kohlbacher;Knut Reinert	2005				NLP	0.8308257029513666	-64.54389184290665	190232
a834b9fa9c4167c18ce6bd392300a572592079b4	new mutant phenotype data curation system in the saccharomyces genome database	biomedical research;bioinformatics	The Saccharomyces Genome Database (SGD; http://www.yeastgenome.org/) organizes and displays molecular and genetic information about the genes and proteins of baker's yeast, Saccharomyces cerevisiae. Mutant phenotype screens have been the starting point for a large proportion of yeast molecular biological studies, and are still used today to elucidate the functions of uncharacterized genes and discover new roles for previously studied genes. To greatly facilitate searching and comparison of mutant phenotypes across genes, we have devised a new controlled-vocabulary system for capturing phenotype information. Each phenotype annotation is represented as an 'observable', which is the entity, or process that is observed, and a 'qualifier' that describes the change in that entity or process in the mutant (e.g. decreased, increased, or abnormal). Additional information about the mutant, such as strain background, allele name, conditions under which the phenotype is observed, or the identity of relevant chemicals, is captured in separate fields. For each gene, a summary of the mutant phenotype information is displayed on the Locus Summary page, and the complete information is displayed in tabular format on the Phenotype Details Page. All of the information is searchable and may also be downloaded in bulk using SGD's Batch Download Tool or Download Data Files Page. In the future, phenotypes will be integrated with other curated data to allow searching across different types of functional information, such as genetic and physical interaction data and Gene Ontology annotations.Database URL:http://www.yeastgenome.org/	annotation;binding (molecular function);controlled vocabulary;cynthia dwork;data curation;digital curation;download;entropic uncertainty;gene ontology;human–computer interaction;locus;laboratory information management system;maschinen krieger zbv 3000;nash equilibrium;observable;phenotype;phrases;saccharomyces cerevisiae;salicylic acid 0.01 mg/mg topical gel [no zit sherlock];table (information);url data type	Maria C. Costanzo;Marek S. Skrzypek;Robert S. Nash;Edith D. Wong;Gail Binkley;Stacia R. Engel;Benjamin C. Hitz;Eurie L. Hong;J. Michael Cherry	2009			biology;medical research;computer science;bioinformatics;data mining;database;world wide web;genetics;information retrieval	Comp.	-1.1037962392269385	-60.67216899256182	190770
810766985215b7aacb3f9aea2a16546b2c0113aa	scidbmaker: new software for computer-aided design of specialized biological databases	software;protein family;user interface;database management systems;protein sequence;databases genetic;computational biology bioinformatics;data analysis;molecular biology;algorithms;sequence analysis;exponential growth;multiple sequence alignment;combinatorial libraries;software design;biological database;computer appl in life sciences;scientific research;information storage and retrieval;biological process;microarrays;bioinformatics	The exponential growth of research in molecular biology has brought concomitant proliferation of databases for stocking its findings. A variety of protein sequence databases exist. While all of these strive for completeness, the range of user interests is often beyond their scope. Large databases covering a broad range of domains tend to offer less detailed information than smaller, more specialized resources, often creating a need to combine data from many sources in order to obtain a complete picture. Scientific researchers are continually developing new specific databases to enhance their understanding of biological processes. In this article, we present the implementation of a new tool for protein data analysis. With its easy-to-use user interface, this software provides the opportunity to build more specialized protein databases from a universal protein sequence database such as Swiss-Prot. A family of proteins known as bacteriocins is analyzed as 'proof of concept'. SciDBMaker is stand-alone software that allows the extraction of protein data from the Swiss-Prot database, sequence analysis comprising physicochemical profile calculations, homologous sequences search, multiple sequence alignments and the building of new and more specialized databases. It compiles information with relative ease, updates and compares various data relevant to a given protein family and could solve the problem of dispersed biological search results.	amino acid sequence;biological database;computer-aided design;databases, protein;list of biological databases;molecular biology;multiple sequence alignment;protein family;published database;swiss-prot;sequence analysis;sequence database;small;switzerland;time complexity;user interface device component;bacteriocin;interest	Riadh Hammami;Abdelmajid Zouhir;Karim Naghmouchi;Jeannette Ben Hamida;Ismail Fliss	2007	BMC Bioinformatics	10.1186/1471-2105-9-121	biology;exponential growth;scientific method;dna microarray;biological database;multiple sequence alignment;computer science;bioinformatics;software design;theoretical computer science;protein sequencing;sequence analysis;data mining;data analysis;protein family;user interface;biological process	Comp.	-2.259229120685563	-59.16050259302151	191177
225b440d6d223b0ac14110b323085487f722d763	attacking hiv, tuberculosis and histoplasmosis with xsede resources	hiv;drug discovery;virtual screening;hpc;histoplasmosis;tuberculosis;supercomputing	HIV, tuberculosis and histoplasmosis are infectious diseases that affect millions of people world-wide. We describe our efforts to find cures for these diseases using the technique of virtual screening to identify possible inhibitors for essential proteins in these organisms using one of the XSEDE supercomputers. We have completed the virtual screens and have found promising compounds for each disease. Cell culture experiments have supported the likelihood of a number of the compounds being effective for treating both histoplasmosis and tuberculosis.	cell (microprocessor);experiment;supercomputer;virtual screening	David Toth;Jimmy Franco;Charlotte Berkes	2013		10.1145/2484762.2484766	medicine;pathology;virology;immunology	Comp.	2.187113535999225	-65.62882510656479	191202
b5c3d19997d0f721a0978bc5d672e52cb2dca69b	database on the structure of small ribosomal subunit rna	ease of use;ribosomal rna;world wide web;secondary structure;nucleotide sequence	The Antwerp database on small ribosomal subunit RNA now offers more than 6000 nucleotide sequences (August 1996). All these sequences are stored in the form of an alignment based on the adopted secondary structure model, which is corroborated by the observation of compensating substitutions in the alignment. Besides the primary and secondary structure information, literature references, accession numbers and detailed taxonomic information are also compiled. For ease of use, the complete database is made available to the scientific community via World Wide Web at URL http://rrna.uia.ac.be/ssu/ .		Yves Van de Peer;Jan Jansen;Peter De Rijk;Rupert De Wachter	1997	Nucleic acids research	10.1093/nar/25.1.111		Comp.	-2.051216057437879	-60.90645373129815	191487
6149adbdcddc2546b76ca6c48a1c569b06acabfd	the biology petri net markup language	extensible markup language;petri net markup language;interchange format;petri net	In this paper a proposal for the Biology Petri Net Markup Language (BioPNML) is presented. The concepts and terminology of the interchange format as well as its syntax that is based on XML (eXtensible Markup Language) are introduced. BioPNML is designed to provide a starting point for the development of a standard interchange format for Bioinformatics and Petri nets. The language will make it possible to present biology Petri net diagrams between all supported hardware platforms and versions. It is also designed to bridge Petri net models to other known metabolic simulators.	bioinformatics;diagram;graphical user interface;petri net markup language;simulation;xml	Ming Chen;Andreas Freier;Jacob Köhler;Alexander Rüegg	2002			ruleml;xml;computer science;pcdata;database;programming language;petri net	Logic	-0.7368393170438609	-65.08153704791752	191807
dedb24ccaa2de1b28ca6665f99db71c128509e5c	diagen: a model-driven framework for integrating bioinformatic tools		Nowadays, the diagnosis of disease based on genomic information is feasible by searching genetic variations on DNA sequences. However, geneticists struggle with bioinformatic tools that are supposed to simplify DNA sequence analysis. As a universal tool to support every requirement is far from be implemented, geneticists themselves must solve the data exchange among several tools. Due to the fact that there are no standards to support this integration task, it must be managed in every analysis. This paper proposes addressing this integration by means of a model-driven framework. The Diagen framework is a software implementation based on conceptual modeling principles that formalizes data exchange and simpli es bioinformatic tool integration. First, we analyze how conceptual modeling can be used to deal with data exchange among tools. And then, as a proof of concept, the presented framework is used to search for variations on the BRCA2 gene using real DNA samples and a set of speci c bioinformatic tools.	bioinformatics;model-driven architecture;model-driven integration;resource description framework;sequence analysis	Maria José Villanueva;Francisco Valverde;Ana M. Levin;Oscar Pastor	2011		10.1007/978-3-642-29749-6_4	computer science;bioinformatics;data science;data mining	Logic	-4.163930204250374	-63.51050039628582	191837
1c8ea3ed2411e9bb06114baba87f0bdfa2c95d57	as2ts system for protein structure modeling and analysis	software;protein structure comparison;capsid proteins;amino acid;amino acid sequence;website design;web service;protein structure;models molecular;3d model;internet;protein conformation;structural homology protein;llnl;protein data bank;structural similarity;sequence analysis protein;modeling and analysis;databases protein;structure alignment	We present a set of programs and a website designed to facilitate protein structure comparison and protein structure modeling efforts. Our protein structure analysis and comparison services use the LGA (local-global alignment) program to search for regions of local similarity and to evaluate the level of structural similarity between compared protein structures. To facilitate the homology-based protein structure modeling process, our AL2TS service translates given sequence-structure alignment data into the standard Protein Data Bank (PDB) atom records (coordinates). For a given sequence of amino acids, the AS2TS (amino acid sequence to tertiary structure) system calculates (e.g. using PSI-BLAST PDB analysis) a list of the closest proteins from the PDB, and then a set of draft 3D models is automatically created. Web services are available at http://as2ts.llnl.gov/.	3d modeling;alignment;amino acid sequence;amino acids;blast;databases;homologous gene;homology (biology);protein data bank;protein, organized by structure;structural similarity;web site;web service;tertiary	Adam Zemla;Carol L. Ecale Zhou;Tom Slezak;Thomas A. Kuczmarski;D. Rama;Clinton Torres;D. Sawicka;Daniel Barsky	2005	Nucleic Acids Research	10.1093/nar/gki457	biology;protein structure;structural alignment;bioinformatics;protein structure database	Comp.	-1.73307957353517	-60.02588410874685	191859
0c05eed174ec790f74fdec0f5865ce7c1af45d13	analysis of rna/interferon structures for virus c type 4			nsa product types	Attalah Hashad;Khaled Kamal;Ahmed Fahmy;Amr Badr	2009	Egyptian Computer Science Journal		control engineering;rna;engineering;virus;virology;interferon	Theory	2.5108283398348124	-64.40326684425447	191921
5e688a06c80d7f5940f72225d9b1c2b0097c14d1	micrornas: mechanisms, functions and progress		In 1993 when Ambros and co-workers [1] discovered that a mysterious Caenorhabditis elegans gene, lin-4, does not encode a protein, but acts in the form of a small RNA and represses the expression of its target gene, lin-14, through base-pairing with its 30 untranslated region (30UTR), nobody would imagine that 20 years later, this category of small RNAs – now widely known as microRNAs (or miRNAs), has 2000 known members in the human genome (and counting), and that miRNA-mediated gene regulation is deeply involved in virtually all important biological processes in animals and plants. There is little doubt that recent advances in genomics and bioinformatics technologies and methodologies have made considerable contributions to our understanding of miRNAs [2]. We present this special issue as an attempt to bring readers an update on the current understanding of the biogenesis and targeting of miRNAs, and some of the most recent developments in the exciting field of miRNA research. Grave and Zeng’s review entitled “Biogenesis of mammalian microRNAs: a global view” [3] offers an upto-date overview of the mechanisms by which a miRNA executes its function. Reyes-Herrera and Ficarra’s “One decade of development and evolution of microRNA target prediction algorithms” [4] and Ding et al.’s “Finding miRNA targets in plants: current status and perspectives” [5] provide a comprehensive survey of the current methods for the identification of miRNA targets in animals and plants, respectively. In addition, Li and Kowdley [6] bring us an up-to-date review about the involvement of miRNAs in human diseases.	bioinformatics;dvd region code;encode (action);lithium;lobular neoplasia;mammals;micrornas;pineal region yolk sac tumor;rna;reyes rendering;staphylococcal protein a;algorithm	Tongbin Li;William C. S. Cho	2012		10.1016/j.gpb.2012.10.002	biology;molecular biology;bioinformatics;genetics	Comp.	2.4220811601165977	-60.946044043240796	192859
6da67c52c05785dba0c61c8e900d1f481fc003ae	biobankwarden: a web-based system to support translational cancer research by managing clinical and biomaterial data	clinical data management;biomaterial management;biological databases;oncogenomics;translational medicine	BACKGROUND Researchers of translational medicine face numerous challenges in attempting to bring research results to the bedside. This field of research covers a wide range of resources, including blood and tissue samples, which are processed for isolation of RNA and DNA to study cancer omics data (genomics, proteomics and metabolomics). Clinical information about patients׳ habits, family history, physical examinations, remissions, etc., is also important to underpin studies aimed at identifying patterns that lead to the development of cancer and to its successful treatment.   PURPOSE Development of a web-based computer system-BioBankWarden-to manage, consolidate and integrate these diversified data, enabling cancer research groups to retrieve and analyze clinical and biomolecular data within an integrative environment. The system has a three-tier architecture comprising database, logic and user-interface layers.   RESULTS The system׳s integrated database and user-friendly interface allow for the control of patient records, biomaterial storage, research groups, research projects, users and biomaterial exchange.   CONCLUSIONS BioBankWarden can be used to store and retrieve specific information from different clinical fields linked to biomaterials collected from patients, providing the functionalities required to support translational research in the field of cancer.	biobank;biomaterials;clinical data;computer;conflict (psychology);congenital neurologic anomalies;database;extraction;gene ontology;genetic research;genetic translation process;genomics;identifier;interface device component;interoperability;logical observation identifiers names and codes;malignant fibrous histiocytoma;metabolomics;multitier architecture;name;neoplasms;omics;ontology (information science);patients;physical examination;proteomics;rna;requirement;translational medical research;translational research;usability;user interface;web application;anatomical layer;research grants	Yuri Ferretti;Newton Shydeo Brandão Miyoshi;Wilson Araújo Silva;Joaquim Cezar Felipe	2017	Computers in biology and medicine	10.1016/j.compbiomed.2015.04.008	medicine;biological database;translational medicine;pathology;bioinformatics	Visualization	-3.1187549482091237	-62.95074511112806	193050
b69603b9561643512c4764e7c40a81b55e243821	refold: a server for the refinement of 3d protein models guided by accurate quality estimates	endnotes;pubications	ReFOLD is a novel hybrid refinement server with integrated high performance global and local Accuracy Self Estimates (ASEs). The server attempts to identify and to fix likely errors in user supplied 3D models of proteins via successive rounds of refinement. The server is unique in providing output for multiple alternative refined models in a way that allows users to quickly visualize the key residue locations, which are likely to have been improved. This is important, as global refinement of a full chain model may not always be possible, whereas local regions, or individual domains, can often be much improved. Thus, users may easily compare the specific regions of the alternative refined models in which they are most interested e.g. key interaction sites or domains. ReFOLD was used to generate hundreds of alternative refined models for the CASP12 experiment, boosting our group's performance in the main tertiary structure prediction category. Our successful refinement of initial server models combined with our built-in ASEs were instrumental to our second place ranking on Template Based Modeling (TBM) and Free Modeling (FM)/TBM targets. The ReFOLD server is freely available at: http://www.reading.ac.uk/bioinf/ReFOLD/.	3d modeling;access network;archive;built-in self-test;estimated;gamma-delta tocotrienol;global distance test;mucin 5ac;nar 2;nucleic acids;page (document);protocols documentation;providing (action);refinement (computing);region of interest;server (computer);server (computing);usability;tertiary	Ahmad N. Shuid;Robert Kempster;Liam James McGuffin	2017		10.1093/nar/gkx249	biology	ML	-1.7915521411009532	-59.306778026910365	193603
037d799f3ef8e39920cc7fe0472d911063c13011	aclame: a classification of mobile genetic elements, update 2010	software;databases nucleic acid;databases genetic;repetitive sequences nucleic acid;plasmids;internet;bacteriophages;interspersed repetitive sequences;genome bacterial;mobile genetic element;algorithms;computational biology;information storage and retrieval	The ACLAME database is dedicated to the collection, analysis and classification of sequenced mobile genetic elements (MGEs, in particular phages and plasmids). In addition to providing information on the MGEs content, classifications are available at various levels of organization. At the gene/protein level, families group similar sequences that are expected to share the same function. Families of four or more proteins are manually assigned with a functional annotation using the GeneOntology and the locally developed ontology MeGO dedicated to MGEs. At the genome level, evolutionary cohesive modules group sets of protein families shared among MGEs. At the population level, networks display the reticulate evolutionary relationships among MGEs. To increase the coverage of the phage sequence space, ACLAME version 0.4 incorporates 760 high-quality predicted prophages selected from the Prophinder database. Most of the data can be downloaded from the freely accessible ACLAME web site (http://aclame.ulb.ac.be). The BLAST interface for querying the database has been extended and numerous tools for in-depth analysis of the results have been added.	annotation;blast;bacteriophages;classification;integrative level;ontology;personnameuse - assigned;protein family;web site	Raphaël Leplae;Gipsi Lima-Mendez;Ariane Toussaint	2010		10.1093/nar/gkp938	biology;the internet;bioinformatics;plasmid;genetics	Comp.	-0.645371866898456	-59.66930477222834	193747
429ba8860dfb742c7748f5c11067d934b94fa742	mirtarbase update 2014: an information resource for experimentally validated mirna-target interactions	rna messenger;databases nucleic acid;disease;high throughput nucleotide sequencing;internet;micro rna;gene expression regulation;transcriptome;humans;candidate disease gene;sequence analysis rna;micrornas;article	MicroRNAs (miRNAs) are small non-coding RNA molecules capable of negatively regulating gene expression to control many cellular mechanisms. The miRTarBase database (http://mirtarbase.mbc.nctu.edu.tw/) provides the most current and comprehensive information of experimentally validated miRNA-target interactions. The database was launched in 2010 with data sources for >100 published studies in the identification of miRNA targets, molecular networks of miRNA targets and systems biology, and the current release (2013, version 4) includes significant expansions and enhancements over the initial release (2010, version 1). This article reports the current status of and recent improvements to the database, including (i) a 14-fold increase to miRNA-target interaction entries, (ii) a miRNA-target network, (iii) expression profile of miRNA and its target gene, (iv) miRNA target-associated diseases and (v) additional utilities including an upgrade reminder and an error reporting/user feedback system.	data sources;emoticon;exception handling;experiment;gene expression profiling;information resources;interaction;micrornas;non-small cell lung carcinoma;rna;rna, untranslated;scientific publication;systems biology	Sheng-Da Hsu;Yu-Ting Tseng;Sirjana Shrestha;Yu-Ling Lin;Anas Khaleel;Chih-Hung Chou;Chao-Fang Chu;Hsi-Yuan Huang;Ching-Min Lin;Shu-Yi Ho;Ting-Yan Jian;Feng-Mao Lin;Tzu-Hao Chang;Shun-Long Weng;Kuang-Wen Liao;I-En Liao;Chun-Chi Liu;Hsien-Da Huang	2014		10.1093/nar/gkt1266	biology;molecular biology;bioinformatics;genetics;microrna	Comp.	-0.1492369125711918	-60.108725383360245	193899
0612ed7e307efd9fa11fdb37a6bbcaf21d3a3d51	mint, the molecular interaction database: 2009 update	software;animals;mice;rats;settore bio 18 genetica;genome viral;databases nucleic acid;databases genetic;internet;proteins;protein structure tertiary;protein binding;algorithms;receptor epidermal growth factor;humans;protein interaction mapping;computational biology;molecular interactions;information storage and retrieval;programming languages;databases protein	MINT (http://mint.bio.uniroma2.it/mint) is a public repository for molecular interactions reported in peer-reviewed journals. Since its last report, MINT has grown considerably in size and evolved in scope to meet the requirements of its users. The main changes include a more precise definition of the curation policy and the development of an enhanced and user-friendly interface to facilitate the analysis of the ever-growing interaction dataset. MINT has adopted the PSI-MI standards for the annotation and for the representation of molecular interactions and is a member of the IMEx consortium.		Arnaud Céol;Andrew Chatr-aryamontri;Luana Licata;Daniele Peluso;Leonardo Briganti;Livia Perfetto;Luisa Castagnoli;Gianni Cesareni	2010	Nucleic acids research	10.1093/nar/gkp983	biology;plasma protein binding;the internet;bioinformatics;genetics	SE	-1.6919869875285314	-61.23641227357224	194291
5459dc54743b1872398da2c1d69889fe27a1c619	identifying novel features from specimen data for the prediction of valuable collection trips		Primary biodiversity data provide “what, where, and when” data points: the assertion that a species occurred at a particular point in space and time. These are most valuable when associated with specimens stored in natural history museums and herbaria, which evidence the assertions with reference to a physical specimen. The research presented uses novel data-mining techniques to uncover two hidden dimensions in specimen data - who collected the specimens and how they were collected. A combination of unsupervised and supervised learning techniques are used, which establish two new entities: collector and collection trip. Features are defined against these higher order representations of the data, which support the use of the data to answer novel questions such as which collection trips discover the most new species? We explore the features by building classifiers to predict species discovery, and compare these with a baseline model grouped using collector team transcriptions derived from the raw specimen data. Preliminary results are promising and whilst the particular focus of this research was botanical specimens, the technique is equally applicable to datasets of field-collected specimens from other scientific domains.		Nicky Nicolson;Allan Tucker	2017		10.1007/978-3-319-68765-0_20	computer science;data mining;trips architecture;supervised learning;herbarium;data point;assertion;cluster analysis;natural history	NLP	-3.697466486735451	-65.59935204755814	194301
412ff0e016f7a602e587f08d237878514eb25458	genelibrarian: an effective gene-information summarization and visualization system	software;text mining;ncku 成功大學 成大 圖書館 機構典藏;semantics;databases genetic;computational biology bioinformatics;chip;gene expression;cluster analysis;internet;clustering method;dissertations and theses journal referred papers conference papers nsc reserach report patent nckur ir ncku institutional repostiory 博碩士論文 期刊論文 國科會研究報告 專利 成大機構典藏;reproducibility of results;algorithms;combinatorial libraries;computer appl in life sciences;visual system;information storage and retrieval;candidate gene;microarrays;bioinformatics;gene ontology	Abundant information about gene products is stored in online searchable databases such as annotation or literature. To efficiently obtain and digest such information, there is a pressing need for automated information-summarization and functional-similarity clustering of genes. We have developed a novel method for semantic measurement of annotation and integrated it with a biomedical literature summarization system to establish a platform, GeneLibrarian, to provide users well-organized information about any specific group of genes (e.g. one cluster of genes from a microarray chip) they might be interested in. The GeneLibrarian generates a summarized viewgraph of candidate genes for a user based on his/her preference and delivers the desired background information effectively to the user. The summarization technique involves optimizing the text mining algorithm and Gene Ontology-based clustering method to enable the discovery of gene relations. GeneLibrarian is a Java-based web application that automates the process of retrieving critical information from the literature and expanding the number of potential genes for further analysis. This study concentrates on providing well organized information to users and we believe that will be useful in their researches. GeneLibrarian is available on http://gen.csie.ncku.edu.tw/GeneLibrarian/	algorithm;annotation;automatic summarization;candidate disease gene;cluster analysis;cryptographic hash function;gene ontology;imagery;information retrieval;java programming language;microarray;published database;text mining;transparency (projection);web application;statistical cluster	Jung-Hsien Chiang;Jyh-Wei Shin;Heng-Hui Liu;Chong-Liang Chin	2006	BMC Bioinformatics	10.1186/1471-2105-7-392	chip;biology;text mining;the internet;gene expression;dna microarray;visual system;computer science;bioinformatics;data mining;semantics;cluster analysis;candidate gene;genetics;information retrieval	Comp.	-1.688043939736459	-61.610470566590195	194744
414ff6c3b40183397e299aa740d83bcd0f5ac61e	integrating protein annotation resources through the distributed annotation system	software;computer graphics;internet;distributed annotation system;user computer interface;systems integration;sequence analysis protein	Using the Distributed Annotation System (DAS) we have created a protein annotation resource available at our web page: http://www.cbs.dtu.dk, as a part of the BioSapiens Network of Excellence EU FP6 project. The DAS protocol allows us to gather layers of annotation data for a given sequence and thereby gain an overview of the sequence’s features. A user-friendly graphical client has also been developed (http://www. cbs.dtu.dk/cgi-bin/das), which demonstrates the possibility of integrating DAS annotation data from multiple sources into a simple graphical view. The client displays protein feature annotations from the Center for Biological Sequence Analysis as well as from the BioSapiens reference UniProt server (http://www.ebi.ac.uk/das-srv/uniprot/das) at the European Bioinformatics Institute. Other DAS data sources for protein annotation will be added as they become available.	bioinformatics;graphical user interface;sequence analysis;server (computing);uniprot;usability;web page	Páll Í Ólason	2005	Nucleic Acids Research	10.1093/nar/gki463	the internet;image retrieval;bioinformatics;computer graphics;system integration	Comp.	-3.2205768550793907	-61.03978302576758	194846
ebe72be969c3d50de78f69cb36cdc8aa679431b6	genetic traces of never born proteins			tracing (software)	Monika Piwowar;Ewa Matczynska;Maciej Malawski;Tomasz Szapieniec;Irena Roterman-Konieczna	2017	Bio-Algorithms and Med-Systems	10.1515/bams-2017-0006	genetics;biology	NLP	1.4132208464146636	-63.892425428244664	194936
4bc92dbec0739d19f6246df2522914ef93f40631	rna frabase 2.0: an advanced web-accessible database with the capacity to search the three-dimensional fragments within rna structures	conformational analysis;software;rna interference;genomics;search engine;rna secondary structure;databases nucleic acid;web accessibility;spectrum;journal article;three dimensional;computational biology bioinformatics;rna structure;internet;rna;nucleic acid conformation;algorithms;user computer interface;sequence analysis rna;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	"""Recent discoveries concerning novel functions of RNA, such as RNA interference, have contributed towards the growing importance of the field. In this respect, a deeper knowledge of complex three-dimensional RNA structures is essential to understand their new biological functions. A number of bioinformatic tools have been proposed to explore two major structural databases (PDB, NDB) in order to analyze various aspects of RNA tertiary structures. One of these tools is RNA FRABASE 1.0, the first web-accessible database with an engine for automatic search of 3D fragments within PDB-derived RNA structures. This search is based upon the user-defined RNA secondary structure pattern. In this paper, we present and discuss RNA FRABASE 2.0. This second version of the system represents a major extension of this tool in terms of providing new data and a wide spectrum of novel functionalities. An intuitionally operated web server platform enables very fast user-tailored search of three-dimensional RNA fragments, their multi-parameter conformational analysis and visualization. RNA FRABASE 2.0 has stored information on 1565 PDB-deposited RNA structures, including all NMR models. The RNA FRABASE 2.0 search engine algorithms operate on the database of the RNA sequences and the new library of RNA secondary structures, coded in the dot-bracket format extended to hold multi-stranded structures and to cover residues whose coordinates are missing in the PDB files. The library of RNA secondary structures (and their graphics) is made available. A high level of efficiency of the 3D search has been achieved by introducing novel tools to formulate advanced searching patterns and to screen highly populated tertiary structure elements. RNA FRABASE 2.0 also stores data and conformational parameters in order to provide """"on the spot"""" structural filters to explore the three-dimensional RNA structures. An instant visualization of the 3D RNA structures is provided. RNA FRABASE 2.0 is freely available at http://rnafrabase.cs.put.poznan.pl . RNA FRABASE 2.0 provides a novel database and powerful search engine which is equipped with new data and functionalities that are unavailable elsewhere. Our intention is that this advanced version of the RNA FRABASE will be of interest to all researchers working in the RNA field."""	algorithm;bio-informatics;bioinformatics;database;graphics;high-level programming language;imagery;interference (communication);ndb cluster;numerous;population parameter;protein data bank;rna interference;server (computer);server (computing);web search engine;web server;tertiary	Mariusz Popenda;Marta Szachniuk;Marek Blazewicz;Szymon Wasik;Edmund K. Burke;Jacek Blazewicz;Ryszard W. Adamiak	2010		10.1186/1471-2105-11-231	biology;three-dimensional space;spectrum;nucleic acid structure;genomics;the internet;rna;dna microarray;bioinformatics;rna interference;web accessibility;nucleic acid secondary structure;world wide web;genetics;search engine	Comp.	-1.618869791303037	-59.85741627047682	194955
178c0928d2fd5de02a0fc5650f617d080f73e84a	growth of the zebrafish anatomy ontology: expanded to support adult morphology and dynamic changes in the early embryo		The Zebrafish Anatomy Ontology (ZFA) is an application ontology used by ZFIN to support curation of expression and phenotype. The research community also uses the ontology to support annotation of high throughput studies. As the research focus of the zebrafish community evolves it drives changes in the ZFA. Here we provide an update on the changes made to support research carried out in adult fish and describe the changes in modeling of the neural crest in the ontology in order to bring the structure of the ontology into closer accordance with the morphological changes that occur during development. Keywords—ZFA; ZFS; anatomy; neural crest	computational anatomy;digital curation;galaxy morphological classification;throughput;zfin;zfs	Ceri E. Van Slyke;Yvonne M. Bradford;Christian Pich	2016			zebrafish;ontology;embryo;anatomy;biology	Web+IR	-1.341911847411908	-62.51361807872828	195323
5ad9a4e6972b742a93fccc17e8ef995d3d8139d1	ensembl comparative genomics resources		Evolution provides the unifying framework with which to understand biology. The coherent investigation of genic and genomic data often requires comparative genomics analyses based on whole-genome alignments, sets of homologous genes and other relevant datasets in order to evaluate and answer evolutionary-related questions. However, the complexity and computational requirements of producing such data are substantial: this has led to only a small number of reference resources that are used for most comparative analyses. The Ensembl comparative genomics resources are one such reference set that facilitates comprehensive and reproducible analysis of chordate genome data. Ensembl computes pairwise and multiple whole-genome alignments from which large-scale synteny, per-base conservation scores and constrained elements are obtained. Gene alignments are used to define Ensembl Protein Families, GeneTrees and homologies for both protein-coding and non-coding RNA genes. These resources are updated frequently and have a consistent informatics infrastructure and data presentation across all supported species. Specialized web-based visualizations are also available including synteny displays, collapsible gene tree plots, a gene family locator and different alignment views. The Ensembl comparative genomics infrastructure is extensively reused for the analysis of non-vertebrate species by other projects including Ensembl Genomes and Gramene and much of the information here is VC The Author(s) 2016. Published by Oxford University Press. Page 1 of 17 This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. (page number not for citation purposes) Database, 2016, 1–17 doi: 10.1093/database/bav096	abel transform;access network;alignment;base pairing;biological evolution;biological factors;chickens;chordata;clamping (graphics);coherence (physics);community-acquired infections;computation;computer systems;concentrate dosage form;contain (action);database;digital object identifier;documentation;encode;ensembl genomes;finch;finches;gene family;gene prediction;genomics;gorilla <western gorilla>;havcr1 protein, human;homology (biology);imagery;informatics (discipline);ixora sp. vidal 5758b;lampreys;license;manuscripts;occupational health services;one thousand;online locator service;orang-utan <sumatran orangutan>;petrogale;protein family;requirement;risk aversion;scientific publication;synteny;trees (plant);web application;whole genome sequencing;zebrafish;zebras;citation	Javier Herrero;Matthieu Muffato;Kathryn Beal;Stephen Fitzgerald;Leo Gordon;Miguel Pignatelli;Albert J. Vilella;Stephen M. J. Searle;M. Ridwan Amode;Simon Brent;William Spooner;Eugene Kulesha;Andrew D. Yates;Paul Flicek	2016		10.1093/database/baw053	bioinformatics;ensembl;data mining;protein family;genome;computer science;ensembl genomes;comparative genomics;small number;annotation;synteny	Comp.	-1.6815763479857342	-60.830523821943196	195391
e0105b6ec9a242622aef43d555a3ae0320e0306c	sewer: a customizable and integrated dynamic html interface to bioinformatics services		SUMMARY Sequence analysis using Web Resources (SeWeR) is an integrated, Dynamic HTML (DHTML) interface to commonly used bioinformatics services available on the World Wide Web. It is highly customizable, extendable, platform neutral, completely server-independent and can be hosted as a web page as well as being used as stand-alone software running within a web browser.	bioinformatics;dynamic html;extensibility;interface device component;internet;sequence analysis;server (computer);server (computing);web page;world wide web	Malay Kumar Basu	2001	Bioinformatics	10.1093/bioinformatics/17.6.577	computer science;operating system;database;world wide web	Web+IR	-4.033484846087123	-59.67730450517992	195468
3c50ee01be431fdb0fc32d3a19bb3f5d27bc210c	seecancer: a resource for somatic events in evolution of cancer genome		Cancer cells progressively evolve from a premalignant to a malignant state, which is driven by accumulating somatic alterations that confer normal cells a fitness advantage. Improvements in high-throughput sequencing techniques have led to an increase in construction of tumor phylogenetics and identification of somatic driver events that specifically occurred in different tumor progression stages. Here, we developed the SEECancer database (http://biocc.hrbmu.edu.cn/SEECancer), which aims to present the comprehensive cancer evolutionary stage-specific somatic events (including early-specific, late-specific, relapse-specific, metastasis-specific, drug-resistant and drug-induced genomic events) and their temporal orders. By manually curating over 10 000 published articles, 1231 evolutionary stage-specific genomic events and 5772 temporal orders involving 82 human cancers and 23 tissue origins were collected and deposited in the SEECancer database. Each entry contains the somatic event, evolutionary stage, cancer type, detection approach and relevant evidence. SEECancer provides a user-friendly interface for browsing, searching and downloading evolutionary stage-specific somatic events and temporal relationships in various cancers. With increasing attention on cancer genome evolution, the necessary information in SEECancer will facilitate understanding of cancer etiology and development of evolutionary therapeutics, and help clinicians to discover biomarkers for monitoring tumor progression.	biological markers;biopolymer sequencing;cancer etiology;color gradient;diploid cell;download;high-throughput computing;interface device component;national origin;neoplasms;phylogenetics;precancerous conditions;scientific publication;therapeutic procedure;throughput;tumor progression;usability;orders - hl7publishingdomain	Hongyi Zhang;Shangyi Luo;Xinxin Zhang;Jianlong Liao;Fei Quan;Erjie Zhao;Chenfen Zhou;Fulong Yu;Wenkang Yin;Yunpeng Zhang;Yun Xiao;Xia Li	2018		10.1093/nar/gkx964	tumor progression;genetics;genome;cancer;somatic cell;biology	Comp.	0.11381011806545714	-61.76430262704324	195793
832862ef9eb24f52d22597ae560b0cfa126a6b5d	building a domain analysis model for the data stored in the database of genotypes and phenotypes (dbgap)			domain analysis	Ko-Wei Lin;Hyeon-Eui Kim	2013			domain analysis;database;genotype-phenotype distinction;biology;bioinformatics	DB	-0.020207564275329187	-64.04129893314011	196143
293a3a9c0632e99095053d707b3e05a8b44ea5ca	a 3d structure database of components from chinese traditional medicinal herbs	chinese traditional medicine;medicinal herb;3d structure	This article described a 3D structure database of components extracted from Chinese Traditional Medicinal (CTM) herbs. It offers not only basic molecular properties and optimized 3D structure of the compounds but also detailed information on their herbal origin, including basic herbal category (e.g. English name, Latin name, and family), effective parts, and clinical effects. An easy to use, interactive GUI browser allows users to perform various searches via complex logical query builder. Combined with the latest network database engine (MySQL), it can achieve excellent performance under both a local network and an Internet environment. We have tested it on the design of inhibitors of NS3-NS4A protease. Results show that the structure database of components extracted from Chinese medicinal herbs can be a rich source in searching the lead compound.	cefotiam;database engine;endopeptidases;extraction;graphical user interface;lead compound;mysql;network model;person name;plants, medicinal;traditional chinese medicine	Xuebin Qiao;Tingjun Hou;Wei Zhang;SenLi Guo;Xiaojie Xu	2002	Journal of chemical information and computer sciences	10.1021/ci010113h	data mining	Web+IR	-2.5036023502782245	-61.83551533953377	196288
7d45a723bb8d125dd02e6925a9b998d0cba5a969	cdna sequence coding for human kidney catalase	dna		dna, complementary;renal tissue	George I. Bell;R. C. Najarian;G. T. Mullenbach;R. A. Hallewell	1986	Nucleic acids research		dna;gene;genetics;molecular biology;catalase;protein primary structure;molecular cloning;kidney;biology;complementary dna	Robotics	2.481781236452028	-64.11973519026044	197732
9bf14350cfd05210af1def7c6b7336e7993d28a8	ptmd: a database of human disease-associated post-translational modifications	akt1;disease−gene network;ptm−disease association;phosphorylation;posttranslational modification	Various posttranslational modifications (PTMs) participate in nearly all aspects of biological processes by regulating protein functions, and aberrant states of PTMs are frequently implicated in human diseases. Therefore, an integral resource of PTM-disease associations (PDAs) would be a great help for both academic research and clinical use. In this work, we reported PTMD, a well-curated database containing PTMs that are associated with human diseases. We manually collected 1950 known PDAs in 749 proteins for 23 types of PTMs and 275 types of diseases from the literature. Database analyses show that phosphorylation has the largest number of disease associations, whereas neurologic diseases have the largest number of PTM associations. We classified all known PDAs into six classes according to the PTM status in diseases and demonstrated that the upregulation and presence of PTM events account for a predominant proportion of disease-associated PTM events. By reconstructing a disease-gene network, we observed that breast cancers have the largest number of associated PTMs and AKT1 has the largest number of PTMs connected to diseases. Finally, the PTMD database was developed with detailed annotations and can be a useful resource for further analyzing the relations between PTMs and human diseases. PTMD is freely accessible at http://ptmd.biocuckoo.org.	biological processes;class;classification;database;gene regulatory network;genetic translation process;largest;mammary neoplasms;mental association;personal digital assistant;phentolamine;polynomial texture mapping;post-translational protein processing;nervous system disorder	Haodong Xu;Yongbo Wang;Shaofeng Lin;Wankun Deng;Di Peng;Qinghua Cui	2018		10.1016/j.gpb.2018.06.004	bioinformatics;database;disease;posttranslational modification;biology	Comp.	-0.17772952408982817	-61.995335893292726	198057
a5bc4ae016723d77eff82da7a2de997ac93aaf02	the code structure of hiv-1	nucleotides;genome sequence	Information of life is stored in a genome sequence and four nucleotides can be regarded as coding elements and their sequence as a certain code of life. We study what kinds of code structure the sequences of HIV-1 genes may have.		Keiko Sato;Naoki Fushimi;Masanori Ohya	2007	Open Syst. Inform. Dynam.	10.1007/s11080-007-9053-3	consensus sequence;nucleotide;whole genome sequencing;genomic organization;sequence logo;genome project;physics	DB	1.9738747621204735	-63.466402703304055	198595
86c7566692bc095e13f882508a1979886e67768f	the edkb: an established knowledge base for endocrine disrupting chemicals	search engine;endocrine disruptor;knowledge bases;androgen receptor;endocrine disruptors;food packaging;relational database;computational biology bioinformatics;government regulation;adverse effect;food and drug administration;molecular weight;endocrine disrupting chemical;indexation;cell proliferation;algorithms;humans;chemical structure;reporter gene assay;databases factual;estrogen receptor;combinatorial libraries;computer appl in life sciences;similarity search;microarrays;bioinformatics;knowledge base;food contamination	Endocrine disruptors (EDs) and their broad range of potential adverse effects in humans and other animals have been a concern for nearly two decades. Many putative EDs are widely used in commercial products regulated by the Food and Drug Administration (FDA) such as food packaging materials, ingredients of cosmetics, medical and dental devices, and drugs. The Endocrine Disruptor Knowledge Base (EDKB) project was initiated in the mid 1990’s by the FDA as a resource for the study of EDs. The EDKB database, a component of the project, contains data across multiple assay types for chemicals across a broad structural diversity. This paper demonstrates the utility of EDKB database, an integral part of the EDKB project, for understanding and prioritizing EDs for testing. The EDKB database currently contains 3,257 records of over 1,800 EDs from different assays including estrogen receptor binding, androgen receptor binding, uterotropic activity, cell proliferation, and reporter gene assays. Information for each compound such as chemical structure, assay type, potency, etc. is organized to enable efficient searching. A user-friendly interface provides rapid navigation, Boolean searches on EDs, and both spreadsheet and graphical displays for viewing results. The search engine implemented in the EDKB database enables searching by one or more of the following fields: chemical structure (including exact search and similarity search), name, molecular formula, CAS registration number, experiment source, molecular weight, etc. The data can be cross-linked to other publicly available and related databases including TOXNET, Cactus, ChemIDplus, ChemACX, Chem Finder, and NCI DTP. The EDKB database enables scientists and regulatory reviewers to quickly access ED data from multiple assays for specific or similar compounds. The data have been used to categorize chemicals according to potential risks for endocrine activity, thus providing a basis for prioritizing chemicals for more definitive but expensive testing. The EDKB database is publicly available and can be found online at http://edkb.fda.gov/webstart/edkb/index.html . Disclaimer: The views presented in this article do not necessarily reflect those of the US Food and Drug Administration.	androgens;boolean;cactaceae;categorization;cell proliferation;chemical formula;chemical structure;cosmetics;database;diphtheria toxoid/tetanus toxoid/inactivated pertussis vaccine;distributed transaction;endocrine disruptors;estrogens;floor and ceiling functions;food allergy;infographic;interface device component;knowledge base;molecular weight;multiple endocrine neoplasia type 1;nc (complexity);similarity search;spreadsheet;toxnet: hazardous substances data bank;united states food and drug administration;usability;web search engine;disclaimer	Don Ding;Lei Xu;Hong Fang;Huixiao Hong;Roger Perkins;Steve Harris;Edward D. Bearden;Leming Shi;Weida Tong	2010		10.1186/1471-2105-11-S6-S5	pharmacology;biology;regulation;knowledge base;reporter gene;dna microarray;adverse effect;toxicology;relational database;computer science;bioinformatics;estrogen receptor;androgen receptor;food contaminant;chemical structure;molecular mass;cell growth;genetics;food packaging;search engine	DB	-1.086880300063921	-61.74023476538926	199246
9ae38234f7cb12cf0e311e3f4f0de6323e2bd9eb	hierarchic genetic search with \alpha -stable mutation				Adam K. Obuchowicz;Maciej Smolka;Robert Schaefer	2015		10.1007/978-3-319-16549-3_12		Robotics	1.7175411957397644	-63.98331998968201	199303
b12502a27f4481465407a84f7a2f8e169cb3f541	yeast protein database (ypd): a database for the complete proteome of saccharomyces cerevisiae	budding yeast;post translational modification;complete genome;saccharomyces cerevisiae;computer communication networks;amino acid sequence;molecular weight;world wide web;subcellular localization;databases factual;fungal proteins	The Yeast Protein Database (YPD) is a database for the proteins of the budding yeast,Saccharomyces cerevisiae. YPD is the first annotated database for the complete proteome of any organism. Now that the complete genome sequence of yeast is available, YPD contains entries for each of the characterized proteins and for each of the uncharacterized proteins predicted from the sequence. Contained in YPD are the calculated properties of each protein such as molecular weight and isoelectric point, experimentally determined properties such as subcellular localization and post-translational modifications, and extensive annotations from the yeast literature. YPD contains 25 000 lines of textual annotation that describe the known functions, mutant phenotypes, interactions, and other properties for the approximately 6000 proteins in the yeast proteome. The information in YPD is updated daily, and it is available on the World Wide Web at http://www.proteome.com/YPDhome.html .	annotation;contain (action);databases, protein;experiment;genetic translation process;interaction;isoelectric point;molecular weight;phenotype;post-translational protein processing;proteome;saccharomyces cerevisiae;saccharomycetales;sequence database;world wide web	William E. Payne;James I. Garrels	1997	Nucleic acids research	10.1093/nar/25.1.57	biology;bioinformatics;posttranslational modification;peptide sequence;molecular mass;genetics	Comp.	-0.8282220577433161	-60.00668388159929	199542
29533161990b555924ac87d6e9bb24f57863ec8e	cross-project uptake of biomedical text mining results for candidate gene searches			biomedical text mining	Christoph M. Friedrich;Christian Ebeling;David Manset	2010	ERCIM News		data mining;candidate gene;biomedical text mining;computer science	ML	-0.4705299565243614	-63.0432782037465	199978
