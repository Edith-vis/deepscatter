id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
85b07c6c89cf97dcb2bf4420c02305bbb088a920	pricing for the optimal coordination of opportunistic agents		We consider a system where a load aggregator (LA) serves a large number of small-sized, economically-driven consumers with deferrable demand, as envisioned in the smart electricity grid and data networks. In these systems, consumers can behave opportunistically by deferring their demand in response to the prices, to obtain economic gains. However, if not controlled properly, such opportunistic behavior can be detrimental to the system by creating aggregate effects that lead to undesirable fluctuations in price and total load. To avoid the unwanted effects of demand-side flexibilities and to reap system-wide benefits from them, we propose two novel real-time dynamic pricing algorithms. The first algorithm communicates individual prices to consumers by adding small random perturbations to a common price. The second algorithm introduces a secondary price that penalizes the change in users' consumption in time. The common feature of both algorithms is creating differentiation among consumers and, thus, regulating the aggregate load. We conduct comprehensive numerical investigations and show that the LA and consumers economically benefit under the proposed pricing schemes.	aggregate data;algorithm;numerical analysis;real-time transcription	Ozgur Dalkilic;Atilla Eryilmaz;Xiaojun Lin	2018	IEEE Transactions on Control of Network Systems	10.1109/TCNS.2017.2648503	mathematical optimization;grid;mathematics;news aggregator;dynamic pricing	Metrics	0.40989579782930324	4.081108299304161	148545
2265e41fef3544a7ded6a760e190a19344559aa3	decentralized dynamics to optimal and stable states in the assignment game	games heuristic algorithms world wide web sociology random variables economics optimization;game theory;matching markets assignment games cooperative games core distributed optimization evolutionary game theory learning linear programming;cooperative games payoff driven adjustment dynamics assignment game decentralized two sided assignment markets decentralized dynamics profitability core allocations;profitability economics game theory;profitability;economics	Payoff-driven adjustment dynamics lead to stable and optimal outcomes in decentralized two-sided assignment markets. Pairs of agents from both sides of the market randomly encounter each other and match if `profitable'. Very little information is available, in particular agents have no knowledge of others' preferences, their past actions and payoffs or the value of the different matches. This process implements optimal and stable - i.e. core - allocations even though agents interact asynchronously and randomly, and there is no central authority enforcing matchings or sharing rules.	algorithm;augmented assignment;integer programming;matching (graph theory);randomness	Heinrich H. Nax;Bary S. R. Pradelski;H. Peyton Young	2013	52nd IEEE Conference on Decision and Control	10.1109/CDC.2013.6760238	bondareva–shapley theorem;non-cooperative game;combinatorial game theory;game theory;simulation;repeated game;sequential game;profitability index	Robotics	-3.017359708040987	-1.8566668400492237	148912
642de12d0f0a3d43a11a0198fa1b0dc4b7e3e9c6	condorcet consistent bundling with social choice		We study the problem of computing optimal bundles given agents’ preferences over individual items when agents derive satisfaction from the entire bundle under constraints on the size k of the bundle. Building on the notion of Condorcet winning sets by Gehrlein [16], we extend common Condorcet consistent voting rules from the single winner voting setting to that of forming bundles of size k. Our main technical contribution involves designing efficient algorithms for computing (approximately)-optimal bundles for multiwinner extensions of the following voting rules: Copeland, Minimax, Ranked Pairs, and Schulze.	algorithmic efficiency;expectation–maximization algorithm;minimax;p (complexity);product bundling	Shreyas Sekar;Sujoy Sikdar;Lirong Xia	2017			machine learning;ranked pairs;condorcet method;artificial intelligence;computer science;mathematical economics;schulze method;bundle;voting;kemeny–young method;minimax;mathematical optimization;social choice theory	AI	-3.327540998862997	-1.2864438887600855	149647
23a57ddb2f7e32d1b8f5e5e6f09d3ed69aa8a598	the computational complexity of nash equilibria in concisely represented games	circuit games;boolean circuits;nash equilibrium;concise games;nash equilibria;journal article;computational game theory;complexity class;computational complexity;graph games	Games may be represented in many different ways, and different representations of games affect the complexity of problems associated with games, such as finding a Nash equilibrium. The traditional method of representing a game is to explicitly list all the payoffs, but this incurs an exponential blowup as the number of agents grows. We study two models of concisely represented games: circuit games, where the payoffs are computed by a given boolean circuit, and graph games, where each agent's payoff is a function of only the strategies played by its neighbors in a given graph. For these two models, we study the complexity of four questions: determining if a given strategy is a Nash equilibrium, finding a Nash equilibrium, determining if there exists a pure Nash equilibrium, and determining if there exists a Nash equilibrium in which the payoffs to the players meet some given guarantees. In many cases, we obtain tight results, showing that the problems are complete for various complexity classes.	boolean circuit;complexity class;computational complexity theory;nash equilibrium;time complexity	Grant Schoenebeck;Salil P. Vadhan	2005	Electronic Colloquium on Computational Complexity (ECCC)	10.1145/1134707.1134737	price of stability;markov perfect equilibrium;game theory;epsilon-equilibrium;mathematical optimization;combinatorics;traveler's dilemma;best response;sequential equilibrium;trembling hand perfect equilibrium;coordination game;computer science;folk theorem;repeated game;mathematics;correlated equilibrium;risk dominance;normal-form game;mathematical economics;subgame perfect equilibrium;equilibrium selection;symmetric game;solution concept;algorithm;nash equilibrium;symmetric equilibrium	ECom	-4.1659722125012495	1.0670338487765487	149739
39aa1e0813dd041a9b37a55ce5276c0295b7de94	robustifying convex risk measures for linear portfolios: a nonparametric approach	grupo de excelencia;robust optimization;ciencias basicas y experimentales;kantorovich distance;norm constrained portfolio optimization;matematicas;soft robust constraints;grupo a	Full terms and conditions of use: http://pubsonline.informs.org/page/terms-and-conditions This article may be used only for the purposes of research, teaching, and/or private study. Commercial use or systematic downloading (by robots or other automatic processes) is prohibited without explicit Publisher approval, unless otherwise noted. For more information, contact permissions@informs.org. The Publisher does not warrant or guarantee the article’s accuracy, completeness, merchantability, fitness for a particular purpose, or non-infringement. Descriptions of, or references to, products or publications, or inclusion of an advertisement in this article, neither constitutes nor implies a guarantee, endorsement, or support of claims made of that product, publication, or service. Copyright © 2014, INFORMS	best, worst and average case;cobham's thesis;download;institute for operations research and the management sciences;mathematical optimization;numerical analysis;ordinary least squares;regular expression;risk measure;robot;robustification;selection rule	David Wozabal	2014	Operations Research	10.1287/opre.2014.1323	econometrics;mathematical optimization;robust optimization;entropic value at risk;portfolio optimization;spectral risk measure;mathematics;dynamic risk measure;welfare economics;statistics	Robotics	1.45324546778395	-0.26232798896990056	149855
55bfc005d83b1e74a314fa2c4f86bc3b85f4edc0	optimal target criteria for stabilization policy	dynamic model;optimal control.;target criterion;optimal policy;econometric models;linear equations;satisfiability;econometric model;expected utility;economics;objective function;dsge model;optimal control;rational expectation	This paper considers a general class of nonlinear rational-expectations models in which policymakers seek to maximize an objective function that may be household expected utility. We show how to derive a target criterion that is: (i) consistent with the models structural equations, (ii) strong enough to imply a unique equilibrium, and (iii) optimal, in the sense that a commitment to adjust the policy instrument at all dates so as to satisfy the target criterion maximizes the objective function. The proposed optimal target criterion is a linear equation that must be satised by the projected paths of certain economically relevant target variables. It takes the same form at all times and generally involves only a small number of target variables, regardless of the size and complexity of the model. While the projected path of the economy requires information about the current state, the target criterion itself can be stated without reference to a complete description of the state of the world. We illustrate the application of the method to a nonlinear DSGE model with staggered price-setting, in which the objective of policy is to maximize household expected utility. Keywords: Optimal policy, target criterion, dynamic model, optimal control. JEL codes: C61, C62, E32, E52 We would like to thank Pierpaolo Benigno and Lars Svensson for helpful discussions, and the NSF for support of the authorsresearch under grants SES-0518770 and SES-0820438. yColumbia Business School, 3022 Broadway, Uris Hall 824, New York, NY 10027. E-mail: mg2190@columbia.edu. zDepartment of Economics, Columbia University, 420 W. 118th Street, New York, NY 10027. E-mail: michael.woodford@columbia.edu. Forecast targeting has become an increasingly popular approach, both to the organization of monetary policy deliberations and to communication with the public about monetary policy decisions, at central banks around the world. In this approach, a contemplated forward path for policy is judged correct to the extent that quantitative projections for one or more economic variables, conditional on the contemplated policy, conform to a target criterion.1 The present paper considers whether the conditions required for the conduct of policy to maximize welfare can be cast in the form of such a target criterion.2 We consider a fairly general class of stabilization problems, in which the set of possible equilibrium evolutions of the economy is determined by a system of forward-looking structural equations, representing optimizing behavior on the part of the private sector. (Our abstract framework need not apply only to monetary policy, though that is the leading example that motivates our formulation of the problem.) We show that it is possible quite generally to choose a target criterion with two important properties. First, we seek a target criterion that is consistent with the structural equations, and that at the same time is strong enough to imply a determinate forward path for the economy. Thus we must verify that there exists an evolution that satises the target criterion, looking forward from any possible situation that may have been reached, and also that the evolution consistent with the target criterion is unique. Second, we seek a target criterion such that the state-contingent evolution determined by the criterion is optimal, in the sense of maximizing an ex ante expected welfare criterion. It might be thought that a su¢ cient solution to this problem would simply be to compute the optimal state-contingent evolution of all endogenous variables, under an optimal commitment chosen at some initial date t0; and to refer to the solution to this problem at any later date t to determine what forward path for policy from date t onward is consistent 1For further discussion and examples, see, e.g., Svensson (1997, 2005) and Woodford (2007). 2This has previously been shown to be possible in special examples in Svensson and Woodford (2005) and Giannoni and Woodford (2005). The present exposition o¤ers a simpler expression for the optimal target criterion than in our previous attempt at a general theory, in Giannoni and Woodford (2003a), in additional to allowing a considerably more general class of possible objectives for policy, so that the present approach can be applied to problems, like the one in section 4, where the objective of policy is assumed to be the maximization of household utility.	broadway (microprocessor);code;columbia (supercomputer);complexity;contingency (philosophy);entropy maximization;expected utility hypothesis;ibm notes;lars bak (computer programmer);linear equation;loss function;mathematical model;nonlinear system;optimal control;optimization problem;pin grid array;property (philosophy)	Marc P. Giannoni;Michael Woodford	2017	J. Economic Theory	10.1016/j.jet.2016.12.003	mathematical optimization;economics;operations management;welfare economics	AI	0.861655822636079	-0.8875836261238229	151026
d78b543d2f7cbf702f420211790ee5c9324c1f24	an optimization-based distributed planning algorithm: a blackboard-based collaborative framework	distributed algorithms;planning collaboration accuracy resource management computer architecture vectors decision making;start time;groupware;optimisation;blackboard architecture;distributed agents;maritime operations centers optimization based distributed resource allocation planning algorithm blackboard based collaborative framework multiple agents distributed framework asset ownership interdependent task collection directed sequence sequential sequence processing time start time release time heterogeneous assets agent based distributed planning framework blackboard communication paradigm information exchange intra agent module interagent module cooperative planning optimization based m best asset allocation algorithm asset pricing;optimization based m best asset allocation algorithm;resource allocation;agent based distributed planning framework;resource management;collaboration;asset ownership;blackboard communication paradigm;heterogeneous assets;processing time;collaborative planning;computer architecture;operational level planning;accuracy;multi agent systems;interagent module;sequential sequence;vectors;distributed framework;information exchange;resource allocation blackboard architecture collaborative planning distributed agents operational level planning;marine engineering;planning;maritime operations centers;cooperative planning;release time;intra agent module;resource allocation distributed algorithms groupware marine engineering multi agent systems optimisation;multiple agents;interdependent task collection;blackboard based collaborative framework;asset pricing;directed sequence;optimization based distributed resource allocation planning algorithm	Motivated by the need for multiple agents to collaborate in order to solve a distributed resource allocation planning problem, this paper develops a distributed framework that combines each agent's information, expertise, responsibility, and asset ownership with the goal of optimizing a given mission objective. A mission is a collection of interdependent tasks to be executed in a directed/sequential sequence. Each task is modeled by a vector of resource requirements, a processing time, and a start time (release time). Each agent has a subset of tasks for which it is responsible, and owns a set of heterogeneous assets, where each asset is modeled by a vector of resource capabilities that it provides. Multiple agents must collaboratively allocate assets to tasks to maximize an expected mission performance, defined by how well all of the tasks' requirements are satisfied by the allocated asset capabilities. Our agent-based distributed planning framework uses a blackboard communication paradigm to exchange information among agents. The framework contains an intra-agent and an interagent module that support individual and cooperative planning, respectively. The intra-agent module employs an optimization-based m-best asset allocation algorithm to match an agent's own tasks with its locally owned assets. The interagent module coordinates the exchange of information and asset allocations among agents to improve the local plans using an asset pricing mechanism, and includes a means for characterizing an agent's cooperative behavior.	agent-based model;algorithm;automated planning and scheduling;blackboard system;edmund m. clarke;enterprise resource planning;integer programming;interdependence;linear programming;mathematical optimization;program optimization;programming paradigm;requirement	Xu Han;Suvasri Mandal;Krishna R. Pattipati;David L. Kleinman;Manisha Mishra	2014	IEEE Transactions on Systems, Man, and Cybernetics: Systems	10.1109/TSMC.2013.2276392	planning;blackboard system;capital asset pricing model;simulation;information exchange;resource allocation;computer science;knowledge management;resource management;accuracy and precision;collaboration	Robotics	-0.5264414446705846	2.502174867538022	151146
7cada5017572c397509803763af824c51ea28c36	nash equilibrium and decentralized pricing for qos aware service composition in cloud computing environments		QoS aware service composition necessitates an effective pricing mechanism in regulating service providers in public cloud computing environments. However, due to the fact that service providers are usually autonomous, strategic and self-motivated, it is far from trivial to deal with the pricing issues between them. In this paper we formulate a non-cooperative service pricing game to understand the performance of a QoS aware service composition model, for which multiple providers strategically bid how to provide and price their elementary services and establish the Nash equilibrium as the final service composition scheme. We also develop a proportional revenue division rule to incentivize elementary service providers to contribute in improving the QoS of the final composite service delivered to end users. Concerning privacy conservation, we develop a decentralized and recursive bidding algorithm, allowing service providers to reach an equilibrium without disclosing their private information. Through theoretical analysis, we show that a Nash equilibrium exists in a QoS aware service composition game. Through extensive simulations, we show that the proposed recursive bidding process can converge quickly to a Nash equilibrium service composition scheme, and its efficiency is generally high.	algorithm;autonomous robot;cloud computing;converge;nash equilibrium;numerical analysis;personally identifiable information;quality of service;recursion;service composability principle;service-oriented modeling;simulation	Li Pan;Bo An;Shijun Liu;Li-zhen Cui	2017	2017 IEEE International Conference on Web Services (ICWS)	10.1109/ICWS.2017.28	mobile qos;computer science;data mining;end user;quality of service;service provider;cloud computing;simulation;bidding;distributed computing;revenue;nash equilibrium	HPC	-0.22757514377488552	3.8388079792552645	151474
2fe07e4dcaed6fde75a4c029f2866716a0eec407	posted prices vs. negotiations: an asymptotic analysis	online algorithm;secretary problems;statistical mechanics;asymptotic analysis;von mises;secretary problem;large scale;distribution function;posted prices;first order;private values;single item auctions;mechanism design;first order statistics;bayesian model;asymptotic equivalence	The design of optimal auctions focuses on ways to negotiate with the bidders for eliciting relevant information that they hold. Sometimes, however, decisions should be made very quickly, and the auctioneer cannot allow a costly iterative procedure of negotiation or waiting for bidders to determine their exact valuation. One solution that has been used in practice is to post prices for the bidders, without collecting any information from the bidders, and ask for their immediate take-it-or-leave-it response.  Our paper compares the expected revenue in full-revelation auctions to that in posted-price auctions. We focus on single-item auctions in a Bayesian model where the values that the bidders are willing to pay for the item are independently identically distributed according to a known distribution.  This paper provides an exact asymptotic characterization of the optimal expected revenue achieved by each one of the above auctions. For posted price auctions, we also present the exact prices that achieve the optimal results.Our results are given up to terms with lower asymptotic order, that is, up to factor of 1--o(1). We provide two sets of results; one for distributions on a support that is bounded from above, and a second set for distributions on unbounded supports. In the first case we require a mild assumption on the way the distribution function approaches the end of the support, called the first von Mises condition; the latter case requires a similar mild condition called the second von Mises condition. These very weak conditions are taken from works on extreme-value theory and highest-order statistics.	asymptote;bayesian network;extreme value theory;iteration;iterative method;value (ethics)	Liad Blumrosen;Thomas Holenstein	2008		10.1145/1386790.1386801	mechanism design;online algorithm;mathematical optimization;asymptotic analysis;economics;statistical mechanics;von mises yield criterion;distribution function;common value auction;first-order logic;mathematics;secretary problem;microeconomics;mathematical economics;bayesian inference;welfare economics;statistics	ECom	-1.471401003459817	-1.6713886950163839	151508
c9540f132aa1596c06c1395f2f7af603253604f4	strong price of anarchy and coalitional dynamics		We introduce a framework for studying the effect of cooperation on the quality of outcomes in utility games. Our framework is a coalitional analog of the smoothness framework of noncooperative games. Coalitional smoothness implies bounds on the strong price of anarchy, the loss of quality of coalitionally stable outcomes, as well as bounds on coalitional versions of coarse correlated equilibria and sink equilibria, which we define as out-of-equilibrium myopic behavior as determined by a natural coalitional version of best-response dynamics. Our coalitional smoothness framework captures existing results bounding the strong price of anarchy of network design games. We show that in any monotone utility-maximization game, if each player’s utility is at least his marginal contribution to the welfare, then the strong price of anarchy is at most 2. This captures a broad class of games, including games with a very high price of anarchy. Additionally, we show that in potential games the strong price of anarchy is close to the price of stability, the quality of the best Nash equilibrium.	anarchy;expectation–maximization algorithm;marginal model;modulus of smoothness;nash equilibrium;network planning and design;price of stability;monotone	Yoram Bachrach;Vasilis Syrgkanis;Éva Tardos;Milan Vojnovic	2013	CoRR		price of stability;economics;microeconomics;mathematical economics;welfare economics;price of anarchy	Theory	-3.750320791294657	-1.0341045404916622	151522
70f84828183ba8116654a561fac630b6d646e397	blockchain mining games	nash equilibrium;consensus protocol;bitcoin;bitcoin blockchain games consensus protocol nash equilibrium;blockchain games	We study the strategic considerations of miners participating in the bitcoin's protocol. We formulate and study the stochastic game that underlies these strategic considerations. The miners collectively build a tree of blocks, and they are paid when they create a node (mine a block) which will end up in the path of the tree that is adopted by all. Since the miners can hide newly mined nodes, they play a game with incomplete information. Here we consider two simplified forms of this game in which the miners have complete information. In the simplest game the miners release every mined block immediately, but are strategic on which blocks to mine. In the second more complicated game, when a block is mined it is announced immediately, but it may not be released so that other miners cannot continue mining from it. A miner not only decides which blocks to mine, but also when to release blocks to other miners. In both games, we show that when the computational power of each miner is relatively small, their best response matches the expected behavior of the bitcoin designer. However, when the computational power of a miner is large, he deviates from the expected behavior, and other Nash equilibria arise.	bitcoin;computation;mined;nash equilibrium	Aggelos Kiayias;Elias Koutsoupias;Maria Kyropoulou;Yiannis Tselekounis	2016		10.1145/2940716.2940773	simulation;economics;repeated game;data mining;mathematical economics;computer security;nash equilibrium	ECom	-4.452009137096059	3.441371396219807	151594
155e8b00fceffc9043d5146881fee8a98afbc5db	solution method of optimal scheme set for water resources scheduling group decision-mahing based on multi-agent computation	multi agent computation;water resources allocation and scheduling;pareto optimization;genetic algorithm;group decision making	Water resources allocation and scheduling management is a typical group decision-making problem. Determining how to realize the effective coordination between the decision makers, and how to generate the optimal solution set by computation are the keys to the research and development of water resources scheduling group decision support system. However, in the existing group decision support systems and literatures about water resources scheduling, the effective solution methods have not been reported. Firstly, this paper analyzes and designs a multi-Agent computation platform which can support the optimal scheme set, and build a functional structure model of multi-Agent computation platform. Then, it provides an algorithm of group decision making optimal scheme set based on Agent computation. The proposed algorithm generates the optimal scheme set by using the multi-Agent computation platform based on the genetic algorithm. Experimental results show that the proposed algorithm can make the coordination satisfaction degree of each group decision-making converge, and generate the optimal solutions set through the effective computation.	computation;converge;decision support system;genetic algorithm;multi-agent system;scheduling (computing)	Chenming Li;Fengzhou Wang;Xiaodong Wei;Zhenli Ma	2011	Intelligent Automation & Soft Computing	10.1080/10798587.2011.10643195	fair-share scheduling;mathematical optimization;genetic algorithm;group decision-making;dynamic priority scheduling;computer science;theoretical computer science;machine learning;distributed computing	AI	-0.44760642596639627	2.4353453376991343	151709
7459432d7f9840b96ff20b1f16069b7f31abf8ca	infinite-horizon team-optimal incentive stackelberg games for linear stochastic systems			stochastic process	Hiroaki Mukaidani	2016	IEICE Transactions		mathematical optimization;mathematical economics;stackelberg competition	ECom	0.5621238341044626	-1.338985158062577	152427
095cc9aafd755b32f00c471b2a2e8023f6602fbe	the shapley value in knapsack budgeted games		We propose the study of computing the Shapley value for a new class of cooperative games that we call budgeted games, and investigate knapsack budgeted games in particular, a version modeled after the classical knapsack problem. In these games, the “value” of a set S of agents is determined only by a critical subset T ⊆ S of the agents and not the entirety of S due to a budget constraint that limits how large T can be. We show that the Shapley value can be computed in time faster than by the näıve exponential time algorithm when there are sufficiently many agents, and also provide an algorithm that approximates the Shapley value within an additive error. For a related budgeted game associated with a greedy heuristic, we show that the Shapley value can be computed in pseudo-polynomial time. Furthermore, we provide generalizations of our techniques that capture a broad class of cooperative games with the property of efficient computation of the Shapley value. The main idea is that the efficient computation can be reduced to the problem of finding an alternative representation of the games and an associated algorithm for computing the underlying value function with small time and space complexities in the representation size.	bellman equation;computation;computational complexity theory;game theory;greedy algorithm;heuristic;knapsack problem;polynomial;pseudo-polynomial time;stable marriage problem;time complexity;utility functions on indivisible goods	Smriti Bhagat;Anthony Kim;S. Muthukrishnan;Udi Weinsberg	2014		10.1007/978-3-319-13129-0_8	mathematical optimization;combinatorics;mathematics;shapley value;mathematical economics	ECom	-2.7877715679763617	-0.5207630098359853	154503
7fddd9f610e43c6d815b38d988b503627e9135f8	convergence of heterogeneous distributed learning in stochastic routing games	mirrors;convergence;routing;stochastic processes;games;statistics;sociology	We study convergence properties of distributed learning dynamics in repeated stochastic routing games. The game is stochastic in that each player observes a stochastic vector, the conditional expectation of which is equal to the true loss (almost surely). In particular, we propose a model in which every player m follows a stochastic mirror descent dynamics with Bregman divergence Dψm and learning rates ηtm = θmt-αm. We prove that if all players use the same sequence of learning rates, then their joint strategy converges almost surely to the equilibrium set. If the learning dynamics are heterogeneous, that is, different players use different learning rates, then the joint strategy converges to equilibrium in expectation, and we give upper bounds on the convergence rate. This result holds for general routing games (no smoothness or strong convexity assumptions are required). These results provide a distributed learning model that is robust to measurement noise and other stochastic perturbations, and allows flexibility in the choice of learning algorithm of each player. The results also provide estimates of convergence rates, which are confirmed in simulation.	algorithm;bregman divergence;convex function;differential privacy;iteration;population dynamics;rate of convergence;routing;simulation	Syrine Krichene;Walid Krichene;Roy Dong;Alexandre M. Bayen	2015	2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)	10.1109/ALLERTON.2015.7447043	mathematical optimization;simulation;online machine learning;mathematics;mathematical economics	ML	-3.029515937156759	1.333018941129988	154899
417a2fe8f1def5aad93ecbcd6fef492703f6de5e	dynamic auction: a tractable auction procedure	dynamic auction;double direction auction;combinatorial auction	Dynamic auctions are trading mechanisms for discovering market-clearing prices and efficient allocations based on price adjustment processes. This paper studies the computational issues of dynamic auctions for selling multiple indivisible items. Although the decision problem of efficient allocations in a dynamic auction in general is intractable, it can be solved in polynomial time if the economy under consideration satisfies the condition of Gross Substitutes and Complements, which is known as the most general condition that guarantees the existence of Walrasian equilibrium. We propose a polynomial algorithm that can be used to find efficient allocations and introduce a double-direction auction procedure to discover a Walrasian equilibrium in polynomial time.	algorithm;decision problem;indivisible;nash equilibrium;polynomial;time complexity	Dongmo Zhang;Laurent Perrussel	2010			walrasian auction;auction algorithm;vickrey auction;combinatorial auction;generalized second-price auction;unique bid auction;computer science;vickrey–clarke–groves auction;revenue equivalence;english auction;double auction;bid shading;auction theory;forward auction	ECom	-2.6670685304579096	-1.532476360712769	154904
8216cab1b057f5735dde54b7d33dc665f7e63465	multi-player and multi-round auctions with severely bounded communication	economie;economia;registre;perdida;upper bound;ciencias economicas;subasta;bidding;number;sciences economiques;economy;enchere;economics;borne superieure;nombre;loss;perte;registro;register;numero;cota superior	We study auctions in which bidders have severe constraints on the size of messages they are allowed to send to the auctioneer. In such auctions, each bidder has a set of k possible bids (i.e. he can send up to t = log(k) bits to the mechanism). This paper studies the loss of economic efficiency and revenue in such mechanisms, compared with the case of unconstrained communication. For any number of players, we present auctions that incur an efficiency loss and a revenue loss of O( 1 k ), and we show that this upper bound is tight. When we allow the players to send their bits sequentially, we can construct even more efficient mechanisms, but only up to a factor of 2 in the amount of communication needed. We also show that when the players’ valuations for the item are not independently distributed, we cannot do much better than a trivial mechanism.	business intelligence development studio	Liad Blumrosen;Noam Nisan;Ilya Segal	2003		10.1007/978-3-540-39658-1_12	numero sign;bidding;common value auction;mathematics;mathematical economics;upper and lower bounds;grammatical number	ECom	-2.1344073732215616	-2.448957118087597	155540
dc4ec76043fcecbef0e4fb6c3f36fc92a3c638b3	allocation with traffic spikes: mixing adversarial and stochastic models		Motivated by Internet advertising applications, online allocation problems have been studied extensively in various adversarial and stochastic models. While the adversarial arrival models are too pessimistic, many of the stochastic (such as i.i.d. or random-order) arrival models do not realistically capture uncertainty in predictions. A significant cause for such uncertainty is the presence of unpredictable traffic spikes, often due to breaking news or similar events. To address this issue, a simultaneous approximation framework has been proposed to develop algorithms that work well both in the adversarial and stochastic models; however, this framework does not enable algorithms that make good use of partially accurate forecasts when making online decisions. In this article, we propose a robust online stochastic model that captures the nature of traffic spikes in online advertising. In our model, in addition to the stochastic input for which we have good forecasting, an unknown number of impressions arrive that are adversarially chosen. We design algorithms that combine a stochastic algorithm with an online algorithm that adaptively reacts to inaccurate predictions. We provide provable bounds for our new algorithms in this framework. We accompany our positive results with a set of hardness results showing that our algorithms are not far from optimal in this framework. As a byproduct of our results, we also present improved online algorithms for a slight variant of the simultaneous approximation framework.	allocation;approximation;online advertising;online algorithm;pessimism;projections and predictions;provable security;stochastic process	Hossein Esfandiari;Nitish Korula;Vahab Mirrokni	2018	ACM Trans. Economics and Comput.	10.1145/3105446		ML	-1.0082400560153686	0.8161090056917757	155858
918047f266acb7a99510dd8d659ccfb712b86e5d	the impact of worst-case deviations in non-atomic network routing games		We introduce a unifying model to study the impact of worst-case latency deviations in non-atomic selfish routing games. In our model, latencies are subject to (bounded) deviations which are taken into account by the players. The quality deterioration caused by such deviations is assessed by the $\textit{Deviation Ratio}$, i.e., the worst-case ratio of the cost of a Nash flow with respect to deviated latencies and the cost of a Nash flow with respect to the unaltered latencies. This notion is inspired by the $\textit{Price of Risk Aversion}$ recently studied by Nikolova and Stier-Moses. Here we generalize their model and results. In particular, we derive tight bounds on the Deviation Ratio for multi-commodity instances with a common source and arbitrary non-negative and non-decreasing latency functions. These bounds exhibit a linear dependency on the size of the network (besides other parameters). In contrast, we show that for general multi-commodity networks an exponential dependency is inevitable. We also improve recent smoothness results to bound the Price of Risk Aversion.	routing	Pieter Kleer;Guido Schäfer	2016		10.1007/978-3-662-53354-3_11	mathematical optimization;mathematics;mathematical economics;welfare economics;statistics	ECom	-3.8116396081589112	2.3979021051375553	157411
a3c6c2aefb3391408b281143d630fb9913b6382b	addressing supply-side risk in uncertain power markets: stochastic nash models, scalable algorithms and error analysis	nash games;rate of convergence;space network;power market;electrical network;variational inequalities;real time;variational problem;market design;cutting plane methods;error analysis;projected gradient schemes;variational inequality;power grid;error bound;stochastic programming;cutting plane method	(2012): Addressing supply-side risk in uncertain power markets: stochastic Nash models, scalable algorithms and error analysis, Optimization Methods and Software, This article may be used for research, teaching, and private study purposes. Any substantial or systematic reproduction, redistribution, reselling, loan, sub-licensing, systematic supply, or distribution in any form to anyone is expressly forbidden. The publisher does not give any warranty express or implied or make any representation that the contents will be complete or accurate or up to date. The accuracy of any instructions, formulae, and drug doses should be independently verified with primary sources. The publisher shall not be liable for any loss, actions, claims, proceedings, demand, or costs or damages whatsoever or howsoever caused arising directly or indirectly in connection with or arising out of the use of this material. Increasing penetration of volatile wind-based generation into the fuel mix is leading to growing supply-side volatility. As a consequence, the reliability of the power grid continues to be a source of much concern, particularly since the impact of supply-side risk exposure, arising from aggressive bidding, 1 is not felt by risk-seeking generation firms; instead, the system operator is largely responsible for managing shortfalls in the real-time market. We propose an alternate design in which the cost of such risk is transferred to firms responsible for imposing such risk. The resulting strategic problem can be cast as a two-period generalized stochastic Nash game with shared strategy sets. A subset of equilibria is given by a solution to a related stochastic variational inequality, that is shown to be both monotone and solvable. Computing solutions of this variational problem is challenging since the size of the problem grows with the cardinality of the sample space, network size and the number of participating firms. Consequently, direct schemes are inadvisable for most practical problems. Instead, we present a distributed regularized primal–dual scheme and a dual projection scheme where both primal and dual iterates are computed separately. Rates of convergence estimates are provided and error bounds are developed for inexact extensions of the dual scheme. Unlike projection schemes for deterministic problems, here the projection step requires the solution of a possibly massive stochastic programme. By utilizing cutting plane methods, we ensure that the complexity of the projection scheme scales slowly with the size of the sample space. We conclude with a study of a 53-node electricity network that allows for deriving insights regarding market …	algorithm;calculus of variations;cutting-plane method;decision problem;error analysis (mathematics);nash equilibrium;polynomial-time approximation scheme;primary source;real-time clock;scalability;social inequality;sysop;variational inequality;volatility;monotone	Aswin Kannan;Uday V. Shanbhag;Harrison M. Kim	2013	Optimization Methods and Software	10.1080/10556788.2012.676756	mathematical optimization;variational inequality;mathematics;mathematical economics	ML	2.473742108536521	-0.5971228862183642	157460
42e148ba541038c08ecf59b96e96cc895fc330f2	optimal scheduling and placement of internet banner advertisements	modelizacion;site web;optimal scheduling internet advertising displays pricing web sites dynamic scheduling job shop scheduling measurement standards;optimal solution;solution optimale;probleme sac a dos;probability;red www;web site revenue;advertising data processing;pricing;probability parameter;modelo hibrido;reseau web;click behavior;user click behavior;probabilistic approach;problema mochila;fijacion precios;modele hybride;hybrid model;optimisation combinatoire;modelisation;internet banner advertisement placement;knapsack problem;web advertisement;tariffication;internet;revenu economique;optimal scheduling;tarification;scheduling;enfoque probabilista;approche probabiliste;solucion optima;dynamic and static scheduling internet advertising;comportement utilisateur;web sites;probability advertising data processing internet pricing;schedules;banner ads;world wide web;planning;dynamic and static scheduling;user behavior;sitio web;publicidad;combinatorial optimization;publicite;internet advertising;renta;modeling;probability parameter optimal scheduling internet banner advertisement placement world wide web hybrid pricing model web site revenue user click behavior;fixation prix;ordonnancement;comportamiento usuario;web site;hybrid pricing model;reglamento;dynamic scheduling;tarificacion;income;optimizacion combinatoria;advertising;knapsack	"""The increasing popularity of the World Wide Web has made it an attractive medium for advertisers. As more advertisers place Internet advertisements (hereafter also called """"ads""""), it has become important for Web site owners to maximize revenue through the optimal selection and placement of these ads. Unlike most previous research, we consider a hybrid pricing model, where the price advertisers pay is a function of 1) the number of exposures of the ad and 2) the number of clicks on the ad. The problem is finding an ad schedule to maximize the Web site revenue under a hybrid pricing model. We formulate two versions of the problem - static and dynamic - and propose a variety of efficient solution techniques that provide near-optimal solutions. In the dynamic version, the schedule of ads is changed based on individual user click behavior. We show by using a theoretical proof under special circumstances and an experimental demonstration under general conditions that a schedule that adapts to the user click behavior consistently outperforms one that does not. We also demonstrate that to benefit from observing the user click behavior, the associated probability parameter need not be estimated accurately. For both of these versions, we examine the sensitivity of the revenue with respect to the model parameters."""	algorithm;computation;game theory;heuristic;integer programming;internet;np-hardness;online advertising;scheduling (computing);strong np-completeness;web banner;world wide web	Subodha Kumar;Milind Dawande;Vijay S. Mookerjee	2007	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2007.190640	simulation;combinatorial optimization;computer science;share of voice;artificial intelligence;database;knapsack problem;world wide web	DB	-0.8812945485601896	-2.078314113128254	157560
0c5dc11c700460ca30410a5f2bfac7d9dcc6ac5f	discounted stochastic ratio games		In a recent work, the authors considered a finite state Markov ratio decision process in which the objective was to maximize the ratio of total discounted rewards. In this paper, discounted Markov ratio decision processes are generalized to discounted stochastic ratio games. These may also be viewed as generalizations of ratio games to a stochastic context where the payoff is the ratio of the two total discounted rewards. We show that in the discounted stochastic ratio game the players have stationary optimal strategies with a unique value. The solution may depend on the initial probability distribution. We also provide a convergent algorithm.	algorithm;markov chain;stationary process	V. Aggarwal;Ramaswamy Chandrasekaran;Kunhiraman Nair	1980	SIAM J. Matrix Analysis Applications	10.1137/0601023	mathematical optimization;mathematics;mathematical economics	ML	-3.7585617716966513	-1.0581358029318435	157784
17a1e191f889be2225196ab2f82e9c13c6500019	ordering electricity via internet and its potentials for smart grid systems	virtual energy provisioning;belief networks;demand side management;pricing;virtual energy provisioning demand side management dynamic pricing hypothesis testing online energy purchase smart metering;bayesian methods;smart metering;power markets;online energy purchase;dynamic pricing;internet;smart power grids;internet pricing predictive models bayesian methods;hypothesis testing;ubiquitous computing;predictive models;dynamic pricing electricity ordering internet smart grid systems ubiquitous communication medium demand side management system online purchase electricity now utility companies bayesian theory hypothesis testing;ubiquitous computing belief networks demand side management internet power markets smart power grids	The Internet has evolved into a ubiquitous communication medium for information exchanges, services requests, and commodity purchasing. This paper proposes the concept, architecture, and the customer incentives for implementing a new demand-side management system called Online Purchase Electricity Now (OPEN). The new system allows customers to directly order the electricity via the Internet as if purchasing a book online. Utility companies, after consolidating the customers' orders, decide an optimal generation and distribution scheme to satisfy customers' demands. The time epoch between the customers' order and the actual generation acts as the lead time during which virtual energy will be scheduled for production. Such a virtual energy provisioning system can improve the reliability and stability of the electric grid which is increasingly integrated with distributed energy resources. Bayesian theory, hypothesis testing, and dynamic pricing are employed to justify the feasibility and applicability of the OPEN system.	embodied energy;epoch (reference date);internet;provisioning;purchasing	Tongdan Jin;Mahmoud Mechehoul	2010	2012 IEEE Power and Energy Society General Meeting	10.1109/TSG.2010.2072995	pricing;statistical hypothesis testing;the internet;bayesian probability;computer science;marketing;predictive modelling;microeconomics;ubiquitous computing;statistics;commerce	Metrics	1.1843625525580834	4.001165670925112	158360
96decfccfd36d4fddaafb0e9e2e8abc1ef100d38	optimal strategies for stochastic linear quadratic differential games with costly information	nash equilibrium;cost function;closed form solutions;stochastic processes;games;mathematical model	A two players stochastic differential game is considered with a given cost function. The players engage in a non-cooperative game where one tries to minimize and the other tries to maximize the cost. The players are given a dynamical system and their actions serve as the control inputs to the dynamical system. Their job is to control the state of this dynamical system to optimize the given objective function. We use the term “state of the game” to describe the state of this dynamical system. The challenge is that none of the players has access to the state of the game for all time, rather they can access the state intermittently and only after paying some information cost. Thus the cost structure is non-classical for a linear-quadratic game and it incorporates the value of information. We provide the Nash equilibrium strategy for the players under full state information access at no cost, as well as under costly state information access. The optimal instances for accessing the state information are also explicitly computed for the players.	dynamical system;information access;loss function;nash equilibrium;optimization problem	Dipankar Maity;John S. Baras	2016	2016 IEEE 55th Conference on Decision and Control (CDC)	10.1109/CDC.2016.7798282	price of stability;non-cooperative game;stochastic process;games;mathematical optimization;example of a game without a value;simulation;best response;simultaneous game;information set;repeated game;mathematical model;rationalizability;mathematics;stochastic game;screening game;normal-form game;mathematical economics;outcome;sequential game;complete information;equilibrium selection;symmetric game;solution concept;nash equilibrium;statistics	ML	0.26474969765532963	-0.5403803481440187	158558
bf07020522183fbff91c24003720211be79e957d	a negotiation-based capacity-planning model	capacity planning autonomous negotiation;capacity planning;manufacturing resources planning budgeting capacity planning manufacturing genetic algorithms;manufacturing resources planning;budgeting;genetic algorithm negotiation based capacity planning model multiple factories negotiation framework autonomous budget allocation manufacturing resources capacity planning optimization;production facilities resource management genetic algorithms manufacturing capacity planning;genetic algorithms;capacity planning manufacturing	Capacity planning deals with the conflicts among multiple factories. This study employs a negotiation framework to allow autonomous budget allocation among factories and make full use of manufacturing resources capacity scattered over individual factories. Factories are modeled as intelligent entities that exchange offer messages with one another. This study investigates the effects of the attitudes of a factory, while it bargains with other factories over the budget. Furthermore, individual factories apply a capacity-planning optimization model and a genetic algorithm to revise their capacity plan right after receiving new messages from other factories. This paper makes a contribution in successfully building a negotiation-based capacity-planning model applied to a multiple-factory environment. The outcome of the experiments shows the efficiency of the proposed model and the effect of different negotiation attitudes.	autonomous robot;entity;experiment;genetic algorithm;mathematical optimization;semiconductor	Kung-Jeng Wang;Shih-Min Wang	2012	IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)	10.1109/TSMCC.2011.2175381	genetic algorithm;computer science;knowledge management;artificial intelligence;machine learning;capacity management	Robotics	-0.3584554751816409	2.3321460556654077	158713
57a85b0fe162d722ec4fb1bc8263fde88c3e9249	an optimal dividend strategy in the discrete sparre andersen model with bounded dividend rates	computacion informatica;sparre andersen risk model;journal;ciencias basicas y experimentales;matematicas;fixed point theory;control;optimal dividend strategy;transformation;grupo a	Weconsider the discrete SparreAndersen riskmodel and its derivativemodels by anewsetting up the initial times, and assume that dividends are paid to the shareholders according to an admissible strategy with dividend rates bounded by a constant. The company controls the amount of dividends in order to maximize the cumulative expected discounted dividends prior to ruin. We show that the optimal value function is the unique bounded solution of a set of discrete Hamilton–Jacobi–Bellman equations. Moreover, we introduce Bellman’s recursive algorithm and offer a simpler algorithm to obtain the optimal strategy and the optimal value functions. Our method is mainly to transform the value functions. Numerical examples are presented to illustrate the transformation method. © 2013 Elsevier B.V. All rights reserved.	algorithm;bellman equation;hamilton–jacobi–bellman equation;jacobi method;numerical method;optimization problem;recursion (computer science)	Jiyang Tan;Pingtian Yuan;Yangjin Cheng;Ziqiang Li	2014	J. Computational Applied Mathematics	10.1016/j.cam.2013.08.029	transformation;mathematical optimization;actuarial science;mathematics;fixed-point theorem;mathematical economics;scientific control	AI	1.7855665158683778	-2.3733030984802284	159187
59f2d904326faf3554c73893be21cd2a32d90813	new formulations of the stochastic user equilibrium with logit route choice as an extension of the deterministic model		This paper addresses the stochastic user equilibrium (SUE) in the case where the route choice is the multinomial logit model (MNL). Our main finding is that MNL SUE can be formulated and solved as an immediate extension of the deterministic user equilibrium (DUE) through a particular application of Wardrop’s first principle. The latter states, in general, that at equilibrium, the cost of all used routes is equal and not higher than those of unused routes. The extension is achieved by applying this statement to the “perceived cost” of a choice alternative, which is defined here as its generalized cost plus the logarithm of its choice probability multiplied by the logit parameter. Thus, substituting in DUE models the generalized costs with the perceived costs allows to easily adapt to MNL SUE the existing formulations and algorithms for DUE, as well as to manage a smooth transition of the route choice model from stochastic to deterministic by reducing the logit parameter down to zero. Particular considerati...		Guido Gentile	2018	Transportation Science	10.1287/trsc.2018.0839	first principle;logit;mathematics;mathematical optimization;logarithm;multinomial logistic regression;deterministic system	AI	2.428808970617053	-2.1329246448764714	159285
7798eda8cfedd1ff13df6afcfa45b92478a0f4c5	strategic queueing behavior for individual and social optimization in managing discrete time working vacation queue with bernoulli interruption schedule	queueing;bernoulli interruption schedule;postprint article;working vacation;conditional sojourn time;joining strategy	In this paper, we consider a discrete time working vacation queue with a utility function for the reward of receiving the service and the cost of waiting in the system. A more flexible switching mechanism between low and regular service states is introduced to enhance the practical value of the working vacation queue. Under different precision levels of the system information, namely observable, almost unobservable and fully unobservable cases, the utility function is studied from both the individual customer's and the system administrator's points of view. By analyzing the steady-state behavior of the system, the associated optimal joining decisions under different information scenarios are obtained. We find that for the fully observable queue, the joining threshold for individual optimization may be less than the one for social optimization in working vacation period. A similar situation also appears in almost unobservable case. Such phenomenon is not possible for the classic first come first served queue due to the fact that there is no vacation time and thus will not cause large fluctuations in customers' conditional waiting time. Additionally, we also conduct some numerical comparisons to demonstrate the effect of the information levels as well as system parameters on customer joining behavior. HighlightsBernoulli interruption of the vacation captures correlations between service and vacation times.Explicit expressions to allow computations of the equilibrium and optimal policies are derived.In some cases, socially optimal strategy accepts more customers than those who join individually.	bernoulli polynomials;interrupt;mathematical optimization	Miaomiao Yu;Attahiru Sule Alfa	2016	Computers & OR	10.1016/j.cor.2016.03.011	real-time computing;simulation;computer science;mathematics;queueing theory;statistics	ECom	2.1265697023294496	0.3629321062796373	159915
f076239f4d736c03d457746edf4c18664020a99d	euro-par 2012 parallel processing		In this talk, we present a selection of important concepts and results in algorithmic game theory in recent years, some of which received the 2012 Gödel Prize, along with some applications in distributed settings. A famous solution concept for non-cooperative games is the Nash equilibrium. In a Nash equilibrium, no selfish player can unilaterally deviate from his current strategy and improve his profit. Nash dynamics is a method to compute a Nash equilibrium. Here, in each round, a single player is allowed to perform a selfish step, i. e. unilaterally change his strategy and improve his cost. The Nash dynamics terminates if it does not run into a cycle. This is always the case if the game has a potential function. In this case, computing a Nash equilibrium is a PLS problem (Polynomial Local Search) and belongs to the large class of well-studied local optimization problems. Inspired by real-world networks, network congestion games have been under severe scrutiny for the last years. Network congestion games model selfish routing of unsplittable units. These units may be weighted or unweighted. Weighted congestion games do not necessarily have a pure Nash equilibrium. Conversely, an unweighted congestion game has a potential function. Computing a pure Nash equilibrium for an unweighted congestion game is PLS-complete. The absence of a central coordinating authority can result in a loss of performance due to the selfishness of the participants. This situation is formalized in the notion “Price of Anarchy”. The Price of Anarchy is defined to be the worst case ratio between the maximal social cost in a Nash equilibrium and the optimal social cost. We present the recent results for congestion games and for the special case of load balancing. Classical game theory assumes that each player acts rationally and wants to improve his profit. This is not realistic in a distributed setting since it requires that each player has the complete information about the state of the system. We introduce the concept of selfish distributed load balancing and describe recent results. We will also consider distributed algorithms for network creation games. In the past, network creation games have mostly been studied under the assumption that the players have a global view on the network, or more precisely, that the players are able to compute the average distance or the maximum distance to the nodes they want to interact with in the given network, depending on the objective function. A player may then decide to add one or more edges for some extra cost or to drop C. Kaklamanis et al. (Eds.): Euro-Par 2012, LNCS 7484, pp. 1–2, 2012. c © Springer-Verlag Berlin Heidelberg 2012 2 B. Monien and C. Scheideler an edge. We will look at network creation games from a different angle. In our case, the players have fixed distances to each other that are based on some underlying metric (determined by, for example, the geographic positions of the players), and the goal is to study the networks formed if players selfishly add and remove edges based on that metric. We show that for certain metrics like the line metric, tree metric, and the Euclidean metric, certain selfish behavior, that only requires a local view of the players on the network, will lead to stable networks that give a good approximation of the underlying metric. Topic 1: Support Tools and Environments Omer Rana, Marios Dikaiakos, Daniel S. Katz, and Christine Morin	algorithmic game theory;anarchy;approximation;best, worst and average case;distributed algorithm;euclidean distance;euro-vo;gödel prize;lecture notes in computer science;load balancing (computing);local search (constraint satisfaction);mathematical optimization;maximal set;metric tree;nash equilibrium;network congestion;optimization problem;polynomial;potential method;routing;springer (tank)	Gerhard Goos;Juris Hartmanis;Jan van Leeuwen;David Hutchison;Christos Kaklamanis;Theodore S. Papatheodorou;Paul G. Spirakis	2012		10.1007/978-3-642-32820-6	parallel computing;computer science;parallel processing	ECom	-2.7236670875361906	2.9362051228177384	160220
ef4e00e39897680b1972114a0439bb1d1dc763d9	finite time ruin probability in non-standard risk model with risky investments	poisson process;non homogeneous poisson process;subexponential distribution;finite horizon;extreme event;ruin probability	In this paper, under the assumption that the claimsize is subexponentially distributed and the insurance capital is totally invested in risky asset, some simple asymptotics of finite horizon ruin probabilities are obtained for non-homogeneous Poisson process and conditional Poisson risk models as well as renewal risk model, when the initial capital is quite large. Extremal event is described in this case because some claim can be larger than initial capital even it is large enough. The results obtained extended the corresponding results of related papers in this area.	financial risk modeling	Tao Jiang	2009		10.1007/978-3-642-02469-6_55	actuarial science;poisson process;ruin theory;mathematics;inhomogeneous poisson process;statistics;compound poisson process	Vision	2.522546217507487	-2.4874465468316047	160227
ee906cb25cee162f503ab1c82ab4997d5db19b1a	a two-layered framework for robust dispatch with transmission constraints	ieee 24 bus reliability test system robust dispatch transmission constraints multiinterval economic dispatch ramping constraints electric energy systems lack of ramp probability lorp ramp capability two layered robust optimization based dispatch real time dispatch multizonal energy systems;generators;robustness uncertainty generators economics indexes load modeling real time systems;transmission networks optimisation power generation dispatch power generation economics;uncertainty;operating zone economic dispatch ramp product robust optimization;ramp product;robust optimization;operating zone;indexes;robustness;economics;economic dispatch;load modeling;real time systems	This paper presents a two-layered framework for managing multi-interval economic dispatch with both transmission and ramping constraints in electric energy systems with a large penetration of variable resources. The proposed model is aimed at ensuring that there is sufficient flexibility in the dispatch to manage large net load ramp events while observing the transmission constraints in the power network. A flexibility metric termed lack of ramp probability (LORP) is used to quantify the ramp capability. This metric is shown to be applicable in system-wide and decomposed zonal settings. A two-layered robust optimization-based dispatch is then formulated as an approach to ensuring a level of LORP flexibility with transmission constraints in large power networks. This two-layered approach is shown to be rigorous in terms of guaranteeing flexibility and is implementable for real-time dispatch in multi-zonal energy systems. The performance of the proposed dispatch framework is illustrated in a modified IEEE 24-bus Reliability Test System.	defense in depth (computing);dynamic dispatch;mathematical optimization;ramp simulation software for modelling reliability, availability and maintainability;real-time clock;robust optimization;turing test	Anupam A. Thatte;Le Xie	2015	2015 48th Hawaii International Conference on System Sciences	10.1109/HICSS.2015.301	database index;mathematical optimization;robust optimization;uncertainty;computer science;operations management;programming language;economic dispatch;robustness	EDA	2.418560354263814	4.036094549111925	160363
2e63499d0135e7830b1249796f71aea42b1e1c60	optimal consumption in a stochastic ramsey model with cobb-douglas production function	qa mathematics	A stochastic Ramsey model is studied with the Cobb-Douglas production function maximizing the expected discounted utility of consumption. We transformed the Hamilton-Jacobi-Bellman (HJB) equation associated with the stochastic Ramsey model so as to transform the dimension of the state space by changing the variables. By the viscosity solution method, we established the existence of viscosity solution of the transformed Hamilton-Jacobi-Bellman equation associated with this model. Finally, the optimal consumption policy is derived from the optimality conditions in the HJB equation.	bellman equation;jacobi method;state space;utility;viscosity solution	Md. Azizul Baten;Anton Abdulbasah Kamil	2013	Int. J. Math. Mathematical Sciences	10.1155/2013/684757	mathematical optimization;mathematical analysis;mathematics;mathematical economics	Theory	1.5572580846406618	-2.2287821378376034	161821
7ca431684de4c6968d25ab10815d26375424dd26	disaster evacuation assistance system based on multi-agent cooperation	constraint optimization;approximation algorithms;multi agent disaster evacuation dcop;dcop;multi agent;evacuation completion time disaster evacuation assistance system dangerous situations multiagent cooperation mobile devices phones mobile pc tablets distributed calculations evacuees locations evacuation timing disaster evacuation problem distributed constraint optimization problem dcop system evaluation multiagent simulation evacuation guidance;mobile handsets timing buildings approximation algorithms approximation methods constraint optimization planning;disaster evacuation;optimisation constraint theory digital simulation disasters emergency management mobile computing mobile radio multi agent systems;mobile handsets;planning;approximation methods;buildings;timing	This paper proposes a system that supports people being evacuated effectively from dangerous situations by using multi-agent cooperation. The main feature of this system is that it does not require central servers. The system uses the mobile devices of evacuees (e.g. Phones, mobile PCs, tablets) and performs distributed calculations while assessing the locations of evacuees. By using this system, the evacuees are able to know the appropriate evacuation timing. This paper focuses on the formalization of the disaster evacuation problem and how to solve it using the framework of the Distributed Constraint Optimization Problem (DCOP). In order to evaluate this system, an experiment was carried out using multi-agent simulation. The result of the experiment showed that, for the case where the evacuees can receive evacuation guidance from this system, the evacuation completion time for all evacuees (in the case) was about 10% - 30% less than in the case where this system is not used.	agent-based model;approximation algorithm;constrained optimization;dcop;distributed constraint optimization;experiment;fairness measure;hands-on computing;hoc (programming language);mathematical optimization;mobile device;mobile phone;multi-agent system;network congestion;optimization problem;server (computing);simulation;tablet computer	Yasuki Iizuka;Kayo Iizuka	2015	2015 48th Hawaii International Conference on System Sciences	10.1109/HICSS.2015.30	planning;constrained optimization;simulation;computer science;management;computer security;approximation algorithm	Robotics	-1.6108600820652579	4.169343852958861	162282
761d856bd226d20240a90dfabc7c203fdbf7bf17	reconciling selfish routing with social good		Selfish routing is one of the most studied problems in algorithmic game theory, with one of the principal applications being that of routing in road networks. The majority of related work, in the many variants of the problem, deals with the inefficiency of equilibria to which users are assumed to converge. Multiple mechanisms for improving the outcomes at equilibria have been considered, such as the use of tolls or the use of Stackelberg strategies, each with different caveats in terms of their applicability to real traffic routing. But the emergence of routing technologies and autonomous driving motivates new solution concepts that can be considered as outcomes of the game and may help in improving the network’s performance. In reality, when users ask their routing devices for good origin to destination paths, they care about the end-to-end delay on their paths without (directly) caring about subpath optimality. This gives a central planner the ability, through routing devices, to provide path flow solutions that circumvent the local subpath optimality conditions imposed by (approximate) Nash equilibria, while they are acceptable to the players and potentially have good social cost. Inspired by the above observation, we consider three possible outcomes for the game: (i) θ-Positive Nash Equilibrium flow, where every path that has non zero flow on all of its edges has cost no greater than θ times the cost of any other path, (ii) θ-Used Nash Equilibrium flow, where every path that appears in the path flow decomposition has cost no greater than θ times the cost of any other path, and (iii) θ-Envy Free flow, where every path that appears in the path flow decomposition has cost no greater than θ times the cost of any other path in the path flow decomposition. We first examine the relations of these outcomes among each other and then measure their possible impact on the network’s performance, through the notions of price of anarchy and price of stability. Afterwards, we examine the computational complexity of finding such flows of minimum social cost and give a range for θ for which this task is easy and a range for θ for which, for the newly introduced concepts of θ-Used Nash Equilibrium flow and θ-Envy Free flow, this task is NP-hard. Finally, we propose deterministic strategies which, in a worst case approach, can be used by a central planner in order to provide good such flows, and also introduce a natural idea for randomly routing players after giving them specific guarantees about their costs in the randomized routing, as a tool for the central planner to implement a desired flow.	affinity analysis;algorithmic game theory;anarchy;approximation algorithm;autonomous car;best, worst and average case;calculus of variations;computation;computational complexity theory;converge;emergence;end-to-end principle;entity framework;fairness measure;flow network;ibm notes;keneth alden simons;microsoft customer care framework;np-hardness;nash equilibrium;network congestion;optimality criterion;price of stability;randomized algorithm;randomness;routing;unbundled network element;variational inequality;whole earth 'lectronic link	Soumya Basu;Ger Yang;Thanasis Lianeas;Evdokia Nikolova;Yitao Chen	2017		10.1007/978-3-319-66700-3_12	algorithmic game theory;mathematical optimization;mathematical economics;mathematics;computational complexity theory;nash equilibrium;social cost	Theory	-2.5965747214958017	2.6068112164215522	162366
6d657c1a4fa0e56bf0f3cf62fb88d3b20a4a566f	towards a decision support system for real-time pricing of electricity rates: design and application		The share of renewable energy in today’s power grids is continually increasing. However, it is notoriously difficult to accurately forecast renewable electricity sources like wind and solar production with the granularity that energy providers require. To compensate for the fluctuating production and forecast errors, energy providers have to use expensive control energy. This partly negates the positive effect of renewables. Various ideas for load smoothing on the production side have been suggested. Here, we focus on load shifting on the consumer side: electricity rates that may vary in hourly intervals can influence smart devices in private consumer households. With real-time pricing (RTP) the energy provider can send high prices when production is behind forecasts. On the other hand, prices should be cheap when the production exceeds the forecast. Cheap rates would incite electricity consumptions. The challenge is to identify the price signal that will result in the desired load shift at consumers. As the behavior of smart devices is still unknown today we use a simulation prototype and train an artificial neural network with simulation data. As it turns out the neural network leads to good results and achieves hit rates in the task of mapping the desired load shift to a price signal. This hit rate only slightly decreases when we submit the price model to some constraints that increase consumer-friendliness. The advantage of using a neural network is that it can adapt to a slowly changing mix of smart devices in households. By regularly retraining the network we are able to react to the future reality.	decision support system;real-time transcription;variable pricing	Cornelius Köpp;Hans-Jörg von Mettenheim;Michael H. Breitner	2012		10.1007/978-3-319-00795-3_47	variable pricing	Embedded	0.9860780092302162	4.0596247926863365	163626
d9709ff001a791fe785fd2047684cde2d037b95d	optimal investment with derivative securities	probability theory and stochastic processes;mathematics;quantitative finance;convex duality;trading strategy;utility maximization;economic theory;finance banking;incomplete markets;business;exponential utility;economics;optimal investment;indifference price;statistics for business economics mathematical finance insurance;incomplete market	We study the problem of portfolio optimization in an incomplete market using derivatives as well as basic assets such as stocks. In such markets, an investor may want to use derivatives, as a proxy for trading volatility, for instance, but they should be traded statically, or relatively infrequently, compared with assumed continuous trading of stocks, because of the much larger transaction costs. We discuss the computational tractability obtained by assuming exponential utility, and the relation of the optimal strategy to the method of utilityindifference pricing. In particular, we show that the optimal number of derivatives to invest in is given by the Legendre transform of the indifference price as a function of quantity, evaluated at the market price. Within popular diffusion stochastic volatility models, we discuss computational approaches for the associated quasilinear indifference pricing PDE. Joint work with A. Ilhan and M. Jonsson.	exponential utility;legendre transformation;mathematical optimization;proxy server;time complexity;volatility	Aytaç Ílhan;Mattias Jonsson;Ronnie Sircar	2005	Finance and Stochastics	10.1007/s00780-005-0154-y	financial economics;economics;finance;microeconomics;mathematical finance;incomplete markets	ECom	1.560962580024848	-2.7013294631560325	164942
1c3515f449110aa046c8f59c2f6b7b4f9b81b3d1	alternating reachability games with behavioral and revenue objectives		We introduce and study alternating reachability games with tolls (ARGTs). An ARGT is a multi-player game played on a directed graph. Each player has a source vertex and a set of target vertices. The vertices of the graph are partitioned among the players. Thus, each player owns a subset of the vertices. In the beginning of the game, each player places a token on her source vertex. Whenever a token reaches a vertex v, the owner of the token pays a toll to the owner of vertex v, who directs the token to one of the successors of v. The objective of each player combines a reachability objective with a minimal-cost maximal-profit objective. For the first, the token of the player needs to reach one of her target vertices. For the second, the player aims at decreasing the toll she pays to other players and increasing the toll paid to her due to visits in vertices she owns. ARGTs model settings in which the vertices are owned by entities who also use the network; for example, communication networks in which service providers own the routers and send messages. ARGTs also offer an extension of rational synthesis with rewards to actions. To the best of our knowledge, this model is the first to combine behavioral and revenue objectives. We study different instances of the game, distinguishing between various network topologies and various levels of overlap among the reachability objectives of the players. We analyze the stability of ARGTs, characterizing instances for which a Nash equilibrium is guaranteed to exist, and studying its inefficiency. We solve the problems of finding optimal strategies for the players and for the society as a whole, and we study the repair of ARGTs that are unstable or suffer from a high price of stability.	control theory;directed graph;entity;graph - visual representation;maximal set;nash equilibrium;network topology;numerous;price of stability;reachability;rewards;router (computing);subgroup;tlr4 protein, human;telecommunications network;unstable medical device problem;vertex (geometry);vertex (graph theory);message	Orna Kupferman;Tami Tamir	2018				ECom	-3.7067940995565816	2.1015910378425375	165397
00307a502b10924a7c61232056e82026e9d46271	an improved search technique for optimal winner determination in combinatorial auctions	electronic commerce;pricing;search algorithm;computational complexity electronic commerce pricing search problems iterative methods combinatorial mathematics;upper bound;iterative methods;electronic commerce internet management information systems upper bound marketing and sales cost accounting consumer electronics design engineering web server electronic equipment;computational complexity;inadmissible heuristic iterative threshold search optimal winner determination combinatorial auction synergistic value optimal price winning bids np complete maximal revenue;revenue maximization;search problems;combinatorial mathematics;lower bound;combinatorial auction	"""Combinatorial auctions allow bidders to bid their synergistic values. Because of complementarities between different assets, bidders give their preferences not just for particular items but also for sets or bundles of items. This form of auction shows great potential under some given circumstances but is still in its infancy. The difficulty lies in finding the optimal price that is the price of a revenue maximizing set of winning bids. Determining the revenue maximizing set of winning bids is NP-complete. In this paper, we review some of the existing approaches as detailed by Sandholm in one of his recent studies. We propose a heuristic, which is a lower bound on the maximal revenue, or an inadmissible heuristic. We then present an algorithm called, """"iterative threshold search (ITS) - hybrid"""". We show using this algorithm that, although inadmissible, such a heuristic near the optimal can be a better choice in practice than a surely admissible or upper bound heuristic. We establish through experiments that this new heuristic coupled with the proposed search algorithm improves the performance result significantly over the one presented by Sandholm."""	admissible heuristic;complementarity theory;experiment;iterative method;maximal set;np-completeness;search algorithm;synergy	Tuomas Sandholm	1999	37th Annual Hawaii International Conference on System Sciences, 2004. Proceedings of the	10.1109/HICSS.2004.1265199	e-commerce;combinatorial auction;economics;computer science;marketing;microeconomics;upper and lower bounds;commerce	AI	-1.26103525475906	-0.5058050279941508	166036
02f98c3a3afd40d7af1a965348e8db297a94d27b	economies with non-convex production and complexity equilibria	pareto efficiency;market equilibrium;computation of market equilibrium;economies of scale;non convex production	The convexity assumptions required for the Arrow-Debreu theorem are reasonable and realistic for preferences; however, they are highly problematic for production because they rule out economies of scale. We take a complexity-theoretic look at economies with non-convex production. It is known that in such markets equilibrium prices may not exist; we show that it is an intractable problem to achieve Pareto efficiency, the fundamental objective achieved by equilibrium prices. The same is true for core efficiency or any one of an array of concepts of stability, with the degree of intractability ranging from F Δ2P-completeness to PSPACE-hardness. We also identify a novel phenomenon that we call complexity equilibrium in which agents quiesce, not because there is no way for any one of group of them to improve their situation, but because discovering the changes necessary for (individual or group) improvement is intractable. In fact, we exhibit a somewhat natural distribution of economies that has an average-case hard complexity equilibrium.	arrow–debreu model;best, worst and average case;computational complexity theory;pspace;pareto efficiency;quiesce	Christos H. Papadimitriou;Christopher A. Wilkens	2011		10.1145/1993574.1993595	mathematical optimization;general equilibrium theory;economics;economies of scale;microeconomics;mathematical economics;welfare economics;economic efficiency;equilibrium selection	ECom	-3.4347060787640618	-2.6656716028499003	166487
9414f7d81ed20fb75109d06854da6eb7c57af1d0	welfare maximization with deferred acceptance auctions in reallocation problems		We design approximate weakly group strategy-proof mechanisms for resource reallocation problems using Milgrom and Segal [9]’s deferred acceptance auction framework: the radio spectrum and network bandwidth reallocation problems in the procurement auction setting and the cost minimization problem with set cover constraints in the selling auction setting. Our deferred acceptance auctions are derived from simple greedy algorithms for the underlying algorithmic problems and guarantee approximately optimal social welfare (cost) of the agents keeping their rights (contracts). In the reallocation problems, we design procurement auctions to purchase agents’ broadcast/access rights to free up some of the resources such that the unpurchased rights can still be exercised with respect to the remaining resources. In the cost minimization problem, we design a selling auction to sell early termination rights to agents with existing contracts such that some minimal constraints are still satisfied with remaining contracts. In these problems, while the “allocated” agents transact, exchanging rights and payments, the objective and feasibility constraints are on the “rejected” agents.	approximation algorithm;expectation–maximization algorithm;greedy algorithm;procurement;set cover problem	Anthony Kim	2015		10.1007/978-3-662-48350-3_67	auction algorithm;economics;microeconomics;welfare economics;auction theory;commerce	AI	-2.853277453711793	-2.243396554454909	167143
699f5413b68f72b10de151dc48b4cdd83102b987	solving coalition structure generation problem with double-layered ant colony optimization	stochastic processes ant colony optimisation computational complexity multi agent systems;cplex coalition structure generation problem double layered ant colony optimization multiagent systems np complete optimal solution stochastic algorithm task oriented coalition structure problem;ant colony optimization;ant colony optimization robot sensing systems complexity theory computer science electronic mail multi agent systems;multi agent systems;ant colony optimization multi agent systems coalition structure generation;coalition structure generation	The coalition structure generation problem is now a big issue in the field of multi-agent systems. With many agents working in the same environment, cooperation may become a key point to complete a mission efficiently. This problem can also be found in many areas such as sensor networks, multi-robot systems, and even e-commerce. However, it has been proved to be NP-complete to find an optimal solution. In the paper, a stochastic algorithm called double-layered ant colony optimization is proposed to deal with the task-oriented coalition structure problem. Then, we evaluate the solution quality by comparing it with the optimal solutions derived by CPLEX. The results indicate that even though this method cannot guarantee the optimal solution, it can find a coalition structure that is good enough within a reasonably short time.	algorithm;ant colony optimization algorithms;cplex;constructive solid geometry;e-commerce;experiment;heuristic;mathematical optimization;multi-agent system;np-completeness;principle of good enough;world-system	ChiaWei Yeh;Toshiharu Sugawara	2016	2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)	10.1109/IIAI-AAI.2016.57	mathematical optimization;ant colony optimization algorithms;engineering;artificial intelligence;operations management;metaheuristic	AI	-0.9911596294687186	2.7935904629078996	167514
80c525654837a143b77ce7d4f43cb471b209e038	emediator: a next generation electronic commerce server	cmu;electronic commerce;nash equilibrium;winner determination;bidding language s;breach;rational agent;user support;contracting;bidding agent s;proxy bidding;design and implementation;next generation;safe exchange;optimal contract;mobile agent;mobile agent s;leveled commitment;combinatorial auction s;combinatorial auction	This paper presents eMediator, an electronic commerce server prototype that demonstrates ways in which algorithmic support and game–theoretic incentive engineering can jointly improve the efficiency of e–commerce. eAuctionHouse, the configurable auction server, includes a variety of generalized combinatorial auctions and exchanges, pricing schemes, bidding languages, mobile agents, and user support for choosing an auction type. We introduce two new logical bidding languages for combinatorial markets: the XOR bidding language and the OR–of–XORs bidding language. Unlike the traditional OR bidding language, these are fully expressive. They therefore enable the use of the Clarke–Groves pricing mechanism for motivating the bidders to bid truthfully. eAuctionHouse also supports supply/demand curve bidding. eCommitter, the leveled commitment contract optimizer, determines the optimal contract price and decommitting penalties for a variety of leveled commitment contracting mechanisms, taking into account that rational agents will decommit strategically in Nash equilibrium. It also determines the optimal decommitting strategies for any given leveled commitment contract. eExchangeHouse, the safe exchange planner, enables unenforced anonymous exchanges by dividing the exchange into chunks and sequencing those chunks to be delivered safely in alternation between the buyer and the seller.	e-commerce	Tuomas Sandholm	2002	Computational Intelligence	10.1111/1467-8640.t01-1-00209	e-commerce;rational agent;combinatorial auction;real-time bidding;computer science;proxy bid;mobile agent;ebidding;nash equilibrium	AI	-2.338582536463573	-2.5840908206206596	167882
bcb239973c7b50c7bea94cacae8e6cada07f148f	analysis of distribution locational marginal prices	reactive power pricing biological system modeling real time systems electricity supply industry generators voltage measurement	Low-voltage distribution networks are emerging as an increasingly important component of power system operations due to the deployment of distributed renewable resources (e.g., rooftop solar supply) and the need to mobilize the flexibility of consumers that are connected to the low-voltage grid. The pricing of electric power at distribution nodes follows directly from the theory of spot pricing of electricity. However, in contrast to linearized lossless models of transmission networks, an intuitive understanding of prices at the distribution level presents challenges due to voltage limits, reactive power flows, and losses. In this paper, we present three approaches toward understanding distribution locational marginal prices by decomposing them: 1) through a duality analysis of the problem formulated with a global power balance constraint; 2) through a duality analysis of a second-order cone program relaxation; and 3) through an analysis of the impact of marginal losses on price. We discuss the relative strengths and weaknesses of each approach in terms of computation and physical intuition, and demonstrate the concepts on a 15-bus radial distribution network.	apple a4;apple a5;computation;conductance (graph);dsos;dadda multiplier;gnutella2;interaction;karush–kuhn–tucker conditions;lagrange multiplier;lagrangian relaxation;linear programming relaxation;lossless compression;marginal model;news aggregator;numerical analysis;numerical error;radial (radio);sap netweaver process integration;second-order cone programming;software deployment	Anthony Papavasiliou	2018	IEEE Transactions on Smart Grid	10.1109/TSG.2017.2673860	financial economics;economics;computer science;stand-alone power system;microeconomics;market economy	Metrics	2.552363574774527	2.883914697336017	168327
c9b1ffe6c0b7aa5e22f59631798a42861e1cee20	automatic generation control and its implementation in real time	silicon;power generation control;generators;frequency control;system dynamics;optimal power flow;barium;power systems;automatic generation control generators barium economics silicon frequency control power systems;area control error;automatic generation control allocation;automatic generation control;automatic generation control allocation automatic generation control area control error optimal power flow system dynamics;economics;optimal power flow automatic generation control power allocation generator agc service quality agc service cost economic dispatch process ramping constraint wecc system;power generation dispatch;power generation economics electric generators power generation control power generation dispatch;electric generators;power generation economics	In power systems, the control mechanism responsible for maintaining the system frequency to the nominal value and the real power interchange between balancing authority areas to the scheduled values is referred to as automatic generation control (AGC). The purpose of this paper is to present a systematic way to determine, in real time, the power allocated to each generator participating in AGC by taking into account the cost and quality of the AGC service provided. To this end, we formulate the economic dispatch process and gain insights into the economic characteristics of the generating units. We value the quality of AGC service by taking into consideration the ramping constraints of the generating units. The proposed methodology is illustrated in the WECC system and is compared with other allocation methods.		Dimitra Apostolopoulou;Peter W. Sauer;Alejandro D. Domínguez-García	2014	2014 47th Hawaii International Conference on System Sciences	10.1109/HICSS.2014.307	operations management;automatic frequency control;barium;system dynamics;electric power system;silicon;electric generator	Robotics	2.2529919562697853	4.100641900314904	168659
2ae90c1f560b91c495ddfe85ef3659d33d274ee2	atomic congestion games among coalitions	algorithmic game theory;nash equilibrium;user participation;price of anarchy;convergence to equilibria;nash equilibria;atomic congestion games;potential function;congestion game;congestion games	We consider algorithmic questions concerning the existence, tractability, and quality of Nash equilibria, in atomic congestion games among users participating in selfish coalitions.  We introduce a coalitional congestion model among atomic players and demonstrate many interesting similarities with the noncooperative case. For example, there exists a potential function proving the existence of pure Nash equilibria (PNE) in the unrelated parallel links setting; in the network setting, the finite improvement property collapses as soon as we depart from linear delays, but there is an exact potential (and thus PNE) for linear delays. The price of anarchy on identical parallel links demonstrates a quite surprising threshold behavior: It persists on being asymptotically equal to that in the case of the noncooperative KP-model, unless the number of coalitions is sublogarithmic.  We also show crucial differences, mainly concerning the hardness of algorithmic problems that are solved efficiently in the noncooperative case. Although we demonstrate convergence to robust PNE, we also prove the hardness of computing them. On the other hand, we propose a generalized fully mixed Nash equilibrium that can be efficiently constructed in most cases. Finally, we propose a natural improvement policy and prove its convergence in pseudopolynomial time to PNE which are robust against (even dynamically forming) coalitions of small size.	anarchy;nash equilibrium;network congestion;pixel;pseudo-polynomial time;robustness (computer science)	Dimitris Fotakis;Spyros C. Kontogiannis;Paul G. Spirakis	2006	ACM Trans. Algorithms	10.1145/1383369.1383383	price of stability;mathematical optimization;simulation;best response;mathematical economics;nash equilibrium	ECom	-3.6378755026224554	0.6271917970114087	168999
93cb3e5e38713f2fecaa8158a442f53e58b0b27a	tugatac broker: a fuzzy logic adaptive reasoning agent for energy trading	artigo em livro de atas de conferencia internacional	Smart Grid technologies are changing the way energy is generated, distributed and consumed. With the increasing spread of renewable power sources, new market strategies are needed to guarantee a more sustainable participation and less dependency of bulk generation. In PowerTAC (Power Trading Agent Competition), different software agents compete in a simulated energy market, impersonating broker companies to create and manage attractive tariffs for customers while aiming to profit. In this paper, we present TugaTAC Broker, a PowerTAC agent that uses a fuzzy logic mechanism to compose tariffs based on its customers portfolio. Fuzzy sets allow adaptive configurations for brokers in different scenarios. To validate and compare the performance of TugaTAC, we have run a local version of the PowerTAC competition. The experiments comprise TugaTAC competing against other simple agents and a more realistic configuration, with instances of the winners of previous editions of the competition. Preliminary results show a promising dynamic: our approach was able to manage imbalances and win the competition in the simple case, but need refinements to compete with more sophisticated market.	experiment;fuzzy concept;fuzzy control system;fuzzy logic;message broker;simulation;software agent	Thiago R. P. M. Rúbio;Jonas Queiroz;Henrique Lopes Cardoso;Ana Paula Rocha;Eugénio C. Oliveira	2015		10.1007/978-3-319-33509-4_16	knowledge management;artificial intelligence;data mining;business	AI	0.5233596005035664	3.5412233786181155	170006
784e368624b82f3df8e3c434c298b8a300977e24	growth-optimal portfolio selection under cvar constraints		Online portfolio selection research has so far focused mainly on minimizing regret defined in terms of wealth growth. Practical financial decision making, however, is deeply concerned with both wealth and risk. We consider online learning of portfolios of stocks whose prices are governed by arbitrary (unknown) stationary and ergodic processes, where the goal is to maximize wealth while keeping the conditional value at risk (CVaR) below a desired threshold. We characterize the asymptomatically optimal risk-adjusted performance and present an investment strategy whose portfolios are guaranteed to achieve the asymptotic optimal solution while fulfilling the desired risk constraint. We also numerically demonstrate and validate the viability of our method on standard datasets.	cvar;ergodicity;numerical analysis;regret (decision theory);stationary process;value at risk	Guy Uziel;Ran El-Yaniv	2018			financial economics;actuarial science;economics;welfare economics	ML	1.8632830013585349	-2.380602239903433	170190
b73a6e0c40d86b9be3dbb9382a286168e50ccc6a	strategic stability in linear-quadratic differential games with nontransferable payoffs		We address the problem of strategically supported cooperation for linear-quadratic differential games with nontransferable payoffs. As an optimality principle, we study Pareto-optimal solutions. It is assumed that players use a payoff distribution procedure guaranteeing individual rationality of a cooperative solution over the entire game horizon. We prove that under these conditions a Pareto-optimal solution can be strategically supported by an e-Nash equilibrium. An example is considered.		Anna V. Tur	2017	Automation and Remote Control	10.1134/S0005117917020151	mathematical optimization;mathematical economics	EDA	-0.1957748389529517	-1.6409847999563631	170790
e8421ed88a39ac2e6de49a16a272544e487ba10d	mean-field interactions among robust dynamic coalitional games with transferable utilities	stochastic stability theory mean field interactions robust dynamic coalitional games transferable utilities homogeneous small worlds homogeneous games continuous time stochastic process dynamic tu game network control problem allocation rules inequity aversion;network flow mean field games consensus multiagent systems;stochastic processes continuous time systems game theory small world networks;games equations robustness resource management sociology statistics stochastic processes	This paper considers a large number of homogeneous “small worlds” or games. Each small world involves a set of players and a corresponding set of possible coalitions, and is modeled as a dynamic game with transferable utilities (TU), where the characteristic function is a continuous-time stochastic process. Considering that a dynamic TU game can be modeled as a network control problem, the overall system appears as an assembly of a large number of networks subject to mean-field interactions. As a result of such mean-field interactions among small worlds, in each game, a central planner allocates revenues based on the extra reward that a coalition has received up to the current time and the extra reward that the same coalition has received in the other games. We obtain allocation rules that make the grand coalition stable in each game, while guaranteeing consensus on the excesses, in the spirit of inequity aversion. Convergences of allocations and excesses are established via stochastic stability theory.	characteristic function (convex analysis);decibel;interaction;risk aversion;stochastic process	Dario Bauso;Tamer Basar	2014	2014 6th International Symposium on Communications, Control and Signal Processing (ISCCSP)	10.1109/ISCCSP.2014.6877919	combinatorial game theory;game theory;example of a game without a value;simulation;economics;repeated game;mathematical economics;sequential game;welfare economics	ECom	-3.846937185744579	-1.308054236159147	171080
96f1a170666629dee84b09c0e6142880d37a40e1	multistage investments with recourse: a single-asset case with transaction costs	dynamic investment decisions;semidefinite programs multistage investments single asset case transaction costs financial decision problem dynamic investment decisions discrete time periods investment returns stochastic multistage optimization problem second order cone;optimisation;investments;instruments;investment decision;transaction cost;semidefinite programs;discrete time systems;discrete time;investment;upper bound;decision problem;symmetric matrices;optimization problem;multistage investments;second order cone;stochastic processes;single asset case;investment returns;discrete time periods;stochastic multistage optimization problem;transaction costs;profitability;approximation methods;stochastic processes discrete time systems investment optimisation;proportional transaction costs;financial decision problem;investments stochastic processes instruments electronic mail cost function random variables mechanical engineering automatic programming functional programming portfolios;programming;semidefinite program	We consider a financial decision problem involving dynamic investment decisions on a single risky instrument over multiple and discrete time periods. Investment returns are assumed stochastic and possibly dependent over time, and proportional transaction costs are considered in the model. In this setting, the investor¿s goal is to determine investment policies that maximize the net profit while maintaining the associated risk under control. We propose approximations of the ensuing stochastic multistage optimization problem that are based on affine recourse strategies and that lead to efficiently solvable second order cone or semidefinite programs.	approximation;decision problem;mathematical optimization;multistage amplifier;optimization problem;semidefinite programming;stochastic process	Ufuk Topcu;Giuseppe Carlo Calafiore;Laurent El Ghaoui	2008	2008 47th IEEE Conference on Decision and Control	10.1109/CDC.2008.4738700	stochastic process;mathematical optimization;transaction cost;investment;mathematics	ML	1.9804377529332755	-1.1677818165988838	171188
063b703b93d65dd084001da3c6c9337c125174c5	relative kw response to residential time-varying pricing in british columbia	space heating load regulation power markets pricing regression analysis;pricing;pricing load flow control shape water heating space heating schedules rivers;power markets;space heating;load regulation;electricity market residential time varying pricing british columbia graphical exploration regression analysis bc hydro residential customer relative kw response tou pricing yields statistically significant evening peak customer location customer size remotely activated load control water heaters space heaters demand response strategy winter peaking utilities;regression analysis;power demand energy management load management	We apply graphical exploration and regression analysis to estimate 1717 participants' relative kW responses in BC Hydro's residential TOU/CPP pilot study. We define a customer's relative kW response as the percentage change in the customer's hourly kW demand due to exposure to time-varying pricing. Compared to the control group of customers facing non-TOU rates, we find that TOU pricing yields a statistically-significant evening peak kW decrease of 4-11%, after controlling for the effects of day of the week, month of the year, weather, customer location, and customer size. CPP produces an additional peak kW reduction of about 9%, which can be further increased to about 33% through remotely-activated load control of space and water heaters. Hence, a scheme of TOU pricing augmented with CPP and load control on system peak days can be a highly effective demand-response strategy for winter-peaking utilities.	columbia (supercomputer);consistent pricing process;graphical user interface;load management;load profile;relative change and difference;terms of service	Chi-Keung Woo;Ira Horowitz;Iris M. Sulyma	2013	IEEE Transactions on Smart Grid	10.1109/TSG.2013.2256940	pricing;economics;marketing;operations management;microeconomics;regression analysis	Metrics	1.9605482542946435	2.007560751826625	171351
7e4237ec69e8494098f98c254bfdb13a3ac36d7d	risk management for e-cash systems with partial real-time audit	economie;anonymity;economia;theoretical model;analisis sistema;real time;gestion risque;risk management;false alarm rate;audit randomise;balance wallet;e cash;anonymat;upper bound;modele theorique;criptografia;cryptography;temps reel;randomized audit;system analysis;tiempo real;cryptographie;analyse systeme;economy;false alarm probability;borne superieure;coin wallet;modelo teorico;cota superior;anonimato	We analyze “coin-wallet” and “balance-wallet” under partial real-time audit, and compute upper bounds on theft due to the fact that not all the transactions are audited in real time, assuming that everything else is perfect. In particular, we assume that the audit regime holds for innocent payees. Let v be the maximum allowed balance in a wallet, and 0 μ 1 be the fraction of transactions that are audited in real time in an audit round. Assume one unit transactions. We show that the upper bound on expected theft for coin-wallet is limμ→0 μ−2, while for plausible (similar) parameter choice the bound for a balance-wallet is O(exp(mvμ)), where 1 < m. The former is nicely bounded for small transactions, however, the bound for balance-wallet can become huge in those cases where we require very small false alarm probability. We conclude that partial audit, may be suitable for coin-wallets with low denomination coins, and possibly for balance-wallet, when we may tolerate a relatively high false alarm rate, but it may be too risky for balance-wallet, where very low false alarm rate is required.	real-time clock;real-time transcription;risk management	Yacov Yacobi	1999		10.1007/3-540-48390-X_5	anonymity;risk management;computer science;cryptography;artificial intelligence;system analysis;computer security;algorithm	Theory	-3.3262092786818873	-0.021864994810259247	171886
dea888f61ff25c38829746f38836e8f5c189999b	asymptotic convergence of optimal policies for resource management with application to harvesting of multiple species forest	lyapunov stability;intertemporal resource allocation;resource allocation;resource manager;discrete time;optimal policy;optimal control;turnpike property;fish farming;infinite horizon;existence and uniqueness;forest management	We study the long-term behavior of the optimal harvesting policies for a mixed forest composed by multiple species of different maturity ages. This model is a prototype for the exploitation of a finite resource such as land or space, which can be allocated to different activities that produce their revenue after certain delays at which the resource is liberated for reuse. We prove the existence and uniqueness of a sustainable state, and we discuss the conditions under which an optimal trajectory converges in the long run toward this state or toward the set of optimal periodic cycles. We also analyze different situations in which the convergence occurs in finite time.	asymptote;attack tree;capability maturity model;computer;converge;greedy algorithm;initial condition;land;lyapunov fractal;mathematical optimization;optimization problem;prototype;random forest	Roberto Cominetti;Adriana Piazza	2009	Math. Oper. Res.	10.1287/moor.1090.0384	fish farming;mathematical optimization;discrete time and continuous time;forest management;optimal control;resource allocation;resource management;mathematics	AI	1.1146617716454514	-1.2667105129949017	171939
b555132911d6ed157067f457b80c6b32d1e4ca96	a mechanism for cooperative demand-side management		Demand-side management (DSM) is an important theme in studies of the Smart Grid and offers the possibility of leveling power consumption with its attendant benefits of reducing capital expenses. This paper develops an algorithmic mechanism that reduces peak total power consumption and encourages prosocial behavior, such as expressing flexibility in one's power consumption and reporting preferences truthfully. The objective is to provide a tractable, budget-balanced mechanism that promotes truth-telling from households. The resulting mechanism is theoretically and empirically proven to be ex ante budget-balanced, weakly Pareto-efficient, and weakly Bayesian incentive-compatible. A simulation study verifies that the mechanism could largely reduce the computational complexity that the optimal allocation requires, while maintaining approximately the same performance. A user study with 20 subjects further shows the effectiveness of the mechanism in preventing participants from defecting and incentivizing them to reveal flexible preferences.	aggregate data;algorithm;cobham's thesis;computation;computational complexity theory;hierarchical and recursive queries in sql;mathematical optimization;pareto efficiency;simulation;time complexity;usability testing	Guangchao Yuan;Chung-Wei Hang;Michael N. Huhns;Munindar P. Singh	2017	2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)	10.1109/ICDCS.2017.300	prosocial behavior;computer science;resource management;distributed computing;cost accounting;smart grid;capital expenditure;computational complexity theory;microeconomics;computer security	Robotics	1.1079696855121028	2.364242914080909	172430
2f4e49a7fdeb703b3e49816444c7a3b66847a1d8	on the existence of nash equilibria in power based flow control for virtual circuits in networks	nash equilibria;virtual circuit;flow control		flow control (data);nash equilibrium;virtual circuit	Ping-Tsai Chung;Richard M. Van Slyke	2004			computer vision;mathematical optimization;artificial intelligence;computer science;mathematical economics;nash equilibrium;flow control (data);virtual circuit	EDA	-4.425563035362594	2.0424570086672773	173276
21ac03d4698a8c8dc899372e87d6126dc2edf958	game of power allocation on networks: balancing equilibrium		This paper defines and studies a special kind of equilibrium termed as “balancing equilibrium” which arises in the power allocation game in [14]. The equilibrium has both unique mathematical property and realistic implications. In the equilibrium, all countries in antagonism have to use all of their own power to counteract the received threats, and the threat made to each adversary only equalizes the threat received from that adversary. This paper establishes necessary and sufficient conditions for countries’ power in order for this equilibrium to exist in different types of networked international environments. It also links the existence of this equilibrium in PAGs on structurally balanced graphs to the Hall’s Maximum Matching problem and the Max Flow problem.	adversary (cryptography);expect;matching (graph theory);maximum flow problem;nash equilibrium	Yuke Li;A. Stephen Morse	2018	CoRR		mathematical economics;mathematical optimization;mathematics;maximum flow problem;adversary;matching (graph theory);graph	ECom	-3.920343685651396	0.9762862887498727	173487
0eaff87c251f689de9df99364c10dee24a3c9232	fairly allocating many goods with few queries		We investigate the query complexity of the fair allocation of indivisible goods. For two agents with arbitrary monotonic valuations, we design an algorithm that computes an allocation satisfying envy-freeness up to one good (EF1), a relaxation of envy-freeness, using a logarithmic number of queries. We show that the logarithmic query complexity bound also holds for three agents with additive valuations. These results suggest that it is possible to fairly allocate goods in practice even when the number of goods is extremely large. By contrast, we prove that computing an allocation satisfying envyfreeness and another of its relaxations, envy-freeness up to any good (EFX), requires a linear number of queries even when there are only two agents with identical additive valua-	algorithm;decision tree model;efx factory;linear programming relaxation;utility functions on indivisible goods	Hoon Oh;Ariel D. Procaccia;Warut Suksompong	2018	CoRR		mathematics;mathematical optimization;valuation (finance);logarithm;monotonic function	ECom	-2.7235656488817064	-0.42420398150107097	173782
70ae92272a2fe6d87480d3d601be72c27f483f80	methods for task allocation via agent coalition formation	approximate algorithm;multi agent cooperation;satisfiability;coalition formation;np hard problem;autonomous agent;computational complexity;agent systems;distributed algorithm;task allocation	Task execution in multi-agent environments may require cooperation among agents. Given a set of agents and a set of tasks which they have to satisfy, we consider situations where each task should be attached to a group of agents that will perform the task. Task allocation to groups of agents is necessary when tasks cannot be performed by a single agent. However it may also be beneficial when groups perform more efficiently with respect to the single agents’ performance. In this paper we present several solutions to the problem of task allocation among autonomous agents, and suggest that the agents form coalitions in order to perform tasks or improve the efficiency of their performance. We present efficient distributed algorithms with low ratio bounds and with low computational complexities. These properties are proven theoretically and supported by simulations and an implementation in an agent system. Our methods are based on both the algorithmic aspects of combinatorics and approximation algorithms for NP-hard problems. We first present an approach to agent coalition formation where each agent must be a member of only one coalition. Next, we present the domain of overlapping coalitions. We proceed with a discussion of the domain where tasks may have a precedence order. Finally, we discuss the case of implementation in an open, dynamic agent system. For each case we provide an algorithm that will lead agents to the formation of coalitions, where each coalition is assigned a task. Our algorithms are any-time algorithms, they are simple, efficient and easy to implement.  1998 Published by Elsevier Science B.V. All rights reserved.	analysis of algorithms;approximation algorithm;autonomous agent;autonomous robot;computation;distributed algorithm;multi-agent system;np-hardness;serializability;simulation	Onn Shehory;Sarit Kraus	1998	Artif. Intell.	10.1016/S0004-3702(98)00045-9	distributed algorithm;simulation;computer science;artificial intelligence;autonomous agent;np-hard;distributed computing;computational complexity theory;algorithm;satisfiability	AI	-1.5760246999410763	3.1497107446860126	174014
fd58880ab97c6cf1fc985317a668793a74799565	valuation of european continuous-installment options	linear complementarity;partial differential equation;optimal stopping problem;closed form solution;free boundary problem;option pricing;installment option;finite difference scheme;optimal stopping;monte carlo;integral representation;integral representation method	This paper is concerned with the valuation of European continuous-installment options where the aim is to determine the initial premium given a constant installment payment plan. The distinctive feature of this pricing problem is the determination, along with the initial premium, of an optimal stopping boundary since the option holder has the right to stop making installment payments at any time before maturity. Given that the initial premium function of this option is governed by an inhomogeneous Black-Scholes partial differential equation, we can obtain two alternative characterizations of the European continuous-installment option pricing problem, for which no closed-form solution is available. First, we formulate the pricing problem as a free boundary problem and using the integral representation method, we derive integral expressions for both the initial premium and the optimal stopping boundary. Next, we use the linear complementarity formulation of the pricing problem for determining the initial premium and the early stopping curve implicitly with a finite difference scheme. Finally, the pricing problem is posed as an optimal stopping problem and then implemented by a Monte Carlo approach.	value (ethics)	Pierangelo Ciurlia	2011	Computers & Mathematics with Applications	10.1016/j.camwa.2011.04.073	mathematical optimization;optimal stopping;mathematics;finite difference methods for option pricing;mathematical economics;statistics	Theory	1.6782074756336967	-2.425668680663053	174467
3e1a2abe68ad39511e1c7670ba500e0f8b9f47bf	learning dynamics in stochastic routing games		We consider a repeated nonatomic network routing game where a large number of risk-neutral users are unsure about the edge latency functions and learn about them using past travel experience. We assume that the network has affine stochastic edge latency functions with unknown slope. We consider a simple process of learning where agents share common observations of travel times, estimate the unknown edge slope parameters via ordinary least squares and, at every step, dispatch their traffic demand over the network according to the Wardrop equilibrium computed using mean latency functions with most recent estimates. We prove that under this learning dynamics, the flow vector in the network converges almost surely to the full information Wardrop equilibrium. Moreover, the slope parameters of all the edges used in the full information Wardrop equilibrium are learned almost surely in the limit.	coefficient;dynamic dispatch;nash equilibrium;network congestion;ordinary least squares;routing	Emily Meigs;Francesca Parise;Asuman E. Ozdaglar	2017	2017 55th Annual Allerton Conference on Communication, Control, and Computing (Allerton)	10.1109/ALLERTON.2017.8262746	mathematical optimization;latency (engineering);computer science;ordinary least squares;almost surely;affine transformation	Theory	-2.9861737778538924	2.5884439089454583	174746
91d06638a5bdfb316a1d30023f8c0bde11e4c820	learning on a budget: posted price mechanisms for online procurement	online algorithm;utility function;online learning;secretary problem;online algorithms;mechanism design;budget constraint	We study online procurement markets where agents arrive in a sequential order and a mechanism must make an irrevocable decision whether or not to procure the service as the agent arrives. Our mechanisms are subject to a budget constraint and are designed for stochastic settings in which the bidders are either identically distributed or, more generally, permuted in random order. Thus, the problems we study contribute to the literature on budget-feasible mechanisms as well as the literature on secretary problems and online learning in auctions.  Our main positive results are as follows. We present a constant-competitive posted price mechanism when agents are identically distributed and the buyer has a symmetric submodular utility function. For nonsymmetric submodular utilities, under the random ordering assumption we give a posted price mechanism that is O(log n)-competitive and a truthful mechanism that is O(1)-competitive but uses bidding rather than posted pricing.	e-procurement;online machine learning;procurement;secretary problem;submodular set function;symmetric multiprocessing;utility	Ashwinkumar Badanidiyuru;Robert D. Kleinberg;Yaron Singer	2012		10.1145/2229012.2229026	online algorithm;mathematical optimization;economics;computer science;operations management;microeconomics;mathematical economics;commerce	ECom	-2.6788490618319556	-2.166157346391069	174875
190eeea41fabe81fb4095298eb75e011c93f2ec0	the expected discounted penalty function under a renewal risk model with stochastic income	laplace transform;defective renewal equation;journal;gerber shiu discounted penalty function;stochastic income	In this paper, we consider a renewal risk model with stochastic premiums income. We assume that the premium number process and the claim number process are a Poisson process and a generalized Erlang ( n ) processes, respectively. When the individual stochastic premium sizes are exponentially distributed, the Laplace transform and a defective renewal equation for the Gerber–Shiu discounted penalty function are obtained. Furthermore, the discounted joint distribution of the surplus just before ruin and the deficit at ruin is given. When the claim size distributions belong to the rational family, the explicit expression of the Gerber–Shiu discounted penalty function is derived. Finally, a specific example is provided.	financial risk modeling;penalty method	Yongxia Zhao;Chuancun Yin	2012	Applied Mathematics and Computation	10.1016/j.amc.2011.11.101	mathematical optimization;control theory;mathematics;mathematical economics;laplace transform	AI	2.399123429327872	-2.5384904050355814	175047
29296e7b6643bc0a67b4af276b18b78906b3f847	assortment optimization under the general luce model		This paper studies the assortment optimization problem under the General Luce Model (GLM), a discrete choice introduced by Echenique and Saito (2015) that generalizes the standard multinomial logit model (MNL). The GLM does not satisfy the Independence of Irrelevant Alternatives (IIA) property but it ensures that each product has an intrinsic utility and uses a dominance relation between products. Given a proposed assortment S, consumers first discard all dominated products in S before using a MNL model on the remaining products. The General Luce Model may violate the traditional regularity condition, which states that the probability of choosing a product cannot increase if the offer set is enlarged. As a result, the model can model behaviour that cannot be captured by any discrete choice model based on random utilities. The paper proves that the assortment problem under the GLM is polynomially-solvable. Moreover, it proves that the capacitated assortment optimization problem under the General Luce Model (GLM) is NP-hard and presents polynomial-time algorithms for the cases where (1) the dominance relation is utility-correlated and (2) its transitive reduction is a forest. The proofs exploit a strong connection between assortments under the GLM and independent sets in comparability graphs.	algorithm;approximation algorithm;choice modelling;decision problem;discrete choice;existential quantification;generalized linear model;itakura–saito distance;mathematical optimization;multinomial logistic regression;np-hardness;optimization problem;optimizing compiler;polynomial;relevance;time complexity;transitive reduction;turing reduction	Álvaro Flores;Gerardo Berbeglia;Pascal Van Hentenryck	2017	CoRR		mathematics;transitive reduction;discrete mathematics;mathematical economics;multinomial logistic regression;mathematical proof;independence of irrelevant alternatives;discrete choice;exploit;comparability;optimization problem	Theory	-1.5239173766976484	-1.3527297305840307	177212
88f7b6650a634ec3457d64da68a8475f55992bc5	auctions with online supply	stochastic supply;dynamic mechanism design;approximation;unknown supply;online auctions;dynamic auctions	Online advertising auctions present settings in which there is uncertainty about the number of items for sale. We study mechanisms for selling identical items when the total supply is unknown but is drawn from a known distribution. Items arrive dynamically, and the seller must make immediate allocation and payment decisions with the goal of maximizing social welfare. We devise a simple incentive-compatible mechanism that guarantees some constant fraction of the first-best solution. A surprising feature of our mechanism is that it artificially limits supply, and we show that limiting the supply is essential for obtaining high social welfare. Although common when maximizing revenue, commitment to limit the supply is less intuitive when maximizing social welfare. The performance guarantee of our mechanism is in expectation over the supply distribution; We show that obtaining similar performance guarantee for every realization of supply is impossible.		Moshe Babaioff;Liad Blumrosen;Aaron Roth	2015	Games and Economic Behavior	10.1016/j.geb.2015.01.004	economics;approximation;microeconomics;welfare economics;commerce	ECom	-2.5718754276570617	-2.1184217982929208	177257
aa9ae01ae85fa697c59e09bcfebc47724f65b635	blockchain-based and multi-layered electricity imbalance settlement architecture		In the power grid, the Balance Responsible Parties (BRPs) purchase energy based on a forecast of the user consumption. The forecasts are imperfect, and the corrections of their real-time deviations are managed by a System Operator (SO), which charges the BRPs for the procured imbalances. Flexible consumers, associated with a BRP, can be involved in a demand response (DR) program to reduce the imbalance costs. However, running the DR program requires the BRP to invest resources in the infrastructure and increases its operating costs. To limit the intervention of BRP, we implement the DR via a blockchain smart contract. Moreover, to reduce the delay of publication of the imbalance price, caused by the inefficient accounting process of the current balancing markets, a second blockchain is adopted at the SO layer, procuring a fast and auditable credit settlements. The feasibility of the proposed architecture is evaluated over an Ethereum blockchain platform. The results show that block chains can enable a high automation of the balancing market, by providing (i) the implementation of aggregators with low operating cost and (ii) the timely and transparent access to the balancing information, thus fostering new business models for the BRPs.		Pietro Danzi;Sarah Hambridge;Cedomir Stefanovic;Petar Popovski	2018	2018 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm)	10.1109/SmartGridComm.2018.8587577	automation;real-time computing;architecture;operations management;smart grid;smart contract;demand response;operating cost;computer science;blockchain;business model	EDA	1.026225298099504	3.5343611107531534	177792
acc59e95db640d1f6dd9ec57df1da3ac526d22a7	agent-based modeling of supply chains for distributed scheduling	schedule stability;schedule stability agent based modeling supply chains distributed scheduling project management modified contract net protocol information sharing;project management;agent based;perforation;contract net protocol;agent based model;supply chains production engineering computing project management scheduling software agents stability supply chain management;agent based modeling;indexing terms;supply chains job shop scheduling costs manufacturing production mass customization contracts project management supply chain management demand forecasting;supply chains;production engineering computing;information sharing;stability;software agents;distributed scheduling;supply chain agent based modeling distributed scheduling information sharing project scheduling;scheduling;modified contract net protocol;simulation study;supply chain;project scheduling;manufacturing automation software;article;supply chain management	This paper considers a supply chain that comprises multiple independent and autonomous enterprises (project managers) that seek and select various contractors to complete operations of their project. Both the project managers and contractors jointly determine the schedules of their operations while no single enterprise has complete information of other enterprises. The centralized scheduling approach that can usually obtain good global performance but must share nearly complete information that is difficult or even impractical due to the distributed nature of real-life supply chains. This paper proposes an agent-based supply chain model to support distributed scheduling. A modified contract-net protocol (MCNP) is proposed to enable more information sharing among the enterprises than conventional CNP. Experimental simulation studies are conducted to compare and contrast the performances of the centralized [centralized heuristic (CTR)], conventional CNP, and MNCP approaches. The results show that MCNP outperforms CNP and performs comparably with CTR when project complexity is high in terms of the total supply chain operating cost. Moreover, it is found that although CTR is better than MCNP in terms of global performance, MCNP yields good schedule stability when facing unexpected disturbances	agent-based model;autonomous robot;centralized computing;computation;concurrency (computer science);contract net protocol;distributed algorithm;experiment;global serializability;heuristic;information model;information privacy;mcnp;mathematical model;performance;real life;requirement;schedule (project management);scheduling (computing);simulation;slack variable;yamaha ymf292	J. S. K. Lau;George Q. Huang;Kai-Ling Mak;L. Liang	2006	IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans	10.1109/TSMCA.2005.854231	project management;real-time computing;supply chain management;computer science;supply chain	Robotics	-0.32477686434425773	2.335246673625593	177910
ff35fd20b76a38bd1d412546ad8e7838ffc5e347	simple primal-dual auctions are not possible	gross substitutes;primal dual auctions;vickrey clarke groves;satisfiability;universal competitive equilibrium;competitive equilibrium;vcg mechanism	de Vries et al. [3] show that if valuation function of each buyer satisfies gross substitutes condition, then we can design primal-dual auctions that implement the Vickrey-Clarke-Groves (VCG) outcome. But they require prices in these auctions to be non-linear and non-anonymous. In this note, we show that such a requirement is necessary. This means, if valuation function of each buyer satisfies gross substitutes, then there does not exist a primal-dual auction which will always converge to the VCG outcome if prices in the auction are (i) linear and non-anonymous, OR (ii) non-linear and anonymous.	converge;edmund m. clarke;nonlinear system;requirement;value (ethics)	Debasis Mishra	2004		10.1145/988772.988818	economics;vickrey–clarke–groves auction;common value auction;mathematics;microeconomics;mathematical economics;welfare economics;satisfiability	ECom	-3.7537774903435452	-1.9331984407568654	178205
2e952eecb994995e2987fc76d58d4ae6ee0b97fd	generalized colonel blotto game		Competitive resource allocation between adversarial decision makers arises in a wide spectrum of realworld applications such as in communication systems, cyber-physical systems security, as well as financial and political competition. Hence, developing analytical tools to model and analyze competitive resource allocation is crucial for devising optimal allocation strategies and anticipating the potential outcomes of the competition. To this end, the Colonel Blotto game is one of the most popular game-theoretic frameworks for modeling and analyzing such competitive resource allocation problems. However, in many practical competitive situations, the Colonel Blotto game does not admit solutions in deterministic strategies and, hence, one must rely on analytically complex mixed-strategies with their associated tractability, applicability, and practicality challenges. In this regard, in this paper, a generalization of the Colonel Blotto game which enables the derivation of deterministic, practical, and implementable equilibrium strategies is proposed while accounting for scenarios with heterogeneous battlefields. In addition, the proposed generalized game factors in the consumed/destroyed resources in each battlefield, a feature that is not considered in the classical Blotto game. For this generalized game, the existence of a Nash equilibrium in pure strategies is shown. Then, closed-form analytical expressions of the equilibrium strategies are derived and the outcome of the game is characterized, based on the number of each player's resources and each battlefield's valuation. The generated results provide invaluable insights on the outcome of the competition. For example, the results show that, when both players are fully rational, the more resourceful player can achieve a better total payoff at the Nash equilibrium, a result that is not mimicked in the classical Blotto game.	approximation;cyber-physical system;game theory;generalized game;mathematical optimization;nash equilibrium;numerical analysis;rendering (computer graphics);value (ethics)	Aidin Ferdowsi;Anibal Sanjab;Walid Saad;Tamer Basar	2018	2018 Annual American Control Conference (ACC)	10.23919/ACC.2018.8431701	mathematics;mathematical economics;resource management;cost accounting;generalized game;valuation (finance);nash equilibrium;expression (mathematics);resource allocation;stochastic game	AI	-0.6684485025354305	-0.06508767191277211	178479
b1e6db204b6ae5da6bee210d103571c5a27f51c3	fragility of arbitrage and bubbles in local martingale diffusion models	arbitrage;bubbles;local martingales;91g10;qa mathematics matematika;transaction costs;62p05	For any positive diffusion with minimal regularity, there exists a semimartingale with uniformly close paths that is a martingale under an equivalent probability. As a result, in models of asset prices based on such diffusions, arbitrage and bubbles alike disappear under proportional transaction costs or under small model mis-specifications. Thus, local martingale diffusion models of arbitrage and bubbles are not robust to small trading and monitoring frictions. Copyright Springer-Verlag Berlin Heidelberg 2015		Paolo Guasoni;Miklós Rásonyi	2015	Finance and Stochastics	10.1007/s00780-015-0256-0	financial economics;transaction cost;fundamental theorem of asset pricing;actuarial science;economics;finance;microeconomics;local martingale;arbitrage	ML	0.7041056356384352	-2.369276535764418	178946
076d21c8b0a7b66ca7a68ade11c93db4c01b0d4e	combinatorial auctions and knapsack problems	multi agent system;time measurement;e commerce;dynamic programming algorithm;agents and complex systems;size measurement;operations research;knapsack problem;permission;synthetic agents human like;heuristic algorithms;taxonomy containers permission laboratories multiagent systems operations research heuristic algorithms size measurement time measurement content addressable storage;taxonomy;multi agent simulation and modeling;winner determination problem;content addressable storage;lifelike and believable qualities;containers;multiagent systems;combinatorial auction	This note summarizes the connection between winner determination problems (WDPs) in multi-unit combinatorial exchanges and generalized knapsack problems (KPs); see [2] for an extensive treatment. Taxonomies of sealed-bid auction WDPs and of KPs align precisely, i.e., the two classes of problems are identical. The relationship between KPs and WDPs has received remarkably little attention in E-commerce and multi-agent systems literature. However the WDP-KP connection is important because it allows us to leverage a vast body of Operations Research literature for developing and benchmarking WDP solvers. For low-dimensional multi-unit CA WDPs (i.e., few types of goods), extremely simple dynamic-programming algorithms are available whose time and memory requirements are linear (in the pseudo-polynomial sense) in three out of four natural measures of problem size.	algorithm;align (company);analysis of algorithms;dynamic programming;e-commerce payment system;knapsack problem;multi-agent system;operations research;pixel;polynomial;requirement	Terence Kelly	2004	Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems, 2004. AAMAS 2004.	10.1109/AAMAS.2004.84	simulation;combinatorial auction;computer science;artificial intelligence;theoretical computer science;dynamic programming;multi-agent system;knapsack problem;time	AI	-2.0683824003089373	-0.1739971087887257	180113
825a914167c5c1f20854aa830944225610240e79	regret based dynamics: convergence in weakly acyclic games	learning algorithms;almost sure convergence;learning algorithm;game theory;multi agent system;nash equilibrium;operant conditioning;large scale;emergent behavior;decision process;cooperative distributed problem solving;multiagent learning	"""No-regret algorithms have been proposed to control a wide variety of multi-agent systems. The appeal of no-regret algorithms is that they are easily implementable in large scale multi-agent systems because players make decisions using only retrospective or """"regret based"""" information. Furthermore, there are existing results proving that the collective behavior will asymptotically converge to a set of points of """"no-regret"""" in any game. We illustrate, through a simple example, that no-regret points need not reflect desirable operating conditions for a multi-agent system. Multi-agent systems often exhibit an additional structure (i.e. being """"weakly acyclic"""") that has not been exploited in the context of no-regret algorithms. In this paper, we introduce a modification of the traditional no-regret algorithms by (i) exponentially discounting the memory and (ii) bringing in a notion of inertia in players' decision process. We show how these modifications can lead to an entire class of regret based algorithms that provide almost sure convergence to a pure Nash equilibrium in any weakly acyclic game."""	algorithm;converge;directed acyclic graph;multi-agent system;nash equilibrium;regret (decision theory)	Jason R. Marden;Gürdal Arslan;Jeff S. Shamma	2007		10.1145/1329125.1329175	game theory;mathematical optimization;convergence of random variables;computer science;artificial intelligence;machine learning;operant conditioning;multi-agent system;nash equilibrium;emergence	ML	-3.111810733267385	0.8982255500677491	180337
94788cd1bda08dcef0f51c5dc91b2e689c768e56	auctioning time: truthful auctions of heterogeneous divisible goods	resource allocation;cake cutting;auctions	We consider the problem of auctioning time - a one-dimensional continuously-divisible heterogeneous good - among multiple agents. Applications include auctioning time for using a shared device, auctioning TV commercial slots, and more. Different agents may have different valuations for the different possible intervals; the goal is to maximize the aggregate utility. Agents are self-interested and may misrepresent their true valuation functions if this benefits them. Thus, we seek auctions that are truthful. Considering the case that each agent may obtain a single interval, the challenge is twofold, as we need to determine both where to slice the interval, and who gets what slice. We consider two settings: discrete and continuous. In the discrete setting, we are given a sequence of m indivisible elements (e1, …, em), and the auction must allocate each agent a consecutive subsequence of the elements. In the continuous setting, we are given a continuous, infinitely divisible interval, and the auction must allocate each agent a subinterval. The agents’ valuations are nonatomic measures on the interval. We show that, for both settings, the associated computational problem is NP-complete even under very restrictive assumptions. Hence, we provide approximation algorithms. For the discrete case, we provide a truthful auctioning mechanism that approximates the optimal welfare to within a log m factor. The mechanism works for arbitrary monotone valuations. For the continuous setting, we provide a truthful auctioning mechanism that approximates the optimal welfare to within an O(log n) factor (where n is the number of agents). Additionally, we provide a truthful 2-approximation mechanism for the case that all pieces must be of some fixed size.	aggregate data;aggregate function;approximation algorithm;bounds checking;computation;computational problem;graph coloring;infinite divisibility;linear programming relaxation;mathematical optimization;np-completeness;p versus np problem;polynomial-time approximation scheme;truthful job scheduling;utility functions on indivisible goods;value (ethics);monotone	Yonatan Aumann;Yair Dombb;Avinatan Hassidim	2015	ACM Trans. Economics and Comput.	10.1145/2833086	economics;resource allocation;microeconomics;mathematical economics;welfare economics	ECom	-2.4161931297675907	-0.2673703546411874	180734
cf20db5800826216bbc547293589168b605226ce	non-zero-sum reinsurance games subject to ambiguous correlations	nash equilibrium;g;journal article;non zero sum stochastic differential game;ambiguous correlation;hamiltonian jacobi bellman isaacs equation;reinsurance	This paper studies the economic implications of ambiguous correlation in a non-zero-sum game between two insurers. We establish the general framework of Nash equilibrium for the coupled optimization problems. For the constant absolute risk aversion (CARA) insurers, we show that the equilibrium reinsurance strategies admit closed-form solutions. Our results indicate that the ambiguous correlation leads to an increase in the equilibrium demand of reinsurance protection for both insurers. Numerical studies examine the effect on the quality of the correlation estimations.	ambiguous grammar;brownian motion;comment (computer programming);dynamic programming;exponential utility;financial times;holographic principle;john d. wiley;mathematical optimization;mathematics of operations research;nash equilibrium;optimal control;p (complexity);recursion (computer science);risk aversion;satellite data unit;volatility;yang	Chi Seng Pun;Chi Chung Siu;Hoi Ying Wong	2016	Oper. Res. Lett.	10.1016/j.orl.2016.06.004	mathematical optimization;reinsurance;haplogroup g-m201;mathematical economics;nash equilibrium	ECom	1.1247362849530236	-2.21417356258849	180949
1ba428ba1566118e7e5407563e349ac208e92e82	a lagrange multiplier method for certain constrained min-max problems	deployment;game theory;lagrange multiplier method;military strategy;steepest descent method;minimax technique;convex sets;fallout shelters;survival general	Constrained min-max problems are constant-sum, two-person games in which the maximizing player enjoys the advantage of moving last and both players select allocations subject to separate constraints on their use of resources. This paper presents a Lagrange multiplier method for addressing such problems where the maximizing player is permitted to mix strategies probabilistically. We derive conditions under which the method will locate optimal solutions and discuss suitable applications. A simple ABM/shelter deployment problem is solved to illustrate the essential features of the method.	lagrange multiplier	Edward S. Pearsall	1976	Operations Research	10.1287/opre.24.1.70	game theory;mathematical optimization;simulation;military strategy;economics;method of steepest descent;mathematics;mathematical economics;lagrange multiplier;management;software deployment	Crypto	0.08199607591108224	-1.3190863732839035	180996
75ec50c0237701e72b4a41a843c027fccc051b05	cost-sharing mechanisms for selfish bin packing		The selfish bin packing problem (SBP) considers the classical bin packing problem in a game-theoretic setting where each item is controlled by a selfish agent. It is well-known that the classical bin packing problem admits an asymptotic fully polynomial-time approximation scheme (AFPTAS). However, all previously-studied cost-sharing mechanisms for the selfish bin packing problem (SBP) have PoA greater than 1.6. Obviously, there is quite a big gap between the results of the two highly-related problems. In this paper, we revisit the SBP and find more efficient mechanisms for SBP to narrow the gap. We first present a simple mechanism with (PoA=1.5), which significantly improves previous bounds. We observe that for a large class of mechanisms for the SBP, 1.5 is actually a lower bound of PoA. Finally, we propose new rules for the SBP which lead a better mechanism with (PoA le 1.467).	bin packing problem;set packing	Chenhao Zhang;Guochuan Zhang	2017		10.1007/978-3-319-71150-8_30	discrete mathematics;computer science;bin packing problem;cost sharing;upper and lower bounds	ECom	-3.5015962531754647	0.4173168473990663	181480
052b706a4b2372403431d9f47ad9832f9712f8b8	coordination of a multi-commodity supply chain with multiple members using flow networks	multiple members;e hub multi commodity supply chain multiple members flow networks supply chain coordination mechanism customer demand supply chain optimizer;coordination mechanisms;satisfiability;supply chains;supply chains manufacturing profitability cost function computer networks supply chain management production transportation humans customer service;supply chains manufacturing data processing;supply chain optimizer;manufacturing data processing;multi commodity supply chain;supply chain coordination mechanism;e hub;supply chain;supply chain coordination e hub flow networks multi commodity;supply chain coordination;customer demand;flow networks;coordination;multi commodity	A successful supply chain responds to customer's requirements with minimum cost. In general, organizations which are members of a supply chain are independent of each other and try to maximize their own benefits. Appropriate behavior of each member is necessary but does not suffice to have a competitive supply chain. A supply chain coordination mechanism leads members to behave such that the entire supply chain satisfies customer demand with minimum costs. Previous research works which provided formally analyzed coordination mechanisms have made assumptions about restrictions on the number of supply chain stages and members in each stage. Moreover, multi-commodity case has not been investigated in the context of supply chain coordination yet. This paper exploits flow networks concept to propose a coordination mechanism which is applicable to supply chains with multiple members, multiple stages and presence of multi-commodity case while each commodity is composed of several basic components. In the proposed solution an entity named supply chain optimizer (SCO) which is actually an e-hub, gathers supply chain state information and after necessary computations, informs members of supply chain of optimal decisions about orders. The goal is to minimize operational costs of the whole supply chain while satisfying customer demand.	computation;digital rights management;flow network;institute for operations research and the management sciences;linear programming;markov chain;mathematical optimization;programming model;requirement;supply chain attack;usb hub	Seyed Kaveh Fayaz;Mohammadreza Razzazi	2008	Second International Conference on the Digital Society	10.1109/ICDS.2008.21	service management;supply chain	AI	0.0988189536047512	1.374099429779481	181590
afabaa2a55638c2160eef2ea781b014dfa511cdc	on stochastic games with stationary optimal strategies	game theory;gaming;stationary optimal strategies;strategy;stochastic processes;games;decision theory;stochastic control;minmax value;optimization;markov processes;and gambling;markov decision processes;stochastic games	We study two-person zero-sum stochastic games in which the state and action spaces are finite. We give both necessary and sufficient conditions for the players to have stationary optimal strategies in the infinite-stage game.	stationary process	Truman Bewley;Elon Kohlberg	1978	Math. Oper. Res.	10.1287/moor.3.2.104	markov decision process;games;game theory;mathematical optimization;simulation;stochastic control;decision theory;continuous-time stochastic process;strategy;stochastic optimization;mathematics;stochastic game;markov process;mathematical economics;sequential game;statistics	ECom	0.28506940054699215	-0.8493905231480392	182070
d485d58415ce2657f7327d7d4e855cffad3ce5a5	value of information in greedy submodular maximization		The maximization of submodular functions an NPHard problem for certain subclasses of functions, for which a simple greedy algorithm has been shown to guarantee a solution whose quality is within 1/2 of that of the optimal. When this algorithm is implemented in a distributed way, agents sequentially make decisions based on the decisions of all previous agents. This work explores how limited access to the decisions of previous agents affects the quality of the solution of the greedy algorithm. Specifically, we provide tight upper and lower bounds on how well the algorithm performs, as a function of the information available to each agent. Intuitively, the results show that performance roughly degrades proportionally to the size of the largest group of agents which make decisions independently. Additionally, we consider the case where a system designer is given a set of agents and a global limit on the amount of information that can be accessed. Our results show that the best designs are to partition the agents into equally-sized sets, and allow agents to access the decisions of all previous agents within the same set.	entropy maximization;expectation–maximization algorithm;greedy algorithm;submodular set function;systems design	David Grimsman;Mohd. Shabbir Ali;João Pedro Hespanha;Jason R. Marden	2018	CoRR		mathematical optimization;discrete mathematics;submodular set function;mathematics;value of information;maximization;greedy algorithm;upper and lower bounds;partition (number theory)	AI	-2.4296029096970178	0.7830651301225535	182215
a222057f691eb457afbb989547ae48a1442f1404	modelling competition in matching markets with non-cooperative game theory			game theory	Ulrich Kamecke	1988				ECom	-4.071619350202672	-2.6760020689307473	182365
95360ca4466b75f8020c6046c222854ccc19d065	cost of selfishness in the allocation of cities in the multiple travelling salesmen problem		The decision to centralise or decentralise human organisations requires quantified evidence but little is available in the literature. We provide such data in a variant of the Multiple Travelling Salesmen Problem (MTSP) in which we study how the allocation sub-problem may be decentralised among selfish selfmen. Our contributions are (i) this modification of the MTSP in order to include selfishness, (ii) the proposition of organisations to solve this modified MTSP, and (iii) the comparison of these organisations. Our 5 organisations may be summarised as follows: (i) OptDecentr is a pure Centralised Organisation (CO) in which a Central Authority (CA) finds the best solution which could be found by a Decentralised Organisation (DO), (ii) Cluster and (iii) Auction are CO/DO hybrids, and (iv) P2P and (v) CNP are pure DO. Sixth and seventh organisations are used as benchmarks: (vi) NoRealloc is a pure DO which ignores the allocation problem, and (vii) FullCentr is a pure CO which solves a different problem, viz., the traditional MTSP. Comparing the efficiency of pairs of these mechanisms quantify the price of decentralising an organisation. In particular, our model of selfishness in OptDecentr makes the total route length 30% (respectively, 60%) longer with 5 (respectively, 9) salesmen than the traditional MTSP in FullCentr when the computation time is limited to 30 minutes. With this time limit, our results also seem to indicate that the level of coercion of the CA impacts more the total route length than the level of centralisation.	benchmark (computing);centralisation;commitment ordering;computation;contract net protocol;didactic organisation;emoticon;industrial engineering;plateau effect;routing;time complexity;travelling salesman problem;vii;viz: the computer game	Thierry Moyaux;Eric Marcon	2018	CoRR		time limit;management science;computer science;centralisation;welfare economics;selfishness	ECom	-3.737326157599449	2.466350605636858	183120
2098b4c63f6e5958103e03d71eae2077d5874073	solution space size in credit risk simulation	portfolio composition;knapsack problems;risk management;investment;portfolios computational complexity computational modeling upper bound security electronic mail context;computational complexity;credit transactions;enumeration task solution space size credit risk simulation securities portfolio lending credit risk evaluation enumerative algorithm computational complexity losses distribution uniform obligor linear obligor exponential obligor;risk management computational complexity credit transactions investment;knapsack problems credit risk portfolio composition;credit risk	In a portfolio of securities, lenders may incur substantial losses if the obligors do not return the money borrowed by them. In credit risk evaluation through simulation, the states of the portfolio associated to large losses are sampled rather than identified exhaustively. Enumeration of all such critical states is however relevant for the early warning of heavy losses. We provide a general enumerative algorithm, and evaluate its computational complexity, which results to be equal to the number of critical states, for three cases of the distribution of losses associated to individual obligors: uniform, linear, and exponential. In the presence of a possibly huge number of critical states, the evaluation of the computational complexity allows us to assess beforehand if the enumeration task is feasible.	algorithm;binomial heap;binomial options pricing model;computational complexity theory;feasible region;knapsack problem;money;simulation;time complexity	Maurizio Naldi;Giuseppe D'Acquisto;Loretta Mastroeni	2013	2013 UKSim 15th International Conference on Computer Modelling and Simulation	10.1109/UKSim.2013.11	financial economics;credit default swap index;actuarial science;finance;business;credit valuation adjustment	Vision	-1.9138524993168289	-0.4867532517636407	183700
085facc6e0591f0b7fb6ba21dec90784963a285a	linear quadratic risk-sensitive and robust mean field games	linear quadratic risk sensitive games large population stochastic differential games robust decentralized control large scale multiagent systems exponentiated cost function worst case risk neutral cost function stochastic differential equation mean field game theory stochastic zero sum differential game risk sensitive optimal control problem fixed point analysis e nash equilibria;risk sensitive optimal control;game theory;cost function;stochastic zero sum differential games;limiting;mean field games;games robustness cost function optimal control game theory limiting sociology;decentralized control mean field games risk sensitive optimal control stochastic zero sum differential games;optimal control;decentralized control mean eld games risk sensitive optimal control stochastic zero sum differential games;games;decentralized control;stochastic zero sum differential games decentralized control mean field games risk sensitive optimal control;decentralised control differential games large scale systems linear quadratic control multi agent systems optimal control robust control stochastic games;robustness;sociology	"""This paper considers two classes of large population stochastic differential games connected to optimal and robust decentralized control of large-scale multiagent systems. The first problem (<bold>P1</bold>) is one where each agent minimizes an exponentiated cost function, capturing risk-sensitive behavior, whereas in the second problem (<bold>P2 </bold>) each agent minimizes a worst-case risk-neutral cost function, where the “worst case” stems from the presence of an adversary entering each agent’s dynamics characterized by a stochastic differential equation. In both problems, the individual agents are coupled through the mean field term included in each agent’s cost function, which captures the average or mass behavior of the agents. We solve both <bold>P1</bold> and <bold>P2</bold> via mean field game theory. Specifically, we first solve a generic risk-sensitive optimal control problem and a generic stochastic zero-sum differential game, where the corresponding optimal controllers are applied by each agent to construct the mean field systems of <bold>P1</bold> and <bold>P2</bold>. We then characterize an approximated mass behavior effect on an individual agent via a fixed-point analysis of the mean field system. For each problem, <bold>P1 </bold> and <bold>P2</bold>, we show that the approximated mass behavior is in fact the best estimate of the actual mass behavior in various senses as the population size, <inline-formula> <tex-math notation=""""LaTeX"""">$N$</tex-math></inline-formula>, goes to infinity. Moreover, we show that for finite <inline-formula> <tex-math notation=""""LaTeX"""">$N$</tex-math></inline-formula>, there exist <inline-formula> <tex-math notation=""""LaTeX"""">$\epsilon$</tex-math></inline-formula>- Nash equilibria for both <bold>P1</bold> and <bold>P2</bold>, where the corresponding individual Nash strategies are decentralized in terms of local state information and the approximated mass behavior. We also show that <inline-formula> <tex-math notation=""""LaTeX"""">$\epsilon$</tex-math></inline-formula> can be taken to be arbitrarily small when <inline-formula> <tex-math notation=""""LaTeX"""">$N$</tex-math></inline-formula> is sufficiently large. We show that the <inline-formula> <tex-math notation=""""LaTeX"""">$\epsilon$</tex-math></inline-formula>- Nash equilibria of <bold>P1</bold> and <bold>P2</bold> are <bold><italic>partially equivalent</italic></bold> in the sense that the individual Nash strategies share identical control laws, but the approximated mass behaviors for <bold>P1 </bold> and <bold>P2</bold> are different, since in <bold>P2</bold>, the mass behavior is also affected by the associated worst-case disturbance. Finally, we prove that the Nash equilibria for <bold>P1</bold> and <bold>P2</bold> both feature robustness, and as the parameter characterizing this robustness becomes infinite, the two Nash equilibria become identical and equivalent to that of the risk-neutral case, as in the one-agent risk-sensitive and robust control theory."""	adversary (cryptography);agent-based model;approximation algorithm;best, worst and average case;control theory;discounted maximum loss;distributed control system;existential quantification;game theory;local variable;loss function;multi-agent system;nash equilibrium;optimal control;robust control	Jun Moon;Tamer Basar	2017	IEEE Transactions on Automatic Control	10.1109/TAC.2016.2579264	games;game theory;mathematical optimization;optimal control;decentralised system;control theory;mathematics;mathematical economics;limiting;robustness	ML	-0.36737946241871994	-0.567057883459954	183968
3c06f1c2074127784e02698c8681b73c764da62d	sequences of take-it-or-leave-it offers: near-optimal auctions without full valuation revelation	equilibrium computation;multiagent system;optimal auction design;expected utility maximization;expected utility;auction design;perfect bayesian equilibrium;multiagent systems;auctions	We introduce take-it-or-leave-it auctions (TLAs) as an allocation mechanism that allows buyers to retain much of their private valuation information, yet generates close-to-optimal expected utility for the seller. We show that if each buyer receives at most one offer, each buyer's dominant strategy is to act truthfully. In more general TLAs, the buyers' optimal strategies are more intricate, and we derive the perfect Bayesian equilibrium for the game. We develop algorithms for finding the equilibrium and also for optimizing the offers so as to maximize the seller's expected utility. In several example settings we show that the seller's expected utility already is close to optimal for a small number of offers. As the number of buyers increases, the seller's expected utility increases, and becomes increasingly (but not monotonically) more competitive with Myerson's expected utility maximizing auction.	algorithm;expected utility hypothesis;value (ethics)	Tuomas Sandholm;Andrew Gilpin	2006		10.1145/1160633.1160839	bayesian game;expected utility hypothesis;artificial intelligence;multi-agent system;forward auction	ECom	-3.2056169753195505	-1.837556597740804	184627
52db249ad899b0970c8e6b1bc0e0cc6e3ac3cbdf	supplier selection in virtual enterprise model of manufacturing supply network	trading agents;network planning;virtual enterprise;supplier selection	The market-based approach to manufacturing supply network planning focuses on the competitive attitudes of various enterprises in the network to generate plans that seek to maximize the throughput of the network. It is this competitive behaviour of the member units that we explore in proposing a solution model for a supplier selection problem in convergent manufacturing supply networks. We present a formulation of autonomous units of the network as trading agents in a virtual enterprise network interacting to deliver value to market consumers and discuss the effect of internal and external trading parameters on the selection of suppliers by enterprise units.	autonomous robot;interaction;internet;procurement;selection algorithm;throughput;virtual enterprise;virtual private network	Toshiya Kaihara;Jayeola Femi Opadiji	2009		10.1007/978-3-642-04568-4_35	enterprise private network;network planning and design;computer science;marketing;operations management;management;commerce	AI	0.09905765954560612	1.1084408657082159	184782
1db7d1e618ccd9af2e3419c4b7fc53aafa17b942	the advantages of compromising in coalition formation with incomplete information	protocols;kernel;social welfare;collaboration;mechanical factors;stability;coalition formation;incomplete information;time factors;computational complexity;proposals;distribution strategy;time factors distribution strategy kernel protocols mechanical factors stability computational complexity collaboration proposals costs;time constraint	This paper presents protocols and strategies for coalition formation with incomplete information under time constraints. It focuses on strategies for coalition members to distribute revenues amongst themselves. Such strategies should preferably be stable, lead to a fair distribution, and maximize the social welfare of the agents. These properties are only partially supported by existing coalition formation mechanisms. In particular, stability and the maximization of social welfare are supported only in the case of complete information, and only at a high computational complexity. Recent studies on coalition formation with incomplete and uncertain information address revenue distribution in a naïve manner. In this study we specifically refer to environments with limited computational resources and incomplete information. We propose a variety of strategies for revenue distribution, including the strategy in which the agents attempt to distribute the estimated net value of a coalition equally. A variation of the equal distribution strategy in which agents compromise and agree to a payoff lower than their estimated equal share, was specifically examined. Our experimental results show that, under time constraints, the compromise strategy is stable and increases the social welfare compared to non-compromise strategies.	computational complexity theory;computational resource;entropy maximization;naivety	Sarit Kraus;Onn Shehory;Gilad Taase	2004	Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems, 2004. AAMAS 2004.	10.1109/AAMAS.2004.259	communications protocol;kernel;stability;computer science;social welfare;computational complexity theory;complete information;collaboration	AI	-3.164556869145971	-1.4631626279404946	185240
71a3890ba18c163f5619f16af04679a6ce32e06e	almost-sure hedging with permanent price impact	article accepte pour publication ou publie;hedging;price impact	We consider a financial model with permanent price impact. Continuous time trading dynamics are derived as the limit of discrete rebalancing policies. We then study the problem of super-hedging a European option. Our main result is the derivation of a quasi-linear pricing equation. It holds in the sense of viscosity solutions. When it admits a smooth solution, it provides a perfect hedging strategy.	financial modeling;viscosity solution	Bruno Bouchard;Grégoire Loeper;Yiyi Zou	2016	Finance and Stochastics	10.1007/s00780-016-0295-1	financial economics;hedge;economics;finance;mathematical economics	ECom	1.2717523991476414	-2.3961097546644665	185580
82d367893c69a5c7cf821dd55765eaa89975e05d	truthful univariate estimators		We revisit the classic problem of estimating the population mean of an unknown singledimensional distribution from samples, taking a game-theoretic viewpoint. In our setting, samples are supplied by strategic agents, who wish to pull the estimate as close as possible to their own value. In this setting, the sample mean gives rise to manipulation opportunities, whereas the sample median does not. Our key question is whether the sample median is the best (in terms of mean squared error) truthful estimator of the population mean. We show that when the underlying distribution is symmetric, there are truthful estimators that dominate the median. Our main result is a characterization of worst-case optimal truthful estimators, which provably outperform the median, for possibly asymmetric distributions with bounded support.	best, worst and average case;game theory;mean squared error;sample rate conversion	Ioannis Caragiannis;Ariel D. Procaccia;Nisarg Shah	2016			econometrics;mathematical optimization;mathematics;truncated mean;statistics	ML	-2.4606751532038955	-1.3993243861523241	186585
a7eca3173b2e0bb9853fd9e05f0954db84c64ef9	the general multimodal network equilibrium problem with elastic balanced demand		The general multimodal network equilibrium problem with elastic balanced demand is studied. This problem is a combination of trip distribution, modal split and trip assignment problems. The problem is approached from an asymmetric network equilibrium point of view with side constraints. The balances for travel demand are taken as side constraints. These balances do not guarantee that the problem’s solution will satisfy the user equilibrium conditions. It is shown that the obtained solution is equilibrium traffic pattern in terms of the generalized travel costs which is constructed with the use of dual variables for demand balance constraints. The economical interpretation of dual variables from the city infrastructure extension point of view is proposed. By calculating of the dual values we know whether or not a city area is suitable for growing. It is established that if the travel costs are co-coercive then the set of shortest routes in terms of generalized travel costs is the same for every solution of the studied problem.	duality (optimization);elastic matching;iterative method;modal logic;multimodal interaction;newman's lemma;planning	Natalia B. Shamray	2016			elasticity (economics);welfare economics;microeconomics;economics	AI	1.3555919308586128	0.759540420283963	186895
51fd7a0947bac911634a369a479cdc9be861efb7	distributed coalition formation in energy-aware cloud federations: a game-theoretic approach (extended version)		In this paper, we address the problem of federation formation for a set of CPs, whose solution is necessary to exploit the potential of cloud federations for the reduction of the energy bill. We devise a distributed algorithm, based on cooperative game theory, that allows a set of CPs to cooperatively set up their federations in such a way that their individual profit is increased with respect to the case in which they work in isolation, and we show that, by using our algorithm and the proposed CPs’ utility function, they are able to self-organize into Nash-stable federations and, by means of iterated executions, to adapt themselves to environmental changes. Numerical results are presented to demonstrate the effectiveness of the proposed algorithm.	distributed algorithm;game theory;iteration;nash equilibrium;self-organization;utility	Marco Guazzone;Cosimo Anglano;Roberto Aringhieri;Matteo Sereno	2013	CoRR		simulation	AI	-0.19070791503294332	3.788101387105009	188731
9b7fd046594ef690bacee372e438d85f8eab7184	towards valuation-aware agent-based traffic control	resource utilization;agent based;traffic control;negotiations;traffic management;agents;waiting time;driver assistance system;intersection control	Traffic authorities work hard to improve resource utilization in traffic. But these efforts do not consider that the valuations of waiting time can be different for each driver, e.g., a driver of a courier service delivering express mail typically has a higher valuation of reduced waiting time than other motorists. We propose that traffic-control mechanisms should be valuation-aware and propose and describe such a mechanism called Time-Slot Exchange. The idea of this mechanism is that vehicles are assigned time slots to cross the intersection, and vehicles, or, more specifically, agent-based driver-assistance systems of the vehicles can then trade these time slots. Simulations show that our mechanism increases overall satisfaction considerably, compared to a state-of-the-art traffic-control mechanism.	agent-based model;computer simulation;control system;value (ethics)	Heiko Schepperle;Klemens Böhm;Simone Forster	2007		10.1145/1329125.1329349	active traffic management;in situ resource utilization;simulation;computer science;artificial intelligence;software agent;negotiation	Mobile	0.24417335480096708	1.8507219758620537	189591
95db6fe2734ee3d971d26601bb4f1d22e92bbee3	gerber-shiu analysis with two-sided acceptable levels	transition kernel;classical poisson risk model;markovian arrival process;truncated gerber shiu function;surplus dependent premium rate;joint distribution of maximum and minimum before ruin	In this paper, insurer’s surplus process moved within upper and lower levels is analyzed. To this end, a truncated type of Gerber–Shiu function is proposed by further incorporating the minimum and the maximum surplus before ruin into the existing ones (e.g. Gerber and Shiu (1998), Cheung et al. (2010a)). A key component in our analysis of this proposed Gerber–Shiu function is the so-called transition kernel. Explicit expressions of the transition function under two different risk models are obtained. These two models are both generalizations of the classical Poisson risk model: (i) the first model provides flexibility in the net premium rate which is dependent on the surplus (such as linear or step function); and (ii) the second model assumes that claims arrive according to a Markovian arrival process (MAP). Finally, we discuss some applications of the truncated Gerber–Shiu function with numerical examples under various scenarios.	gerber format	Jae-Kyung Woo;Ran Xu;Hailiang Yang	2017	J. Computational Applied Mathematics	10.1016/j.cam.2017.02.014	mathematical optimization;mathematics;markovian arrival process;statistics	NLP	2.576244577502352	-2.2360794567476447	190137
098e48cb422660a0b8a8c59053b5db16359d4371	imputing a convex objective function	stochastic process;cost function;convex programming;utility function;prior knowledge;dynamic program;objective function;optimization problem;control problem;convex function;process control;value function;parametric optimization;flow network convex objective function optimizing process parametric optimization problem consumer utility function purchasing choices value function control problem cost function;heuristic algorithm;convex functions dynamic programming process control cost function stochastic processes heuristic algorithms	We consider an optimizing process (or parametric optimization problem), i.e., an optimization problem that depends on some parameters. We present a method for imputing or estimating the objective function, based on observations of optimal or nearly optimal choices of the variable for several values of the parameter, and prior knowledge (or assumptions) about the objective. Applications include estimation of consumer utility functions from purchasing choices, estimation of value functions in control problems, given observations of an optimal (or just good) controller, and estimation of cost functions in a flow network.	c date and time functions;controller (computing);convex function;convex optimization;dynamic programming;flow network;image noise;karush–kuhn–tucker conditions;machine learning;mathematical optimization;matrix regularization;optimization problem;purchasing;recueil des historiens des croisades;robotics;semiconductor;usb on-the-go;vii	Arezou Keshavarz;Yang Wang;Stephen P. Boyd	2011	2011 IEEE International Symposium on Intelligent Control	10.1109/ISIC.2011.6045410	mathematical optimization;mathematics;mathematical economics;welfare economics	Robotics	2.5507764548555727	-0.5319840826793917	190273
ebf3cd621b0e2474a6ed388bb646735f6e9f29e1	combinatorial auctions for coordination and control of manufacturing mas: updating prices methods	multiagent system;production process;dynamic environment;robust stability;job shop;task scheduling;manufacturing system;combinatorial auction	  We use the paradigm of multiagent systems to solve the Job Shop problem. It concerns the allocation of machines to operations  of some production process over time periods and its goal is the optimization of one or several objectives. We propose a combinatorial  auction mechanism to coordinate agents. The “items” to be sold are the time slots that we divide the time horizon into. In  tasks scheduling problems tasks need a combination of time slots of multiple resources to do the operations. The use of auctions  in which different valuations of interdependent items are considered (e.g. combinatorial auctions) is necessary. The auctioneer  fixes prices comparing the demand over a time slot of a resource with the capacity of the resource in this time slot. Our  objective is to find an updating price method for combinatorial auctions that meet the needings of scheduling manufacturing  systems in dynamic environments, e.g. robustness, stability, adaptability, and efficient use of available resources.    		Juan José Lavios Villahoz;Ricardo del Olmo Martínez;José Alberto Araúzo Araúzo	2010		10.1007/978-3-642-13161-5_4	mathematical optimization;simulation;combinatorial auction;scheduling	Robotics	-0.3154840420759141	2.4076926716895852	190304
323128767bbf6894e2d57f7ebc65fd998c316bb2	scheduling multi-task multi-agent systems	multiagent teams;multi agent system;coevolution;upper bound;robot soccer;distributed algorithm;heterogeneous network;coordination	We present a centralized and a distributed algorithms for scheduling multi-task agents in heterogeneous networks. Our centralized algorithm has an upper bound on the overall completion time and is used as a module in the distributed algorithm. Extensive simulations show promising results.	centralized computing;computer multitasking;distributed algorithm;multi-agent system;schedule (project management);scheduling (computing);simulation	Rong Xie;Daniela Rus;Clifford Stein	2001		10.1145/375735.376036	fair-share scheduling;distributed algorithm;real-time computing;simulation;heterogeneous network;coevolution;computer science;artificial intelligence;multi-agent system;distributed computing;upper and lower bounds	AI	-1.3845451872215098	3.1825761597856426	190440
e00405d948dbb158e7f4dfb19348d34aadec3364	optimal cost sharing protocols for scheduling games	cost function;price of anarchy;satisfiability;scheduling;cost sharing;congestion game;congestion games;lower bound;harmonic number;pure strategy nash equilibrium;pure strategy nash equilibria	We consider the problem of designing cost sharing protocols to minimize the price of anarchy and stability for a class of scheduling games. Here, we are given a set of players, each associated with a job of certain non-negative weight. Any job fits on any machine, and the cost of a machine is a non-decreasing function of the total load on the machine. We assume that the private cost of a player is determined by a cost sharing protocol. We consider four natural design restrictions for feasible protocols: stability, budget balance, separability, and uniformity. While budget balance is self-explanatory, the stability requirement asks for the existence of pure-strategy Nash equilibria. Separability requires that the resulting cost shares only depend on the set of players on a machine. Uniformity additionally requires that the cost shares on a machine are instance-independent, that is, they remain the same even if new machines are added to or removed from the instance. We call a cost sharing protocol basic, if it satisfies only stability and budget balance. Separable and uniform cost sharing protocols additionally satisfy separability and uniformity, respectively. For n-player games we show that among all basic and separable cost sharing protocols, there is an optimal protocol with price of anarchy and stability of precisely the n-th harmonic number. For uniform protocols we present a strong lower bound showing that the price of anarchy is unbounded. Moreover, we obtain several results for special cases in which either the cost functions are restricted, or the job sizes are restricted. As a byproduct of our analysis, we obtain a complete characterization of outcomes that can be enforced as a pure-strategy Nash equilibrium by basic and separable cost sharing protocols.	anarchy;circuit complexity;fits;linear separability;nash equilibrium;scheduling (computing)	Philipp von Falkenhausen;Tobias Harks	2011		10.1145/1993574.1993618	price of stability;mathematical optimization;harmonic number;economics;computer science;mathematics;strategy;microeconomics;mathematical economics;upper and lower bounds;scheduling;welfare economics;price of anarchy;satisfiability	Theory	-3.879293928795203	0.14590726210717664	190712
79fe051b8d7f5fdcecfab1717c73c92aff16878e	incentive design for demand-response based on building constraints: a utility perspective		Electrical utilities offer incentives to their customers to reduce their demand during temporary supply-demand mismatches. While customers would prefer a higher incentive to participate, utilities would prefer to minimize the incentive while achieving a target reduction. Because the incentive affects the bottomline of the utility, identifying the optimal incentive reflecting this trade-off is important.  Several works have focused on how to implement DR in a building, but there has been little work on identifying the optimal incentive from the utility's perspective. We complement existing work with an approach on how a utility can identify the optimal incentive for a set of buildings that it serves, while meeting individual buildings' constraints. To this end, we build Demand-Response Potential (DRP) models that give the economically rational demand reduction of a building as a function of the utility's offered incentive. For handling scalability at the utility level, we approximate the DRP using regression based approach.  We evaluate our approach on the PLUTO dataset of building types and sizes. We find that the DRP varies with building types (from 19% for restaurants to 54% for warehouses). It is typically low for buildings with high thermal inertia; and building types with low individual DRP can contribute significantly in aggregate due to their numbers. Offering non-uniform incentives to different buildings can improve the utility's DR benefit by up to 19% compared to offering uniform incentives.	aggregate data;approximation algorithm;baseline (configuration management);disaster recovery plan;requirement;scalability	Kundan Kandhway;Arunchandar Vasan;Srinarayana Nagarathinam;Venkatesh Sarangan;Anand Sivasubramaniam	2017		10.1145/3137133.3137142	demand response;scalability;business;microeconomics;incentive;demand reduction;warehouse	AI	2.6326242800432875	2.3726294209658683	191169
3248d110c0b5df27c97f1ca823b37f3275afdb88	the burden of risk aversion in mean-risk selfish routing	risk averse wardrop equilibrium;mean stdev risk measure;stochastic networks;stochastic selfish routing;nash equilibrium;mean var risk measure;congestion game	Considering congestion games with uncertain delays, we compute the inefficiency introduced in network routing by risk-averse agents. At equilibrium, agents may select paths that do not minimize the expected latency so as to obtain lower variability. A social planner, who is likely to be more risk neutral than agents because it operates at a longer time-scale, quantifies social cost with the total expected delay along routes. From that perspective, agents may make suboptimal decisions that degrade long-term quality. We define the price of risk aversion (PRA) as the worst-case ratio of the social cost at a risk-averse Wardrop equilibrium to that where agents are risk-neutral. For networks with general delay functions and a single source-sink pair, we show that the PRA depends linearly on the agents' risk tolerance and on the degree of variability present in the network. In contrast to the price of anarchy, in general the PRA increases when the network gets larger but it does not depend on the shape of the delay functions. To get this result we rely on a combinatorial proof that employs alternating paths that are reminiscent of those used in max-flow algorithms. For series-parallel (SP) graphs, the PRA becomes independent of the network topology and its size. As a result of independent interest, we prove that for SP networks with deterministic delays, Wardrop equilibria maximize the shortest-path objective among all feasible flows.	algorithm;anarchy;best, worst and average case;heart rate variability;maximum flow problem;nash equilibrium;network congestion;network topology;physical review a;risk aversion;routing;series-parallel graph;shortest path problem;spatial variability	Evdokia Nikolova;Nicolás E. Stier Moses	2015		10.1145/2764468.2764485	mathematical optimization;economics;microeconomics;mathematical economics;welfare economics;nash equilibrium	ECom	-3.6647424428104896	2.0853799122309775	191243
ad72d9058531f10b3111bfa0f25c46f11ceca6d2	on the optimal dividend problem for insurance risk models with surplus-dependent premiums	integro differential hjb equation;93e20;optimal strategy;60g50;gerber shiu function;60k25;barrier strategy;60g51;stochastic controls;pdmp	This paper concerns an optimal dividend distribution problem for an insurance company with surplus-dependent premium. In the absence of dividend payments, such a risk process is a particular case of so-called piecewise deterministic Markov processes. The control mechanism chooses the size of dividend payments. The objective consists in maximizing the sum of the expected cumulative discounted dividend payments received until the time of ruin and a penalty payment at the time of ruin, which is an increasing function of the size of the shortfall at ruin. A complete solution is presented to the corresponding stochastic control problem. We identify the associated Hamilton---Jacobi---Bellman equation and find necessary and sufficient conditions for optimality of a single dividend-band strategy, in terms of particular Gerber---Shiu functions. A number of concrete examples are analyzed.	financial risk modeling	Ewa Marciniak;Zbigniew Palmowski	2016	J. Optimization Theory and Applications	10.1007/s10957-015-0755-3	actuarial science;mathematical economics	Theory	2.226407684534005	-2.5741530961063765	191505
09b7f07e4b3bb41ccf2311013c2ca8f4ee56ae4a	coalition formation game for task allocation in the social network		Coalition formation is an important research issue in the field of multi-agent, which can be widely applied in task allocation. This paper is different from traditional social task allocation problem. We propose that a mobile agent is assigned to each subtask that is decomposed by a complex task. Mobility refers to the ability of each agent to move to individuals with relevant professional capability. In this work, we model cooperation among mobile agents through coalition formation game in which mobile agents are graph-constrained and workers are in the social network. We propose a simple and distributed algorithm for the mobile agents who self-organize into independent disjoint coalitions. Compared with a non-cooperative approach where each mobile agent is self-interested to minimize its own operation cost, mobile agents decide to form disjoint coalitions to reduce the total operation cost. In addition, we prove the convergence of the algorithm. Simulation results show that, in different cases, coalition formation presents a performance improvement.	distributed algorithm;mobile agent;multi-agent system;requirement;self-organization;simulation;social network	Yu Zhou;Yonglong Zhang;Bin Li	2018	2018 IEEE 22nd International Conference on Computer Supported Cooperative Work in Design ((CSCWD))	10.1109/CSCWD.2018.8465284	distributed computing;task analysis;distributed algorithm;resource management;mobile agent;performance improvement;computer science;social network;disjoint sets;convergence (routing)	AI	-1.4335220983692119	3.2438231906613217	192467
605e5b0645bf7e6741305bb87cd378e88bfbccee	a continuum-discrete model for supply chains dynamics	discrete model;supply chain	This paper is focused on continuum-discrete models for supply chains. In particular, we consider the model introduced in [10], where a system of conservation laws describe the evolution of the supply chain status on sub-chains, while at some nodes solutions are determined by Riemann solvers. Fixing the rule of flux maximization, two new Riemann Solvers are defined. We study the equilibria of the resulting dynamics, moreover some numerical experiments on sample supply chains are reported. We provide also a comparison, both of equilibria and experiments, with the model of [15].	expectation–maximization algorithm;experiment;numerical analysis;triune continuum paradigm	Gabriella Bretti;Ciro D'Apice;Rosanna Manzo;Benedetto Piccoli	2007	NHM	10.3934/nhm.2007.2.661	mathematics;supply chain	Robotics	0.11871262032764252	-2.7876477680246685	192527
7cfd9a7188d6212b9614eea77863c3790c8bc41a	penalty-regulated dynamics and robust learning procedures in games	learning;quantal response equilibria;stochastic approximation;smooth best responses	Starting from a heuristic learning scheme for strategic n-person games, we derive a new class of continuous-time learning dynamics which consist of a replicator-like term adjusted by an entropic penalty that keeps players’ strategies away from the boundary of the game’s strategy space. These entropy-driven dynamics are equivalent to players taking an exponentially discounting aggregate of their on-going payoffs and then using a quantal response choice model to pick an action based on these performance scores. Owing to this inherent duality, these dynamics satisfy a variant of the folk theorem of evolutionary game theory and converge to (arbitrarily precise) quantal approximations of Nash equilibria in potential games. Motivated by applications to traffic engineering, we exploit this duality in order to design a discrete-time, payoff-based learning algorithm which retains these convergence properties and only requires players to observe their in-game payoffs: in fact, the algorithm retains its robustness in the presence of stochastic perturbations and observation errors, and does not require any synchronization between players.	aggregate data;algorithm;approximation;choice modelling;converge;game theory;heuristic;nash equilibrium;quantum;virtual world	Pierre Coucheney;Bruno Gaujal;Panayotis Mertikopoulos	2015	Math. Oper. Res.	10.1287/moor.2014.0687	stochastic approximation;mathematical optimization;simulation;best response;mathematics;mathematical economics;algorithm	AI	-2.837230624781649	1.3805198235783305	192609
d91a264a8fe1044dd3d83b6754bf1948968c2c97	optimal consumption under deterministic income		We consider an individual or household endowed with an initial wealth, having an income and consuming goods and services. The wealth development rate is assumed to be a deterministic continuous function of time. The objective is to maximize the discounted consumption. Via the Hamilton–Jacobi–Bellman approach we prove the existence and the uniqueness of the solution to the considered problem in the viscosity sense. Furthermore we derive an algorithm for explicit calculation of the value function and optimal strategy. It turns out that the value function is in general not continuous. The method is illustrated by two examples.		Julia Eisenberg;Peter Grandits;Stefan Thonhauser	2014	J. Optimization Theory and Applications	10.1007/s10957-013-0320-x	mathematical optimization;mathematical economics	AI	1.3607675882142027	-2.741699976566659	194014
6c36968cac352bd0121b6f71a4baa36603d6c1e0	on stackelberg routing on parallel networks with horizontal queues	vehicle routing computational complexity game theory queueing theory;game theory;queueing theory;vehicle routing;transportation networks game theory nash equilibrium network analysis and control routing stackelberg game;compliant drivers parallel networks horizontal queues stackelberg routing games transportation networks latency functions physical queues congestion games literature multiple nash equilibria polynomial time algorithm central authority compliant flow noncompliant first strategy ncf strategy congestion relief traffic management agency;computational complexity;routing games nash equilibrium vehicles polynomials indexes	In order to address inefficiencies of Nash equilibria for congestion networks with horizontal queues, we study the Stackelberg routing game on parallel networks: assuming a coordinator has control over a fraction of the flow, and that the remaining players respond selfishly, what is an optimal Stackelberg strategy of the coordinator, i.e. a strategy that minimizes the cost of the induced equilibrium? We study Stackelberg routing for a new class of latency functions, which models congestion on horizontal queues. We introduce a candidate strategy, the non-compliant first strategy, and prove it to be optimal. Then we apply these results by modeling a transportation network in which a coordinator can choose the routes of a subset of the drivers, while the rest of the drivers choose their routes selfishly.	nash equilibrium;network congestion;routing	Walid Krichene;Jack Reilly;Saurabh Amin;Alexandre M. Bayen	2012	2012 IEEE 51st IEEE Conference on Decision and Control (CDC)	10.1109/TAC.2013.2289709	game theory;routing;simulation;mathematics;mathematical economics;queueing theory;computational complexity theory	Theory	-2.9884797494514004	2.74673434459332	194092
0d2e6d9bd5b21ce45c5eade8811084ca2de87620	shadow prices, fractional brownian motion, and portfolio optimisation under transaction costs		The present paper accomplishes a major step towards a reconciliation of two conflicting approaches in mathematical finance: on the one hand, the mainstream approach based on the notion of no arbitrage (Black, Merton & Scholes); and on the other hand, the consideration of non-semimartingale price processes, the archetype of which being fractional Brownian motion (Mandelbrot). Imposing (arbitrarily small) proportional transaction costs and considering logarithmic utility optimisers, we are able to show the existence of a semimartingale, frictionless shadow price process for an exponential fractional Brownian financial market. MSC 2010 Subject Classification: 91G10, 93E20, 60G48 JEL Classification Codes: G11, C61	black–scholes model;brownian motion;mandelbrot set;mathematical optimization;merton's portfolio problem;shadow price;time complexity	Christoph Czichowsky;Rémi Peyre;Walter Schachermayer;Junjian Yang	2018	Finance and Stochastics	10.1007/s00780-017-0351-5	financial economics;mathematical optimization;economics;mathematics;mathematical economics	Theory	0.7504624479684193	-2.2060757090625187	194124
e32215410ef1e35a843931b2278258ed9b683888	concise bid optimization strategies with multiple budget constraints		A major challenge faced by marketers attempting to optimize their advertising campaigns is to deal with budget constraints. The problem is even harder in the face of multidimensional budget constraints, particularly in the presence of many decision variables involved and the interplay among the decision variables through such constraints. Concise bidding strategies help advertisers deal with this challenge by introducing fewer variables to act on. In this paper, we study the problem of finding optimal concise bidding strategies for advertising campaigns with multiple budget constraints. Given bid landscapes—i.e., the predicted value (e.g., number of clicks) and the cost per click for any bid—that are typically provided by ad-serving systems, we optimize the value of an advertising campaign given its budget constraints. In particular, we consider bidding strategies that consist of no more than k different bids for all keywords. For constant k, we provide a PTAS to optimize the profit, whereas for arbitrary k we show how a constant-factor approximation algorithm can be obtained via a very fast dependent randomized rounding of the LP relaxation of the problem that runs in linear time and may be of independent interest. In addition to being able to deal with multi-dimensional budget constraints, our results do not assume any specific payment scheme and can be applied on pay-per-click, pay-per-impression, or pay-per-conversion models. Also, no assumption about the concavity of value or cost functions is made. We evaluate the performance of our algorithms on real datasets in two regimes with 1and 3-dimensional budget constraints. In the former case, where uniform bidding (introduced by Feldman et al. 2007 and currently used in practice) has provable performance guarantee, our algorithm beats the state of the art by an increase of 1% to 6% in the expected number of clicks. This is achieved by only two or three clusters—in contrast with the single cluster permitted in uniform bidding. With only three dimensions in the budget constraint (one for total consumption, and two others for enforcing minimal diversity), the gap between the performance of our algorithm and an enhanced version of uniform bidding grows to an average of 5% to 6%.	apx;ad serving;approximation algorithm;concave function;cost per impression;decision theory;lp-type problem;linear programming relaxation;ptas reduction;program optimization;provable prime;randomized algorithm;randomized rounding;time complexity	Arash Asadpour;MohammadHossein Bateni;Kshipra Bhawalkar;Vahab S. Mirrokni	2014		10.1007/978-3-319-13129-0_21	mathematical optimization;budget constraint;simulation;economics;operations management;microeconomics;mathematical economics;welfare economics;algorithm	ECom	-1.1517287051727911	-1.6111280356406787	195527
ab3a2b1187559dfe09ff2260cdac57574ab09f01	optimal portfolios when stock prices follow an exponential lévy process	downside risk measure;exponential levy process;brownian motion;value at risk;mean variance;portfolio optimization;upper bound;stock price;l evy process;capital at risk;compound poisson process;weak limit law for levy processes;downside risk;stochastic exponential;optimal portfolio;limit laws	We investigate some portfolio problems that consist of maximizing expected terminal wealth under the constraint of an upper bound for the risk, where we measure risk by the variance, but also by the Capital-at-Risk (CaR). The solution of the mean-variance problem has the same structure for any price process which follows an exponential Lévy process. The mean-CaR involves a quantile of the corresponding wealth process of the portfolio. We derive a weak limit law for its approximation by a simpler Lévy process, often the sum of a drift term, a Brownian motion and a compound Poisson process. Certain relations between a Lévy process and its stochastic exponential are investigated.	approximation;brownian motion;time complexity	Susanne Emmer;Claudia Klüppelberg	2004	Finance and Stochastics	10.1007/s00780-003-0105-4	financial economics;variance gamma process;actuarial science;economics;finance;lévy process;portfolio optimization;brownian motion;mathematics;mathematical economics;upper and lower bounds;statistics;limit of a function;compound poisson process;value at risk	AI	1.8887818358985733	-2.626426649327253	195724
28be35b96d3b3919adc116396de64167412f32cc	an agent-based optimization approach for distributed project scheduling in supply chain with partial information sharing	agent based;partial information;supply chain;project scheduling	This paper focuses on the optimization problem of distributed project scheduling in the supply chain network which is made up of order manager, service brokers and service suppliers. Based on the initial scheduling by bids of service brokers, we present a heuristic approach with agent negotiation mechanism for the problem. The approach seeks optimal schedule by distributed negotiations, which apply the agent negotiation mechanism and share limited information, between order manager and brokers. Computational experiments show the approach is effective with good optimization performance.	centralized computing;computation;distributed computing;experiment;heuristic;mathematical optimization;optimization problem;program optimization;scheduling (computing);service-oriented architecture;supply chain network	Hanlin Zhang;Guorui Jiang;Tiyun Huang	2010			fair-share scheduling;real-time computing;dynamic priority scheduling;distributed computing;supply chain;schedule	AI	-0.2837119796306781	2.325789703283355	195991
b5ba18d6abe85c063a0e4337e1cf9489ed7849a1	on the value of information in coordination games (preliminary version)	maximum out degree;optimisation;game theory;game theory artificial intelligence optimisation parallel algorithms;virtual circuit;coordination game;optimization problem;maximum out degree coordination games distributed artificial intelligence load balancing virtual circuit routing directed graph;directed graph;distributed artificial intelligence;load balancing;artificial intelligence;algorithm design and analysis circuits routing information analysis loss measurement computer science ear context modeling;load balance;value of information;virtual circuit routing;coordination games;parallel algorithms	"""We discuss settings where several """"agents"""" combine efforts to solve problems. This is a well-known setting in distributed artificial intelligence. Our work addresses theoretical questions in this model which are motivated by the work of X. Deng and C.H. Papadimitriou (1992). We consider optimization problems, in particular load balancing and virtual circuit routing, in which the input is divided among the agents. An underlying directed graph, whose nodes are the agents, defines the constraints on the information each agent may have about the portion of the input held by other agents. The questions we discuss are: Given a bound on the maximum out-degree in this graph, which is the best graph? What is the quality of the solution obtained as a function of the maximum out-degree?. >"""		Sandy Irani;Yuval Rabani	1993		10.1109/SFCS.1993.366886	game theory;coordination game;computer science;load balancing;theoretical computer science;machine learning;distributed computing	Theory	-2.577240174630881	2.996331260377296	196388
f4f8eb84b22e4d9e9ef9cf7c28b849f0f2fa7abb	mixing coins of different quality: a game-theoretic approach		Cryptocoins based on public distributed ledgers can differ in their quality due to different subjective values users assign to coins depending on the unique transaction history of each coin. We apply game theory to study how qualitative differentiation between coins will affect the behavior of users interested in improving their anonymity through mixing services. We present two stylized models of mixing with perfect and imperfect information and analyze them for three distinct quality propagation policies: poison, haircut, and seniority. In the game of perfect information, mixing coins of high quality remains feasible under certain conditions, while imperfect information eventually leads to a mixing market where only coins of the lowest quality are mixed.	coins;display resolution;game theory;software propagation	Svetlana Abramova;Pascal Schöttle;Rainer Böhme	2017		10.1007/978-3-319-70278-0_18	computer security;haircut;stylized fact;computer science;anonymity;game theory;blacklisting;perfect information;database transaction	Metrics	-2.654129024828173	-2.5308606938641027	196436
48c4498356a1458c9ae54ed2ca9698555210da1e	modularity and greed in double auctions	deferred-acceptance auctions;economics;general;trade reduction mechanism	Designing double auctions is a complex problem, especially when there are restrictions on the sets of buyers and sellers that may trade with one another. The goal of this paper is to develop ``black-box reductions'' from double-auction design to the exhaustively-studied problem of designing single-sided mechanisms. We consider several desirable properties of a double auction: feasibility, dominant-strategy incentive-compability, the still stronger incentive constraints offered by a deferred-acceptance implementation, exact and approximate welfare maximization, and budget-balance. For each of these properties, we identify sufficient conditions on the two one-sided mechanisms --- one for the buyers, one for the sellers --- and on the method of composition, that guarantee the desired property of the double auction. Our framework also offers new insights into classic double-auction designs, such as the VCG and McAfee auctions with unit-demand buyers and unit-supply sellers.		Paul Dütting;Inbal Talgam-Cohen;Tim Roughgarden	2017	Games and Economic Behavior	10.1016/j.geb.2017.06.008	eauction;economics;computer science;common value auction;double auction;microeconomics;welfare economics;commerce;forward auction	ECom	-3.6905608236803777	-2.397026534916591	196549
6dedc9d355605cd0cf0e8f1c1abdc9794c6041b5	a market based approach for complex task allocation for wireless network based multi-robot system	resource exchange;radio networks;protocols;wireless networks;winner determination;virtual economy;complex task tree allocation;ccmm;wireless network;resource management;multirobot system;bid submission;multi robot system;contracts;wireless network constraint;mobile robots;bid valuation;trees mathematics;trees mathematics mobile robots multi robot systems protocols radio networks;resource exchange market based trade approach complex task tree allocation wireless network constraint multirobot system mba virtual economy auction protocol auction announcement bid valuation bid submission winner determination control and coordination of mobile mote ccmm;auction protocol;multi robot systems;control and coordination of mobile mote;auction announcement;market based trade approach;mba;conferences;task allocation;robot kinematics;wireless networks multirobot systems robot kinematics protocols contracts consumer electronics humans robotics and automation technological innovation performance evaluation	Market based approach (MBA) provides communication and coordination for robots in a virtual economy in which they can exchange tasks and resources for payment. Furthermore, trades are enabled via market mechanisms such as auction protocols in which an auctioneer is able to determine the robots best capable of achieving the tasks being offered. In this paper we purpose a modification of MBA for task allocation. This approach consists of auction announcement, bid valuation and submission and winner determination. Several scenarios where robots need to visit particular locations with time and range of wireless network constraints are used for approach verification. Additionally, the results obtained by this approach are compared with results from approach in Control and Coordination of Mobile Motes (CCMM).	auction algorithm;robot;value (ethics);virtual economy	Merid Ljesnjanin;Jasmin Velagic	2009	2009 XXII International Symposium on Information, Communication and Automation Technologies	10.1109/ICAT.2009.5348428	simulation;operations management;business;commerce	Robotics	-0.9403402670415034	2.708972982259563	196572
8eb5e319601636d432f2bd5f6673931bf67a2710	superreplication in stochastic volatility models and optimal stopping	optimal stopping problem;stochastic volatility model;black scholes model;superreplication;incomplete markets;stochastic volatility;optimal stopping;value function;incomplete market	In this paper we discuss the superreplication of derivatives in a stochastic volatility model under the additional assumption that the volatility follows a bounded process. We characterize the value process of our superhedging strategy by an optimal-stopping problem in the context of the BlackScholes model which is similar to the optimal stopping problem that arises in the pricing of American-type derivatives. Our proof is based on probabilistic arguments. We study the minimality of these superhedging strategies and discuss PDE-characterizations of the value function of our superhedging strategy. We illustrate our approach by examples and simulations.	bellman equation;optimal stopping;simulation;volatility	Rüdiger Frey	2000	Finance and Stochastics	10.1007/s007800050010	financial economics;actuarial science;optimal stopping;economics;volatility smile;superhedging price;mathematical economics;stochastic volatility;sabr volatility model;incomplete markets	AI	0.9179091703931455	-2.484079082165471	196588
e7633e5229517a2406de0d78ec2f8256397f0f12	stochastic payoff-based learning in multi-agent systems modeled by means of potential games	convergence;multi agent systems;stochastic processes;games;linear programming;optimization;algorithm design and analysis	Game theory serves as a powerful tool for distributed optimization in multiagent systems in different applications. In this paper we consider multiagent systems that can be modeled as a potential game whose potential function coincides with a global objective function to be maximized. This approach renders the agents the strategic decision makers and the corresponding optimization problem the problem of learning a maximum of the potential function in the designed game. The paper deals with a payoff-based approach to such learning. Here, we assume that at each iteration agents can only observe their own played actions and experienced payoffs. To develop the corresponding algorithms guaranteeing convergence to a local maximum of the potential function, we utilize the idea of the well-known Robbins-Monro procedure based on the theory of stochastic approximation.	agent-based model;algorithm;converge;game theory;iteration;mathematical optimization;maxima and minima;multi-agent system;optimization problem;rendering (computer graphics);stochastic approximation;whole earth 'lectronic link	Tatiana Tatarenko	2016	2016 IEEE 55th Conference on Decision and Control (CDC)	10.1109/CDC.2016.7799081	games;algorithm design;mathematical optimization;simulation;convergence;computer science;linear programming;machine learning;repeated game;mathematics;stochastic game	AI	-2.201374767450366	1.613830041892144	197012
4da14e6d9d146331cd05b639cf8b01eeff62ebba	an extension of the consensus-based bundle algorithm for multi-agent tasks with task based requirements	uav;consensus;task analysis autonomous aerial vehicles multi agent systems;cbaa;cooperation;vectors algorithm design and analysis resource management receivers educational institutions computer science unmanned aerial vehicles;multi agent systems;cbba;consensus based grouping algorithm consensus based bundle algorithm task based requirement multiagent assignment multiagent requirement unmanned aerial vehicle;cooperation cbaa cbba cbga uav consensus task allocation;task analysis;cbga;autonomous aerial vehicles;task allocation	This paper addresses the problem of multi-agent, multi-task assignment with multiple agent requirements on tasks for unmanned aerial vehicles by presenting the Consensus Based Grouping Algorithm. The algorithm is an extension of the Consensus Based Bundle Algorithm that converges to a conflict free, feasible solution of which previous algorithms are unable to account for. Furthermore the algorithm creates a framework to take into account task based requirements, deadlocking and a method to store assignments for a dynamical environment.	aerial photography;algorithm;computer multitasking;multi-agent system;requirement;unmanned aerial vehicle	Simon Hunt;Qinggang Meng;Chris J. Hinde	2012	2012 11th International Conference on Machine Learning and Applications	10.1109/ICMLA.2012.163	real-time computing;simulation;consensus;computer science;multi-agent system;task analysis;distributed computing;cooperation	Robotics	-1.292125862519203	3.110550504985885	197099
287592e19cb7b8fa9c1b4c06d63a9e0a7d6175d6	welfare maximization and the supermodular degree	approximation algorithms;combinatorial auctions;submodular functions	Given a set of items and a collection of players, each with a nonnegative monotone valuation set function over the items, the welfare maximization problem requires that every item be allocated to exactly one player, and one wishes to maximize the sum of values obtained by the players, as computed by applying the respective valuation function to the bundle of items allocated to the player. This problem in its full generality is NP-hard, and moreover, at least as hard to approximate as set-packing. Better approximation guarantees are known for restricted classes of valuation functions.  In this work we introduce a new parameter, the supermodular degree of a valuation function, which is a measure for the extent to which the function exhibits supermodular behavior. We design an approximation algorithm for the welfare maximization problem whose approximation guarantee is linear in the supermodular degree of the underlying valuation functions.	approximation algorithm;entropy maximization;expectation–maximization algorithm;np-hardness;set packing;supermodular function;value (ethics);monotone	Uriel Feige;Rani Izsak	2013	Electronic Colloquium on Computational Complexity (ECCC)	10.1145/2422436.2422466	mathematical optimization;discrete mathematics;mathematics;welfare economics	ECom	-2.741090923495827	-1.116842367979067	198203
888ce366dc4b2b321af46b6476e44ef0c736524e	a bounded-risk mechanism for the kidney exchange game		In this paper we introduce and study the notion of low risk mechanisms. Intuitively, we say a mechanism is a low risk mechanism if the randomization of the mechanism does not effect the utility of agents by a lot. Specifically, we desire to design mechanisms in which the variance of the utility of agents are small. Inspired by our work, later, Procaccia et al. [13] study the approximation-variance tradeoffs in mechanism design. In particular here we present a low risk mechanism for the pairwise kidney exchange game. This game naturally appears in situations that some service providers benefit from pairwise allocations on a network, such as the kidney exchanges between hospitals. Ashlagi et al. [3] present a 2-approximation randomized truthful mechanism for this problem. This is the best known result in this setting with multiple players. However, we note that the variance of the utility of an agent in this mechanism may be as large as Ω(n),where n is the number of vertices. Indeed, this is not desirable in a real application. In this paper we resolve this issue by providing a 2-approximation randomized truthful mechanism in which the variance of the utility of each agent is at most 2 + . As a side result, we apply our technique to design a deterministic mechanism such that, if an agent deviates from the mechanism, she does not gain more than 2dlog2me, where m is the number of players.	approximation;randomized algorithm	Hossein Esfandiari;Guy Kortsarz	2016		10.1007/978-3-662-49529-2_31	discrete mathematics;service provider;mechanism design;vertex (geometry);randomization;mathematics;pairwise comparison;bounded function	ECom	-2.8128622843843694	0.13904379610554138	198476
c0ea16efb575126e64715a7bc23824346c43147c	exponential utility and ruin constraints	game theory;decision rule game theory ruin constraints buying price equation lotteries exponential utility probability repeated play utility parameter assessment axiom free motivation;game theory decision theory;decision theory;marine animals polynomials sociology statistics economics games	A buying price equation for lotteries identical to that implied by exponential utility is derived using a constraint on the probability of ruin for indefinitely repeated play. Applications explored are utility parameter assessment and the axiom-free motivation of a decision rule indistinguishable from maximizing expected exponential utility.	exponential utility	Paul Snow	1984	IEEE Transactions on Systems, Man, and Cybernetics	10.1109/TSMC.1984.6313298	game theory;minimax;mathematical optimization;optimal decision;decision theory;expected utility hypothesis;decision rule;cardinal utility;subjective expected utility;transferable utility;mathematical economics;von neumann–morgenstern utility theorem;statistics	Visualization	-4.2560362709959065	-1.3628406449118744	199323
f9742b45eadc0dc024fcc7f4f4333f4015c99e4a	a bayesian game to estimate the optimal initial resource demand for entrant virtual network operators				Abu Hena Al Muktadir;Ved P. Kafle;Pedro Martinez-Julia;Hiroaki Harai	2018	IEICE Transactions		operator (computer programming);virtual network;simultaneous game;complete information;bayesian game;computer science;distributed computing	Metrics	-3.6328715741344224	-2.5842034219186645	199622
9866f959e885250b98bcc5e0b8814340642097d5	clearing markets via bundles		We study algorithms for combinatorial market design proble ms, where a set of heterogeneous and indivisible objects are priced and sold to potential buyers su bject to equilibrium constraints. Extending the CWE notion introduced by Feldman et al. [STOC 2013], we intro duce the concept of a Market-Clearing Combinatorial Walrasian Equilibium(MC-CWE) as a natural relaxation of the classical Walrasian equilibrium (WE) solution concept. The only difference between a MC-CWE and a WE is the ability for the seller to bundle the items prior to sale. This innocuous a nd natural bundling operation imposes a plethora of algorithmic and economic challenges and opport unities. Unlike WE, which is guaranteed to exist only for (gross) substitutes valuations, a MC-CWE a lways exists. The main algorithmic challenge, therefore, is to design computationally efficient me chanisms that generate MC-CWE outcomes that approximately maximize social welfare. For a variety o f valuation classes encompassing substitutes and complements (including super-additive, single-minde d and budget-additive valuations), we design polynomial-time MC-CWE mechanisms that provide tight welf are approximation results.	algorithm;algorithmic efficiency;approximation;common weakness enumeration;linear programming relaxation;nash equilibrium;polynomial;symposium on theory of computing;time complexity;utility functions on indivisible goods;value (ethics)	Michal Feldman;Brendan Lucier	2014		10.1007/978-3-662-44803-8_14	economics;public economics;mathematics;microeconomics;mathematical economics;welfare economics;algorithm	ECom	-2.8090293648290836	-1.2185859414202047	199781
281b05e92e54654982cb668663e8ee1769a42b29	complexity of optimal lobbying in threshold aggregation	time complexity;optimal lobbying;threshold function	Optimal Lobbying is the problem a lobbyist or a campaign manager faces in a full-information voting scenario of a multiissue referendum when trying to influence the result. The Lobby is faced with a profile that specifies for each voter and each issue whether the voter approves or rejects the issue, and seeks to find the smallest set of voters it must influence to change their vote, for a desired outcome to be obtained. We study the computational complexity of Optimal Lobbying when the issues are aggregated using an anonymous monotone function and the family of desired outcomes is an upward-closed family. We analyze this problem with regard to two parameters: the minimal number of supporters needed to pass an issue, and the size of the maximal minterm of the desired set. We show that for extreme values of the parameters, the problem is tractable, and provide algorithms. On the other hand, we prove intractability of the problem for the complementary cases, which are most of the values of the parameters.	algorithm;cobham's thesis;computational complexity theory;maximal set;monotone	Ilan Nehama	2013		10.1007/978-3-319-23114-3_23	time complexity;computer science;mathematics;statistics	AI	-2.4143019995515447	0.5900843225052678	199997
