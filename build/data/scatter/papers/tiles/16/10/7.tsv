id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
7b784e91fa3672d531a9a2321b28522f88abb2d5	constrained multiobjective optimization algorithm based on immune system model	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;cloning;research articles;abstracts;heuristic algorithms;open access;immune system;life sciences;clinical guidelines;statistics;linear programming;optimization;full text;sociology;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	An immune optimization algorithm, based on the model of biological immune system, is proposed to solve multiobjective optimization problems with multimodal nonlinear constraints. First, the initial population is divided into feasible nondominated population and infeasible/dominated population. The feasible nondominated individuals focus on exploring the nondominated front through clone and hypermutation based on a proposed affinity design approach, while the infeasible/dominated individuals are exploited and improved via the simulated binary crossover and polynomial mutation operations. And then, to accelerate the convergence of the proposed algorithm, a transformation technique is applied to the combined population of the above two offspring populations. Finally, a crowded-comparison strategy is used to create the next generation population. In numerical experiments, a series of benchmark constrained multiobjective optimization problems are considered to evaluate the performance of the proposed algorithm and it is also compared to several state-of-art algorithms in terms of the inverted generational distance and hypervolume indicators. The results indicate that the new method achieves competitive performance and even statistically significant better results than previous algorithms do on most of the benchmark suite.	affinity analysis;algorithm;benchmark (computing);clone;converge;crossover (genetic algorithm);engineering design process;experiment;hl7publishingsubsection <operations>;immune system;mathematical optimization;multimodal imaging;multimodal interaction;mutation;nonlinear system;numerical analysis;optimization problem;pareto efficiency;polynomial;population;premature menopause;reliability engineering;simulation;solutions	Shuqu Qian;Yongqiang Ye;Bin Jiang;Jianhong Wang	2016	IEEE Transactions on Cybernetics	10.1109/TCYB.2015.2461651	mathematical optimization;text mining;immune system;computer science;bioinformatics;linear programming;artificial intelligence;machine learning;data mining;cloning;mathematics;statistics	EDA	25.128708840125203	-3.574755222291462	54236
7c94fed77b7379982e2d78fd50c4a0d1e2155900	improving proximity and diversity in multiobjective evolutionary algorithms	evolutionary algorithm;mutation;proximity;evolutionary algorithms;multiobjective optimization		evolutionary algorithm	Chang Wook Ahn;Yehoon Kim	2010	IEICE Transactions		evolutionary programming;mutation;mathematical optimization;computer science;multi-objective optimization;machine learning;evolutionary algorithm;distance;evolutionary computation	DB	25.279089382585838	-5.234903447626565	54303
d82224e96acdb07085e3fde6027ca3de55dfb225	coevolutionary algorithms for realization of intelligent systems	schema theorem;optimal method;building block hypothesis;simple genetic algorithm;natural selection;intelligent system;biological systems;evolutionary algorithm;co evolutionary algorithm;theoretical foundation;evolutionary system	Abstract Simple,Genetic,Algorithm(SGA) proposed,by,J. H. Holland,is,a,population-based optimization,method,based,on,the,principle,of,the,Darwinian,natural,selection. The theoretical foundations of GA are the Schema Theorem,and,the Building Block,Hypothesis. Although GA does well in many applications as an optimization method, still it does not guarantee the,convergence to,a,global optimum,in,some problems. In,designing,intelligent systems, specially, since there is no deterministic solution, a heuristic trial-and error procedure is usually used to determine the systems' parameters. As an alternative scheme, therefore, there is a growing interest in a co-evolutionary system, where two populations constantly,interact,and,co-evolve. In,this,paper,we,review,the,existing,co-evolutionary algorithms and,propose,co-evolutionary,schemes designing,intelligent systems,according,to the relation between the system's components. Ⅰ. Introduction,) The concept of natural selection has influenced our view,of biological systems	algorithm	Hyo-Byung Jun;Kwee-Bo Sim	1999	JACIII	10.20965/jaciii.1999.p0418	evolutionary programming;mathematical optimization;natural selection;genetic algorithm;interactive evolutionary computation;cultural algorithm;computer science;artificial intelligence;machine learning;evolutionary algorithm	Robotics	24.70570950137179	-7.936407206818966	54342
0a1b0c49cc4845ad9110ac939796f3432ef3312e	numerical improvement for the mechanical performance of bikes based on an intelligent pso-abc algorithm and wsn technology		This paper proposed a novel hybrid optimization algorithm, particle swarm optimization-artificial bee colony (PSO-ABC), based on the PSO and ABC algorithms. The ABC algorithm can offset defects in the PSO algorithm that easily fall into a local optimization; combining the algorithms can improve the optimization ability of the PSO algorithm to a certain extent. Therefore, this paper applied the PSO-ABC hybrid algorithm and the finite-element method to systematically optimize the mechanical performance of the disc rotor of a bike and verified the numerical computation model via the wireless sensor network technology. The experimental test was completed with wireless sensor network technologies. To verify the optimized effects of the proposed PSO-ABC hybrid algorithm after parameter selection, the algorithm was compared with the traditional PSO and ABC models. The PSO, ABC, and PSO-ABC models adopted the same population to conduct a multi-objective optimization for vibration accelerations of the disc rotor. Comparing the results from these models proved that the proposed PSO-ABC method is superior for the optimization of vibration characteristics of the disc rotors.	approximation algorithm;finite element method;genetic algorithm;hybrid algorithm;mathematical optimization;model of computation;multi-objective optimization;numerical analysis;particle swarm optimization;phase-shift oscillator;r.o.t.o.r.	Zidong Han;Yufeng Li;Jiuyang Liang	2018	IEEE Access	10.1109/ACCESS.2018.2845366	wireless sensor network;rotor (electric);local search (optimization);computation;hybrid algorithm;computer science;algorithm;offset (computer science);population;particle swarm optimization	EDA	27.92063836014293	-3.284468381802344	54443
d13e53738f6f2a06a15e532d822f3e36b5feed5e	many-objective evolutionary algorithm: objective space reduction and diversity improvement	convergence;evolutionary computation;pareto optimisation convergence;sociology statistics convergence optimization algorithm design and analysis evolutionary computation diversity methods;many objective evolutionary algorithms objective space reduction diversity improvement strategy many objective optimization problems;statistics;optimization;algorithm design and analysis;sociology;diversity methods;manyobjective evolutionary algorithm diversity performance improvement convergence performance improvement diversity improvement strategy true pareto front target points maop evolutionary operator fitness evaluation multiobjective optimization problems diversified approximate pareto optimal front converged approximate pareto optimal front objective space reduction	Evolutionary algorithms have been successfully applied for exploring both converged and diversified approximate Pareto-optimal fronts in multiobjective optimization problems, two- or three-objective in general. However, when solving problems with many objectives, nearly all algorithms perform poorly due to the loss of selection pressure in fitness evaluation. An extremely large objective space could inadvertently deteriorate the effect of an evolutionary operator. In this paper, we propose a new approach to directly handle the challenges to solve many-objective optimization problems (MaOPs). This novel design includes two stages: first, the whole population quickly approaches a small number of “target” points near the true Pareto front; then, the proposed diversity improvement strategy is applied to facilitate these individuals to spread and well distribute. As a case study, the proposed algorithm based on this design is compared with five state-of-the-art algorithms. Experimental results show that the proposed method exhibits improved performance in both convergence and diversity for solving MaOPs.	approximation algorithm;benchmark (computing);evolutionary algorithm;fitness function;internet gateway device protocol;mathematical optimization;multi-objective optimization;pareto efficiency	Zhenan He;Gary G. Yen	2016	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2015.2433266	algorithm design;mathematical optimization;convergence;interactive evolutionary computation;computer science;multi-objective optimization;machine learning;mathematics;management science;statistics;evolutionary computation	AI	25.296587146350618	-3.985266825193647	54630
4905568203ee222037d5911e4053d12a99e7187a	recorded step directional mutation for faster convergence	fitness landscape;optimisation;high dimensionality;algorithm analysis;optimizacion;evolutionary programming;stochastic convergence;algoritmo genetico;convergence stochastique;science learning;convergencia estocastica;adaptive method;algorithme genetique;algorithme evolutionniste;genetic algorithm;optimization;analyse algorithme;evolutionary algorithm;evolutionary optimization;analisis algoritmo;covariance matrix;evolutionary computing	Two meta-evolutionary optimization strategies described in this paper accelerate the convergence of evolutionary programming algorithms while still retaining much of their ability to deal with multi-modal problems. The strategies , called directional mutation and recorded step in this paper, can operate independently but together they greatly enhance the ability of evolutionary programming algorithms to deal with fitness landscapes characterized by long narrow valleys. The directional mutation aspect of this combined method uses correlated meta-mutation but does not introduce a full covari-ance matrix. These new methods are thus much more economical in terms of storage for problems with high dimensionality. Additionally, directional mutation is rotationally invariant which is a substantial advantage over self-adaptive methods which use a single variance per coordinate for problems where the natural orientation of the problem is not oriented along the axes. Step-recording is a subtle variation on conventional meta-mutational algorithms which allows desirable meta-mutations to be introduced quickly. Directional mutation, on the other hand, has analogies with conjugate gradient techniques in deterministic optimization algorithms. Together, these methods substantially improve performance on certain classes of problems, without incurring much in the way of cost on problems where they do not provide much benefit. Somewhat surprisingly their effect when applied separately is not consistent. This paper examines the performance of these new methods on several standard problems taken from the literature. These new methods are directly compared to more conventional evolutionary algorithms. A new test problem is also introduced to highlight the difficulties inherent with long narrow valleys.	conjugate gradient method;evolutionary algorithm;evolutionary programming;mathematical optimization;modal logic	Ted Dunning	1998		10.1007/BFb0040808	evolutionary programming;covariance matrix;mathematical optimization;genetic algorithm;fitness landscape;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;algorithm	AI	29.010883611539203	-0.05536034881098214	54933
d4508259a9c246707dfd5f47b7368069ab5c132c	an image encryption algorithm for new multiple chaos-based	circular shift algorithm;dynamical multiple chaos;image encryption	An image encryption scheme based on high-dimensional dynamical multiple chaotic maps are proposed in this paper. In order to produce fast encryption and more avalanche effect, the circular shift algorithm is utilized to permute the positions of the image pixels in the spatial domain. The experimental results show that it is more efficient than traditional encryption schemes and it provides an secure way for image encryption.	algorithm;avalanche effect;circular shift;encryption;map;pixel	Xiaojun Tong;Yang Liu	2011		10.1007/978-3-642-23357-9_17	multiple encryption;discrete mathematics;watermarking attack;disk encryption theory;40-bit encryption;plaintext-aware encryption;theoretical computer science;mathematics;distributed computing;deterministic encryption;probabilistic encryption	Vision	38.69919954850725	-8.666321644866686	55040
fadd8a197b974294c8d9dfeb1057be21b9ef88ac	does crossover probability depend on fitness and hamming differences in genetic algorithms?	algoritmo busqueda;algorithme recherche;search algorithm;algoritmo genetico;hamming distance;distance hamming;algorithme genetique;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;evolutionary algorithm;reseau neuronal;red neuronal;distancia hamming;genetic similarity;neural network	The goal of this paper is to study if there is a dependency between the probability of crossover with the genetic similarity (in terms of hamming distance) and the fitness difference between two individuals. In order to see the relation between these parameters, we will find a neural network that simulates the behavior of the probability of crossover with these differences as inputs. An evolutionary algorithm will be used, the goodness of every network being determined by a genetic algorithm that optimizes a well-known function.	genetic algorithm;window function	José Luis Fernández-Villacañas Martín;Mónica Sierra Sánchez	2002		10.1007/3-540-46084-5_63	crossover;hamming distance;genetic algorithm;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;artificial neural network;algorithm;search algorithm	AI	26.92334085769373	-9.780486454205064	55107
c8a7777131e63d981d1d02ac33ae5162d2548030	island model cooperating with speciation for multimodal optimization	algoritmo paralelo;parallel algorithm;algorithm performance;algoritmo genetico;operateur evolution;algorithme parallele;resolucion problema;resultado algoritmo;performance algorithme;algorithme genetique;evolution operator;genetic algorithm;optimisation fonction;operador evolucion;problem solving;resolution probleme	"""This paper considers a new method that enables a genetic algorithm (GA) to identify and maintain multiple optima of a multi-modal function, by creating subpopulations within the niches deened by the multiple optima, thus warranting a good \diversity"""". The algorithm is based on a splitting of the traditional GA into a sequence of two processes. Since the GA behavior is determined by the exploration / exploitation balance, during the rst step (Exploration), the multipop-ulation genetic algorithm coupled with a speciation method detects the potential niches by classifying \similar"""" individuals in the same population. Once the niches are detected, the algorithm achieves an inten-siication (Exploitation), by allocating a separate portion of the search space to each population. These two steps are alternately performed at a given frequency. Empirical results obtained with F6 Schaaer's function are then presented to show the reliability of the algorithm."""	evolutionary multimodal optimization;exploit (computer security);genetic algorithm;modal logic;multimodal interaction	Mourad Bessaou;Alain Pétrowski;Patrick Siarry	2000		10.1007/3-540-45356-3_43	genetic algorithm;computer science;artificial intelligence;parallel algorithm;algorithm	ML	26.790442949916567	1.2691598530024004	55589
788bed87207df0f6bc491a103925aea50da001e8	lukasiewicz fuzzy logic networks and their ultra low power hardware implementation	ultra low power;fuzzy set;neural networks;current mode;fuzzy sets;fuzzy logic;logic neurons;ultra low power electronics;hardware implementation;cmos analog devices;neural network	Abstract. In this paper, we propose a new category of current-mode Łukasiewicz OR and AND logic neurons and logic networks and show their ultra low power realization. The introduced circuits can operate with very low input signals that set up the operating point of transistors in the subthreshold region. In this region, the mismatch between transistors has much stronger impact on the current mirror gain than in the strong inversion region. The proposed solution minimizes this problem by reducing the number of current mirrors between the input and output of the neuron to only one.	current mirror;fuzzy logic;input/output;neuron;operating point;transistor;łukasiewicz logic	Rafal Dlugosz;Witold Pedrycz	2009	Neurocomputing	10.1016/j.neucom.2009.11.027	fuzzy electronics;computer science;machine learning;pass transistor logic;control theory;mathematics;fuzzy set;artificial neural network	EDA	38.65740720680691	-2.609220885973918	55647
24ac0faa7562ab716847352a21a8efe21be163e4	bacterial foraging algorithm for dynamic environments	performance evaluation bacterial foraging algorithm dynamic environments static optimization problems searching ability evolutionary algorithms static optimization problems;optimisation;evolutionary computation;search problems evolutionary computation optimisation;test bed;optimization problem;dynamic environment;simulation study;search problems;evolutionary algorithm;environmental change;microorganisms heuristic algorithms convergence diversity reception evolutionary computation algorithm design and analysis design optimization biology testing computational modeling	Optimization in dynamic environments has received great attention in recent years [1]. Different from static optimization problems, its convergence and searching ability is cautiously desired. Over the last two decades, evolutionary algorithms (EAs), designed to solve the static optimization problems, have been comprehensively and intensively investigated. In recent years, as the emergence of another member of the EA family -bacterial foraging algorithm (BFA), the self-adaptability of individuals in the group searching activities has attracted a great deal of interests. In this paper, a BFA aiming for optimization in dynamic environments, called DBFA, is studied. A test bed proposed previously in [2] is adopted to evaluate the performance of DBFA. The simulation studies offer a range of changes in a dynamic environment. The simulation results show that DBFA can adapt to various environmental changes which occur in different probabilities, with both satisfactory accuracy and stability, in comparison with a recent work on bacterial foraging [3].	emergence;evolutionary algorithm;mathematical optimization;simulation;testbed	W. J. Tang;Q. Henry Wu;J. R. Saunders	2006	2006 IEEE International Conference on Evolutionary Computation	10.1109/CEC.2006.1688462	optimization problem;mathematical optimization;simulation;environmental change;computer science;artificial intelligence;machine learning;evolutionary algorithm;imperialist competitive algorithm;evolutionary computation;testbed	Robotics	26.099506602050784	-5.427874412647283	55876
78eb4de91c2769ba1366f488a7292c91e5c66b8b	evolutionary algorithms to optimize low-thrust trajectory design in spacecraft orbital precession mission		In space environment, perturbations make the spacecraft lose its predefined orbit in space. One of these undesirable changes is the in-plane rotation of space orbit, denominated as orbital precession. To overcome this problem, one option is to correct the orbit direction by employing low-thrust trajectories. However, in addition to the orbital perturbation acting on the spacecraft, a number of parameters related to the spacecraft and its propulsion system must be optimized. This article lays out the trajectory optimization of orbital precession missions using Evolutionary Algorithms (EAs). In this research, the dynamics of spacecraft in the presence of orbital perturbation is modeled. The optimization approach is employed based on the parametrization of the problem according to the space mission. Numerous space mission cases have been studied in low and middle Earth orbits, where various types of orbital perturbations are acted on spacecraft. Consequently, several EAs are employed to solve the optimization problem. Results demonstrate the practicality of different EAs, along with comparing their convergence rates. With a unique trajectory model, EAs prove to be an efficient, reliable and versatile optimization solution, capable of being implemented in conceptual and preliminary design of spacecraft for orbital precession missions.	cluster analysis;evolutionary algorithm;heuristic (computer science);mathematical optimization;molecular orbital;optimization problem;orbital magnetization;perturbation theory (quantum mechanics);phase-shift oscillator;population;software release life cycle;thrust;trajectory optimization	Abolfazl Shirazi;Josu Ceberio;José Antonio Lozano	2017	2017 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2017.7969517	computer science;space environment;mathematical optimization;orbit;trajectory optimization;orbital mechanics;orbital maneuver;spacecraft;perturbation (astronomy);frozen orbit	Robotics	28.712577046369763	-3.8409194200899495	56025
ce85b27c7974909749577e510299e594d3d891a5	on the analysis of the (1+1) evolutionary algorithm with short-term memory	short term memory;evolutionary computation;boolean functions;randomised algorithms;pseudo boolean functions 1 1 evolutionary algorithm short term memory randomized local search algorithm;1 1 evolutionary algorithm;randomized local search algorithm;pseudo boolean functions;search problems boolean functions evolutionary computation randomised algorithms;search problems;evolutionary algorithm;pseudo boolean;local search;random search	Given any randomized search algorithm, we can avoid re-evaluating the fitness of previously visited points by storing the information in memory. This idea is applied to the (1+1) evolutionary algorithm with standard mutation and the randomized local search (RLS) algorithm. Our analysis shows that a large reduction in running time can be obtained if we store recently visited points and execute those algorithms on some pseudo-boolean functions. Besides, the stored information can also be used to affect the generation of new search points. We illustrate this idea by designing an algorithm called progressive randomized local search. In contrary to RLS, it is capable of escaping from local maxima.	evolutionary algorithm;like button;local search (optimization);long short-term memory;maxima and minima;pseudo-boolean function;randomized algorithm;recursive least squares filter;search algorithm;time complexity;universal quantification	Chi Wan Sung;Shiu Yin Yuen	2008	2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)	10.1109/CEC.2008.4630805	beam search;mathematical optimization;random search;cultural algorithm;computer science;local search;machine learning;evolutionary algorithm;jump search;mathematics;short-term memory;best-first search;boolean function;algorithm;difference-map algorithm;guided local search;evolutionary computation;binary search algorithm;search algorithm	Vision	27.82898443383813	-0.5743386184597408	56301
91f3091bbc24f31ece271d70fa51221d40b5e94f	a hybrid artificial bee colony optimization and quantum evolutionary algorithm for continuous optimization problems	artificial bee colony;premature;quantum evolutionary algorithm qea;q bit chromosome;continuous optimization;artificial bee colony abc;evolutionary algorithm;genetic algorithm ga	In this paper, a novel hybrid Artificial Bee Colony (ABC) and Quantum Evolutionary Algorithm (QEA) is proposed for solving continuous optimization problems. ABC is adopted to increase the local search capacity as well as the randomness of the populations. In this way, the improved QEA can jump out of the premature convergence and find the optimal value. To show the performance of our proposed hybrid QEA with ABC, a number of experiments are carried out on a set of well-known Benchmark continuous optimization problems and the related results are compared with two other QEAs: the QEA with classical crossover operation, and the QEA with 2-crossover strategy. The experimental comparison results demonstrate that the proposed hybrid ABC and QEA approach is feasible and effective in solving complex continuous optimization problems.	artificial bee colony algorithm;bees algorithm;benchmark (computing);colony collapse disorder;continuous optimization;entity name part qualifier - adopted;evolutionary algorithm;experiment;local search (optimization);mathematical optimization;optimization problem;population;premature convergence;program optimization;quantum;randomness	Hai-Bin Duan;Chun-Fang Xu;Zhi-Hui Xing	2010	International journal of neural systems	10.1142/S012906571000222X	mathematical optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm;continuous optimization;artificial bee colony algorithm	AI	26.595989747582408	-4.515609809002548	56381
69bb6dc2ddf88332f03b5046c3318ff59372cc3c	comprehensive learning particle swarm optimizer with guidance vector selection	vectors particle swarm optimization sociology statistics optimization search problems equations;cec 2005 benchmark problems;clpso;guidance vector selection clpso;candidate guidance vector;shifted optimization problem comprehensive learning particle swarm optimizer guidance vector selection clpso particle velocity particle position candidate guidance positions candidate guidance vector cec 2005 benchmark problems rotated optimization problem;vectors;comprehensive learning particle swarm optimizer;guidance vector selection;particle swarm optimization;particle velocity;statistics;rotated optimization problem;optimization;search problems;candidate guidance positions;vectors benchmark testing particle swarm optimisation;particle swarm optimisation;particle position;sociology;benchmark testing;shifted optimization problem	In this paper, comprehensive learning particle swarm optimizer (CLPSO) is integrated with guidance vector selection. To update a particle's velocity and position, several candidate guidance positions are constructed based on all particles' best positions. Then the candidate guidance vector with the best fitness is selected to guide the particle. Simulation study is performed on CEC 2005 benchmark problems and the results show that the CLPSO with guidance vector selection has better performance when solving shifted and rotated optimization problems.	benchmark (computing);mathematical optimization;particle swarm optimization;simulation;velocity (software development)	Nandar Lynn;Ponnuthurai Nagaratnam Suganthan	2013	2013 IEEE Symposium on Swarm Intelligence (SIS)	10.1109/SIS.2013.6615162	mathematical optimization;simulation;engineering;machine learning;particle swarm optimization	Embedded	27.817141853761708	-4.57028681378918	56673
6bbe9afc09ffc632e9d56830388d015a3ed34c46	extremal optimisation and bin packing	bin packing problem;assignment problem;bin packing;bepress selected works;extremal optimisation optimisation techniques bin packing problem;swinburne;extremal optimisation;optimisation techniques	Extremal Optimisation (EO) is a fairly new entrant into the realms of stochastic based optimisation techniques. Its behaviour differs from other more common algorithms as it alters a poorly performing part of the one solution used without regard to the effect this will have on the quality of the solution. While this means that its performance on assignment problems may be poor if used on its own, this same `failing' makes it a very suitable base for a meta-heuristic. An analysis of the performance of naive EO on the classic bin packing problem is performed in this paper. Results are also presented that show that the same naive EO can be used in a meta-heuristic that performs very well.	bin packing problem;mathematical optimization;set packing	Tim Hendtlass;Marcus Randall	2008		10.1007/978-3-540-89694-4_23	mathematical optimization;combinatorics;bin packing problem;computer science;mathematics	Vision	28.060848464747572	3.452900287112424	56897
587c1d5a73015331bb4382faa22e073ea77135d3	selection mechanisms in evolutionary algorithms	couple selection;selection methods;interaction of operators;evolutionary algorithm	The selection operator is one of the main operators in evolutionary algorithms. It interacts with other operators (e.g., crossover, mutation) in a complex way. Consequently, the effects of selection should be considered also together with these operators. This paper provides an overview of several presently used selection operators and discusses a new selection operator specifically devised to assist MCPC, an exploitation-oriented multiple crossover per couple approach, to overcome premature convergence. Some experimental results are also provided.	evolutionary algorithm	Susana C. Esquivel;Héctor A. Leiva;Raúl Héctor Gallard	1998	Fundam. Inform.	10.3233/FI-1998-35123402	truncation selection;mathematical optimization;genetic algorithm;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics	AI	25.376740174538938	-4.685634877654675	57130
1e27fe633a15fba78bba2b470561552cc1ae83dc	multi-criteria analysis of wastewater treatment plant design and control scenarios under uncertainty	cascade controller;activated sludge model;multi criteria assessment;oxygen;simulation;anoxic volume;multi criteria analysis;wastewater;closed loop control;process design;bsm2;activated sludge;wastewater treatment plant;digestion;sludges;uncertainty analysis;technology and engineering;monitoring;linear process;scenario analysis;quality;environment;model;optimal design;anaerobic digestion;evaluation;waste treatment;analysis;point of view;monte carlo;monte carlo simulation;simulation model;models;assessment;wastewater treatment;water treatment;activated sludge models;anaerobic treatment;simulation models;multi criteria evaluation	Wastewater treatment plant control and monitoring can help to achieve good effluent quality, in a complex, highly non-linear process. The Benchmark Simulation Model no. 2 (BSM2) is a useful tool to competitively evaluate plant-wide control on a long-term basis. A method to conduct scenario analysis of process designs by means of Monte Carlo (MC) simulations and multi-criteria evaluation is presented. It is applied to the open loop version of BSM2 and to two closed loop versions, one with a simple oxygen controller and the other one with an ammonium controller regulating the set-point of the oxygen controller (cascade controller). The results show a much greater benefit of the cascade controller compared to the simple controller, both in environmental and economic terms. From an optimal process design point of view, the results show that the volume of the primary clarifier and the anoxic fraction of the reactor volume have an important impact on process performance. The uncertainty analysis of the optimal designs, also performed with MC simulations, highlights the improved and more stable effluent under closed loop control.		Lorenzo Benedetti;Bernard De Baets;Ingmar Nopens;Peter A. Vanrolleghem	2010	Environmental Modelling and Software	10.1016/j.envsoft.2009.06.003	environmental engineering;engineering;operations management;simulation modeling;water treatment;mathematics;waste management;statistics;monte carlo method	Robotics	36.19699596761121	-4.569394387249857	57245
4f1f5c7dfdae914115eb9ed2a05311eebf13003f	automotive magnetorheological dampers: modelling and parameter identification using contrast-based fruit fly optimisation		The present study discusses the mechanical behaviour and modelling of a prototype automotive magnetorheological (MR) damper, which presents different viscous damping coefficients in jounce and rebound. The force generated by the MR damper is measured at different velocities and electrical currents, and a modified damper model is proposed to improve fitting of the experimental data. The model is calibrated by means of parameter identification, and for this purpose a new swarm intelligence algorithm is proposed, that we call the contrast-based Fruit Fly Optimisation Algorithm (c-FOA). The performance of c-FOA is compared with that of Genetic Algorithms, Particle Swarm Optimisation, Differential Evolution and Artificial Bee Colony. The comparison is made on the basis of no a-priori knowledge of the damper model parameters range. The results confirm the good performance of c-FOA under parametric range uncertainty. A sensitivity analysis discusses c-FOA’s performance with respect to its tuning parameters. Finally, a ride comfort simulation study quantifies the discrepancies in the results, for different identified damper model sets. The discrepancies underline the importance of accurately describing MR damper nonlinear behaviour, considering that virtual sign-off processes are increasingly gaining momentum in the automotive industry.	mathematical optimization	Stratis Kanarachos;Dzmitry Savitski;Nikos D. Lagaros;Michael Fitzpatrick	2018	Soft Comput.	10.1007/s00500-017-2757-6	swarm intelligence;experimental data;damper;parametric statistics;computer science;system identification;magnetorheological fluid;control theory;jounce;particle swarm optimization	Robotics	31.875424632776323	-7.28306066362788	57458
07255ccbb451b03b7d8e65c9ac234a6aa26a5c9a	effects of simulated annealing strategy on swarm intelligence algorithm		Swarm intelligence algorithm (SI) is a kind of stochastic search algorithm based on swarm. Similar to other evolutionary algorithm, when solving the complicated multimodal problem using SI, it is easy to have premature convergence. So, to promote the optimization of swarm intelligence algorithm, the typical algorithm (Particle swarm optimizer) of swarm intelligence algorithm is selected to explore some strategies how to improve the performance. In this paper, we explore the follow research: firstly, the mutation operation is introduced to produce new learn example for each individual in itself evolution process; secondly, in the view of the idea of simulated annealing, the range strategy of fitness of each individual is proposed; finally, to make best use of each individual information, the comprehensive learning strategy is adopted to improve each individual evolution mechanism.	algorithm;simulated annealing;swarm intelligence	Yanmin Liu;Chengqi Li;Qingyu Zeng;Zhuanzhou Zhang;Rui Liu;Tao Huang	2016		10.1007/978-3-319-42291-6_66	adaptive simulated annealing	AI	26.293742327432113	-4.105326531836117	57522
df876311d666e4b903eb3d28959867798a08c173	neutral variations cause bloat in linear gp	evolutionary computation;calcul evolutionniste;genetic programming;programacion lineal;programmation genetique;linear programming;programmation lineaire;algorithme evolutionniste;algoritmo evolucionista;evolutionary algorithm;variation neuronale	In this contribution we investigate the influence of different variation effects on the growth of code. A mutation-based variant of linear GP is applied that operates with minimum structural step sizes. Results show that neutral variations are a direct cause for (and not only a result of) the emergence and the growth of intron code. The influence of non-neutral variations has been found to be considerably smaller. Neutral variations turned out to be beneficial by solving two classification problems more successfully.	blue (queue management algorithm);calculus of variations;emergence;imperative programming;mutation (genetic algorithm);software bloat;test case	Markus Brameier;Wolfgang Banzhaf	2003		10.1007/3-540-36599-0_26	genetic programming;mathematical optimization;computer science;linear programming;artificial intelligence;machine learning;evolutionary algorithm;mathematics;algorithm;evolutionary computation	PL	24.862066508794978	-8.521143700277124	57674
9392f1e5e7161c2e47bb6421ddba89fbe37c4de8	adaptive sizing of populations and number of islands in distributed genetic algorithms	adaptive genetic algorithm;population size;population sizing;internet computing;adaptation;distributed genetic algorithm;genetic algorithm;genetic algorithms	Deciding the appropriate population size and number of islands for distributed island-model genetic algorithms is often critical to the algorithm's success. This paper outlines a method that automatically searches for good combinations of island population sizes and the number of islands. The method is based on a race between competing parameter sets, and collaborative seeding of new parameter sets. This method is applicable to any problem, and makes distributed genetic algorithms easier to use by reducing the number of user-set parameters. The experimental results show that the proposed method robustly and reliably finds population and islands settings that are comparable to those found with traditional trial-and-error approaches.	genetic algorithm;population	Johan Berntsson;Maolin Tang	2005		10.1145/1068009.1068266	quality control and genetic algorithms;mathematical optimization;genetic algorithm;cultural algorithm;computer science;bioinformatics;genetic representation;algorithm;population-based incremental learning	AI	26.070318859387406	-6.660834657891949	57814
ef4be1e6cf6a7751267c128e5895de54e0d63c51	finding robust solutions to dynamic optimization problems	evolutionary dynamic optimization;population based search algorithms;robust optimization over time	Most research in evolutionary dynamic optimization is based on the assumption that the primary goal in solving Dynamic Optimization Problems (DOPs) is Tracking Moving Optimum (TMO). Yet, TMO is impractical in cases where keeping changing solutions in use is impossible. To solve DOPs more practically, a new formulation of DOPs was proposed recently, which is referred to as Robust Optimization Over Time (ROOT). In ROOT, the aim is to find solutions whose fitnesses are robust to future environmental changes. In this paper, we point out the inappropriateness of existing robustness definitions used in ROOT, and therefore propose two improved versions, namely survival time and average fitness. Two corresponding metrics are also developed, based on which survival time and average fitness are optimized respectively using population-based algorithms. Experimental results on benchmark problems demonstrate the advantages of our metrics over existing ones on robustness definitions survival time and average fitness.	algorithm;benchmark (computing);computer performance;mathematical optimization;optimization problem;optimizing compiler;population;program optimization;root;robust optimization;search algorithm;simulation	Haobo Fu;Bernhard Sendhoff;Ke Tang;Xin Yao	2013		10.1007/978-3-642-37192-9_62	control engineering;mathematical optimization;simulation;engineering	AI	25.567112296625982	-4.519085755867419	57860
520ab7baf12eac3e3954ac3a5dc638b3293f86bc	a digital fuzzy-logic controller with a simple architecture	centroid method;probabilistic logic cmos logic circuits controllers digital control fuzzy control inference mechanisms;cmos technology;1 5 micron;controller architecture;fuzzy control;digital fuzzy logic controller;inference mechanisms;fuzzy logic controller;cmosfet logic devices;cmos logic circuits;controllers;digital control fuzzy control cmos logic circuits prototypes fuzzy logic input variables cmos technology control systems bismuth fuzzy sets;1 5 micron digital fuzzy logic controller stochastic logic defuzzification process cmos technology controller architecture centroid method;digital control;probabilistic logic;defuzzification process;stochastic logic	A digital implementation of a fuzzy-logic controller is presented. The controller uses stochastic logic to implement the operations involved in the defuzzification process. A proper selection of the different parts of the controller and the use of stochastic logic leads to a very simple architecture. A prototype is being designed using a 1.5 /spl mu/m CMOS technology. In spite of its simple architecture, the proposed controller achieves more than 100000 FLIPs. >	fuzzy control system;fuzzy logic	Francisco Colodro Ruiz;Antonio Torralba;Leopoldo García Franquelo	1994		10.1109/ISCAS.1994.408915	control engineering;open-loop controller;electronic engineering;digital control;computer science;control theory;mathematics;probabilistic logic;cmos;fuzzy control system	Arch	38.795928153956886	-3.002369223072311	57877
30d30d5988d3f2ed380a9b9be9975c0e6ad1a196	using fuzzy logic controller in ant colony optimization		The new modification of ant colony optimization has been proposed to solve travelling salesman problem. This modification is based on using fuzzy rules and fuzzy terms like «a little», «much», «almost» etc. Fuzzy logic controller was developed to define fuzzy rules. This controller allows to regulate values of heuristic coefficients of ant colony optimization dynamically. Experimental research was carried out. The results received show high effectiveness of fuzzy logic controller using in ant colony optimization. The modified ant colony optimization algorithm finds shorter routes on 1-3%. This modification can be used to solve other problems.		Victor M. Kureichik;Asker Kazharov	2015		10.1007/978-3-319-18476-0_16	ant colony optimization algorithms	Logic	25.621688720805704	-6.501164951663015	58018
40421b20702aac2cc1ba94d690f8bf431350acf0	towards the evolutionary process algebra	algebra cognition cognitive science humans artificial intelligence psychology problem solving information processing intelligent sensors machine intelligence;search space;process algebra genetic algorithms markov processes;probability density function;population size;schemata theory;data mining;statistical models;statistical model;time domain analysis;metaheuristic techniques;algebra;markovian process algebra;genetic algorithm;genetic algorithms;markov processes;probabilistic logic;evolutionary process;process algebra;gallium;markov chains;evolutionary process algebra;markovian process algebra evolutionary process algebra genetic algorithms metaheuristic techniques schemata theory statistical models markov chains	Genetic Algorithms, GA's are metaheuristic techniques that have obtained good results in problems in which exhaustive techniques fail due to the size of the search space. GA's [1], [2] have been widely used to solve problems in the fields of combinatorial and numerical optimization.	genetic algorithm;mathematical optimization;metaheuristic;numerical analysis;software release life cycle	Fernando López Pelayo;Luis de la Ossa;Fernando Cuartero;Maria L. Pelayo;Juan Luis García Guirao	2009	2009 8th IEEE International Conference on Cognitive Informatics	10.1109/COGINF.2009.5250810	combinatorics;parallel metaheuristic;theoretical computer science;machine learning;mathematics	Robotics	28.029113926027826	-8.872094508860977	58232
42f17d2e3bdcc161d85954adc4e8e6eabf5ad107	research on qos service composition based on coevolutionary genetic algorithm		Traditional genetic algorithms overemphasize the struggle for survival and neglect all other aspects of biology. In addition, binary encoding is widely used in individual coding. Since the individual chromosomes produced are longer in length, it is difficult to ensure the efficiency of the algorithm. In this study, a coevolutionary genetic algorithm is proposed for web service composition based on quality of service (QoS), which fully considers the individual relationships among populations. The real coding method is adopted to solve the service selection problem based on QoS, so that the negative effect of the long length of chromosomes in the algorithm is avoided. Moreover, in view of the difficulty of determining the weight of each QoS attribute in web services, we propose to use the entropy method to determine the weights of each one. Compared with the traditional genetic algorithm, the experimental results show that the proposed algorithm converges faster in the service composition, and the fitness of the optimal solution is higher.		Yuanzhang Li;Jingjing Hu;Zhuozhuo Wu;Chen Liu;Feifei Peng;Yu Zhang	2018	Soft Comput.	10.1007/s00500-018-3510-5	machine learning;genetic algorithm;theoretical computer science;web service;artificial intelligence;quality of service;computer science;binary number;composition (visual arts)	Embedded	27.50078357370175	-9.443958619572907	58333
ec5c2fa34dabf20d3bb8d0cda5938b7f7ca98ae9	escaping local optima using crossover with emergent diversity		Population diversity is essential for avoiding premature convergence in genetic algorithms (GAs) and for the effective use of crossover. Yet the dynamics of how diversity emerges in populations are not well understood. We use rigorous runtime analysis to gain insight into population dynamics and GA performance for the ( ${\mu +1}$ ) GA and the Jump test function. We show that the interplay of crossover followed by mutation may serve as a catalyst leading to a sudden burst of diversity. This leads to significant improvements of the expected optimization time compared to mutation-only algorithms like the (1 + 1) evolutionary algorithm. Moreover, increasing the mutation rate by an arbitrarily small constant factor can facilitate the generation of diversity, leading to even larger speedups. Experiments were conducted to complement our theoretical findings and further highlight the benefits of crossover on the function class.		Duc-Cuong Dang;Tobias Friedrich;Timo K&#x00F6;tzing;Martin S. Krejca;Per Kristian Lehre;Pietro Simone Oliveto;Dirk Sudholt;Andrew M. Sutton	2018	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2017.2724201	mathematics;local optimum;genetic algorithm;mathematical optimization;mutation rate;evolutionary algorithm;crossover;test functions for optimization;population;premature convergence	ML	25.489198754922093	-8.419821370730281	58350
2928cc2b0d0d86505da2c349c0e6e8221da36ebc	fuzzy clustering based genetic algorithm for the multi-depot polygon visiting dubins multiple traveling salesman problem		A genetic algorithm (GA) and Fuzzy Logic System (FLS) based approach to the path representation of a variant of the Traveling Salesman Problem (TSP), the Multi-Depot Polygon Visiting Dubins Multiple Traveling Salesman Problem (MDPVDMTSP) is presented. Utilizing a hybridization of control techniques, this work effectively and efficiently approximates path planning and visbility problems encountered by a UAV swarm in the constant altitude, constant velocity, two-dimensional case. Benchmarking capabilities only exist for a 20 polygon PVDTSP case (1 UAV), but for this case a 9.8% increase in accuracy along with an order of magnitude decrease in run-time was found compared to the alternative method, despite utilizing a slower computer and programming language. Over 100 runs, the best solution was found 99% of the times, with a 1% chance of settling to a local minima. Comparison opportunities for MDPVDMTSP’s are currently not present, but the algorithms work similarly well for this scenario. MDPVDMTSP’s with 250 polygons, 20 UAV’s, and 4 different depots can be accurately approximated in under 30 seconds on the same machine. Being a combination of approximate methods, a decrease in run-time was expected, however the accuracy of this work shows great future promise for more complex variants of this problem.	fuzzy clustering;genetic algorithm;travelling salesman problem	Nicholas Ernest;Kelly Cohen	2012		10.2514/6.2012-2562	2-opt;mathematical optimization;combinatorics;machine learning;mathematics;bottleneck traveling salesman problem	EDA	25.53266268832794	-0.5397409071200301	58547
4c80be992ce7755ddb5a884f24680e62079c0bbf	continuous space pattern reduction for genetic clustering algorithm	cluster algorithm;k means;combinatorial optimization problem;genetics;data clustering;clustering;pattern reduction;genetic algorithm	We have recently proposed a highly effective method for speeding up metaheuristics in solving combinatorial optimization problems called pattern reduction (PR). It is, however, limited to problems with solutions that are either binary or integer encoded. In this paper, we proposed a new pattern reduction algorithm named continuous space pattern reduction (CSPR) to overcome this limitation. Simulations show that the proposed algorithm can significantly reduce the computation time of k-means with genetic algorithm (KGA) for solving the data clustering problem using continuous encoding.	cluster analysis;combinatorial optimization;computation;computer simulation;effective method;genetic algorithm;k-means clustering;mathematical optimization;metaheuristic;time complexity	Chun-Wei Tsai;Tzu-Yuan Lin;Ming-Chao Chiang;Chu-Sing Yang;Tzung-Pei Hong	2012		10.1145/2330784.2330998	correlation clustering;mathematical optimization;data stream clustering;canopy clustering algorithm;machine learning;cure data clustering algorithm;mathematics;fsa-red algorithm;cluster analysis;algorithm;population-based incremental learning	AI	26.400626851369704	-2.575362169039772	58744
ee93b6b6085f90af08c09d6ea87f54daa652014b	a cooperative coevolutionary biogeography-based optimizer	biogeography based optimization bbo;decomposition;cooperation;coevolution;context vector	With its unique migration operator and mutation operator, Biogeography-Based Optimization (BBO), which simulates migration of species in natural biogeography, is different from existing evolutionary algorithms, but it has shortcomings such as poor convergence precision and slow convergence speed when it is applied to solve complex optimization problems. Therefore, we put forward a Cooperative Coevolutionary Biogeography-Based Optimizer (CBBO) in this paper. In CBBO, the whole population is divided into multiple sub-populations first, and then each subpopulation is evolved with an improved BBO separately. The fitness evaluation of habitats of a subpopulation is conducted by constructing context vectors with selected habitats from other sub-populations. Our CBBO tests are based on 13 benchmark functions and are also compared with several other evolutionary algorithms. Experimental results demonstrate that CBBO is able to achieve better results than other evolutionary algorithms on most of the benchmark functions.	benchmark (computing);black bag operation;decision theory;decomposition (computer science);emoticon;evolutionary algorithm;habitat;mathematical optimization;phase-shift oscillator;population;programming paradigm;xfig	Xiangwei Zheng;Dianjie Lu;Xiao-Guang Wang;Hong Liu	2014	Applied Intelligence	10.1007/s10489-014-0627-9	coevolution;decomposition;cooperation	AI	25.59382891887569	-4.743727160699754	58760
6eb4aaeb622ab1564c0fb5a67bd12d7b2c63da50	moea/d with baldwinian learning inspired by the regularity property of continuous multiobjective problem	multiobjective optimization;moea d;regularity property;memetic strategy	The traditional reproduction operators, which are originally designed for single-objective optimization, are directly adopted in most state-of-the-art multi-objective evolutionary algorithms (MOEAs). However, these reproduction operators might not be suitable for multiobjective optimization problems (MOPs) due to the regularity property of continuous MOP, and that is to say its Pareto optimal set in the decision space is generally piecewise continuous manifold rather than a set of independent points. Few researches have used this regularity property of continuous MOP to help design their algorithms. In this paper, based on the regularity property, a Baldwinian learning operator is incorporated into the framework of MOEA/D (multi-objective evolutionary algorithm based on decomposition) and thereby we propose MOEA/D/BL. The Baldwinian learning operator obtains the evolving information based on the learned distribution model of a current population. It constructs a candidate descent direction based on the learned distribution model and the evolving history of the parent individuals. Experimental results on twenty-three popular test problems show that the proposed algorithm performs better than or as well as four other compared algorithms. It also experimentally demonstrates that the proposed Baldwinian learning operator can accelerate the convergence of solutions.	moea framework;multi-objective optimization	Xiaoliang Ma;Fang Liu;Yutao Qi;Lingling Li;Licheng Jiao;Meiyun Liu;Jianshe Wu	2014	Neurocomputing	10.1016/j.neucom.2014.05.025	mathematical optimization;artificial intelligence;multi-objective optimization;machine learning;mathematics	AI	24.849790418939303	-4.189049898184556	58793
c5d3f31c46db9dd152ea6d92fbc26601d2294b6f	robust trajectory optimization of space launch vehicle using computational intelligence	uncertainty;space launch vehicle uncertainty based design optimization metamodel computational intelligence latin hypercube sampling learning machine;uncertainty trajectory computational modeling optimization robustness vehicles artificial neural networks;uncertain systems neurocontrollers reliability robust control safety simulated annealing space vehicles stochastic processes trajectory optimisation aerospace;artificial neural networks;computational modeling;trajectory;simulated annealing robust trajectory optimization space launch vehicle computational intelligence metamodeling techniques uncertainty based design optimization udo stochastic optimization expensive simulation models optimal trajectory generation slv design vehicle reliability vehicle safety operational cost latin hypercube sampling lhs extreme learning machine elm neural network hybrid search algorithm hsa;robustness;optimization;vehicles	Metamodeling techniques using computational intelligence have been used in Uncertainty-based Design Optimization (UDO) to reduce the high computational cost of the uncertainty analysis and improve the performance of stochastic optimization problems with computationally expensive simulation models. Optimal trajectory generation is a major part of Space Launch Vehicle (SLV) design and if it is robust relative to uncertainties can improve vehicle reliability, safety and operational cost. This paper presents a combination of Latin Hypercube Sampling (LHS) and Extreme Learning Machine (ELM) in order to create an appropriate trajectory metamodel for reducing computational time of robust trajectory design optimization of a two-stage-to-orbit SLV. The sampled data of LHS is then used as training data for ELM. Complex and costly uncertainty analyses are replaced by an ELM Neural Network (NN) which is used to instantaneously estimate the mean and standard deviation of objective function and constraints. The evolutionary genetic algorithm is used for global optimization of layers' connection weights and biases to minimize the learning error during learning phase of NN. A Hybrid Search Algorithm (HSA), which associates Simulated Annealing (SA) as a global optimizer with Simplex as a local optimizer is employed to find robust optimum point of this metamodel. The optimal and robust trajectories are compared. The results show excellent approximation of highly non-linear design space and drastic reduction in overall UDO time, due to greatly reduced number of exact trajectory analyses.	algorithmic efficiency;analysis of algorithms;approximation;artificial neural network;computation;computational intelligence;elm;genetic algorithm;global optimization;heterogeneous system architecture;mathematical optimization;metamodeling;nonlinear system;optimization problem;search algorithm;simulated annealing;simulation;star catalogue;stochastic optimization;time complexity;trajectory optimization	Ali A. Bataleblu;J. Roshanian	2015	2015 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2015.7257318	probabilistic-based design optimization;trajectory optimization;mathematical optimization;simulation;uncertainty;computer science;trajectory;machine learning;computational model;artificial neural network;statistics;robustness	Robotics	33.19045314296162	-8.90920195113267	59260
34ffbb2ff557f6045b8d503d4f217a8374b0756e	the maximum hypervolume set yields near-optimal approximation	performance measure;asymptotic optimality;pareto front;speed of convergence;search algorithm;evolutionary multiobjective optimization;approximation;hypervolume indicator;performance measures;multiobjective optimization;asymptotic approximation	In order to allow a comparison of (otherwise incomparable) sets, many evolutionary multiobjective optimizers use indicator functions to guide the search and to evaluate the performance of search algorithms. The most widely used indicator is the hypervolume indicator. It measures the volume of the dominated portion of the objective space.  Though the hypervolume indicator is very popular, it has not been shown that maximizing the hypervolume indicator is indeed equivalent to the overall objective of finding a good approximation of the Pareto front. To address this question, we compare the optimal approximation factor with the approximation factor achieved by sets maximizing the hypervolume indicator. We bound the optimal approximation factor of n points by 1+Θ(1/n) for arbitrary Pareto fronts. Furthermore, we prove that the same asymptotic approximation ratio is achieved by sets of n points that maximize the hypervolume indicator. This shows that the speed of convergence of the approximation ratio achieved by maximizing the hypervolume indicator is asymptotically optimal.  This implies that for large values of n, sets maximizing the hypervolume indicator quickly approach the optimal approximation ratio. Moreover, our bounds show that also for relatively small values of n, sets maximizing the hypervolume indicator achieve a near-optimal approximation ratio.	approximation algorithm;asymptotically optimal algorithm;characteristic function (convex analysis);pareto efficiency;rate of convergence;search algorithm	Karl Bringmann;Tobias Friedrich	2010		10.1145/1830483.1830576	mathematical optimization;combinatorics;computer science;multi-objective optimization;mathematics;statistics	ECom	29.36740025032392	2.663227945721621	59386
a8584d420670a0a3a27088b2f54a5d65560cd4b5	formal validation of asynchronous interaction-agents algorithms for reaction-diffusion problems	interface agents;chemical reactors;convergence;coagulation;chaos;agent modeling;reaction diffusion systems;reaction diffusion;biological system modeling;formal validation;program verification;interface agent;blood vessel;partial derivative equations formal validation asynchronous interaction agents algorithms reaction diffusion problems biological complex systems multi agent simulation interface agents;biological system modeling context modeling mathematical model chemical reactors chemical products engines chaos equations convergence coagulation;multi agent simulation;multi agent systems;biological complex systems;engines;complex system;chemical products;uct;mathematical model;asynchronous interaction agents algorithms;reaction diffusion problems;chemical reaction;context modeling;reaction diffusion systems multi agent systems program verification;partial derivative equations	In the context of biological complex systems multi-agent simulation, we present an interaction-agentmodel for reaction-diffusion problems that enables interaction with the simulation during the execution, and we establish a mathematical validation for our model. We use two types of interaction-agents: on one hand, in a chemical reactor with no spatial dimension -e.g. a cell-, a reaction-agent represents an autonomous chemical reaction between several reactants, and modifies the concentration of reaction products. On the other hand, we use interface-agents in order to take into account the spatial dimension that appears with diffusion : interface-agents achieve the matching transfer of reactants between cells. This approach, where the simulation engine makes agents intervene in a chaotic and asynchronous way, is an alternative to the classical model - which is not relevant when the limits conditions are frequently modified- based on partial derivative equations. We enounciate convergence results for our interaction-agent methods, and illustrate our model with an example about coagulation inside a blood vessel.	agent-based model;autonomous robot;chaos theory;complex systems;reactor (software);simulation	Pascal Redou;Sébastien Kerdélo;Gireg Desmeulles;Jean François Abgrall;Vincent Rodin;Jacques Tisseau	2007	21st International Workshop on Principles of Advanced and Distributed Simulation (PADS'07)	10.1109/PADS.2007.19	complex systems;simulation;chemical reaction;convergence;computer science;theoretical computer science;chemical reactor;multi-agent system;mathematical model;context model;reaction–diffusion system;computer network	AI	34.4240529020801	-9.655342119531271	59463
e3a6fc7c5117f50b7e9bf798e6eec77743584fc5	ga-based global path planning for mobile robot employing a* algorithm		Global path planning for mobile robot using genetic algorithm and A* algorithm is investigated in this paper. The proposed algorithm includes three steps: the MAKLINK graph theory is adopted to establish the free space model of mobile robots firstly, then Dijkstra algorithm is utilized for finding a feasible collision-free path, finally the global optimal path of mobile robots is obtained based on the hybrid algorithm of A* algorithm and genetic algorithm. Experimental results indicate that the proposed algorithm has better performance than Dijkstra algorithm in term of both solution quality and computational time, and thus it is a viable approach to mobile robot global path planning.	a* search algorithm;computation;dijkstra's algorithm;genetic algorithm;graph theory;hybrid algorithm;mobile robot;motion planning;simulation;software release life cycle;time complexity	Cen Zeng;Qiang Zhang;Xiaopeng Wei	2012	JCP	10.4304/jcp.7.2.470-474	out-of-kilter algorithm;algorithm design;mathematical optimization;suurballe's algorithm;dijkstra's algorithm;a* search algorithm;computer science;pathfinding;machine learning;yen's algorithm;distributed computing;fsa-red algorithm;shortest path problem;dinic's algorithm;k shortest path routing;shortest path faster algorithm;difference-map algorithm;population-based incremental learning	Robotics	30.138537523456804	-2.6847072206568603	59566
1870d8785138cc4afe6a679e91328fd572483f12	a new ant colony algorithm using the heterarchical concept aimed at optimization of multiminima continuous functions	continuous function;ant colony optimization;insecto social;adaptive memory programming;ant colony;canal transmision;heuristic method;metodo heuristico;fonction continue;flujo informacion;flux information;information flow;emergent properties;funcion continua;canal transmission;ant colony algorithm;transmission channel;methode heuristique;insecte social;social insect;communication channels	Ant colony algorithms are a class of metaheuristics which are inspired from the behaviour of real ants. The original idea consisted in simulating the stigmergic communication, therefore these algorithms are considered as a form of adaptive memory programming. A new formalization is proposed for the design of ant colony algorithms, introducing the biological notions of heterarchy and communication channels. We are interested in the way ant colonies handle the information. According to these issues, an heterarchical algorithm called “Continuous Interacting Ant Colony” (CIAC) is designed for the optimization of multiminima continuous functions. CIAC uses two communication channels showing the properties of stigmergic and direct communications. CIAC presents interesting emergent properties as it was shown through some analytical test functions.	algorithm;ant colony optimization algorithms;distribution (mathematics);emergence;mathematical optimization;metaheuristic;self-management (computer science);simulation;stigmergy	Johann Dréo;Patrick Siarry	2002		10.1007/3-540-45724-0_18	ant colony optimization algorithms;parallel metaheuristic;computer science;artificial intelligence;metaheuristic	DB	24.76548086800411	-6.791240273289861	59833
ef63929e202633e73c3080420293f1279b65b5d1	an efficient genetic algorithm for the traveling salesman problem	differing operator;genetic algorithm;inver-over operator based on distance neighbor tabulation;traveling salesman problem	Based on an existing Genetic algorithm (GA) to TSP (IGT algorithm), by amending the original mapping operator and Inver-over operator and introducing differing operator for the first time, a new GA to TSP is proposed. Empirical results show that this new algorithm outperforms IGT algorithm in terms of solution quality, means and variances. Moreover, T-test exhibits the comprehensive advantage of the new algorithm. © 2010 Springer-Verlag.	genetic algorithm;travelling salesman problem	Guangfu Sun;Chengjun Li;Jiacheng Zhu;Yanpeng Li;Wei Liu	2010		10.1007/978-3-642-16388-3_12	2-opt;greedy algorithm;christofides algorithm;3-opt;bottleneck traveling salesman problem	EDA	25.136707984759834	-0.7667611445538177	60318
730b12970f947a7cbd14c43c4580fb3aa45f9774	a mixed analog/digital vlsi design and simulation of an adaptive resonance theory (art) neural network architecture	neural networks;multiplication operator;parallel mechanism;vlsi design;analog circuits;analog digital design;aart1 nn;nonlinear differential equation;vlsi;digital circuits;adaptive resonance theory art;adaptive resonance theory;neural network	approach and mixed analog/digital components, in which analog circuits are used to fully incorporate the parallel mechanism of the neural network, whereas digital circuits are used to provide a reduced circuit size as well as more precise multiplication operation. The AART1-NN circuit implemented is simulated using Pspice, and the results are in good agreement with those calculated numerically from the coupled nonlinear differential equations governing the AART1-NN.	adaptive resonance theory;analogue electronics;artificial neural network;digital electronics;network architecture;nonlinear system;numerical analysis;simulation;very-large-scale integration	Ching S. Ho;Juin J. Liou;Michael Georgiopoulos;Christos G. Christodoulou	1996	Simulation	10.1177/003754979606600104	mixed-signal integrated circuit;control engineering;electronic engineering;computer science;theoretical computer science;very-large-scale integration;artificial neural network;analog multiplier	EDA	39.067296033389255	-3.2102881871392612	60464
ef1eda8138d7bc4a3f3f0ddb98aa242e46f72fb5	optifel: a convergent heterogeneous particle swarm optimization algorithm for takagi–sugeno fuzzy modeling	generalization ability optifel convergent heterogeneous particle swarm optimization algorithm takagi sugeno fuzzy modeling data driven design ts fuzzy system model structure optimization framework pso algorithm premature convergence local optima t s fuzzy system parameters searching strategy heterogeneous multiswarm pso mspso searching performance enhancement multiple cooperative subswarms search behavior multiple subswarms strategy optimal parameters particle convergence stable points fuzzy system model;fuzzy systems optimization particle swarm optimization convergence mathematical model vectors computational modeling;stability control system synthesis convergence fuzzy systems particle swarm optimisation search problems;takagi sugeno t s fuzzy system convergence analysis heterogeneous search optifel particle swarm optimization pso	Data-driven design of accurate and reliable Takagi-Sugeno (T-S) fuzzy systems has attracted a lot of attention, where the model structures and parameters are important and often solved in an optimization framework. The particle swarm optimization (PSO) algorithm is widely applied in the field. However, the classical PSO suffers from premature convergence, and it is trapped easily into local optima, which will significantly affect the model accuracy. To overcome these drawbacks, we have developed a new T-S fuzzy system parameters searching strategy called OptiFel with a heterogeneous multiswarm PSO (MsPSO) to enhance the searching performance. MsPSO groups the whole population into multiple cooperative subswarms, which perform different search behaviors for the potential solutions. We have found that the multiple subswarms strategy proposed in this paper is greatly helpful for finding the optimal parameters suitable for the subspaces of the T-S fuzzy model. Our theoretical proof has also demonstrated that the cooperation among the subswarms can maintain a balance between exploration and exploitation to ensure the particles converge to stable points. Experimental results show that MsPSO performs significantly better than traditional PSO algorithms on six benchmark functions. With the improved MsPSO, OptiFel can generate a good fuzzy system model with high accuracy and strong generalization ability.	algorithm;benchmark (computing);converge;fuzzy control system;local optimum;mathematical optimization;particle swarm optimization;premature convergence	Ngaam J. Cheung;Xueming Ding;Hong-Bin Shen	2014	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2013.2278972	mathematical optimization;multi-swarm optimization;machine learning;control theory;mathematics;metaheuristic	ML	31.021981756060658	-6.166626486932644	61070
8e2cd060a34062491f0a4b5ffc741f8025a12f0e	a novel water wave optimization based memetic algorithm for flow-shop scheduling	job shop scheduling;memetics;heuristic algorithms;statistics;optimization;algorithm design and analysis;sociology	Recently, Water Wave Optimization (WWO) has been presented as an optimization approach which takes inspiration from shallow wave model considering wind forcing, nonlinear wave interaction, and frictional dissipation. In contrast to WWO dedicated for continuous optimization problems, this paper extends WWO for solving combinatorial permutation flow-shop scheduling problem (PFSSP). In particular, three fundamental search operators in WWO, i.e., propagation, refraction, and breaking have been re-formulated to make WWO suitable for solving combinatorial optimization problem. To enhance the searching performance and efficiency, an improved NEH based algorithm has been applied. Simulation results based on well-known benchmarks and comparisons indicate the competitive advantage of the proposed WWO based memetic algorithm in which the global exploration and the local exploitation are well balanced, providing satisfactory solutions over the state-of-the-art (meta) heuristics such as genetic algorithm for PFSSP.	combinatorial optimization;continuous optimization;flow shop scheduling;genetic algorithm;heuristic (computer science);mathematical optimization;memetic algorithm;nonlinear system;optimization problem;program optimization;scheduling (computing);simulation;software propagation	Xin Yun;Xiaoyi Feng;Xin Lyu;Shouyang Wang;Bo Liu	2016	2016 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2016.7744029	job shop scheduling;algorithm design;memetics;mathematical optimization;computer science;artificial intelligence;machine learning;mathematics	EDA	25.660419258427524	-3.8939593959216814	61196
db3947e30a9b1b7d8703ff49b7e0ab142849877e	study on construction of objective function for damage identification using improved genetic algorithm	object recognition;analytical result;damage location;damage severity;frequency residual;measured result;bridges;model updating damage identification improved genetic algorithm objective function;vibration testing quality;structural engineering beams structures condition monitoring dynamic testing finite element analysis genetic algorithms;data mining;objective function;optimization problem;shape;condition monitoring;analytical result objective function construction damage identification improved genetic algorithm damage location damage severity finite element model error minimization vibration testing quality frequency residual weight coefficient supported beam measured result;supported beam;structural engineering;objective function construction;finite element model;improved genetic algorithm;genetic algorithms genetic mutations civil engineering structural beams vibrations testing optimization methods finite element methods frequency materials science and technology;weight coefficient;beams structures;genetic algorithms;optimization;model updating;finite element analysis;error minimization;optimal algorithm;dynamic testing;damage identification;gallium	An improved genetic algorithm-based damage identification method is presented that accurately identifies both the location and severity of damage in a simulated simply supported beam. Damage identification based on finite element model updating is often used and damage is identified by minimizing the error between measured and analytical results. But whether model updating can be carried out successfully mainly depends on accuracy of model, quality of vibration testing, definition of optimization problem and calculation performance of optimization algorithm. In the paper, an improved genetic algorithm (IGA) is presented firstly, the construction technique of objective function based on different residuals and their weight coefficients is introduced secondly, in the end through the simulation of a simply supported beam, and damage identification is studied comparatively. From the results it can be seen that the damage identification method developed using IGA provides greater accuracy in identifying the location and severity of damage, and the performance is better when frequency residual has a larger weight coefficient.	genetic algorithm;loss function	Minshui Huang;Jie Li;Hong-ping Zhu	2009		10.1109/ICNC.2009.493	structural engineering;mathematical optimization;engineering;engineering drawing	AI	35.1698338102136	-4.111734458513051	61206
c273b97edb84376029d1470d5010235f0558dc04	a hybrid selection algorithm for time series modeling	population diversity;clonal selection principle;gene expression programming;evolutionary algorithm;time series prediction	An evolutionary algorithm becomes trapped in local optima when a premature convergence occurs. Research has suggested maintaining population diversity to address this problem. However, traditional methods are excessively complex and time consuming. This study proposes a hybrid selection mechanism in which clonal and roulette wheel selections are alternated to maintain population diversity during evolution. The proposed method is based on a genetic programming technique known as gene expression programming (GEP). The prediction power and efficiency of the proposed method were compared with those of other GEP-based algorithms by using five time series benchmarks. The experimental results indicated that the proposed algorithm outperforms the other algorithms.	selection algorithm;time series	Julie Yu-Chih Liu;Juo-Chiang Hsieh	2015	Soft Comput.	10.1007/s00500-014-1236-6	evolutionary programming;mathematical optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm;time series;gene expression programming	ECom	27.23077128443328	-4.367519811020306	61226
185f1261697b26cb88f3290b22f9ba057cc8037f	a chaotic ergodicity based evolutionary computation algorithm	evolutionary computation;chaos;fusion technology chaos evolution chaos ergodicity evolutionary computation;benchmark functions chaotic ergodicity evolutionary computation algorithm population based optimization algorithm chaotic evolution exploitation functions exploration functions control parameter direction factor rate search capability;fusion technology;chaos vectors optimization benchmark testing equations proposals logistics;search problems chaos evolutionary computation optimisation;chaos evolution;ergodicity	We propose a novel population-based optimization algorithm, Chaotic Evolution (CE), that uses a chaotic ergodicity to implement exploitation and exploration functions of the evolutionary computation algorithm. A new control parameter, direction factor rate, is proposed in CE to guide search direction. Compared with differential evolution (DE), our proposal works with the more simple principle, and can obtain the better optimization performance, escape from the local optimum and avoid the premature. By changing the chaotic system in our proposal, it is easy to extend its search capability, i.e., the scalability of our proposal is higher than DE. A series of comparative evaluations are conducted to analyze the feature of the proposal. From these results and analysis, our proposed algorithm can optimize most of benchmark functions and outperforms better than DE.	algorithm;benchmark (computing);chaos theory;differential evolution;ergodicity;evolutionary algorithm;evolutionary computation;iteration;local optimum;mathematical optimization;scalability	Yan Pei	2013	2013 Ninth International Conference on Natural Computation (ICNC)	10.1109/ICNC.2013.6818019	mathematical optimization;interactive evolutionary computation;human-based evolutionary computation;artificial intelligence;theoretical computer science;mathematics;evolution strategy	AI	26.998780413047694	-5.2292783427202485	61268
f234c660ba32805392249a392f74ad0ebe1e2993	mosquito host-seeking algorithm based on random walk and game of life		Mosquito Host-seeking Algorithm (MHSA) is a novel bionic algorithm. It simulates the behavior of mosquito seeking host. MHSA can find near-optimum solutions for the traveling salesman problem (TSP), however there are two drawbacks. First, it may be trapped into local optimum. Second, the solution exists several circles sometimes. In this paper, we adopt the Random Walk and the Game of Life strategies to improve MHSA, and propose a Random Walk and Game of Life Host-seeking Algorithm (RGHSA). RGHSA model is proposed to solve these two drawbacks. We use set theory and probability theory to prove the validity of the model. TSPlib is a benchmark for TSP. In the simulation, we choose server datasets from TSPlib, and compare the simulation result of RGHSA with original MHSA, Simulated Annealing Algorithm (SA) and Ant Colony Optimization Algorithm (ACO). The result shows that RGHSA have a good performance in TSP.	algorithm;conway's game of life	Yunxin Zhu;Xiang Feng;Huiqun Yu	2018		10.1007/978-3-319-95933-7_78	ant colony optimization algorithms;computer science;artificial intelligence;machine learning;local optimum;random walk;probability theory;algorithm;simulated annealing;set theory;travelling salesman problem	NLP	27.706151070235236	-3.2527364359689996	61392
540326e512c666a52dc67cb47c5cb9c591e2dc3e	immunity-based adaptive genetic algorithm for multi-robot cooperative exploration	premature convergence;adaptive genetic algorithm;immune algorithm;np hard problem;immunity;exploration;genetic algorithm;parallel processing;multi robot	The key to multi-robot exploration is how to select appropriate targets for robots to avoid collision and overlap. However, the distribution of targets for multiple robots is an NP hard problem. This paper presents a multirobot cooperative exploration strategy based on the immune genetic algorithm. With its random global searching and parallel processing, genetic algorithm is applied for multi-robots multiple targets combinatorial distribution. With its antibody diversity maintaining mechanism, the immune algorithm is used to get over the premature convergence of genetic algorithm. The selection probability is computed based on the similarity vector distance to guarantee the antibody’s diversity. The crossover and mutation probability are adjusted based on the fitness of antibody to decrease the possibility of local optimal. The extensive simulations demonstrate that the immunity-based adaptive genetic algorithm can effectively distribute the targets to multiple robots in various environments. The multiple robots can explore the unknown environment quickly.	computation;genetic algorithm;parallel computing;premature convergence;robot;simulation;time complexity	Xin Ma;Qin Zhang;Weidong Chen;Yibin Li	2007		10.1007/978-3-540-74205-0_65	parallel processing;mathematical optimization;genetic algorithm;exploration;computer science;artificial intelligence;machine learning;np-hard;mathematics;premature convergence;population-based incremental learning	Robotics	28.958006131555713	-6.166773317322471	61744
6e1aeccdb494f1e039cfc3c6a327a1131328f323	genetic code optimality studied by means of simulated evolution and within the coevolution theory of the canonical code organization	coevolution theory of the genetic code;nucleotides;genetic code;coevolution;simulated evolution;genetics;genetic code theories;error minimization hypothesis;genetic algorithm;genetic algorithms	We have studied the canonical genetic code optimality by means of simulated evolution. A genetic algorithm is used to search for better adapted hypothetical codes and as a method to guess the difficulty in finding such alternative codes. Such analysis is performed within the coevolution theory of the genetic code organization. We have studied the progression of the canonical genetic code optimality within such theory, considering a possible scenario of a previous code with two-letter codons as well as the current organization of the canonical code. Moreover, we have analysed the particular optimality and progression of adaptability of the individual nucleotide bases.	code;color gradient;genetic algorithm	José Santos Reyes;Ángel Monteagudo	2008	Natural Computing	10.1007/s11047-008-9092-x	genetic algorithm;computer science;bioinformatics;genetic representation;genetics;algorithm	SE	26.49323250439549	-8.872084234174379	61788
f4c713e8ebe6b32e4359bfab3bf7f620750de4d3	optimal control of uncertain systems using sample average approximations	49k45;primary;optimal control;secondary;numerical methods;parameter uncertainty;49m25	In this paper, we introduce the uncertain optimal control problem of determining a control that minimizes the expectation of an objective functional for a system with parameter uncertainty in both dynamics and objective. We present a computational framework for the numerical solution of this problem, wherein an independently drawn random sample is taken from the space of uncertain parameters, and the expectation in the objective functional is approximated by a sample average. The result is a sequence of approximating standard optimal control problems that can be solved using existing techniques. To analyze the performance of this computational framework, we develop necessary conditions for both the original and approximate problems and show that the approximation based on sample averages is consistent in the sense of Polak [Optimization: Algorithms and Consistent Approximations, Springer, New York, 1997]. This property guarantees that accumulation points of a sequence of global minimizers (stationary points) of the approximate problem are global minimizers (stationary points) of the original problem. We show that the uncertain optimal control problem can further be approximated in a consistent manner by a sequence of nonlinear programs under mild regularity assumptions. In numerical examples, we demonstrate that the framework enables the solution of optimal search and optimal ensemble control problems.	approximation algorithm;computation;nonlinear system;numerical analysis;numerical partial differential equations;optimal control;springer (tank);stationary process;tree accumulation	Chris Phelps;Johannes O. Royset;Qi Gong	2016	SIAM J. Control and Optimization	10.1137/140983161	econometrics;mathematical optimization;optimal control;numerical analysis;control theory;mathematics;statistics;algebra	ML	36.43886486500071	4.107718635224675	61824
0aad7a1f3c96d954ffc15277e1c3dc5a8d3d028d	distributed evolutionary algorithms inspired by membranes in solving continuous optimization problems	continuous optimization;evolutionary algorithm	In this paper we present a new strategy to apply the operators in evolutionary algorithms. This strategy is inspired from the way the evolution rules are used in membrane systems. Moreover, analyzing the similarities and differences between the evolutionary operators and the evolution rules in membrane systems, between membrane structures and communication topologies, and between communication rules in membrane systems and communication policies in evolutionary algorithms, we introduce and a hybrid distributed evolutionary algorithm and test it for continuous optimization problems.	approximation algorithm;continuous optimization;evolutionary algorithm;evolutionary computation;evolutionary programming;heuristic (computer science);mathematical optimization;membrane computing;metaheuristic;numerical analysis;semantics (computer science);steady state	Daniela Zaharie;Gabriel Ciobanu	2006		10.1007/11963516_34	evolutionary programming;mathematical optimization;genetic algorithm;cma-es;interactive evolutionary computation;human-based evolutionary computation;java evolutionary computation toolkit;bioinformatics;machine learning;evolutionary algorithm;evolutionary acquisition of neural topologies;mathematics;evolution strategy;memetic algorithm;evolutionary computation	AI	25.3254107894271	-5.6970086991273465	62017
5c485dc3505198c3cd721e51bad708edd6286d97	an optimization algorithm based on brainstorming process		In this paper, the human brainstorming process is modeled, based on which two versions of Brain Storm Optimization (BSO) algorithm are introduced. Simulation results show that both BSO algorithms perform reasonably well on ten benchmark functions, which validates the effectiveness and usefulness of the proposed BSO algorithms. Simulation results also show that one of the BSO algorithms, BSO-II, performs better than the other BSO algorithm, BSO-I, in general. Furthermore, average inter-cluster distance Dc and inter-cluster diversity De are defined, which can be used to measure and monitor the distribution of cluster centroids and information entropy of the population over iterations. Simulation results illustrate that further improvement could be achieved by taking advantage of information revealed by Dc and/or De, which points at one direction for future research on BSO algorithms.	approximation algorithm;benchmark (computing);entropy (information theory);iteration;simulation	Yuhui Shi	2011	IJSIR	10.4018/IJSIR.2011100103	computer science;artificial intelligence;theoretical computer science;algorithm	ML	27.01897724641852	-5.189759164695252	62024
d2b0c02e984fea4e4574ce94989dcc47ea4eb4dc	a new mechanism for metastability of under-saturated traffic responsible for time-delayed traffic breakdown at the signal	queue;traffic flow;traffic light;traffic breakdown	In this paper we introduce a newmechanism of metastability of under-saturated traffic at the signal that is responsible for a time-delayed traffic breakdown revealed by Kerner (2011). In our model, we assume that the metastability of under-saturated traffic at the signal is caused by a dependence of the mean time of driver acceleration from a queue at the signal on the driver’s stopped time within the queue. With the use of Nagel–Schreckenberg model, we demonstrate that this mechanism of the metastability of city traffic can lead to the time-delayed traffic breakdown at the signal. © 2014 Elsevier B.V. All rights reserved. Vehicular flow is a many-particle system far from equilibrium and it exhibits diverse interesting non-equilibrium features. For instance, capacity drop phenomenon is widely observed, which is believe to be related to first-order phase transition from free flow to congested flow. Phantom jam is another interesting phenomenon observed in real traffic [1–7]. However, there is controversy about whether phantom jam is usually formed in a sequence free flow → synchronized flow → jam (F→S→J transitions) (as stated in Kerner’s three-phase theory [9]) or from free flow directly (F→J transition) (as stated in two-phase traffic flow theories [1–4, 8,11–15]). The mechanism of wide scattering of statistical data in congested flow in the flow rate density plane is not clear, either [8–13]. To explain the features of vehicular flow,many traffic flowmodels have been proposed, which can be roughly classified into three types. In Lighthill–Whitham–Richards model, the traffic flow is always stable [14,15]. It is believed that complex traffic flow phenomena are induced by external factors (e.g., traffic bottlenecks, lane changing behaviors) [8]. On the other hand, the two-phase traffic theory (see [1,2,11–13] and references therein) and Kerner’s three-phase traffic theory [9] assume that traffic flow is not always stable, and the complex traffic phenomena are related to traffic instability. Nevertheless, there are several heated debates of the ∗ Corresponding author at: School of Engineering Science, University of Science and Technology of China, Hefei 230026, China. Tel.: +86 551 63600127. E-mail address: rjiang@ustc.edu.cn (R. Jiang). http://dx.doi.org/10.1016/j.cpc.2014.02.011 0010-4655/© 2014 Elsevier B.V. All rights reserved. two theories about whether a unique relationship between flow rate and density exists or a two-dimensional region exists in the steady state, and traffic breakdown is associated with F→S transition [9] or F→J transition [1,2,11–13]. The latter point is the most important one. This is because if the F→S transition determines traffic breakdown at highway bottlenecks as stated in Kerner’s three-phase theory [9], then the reliable application of all classical methods for traffic control and optimization in transportation networks is a very questionable one as explained in a recent review [10]. The above mentioned controversy about traffic flow mainly arises in uninterrupted flow observed on highways, freeways or expressways. In city traffic, the Biham–Middleton–Levinemodel is the first city traffic model in the community of traffic physics [16]. Although the model is extremely simple, it displays some interesting behaviors, e.g., self-organization of alternating stripes in free flow. Since its proposal, many extensive studies have been carried out based on the model (see e.g. Refs. [17–19]). Since vehicles have to stop and start frequently at the traffic lights, it is generally believed that whether to consider instabilities or not is not important. However, recently, Kerner showed that, in undersaturated traffic, spontaneous traffic breakdown can occur at the light signal after a random time delay [20]. It has been argued that this traffic breakdown is initiated by a phase transition from free flow to synchronized flow (in the three-phase traffic model) or by a phase transition from free flow to jam (in the two-phase model) occurring upstream of the queue. Kerner further studied the green-wave breakdown at traffic signal [21–23]. He proposed 1440 R. Jiang et al. / Computer Physics Communications 185 (2014) 1439–1442	biham–middleton–levine traffic model;broadcast delay;durand–kerner method;first-order predicate;flaming (internet);instability;jam;many-body problem;mathematical optimization;metastability in electronics;nagel–schreckenberg model;open road tolling;particle system;phantom reference;self-organization;spontaneous order;steady state;stripes;theory;two-phase commit protocol;two-phase locking	Rui Jiang;Mao-Bin Hu;Bin Jia;Ziyou Gao	2014	Computer Physics Communications	10.1016/j.cpc.2014.02.011	real-time computing;simulation;traffic congestion reconstruction with kerner's three-phase theory;traffic flow;three-phase traffic theory;traffic bottleneck;traffic wave;queue	Metrics	38.25704516733122	1.3849278149107915	62035
08669ca6923e2ffa6d044564d6141ec16179c49d	modeling and simulation for hybrid electric vehicles. i. modeling	conventional vehicle;hybrid electric vehicle;specific power control strategy;electric-assisted hev;pure electric vehicle;power output;power control strategy;auxiliary power unit;power control scheme;vehicle operation;energy storage;regeneration;regenerative braking;engines;real time;modeling and simulation;data analysis;torque;simulation;power control;acceleration;helium	A model for the hybrid electric vehicle (HEV) powertrain simulation has been constructed with a specific power control strategy for an electric-assisted HEV in parallel configuration. The HEV was built by the University of Tennessee, Knoxville. Experimental procedures and data analysis for characterizing power output from the battery and the auxiliary power unit (APU) are presented. The model is implemented based on the empirical formulation and power control scheme, a power control strategy by means of throttle position. It also incorporates regeneration and regenerative braking for battery capacity recovery. The model allows for real time evaluation of a wide range of parameters in vehicle operation as a HEV, a pure electric vehicle, or as a conventional vehicle.	simulation	Xiaoling He;Jeffrey W. Hodgson	2002	IEEE Trans. Intelligent Transportation Systems			Robotics	36.30156549789586	-3.372842346442685	62062
0c6cf6099f47c39ac10755fe6026aee691b5414e	programming and simulation of quantum search agents	multiagent system;programming language;agent based;program design;nuclear magnetic resonance;agents;quantum computer;quantum physics;reactive and deliberative;pattern matching;hybrid architecture;thermodynamics;brokering and matchmaking;architectures;agent architecture;multiagent systems	Key idea of this work is to appropriately extend one prominent generic agent architecture, namely InteRRap [8], to the case of a quantum pattern matching (QPM) based type-I quantum search agent (QSA) that is supposed to run on a hybrid quantum computer, and to show it's feasibility by instantiating the respective QuantumInteRRap architecture. For a comprehensive and in-depth introduction to quantum computation (QC) we refer the interested reader to [10]. An extended version of this work can be found at [6].	agent architecture;computation;norm (social);pattern matching;qtscript;quantum computing;simulation	Matthias Klusch;René Schubotz	2007	2007 IEEE International Conference on Systems, Man and Cybernetics	10.1145/1329125.1329230	agent architecture;quantum information;simulation;computer science;artificial intelligence;theoretical computer science;software agent;pattern matching;multi-agent system;program design language;quantum computer	Robotics	28.310744433633285	-8.926744236391302	62150
c267f2f1fe9cb056e0a41785097879bd9ed7e0fe	an improved pso and its application in research on reservoir operation function of long-term	reservoir operation;reservoirs;convergence;reservoirs convergence testing optimization methods particle swarm optimization genetic mutations analysis of variance regression analysis analytical models arithmetic;optimal method;variance analysis;local convergence;mutation operator;self adapting inertia;local convergence problem;optimization problem;particle swarm optimizer;particle swarm optimization;regression analysis particle swarm optimization reservoir operation function mutation operator self adapting inertia local convergence problem variance analysis;regression analysis;reservoir operation function;particle swarm optimisation;reservoirs convergence particle swarm optimisation	An improved particle swarm optimization called IPSO is presented in this article. By importing mutation operator and adopting self-adapting inertia, the IPSO overcomes the local convergence problem and slow later convergence problem of the basic PSO effectively. The variance analysis is applied to evaluate the optimization effectiveness of key parameters of IPSO. In order to test the performance of IPSO, it is applied to the research on the function of reservoir long-term operation. In the case study, the reservoir operation function achieved by IPSO is tested and the superiority is apparent compared with two other ones that are obtained by PSO and through regression analysis on the simulation operation course gained by the progressive optimization arithmetic respectively. The application results fully show that IPSO is a promising and valuable optimization method, meaning that a novel and effective solution is provided for complex optimization problems.	ipso alliance;local convergence;mathematical optimization;particle swarm optimization;simulation	Ming Zhang;Chengjun Li;Xiaohui Yuan;Yongchuan Zhang	2007	Third International Conference on Natural Computation (ICNC 2007)	10.1109/ICNC.2007.224	mathematical optimization;machine learning;mathematics;mathematical economics	EDA	28.750208160276962	-5.618528449259611	62279
d60505d13e14c72bd21a328dad1751e1ebd97d5d	modified firefly algorithm using randomized mechanisms	exponential distribution;convergence;standards;weibull distribution;optimization;gaussian distribution;benchmark testing	The firefly algorithm is a stochastic meta-heuristic algorithm that incorporates randomness into a search process. In essence, the randomness is useful when determining the next point in the search space and therefore has a crucial impact when exploring the new solution. Simultaneously, randomized mechanism plays an important role in balance the exploration and exploitation during the process. In this paper, an extensive comparison is made between 8 different probability distributions that can be used for randomizing the firefly algorithm's attractive mechanism, e.g., Uniform distribution, Gaussian distribution, Exponential distribution, Cauchy distribution, and so on. In our experiments, variously randomized firefly algorithms are developed and extensive experiments are conducted on 13-benchmark functions. The results of these experiments show that these randomized mechanisms can improve the convergence rate and the robustness of the firefly algorithm significantly.	experiment;exploit (computer security);firefly (cache coherence protocol);firefly algorithm;heuristic (computer science);randomized algorithm;randomness;rate of convergence	Lina Zhang;Liqiang Liu;Gan-Nan Yuan;Yuntao Dai	2016	2016 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2016.7744067	normal distribution;exponential distribution;weibull distribution;benchmark;econometrics;mathematical optimization;convergence;computer science;mathematics;statistics	AI	27.811732303040852	-5.05750077407173	62732
e60948f8c447d9f309e3bd7b30f308d52d04d674	gravitational search algorithm with linearly decreasing gravitational constant for parameter estimation of photovoltaic cells		Due to undeniable environmental, economical and technical reasons, renewable energy-based power generation in electric power systems is continually increasing. Among renewables, photovoltaic (PV) power generation is a viable and attractive choice. For modeling photovoltaic systems, accurate modeling of PV cells is a must. PV cells are often modeled as single diode or double diode models. The process of estimating circuit model parameters of PV cells based on datasheet information or experimental I–V measurements is called PV cell parameter estimation problem and is being frequently researched in the last three decades. The research effort is being put to achieve more accurate circuit model parameters. In this paper, gravitational search algorithm (GSA) with linearly decreasing gravitational constant is proposed for solving PV cell parameter estimation problem. The results of application of the proposed GSA to PV cell parameter estimation problem vividly show its outperformance over GSA with constant gravitational constant, GSA with exponentially decreasing gravitational constant, genetic algorithm, evolutionary programming and Newton algorithm.	cell (microprocessor);datasheet;diode;estimation theory;evolutionary programming;genetic algorithm;global storage architecture;ibm power systems;newton;newton's method;page view;search algorithm;solar cell	A. Rezaee Jordehi	2017	2017 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2017.7969293	electric power system;mathematical optimization;electricity generation;gravitational constant;evolutionary programming;computer science;estimation theory;exponential growth;search algorithm;photovoltaic system;control theory	EDA	33.52012693593683	-8.273073039442913	62745
5a618d2e321c1e809d0b55c0164cc739e67306a0	randomized block coordinate non-monotone gradient method for a class of nonlinear programming		In this paper we propose a randomized block coordinate non-monotone gradient (RBCNMG) method for minimizing the sum of a smooth (possibly nonconvex) function and a block-separable (possibly nonconvex nonsmooth) function. At each iteration, this method randomly picks a block according to any prescribed probability distribution and typically solves several associated proximal subproblems that usually have a closed-form solution, until a certain sufficient reduction on the objective function is achieved. We show that the sequence of expected objective values generated by this method converges to the expected value of the limit of the objective value sequence produced by a random single run. Moreover, the solution sequence generated by this method is arbitrarily close to an approximate stationary point with high probability. When the problem under consideration is convex, we further establish that the sequence of expected objective values generated by this method converges to the optimal value of the problem. In addition, the objective value sequence is arbitrarily close to the optimal value with high probability. We also conduct some preliminary experiments to test the performance of our RBCNMG method on the `1-regularized least-squares problem. The computational results demonstrate that our method substantially outperform the randomized block coordinate descent method proposed in [16].	approximation algorithm;computation;convex function;coordinate descent;experiment;gradient method;iteration;least squares;loss function;nonlinear programming;optimization problem;randomized algorithm;randomness;stationary process;with high probability;monotone	Zhaosong Lu;Lin Xiao	2013	CoRR		mathematical optimization;combinatorics;discrete mathematics	ML	35.78014225302046	4.041073228455036	62847
706fe08e52a602ed856860f247bd194369358895	clustering bin packing instances for generating a minimal set of heuristics by using grammatical evolution		Grammatical Evolution has been used to evolve heuristics for the Bin Packing Problem. It has been shown that the use of Grammatical Evolution can generate an heuristic for either one instances or a full instance set for this problem. In many papers the selection of instances for heuristics generation has been done randomly. The present work proposes a methodology to cluster bin packing instances and choose the instances to generate an heuristic for each cluster. The number of heuristics generated is based on the number of clusters. There were used only one instance by cluster. The results obtained were compared through non-parametric tests against the best known heuristics.	bin packing problem;computer cluster;grammatical evolution;heuristic (computer science);set packing	Marco Aurelio Sotelo-Figueroa;Héctor José Puga Soberanes;Juan Martín Carpio Valadez;H. J. Fraire HéctorJ.Fraire;Laura Cruz Reyes;Jorge Alberto Soria-Alcaraz	2015		10.1007/978-3-319-10960-2_10	mathematical optimization;combinatorics;machine learning	AI	25.220391401205504	3.923016095169523	62922
65e112be4dc7d6ad152d095ec0a97da2ca89e1da	a study of multiobjective metaheuristics when solving parameter scalable problems	estensibilidad;quality assurance;ant colony optimization performance evaluation scalability benchmark testing algorithm design and analysis particle swarm optimization pareto optimization pareto analysis technological innovation contracts;multiobjective programming;optimum pareto;programmation multiobjectif;search capability;swarm intelligence;pareto optimisation;differential evolution;parameter scalable problems;metaheuristics;technological innovation;ant colony optimization;performance evaluation;intelligence en essaim;optimizacion pso;particle swarm optimisation pareto optimisation;efficiency;pareto front;heuristic method;multi objective optimization;metodo heuristico;contracts;indice aptitud;pareto optimization;resolucion problema;indice aptitude;aseguracion calidad;quality indicator;zitzler deb thiele test suite;metamodel;particle swarm optimizer;metamodele;hypervolume indicator;quality indicators;capability index;metamodelo;particle swarm optimization;comparative study;optimisation pso;extensibilite;scalability;methode heuristique;parameter wise scalable problems;scalability comparative study efficiency metaheuristics multi objective optimization;pareto optimum;inteligencia de enjambre;assurance qualite;particle swarm optimisation;optimo pareto;algorithm design and analysis;benchmark testing;pareto analysis;problem solving;resolution probleme;differential evolution multiobjective metaheuristics parameter scalable problems search capability quality indicators parameter wise scalable problems hypervolume indicator zitzler deb thiele test suite pareto front particle swarm optimization;programacion multiobjetivo;multiobjective metaheuristics	To evaluate the search capabilities of a multiobjective algorithm, the usual approach is to choose a benchmark of known problems, to perform a fixed number of function evaluations, and to apply a set of quality indicators. However, while real problems could have hundreds or even thousands of decision variables, current benchmarks are normally adopted with relatively few decision variables (normally from 10 to 30). Furthermore, performing a constant number of evaluations does not provide information about the effort required by an algorithm to get a satisfactory set of solutions; this information would also be of interest in real scenarios, where evaluating the functions defining the problem can be computationally expensive. In this paper, we study the effect of parameter scalability in a number of state-of-the-art multiobjective metaheuristics. We adopt a benchmark of parameter-wise scalable problems (the Zitzler-Deb-Thiele test suite) and analyze the behavior of eight multiobjective metaheuristics on these test problems when using a number of decision variables that range from 8 up to 2048. By using the hypervolume indicator as a stopping condition, we also analyze the computational effort required by each algorithm in order to reach the Pareto front. We conclude that the two analyzed algorithms based on particle swarm optimization and differential evolution yield the best overall results.	algorithm;analysis of algorithms;benchmark (computing);computation;decision theory;differential evolution;dynamic energy budget;fastest;image scaling;mathematical optimization;metaheuristic;multi-objective optimization;open research;pareto efficiency;particle swarm optimization;scalability;test suite;wait-for graph	Juan José Durillo;Antonio J. Nebro;Carlos A. Coello Coello;José García-Nieto;Francisco Murilo Tavares Luna;Enrique Alba	2010	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2009.2034647	quality assurance;mathematical optimization;swarm intelligence;computer science;multi-objective optimization;machine learning	SE	26.313891506844588	0.5784887281004146	63043
14cc70ad7f5a03875feb68fbe52552e994357b69	clustered genetic search in continuous landscape exploration	basin of attraction;genetics;clustering;genetic algorithm;global optimization;continuation method;error estimate;finite mixture model	We present the strategy of clustered genetic search as a case-oriented tool for global optimization problems. The strategy is performed in two quite different manners—as an iterative discrete hill-crunching approach and as a continuous method based on a finite mixture model. We set up the main points of theory on convergence, stop condition and error estimation. We illustrate the properties of both methods in two examples, including the problem of optimal geometry for argon cluster.		Robert Schaefer;Katarzyna Adamska;Henryk Telega	2004	Eng. Appl. of AI	10.1016/j.engappai.2004.04.014	mathematical optimization;genetic algorithm;computer science;machine learning;mixture model;cluster analysis;global optimization	AI	29.119556251184704	-7.036278874517883	63398
6e1a77671b1027cd7ba94585b84b2d3dc0fbb08a	an immune-based algorithm for topology optimization	design process;evolutionary computation;evolutionary computation artificial immune systems computational geometry engineering computing;artificial immune system;engineering computing;computational geometry;computational method;topology optimization;design space;artificial immune systems immune based algorithm topology optimization shape optimization engineering devices user defined material configuration objective functions user defined parameters evolutionary paradigm;objective function;shape optimization;topology shape design optimization space exploration distributed computing process design algorithm design and analysis material properties optimization methods artificial immune systems;optimal algorithm;artificial immune systems;material properties	Traditional shape optimization of engineering devices usually starts with an initial user-defined configuration of material. Optimization algorithms are then applied for optimizing objective functions of predefined parameters. While this approach can yield efficient results, it is essentially limited, since limitations in the initial design forbid the computational methods to explore different distributions of material as solutions for a given problem. In other words, the algorithms are not allowed to exhibit creativity in the design process. Topology optimization is a paradigm for optimization that allows such creativity to emerge. Instead of optimizing functions of user-defined parameters, this paradigm optimizes the material properties of each point of the design space, and its methods are theoretically able to describe all possible devices within a limited space. This work presents a new methodology for topology optimization, based on an evolutionary paradigm known as artificial immune systems. The proposed technique is capable of exploring the space locally as well as globally, efficiently searching for the optimal distribution of material. It also incorporates strategies for the evolution of smoother, more regular shapes, in order to generate physically feasible solutions for engineering problems.	artificial immune system;binary number;computation;evolution strategy;evolutionary algorithm;genetic algorithm;mathematical optimization;optimizing compiler;pattern matching;point of view (computer hardware company);program optimization;programming paradigm;shape optimization;topology optimization	Felipe Campelo;F. G. Guimaraes;Hajime Igarashi;Kota Watanabe;J. A. Ramirez	2006	2006 IEEE International Conference on Evolutionary Computation	10.1109/CEC.2006.1688715	probabilistic-based design optimization;mathematical optimization;topology optimization;engineering optimization;test functions for optimization;computational geometry;computer science;theoretical computer science;machine learning;vector optimization;artificial immune system;random optimization;evolutionary computation	EDA	31.788663081943987	2.2833598822592687	63989
e13fb060f6fb5cfe705db7b9a31a8b98a706a1cd	adaptive bees algorithm - bioinspiration from honeybee foraging to optimize fuel economy of a semi-track air-cushion vehicle	ta engineering general civil engineering general	This interdisciplinary study covers bionics, optimization and vehicle engineering. Semi-track aircushion vehicle (STACV) provides a solution to transportation on soft terrain, whereas it also brings a new problem of excessive fuel consumption. By mimicking the foraging behaviour of honeybees, the bioinspired adaptive bees algorithm (ABA) is proposed to calculate its running parameters for fuel economy optimization. Inherited from the basic algorithm prototype, it involves paralleloperated global search and local search, which undertake exploration and exploitation, respectively. The innovation of this improved algorithm lies in the adaptive adjustment mechanism of the range of local search (called ‘patch size’) according to the source and the rate of change of the current optimum. Three gradually in-depth experiments are implemented for 143 kinds of soils. First, the two optimal STACV running parameters present the same increasing or decreasing trend with soil parameters. This result is consistent with the terramechanics-based theoretical analysis. Second, the comparisons with four alternative algorithms exhibit the ABA’s effectiveness and efficiency, and accordingly highlight the advantage of the novel adaptive patch size adjustment mechanism. Third, the impacts of two selected optimizer parameters to optimization accuracy and efficiency are investigated and their recommended values are thus proposed.	aba problem;algorithmic efficiency;ant colony optimization algorithms;bees algorithm;experiment;gd-rom;local search (optimization);mathematical optimization;optimization problem;prototype;semiconductor industry;simulation;software release life cycle	Shuo Xu;Fan Yu;Zhe Luo;Ze Ji;Duc Truong Pham;Renxi Qiu	2011	Comput. J.	10.1093/comjnl/bxq097	simulation;computer science;bees algorithm;operations research	AI	27.95640770324757	-3.7448261297537604	64037
b44e79fac0e7d389b09cfbeb6d5f2ded8bc11bbe	dynamic evolutionary algorithm with variable relocation	dynamic programming;fitness landscape;evolutionary history;optimisation;cambio variable;programacion dinamica;fonction valeur;convergence;evolutionary computation;relocation;history;optimizacion;evolutionary information;variable relocation;competitividad;job shop scheduling;uncertainty;reutilizacion;reponse transitoire;benchmark problem;environmental conditions;adaptive dynamics;portfolios;funcion valor;essai dynamique;dynamic benchmark problems dynamic evolutionary algorithm real world optimization problems uncertainty problems dynamic optimization category computational cost evolutionary information variable relocation randomly generated population;reuse;optimization problem;randomly generated population;uncertainty problems;performance improvement;transient response;respuesta transitoria;general population;relocation adaptation dynamic evolutionary algorithm dea optimization;random processes evolutionary computation optimisation;mathematical programming;dynamic benchmark problems;evolutionary computation uncertainty frequency convergence portfolios electricity supply industry deregulation electricity supply industry job shop scheduling computational efficiency history;adaptation;changement variable;random processes;programmation dynamique;competitiveness;computational cost;cost effectiveness;algorithme evolutionniste;algoritmo evolucionista;optimization;value function;dynamic evolutionary algorithm dea;evolutionary algorithm;electricity supply industry;evolutionary process;ensayo dinamico;dynamic test;dynamic optimization category;frequency;computational efficiency;competitivite;programmation mathematique;dynamic evolutionary algorithm;programacion matematica;variable transformation;reutilisation;fitness function;electricity supply industry deregulation;dynamic optimization;real world optimization problems	Many real-world optimization problems have to be solved under the presence of uncertainties. A significant number of these uncertainty problems falls into the dynamic optimization category in which the fitness function varies through time. For this class of problems, an evolutionary algorithm is expected to perform satisfactorily in spite of different degrees and frequencies of change in the fitness landscape. In addition, the dynamic evolutionary algorithm should warrant an acceptable performance improvement to justify the additional computational cost. Effective reuse of previous evolutionary information is a must as it facilitates a faster convergence after a change has occurred. This paper proposes a new dynamic evolutionary algorithm that uses variable relocation to adapt already converged or currently evolving individuals to the new environmental condition. The proposed algorithm relocates those individuals based on their change in function value due to the change in the environment and the average sensitivities of their decision variables to the corresponding change in the objective space. The relocation occurs during the transient stage of the evolutionary process, and the algorithm reuses as much information as possible from the previous evolutionary history. As a result, the algorithm shows improved adaptation and convergence. The newly adapted population is shown to be fitter to the new environment than the original or most randomly generated population. The algorithm has been tested by several dynamic benchmark problems and has shown competitive results compared to some chosen state-of-the-art dynamic evolutionary approaches.	algorithmic efficiency;benchmark (computing);circuit restoration;computation;cone;distribution (mathematics);dynamic programming;evolutionary algorithm;fitness function;mpeg-1 audio layer i;mathematical optimization;population;procedural generation;relocation (computing);time-invariant system;vergence	Yonas G. Woldesenbet;Gary G. Yen	2009	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2008.2009031	evolutionary programming;optimization problem;job shop scheduling;mathematical optimization;simulation;cost-effectiveness analysis;convergence;uncertainty;interactive evolutionary computation;fitness landscape;cultural algorithm;computer science;artificial intelligence;machine learning;dynamic programming;evolutionary algorithm;frequency;reuse;dynamic testing;bellman equation;fitness function;transient response;algorithm;evolutionary computation;adaptation	ML	26.581055980933865	0.9733410017965917	64158
7f1dde1ef70e85145021e6d7a80487cfff937ee5	soccer game optimization with substitute players	computacion informatica;metaheuristic methods;player substitution;soccer games optimization;ciencias basicas y experimentales;matematicas;grupo a	Metaheuristic methods are powerful optimization methods to solve various problems and have been used widely. In this paper, a player substitution mechanism to enhance the performance of the Soccer Game Optimization (SGO) is proposed. The substitution mechanism refers to the competition concept existing in the evolutionary algorithm. The substitute players are continuously updated to keep up with a set of best solutions so far. This paper discusses the sensitivity of its parameters as well as assesses the performance of the proposed method using unconstraint continuous problems. The proposed method is compared to the SGO without player substitution, Biogeography-based optimization (BBO), Ant Colony Optimization (ACO), Differential Evolution (DE), Evolutionary Strategies (ES), Genetic Algorithm (GA) and Particle Swarm Optimization (PSO). The experiment results show that the proposed method performs better than other algorithms used in this paper. Player substitution mechanism is proposed to enhance the Soccer Games Optimization.The proposed method is compared to SGO without substitution.The experiment results confirm the proposed method is better.We investigate the method sensitivity for unimodal and multimodal functions.	mathematical optimization	Hindriyanto Dwi Purnomo;Hui-Ming Wee	2015	J. Computational Applied Mathematics	10.1016/j.cam.2015.01.008	mathematical optimization	Theory	26.316767623842377	-3.4482459880867737	64170
1cf0866fa1a8bc6fd95c1cb7034e2381781e3d4e	coupled simulated annealing	chemical industry;continuous variables optimization;control systems;probability;simulated annealing probability;nonlinear control systems;continuous variable;temperature control;temperature sensors;simulated annealing sa;biological control systems;simulated annealing;distributed optimization;coupled simulated annealing;cooperative behavior;simulated annealing nonlinear control systems biological control systems control systems optimization methods temperature control quantum computing chemical industry temperature distribution temperature sensors;cooperative behavior coupled simulated annealing continuous variables optimization acceptance probability function parallel sa processes coupling term;coupling term;information exchange;parallel sa processes;acceptance probability function;global optimization;quantum computing;sista;simulated annealing sa cooperative behavior distributed optimization global optimization;temperature distribution;optimization methods	We present a new class of methods for the global optimization of continuous variables based on simulated annealing (SA). The coupled SA (CSA) class is characterized by a set of parallel SA processes coupled by their acceptance probabilities. The coupling is performed by a term in the acceptance probability function, which is a function of the energies of the current states of all SA processes. A particular CSA instance method is distinguished by the form of its coupling term and acceptance probability. In this paper, we present three CSA instance methods and compare them with the uncoupled case, i.e., multistart SA. The primary objective of the coupling in CSA is to create cooperative behavior via information exchange. This aim helps in the decision of whether uphill moves will be accepted. In addition, coupling can provide information that can be used online to steer the overall optimization process toward the global optimum. We present an example where we use the acceptance temperature to control the variance of the acceptance probabilities with a simple control scheme. This approach leads to much better optimization efficiency, because it reduces the sensitivity of the algorithm to initialization parameters while guiding the optimization process to quasioptimal runs. We present the results of extensive experiments and show that the addition of the coupling and the variance control leads to considerable improvements with respect to the uncoupled case and a more recently proposed distributed version of SA.	algorithm;code;control theory;emitter-coupled logic;energy, physics;evaluation;experiment;global optimization;information exchange;loss function;mathematical optimization;method (computer programming);probability;sample variance;simulated annealing;version	Samuel Xavier de Souza;Johan A. K. Suykens;Joos Vandewalle;Désiré Bollé	2010	IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)	10.1109/TSMCB.2009.2020435	mathematical optimization;chemical industry;information exchange;simulated annealing;computer science;machine learning;probability;temperature control;mathematics;quantum computer;statistics;global optimization	Vision	30.670882434405776	-6.35075964457794	64266
8956506e2eaa7f2109aa015e764aa54dbdc06d7f	a discrete competitive hopfield neural network for cellular channel assignment problems	satisfiability;hopfield neural network;channel assignment problem;stochastic dynamics;local minima;discrete competitive hopfield neural network	In this paper, we propose a discrete competitive Hopfield neural network (DCHNN) for the cellular channel assignment problem (CAP). The DCHNN can always satisfy the problem constraint and therefore guarantee the feasibility of the solutions for the CAP. Furthermore, the DCHNN permits temporary energy increases to escape from local minima by introducing stochastic dynamics. Simulation results show that the DCHNN has superior ability for the CAP within reasonable number of iterations. r 2005 Elsevier B.V. All rights reserved.	artificial neural network;assignment problem;benchmark (computing);hopfield network;iteration;maxima and minima;simulation;stochastic process	Jiahai Wang;Zheng Tang;Xinshun Xu;Yong Li	2005	Neurocomputing	10.1016/j.neucom.2004.08.007	stochastic neural network;mathematical optimization;artificial intelligence;machine learning;maxima and minima;mathematics;hopfield network;satisfiability	AI	30.639134155299896	3.408330981435998	64307
4bafd156bdf7af6d8b3105a309c37ba7050d0ec3	an enhanced bacterial foraging optimization with adaptive elimination-dispersal probability and pso strategy	convergence;particle swarm optimization;statistics;optimization;microorganisms;algorithm design and analysis;sociology	Bacterial Foraging Optimization(BFO) is a comparatively new optimization algorithm which learn from the foraging behavior of bacteria. The elimination and dispersal step is the major step of BFO to get the global search ability. An Enhanced Bacterial Foraging Algorithm (EBFO) is presented in this paper, which is a variation of the original BFO algorithm. This new algorithm uses an adaptive elimination-dispersal probability according to bacterial fitness, meanwhile it carry out an Particle Swarm Optimization (PSO) operator just after the swim step. From the result of experiment on 6 benchmark functions, we can draw the following conclusions that the new algorithm has the advantages of better global searching ability, speeder convergence and more precise convergence.	algorithm;basic formal ontology;benchmark (computing);mathematical optimization;particle swarm optimization;vergence	Xiong-fa Mai	2016	2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)	10.1109/FSKD.2016.7603168	algorithm design;mathematical optimization;multi-swarm optimization;meta-optimization;convergence;computer science;artificial intelligence;machine learning;microorganism;particle swarm optimization	Robotics	27.518927371124587	-4.845172705744059	64620
2d7d973bcbb330facf716fe5a0c1c89c20e3237d	diversification and entropy improvement on the dpso algorithm for dtsp		This paper introduces a new Discrete Particle Swarm Optimization (DPSO) algorithm for solving the Dynamic Traveling Salesman Problem (DTSP) with entropy diversity control. An experimental environment is stochastic and dynamic. Changeability requires the algorithm to have the ability to quickly adapt. Most scientists draw attention to the correlation between the population diversity and the convergence to the optimum. Controlling population variation allows for the control of a stable convergence of the algorithm to the optimum and provides a good mechanism for avoiding stagnation. This article describes the control of this parameter by examining the pheromone matrix by using the entropy measure. The results of the research on the different variants of the measure in the context of a dynamic TSP are presented.	algorithm;diversification (finance)	Urszula Boryczka;Lukasz Strak	2015		10.1007/978-3-319-15702-3_33	computer science;travelling salesman problem;matrix (mathematics);diversification (marketing strategy);population;algorithm;particle swarm optimization;convergence (routing)	NLP	27.444631140446358	-4.711821778602848	64841
022e65fd3245b36ada76c04cfdeaf3f915656cb5	improving interpretability in approximative fuzzy models via multi-objective evolutionary algorithms	multiobjective evolutionary algorithm;fuzzy model	Current research lines in fuzzy modeling mostly tackle with improving the accuracy in descriptive models, and the improving of the interpretability in approximative models. This paper deals with the second issue approaching the problem by means of multi-objective optimization in which accurate and interpretability criteria are simultaneously considered. Evolutionary Algorithms are specially appropriated for multi-objective optimization because they can capture multiple Pareto solutions in a single run of the algorithm. We propose a multi-objective evolutionary algorithm to find multiple Pareto solutions (fuzzy models) showing a trade-off between accuracy and interpretability. Additionally neural network based techniques in combination with ad hoc techniques for interpretability improving, are incorporated into the multi-objective evolutionary algorithm in order to improve the efficacy of the algorithm.	artificial neural network;evolutionary algorithm;fuzzy concept;hoc (programming language);kinetic data structure;mathematical optimization;multi-objective optimization;niche blogging;pareto efficiency	Antonio F. Gómez-Skarmeta;Fernando Jiménez;Gracia Sánchez	2003		10.1002/int.20233	mathematical optimization;computer science;artificial intelligence;machine learning;mathematics	AI	24.916448591328685	-7.176108963954035	64887
eaf6474047023288716db914877037a946a02087	global sensitivity analysis based on direct-kg-hdmr and thermal optimization of pin-fin heat sink for the platform inertial navigation system		In this study, in order to reduce the local high temperature of the platform in inertial navigation system (PINS), a pin-fin heat sink with staggered arrangement is designed. To reduce the dimension of the inputs and improve the efficiency of optimization, a feasible global sensitivity analysis (GSA) based on Kriging-High Dimensional Model Representation with DIviding RECTangles sampling strategy (DIRECT-KG-HDMR) is proposed. Compared with other GSA methods, the proposed method can indicate the effects of the structural and the material parameters on the maximum temperature at the bottom of the heat sink by using both sensitivity and coupling coefficients. From the results of GSA, it can be found that the structural parameters have greater effects on thermal performance than the material ones. Moreover, the coupling intensities between the structural and material parameters are weak. Therefore, the structural parameters are selected to optimize the thermal performance of the heat sink, and several popular optimization algorithms such as GA, DE, TLBO, PSO and EGO are used for the optimization. Moreover, steady thermal response of the PINS with the optimized heat sink is also studied, and its result shows that the maximum temperature of high temperature region of the platform is reduced by 1.09 °C compared with the PINS without the heat sink.	algorithm;coefficient;ego;global storage architecture;heat sink;inertial navigation system;kasparov's gambit;kriging;mathematical optimization;particle swarm optimization;pin grid array;sampling (signal processing);software release life cycle	Xiaosan Luo;Fengtao Xu;Ting Wang;Ting Wang;Yang Zeng	2018	CoRR			EDA	33.378146046882705	-3.9595565481389485	65039
87f33221175ac0b9accf8a1dd6a8e8490d32196e	hierarchical importance sampling instead of annealing	probabilistic models hierarchical importance sampling evolutionary algorithms;evolutionary computation;probability;cost function;probabilistic model;ising model;probability evolutionary computation;evolutionary algorithm;importance sampling;probability model;monte carlo methods electronic design automation and methodology evolutionary computation mathematical model entropy genetic algorithms optimization methods simulated annealing stability cost function	This paper proposes a novel method, hierarchical importance sampling (HIS), which can be used instead of converging the population for evolutionary algorithms based on probabilistic models (EAPM). In HIS, multiple populations are simulated simultaneously so that they have different diversities. This mechanism allows HIS to obtain promising solutions with various diversities. Experimental comparisons between HIS and the annealing (i.e., general EAPM) have revealed that HIS outperforms the annealing when applying to a problem of a 2D Ising model, which have many local optima. Advantages of HIS can be summarized as follows: (1) Since populations do not need to converge and do not change rapidly, HIS can build probability models with stability; (2) Since samples with better cost function values can be used for building probability models in HIS, HIS can obtain better probability models; (3)HIS can reuse historical results, which are normally discarded in the annealing.	converge;evolutionary algorithm;importance sampling;ising model;local optimum;loss function;population;sampling (signal processing);simulated annealing	Takayuki Higo;Keiki Takadama	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424464	ising model;statistical model;mathematical optimization;importance sampling;computer science;machine learning;evolutionary algorithm;probability;statistics;evolutionary computation	Vision	28.018347038185787	-8.222783502142635	65130
4218463a5406d0ede576311e09200ceffb20423e	the kl-ucb algorithm for bounded stochastic bandits and beyond	satisfiability;exponential family;large scale;science learning;indexation;timing analysis;lower bound	This paper presents a finite-time analysis of the KL-UCB algorithm, an online, horizonfree index policy for stochastic bandit problems. We prove two distinct results: first, for arbitrary bounded rewards, the KL-UCB algorithm satisfies a uniformly better regret bound than UCB and its variants; second, in the special case of Bernoulli rewards, it reaches the lower bound of Lai and Robbins. Furthermore, we show that simple adaptations of the KL-UCB algorithm are also optimal for specific classes of (possibly unbounded) rewards, including those generated from exponential families of distributions. A large-scale numerical study comparing KL-UCB with its main competitors (UCB, MOSS, UCB-Tuned, UCB-V, DMED) shows that KL-UCB is remarkably efficient and stable, including for short time horizons. KL-UCB is also the only method that always performs better than the basic UCB policy. Our regret bounds rely on deviations results of independent interest which are stated and proved in the Appendix. As a by-product, we also obtain an improved regret bound for the standard UCB algorithm.	algorithm;euler–bernoulli beam theory;kullback–leibler divergence;map overlay and statistical system;numerical analysis;rl (complexity);regret (decision theory);reinforcement learning;robbins v. lower merion school district;time complexity	Aurélien Garivier;Olivier Cappé	2011			mathematical optimization;exponential family;mathematics;mathematical economics;upper and lower bounds;static timing analysis;algorithm;statistics;satisfiability	ML	36.931166566599465	3.7333794556292483	65431
9269ebb05f92a5213a31e41688cda5a8af31aec9	computer-aided molecular design using tabu search	computacion informatica;grupo de excelencia;satisfiability;transition metal;optimization problem;transition metal catalysts;ciencias basicas y experimentales;computer aided molecular design;quimica;genetic algorithm;tabu search;computation time;molecular structure	A detailed implementation of the Tabu Search (TS) algorithm for computer-aided molecular design (CAMD) of transition metal catalysts is presented in this paper. Previous CAMD research has applied deterministic methods or genetic algorithms to the solution of the optimization problems which arise from the search for a molecule satisfying a set of property targets. In this work, properties are estimated using correlations based on connectivity indices, which allows the TS algorithm to use several novel operators to generate neighbors, such as swap and move, which would have no effect with a traditional group contribution-based approach. In addition, the formulation of the neighbor generation process guarantees that molecular valency and connectivity constraints are met, resulting in a complete molecular structure. Results on two case studies using TS are compared with a deterministic approach and show that TS is able to provide a list of good candidate molecules while using a much smaller amount of computation time.	adjacency matrix;atomic formula;commodore amiga midi driver;computation;electronic structure;feasible region;genetic algorithm;mathematical optimization;paging;tabu search;time complexity;topological index	Bao Lin;Sunitha Chavali;Kyle V. Camarda;David C. Miller	2005	Computers & Chemical Engineering	10.1016/j.compchemeng.2004.10.008	optimization problem;mathematical optimization;transition metal;simulation;genetic algorithm;molecule;tabu search;computer science;artificial intelligence;machine learning;mathematics;algorithm;satisfiability	EDA	24.852805119133464	1.9787409273537333	65518
ec4c762363a0fc30db6adda6ef70a61cdc155940	selection search for mean and temperature of multi-branch combinatorial games	article	This paper shows a new algorithm to calculate the mean and temperature of multi-branch combinatorial games. The algorithm gradually, one node at a time, expands the offspring of a game. After each step of expansion, the lower and upper bounds of the mean and temperature of the game is re-calculated. As the expanding process continues, the range between the lower and upper bounds is narrowed. The key feature of the algorithm is its ability to generate a path whose outcome is most likely to reduce the distance between the lower and upper bounds.	display resolution;game theory;mathematical model;national supercomputer centre in sweden;pc game;search algorithm;the offspring;web search engine	Kuo-Yuan Kao;I-Chen Wu;Yi-Chang Shan;Shi-Jim Yen	2012	ICGA Journal	10.3233/ICG-2012-35303	mathematical optimization;computer science;machine learning;mathematics;mathematical economics;combinatorial search	ML	26.03300913843368	1.9639929248032293	65988
ecdece930aa900a6336e901dff72ec6a00d22bda	optimal feature selection using distance-based discrete firefly algorithm with mutual information criterion		In this paper, we investigate feature subset selection problem by a new self-adaptive firefly algorithm (FA), which is denoted as DbFAFS. In classical FA, it uses constant control parameters to solve different problems, which results in the premature of FA and the fireflies to be trapped in local regions without potential ability to explore new search space. To conquer the drawbacks of FA, we introduce two novel parameter selection strategies involving the dynamical regulation of the light absorption coefficient and the randomization control parameter. Additionally, as an important issue of feature subset selection problem, the objective function has a great effect on the selection of features. In this paper, we propose a criterion based on mutual information, and the criterion can not only measure the correlation between two features selected by a firefly but also determine the emendation of features among the achieved feature subset. The proposed approach is compared with differential evolution, genetic algorithm, and two versions of particle swarm optimization algorithm on several benchmark datasets. The results demonstrate that the proposed DbFAFS is efficient and competitive in both classification accuracy and computational performance.	benchmark (computing);coefficient;computation;differential evolution;eisenstein's criterion;feature selection;firefly (cache coherence protocol);firefly algorithm;genetic algorithm;loss function;mathematical optimization;mutual information;optimization problem;particle swarm optimization;selection algorithm;software release life cycle	Long Zhang;Linlin Shan;Jianhua Wang	2016	Neural Computing and Applications	10.1007/s00521-016-2204-0	mathematical optimization;machine learning;pattern recognition;mathematics;feature selection	ML	26.744570602713814	-4.920364156580211	65992
46fbe2e3d82b6f058806e550431df7b41fd909ca	modified differential evolution with local search algorithm for real world optimization	optimisation;differential evolution;convergence;evolutionary computation;local search algorithm;cdels algorithm differential evolution local search algorithm real world optimization problems evolutionary algorithm multipopulation based memetic algorithm distant search method hybrid mutation strategy proximity checking method;search space;search problems evolutionary computation optimisation;search methods;search method;optimization algorithm design and analysis evolutionary computation search methods genetic algorithms convergence gaussian distribution;numerical optimization;memetic algorithm;optimization problem;real world application;real world numerical optimization problems;real world numerical optimization problems memetic algorithm differential evolution;genetic algorithm;genetic algorithms;optimization;search problems;evolutionary algorithm;optimal algorithm;local search;algorithm design and analysis;gaussian distribution;evolutionary computing	Real world optimization problems are used to judge the performance of any Evolutionary Algorithm (EA) over real world applications. This is why the performance of any EA over the real world optimization problems is very important for judging its efficiency. In this work, we represent a multi-population based memetic algorithm CDELS. It is hybridization of a competitive variant of Differential Evolution (DE) and a Local Search method. As the number of optima is large in this case, we have also incorporated a distant search method to hop from one optima to other optima. However, it is well known that DE has fast but less reliable convergence property. To overcome this limitation, a hybrid mutation strategy is developed to balance between exploration and thorough search. In addition, a proximity checking method is applied to distribute the subpopulations over a larger portion of the search space as this further enhances the searching ability of the algorithm. The performance of CDELS algorithm is evaluated on the test suite provided for the Competition on Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems in the 2011 IEEE Congress on Evolutionary Computation and the simulation results are shown in this paper.	differential evolution;evolutionary algorithm;ieee congress on evolutionary computation;local optimum;local search (constraint satisfaction);local search (optimization);mathematical optimization;maxima and minima;memetic algorithm;optimization problem;radiation pattern;search algorithm;simulation;table (information);test suite	Ankush Mandal;Aveek Kumar Das;Prithwijit Mukherjee;Swagatam Das;Ponnuthurai Nagaratnam Suganthan	2011	2011 IEEE Congress of Evolutionary Computation (CEC)	10.1109/CEC.2011.5949802	mathematical optimization;genetic algorithm;computer science;local search;machine learning;mathematics;algorithm;evolutionary computation	Robotics	26.097345321386975	-3.582505046759787	66255
1867bb287a0818d63dbe610322710f338b5b7551	on free surface pde constrained shape optimization problems	shape optimization;fluid dynamics;free surface flow	Shape optimization problems in fluid dynamics governed by the free surface flows are considered. Such problems are inspired by the process of continuous casting of steel where optimization of large vortex structures in different metallurgical reactors is of paramount importance to ensure good quality output. The pseudo-transient approach is used as solution strategy for solving the free surface problem. Design sensitivities involving different cost functionals are derived using a formal Lagrangian framework. Numerical results are presented which indicate the success of the proposed algorithm for solving this free surface shape optimization problem.	algorithm;linear programming relaxation;mathematical optimization;numerical analysis;numerical method;optimization problem;shape optimization;vortex	H. Kasumba;Karl Kunisch	2012	Applied Mathematics and Computation	10.1016/j.amc.2012.05.032	mathematical optimization;shape optimization;control theory;mathematics;geometry;continuous optimization;fluid dynamics	Vision	30.17859354970947	-0.55368656720459	66368
84377efafd8fd2959d85274e8c878ecd640942bc	opposition-based initialization and a modified pattern for inertia weight (iw) in pso		Particle Swarm Optimization (PSO) is an evolutionary computing algorithm and is successfully used to solve complex real world optimization problems. Due to the complex nature of optimization problems, PSO endures the problems like premature convergence or being trapped in local minima, to avoid such situation the role of swarm initialization is very important. In this research we propose a new method to initialize the swarm particles on the basis of Generalized Opposition-based Learning (GOBL). The aim for GOBL strategy is to have an initial swarm with already fittest particles to set a solid ground for the rest of PSO algorithm to execute. Moreover, a strategy for linearly decreasing Inertia Weight has been proposed to equalize the proportions of exploration as well as exploitation capabilities of particles during the search process. The motivation behind incorporating the changes in standard PSO is to evade the earlier convergence and to help the algorithm in escaping from being trapped in local minimum. To assess the performance of proposed PSO variant, we practiced this algorithm on 8 different benchmark functions and results were compared with 4 other PSO versions found in literature. From the results analysis it is apparent that projected changes in the PSO increases its overall performance and efficiency especially when dealing with the noisy optimization problems. Also the proposed algorithm performs better and is more robust as compared to other algorithms for achieving desired results.	algorithm;benchmark (computing);computational complexity theory;evolutionary computation;exploit (computer security);iw engine;local optimum;mathematical optimization;maxima and minima;optimization problem;particle swarm optimization;premature convergence;vii	Mehr Umer Farooq;Akhlaque Ahmad;Abdul Hameed	2017	2017 IEEE International Conference on INnovations in Intelligent SysTems and Applications (INISTA)	10.1109/INISTA.2017.8001139	evolutionary computation;swarm behaviour;initialization;multi-swarm optimization;mathematical optimization;machine learning;particle swarm optimization;premature convergence;artificial intelligence;convergence (routing);mathematics;optimization problem	Robotics	27.368542304661123	-4.355635547709633	66500
9332bcde5aba9a4fa7c652c43510ecccad141f3a	color image cryptosystem using chaotic maps	image encryption;diffusion image encryption chaos theory chaotic map color image confusion;image coding;chaotic map;confusion;image colour analysis;cryptography;real time image encryption color image cryptosystem chaotic maps random like behavior encryption algorithm symmetric image cipher confusion diffusion architecture chaotic 2d standard map 1d logistic map chaotic standard map brute force attack diffusion process key space analysis key sensitivity test statistical analysis visual test correlation coefficients differential analysis;diffusion;color image;image colour analysis cryptography image coding;chaos theory;pixel encryption chaotic communication logistics	Image encryption is somehow different from text encryption due to some inherent features of image such as bulk data capacity and high correlation among pixels, which are generally difficult to handle by traditional methods. The exceptionally desirable properties of the chaotic maps such as sensitivity to initial conditions and random-like behavior have attracted the attention of cryptographers to develop new encryption algorithms. This paper proposes a new symmetric image cipher based on the widely used confusion-diffusion architecture which utilizes the chaotic 2D Standard map and 1D Logistic map. It is specifically designed for the color images, which are 3D arrays of data streams. We prefer chaotic Standard map to Baker and Cat maps since the key space of the chaotic Standard map is large enough as compared to the Baker and Cat maps, which makes the brute-force attack infeasible. The initial conditions and system parameters of the chaotic maps constitute the secret key of the algorithm. To further enhance the security, the control parameters used in the confusion stage and the keystream employed for diffusion stage are distinct in different rounds and related to the plain-image. These control parameters are generated by a Tent map. For getting higher security and higher complexity, the current scheme employs two kinds of diffusion processes namely the horizontal and vertical diffusions which are completed by mixing the properties of horizontally and vertically adjacent pixels using a Logistic map, respectively. The results of several experiments, including the most important ones like key space analysis, key sensitivity test, statistical analysis, and visual test by histograms of encrypted images, the correlation coefficients of adjacent pixels, and differential analysis, demonstrate the satisfactory security and efficiency of the proposed image encryption scheme for real-time image encryption and transmission.	128-bit;3d computer graphics;algorithm;brute-force attack;cipher;coefficient;color image;confusion and diffusion;cryptosystem;encryption;experiment;information security;initial condition;key (cryptography);key space (cryptography);list of chaotic maps;list of cryptographers;logistic map;numerical analysis;pixel;real-time clock;standard map;tent map;visual test	Sahar Mazloom;Amir-Masoud Eftekhari-Moghadam	2011	2011 IEEE Symposium On Computational Intelligence For Multimedia, Signal And Vision Processing	10.1109/CIMSIVP.2011.5949254	computer vision;theoretical computer science;mathematics;computer security;probabilistic encryption	Vision	38.520309980694805	-8.79408328322802	66699
bda87344059f5d6fa4f5a2316a4230337c2cb05c	adaptive mufti-objective particle swarm optimization algorithm	performance measure;evolutionary computation;multi objective optimization;function optimization;multi objective particle swarm optimization;particle swarm optimizer;function optimization problems adaptive multiobjective particle swarm optimization acceleration coefficient diversity parameter evolutionary algorithms;particle swarm optimisation evolutionary computation;evolutionary algorithm;particle swarm optimization algorithm;particle swarm optimisation;particle swarm optimization acceleration evolutionary computation nearest neighbor searches birds programmable control adaptive control sorting testing displays	In this article we describe a novel Particle Swarm Optimization (PSO) approach to Multi-objective Optimization (MOO) called Adaptive Multi-objective Particle Swarm Optimization (AMOPSO). AMOPSO algorithm's novelty lies in its adaptive nature, that is attained by incorporating inertia and the acceleration coefficient as control variables with usual optimization variables, and evolving these through the swarming procedure. A new diversity parameter has been used to ensure sufficient diversity amongst the solutions of the non dominated front. AMOPSO has been compared with some recently developed multi-objective PSO techniques and evolutionary algorithms for nine function optimization problems, using different performance measures.	archive;coefficient;evolutionary algorithm;mathematical optimization;multi-objective optimization;pareto efficiency;particle swarm optimization;premature convergence;program optimization	Praveen Kumar Tripathi;Sanghamitra Bandyopadhyay;Sankar K. Pal	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424755	mathematical optimization;multi-swarm optimization;meta-optimization;parallel metaheuristic;swarm intelligence;computer science;derivative-free optimization;artificial intelligence;multi-objective optimization;machine learning;evolutionary algorithm;mathematics;imperialist competitive algorithm;particle swarm optimization;metaheuristic;evolutionary computation	Vision	26.24669301626519	-6.2937919052142	66799
b2f47fe29a709d1ec6e03c3b6eee5756cdcdedbf	use of quadratic models with mesh-adaptive direct search for constrained black box optimization	constrained optimization;mesh adaptive direct search;quadratic models;mesh adaptive direct search algorithms mads;mesh adaptive direct search mads algorithms;derivative free optimization;direct search;black box optimization	We consider derivative-free optimization, and in particular black box optimization, where the functions to minimize and the functions representing the constraints are given by black boxes without derivatives. Two fundamental families of methods are available: Model-based methods and directional direct search algorithms. This work exploits the flexibility of the second type of method in order to integrate to a limited extent the models used in the first family. Intensive numerical tests on two sets of forty-eight and one hundred and four test problems illustrate the efficiency of this hybridization and show that the use of models improves significantly the mesh adaptive direct search algorithm.	black box;derivative-free optimization;mathematical optimization;numerical analysis;search algorithm	Andrew R. Conn;Sébastien Le Digabel	2013	Optimization Methods and Software	10.1080/10556788.2011.623162	beam search;mathematical optimization;constrained optimization;simulation;test functions for optimization;derivative-free optimization;machine learning;mathematics;metaheuristic	ML	28.75373203086644	-1.050801154295838	67013
4f1cd1bbdc69400d3e188534b90a00c5ca71e10a	real-coded chemical reaction optimization with different perturbation functions	optimisation chemical reactions exponential distribution gaussian distribution;optimisation;exponential distribution;conference_paper;rayleigh distribution;evolutionary algorithm chemical reaction optimization gaussian distribution cauchy distribution exponential distribution rayleigh distribution;chemical reaction optimization;distribution function real coded chemical reaction optimization perturbation function metaheuristic cro design continuous problem probability distribution gaussian distribution cauchy distribution exponential distribution rayleigh distribution benchmark function;cauchy distribution;optimization;chemical reactions;gaussian distribution optimization benchmark testing exponential distribution distribution functions containers;distribution functions;evolutionary algorithm;gaussian distribution;benchmark testing;containers	Chemical Reaction Optimization (CRO) is a powerful metaheuristic which mimics the interactions of molecules in chemical reactions to search for the global optimum. The perturbation function greatly influences the performance of CRO on solving different continuous problems. In this paper, we study four different probability distributions, namely, the Gaussian distribution, the Cauchy distribution, the exponential distribution, and a modified Rayleigh distribution, for the perturbation function of CRO. Different distributions have different impacts on the solutions. The distributions are tested by a set of wellknown benchmark functions and simulation results show that problems with different characteristics have different preference on the distribution function. Our study gives guidelines to design CRO for different types of optimization problems.	benchmark (computing);fits;feasible region;global optimization;interaction;lam/mpi;mathematical optimization;metaheuristic;perturbation function;program optimization;rayleigh–ritz method;simulation;time complexity;woo–lam	James J. Q. Yu;Albert Y. S. Lam;Victor O. K. Li	2012	2012 IEEE Congress on Evolutionary Computation	10.1109/CEC.2012.6252925	normal distribution;exponential distribution;benchmark;mathematical optimization;chemical reaction;rayleigh distribution;distribution function;evolutionary algorithm;cauchy distribution;statistics	Metrics	29.156570249191958	-8.421316178553186	67065
fe5e65be44e840e5ea541bd225a0a5c6e12c77fa	parallel image encryption with bitplane decomposition and genetic algorithm		Image encryption is an efficient technique to protect image content from unauthorized parties. In this paper a parallel image encryption method based on bitplane decomposition is proposed. The original grayscale image is converted to a set of binary images by local binary pattern (LBP) technique and bitplane decomposition (BPD) methods. Then, permutation and substitution steps are performed by genetic algorithm (GA) using crossover and mutation operations. Finally, these scrambled bitplanes are combined together to obtain encrypted image. Instead of random population selection in GA, a deterministic method with security keys is utilized to improve security level. The proposed encryption method has parallel processing capability for multiple bitplanes encryption. This distributed GA with multiple populations increases encryption speed and makes it suitable for real-time applications. Simulations and security analysis are done to demonstrate efficiency of our algorithm.	authorization;binary image;binary pattern (image generation);bit plane;computer simulation;crossover (genetic algorithm);encryption;experiment;genetic algorithm;graphics processing unit;grayscale;key (cryptography);local binary patterns;parallel computing;pixel;population;qr decomposition;randomness;real-time computing;real-time transcription;robustness (computer science);software release life cycle	Saeed Mozaffari	2018	Multimedia Tools and Applications	10.1007/s11042-018-5817-8	computer science;permutation;local binary patterns;genetic algorithm;grayscale;artificial intelligence;crossover;encryption;pattern recognition;binary image;population	EDA	38.75803356753639	-8.893871943694675	67071
e981ae637455c1aa6569bbdf50e8258d3bb93c07	investigating multi-view differential evolution for solving constrained engineering design problems	constrained optimization;differential evolution;metaheuristics;evolutionary computations;global optimization	Several constrained and unconstrained optimization problems have been adequately solved over the years thanks to advances in the metaheuristics area. In the last decades, di erent metaheuristics have been proposed employing new ideas, and hybrid algorithms that improve the original metaheuristics have been developed. One of the most successfully employed metaheuristics is the Di erential Evolution. In this paper it is proposed a Multi-View Di erential Evolution algorithm (MVDE) in which several mutation strategies are applied to the current population to generate di erent views at each iteration. The views are then merged according to the winner-takes-all paradigm, resulting in automatic exploration/exploitation balance. MVDE was tested to solve a set of well-known constrained engineering design problems and the obtained results were compared to those from many state-of-the-art metaheuristics. Results show that MVDE was very competitive in the considered problems, largely outperforming several of the compared algorithms.	algorithm;differential evolution;engineering design process;iteration;mathematical optimization;metaheuristic;programming paradigm	Vinicius Veloso de Melo;Grazieli Luiza Costa Carosio	2013	Expert Syst. Appl.	10.1016/j.eswa.2012.12.045	differential evolution;mathematical optimization;constrained optimization;ant colony optimization algorithms;parallel metaheuristic;computer science;machine learning;mathematics;algorithm;global optimization	AI	25.406801353520116	-3.1563747972844065	67125
9ad33ea0cf31c849a62705bf72081ae07d7bff02	robust motion estimation for overlapping images via genetic algorithm	levenberg marquardt;genetic algorithms encoding robustness optimization motion estimation computer vision biological cells;least mean squares methods;motion estimation computer vision genetic algorithms least mean squares methods;motion estimation;computer vision;levenberg marquardt algorithm robust motion estimation overlapping images genetic algorithm computer vision motion parameter chromosome roulette wheel selection arithmetic crossover adaptive mutation operator normalized registration error least squares algorithm;least square;robust method;genetic algorithm;genetic algorithms;direct search	We propose a robust method based on genetic algorithm for the estimation of the motion between two successive overlapping images, a classic problem in computer vision. To calculate the motion parameters encoded as a chromosome, we employed roulette wheel selection and total arithmetic crossover and developed a novel adaptive mutation operator. The experimental results show that the normalized registration error of the final solution exhibits a significant improvement over those obtained by direct search approaches to such problems. Also, in contrast to other popular approaches such as the least-squares and Levenberg-Marquardt algorithm, the proposed method can escape from local extrema and can potentially produce the global optimum.	artificial intelligence;computer vision;fitness function;fitness proportionate selection;genetic algorithm;global optimization;least squares;levenberg–marquardt algorithm;mathematical optimization;maxima and minima;motion estimation;optimization problem;software release life cycle	Yingchun Zhang;Juan Cao;Bohong Su	2012	2012 8th International Conference on Natural Computation	10.1109/ICNC.2012.6234722	computer vision;mathematical optimization;computer science;machine learning;population-based incremental learning	Robotics	29.57030952607318	-4.696966305292228	67128
5c518d67b804fabd4612f5c73f08a13321388119	a computational intelligence algorithm for simulation-driven optimization problems	model selection;classification;simulation driven optimization;expensive functions;evolutionary algorithms;modeling	The modern engineering design process often relies on computer simulations to evaluate candidate designs. This simulation-driven approach results in what is commonly termed a computationally expensive black-box optimization problem. In practise, there will often exist candidate designs which cause the simulation to fail. Such simulation failures can consume a large portion of the allotted computational resources, and thus can lead to search stagnation and a poor final solution. To address this issue, this study proposes a new computational intelligence optimization algorithm which combines a model and a k-NN classifier. The latter predicts which solutions are expected to cause the simulation to fail, and its prediction is incorporated with the model prediction to bias the search towards valid solutions, namely, for which the simulation is expected to succeed. A main contribution of this study is that to further improve the search efficacy, the proposed algorithm leverages on model-selection theory and continuously calibrates the classifier during the search. An extensive performance analysis using an engineering application of airfoil shape optimization shows the efficacy of the proposed algorithm. 2011 Elsevier Ltd. All rights reserved.	analysis of algorithms;black box;computation;computational intelligence;computational resource;computer simulation;engineering design process;k-nearest neighbors algorithm;mathematical optimization;model selection;optimization problem;shape optimization	Yoel Tenne	2012	Advances in Engineering Software	10.1016/j.advengsoft.2011.12.009	mathematical optimization;engineering optimization;systems modeling;biological classification;computer science;artificial intelligence;machine learning;evolutionary algorithm;data mining;mathematics;algorithm;model selection;statistics	AI	30.886018903233655	-6.756552603788505	67269
7f7b4a4484f85e88026fe03ccecf50054086d7fc	combinatorial optimization of stochastic multi-objective problems: an application to the flow-shop s	stochastic processing times;stochastic process;multi objective optimization;flow shop scheduling;dynamic environment;stochasticity;probability distribution;random variable;multi objective combinatorial optimization;evolutionary algorithm;combinatorial optimization;flow shop;evolutionnary algorithms;fitness function	The importance of multi-objective optimization is globably established nowadays. Furthermore, a great part of real-world problems are subject to uncertainties due to, e.g., noisy or approximated fitness function(s), varying parameters or dynamic environments. Moreover, although evolutionary algorithms are commonly used to solve multiobjective problems on the one hand and to solve stochastic problems on the other hand, very few approaches combine simultaneously these two aspects. Thus, flow-shop scheduling problems are generally studied in a single-objective deterministic way whereas they are, by nature, multiobjective and are subjected to a wide range of uncertainties. However, these two features have never been investigated at the same time. In this paper, we present and adopt a proactive stochastic approach where processing times are represented by random variables. Then, we propose several multi-objective methods that are able to handle any type of probability distribution. Finally, we experiment these methods on a stochastic bi-objective flow-shop problem.	approximation algorithm;combinatorial optimization;evolutionary algorithm;fitness approximation;flow shop scheduling;mathematical optimization;multi-objective optimization;scheduling (computing)	Arnaud Liefooghe;Matthieu Basseur;Laetitia Vermeulen-Jourdan;El-Ghazali Talbi	2006		10.1007/978-3-540-70928-2_36	stochastic neural network;stochastic programming;probabilistic-based design optimization;optimization problem;mathematical optimization;combinatorics;continuous-time stochastic process;stochastic optimization;machine learning;mathematics	AI	30.159064039350692	1.8373125933948504	67439
62ae4296700d2365640249716e0ad096bb5204d3	fast path-based neural branch prediction	learning (artificial intelligence);neural nets;parallel architectures;perceptrons;performance evaluation;branch misprediction latency;fast path-based neural branch prediction;industrial designs;instructions-per-cycle rate;microarchitectural prediction;microarchitectures;neural learning;neural prediction;perceptron predictor	Microarchitectural prediction based on neural learninghas received increasing attention in recent years. However,neural prediction remains impractical because its superioraccuracy over conventional predictors is not enough to offsetthe cost imposed by its high latency. We present a newneural branch predictor that solves the problem from bothdirections: it is both more accurate and much faster thanprevious neural predictors. Our predictor improves accuracyby combining path and pattern history to overcomelimitations inherent to previous predictors. It also has muchlower latency than previous neural predictors. The result isa predictor with accuracy far superior to conventional predictorsbut with latency comparable to predictors from industrialdesigns. Our simulations show that a path-basedneural predictor improves the instructions-per-cycle (IPC)rate of an aggressively clocked microarchitecture by 16%over the original perceptron predictor.	branch predictor;clock rate;fast path;instructions per cycle;kerrison predictor;microarchitecture;neural oscillation;perceptron;simulation	Daniel A. Jiménez	2003		10.1145/956417.956562	parallel computing;real-time computing;industrial design;computer science;perceptron;machine learning;time delay neural network;branch predictor;instructions per cycle	Arch	37.54365119729403	-2.185612910329326	67605
065a355ebb51570c7a7f13dd41a0ec0e40675c17	adaptive particle swarm optimizer with nonextensive schedule	swarm intelligence;global search;particle swarm optimizer;nonextensive statistical mechanics	This paper introduces a class of adaptive particle swarm optimization (PSO) methods that build on the theory of nonextensive statistical mechanics. These methods combine the traditional position update rule with an annealing schedule that is based on the nonextensive entropy. Comparative experiments conducted on benchmark functions, have showed that the tested algorithms outperform the standard PSO.	approximation algorithm;benchmark (computing);experiment;mathematical optimization;nonextensive entropy;particle swarm optimization;phase-shift oscillator;simulated annealing	Aristoklis D. Anastasiadis;George D. Georgoulas;George D. Magoulas;Anthony Tzes	2007		10.1145/1276958.1276982	mathematical optimization;multi-swarm optimization;swarm intelligence;computer science;artificial intelligence;machine learning	AI	26.902180856407146	-4.83051010667179	67679
cb96152338d77d4b06ffc49ec34c30c025316ece	a hybrid evolution strategy for mixed discrete continuous constrained problems	continuous variable;optimization problem;hybrid method;evolution strategy;evolutionary algorithm;mechanism design	In this paper, a hybrid evolution strategy is proposed to solve mixed discrete continuous constrained problems. We consider that the functions of the problems are differentiable with respect to the continuous variables but are not with respect to the discrete ones. Evolutionary algorithms are well suited to solve these difficult optimization problems but the number of evaluations is generally very high. The presented hybrid method combines the advantages of evolutionary algorithms for the discrete variables and those of classical gradient-based methods for the continuous variables in order to accelerate the search. The algorithm is based on a dual formulation of the optimization problem. The efficiency of the method is demonstrated through an application to two complex mechanical design problems with mixed-discrete variables.	constrained optimization;evolution strategy;evolutionary algorithm;gradient;mathematical optimization;newton;optimization problem	Laurence Giraud-Moreau;Pascal Lafon	1999		10.1007/10721187_9	optimization problem;mathematical optimization;constrained optimization;cma-es;machine learning;continuous optimization;evolution strategy;mathematical economics	AI	29.094958178575492	-0.9068026090647405	67767
b48a8c619a36285bf04eaeb95ac06384caf742bf	a modified particle swarm optimization algorithm for community detection in complex networks		Community structure is an interesting feature of complex networks. In recent years, various methods were introduced to extract community structure of networks. In this study, a novel community detection method based on a modified version of particle swarm optimization, named PSO-Net is proposed. PSO-Net selects the modularity Q as the fitness function which is a suitable quality measure. Our innovation in PSO algorithm is changing the moving strategy of particles. Here, the particles take part in crossover operation with their personal bests and the global best. Then, in order to avoid falling into the local optimum, a mutation operation is performed. Experiments on synthetic and real-world networks confirm a significant improvement in terms of convergence speed with higher modularity in comparison with recent similar approaches.	algorithm;particle swarm optimization	Alireza Abdollahpouri;Shadi Rahimi;Shahnaz Mohammadi Majd;Chiman Salavati	2018		10.1007/978-3-319-99740-7_2	crossover;complex network;local optimum;mathematical optimization;modularity;community structure;particle swarm optimization;computer science;convergence (routing);fitness function	AI	26.96058456431239	-4.094338028510852	67874
54cf48a9397cd868695bbe60a1d3206369ea1fd7	mixed ifs: resolution of the inverse problem using genetic programming	inverse problem for ifs;fractals;genetic program;genetic programming;simulated annealing;inverse problem;genetic algorithm	"""We address here the resolution of the so-called inverse problem for IFS. This problem has already been widely considered, and some studies have been performed for a ne IFS, using deterministic or stochastic methods (Simulated Annealing or Genetic Algorithm) [17, 10]. When dealing with non a ne IFS, the usual techniques do not perform well, except if some a priori hypotheses on the structure of the IFS (number and type functions) are made. In this work, a Genetic Programming method is investigated to solve the \general"""" inverse problem, which permits to perform at the same time a numeric and a symbolic optimization. The use of \mixed IFS"""", as we call them, may enlarge the scope of some applications, as for example image compression, because they allow to code a wider range of shapes. Key-words: Fractals, Genetic Programming, Inverse problem for IFS"""	fractal;genetic algorithm;genetic programming;image compression;mathematical optimization;ne (complexity);simulated annealing	Guillaume Cretin;Evelyne Lutton;Jacques Lévy Véhel;Philippe Glevarec;Cédric Roll	1995		10.1007/3-540-61108-8_42	mathematical optimization;combinatorics;discrete mathematics;mathematics	PL	28.917451989170015	-0.05795512616344653	67913
636f16d5d32e51e31cca1ad239783a195f6aea0b	constraint-directed search in computational finance and economics	constraint satisfaction;direct search;computational finance	Constraints shield solutions from a problem solver. However, in the hands of trained constraint problem solvers, the same constraints that create the problems in the first place can also guide problem solvers to solutions. Constraint satisfaction is all about learning how to flow with the force of the constraints. Examples of using constraints to guide one’s search are abundant in complete search methods (e.g. see [1, 2]). Lookahead algorithms propagate constraints in order to (a) reduce the remaining problem to smaller problems and (b) detect dead-ends. Dependency-directed backtracking algorithms use constraints to identify potential culprits in dead-ends. This helps the search to avoid examining (in vain) combinations of variables assignments that do not matter. Constraint-directed search is used in stochastic search too. Constraints were used in Guided Local Search (GLS) [3] and Guided Genetic Algorithm (GGA) [4] to guide the search to promising areas of the search space. In stochastic methods, a constraint satisfaction problem is handled as an optimization problem, where the goal is to minimize the number of constraints violated. The approach in GLS is to use constraints to augment the objective function. This helps local search to escape local optima. GGA uses the GLS penalty scheme to change the behaviour of genetic algorithms. This results in a more robust algorithm which finds quality results consistently. GLS and GGA have been applied to many optimization problems, including the well-known travelling salesman problem and quadric assignment problem. The GLS idea was generalized to “penalties” and “incentives” in evolutionary computation. This paper explains how such ideas were applied to two applications in finance and economics: financial forecasting and automated bargaining.	assignment problem;backtracking;computational finance;constraint satisfaction problem;emoticon;evolutionary computation;generalized least squares;genetic algorithm;guided local search;local optimum;local search (constraint satisfaction);local search (optimization);mathematical optimization;optimization problem;parsing;solver;stochastic optimization;travelling salesman problem;whole earth 'lectronic link	Edward P. K. Tsang	2010		10.1007/978-3-642-15396-9_2	mathematical optimization;actuarial science;constraint satisfaction;computational finance;computer science;mathematical economics	AI	29.387593038375968	0.2724704422098573	67921
47d1df4be112e6fe69989bd079d15ab741bb2303	local search metaheuristics with reduced searching diameter		In the paper we present some methods of empirical research of optimization problems’ solution space, for which solutions are represented by permutations. Sampling the feasible solutions set we determine a histogram of frequency of incidence of local minima measuring its distance to the neighborhood graph’s center. On its basis we verify a statistical hypothesis on normal distribution occurrence of local minima. Due to this research we can significantly reduce the area of the searching process during a local search metaheuristics work, focusing the searching process on Big Valley. We propose an algorithm with changeable diameter of the search.	local search (optimization);metaheuristic	Wojciech Bozejko;Andrzej Gnatowski;Czeslaw Smutnicki;Mariusz Uchronski;Mieczyslaw Wodecki	2017		10.1007/978-3-319-74718-7_54	machine learning;artificial intelligence;computer science;permutation;statistical hypothesis testing;sampling (statistics);local search (optimization);metaheuristic;histogram;maxima and minima;optimization problem	Robotics	25.610647040634053	-0.4478591431710819	67955
929e86a3b23faf6fc12bfcd0cfec8c9c642e980a	voronoi diagrams based function identification	spatial structure;evolutionary algorithm;voronoi diagram;evolutionary algo rithm	Evolutionary algorithms have been applied to function identification problems with great success. This paper presents an approach in which the individuals represent a partition of the input space in Voronoi regions together with a set of local functions associated to each one of these regions. In this way, the solution corresponds to a combination of local functions over a spatial structure topologically represented by a Voronoi diagram. Experiments show that the evolutionary algorithm can successfully evolve both the partition of the input space and the parameters of the local functions in simple problems.	evolutionary algorithm;voronoi diagram	Carlos Kavka;Marc Schoenauer	2003		10.1007/3-540-45105-6_118	mathematical optimization;combinatorics;discrete mathematics;weighted voronoi diagram;voronoi diagram;centroidal voronoi tessellation;computer science;lloyd's algorithm;evolutionary algorithm;mathematics	Graphics	26.82007336043506	1.0712748640672143	68235
c6de80fb4ce667d5dab22757264ab97104650dd1	multipopulational metaheuristic approaches to real-parameter optimization		Multipopulational metaheuristic methods have been used to solve a variety of problems. The use of multiple populations evolved in parallel and exchanging data according to a particular communication strategy is known to mitigate premature convergence, enlarge diversity of the populations, and generally improve the results obtained by the methods maintaining a sole panmictic population of candidate solutions. Moreover, multipopulational algorithms can be easily parallelized and efficiently accelerated by contemporary multicore and distributed architectures. In this work, we study two populational real-parameter optimization metaheuristics in a traditional and multipopulational configuration, and propose a new heterogeneous multipopulational approach. The usefulness of the new method is briefly evaluated on experiments with several well known test functions for real-parameter optimization.	metaheuristic;program optimization	Václav Snásel;Pavel Krömer	2014		10.1007/978-3-319-12286-1_11	parallel metaheuristic;tabu search;search-based software engineering;metaheuristic	EDA	25.33728731075169	-3.516766836378203	68294
c047acfcfea318630fc4f739d12de04dd8d8e5e3	in memoriam alex s. fraser [1923-2002]	obituary;obituary alex s fraser;alex s fraser	T HE EVOLUTIONARY computation community lost one of its pioneers on July 14, 2002, when Alex S. Fraser passed away as a result of complications from a heart attack. Fraser was one of the first to conceive and execute computer simulations of genetic systems, and his efforts in the 1950s and 1960s had a profound impact on computational models of evolutionary systems. The simulation algorithms he used were important not only in the simulation of genetical problems, but provided a menu of techniques that enriched the entire simulation effort in any problem that involved probability sampling among a population of alternatives, the heart of Monte Carlo methods. Fraser was born in London, U.K., and lived in Hong Kong for most of his youth; however, he studied at the University of New Zealand, and later went to the University of Edinburgh, and subsequently to the Commonwealth Scientific and Industrial Research Organisation (CSIRO) in Sydney, Australia. It was at the CSIRO where Fraser made his seminal contributions to evolutionary computation. Following the construction of the ILLIAC computer at the University of Chicago, CSIRO designed and built their own version, called the SILLIAC, and Fraser began using it to simulate genetic selection processes. Beginning with [1], Fraser embarked on a comprehensive series of simulations of evolutionary processes [2]–[13], and encouraged and collaborated with others on many related publications in this series [14]–[18]. Fraser published extensively in the Australian Journal of Biological Sciences , and his efforts influenced colleagues in evolutionary biology significantly [19]–[21]. Fraser’s first efforts [1], published in 1957, studied the case of diploid organisms represented by binary strings of a given length, say . Each bit in a string represented an allele (either dominant or recessive) and the phenotype of each organism was determined by its genetic composition. Reproduction was accomplished using an-point crossover operator where each position along an organism’s genetic string was assigned a proba-	computational model;computer simulation;evolutionary computation;evolutionary systems;genetic algorithm;illiac;monte carlo method;sampling (signal processing);the australian	David B. Fogel	2002	IEEE Trans. Evolutionary Computation	10.1109/TEVC.2002.805212	machine learning;artificial intelligence;mathematics;obituary	Theory	31.367401819168258	-1.951237940863931	68404
296947780eacc9adf2e3d0d273dec80f1cd8fd01	approach of using a density equalizing function to self-organizing learning for solving travelling salesman problem	minimisation;optimal solution;travelling salesman problem;neurons cities and towns cost function neural networks traveling salesman problems network topology testing simulated annealing upper bound;most probable solution density equalizing function self organizing learning travelling salesman problem 30 city problem practical testing convergence optimal solution;minimisation travelling salesman problems self organising feature maps combinatorial mathematics;self organising feature maps;travelling salesman problems;self organization;combinatorial mathematics	In this paper, we propose a new approach which requires neither neuron addition nor deletion, and at the same time, N neurons are sufficient to solve an Ncity travelling salesman problem. We begm with a description of our model, and then results for applying the model to solve the 3oCity problem from Hopfield are presented. Results of our practical testmg show that our approach always converges. It has the highest chance to achieve the optimal solution, and gives the best most probable solution, as compared to other selfapnizhg algorithms.	algorithm;hopfield network;neuron;organizing (structure);self-organization;travelling salesman problem	Clifford Sze-Tsan Choy;Wan-Chi Siu	1994		10.1109/ICASSP.1994.389589	nearest neighbour algorithm;traveling purchaser problem;extremal optimization;2-opt;minimisation;mathematical optimization;self-organization;christofides algorithm;computer science;lin–kernighan heuristic;artificial intelligence;vehicle routing problem;machine learning;mathematics;travelling salesman problem;3-opt;statistics;bottleneck traveling salesman problem	AI	27.079641811248973	-1.2116033089488867	68695
76a20611a0d8dd3697d65942cdc3d8a32565323d	a simple self-adaptive differential evolution algorithm with application on the alstom gasifier	differential evolution;benchmark problem;gasifier control;global optimisation;multivariable control;control system design;direct search;evolutionary computing	Differential Evolution (DE) has gathered a reputation for being a powerful yet simple global optimiser with continually outperforming many of the already existing stochastic and direct search global optimisation techniques. It is however well established that DE is particularly sensitive to its control parameters, most notably the mutation weighting factor F. This sensitivity is further studied here and a simple randomised self-adaptive scheme is proposed for the DE mutation weighting factor F. The performance of this algorithm is studied with the use of several benchmark problems and applied to a difficult control systems design case study.	algorithm;differential evolution	Amin Nobakhti;Hong Wang	2008	Appl. Soft Comput.	10.1016/j.asoc.2006.12.005	differential evolution;mathematical optimization;computer science;control theory;evolutionary computation	Logic	25.26204685906714	-6.209394181181211	68718
9a827bc8c6766c777042410bbb31065f0ac73df5	a study on real-coded genetic algorithm for process optimization using ranking selection, direction-based crossover and dynamic mutation	process optimization real coded genetic algorithm direction based crossover dynamic mutation constrained optimization;constrained optimization;direction based crossover;generators;convergence;premature convergence;benchmark problem;dbx operator;ranking selection;convergence speed;evolution biology;single objective optimization benchmark problem;biological cells;genetic algorithms convergence;dynamic random mutation;drm operator;heuristic algorithms;process optimization;comparative study;comparative method;rs operator;biological cells optimization convergence genetic algorithms evolution biology generators heuristic algorithms;genetic algorithm;genetic algorithms;optimization;dynamic mutation;convergence speed real coded genetic algorithm process optimization ranking selection direction based crossover dynamic random mutation rs operator dbx operator drm operator single objective optimization benchmark problem;real coded genetic algorithm;heuristic algorithm	In this paper, a novel and efficient real-coded genetic algorithm (RCGA) for process optimization is developed. The proposed RCGA is equipped with Ranking Selection (RS), Direction-Based Crossover (DBX) and Dynamic Random Mutation (DRM) operators. The RS operator is used to eliminate the bad solutions and reproduce good solutions, making the whole population to achieve a better average fitness. The DBX operator uses relative fitness information to direct the crossover toward a direction that significantly improves the objective fitness. The DRM operator prevents the premature convergence of RCGA and at the same time increases the precision of the searched solution. The effectiveness and application of the proposed RCGA are demonstrated through a variety of single-objective optimization benchmark problems. For comparative study, other existing RCGAs with different evolution operators are also performed to the same problem set. Extensive experiment results reveal that the proposed RCGA provides a significantly faster convergence speed and much better search performance than comparative methods.	benchmark (computing);genetic algorithm;mathematical optimization;premature convergence;process optimization	Yao-Chen Chuang;Chyi-Tsong Chen	2011	2011 IEEE Congress of Evolutionary Computation (CEC)	10.1109/CEC.2011.5949926	mathematical optimization;constrained optimization;genetic algorithm;computer science;theoretical computer science;machine learning;mathematics	Vision	26.632298675617648	-3.955355626327302	68938
1e479346dbd08272cea49ea4e1261d9b53782f56	solving the constrained p-center problem using heuristic algorithms	location problem;p center problem;computational geometry;operations research;heuristic algorithms;optimization;heuristic algorithm;voronoi diagram	The p-center problem is one of the location problems that have been studied in operations research and computational geometry. This paper describes a compatible discrete space version of the heuristic Voronoi diagram algorithm. Since the algorithm gets stuck in local optimums in some cases, we apply a number of changes in the body of the algorithm with regard to the geometry of the problem, in a way that it can reach the global optimum with a high probability. Finally, a comparison between the results of these two algorithms on several test problems and a real-world problem are presented. © 2011 Elsevier B.V. All rights reserved.	algorithm;computational geometry;global optimization;heuristic;operations research;turing test;voronoi diagram	Mansoor Davoodi Monfared;Ali Mohades;Jafar Rezaei	2011	Appl. Soft Comput.	10.1016/j.asoc.2011.01.001	consistent heuristic;computational problem;heuristic;null-move heuristic;mathematical optimization;combinatorics;greedy algorithm;voronoi diagram;computational geometry;theoretical computer science;facility location problem;min-conflicts algorithm;mathematics	AI	24.628805967355465	1.7879472615181866	69111
9d48032a94869356b0e16225a27398a08ffdb0bb	a new approach to chaotic image encryption based on quantum chaotic system, exploiting color spaces	image encryption;lifting wavelet transform lwt;toral automorphism;quantum chaotic system	How to protect the secret information is an important issue in commercial or military application. Attributed to quantum chaotic system that can be characterized by sensitive dependence to initial conditions/parameters, a new color image encryption scheme based on quantum chaotic system is proposed in this paper. Firstly, a new substitution scheme is achieved based on toral automorphism in integer wavelet transform by scrambling only the Y (Luminance) component of low frequency subband. Then two diffusion modules are achieved by mixing the features of horizontally and vertically adjacent pixels with the help of adopted quantum chaotic map. Finally, substitution/confusion is accomplished by generating an intermediate chaotic key stream image with the help of quantum chaotic system. Several security and performance analyses have been provided thoroughly based on several experimental tests and analysis. Brilliant characteristics of the proposed color image encryption approach are enough security and good performance. Through comparison, most of the results are in favor of the proposed scheme.	chaos theory;color space;encryption	Ahmed A. Abd El-Latif;Li Li;Ning Wang;Qi Han;Xiamu Niu	2013	Signal Processing	10.1016/j.sigpro.2013.03.031	discrete mathematics;theoretical computer science;pure mathematics;mathematics	Robotics	39.06234456242659	-9.330784039965097	69228
893798621740dcab7170e570149ee08009f946a6	study of bp neural network based on meca	evolutionary computation;premature convergence;neural nets;neural networks evolution biology cloning algorithm design and analysis biological system modeling artificial neural networks information processing network topology convergence educational institutions;backpropagation;genetic algorithm bp neural network mind evolution clone mind evolution population clone mechanism biology convergence problem training xor;simple genetic algorithm;backpropagation neural nets evolutionary computation;global optimization;neural network	This paper designs BP neural network with mind evolution clone algorithm (MECA). Taking the relation between diversity of mind evolution population and clone mechanism of biology into account, MECA is proposed in the paper. Not only can the algorithm converge to globally optimal solution, but also it solves premature convergence problem efficiently. The algorithm has been applied to training XOR. Simulation results show that MECA presented in this thesis performs better in contrast with simple genetic algorithm and BP algorithm. There is a great improvement in the quality and efficiency of the training of neural network.	artificial neural network;backpropagation;converge;exclusive or;genetic algorithm;maxima and minima;premature convergence;simulation	Hongbo Guo;Gang Xie;Zehua Chen;Keming Xie	2005	2005 IEEE International Conference on Granular Computing	10.1109/GRC.2005.1547333	computer science;artificial intelligence;backpropagation;machine learning;time delay neural network;artificial neural network;algorithm;premature convergence	Robotics	27.89980068430539	-6.442957837077371	69389
94eb20730801d91aea784d0b5b663b6182ff4536	a robust measurement placement method for active distribution system state estimation considering network reconfiguration	measurement uncertainty decision support systems uncertainty state estimation network topology weight measurement robustness;robust measurement placement analytic hierarchy process distributed generations distribution system state estimation markov chain measurement saturation	The influences of network reconfiguration and distributed generations (DGs) on distribution system state estimation (DSSE) and measurement placement should not be ignored in active distribution systems. In this paper, considering network reconfiguration and the output uncertainties of DGs, a robust measurement placement method for active distribution systems is proposed based on measurement saturation analysis and heuristic algorithm. First, the saturation number determined by measurement saturation characteristic is chosen as the measurement number. Then, the impacts of different network topologies are represented by various weights in the robust measurement placement model, which are computed by Markov chain and analytic hierarchy process. In addition, Gaussian mixture model is applied to approximate the power fluctuations of DGs. Uncertainties caused by measurements are considered by Monte Carlo simulations. The accuracy of DSSE in different network topologies can be guaranteed by the proposed robust measurement placement method. Simulation results based on the IEEE 33-bus and 119-bus distribution systems demonstrate the effectiveness of the proposed method.	algorithmic efficiency;analytical hierarchy;approximation algorithm;heuristic (computer science);markov chain;mixture model;monte carlo method;network topology;simulation	Hong Wang;Wen Zhang	2018	IEEE Transactions on Smart Grid	10.1109/TSG.2016.2606700	control engineering;mathematical optimization;computer science;control theory;mathematics	Metrics	35.65431284877394	-2.2456041134151588	69605
f48b2cbbea7221f0485e4fcec67b43dc37c69bcf	multi-basin particle swarm intelligence method for optimal calibration of parametric lévy models	levy models;particle swarm intelligence;option pricing and calibration;global optimization;dynamical systems	In this paper, we propose a novel intelligent method to improve the calibration quality of parametric exponential Levy models that have recently emerged as alternative option pricing models. The method based on so-called multi-basin systems consists of three sequential phases to expedite the search for a good parameter set and to reduce the burden of selecting proper initial set of particles for particle swarm intelligence techniques. We conduct simulations on model-generated option prices and real data of option prices to verify the performance of the proposed method and show that the method can significantly improve the calibration quality in a systematic and automatic way.	swarm intelligence	Seung-Ho Yang;Jaewook Lee	2012	Expert Syst. Appl.	10.1016/j.eswa.2011.07.039	econometrics;mathematical optimization;dynamical systems theory;global optimization	AI	31.072119964274425	-7.328240561216454	69741
bfb1aafe14bc408c363dee17bb39aa83ffde7bc7	memetic algorithm for dynamic bi-objective optimization problems	quadratic programming;convergence;evolutionary computation;quadratic programming evolutionary computation;performance evaluation;constraint optimization;aerodynamics;multi objective optimization;testing;orthogonal epsilon constrained formulation;pareto optimization;memetic algorithm;sequential quadratic programming;optimization problem;distance measurement;heuristic algorithms convergence constraint optimization evolutionary computation testing aerodynamics pareto optimization predictive models australia performance evaluation;optical fibers;heuristic algorithms;sequential quadratic programming solver;benchmark functions;predictive models;optimization;evolutionary algorithm;benchmark functions memetic algorithm dynamic biobjective optimization problems sequential quadratic programming solver orthogonal epsilon constrained formulation evolutionary algorithm;dynamic biobjective optimization problems;australia	Dynamic multi-objective optimization (DMO) is a challenging class of problems where the objective and/or the constraint function(s) change over time. DMO has received little attention in the past and none of the existing multi-objective optimization algorithms have performed too well on the set DMO test problems. In this paper, we introduce a memetic algorithm (MA) embedded with a sequential quadratic programming (SQP) solver for faster convergence and an orthogonal epsilon-constrained formulation is used to deal with two objectives. The performance of the memetic algorithm is compared with an evolutionary algorithm (EA) embedded with a Sub-EA with and without restart mechanisms on two benchmark functions FDA1 and modified FDA2. The memetic algorithm consistently outperforms the evolutionary algorithm for both FDA1 and modified FDA2 problems.	benchmark (computing);constraint (mathematics);directx;embedded system;evolutionary algorithm;mathematical optimization;memetic algorithm;memetics;multi-objective optimization;sequential quadratic programming;solver;warhammer 40,000: dark millennium	Amitay Isaacs;Tapabrata Ray;Warren Smith	2009	2009 IEEE Congress on Evolutionary Computation	10.1109/CEC.2009.4983147	optimization problem;mathematical optimization;convergence;aerodynamics;computer science;multi-objective optimization;machine learning;evolutionary algorithm;mathematics;sequential quadratic programming;quadratic programming;algorithm;memetic algorithm;evolutionary computation	AI	25.52867535973124	-2.489634536316029	69894
dc5b41550496cf7a0c1ef7b247a266811e54bd3c	a quantum watermarking scheme using simple and small-scale quantum circuits	quantum watermarking;quantum computation;quantum circuit;quantum image processing	A new quantum gray-scale image watermarking scheme by using simple and small-scale quantum circuits is proposed. The NEQR representation for quantum images is used. The image sizes for carrier and watermark are assumed to be $$2n \times 2n$$2n×2n and $$n \times n$$n×n, respectively. At first, a classical watermark with $$n \times n$$n×n image size and 8 bits gray scale is expanded to an image with $$2n \times 2n$$2n×2n image size and 2 bits gray scale. Then the expanded image is scrambled to be a meaningless image by the SWAP gates that controlled by the keys only known to the operator. The scrambled image is embedded into the carrier image by the CNOT gates (XOR operation). The watermark is extracted from the watermarked image by applying operations in the reverse order. Simulation-based experimental results show that our proposed scheme is excellent in terms of three items, visual quality, robustness performance under noises, and computational complexity.		S. Miyake;Koji Nakamae	2016	Quantum Information Processing	10.1007/s11128-016-1260-9	quantum fourier transform;discrete mathematics;quantum information;theoretical computer science;quantum capacity;quantum circuit;mathematics;quantum computer;quantum algorithm;physics;quantum mechanics;quantum error correction	Theory	38.718078736199196	-9.21684046069227	70328
74c6608b27d676602a1496ac00b6c55c0dc701c9	when is an estimation of distribution algorithm better than an evolutionary algorithm?	distributed algorithms;estimation theory;optimisation;evolutionary computation;application software;probability density function;distributed computing;random variables;data mining;runtime;substring;electronic design automation and methodology;estimation of distribution algorithm;estimation;probability distribution;evolutionary computation runtime electronic design automation and methodology probability distribution application software computer science algorithm design and analysis genetic mutations distributed computing computational efficiency;genetic mutations;computer science;evolutionary algorithm;computational efficiency;univariate marginal distribution algorithm;univariate marginal distribution algorithm evolutionary algorithm estimation theoretical proof optimisation problems substring;optimisation problems;titanium;algorithm design and analysis;theoretical proof;optimisation distributed algorithms estimation theory evolutionary computation	Despite the wide-spread popularity of estimation of distribution algorithms (EDAs), there has been no theoretical proof that there exist optimisation problems where EDAs perform significantly better than traditional evolutionary algorithms. Here, it is proved rigorously that on a problem called SUBSTRING, a simple EDA called univariate marginal distribution algorithm (UMDA) is efficient, whereas the (1+1) EA is highly inefficient. Such studies are essential in gaining insight into fundamental research issues, i.e., what problem characteristics make an EDA or EA efficient, under what conditions an EDA is expected to outperform an EA, and what key factors are in an EDA that make it efficient or inefficient.	analysis of algorithms;bitwise operation;converge;electronic design automation;estimation of distribution algorithm;evolutionary algorithm;existential quantification;expectation propagation;like button;linear programming relaxation;marginal model;mathematical optimization;regular language description for xml;substring	Tianshi Chen;Per Kristian Lehre;Ke Tang;Xin Yao	2009	2009 IEEE Congress on Evolutionary Computation	10.1109/CEC.2009.4983116	probability distribution;random variable;titanium;algorithm design;mathematical optimization;estimation;probability density function;application software;estimation of distribution algorithm;computer science;substring;theoretical computer science;machine learning;evolutionary algorithm;estimation theory;statistics;evolutionary computation	DB	29.724325374014075	1.90894988436972	70339
333a599db75dc6de1b8fc2789a3137ab73b4714a	mesh searching algorithm for evaluating cylindricity error		A new kind of method of evaluating cylindricity error, which named as Mesh Searching Algorithm (MSA), has been presented in  this paper. The optimization method and linearization method usually used are not be adopted in this algorithm. The value  of cylindricity error can be obtained through calling repeatedly the formula for distance between the point and straight line  and the simple judgement using this algorithm. The principle and step of using the algorithm to solve the cylindricity error  is detailed described. The simulation reveals that the cylindricity error can be evaluated effectually and accurately by using  this method.  	algorithm	Xianqing Lei;Jishun Li;Yujun Xue;Wei Ma;Mingde Duan	2009		10.1007/978-3-642-10430-5_49	mathematical optimization;machine learning;mathematics;engineering drawing	NLP	34.047018417714696	-1.5151469429511701	70971
7b5b3ac8c7bcd32d1452c6e3d1a525b1ac9f135a	using evolution strategies to perform stellar population synthesis for galaxy spectra from sdss	sloan digital sky survey;theoretical model;evolutionary computation;galaxy spectra;galaxy formation;spectrum;parameter extraction;stellar population;stellar evolution astronomical spectra astronomical surveys astronomy computing data analysis evolutionary computation galaxies stellar composition;optimization problem;galaxies;data analysis;astronomy computing;astronomical spectra;evolution strategies;data mining algorithm design and analysis astronomy information analysis computational modeling chemical elements observatories data analysis image databases parameter extraction;parameter space;astronomical surveys;evolution strategy;information need;stellar evolution;stellar composition;difference function evolution strategy stellar population synthesis galaxy spectra sdss astronomical observation sloan digital sky survey data analysis knowledge extraction mega database stellar age stellar metallicity stellar reddening cosmological study galaxy formation galaxy composition galaxy evolution optimization problem	Current surveys from modern astronomical observatories contain a huge amount of data; in particular, the Sloan Digital Sky Survey (SDSS) has reached the order of terabytes of data in images and spectra. Such an amount of information needs to be exploited by sophisticated algorithms that automatically analyze the data in order to extract useful knowledge from the mega databases. In this work we employ evolution strategies (ES) to automatically extract a set of physical parameters corresponding to stellar population synthesis (ages, metallicities, reddening and relative contributions) from a sample of galaxy spectra taken from SDSS. Such parameters are useful in cosmological studies and for understanding galaxy formation, composition, and evolution. We pose this parameter extraction as an optimization problem and then solve it using ES. The idea is to reconstruct each galaxy spectrum from the sample by means of a linear combination of three similar theoretical models, each contributing in a different way to the stellar population synthesis. This linear combination produces a model spectrum that is compared with the original spectrum using a simple difference function. The goal is to find a model that minimizes this difference, using ES as the algorithm to explore the parameter space. We present experimental results using a set of 100 spectra from SDSS Data Release 2 that show that ES are very well suited to extract stellar population parameters from galaxy spectra.	evolution strategy;spatial decision support system;stellar (payment network)	Juan-Carlos Gomez;Olac Fuentes	2007		10.1109/CEC.2007.4424692	galaxy;optimization problem;spectrum;information needs;stellar evolution;computer science;galaxy formation and evolution;evolution strategy;parameter space;data analysis;statistics;evolutionary computation	Logic	31.103098339912222	-9.490661630445059	71299
21276597a48d314cdd01c8616595894b693a65a4	cascade chaotic system with applications	chaos logistics bifurcation encryption trajectory correlation;encryption;bifurcation;chaos;trajectory;logistics;pseudo random number generator prng cascade chaotic system ccs chaotic map data encryption;correlation;data security cascade chaotic system ccs electronic circuits 1d chaotic maps seed maps pseudorandom number generator prng data encryption system;random number generation cascade systems chaos cryptography	Chaotic maps are widely used in different applications. Motivated by the cascade structure in electronic circuits, this paper introduces a general chaotic framework called the cascade chaotic system (CCS). Using two 1-D chaotic maps as seed maps, CCS is able to generate a huge number of new chaotic maps. Examples and evaluations show the CCS's robustness. Compared with corresponding seed maps, newly generated chaotic maps are more unpredictable and have better chaotic performance, more parameters, and complex chaotic properties. To investigate applications of CCS, we introduce a pseudo-random number generator (PRNG) and a data encryption system using a chaotic map generated by CCS. Simulation and analysis demonstrate that the proposed PRNG has high quality of randomness and that the data encryption system is able to protect different types of data with a high-security level.	cns disorder;cascade device component;chaos theory;differential cryptanalysis;display resolution;division of extramural activities;electronic circuit;encryption;evaluation;high-level programming language;list of chaotic maps;logistic map;neurocutaneous melanosis;pseudo brand of pseudoephedrine;pseudorandom number generator;pseudorandomness;random number generation;randomness;simulation;tandy 1000;testu01;thallium;transform, clipping, and lighting;triple des	Yicong Zhou;Zhongyun Hua;Chi-Man Pun;C. L. Philip Chen	2015	IEEE Transactions on Cybernetics	10.1109/TCYB.2014.2363168	logistics;simulation;computer science;trajectory;theoretical computer science;mathematics;distributed computing;correlation;encryption	Visualization	38.48594444969056	-8.503098788206561	71365
7e77a69a47c3c26886e89009ff90f57868e3e306	analysis of the state of information security on the basis of surious emission electronic components		The article deals with an approach to determining the state of information security based on the analysis of spurious emission of electromagnetic components. Attention is drawn to the possibility of the formation of the data, obtain samples for the analysis of the state of the information security. An experiment in result of which the amplitude-frequency characteristics of the analyzed radiation. Formed data tuples estimated probability values correctly determine the state on the basis of the data obtained.	electronic component;information security;spurious emission	Ilya Lebedev;Nurzhan Bazhayev;Mikhail E. Sukhoparov;Vadim Petrov;Andrey V. Gurtov	2017	2017 20th Conference of Open Innovations Association (FRUCT)	10.23919/FRUCT.2017.8071314	tuple;information security;data mining;radiation;spurious emission;engineering;electronic component	DB	34.611548131485435	-8.739761006543482	71554
0b308f3cfb64d032fdac5de1281ee820e7526677	use of darwinian particle swarm optimization technique for the segmentation of remote sensing images	remote sensing image;geophysical image processing;dpso;image segmentation;darwinian particle swarm optimization technique;multilevel segmentation;swarm optimization;particle swarm optimizer;image segmentation particle swarm optimization sociology statistics optimization algorithm design and analysis remote sensing;remote sensing multilevel segmentation swarm optimization;particle swarm optimization;remote sensing;statistics;optimization;n 1 optimal n level threshold;remote sensing geophysical image processing image segmentation particle swarm optimisation;n 1 optimal n level threshold darwinian particle swarm optimization technique dpso remote sensing images image segmentation;remote sensing images;particle swarm optimisation;algorithm design and analysis;sociology	In this work, a novel method for segmentation of Remote Sensing (RS) images based on the Darwinian Particle Swarm Optimization (DPSO) for determining the n-1 optimal n-level threshold on a given image is proposed. The efficiency of the proposed method is compared with the Particle Swarm Optimization (PSO) based segmentation method. Results show that DPSO-based image segmentation performs better than PSO-based method in a number of different measures.	image segmentation;particle swarm optimization	Pedram Ghamisi;Micael S. Couceiro;Nuno M. Fonseca Ferreira;Lalit Kumar	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6351718	algorithm design;computer vision;mathematical optimization;multi-swarm optimization;computer science;machine learning;image segmentation;particle swarm optimization	Robotics	29.52719876280697	-5.821362109187352	71701
1aeaeffe27855e43193bc8a58b73b649154848e7	an efficient genetic algorithm for discovering diverse-frequent patterns	genetic algorithms data mining;indium tin oxide phasor measurement units sociology statistics;indium tin oxide;optimization pattern set mining concept learning genetic algorithm;statistics;genetic algorithm relative encoding scheme heuristic search algorithm pattern set mining;phasor measurement units;sociology	Working with exhaustive search on large dataset is infeasible for several reasons. Recently, developed techniques that made pattern set mining feasible by a general solver with long execution time that supports heuristic search and are limited to small datasets only. In this paper, we investigate an approach which aims to find diverse set of patterns using genetic algorithm to mine diverse frequent patterns. We propose a fast heuristic search algorithm that outperforms state-of-the-art methods on a standard set of benchmarks and capable to produce satisfactory results within a short period of time. Our proposed algorithm uses a relative encoding scheme for the patterns and an effective twin removal technique to ensure diversity throughout the search.	benchmark (computing);brute-force search;crossover (genetic algorithm);fast fourier transform;genetic algorithm;heuristic;hill climbing;line code;local search (optimization);mutation (genetic algorithm);run time (program lifecycle phase);search algorithm;solver;tweaking	Shanjida Khatun;Hasib Ul Alam;Swakkhar Shatabda	2015	2015 International Conference on Electrical Engineering and Information Communication Technology (ICEEICT)	10.1109/ICEEICT.2015.7307428	beam search;indium tin oxide;computer science;theoretical computer science;machine learning;data mining;fsa-red algorithm;best-first search;statistics;population-based incremental learning	Robotics	25.996005305903218	-1.8213289675856044	71846
c825b144fbb5989bc45dcf16b83ab92ab7b8f6fa	an improved glowworm swarm optimization algorithm based on parallel hybrid mutation	pso;hybrid mutation;global search;gso	Glowworm swarm optimization (GSO) algorithm is a novel algorithm based on swarm intelligence and inspired from light emission behavior of glowworms to attract a peer or prey in nature. The main application of this algorithm is to capture all local optima of multimodal function. GSO algorithm has shown some such weaknesses in global search as low accuracy computation and easy to fall into local optimum. In order to overcome above disadvantages of GSO, this paper presented an improved GSO algorithm, which called parallel hybrid mutation glowworm swarm optimization (PHMGSO) algorithm. Experimental results show that PHMGSO has higher calculation accuracy and convergence faster speed compared to standard GSO and PSO algorithms.	algorithm;swarm	Zhonghua Tang;Yongquan Zhou;Xin Chen	2013		10.1007/978-3-642-39482-9_23	mathematical optimization;simulation;computer science;artificial intelligence;geosynchronous orbit	EDA	27.523549758058447	-4.265050287863668	71896
59be03266ddbbb607b1089357b84c336d76b4d11	solving the rural postman problem using a genetic algorithm with a graph transformation	graph transformation;hamiltonian graph;rural postman problem;genetic algorithm	This paper describes a genetic algo-rithm(GA) and proposes a structure of chromosome for Rural Postman Problem (RPP) which is to find a minimum cost tour that must pass through edges in E' (C E) at least once in a given graph G=(V, E). In this paper, we transform a graph of RPP into a Hamiltonian graph to construct chromosomes. Hence, we can reduce the length of a chromosome and the size of the solution space. In simulation, we compare a GA with the proposed chromosome structure with a GA with an exsisting chromosome structure.	feasible region;genetic algorithm;genetic programming;graph rewriting;hamiltonian path;route inspection problem;simulation;software release life cycle	Myung-Ju Kang;Chi-Geun Han	1998		10.1145/330560.330839	hamiltonian path;mathematical optimization;factor-critical graph;genetic algorithm;graph bandwidth;computer science;route inspection problem;voltage graph;distance-hereditary graph;graph	AI	24.808589541906453	2.3347500217746475	72094
6106347cdc70c0b58a5156c1a0cf3a7e9f374e3f	ds-dpso: a dual surrogate approach for intelligent watermarking of bi-tonal document image streams	evolutionary computation;intelligent watermarking;surrogate based optimization;gaussian mixture models;particle swarm optimization	Intelligent watermarking (IW) techniques employ population-based evolutionary computing in order to optimize embedding parameters that trade-off between watermark robustness and image quality for digital watermarking systems. Recent advances indicate that it is possible to decrease the computational burden of IW techniques in scenarios involving long heterogeneous streams of bi-tonal document images by recalling embedding parameters (solutions) from a memory based on Gaussian Mixture Model (GMM) representation of optimization problems. This representation can provide ready-to-use solutions for similar optimization problem instances, avoiding the need for a costly re-optimization process. In this paper, a dual surrogate dynamic Particle Swarm Optimization (DS-DPSO) approach is proposed which employs a memory of GMMs in regression mode in order to decrease the cost of re-optimization for heterogeneous bi-tonal image streams. This approach is applied within a four level search for near-optimal solutions, with increasing computational burden and precision. Following previous research, the first two levels use GMM re-sampling to recall solutions for recurring problems, allowing to manage streams of heterogeneous images. Then, if embedding parameters of an image require a significant adaptation, the third level is activated. This optimization level relies on an off-line surrogate, using Gaussian Mixture Regression (GMR), in order to replace costly fitness evaluations during optimization. The final level also performs optimization, but GMR is employed as a costlier on-line surrogate in a worst-case scenario and provides a safeguard to the IW system. Experimental validation were performed on the OULU image data set, featuring heterogeneous image streams with a varying levels of attacks. In this scenario, the DS-DPSO approach has been shown to provide comparable level of watermarking performance with a 93% decline in computational cost compared to full re-optimization. Indeed, when significant parameter adaptation is required, fitness evaluations may be replaced with GMR. The decreasing costs of data transmission and storage provided numerous opportunities for sharing multimedia documents like images. This has led to the creation of a digital economy with new services that are available 24 h a day, 7 days a week, around the globe. Individuals and businesses depend more and more on sharing important documents which raises serious privacy concerns. Enforcing the security of document images is an important issue. Cryptography can solve part of this issue. However, specially with multimedia documents like images, the protection allowed by cryptography vanishes as the data has been decrypted. Digital watermarking (Cox et al., 2002) which consists of embedding image related secret …	algorithmic efficiency;cryptography;digital watermarking;evolutionary computation;google map maker;iw engine;image quality;mathematical optimization;mixture model;online and offline;optimization problem;particle swarm optimization;privacy;sampling (signal processing);worst-case scenario	Eduardo Vellasques;Robert Sabourin;Eric Granger	2013	Expert Syst. Appl.	10.1016/j.eswa.2013.03.021	simulation;computer science;artificial intelligence;machine learning;mixture model;data mining;particle swarm optimization;statistics;evolutionary computation	ML	36.09601473124057	-9.044194918235727	72150
073015b5207019dd91f06ed278e38d105a4a475f	local search: a guide for the information retrieval practitioner	busqueda informacion;search engine;buscador;information retrieval;statistical significance;optimisation combinatoire;recherche information;evaluation;evaluacion;moteur recherche;combinatorial optimization;local search;z665 library science information science;combinatorial optimisation;test collection;fitness function;optimizacion combinatoria	There are a number of combinatorial optimisation problems in information retrie val in which the use of local search methods are worthwhile. The purpose of this paper is to show how local search can be used to sol v some well known tasks in Information Retri eval (IR), how previous research in the field is piecemeal, bereft of a structur e and methodologically flawed, and to suggest more rigorous ways of applying local search methods to solve IR problems. We provide a Query based taxonomy for analysing the use of local search in IR tasks and an overview of issues such as fitness functions, statistical significance and test collections whe n conducting experiments on combinatorial optimisation problems. The paper gives a guide on the pitfalls and problems f or IR practitioners who wish to use local search to solve their research issues, and gives practical advice on the use of such met hods. Th Query based taxonomy is a novel structure which can be used by the IR practitioner in order to examine t he use of local sea rch in IR.	combinatorial optimization;eval;evolutionary computation;experiment;fitness function;information retrieval;local search (optimization);mathematical optimization;nfl;neighbourhood (graph theory);positive feedback;programming paradigm;tabu search;taxonomy (general)	Andrew MacFarlane;Andrew Tuson	2009	Inf. Process. Manage.	10.1016/j.ipm.2008.09.002	combinatorial optimization;computer science;artificial intelligence;local search;evaluation;machine learning;data mining;mathematics;statistical significance;world wide web;fitness function;information retrieval;search engine	AI	24.853276415270244	3.2486336364642683	72194
34e32b87b35bd856c2c47b34d5fb73bc7cffaee2	optimizing rfid network planning by using a particle swarm optimization algorithm with redundant reader elimination	evolutionary computation;telecommunication network planning;computational complexity;rfid network planning rnp particle swarm optimization pso radio frequency identification rfid redundant reader elimination;search problems;radiofrequency identification particle swarm optimization algorithm design and analysis interference;telecommunication network planning computational complexity evolutionary computation particle swarm optimisation radiofrequency identification search problems;particle swarm optimisation;radiofrequency identification;success rate improvement rfid network planning particle swarm optimization algorithm redundant reader elimination radiofrequency identification technology rnp problem np hard evolutionary computation ec swarm intelligence si network complexity network cost pso algorithm tentative reader elimination operator tre operator search process mutation operator	The rapid development of radio frequency identification (RFID) technology creates the challenge of optimal deployment of an RFID network. The RFID network planning (RNP) problem involves many constraints and objectives and has been proven to be NP-hard. The use of evolutionary computation (EC) and swarm intelligence (SI) for solving RNP has gained significant attention in the literature, but the algorithms proposed have seen difficulties in adjusting the number of readers deployed in the network. However, the number of deployed readers has an enormous impact on the network complexity and cost. In this paper, we develop a novel particle swarm optimization (PSO) algorithm with a tentative reader elimination (TRE) operator to deal with RNP. The TRE operator tentatively deletes readers during the search process of PSO and is able to recover the deleted readers after a few generations if the deletion lowers tag coverage. By using TRE, the proposed algorithm is capable of adaptively adjusting the number of readers used in order to improve the overall performance of RFID network. Moreover, a mutation operator is embedded into the algorithm to improve the success rate of TRE. In the experiment, six RNP benchmarks and a real-world RFID working scenario are tested and four algorithms are implemented and compared. Experimental results show that the proposed algorithm is capable of achieving higher coverage and using fewer readers than the other algorithms.	algorithm;embedded system;evolutionary computation;interference (communication);mathematical optimization;optimizing compiler;particle swarm optimization;radio frequency;radio-frequency identification;software deployment;swarm intelligence;tre;tag cloud;von neumann architecture	Yue-jiao Gong;Meie Shen;Jun Zhang;Okyay Kaynak;Wei-neng Chen;Zhi-hui Zhan	2012	IEEE Transactions on Industrial Informatics	10.1109/TII.2012.2205390	mathematical optimization;multi-swarm optimization;computer science;artificial intelligence;machine learning;computational complexity theory;evolutionary computation	Mobile	27.473752762137043	-1.8201123998229383	72658
5708221f991a45058ed8695abea0b2fcc91c08f9	introduction to fireworks algorithm	multi-objective fireworks algorithm;benchmark function;improved firework;improved fwa;conventional fireworks algorithm;fireworks explosion;fireworks algorithm;extensive experiment;fireworks algorithm;conventional firework;improved fireworks algorithm	Inspired by fireworks explosion at night, conventional fireworks algorithm (FWA) was developed in 2010. Since then, several improvements and some applications were proposed to improve the efficiency of FWA. In this paper, the conventional fireworks algorithm is first summarized and reviewed and then three improved fireworks algorithms are provided. By changing the ways of calculating numbers and amplitudes of sparks in fireworks’ explosion, the improved FWA algorithms become more reasonable and explainable. In addition, the multi-objective fireworks algorithm and the graphic processing unit (GPU) based fireworks algorithm are also presented, particularly the GPU based fireworks algorithm is able to speed up the optimization process considerably. Extensive experiments on 13 benchmark functions demonstrate that the three improved fireworks algorithms significantly increase the accuracy of found solutions, yet decrease the running time dramatically. At last, some applications of fireworks algorithm are briefly described, while its shortcomings and future research directions are identified.	benchmark (computing);big data;experiment;fireworks algorithm;graphics processing unit;list of minor characters in the matrix series;mathematical optimization;open-source software;parallel computing;speedup;time complexity	Ying Tan;Chao Yu;Shaoqiu Zheng;Ke Ding	2013	IJSIR	10.4018/ijsir.2013100103	simulation;computer graphics (images)	Graphics	26.74520562001888	-0.4024693067607556	72943
df0bf7bac8baa53a53cb2b5745571cde59a45083	research on and application of foa based on dynamic population and direction correcting		Fruit fly Optimization Algorithm (FOA) is a kind of relatively new swarm intelligence optimization algorithm with strong performance. In this paper a kind of FOA based on dynamic population and direction correct (DPDC-FOA) is proposed on the question of premature convergence. By changing the fruit fly group's search range, number of individuals and group position selection strategy during the movement process, this improved algorithm enhances the basic algorithm's ability to search the global optimal. We use 6 functions as benchmark and the result shows that the improved algorithm has better performance in the rate and the precision of convergence. Using this algorithm in the parameter optimization of support vector machine (SVM), the classification accuracy got increased.	algorithm;benchmark (computing);global optimization;mathematical optimization;premature convergence;rate of convergence;support vector machine;swarm intelligence;the fiber optic association	Zenghao Li;Ting Jiang	2016	2016 19th International Symposium on Wireless Personal Multimedia Communications (WPMC)		multi-swarm optimization;swarm intelligence;meta-optimization;metaheuristic;population-based incremental learning;mathematical optimization;computer science;particle swarm optimization;premature convergence;population	EDA	27.162601161046506	-4.349680359287495	73411
6a1f89b82a15e1d97b9e362e732dd4bb907a9209	quantum-behaved particle swarm optimization based on immune memory and vaccination	biological tissues;convergence;evolutionary computation;indexing terms;particle swarm optimizer;birds;particle swarm optimization;immune system;sun;cells biology;optimization methods;particle swarm optimization immune system sun optimization methods birds convergence evolutionary computation biological tissues cells biology equations	The immune operation based on the regulation of the antibody thickness and vaccination operation in immune system is introduced into Quantum-behaved Particle Swarm Optimization, and then the Quantum-behaved Particle Swarm Optimization with immune operator is proposed in this paper. The results of typical optimization function showed that QPSO with immune operator performs much better than PSO and QPSO without immune operator.	mathematical optimization;particle swarm optimization;phase-shift oscillator;quantum	Jing Liu;Jun Sun;Wenbo Xu;X. H. Kong	2006	2006 IEEE International Conference on Granular Computing	10.1109/GRC.2006.1635838	mathematical optimization;multi-swarm optimization;immune system;index term;convergence;computer science;bioinformatics;imperialist competitive algorithm;particle swarm optimization;metaheuristic;evolutionary computation	Robotics	28.356562779248133	-6.019346095598583	73500
05c7ca0c31eec0578de4c762ee1a9c3d25a4710a	parallel multi-objective algorithms for the molecular docking problem	benchmarking;drugs;biology computing;atomic measurements;low energy;drugs algorithm design and analysis genetic algorithms databases simulated annealing predictive models costs software packages software algorithms search methods;synthetic aperture sonar;probes;solvents;multi objective genetic algorithm;proteins;drug design;nsga ii;parallel multiobjective algorithm;genetic algorithms;multi objective modelling;benchmarking parallel multiobjective algorithm molecular docking problem drug design genetic algorithms;molecular docking problem;parallel algorithms benchmark testing biology computing drugs genetic algorithms;ibea;quantitative method;molecular docking;algorithm design and analysis;benchmark testing;object model;parallel algorithms	Molecular docking is an essential tool for drug design. It helps the scientist to rapidly know if two molecules, respectively called ligand and receptor, can be combined together to obtain a stable complex. We propose a new multi-objective model combining an energy term and a surface term to gain such complexes. The aim of our model is to provide complexes with a low energy and low surface. This model has been validated with two multi-objective genetic algorithms on instances from the literature dedicated to the docking benchmarking.	docking (molecular);force field (chemistry);genetic algorithm;grid computing;mathematical optimization;online and offline;premature convergence;rate of convergence;robustness (computer science);sampling (signal processing);triangular function;vergence	Jean-Charles Boisson;Laetitia Vermeulen-Jourdan;El-Ghazali Talbi;Dragos Horvath	2008	2008 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology	10.1109/CIBCB.2008.4675777	algorithm design;benchmark;mathematical optimization;synthetic aperture sonar;genetic algorithm;object model;docking;quantitative research;computer science;bioinformatics;machine learning;parallel algorithm;drug design;benchmarking	Embedded	29.810045085571875	-8.282163668720415	73678
90b88ecebe460bca532ead6f48f0320334e9e90f	a comparison of simulated annealing with a simple evolutionary algorithm	fonction booleenne;metodo analitico;optimisation;algorithmique;algorithm performance;optimizacion;heuristic method;boolean function;metodo heuristico;simulated annealing;algoritmo genetico;similitude;aleatorizacion;recuit simule;algorithmics;algoritmica;resultado algoritmo;transfer function;funcion traspaso;funcion booliana;analytical method;similarity;performance algorithme;algorithme genetique;randomisation;methode analytique;algorithme evolutionniste;genetic algorithm;recocido simulado;fonction transfert;algoritmo evolucionista;optimization;methode heuristique;similitud;evolutionary algorithm;randomization;pseudo boolean;random search	Evolutionary algorithms belong to the class of general randomized search heuristics. Theoretical investigations often concentrate on simple instances like the well-known (1+1) EA. This EA is very similar to simulated annealing, another general randomized search heuristic. These two algorithms are systematically compared under the perspective of the expected optimization time when optimizing pseudo-boolean functions. It is investigated how well the algorithmic similarities can be exploited to transfer analytical results from one algorithm to the other. Limitations of such an approach are illustrated by the presentation of example functions where the performance of the two algorithms differs in an extreme way. Furthermore, an attempt is made to characterize classes of functions where such a transfer of results is more successful.	evolutionary algorithm;simulated annealing	Thomas Jansen	2005		10.1007/11513575_3	randomization;mathematical optimization;combinatorics;random search;genetic algorithm;similarity;simulated annealing;computer science;similitude;evolutionary algorithm;mathematics;transfer function;boolean function;algorithmics;algorithm	Vision	27.844245288016708	2.351496622460858	73709
0aa40a1589f79f360a8a9e1769b58b1467bd8c93	ants can solve constraint satisfaction problems	artificial ants;utilisation information;heuristic;filtering;optimisation;aco algorithm;ant colony optimization;constraint optimization;optimizacion;information use;insecto social;search space;heuristic method;resource management;space exploration;metodo heuristico;indexing terms;operations research;constraint satisfaction problems;constraint satisfaction;csps;resolucion problema;combinatorial problem;satisfaction contrainte;ant colony optimization costs filtering space exploration constraint optimization resource management machine vision stochastic processes traveling salesman problems vehicles;probleme combinatoire;problema combinatorio;stochastic processes;ant colony optimization metaheuristic;machine vision;constraint theory;preprocessing step;optimization;search problems constraint theory operations research optimisation;constraint satisfaction problem;search problems;traveling salesman problems;vehicles;methode heuristique;satisfaccion restriccion;insecte social;social insect;pheromone information;utilizacion informacion;local search constraint satisfaction problems csps ant colony optimization metaheuristic artificial ants search space pheromone information heuristic aco algorithm preprocessing step;local search;recherche locale;problem solving;resolution probleme	In this paper, we describe a new incomplete approach for solving constraint satisfaction problems (CSPs) based on the ant colony optimization (ACO) metaheuristic. The idea is to use artificial ants to keep track of promising areas of the search space by laying trails of pheromone. This pheromone information is used to guide the search, as a heuristic for choosing values to be assigned to variables. We first describe the basic ACO algorithm for solving CSPs and we show how it can be improved by combining it with local search techniques. Then, we introduce a preprocessing step, the goal of which is to favor a larger exploration of the search space at a lower cost, and we show that it allows ants to find better solutions faster. Finally, we evaluate our approach on random binary problems.	algorithm;ant colony optimization algorithms;artificial ants;constraint satisfaction problem;heuristic;iso 10303;local search (optimization);mathematical optimization;metaheuristic;preprocessor	Christine Solnon	2002	IEEE Trans. Evolutionary Computation	10.1109/TEVC.2002.802449	mathematical optimization;heuristic;machine vision;computer science;artificial intelligence;resource management;machine learning;mathematics;constraint satisfaction problem	AI	25.40140002224947	1.090679591588288	73728
a6c21b3617326a96edf2ccbb61c6b34e0c14b412	a dominance tree and its application in evolutionary multi-objective optimization	evolutionary computation;evolutionary multi objective optimization;multi objective evolutionary algorithm;pareto dominance;computational complexity;fitness assignment;data structure;pareto optimality;evolutionary computing;binary tree	Most contemporary multi-objective evolutionary algorithms (MOEAs) store and handle a population with a linear list, and this may impose high computational complexities on the comparisons of solutions and the fitness assignment processes. This paper presents a data structure for storing the whole population and their dominating information in MOEAs. This structure, called a Dominance Tree (DT), is a binary tree that can effectively and efficiently store three-valued relations (namely dominating, dominated or non-dominated) among vector values. This paper further demonstrates DT’s potential applications in evolutionary multi-objective optimization with two cases. The first case utilizes the DT to improve NSGA-II as a fitness assignment strategy. The second case demonstrates a DTbased MOEA (called a DTEA), which is designed by leveraging the favorable properties of the DT. The simulation results show that the DT-improved NSGA-II is significantly faster than NSGA-II. Meanwhile, DTEA is much faster than SPEA2, NSGA-II and an improved version of NSGA-II. On the other hand, in regard to converging to the Pareto optimal front and maintaining the diversity of solutions, DT-improved NSGA-II and DTEA are found to be competitive with NSGA-II and SPEA2. 2009 Elsevier Inc. All rights reserved.	binary tree;data structure;evolutionary algorithm;moea framework;mathematical optimization;multi-objective optimization;pareto efficiency;simulation	Chuan Shi;Zhenyu Yan;Kevin Lü;Zhongzhi Shi;Bai Wang	2009	Inf. Sci.	10.1016/j.ins.2009.06.035	evolutionary programming;mathematical optimization;binary tree;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;programming language;computational complexity theory;evolutionary computation	AI	24.672935397481286	-1.3801444235233626	73756
14943a05b2e92c6942c08d7e5310a37829116a8b	lagrangian-based evolutionary programming for constrained optimization	constrained optimization;evolutionary programming;lagrange multiplier;objective function;constrained optimization problem;augmented lagrangian;article;evolutionary computing	In this paper, Lagrangian-based evolutionary programming, Evolian is proposed for the general constrained optimization problem, which incorporates the concept of (1) multi-phase optimization process and (2) constraint scaling techniques to resolve the ill-conditioning problem. In each phase of Evolian, the typical EP is performed using augmented Lagrangian objective function with a penalty parameter fixed. If there is no improvement in the best objective function in one phase, another phase is performed after scaling the constraints, and updating the Lagrange multipliers and penalty parameter. Simulation results indicate that Evolian gives outperforming or at least reasonable solutions for multivariable heavily constrained optimization problem compared to other several evolutionary computation based methods.	constrained optimization;evolutionary programming	Hyun Myung;Jong-Hwan Kim	1996		10.1007/BFb0028519	evolutionary programming;mathematical optimization;constrained optimization;cobyla;augmented lagrangian method;lagrangian relaxation;interactive evolutionary computation;computer science;machine learning;quadratically constrained quadratic program;mathematical economics;lagrange multiplier;quadratic programming	Theory	29.462748852530716	-0.8021971848531052	73955
0e5d9473d70563c6f99d1eb0e77b5a3c13940440	fractop: a geometric partitioning metaheuristic for global optimization	geometrik bolumleme;fuzzy measure;fractop;simulated annealing;geometric partitioning;computer experiment;bulanik onlemler;genetic algorithm;global optimization;fuzzy measures;article;random search;parallel processing	We propose a new metaheuristic, FRACTOP, for global optimization. FRACTOP is based on the geometric partitioning of the feasible region so that search metaheuristics such as Simulated Annealing (SA), or Genetic Algorithms (GA) which are activated in smaller subregions, have increased reliability in locating the global optimum. FRACTOP is able to incorporate any search heuristic devised for global optimization. The main contribution of FRACTOP is that it provides an intelligent guidance (through fuzzy measures) in locating the subregion containing the global optimum solution for the search heuristics imbedded in it. By executing the search in nonoverlapping subregions, FRACTOP eliminates the repetitive visits of the search heuristics to the same local area and furthermore, it becomes amenable for parallel processing. As FRACTOP conducts the search deeper into smaller subregions, many unpromising subregions are discarded from the feasible region. Thus, the initial feasible region gains a fractal structure with many space gaps which economizes on computation time. Computational experiments with FRACTOP indicate that the metaheuristic improves significantly the results obtained by random search (RS), SA and GA.	global optimization;metaheuristic	Melek Demirhan;Linet Özdamar;Levent Helvacioglu;Sevket Ilker Birbil	1999	J. Global Optimization	10.1023/A:1008384329041	parallel processing;mathematical optimization;combinatorics;random search;genetic algorithm;computer experiment;parallel metaheuristic;simulated annealing;tabu search;local search;machine learning;mathematics;metaheuristic;global optimization	EDA	24.739442524756882	0.3866727764411068	73967
0e68273a19bc45952a35b03acb4a0a824fa6ce52	particle swarm optimization algorithm with asymmetric time varying acceleration coefficients	time varying;convergence;optimal method;modified particle swarm optimization;acceleration;gears;compound gear transmission ratio optimization particle swarm optimization algorithm asymmetric time varying acceleration coefficients global search local search pso algorithm benchmark test functions simulation;particle swarm optimization;teeth;optimization;particle swarm optimization acceleration optimization methods convergence robustness benchmark testing gears robots biomimetics birds;particle swarm optimization algorithm;particle swarm optimisation;local search;benchmark testing	To update the performance of the standard optimization method, a modified particle swarm optimization (MPSO) algorithm is proposed based on the earlier works. An asymmetric time-varying acceleration coefficients adjusting strategy introduced in this paper is to keep the balance between the global search and the local search with the great advantages of convergence property and robustness compared with basic PSO algorithm. The relationship between swarm average velocity and convergence is studied through Benchmark test functions simulation. All the merits mentioned above are demonstrated by the compound gear transmission ratio optimization in transmission systems.	algorithm;benchmark (computing);coefficient;distribution (mathematics);local search (optimization);mathematical optimization;particle swarm optimization;simulation;velocity (software development)	Guangqing Bao;K. F. Mao	2009	2009 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2009.5420504	acceleration;benchmark;mathematical optimization;multi-swarm optimization;simulation;meta-optimization;convergence;gear;computer science;engineering;derivative-free optimization;local search;machine learning;imperialist competitive algorithm;particle swarm optimization;tooth;metaheuristic	Robotics	28.151145827581264	-4.699084108659702	74068
d20c9528e362e6ffe3f2efc7cfcad48beee5388b	a digital neuromorphic vlsi architecture with memristor crossbar synaptic array for machine learning	vlsi analogue digital conversion cmos digital integrated circuits learning artificial intelligence memristors neural nets;neural nets;memristors;neurons arrays memristors neuromorphics hardware electric potential;cmos digital integrated circuits;analogue digital conversion;vlsi;size 90 nm memristor crossbar synaptic array machine learning reconfigurable digital neuromorphic vlsi architecture large scale spiking neural networks memristor nanodevice synaptic weights digital leaky integrate and fire neurons digital lif neurons online learning circuits spike timing dependent learning rule analog to digital conversion scheme pre synaptic weights silicon area power dissipation cmos technology power 9 46 mw;learning artificial intelligence	This paper presents a reconfigurable digital neuromorphic VLSI architecture for large scale spiking neural networks. We leverage the memristor nanodevice to build an N×N crossbar array to store synaptic weights with significantly reduced area cost. Our design integrates N digital leaky integrate-and-fire (LIF) neurons and the respective on-line learning circuits for a spike timing-dependent learning rule. The proposed analog-to-digital conversion scheme accumulates pre-synaptic weights of a neuron efficiently and reduces silicon area by using only one shared adder for processing LIF operations of N neurons. The proposed architecture is shown to be both area and power efficient. With 256 neurons and 64K synapses, the power dissipation and the area of our design are evaluated as 9.46-mW and 0.66-mm2, respectively, in a 90-nm CMOS technology.	adder (electronics);analog-to-digital converter;artificial neural network;biological neuron model;cmos;crossbar switch;learning rule;low insertion force;memristor;neuromorphic engineering;online and offline;online machine learning;overhead (computing);spiking neural network;synapse;synaptic weight;very-large-scale integration	Yongtae Kim;Yong Zhang;Peng Li	2012	2012 IEEE International SOC Conference	10.1109/SOCC.2012.6398336	electronic engineering;memristor;computer science;electrical engineering;theoretical computer science;very-large-scale integration;artificial neural network	EDA	38.83555278199912	-1.7108713552325412	74088
528aad118e83d10e9f258a0ab0f78ca37738099a	fourier series chaotic neural networks	non-monotonous degree;maximal lyapunov exponent;salesman problem;single neural unit;chaotic neural network model;new model;optimization problem;common chaotic neural network;local minimum;fourier series	In this paper, Fourier series chaotic neural network model is presented to improve the ability to escape the local minima so that it can effectively solve optimization problems. 10-city traveling salesman problem was given and the effects of the non-monotonous degree in the model on solving 10-city traveling salesman problem were discussed, the figures of the reversed bifurcation and the maximal Lyapunov exponents of single neural unit were given. The new model is applied to solve several function optimizations. Seen from the simulation results, the new model is powerful than the common chaotic neural network.	bifurcation theory;lyapunov fractal;mathematical optimization;maxima and minima;maximal set;network model;neural networks;simulation;travelling salesman problem	Jia-hai Zhang;Chen-zhi Sun;Yao-qun Xu	2010		10.1007/978-3-642-13278-0_18	mathematical optimization;artificial intelligence;machine learning;mathematics;3-opt	ML	30.742401546247915	3.5601028295316506	74337
8e4c67aa667108e1ceedbc970bea16a90ed09cd4	ant colony optimization with stepwise localization of the discrete search space to solve function optimization problems		A new application of Ant Colony Optimization (ACO) called improved-EAS (i-EAS) is proposed for solving the function optimization problem. i-EAS is an improvement on the elitist ant system (EAS) which was devised to solve the Travelling Salesman Problem (TSP). It is capable of stepwise localization of the search space. Here, we examined methods that search for solutions in the real space Rn by approximating them using discrete values (binary data). Our proposed ACO uses stepwise localization of the search space to improve the accuracy of solutions. To localize the search space on the current step, our ACO searches for solutions recursively in neighbors of the best solution β found on the previous step. We assume that α is the number of times that the search space is localized, then we reduce the search space so that R(α) satisfies the equation R(α) = RANGE × (1 / 2)(α × ln α), where RANGE is provided as an initial value. Although the domain of each independent variable is reduced, the number of observable points is 2l and does not change according to α, which means that solution accuracy can be improved so that d(α) = RANGE × (1 / 2)(α × ln α)+l-1, where d(α) is the interval of the observable data. To improve solution accuracy further, we perform mutation operations on the solution found by each ant every time it finishes a tour in search of solutions. Furthermore, in order to maintain population diversity, we dynamically altered the weight of elitist ant pheromone cyclically. The validity of i-EAS is verified by using well-known standard test functions with multiple peaks.	ant colony optimization algorithms;binary data;distribution (mathematics);mathematical optimization;observable;optimization problem;program optimization;recursion;reduction (complexity);stepwise regression;thomas' cyclically symmetric attractor;travelling salesman problem	Ryouei Takahashi;Yukihiro Nakamura	2017	2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)	10.1109/ICMLA.2017.00-78	initial value problem;artificial intelligence;computer science;algorithm;recursion;pattern recognition;travelling salesman problem;ant colony optimization algorithms;observable;population;binary data;optimization problem	Robotics	27.726702292381347	-2.811036794307036	74640
c339938713ff43d7d2e3fc806191c09180118b0b	simultaneous graphic generalization of vector data sets	scandinavie;tratamiento datos;maps;optimal solution;europa;scandinavia;optimisation;finlandia;delaunay triangulation;mapa;optimizacion;least squares adjustment;model generation;finlande;point location;production system;graphic generalization;data processing;conceptual model;traitement donnee;analyse moindres carres;cartographie;conjugate gradients method;conjugate gradient method;carte;optimization problem;least squares;modelo;cartografia;finland;triangulacion;least square;cartography;optimization;modele;triangulation;vector data;samhallsbyggnadsteknik;europe;map generalization;models	Manual cartographic generalization is a simultaneous process. However, most automatic approaches so far have been sequential; generalization operators are applied one at a time in a certain order. This has been the case both for model generalization (generalization of the conceptual model) and graphic generalization. Our research seeks to demonstrate that the graphic part of cartographic generalization can be formulated as an optimization problem and accordingly be solved in a single step. This paper deals with several issues regarding this optimization approach. Firstly, a set of appropriate analytical constraints for the generalization process is given, as well as rules for when to apply these constraints. In our approach, we are limited to formulating these constraints on point locations. Secondly, least-squares adjustment is proposed to find the optimal solution according to the constraints. Finally, the conjugate-gradients method is recommended for solving the normal equations. A prototype system for simultaneous graphic generalization has been implemented in C++, which communicates with a commercial map production system. Results from three tests of the prototype system are included in the paper.		Lars Harrie;Tapani Sarjakoski	2002	GeoInformatica	10.1023/A:1019765902987	generalization;mathematical optimization;data processing;computer science;artificial intelligence;mathematics;geometry;least squares;algorithm;cartography;statistics	ML	34.05750371792448	0.7958264502370422	75001
bb099f6d159b2547991febbaed3fb831f9abdaa6	non-uniform variance fuzzy guided particle swarm algorithm	nonuniform idea;particle swarm;nonuniform variance fuzzy guided particle swarm algorithm;convergence;premature convergence;uncertainty;nonuniform mutation operation;fuzzy global best;particle swarm optimization genetic mutations convergence analysis of variance stochastic processes telecommunication computing mathematics evolutionary computation robustness heuristic algorithms;data mining;stochastic programming convergence fuzzy set theory particle swarm optimisation search problems;fuzzy set theory;particle swarm optimizer;heuristic algorithms;particle swarm optimization;space searching;optimization;search problems;stochastic heuristic algorithms;evolutionary algorithm;diversity maintenance;stochastic programming;particle swarm optimisation;stochastic heuristic algorithms nonuniform variance fuzzy guided particle swarm algorithm evolutionary algorithm fuzzy global best premature convergence diversity maintenance nonuniform mutation operation space searching nonuniform idea nonuniform variance fuzzy guided particle updating scheme;heuristic algorithm;nonuniform variance fuzzy guided particle updating scheme	The particle swarm optimization (PSO) attracts many researchers' interests. However, its quick convergence often implies a rapid loss of diversity, which inevitably results in prematurity. Borrowed the idea of non-uniform mutation from evolutionary algorithm (EA) a non-uniform variance fuzzy guided PSO (fGuiPSO) is presented in this paper. The new particle updating strategy is based on the concept of fuzzy global best to deal with the premature convergence and diversity maintenance within the swarm. The variance of the global best determines its perturbing neighbor size and the non-uniform mutation operation has the merits of searching the space uniformly initially and very locally at later stage. Therefor the non-uniform idea is applied to adjust the variance of the global best particle. This non-uniform variance fuzzy guided particle updating scheme is also theoretically analyzed. Eight benchmarks are used to validate fGuiPSO and experiments indicate that fGuiPSO performs much better than PSO both in quality of solutions and robustness. The experiments confirm us that the non-uniform fuzzy particle updating strategy is a useful attempt for stochastic heuristic algorithms.	algorithm;particle swarm optimization	Xinchao Zhao	2009		10.1109/ICNC.2009.294	mathematical optimization;theoretical computer science;machine learning;mathematics	Robotics	27.957358632484887	-5.7186181406626	75105
b4bd0021a4a14fe925d8f9844bd9b4ac8f2dd21b	theoretical results on the effect of 'shortcut' actions in mdps	reinforcement learning;temporal abstraction;mixing time;markov chains	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	3d projection;algorithm;approximation;automated planning and scheduling;branching factor;francis;keyboard shortcut;map;markov chain;markov decision process;mathematical optimization;primary source;run time (program lifecycle phase);stereoscopy;time complexity;time-invariant system	Sara M. McCarthy;Doina Precup	2014	Connect. Sci.	10.1080/09540091.2014.885304	markov chain;simulation;computer science;artificial intelligence;machine learning;reinforcement learning	Robotics	38.66846610067139	3.947992838911599	75249
6ab4c31b48a7d43b60575ef1d94205a5392aefa0	pattern search optimization with applications on synthesis of linear antenna arrays	convergence;pattern search;pattern search psearch;genetic algorithm;optimization;derivative free optimization;antenna array;direct search;objectives;multi objective optimization problem;fitness function	In this work, Pattern Search (PSearch) method is introduced as a direct, efficient and derivative-free optimization tool with the applications on the antenna array synthesis in the antenna engineering. PSearch is a nonrandom method which can be exploited as a direct searching tool for minimization of a function which is not necessarily differentiable, stochastic, or even continuous. Thus, firstly antenna array synthesis is defined as a multi-objective optimization problem with its feasible variable and target spaces. For this aim, maximum amount of the side-lobe suppressions and broad/narrow null generations in any desired directions are simultaneously expressed as objectives in the target space while ensuring maximization in the gain performance of the antenna array. At the same time, the inter-element spacings and excitation amplitudes are considered as optimization variables that results in determination of the physical layout and feeding network of the array. In the optimization procedure, a fitness function is defined based on the target and synthesis variable spaces that can be applied into various antenna array designs, combining part by part with the different requirements. Besides convergence is made fast by a seeding process which consists of running ‘‘genetic” algorithm once with the random initial values. Finally, the whole PSearch synthesis method is verified by applying into the many linear antenna arrays synthesizes with various multi-objective requirements, and all of the optimized arrays are observed to outperform uniform arrays and representative designs. 2009 Elsevier Ltd. All rights reserved.	acoustic lobing;derivative-free optimization;expectation–maximization algorithm;fitness function;genetic algorithm;integrated circuit layout;mathematical optimization;multi-band excitation;multi-objective optimization;optimization problem;pattern search (optimization);requirement	Filiz Günes;Fikret Tokan	2010	Expert Syst. Appl.	10.1016/j.eswa.2009.11.012	pattern search;mathematical optimization;genetic algorithm;convergence;computer science;derivative-free optimization;antenna array;fitness function	EDA	31.644613868541516	-3.9540218750263283	75391
8ef84aea84a1b423687a0e2ab5274b3b9a77379b	weighted ℋ∞ mixed-sensitivity minimization for stable distributed parameter plants under sampled data control				Delano R. Carter;Armando A. Rodriguez	1999	Kybernetika			Robotics	33.19944134392936	2.408988653472251	75396
e8df306227a301c21145796006d0b81dace4b953	improved genetic algorithm for aircraft departure sequencing problem	adaptive genetic algorithms;departure sequencing;probability;adaptive genetic algorithm;aircraft departure sequencing problem;airports;big probability mutation;genetic algorithms traffic control arithmetic aircraft manufacture genetic mutations airports image motion analysis air traffic control evolutionary computation automobiles;evolutionary policy;wake vortex separation;adaptation model;particle swarm optimizer;transportation airports genetic algorithms particle swarm optimisation probability;particle swarm optimization;transportation;improved genetic algorithm;mathematical model;genetic algorithm;genetic algorithms;optimization;particle swarm optimization genetic algorithm aircraft departure sequencing problem optimization model symbolic coding total probability crossover big probability mutation evolutionary policy;symbolic coding;atmospheric modeling;encoding;particle swarm optimisation;total probability crossover;optimization model;wake vortex separation departure sequencing adaptive genetic algorithms total probability crossover;aircraft	Optimization model is build for solving the aircraft departure sequencing problem in this paper first. Then, an improved genetic algorithm (GA) using symbolic coding is proposed, where a type of total probability crossover and big probability mutation are performed. In this way, the evolutionary policy of Particle Swarm Optimization (PSO) is absorbed into the improved GA, which reduces the complexity and enhance the efficiency greatly. Last, a simulation program using basic GA, adaptive GA, and improved GA is performed. The simulation result shows that the model is effective and Improved GA has better performance than Basic GA or Adaptive GA.	author domain signing practices;genetic algorithm;mathematical model;mathematical optimization;particle swarm optimization;simulation	Lai-jun Wang;Da-wei Hu;Rui-zi Gong	2009	2009 Third International Conference on Genetic and Evolutionary Computing	10.1109/WGEC.2009.125	mathematical optimization;simulation;genetic algorithm;computer science;machine learning;statistics	Robotics	28.273444472974223	-2.8670250519888882	75501
c43306f802bab799b643dcf9542a2dbcf6e1d991	a novel hybrid multi-objective immune algorithm with adaptive differential evolution	differential evolution;immune algorithm;multi objective optimization;adaptive parameter control;期刊论文	In this paper, we propose a novel hybrid multi-objective immune algorithm with adaptive differential evolution, named ADE-MOIA, in which the introduction of differential evolution (DE) into multiobjective immune algorithm (MOIA) combines their respective advantages and thus enhances the robustness to solve various kinds of MOPs. In ADE-MOIA, in order to effectively cooperate DE with MOIA, we present a novel adaptive DE operator, which includes a suitable parent selection strategy and a novel adaptive parameter control approach. When performing DE operation, two parents are respectively picked from the current evolved and dominated population in order to provide a correct evolutionary direction. Moreover, based on the evolutionary progress and the success rate of offspring, the crossover rate and scaling factor in DE operator are adaptively varied for each individual. The proposed adaptive DE operator is able to improve both of the convergence speed and population diversity, which are validated by the experimental studies. When comparing ADE-MOIA with several nature-inspired heuristic algorithms, such as NSGA-II, SPEA2, AbYSS, MOEA/D-DE, MIMO and DMOPSO, simulations show that ADE-MOIA performs better on most of 21 well-known benchmark problems. & 2015 Published by Elsevier Ltd.	benchmark (computing);differential evolution;genetic algorithm;heuristic;image scaling;mimo;moea framework;mathematical optimization;population;simulation	Qiuzhen Lin;Qingling Zhu;Peizhi Huang;Jianyong Chen;Zhong Ming;Jianping Yu	2015	Computers & OR	10.1016/j.cor.2015.04.003	differential evolution;mathematical optimization;artificial intelligence;multi-objective optimization;machine learning;mathematics	AI	27.09055665092099	-4.231664052637516	76232
2a4ca6801fab6ede2fee73fe571e353518e5839f	a cluster and gradient-based artificial immune system applied in optimization scenarios	dynamic programming;cluster algorithm;pattern clustering;convergence;optimization scenarios;artificial immune system;nonlinear optimization artificial immune systems clustering gradient based algorithms;numerical information;cluster based artificial immune system;maturation control;cloning;pattern clustering artificial immune systems dynamic programming gradient methods numerical analysis;optimization problem;numerical analysis;ais;vectors;immunological principles;clustering;optimization system;hypermutation approach;immune system;gradient based artificial immune system;dynamic optimization scenarios;clustering algorithms;gradient methods;convergence process;cloning process;optimization;tv;dynamic optimization scenarios gradient based artificial immune system cluster based artificial immune system optimization scenarios ais immunological principles numerical information hypermutation approach optimization system cloning process maturation control convergence process;gradient based algorithms;nonlinear optimization;local search;artificial immune systems;optimization immune system cloning vectors convergence clustering algorithms tv;dynamic optimization	The main objective of this paper is to use artificial immune systems (AIS) in optimization problems. For this purpose, two major immunological principles presented in the literature are revisited: hypermutation, which is responsible for local search, and receptor edition, used to explore different areas in the solution space. This paper presents three major modifications divided into two different goals. The first goal is to speed up the convergence of each individual. This is done through a new hypermutation approach that uses the numerical information provided by the optimization system to drive the cloning process to interesting directions into the solution space. The second goal regards the reduction of the computational effort necessary to simulate the whole population. This is accomplished by adding to the AIS algorithm two more features of the natural immune system: maturation control and memory cells. The maturation control analyzes the antibodies and, during the convergence process, eliminates possible redundancies, represented by individuals driving to the same local optimum. The last proposed improvement is the use of memory cells in dynamic-optimization scenarios. In such situations, a repertoire of successful cases is used to forecast part of the initial population. Combining these concepts together decreases the number of antibodies, generations, and clones, consequently speeding up the convergence process. Applications illustrate the performance of the proposed method.	algorithm;artificial immune system;computation;computer cluster;feasible region;gradient;local optimum;local search (optimization);mathematical optimization;memory cell (binary);numerical analysis;simulation	Leonardo de Mello Honório;Armando M. Leite da Silva;Daniele A. Barbosa	2012	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2010.2044242	mathematical optimization;nonlinear programming;computer science;bioinformatics;artificial intelligence;machine learning;cluster analysis;artificial immune system	Vision	27.991326918615517	-5.806364354659885	76309
6076d4e6bd2ed9f83446142b7eeed8ad3b676f52	adaptive diversity in pso	swarm intelligence;adaptive optimization;particle swarm optimizer;adaptation;optimization	Spatial Extension PSO (SEPSO) and Attractive-Repulsive PSO (ARPSO) are methods for artificial injection of diversity into particle swarm optimizers that are intended to encourage converged swarms to engage in exploration. While simple to implement, effective when tuned correctly, and benefiting from intuitive appeal, SEPSO behavior can be improved by adapting its radius and bounce parameters in response to collisions. In fact, adaptation can allow SEPSO to compete with and outperform ARPSO. The adaptation strategies presented here are simple to implement, easy to tune, and retain SEPSO's intuitive appeal.	particle swarm optimization;phase-shift oscillator	Christopher K. Monson;Kevin D. Seppi	2006		10.1145/1143997.1144006	adaptive optimization;mathematical optimization;simulation;swarm intelligence;computer science;artificial intelligence;machine learning;adaptation	HCI	29.11337058154852	-4.221195433182231	76572
739a6de7c258de5f7e55e80b3ad3459333aaceb2	a new simple chaotic system and its application in medical image encryption		Today, medical imaging suffers from serious issues such as malicious tampering and privacy leakage. Encryption is an effective way to protect these images from security threats. Among the available encryption algorithms, chaos-based methods have strong cryptographic properties, because chaotic systems are sensitive to initial conditions and parameters. However, traditional chaotic systems are easy to build, analyze, predict and can be re-scaled to any desired frequency. Thus, encryption schemes using traditional chaotic systems have low security levels. In this work, we propose a new simple chaotic system that utilizes a hyperbolic sine as its nonlinearity; this nonlinearity has rarely appeared in previous studies. Furthermore, the new chaotic system uses a decorrelation operation to enhance its performance. Statistical testing verifies that the chaotic sequence has good pseudorandom characteristics. In this study, we propose a scheme for medical image encryption based on this new chaotic system. The results of tests show that this encryption method can encrypt images effectively in a single round and that the proposed scheme provides sufficient security against known attacks.	algorithm;brute-force attack;chaos theory;ciphertext;cryptography;cryptosystem;dicom;decorrelation;differential cryptanalysis;encryption;information security;initial condition;key space (cryptography);known-plaintext attack;medical imaging;nonlinear system;plaintext;pseudorandomness;randomness;run time (program lifecycle phase);spectral leakage	Jizhao Liu;Yide Ma;Shouliang Li;Jing Lian;Xinguo Zhang	2017	Multimedia Tools and Applications	10.1007/s11042-017-5534-8	computer vision;cryptography;computer science;hyperbolic function;artificial intelligence;theoretical computer science;encryption;nonlinear system;chaotic;pseudorandom number generator;decorrelation	Security	38.465114443748085	-8.6610258781692	76689
ac8b418a289abe1f6bf2707d25dab851d9e25949	big valley in scheduling problems landscape — metaheuristics with reduced searching area		Created in the 90s of the past century methods of constructing algorithms (metaheuristic), inspired by the no free lunch theorem of Wolpert and Macready, using specific properties of problems, do not meet present expectations of practitioners. Commonly used artificial intelligence algorithms in recent years have also proved to be ineffective in solving a large group of extremely difficult instances of various problems. In the work we present some empirical methods of exploration of solution space in optimization problems whose solutions are represented by permutations. While sampling the set of permissible solutions we designate the histogram of the frequency of occurrence of local minima and on this basis we verify the statistical hypothesis concerning the (normal) distribution of occurrence of these minima. Due to this process we can flexibly change the “radius” of the searched area. Computational experiments performed on examples of the job shop problem are promising and inspire to conduct further research in this direction.	algorithm;artificial intelligence;computation;experiment;feasible region;job shop scheduling;mathematical optimization;maxima and minima;maximal set;metaheuristic;no free lunch theorem;null-terminated string;numerical analysis;sampling (signal processing);scheduling (computing);tabu search	Wojciech Bozejko;Czeslaw Smutnicki;Mariusz Uchronski;Mieczyslaw Wodecki	2017	2017 22nd International Conference on Methods and Models in Automation and Robotics (MMAR)	10.1109/MMAR.2017.8046871	no free lunch theorem;no free lunch in search and optimization;algorithm design;metaheuristic;machine learning;approximation algorithm;computational complexity theory;job shop;mathematical optimization;optimization problem;artificial intelligence;mathematics	Robotics	25.50424851052325	3.849909198061088	76811
0b2514f782c448a898e32baf1eda392031364342	fitness costs of mutation rate adaption and its application to optimization of dynamic objective functions	pre- mature convergence;mutation rate;optimization;evolutionary algorithm;adaptation.;premature convergence;objective function;fitness landscape;functional unit	Evolutionary algorithms can be used to solve complex optimization tasks. However, adequate parameterization is crucial for efficient optimization. Evolutionary adaptation of mutation rates provides a solution to the problem of finding suitable mutation rate settings. However, evolution of low mutation rates may lead to premature convergence. In nature, mutation rate control coevolves with other functional units in a genome, and it is constrained because mutation rate control requires energy and resources. This principle can be captured by an abstract concept of fitness cost associated mutation rate adaptation, which can be generically applied in evolutionary algorithms. Application of this principle can be useful for addressing problems of premature convergence. This contribution explores applications of this concept within the context of dynamic fitness landscapes. It is shown that fitness costs for mutation rate adaptation is no less advantageous in dynamic fitness landscapes than in static ones, and that interesting synergies can arise in conjunction with dynamics in multimodal fitness landscapes.	evolutionary algorithm;mathematical optimization;multimodal interaction;premature convergence;synergy	Jan T. Kim	2003				PL	25.567281104818147	-7.956368730278869	76923
ee9385efb66ee0b1bee31c1632141729bb7fb6f5	numerical simplification for bloat control and analysis of building blocks in genetic programming	genetic program;building block;program simplification;genetic programming;algebraic method;building blocks;code bloat;fitness function	In tree-based genetic programming, there is a tendency for the size of the programs to increase from generation to generation, a phenomenon known as bloat. It is standard practice to place some form of control on program size either by limiting the number of nodes or the depth of the program trees, or by adding a component to the fitness function that rewards smaller programs (parsimony pressure). Others have proposed directly simplifying individual programs using algebraic methods. In this paper, we add node-based numerical simplification as a tree pruning criterion to control program size. We investigate the effect of online program simplification, both algebraic and numerical, on program size and resource usage. We also investigate the distribution of building blocks within a genetic programming population and how this is changed by using simplification. We show that simplification results in reductions in expected program size, memory use and computation time. We also show that numerical simplification performs at least as well as algebraic simplification, and in some cases will outperform algebraic simplification. We further show that although the two online simplification methods destroy some existing building blocks, they effectively generate additional new and more diverse building blocks during evolution, which compensates for the negative effect of disruption of building blocks.	central processing unit;denial-of-service attack;experiment;fitness function;genetic programming;java virtual machine;level of detail;maximum parsimony (phylogenetics);norm (social);numerical analysis;numerical linear algebra;numerical method;occam's razor;runtime system;software bloat;symbolic computation;text simplification;time complexity;victoria (3d figure)	David Kinzett;Mark Johnston;Mengjie Zhang	2009	Evolutionary Intelligence	10.1007/s12065-009-0029-9	genetic programming;code bloat;computer science;artificial intelligence;theoretical computer science;machine learning;fitness function;algorithm	PL	25.18831864621211	-9.176766935433841	76932
862db87fb24f361345a4e23489643983e2d8d64a	normalization for genetic algorithms with nonsynonymously redundant encodings	synonymous encoding;synonymy;parent genotype;evolutionary computation;sinonimia;fitness distance analysis;synonymie;redundant encoding;genotype;redundancia;search space;government;crossover;genetic algorithms encoding moon evolutionary computation algorithm design and analysis optimization methods genetic programming function approximation engines government;uncorrelated search spaces genetic algorithms normalization nonsynonymously redundant encodings parent genotype;genetic programming;algoritmo genetico;synonymous encoding crossover fitness distance analysis genetic algorithm ga nonsynonymous encoding normalization redundant encoding;search problems encoding genetic algorithms;nonsynonymous encoding;redundancy;engines;function approximation;moon;normalization;algorithme genetique;nonsynonymously redundant encodings;uncorrelated search spaces;algorithme evolutionniste;genetic algorithm;genetic algorithms;algoritmo evolucionista;search problems;evolutionary algorithm;encoding;algorithm design and analysis;redondance;genotipo;genetic algorithm ga;optimization methods	Normalization transforms one parent genotype to be consistent with the other before crossover. In this paper, we explain how normalization alleviates the difficulties caused by nonsynonymously redundant encodings in genetic algorithms. We define the encodings with maximally nonsynonymous property and prove that the encodings induce uncorrelated search spaces. Extensive experiments for a number of problems show that normalization transforms the uncorrelated search spaces to correlated ones and leads to significant improvement in performance.	artificial neural network;character encoding;database normalization;experiment;genetic algorithm;genetic programming;mathematical optimization;search algorithm	Sung-Soon Choi;Byung Ro Moon	2008	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2007.913699	genetic algorithm;computer science;bioinformatics;artificial intelligence;machine learning;evolutionary algorithm;mathematics;algorithm;evolutionary computation	DB	28.454192598771783	-7.163372619908327	76949
7e15daa560e38c242e4fc7e7f8755b86d00e3cc2	making and breaking power laws in evolutionary algorithm population dynamics	algorithm analysis;search algorithm;population dynamic;historical coupling;analytical method;evolutionary algorithms;population dynamics;genealogical graphs;artificial intelligence;optimization;population topology;power law;evolutionary algorithm;optimal algorithm;evolutionary computing	Deepening our understanding of the characteristics and behaviors of population-based search algorithms remains an important ongoing challenge in Evolutionary Computation. To date however, most studies of Evolutionary Algorithms have only been able to take place within tightly restricted experimental conditions. For instance, many analytical methods can only be applied to canonical algorithmic forms or can only evaluate evolution over simple test functions. Analysis of EA behavior under more complex conditions is needed to broaden our understanding of this populationbased search process. This paper presents an approach to analyzing EA behavior that can be applied to a diverse range of algorithm designs and environmental conditions. The approach is based on evaluating an individual’s impact on population dynamics using metrics derived from genealogical graphs. From experiments conducted over a broad range of conditions, some important conclusions are drawn in this study. First, it is determined that very few individuals in an EA population have a significant influence on future population dynamics with the impact size fitting a power law distribution. The power law distribution indicates there is a non-negligible probability that single individuals will dominate the entire population, irrespective of population size. Two EA design features are however found to cause strong changes to this aspect of EA behavior: i) the population topology and ii) the introduction of completely new individuals. If the EA population topology has a long path length or if new (i.e. historically uncoupled) individuals are continually inserted into the population, then power law deviations are observed for large impact sizes. It is concluded that such EA designs can not be dominated by a small number of individuals and hence should theoretically be capable of exhibiting higher degrees of parallel search behavior.	distribution (mathematics);evolutionary algorithm;evolutionary computation;experiment;population dynamics;search algorithm	James M. Whitacre;Ruhul A. Sarker;Q. Tuan Pham	2009	Memetic Computing	10.1007/s12293-009-0009-8	mathematical optimization;power law;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;population dynamics;algorithm;search algorithm	Metrics	28.315817987827938	2.874947326353698	77052
e941fb14531c299409c8ae9c52b12fb0ace47789	moves by taking account into other players in othello	modified td method modified temporal difference method 1 ply othello temporal learning method memetic algorithm ea local search method;search problems evolutionary computation games of skill	In this paper, we introduce a modified Temporal Difference method which takes account into the moves of other players in populations for 1-ply Othello. That is, by using Temporal Learning method, we introduce Memetic Algorithm, i.e., hybridization of EA with local search method. The proposed modified TD-method can maintain the diversity in populations. Experimental results show the effectiveness of the proposed method.	evolutionary algorithm;local search (optimization);loss function;machine learning;memetic algorithm;memetics;newton's method;optimization problem;population;reversi;temporal difference learning;temporal logic	Hisashi Handa	2012	The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Symposium on Advanced Intelligence Systems	10.1109/SCIS-ISIS.2012.6505278	mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;algorithm	Robotics	26.360132686014836	-4.483074045491396	77148
dd776de2c55e1c8e1f967bf2f5a730055b6195c7	optimal multiuser detection with artificial fish swarm algorithm	multiuser detection	The optimal multiuser detection for communication systems can be characterized as an NP-hard optimization problem. In this paper, as a new heuristic intelligent optimization algorithm, Artificial Fish Swarm Algorithm (AFSA) is employed for the detection problem, the results show that it has better performances such as good global convergence, strong robustness, insensitive to initial values, simplicity of implementation and faster convergent speed with random initial values compared with genetic algorithm (GA). With the increase of fish or iteration number, the AFSA has only the linear increment of complexity and maintain a superior performance; its improved methods are also proposed and analysed in the end.	genetic algorithm;heuristic;iteration;local convergence;mud;mathematical optimization;multi-user;np-hardness;optimization problem;pattern recognition;performance;signal processing;software release life cycle;swarm	Mingyan Jiang;Yong Wang;Stephan Pfletschinger;Miguel Angel Lagunas;Dongfeng Yuan	2007		10.1007/978-3-540-74282-1_121	computer science	AI	29.81848944389494	-4.119642243185231	77159
e7b7a4274eb7e000025a3453988f0f8b900c397d	capacity, fidelity, and noise tolerance of associative spatial-temporal memories based on memristive neuromorphic networks	crossnets;associative memories;capacity;memristors;nanoelectronics;neuromorphic networks;noise tolerance;spatial-temporal memories	"""We have calculated key characteristics of associative (content-addressable) spatial-temporal memories based on neuromorphic networks with restricted connectivity-""""CrossNets."""" Such networks may be naturally implemented in nanoelectronic hardware using hybrid memristive circuits, which may feature extremely high energy efficiency, approaching that of biological cortical circuits, at much higher operation speed. Our numerical simulations, in some cases confirmed by analytical calculations, show that the characteristics depend substantially on the method of information recording into the memory. Of the four methods we have explored, two methods look especially promising-one based on the quadratic programming, and the other one being a specific discrete version of the gradient descent. The latter method provides a slightly lower memory capacity (at the same fidelity) then the former one, but it allows local recording, which may be more readily implemented in nanoelectronic hardware. Most importantly, at the synchronous retrieval, both methods provide a capacity higher than that of the well-known Ternary Content-Addressable Memories with the same number of nonvolatile memory cells (e.g., memristors), though the input noise immunity of the CrossNet memories is lower."""	algorithm;analog;cmos;cyp19a1 wt allele;channel capacity;content-addressable memory;crossbreeding;data compression;discontinuous galerkin method;frame (physical object);gradient descent;heart rate variability;immune tolerance;memristor;neuromorphic engineering;nonvolatile bios memory;numerical analysis;overhead (computing);quadratic programming;simulation;supercomputer;supervised learning;synapses;whole earth 'lectronic link;decigram;mitotic dna replication maintenance of fidelity	Dmitri Gavrilov;Dmitri B. Strukov;Konstantin K. Likharev	2018		10.3389/fnins.2018.00195	memristor;theoretical computer science;nanoelectronics;electronic circuit;ternary operation;gradient descent;non-volatile memory;cmos;neuromorphic engineering;computer science	ML	39.03988880291501	-0.4491665935798013	77207
0e5255a50a1fac888f6f64887d395897e7281bee	inverse modeling in geoenvironmental engineering using a novel particle swarm optimization algorithm	inverse model;premature convergence;search space;efficient algorithm;center of mass;inverse modeling;particle swarm optimizer;inverse problem;contaminant transport;particle swarm optimization;success rate;particle swarm optimization algorithm	Algorithms derived by mimicking the nature are extremely useful for solving many real world problems in different engineering disciplines. Particle swarm optimization (PSO) especially has been greatly acknowledged for its simplicity and efficiency in obtaining good solutions for complex problems. However, premature convergence of the standard PSO and many of its variants is a downside particularly for its application to the inverse problems. This aspect encourages further research in developing efficient algorithms for such problems. In this work, a novel PSO algorithm is proposed by introducing fitness of a new location in the search space into the standard PSO which enables to enhance the success rate of the algorithm. The proposed algorithm uses center of mass of the population to compare the fitness of global best particle in each iteration. The proposed algorithm is applied to solve contaminant transport inverse problem. The performance of different PSO algorithms is compared on synthetic test data and it is shown that the proposed algorithm outperforms its counterparts. Further, accurate design parameters are estimated using the proposed inverse model from the experimental data.	algorithm;dhrystone;fitness function;iteration;mathematical optimization;particle swarm optimization;phase-shift oscillator;premature convergence;test data;turing test	Tadikonda Venkata Bharat;Jitendra Sharma	2010		10.1007/978-3-642-15461-4_43	mathematical optimization;multi-swarm optimization;inverse problem;artificial intelligence;machine learning;mathematics;imperialist competitive algorithm;particle swarm optimization	AI	29.008291174372243	-4.251803776842146	77314
594f60735fb8b8f390b3bd598ebe978133c3d806	parameter control mechanisms in differential evolution: a tutorial review and taxonomy	differential evolution parameter control mechanism continuous optimization de algorithms candidate parameter values design features algorithm classification taxonomy;optimisation;differential evolution;parameter control;evolutionary computation;self adaptive;classification;taxonomy differential evolution parameter control adaptive self adaptive classification;vectors sociology statistics taxonomy classification algorithms algorithm design and analysis gaussian distribution;adaptive;pattern classification evolutionary computation optimisation;taxonomy;pattern classification	Differential evolution (DE) is a promising algorithm for continuous optimization. Its two parameters, CR and F, have great effect on the algorithm performance. In recent years many DE algorithms with parameter control mechanisms were proposed. In this paper we propose a taxonomy to classify these algorithms according to the number of candidate parameter values, the number of parameter values used in a single generation, and the source of considered information. We classify twenty-three recent studies into nine categories and review their design features. Two types of relationships between these algorithms and several research directions are also summarized.	algorithm;continuous optimization;control system;differential evolution;mathematical optimization;taxonomy (general)	Tsung-Che Chiang;Cheng-Nan Chen;Yu-Chieh Lin	2013	2013 IEEE Symposium on Differential Evolution (SDE)	10.1109/SDE.2013.6601435	mathematical optimization;machine learning;data mining;mathematics	Logic	26.037050115080987	-6.8843348056562075	77446
0949d5f3571b1be7d0e8b436ec546cc876e3840a	enhancing the harmony search algorithm performance on constrained numerical optimization		In this paper, an improved harmony search (ImHS) algorithm is presented. HS is a simple but efficient metaheuristic method explored in recent literature, that simulates the process of musical improvisation. Two modifications for parameter tuning are proposed to enhance the algorithm performance in the solution of constrained numerical optimization problems, maintaining the simplicity of its original design. Metaheuristics are methods for solving optimization problems, and are based in two processes: exploration (diversification) and exploitation (intensification). The proposed modifications improve both processes in HS, without breaking their balance. A well-known ideal problem set was used as a reference to compare the efficiency of the developed algorithm ImHS with HS and three of its most successful variants, and also with two other metaheuristics of different nature, artificial bee colony (ABC) and modified ABC (MABC). Various techniques were applied to evaluate the algorithm performance with the proposed modifications, in order to validate the reliability of the comparison. In most case studies, ImHS far surpassed the results of HS and ABC, also improving the performance of the selected variants. Additionally, its results reached a similar quality than the obtained with MABC but with a significantly lower computational cost, suggesting that it can be a useful tool for solving real-world optimization problems if they are modeled as constrained numerical cases.	artificial bee colony algorithm;computation;computational complexity theory;diversification (finance);harmony search;mathematical optimization;metaheuristic;numerical analysis;numerical method;search algorithm;shadow volume	Edgar Alfredo Portilla-Flores;&#x00C1;Lvaro S&#x00E1;nchez-M&#x00E1;rquez;Leticia Flores-Pulido;Eduardo Vega-Alvarado;Maria B&#x00E1;rbara Calva Y&#x00E1;&#x00F1;ez;Jorge Alexander Aponte-Rodr&#x00ED;guez;Paola Andrea Ni&#x00F1;o-Su&#x00E1;rez	2017	IEEE Access	10.1109/ACCESS.2017.2771741	problem set;harmony search;metaheuristic;constrained optimization;algorithm design;computer science;linear programming;mathematical optimization;optimization problem	HPC	26.23155827154652	-3.496534749627922	77501
0888ad6367397320d2f73d3be58c50047b6c43c0	tuning extreme learning machine by an improved artificial bee colony to model and optimize the boiler efficiency	artificial bee colony;greedy selection mechanism;extreme learning machine;coal fired boilers;opposition based learning	In this paper, a novel optimization technique based on artificial bee colony algorithm (ABC), which is called as PS-ABCII, is presented. In PS-ABCII, there are three major differences from other ABC-based techniques: (1) the opposition-based learning is applied to the population initialization; (2) the greedy selection mechanism is not adopted; (3) the mode that employed bees become scouts is modified. In order to illustrate the superiority of the proposed modified technique over other ABC-based techniques, ten classical benchmark functions are employed to test. In addition, a hybrid model called PS-ABCII-ELM is also proposed in this paper, which is combined of the PS-ABCII and Extreme Learning Machine (ELM). In PS-ABCII-ELM, the PS-ABCII is applied to tune input weights and biases of ELM in order to improve the generalization performance of ELM. And then it is applied to model and optimize the thermal efficiency of a 300MW coal-fired boiler. The experimental results show that the proposed model is very convenient, direct and accurate, and it can give a general and suitable way to predict and improve the boiler efficiency of a coal-fired boiler under various operating conditions.	artificial bee colony algorithm	Guoqiang Li;Peifeng Niu;Yunpeng Ma;Hongbin Wang;Weiping Zhang	2014	Knowl.-Based Syst.	10.1016/j.knosys.2014.04.042	artificial intelligence;machine learning;pulverized coal-fired boiler;operations research	AI	25.553216542711386	-6.723595797103377	77582
22b827d52e8e4280bd70c8756cf4ae4d60d28f4a	coding tsp tours as permutations via an insertion heuristic	traveling salesman problem;insertion heuristics;search space;genetics;permutation coding	An insertion heuristic for the traveling salesman problem builds a tour one city at a time by inserting each city into the tour at a position that increases the tour’s length the least. Permutations can encode TSP tours for genetic search via this heuristic. Decoding such a chromosome consists of inserting the cities into a tour in the order the chromosome lists them. The chromosome specifies when each city is inserted into the tour rather than where; this scheme enlists the heuristic’s power in the genetic search. This paper describes a genetic algorithm for TSP that encodes candidate tours as permutations via the insertion heuristic, as well as two crossover operators appropriate to the coding. Tests on thirteen TSP instances indicate that the algorithm is effective on instances of moderate size, often identifying optimal tours, and that it continues to find tours that are short, though not optimal, as the number of cities increases and the search space grows.	encode;genetic algorithm;heuristic;optimal design;set tsp problem;travelling salesman problem	Bryant A. Julstrom	1999		10.1145/298151.298356	mathematical optimization;computer science;travelling salesman problem;algorithm	AI	25.389698854600695	2.6618138796639754	77636
ba0637747ba6387f288f9ee18f6776a27ff24f6d	swarm-based spreading points		In this paper we propose a Swarm-based Spreading Points algorithm (SSP) for improving the solutions for packing problems. The SSP repositions the initial set of points and evolves it to improve the minimum distance between points. During the evolving process, for each point, a feasible direction of movement is computed according to its nearest neighbors so that the shortest pairwise distance between the point and other points can be increased along this direction (if any). Our experiments showed that the SSP algorithm can improve certain best-known solutions for some problems previously reported in the literature.	algorithm;experiment;set packing;swarm	Xiangyang Huang;LiGuo Huang;Shudong Zhang;Lijuan Zhou	2017		10.1007/978-3-319-61833-3_17	swarm behaviour;mathematical optimization;machine learning;artificial intelligence;packing problems;computer science;pairwise comparison;particle swarm optimization	Robotics	28.525632777880485	-2.148525862994171	77649
8e61098521c7849df04488e9da754f61f0f8f2f4	adaptive parameter selection of quantum-behaved particle swarm optimization on global level	particle swarm;modelizacion;metodo adaptativo;swarm intelligence;algorithm performance;methode adaptative;intelligence artificielle;systeme ouvert;sistema particulas;optimization problem;modelisation;quantum computation;particle swarm optimizer;parameter selection;optimizacion enjambre particula;mathematical programming;resultado algoritmo;adaptive method;particle system;performance algorithme;optimisation essaim particule;artificial intelligence;algorithme evolutionniste;algoritmo evolucionista;inteligencia artificial;evolutionary algorithm;calcul quantique;reseau neuronal;particle swarm optimization algorithm;open systems;sistema abierto;calculo cuantico;modeling;high dimension;programmation mathematique;programacion matematica;red neuronal;control method;neural network;systeme particules	The conventional parameter optimisation of PID controller is easy to produce surge and big overshoot, and therefore heuristics such as genetic algorithm (GA), particle swarm optimisation (PSO) are employed to enhance the capability of traditional techniques. But the major problem of these algorithms is that they may be trapped in the local optima of the objective and lead to poor performance. In this paper, a quantum-behaved particle swarm optimisation (QPSO) for the parameter optimisation of PID controller is proposed from sub-optimal perspective. This method is very advantageous for practical control systems. Three examples are given to illustrate the design procedure and exhibit the effectiveness of the proposed method via a comparison study with an existing Z-N, GA and PSO approaches	control system;genetic algorithm;heuristic (computer science);local optimum;mathematical optimization;overshoot (signal);pid;particle swarm optimization;process identifier;quantum;software release life cycle	Wenbo Xu;Jun Sun	2005		10.1007/11538059_44	optimization problem;mathematical optimization;multi-swarm optimization;meta-optimization;systems modeling;swarm intelligence;computer science;artificial intelligence;machine learning;evolutionary algorithm;particle system;mathematics;open system;imperialist competitive algorithm;quantum computer;particle swarm optimization;artificial neural network;algorithm;metaheuristic	AI	27.702099957212596	0.6567895236584433	77716
e94ec87aaf7ccec00e69074b8da9be843b0ca698	a new evolutionary algorithm based on alopex and harmony search algorithm	engineering optimization evolutionary algorithm harmony search algorithm simulated annealing alopex based evolutionary algorithm;optimization algorithm design and analysis annealing convergence evolutionary computation benchmark testing instruments;instruments;convergence;evolutionary computation;annealing;optimal method;alopex based evolutionary algorithm;search problems evolutionary computation;alopex;simulated annealing;gradient descent;genetic algorithm;optimization;search problems;engineering optimization;evolutionary algorithm;harmony search;optimization alopex harmony search;algorithm design and analysis;harmony search algorithm;benchmark testing;heuristic algorithm	Alopex (Algorithm of Pattern Extraction) was a correlation-based algorithm which possessed characteristics of both gradient descent and simulated annealing. It had been proved to be an effective tool for engineering optimization. The HS (Harmony Search) algorithm was a meta-heuristic algorithm proposed in recent years and had been shown several advantages compared with traditional optimization methods such as GA (genetic algorithm). In this paper, HS was embedded into the Alopex-based evolutionary algorithm (AEA) to form an improved evolutionary algorithm HS-Alopex. In the HS-Alopex, with the help of the random nature of HS, the diversity of population was improved and the prematurity problem was alleviated to a certain extent. The proposed algorithm is investigated on ten commonly used benchmark functions. Simulation results demonstrate that the new algorithm can obtain a better solution quality and faster convergence speed, comparing with the single AEA and HS algorithm.	alopex;benchmark (computing);embedded system;evolutionary algorithm;genetic algorithm;gradient descent;hs algorithm;harmony search;heuristic (computer science);mathematical optimization;pattern recognition;randomness;search algorithm;simulated annealing;simulation	Fei Li;Zhenzhen Mei;Shaojun Li	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5583307	mathematical optimization;computer science;artificial intelligence;machine learning;fsa-red algorithm;dinic's algorithm;population-based incremental learning	Robotics	27.281121132150986	-4.882028542100513	77746
c70025eb7dd8d83a46e2f7bcf22622a10970d782	starting from scratch: growing longest common subsequences with evolution	optimisation sous contrainte;suite aleatoire;constrained optimization;algoritmo paralelo;secuencia binaria;binary sequence;parallel algorithm;optimum;genotype;sous sequence commune la plus longue;heuristic method;chaine caractere;bioinformatique;metodo heuristico;probabilistic approach;algoritmo genetico;sucesion aleatoria;algorithme parallele;initially empty solutions;optimizacion con restriccion;longest common subsequence;enfoque probabilista;approche probabiliste;optimo;cadena caracter;random sequence;algorithme genetique;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;subsecuencia comun la mas larga;methode heuristique;bioinformatica;evolutionary algorithm;sequence binaire;longest common subsequence lcs;genotipo;character string;bioinformatics	An evolutionary algorithm (EA) usually initializes its population with random genotypes, which represent random solutions to the target problem instance. If the problem is one of constrained optimization, an initial population whose genotypes all represent empty solutions might allow the EA to grow valid solutions as much as search for them and thereby identify good solutions more quickly. This is the case in a genetic algorithm (GA) for the longest common subsequence problem, which seeks the length of a longest subsequence common to each of a set of given strings. The GA encodes sequences as binary strings that indicate subsequences of the shortest or first given string. In tests on a variety of problem instances, the GA always identifies an optimum subsequence, but on most instances, the GA reaches an optimum more quickly when its initial population encodes empty sequences than when its initial genotypes represent random sequences.		Bryant A. Julstrom;Brenda Hinkemeyer	2006		10.1007/11844297_94	mathematical optimization;constrained optimization;combinatorics;genetic algorithm;longest increasing subsequence;string;computer science;artificial intelligence;random sequence;evolutionary algorithm;genotype;longest common subsequence problem;pseudorandom binary sequence;mathematics;parallel algorithm;longest alternating subsequence;algorithm	NLP	26.70995593818377	2.4596249180178726	77841
4d6e54284e6eebdf468d2e62a9130e8965a36031	an orthogonal multi-objective evolutionary algorithm for multi-objective optimization problems with constraints	strict partial ordered relation;optimal method;multi objective optimization;multi objective evolutionary algorithm;paretooptimal set;orthogonal design;evolutionary algorithms;evolutionary algorithm;numerical experiment;multi objective optimization problem;pareto optimality;strict partial ordered relation evolutionary algorithms orthogonal design multi objective optimization paretooptimal set;uniform distribution;partial order	In this paper, an orthogonal multi-objective evolutionary algorithm (OMOEA) is proposed for multi-objective optimization problems (MOPs) with constraints. Firstly, these constraints are taken into account when determining Pareto dominance. As a result, a strict partial-ordered relation is obtained, and feasibility is not considered later in the selection process. Then, the orthogonal design and the statistical optimal method are generalized to MOPs, and a new type of multi-objective evolutionary algorithm (MOEA) is constructed. In this framework, an original niche evolves first, and splits into a group of sub-niches. Then every sub-niche repeats the above process. Due to the uniformity of the search, the optimality of the statistics, and the exponential increase of the splitting frequency of the niches, OMOEA uses a deterministic search without blindness or stochasticity. It can soon yield a large set of solutions which converges to the Pareto-optimal set with high precision and uniform distribution. We take six test problems designed by Deb, Zitzler et al., and an engineering problem (W) with constraints provided by Ray et al. to test the new technique. The numerical experiments show that our algorithm is superior to other MOGAS and MOEAs, such as FFGA, NSGAII, SPEA2, and so on, in terms of the precision, quantity and distribution of solutions. Notably, for the engineering problem W, it finds the Pareto-optimal set, which was previously unknown.	circuit complexity;dynamic energy budget;evolutionary algorithm;evolutionary computation;experiment;moea framework;mathematical optimization;multi-objective optimization;new type;niche blogging;numerical analysis;numerous;order (action);pareto efficiency;sion's minimax theorem;solutions;stochastic process;erythritol anhydride;exponential	Sanyou Zeng;Lishan Kang;Lixin X. Ding	2004	Evolutionary Computation	10.1162/evco.2004.12.1.77	partially ordered set;mathematical optimization;combinatorics;principle of orthogonal design;computer science;artificial intelligence;multi-objective optimization;machine learning;evolutionary algorithm;mathematics;uniform distribution;statistics	DB	29.485098607863527	1.5516744023613889	78063
617058896416bad870a02aafae9ea80a00fd9c02	improved accelerated pso algorithm for mechanical engineering optimization problems	diversity;meta heuristic;particle swarm optimization;engineering problems;memory	Flowchart of the improved accelerated particle swarm optimization. A new improved accelerated particle swarm optimization algorithm is proposed (IAPSO).Individual particles memories are incorporated in order to increase swarm diversity.Balance between exploration and exploitation is controlled through two selected functions.IAPSO outperforms several recent meta-heuristic algorithms, in terms of accuracy and convergence speed.New optimal solutions, for some benchmark engineering problems, are obtained. This paper introduces an improved accelerated particle swarm optimization algorithm (IAPSO) to solve constrained nonlinear optimization problems with various types of design variables. The main improvements of the original algorithm are the incorporation of the individual particles memories, in order to increase swarm diversity, and the introduction of two selected functions to control balance between exploration and exploitation, during search process. These modifications are used to update particles positions of the swarm. Performance of the proposed algorithm is illustrated through six benchmark mechanical engineering design optimization problems. Comparison of obtained computation results with those of several recent meta-heuristic algorithms shows the superiority of the IAPSO in terms of accuracy and convergence speed.	algorithm;mathematical optimization;particle swarm optimization	Najeh Ben Guedria	2016	Appl. Soft Comput.	10.1016/j.asoc.2015.10.048	mathematical optimization;multi-swarm optimization;meta-optimization;computer science;derivative-free optimization;artificial intelligence;memory;imperialist competitive algorithm;particle swarm optimization;algorithm;metaheuristic	DB	27.038443504352422	-3.9705983947993295	78202
68efbd54987f9720b108e91b6efcaa6256c55fd6	stochastic runtime analysis of the cross-entropy algorithm	analysis of randomized algorithms cross entropy algorithm 1 ant algorithm stochastic runtime analysis of evolutionary algorithms stochastic complexity;runtime algorithm design and analysis optimization stochastic processes complexity theory evolutionary computation mathematical model	"""This paper analyzes the stochastic runtime of the cross-entropy (CE) algorithm for the well-studied standard problems OneMax and LeadingOnes. We prove that the total number of solutions the algorithm needs to evaluate before reaching the optimal solution (i.e., its runtime) is bounded by a polynomial <inline-formula> <tex-math notation=""""LaTeX"""">${Q(n)}$ </tex-math></inline-formula> in the problem size <inline-formula> <tex-math notation=""""LaTeX"""">${n}$ </tex-math></inline-formula> with a probability growing exponentially to 1 with <inline-formula> <tex-math notation=""""LaTeX"""">${n}$ </tex-math></inline-formula> if the parameters of the algorithm are adapted to <inline-formula> <tex-math notation=""""LaTeX"""">${n}$ </tex-math></inline-formula> in a reasonable way. Our polynomial bound <inline-formula> <tex-math notation=""""LaTeX"""">${Q(n)}$ </tex-math></inline-formula> for OneMax outperforms the well-known runtime bound of the 1-ANT algorithm, a particular ant colony optimization algorithm. Our adaptation of the parameters of the CE algorithm balances the number of iterations needed and the size of the samples drawn in each iteration, resulting in an increased efficiency. For the LeadingOnes problem, we improve the runtime of the algorithm by bounding the sampling probabilities away from 0 and 1. The resulting runtime outperforms the known stochastic runtime for a univariate marginal distribution algorithm, and is very close to the known <italic>expected</italic> runtime of variants of max-min ant systems. Bounding the sampling probabilities allows the CE algorithm to explore the search space even for test functions with a very rugged landscape as the LeadingOnes function."""	algorithm;analysis of algorithms;ant colony optimization algorithms;cross entropy;distribution (mathematics);iteration;marginal model;mathematical optimization;maxima and minima;polynomial;rugged computer;sampling (signal processing);whole earth 'lectronic link	Zijun Wu;Michael Kolonko;Rolf H. M&#x00F6;hring	2017	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2017.2667713	mathematical optimization;probabilistic analysis of algorithms;computer science;theoretical computer science;stochastic optimization;machine learning	ML	29.01547149181622	2.387246887701309	78274
bd9065beee624fb5f26da3f64c4e9496dad3e690	performance degradation of genetic algorithms under coordinate rotation	genetic algorithm		elegant degradation;genetic algorithm	Ralf Salomon	1996			genetic algorithm;meta-optimization;rotation (mathematics);mathematical optimization;mathematics	Robotics	29.957588280862495	-4.716228021838309	78696
9fb99a8bfa9a647ff65f3e5d56aec6900a6ede42	cooling strategies for the moment-generating function in bayesian global optimization		Bayesian Global Optimization algorithm is designed to optimize expensive objective functions with small evaluation budget. This algorithm employs a surrogate model and assesses the potential improvement of unseen solutions through the so-called infill-criterion. A novel infill-criterion proposed in our previous work is derived from the moment-generating function of the improvement. In contrast to other techniques, it features a continuous parameter that can be used to adjust the exploration-exploitation tradeoff smoothly. In this work, two cooling strategies (linear and exponential) are adopted to enhance the explorative behavior in the early stage of the search and the exploitative effect in the final converging stage. Moreover, the initial temperature and cooling speed are investigated on some selected multi-modal functions, showing that the good setting of those two parameters depends on the problems specifics. The proposed Bayesian optimization with cooling strategy is tested on well-known BBOB benchmark. The results shows that without tuning the initial temperature and cooling speed, the proposed approach improves the performance on a range of multi-modal functions as compared to the commonly used expected improvement criterion.	algorithm;bayesian optimization;benchmark (computing);computer cooling;global optimization;mathematical optimization;modal logic;multi-core processor;optimization problem;program optimization;smoothing;surrogate model;time complexity	Hao Wang;Michael T. M. Emmerich;Thomas Bäck	2018	2018 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2018.8477956	global optimization;machine learning;bayesian optimization;mathematical optimization;artificial intelligence;computer science;gaussian process;moment-generating function;linear programming;bayesian probability;surrogate model;benchmark (computing)	Vision	29.125356787955845	-9.492032724161811	78910
e098657e366eb4a0e146eca6cfbc1afcb85aa582	dynamic search fireworks algorithm with covariance mutation for solving the cec 2015 learning based competition problems	silicon;swarm intelligence covariance matrices gaussian distribution learning artificial intelligence optimisation search problems;covariance matrices;heuristic algorithms;afwa dynamic search fireworks algorithm covariance mutation cec 2015 learning based competition problems revolutionary swarm intelligence algorithm optimization problems dynamic fireworks algorithm with covariance mutation dynfwacm covariance matrix mean value gaussian distribution learning based real parameter single objective optimization;sparks;explosions;optimization;algorithm design and analysis;sparks explosions covariance matrices heuristic algorithms optimization silicon algorithm design and analysis	As a revolutionary swarm intelligence algorithm, fireworks algorithm (FWA) is designed to solve optimization problems. In this paper, the dynamic fireworks algorithm with covariance mutation (dynFWACM) is proposed. After applying the explosion operator, the mutation operator is introduced, which calculates the mean value and covariance matrix of the better sparks and produces sparks according with Gaussian distribution. DynFWACM is compared with the most advanced fireworks algorithms to proof its effectiveness. In addition, 15 functions of CEC 2015 competition on learning based real-parameter single objective optimization are used to test the performance of our new proposed algorithm. The experimental results show that dynFWACM outperforms both AFWA and dynFWA, as well as the experimental results of the 15 functions given.	fireworks algorithm;list of minor characters in the matrix series;mathematical optimization;swarm intelligence	Chao Yu;Lingchen Kelley;Ying Tan	2015	2015 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2015.7257013	algorithm design;mathematical optimization;simulation;cma-es;computer science;machine learning;mathematics;silicon;algorithm	AI	27.90119894121928	-4.93925108886948	79030
95e750500d9911ce7f383671b67db175357ee444	global optimization of parameters in the reactive force field reaxff for sioh	force field fitting;reactive force fields;evolutionary algorithms;genetic algorithms;global optimization	We have used unbiased global optimization to fit a reactive force field to a given set of reference data. Specifically, we have employed genetic algorithms (GA) to fit ReaxFF to SiOH data, using an in-house GA code that is parallelized across reference data items via the message-passing interface (MPI). Details of GA tuning turn-ed out to be far less important for global optimization efficiency than using suitable ranges within which the parameters are varied. To establish these ranges, either prior knowledge can be used or successive stages of GA optimizations, each building upon the best parameter vectors and ranges found in the previous stage. We have finally arrive-ed at optimized force fields with smaller error measures than those published previously. Hence, this optimization approach will contribute to converting force-field fitting from a specialist task to an everyday commodity, even for the more difficult case of reactive force fields.	force field (chemistry);genetic algorithm;global optimization;interface device component;mathematical optimization;message passing interface;parallel computing;population parameter;reaxff;scientific publication;small;software release life cycle	Henrik R. Larsson;Adri C. T. van Duin;Bernd Hartke	2013	Journal of computational chemistry	10.1002/jcc.23382	mathematical optimization;genetic algorithm;computational chemistry;global optimization	Visualization	31.241328875933302	-7.7587913652677045	79208
de43dd34afc9724b6fce84c231067f41e3730b74	weighted superposition attraction (wsa): a swarm intelligence algorithm for optimization problems - part 2: constrained optimization	constrained global optimization;swarm intelligence;non linear programming;meta heuristics;design optimization;constraint handling;global optimization;wsa algorithm	This paper is the second one of the two papers entitled “Weighted Superposition Attraction (WSA) Algorithm”, which is about the performance evaluation of the WSA algorithm in solving the constrained global optimization problems. For this purpose, the well-known mechanical design optimization problems, design of a tension/compression coil spring, design of a pressure vessel, design of a welded beam and design of a speed reducer, are selected as test problems. Since all these problems were formulated as constrained global optimization problems, WSA algorithm requires a constraint handling method for tackling them. For this purpose we have selected 6 formerly developed constraint handling methods for adapting into WSA algorithm and analyze the effect of the used constraint handling method on the performance of the WSA algorithm. In other words, we have the aim of producing concluding remarks over the performance and robustness of the WSA algorithm through a set of computational study in solving the constrained global optimization problems. Computational study indicates the robustness and the effectiveness of the WSA in terms of obtained results, reached level of convergence and the capability of coping with the problems of premature convergence, trapping in a local optima and stagnation. © 2015 Elsevier B.V. All rights reserved.	algorithm;computation;constrained optimization;global optimization;local optimum;mathematical optimization;performance evaluation;premature convergence;swarm intelligence;whole earth 'lectronic link;winsock	Adil Baykasoglu;Sener Akpinar	2015	Appl. Soft Comput.	10.1016/j.asoc.2015.08.052	mathematical optimization;combinatorics;multidisciplinary design optimization;swarm intelligence;computer science;machine learning;mathematics;algorithm;global optimization	AI	25.54839808181725	-3.248673107583307	79261
063d2b43b06fcad569629adac14f8d668a84989f	a brief introduction to optimization via simulation	ovs problem;discrete ovs problem;brief introduction;continuous ovs problem;current research development;commercial ovs software;approximation algorithms;bayesian methods;switches;optimization;computational modeling	Optimization via simulation (OvS) is an exciting and fast developing area for both research and practice. In this article, we introduce three types of OvS problems: the R&S problems, the continuous OvS problems and the discrete OvS problems, and discuss the issues and current research development for these problems. We also give some suggestions on how to use commercial OvS software in practice.	mathematical optimization;program optimization;simulation	L. Jeff Hong;Barry L. Nelson	2009	Proceedings of the 2009 Winter Simulation Conference (WSC)		computational science;simulation;network switch;bayesian probability;computer science;theoretical computer science;computational model;approximation algorithm	EDA	30.396383477291163	2.024238357334407	79266
a7121630c53b6cd44bcc975c293e9bca065498db	differential evolution with local information for neuro-fuzzy systems optimisation	neuro fuzzy systems optimisation;optimisation;evolutionary algorithm ea;differential evolution de;neuro fuzzy systems nfss;article	This paper proposes a differential evolution with local information (DELI) algorithm for Takagi–Sugeno– Kang-type (TSK-type) neuro-fuzzy systems (NFSs) optimisation. The DELI algorithm uses a modified mutation operation that considers a neighbourhood relationship for each individual to maintain the diversity of the population and to increase the search capability. This paper also proposes an adaptive fuzzy c-means method for determining the number of rules and for identifying suitable initial parameters for the rules. Initially, there are no rules in the NFS model; the rules are automatically generated by the fuzzy measure and the fuzzy c-means method. Until the firing strengths of all of the training patterns satisfy a pre-specified threshold, the process of rule generation is terminated. Subsequently, the DELI algorithm optimises all of the free parameters for NFSs design. To enhance the performance of the DELI algorithm, an adaptive parameter tuning based on the 1/5th rule is used for the tuning scale factor F. The 1/5th rule dynamically adjusts the tuning scale factor in each period to enhance the search capability of the DELI algorithm. Finally, the proposed NFS with DELI model (NFS-DELI) is applied to nonlinear control and prediction problems. The results of this paper demonstrate the effectiveness of the proposed NFS-DELI model. Crown Copyright 2013 Published by Elsevier B.V. All rights reserved.	algorithm;crown group;differential evolution;fuzzy control system;fuzzy measure theory;mathematical optimization;neuro-fuzzy;nonlinear system	Ming-Feng Han;Chin-Teng Lin;Jyh-Yeong Chang	2013	Knowl.-Based Syst.	10.1016/j.knosys.2013.01.023	artificial intelligence;machine learning	AI	25.571640653922447	-6.842923793518033	79277
0ac311e5a0e81e63f76f3125c6b24eab143aedf9	on the landscape of combinatorial optimization problems	optimization color correlation hamming distance search problems algorithm design and analysis;color;travelling salesman problems computability graph colouring principal component analysis probability quadratic programming;combinatorial optimization problems maximum satisfiability problem principle component analysis probability local optima properties local average properties quadratic assignment traveling salesman problem graph coloring max sat problem fitness landscape;hamming distance;cities and towns;optimization;search problems;correlation;algorithm design and analysis;long range correlation combinatorial optimisation problems graph colouring problem travelling salesman problem maximum satisfiability problem quadratic assignment problem fitness landscape scaling analysis	This paper carries out a comparison of the fitness landscape for four classic optimization problems: Max-Sat, graph-coloring, traveling salesman, and quadratic assignment. We have focused on two types of properties, local average properties of the landscape, and properties of the local optima. For the local optima we give a fairly comprehensive description of the properties, including the expected time to reach a local optimum, the number of local optima at different cost levels, the distance between optima, and the expected probability of reaching the optima. Principle component analysis is used to understand the correlations between the local optima. Most of the properties that we examine have not been studied previously, particularly those concerned with properties of the local optima. We compare and contrast the behavior of the four different problems. Although the problems are very different at the low level, many of the long-range properties exhibit a remarkable degree of similarity.	average-case complexity;combinatorial optimization;graph coloring;local optimum;mathematical optimization;maximum satisfiability problem;optimization problem;principal component analysis	Mohammad-Hassan Tayarani-Najaran;Adam Prügel-Bennett	2014	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2013.2281502	optimization problem;algorithm design;mathematical optimization;combinatorics;discrete mathematics;hamming distance;cross-entropy method;computer science;mathematics;correlation;algorithm;3-opt;bottleneck traveling salesman problem;quadratic assignment problem	ML	27.669410714520787	3.319183117587728	79624
f4aad49612c753f592ea3cb3c2c3f5d89d50aa54	simulated annealing with adaptive neighborhood: a case study in off-line robot path planning	cost function;optimization technique;path planning;simulated annealing;boundary condition;probability distribution;optimization;spline interpolation	Simulated annealing (SA) is an optimization technique that can process cost functions with degrees of nonlinearities, discontinuities and stochasticity. It can process arbitrary boundary conditions and constraints imposed on these cost functions. The SA technique is applied to the problem of robot path planning. Three situations are considered here: the path is represented as a polyline; as a Bezier curve; and as a spline interpolated curve. In the proposed SA algorithm, the sensitivity of each continuous parameter is evaluated at each iteration increasing the number of accepted solutions. The sensitivity of each parameter is associated to its probability distribution in the definition of the next candidate.	motion planning;online and offline;robot;simulated annealing	Renato Seiji Tavares;Thiago de Castro Martins;Marcos de Sales Guerra Tsuzuki	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.08.084	spline interpolation;probability distribution;mathematical optimization;combinatorics;simulated annealing;boundary value problem;computer science;machine learning;mathematics;motion planning;adaptive simulated annealing	Robotics	34.13290199182355	-1.0337688834525676	79626
63dbec720aa1d52c5ddf6c683d0a2ed1fbb60192	solution clustering analysis in brain storm optimization algorithm	swarm intelligence convergence particle swarm optimisation pattern clustering search problems;pattern clustering;swarm intelligence;convergence;search problems;exploration exploitation swarm intelligence brain storm optimization population diversity solution clustering convergence;search space solution clustering analysis brain storm optimization algorithm swarm intelligence algorithms premature convergence clustering strategy bso solution distribution;particle swarm optimisation;clustering algorithms optimization storms particle swarm optimization sociology statistics convergence	In swarm intelligence algorithms, premature convergence happens partially due to the solutions getting clustered together, and not diverging again. However, solution clustering is not always harmful for optimization. The solution clustering strategy is utilized in brain storm optimization (BSO) to guide individuals to move toward the better and better areas. The information of clusters indicates the solutions' distribution in the search space, which could be utilized to reveal the landscapes and other proprieties of problems being optimized. In this paper, the solution clustering, and other properties of the brain storm optimization algorithm are analyzed and discussed. Experimental results show that brain storm optimization is a very promising algorithm for solving different kinds of problems.	algorithm;cluster analysis;curse of dimensionality;local optimum;mathematical optimization;premature convergence;swarm intelligence	Shi Cheng;Yuhui Shi;Quande Qin;Shujing Gao	2013	2013 IEEE Symposium on Swarm Intelligence (SIS)	10.1109/SIS.2013.6615167	correlation clustering;mathematical optimization;multi-swarm optimization;geography;swarm intelligence;derivative-free optimization;artificial intelligence;machine learning;cure data clustering algorithm;particle swarm optimization;metaheuristic	AI	27.966550977587847	-5.712143563476976	79865
dc18ed580a937cfa30124570c173d8c19bf3bb91	stability analysis of particle dynamics in gravitational search optimization algorithm	convergence;gravitational search algorithm;lyapunov stability analysis;optimization	In this paper, particle dynamics and stability analysis of gravitational search algorithm (GSA) are investigated. The GSA is a swarm optimization algorithm which is inspired by the Newtonian laws of gravity and motion. Previously, the convergence analysis of the GSA and improved GSA algorithms were presented to demonstrate each particle converges. In this study, the stability of the particle dynamics using Lyapunov stability theorem and the system dynamics concept is analyzed. Sufficient conditions of stability analysis are investigated and utilized for adapting parameters of the GSA. The modified algorithm based on stability analysis is compared with the standard GSA, PSO, RGA, and two methods of improved GSA in terms of average, median, and standard deviation of best-so-far solutions. Simulation results demonstrate the validity and feasibility of the proposed modified GSA. In solving the optimization problem of various nonlinear functions, the high performance is achieved.	algorithm;mathematical optimization	Faezeh Farivar;Mahdi Aliyari Shoorehdeli	2016	Inf. Sci.	10.1016/j.ins.2015.12.017	mathematical optimization;convergence;computer science;calculus;control theory;mathematics	Theory	29.161738578930972	-4.809094375404528	80483
7212860f20d3d96e918fe46922676cf00fbf8b9f	adaptively evolving probabilities of genetic operators	rate of convergence;differential evolution;genetic program;genetic operator;evolutionary computation;evolved evolutionary algorithm;probability;gene expression programming genetic operator probability adaptive method evolved evolutionary algorithm supplementary mutation operator numerical optimization model differential evolution;numerical optimization model;numerical optimization;genetics;mathematical operators;evolution biology;biological cells;adaptive method;genetic algorithm;genetic algorithms;optimization;genetic mutations genetic programming biological cells evolutionary computation numerical models artificial intelligence laboratories process control counting circuits machine learning;gene expression programming;evolutionary algorithm;evolutionary process;genetic parameter;genetic operator probability;supplementary mutation operator;probability genetic algorithms mathematical operators;gallium	This work is concerned with proposing an adaptive method to dynamically adjust genetic operator probabilities throughout the evolutionary process. The proposed method relies on the individual preferences of each chromosome, rather than the global behavior of the whole population. Hence, each individual carries its own set of parameters, including the probabilities of the genetic operators. The carried parameters undergo the same evolutionary process as the carriers--the chromosomes - do. We call this method Evolved Evolutionary Algorithm (E2A) as it has an additional evolutionary process to evolve control parameters. Furthermore, E2A employs a supplementary mutation operator (DE-mutation) which utilizes the previously overlooked numerical optimization model known as the Differential Evolution to expedite the optimization rate of the genetic parameters. To leverage our previous work, we used Gene Expression Programming (GEP) as a benchmark to determine the performance of our proposed method. Nevertheless, E2A can be easily extended to other genetic programming variants. As the experimental results on a wide array of regression problems demonstrate, the E2A method reveals a faster rate of convergence and provides fitter ultimate solutions. However, to further expose the power of the E2A method, we compared it to related methods using self-adaptation previously applied to Genetic Algorithms. Our benchmarking on the same set of regression problems proves the supremacy of our proposed method both in the accuracy and simplicity of the final solutions.	benchmark (computing);differential evolution;evolutionary algorithm;gene expression programming;genetic algorithm;genetic operator;genetic programming;mathematical optimization;numerical analysis;rate of convergence;supremacy: your will be done	Fatemeh Vafaee;Weimin Xiao;Peter C. Nelson;Chi Zhou	2008	2008 Seventh International Conference on Machine Learning and Applications	10.1109/ICMLA.2008.45	evolutionary programming;mathematical optimization;genetic algorithm;computer science;bioinformatics;artificial intelligence;genetic operator;machine learning;evolutionary algorithm;genetic representation;mathematics;gene expression programming;evolutionary computation	Robotics	27.51162841394016	-6.006483671988351	80547
5dda2d2e80c7fa196067f50014242643ec42fc59	exploiting linkage information in real-valued optimization with the real-valued gene-pool optimal mixing evolutionary algorithm		The recently introduced Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA) has been shown to be among the state-of-the-art for solving discrete optimization problems. Key to the success of GOMEA is its ability to efficiently exploit the linkage structure of a problem. Here, we introduce the Real-Valued GOMEA (RV-GOMEA), which incorporates several aspects of the real-valued EDA known as AMaLGaM into GOMEA in order to make GOMEA well-suited for real-valued optimization. The key strength of GOMEA to competently exploit linkage structure is effectively preserved in RV-GOMEA, enabling excellent performance on problems that exhibit a linkage structure that is to some degree decomposable. Moreover, the main variation operator of GOMEA enables substantial improvements in performance if the problem allows for partial evaluations, which may be very well possible in many real-world applications. Comparisons of performance with state-of-the-art algorithms such as CMA-ES and AMaLGaM on a set of well-known benchmark problems show that RV-GOMEA achieves comparable, excellent scalability in case of black-box optimization. Moreover, RV-GOMEA achieves unprecedented scalability on problems that allow for partial evaluations, reaching near-optimal solutions for problems with up to millions of real-valued variables within one hour on a normal desktop computer.	benchmark (computing);black bag operation;black box;cma-es;computation;computational complexity theory;desktop computer;discrete optimization;evolutionary algorithm;experiment;gene expression programming;gene pool;linkage (software);mathematical optimization;open road tolling;rota vector;scalability;time complexity	Anton Bouter;Tanja Alderliesten;Cees Witteveen;Peter A. N. Bosman	2017		10.1145/3071178.3071272	operator (computer programming);mathematical optimization;artificial intelligence;computer science;machine learning;gene pool;discrete optimization;scalability;evolutionary algorithm;exploit	ML	25.18422132358901	-0.9966455413032846	80648
9d517649b2c3e3391386f178990eae4ea37d8a55	escaping local optima: constraint weights vs. value penalties	conference publications;constraint weights;penalty based algorithm;constraint satisfaction problems;iterative improvement techniques;constraint satisfaction problem;constraint violation;local optima	Constraint Satisfaction Problems can be solved using either iterative improvement or constructive search approaches. Iterative improvement techniques converge quicker than the constructive search techniques on large problems, but they have a propensity to converge to local optima. Therefore, a key research topic on iterative improvement search is the development of effective techniques for escaping local optima, most of which are based on increasing the weights attached to violated constraints. An alternative approach is to attach penalties to the individual variable values participating in a constraint violation. We compare both approaches and show that the penalty-based technique has a more dramatic effect on the cost landscape, leading to a higher ability to escape local optima. We present an improved version of an existing penalty-based algorithm where penalty resets are driven by the amount of distortion to the cost landscape caused by penalties. We compare this algorithm with an algorithm based on constraint weights and justify the difference in their performance.	algorithm;breakout box;constraint satisfaction problem;converge;deadlock;distortion;iterative method;local optimum;local search (optimization);qualitative comparative analysis;reset button	Muhammed Basharu;Inés Arana;Hatem Ahriz	2007		10.1007/978-1-84800-094-0_5	mathematical optimization;combinatorics;binary constraint;constraint satisfaction;constraint learning;constraint satisfaction dual problem;mathematics;mathematical economics;constraint;constraint satisfaction problem;hybrid algorithm;local consistency;backtracking	AI	28.29940782873174	-1.055879203128409	80736
e556034ba9c4411202a4b7ff7be01e29bbca60ef	double-swarm binary particle swarm optimization		The Binary Particle Swarm Optimization (BPSO) is the most popular swarm-based algorithm to tackle binary optimization problems. Based on the high performance of the BPSO, many proposals have been developed presenting modifications in the standard method. However, in the last decade, the Binary Cat Swarm Optimization (BCSO) has gained attention. In this paper, we introduce a new algorithm called Double-Swarm BPSO, which presents some modifications on the BPSO inspired in the BCSO optimization process. In this case, we propose to divide the agents into two sub-swarms. The experiments showed that the proposal overcomes the previous popular swarm-based methods and binary versions of the Genetic Algorithm in some instances of the 0/1 knapsack problem, especially in high dimension cases.	chief security officer;continuous optimization;experiment;flying-spot scanner;genetic algorithm;knapsack problem;mathematical optimization;particle swarm optimization;software release life cycle	Hugo Siqueira;Elliackin M. N. Figueiredo;Mariana Macedo;Clodomir J. Santana;Pedro Santos;Carmelo J. A. Bastos Filho;Anu A. Gokhale	2018	2018 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2018.8477937	mathematical optimization;artificial intelligence;swarm behaviour;genetic algorithm;machine learning;computer science;knapsack problem;binary number;particle swarm optimization;optimization problem	Vision	25.7446134795217	-2.654360371619152	80821
780d619781a1582964baf33229f44ba4a635e4c2	apdde: self-adaptive parameter dynamics differential evolution algorithm		In real-time high-dimensional optimization problem, how to quickly find the optimal solution and give a timely response or decisive adjustment is very important. This paper suggests a self-adaptive differential evolution algorithm (abbreviation for APDDE), which introduces the corresponding detecting values (the values near the current parameter) for individual iteration during the differential evolution. Then, integrating the detecting values into two mutation strategies to produce offspring population and the corresponding parameter values of champion are retained. In addition, the whole populations are divided into a predefined number of groups. The individuals of each group are attracted by the best vector of their own group and implemented a new mutation strategy DE/Current-to-lbest/1 to keep balance of exploitation and exploration capabilities during the differential evolution. The proposed variant, APDDE, is examined on several widely used benchmark functions in the CEC 2015 Competition on Learning-based Real-Parameter Single Objective Optimization (13 global numerical optimization problems) and 7 well-known basic benchmark functions, and the experimental results show that the proposed APDDE algorithm improves the existing performance of other algorithms when dealing with the high-dimensional and multimodal problems.	algorithm;differential evolution	Hong-Bo Wang;Xue-Na Ren;Guoqiang Li;Xu-Yan Tu	2018	Soft Comput.	10.1007/s00500-016-2418-1	machine learning;differential evolution;mathematical optimization;computer science;meta-optimization;algorithm;artificial intelligence;population;new mutation;optimization problem	Vision	26.56884063812761	-4.2712655533551045	80950
cac04608fc544c83df0d06cb369924ed9ed19f27	an evolutionary optimization approach to cost-based abduction, with comparison to pso	evolutionary computation;cost based abduction;inference mechanisms;uncertainty handling;pso;uncertainty handling evolutionary optimization cost based abduction pso least cost proof particle swarm optimization;least cost proof;particle swarm optimization;evolutionary algorithm;evolutionary optimization;particle swarm optimisation;uncertainty handling evolutionary computation inference mechanisms particle swarm optimisation;costs linear programming polynomials integrated circuit modeling computer science logic programming neural networks evolutionary computation uncertainty genetic algorithms	Abduction is the process of proceeding from data describing a set of observations or events, to a set of hypotheses which best explains or accounts for the data. Cost-based abduction (CBA) is a formalism in which evidence to be explained is treated as a goal to be proven, proofs have costs based on how much needs to be assumed to complete the proof, and the set of assumptions needed to complete the least-cost proof are taken as the best explanation for the given evidence. In this paper, we apply an evolutionary algorithm (EA) to the problem of finding least-cost proofs in cost-based abduction systems, comparing performance to PSO using a difficult problem instance.	abductive reasoning;evolutionary algorithm;particle swarm optimization;phase-shift oscillator;semantics (computer science)	Shawn T. Chivers;Gene A. Tagliarini;Ashraf M. Abdelbar	2007	2007 International Joint Conference on Neural Networks	10.1109/IJCNN.2007.4371425	evolutionary programming;mathematical optimization;multi-swarm optimization;interactive evolutionary computation;human-based evolutionary computation;computer science;machine learning;evolutionary algorithm;mathematics;imperialist competitive algorithm;particle swarm optimization;algorithm;evolutionary computation	AI	27.815010650548633	-9.048377465951104	81463
320e3ac3dc2543d1ae136c3685e168dd7320c267	a statistical study of the differential evolution based on continuous generation model	function optimization problem;reproduction selection method;optimisation;differential evolution;evolutionary computation;pediatrics;generic model;probability density function;continuous generation model;population size;data mining;discrete generation model;analysis of variance pediatrics evolutionary computation genetic mutations learning systems robustness design methodology constraint optimization design optimization character generation;function optimization;survival selection method;statistical analysis;ieee;statistical analysis evolutionary computation optimisation;statistical analysis differentiation evolutionary algorithm function optimization problem continuous generation model discrete generation model survival selection method reproduction selection method population size;analysis of variance;optimization;evolutionary algorithm;benchmark testing;differentiation evolutionary algorithm	Differentiation Evolution (DE) is an Evolutionary Algorithm (EA) for solving function optimization problems. In order to renew the population in EA, there are two generation models. The first one is “discrete generation model”, and the second one is “continuous generation model”. Conventional DEs have been based on the discrete generation model in which the current generation's population is replaced by the next generation's population at a time. In this paper, a novel DE based on the continuous generation model is described. Because a newborn excellent individual is added to an only population and can be used immediately to generate offspring in the continuous generation model, it can be expected that the novel DE converges faster than the conventional ones. Furthermore, by employing the continuous generation model, it becomes easy to introduce various survival selection methods into DE. Therefore, three survival selection methods are contrived for the novel DE based on the continuous generation model. Finally, the effects of the generation model, the survival selection method, the reproduction selection method, the population size and their interactions on the performance of DE are evaluated statistically by using the analysis of variance (ANOVA).	differential evolution;evolutionary algorithm;interaction;mathematical optimization;population	Kiyoharu Tagawa	2009	2009 IEEE Congress on Evolutionary Computation	10.1109/CEC.2009.4983270	differential evolution;benchmark;mathematical optimization;probability density function;population size;analysis of variance;computer science;artificial intelligence;machine learning;evolutionary algorithm;statistics;evolutionary computation	SE	27.611363639455423	-7.3163854274899975	81474
aa7d2b7d2899ecc4f094436b1104baaa8130b6b9	bacterial foraging algorithm-based optimisation for controlling conditioner temperature of a ring die granulator	bacterial foraging algorithm;ring die granulator;bfa;svm;prediction model;support vector machine;bio inspired optimisation	Support vector regression (SVR) is firmly grounded in the framework of statistical learning theory that has been deployed to solve many engineering problems in recent years. To optimise its parameters and achieve optimised results, this paper deploys a novel bacterial foraging algorithm (BFA), combining with support vector machine (SVM) to achieve the good condition temperature prediction of a ring die granulator. With a strong globally searching capability, the proposed method can achieve dynamic optimisation of systematic parameters and overcome the problem of inefficiency in selecting optimal parameters. Simulation results show that the proposed bacterial foraging algorithm is effective in parameter optimisation of the controller for a ring die granulator.	algorithm;mathematical optimization	Kun Zhang;Peijian Zhang;Jianguo Wu;Hossein Farid Ghassem Nia;Huiyu Zhou	2014	IJMIC	10.1504/IJMIC.2014.066267	control engineering;support vector machine;simulation;computer science;engineering;machine learning	Vision	35.45995279022672	-5.903447556712146	81496
7b863b7bb2c311592bd941b1e51dfcffcbf646d1	a selective teaching-learning based niching technique with local diversification strategy	local neighbourhood;swarm-based niching technique;selective teaching-learning;local site;optimal solution;local diversification strategy;learning strategy;controlled exploitation;population diversity;niching parameter;tlb-lds algorithm	local neighbourhood;swarm-based niching technique;selective teaching-learning;local site;optimal solution;local diversification strategy;learning strategy;controlled exploitation;population diversity;niching parameter;tlb-lds algorithm	diversification (finance)	Souvik Kundu;Subhodip Biswas;Swagatam Das;Digbalay Bose	2012		10.1007/978-3-642-35380-2_20	mathematical optimization;artificial intelligence;machine learning	EDA	26.100033304064176	-4.121148704830039	81539
d9af2d057e95cc6d5fb42235a9396ada61510443	estimation multivariate normal algorithm with thresheld convergence	convergence;estimation;covariance matrices;aerospace electronics;next generation networking;sociology	Estimation of Distribution Algorithms (EDAs) use a subset of solutions from the current population to build a distribution function from which the next generation of solutions is created. If there is poor diversity in the current population, then there is poor diversity in the subset of solutions selected from it and in the next generation that is created from it. Like many metaheuristics, EDAs can suffer from an autocatalytic process in which convergence begets more convergence. In Thresheld Convergence, convergence is “held” back by a threshold function, and this new technique has been successfully applied to other metaheuristics to prevent autocatalytic convergence from cascading into premature convergence. In this paper, Thresheld Convergence is applied to Estimation Multivariate Normal Algorithm with a key difference: convergence is controlled in the parameter space instead of the search space. Computational results show that significant improvements can be achieved across a broad range of multimodal functions.	computation;estimation of distribution algorithm;metaheuristic;multimodal interaction;next-generation network;premature convergence	Dania Tamayo-Vera;Antonio Bolufé Röhler;Stephen Chen	2016	2016 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2016.7744223	econometrics;mathematical optimization;estimation;convergence;computer science;artificial intelligence;compact convergence;machine learning;mathematics;statistics	Vision	28.431662801185475	-7.83693402273381	81582
5d5ee5e10e88fc61ce0150d87586cb1a5361f448	intelligent selection of parents for mutation in differential evolution		In most DE algorithms, the parents for mutation are randomly selected from the current population, which will mean that all vectors involved in mutation are equally selected as parents without any selection pressure. Although such a mutation strategy is easy to use, it is inefficient for solving complex problems. To address this issue, we present an intelligent parents selection strategy (IPS) for DE. The new algorithmic framework is named as DE with IPS-based mutation (IPSDE). In IPSDE, the neighbourhood of each individual is firstly constructed with a population topology. Then, all the neighbours of each individual are partitioned into two groups based on their fitness values and a probability value for each neighbour is selected as the parents in the respective groups are calculated based on its distance from the current individual. With the probability values, IPS selects the parents from the neighbourhood of the current individual to guide the mutation process of DE. To evaluate the effectiveness of ...	differential evolution	Meng Zhao;Yiqiao Cai	2018	IJCSE	10.1504/IJCSE.2016.10002299	machine learning;theoretical computer science;artificial intelligence;differential evolution;neighbourhood (mathematics);computer science;population;mutation	NLP	27.416915098628046	-3.370216599223853	82198
7eaf335cf5095f22230fda571256f212a920a0aa	advanced markovian wind energy models for smart grid applications	wind power plants markov processes offshore installations smart power grids;wind power plants;smart power grids;power system simulation smart grids wind energy generation markov processes energy resources;data models wind speed computational modeling analytical models wind energy time series analysis;offshore installations;markov processes;smart grid analysis advanced markovian wind energy models smart grid applications markov chains wind energy resource models power system analysis markovian wind models wind speed power output nested markov chains higher frequency variations offshore wind data sets onshore wind data sets	Markov Chains are widely used for developing wind energy resource models for power system analysis applications. However, the Markovian wind models currently available in the literature cannot capture the temporal variations in wind speed/power output over time periods shorter than 1 hour. This means that they are unsuitable for smart grid applications, which typically require simulations with short time steps, e.g. to the order of minutes or seconds. This paper introduces a novel approach to modelling wind energy resources using “Nested Markov Chains”. It is shown in the paper that this method can accurately capture higher-frequency variations in the wind energy resource. The methodology is demonstrated using recorded onshore and offshore wind data sets. The resulting model can be readily applied for smart grid analysis, allowing the user to replace large historical wind data sets with a simple and efficient analytical model.	markov chain;simulation;system analysis	Barry Hayes;Sasa Z. Djokic	2013	IEEE PES ISGT Europe 2013	10.1109/ISGTEurope.2013.6695377	electronic engineering;simulation;engineering;operations management;smart grid	Metrics	35.998189167255106	-2.794372930797431	82365
59f8205186dd08c87c99151e0f2b47dd21760c9a	the optimal multi-objective optimization using pso in blind color image fusion	particle swarm optimisation image colour analysis image fusion;swarm intelligence;pareto optimisation;yuv color space;blind color image fusion;color space;image fusion;multi objective optimization;optimal multiobjective optimization;pso;uniform design;color particle swarm optimization algorithm design and analysis convergence image fusion birds genetic mutations sorting evolutionary computation educational institutions;pareto optimisation optimal multiobjective optimization pso blind color image fusion particle swarm optimization epsiv dominance yuv color space;particle swarm optimizer;social behavior;image colour analysis;particle swarm optimization;mutual information;particle swarm optimisation;pareto optimality;color image;epsiv dominance	The particle swarm optimization (PSO) is a new swarm intelligence technique inspired by social behavior of bird flocking. In this paper, the optimal multi-objective optimization based on PSO (OMOPSO) is presented. Since the parameters determines the performance of the algorithm, the uniform design is introduced to obtain the optimal combination of the parameters. Additionally, a new crowding operator is used to improve the distribution of nondominated solutions, and epsiv-dominance is used to fix the size of the set of final solutions. OMOPSO is also applied to optimize the indices of blind color image fusion. First the model of blind color image fusion in YUV color space is established, and then the proper evaluation indices without the reference image are given, in which a new indices of conditional mutual information is proposed. Experimental results indicate that OMOPSO has better exploratory capabilities, and that the approach to blind color image fusion realizes the Pareto optimal blind color image fusion.	algorithm;color image;color space;conditional mutual information;crowding;existential quantification;flocking (behavior);image fusion;mathematical optimization;multi-objective optimization;pareto efficiency;particle swarm optimization;performance;swarm intelligence	Yifeng Niu;Lincheng Shen	2007	2007 International Conference on Multimedia and Ubiquitous Engineering (MUE'07)	10.1109/MUE.2007.204	mathematical optimization;color image;social behavior;swarm intelligence;computer science;artificial intelligence;multi-objective optimization;machine learning;mutual information;color space;image fusion;particle swarm optimization	Robotics	29.809540454386298	-5.588230610124037	82420
df5d01ab93539e0bf508d021a84a671eb197d9f4	different local search algorithms in stage for solving bin packing problem	surface structure;bin packing problem;optimal solution;evaluation function;solution optimale;algoritmo busqueda;methode plus grande pente;local search algorithm;probleme np complet;algorithme recherche;reinforcement learning;estructura superficie;search algorithm;steepest descent method;combinatorial optimization problem;problema relleno;costo;optimisation combinatoire;solucion optima;metodo mas grande inclinacion;probleme remplissage;structure surface;problema np completo;hill climbing;combinatorial optimization;local minima;local search;recherche locale;np complete problem;steepest descent;optimizacion combinatoria;cout	Previous researches have shown the success of using Reinforcement Learning in solving combinatorial optimization problems. The main idea of these methods is to learn (near) optimal evaluation functions to improve local searches and find (near) optimal solutions. STAGE algorithm, introduced by Boyan & Moore, is one of the most important algorithms in this area. In this paper, we focus on Bin-Packing problem, an important NP-Complete problem. We analyze cost surface structure of this problem and investigate “big valley” structure for the set of its local minima. The result gives reasons for STAGE’s success in solving this problem. Then by comparing the results of experiments on Bin-Packing problem, we analyze the effectiveness of steepest-descent hill climbing, stochastic hill climbing and first-improvement hill climbing as the local search algorithms in STAGE.	bin packing problem;boyer–moore string search algorithm;combinatorial optimization;complete (complexity);evaluation function;experiment;gradient descent;local search (optimization);mathematical optimization;maxima and minima;multilayer perceptron;np-completeness;polynomial;reinforcement learning;set packing;stochastic hill climbing	Saeed Bagheri Shouraki;Gholamreza Haffari	2002		10.1007/3-540-36087-5_12	mathematical optimization;combinatorics;combinatorial optimization;computer science;local search;hill climbing;iterated local search;mathematics;reinforcement learning;algorithm	AI	26.08600285221762	2.2755346306577655	82723
40acca93e076df9249f1f75f4c4c12d79a61322a	efficient hybrid grid synthesis method based on genetic algorithm for power/ground network optimization with dynamic signal consideration	tecnologia electronica telecomunicaciones;g network;distributed networks;ground p;power ground p g network;gene disturbance;genetics;global area optimization;random walk;dynamic signal simulation;network optimization;linear transformation;genetic algorithm;global optimization;tecnologias;grupo a;power;trapezoidal modified euler tme;power distribution network;hybrid slp;genetic algorithm ga	This paper proposes an efficient design algorithm for power/ground (P/G) network synthesis with dynamic signal consideration, which is mainly caused by Ldi/dt noise and Cdv/dt decoupling capacitance (DECAP) current in the distribution network. To deal with the nonlinear global optimization under synthesis constraints directly, the genetic algorithm (GA) is introduced. The proposed GA-based synthesis method can avoid the linear transformation loss and the restraint condition complexity in current SLP, SQP, ICG, and random-walk methods. In the proposed Hybrid Grid Synthesis algorithm, the dynamic signal is simulated in the gene disturbance process, and Trapezoidal Modified Euler (TME) method is introduced to realize the precise dynamic time step process. We also use a hybrid-SLP method to reduce the genetic execute time and increase the network synthesis efficiency. Experimental results on given power distribution network show the reduction on layout area and execution time compared with current P/G network synthesis methods.	genetic algorithm	Yun Yang;Shinji Kimura	2008	IEICE Transactions	10.1093/ietfec/e91-a.12.3431	g-network;mathematical optimization;genetic algorithm;telecommunications;electrical engineering;power;control theory;mathematics;linear map;random walk;algorithm;statistics;global optimization	EDA	33.612360523262566	-5.044283463112331	82783
4e689cc7d618841d5af71968b19aebb1c355ee8c	on evolutionary strategy based on hybrid crossover operators	crossover operators evolutionary strategy mixed crossover;evolutionary computation;two point crossover evolutionary strategy hybrid crossover operators mixed crossover strategy uniform crossover arithmetic crossover;mathematical operators evolutionary computation;mathematical operators;encoding optimization hybrid power systems educational institutions genetic algorithms biological cells programming;evolutionary strategy	Crossover operators play an important role in evolutionary strategy. Several different crossover operators have been developed in the past decades. However, each crossover operator is only efficient in some type of problems, but fails in another one. In order to overcome the disadvantage, a possible solution is to use a mixed crossover strategy, which mixes various crossover operators. In this paper, an example of such strategies is introduced which employs four different crossover strategies: two-point crossover, uniform crossover, arithmetic crossover. The simulation results show that the mixed crossover strategy is superior to any pure crossover strategy.	crossover (genetic algorithm);genetic algorithm;simulation	Xiaodong Yu;Jingbo Shao;Hongbin Dong	2011	Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology	10.1109/EMEIT.2011.6023583	mathematical optimization;crossover;simulation;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;evolution strategy;algorithm;evolutionary computation	Robotics	27.597935205810156	-7.077572716052331	83174
876d5e1a29fc3db010b14fdfd694556c130188d3	the compact genetic algorithm is efficient under extreme gaussian noise	gaussian noise;evolutionary computation;noise measurement;sociology statistics optimization noise measurement evolutionary computation genetic algorithms gaussian noise;statistics;evolutionary algorithms noisy optimization run time analysis;genetic algorithms;optimization;sociology	Practical optimization problems frequently include uncertainty about the quality measure, for example, due to noisy evaluations. Thus, they do not allow for a straightforward application of traditional optimization techniques. In these settings, randomized search heuristics such as evolutionary algorithms are a popular choice because they are often assumed to exhibit some kind of resistance to noise. Empirical evidence suggests that some algorithms, such as estimation of distribution algorithms (EDAs) are robust against a scaling of the noise intensity, even without resorting to explicit noise-handling techniques such as resampling. In this paper, we want to support such claims with mathematical rigor. We introduce the concept of graceful scaling in which the run time of an algorithm scales polynomially with noise intensity. We study a monotone fitness function over binary strings with additive noise taken from a Gaussian distribution. We show that myopic heuristics cannot efficiently optimize the function under arbitrarily intense noise without any explicit noise-handling. Furthermore, we prove that using a population does not help. Finally, we show that a simple EDA called the compact genetic algorithm can overcome the shortsightedness of mutation-only heuristics to scale gracefully with noise. We conjecture that recombinative genetic algorithms also have this property.	additive white gaussian noise;automated theorem proving;color graphics adapter;emoticon;estimation of distribution algorithm;evolutionary algorithm;expanded memory;fitness function;genetic algorithm;heuristic (computer science);image scaling;iteration;linear algebra;mathematical optimization;optimization problem;population;randomized algorithm;recursive least squares filter;resampling (statistics);run time (program lifecycle phase);scalability;utility functions on indivisible goods;monotone	Tobias Friedrich;Timo Kötzing;Martin S. Krejca;Andrew M. Sutton	2017	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2016.2613739	quality control and genetic algorithms;gaussian noise;mathematical optimization;genetic algorithm;computer science;noise measurement;artificial intelligence;machine learning;mathematics;algorithm;statistics;evolutionary computation	AI	29.156542148827107	1.049775245753113	83393
33121e8f65d06d83f24850ab71a82c3201d92f78	discrete stochastic optimization using linear interpolation	desirable convergence property;numerical experiment;discrete point;continuous optimization technique;discrete stochastic optimization problem;linear interpolation;deterministic approximating problem;simulation oracle;random search algorithm;continuous search;objective function;simulation;stochastic processes;continuous optimization;random search;optimization problem;interpolation;random processes;stochastic optimization;mean squared error	We consider discrete stochastic optimization problems where the objective function can only be estimated by a simulation oracle; the oracle is defined only at the discrete points. We propose a method using continuous search with simplex interpolation to solve a wide class of problems. A retrospective framework provides a sequence of deterministic approximating problems that can be solved using continuous optimization techniques that guarantee desirable convergence properties. Numerical experiments show that our method finds the optimal solutions for discrete stochastic optimization problems orders of magnitude faster than existing random search algorithms.	approximation algorithm;continuous optimization;experiment;linear interpolation;mathematical optimization;numerical method;optimization problem;random search;search algorithm;simplex algorithm;simulation;stochastic optimization	Honggang Wang;Bruce W. Schmeiser	2008	2008 Winter Simulation Conference		stochastic programming;probabilistic-based design optimization;discrete optimization;optimization problem;stochastic process;mathematical optimization;combinatorics;discrete mathematics;random search;combinatorial optimization;interpolation;stochastic optimization;discrete-time stochastic process;mathematics;mean squared error;continuous optimization;linear interpolation	ML	30.65218278589699	1.492916643791348	83394
1edaf80d1c561f639cd5f831d968a287ca09951f	dynamic isd scheme for the avm system - a preliminary study	accuracy metrology semiconductor device modeling heuristic algorithms current measurement data models production;metrology;accuracy;current measurement;semiconductor device modeling;heuristic algorithms;production;semiconductor manufacturing dynamic isd scheme avm system production cost reduction automatic virtual metrology original intelligent sampling decision scheme original isd scheme sampling rate reduction;virtual manufacturing cost reduction decision theory manufacturing systems semiconductor industry;dynamic intelligent sampling decision dynamic isd scheme automatic virtual metrology avm system original intelligent sampling decision original isd scheme;data models	Reducing the sampling rate to as low as possible is a high priority for many factories to reduce production cost. Automatic-Virtual-Metrology (AVM) based Original Intelligent Sampling Decision (Original ISD) scheme had been previously developed for reducing the sampling rate and sustaining the VM accuracy. However, the desired sampling rate of the Original ISD scheme is fixed and set manually. Hence, whenever the VM accuracy gets worse, it cannot dynamically increase the desired sampling rate in the Original ISD scheme. As a consequence, it would take more time to collect enough samples for improving the VM accuracy. Moreover, when the VM accuracy performs well all the time, it cannot automatically decrease the desired sampling rate in Original ISD, which may result in unnecessary waste. Accordingly, this paper proposes a preliminary study of a Dynamic ISD scheme to dynamically and automatically modify the sampling rate online and in real time. The Dynamic ISD scheme can monitor the VM accuracy on line as well as update the VM models in real time for maintaining the VM accuracy when the VM accuracy becomes poor. Also, the Dynamic ISD scheme can automatically reduce the sampling rate while the VM accuracy performs well.	astronomy visualization metadata;sampling (signal processing)	Yao-Sheng Hsieh;Fan-Tien Cheng;Chun-Fang Chen;Jhao-Rong Lyu;Ting-Yu Lin	2015	2015 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2015.7139469	data modeling;semiconductor device modeling;simulation;computer science;accuracy and precision;engineering drawing;metrology;statistics	Embedded	37.57543385620653	-5.0512663693317	83707
5ab770d3926ae484e389efce2cc81b3f2896473e	quantum-inspired genetic algorithm with two search supportive schemes and artificial entanglement	computers;interference;biological cells;artificial entanglement quantum computing genetic algorithms search supportive scheme numerical optimization;search problems genetic algorithms probability quantum computing quantum entanglement;statistics;numerical optimization functions two search supportive schemes artificial entanglement enhanced quantum inspired genetic algorithm eqiga exploration exploitation explore scheme exploit scheme quantum computing probabilistic representation probabilistic superposition fitness threshold quantum side stepping;optimization;sociology statistics quantum entanglement biological cells interference computers optimization;quantum entanglement;sociology	In this paper, we present an enhanced quantum-inspired genetic algorithm (eQiGA) with a combination of proposed mechanisms: two search supportive schemes and artificial entanglement. This combination is aimed at balancing exploration and exploitation. Two schemes, namely Explore and Exploit scheme are designed with aggressive specific roles reflecting its name. Entanglement is considered to be one of the significant strengths in quantum computing aside the probabilistic representation and superposition. Hence we attempt to apply its concept as part of our strategy for its potential. In addition, two new sub-strategies are proposed: fitness threshold, and quantum side-stepping. The algorithm is tested on multiple numerical optimization functions, and significant results of improved performance are obtained, studied, and discussed.	a* search algorithm;computable function;computer;control engineering;differential evolution;evolutionary algorithm;evolutionary computation;evolutionary programming;exploit (computer security);genetic algorithm;global optimization;han unification;heuristic;ieee information theory society;information and computation;knapsack problem;local interconnect network;mathematical optimization;quantum computing;quantum entanglement;quantum mechanics;stepping level;travelling salesman problem;wang tile	Chee Ken Choy;Kien Quang Nguyen;Ruck Thawonmas	2014	2014 IEEE Symposium on Foundations of Computational Intelligence (FOCI)	10.1109/FOCI.2014.7007802	combinatorics;quantum information;theoretical computer science;quantum network;quantum capacity;mathematics;interference;quantum computer;quantum entanglement;quantum algorithm;quantum phase estimation algorithm	AI	27.394940033069417	-7.888080557205648	83775
e341676dddd1e73fd7aca8af0e904717a80b132f	optimizaton using clonal selection algorithm and immune memory based on self-organizing map	topology optimization clonal selection algorithm self organizing map immune memory;immune system approximation algorithms abstracts adaptation models irrigation;self organising feature maps artificial immune systems search problems;multimodal optimization search optimization clonal selection algorithm immune memory self organizing map immune system optimum search quality immune algorithm som based management solution quality search performance	In this work an approach of integration of clonal selection algorithm and immune memory based on self-organizing map(SOM) is presented to solve optimization problem. Immune memory lays the foundation for a rapid and massive secondary response of immune system. Management of immune memory is important for improving performance and quality of optimum search using immune algorithm. The adaptive functionality of SOM is applied for emulation of the dynamic behavior of immune memory. From results obtained using proposed approach SOM-based management of immune memory can keep balance between exploration and exploitation for good solution quality and search performance. Besides SOM can improve the clonal selection algorithm in performance for multi-modal optimization search.	clonal selection algorithm;emulator;mathematical optimization;modal logic;optimization problem;organizing (structure);self-organization;self-organizing map	Chun-Yin Wu;Chin-Chiang Ku	2013	2013 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2013.6890776	bioinformatics;artificial intelligence;machine learning	EDA	25.24320006853264	-6.412991539095686	83857
a9137ce76259b6947fc95bb501c6e94dd0aec498	optimization of simulation via quasi-newton methods	response surface methodology;simulation;quasi newton method;optimization	This paper discusses the application of quasi-Newton methods to optimization of simulation. Specifically, it describes a general methodology that combines response surface methodology and other optimization techniques with quasi-Newton methods. Using quasi-Newton methods in the vicinity of the optimum speeds up the convergence rate of response surface methodology, the gradient, and search methods. From the class of quasi-Newton methods, we recommend BFGS and Davidon's methods. These methods are effective without exact line searches. Two examples demonstrate the effectiveness of the proposed methodology. INFORMS Journal on Computing , ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499.	newton;program optimization;quasi-newton method;simulation	M. Hossein Safizadeh;Robert Signorile	1994	INFORMS Journal on Computing	10.1287/ijoc.6.4.398	mathematical optimization;response surface methodology;quasi-newton method;computer science;mathematics;operations research	EDA	29.94281892241461	0.33339185833350116	84441
4b952a516f8005cc8d75d7eacb7d8bc8d12d64ff	a genetic algorithm with tabu search for multimodal and multiobjective function optimization	similarity solution;function optimization;genetic algorithm;tabu search	The integration of genetic algorithms (GAs) and tabu search is one of traditional problems in function optimization in the GA literature. However, most proposed methods have utilized genetic algorithms to explore global candidates and tabu search to exploit local optimal points. Unlike such methods so far, this paper proposes a new algorithm to directly store individuals into multiple tabu lists during GA-iterations. The tabu lists inhibit similar solution candidates from being selected so often. The proposed algorithm is so simple but strong that we can solve both multimodal and multiobjective problems in the same manner. The paper describes the basic idea, algorithms, and experimental results.	genetic algorithm;iteration;mathematical optimization;multimodal interaction;software release life cycle;tabu search	Setsuya Kurahashi;Takao Terano	2000			mathematical optimization;genetic algorithm;tabu search;computer science;artificial intelligence;hill climbing;machine learning;mathematics;algorithm;metaheuristic;guided local search	AI	25.8999865904716	-3.1087521704879295	84451
60d96a95ca646d99e744ceff0585c5670a558733	a hybrid bpso-ga algorithm for 0-1 knapsack problems	binary particle swarm optimization (bpso);genetic algorithm;hybrid algorithm;knapsack problems	0-1 knapsack problems (KPs) is a typical NP-hard problem in combinatorial optimization problem. For the sake of efficiency, it becomes increasingly popular for researchers to apply heuristic techniques to solve the 0-1 KPs. Due to its simplicity and convergence speed, an increasing number of techniques based on binary particle swarm optimization (BPSO) has been presented. However, BPSO-based techniques suffered from a major shortcoming which is the premature convergence of a swam. To address the problem, this paper proposed a hybrid BPSO-GA algorithm which combines the strengths of BPSO and genetic algorithm (GA). Experimental results show that our proposal is able to find more optimal solutions than BPSO-based algorithm. © 2018, Springer International Publishing AG.	algorithm;software release life cycle	Jinshui Wang;Jianhua Liu;Jeng-Shyang Pan;Xingsi Xue;Lili Huang	2017		10.1007/978-3-319-68527-4_37	machine learning;computer science;artificial intelligence;genetic algorithm;hybrid algorithm;knapsack problem;combinatorial optimization;continuous knapsack problem;algorithm;polynomial-time approximation scheme;premature convergence;particle swarm optimization	Theory	25.74032542902261	-2.546143013721066	85072
1f9819d66640a52849f53cb962b1ab5d2171b07a	enhanced artificial bee colony algorithm through differential evolution	differential evolution;population initialization;evaluation strategy;artificial bee colony algorithm	HighlightsWhen producing the initial population, the chaotic opposition-based population initialization method is employed to enhance the global convergence.A learning strategy is developed with an attempt to use more prior information of previous search experience.A hybrid approach that combines DE with gbest-guided ABC, is designed to improve the performance of ABC.The experiment results demonstrate the good performance of the proposed algorithm. Artificial bee colony algorithm (ABC) is a relatively new optimization algorithm. However, ABC does well in exploration but badly in exploitation. One possible way to improve the exploitation ability of the algorithm is to combine ABC with other operations. Differential evolution (DE) can be considered as a good choice for this purpose. Based on this consideration, we propose a new algorithm, i.e. DGABC, which combines DE with gbest-guided ABC (GABC) by an evaluation strategy with an attempt to utilize more prior information of the previous search experience to speed up the convergence. In addition, to improve the global convergence, when producing the initial population, a chaotic opposition-based population initialization method is employed. The comparison results on a set of 27 benchmark functions demonstrate that the proposed method has better performance than the other algorithms.	artificial bee colony algorithm;differential evolution	Weifeng Gao;Lingling Huang;Jue Wang;San-Yang Liu;Chuan-dong Qin	2016	Appl. Soft Comput.	10.1016/j.asoc.2015.10.070	differential evolution;mathematical optimization;computer science;artificial intelligence;machine learning;artificial bee colony algorithm;evaluation strategy	Logic	27.39791882667374	-4.4132505778939315	85089
faa1a7696756c36fff7dcf75d91804ce200fee36	a hybrid particle swarm with a time-adaptive topology for constrained optimization	continuous space optimization;disjoint feasible regions;constrained optimization problems;particle swarm optimization	For constrained optimization problems set in a continuous space, feasible regions might be disjointed and the optimal solution might be in any of these regions. Thus, locating these feasible regions (ideally all of them) as well as identifying the most promising region (in terms of objective value) at the end of the optimization process would be of a great significance. In this paper a time-adaptive topology is proposed that enables a variant of the particle swarm optimization (PSO) to locate many feasible regions at the early stages of the optimization process and to identify the most promising one at the latter stages of the optimization process. This PSO variant is combined with two local searches which improve the ability of the algorithm in both finding feasible regions and higher quality solutions. This method is further hybridized with covariance matrix adaptation evolutionary strategy (CMA-ES) to enhance its ability to improve the solutions at the latter stages of the optimization process. Results generated by this hybrid method are compared with the results of several other state-of-the-art methods in dealing with standard benchmark constraint optimization problems. & 2014 Elsevier B.V. All rights reserved.	adaptive filter;algorithm;benchmark (computing);cma-es;cops (software);constrained optimization;ecmascript;local search (optimization);mathematical optimization;mg (editor);optimization problem;particle swarm optimization;test case	Mohammad Reza Bonyadi;Xiang Li;Zbigniew Michalewicz	2014	Swarm and Evolutionary Computation	10.1016/j.swevo.2014.06.001	probabilistic-based design optimization;optimization problem;mathematical optimization;multi-swarm optimization;constrained optimization;combinatorics;topology optimization;test functions for optimization;meta-optimization;combinatorial optimization;derivative-free optimization;machine learning;mathematics;imperialist competitive algorithm;vector optimization;random optimization;metaheuristic;global optimization	AI	25.962498545757597	-2.6155780797029835	85103
ab8c3f8fcf8b5a3473e93eb13981418e133beefd	photovoltaic plants predictive model by means of ann trained by a hybrid evolutionary algorithm	bio inspired heuristic search technique;solar cells;forecasting;neural network application;swarm intelligence;production forecasting;hybrid evolutionary algorithm;combinatorial optimization problems;neural nets;combinatorial optimization problems photovoltaic plants predictive model ann hybrid evolutionary algorithm artificial neural network production forecasting solar energy pv plants particle swarm optimization genetic algorithm bio inspired heuristic search technique;training;combinatorial optimization problem;solar energy;ann;artificial neural networks gallium optimization particle swarm optimization forecasting training production;heuristic search;artificial neural networks;power engineering computing;particle swarm optimizer;natural selection;particle swarm optimization;production;artificial intelligence;genetic algorithm;genetic algorithms;optimization;prediction model;photovoltaic plants predictive model;photovoltaic power systems;evolutionary optimization;social behaviour;particle swarm optimisation;combinatorial mathematics;solar cells artificial intelligence combinatorial mathematics genetic algorithms neural nets particle swarm optimisation photovoltaic power systems power engineering computing;artificial neural network;gallium;solar energy pv plants	This paper introduces a hybrid evolutionary optimization algorithm as a tool for training an Artificial Neural Network used for production forecasting of solar energy PV plants. This hybrid technique is developed in order to exploit in the most effective way the uniqueness and peculiarities of two classical optimization approaches, Particle Swarm Optimization (PSO) and Genetic Algorithms (GA). This procedure essentially represent a bio-inspired heuristic search technique, which can be used to solve combinatorial optimization problems, modeled on the concepts of natural selection and evolution (GA), but also based on cultural and social behaviours derived from the analysis of the swarm intelligence and interaction among particles (PSO). Some simulation results are reported to highlight advantages and drawbacks of the proposed technique in order to suitably apply this algorithm to neural network applications in engineering problems.	artificial neural network;bilateral filter;british informatics olympiad;combinatorial optimization;evolutionary algorithm;genetic algorithm;heuristic;load profile;mathematical optimization;neural networks;optimizing compiler;particle swarm optimization;predictive modelling;simulation;swarm intelligence	Davide Caputo;Francesco Grimaccia;Marco Mussetta;Riccardo Enrico Zich	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596782	mathematical optimization;multi-swarm optimization;meta-optimization;genetic algorithm;computer science;artificial intelligence;machine learning;imperialist competitive algorithm;artificial neural network;metaheuristic	AI	24.80088390831762	-5.945904021208377	85119
0b9ce5687acd0b8446fcb623d1b4f8dc2e5589c8	a chaos-based image encryption scheme using chaotic coupled map lattices	international journal of computer applications ijca	In this letter, after reviewing the main points of the chaotic trigonometric maps and the coupled map lattices, we introduce the scheme of chaos-based image encryption based on coupled map lattices. The scheme decreases periodic effect of the ergodic dynamical systems in the chaos-based image encryption. To evaluate the security of the encrypted image of this scheme, the key space analysis, the correlation of two adjacent pixels and differential attack were performed. This scheme tries to improve the problem of failure of encryption such as small key space and level of security.	chaos;coupled map lattice;differential cryptanalysis;dynamical system;encryption;ergodicity;key space (cryptography);pixel	Sodeif Ahadpour;Yaser Sadra	2012	CoRR	10.5120/7599-0311	computer science;theoretical computer science;probabilistic encryption	Crypto	38.69845691206451	-8.611209671120088	85245
21d077ffee45284074b395169806ee10b8f9b5f9	the factorized distribution algorithm and the minimum relative entropy principle	spin glass;minimum relative entropy;maximum entropy principle;004;benchmark problem;optimization problem;relative entropy;statistical physics;estimation of distribution algorithm;boltzmann distribution;junction tree minimum relative entropy maximum likelihood bethe kikuchi approximation;distributed algorithm;constrained optimization problem;estimation of distribution	Estimation of Distribution Algorithms (EDA) have been proposed as an extension of genetic algorithms. In this paper the major design issues of EDA’s are discussed using an interdisciplinary framework, the minimum relative entropy (MinRel) approximation. We assume that the function to be optimized is additively decomposed (ADF). The interaction graph GADF of the ADF is used to create exact or approximate factorizations of the Boltzmann distribution. The relation between the Factorized Distribution Algorithm FDA and the MinRel approximation is shown. We present a new algorithm, derived from the Bethe-Kikuchi approach developed in statistical physics. It minimizes the relative entropy KLD(q|pβ) to the Boltzmann distribution pβ by solving a difficult constrained optimization problem. We present in detail the concave-convex minimization algorithm CCCP to solve the optimization problem. The two algorithms are compared using popular benchmark problems (2-d grid problems, 2-d Ising spin glasses, Kaufman’s n−k function.) We use instances up to 900 variables.	approximation algorithm;benchmark (computing);bethe lattice;bethe–salpeter equation;computation;concave function;constrained optimization;constraint (mathematics);convex optimization;download;empirical risk minimization;estimation of distribution algorithm;genetic algorithm;graphical model;heuristic (computer science);ising model;kullback–leibler divergence;mathematical optimization;microsoft outlook for mac;numerical analysis;optimization problem;point of view (computer hardware company);polynomial;sampling (signal processing);time complexity;tree decomposition	Heinz Mühlenbein;Robin Höns	2006		10.1007/978-3-540-34954-9_2	mathematical optimization;joint entropy;combinatorics;quantum relative entropy;generalized relative entropy;binary entropy function;transfer entropy;entropy maximization;maximum entropy probability distribution;principle of maximum entropy;calculus;mathematics;boltzmann's entropy formula;maximum entropy thermodynamics;joint quantum entropy;configuration entropy;maximum entropy spectral estimation;entropy rate;entropy	ML	33.58549456220308	3.9986796301632026	85291
5588f8c2df5e11a20e54995d7ce5a6f2b8a8b1f4	evolutionary multimodel partitioning filters for multivariable systems	convergence;evolutionary multimodel partitioning filters mutation operators crossover operators parameters coding fitness function a posteriori probability genetic algorithms partitioning theorem mmaf multimodel adaptive filter multivariable systems;probability adaptive filters encoding genetic algorithms multivariable systems;adaptive filters;genetic algorithms adaptation models adaptive filters convergence sociology adaptive estimation;genetic algorithms;adaptation models;sociology;adaptive estimation	It is known that for the adaptive filtering problem, the Multi Model Adaptive Filter (MMAF) based to the Partitioning Theorem is the best solution. It is also known that Genetic Algorithms (GAs) are one of the best methods for searching and optimization. In this work a new method, concerning multivariable systems, which combines the effectiveness of MMAF and GAs' robustness has been developed. Specifically, the a-posteriori probability that a specific model, of the bank of the conditional models, is the true model can be used as fitness function for the GA. Although the parameters' coding is more complicated, simulation results show that the proposed algorithm succeeds better estimation of the unknown parameters compared to the conventional MMAF, even in the case where it is not included in the filters bank. Finally, a variety of defined crossover and mutation operators is investigated in order to accelerate algorithm's convergence.	adaptive filter;filter bank;fitness function;genetic algorithm;mathematical optimization;simulation;software release life cycle	Grigorios N. Beligiannis;K. G. Berketis;O. A. Fotakis;Spiridon D. Likothanassis	1998	9th European Signal Processing Conference (EUSIPCO 1998)		adaptive filter;mathematical optimization;machine learning;control theory;mathematics	EDA	31.47888727552916	-5.319574781031071	85414
6baf725d88d2655daa93e3c1b7748ac570dce2f3	tuning evolutionary programming for conformationally flexible molecular docking	evolutionary programming;molecular docking		docking (molecular);evolutionary programming	Daniel K. Gehlhaar;David B. Fogel	1996			evolutionary programming;docking (molecular);computer science;bioinformatics	Logic	29.831410250397518	-8.416831829937486	85661
7f41e281872124d51e14adb67c2db1aa342120a2	global optimality test for maximin solution of bilevel linear programming with ambiguous lower-level objective function		Abilevel linear programming problemwith ambiguous lower-level objective function is a sequential decision making under uncertainty of rational reaction. The ambiguous lower-level objective function is assumed that the coefficient vector of the follower lies in a convex polytope. We apply the maximin solution approach and formulate it as a special kind of three-level programming problem. Since an optimal solution exists at a vertex of feasible region, we adopt k-th best method to search an optimal solution. At each iteration of the k-th best method, we check rationality, local optimality and global optimality of the candidate solution. In this study, we propose a global optimality test based on an inner approximation method and compare its computational efficiency to other test methods based on vertex enumeration. We also extensively utilize the history of rationality tests to verify the rationality of the solution in the follower’s problem. Numerical experiments show the advantages of the proposed methods.	approximation;coefficient;computation;decision theory;experiment;feasible region;global optimization;iteration;linear programming;local optimum;loss function;mathematical optimization;minimax;numerical analysis;numerical method;optimization problem;rationality;round-off error;subroutine;vertex enumeration problem	Puchit Sariddichainunta;Masahiro Inuiguchi	2017	Annals OR	10.1007/s10479-016-2293-2	mathematical optimization;combinatorics;mathematics;mathematical economics	AI	29.679561484145268	1.1318251928679415	86048
073e644cb568cc4a891776094faec06ddf8e0c2f	a novel multi-swarm algorithm for optimization in dynamic environments based on particle swarm optimization	multi swarm;swarm intelligence;dynamic environments;moving peak benchmark;particle swarm optimization	Optimization in dynamic environment is considered among prominent optimization problems. There are particular challenges for optimization in dynamic environments, so that the designed algorithms must conquer the challenges in order to perform an efficient optimization. In this paper, a novel optimization algorithm in dynamic environments was proposed based on particle swarm optimization approach, in which several mechanisms were employed to face the challenges in this domain. In this algorithm, an improved multi-swarm approach has been used for finding peaks in the problem space and tracking them after an environment change in an appropriate time. Moreover, a novel method based on change ynamic environments warm intelligence oving Peak Benchmark ulti-swarm in velocity vector and particle positions was proposed to increase the diversity of swarms. For improving the efficiency of the algorithm, a local search based on adaptive exploiter particle around the best found position as well as a novel awakening–sleeping mechanism were utilized. The experiments were conducted on Moving Peak Benchmark which is the most well-known benchmark in this domain and results have been compared with those of the state-of-the art methods. The results show the superiority of the proposed method.	algorithm;benchmark (computing);experiment;local search (optimization);mathematical optimization;optimization problem;particle swarm optimization;problem domain;program optimization;velocity (software development)	Danial Yazdani;Babak Nasiri;Alireza Sepas-Moghaddam;Mohammad Reza Meybodi	2013	Appl. Soft Comput.	10.1016/j.asoc.2012.12.020	mathematical optimization;multi-swarm optimization;simulation;test functions for optimization;meta-optimization;swarm intelligence;computer science;derivative-free optimization;machine learning;particle swarm optimization;metaheuristic	AI	26.18684437589952	-4.199391103467922	86151
736c24713c634d60981774a035046f625b46b2fa	integration of improved predictive model and adaptive differential evolution based dynamic multi-objective evolutionary optimization algorithm	forecasting model;期刊论文;dynamic multiobjective optimization;self adaptive differential evolution	A novel dynamic multi-objective optimization evolutionary algorithm is proposed in this paper to track the Pareto-optimal set of time-changing multi-objective optimization problems. In the proposed algorithm, to initialize the new population when a change is detected, a modified prediction model utilizng the historical optimal sets obtained in the last two times is adopted. Meantime, to improve both convergence and diversity, a self-adaptive differential evolution crossover operator is used. We conducted two experiments: the first one compares the proposed algorithm with the other three dynamic multiobjective evolutionary algorithms, and the second one investigates the performance of the two proposed operators. The statistical results indicate that the proposed algorithm has better conergence speed and diversity and it is very promising for dealing with dynamic environment.	differential evolution;evolutionary algorithm;experiment;mathematical optimization;multi-objective optimization;pareto efficiency;performance;predictive modelling	Ruochen Liu;Jing Fan;Licheng Jiao	2014	Applied Intelligence	10.1007/s10489-014-0625-y	mathematical optimization;meta-optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm	ML	26.978196305108945	-4.547439952962183	86177
fa84fd29632d75685bea9a3837cfd6ec542fbffe	differential evolution strategy based on the constraint of fitness values classification	vectors sociology statistics support vector machine classification linear programming optimization classification algorithms;vectors evolutionary computation functions;real parameter single objective optimization differential evolution strategy fitness function values classification constraint fcde global fitness value distribution information objective function donor vector differential vector cec2014;classification differential evolution constraint optimization fitness values	This paper presents a new Differential Evolution (DE) strategy, named as FCDE, based on the constraint of classification of fitness function values. To ensure the population could move to the better fitness landscape, the global fitness value distribution information of the objective function are used and all points in the population are classified into three class by their fitness values in each generation, so the points in each class choose their donor vector and differential vector from the points in adjacent senior class to form the trial vector. This strategy could speed up the convergence to global optimal as well as avoid falling into the local optimal. Another attractive character of FCDE is the control parameters in this DE variant are self-adaptive. This method is tested on the 30 benchmark functions of CEC2014 special session and competition on single objective real-parameter numerical optimization. The experimental results showed acceptable reliability of this strategy in high search dimension. This paper will participate in the competition on real parameter single objective optimization to compare with other algorithms.	algorithm;benchmark (computing);differential evolution;evolution strategy;fitness function;loss function;mathematical optimization;optimization problem	Zhihui Li;Zhigang Shang;Boyang Qu;Jing J. Liang	2014	2014 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2014.6900507	mathematical optimization;machine learning;evolutionary algorithm;pattern recognition;mathematics;fitness approximation;fitness function;natural evolution strategy	AI	27.181524625101883	-5.7419148790158445	86212
71f802322c723240e0340a626a500fc6c3c01f3c	a simple chaotic map-based image encryption system using both plaintext related permutation and diffusion		Recently, to conquer most non-plain related chaos-based image cryptosystems’ security flaws that cannot resist the powerful chosen/knownn plain-text attacks or differential attacks efficiently for less plaintext sensitivity, many plain related chaos-based image cryptosystems have been developed. Most cryptosystems that have adopted the traditional permutation–diffusion structure still have some drawbacks and security flaws: (1) most plaintext related image encryption schemes using only plaintext related confusion operation or only plaintext related diffusion operation relate to plaintext inadequately that cannot achieve high plaintext sensitivity; (2) in some algorithms, the generation of security key that needs to be sent to the receiver is determined by the original image, so these algorithms may not applicable to real-time image encryption; (3) most plaintext related image encryption schemes have less efficiency because more than one round permutation–diffusion operation is required to achieve high security. To obtain high security and efficiency, a simple chaotic based color image encryption system by using both plaintext related permutation and diffusion is presented in this paper. In our cryptosystem, the values of the parameters of cat map used in permutation stage are related to plain image and the parameters of cat map are also influenced by the diffusion operation. Thus, both the permutation stage and diffusion stage are related to plain images, which can obtain high key sensitivity and plaintext sensitivity to resist chosen/known plaintext attacks or differential attacks efficiently. Furthermore, only one round of plaintext related permutation and diffusion operation is performed to process the original image to obtain cipher image. Thus, the proposed scheme has high efficiency. Complete simulations are given and the simulation results prove the excellent security and efficiency of the proposed scheme.	algorithm;arnold's cat map;brute-force attack;chaos theory;cipher;color image;cryptosystem;differential cryptanalysis;digital image;encryption;experiment;ibm notes;interpretation (logic);known-plaintext attack;permutation box;pixel;plaintext;real-time clock;security token;simulation	Linqing Huang;Shuting Cai;Mingqing Xiao;Xiaoming Xiong	2018	Entropy	10.3390/e20070535	discrete mathematics;permutation;mathematical optimization;mathematics;encryption;chaotic;plaintext	Crypto	38.5896138592583	-8.84110790914047	86544
8797617a2110648595593efcf694b97cc5264098	a dynamic history-driven evolutionary algorithm	heuristic algorithms reliability sociology statistics evolutionary computation history optimization;search problems evolutionary computation;dynamic objective problem time instances jumping global optimum tracing doea dynamic objective history driven evolutionary algorithm dyhdea search history storage position value time evaluation dynamic fitness tree 10 dimensional dop unimodal problem multimodal problem separable problem nonseparable problem performance analysis benchmark doea artificial immune algorithm differential evolution evolutionary programming particle swarm optimization dynamic global optimum traces jumping transitions	Dynamic objective problem (DOP) raises two challenging issues to evolutionary algorithm: comparing two individuals evaluated at different time instances and tracing the jumping global optimum. This paper presents a dynamic objective evolutionary algorithm (DOEA) that handles these issues through search history. The presented algorithm, namely dynamic objective history driven evolutionary algorithm (DyHdEA), stores the entire search history including the position, the fitness and the evaluated time of the solutions in a dynamic fitness tree. In the experiment section, DyHdEA is examined on a 10-dimensional DOP that is composed of five basis problems ranging from uni-modal to multi-modal, and from separable to non-separable. Meanwhile, the performance of DyHdEA is compared with five benchmark DOEAs including artificial immune algorithm, differential evolution, evolutionary programming, and particle swarm optimization. Seen from the result, DyHdEA effectively traces the dynamic global optimum with jumping transitions.	benchmark (computing);differential evolution;evolutionary algorithm;evolutionary programming;global optimization;mathematical optimization;modal logic;particle swarm optimization;tracing (software)	Chi Kin Chow;Shiu Yin Yuen	2014	2014 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2014.6900382	evolutionary programming;mathematical optimization;interactive evolutionary computation;human-based evolutionary computation;artificial intelligence;machine learning;evolutionary algorithm;mathematics;memetic algorithm;evolutionary computation	PL	25.879931622896667	-5.310693630748046	86591
60ac01e4e9c727744f8861b0420b440e8e03f762	an integrated framework for deterministic and stochastic optimization	control theory;random sampling;operations research;simulated annealing;optimization problem;stochastic optimization;stochastic processes;computational complexity;stochastic processes optimization methods stochastic systems computational complexity simulated annealing industrial engineering sampling methods computer science control theory operations research;technical report;computer science;stochastic systems;sampling methods;industrial engineering;optimization methods;markov chain	where J(θ) is the average performance measure of interest, L(θ, ω) is the sample performance and ω represents the stochastic effects of the system. It should be noted that solving (2) is much more difficult than solving (1) as in most cases, an analytical expression relating the performance function J(θ) to a solution θ ∈ Θ does not exist. Often, one has to use real-time observations or to resort to simulation in order to evaluate the objective function. In this paper, we will address both of these optimization problems in a unified framework. In particular, we will use discrete event simulation techniques for solving the stochastic problem. Solving large-scale combinatorial problems is, as we stated above, a very difficult problem. The emergence of parallel processing capabilities opens up an intriguing possibility for the development of new parallel search techniques. Several applications of parallel computing have already been successfully developed in the field of combinatorial optimization (Ferreira and Pardalos 1996). Unfortunately, the theory of computational complexity has established several important problems, such as the traveling salesman problem and quadratic assignment problem, to be intrinsically difficult in the sense that the problem of finding an -approximate solution for these problems remains NP-hard (Sahni and Gonzalea 1976; Pardalos and Wolkowicz 1996). It is, therefore, widely believed that neither sequential nor parallel deterministic algorithms can be used to efficiently solve these problems. The last decade has witnessed a rapid growth in the area of randomized algorithms. In particular, many Markov chain based methods have been proposed in recent years. Earlier methods include the Metropolis method (Hastings 1970), and Simulated Annealing (Kirkpatrick, Gelatt, and Vecchi 1983). Recent methods include those proposed by Ho and LarABSTRACT	best, worst and average case;combinatorial optimization;computational complexity theory;computer architecture;emergence;experiment;feasible region;heuristic;local search (optimization);markov chain;mathematical optimization;metropolis;metropolis–hastings algorithm;np-hardness;numerical analysis;optimization problem;parallel computing;quadratic assignment problem;randomized algorithm;real-time clock;sampling (signal processing);simulated annealing;simulation;stochastic optimization;stochastic process;travelling salesman problem;unified framework	Leyuan Shi;Sigurdur Ólafsson	1997		10.1145/268437.268508	stochastic programming;probabilistic-based design optimization;optimization problem;stochastic process;sampling;mathematical optimization;computer science;theoretical computer science;stochastic optimization;machine learning;mathematics;statistics	AI	30.20061797569006	1.9571134868426885	86617
5db7fed528365c221eb29876565085c38924a70e	search techniques for evolutionary constrained optimization			constrained optimization;program optimization	Noha M. Hamza	2016				Theory	26.499499792544512	0.0023925823454083034	86656
a120b1f18594f536384cd7bbe9fb942f7384e2d7	image encryption with multiorders of fractional fourier transforms	linear systems;image encryption;interpolation;image coding;fractional fourier transform;encryption;information security;fourier transforms encryption linear systems interpolation;interpolation cryptography discrete fourier transforms image coding;linear system;image decryption;fast fourier transform;image decryption fractional fourier transform image encryption inverse discrete frft linear system fractional fourier domain analysis interpolation information security fast fourier transform;cryptography;fourier transforms;secure system;fractional fourier domain analysis;fractional fourier transform frft;discrete fractional fourier transform dfrft;inverse discrete frft;domain analysis;discrete fourier transforms;linear system discrete fractional fourier transform dfrft fractional fourier transform frft image encryption interpolation	The original information in the existing security system based on the fractional Fourier transform (FRFT) is essentially protected by only a certain order of FRFT. In this paper, we propose a novel method to encrypt an image by multiorders of FRFT. In the image encryption, the encrypted image is obtained by the summation of different orders inverse discrete FRFT of the interpolated subimages. And the original image can be perfectly recovered using the linear system constructed by the fractional Fourier domain analysis of the interpolation. The proposed method can be applied to the double or more image encryptions. Applying the transform orders of the utilized FRFT as secret keys, the proposed method is with a larger key space than the existing security systems based on the FRFT. Additionally, the encryption scheme can be realized by the fast-Fourier-transform-based algorithm and the computation burden shows a linear increase with the extension of the key space. It is verified by the experimental results that the image decryption is highly sensitive to the deviations in the transform orders.	algorithm;computation;domain analysis;encryption;fast fourier transform;fourier analysis;fractional fourier transform;interpolation;key space (cryptography);linear system;pixel	Ran Tao;Xiangyi Meng;Yue Wang	2010	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2010.2068289	mathematical optimization;mathematical analysis;discrete mathematics;computer science;information security;mathematics;linear system;computer security	Vision	39.09810912682953	-8.953477817059136	86697
3885f6d32ee6a7cabbada3c9857001b58ffec99a	a hybrid grey wolf optimizer and artificial bee colony algorithm for enhancing the performance of complex systems		Abstract In this paper, a novel hybrid algorithm based on grey wolf optimizer (GWO) and artificial bee colony (ABC) algorithm called GWO-ABC is proposed to inherit their advantages and overcome their drawbacks. In GWO-ABC algorithm, wolves adopt the information sharing strategy of bees to promote their exploration ability while wolves keep their original hunting strategy to retain exploitation ability. Moreover, a new method based on chaotic mapping and opposition based learning is proposed to initialize the population. The aim for this new initialization method is to generate an initial population with already better individuals to set a solid ground for rest of the GWO-ABC algorithm to execute. The sole motivation behind incorporating changes in GWO is to help the algorithm to evade premature convergence and to steer the search towards the potential search region in faster manner. To assess the performance of the GWO-ABC, it is tested on a test bed of 27 synthesis benchmark functions of different properties; and result are compared with 5 other efficient algorithms. From the analysis of the numerical results, it is apparent that the projected changes in the GWO ameliorate its overall performance and efficacy especially while dealing with noisy (problem with many sub-optima) problems. Furthermore, GWO-ABC is applied to design an optimal fractional order PID (FOPID) controllers for variety of typical benchmark complex transfer functions and trajectory tracking problem of 2 degree-of-freedom (DOF) robotic manipulator. All simulation results, illustrations, and comparative analysis establish the GWO-ABC as viable alternative to design a controller with optimal parameters and enhance the performance of complex systems.	artificial bee colony algorithm;complex systems;mathematical optimization	Prashant J. Gaidhane;Madhav J. Nigam	2018	J. Comput. Science	10.1016/j.jocs.2018.06.008	artificial bee colony algorithm;control theory;pid controller;mathematical optimization;hybrid algorithm;initialization;chaotic;computer science;population;premature convergence	Theory	27.93330904146401	-4.015623832338094	86862
2870b378be4eba8167ea2a5d14d70b9e2def59d5	a novel association rule decision algorithm based on ant colony optimization algorithm for ball mill pulverizing system	automatic control;optimisation;ant colony optimization;fitness function association rule decision algorithm ant colony optimization ball mill pulverizing system automatic control pheromone matrix heuristic value assignment approach;bismuth;niobium;ball mill pulverizing system;association rule decision algorithm;ball milling;process control ball milling data mining matrix algebra optimisation;association rule decision;association rules;matrix algebra;data mining;decision problem;optimization problem;artificial neural networks;association rule;heuristic algorithms;process control;fuzzy association rules association rule decision ball mill pulverizing system ant colony optimization algorithm;heuristic value assignment approach;pheromone matrix;association rules ant colony optimization ball milling automatic control software algorithms control systems fuzzy systems powders data mining steady state;system simulation;ant colony optimization algorithm;fitness function;steady state;fuzzy association rules	Optimization of automatic control is very important in ball mill pulverizing system and a novel association rule decision algorithm based on ant colony optimization algorithm (ACO) is proposed for improving the control performance. The proposed algorithm, based on ACO, formulates the association rule decision problem as an optimization problem. In the algorithm, a new pheromone matrix is defined on the construction of the problem, and an effective heuristic values assignment approach, which is used with the knowledge of controlled plant, is proposed. The fitness function is established on the system control quality, such as the overshoot, the settling time and the steady state error. We performed the experiments on a mined association rules base of ball mill pulverizing system. Simulation results verify that the proposed algorithm can find the best association rule to optimize the system control performance.	algorithm;ant colony optimization algorithms;association rule learning;automatic control;computer simulation;decision problem;experiment;fitness function;heuristic;local search (optimization);mathematical optimization;mined;optimization problem;overshoot (signal);program optimization;scheme;settling time;steady state	Wenzhi Zhu;Jingcheng Wang;Hui Cao;Yanbin Zhang	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.1171	association rule learning;computer science;artificial intelligence;machine learning;automatic control;process control;fsa-red algorithm;artificial neural network	Robotics	34.437776901986105	-6.439943949109323	86881
20a9c1d963085f5829e0d5edf97ff8f9f236a41f	fuzzy-vq image compression based hybrid psogsa optimization algorithm	image coding vector quantization algorithm design and analysis clustering algorithms optimization particle swarm optimization fuzzy logic;image coding;fuzzy logic;vector quantization;particle swarm optimization;clustering algorithms;optimization;gravitational search particle swarm optimization fuzzy logic vector quantization image compression systems evolutionary learning algorithm;algorithm design and analysis	The transmission speed of big data in multimedia, social networking, and web services, can be enhanced by image compression technology. Fuzzy vector quantization (VQ) image compression is a significant tool for achieving a codebook to illuminate lineaments of big data. A functionality combination of PSO and GSA algorithms, with parallel running, have been used to design a fuzzy-VQ image compression system. The improvement of the compressed image quality has been executed by carrying out suitable parameters selection using the proposed algorithm. Comparative study between sophisticated learning schemes and Linde-Buzo-Gray (LBG) based VQ learning process has been introduced. The proposed algorithms provide an achievement in the behavior of pure image compression.	big data;codebook;genetic algorithm;global storage architecture;image compression;image quality;linde–buzo–gray algorithm;location-based game;mathematical optimization;particle swarm optimization;phase-shift oscillator;social network;vector quantization;web service	Salem Alkhalaf;Osama Alfarraj;Ashraf Mohamed Hemeida	2015	2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2015.7337998	fuzzy logic;algorithm design;mathematical optimization;multi-swarm optimization;computer science;theoretical computer science;machine learning;mathematics;cluster analysis;linde–buzo–gray algorithm;particle swarm optimization;vector quantization	Robotics	30.084022888384943	-5.515531188492155	86926
4030590ff7f3a00287f0f231e13852d562f9aef7	real-coded memetic algorithms with crossover hill-climbing	genetic operator;crossover hill climbing;real coding;memetic algorithm;steady state genetic algorithm;memetic algorithms;hill climbing;crossover hill climbing memetic algorithms real coding steady stated genetic algorithms;adaptive capacity;steady stated genetic algorithms;local search	This paper presents a real-coded memetic algorithm that applies a crossover hill-climbing to solutions produced by the genetic operators. On the one hand, the memetic algorithm provides global search (reliability) by means of the promotion of high levels of population diversity. On the other, the crossover hill-climbing exploits the self-adaptive capacity of real-parameter crossover operators with the aim of producing an effective local tuning on the solutions (accuracy). An important aspect of the memetic algorithm proposed is that it adaptively assigns different local search probabilities to individuals. It was observed that the algorithm adjusts the global/local search balance according to the particularities of each problem instance. Experimental results show that, for a wide range of problems, the method we propose here consistently outperforms other real-coded memetic algorithms which appeared in the literature.	genetic operator;hill climbing;local search (optimization);memetic algorithm;memetics;population parameter;probability;solutions	Manuel Lozano;Francisco Herrera;Natalio Krasnogor;Daniel Molina	2004	Evolutionary Computation	10.1162/1063656041774983	mathematical optimization;crossover;computer science;artificial intelligence;machine learning;mathematics;memetic algorithm	AI	26.810414637329853	-4.760932849889742	87028
1b13086ec72cab25871bee39e766c6cade625e2f	data structures in multi-objective evolutionary algorithms	najwa altwaijry mohamed e1 bachir menai 多目标进化算法 数据结构 多目标优化问题 搜索过程 档案馆 吸引力 非劣解 适用性 data structures in multi objective evolutionary algorithms	Data structures used for an algorithm can have a great impact on its performance, particularly for the solution of large and complex problems, such as multi-objective optimization problems (MOPs). Multi-objective evolutionary algorithms (MOEAs) are considered an attractive approach for solving MOPs, since they are able to explore several parts of the Pareto front simultaneously. The data structures for storing and updating populations and non-dominated solutions (archives) may affect the efficiency of the search process. This article describes data structures used in MOEAs for realizing populations and archives in a comparative way, emphasizing their computational requirements and general applicability reported in the original work.	archive;computation;data structure;decision tree;distribution (mathematics);dominance drawing;evolutionary algorithm;grid computing;irreducibility;mathematical optimization;multi-objective optimization;parallel computing;pareto efficiency;performance;population;quadtree;requirement	Najwa Altwaijry;Mohamed El Bachir Menai	2012	Journal of Computer Science and Technology	10.1007/s11390-012-1296-y	mathematical optimization;simulation;computer science;artificial intelligence;theoretical computer science;machine learning;data mining;database;algorithm	AI	25.190602002576004	-1.3743714560500253	87103
1ac2d9b4257535c2a3999eff3c50c0f571acb262	finding variational structure in data by cross-entropy optimization	cross entropy		cross entropy;program optimization;variational principle	Matthew Brand	2000			mathematical optimization;combinatorics;entropy maximization;computer science;cross entropy;statistics	ML	33.609795876096854	3.71311038002653	87116
c4fcc901f6d6bde5c62a889edf1de4f8b1d0a049	hybridization of chaotic systems and success-history based adaptive differential evolution		This research paper focuses on hybridization of two soft computing fields – chaos theory and evolutionary algorithms, specifically on the implementation of Chaotic map based Pseudo-Random Number Generator (CPRNG) into the process of parent selection in Success-History Based Adaptive Differential Evolution (SHADE) algorithm. The impact on performance of the algorithm is tested on CEC2015 benchmark set where five different chaotic maps are used for random integer generation. Performance comparison shows that there is a potential in replacing classic Pseudo-Random Number Generators (PRNGs) with chaotic ones. The results provided in this paper show that the choice of CPRNG for given problem is crucial in terms of affecting the performance of the algorithm, therefore the next research step will be focused on the development of the framework which will adapt to the solved problem and select the most suitable CPRNG or their combination.	chaos theory;differential evolution	Adam Viktorin;Roman Senkerik;Michal Pluhacek	2016		10.1007/978-3-319-39636-1_11	differential evolution;mathematical optimization;chaos theory;chaotic;evolutionary algorithm;pseudorandom number generator;soft computing;mathematics;integer	Vision	27.0344858589669	-3.2136898721818845	87385
90e6cf8d996c287777e4931982c7f3453f190f35	multiple-parameter fractional quaternion fourier transform and its application in colour image encryption		In this study, by using the quaternion algebra, multiple-parameter fractional quaternion Fourier transform (MPFrQFT) is proposed to generalise the conventional multiple-parameter fractional Fourier transform (MPFrFT) to quaternion signal processing in a holistic manner. First, the new transform MPFrQFT and its inverse transform are defined. An efficient discrete implementation method of MPFrQFT is then proposed, in which the relationship between MPFrQFT and MPFrFT of four components is utilised for a quaternion signal. Finally, a new colour image encryption algorithm based on the proposed MPFrQFT and the double random phase encoding technique is proposed to evaluate the performance of the proposed MPFrQFT. Experimental results demonstrate that: (i) the computational time of the proposed implementation method is almost a half of the direct methodu0027s time; (ii) the proposed MPFrQFT-based encryption algorithm has an overall better performance than eight compared algorithms in security test and robustness test: it is more secure than the compared frequency-based algorithms due to the larger key space and the more sensitive key ‘transform orders’; it is also more robust than the compared spatial-domain algorithms.		Beijing Chen;Ming Yu;Yuhang Tian;Leida Li;Dingcheng Wang;Xingming Sun	2018	IET Image Processing	10.1049/iet-ipr.2018.5440	discrete mathematics;robustness (computer science);quaternion;fourier transform;encryption;signal processing;artificial intelligence;fractional fourier transform;quaternion algebra;pattern recognition;mathematics;key space	Vision	39.10873799109406	-9.250980264037889	87388
42316cb8216bfdc3557ff79aae8f8da013db354f	primal-dual method for searching equilibrium in hierarchical congestion population games		In this paper, we consider a large class of hierarchical congestion population games. One can show that the equilibrium in a game of such type can be described as a minimum point in a properly constructed multi-level convex optimization problem. We propose a fast primal-dual composite gradient method and apply it to the problem, which is dual to the problem describing the equilibrium in the considered class of games. We prove that this method allows to find an approximate solution of the initial problem without increasing the complexity.	apply;approximation algorithm;convex optimization;gradient method;mathematical optimization;monte carlo method;network congestion;optimization problem	Pavel Dvurechensky;Alexander Gasnikov;Evgenia Gasnikova;Sergey Matsievsky;Anton Rodomanov;Inna Usik	2016			mathematical optimization;combinatorics;mathematics;mathematical economics;equilibrium selection	ECom	33.765207804530924	3.4260740383903534	87499
ff41117c770281c14d08b56491d597f70875f698	an iterative global optimization algorithm for potential energy minimization	differential evolution;pair potential;energy function;lennard jones;many body;global optimization;iterative;potential energy;binding energy	In this paper we propose an algorithm for the minimization of potential energy functions. The new algorithm is based on the differential evolution algorithm of Storn and Price [1]. The algorithm is tested on two different potential energy functions. The first function is the Lennard Jones energy function and the second function is the many-body potential energy function of Tersoff [2, 3]. The first problem is a pair potential and the second problem is a semi-empirical manybody potential energy function considered for silicon-silicon atomic interactions. The minimum binding energies of up to atoms are reported.	algorithm;differential evolution;energy minimization;first draft of a report on the edvac;global optimization;interaction;iterative method;jones calculus;lennard-jones potential;many-body problem;mathematical optimization;maxima and minima;plasma active;problem domain;semiconductor industry	N. P. Moloi;M. M. Ali	2005	Comp. Opt. and Appl.	10.1007/s10589-005-4555-9	differential evolution;mathematical optimization;iteration;lennard-jones potential;potential energy;mathematics;binding energy;global optimization	Vision	30.56296218872376	-8.079709797785714	87666
a2b711a9af9145f27f87e0e2904993e04f4d39d7	the response to selection equation for skew fitness distributions	power analysis;modal values response to selection equation skew fitness distributions genetic algorithms gamma distribution fitness values normal distribution selection intensities population mean fitness prediction multimodal functions;equations gaussian distribution genetic algorithms distributed computing autobiographies predictive models algorithm design and analysis minimization methods marine vehicles frequency measurement;normal distribution;response to selection;gamma distribution;functions genetic algorithms equations gamma distribution;genetic algorithm;genetic algorithms;functions;modeling tool	The equation for the response to selection is a powerful analysis and modeling tool for genetic algorithms In this paper we extend the classical analysis which is re stricted to a normal distribution to skew tness distribu tions We show that for a small number of variables the Gamma distribution ts the distribution of the tness val ues better than a normal distribution We compute the se lection intensities for the Gamma distribution It is shown that with these values the prediction for the mean tness of the population is very accurate Finally we show that multi modal functions may lead to tness distributions hav ing several modal values	genetic algorithm;modal logic;ues (cipher)	Hans-Michael Voigt;Heinz Mühlenbein;Dirk Schlierkamp-Voosen	1996		10.1109/ICEC.1996.542707	inverse distribution;skew normal distribution;gamma distribution;econometrics;mathematical optimization;inverse-gamma distribution;normal-gamma distribution;fitness proportionate selection;inverse-chi-squared distribution;mathematics;generalized integer gamma distribution;asymptotic distribution;generalized gamma distribution;fitness approximation;statistics	AI	28.276426050220227	-9.051048813235514	87716
16f22c8f532e9aa6e0c791a394cb69e223bb315b	identifying and exploiting the scale of a search space in differential evolution	optimisation;differential evolution;sociology statistics convergence benchmark testing approximation methods educational institutions clustering algorithms;search problems convergence evolutionary computation optimisation;convergence search space scale exploitation search space scale identification differential evolution multimodal landscapes optimisation optimum region identification local optimum location identification region value metaheuristic algorithm convergence rate control unknown function landscape clustering based method multistart de algorithm;search space analysis	Optimisation in multimodal landscapes involves two distinct tasks: identifying promising regions and location of the (local) optimum within each region. Progress towards the second task can interfere with the first by providing a misleading estimate of a region's value. Thresheld convergence is a generally applicable “meta”-heuristic designed to control an algorithm's rate of convergence and hence which mode of search it is using at a given time. Previous applications of thresheld convergence in differential evolution (DE) have shown considerable promise, but the question of which threshold values to use for a given (unknown) function landscape remains open. This work explores the use of clustering-based method to infer the distances between local optima in order to set a series of decreasing thresholds in a multi-start DE algorithm. Results indicate that on those problems where normal DE converges, the proposed strategy can lead to sizable improvements.	algorithm;cluster analysis;differential evolution;local optimum;mathematical optimization;multimodal interaction;rate of convergence	James Montgomery;Stephen Chen;Yasser González-Fernández	2014	2014 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2014.6900579	differential evolution;mathematical optimization;combinatorics;computer science;machine learning;mathematics	ML	27.93620098157091	-6.007669028757949	87882
299ead06d1ca3a250f40f43119994168c0db0af5	simulation optimization using metamodels	optimization methods stochastic processes discrete event simulation design optimization supply chains information systems buildings iterative methods design methodology polynomials;optimisation;response surface methodology;polynomial metamodels;optimal method;simulation optimization;iterative optimization methods;polynomials;fitting;objective function;iterative methods;computational modeling;stochastic processes;optimisation discrete event simulation iterative methods;polynomial metamodels iterative optimization methods deterministic objective functions discrete event simulation simulation optimization;optimization;approximation methods;discrete event;deterministic objective functions;discrete event simulation	Many iterative optimization methods are designed to be used in conjunction with deterministic objective functions. These optimization methods can be difficult to apply to an objective generated by a discrete-event simulation, due to the stochastic nature of the response(s) and the potentially extensive run times. A metamodel aids simulation optimization by providing a deterministic objective with run times that are generally much shorter than the original discrete-event simulation. Polynomial metamodels generally provide only local approximations, and so a series of metamodels must be fit as the optimization progresses. Other classes of metamodels can provide global fit; fitting can be done either by constructing the global model once at the start of the optimization, or by using the optimization results to identify additional discrete-event runs to refine the global model. This tutorial surveys both local and global metamodel-based optimization methods.	approximation;iterative method;mathematical optimization;metamodeling;polynomial;simulation	Russell R. Barton	2009	Proceedings of the 2009 Winter Simulation Conference (WSC)	10.1109/WSC.2009.5429328	probabilistic-based design optimization;stochastic process;mathematical optimization;response surface methodology;test functions for optimization;computer science;theoretical computer science;discrete event simulation;stochastic optimization;machine learning;mathematics;iterative method;computational model;random optimization;statistics;polynomial;global optimization	EDA	30.85633913502227	1.6294139040789029	88018
6a5ce814fd5cba28ee6d6c9774d010ac70d976dc	a fish school search based algorithm for image channel-optimized vector quantization	image coding;training;indexes;vector quantization;image reconstruction;clustering algorithms;algorithm design and analysis	Channel-Optimized Vector Quantization (COVQ) is an alternative to Vector Quantization (VQ) in the scenario of transmission over noisy channels. The codebook design is an optimization problem in which a set of vectors must be optimized to represent the signals to be quantized. This paper presents a new approach to COVQ codebook design, which is a challenging optimization problem. The proposed technique embeds the Fish School Search (FSS) as a Swarm Clustering Algorithm to COVQ. Simulation results concerning a Binary Symmetric Channel (BSC) reveal the superiority of the proposed technique over conventional COVQ codebook design in terms of the quality of reconstructed images.	algorithm;bat algorithm;binary symmetric channel;business architecture;cluster analysis;codebook;computer cluster;cooperative breeding;embedded system;firefly algorithm;fish school search;flying-spot scanner;lenna;location-based game;mathematical optimization;nearest neighbor search;optimization problem;peak signal-to-noise ratio;quantization (signal processing);search algorithm;simulation;swarm;swarm intelligence;vector quantization;x.690	Felipe A. B. S. Ferreira;F. Madeiro	2016	2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2016.7844479	iterative reconstruction;database index;algorithm design;computer science;theoretical computer science;machine learning;pattern recognition;mathematics;cluster analysis;linde–buzo–gray algorithm;vector quantization	EDA	30.147455997457396	-5.483741506123188	88040
d0d6f324b8e874c3bfbdd3c17374e3121d0977b7	advances in distributed optimization using probability collectives	game theory;monte carlo sampling;bounded rationality;probability collectives;distributed optimization;objective function;control problem;probability distribution;monte carlo;distributed control;information theory;mixed strategy	Recent work has shown how information theory extends conventional full-rationality game theory to allow bounded rational agents. The associated mathematical framework can be used to solve distributed optimization and control problems. This is done by translating the distributed problem into an iterated game, where each agent’s mixed strategy (i.e., its stochastically determined move) sets a different variable of the problem. So the expected value of the objective function of the distributed problem is determined by the joint probability distribution across the moves of the agents. The mixed strategies of the agents are updated from one game iteration to the next so as to converge on a joint distribution that optimizes that expected value of the objective function. Here a set of new techniques for this updating is presented. These and older techniques are then extended to apply to uncountable move spaces. We also present an extension of the approach to include (in)equality constraints over the underlying variables. Another contribution is that we how to extend the Monte Carlo version of the approach to cases where some agents have no Monte Carlo samples for some of their moves, and derive an “automatic annealing schedule”.	brouwer fixed-point theorem;chart;constrained optimization;converge;emoticon;experiment;game theory;information theory;intelligent agent;iteration;loss function;mathematical optimization;monte carlo method;optimal stopping;optimization problem;program optimization;rational agent;rationality;simulated annealing	David H. Wolpert;Charlie E. M. Strauss;Dev G. Rajnarayan	2006	Advances in Complex Systems	10.1142/S0219525906000884	game theory;mathematical optimization;combinatorics;information theory;computer science;artificial intelligence;machine learning;mathematics;mathematical economics;statistics;monte carlo method	AI	36.437225488961616	3.8394831720566316	88045
5b89d77c670b979d5437459e091f509d3281c7f7	adaptive tabu search with strategic oscillation for the bipartite boolean quadratic programming problem with partitioned variables		The bipartite boolean quadratic programming problem with partitioned variables (BQPPV) is an NP-hard combinatorial optimization problem that accommodates a variety of real-life applications. We propose an adaptive tabu search with strategic oscillation (ATSSO) approach for BQP-PV, which employs a multi-pass search framework where each pass consists of an initial constructive phase, an adaptive tabu search phase and a frequencydriven strategic oscillation phase. In particular, the adaptive tabu search phase combines different move operators to collectively conduct neighborhood exploration and an adaptive tabu tenure management mechanism that obviates the task of determining a proper tabu tenure. The frequency-driven strategic oscillation phase diversifies the search when the search reaches a critical solution, drawing on a destructive procedure to unassign some variables by reference to frequency memory and a constructive procedure to re-assign these variables utilizing both frequency memory and problem specific knowledge. Computational experiments on five classes of problem instances indicate that the proposed ATS-SO algorithm is able to find improved solutions for 14 instances and match the best known solutions for all remaining instances, whereas no previous method has succeeded in finding the previous best solutions for all instances. Statistical tests indicate that ATS-SO significantly outperforms the state-of-the-art algorithms in the literature. © 2018 Elsevier Inc. All rights reserved.	algorithm;bqp;combinatorial optimization;computation;computational complexity theory;experiment;mathematical optimization;optimization problem;quadratic programming;real life;tabu search	Yang Wang;Qinghua Wu;Abraham P. Punnen;Fred Glover	2018	Inf. Sci.	10.1016/j.ins.2018.03.045	artificial intelligence;machine learning;statistical hypothesis testing;constructive;mathematics;mathematical optimization;quadratic programming;combinatorial optimization;tabu search;operator (computer programming);bipartite graph;oscillation	AI	26.231154907548735	3.2480447711437757	88130
8993676fd83cff2b5b7f6f97f9fbc13a74e63565	multipopulation-based differential evolution with speciation-based response to dynamic environments		Unlike static optimization problems, the position, height and width of the peaks may vary with time instances in dynamic optimization problems (DOPs). Many real world problems are dynamic in nature. Evolutionary Algorithms (EAs) have been considered to solve the DOPs in the recent years. This article proposes a multi-population based Differential Evolution algorithm which uses a local mutation to control the perturbation of individuals and also avoid premature convergence. An exclusion rule is used to maintain the diversity in a subpopulation to cover a larger search space. Speciation-based memory archive has been used to utilize the previously found optimal information in the new change instance. Furthermore the proposed algorithm has been compared with four other state-of-the-art EAs over the Moving Peak Benchmark (MPB) problem and a benchmarks set named Generalized Dynamic Benchmark Generator (GDBG) proposed for the 2009 IEEE Congress on Evolutionary Computation (CEC) competition.		Souvik Kundu;Debabrota Basu;Sheli Sinha Chaudhuri	2013		10.1007/978-3-319-03753-0_21	mathematical optimization;artificial intelligence;machine learning;mathematics;algorithm	ML	25.71591750133484	-4.144386647952688	88567
950ac1de6f0d44bd58fa8856f92e1ec25eee1b60	multi-objective differential evolution algorithm based on fast sorting and a novel constraints handling technique	sorting constraint handling evolutionary computation optimisation;multi objective problems differential evolution fast sorting constraint handling;multiobjective optimization multiobjective differential evolution algorithm fast sorting constraint handling technique;optimization sorting linear programming convergence heuristic algorithms sociology statistics	In this paper, an improved multi-objective differential evolution algorithm is proposed to solve constraints in multi-objective optimization. Research has shown that the information of infeasible solutions is also important and can help the algorithm improve the convergence and diversity of solutions. A novel constraint handling method is introduced to ensure that a certain number of good infeasible solutions will be kept in the procedure of evolution to guide the search of the individuals. The proposed method is compared with two other constrained multi-objective differential evolution algorithms and the results show that the proposed method is competitive.	algorithm;benchmark (computing);differential evolution;mathematical optimization;multi-objective optimization;next-generation network;sorting	Jing J. Liang;Bojian Zheng;Fangyuan Xu;Bo-Yang Qu;Hui Song	2014	2014 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2014.6900525	mathematical optimization;machine learning;mathematics;algorithm	Vision	25.215662930998565	-2.7110313317006884	88681
64f2887307e3b5d15462b2c124e503a92a9699b0	parallelization and performance optimization of a dynamic pde fixed bed reactor model for practical applications	chemical reactors;poisson equation;computacion informatica;viscous flow;numerical solution;optimizing compiler;model performance;grupo de excelencia;conjugate gradient;ciencias basicas y experimentales;compiler optimization;quimica;cfd;flow simulation;optimal algorithm;model parallelization;model performance optimization;performance optimization;optimization model;model simulation	An important inherent limitation of dynamic multiphase reactor flow simulations is the computational time requirements, making long time statistics intractable. A parallel CFD model has therefore been developed intended for the simulation of multi-phase reactors. The present version of the model simulates 2D reactive flows in a fixed bed reactor. The simulations are performed on two grids of different resolutions. The predicted profiles are in accordance with results reported in the literature. Parallelization and performance optimization of the model have been performed to reduce the computational time. Further reductions have been achieved by applying compiler optimization. The most expensive part of the numerical solution algorithm is the implicit solution of the Poisson equation for the pressure. To solve the Poisson equation a TDMA-algorithm with and without a global block correction procedure, several variations of the conjugated gradients-algorithm and a bi-orthogonal conjugate gradient-algorithm were tested.#R##N##R##N#The optimization work performed has shown that, compared to the serial non-optimized version of the code, the computational time spend solving the model has been reduced by more than an order of magnitude by using an optimized algorithm combined with optimal compiler options. Further reductions in computational time has been achieved by parallelizing the program.#R##N##R##N#With this type of model performance optimization, the multiphase reactive flow systems in chemical reactors are expected to be simulated within feasible time limits.	automatic parallelization;mathematical optimization;parallel computing;reactor (software)	Håvard Lindborg;Vegard Eide;Steffen Unger;Siren T. Henriksen;Hugo A. Jakobsen	2004	Computers & Chemical Engineering	10.1016/j.compchemeng.2003.12.009	mathematical optimization;simulation;computer science;theoretical computer science;optimizing compiler	HPC	34.44311504010242	-3.2620992628739063	88774
544dbf959eed78e52d5142c7df8e9163a7a4ec88	speeding up evolutionary algorithms through restricted mutation operators	algoritmo paralelo;parallel algorithm;equation euler;heuristic method;metodo heuristico;algorithme parallele;upper bound;conference paper;ecuacion euler;borne inferieure;algorithme evolutionniste;algoritmo evolucionista;methode heuristique;evolutionary algorithm;borne superieure;lower bound;cota superior;cota inferior;euler equation	We investigate the effect of restricting the mutation operator in evolutionary algorithms with respect to the runtime behavior. For the Eulerian cycle problem; we present runtime bounds on evolutionary algorithms with a restricted operator that are much smaller than the best upper bounds for the general case. It turns out that a plateau that both algorithms have to cope with is left faster by the new algorithm. In addition, we present a lower bound for the unrestricted algorithm which shows that the restricted operator speeds up computation by at least a linear factor.	combinatorial optimization;computation;eulerian path;evolutionary algorithm;linear function;mathematical optimization	Benjamin Doerr;Nils Hebbinghaus;Frank Neumann	2006		10.1007/11844297_99	mathematical optimization;computer science;evolutionary algorithm;calculus;mathematics;upper and lower bounds;algorithm	Theory	27.938665142224966	2.6547523674687086	88815
d56f1af84cf17f6585047006f071d1396db0fee2	how the (1+λ) evolutionary algorithm optimizes linear functions	runtime analysis;population based ea;theory	We analyze how the (1+λ) evolutionary algorithm (EA) optimizes linear pseudo-Boolean functions. We prove that it finds the optimum of any linear function within an expected number of O(1/λn log n+n) iterations. We also show that this bound is sharp for some functions, e.g., the binary value function. Hence unlike for the(1+1) EA, for the (1+λ) EA different linear functions may have run-times of different asymptotic order. The proof of our upper bound heavily relies on a number of classic and recent drift analysis methods. In particular, we show how to analyze a process displaying different types of drifts in different phases. Our work corrects a wrongfully claimed better asymptotic runtime in an earlier work~\cite{He10}.	bellman equation;binary number;evolutionary algorithm;iteration;like button;linear function	Benjamin Doerr;Marvin Künnemann	2013		10.1145/2463372.2463569	mathematical optimization;artificial intelligence;machine learning;mathematics;theory;algorithm	ML	29.36453809219019	1.8574253367368563	88819
8d5c7c8fd2be58c5e961983763b7c4142cd568d4	mathematical analysis of schema survival for genetic algorithms having dual mutation		Genetic algorithms are widely used in the field of optimization. Schema theory forms the foundational basis for the success of genetic algorithms. Traditional genetic algorithms involve only a single mutation phase per iteration of the algorithm. In this paper, a novel concept of genetic algorithms involving two mutation steps per iteration is proposed. The purpose of adding a second mutation phase is to improve the explorative power of the genetic algorithms. All the possible cases regarding the working of the proposed variant of the genetic algorithms are explored. After a meticulous analysis of all these cases, three lemmas are proposed regarding the survival of a schema after the application of the dual mutation. Based on these three lemmas, a theorem is proved, and a mathematical expression representing the probability of survival of a schema after the application of the crossover and dual mutation is derived. This expression provides a new insight about the penetration of a schema for such scenario and improves our understanding of the functioning of this modified form of the genetic algorithm.	genetic algorithm	Apoorva Mishra;Anupam Shukla	2018	Soft Comput.	10.1007/s00500-017-2650-3	defining length;computer science;bioinformatics;machine learning;algorithm	SE	28.35399850795863	-7.52531573726113	88998
41cc2829f7fc8e91aabe256975413b6ffda40b4d	accelerating optimization using probabilistic affinity evaluation and clonal selection principle	optimisation;evolutionary computation;probability;probabilistic objective function evaluation optimization probabilistic affinity evaluation clonal selection principle evolutionary algorithms search algorithm;clonal selection;search algorithm;search problems evolutionary computation optimisation probability;probabilistic affinity evaluation;objective function;acceleration evolutionary computation robustness testing optimization methods neural networks systems engineering and theory artificial immune systems iterative algorithms immune system;evolutionary algorithms;clonal selection principle;probabilistic objective function evaluation;optimization;search problems;evolutionary algorithm	The performance of evolutionary algorithms in optimization is tightly coupled to the computational effort required by the evaluation of the objective function. If the objective function is too expensive to evaluate, then, the elaboration of the procedures of the search algorithm alone may not result in the required improvement in algorithm's performance. However, if there is a way to speed up or decrease the number of objective function evaluations, even a basic algorithms can potentially achieve better results due to the increased number of generation run in given time. This paper considers a probabilistic objective function evaluation scheme in which the candidate solutions are evaluated and evolved based on their objective function value.	evolutionary algorithm;loss function;mathematical optimization;optimization problem;processor affinity;search algorithm	Jarno Martikainen;Seppo J. Ovaska;Xiao Zhi Gao	2007	2007 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2007.4413691	mathematical optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm;evaluation function;probability;mathematics;search algorithm	Robotics	27.732340401539535	-7.142252252322981	89071
7bf3d0871fafd9651c39f62d5258de8305eaa50e	coping with nonstationary environments: a genetic algorithm using neutral variation	optimization genetic algorithms ladder network neutral variation nonstationary environment self adaptability;neutral theory;variational techniques;genetic algorithms biological cells genetic mutations acceleration information science computer science education humans;genetic algorithm;genetic algorithms;variational techniques genetic algorithms;environmental change	In nonstationary environments, it is difficult to apply traditional genetic algorithms (GAs) because they use strong selection pressure and lose the diversity of individuals rapidly. We propose a GA with neutral variation that can track environmental changes. The idea of this GA is inspired by Kimura's neutral theory (1983). The scheme of this GA allows neutral characters, which do not directly affect the fitness with respect to environments, thus increasing the diversity of individuals. In order to demonstrate the properties of this GA, we apply it to a permutation problem called the ladder-network, of which the imposed alignment on the output changes regularly. We show that the GA with neutral variation can adapt better to environmental changes than a traditional GA.		Teijiro Isokawa;Nobuyuki Matsui;Haruhiko Nishimura;Ferdinand Peper	2002	IEEE Trans. Systems, Man, and Cybernetics, Part A	10.1109/TSMCA.2002.804818	quality control and genetic algorithms;mathematical optimization;genetic algorithm;computer science;artificial intelligence;machine learning;genetic representation;mathematics	Robotics	27.357679619403132	-8.39785944670332	89093
a742c18a52fbc3d827cd4513b0cbf16ff7214a63	phased local search for the maximum clique problem	recherche dynamique;graph theory;iterative method;teoria grafo;algoritmo busqueda;local search algorithm;maximum clique problem;pre2009 other artificial intelligence;algorithme recherche;faculty of science environment engineering and technology;search algorithm;programmation stochastique;theorie graphe;journal article;metodo iterativo;optimisation combinatoire;busca local;maximum clique;methode iterative;adaptive search;280213;dynamic search;combinatorial optimization;stochastic programming;local search;programacion estocastica;recherche locale;optimizacion combinatoria	This paper introduces Phased Local Search (PLS), a new stochastic reactive dynamic local search algorithm for the maximum clique problem. PLS interleaves sub-algorithms which alternate between sequences of iterative improvement, during which suitable vertices are added to the current clique, and plateau search, where vertices of the current clique are swapped with vertices not contained in the current clique. The sub-algorithms differ in their vertex selection techniques in that selection can be solely based on randomly selecting a vertex, randomly selecting within highest vertex degree or randomly selecting within vertex penalties that are dynamically adjusted during the search. In addition, the perturbation mechanism used to overcome search stagnation differs between the sub-algorithms. PLS has no problem instance dependent parameters and achieves state-of-the-art performance for the maximum clique problem over a large range of the commonly used DIMACS benchmark instances.	benchmark (computing);clique (graph theory);clique problem;cluster analysis;combinatorial optimization;dls format;degree (graph theory);iterative method;local search (constraint satisfaction);local search (optimization);mathematical optimization;maximal set;programming paradigm;randomness;search algorithm;springer (tank);vertex (graph theory)	Wayne J. Pullan	2006	J. Comb. Optim.	10.1007/s10878-006-9635-y	mathematical optimization;combinatorics;combinatorial optimization;local search;graph theory;machine learning;vertex;mathematics;algorithm	AI	26.387158165397697	3.206334148879591	89521
029e7af31710524133cd9afcca919b8406ae3f86	wind turbine generator modeling for power production estimation & reliability analysis	wind turbines;ac generators;reliability generators mathematical model wind power generation wind speed markov processes;power generation reliability;monte carlo simulation reliability analysis wind turbine modeling power generation markov chain;wind power station wind turbine generator modeling power production estimation wind turbine generator power output state duration sampling markov chain approach power system reliability analysis data clustering state probability estimation monte carlo estimation matlab platform;markov processes;sampling methods;monte carlo methods;wind turbines ac generators markov processes monte carlo methods power generation reliability sampling methods	This paper presents a modeling strategy for wind turbine generator power output using state duration sampling along with Markov chain approach. The proposed model is especially suitable for power production estimation and reliability analysis of a power system. The proposed strategy comprised of four steps: data clustering, state probability estimation, Monte Carlo estimation, and simulation of the output power. This strategy was implemented on MATLAB platform to model an existing wind power station. The results obtained validated to a reasonable extent the proposed strategy. The analysis and results are presented and discussed.	cluster analysis;matlab;markov chain;mathematical model;monte carlo method;reliability engineering;sampling (signal processing);simulation	Sara A. Mohamed;Yasser G. Hegazy	2012	2012 3rd IEEE PES Innovative Smart Grid Technologies Europe (ISGT Europe)	10.1109/ISGTEurope.2012.6465879	control engineering;electronic engineering;simulation;engineering;power optimizer	EDA	36.0189728144093	-2.8941044948693775	90054
2489648a5725ddcc7ddbecb2414ec70f50ea97cb	hybrid evolutionary algorithms for large scale continuous problems	differential evolution;hybrid evolutionary algorithm;population size;optimization problem;large scale;continuous optimization;hybrid evolutionary methods;evolution strategies;evolution strategy;genetic algorithm;genetic algorithms;multiple offspring sampling;evolutionary algorithm;large scale problem;large scale problems	Evolutionary Algorithms (EAs) are powerful metaheuristics that can be applied to almost any optimization problem. However, different Evolutionary Algorithms own different search capabilities that make them more suitable for one or another optimization problem. Furthermore, the combination of several EAs can boost the performance of individual approaches. In this paper we try to exploit the benefits of the combination of several evolutionary approaches by means of a Hybrid Evolutionary Algorithm, where the participation of each individual algorithm on the overall process is dynamically adjusted through its execution. Two different strategies to perform this adjustment are proposed: one with a constant global population size and another one with variable global population size. Experimental results demonstrate that Hybrid Evolutionary Algorithms outperform the individual ones and that the dynamic strategy with variable population size obtains better results on most of the proposed functions.	evolutionary algorithm;mathematical optimization;metaheuristic;optimization problem	Antonio LaTorre;José María Peña Sánchez;Santiago Muelas;Manuel Zaforas	2009		10.1145/1569901.1570205	evolutionary programming;genetic programming;mathematical optimization;genetic algorithm;cma-es;interactive evolutionary computation;human-based evolutionary computation;cultural algorithm;java evolutionary computation toolkit;computer science;bioinformatics;machine learning;evolutionary algorithm;evolutionary acquisition of neural topologies;genetic representation;continuous optimization;evolution strategy;imperialist competitive algorithm;memetic algorithm;evolutionary computation	AI	25.38226076803803	-4.52684443397382	90326
18e4a821cb95e00465eff5137957ed0e69e6ceba	image encryption algorithm with compound chaotic maps		This paper proposes a novel image encryption scheme based on two even-symmetric chaotic maps and a skew tent chaotic map. In the permutation process, a P-box produced by sorting an even-symmetric chaotic sequence is applied to shuffle the positions of all image pixels. In the diffusion process, both even-symmetric chaotic map and skew tent map are used to generate the key stream. The pixels in the permuted image determine which of two evensymmetric chaotic maps is iterated for next byte in the keystream each time, so the keystream is closely related to the plain image. The performance and security of the proposed method are evaluated thoroughly histogram, correlation of adjacent pixels, information entropy and sensitivity analysis. Results are encouraging and suggest that the scheme is reliable to be adopted for the secure image communication application.	algorithm;brute-force attack;byte;chaos theory;cipher;encryption;entropy (information theory);iteration;key space (cryptography);known-plaintext attack;list of chaotic maps;pixel;plaintext;sorting;tent map	Xuan Li;Guoji Zhang;Xia-Yan Zhang	2015	J. Ambient Intelligence and Humanized Computing	10.1007/s12652-013-0217-4	theoretical computer science	Vision	38.47407778687494	-8.788564882315164	90408
274d83c24259e2a77242d670276367565adfbd85	a simulation-based multi-objective design optimization of electronic packages under thermal cycling and bending	response surface method;carte electronique;evaluation performance;search engine;optimisation;finite element simulation;fiabilidad;reliability;differential evolution;buscador;algoritmo busqueda;performance evaluation;methode parametrique;methode element fini;metodo elemento finito;optimizacion;generic model;packaging electronico;printed circuit;solder joint reliability;numerical method;algorithme recherche;metodo parametrico;concepcion optimal;evaluacion prestacion;parametric method;search algorithm;conception optimale;multi objective optimization;finite element method;design optimization;surface reponse;packaging electronique;thermal cycling;integrated circuit bonding;metodo numerico;cycle thermique;assemblage circuit integre;fiabilite;electronic packaging;tarjeta electronica;finite element model;superficie respuesta;optimal design;optimization;ciclo termico;printed circuit board;moteur recherche;assemblage brasage tendre;algoritmo optimo;thermal cycle;local minima;algorithme optimal;optimal algorithm;response surface;printed wiring board;junta soldada;circuit imprime;soldered joint;methode numerique;circuito imprimido	In this study, a simulation-based multi-objective design optimization methodology was developed for improving electronic packaging reliability. It was demonstrated using a generic model of an electronic package on a printed wiring board. The objective for the optimization was to improve the reliability of solder joints under both thermal cycling and bending by optimizing a group of design parameters. A parametric finite element model was developed using ANSYS for both load conditions. To improve the numerical efficiency of the optimization, a multi-quadric response surface method was implemented to approximate the response of finite element simulations for each loading condition. Subsequently, the multi-objective optimization of solder joint reliability was implemented using a Minmax principle on all response surfaces and a differential evolution algorithm as optimal search engine, which is capable of finding global minimum when local minima exist. Our study demonstrated that the reliability of the solder joints is significantly improved for this given generic model of electronic package. The proposed methodology can be effectively used in improving the reliability of electronic packages. 2004 Elsevier Ltd. All rights reserved.	algorithmic efficiency;approximation algorithm;computation;differential evolution;electronic packaging;finite element method;mathematical optimization;maxima and minima;minimax;multi-objective optimization;nonlinear system;numerical analysis;optimal design;printed circuit board;printing;response surface methodology;robustness (computer science);simulation;soldering;web search engine;wiring	Leon Xu;Tommi Reinikainen;Wei Ren;Bo Ping Wang;Zhenxue Han;Dereje Agonafer	2004	Microelectronics Reliability	10.1016/j.microrel.2004.04.024	structural engineering;electronic engineering;engineering;mathematics;printed circuit board;engineering drawing	EDA	34.315783751578984	-0.021462642427374303	90632
43a01dc9b86585305551204b5e1220dc9f9d6fbc	three alternatives for parallel gpu-based implementations of high performance particle swarm optimization	heuristics-based method;particle swarm optimization;pso algorithm;gpu-based implementation;gpgpu-based architecture;many-dimensional problem;parallel gpu-based implementation;particles act;high performance particle swarm;alternative algorithm;proposed algorithm;problem dimension	Particle Swarm Optimization (PSO) is heuristics-based method, in which the solution candidates of a problem go through a process that simulates a simplified model of social adaptation. In this paper, we propose three alternative algorithms to massively parallelize the PSO algorithm and implement them using a GPGPU-based architecture. We aim at improving the performance of computationally demanding optimizations of many-dimensional problems. The first algorithm parallelizes the particle's work. The second algorithm subdivides the search space into a grid of smaller domains and distributes the particles among them. The optimization subprocesses are performed in parallel. The third algorithm focuses on the work done with respect to each of the problem dimensions and does it in parallel. Note that in the second and third algorithms, all particles act in parallel too. We analyze and compare the speedups achieved by the GPU-based implementations of the proposed algorithms, showing the highlights and limitations imposed.	graphics processing unit;particle swarm optimization	Rogério De Moraes Calazan;Nadia Nedjah;Luiza de Macedo Mourelle	2013		10.1007/978-3-642-38679-4_23	mathematical optimization;multi-swarm optimization;simulation;computer science;theoretical computer science	HPC	26.618532181223074	-0.48955513410560236	90655
eb269e8987af26331a9f9ec79d47164dd0e68fae	real-valued compact genetic algorithms for embedded microcontroller optimization	experimental design;microcontrollers;optimisation;memory requirements;lenguaje ensamblador;mise a jour;motor electrico;calculateur embarque;algoritmo busqueda;optimizacion;electric motor;algorithme recherche;accionamiento electrico;search algorithm;search methods;plan experiencia;search method;online optimization;traitement vectoriel;probabilistic approach;probability vector;algoritmo genetico;design optimization;electric drive;embedded system;benchmark functions real valued compact genetic algorithms embedded microcontroller optimization memory requirements probability vector microcontroller based control platforms binary encoding schemes;actualizacion;embedded systems;compact genetic algorithms cgas;computational modeling;binary encoding schemes;langage assembleur;plan experience;real valued compact genetic algorithms;enfoque probabilista;approche probabiliste;microregisseur;microcontroller based control platforms;benchmark functions;comparative study;boarded computer;electric drives;algorithme genetique;algorithme evolutionniste;genetic algorithm;genetic algorithms microcontrollers field programmable gate arrays design optimization optimization methods search methods encoding computational efficiency computational modeling embedded system;genetic algorithms;compact genetic algorithm;algoritmo evolucionista;optimization;online optimization compact genetic algorithms cgas electric drives embedded systems;assembler;microcontrolador;moteur electrique;evolutionary algorithm;field programmable gate arrays;entrainement electrique;microcontrollers embedded systems genetic algorithms;computational efficiency;encoding;calculador embarque;vector processing;updating;microcontroller;optimization methods;embedded microcontroller optimization	Recent research on compact genetic algorithms (cGAs) has proposed a number of evolutionary search methods with reduced memory requirements. In cGAs, the evolution of populations is emulated by processing a probability vector with specific update rules. This paper considers the implementation of cGAs in microcontroller-based control platforms. In particular, to overcome some problems related to the binary encoding schemes adopted in most cGAs, this paper also proposes a new variant based on a real-valued solution coding. The presented variant achieves final solutions of the same quality as those found by binary cGAs, with a significantly reduced computational cost. The potential of the proposed approach is assessed by means of an extensive comparative study, which includes numerical results on benchmark functions, simulated and experimental microcontroller design problems.	algorithmic efficiency;artificial neural network;binary file;computation;embedded system;emulator;genetic algorithm;graph embedding;interaction;interpolation;iteration;loose coupling;mathematical optimization;microcontroller;nonlinear system;numerical analysis;population;requirement;tournament selection	Ernesto Mininno;Francesco Cupertino;David Naso	2008	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2007.896689	microcontroller;embedded system;genetic algorithm;computer science;theoretical computer science;evolutionary algorithm;algorithm	Robotics	28.037459371935977	0.6056077407833809	90709
998927e47813d188879fa187464025b25c6bf606	an exponential moving average algorithm	evolutionary computation;sudoku computational intelligence evolutionary computation games mean variance optimization;sudoku;computational intelligence;mean variance optimization;usa councils;multidimensional problem exponential moving average algorithm evolutionary algorithms sudoku puzzles search space optimizer optimal value mutation technique ema algorithms computational intelligence algorithms ci algorithms ordinary evolutionary algorithm mean variance optimization mvo;cells biology evolutionary computation indexes optimization usa councils;indexes;games of skill;games;optimization;search problems;search problems evolutionary computation games of skill;cells biology	Techniques to reduce the search space when an optimizer seeks an optimal value are studied in this paper. A new mutation technique called the “Exponential Moving Average” algorithm (EMA) is introduced. The performance of EMA algorithms is compared to two other similar Computational Intelligence (CI) algorithms (an ordinary Evolutionary Algorithm (EA) and a “Mean-Variance Optimization” (MVO)) to solve a multi-dimensional problem which has a large search space. The classic Sudoku puzzle is chosen as the problem with a large search space.	computation;computational intelligence;evolutionary algorithm;mathematical optimization;optimization problem;sudoku	David Haynes;Steven M. Corns;Ganesh K. Venayagamoorthy	2012	2012 IEEE Congress on Evolutionary Computation	10.1109/CEC.2012.6252962	database index;games;mathematical optimization;cultural algorithm;computer science;artificial intelligence;machine learning;computational intelligence;evolutionary algorithm;mathematics;metaheuristic;evolutionary computation	DB	27.36442795676256	-6.923226073562731	90716
641a183de572d6b43213eec99d57c87f9935225c	evolving plastic neural networks with novelty search	neuroevolution;neural networks;neuromodulation;learning;search algorithm;adaptive behavior;adaptation and learning;learning to learn;adaptation;adaptive learning;adaptive system;novelty search;evolutionary algorithm;artificial neural network;neural network	Biological brains can adapt and learn from past experience. Yet neuroevolution, i.e. automatically creating artificial neural networks (ANNs) through evolutionary algorithms, has sometimes focused on static ANNs that cannot change their weights during their lifetime. A profound problem with evolving adaptive systems is that learning to learn is highly deceptive. Because it is easier at first to improve fitness without evolving the ability to learn, evolution is likely to exploit domain-dependent static (i.e. non-adaptive) heuristics. This paper analyzes this inherent deceptiveness in a variety of different dynamic, reward-based learning tasks, and proposes a way to escape the deceptive trap of static policies based on the novelty search algorithm. The main idea in novelty search is to abandon objective-based fitness and instead simply search only for novel behavior, which avoids deception entirely. A series of experiments and an in-depth analysis show how behaviors that could potentially serve as a stepping stone to finding adaptive solutions are discovered by novelty search yet are missed by fitness-based search. The conclusion is that novelty search has the potential to foster the emergence of adaptive behavior in reward-based learning tasks, thereby opening a new direction for research in evolving plastic ANNs.	adaptive behavior;adaptive system;artificial neural network;emergence;evolutionary algorithm;experiment;fitness function;heuristic (computer science);neuroevolution;reinforcement learning;search algorithm;stanley (vehicle);stepping level	Sebastian Risi;Charles E. Hughes;Kenneth O. Stanley	2010	Adaptive Behaviour	10.1177/1059712310379923	psychology;neuroevolution;simulation;computer science;artificial intelligence;adaptive behavior;machine learning;adaptive learning;artificial neural network;neuromodulation;adaptation;search algorithm	ML	25.19009338424539	-9.73454282609315	90818
b1e6f1243dcb418844d81a0c64672a93813b8c21	efficient confusion-diffusion chaotic image cryptosystem using enhanced standard map		This paper proposed an efficient confusion–diffusion chaotic image cryptosystem based on a modified Standard chaotic map. The proposed chaotic image cryptosystem employed image confusion and pixel diffusion in two phases. In the first phase, the plain image is shuffled by a modification of Standard chaotic map for n rounds. In the second phase, the shuffled image is diffused by Henon chaotic map. Then, the overall process is repeated m rounds. Comparison between Standard map and the proposed modification is held to prove the effectiveness of the proposed chaotic image cryptosystem. The experimental results show that the proposed chaotic image cryptosystem can successfully encrypt/decrypt images with the same secret keys with good encryption effect and large key space. Moreover, the simulation analysis demonstrates that the encrypted images have good information entropy and very low correlation coefficients, and the distribution of the gray values in the encrypted image has random-like behavior.	confusion and diffusion;cryptosystem;standard map	Osama S. Faragallah	2015	Signal, Image and Video Processing	10.1007/s11760-014-0683-y	telecommunications;theoretical computer science;mathematics;computer security	Vision	38.67511215833331	-8.882081574170686	90879
36d217fb79c26f9a10dbf2cdf2a1a6afa86a838c	hybrid single node genetic programming for symbolic regression		This paper presents a first step of our research on designing an effective and efficient GP-based method for symbolic regression. First, we propose three extensions of the standard Single Node GP, namely (1) a selection strategy for choosing nodes to be mutated based on depth and performance of the nodes, (2) operators for placing a compact version of the best-performing graph to the beginning and to the end of the population, respectively, and (3) a local search strategy with multiple mutations applied in each iteration. All the proposed modifications have been experimentally evaluated on five symbolic regression benchmarks and compared with standard GP and SNGP. The achieved results are promising showing the potential of the proposed modifications to improve the performance of the SNGP algorithm. We then propose two variants of hybrid SNGP utilizing a linear regression technique, LASSO, to improve its performance. The proposed algorithms have been compared to the state-of-the-art symbolic regression methods that also make use of the linear regression techniques on four real-world benchmarks. The results show the hybrid SNGP algorithms are at least competitive with or better than the compared methods.	algorithm;benchmark (computing);experiment;genetic programming;high- and low-level;iteration;lasso;local optimum;local search (optimization);rate of convergence;symbolic regression	Jirí Kubalík;Eduard Alibekov;Jan Zegklitz;Robert Babuska	2016	Trans. Computational Collective Intelligence	10.1007/978-3-662-53525-7_4	mathematical optimization;machine learning;algorithm	AI	26.928234090334158	-2.747717678378182	91172
9d30d6a8a1d6f055c05983bfac2ee8922b0a4312	kudu herd optimization	sociology statistics optimization lead particle swarm optimization vectors standards;standards;vectors;lead;particle swarm optimization;statistics;genetic algorithms;optimization;search problems;particle swarm optimisation;sociology;high dimensional problems kudu herd optimization unconstrained numeric optimization continuous spaces candidate solutions search space population based algorithms artificial bee colony differential evolution genetic algorithm particle swarm optimization;search problems genetic algorithms particle swarm optimisation	This work proposes a new and simple algorithm for unconstrained numeric optimization over continuous spaces. A population of candidate solutions styled as a herd of kudus performs a succession of jumps through the search space in order to find the best solution (the kudu is a species of antelope). The logic of this algorithm is quite different from that of most population-based algorithms, as the individual solutions are moved together in a herd-like fashion. Performance comparisons are conducted with the Artificial Bee Colony, Differential Evolution, the Genetic Algorithm and Particle Swarm Optimization on benchmark functions. The kudu herd seems to perform well in the early stages and on high-dimensional problems.	benchmark (computing);complementarity theory;constrained optimization;differential evolution;exploit (computer security);genetic algorithm;iteration;mathematical optimization;particle swarm optimization;scalability;succession	Julien Boelaert	2012	2012 6th IEEE International Conference Intelligent Systems	10.1109/IS.2012.6335199	mathematical optimization;multi-swarm optimization;test functions for optimization;meta-optimization;swarm intelligence;engineering;derivative-free optimization;artificial intelligence;machine learning;imperialist competitive algorithm;particle swarm optimization;metaheuristic	Robotics	26.315452705431692	-5.052506666168951	91187
71711fdf4ea415090cd3d310736ca532e8c49a1d	a novel non-lyapunov approach through artificial bee colony algorithm for detecting unstable periodic orbits with high orders	non lyapunov;artificial bee colony algorithm;unstable periodic orbits;non negative functions minimization	In this paper, a novel non-Lyapunov way is proposed to detect the unstable periodic orbits (UPOs) with high orders by a new artificial bee colony algorithm (ABC). And UPOs with high orders of nonlinear systems, are one of the most challenging problems of nonlinear science in both numerical computations and experimental measures. The proposed method maintains an effective searching mechanism with fine equilibrium between exploitation and exploration. To improve the performance for the optimums of the multi-model functions and to avoid the coincidences among the UPOs with different orders, we add the techniques as function stretching, deflecting and repulsion to ABC. The problems of detecting the UPOs are converted into a non-negative functions' minimization through a proper translation, which finds a UPO such that the objective function is minimized. Experiments to different high orders UPOs of 5 wellknown and widely used nonlinear maps indicate that the proposed algorithm is robust, by comparison of results through the ABC and quantum-behaved particle swarm optimization (QPSO), respectively. And it is effective even in cases where the Newton-family algorithms may not be applicable. Density of the orbits are discussed. Simulation results show that ABC is superior to QPSO, and it is a successful method in detecting the UPOs, with the advantages of fast convergence, high precision and robustness.	artificial bee colony algorithm;control theory;lyapunov fractal;sensor	Fei Gao;Feng-xia Fei;Yanfang Deng;Yibo Qi;Ilangko Balasingham	2012	Expert Syst. Appl.	10.1016/j.eswa.2012.04.083	mathematical optimization;computer science;artificial intelligence;mathematics;artificial bee colony algorithm;algorithm	DB	29.415119390984675	-4.6407257652473355	91229
2781785c373e4970b4183f69669ecae80e2e037d	afsaocp: a novel artificial fish swarm optimization algorithm aided by ocean current power	artificial swarm algorithm;swarm intelligence;ocean current power;optimization problem	Artificial Fish Swarm is a kind of swarm intelligence algorithm, which focuses on the behavior of individual fishes and information interactions among them during foraging and preying on something in real environment. A novel Artificial Fish Swarm Optimization Algorithm Aided by Ocean Current Power (abbreviation for AFSAOCP) is proposed, which assumes the ocean current always causes certain influence on the fishes’ activity speed. Firstly, the computing model of ocean current is developed and constructed. Then the influence level of the ocean current on fishes is analyzed. If fishes are swimming along ocean current direction, ocean current will drive fishes’ speed increment, which is called positive influence; if fishes are swimming against ocean current, the current will hinder the fishes’ speed, which is called negative influence. In addition, fishes’ speed is not influenced by the ocean current, which is called merits offset faults. To sum this up, fishes in each group have different speed range, respectively. Grouping strategies can not only increase species diversity, but it can also make the algorithm escape from local optimal value in the iteration process. The proposed variant, AFSAOCP, is examined on several widely used benchmarked functions, and the experimental results show that the proposed AFSAOCP algorithm improves the existing performance of other algorithms when dealing with the different dimension and multimodal problems.	algorithm;benchmark (computing);iteration;mathematical optimization;multimodal interaction;optimization problem;program optimization;swarm intelligence;xslt/muenchian grouping	Hong-Bo Wang;Chengcheng Fan;Xu-Yan Tu	2016	Applied Intelligence	10.1007/s10489-016-0798-7	artificial intelligence	AI	27.624125577907336	-3.9764931969368966	91641
440b43f901391bfc30e96a4b1679dfe3d16136ac	image encryption based on a genetic algorithm and a chaotic system			chaos theory;encryption;genetic algorithm	Xiaoqiang Zhang;Xuesong Wang;Yuhu Cheng	2015	IEICE Transactions		discrete mathematics;theoretical computer science	EDA	38.391741569619974	-7.804743819489445	91649
7ef526edfccfcf2478d60a3ab9c005a3f554cb85	improving the preformance of genetic algorithms through derandomization	computational complexity;genetics;genetic algorithm	Genetic algorithms are believed by some to be very eecient optimization and adaptation tools. So far, the eecacy of genetic algorithms has been described by empirical results, and yet theoretical approaches are far behind. This paper aims at raising fundamental theoretical questions about the utility and performance of genetic algorithms from an algorithmic point of view, i.e., space requirements and computational complexity. These questions originate from various existing theories and the no-free-lunch theorem, which compares all possible optimization procedures with respect to an equal distribution of all possible objective functions. While these questions are open at least in part, they all strongly indicate that genetic algorithms are less eecient than other (determinis-tic) optimization algorithms. From an algorithmic point of view, the no-free-lunch theorem suggests that the random application of variation operators signiicantly degrades the performance of genetic algorithms , since resampling of already visited points is not avoided. Consequently, this paper proposes a simple transformation that is strictly more eecient than the equivalent genetic algorithm.	computational complexity theory;genetic algorithm;mathematical optimization;no free lunch in search and optimization;no free lunch theorem;randomized algorithm;requirement	Ralf Salomon	1997	Software - Concepts and Tools		genetic algorithm;computer science;theoretical computer science;computational complexity theory	Theory	28.87210354483834	2.227874436238174	91744
e4ac95a3626aeda38098760cbf9075b1e2e16d40	fixed-point digital iir filter design using multi-objective optimization evolutionary algorithm	optimal solution;linear phase;loss of control;order;iir filter;multi objective optimization;multi objective evolutionary algorithm;digital infinite impulse response iir filter;optimization problem;design method;infinite impulse response;evolutionary algorithm;local search;multi objective optimization problem	The research of designing floating-point digital infinite-impulse response (IIR) filter using multi-objective optimization evolutionary algorithm (MOEA) is a newly emerged research field. However, none of previous work takes notice of the fixed-point representation in the MOEA based digital IIR filter design research. In this paper, we introduce fixed-point representation in a new local search operator enhanced multi-objective evolutionary algorithm (LS-MOEA), which is specifically proposed for multi-objective optimization digital IIR filter design problems, to form a new version LS-MOEA with floating-point representation (LS-MOEA-FR). The effectiveness and efficiency of LS-MOEA-FR is verified on four types of digital IIR filter design problems, including low pass (LP), high pass (HP), band pass (BP) and band stop (BS).	evolutionary algorithm;evolutionary computation;filter design;fixed point (mathematics);fixed-point arithmetic;infinite impulse response;least squares;local search (optimization);low-pass filter;moea framework;mathematical optimization;multi-objective optimization	Yu Wang;Bin Li;Yunbi Chen	2010	2010 IEEE Youth Conference on Information, Computing and Telecommunications	10.1016/j.asoc.2010.05.034	adaptive filter;mathematical optimization;digital filter;computer science;2d filters;evolutionary algorithm;root-raised-cosine filter;linear filter;control theory;mathematics;filter design;infinite impulse response	EDA	31.398164068876543	-4.420115934366096	91831
34598613eb0c44ad46519d87a9ceabdf6bc83e0a	the self-adaptive comprehensive learning particle swarm optimizer.	self-adaptive comprehensive learning particle;particle swarm optimization;swarm optimizer;search commences;control parameter;optimization problem;test function;position vector;wide range;appropriate value	self-adaptive comprehensive learning particle;particle swarm optimization;swarm optimizer;search commences;control parameter;optimization problem;test function;position vector;wide range;appropriate value		Adiel Ismail;Andries Petrus Engelbrecht	2012		10.1007/978-3-642-32650-9_14	mathematical optimization;multi-swarm optimization;artificial intelligence;machine learning;particle swarm optimization;metaheuristic	Robotics	26.263230757071206	-4.605299086277449	91920
13cd551db7c9df523f454553d2a386cafdeec819	effective evolutionary algorithms for many-specifications attainment: application to air traffic control tracking filters	metodo caso peor;agregacion;nonlinear filters;multicriteria analysis;multiobjective programming;programmation multiobjectif;air traffic control;concepcion ingenieria;engineering design;pistage;controleur trafic;evolutionary computation;traffic controller;design engineering;non linear filter;optimization technique;uncertainty;helium;conception ingenierie;trafico aereo;multicriteria design;filters;rastreo;optimum global;evolutionary computation air traffic control filters design engineering design optimization delta modulation proposals uncertainty pareto analysis;tracking filters;global optimum;algoritmo genetico;delta modulation;design optimization;aggregation;nonlinear tracking filter;multiobjective evolutionary algorithm;tracking movable target;resolucion problema;tracking filters air traffic control evolutionary computation nonlinear filters;regulation trafic aerien;evolution strategies;methode cas pire;algorithme genetique;agregation;evolution strategy;algorithme evolutionniste;multiobjective optimization;genetic algorithm;global optimization;algoritmo evolucionista;filtro no lineal;supervisor trafico;poursuite;analisis multicriterio;multiply specified tracking filters evolution strategies multicriteria design multiobjective optimization;analyse multicritere;evolutionary algorithm;trafic aerien;worst case method;proposals;optimo global;air traffic;multiply specified tracking filters;tracking;air traffic control tracking filter;filtre non lineaire;persecucion y continuacion;pareto analysis;problem solving;resolution probleme;fitness function;evolutionary computing;fitness function evolutionary algorithm air traffic control tracking filter optimization technique nonlinear tracking filter;programacion multiobjetivo	This paper addresses a real-world engineering design requiring the application of effective and global optimization techniques. The problem it deals with is the design of nonlinear tracking filters under up to several hundreds of performance specifications. The suitability of different evolutionary computation techniques for solving multiobjective problems is explored, contrasting the performance achieved with recent multiobjective evolutionary algorithm (MOEAs) proposals and different aggregation schemes. In particular, a new scheme is proposed to build a fitness function based on an operator that selects worst cases of multiple specifications in different situations. They have been evaluated in the design of an air traffic control (ATC) tracking filter that should accomplish a specific normative with 264 specifications. Results show their performance in terms of effectiveness and computational load, comparing their capability to scale the problem with respect to problem size.	activity tracker;advanced transportation controller;analysis of algorithms;best, worst and average case;converge;crowding;dominating set;engineering design process;evolutionary algorithm;evolutionary computation;fitness function;global optimization;gradient descent;moea framework;mathematical optimization;multi-objective optimization;nonlinear system;numerical analysis;offset binary;parallel coordinates;pareto efficiency;performance;qualitative comparative analysis;random search;search algorithm;simulation;sorting	Jesús García Herrero;Antonio Berlanga;José M. Molina López	2009	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2008.920677	mathematical optimization;simulation;computer science;artificial intelligence;air traffic control;machine learning;evolutionary computation	Robotics	33.18384419821243	-5.222001375843403	92008
921410c3cd9cca5546c6261a3ec9b1f2d4d6f25b	an incorporated constrained differential evolution algorithm and its application on parameter identification of machine joint surfaces		In this paper, an incorporated constrained differential evolution algorithm based on Invasive Weed Optimisation (IWCDE) had been proposed. The IWCDE algorithm is based on the standard differential evolution algorithm and incorporates the Invasive Weed Optimisation Algorithm. The IWCDE algorithm proposed the new mutation strategy and the strategy of u0027Infeasible individual evolutionu0027. The proposed algorithm was compared with several other evolutionary algorithms, the results showed that the proposed algorithm could overcome the premature convergence efficiently and had better global convergence and robustness. Finally, the paper established the optimisation model of parameter identification on machine joint surfaces, solved the problem by the IWCDE algorithm.	algorithm;differential evolution	Qing-Bo Lu;Li-Qin Liu;Xue-Liang Zhang	2017	IJWMC	10.1504/IJWMC.2017.10008210	robustness (computer science);differential evolution;mathematical optimization;evolutionary algorithm;computer science;algorithm;convergence (routing);new mutation;premature convergence	ML	26.997321665211704	-3.975189813344045	92049
cfc106570bf5739d38b34affee8cdb2996908c77	multiobjective environment/economic power dispatch using evolutionary multiobjective optimization		Environmental/economic dispatch (EED) problems play a salient role in the power system, which can be defined as a complex constrained optimization problem. Many different methods have been introduced to handle EED problems and got some inspiring positive results in the research. In this paper, a new multiobjective global best artificial bee colony (ABC) algorithm is proposed to tackle multiobjective EED problems. To manipulate this problem effectively, we propose a global best ABC algorithm to generate the new individual to speed up the convergence of the proposed algorithm. Afterwards, a crowding distance assignment approach is employed to evolve the population. Finally, a straightforward constraint checking procedure is used to tackle those different constraints of EED problems. Experimental results can conclude that MOGABC can provide best solutions in solving multiobjective EED problems.	artificial bee colony algorithm;constrained optimization;constraint (mathematics);crowding;dynamic dispatch;mathematical optimization;multi-objective optimization;optimization problem	Shijing Ma;Yunhe Wang;Yinghua Lv	2018	IEEE Access	10.1109/ACCESS.2018.2795702	evolutionary computation;multi-objective optimization;mathematical optimization;electric power system;constrained optimization;distributed computing;economic dispatch;computer science;linear programming;convergence (routing);population	EDA	24.790453797873827	-3.5243125038762426	92106
0df8ffbce2cb1698c94863ec90a837b1610cd9a2	new computer methods for global optimization (h. ratschek and j. rokne)	computational method;global optimization		global optimization	Faiz A. Al-Khayyal;Panos M. Pardalos	1991	SIAM Review	10.1137/1033168	discrete optimization;multidisciplinary design optimization;mathematics	Theory	26.77949272910892	0.028629374844724796	92222
e561e79d214509d595b4af9d97fded60379479a9	synthesis of heat-integrated complex distillation systems via genetic programming	hierarchical structure;genetic program;genetic programming;synthesis;chemical engineering;domain knowledge;complex distillation system	This paper addresses the application of Genetic Programming (GP) to the synthesis of heat-integrated complex distillation system and the owsheet of complex separation can be expressed directly using GP’s special hierarchical structure. A series of unique encoding method and olution strategy is proposed and some evolutionary factor is improved based on the domain knowledge of chemical engineering. A shortcut ethod is applied to calculate all required design parameters. Conventional and complex columns, thermally coupled (linked) side strippers and ide rectifiers, fully thermally coupled columns as well as heat integration between any different columns are simultaneously considered. Two llustrating examples are presented to demonstrate the effective computational strategies. 2007 Elsevier Ltd. All rights reserved.	column (database);genetic programming;keyboard shortcut;rectifier	Xiao-Hong Wang;Yu-Gang Li;Yang-Dong Hu;Yinglong Wang	2008	Computers & Chemical Engineering	10.1016/j.compchemeng.2007.10.009	control engineering;genetic programming;computer science;engineering;artificial intelligence;domain knowledge	AI	34.469924033771015	-0.1405245801642317	92645
348859e8cc6a9241bc3df518a100df3f3dcba3de	evopol: a framework for optimising social regulation policies	cybernetics;programming and algorithm theory;policy analysis;fuzzy control;knowledge management;genetics;optimization problem;decision support system;fuzzy rule base;neuro fuzzy;adaptive method;fuzzy inference;membership function;evolutionary algorithm;neural network;design methodology;knowledge base	Purpose – This paper aims to propose a novel computational framework called EvoPOL (EVOlving POLicies) to support governmental policy analysis in restricting recruitment of smokers. EvoPOL is a fuzzy inference-based decision support system that uses an evolutionary algorithm (EA) to optimize the if-then rules and its parameters. The performance of the proposed method is compared with a fuzzy inference method adapted using neural network learning technique (neuro-fuzzy). Design/methodology/approach – EA is a population-based adaptive method, which may be used to solve optimization problems, based on the genetic processes of biological organisms. The Takagi-Sugeno fuzzy decision support system was developed based on three sub-systems: fuzzification, fuzzy knowledge base (if-then rules) and defuzzification. The fine-tuning of the fuzzy rule base and membership function parameters is achieved by using an EA. Findings – The proposed EvoPOL technique is simple and efficient when compared to the neuro-fuzzy approach. However, EvoPOL attracts extra computational cost due to the population-based hierarchical search process. When compared to neuro-fuzzy model the error values on the test sets have improved considerably. Hence, when policy makers require more accuracy EvoPOL seems to be a good solution. Originality/value – When policy makers require more accuracy EvoPOL seems to be a good solution. For complicated decision support systems involving more input variables, EvoPOL would be an excellent candidate for framing if-then rules with precise decision scores that could help the government representatives as to what extent to concentrate on available social regulation measures in restricting the recruitment of smokers.	adaptive neuro fuzzy inference system;algorithmic efficiency;artificial neural network;decision support system;defuzzification;evolutionary algorithm;framing (world wide web);fuzzy logic;fuzzy rule;fuzzy set;knowledge base;machine learning;mathematical optimization;monte carlo method;neuro-fuzzy;optimization problem;rule-based system;search algorithm	Ajith Abraham;Sonja Petrovic-Lazarevic;Ken Coghill	2006	Kybernetes	10.1108/03684920610662601	optimization problem;knowledge base;decision support system;membership function;cybernetics;defuzzification;design methods;adaptive neuro fuzzy inference system;fuzzy classification;computer science;artificial intelligence;policy analysis;neuro-fuzzy;machine learning;evolutionary algorithm;data mining	ML	25.07671160923615	-7.603903757532572	92876
f763f52fd98d4c37f3db7f9086aef8a83688e8f4	a variant of differential evolution based on permutation regulation mechanism	permutation regulation mechanism;differential evolution;search method;optimization problem;learning strategies	Differential evolution (DE) is a stochastic, population based search method, which has emerged as a powerful tool for solving optimization problems. This paper presents a novel algorithm based on traditional DE and permutation regulation mechanism to enhance the performance of DE. As a kind of enhanced learning strategy, the permutation regulation mechanism, which makes efforts in the evolving, is constructed by rearranging the selected three father vectors. In order to verify the performance of the proposed algorithm, two experiments on some well-known benchmark functions are conducted. Performance compared with other three DE variants confirms that the new algorithm outperforms better in terms of solution accuracy.	differential evolution	Dazhi Jiang;Hui Wang;Zhijian Wu	2010		10.1007/978-3-642-16493-4_8	mathematical optimization;artificial intelligence;mathematics;algorithm	Crypto	26.933150558177484	-4.373610651547718	92896
f7be092dc8628d0a012e105830538c80d9081002	reuse of waste energy from power plants in greenhouses through mas-based architecture		Today, most energy-intensive processes have a high degree of optimization. However, in some of these processes large amounts of energy are inevitably released due to the way in which this energy is used. One of the most obvious examples is produced in the power plants during the process of obtaining electrical energy through the transformation of some kind of energy (chemical, kinetic, thermal, lighting, and nuclear or solar energy, among others). This released energy can be used in other processes that may need it so that no additional energy is needed. One of the possible uses of this energy is its use in greenhouses. Greenhouses need large amounts of energy to recreate the climatic conditions that crops need, which are not those of the weather station. To take advantage of the energy released from the power stations in greenhouses, a system based on agents has been developed that manages energy and allows it to be reused. This paper explains how the system allows us to reuse energy by a power plant and how the agents that integrate the system by means of communication with sensors and actuators and the use of data analysis algorithms allow us to use this energy in greenhouses, providing a reduction of the energy they need without the system. The system has been tested in several greenhouses with a pepper crop.		Alfonso González-Briones;Pablo Chamoso;Sara Rodríguez;Hyun Yoe;Juan Manuel Corchado	2018	Wireless Communications and Mobile Computing	10.1155/2018/6170718	distributed computing;architecture;kinetic energy;computer science;architectural engineering;power station;electric potential energy;reuse;greenhouse;solar energy	Mobile	36.44531604477252	-5.395097732132739	92925
f55b38bb39ff6ed0b1f01cdd16ae0e7a0adc744b	refining the phase transition in combinatorial search	search method;graph coloring;constraint satisfaction;phase transition;structure prediction;search cost	Abstract   Many recent studies have identified phase transitions from under- to overconstrained instances in classes of constraint satisfaction search problems, and their relation to search cost. For example, cases that are difficult to solve with a variety of search methods are concentrated near these transitions. These studies show that a simple parameter describing the problem structure predicts the difficulty of solving the problem, on average. However, this prediction is associated with a large variance and depends on the somewhat arbitrary choice of the problem class. Thus these results are of limited direct use for individual instances. To help address this limitation, additional parameters, describing problem structure as well as heuristic effectiveness, are introduced. These are shown to reduce the variation in some cases. This also provides further insight into the nature of intrinsically hard search problems.	combinatorial search	Tad Hogg	1996	Artif. Intell.	10.1016/0004-3702(95)00050-X	phase transition;beam search;mathematical optimization;combinatorics;constraint satisfaction;machine learning;search cost;graph coloring;mathematics;incremental heuristic search;combinatorial search	AI	28.196580713615926	3.163309692161749	92999
0c3ffd5f1b577e38604f361ee71feb312b5b0cab	solving constraint satisfaction problems through belief propagation-guided decimation	random graph;statistical mechanics;message passing algorithms;satisfiability;constraint satisfaction;artificial intelligent;statistical physics;computational complexity;belief propagation;constraint satisfaction problem;disordered system;neural network;numerical simulation	Message passing algorithms have proved surprisingly successful in solving hard constraint satisfaction problems on sparse random graphs. In such applications, variables are fixed sequentially to satisfy the constraints. Message passing is run after each step. Its outcome provides an heuristic to make choices at next step. This approach has been referred to as ‘decimation,’ with reference to analogous procedures in statistical physics. The behavior of decimation procedures is poorly understood. Here we consider a simple randomized decimation algorithm based on belief propagation (BP), and analyze its behavior on random k-satisfiability formulae. In particular, we propose a tree model for its analysis and we conjecture that it provides asymptotically exact predictions in the limit of large instances. This conjecture is confirmed by numerical simulations.	backtracking;belief propagation;boolean satisfiability problem;complex systems;computation;computer simulation;constrained optimization;constraint (mathematics);constraint satisfaction problem;decimation (signal processing);http 404;heuristic;integrated project support environment;message passing;numerical analysis;performance;pseudocode;random graph;randomized algorithm;software propagation;sparse matrix;time complexity	Andrea Montanari;Federico Ricci-Tersenghi;Guilhem Semerjian	2007	CoRR		random graph;mathematical optimization;combinatorics;constraint satisfaction;statistical mechanics;computer science;constraint graph;artificial intelligence;theoretical computer science;machine learning;constraint satisfaction dual problem;mathematics;complexity of constraint satisfaction;computational complexity theory;constraint satisfaction problem;artificial neural network;hybrid algorithm;statistics;belief propagation;satisfiability	AI	28.99794428627856	3.508657639684771	93018
f1de240e216e29f86e40eb53441ac51add5419a6	improving firefly algorithm performance using fuzzy logic		Exploration and exploitation are two strategies used to search the problem space in Evolutionary Algorithms (EAs). To significantly increase the performance of these optimization techniques in terms of the solution optimality is to strike the right balance between exploration and exploitation. Firefly is one of the most favored EAs. In this study, we introduce an entire fuzzy system to tune dynamically the firefly parameters in order to keep the exploration and exploitation in balance in each of the searching steps. A serious concern of EAs is to be stuck in local optimum solutions. The proposed fuzzy controller helps the firefly algorithm to converge to the optimal solution and escape from local optimums. To evaluate the eificiency of the fuzzy-based firefly algorithm, we conduct experiments on a set of high dimensional benchmark functions. The goal here is to compare the new firefly method with the standard firefly and well-known nature-inspired optimization algorithms. The results of the experiments show the superiority of the proposed Fuzzy firefly algorithm over the standard one.	benchmark (computing);converge;evolutionary algorithm;experiment;exploit (computer security);firefly (cache coherence protocol);firefly algorithm;fuzzy control system;fuzzy logic;local optimum;mathematical optimization;problem domain	Mahdi Bidar;Samira Sadaoui;Malek Mouhoub;Mohsen Bidar	2017	2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2017.8122931	local optimum;artificial intelligence;fuzzy logic;firefly algorithm;machine learning;algorithm design;control theory;fuzzy control system;firefly protocol;computer science;evolutionary algorithm	Robotics	26.62753540233454	-4.572602543385128	93066
ef96f446eec1ac84c7362367c22b6c91de94111f	differential cryptanalysis of feal4 using evolutionary algorithm		This paper presents a differential cryptanalysis attack on the Fast Data Encipherment Algorithm (FEAL4) reduced to four rounds, using an Evolutionary Algorithm (EA). The main purpose of the developed attack is to find six subkeys of the encryption algorithm, which will be used to decipher the captured ciphertext. Furthermore, an additional heuristic negation operator was introduced to improve local search of EA. The algorithm is based on a chosen-plaintext attack. In order to improve an effectiveness, the attack uses the differential cryptanalysis techniques. The results of the developed algorithm were compared against a corresponding Hill Climbing (HC), Simple Evolutionary Algorithm (SEA) and Brute Force (BF) attacks.	differential cryptanalysis;evolutionary algorithm	Kamil Dworak;Urszula Boryczka	2016		10.1007/978-3-319-45246-3_10	computer science;artificial intelligence;ciphertext;machine learning;cryptography;operator (computer programming);encryption;differential cryptanalysis;local search (optimization);evolutionary algorithm;hill climbing	Crypto	27.480165448748817	-2.1498164315566615	93097
8aa28f4104ecc633d6e93d37c1fe607e3244c0fc	analysis of the distribution of individuals in modified genetic algorithms	fuzzy logic controller;function optimization;artificial intelligent;fuzzy logic;artificial intelligence;genetic algorithm;genetic algorithms	The article presents the results of the analysis of the distribution of individuals in a modified genetic algorithm for solving function optimization problems. In the proposed modification of the genetic algorithm, we use the fuzzy logic controller (FLC). The authors proposed the FLC, which estimates all individuals in the population and modifies the probability of the selection to the parents' pool and the probability of the mutation of their genes. In the article we present the results of the analysis of the distribution of individuals in all generations of the algorithm. We compared the results of the elementary algorithm and the algorithm with the adaptation of the selection and mutation probabilities. The new algorithm has been tested on a number of sophisticated functions with satisfactory results.	genetic algorithm	Krzysztof Pytel;Tadeusz Nawarycz	2010		10.1007/978-3-642-13232-2_24	meta-optimization;genetic algorithm;cultural algorithm;computer science;artificial intelligence;machine learning;mathematics;algorithm;population-based incremental learning	ECom	26.930879914475145	-6.784261267635341	93175
2c2cf0dea8f3e309a96a699fa2dbc8144cd10f86	two-layer particle swarm optimization for unconstrained optimization problems	high dimensionality;evolutionary learning method;optimization problem;particle swarm optimizer;particle swarm optimization;unconstrained optimization;evolutionary learning	In this article, a two-layer particle swarm optimization (TLPSO) is proposed to increase the diversity of the particles so that the drawback of trapping in a local optimum is avoided. In order to design the TLPSO, a structure with two layers (top layer and bottom layer) is proposed so that M swarms of particles and one swarm of particles are generated in the bottom layer and the top layer, respectively. Each global best position in each swarm of the bottom layer is set to be the position of the particle in the swarm of the top layer. Therefore, the global best position in the swarm of the top layer influences indirectly the particles of each swarm in the bottom layer so that the diversity of the particles increases to avoid trapping into a local optimum. Besides, a mutation operation is added into the particles of each swarm in the bottom layer so that the particles leap the local optimum to find the global optimum. Finally, some optimization problems of different types of high dimensional functions are used to illustrate the efficiency of the proposed method.	mathematical optimization;particle swarm optimization	Chia-Chong Chen	2011	Appl. Soft Comput.	10.1016/j.asoc.2009.11.020	optimization problem;mathematical optimization;multi-swarm optimization;computer science;artificial intelligence;machine learning;particle swarm optimization;metaheuristic	EDA	27.25389985396509	-4.135875317309626	93235
841a166edf8a6bfc0c9c85edca7e0d4b01d11576	adaptive bacterial foraging optimization algorithm based on social foraging strategy	bacterial foraging optimization algorithm;multimodal numerical optimization;social foraging	In 2002, K. M. Passino proposed Bacterial Foraging Optimization Algorithm (BFOA) for distributed optimization and control. Biologic foraging strategies are diverse. Based on social and intelligent foraging theory, this paper proposed an adaptive bacterial foraging optimization algorithm, and introduced six foraging operators: chaos run operator, assimilation run operator, tumble operator, swimming operator, reproduction operator and elimination-dispersal operator. Among those operators, chaos run operator, assimilation run operator and reproduction operator were redefined in accordance with social foraging strategy. And others were same with the original algorithm. Experiments were conducted on 10 multimodal unconstrained benchmark optimization problems for demonstration the effectiveness and stability. The results demonstrate remarkable performance of the proposed algorithm on all chosen benchmark functions when compared to several successful optimization techniques.		Hai Shen;Yunlong Zhu	2014	JNW	10.4304/jnw.9.3.799-806	artificial intelligence	DB	26.528237787888543	-4.089701092382602	93279
85d944ca14dcbc5e36ac326fb58c1fadbdc322b3	asic implementation of a nonlinear dynamical model for hippocampal prosthesis		A hippocampal prosthesis is a very large scale integration (VLSI) biochip that needs to be implanted in the biological brain to solve a cognitive dysfunction. In this letter, we propose a novel low-complexity, small-area, and low-power programmable hippocampal neural network application-specific integrated circuit (ASIC) for a hippocampal prosthesis. It is based on the nonlinear dynamical model of the hippocampus: namely multi-input, multi-output (MIMO)–generalized Laguerre-Volterra model (GLVM). It can realize the real-time prediction of hippocampal neural activity. New hardware architecture, a storage space configuration scheme, low-power convolution, and gaussian random number generator modules are proposed. The ASIC is fabricated in 40 nm technology with a core area of 0.122 mm2 and test power of 84.4 μW. Compared with the design based on the traditional architecture, experimental results show that the core area of the chip is reduced by 84.94% and the core power is reduced by 24.30%.	application-specific integrated circuit;artificial neural network;biochip;biological neural networks;cognition disorders;convolution;core (optical fiber);dynamical system;impaired cognition;implants;integrated circuit device component;low-power broadcasting;mimo;mimo-ofdm;nonlinear system;normal statistical distribution;numerous;prosthesis implantation;random number generation;real-time clock;very-large-scale integration;square millimeter (qualifier value)	Zhitong Qiao;Yan Han;Xiaoxia Han;Han Xu;Will X. Y. Li;Dong Song;Theodore W. Berger;Ray C. C. Cheung	2018	Neural Computation	10.1162/neco_a_01107	very-large-scale integration;application-specific integrated circuit;chip;mathematical optimization;mathematics;hardware architecture;artificial neural network;computer hardware;integrated circuit;convolution;hippocampal prosthesis	EDA	38.6084948508088	-1.541573794713185	93353
84575ed4a9aa7a6dbee694246f9419edf98053e9	a simple yet efficient function optimizer	optimisation;parameter vector;point location;population size;genetic mutations ant colony optimization particle swarm optimization genetic algorithms mathematics educational institutions evolutionary computation birds simulated annealing;mutation probability function optimizer function optimization algorithm water flowing water flow optimization parameter vector;function optimization;computational fluid dynamics;function optimizer;optimisation computational fluid dynamics;mutation probability;water flowing;water flow;optimal algorithm;water flow optimization;function optimization algorithm	A new function optimization algorithm inspired by water flowing to the lowest point was proposed. We call it water flow optimization (WFO). No matter wherever the global lowest point locates could water find it if only enough water was poured into. We propose WFO by imitating the process of water flowing to the global lowest point. In this new algorithm, a population of parameter vector standing for a solution to the function optimization problem move to an attractive center which is continuously transferring. Verified by function optimization experiments, it is an efficient optimization algorithm. With an apt mutation probability, the WFO algorithm could efficiently avoid getting trapped by local optima, and it could find global optimum quickly and accurately as well. In addition, the algorithm has only two parameters: the population size and the mutation probability.	algorithm;experiment;global optimization;local optimum;mathematical optimization;mutation (genetic algorithm);optimization problem;performance	Xinsheng Lai	2007	Third International Conference on Natural Computation (ICNC 2007)	10.1109/ICNC.2007.138	mathematical optimization;artificial intelligence;machine learning;mathematics	EDA	28.20582465868306	-5.739912753434357	93406
cbe403b19c0a2eadf035826be913c7a3cafbe44f	astute image encryption and decryption using modified secure image encryption algorithm (m-sip)	image encryption;ioim;cpld;scale function;emi;vme;symmetric encryption;color image	With rapid development in digitalized technology the use of images has become a major necessity of the technology oriented world. This has led to the use of highly secured and integrated images. This paper intends to enhance the security of images by using Modified Secure Image Encryption (M-SIP) and compare its efficiency with Secure Image Encryption (SIP). M-SIP intelligently encrypts as well as decrypts the images in a less complex manner. The pixels of an image in M-SIP undergo symmetric encryption by converting Color Image to Grayscale Image, Baker's Transformation function, XOR gray scale function, inverse gray scale function and Shift function. For secure decryption the above steps are implemented in reverse order.	color image;encryption;exclusive or;grayscale;pixel;symmetric-key algorithm	Akshay Wattal;Anjali Agarwal;Ankit Kathuria	2010		10.1145/1741906.1742176	multiple encryption;computer vision;disk encryption theory;40-bit encryption;disk encryption;computer science;theoretical computer science;link encryption;filesystem-level encryption;on-the-fly encryption;disk encryption hardware;deterministic encryption;computer security;encryption;probabilistic encryption	Vision	38.652848682521984	-9.562993308791915	93450
75d5c28237aac48cbae991cdb404715c2987c929	impact of the topology on the performance of distributed differential evolution		Migration topology plays a key role in designing effective distributed evolutionary algorithms. In this work we investigate the impact of several network topologies on the performance of a stepping–stone structured Differential Evolution model. Although some issues on the control parameters of the migration process and the way they affect the efficiency of the algorithm and the solution quality deserve further evaluative study, the influence of the topology on the performance both in terms of solution quality and convergence rate emerges from the empirical findings carried out on a set of test problems.		Ivanoe De Falco;Antonio Della Cioppa;Domenico Maisto;Umberto Scafuri;Ernesto Tarantino	2014		10.1007/978-3-662-45523-4_7	rate of convergence;differential evolution;evolutionary algorithm;network topology;mathematics;topology	Metrics	25.271862099051155	-5.343184139075893	93708
55af17ad690573274dbb8cd0786e6aac5126c8d9	mass distribution, vehicle structures, light-weighting and optimization			shadow volume	Mike Blundell;Jesper Christensen	2015		10.3233/978-1-61499-576-0-358	mass distribution;mathematical optimization;mathematics;weighting	Theory	34.12806618203562	-1.9192017827972179	93718
c2fb541c404480d800dbd5f90784a2656ec8feb6	a direct search algorithm for global optimisation of multivariate functions	global optimisation;direct search		global optimization;global serializability;mathematical optimization;search algorithm	K. K. Benke;D. R. Skinner	1991	Australian Computer Journal		computer science	Vision	26.771957273083	0.2603676088564029	94039
e8b2c94605d41901f0ed2864fa3d5e08cb3d6b50	adaptive fireworks algorithm based on two-master sub-population and new selection strategy		Adaptive Fireworks Algorithm (AFWA) is an effective algorithm for solving optimization problems. However, AFWA is easy to fall into local optimal solutions prematurely and it also provides a slow convergence rate. In order to improve these problems, the purpose of this paper is to apply two-master sub-population (TMS) and new selection strategy to AFWA with the goal of further boosting performance and achieving global optimization. Our simulation compares the proposed algorithm (TMSFWA) with the FWA-Based algorithms and other swarm intelligence algorithms. The results show that the proposed algorithm achieves better overall performance on the standard test functions.	fireworks algorithm	Xi-Guang Li;Shou-Fei Han;Liang Zhao;Changqing Gong	2017		10.1007/978-3-319-70093-9_8	rate of convergence;global optimization;boosting (machine learning);swarm intelligence;fireworks;algorithm;computer science;population;optimization problem	EDA	26.840627056142672	-3.9493614783341866	94048
5feff74cc29f37fcf96594bc079448437fd8ae48	an enhanced firefly algorithm for function optimisation problems	stochastic factor;firefly algorithm;function optimisation problems;virtual standard space;adaptive randomness;fine gained evaluation strategy;fa	An enhanced firefly algorithm (EFA) is proposed to improve the performance of the standard firefly algorithm (FA). After analysing the impacts of the attraction and the randomisation parameter in FA’s movement, we introduce three improvement strategies. First, a virtual standard space is constructed to eliminate the negative influence generated by the long distance between two fireflies. Second, the randomisation parameter in FA’s movement is replaced by a stochastic factor, which is integrated into FA’s attractiveness to produce adaptive randomisation. Finally, a fine-grained evaluation strategy is applied to deal with the negative mutual influence among different dimensions. The experiments carried on classic and shifted benchmark functions show that the proposed EFA performs significantly better than standard FA in terms of both convergent speed and solution precision.	firefly algorithm;mathematical optimization	Xiaoyu Lin;Yiwen Zhong;Hui Zhang	2013	IJMIC	10.1504/IJMIC.2013.052298	mathematical optimization;simulation;computer science;engineering;artificial intelligence;firefly algorithm	Vision	28.69842685144544	-4.208406564420285	94290
bdd765ce272589bb15497792f883449d4a3b7c2f	particle swarm optimization based diophantine equation solver	velocity;fermat s equation;position;numerical solution;elliptic curves;s equation;diophantine equation;pso;learning factors;bio inspired computation;numerical analysis;particle swarm optimizer;socio cognitive coefficients;fermat;particle swarm optimisation;fitness function;evolutionary computing	The paper introduces particle swarm optimization as a viable strategy to find numerical solution of Diophantine equation, for which there exists no general method of finding solutions. The proposed methodology uses a population of integer particles. The candidate solutions in the feasible space are optimised to have better positions through particle best and global best positions. The methodology, which follows fully connected neighbourhood topology, can offer many solutions of such equations.	mathematical optimization;numerical partial differential equations;particle swarm optimization;solver	Siby Abraham;Sugata Sanyal;Mukund A. Sanglikar	2010	IJBIC	10.1504/IJBIC.2010.032126	mathematical optimization;mathematical analysis;fermat's last theorem;numerical analysis;computer science;position;diophantine equation;mathematics;geometry;elliptic curve;velocity;particle swarm optimization;fitness function;evolutionary computation	EDA	29.503745545741488	-2.031355088648789	94369
45ad474d1bffc6dee42d2c12d1d63c5bda2f073c	integration of constraint programming and evolution programs: application to channel routing	optimisation sous contrainte;constrained optimization;genetic operator;routing;search space;arc consistency;physical design;algoritmo genetico;constraint satisfaction;interconnection network;optimizacion con restriccion;satisfaction contrainte;very large scale integrated circuit;constraint programming;algorithme genetique;algorithme evolutionniste;genetic algorithm;encaminamiento;satisfaccion restriccion;evolutionary algorithm;red interconexion;acheminement;reseau interconnexion	This paper presents a novel approach for the integration of constraint programming techniques and evolution programs. In this approach the genetic operators implementation is based on a constraint solver, and chromosomes are arc-consistent solutions to the problem, represented as arrays of finite integer domains. This method allows to tackle efficiently constrained optimisation problems over finite integer domains with a large search space. The paper describes the main issues arising in this integration: chromosome representation and evaluation, selection and replacement strategies, and genetic operators design. The implemented system has been applied to the channel routing problem, a particular kind of the interconnection routing problem, one of the major tasks in the physical design of very large scale integration circuits.		Alvaro Ruiz-Andino;José J. Ruz	1998		10.1007/3-540-64582-9_775	physical design;mathematical optimization;constraint programming;routing;constrained optimization;genetic algorithm;constraint satisfaction;computer science;artificial intelligence;genetic operator;evolutionary algorithm;mathematics;algorithm;local consistency	Robotics	25.050090292192984	2.896181159986708	94383
813afc5d2ad1e0c6ac326c3a4594a776b27b5527	chaotic whale optimizer variants for parameters estimation of the chaotic behavior in permanent magnet synchronous motor				Dalia Yousri;Dalia Allam;M. B. Eteiba	2019	Appl. Soft Comput.	10.1016/j.asoc.2018.10.032		Robotics	32.267920648979626	-5.420494608837723	94541
d7311850690a5ba315518fa55e27a8b48fe7664b	hybrid distributed real-coded genetic algorithms	algorithm performance;sistema hibrido;algorithm analysis;algoritmo genetico;resolucion problema;resultado algoritmo;algorithme reparti;performance algorithme;hybrid system;algorithme genetique;distributed genetic algorithm;genetic algorithm;algoritmo repartido;analyse algorithme;distributed algorithm;analisis algoritmo;real coded genetic algorithm;problem solving;resolution probleme;systeme hybride	1 I n t r o d u c t i o n Distributed genetic algorithms (DGAs) are one of the most important representatives of methods based on spatial separation ([4, 16, 21]). Their basic idea lies in the partit ion of the population into several subpopulations (whose sizes are relatively small), each one of them being processed by a genetic algorithm (GA), independently from the others. A migration mechanism produces a chromosome exchange between the subpopulations. These algorithms show two determinant advantages: The preservation of the diversity due to the semi-isolation of the subpopulations, which may stand up to the premature convergence problem, and They may be easily implemented on parallel hardware, obtaining, in this way, substantial improvements on computational time. DGAs may be assigned to the following two categories with regards to the subpopulation homogeneity ([14]): * This research has been partially supported by CICYT TIC96-0778 and DGICYT SAB95-0473.	computation;genetic algorithm;premature convergence;semiconductor industry;software release life cycle;time complexity	Francisco Herrera;Manuel Lozano;Claudio Moraga	1998		10.1007/BFb0056902	quality control and genetic algorithms;distributed algorithm;mathematical optimization;crossover;genetic algorithm;computer science;artificial intelligence;genetic representation;mathematics;distributed computing;chromosome;algorithm;hybrid system	Theory	27.06073133965284	1.4615007229882881	94721
c431f9b99b64424e271726b1f78af466b93c3237	a novel numerical optimization algorithm inspired from weed colonization	numerical optimization;simulated annealing;memetic algorithm;multi dimensional;stochastic optimization;particle swarm optimizer;nonlinear multi dimensional functions;power optimization;evolutionary algorithms;genetic algorithm;global optimization;invasive weed optimization;evolutionary algorithm;direct search;local minima;optimal algorithm	This paper introduces a novel numerical stochastic optimization algorithm inspired from colonizing weeds. Weeds are plants whose vigorous, invasive habits of growth pose a serious threat to desirable, cultivated plants making them a threat for agriculture. Weeds have shown to be very robust and adaptive to change in environment. Thus, capturing their properties would lead to a powerful optimization algorithm. It is tried to mimic robustness, adaptation and randomness of colonizing weeds in a simple but effective optimizing algorithm designated as Invasive Weed Optimization (IWO). The feasibility, the efficiency and the effectiveness of IWO are tested in details through a set of benchmark multi-dimensional functions, of which global and local minima are known. The reported results are compared with other recent evolutionary-based algorithms: genetic algorithms, memetic algorithms, particle swarm optimization, and shuffled frog leaping. The results are also compared with different versions of simulated annealing — a generic probabilistic meta-algorithm for the global optimization problem — which are simplex simulated annealing, and direct search simulated annealing. Additionally, IWO is employed for finding a solution for an engineering problem, which is optimization and tuning of a robust controller. The experimental results suggest that results from IWO are better than results from other methods. In conclusion, the performance of IWO has a reasonable performance for all the test functions.	algorithm;mathematical optimization	Ali Reza Mehrabian;Caro Lucas	2006	Ecological Informatics	10.1016/j.ecoinf.2006.07.003	mathematical optimization;genetic algorithm;simulated annealing;computer science;artificial intelligence;machine learning;maxima and minima;evolutionary algorithm;power optimization;metaheuristic;memetic algorithm	EDA	26.79840538014236	-5.687475736691297	94814
393ac986170a17c8b2894ccaa738fde5dad72558	validation of a dynamic planning navigation strategy applied to mobile terrestrial robots	autonomous navigation;dynamic planning;genetic algorithms;mobile robots	This work describes the performance of a DPNA-GA (Dynamic Planning Navigation Algorithm optimized with Genetic Algorithm) algorithm applied to autonomous navigation in unknown static and dynamic terrestrial environments. The main aim was to validate the functionality and robustness of the DPNA-GA, with variations of genetic parameters including the crossover rate and population size. To this end, simulations were performed of static and dynamic environments, applying the different conditions. The simulation results showed satisfactory efficiency and robustness of the DPNA-GA technique, validating it for real applications involving mobile terrestrial robots.		C Dealmeida Silva;Átila V F M de Oliveira;Marcelo A. C. Fernandes	2018		10.3390/s18124322		Robotics	30.371818307327807	-6.921622048136905	95427
6982422d2450549edeff346c7ce56dba41f81a61	parallel feature selection algorithm based on rough sets and particle swarm optimization	stochastic processes approximation theory computational complexity data mining feature selection mathematical operators particle swarm optimisation rough set theory scheduling;parallel asynchronous particle swarm optimization feature selection rough sets particle swarm optimization;algorytmy;mathematical functions;accuracy;particle swarm optimization equations sociology statistics program processors rough sets accuracy;particle swarm optimization;statistics;funkcje matematyczne;zbiory przyblizone;rough sets;algorithms;program processors;sociology;uci repository parallel feature selection algorithm rough sets particle swarm optimization data mining problems computational complexity reduct approximation stochastic metaheuristic mathematical operators parallel asynchronous version scheduling calculations complex fitness function slave processors	The aim of this paper is to propose a new method of solving feature selection problem. Foundations of presented algorithm lie in the theory of rough sets. Feature selection methods based on rough sets have been used with success in many data mining problems, but their weakness is their computational complexity. In order to overcome the above-mentioned problem, researches used diverse approximation techniques. This paper presents a new approach to approximation of reducts. Particle swarm optimization (PSO) is a stochastic metaheuristic similar to genetic algorithms. The idea is to see each potential solution as a particle with certain velocity flying through the problem space. The PSO finds optimal solutions by interactions of individuals in population. The main advantage of the PSO over genetic algorithms, is that PSO does not require complex operators such as crossover or mutation. It only uses simple mathematical operators to update position and velocity of each particle, which makes PSO computationally inexpensive in terms of both memory and runtime. The presented feature selection algorithm treats each feature subset as separate particle. Optimal subset, in terms of selected measure, is discovered as particles fly within the problem space. In order to speed up calculations and balance usage of hardware resources (processors, memory), parallel asynchronous version of PSO is applied. It is based on scheduling calculations of complex fitness function on slave processors, while the main one is responsible for updating particles data and checking algorithm's convergence. Applied approach scales well and provides balanced usage of given resources even if it is not feasible to use the same computational power of every processor, for instance when used resources are not homogeneous. Proposed method was tested on selected set of data sets from the UCI repository and results were compared to some of the classical algorithms.	approximation;central processing unit;cluster analysis;coefficient;computation;computational complexity theory;crossover (genetic algorithm);data compression;data mining;feature selection;fitness function;genetic algorithm;interaction;mathematical optimization;metaheuristic;monomial;mutation (genetic algorithm);numerical analysis;particle swarm optimization;population;problem domain;rough set;rule 184;scheduling (computing);selection algorithm;speedup;velocity (software development)	Mateusz Adamczyk	2014	2014 Federated Conference on Computer Science and Information Systems	10.15439/2014F389	mathematical optimization;multi-swarm optimization;rough set;computer science;theoretical computer science;machine learning;mathematics;accuracy and precision;particle swarm optimization;function;metaheuristic;statistics	AI	29.144581303041093	-6.4208386244214966	95545
f738e67e399d2f485e2c25331560cae750acdda8	pso based memetic algorithm for unimodal and multimodal function optimization	fitness information;memetic algorithm;proposed memetic algorithm;genetic algorithm;memetic process;best fitness value;good exploration capability;individual learning;multimodal function optimization;better performance;proposed algorithm	fitness information;memetic algorithm;proposed memetic algorithm;genetic algorithm;memetic process;best fitness value;good exploration capability;individual learning;multimodal function optimization;better performance;proposed algorithm	memetic algorithm;memetics;multimodal interaction;particle swarm optimization	Swapna Devi;Devidas G. Jadhav;Shyam S. Pattnaik	2011		10.1007/978-3-642-27172-4_16	mathematical optimization;artificial intelligence;machine learning;mathematics;memetic algorithm	Vision	26.058293473922348	-4.456984876773845	95601
36c81cebda6d42bbbd985f453299bd6cf4f4eff0	a novel rough set reduct algorithm to feature selection based on artificial fish swarm algorithm		With the purpose of finding the minimal reduct, this paper proposes a novel feature selection algorithm based on artificial fish swarm algorithm (AFSA) hybrid with rough set (AFSARS). The proposed algorithm searches the minimal reduct in an efficient way to observe the change of the significance of feature subsets and the number of selected features, which is experimentally compared with the quick reduct and other hybrid rough set methods such as genetic algorithm (GA), ant colony optimization (ACO), particle swarm optimization (PSO) and chaotic binary particle swarm optimization (CBPSO). Experiments demonstrate that the proposed algorithm could achieve the minimal reduct more efficiently than the other methods.	algorithm;feature selection;rough set;swarm	Fei Wang;Jiao Xu;Lian Li	2014		10.1007/978-3-319-11897-0_4	machine learning;pattern recognition;data mining	Robotics	26.54804625859074	-3.055683495755084	95723
5e8a948c6b3b576259015b0849592c41d59dd603	iterated local search with guided mutation	genetic mutations iterative algorithms data mining electronic design automation and methodology sun computer science evolutionary computation testing algorithm design and analysis heuristic algorithms;iterated local search;iterative methods;quadratic assignment problem iterated local search guided mutation distribution algorithms estimation global statistical information;estimation of distribution algorithm;search problems iterative methods;quadratic assignment problem;search problems	Guided mutation uses the idea of estimation of distribution algorithms to improve conventional mutation operators. It combines global statistical information and the location information of good individual solutions for generating new trial solutions. This paper suggests using guided mutation in iterative local search. An experimental comparison between a conventional iterated local search (CILS) and an iterated local search with guided mutation has been conducted on four classes of the test instances of the quadratic assignment problem.	estimation of distribution algorithm;experiment;guided local search;heuristic (computer science);iterated function;iterated local search;iteration;local optimum;local search (optimization);metaheuristic;mutation (genetic algorithm);quadratic assignment problem	Qingfu Zhang;Jianyong Sun	2006	2006 IEEE International Conference on Evolutionary Computation	10.1109/CEC.2006.1688410	beam search;mathematical optimization;combinatorics;estimation of distribution algorithm;computer science;artificial intelligence;local search;machine learning;iterated local search;mathematics;iterative deepening depth-first search;iterative method;quadratic assignment problem;guided local search	Robotics	26.113249556292363	-1.9910811488880764	95749
8588e36f15a311c487925d1249ad419561a7f3a5	some modifications to enhance the performance of artificial bee colony	optimization algorithm design and analysis tin particle swarm optimization radiation detectors convergence benchmark testing;diversity;artificial bee colony;rank selection;ant colony optimisation;convergence;radiation detectors;particle swarm optimization;colony size reduction;rank selection strategy artificial bee colony abc algorithm real parameter optimization foraging behaviour colony size population size reduction mechanism evolutionary process perturbation scheme population diversity;optimization;rank selection artificial bee colony colony size reduction diversity;tin;algorithm design and analysis;benchmark testing	The Artificial Bee Colony (ABC) algorithm, proposed by Karaboga in 2005 for real-parameter optimization, is a recently introduced optimization algorithm which simulates the foraging behaviour of a bee colony. The proposed variant employs colony size (population size) reduction mechanism during the evolutionary process. Then modification is done to enhance the perturbation scheme. Further, in order to improve the population diversity and avoid the premature convergence, rank selection strategy is applied and analyzed through simulation. The results show that the modified algorithm outperforms the basic ABC algorithm.	artificial bee colony algorithm;benchmark (computing);dijkstra's algorithm;genetic algorithm;mathematical optimization;numerical analysis;premature convergence;simulation	Tarun Kumar Sharma;Millie Pant;Jagdish Chand Bansal	2012	2012 IEEE Congress on Evolutionary Computation	10.1109/CEC.2012.6252993	algorithm design;benchmark;mathematical optimization;ant colony optimization algorithms;meta-optimization;convergence;tin;computer science;artificial intelligence;artificial bee colony algorithm;particle detector;particle swarm optimization;metaheuristic	EDA	27.0169025134278	-4.8468225473979	95774
af70f66f056cd50d17bad36787b6ca56fabbfe5f	minimal criterion coevolution: a new approach to open-ended search		Recent studies have emphasized the merits of search processes that lack overarching objectives, instead promoting divergence by rewarding behavioral novelty. While this less objective search paradigm is more open-ended and divergent, it still differs significantly from nature's mechanism of divergence. Rather than measuring novelty explicitly nature is guided by a single, fundamental constraint: survive long enough to reproduce. Surprisingly, this simple constraint produces both complexity and diversity in a continual process unparalleled by any algorithm to date. Inspired by the relative simplicity of open-endedness in nature in comparison to recent non-objective algorithms, this paper investigates the extent to which interactions between two coevolving populations, both subject to their own constraint, or minimal criterion, can produce results that are both functional and diverse even without any behavior characterization or novelty archive. To test this new approach, a novel maze navigation domain is introduced wherein evolved agents must learn to navigate mazes whose structures are simultaneously coevolving and increasing in complexity. The result is a broad range of maze topologies and successful agent trajectories in a single run, thereby suggesting the viability of minimal criterion coevolution as a new approach to non-objective search and a step towards genuinely open-ended algorithms.	archive;constraint algorithm;interaction;nonlinear gameplay;population;programming paradigm;vergence	Jonathan C. Brant;Kenneth O. Stanley	2017		10.1145/3071178.3071186	computer science;artificial intelligence;novelty;machine learning;network topology;coevolution;artificial life	AI	25.292287030116263	-9.408558290197197	95785
83a747d1931d745b5ea847480733341549e8a999	estimating parameters of van genuchten equation based on teaching-learning-based optimization algorithm		The Van Genuchten Equation (VGE) is used to describe the characteristic of soil water movement, but it is super-set, nonlinear and containing many unknown parameters. Using the traditional method to estimate the parameters of VGE often results in a high margin of error because of complication. The teaching-learning-based optimization (TLBO) is a new swarm intelligent optimization method for solving complex nonlinear models. In this paper, the solution program of TLBO is compiled and used to estimate parameters of the VGE. The results show that the estimate method by TLBO is more efficient and accurate. Consequently, TLBO can be used as a new method to estimate parameters of VGE.	algorithm;estimation theory;optimization problem	Fahui Gu;Kangshun Li;Lei Yang;Wei Li	2015		10.1007/978-981-10-0356-1_35	mathematical optimization	Vision	31.999137965861614	-7.2765344644087735	95835
9a184f6c165f093ff2cb2f7dcd74cdaf7ded9533	on the analysis of performance of the improved artificial-bee-colony algorithm	artificial bee colony;swarm intelligence;multimodal function with high dimensionality swarm intelligence artificial bee colony numerical optimization;fixed point theorem;high dimensionality;multimodal function with high dimensionality;performance analysis algorithm design and analysis artificial intelligence space technology equations tin information analysis automation educational institutions genetics;banach space;numerical optimization;multimodal engineering problems artificial bee colony algorithm search iteration operator fixed point theorem contractive mapping banach spaces artificial colony algorithm multivariable benchmark functions global optimization;banach spaces;evolution biology;multimodal engineering problems;indexes;artificial bee colony algorithm;search problems artificial intelligence banach spaces;mathematical model;artificial intelligence;global optimization;optimization;artificial colony algorithm;search problems;contractive mapping;multivariable benchmark functions;algorithm design and analysis;benchmark testing;search iteration operator	This paper introduces an improved artificial colony algorithm. In the algorithm, a new search iteration operator based on the fixed point theorem of Contractive Mapping in Banach Spaces is proposed. In this work, the improved artificial colony algorithm is used to 10 multivariable benchmark functions. The simulation results show that the algorithm possesses an excellent performance in the global optimization, and can be efficiently employed to solve the multimodal engineering problems with high dimensionality.	artificial bee colony algorithm;benchmark (computing);fixed point (mathematics);fixed-point theorem;global optimization;iteration;mathematical optimization;multimodal interaction;simulation;spaces	Haiyan Quan;Xinling Shi	2008	2008 Fourth International Conference on Natural Computation	10.1109/ICNC.2008.211	mathematical optimization;ramer–douglas–peucker algorithm;artificial intelligence;machine learning;mathematics;fsa-red algorithm;difference-map algorithm;population-based incremental learning	Robotics	26.909389775628842	-7.121780497764573	96070
abd62d2203c78fa0d8925f117c010986d791b2c6	a membrane-genetics algorithm for multi-objective optimization problems		This paper proposes a multi-objective optimization algorithm based on the membrane computing. Inspired by the theory of membrane optimization, the membrane structure, multiple sets and reaction rules is employed to tackle multi-objective optimization issues. Aiming at adaptability of algorithm, the cross-over and mutation mechanism of the genetic algorithm are introduced to combine with membrane framework. Moreover, for the sake of improving the diversity of global search solution, the non-dominated sorting and crowding distance are used to update external archive. The experimental results demonstrate that the proposed algorithm is not only practicable and efficient but also capable of obtaining the approximate Pareto front in KUR and ZDT test function.	approximation algorithm;archive;benchmark (computing);computation;crowding;distribution (mathematics);genetic algorithm;mapreduce;mathematical optimization;membrane computing;multi-objective optimization;paradiseo;pareto efficiency;spark;simulation;software release life cycle;sorting	Taowei Chen;Yiming Yu;Kun Zhao;Zhibing Yu	2017	2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)	10.1109/CISP-BMEI.2017.8302326	genetic algorithm;multi-objective optimization;adaptability;membrane;test functions for optimization;membrane computing;algorithm;computer science;sorting	Robotics	25.609016085680903	-4.884086134521668	96209
ddf7226fa03d61bd3fdb1439b1921c30be41ed6b	hybrid invasive weed optimization algorithm for parameter estimation of pharmacokinetic model	two compartment model;pharmacokinetics;hooke jeeves;invasive weed optimization;parameter optimization	Given that the traditional methods of estimating pharmacokinetic parameters are constrained by the sensitivity of their initial value and incapability of evolutionary algorithm to determine search range, this paper proposes a hybrid invasive weed optimization (HIWO) algorithm by combining the Hooke–Jeeves (HJ) and invasive weed optimization (IWO) algorithm. Using the HIWO algorithm for the parameter optimization by the experiment of extravascular administration two-compartment model, we can see that the proposed method is not only better than traditional feathering method (FM) in terms of numerical stability, but also better than HJ and IWO in terms of error minimization. The experimental results show that HIWO algorithm is a feasible method to optimize the pharmacokinetic parameters, which has higher precision and stronger robustness than the other techniques.	estimation theory;evolutionary algorithm;fm broadcasting;feathering;heterojunction;hooke's atom;horner's method;mathematical model;mathematical optimization;multi-compartment model;nl (complexity);numerical aperture;numerical stability;pattern search (optimization);xfig	Tan Deng;Keqin Li	2017	IJPRAI	10.1142/S0218001417590030	mathematical optimization;simulation;meta-optimization;artificial intelligence;pharmacokinetics	AI	31.494011184672406	-5.138682034664174	96218
10d5a77eebd09528eed288d60b59ef0275070460	adaptation and ruggedness in an evolvability landscape	evolvability landscape	Evolutionary processes depend on both selection—how fit any given individual may be, and on evolvability—how and how effectively new and fitter individuals are generated over time. While genetic algorithms typically represent the selection process explicitly by the fitness function and the information in the genomes, factors affecting evolvability are most often implicit in and distributed throughout the genetic algorithm itself, depending on the chosen genomic representation and genetic operators. In such cases, the genome itself has no direct control over evolvability except as determined by its fitness. Researchers have explored mechanisms that allow the genome to affect not only fitness but also the distribution of offspring, thus opening up the potential of evolution to improve evolvability. In prior work [1] we demonstrated that effect with a simple model focusing on heritable evolvability in a changing environment. In our current work [2], we introduce a simple evolvability model, similar in spirit to those of Evolution Strategies. In addition to genes that determine the fitness of the individual, in our model each individual contains a distinct set of ‘evolvability genes’ that determine the distribution of that individual’s potential offspring. We also present a simple dynamic environment that provides a canonical ‘evolvability opportunity’ by varying in a partially predictable manner. That evolution might lead to improved evolvability is far from obvious, because selection operates only on an individual’s current fitness, but evolvability by definition only comes into play in subsequent generations. Two similarly-fit individuals will contribute about equally to the next generation, even if their evolvabilities vary drastically. Worse, if there is any fitness cost associated with evolvability, more evolvable individuals might get squeezed out before their advantages could pay off. The basic hope for increasing evolvability is circumstances where weak selective pressure allows diverse individuals to contribute offspring to the next generation, and then those individuals with better evolvability in the current generation will tend to produce offspring that will dominate in subsequent fitness competitions. In this way, evolvability advantages in the ancestors can lead to fitness advantages in the descendants, which then preserves the inherited evolvability mechanisms. A common tool for imagining evolutionary processes is the fitness landscape, a function that maps the set of all genomes to a single-dimension real fitness value. Evolution is seen as the process of discovering peaks of higher fitness, while avoiding valleys of low fitness. If we can derive a scalar value that plau-	evolution strategy;evolvability (computer science);fitness function;genetic algorithm;genetic operator;map;next-generation network;selection (user interface)	Terry Van Belle;David H. Ackley	2003		10.1007/3-540-45105-6_18	artificial intelligence;machine learning;computer science;evolvability	HCI	25.699064129049184	-8.746637648588642	96379
d547711930338d61b278ad77ce54c4c7782de3e8	artificial fish swarm optimization algorithm based on mixed crossover strategy	local search strategy;hybrid algorithm;artificial intelligence;optimization algorithm;hybrid algorithm-artificial fish swarm;engineering optimization;mixed crossover strategy;optimization problem;artificial fish swarm optimization;artificial fish swarm algorithm;artificial fish	The nonlinear constrained optimization problems have been widely used in many fields, such as engineering optimization and artificial intelligence. According to the deficiency of artificial fish swarm algorithm (AFSA), that the artificial fishes walk around aimlessly and randomly or gather in non-global optimal points, a hybrid algorithm-artificial fish swarm optimization algorithm based on mixed crossover strategy is presented. By improving the artificial fish's behaviors, the genetic operation of mixed crossover strategy is used as a local search strategy of AFSA. So the efficiency of local convergence of AFSA is improved, and the algorithm's running efficiency and solution quality are improved obviously. Based on test verification for typical functions, it is shown that the hybrid algorithm has some better performance such as fast convergence and high precision.	algorithm;swarm	Li-yan Zhuang;Jing-qing Jiang	2013		10.1007/978-3-642-39068-5_45	mathematical optimization;multi-swarm optimization;artificial intelligence;machine learning	EDA	27.497752284641383	-4.156495377791215	96510
718ff0ebe8ebb54b9f999be715ed532e3d6890bb	stochastic simulation based genetic algorithm for chance constraint programming problems with some discrete random variables			constraint programming;genetic algorithm;simulation	R. K. Jana;M. P. Biswal	2004	Int. J. Comput. Math.	10.1080/0020716042000272584		AI	33.63090924986486	3.4258129038461504	96742
5098710bb9b4a211a3d93754aedcfd01aae2f7b7	supervised learning of an opto-magnetic neural network with ultrashort laser pulses		The explosive growth of data and its related energy consumption is pushing the need to develop novel, brain-inspired and energy-efficient schemes and materials for data processing and storage. Here, we demonstrate experimentally that Co/Pt films can be used as artificial synapses by manipulating their magnetization state using circularly-polarized ultrashort optical pulses at room temperature. We also show an efficient implementation of supervised perceptron learning on an opto-magnetic neural network, built from such magnetic synapses. Importantly, we demonstrate that the optimization of synaptic weights can be achieved using a global feedback mechanism, such that the learning does not rely on external storage or additional optimization schemes. These results suggest there is high potential for realizing artificial neural networks using optically-controlled magnetization in technologically relevant materials, that can learn not only fast but also energy-efficient.	artificial neural network;circular polarization;experiment;external storage;feedback;mathematical optimization;perceptron;supervised learning;synapse;synaptic weight	Arghya Chakravarty;J. H. Mentink;Charli S. Davies;K. Yamada;A. V. Kimel;Th. Rasing	2018	CoRR			ML	38.912254849659035	-0.7123423430137862	96744
fc1714a30384cd4c27715cec322e04d94005882b	modified bat algorithm with quaternion representation	research outputs;optimisation evolutionary computation number theory;research publications;quaternions particle swarm optimization optimization sociology statistics linear programming;particle swarm optimization;statistics;linear programming;optimization;bat algorithm quaternion swarm intelligence evolutionary computation representation of individuals;evolutionary algorithms modified bat algorithm quaternion representation complex numbers theoretical physics fast rotation calculations optimization swarm intelligence family;sociology;quaternions	This paper introduces a modified bat algorithm using quaternion representation of individuals. Quaternions are a number system, which extends complex numbers. They are successfully applied to problems of theoretical physics and to those areas needing fast rotation calculations. We propose the application of quaternions in optimization, more precisely, we have been using quaternions for representation of individuals in bat algorithm belonging to a swarm intelligence family. It is expected that the problems with stagnation in swarm intelligence should be reduced or even eliminated. We believe that this representation could successfully be applied also to the other swarm intelligence and evolutionary algorithms.	abc;bat algorithm;benchmark (computing);business architecture;computation;evolutionary algorithm;linear algebra;mathematical optimization;swarm intelligence;whole earth 'lectronic link	Iztok Fister;Janez Brest;Iztok Fister;Xin-She Yang	2015	2015 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2015.7256930	mathematical optimization;multi-swarm optimization;combinatorics;linear programming;artificial intelligence;machine learning;mathematics;particle swarm optimization;metaheuristic;quaternion	Vision	25.361191085811935	0.059049872806423494	96915
27f237aecebfba3beadcf8a683f0aa8e2f031a09	a combined deterministic and sampling-based sequential bounding method for stochastic programming	rule theory;computational result;sampling-based sequential bounding method;combined deterministic;two-stage stochastic programming;control variate variance reduction;asymptotically valid confidence interval;right-hand side;random vector;optimal objective function value;stratified monte carlo sampling procedure;stopping rule theory;deterministic-based sequential bounding method;control variate variance reduction scheme;convex second stage program;jensen inequality;lower bounds;monte carlo methods;sampling methods;approximation method;sampling-based sequential;proposed solution;deterministically valid lower bound;stochastic programming;upper bound estimator;upper bound;linear approximation;approximation algorithms;confidence interval;monte carlo method;variance reduction;monte carlo sampling;lower bound;jensen s inequality;control variates;vectors;objective function	We develop an algorithm for two-stage stochastic programming with a convex second stage program and with uncertainty in the right-hand side. The algorithm draws on techniques from bounding and approximation methods as well as sampling-based approaches. In particular, we sequentially refine a partition of the support of the random vector and, through Jensen's inequality, generate deterministically valid lower bounds on the optimal objective function value. An upper bound estimator is formed through a stratified Monte Carlo sampling procedure that includes the use of a control variate variance reduction scheme. The algorithm lends itself to a stopping rule theory that ensures an asymptotically valid confidence interval for the quality of the proposed solution. Computational results illustrate our approach.	algorithm;approximation;computation;control variates;jensen's inequality;loss function;monte carlo method;optimization problem;sampling (signal processing);social inequality;stochastic programming;variance reduction	Péguy Pierre-Louis;Güzin Bayraksan;David P. Morton	2011	Proceedings of the 2011 Winter Simulation Conference (WSC)		mathematical optimization;combinatorics;mathematics;approximation algorithm;statistics;monte carlo method	Robotics	35.68872336651289	3.6907623407952976	96978
23e37ee5bfd6769cdb79d13bde794d567af0635c	evaluation mode research on particle swarm optimization algorithm	control systems;intelligent particle swarm optimization;evaluation indexes;design optimization;function optimization problems;computer networks;function optimization;search problems artificial intelligence function evaluation particle swarm optimisation;evaluation mode;artificial neural networks;particle swarm optimizer;population dynamic;function evaluation;particle swarm optimization;particle swarm optimization intelligent networks competitive intelligence artificial intelligence algorithm design and analysis computer networks control systems design optimization artificial neural networks optimization methods;indexation;function optimization problems evaluation indexes intelligent particle swarm optimization basal evaluation index system population dynamics;population dynamics;population dynamics particle swarm optimization evaluation mode general optimization performance;competitive intelligence;basal evaluation index system;artificial intelligence;search problems;intelligent networks;particle swarm optimization algorithm;general optimization performance;particle swarm optimisation;algorithm design and analysis;evaluation model;optimization methods	This paper presents a series of evaluation indexes for intelligent particle swarm optimization based on the basal evaluation index system in the field of intelligent optimization. A kind of evaluation model used to evaluate synthetically the general optimization performance and population dynamics of particle swarm optimization is proposed. This evaluation model is simulated and validated by function optimization problems.	algorithm;particle swarm optimization	Qi Kang;Lei Wang;Hui Xiao;Qidi Wu	2007		10.1109/ICNSC.2007.372891	probabilistic-based design optimization;algorithm design;mathematical optimization;intelligent network;multi-swarm optimization;multidisciplinary design optimization;test functions for optimization;meta-optimization;computer science;engineering;derivative-free optimization;artificial intelligence;machine learning;population dynamics;continuous optimization;imperialist competitive algorithm;particle swarm optimization;metaheuristic	Robotics	26.784357477452126	-7.302146880032115	97010
7b797391f6ed8d0f8f5ad24e5931826dadd71322	a chaos based image encryption and lossless compression algorithm using hash table and chinese remainder theorem	chaos;chinese remainder theorem;hash table;lorenz equations;hyper chaos	A chaos based image encryption and lossless compression algorithm using hash table and Chinese Remainder Theorem is proposed. Initially, the Henon map is used to generate the scrambled blocks of the input image. The scrambled block undergoes a fixed number of iterations based on the plain image using Arnold cat map. Since hyper chaos system has complex dynamical characteristics than chaos, the confused image is further permuted using the index sequence generated by the hyper chaos along with hash table structure. The permuted image is divided into blocks and the diffusion is carried out either eywords: haos hinese Remainder Theorem orenz equations yper chaos ash table by using Lorenz equations or by using another complex matrix generated from the plain image appropriately. Along with diffusion, compression is also carried out by Chinese Remainder Theorem for each block. This encryption algorithm has high key space, good NPCR and UACI values and very less correlation among adjacent pixels. Simulation results show the high effectiveness and security features of the proposed algorithm. © 2015 Elsevier B.V. All rights reserved.	algorithm;arnold's cat map;chaos theory;encryption;hash table;hénon map;iteration;key space (cryptography);lorenz system;lossless compression;norm (social);pixel;simulation	M. Brindha;N. Ammasai Gounden	2016	Appl. Soft Comput.	10.1016/j.asoc.2015.09.055	arithmetic;hash table;combinatorics;discrete mathematics;computer science;lorenz system;chinese remainder theorem;mathematics	Robotics	38.628423352885264	-8.562947339699706	97353
9644b48311e39ff62367794380a6b981286de1cd	delayed chaotic neural network with annealing controlling for maximum clique problem	maximum clique problem;chaotic dynamics;journal;delayed self feedback connection;chaotic neural network	In this paper, we propose a delayed chaotic neural network with annealing controlling strategies (DCNNAC) to solve the NP-complete maximum clique problem (MCP). We point out some flaws in the variable delayed neural network proposed by Chen, and demonstrate that DCNN-AC is a powerful chaotic neural network through analyzing its single neural model and its “beautiful” chaotic dynamics. DCNN-AC has richer and more flexible chaotic dynamics and flexible annealing controlling strategies, so that it can be expected to have higher searching ability for globally optimal or near-optimal solutions. The DCNN-AC performance has been verified by simulations on some MCP benchmark instances. The comparisons with some famous proximate algorithms show the superiority of DCNN-AC in terms of the solution quality and the comparable computation time. & 2013 Elsevier B.V. All rights reserved.	algorithm;artificial neural network;benchmark (computing);biological neuron model;chaos theory;clique (graph theory);clique problem;combinatorial optimization;complex network;computation;current sense amplifier;entity–relationship model;flexible-fuel vehicle;hopfield network;mathematical optimization;maxima and minima;np-completeness;simulated annealing;simulation;solid-state drive;time complexity	Gang Yang;Junyan Yi	2014	Neurocomputing	10.1016/j.neucom.2013.08.036	artificial intelligence;theoretical computer science;machine learning;mathematics	AI	30.669747091758275	3.4267752248491052	97680
19c3fbe8f1832fdcd69fbc5bb2a516ebdd587b39	computing epistasis of template functions through walsh transforms	walsh transform	Manuscript received 21 May 2004; revised 2 May 2005Abstract. Template functions have been introduced as a class of test functions,allowing to study the convergence behaviour of genetic algorithms. In this note,we show how to use Walsh transforms to calculate the normalized epistasis of thesefunctions.Keywords: Genetic algorithm, GA hardness, epistasis, Walsh transform, Fouriertransform, template function	hadamard transform	Maria Teresa Iglesias;Concepción Vidal;Alain Verschoren	2005	Computers and Artificial Intelligence		genetic algorithm;theoretical computer science;epistasis;hadamard transform;artificial intelligence;machine learning;mathematics;walsh matrix	AI	32.68815506252237	-1.149486006906072	97794
20781bd6353fee43066e69fe64823899a9df89cc	on favoring positive correlations between form and quality of candidate solutions via the emergence of genomic self-similarity	representation;emergence;genomic self similarity;self organization;genetic algorithm;proportional genetic algorithm;evolutionary algorithm;fitness function;stochastic search	A key property for the effectiveness of stochastic search techniques, including evolutionary algorithms, is the existence of a positive correlation between the form and the quality of candidate solutions. In this paper, we show that when the ordering of genomic symbols in a genetic algorithm is completely independent of the fitness function and therefore free to evolve along the candidate solutions it encodes, the resulting genomes self-organize into self-similar structures that favor this key stochastic search property.	emergence;evolutionary algorithm;fitness function;genetic algorithm;self-organization;self-similarity;stochastic optimization	Ivan I. Garibay;Annie S. Wu;Ozlem O. Garibay	2005		10.1145/1068009.1068204	mathematical optimization;self-organization;genetic algorithm;cultural algorithm;computer science;bioinformatics;artificial intelligence;evolutionary algorithm;representation;fitness function;emergence	AI	25.978151685294712	-8.619264351797714	97808
cc8622a35c4df4cff5350016e97d6c6b863fc6fc	the application of gls algorithm to 2 dimension irregular-shape cutting problem	local search algorithm;genetics;computer experiment	This paper describes the application of the Genetics Local Search Algorithm (GLS) to the 2 Dimension irregular-shape Cutting Problem. We describe different recombination operators used to generate feasible solutions, as well as an algorithm that can be used to rotate figures in this problem. In our case, each offspring resulting from a recombination is a starting point for local optimization. The resulting solutions are permutations of the figure labels (i.e. sequence-coding). One of the distinctive features of our method is a specific representation of figures, in which a 32 bit binary vector is transformed into an integer value. Figures obtained in this way are then placed on the strip (encoded in the same way) in order to obtain the final solution. The paper includes results of computational experiments demonstrating the efficiency of the proposed approach.	algorithm;generalized least squares	Luiza Budzynska;Pawel Kominek	2004		10.1007/978-3-540-24688-6_160	mathematical optimization;combinatorics;computer experiment;computer science;artificial intelligence;local search;machine learning;mathematics;algorithm;statistics	Theory	24.610018462140488	0.4841528557038902	97915
d6fca88605230c8846c28e7ad03a3adce85de1c3	gaussian global-best harmony search algorithm for optimization problems		In this paper, a novel optimization approach is proposed using Gaussian distribution function to improve harmony search (HS) algorithm, namely “Gaussian global-best harmony search” (GGHS) algorithm. The harmony memory (HM) is adjusted using Gaussian random generation in GGHS. The GGHS algorithm consists of two adjustment steps; in the first stage, the harmony memory is adjusted by a dynamic bandwidth and the Gaussian distribution with a mean of 0 and a standard deviation of 1. In the second stage, the best memory is adjusted using a random Gaussian number with a mean of 0 and a dynamic standard deviation. The dynamic bandwidth and standard deviation are adaptively determined based on iteration number, the maximum and minimum of each design variable in the HM. Accuracy and efficiency of the GGHS algorithm have been evaluated using several benchmark mathematical examples. The numerical results illustrate that the GGHS algorithm is more accurate and efficient than other existing modified versions of harmony search algorithm. The capability of the dynamic bandwidth enhances the performance of this modified HS algorithm. The GGHS produces the better optimum results in comparison with other improved versions of harmony search algorithm.	harmony search;mathematical optimization;search algorithm	Behrooz Keshtegar;Mahmoud Oukati Sadeq	2017	Soft Comput.	10.1007/s00500-016-2274-z	mathematical optimization;machine learning;mathematics;statistics	AI	28.03422218684444	-5.07993442947227	98025
dbf02079a58a19fc613978e4b1490c9dae3a045c	subthreshold-seeking behavior and robust local search	gray code;benchmark problem;search algorithm;local search	Subthreshold-seeking behavior occurs when the majority of the points that an algorithm samples have an evaluation less than some target threshold. We characterize sets of functions where subthresholdseeking behavior is possible. Analysis shows that subthreshold-seeking behavior, when possible, can be increased when higher bit precision is used with a bit climber search algorithm and a Gray code representation. However, higher precision also can reduce exploration. A simple modification to a bit-climber can improve its subthreshold-seeking behavior. Experiments show that this modification results in both improved search efficiency and effectiveness on common benchmark problems.	algorithmic inference;benchmark (computing);climber (beam);converge;experiment;failure cause;local optimum;local search (optimization);no free lunch in search and optimization;no free lunch theorem;sampling (signal processing);search algorithm	L. Darrell Whitley;Keith Bush;Jonathan E. Rowe	2004		10.1007/978-3-540-24855-2_25	beam search;gray code;mathematical optimization;computer science;local search;theoretical computer science;machine learning;mathematics;search algorithm	AI	28.13123562593095	-0.23152446090931647	98136
12ed13e42b6b7438a5a33650aff849d1f867bdb0	approximate dynamic programming for control of a residential water heater	water supply discrete time systems dynamic programming heating intelligent control markov processes thermodynamics;heating;thigh;lead;heating robustness lead mathematical model programming thigh;mathematical model;robustness;load smoothing approximate dynamic programming residential water heater control residential hot water suppy discrete time finite state markov decision process density estimation asymptotically optimal solution hot water demand thermodynamics solar water heating residential water heaters;programming	We formulate the problem of minimizing the operating cost of supplying residential hot water as a discrete-time finite-state Markov decision process. We apply state aggregation to reduce the effective size of the state space and utilize density estimation to obtain an algorithm that is robust to modeling changes in the cost function. We then use approximate policy iteration to obtain an asymptotically optimal solution to the problem when hot water demand is assumed to be independent of previous demand. We also provide heuristics for solving the problem when the demand is not assumed to be independent of its history. To evaluate the performance of the algorithms, we model the thermodynamics of a 20 gal water heater and simulate hot water demand for a typical two-person household. Test results show that when compared to a regular water heater, the ADP solution can reduce water heating costs by as much as 1/3 while maintaining nearly the same level of comfort. In addition, we discuss how the algorithm can be modified to incorporate solar water heating and we consider the related problem of using residential water heaters for load smoothing.	approximation algorithm;asymptotically optimal algorithm;dynamic programming;heuristic (computer science);iteration;loss function;markov chain;markov decision process;simulation;smoothing;state space;uml state machine	Matthew Motoki;Monica Umeda;Matthias Fripp;Anthony Kuh	2015	2015 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2015.7280735	programming;mathematical optimization;lead;simulation;computer science;mathematical model;robustness	ML	38.26178521452847	2.2919098959561666	98286
412e69eba1c66338c9ff054fab9301ebd45d5b5f	a genetic algorithm based augmented lagrangian method for computationally fast constrained optimization	constrained optimization;dynamic change;lagrange multiplier;objective function;augmented lagrangian method;adaptive algorithm;genetic algorithm;evolutionary algorithm;augmented lagrangian	Among the penalty based approaches for constrained optimization, Augmented Lagrangian (AL) methods are better in at least three ways: (i) they have theoretical convergence properties, (ii) they distort the original objective function minimally to allow a better search behavior, and (iii) they can find the optimal Lagrange multiplier for each constraint as a by-product of optimization. Instead of keeping a constant penalty parameter throughout the optimization process, these algorithms update the parameters adaptively so that the corresponding penalized function dynamically changes its optimum from the unconstrained minimum point to the constrained minimum point with iterations. However, the flip side of these algorithms is that the overall algorithm is a serial implementation of a number of optimization tasks, a process that is usually time-consuming. In this paper, we devise a genetic algorithm based parameter update strategy to a particular AL method. The strategy is self-adaptive in order to make the overall genetic algorithm based augmented Lagrangian (GAAL) method parameter-free. The GAAL method is applied to a number of constrained test problems taken from the EA literature. The function evaluations required by GAAL in many problems is an order or more lower than existing methods.	augmented lagrangian method;constrained optimization;genetic algorithm;program optimization	Soumil Srivastava;Kalyanmoy Deb	2010		10.1007/978-3-642-17563-3_40	mathematical optimization;constrained optimization;combinatorics;meta-optimization;augmented lagrangian method;lagrangian relaxation;computer science;machine learning;evolutionary algorithm;penalty method;mathematics	EDA	29.211263660168736	-0.8831234963705061	98564
af5bb47b1cf088485e02638e33e624f593463693	the influence of different coding schemes on the computational complexity of genetic algorithms in function optimization	gray code;function optimization;computational complexity;genetic algorithm;floating point	Function optimization is a typical application domain for genetic algorithms (GAs). Traditionally, GAs work on bit strings of xed total length l. Signiicant research has been done on designing and analyzing diierent coding schemes, of which Gray coding is one of the most used forms. Surprisingly little attention has been devoted to directly encoding the parameters by oating-point values provided by the programming language. This form of coding has been in favor in evolution strategy. This paper discusses several coding schemes and derives the resulting complexity when optimizing functions with n independent continuous parameters. It turns out that the direct use of real-valued parameters has certain advantages. First of all, it speeds up convergence by a factor of up to l q?1 , where q denotes the number of bits per parameter. Furthermore, the use of real-valued parameters allows for more exibility in designing the mutation operator and eases many implementation issues. The theoretical analysis presented here strongly suggests that real-valued parameters (implemented by oating point values provided by the programming language) should be the best choice when applying a GA in the eld of function optimization.	application domain;computational complexity theory;evolution strategy;genetic algorithm;mathematical optimization;programming language;software release life cycle	Ralf Salomon	1996		10.1007/3-540-61723-X_987	computational problem;quality control and genetic algorithms;gray code;mathematical optimization;probabilistic analysis of algorithms;meta-optimization;genetic algorithm;average-case complexity;decision tree model;computer science;floating point;theoretical computer science;computational resource;worst-case complexity;computational complexity theory;asymptotic computational complexity;algorithm	Theory	32.313925419553655	-1.1085215897072629	98571
79bd0fbb6168bc789d48e6df7baddf4e1b16eaf6	optimal mutation rates and selection pressure in genetic algorithms	mutation rate;error threshold;genetic algorithm	It has been argued that optimal per locus mutation rates in GAs are proportional to selection pressure and the reciprocal of geno type length In this paper we suggest that the notion of error threshold borrowed from molecular evolution sheds new light on this argument We show empirically the existence of error thresholds in GAs running on a sim ple abstract landscape and then investigate a real world industrial problem demonstrat ing comparable phenomena in a practical ap plication We study the correspondence be tween error thresholds and optimal mutation rates on these two problems and explore the e ect of di erent selection pressures Re sults suggest that error thresholds and op timal mutation rates are indeed correlated Moreover as the selection pressure increases both error thresholds and optimal mutation rates increase These ndings may have prac tical consequences as heuristics for measur ing error thresholds in real world applications will provide useful guidelines for setting op timal mutation rates	genetic algorithm;heuristic (computer science);locus;regular expression	Gabriela Ochoa;Inman Harvey;Hilary Buxton	2000			mutation rate;econometrics;mathematical optimization;genetic algorithm;computer science;error threshold;mathematics;statistics	ML	26.620708481091288	-9.16164758662956	98722
8ea7fc2e790aa79b59b1d605cfdbd1d28f93bc53	on the locality of dominance and recombination in multiobjective evolutionary algorithms	random principle search direction;search problems combinatorial mathematics evolutionary computation;evolutionary computation;local dominance;local recombination;search methods;evolutionary computation genetic mutations size control;multiobjective evolutionary algorithm;combinatorial multiobjective problems;polar coordinate;search problems;random principle search direction local dominance local recombination multiobjective evolutionary algorithms combinatorial multiobjective problems;combinatorial mathematics;multiobjective evolutionary algorithms	This work studies and compares the effects on performance of local dominance and local recombination applied with different locality in multiobjective evolutionary algorithms on combinatorial multiobjective problems. For this purpose, we introduce a method that creates a neighborhood around each individual and assigns a local dominance rank after rotating the principal search direction of the neighborhood by using polar coordinates in objective space. For recombination a different neighborhood determined around a random principle search direction is created. The neighborhood sizes for dominance and recombination are separately controlled by two different parameters. Experimental results show that the optimum locality of dominance is different from the optimum locality of recombination. Additionally, it is shown that the performance of the algorithm that applies local dominance and local recombination with different locality is significantly better than the performance of algorithms applying local dominance alone, local recombination alone, or dominance and recombination globally as conventional approaches do	crossover (genetic algorithm);evolutionary algorithm;locality of reference	Hiroyuki Sato;Hernán E. Aguirre;Kiyoshi Tanaka	2005	2005 IEEE Congress on Evolutionary Computation	10.1109/CEC.2005.1554718	mathematical optimization;combinatorics;polar coordinate system;computer science;artificial intelligence;machine learning;mathematics;evolutionary computation	ML	28.039583371151366	-6.699955268331544	98935
a2f050fba2babdf14eb8e611c5a7e3c32ce94ef9	hardware implementation of an analog neural nonderivative optimizer	simulation ordinateur;electronic circuit;circuito analogico;gradiente;circuito electronico;gradient;analog circuit;neural system;convex function;artigo;simulacion computadora;reseau neuronal;fonction convexe;computer simulation;circuit electronique;hardware implementation;red neuronal;circuit analogique;funcion convexa;neural network	Analog neural systems that can automatically find the minimum value of the outputs of unknown analog systems, described by convex functions, are studied. When information about derivative or gradient are not used, these systems are called analog nonderivative optimizers. An electronic circuit for the analog neural nonderivative optimizer proposed by Teixeira and Żak, and its simulation with software PSPICE, is presented. With the simulation results and hardware implementation of the system, the validity of the proposed optimizer can be verified. These results are original, from the best of the authors knowledge.	mathematical optimization	Rodrigo Cardim;Marcelo C. M. Teixeira;Edvaldo Assunção;Nobuo Oki;Aparecido Augusto de Carvalho;Márcio R. Covacic	2006		10.1007/11893295_125	computer simulation;convex function;electronic circuit;analogue electronics;computer science;artificial intelligence;theoretical computer science;machine learning;gradient;artificial neural network	ML	38.31863257242119	-3.7465832262690544	99098
4d908c5ed2144d9bf69d8711c823a03ec65d535f	multimodal optimization using a biobjective differential evolution algorithm enhanced with mean distance-based selection	nonparametric statistics;sorting;sorting genetic algorithms nonparametric statistics;sociology statistics optimization sorting measurement vectors linear programming;nonparametric statistical test multimodal optimization biobjective differential evolution algorithm mean distance based selection niching scheme single objective evolutionary algorithm multiobjective evolutionary algorithm hypervolume measure based sorting biobjective multipopulation genetic algorithm nondominated sorting genetic algorithm ii mobide algorithm;nondominated sorting crowding differential evolution de multimodal optimization multiobjective optimization niching;genetic algorithms	In contrast to the numerous research works that integrate a niching scheme with an existing single-objective evolutionary algorithm to perform multimodal optimization, a few approaches have recently been taken to recast multimodal optimization as a multiobjective optimization problem to be solved by modified multiobjective evolutionary algorithms. Following this promising avenue of research, we propose a novel biobjective formulation of the multimodal optimization problem and use differential evolution (DE) with nondominated sorting followed by hypervolume measure-based sorting to finally detect a set of solutions corresponding to multiple global and local optima of the function under test. Unlike the two earlier multiobjective approaches (biobjective multipopulation genetic algorithm and niching-based nondominated sorting genetic algorithm II), the proposed multimodal optimization with biobjective DE (MOBiDE) algorithm does not require the actual or estimated gradient of the multimodal function to form its second objective. Performance of MOBiDE is compared with eight state-of-the-art single-objective niching algorithms and two recently developed biobjective niching algorithms using a test suite of 14 basic and 15 composite multimodal problems. Experimental results supported by nonparametric statistical tests suggest that MOBiDE is able to provide better and more consistent performance over the existing well-known multimodal algorithms for majority of the test problems without incurring any serious computational burden.	archive;constraint (mathematics);differential evolution;distribution (mathematics);euclidean distance;evolutionary algorithm;evolutionary multimodal optimization;experiment;genetic algorithm;gradient;hoc (programming language);local optimum;mathematical optimization;multi-objective optimization;multimodal interaction;optimization problem;particle swarm optimization;performance;sorting;test suite	Aniruddha Basak;Swagatam Das;Kay Chen Tan	2013	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2012.2231685	nonparametric statistics;mathematical optimization;genetic algorithm;computer science;sorting;machine learning;mathematics;algorithm;statistics	AI	25.0841461359998	-3.953813408291565	99273
9abb59a6b21b16efe01d495deae0c83ec9933296	probabilistic hosting capacity for active distribution networks		The increased connection of distributed generation (DG), such as photovoltaic (PV) and wind turbine (WT), has shifted the current distribution networks from being passive (consuming energy) into active (consuming/producing energy). However, there is still no consensus about how to determine the maximum amount of DGs that are allowed to be connected, i.e., how to quantify a so-called “hosting capacity” (HC). Therefore, this paper proposes a novel risk assessment tool for estimating network HC by considering uncertainties associated with PV, WT, and loads. This evaluation is performed using the likelihood approximation approach. The paper, also, proposes a utilization of clearness index for localized solar irradiance prediction of PV. In addition, we propose the use of sparse grid technique as an effective means for uncertainty computation while the use of Monte Carlo technique is taken for a comparison purpose. Two actual distribution networks (11-buses and South Australian large feeder) are considered as case studies to demonstrate the usefulness of the proposed tool.	approximation;computation;discontinuous galerkin method;monte carlo method;risk assessment;sparse grid;sparse matrix	Hassan Al-Saadi;Rastko Zivanovic;Said F. Al-Sarawi	2017	IEEE Transactions on Industrial Informatics	10.1109/TII.2017.2698505	computer science;solar irradiance;probabilistic logic;monte carlo method;distributed generation;risk management tools;photovoltaic system;reliability engineering	HPC	35.62704879178213	-2.211046973486408	99563
efb5c9b4c4bd2e9af51da109c9dbcb76fe497286	chaotic hybrid algorithm and its application in circle detection	ga;chaos;chaotic dynamics;pso;conference paper;particle swarm optimizer;multimodal optimization;genetic algorithm;circle detection;hybrid algorithm	An evolutionary circle detection method based on a novel Chaotic Hybrid Algorithm (CHA) is proposed. The method combines the strengths of particle swarm optimization, genetic algorithms and chaotic dynamics, and involves the standard velocity and position updating rules of PSO with the ideas of GA selection, crossover and mutation. In addition, the notion of species is introduced into the proposed CHA to enhance its performance in solving multimodal problems. The effectiveness of the Species based Chaotic Hybrid Algorithm (SCHA) is proven through simulations and benchmarking, and finally, it is successfully applied to solve circle detection problems.	hybrid algorithm	Chun-Ho Wu;Na Dong;Andrew W. H. Ip;Ching-Yuen Chan;Kai-Leung Yung;Zengqiang Chen	2010		10.1007/978-3-642-12239-2_31	mathematical optimization;artificial intelligence;machine learning;mathematics	Vision	27.258489613345716	-4.707684707210216	99651
90c5661c0eba4583d9c1c559f0ca0b3979215dbc	a study of the applicability of hopfield decision neural nets to vlsi cad	neural networks hopfield neural networks very large scale integration neurons permission artificial neural networks design optimization circuit synthesis circuit simulation neural network hardware;neural networks;very large scale integration;vlsi circuit design;design optimization;optimization problem;circuit simulation;artificial neural networks;neural net;hopfield neural networks;permission;neural network hardware;hill climbing;neurons;hardware implementation;circuit synthesis	Hopfield decision neural nets have been claimed to be good for solving a class of optimization problems such as the traveling salesman's problem. A study was undertaken to determine if these techniques were applicable to the many optimization problems that occur in VLSI circuit design and layout. Module placement was chosen as a representative problem. It was observed that the convergence process closely resembles that of greedy hill climbing algorithms. Apart from the known problems of long simulation times and hardware implementation complexity, it was noted that the quality of solution was mediocre, at best, and highly sensitive to network parameters. Various modifications were attempted, none of which significantly improved the result. It is concluded that Hopfield neural nets do not, in their present form, provide an interesting solution to this class of CAD problems.	artificial neural network;circuit design;computer-aided design;greedy algorithm;hill climbing;hopfield network;mathematical optimization;neural oscillation;optimization problem;simulation	M. L. Yu	1989	26th ACM/IEEE Design Automation Conference	10.1145/74382.74451	optimization problem;mathematical optimization;multidisciplinary design optimization;computer science;artificial intelligence;theoretical computer science;hill climbing;machine learning;very-large-scale integration;hopfield network;artificial neural network	EDA	30.31814351007315	3.765088368702295	99746
123fd6f0f8ee6121bb5d07c1154ed8cfea4550aa	gpu particle swarm optimization applied to travelling salesman problem	tsp;gpu;pso;cuda;optimization	Recently, the Graphic Processing Unit (GPUs) are used as an exciting new hardware environment for truly parallel implementation and execution of nature and Bio-inspired algorithms thanks to their excellent price-to-power ratio. Indeed, they are represented by the software platform using compute unified device architecture from NVIDIA, and the one of particle swarm optimization (PSO) which can be executed simultaneously on GPUs to speed up complex optimization problems such as Travelling Salesman Problem (TSP). In this paper, we illustrate a novel parallel approach to run standard particle swarm optimization PSO on GPUs and applied to TSP (GPU-PSO-A-TSP). Both the developed and the previous PSO centroid algorithm are implemented on the GPUs. The achieved results show that we have obtained at least one order of magnitude difference between speed of the GPUs and a typical sequential CPU implementation for performance optimization. Results show also that running speed of GPU-PSO is four times as fast as that of CPU-PSO.	algorithm;cuda;central processing unit;graphics processing unit;mathematical optimization;particle swarm optimization;performance tuning;phase-shift oscillator;population;run time (program lifecycle phase);speedup;travelling salesman problem	Olfa Bali;Walid Elloumi;Pavel Krömer;Adel M. Alimi	2015	2015 IEEE 9th International Symposium on Embedded Multicore/Many-core Systems-on-Chip	10.1109/MCSoC.2015.18	mathematical optimization;multi-swarm optimization;parallel computing;computer science;theoretical computer science;3-opt	Arch	26.800034815565873	-0.6522856618995897	99954
5c7c3254225b416fe1dff8a74897aaf5e0aedeff	differential evolution algorithm with the second order difference vector		DE is challenging to maintain a balance between exploration and exploitation behaviors, and also the neighborhood and direction information of the difference vector is not completely utilized. In this paper, a completely novel DE variant, SODE, is proposed with the second order difference information, which is introduced to DE for even more fully utilizing the heuristic direction information. The second order difference information also enriches the neighborhood structure and enlarges the neighborhood domain with more heuristic information. Preliminary experimental results show that SODE is better than, or at least comparable to, the classical first order DE algorithms in terms of convergence performance and accuracy.	algorithm;differential evolution	Xinchao Zhao;Dongyue Liu;Xingquan Zuo;Huiping Liu;Rui Li	2016		10.1007/978-981-10-3614-9_27	machine learning;differential evolution;mathematical optimization;vector operator;artificial intelligence;computer science;algorithm;heuristic;convergence (routing)	DB	26.828694837293394	-3.78377723612974	100008
9ce59a118ac068b8cc17e94ca62afdef69035f8a	stopping criteria, initialization, and implementations of bfgs and their effect on the bbob test suite		Benchmarking algorithms is a crucial task to understand them and to make recommendations for which algorithms to use in practice. However, one has to keep in mind that we typically compare only algorithm implementations and that care must be taken when making general statements about an algorithm while implementation details and parameter settings might have a strong impact on the performance. In this paper, we investigate those impacts of initialization, internal parameter setting, and algorithm implementation over different languages for the well-known BFGS algorithm. We must conclude that even in the default setting, the BFGS algorithms in Python's scipy library and in Matlab's fminunc differ widely---with the latter even changing significantly over time.	black box;broyden–fletcher–goldfarb–shanno algorithm;experiment;finite difference;gradient;matlab;mathematical optimization;nonlinear system;numerical analysis;optimization problem;patch (computing);python;scipy;test suite;whole earth 'lectronic link	Aurore Blelly;Matheus Felipe-Gomes;Anne Auger;Dimo Brockhoff	2018		10.1145/3205651.3208303	implementation;computer science;machine learning;broyden–fletcher–goldfarb–shanno algorithm;artificial intelligence;benchmarking;matlab;python (programming language);test suite;initialization	ML	31.494316210863207	-0.4958175045236736	100040
788650d730e4521635e1600fabd8a9d0568a1145	multikulti algorithm: using genotypic differences in adaptive distributed evolutionary algorithm migration policies	discrete optimization;convergence;evolutionary computation;probability density function;data mining;migration policies multikulti algorithm genotypic differences adaptive distributed evolutionary algorithm;adaptive distributed evolutionary algorithm;evolutionary computation frequency synchronous generators topology phase detection random number generation entropy concurrent computing;biological cells;ieee;genotypic differences;multikulti algorithm;migration policies;optimization;evolutionary algorithm;migration policy	Migration policies in distributed evolutionary algorithms are bound to have, as much as any other evolutionary operator, an impact on the overall performance. However, they have not been an active area of research until recently, and this research has concentrated on the migration rate. In this paper we compare different migration policies, including our proposed multikulti methods, which choose the individuals that are going to be sent to other nodes based on the principle of multiculturalism: the individual sent should be as different as possible to the receiving population (represented in several possible ways). We have checked this policy on two discrete optimization problems for different number of nodes, and found that, in average or in median, multikulti policies outperform others like sending the best or a random individual; however, their advantage changes with the number of nodes involved and the difficulty of the problem. The success of these kind of policies is explained via the measurement of entropies, which are known to have an impact in the performance of the evolutionary algorithm.	discrete optimization;evolutionary algorithm;genetic algorithm;mathematical optimization	Lourdes Araujo;Juan Julián Merelo Guervós	2009	2009 IEEE Congress on Evolutionary Computation	10.1109/CEC.2009.4983301	discrete optimization;mathematical optimization;probability density function;convergence;computer science;artificial intelligence;theoretical computer science;machine learning;evolutionary algorithm;statistics;evolutionary computation	Metrics	28.037124634704288	-6.387172278191778	100061
bc782c7a4560985371ecdbdf6526ecac1e7c7c70	dividing wall column structure design using response surface methodology	structure design;response surface methodology;dividing wall column;distillation process	Designing dividing wall columns (DWC) – energy-efficient separators of ternary mixtures – involves multivariable problem solving. These variables interact with each other and need to be optimized simultaneously to obtain the best design. In this work, a practical method employing response surface methodology (RSM) is proposed for DWC design and optimization. The optimum DWC structure can be vailable online 18 July 2011	column (database);mathematical optimization;problem solving;response surface methodology	Nguyen Van Duc Long;Moonyong Lee	2012	Computers & Chemical Engineering	10.1016/j.compchemeng.2011.07.006	mathematical optimization;response surface methodology;computer science;engineering;mathematics;engineering drawing;distillation	EDA	34.28929703637551	-0.11067249300021263	100134
ad24d7dcdc883aeb52a1bda3bac3363e97f2d75e	exchange market algorithm based optimum reactive power dispatch	optimal power flow;optimum reactive power dispatch;exchange market algorithm;stability index	Graphical abstractDisplay Omitted This paper presents a maiden application of EMA to solve power system ORPD problems.Steps of implementation of EMA to solve ORPD are elaborately discussed.The performance of EMA is tested on standard IEEE test systems.The selection of control parameters of EMA is done through exhaustive parametric study. In this paper, an exchange market algorithm (EMA) approach is applied to solve highly non-linear power system optimal reactive power dispatch (ORPD) problems. ORPD is most vital optimization problems in power system study and are usually devised as optimal power flow (OPF) problem. The problem is formulated as nonlinear, non-convex constrained optimization problem with the presence of both continuous and discrete control variables. The EMA searches for optimal solution via two main phases; namely, balanced market and oscillation market. Each of the phases comprises of both exploration and exploitation, which makes the algorithm unique. This uniqueness of EMA is exploited in this paper to solve various vital objectives associated with ORPD problems. Programs are developed in MATLAB and tested on standard IEEE 30 and IEEE 118 bus systems. The results obtained using EMA are compared with other contemporary methods in the literature. Simulation results demonstrate the superiority of EMA in terms of its computational efficiency and robustness. Consumed function evaluation for each case study is mentioned in the convergence plot itself for better clarity. Parametric study is also performed on different case studies to obtain the suitable values of tuneable parameters.	algorithm;dynamic dispatch	Abhishek Rajan;Tanmoy Malakar	2016	Appl. Soft Comput.	10.1016/j.asoc.2016.02.041	mathematical optimization;simulation;artificial intelligence	Logic	29.616914536964252	-0.8024528552903716	100175
16bacb74faa15e1bedda661a25b42b4abeb4f43a	ant colony optimization with immigrants schemes in dynamic environments	ant colony optimization;travelling salesman problem;conference;immigrants schemes;conference paper;dynamic environment;evolutionary algorithm;institutional repository research archive oaister;dynamic optimization problem;dynamic optimization	In recent years, there has been a growing interest in addressing dynamic optimization problems (DOPs) using evolutionary algorithms (EAs). Several approaches have been developed for EAs to increase the diversity of the population and enhance the performance of the algorithm for DOPs. Among these approaches, immigrants schemes have been found beneficial for EAs in DOPs. In this paper, random, elitismbased, and hybrid immigrants schemes are applied to ant colony optimization (ACO) for the dynamic travelling salesman problem (DTSP). The experimental results show that random immigrants are beneficial for ACO in fast changing environments, whereas elitism-based immigrants are beneficial for ACO in slowly changing environments. The ACO algorithm with hybrid immigrants scheme combines the merits of the random and elitism-based immigrants schemes. Moreover, the results show that the proposed algorithms outperform compared approaches in almost all dynamic test cases and that immigrant schemes efficiently improve the performance of ACO algorithms in DTSP.	ant colony optimization algorithms;dynamic programming;evolutionary algorithm;expectation propagation;iteration;langton's ant;mathematical optimization;randomness;sting;smart environment;test case;travelling salesman problem;iversity	Michalis Mavrovouniotis;Shengxiang Yang	2010		10.1007/978-3-642-15871-1_38	mathematical optimization;ant colony optimization algorithms;simulation;computer science;artificial intelligence;evolutionary algorithm;travelling salesman problem	AI	26.40839579935555	-4.519756660071354	100210
787a6f7cb1c316fa6e6d6a09e08bc0628d1c3510	a new back-propagation neural network optimized with cuckoo search algorithm	back propagation neural network;artificial bee colony algorithm;cuckoo search algorithm;local minima;qa76 computer software	Back-propagation Neural Network (BPNN) algorithm is one of the most widely used and a popular technique to optimize the feed forward neural network training. Traditional BP algorithm has some drawbacks, such as getting stuck easily in local minima and slow speed of convergence. Nature inspired meta-heuristic algorithms provide derivative-free solution to optimize complex problems. This paper proposed a new meta-heuristic search algorithm, called cuckoo search (CS), based on cuckoo bird’s behavior to train BP in achieving fast convergence rate and to avoid local minima problem. The performance of the proposed Cuckoo Search Back-Propagation (CSBP) is compared with artificial bee colony using BP algorithm, and other hybrid variants. Specifically OR and XOR datasets are used. The simulation results show that the computational efficiency of BP training process is highly enhanced when coupled with the proposed hybrid method.	4-bit;artificial bee colony algorithm;artificial neural network;backpropagation;color depth;computation;cuckoo search;exclusive or;heuristic;machine learning;maxima and minima;newton's method;rate of convergence;search algorithm;simulation;software propagation	Nazri Mohd Nawi;Abdullah Khan;Mohammad Zubair Rehman	2013		10.1007/978-3-642-39637-3_33	mathematical optimization;artificial intelligence;machine learning;maxima and minima;artificial bee colony algorithm	ML	29.398703634630433	-5.384139685894012	100391
127c92998e056578cac8b8d0757f4e57f28d20e5	binary particle swarm optimization based algorithm for feature subset selection	set theory combinatorial mathematics particle swarm optimisation;binary particle swarm optimization;probability density function;combinatorial optimization problem;genetic algorithm binary particle swarm optimization feature subset selection combinatorial optimization problem;set theory;data mining;simulation experiment;particle swarm optimizer;evolutionary optimization technique;particle swarm optimization;feature subset selection;pattern recognition;evolutionary optimization technique binary particle swarm optimization feature subset selection;genetic algorithm;iris;evolutionary optimization;particle swarm optimisation;combinatorial mathematics;gallium;sonar	The feature subset selection  can be considered as a global combinatorial optimization problem in which the   optimum subset of features is selected from a large set of features. Lots of techniques have developed so far, still research is going on to find better solution in terms of optimality and computational ease. In this work  an algorithm based on binary particle swarm optimization (bPSO) is proposed for feature subset selection. From simple simulation experiments  it has been found that bPSO based algorithm performs well and computationally less demanding than genetic algorithm, another  population based evolutionary search technique.	combinatorial optimization;computation;experiment;feature selection;genetic algorithm;mathematical optimization;optimization problem;particle swarm optimization;simulation	Basabi Chakraborty	2009	2009 Seventh International Conference on Advances in Pattern Recognition	10.1109/ICAPR.2009.111	mathematical optimization;multi-swarm optimization;machine learning;pattern recognition;mathematics	Robotics	25.794342656170834	-2.721751362872449	100475
6ae414d58e5735e153546ebba60d0dcc32b47216	structure oriented search algorithm to solve knapsack problems	complex optimization problems structure oriented search algorithm knapsack problems genetic algorithm;knapsack problems;search methods stochastic processes design methodology physics algorithm design and analysis simulated annealing genetics design optimization optimization methods costs;search space;search algorithm;search method;simulated annealing;optimization problem;heuristic search;knapsack problem;stochastic processes knapsack problems search problems genetic algorithms;stochastic optimization;stochastic processes;landscape structure;structure oriented search algorithm;genetic algorithm;genetic algorithms;big valley structure;search problems;numerical experiment	In this paper, we analyze the landscape of knapsack problems and propose a new search method called structure oriented search algorithm (SOSA). The heuristic search methods such as a simulated annealing and a genetic algorithm can be applied to complex optimization problems such as combinatorial ones. However, these methods are often redundant and inefficient. The key idea of the SOSA is approximating the landscape structure of the search space, so that the sampling domain can be directly moved to the promising region. The numerical experiments to solve knapsack problems hare been conducted and the results are compared with that of genetic algorithms. The experimental results show the effectiveness of our method from the viewpoint of accuracy and calculation cost.	experiment;genetic algorithm;heuristic;knapsack problem;mathematical optimization;numerical analysis;redundancy (engineering);sampling (signal processing);search algorithm;simulated annealing	Hiroki Yoshizawa;Shuji Hashimoto	2004	2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)	10.1109/ICSMC.2004.1401145	beam search;continuous knapsack problem;mathematical optimization;combinatorics;genetic algorithm;computer science;stochastic optimization;machine learning;mathematics;incremental heuristic search;best-first search;knapsack problem	Robotics	25.864398931766935	-1.4173051112512065	100742
56fac722d9199c8d01c9574042620208ce4df29b	understanding the role of noise in stochastic local search: analysis and experiments	markov chain model;fonction rationnelle;algoritmo aleatorizado;bayesian network;optimisation;chaine markov;cadena markov;algoritmo busqueda;analisis estadistico;temps polynomial;caracteristique temporelle;modelo markov;optimizacion;markov chain models;bepress selected works;algorithme recherche;search algorithm;convexite;analyse stochastique;programmation stochastique;analyse temporelle;intelligence artificielle;aprendizaje probabilidades;algorithme randomise;probabilistic approach;curva analitica;analisis temporal;courbe analytique;time curve;convexidad;time analysis;busca local;reseau bayes;systematic experiments;aproximacion polinomial;markov model;statistical analysis;noise response curves;red bayes;convex function;enfoque probabilista;approche probabiliste;hitting time;analyse statistique;approximation polynomiale;most probable explanation;polynomial time;stochastic analysis;bayes network;caracteristica temporal;randomized algorithm;apprentissage probabilites;artificial intelligence;optimization;stochastic local search;inteligencia artificial;probabilistic logic;modele markov;convexity;rational functions;funcion racional;analytical curve;stochastic programming;theoretical foundation;logique probabiliste;rational function;fonction convexe;expected hitting times;local search;programacion estocastica;parameter optimization;recherche locale;probability learning;probabilistic reasoning;analisis estocastico;polynomial approximation;noise;funcion convexa;bayesian networks;markov chain;tiempo polinomial	Stochastic local search (SLS) algorithms have recently been proven to be among the best approaches to solving computationally hard problems. SLS algorithms typically have a number of parameters, optimized empirically, that characterize and determine their performance. In this article, we focus on the noise parameter. The theoretical foundation of SLS, including an understanding of how to the optimal noise varies with problem difficulty, is lagging compared to the strong empirical results obtained using these algorithms. A purely empirical approach to understanding and optimizing SLS noise, as problem instances vary, can be very computationally intensive. To complement existing experimental results, we formulate and analyze several Markov chain models of SLS in this article. In particular, we compute expected hitting times and show that they are rational functions for individual problem instances as well as their mixtures. Expected hitting time curves are analytical counterparts to noise response curves reported in the experimental literature. Hitting time analysis using polynomials and convex functions is also discussed. In addition, we present examples and experimental results illustrating the impact of varying noise probability on SLS run time. In experiments, where most probable explanations in Bayesian networks are computed, we use synthetic problem instances as well as problem instances from applications. We believe that our results provide an improved theoretical understanding of the role of noise in stochastic local search, thereby providing a foundation for further progress in this area. © 2008 Elsevier B.V. All rights reserved.	algorithm;bayesian network;convex function;experiment;local search (optimization);markov chain;polynomial;run time (program lifecycle phase);standard sea level;synthetic intelligence	Ole J. Mengshoel	2008	Artif. Intell.	10.1016/j.artint.2007.09.010	stochastic process;econometrics;computer science;bayesian network;mathematics;algorithm;statistics	AI	28.031995769160922	2.4424871153990306	100865
70e09ea122216e96a37e286f6494d87eb6b8bf3d	a non-destructive grammar modification approach to modularity in grammatical evolution	genetic program;conference publication;genetic programming;grammars;grammatical evolution;modularity;evolutionary computing	Modularity has proven to be an important aspect of evolutionary computation. This work is concerned with discovering and using modules in one form of grammar-based genetic programming, grammatical evolution (GE). Previous work has shown that simply adding modules to GE's grammar has the potential to disrupt fit individuals developed by evolution up to that point. This paper presents a solution to prevent the disturbance in fitness that can come with modifying GE's grammar with previously discovered modules. The results show an increase in performance from a previously examined grammar modification approach and also an increase in performance when compared to standard GE.	evolutionary computation;genetic programming;grammatical evolution	John Mark Swafford;Erik Hemberg;Michael O'Neill;Miguel Nicolau;Anthony Brabazon	2011		10.1145/2001576.2001766	natural language processing;genetic programming;synchronous context-free grammar;computer science;artificial intelligence;affix grammar;machine learning;modularity;grammatical evolution;attribute grammar;adaptive grammar;mildly context-sensitive grammar formalism;algorithm;evolutionary computation	NLP	25.033757036725568	-9.474219745921166	101091
4fd045d2a594f8edd89cc334e67bc4982c3cde56	a new metaheuristic based on the self-defense mechanisms of the plants with a fuzzy approach applied to the cec2015 functions		In this paper a new metaheuristic based on coping strategies of plants with a fuzzy approach is presented. In this work the authors propose a variant of the original algorithm of the plants with a fuzzy approach, The new proposal consists of adding fuzzy logic to adapt the parameters of the algorithm dynamically. In this work, a fuzzy controller is responsible of find the optimal values of the variables α, β, δ, λ, in order to help the algorithm to have a greater performance in solving problems, in the previous works the authors apply the original algorithm to optimization problems, and the parameters of the variables are moved manually, however the results obtained are acceptable in some cases, but we consider that they can be improved using the intelligent technique for the adaptation of parameters.	fuzzy logic;metaheuristic	Camilo Caraveo;Fevrier Valdez;Oscar Castillo	2017		10.1007/978-3-319-67137-6_12	fuzzy logic;self;machine learning;artificial intelligence;control theory;computer science;metaheuristic;mathematical optimization;optimization problem;parallel metaheuristic	Logic	25.48065903338559	-6.940802765949676	101573
ab9dd318c798769bd62bb89627c64172398ef79e	brain storm optimization with multi-population based ensemble of creating operations		Brain storm optimization (BSO) algorithm is a novel swarm intelligence algorithm. Inspired by differential evolution (DE) with multi-population based ensemble of mutation strategies (MPEDE), a new variant of BSO algorithm, called brain storm optimization with multi-population based ensemble of creating operations (MPEBSO), is proposed in this paper. There are three equally sized smaller indicator subpopulations and one much larger reward subpopulation. BSO algorithm is used to update individuals in every subpopulation. At first, each creating operation has one smaller indicator subpopulation, in which different mutation strategy is used to add noise instead of the Gaussian random strategy. After every certain number of generations, the larger reward subpopulation will be adaptively assigned to the best performing creating operation with more computational resources. The competitive performance of the proposed MPEBSO on CEC2005 benchmark functions is highlighted compared with DE, MPEDE, and other four variants of BSO.		Yuehong Sun;Ye Jin;Dan Wang	2018		10.1007/978-3-319-93815-8_36	swarm intelligence;mathematical optimization;differential evolution;computer science;storm;artificial intelligence;population;gaussian	EDA	26.71629531821198	-4.910038998902547	101641
1abb2c0f6333563853c3f7efdb2f1c975e86b203	value-directed compression of pomdps	lossy compression;policy evaluation;state space	We examine the problem of generating state-space compressions of POMDPs in a way that minimally impacts decision quality. We analyze the impact of compressions on decision quality, observing that compressions that allow accurate policy evaluation (prediction of expected future reward) will not affect decision quality. We derive a set of sufficient conditions that ensure accurate prediction in this respect, illustrate interesting mathematical properties these confer on lossless linear compressions, and use these to derive an iterative procedure for finding good linear lossy compressions. We also elaborate on how structured representations of a POMDP can be used to find such compressions.	decision quality;iterative method;lossless compression;lossy compression;partially observable markov decision process;state space	Pascal Poupart;Craig Boutilier	2002			lossy compression;mathematical optimization;simulation;computer science;state space;machine learning;mathematics;statistics	ML	37.50581062259752	2.4105928201891937	101677
46438f66c2d43c5cf08e1d05597a1172f1d83965	vine creeping algorithm for global optimisation	levenberg marquardt;search problems genetic algorithms;mutation process vine creeping algorithm global optimisation levenberg marquardt algorithm revised nonrevisiting genetic algorithm global search selection process;global optimisation;voltage controlled oscillators gallium world wide web artificial neural networks convergence;binary space partition;success rate;evolutionary algorithms;genetic algorithm;genetic algorithms;search problems;binary space partition evolutionary algorithms global optimisation genetic algorithm levenberg marquardt;evolutionary algorithm	This paper presents a novel vine creeping optimisation algorithm based on the integration of the Levenberg-Marquardt algorithm into a revised non-revisiting genetic algorithm. The global search of the genetic algorithm is enhanced in efficiency and accuracy by incorporating the Levenberg-Marquardt algorithm into the selection and mutation process. The term revisit is redefined as a local region of convergence by the Levenberg-Marquardt algorithm, rather than a particular point selected. The redefinition of a revisit allows a larger step size in mutation hence reducing the number of evaluations in order to flag the current space as saturated. The effect of the revisited regions filling out the current local minimum regions and branching into unvisited space results in the vine creeping effect. The proposed algorithm was tested against three well known benchmark functions, and was able to converge upon the global optimum within an average of 63.91 generations, with a success rate ranging between 96–100%.	archive;benchmark (computing);converge;definition;genetic algorithm;global optimization;grid (spatial index);levenberg–marquardt algorithm;local search (optimization);mathematical optimization;maxima and minima;rate of convergence;vine toolkit;voltage-controlled oscillator	Christopher Neil Young;Ju Jia Zou;Chin Jian Leo	2010	2010 Second World Congress on Nature and Biologically Inspired Computing (NaBIC)	10.1109/NABIC.2010.5716334	mathematical optimization;genetic algorithm;cultural algorithm;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;fsa-red algorithm;search algorithm;population-based incremental learning	Vision	27.915733847862587	-4.771652293220516	101935
c5598d74ca27f7ddc2d8132c36a700326813c38f	optimal and sub-optimal stopping rules for the multistart algorithm in global optimization	optimal sampling with recall;optimisation;optimizacion;multistart method;stopping rule;simulation;optimum global;simulacion;global optimum;regla parada;algorithme;decision estadistica;algorithm;stopping criterion;optimal stopping;global optimization;optimization;statistical decision;local search;optimo global;decision statistique;sequential sampling;regle arret;algoritmo	In this paper the problem of stopping the Multistart algorithm for global optimization is considered. The algorithm consists of repeatedly performing local searches from randomly generated starting points. The crucial point in this algorithmic scheme is the development of a stopping criterion; the approach analyzed in this paper consists in stopping the sequential sampling as soon as a measure of the trade-off between the cost of further local searches is greater than the expected benefit, i.e. the possibility of discovering a better optimum.	genetic algorithm;global optimization;mathematical optimization;optimal stopping	Bruno Betrò;Fabio Schoen	1992	Math. Program.	10.1007/BF01581094	mathematical optimization;combinatorics;optimal stopping;local search;sequential analysis;mathematics;global optimum;algorithm;global optimization	ML	27.04997280492356	2.023384665633171	102169
78e7a4ed7b0d99c64ead8f467869fb5b4aa09ed3	quickest time detection and constrained optimal social learning with variance penalty	quickest time herding constrained optimal social learning bayesian quickest time change detection phase type distributed change variance stopping penalty lattice programming stochastic order optimal decision policy threshold switching curve structure posterior distribution social welfare function;constrained optimization;optimisation;stochastic processes bayes methods decision theory optimisation social sciences statistical distributions;time change;social learning;bayes methods;social sciences;bayesian methods;switches bayesian methods markov processes approximation methods programming optimization;statistical distributions;posterior distribution;stochastic processes;decision theory;stochastic order;phase type distribution;optimization;approximation methods;markov processes;social welfare function;switches;programming	This paper considers Bayesian quickest time change detection with phase-type distributed change and a variance stopping penalty. Using lattice programming and stochastic orders, we prove that the optimal decision policy has a threshold switching curve structure on the space of posterior distributions. We then consider example in constrained optimal social learning. Each agent is benevolent and chooses its mode to reveal full information or herd to optimize a social welfare function to facilitate social learning. It is proved that the optimal decision for quickest time herding is characterized by a switching curve.	ordinal optimization	Vikram Krishnamurthy	2010	49th IEEE Conference on Decision and Control (CDC)	10.1109/CDC.2010.5717548	probability distribution;programming;econometrics;mathematical optimization;constrained optimization;social learning;decision theory;daylight saving time;network switch;bayesian probability;machine learning;mathematics;phase-type distribution;markov process;posterior probability;statistics	AI	36.35080647869067	3.285946626864586	102348
3abc326bbc5e9ac1bd19676565b27a178cadf44a	state of art of optimisation and meta heuristic a comparative study of the harmony search algorithm	heuristic algorithms;particle swarm optimization;linear programming;mathematical model;genetic algorithms;optimization;search problems	Over the years the science has developed rapidly. And the Optimization science also has been developed to solve the difficult problems. Now the optimization science is the tendency to solve several problems by applying algorithms and optimization methods (Meta heuristics Algorithms). In the previous decades, the researchers have worked and solved their problems with limited optimization methods (deterministic methods), that provide exact solution. But now these methods are not effective for the very complex problems, and this obstacle push the researchers to build other methods. In this paper a big state of art, and a very important comparative study are proposed. We talk about the state of art to more understand the methods and algorithms of optimization, also their procedure. For the comparative study we propose some algorithms of optimization next to the Harmony Search Algorithm (HS), we applied this algorithms on some tests functions to prove why Harmony search is successful.	diversification (finance);hs algorithm;harmony search;heuristic (computer science);mathematical optimization;metaheuristic;optimizing compiler;search algorithm	Mounia Aarich;Hanaa Hachimi;Nabil Hmina	2016	2016 4th IEEE International Colloquium on Information Science and Technology (CiSt)	10.1109/CIST.2016.7804985	quality control and genetic algorithms;optimization problem;extremal optimization;mathematical optimization;multi-swarm optimization;engineering optimization;test functions for optimization;meta-optimization;computer science;derivative-free optimization;stochastic optimization;multi-objective optimization;machine learning;incremental heuristic search;management science;imperialist competitive algorithm;l-reduction;metaheuristic	Robotics	25.478029478884498	-4.5526662711069	102395
a0cf27a5c19c242262d860b57458f974b4174675	modified line search method for global optimization	differential evolution;line search;search problems genetic algorithms;search methods;differential evolution global optimization modified line search genetic algorithms;multilevel systems;genetic algorithm;genetic algorithms;global optimization;search problems;search methods optimization methods multilevel systems genetic algorithms quality of service asia;quality of service;modified line search;asia;optimization methods	This paper introduces a modified version of the well known global optimization technique named line search method. The modifications refer to the way in which the direction and the steps are determined. The modified line search technique (MLS) is applied for some global optimization problems. Functions having a high number of dimensions are considered (50 in this case). Results obtained by the proposed method on a set of well known benchmarks are compared to the results obtained by the standard line search method, genetic algorithms and differential evolution. Numerical results show the effectiveness of the proposed approach while compared to the other techniques	differential evolution;distribution (mathematics);experiment;genetic algorithm;global optimization;line search;map projection;mathematical optimization;numerical analysis;numerical method;optimization problem;randomness;search algorithm;shadow volume;whole earth 'lectronic link	Crina Grosan;Ajith Abraham	2007	First Asia International Conference on Modelling & Simulation (AMS'07)	10.1109/AMS.2007.68	quality control and genetic algorithms;pattern search;beam search;mathematical optimization;meta-optimization;beam stack search;tabu search;derivative-free optimization;local search;hill climbing;machine learning;mathematics;incremental heuristic search;best-first search;combinatorial search;line search;algorithm;metaheuristic;global optimization;guided local search;search algorithm	EDA	25.676933770822608	-1.0805198717580027	102431
5c81e5135ea726b543f09bc11c45afacdf1f571b	reference-inspired many-objective evolutionary algorithm based on decomposition				Xiaogang Fu;Jianyong Sun	2018	Comput. J.	10.1093/comjnl/bxx077	theoretical computer science;evolutionary programming;computer science;evolutionary algorithm	Theory	24.63931984102218	-5.146987780593318	102833
ac18fb179a405f80bcfe94704ede659edafa1ee8	a modified artificial bee colony algorithm for real-parameter optimization	artificial bee colony;swarm intelligence;honey bee;artificial bee colony algorithm;self organization;collective intelligence;real parameter optimization;parameter optimization;foraging behaviour	Swarm intelligence is a research field that models the collective intelligence in swarms of insects or animals. Many algorithms that simulates these models have been proposed in order to solve a wide range of problems. The Artificial Bee Colony algorithm is one of the most recent swarm intelligence based algorithms which simulates the foraging behaviour of honey bee colonies. In this work, modified versions of the Artificial Bee Colony algorithm are introduced and applied for efficiently solving real-parameter optimization problems. 2010 Elsevier Inc. All rights reserved.	artificial bee colony algorithm;collective intelligence;mathematical optimization;swarm intelligence	Bahriye Akay;Dervis Karaboga	2012	Inf. Sci.	10.1016/j.ins.2010.07.015	ant colony optimization algorithms;self-organization;swarm intelligence;computer science;artificial intelligence;machine learning;collective intelligence;artificial bee colony algorithm;metaheuristic	AI	25.943035845690353	-4.633645632313349	102979
981d2ed47faf22746912eec029dd40033e737d71	comparative study of derivative free optimization algorithms	particle swarm;convergence genetic algorithms algorithm design and analysis gradient methods particle swarm optimization;optimisation;differential evolution;convergence;gradient method;convergence of numerical methods;particle swarm optimization pso;simplex method;convergence rate;indexing terms;quasi gradient method simplex method genetic algorithm ga differential evolution algorithm de particle swarm optimization pso;optimisation convergence of numerical methods gradient methods;particle swarm optimizer;quasi gradient method;particle swarm optimization;success rate;gradient methods;genetic algorithm;genetic algorithms;nelder mead simplex method derivative free optimization algorithms quasigradient solution convergence rate convergence speed;derivative free optimization;optimal algorithm;algorithm design;algorithm design and analysis;large scale problem;differential evolution algorithm de;genetic algorithm ga	Derivative free optimization algorithms are often used when it is difficult to find function derivatives, or if finding such derivatives are time consuming. The Nelder Mead's simplex method is one of the most popular derivative free optimization algorithms in the fields of engineering, statistics, and sciences. This algorithm is favored and widely used because of its fast convergence and simplicity. The simplex method converges really well with small scale problems of some variables. However, it does not have much success with large-scale problems of multiple variables. This factor has reduced its popularity in optimization sciences significantly. Two solutions of quasi-gradients are introduced to improve it in terms of the convergence rate and the convergence speed. The improved algorithm with higher success rate and faster convergence which still maintains the simplicity is the key feature of this paper. This algorithm will be compared on several benchmark functions with other popular optimization algorithms such as the genetic algorithm, the differential evolution algorithm, the particle swarm algorithm, and the original simplex method. Then, the comparing results will be reported and discussed.	artificial neural network;benchmark (computing);computation;converge;derivative-free optimization;differential evolution;disjoint-set data structure;evolutionary algorithm;experiment;genetic algorithm;gradient;gradient descent;mathematical optimization;maxima and minima;monte carlo method;numerical analysis;optimizing compiler;rate of convergence;simplex algorithm;swarm	Nam Pham;A. Malinowski;T. Bartczak	2011	IEEE Transactions on Industrial Informatics	10.1109/TII.2011.2166799	algorithm design;mathematical optimization;multi-swarm optimization;meta-optimization;genetic algorithm;computer science;derivative-free optimization;machine learning;mathematics;particle swarm optimization;simplex algorithm;algorithm	ML	28.267307641933478	-5.281547621383113	103104
3002c7deaee77d6c70e1816cc6cef81174d579bf	a tunable magnetic skyrmion neuron cluster for energy efficient artificial neural network		Artificial neuron is one of the fundamental computing unit in brain-inspired artificial neural network. The standard CMOS based artificial neuron designs to implement non-Unear neuron activation function typically consist of large number of transistors, which inevitably causes large area and power consumption. There is a need for novel nanoelectronic device that can intrinsically and efficiently implement such complex non-Unear neuron activation function. Magnetic skyrmions are topologically stable chiral spin textures due to Dzyaloshinskii-Moriya interaction in bulk magnets or magnetic thin films. They are promising next-generation information carrier owing to ultra-small size (sub-10nm), high speed (>100n]/s) with ultra-low depinning current density (MA/cm2) and high defect tolerance compared to conventional magnetic domain wall motion devices. In this work, to the best of our knowledge, we are the first to propose a threshold-tunable artificial neuron based on magnetic skyrmion. Meanwhile, we propose a Skyrmion Neuron Cluster (SNC) to approximate non-linear soft-limiting neuron activation functions, such as the most popular sigmoid function. The device to system simulation indicates that our proposed SNC leads to 98.74% recognition accuracy in deep learning Convolutional Neural Network (CNN) with MNIST handwritten digits dataset Moreover, the energy consumption of our proposed SNC is only 3.1 fj/step, which is more than two orders lower than that of CMOS counterpart.	activation function;approximation algorithm;artificial neural network;artificial neuron;benchmark (computing);cmos;chirality (chemistry);convolutional neural network;deep learning;electrical engineering;http public key pinning;mnist database;magnetic skyrmion;nonlinear system;sap netweaver;sigmoid function;simulation;software bug;transistor	Zhezhi He;Deliang Fan	2017	Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017		electronic engineering;logic gate;telecommunications;sensor;electrical engineering;electrode;current density	EDA	38.97923494393986	-0.9088030860905087	103287
1eba65a7d2c4dfde43f79e45c8fd6644701fbc51	a coupled chaos based image encryption scheme using bit level diffusion		A chaos based image encryption scheme with bit level operation and nonlinear chaotic map is proposed in this paper. The bit plane permutation and diffusion using bits from neighboring pixel and other two colour channels introduce confusion and diffusion within the colour components as well as between the colour components. Simulation results show that the security of the scheme is enhanced when compared with certain known existing schemes.	encryption	P. Devaraj;C. Kavitha	2015		10.1007/978-3-319-22915-7_23	theoretical computer science;distributed computing	Vision	38.74669533299289	-8.89557003916671	103537
23b139044d64553342135471d8e4360de0d51724	a new crossover operator for genetic algorithms	convergence;decoding;search space;algorithm theory genetic algorithms search problems;testing;search space crossover operator genetic algorithms;crossover operator;algorithm theory;genetic algorithm;genetic algorithms;search problems;genetic mutations;genetic algorithms testing convergence genetic mutations decoding	Starting from a mathematical reinterpretation of the classical crossover operator, a new type of crossover is introduced. The proposed new crossover operator gives better performances than the classical 1 point, 2 point or uniform crossover operators. In the paper a theorical investigation of the behaviour of the new crossover is presented. In comparison to the classical crossover operator, it allows a better exploration of the searching space and gives better findings. Some comparative results relative to the optimization of test functions taken from literature are given.	crossover (genetic algorithm);distribution (mathematics);genetic algorithm;mathematical optimization;performance	Moreno Coli;G. Gennuso;Paolo Palazzari	1996		10.1109/ICEC.1996.542361	quality control and genetic algorithms;mathematical optimization;combinatorics;crossover;genetic algorithm;genetic operator;mathematics;chromosome;algorithm	ML	27.596047741307036	-7.231277698541433	104025
7292f485b42df10c3fe8c5dd6eb471ecf8846dbb	improvement on pso with dimension update and mutation	dimension;diversity;optimization;s-dpso	Sub-dimension particle swarm optimization(s-dPSO) is proposed based on basic particle swarm optimization (bPSO). Each dimension of particle in s-dPSO is updated in turn. The dimensions with poor diversity would be mutated that is initialized again to improve the diversity of population and get global optimal solution when the algorithm is in the local convergence. Most Benchmark function get good result with s-dPSO which ability of optimization is better than bPSO.	benchmark (computing);global optimization;local convergence;mathematical optimization;optimization mechanism;particle swarm optimization;randomized algorithm;simulation	Hui Xu;Yongguo Yang;Lei Mao;Hongxia Xie	2013	JSW		mathematical optimization;multi-swarm optimization;artificial intelligence;machine learning;dimension	ML	26.919721248654234	-4.601570251468022	104421
b11eae8f24ed0bf9d9b9a1b76da01999c74766b5	il-shade: improved l-shade algorithm for single objective real-parameter optimization	evolutionary computation;thyristors;cec 2014 benchmark functions il shade algorithm single objective real parameter optimization differential evolution algorithm;indexes;statistics;optimization sociology statistics indexes thyristors benchmark testing evolutionary computation;optimization;sociology;benchmark testing	In this paper we present a differential evolution algorithm (iL-SHADE) for solving single objective real-parameter optimization problems. It is an improved version of the well-known L-SHADE algorithm. The experimental results of our algorithm are presented on CEC 2014 benchmark functions. The experiments were performed on 30 benchmark functions and on four different dimensions. The obtained results show that our algorithm performs highly competitive in comparison with the original L-SHADE algorithm.	algorithm;benchmark (computing);differential evolution;experiment;mathematical optimization;shade 3d;whole earth 'lectronic link	Janez Brest;Mirjam Sepesy Maucec;Borko Boskovic	2016	2016 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2016.7743922	thyristor;database index;benchmark;mathematical optimization;meta-optimization;computer science;machine learning;mathematics;fsa-red algorithm;imperialist competitive algorithm;algorithm;statistics;evolutionary computation;population-based incremental learning	EDA	25.75079776391854	-4.209316616046795	104499
9e1e53d3ad272ba103d9754be1fe2348d745a880	a simple and effective immune particle swarm optimization algorithm	diversity;clonal selection;global search;immune memory;particle swarm optimization;immune system	The Particle Swarm Optimization (PSO) algorithm is a population based evolutional search strategy, which has easer implementation and fewer presetting parameters. But the most difficulty of PSO having to encounter with is premature convergence. This is due to a decrease of diversity during the evolutional process that leads to plunging into local optimum and ultimately fitness stagnation of the swarm. In order to maintain appropriate diversity, a simple and effective immune PSO (IPSO) algorithm is proposed in the paper. IPSO takes advantage of immune operators to update the particles when the algorithm fails to converge to a given threshold. The most difference of IPSO here among other optimization algorithms with immunity is that Gaussian mutation is executed before selecting particles from immune memory library. So the diversity of population is extended adequately, and the risk of trapping into local optimum is depressed effectively. Testing over the benchmark problems, the experimental results indicate the IPSO algorithm prevents premature convergence to a high degree and has better convergence performance than Standard PSO algorithm.	algorithm;particle swarm optimization	Wei Jiao;Weimin Cheng;Mei Zhang;Tianli Song	2012		10.1007/978-3-642-30976-2_59	mathematical optimization;multi-swarm optimization;immune system;computer science;artificial intelligence;machine learning;mathematics;particle swarm optimization	EDA	27.587676445543316	-4.768930406330297	104662
69b51be1bf857e737aa64d099d69ad550845feaa	optimal parameter regions and the time-dependence of control parameter values for the particle swarm optimization algorithm		The particle swarm optimization (PSO) algorithm is a stochastic search technique based on the social dynamics of a flock of birds. It has been established that the performance of the PSO algorithm is sensitive to the values assigned to its control parameters. Many studies have examined the long-term behaviours of various PSO parameter configurations, but have failed to provide a quantitative analysis across a variety of benchmark problems. Furthermore, two important questions have remained unanswered. Specifically, the effects of the balance between the values of the acceleration coefficients on the optimal parameter regions, and whether the optimal parameters to employ are timedependent, warrant further investigation. This study addresses both questions by examining the performance of a global-best PSO using 3036 different parameter configurations on a set of 22 benchmark problems. Results indicate that the balance between the acceleration coefficients does impact the regions of parameter space that lead to optimal performance. Additionally, this study provides concrete evidence that, for the examined problem dimensions, larger acceleration coefficients are preferred as the search progresses, thereby indicating that the optimal parameters are, in fact, time-dependent. Finally, this study provides a general recommendation for the selection of PSO control parameter ∗Corresponding author Email address: kharrison@outlook.com (Kyle Robert Harrison) Preprint submitted to Swarm and Evolutionary Computation October 30, 2017 M AN US CR IP T AC CE PT ED ACCEPTED MANUSCRIPT values.	algorithm;benchmark (computing);coefficient;computer performance;email;evolutionary computation;flock;mathematical optimization;particle swarm optimization;phase-shift oscillator;social dynamics;stochastic optimization	Kyle Robert Harrison;Andries Petrus Engelbrecht;Beatrice M. Ombuki-Berman	2018	Swarm and Evolutionary Computation	10.1016/j.swevo.2018.01.006	mathematical optimization;benchmarking;estimation theory;engineering research;computer science;particle swarm optimization	ML	29.225238931200735	-5.244334641703116	104713
7f24f97487233026aa8f7006d31758823def658b	adaptive clonal selection with elitism-guided crossover for function optimization	evolutionary computation;micromutation operator;clonal selection;search space;function optimization;cloning runtime pathogens educational institutions automation evolutionary computation immune system pattern recognition topology response surface methodology;adaptive clonal selection algorithm;elitism guided crossover operator;search problems artificial intelligence evolutionary computation;artificial intelligence;floating point;search problems;evolutionary algorithm;micromutation operator adaptive clonal selection algorithm elitism guided crossover operator function optimization evolutionary algorithm floating point number encoding;floating point number encoding	Based on clonal selection principle, a novel evolutionary algorithm encoded in floating-point-number is proposed to solve function optimization problems. A micro-mutation operator and an elitism-guided crossover operator are defined respectively for the best and medium antibodies. The main features of the algorithm are combination of meticulous local with double-quick global search, and automatic adjustment of run-time parameters (adaptive extension or shrink of search space). The algorithm is empirically compared with similar approaches from the literature. The results demonstrate that the proposed algorithm can promptly and accurately locate the global optimum of complex function and has good stabilization	algorithmic efficiency;clonal selection algorithm;computation;evolution strategy;evolutionary algorithm;global optimization;local search (optimization);mathematical optimization;profile-guided optimization	Jiang-Qiang Hu;Chen Guo;Tie-shan Li;Jian-Chuan Yin	2006	First International Conference on Innovative Computing, Information and Control - Volume I (ICICIC'06)	10.1109/ICICIC.2006.35	evolutionary programming;mathematical optimization;genetic algorithm;interactive evolutionary computation;computer science;floating point;artificial intelligence;machine learning;evolutionary algorithm;mathematics;evolutionary computation	Robotics	27.375006875649614	-5.223355546636624	104920
eddfbfd378c30088fd0b7ba6ed86803764051773	self-adaptive ant colony system for the traveling salesman problem	traveling salesman problem;optimisation;convergence;ant colony optimization;average tour similarity indicator;average tour similarity indicator self adaptive ant colony system traveling salesman problem pheromone decay parameters;travelling salesman problems adaptive systems optimisation;convergence rate;data mining;ant colony system acs;traveling salesman problems job shop scheduling cybernetics usa councils computer science sun computer industry systems engineering and theory adaptive systems programmable control;adaptive systems;ant colony system;traveling salesman problem ant colony system acs adaptive parameters control;travelling salesman problems;pheromone decay parameters;cities and towns;optimization;traveling salesman problems;benchmark testing;self adaptive ant colony system;adaptive parameters control	In the ant colony system (ACS) algorithm, ants build tours mainly depending on the pheromone information on edges. The parameter settings of pheromone updating in ACS have direct effect on the performance of the algorithm. However, it is a difficult task to choose the proper pheromone decay parameters α and ρ for ACS. This paper presents a novel version of ACS algorithm for obtaining self-adaptive parameters control in pheromone updating rules. The proposed adaptive ACS (AACS) algorithm employs Average Tour Similarity (ATS) as an indicator of the optimization state in the ACS. Instead of using fixed values of α and ρ, the values of α and ρ are adaptively adjusted according to the normalized value of ATS. The AACS algorithm has been applied to optimize several benchmark TSP instances. The solution quality and the convergence rate are favorably compared with the ACS using fixed values of α and ρ. Experimental results confirm that our proposed method is effective and outperforms the conventional ACS.	aacs encryption key controversy;adaptive filter;adaptive grammar;algorithm;ant colony;benchmark (computing);mathematical optimization;rate of convergence;travelling salesman problem	Wei-jie Yu;Xiaomin Hu;Jun Zhang;Rui-zhang Huang	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346279	benchmark;mathematical optimization;ant colony optimization algorithms;convergence;computer science;artificial intelligence;adaptive system;rate of convergence;travelling salesman problem	Robotics	28.24531885761543	-5.273654755621455	104934
1ae70e75103d3fec0cced354af99309c667396ad	using ants as a genetic crossover operator in gls to solve stsp	traveling salesman problem;gls;heuristic crossover;genetic local search;tsp;local search aca gls heuristic crossover;genetics;arrays;traveling salesman problems cities and towns genetics search problems conferences classification algorithms arrays;ant colony algorithm;symmetric tsp;aca;travelling salesman problems;classification algorithms;travelling salesman problems genetic algorithms search problems;optimization algorithms genetic crossover operator ant colony algorithm aca genetic local search gls symmetric tsp stsp traveling salesman problem tsp;cities and towns;genetic algorithms;search problems;traveling salesman problems;optimization algorithms;optimal algorithm;local search;stsp;genetic crossover operator;conferences	Ant Colony Algorithm (ACA) and Genetic Local Search (GLS) are two optimization algorithms that have been successfully applied to the Traveling Salesman Problem (TSP). In this paper we define new crossover operator then redefine ACA's ants as operate according to defined crossover operator then put forward our GLS that uses these ants to solve Symmetric TSP (STSP) instances.	american cryptogram association;ant colony optimization algorithms;crossover (genetic algorithm);generalized least squares;genetic algorithm;heuristic;local search (optimization);mathematical optimization;pointer (computer programming);travelling salesman problem	Hassan Ismkhan	2010	2010 International Conference of Soft Computing and Pattern Recognition	10.1109/SOCPAR.2010.5686165	statistical classification;mathematical optimization;ant colony optimization algorithms;genetic algorithm;computer science;local search;machine learning;travelling salesman problem;algorithm	Robotics	25.07536641987938	-0.9006535354368945	105004
5b0d3aa88f1e66d3f147fe6856cdc9f717ca369e	evolutionary constrained self-localization for autonomous agents	evolutionary computation;robotics;autonomous agent;robotic self localization;evolutionary computing	Abstract: In this paper, a new model for robotic self-localization using constrained evolutionary computation techniques is proposed. The approach uses a previous stage of location estimation based on Kalman filters in order to redefine the search space for a Genetic Algorithm that finds the most accurate current position of a robot. Genetic Algorithms (GAs) have the advantage of being non-gradient-based optimization methods that have an important role in non-linear systems with high noise to signal ratio. The set of solutions is modified according to natural evolution mechanisms. In addition, GAs are used as a parallel, global search technique, and it evaluates many localization solutions simultaneously, improving the probability of finding the global optimum. Experiments using the approach show the promise of the method to predict the correct position in a robotic soccer field with a error margin better than other state-of-the-art techniques.	autonomous robot	Fernando Gutiérrez;John Atkinson	2011	Appl. Soft Comput.	10.1016/j.asoc.2011.01.031	evolutionary programming;mathematical optimization;simulation;interactive evolutionary computation;human-based evolutionary computation;computer science;artificial intelligence;autonomous agent;machine learning;genetic representation;evolutionary robotics;evolutionary computation	AI	28.057078145773698	-3.9161115045939647	105029
7d554e718322076cd998d5e10499dd7cef6603d6	endocrine control evolutionary algorithm	evolutionary computation;endocrine system;glands;endocrine;multiple optima vicinities estimation endocrine control evolutionary algorithm population dynamic control hormones concentration multimodal optimization static environment dynamic environment;dynamic environment;heuristic algorithms;dynamic environment endocrine optimization;aerospace electronics;biochemistry glands optimization endocrine system evolutionary computation heuristic algorithms aerospace electronics;optimization;evolutionary algorithm;evolutionary optimization;biochemistry	The paper presents a new technique for the control of the population's dynamic in evolutionary optimization. The technique is inspired by the endocrine system, respectively, by the control mechanism of the hormones concentration. The approach is suitable for multimodal optimization in static or dynamic environment. The major advantage of the proposal is given by the fact that there is no need of a supplementary mechanism for detecting the changes or an extra parameter for estimate the multiple optima vicinities.	computation;distribution (mathematics);evolutionary algorithm;evolutionary multimodal optimization;experiment;mathematical optimization;multi-objective optimization;multimodal interaction;population;requirement;sensor	Corina Rotar	2010	2010 12th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing	10.1109/SYNASC.2010.27	evolutionary programming;simulation;interactive evolutionary computation;computer science;artificial intelligence;machine learning;evolutionary algorithm;endocrine system;evolutionary computation	Arch	26.969459271631802	-6.027763776069946	105107
69183057b5fc3791c2abe06edfacd3feefa62ada	particle swarm optimizer networks with stochastic connection for improvement of diversity search ability to solve multimodal optimization problems			evolutionary multimodal optimization;mathematical optimization;multimodal interaction;program optimization;swarm	Tomoyuki Sasaki;Hidehiro Nakano;Arata Miyauchi;Akira Taguchi	2017	IEICE Transactions		mathematical optimization;multi-swarm optimization;parallel metaheuristic;computer science;artificial intelligence;machine learning;network topology;metaheuristic	ML	25.57267270307286	-5.30699556096767	105220
927e573581d555e4c648259a3e7d85a27aa14f75	a knowledge-based artificial fish-swarm algorithm	protocols;marine animals;optimization performance;optimal method;blind search;population based optimization algorithm;cafac;function optimization;cultural algorithms ca;visualization;culture algorithm;crossover operator;marine animals optimization cultural differences algorithm design and analysis visualization programming protocols;hybrid optimization methods;search problems artificial life knowledge based systems particle swarm optimisation;nonlinear function optimization;multipeak function knowledge based artificial fish swarm algorithm population based optimization algorithm blind search cafac optimization performance crossover operator culture algorithm;optimization;search problems;optimal algorithm;high dimension;particle swarm optimisation;programming;multipeak function;nonlinear function optimization artificial fish swarm algorithm afa cultural algorithms ca hybrid optimization methods;algorithm design and analysis;knowledge based artificial fish swarm algorithm;artificial life;knowledge based systems;cultural differences;artificial fish swarm algorithm afa;numerical simulation;knowledge base	The Artificial Fish-swarm Algorithm (AFA) is an intelligent population-based optimization algorithm inspired by the behaviors of fish swarm. Unfortunately, it sometimes fails to maintain an appropriate balance between exploration and exploitation, and has a drawback of blind search. In this paper, a novel cultured AFA with the crossover operator, namely CAFAC, is proposed to enhance its optimization performance. The crossover operator utilized is to promote the diversification of the artificial fish and make them inherit their parents’ characteristics. The Culture Algorithms (CA) is also combined with the AFA so that the blind search can be combated with. A total of 10 high-dimension and multi-peak functions are employed to investigate the optimization property of our CAFAC. Numerical simulation results demonstrate that the proposed CAFAC can indeed outperform the original AFA.	academy;algorithm;alternating finite automaton;diversification (finance);embedded system;mathematical optimization;simulation;swarm	Xiao Zhi Gao;Ying Wu;Kai Zenger;Xianlin Huang	2010	2010 13th IEEE International Conference on Computational Science and Engineering	10.1109/CSE.2010.49	communications protocol;algorithm design;programming;mathematical optimization;knowledge base;visualization;computer science;artificial intelligence;machine learning;cultural diversity;artificial life	Robotics	27.920187448353047	-5.927384034524864	105333
62bddb6685ec8c99fbcde802fe64f1a301b56330	an improved gbest-guided artificial bee colony algorithm based on dynamic regulatory factor	search problems convergence optimisation;approximation algorithms;heuristic algorithms optimization algorithm design and analysis search problems approximation algorithms process control particle swarm optimization;heuristic algorithms;particle swarm optimization;optimization algorithm artificial bee colony algorithm gbest guided artificial bee colony algorithm dynamic regulatory factor;process control;optimization;search problems;algorithm design and analysis;complex function gbest guided artificial bee colony algorithm dynamic regulatory factor searching process artificial algorithm global optimization process regulation local optimal process numerical test functions convergence performance drf gabc algorithm optimization problems	To address the problems of Gbest-guided artificial bee colony (GABC) algorithm that the low speed in the searching process and the solution is easy to fall into the local optimal, we presented an improved artificial algorithm with the dynamic regulatory factor (DRF-GABC). The dynamic regulatory factor was introduced into GABC algorithm to dynamically regulate the global optimization process and local optimal process of the algorithm. The improved algorithm was used for optimizing a set of numerical test functions and compared with the original ABC algorithm and the GABC algorithm. The experiments results show that the convergence performance of DRF-GABC algorithm is better than ABC algorithm and GABC algorithm, and it is suitable for solving optimization problems of complex function.	artificial bee colony algorithm;dijkstra's algorithm;distribution (mathematics);experiment;genetic algorithm;global optimization;mathematical optimization;numerical analysis	Jiuyuan Huo;Fanming Meng	2016	2016 Eighth International Conference on Advanced Computational Intelligence (ICACI)	10.1109/ICACI.2016.7449836	mathematical optimization;meta-optimization;computer science;artificial intelligence;machine learning;bees algorithm;fsa-red algorithm;artificial bee colony algorithm;metaheuristic;population-based incremental learning	Robotics	27.786424095724115	-5.12242362417442	105460
6a468d394443d06921ea9677110e960d098e6c0d	a self adaptive hybrid artificial bee colony algorithm for solving cec 2013 real-parameter optimization problems	optimisation;swarm intelligence;swarm intelligence optimisation;optimization convergence particle swarm optimization signal processing algorithms sociology statistics standards;honey bee colonies self adaptive hybrid artificial bee colony algorithm cec 2013 real parameter optimization problems self adaptive hybrid abc algorithm sahabc algorithms swarm intelligence based algorithm	Artificial bee colony (ABC) algorithm is one of the most recently introduced swarm intelligence based algorithm which foraging the behavior of honey bee colonies. In order to improve the convergence performance and searching speed of finding best solution, self adaptive hybrid ABC (SAHABC) is proposed in this paper. For evaluating the performance of standard ABC and proposed SAHABC algorithms, we implemented experiments on CEC 2013 real-parameter single objective optimization problems testbed. SAHABC algorithm demonstrated competitive performance on the optimization problems with the dimension size of 10, 30, and 50 respectively.	artificial bee colony algorithm;experiment;mathematical optimization;swarm intelligence;testbed	Hai Shan;Toshiyuki Yasuda;Kazuhiro Ohkura	2013	Proceedings of the 2013 IEEE/SICE International Symposium on System Integration	10.1109/SII.2013.6776717	mathematical optimization;multi-swarm optimization;ant colony optimization algorithms;meta-optimization;swarm intelligence;engineering;artificial intelligence;machine learning;artificial bee colony algorithm;metaheuristic	Embedded	25.991985794423147	-4.539116868971506	105582
40f9dbb200bfe8694157c22d4d99619de22a17a3	analog learning neural network using two-stage mode by multiple and sample hold circuits	electronic circuit;flexible learning;biomedical vision system;multiple circuit;neural network	In the neural network field, many application models have been proposed. A neuro chip and an artificial retina chip are developed to comprise the neural network model and simulate the biomedical vision system. Previous analog neural network models were composed of the operational amplifier and fixed resistance. It is difficult to change the connection coefficient. In this study, we used analog electronic multiple and sample hold circuits. The connecting weights describe the input voltage. It is easy to change the connection coefficient. This model works only on analog electronic circuits. It can finish the learning process in a very short time and this model will enable more flexible learning.	artificial neural network	Masashi Kawaguchi;Naohiro Ishii;Takashi Jimbo	2014	IJSI	10.4018/ijsi.2014010105	control engineering;electronic engineering;computer science;machine learning;physical neural network;time delay neural network	ML	39.10767352975585	-1.9257552043845465	105586
15ba4e1dc5cf19836effed5bacda742c3582eb60	parallel radial basis function methods for the global optimization of expensive functions	expensive function;optimisation sous contrainte;modelizacion;parallelisme;constrained optimization;algoritmo paralelo;constrained global optimization;parallel evolutionary algorithm;parallel algorithm;intervalo confianza;fonction base radiale;optimum global;boite noire;global optimum;algoritmo genetico;algorithme parallele;response surface model;approximation fonction;surface reponse;optimizacion con restriccion;modelisation;confidence interval;trust region;parallelism;black box;paralelismo;radial basis function;response function;function approximation;intervalle confiance;superficie respuesta;algorithme genetique;algorithme evolutionniste;genetic algorithm;global optimization;algoritmo evolucionista;caja negra;evolutionary algorithm;funcion respuesta;funcion radial base;response surface;modeling;optimo global;parallel optimization;surrogate model;fonction reponse	We introduce a master–worker framework for parallel global optimization of computationally expensive functions using response surface models. In particular, we parallelize two radial basis function (RBF) methods for global optimization, namely, the RBF method by Gutmann [Gutmann, H.M., 2001a. A radial basis function method for global optimization. Journal of Global Optimization 19(3), 201–227] (Gutmann-RBF) and the RBF method by Regis and Shoemaker [Regis, R.G., Shoemaker, C.A., 2005. Constrained global optimization of expensive black box functions using radial basis functions, Journal of Global Optimization 31, 153–171] (CORS-RBF). We modify these algorithms so that they can generate multiple points for simultaneous evaluation in parallel. We compare the performance of the two parallel RBF methods with a parallel multistart derivative-based algorithm, a parallel multistart derivative-free trust-region algorithm, and a parallel evolutionary algorithm on eleven test problems and on a 6-dimensional groundwater bioremediation application. The results indicate that the two parallel RBF algorithms are generally better than the other three alternatives on most of the test problems. Moreover, the two parallel RBF algorithms have comparable performances on the test problems considered. Finally, we report good speedups for both parallel RBF algorithms when using a small number of processors. 2006 Elsevier B.V. All rights reserved.	analysis of algorithms;black box;central processing unit;evolutionary algorithm;global optimization;hierarchical rbf;mathematical optimization;parallel computing;performance;peter gutmann (computer scientist);procedural parameter;radial (radio);radial basis function network;regis;real time kinematic;response surface methodology;trust region	Rommel G. Regis;Christine A. Shoemaker	2007	European Journal of Operational Research	10.1016/j.ejor.2006.08.040	mathematical optimization;constrained optimization;radial basis function;black box;response surface methodology;systems modeling;genetic algorithm;confidence interval;function approximation;computer science;evolutionary algorithm;surrogate model;calculus;mathematics;parallel algorithm;trust region;global optimum;algorithm;global optimization	HPC	27.948824834600085	1.2696234083304672	105646
f2c2cdea0ad57b95f5defe53675bda540b353dbe	spiking neural network-based auto-associative memory using fpga interconnect delays	neural nets content addressable storage field programmable gate arrays;field programmable gate array;neural nets;building block;delay lines;training;neurons context delay field programmable gate arrays biological neural networks delay lines training;chip;onchip soft processor spiking neural network based autoassociative memory fpga interconnect delays snn fpga architectures biological neural networks signal processing circuitry parallel building blocks;spiking neural network;signal processing;fpga architecture;associative memory;resource availability;neurons;field programmable gate arrays;content addressable storage;context;biological neural networks;neural network	This paper describes the design of an auto-associative memory based on a spiking neural network (SNN). The architecture is able to effectively utilize the massive interconnect resources available in FPGA architectures as a good match to the axons in biological neural networks. A complete implementation of the memory on a single FPGA is presented. The signal processing circuitry is composed from simple, parallel building blocks and the training logic is implemented using an on-chip soft processor.	autoassociative memory;combinational logic;content-addressable memory;digital data;electronic circuit;field-programmable gate array;parallel building blocks;programming paradigm;signal processing;spiking neural network	Chong H. Ang;Craig T. Jin;Philip Heng Wai Leong;André van Schaik	2011	2011 International Conference on Field-Programmable Technology	10.1109/FPT.2011.6132701	embedded system;parallel computing;computer science;artificial neural network;field-programmable gate array	EDA	38.714148961554606	-1.5857595657269328	105715
a1db38259c75c09f0c75726cd680c7fd027b0aa4	drawing graphs in parallel lines with artificial neural networks	graph theory;neuron state;graph drawing;neural model;neural nets;multivalued neural network graph drawing;neurons artificial neural networks layout computer science computational modeling optimization books;parallel lines;layout;graphs;books;optimization problem;artificial neural networks;computational modeling;heuristic approach graph drawing parallel lines artificial neural networks multivalued recurrent neural network neural model neuron state two dimensional discrete vector;neural nets graph theory graphs;multivalued recurrent neural network;optimization;multivalued neural network;neurons;computer science;heuristic approach;two dimensional discrete vector;artificial neural network;neural network	In this work, we propose the use of a multivalued recurrent neural network with the aim of graph drawing. Particularly, the problem of drawing a graph in two parallel lines with the minimum number of crossings between edges is studied, and a formulation for this problem is presented. The neural model MREM is used to solve this problem. This model has been successfully applied to other optimization problems. In this case, a slightly different version is used, in which the neuron state is represented by a two dimensional discrete vector, representing the nodes assigned to a given position in each of the parallel lines. Some experimental simulations have been carried out in order to compare the efficiency of the neural network with a heuristic approach designed to solve the problem at hand. These simulations confirm that our neural model outperforms the heuristic approach, obtaining a lower number of crossings on average.	artificial neural network;graph (discrete mathematics);graph drawing;heuristic;mathematical optimization;neural networks;neuron;recurrent neural network;simulation	Enrique Mérida Casermeiro;Domingo López-Rodríguez	2008	2008 Eighth International Conference on Hybrid Intelligent Systems	10.1109/HIS.2008.89	computer science;artificial intelligence;theoretical computer science;machine learning	AI	30.458305784813934	3.815540034037371	105920
5c5b427ef092d9f96e231132e353f5dcce9b3797	genetic search for golomb arrays	autocorrelation function;genetic operator;search space;genetics arrays search problems binary codes binary decision diagrams;binary codes;search method;genetics;arrays;binary decision diagrams;binary codes golomb arrays genetic search decision level chromosome binary array discrete autocorrelation function golomb ruler search space chromosome bit iterative construction binary decisions genetic operations crossover mutation descendent chromosomes experimental results hypergraphs;search problems	Genetic search with a decision level chromosome is used to search efficiently for Golomb (1982) arrays. A Golomb array A is a binary array with three values for its discrete autocorrelation function; M, the number of ones in A for no offset, 1 when there is partial overlap, and 0 otherwise. In one dimension, A is known as a Golomb ruler. The method yields improvement because the genetic search considers only feasible solutions in the most likely portion of the search space. Each chromosome bit represents a decision to place a one in an iterative construction. The representation includes all possible arrays. Since the chromosome bits represent binary decisions in the search space, genetic operations (such as crossover and mutation) always result in feasible descendent chromosomes. Experimental results include comparison to previously known search methods and several new arrays. These results indicate that the proposed search is significantly more efficient than prior methods.	golomb ruler;tiling array	John P. Robinson	2000	IEEE Trans. Information Theory	10.1109/18.841202	binary code;combinatorics;autocorrelation;computer science;theoretical computer science;genetic operator;self-balancing binary search tree;mathematics;uniform binary search;ternary search tree;algorithm;statistics;binary search algorithm;golomb coding	Theory	25.773223862634094	2.9806617668488413	106280
546474fc54da0b35f365ad09d5879c921b40c3a7	a new hybrid memetic multi-objective optimization algorithm for multi-objective optimization		Abstract To deal with the multi-objective optimization problems (MOPs), a meta-heuristic based on an improved shuffled frog leaping algorithm (ISFLA) which belongs to memetic evolution is presented. For the MOPs, both diversity maintenance and searching effectiveness are crucial for algorithm evolution. In this work, modified calculation of crowding distance to evaluate the density of a solution, memeplex clustering analyses based on a grid to divide the population, and new selection measure of global best individual are proposed to ensure the diversity of the algorithm. A multi-objective extremal optimization procedure (MEOP) is also introduced and incorporated into ISFLA to enable the algorithm to evolve more effectively. Finally, the experimental tests on thirteen unconstrained MOPs and DTLZ many-objective problems show that the proposed algorithm is flexible to handle MOPs and many-objective problems. The effectiveness and robustness of the proposed algorithm are also analyzed in detail.	algorithm;mathematical optimization;memetics;multi-objective optimization	Jianping Luo;Yun Yang;Qiqi Liu;Xia Li;Min-Rong Chen;Kai-Zhou Gao	2018	Inf. Sci.	10.1016/j.ins.2018.03.012	grid;robustness (computer science);extremal optimization;cluster analysis;multi-objective optimization;mathematics;shuffled frog leaping algorithm;algorithm;population;optimization problem	AI	25.533297807273648	-3.83886869650703	106336
06a767050e8e79310459dc857416368e9d36801d	robustness of power systems under a democratic fiber bundle-like model		We consider a power system with N transmission lines whose initial loads (i.e., power flows) L(1),...,L(N) are independent and identically distributed with P(L)(x)=P[L≤x]. The capacity C(i) defines the maximum flow allowed on line i and is assumed to be given by C(i)=(1+α)L(i), with α>0. We study the robustness of this power system against random attacks (or failures) that target a p fraction of the lines, under a democratic fiber-bundle-like model. Namely, when a line fails, the load it was carrying is redistributed equally among the remaining lines. Our contributions are as follows. (i) We show analytically that the final breakdown of the system always takes place through a first-order transition at the critical attack size p(☆)=1-(E[L]/max(x)(P[L>x](αx+E[L|L>x])), where E[·] is the expectation operator; (ii) we derive conditions on the distribution P(L)(x) for which the first-order breakdown of the system occurs abruptly without any preceding diverging rate of failure; (iii) we provide a detailed analysis of the robustness of the system under three specific load distributions-uniform, Pareto, and Weibull-showing that with the minimum load L(min) and mean load E[L] fixed, Pareto distribution is the worst (in terms of robustness) among the three, whereas Weibull distribution is the best with shape parameter selected relatively large; (iv) we provide numerical results that confirm our mean-field analysis; and (v) we show that p(☆) is maximized when the load distribution is a Dirac delta function centered at E[L], i.e., when all lines carry the same load. This last finding is particularly surprising given that heterogeneity is known to lead to high robustness against random failures in many other systems.	assumed;dirac delta function;disintegration (morphologic abnormality);emoticon;first-order predicate;ibm power systems;load balancing (computing);maximum flow problem;numerical analysis;pareto efficiency;population parameter;tissue fiber;transmission line	Osman Yagan	2015	Physical review. E, Statistical, nonlinear, and soft matter physics		mathematical optimization;mathematics;statistics	Metrics	37.87933004737622	1.232084107906827	106455
e5bc3ec8630d97aa32f17b25d6889d2b243615d8	hybrid particle swarm - evolutionary algorithm for search and optimization	particle swarm;search problem;swarm intelligence;algoritmo busqueda;search space;algorithme recherche;random generation;speed of convergence;search algorithm;problema investigacion;algoritmo genetico;optimization problem;particle swarm optimizer;optimizacion enjambre particula;mathematical programming;algorithme genetique;optimisation essaim particule;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;evolutionary algorithm;reseau neuronal;probleme recherche;programmation mathematique;programacion matematica;red neuronal;hybrid algorithm;neural network;evolutionary algo rithm	Particle Swarm Optimization (PSO) technique has proved its ability to deal with very complicated optimization and search problems. Several variants of the original algorithm have been proposed. This paper proposes a novel hybrid PSO evolutionary algorithm for solving the well known geometrical place problems. Finding the geometrical place could be sometimes a hard task. In almost all situations the geometrical place consists more than one single point. The performance of the newly proposed PSO algorithm is compared with evolutionary algorithms. The main advantage of the PSO technique is its speed of convergence. Also, we propose a hybrid algorithm, combining PSO and evolutionary algorithms. The hybrid combination is able to detect the geometrical place very fast for which the evolutionary algorithms required more time and the conventional PSO approach even failed to find the real geometrical place.	converge;evolutionary algorithm;hybrid algorithm;iteration;mathematical optimization;particle swarm optimization;phase-shift oscillator;program optimization;rate of convergence;vergence;whole earth 'lectronic link	Crina Grosan;Ajith Abraham;Sang-Yong Han;Alexander F. Gelbukh	2005		10.1007/11579427_63	optimization problem;mathematical optimization;genetic algorithm;hybrid algorithm;search problem;swarm intelligence;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;imperialist competitive algorithm;particle swarm optimization;artificial neural network;algorithm;search algorithm	AI	27.377557467975343	0.8477295838467751	106507
f5771133b873d007bdde06784795f7bdc1b1127d	a survey of computational approaches to three-dimensional layout problems	encapsulation;concepcion asistida;computer aided design;optimisation;modele geometrique;sistema experto;modelo 3 dimensiones;optimizacion;packaging electronico;modele 3 dimensions;layout problem;probleme agencement;three dimensional model;programmation stochastique;encapsulacion;packaging;three dimensional;packaging electronique;stochastic optimization;mathematical programming;electronic packaging;product layout;conception assistee;problema disposicion;empaque;optimization;intelligent packaging;systeme expert;stochastic programming;programmation mathematique;programacion estocastica;programacion matematica;emballage;geometrical model;expert system;modelo geometrico	Component layout plays an important role in the design and usability of many engineering products. The layout problem is also classified under the headings of packing, packaging, configuration, container stuffing, pallet loading or spatial arrangement in the literature. The problem involves the placement of components in an available space such that a set of objectives can be optimized while satisfying optional spatial or performance constraints.	algorithmic efficiency;apache axis;bounding volume hierarchy;catastrophic interference;computation;force-directed graph drawing;fractal;gradient descent;heuristic (computer science);interference (communication);iteration;logic programming;mathematical optimization;modal logic;nonlinear system;octree;opaque binary blob;optimization problem;paging;pattern search (optimization);polygon mesh;problem solving;randomness;rough set;seamless3d;search algorithm;set packing;software release life cycle;stochastic optimization;usability	Jonathan Cagan;K. Shimada;Sun Yin	2002	Computer-Aided Design	10.1016/S0010-4485(01)00109-9	stochastic programming;three-dimensional space;packaging and labeling;simulation;encapsulation;computer science;artificial intelligence;stochastic optimization;computer aided design;mathematics;electronic packaging;engineering drawing;expert system	EDA	34.689096199088155	0.5516876990817191	106571
5d5939c9287e3025abef9e2eaac378435f8fb397	problem difficulty and code growth in genetic programming	population diversity;genetic program;problem difficulty;genetic pro gramming;genetic programming;genetic diversity;symbolic regression;code growth	This paper investigates the relationship between code growth and problem difficulty in genetic programming. The symbolic regression problem domain is used to investigate this relationship using two different types of increased instance difficulty. Results are supported by a simplified model of genetic programming and show that increased difficulty induces higher selection pressure and less genetic diversity, which both contribute toward an increased rate of code growth.	causal filter;genetic programming;problem domain;regular expression;symbolic regression	Steven M. Gustafson;Anikó Ekárt;Edmund K. Burke;Graham Kendall	2004	Genetic Programming and Evolvable Machines	10.1023/B:GENP.0000030194.98244.e3	genetic programming;computer science;artificial intelligence;machine learning;genetic representation;genetics;genetic diversity;algorithm	AI	24.85977182915366	-8.653087360067802	106613
bdda42c5bb0be112498ac7f6b17414625a010ed4	a new chaos particle swarm optimisation algorithm and its applications for transportation continuous network design problem	bi level programming;premature convergence;particle swarms optimisation algorithm;ndp;chaos optimisation;network design problem	In order to overcome the drawback of basic particle swarm optimisation algorithm, such as being subject to fall into local optimisation and being poor in performance of precision, a chaos multi-population particle swarm optimisation algorithm has been proposed, and the algorithm has been effectively used in dealing with the optimisation of transportation continuous network design problem. In this algorithm, multi-population parallel tactics are introduced to improve the global optimising ability and the chaotic search which behaves well in local searching is introduced to improve the solution. The transportation continuous network design problem is solved based on chaos multi-population particle swarm optimisation algorithm. Two examples are presented to compare the proposed method with some existing algorithms. The simulation results show the new particle swarm optimisation algorithm can effectively alleviate the problem of premature convergence and strengthen the global searching ability. The algorithm presented in the paper can apply to solve the large scale traffic design problems.		Changxi Ma;Yinzhen Li;Ruichun He;Zhizhong Chen;Bo Qi;Aixia Diao	2012	IJCSE	10.1504/IJCSE.2012.048087	mathematical optimization;simulation;artificial intelligence;premature convergence	EDA	27.454337602994652	-4.3818408321389235	106682
e3b28da52d236f862637fd6d3605608d4ad7f40a	a novel oriented cuckoo search algorithm to improve dv-hop performance for cyber-physical systems	levy flight;dv hop algorithm;cyber physical systems;probability distribution;oriented cuckoo search algorithm	Wireless sensor network (WSN) is an important component of a cyber–physical system. Locating node information is a crucial problem for WSN. Currently, distance vector-hop method (DV-Hop), one of popular range-free algorithms, is widely deployed to estimate the location. However, the estimation precision is challenging. In this paper, a new evolutionary algorithm named oriented cuckoo search algorithm (OCS) is designed. In OCS, the global search capability is dominated by the combination of two different random distributions. To provide a deep investigation, ten different random distributions are employed and compared with CEC2013 test suits. Numerical results show the hybrid distribution combined with Levy distribution and Cauchy distribution achieves the best performance. Furthermore, OCS with this hybrid distribution is also incorporated into the methodology of DV-Hop algorithm to improve the precision performance. Simulation results demonstrate that our modification achieves better precision performance when compared with three other DV-Hop algorithms.	cuckoo search;cyber-physical system;hop;search algorithm	Zhihua Cui;Bin Sun;Gaige Wang;Jinjun Chen	2017	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2016.10.011	probability distribution;mathematical optimization;simulation;lévy flight;computer science;artificial intelligence;cyber-physical system;statistics	HPC	29.988528400211024	-7.200841286559333	106969
5f776b299666df807efbbfc670f7451036770100	the baldwin effect hinders self-adaptation		The “end-game” of evolutionary optimisation is often largely governed by the efficiency and effectiveness of searching regions of space known to contain high quality solutions. In a traditional EA this role is done via mutation, which creates a tension with its other different role of maintaining diversity. One approach to improving the efficiency of this phase is self-adaptation of the mutation rates. This leaves the fitness landscape unchanged, but adapts the shape of the probability distribution function governing the generation of new solutions. A different approach is the incorporation of local search – so-called Memetic Algorithms. Depending on the paradigm, this approach either changes the fitness landscape (Baldwinian learning) or causes a mapping to a reduced subset of the previous fitness landscape (Lamarkian learning). This paper explores the interaction between these two mechanisms. Initial results suggest that the reduction in landscape gradients brought about by the Baldwin effect can reduce the effectiveness of self-adaptation. In contrast Lamarkian learning appears to enhance the process of self-adaptation, with very different behaviours seen on different problems.	display resolution;gradient;local search (optimization);mathematical optimization;memetic algorithm;memetics;mutation (genetic algorithm);programming paradigm	Jim Smith	2014		10.1007/978-3-319-10762-2_12	artificial intelligence;machine learning	AI	25.58421474073224	-8.531353066842204	107028
e74977eb70c13726d02103302d006840b5118189	fitness landscapes and problem difficulty: the effect of spin-flip symmetry on the performance of the simple ga	optimisation;convergence;algoritmo busqueda;algorithm analysis;optimizacion;algorithme recherche;search algorithm;algoritmo genetico;resolucion problema;convergencia;nearest neighbor;algorithme genetique;genetic algorithm;optimization;analyse algorithme;analisis algoritmo;problem solving;resolution probleme	We use the one-dimensional nearest neighbor interaction functions (NNIs) to show how the presence of symmetry in a tness function greatly innuences the convergence behavior of the simple genetic algorithm (SGA). The eeect of symmetry on the SGA supports the statement that it is not the amount of interaction present in a t-ness function, measured e.g. by Davidor's epistasis variance and the experimental design techniques introduced by Reeves and Wright, which is important, but the kind of interaction. The NNI functions exhibit a minimal amount of second order interaction, are trivial to optimize de-terministically and yet show a wide range of SGA behavior. They have been extensively studied in statistical physics; results from this eld explain the negative eeect of symmetry on the convergence behavior of the SGA. This note intends to introduce them to the GA-community.	design of experiments;distribution (mathematics);earthbound;genetic algorithm;software release life cycle;synthetic genetic array;unbalanced circuit	Bart Naudts;Jan Naudts	1998		10.1007/BFb0056850	mathematical optimization;genetic algorithm;convergence;computer science;artificial intelligence;machine learning;mathematics;k-nearest neighbors algorithm;algorithm;search algorithm	ECom	27.757000437817187	1.2795230933680823	107314
7ae1865e18ea22338df84080297b99d656a3795b	data compression and recovery for power consumption at specific time instances and in peak periods		Compression and recovering of power consumption data through wavelet analysis is described. This technique will reduce the storage needs of such data, enable the reconstruction of data at a sufficient level of accuracy for invoicing, and allow for better energy planning in production facilities.	24-hour clock;coefficient;data compression;download;power supply;time series;wavelet transform	Tetiana Lutchyn;Bernt Lie;Anatoliy Voloshko	2013		10.7148/2013-0587	mathematical optimization;real-time computing;operations management	HCI	37.72795061760121	-4.923862981676826	107581
a9449606615b6e10e60e4ecaf205fe37b7cddfe7	an adaptive genetic algorithm for solving traveling salesman problem	traveling salesman problem;adaptive genetic algorithm;convergence rate;np hard problem;standard genetic algorithm;success rate;genetic algorithm;fuzzy system	Traveling salesman problem (TSP) is a classical NP-hard problem in combinational optimization. This paper adopted a novel genetic algorithm which adjust the crossover probability and mutation probability adaptively based on clustering and fuzzy system, and designed a new crossover operator to improve the performance of genetic algorithm (GA) for TSP. Experiments show that the proposed method is much better than the standard genetic algorithm with a higher convergent rate and success rate.	genetic algorithm;travelling salesman problem	Jina Wang;Jian Huang;Shuqin Rao;Shaoe Xue;Jian Yin	2008		10.1007/978-3-540-85984-0_23	2-opt;mathematical optimization;greedy algorithm;meta-optimization;genetic algorithm;christofides algorithm;computer science;genetic operator;machine learning;np-hard;mathematics;chromosome;rate of convergence;travelling salesman problem;algorithm;fuzzy control system;3-opt;bottleneck traveling salesman problem;population-based incremental learning	Logic	26.690332975094478	-3.316257210970545	107594
1fba187968efbc18523ddee2548d62a31ec0c243	robust granular optimization: a structured approach for optimization under integrated uncertainty	target based tradeoff model robust granular optimization structured optimization approach integrated uncertainty granular computing robust optimization techniques uncertainty identification phase information granulation phase robust optimization phase;uncertainty;integrated uncertainty information granulation granular computing robust optimization;uncertainty optimization robustness computational modeling probabilistic logic stochastic processes fuzzy sets;fuzzy sets;computational modeling;stochastic processes;robustness;optimization;probabilistic logic;uncertainty handling granular computing optimisation	Solving optimization problems under hybrid uncertainty bears a heavy computational burden. In this study, we propose a unified structured optimization approach, termed robust granular optimization (RGO), to tackle the optimization problems under hybrid manifold uncertainties in a computationally tractable manner. Essentially, the RGO can be regarded as a complementary fusion of granular computing and robust optimization techniques. The paradigm of RGO consists of three core phases: 1) uncertainty identification, 2) information granulation in which basic granular units (BGUs) are formed, and 3) robust optimization realized over the BGUs. Following the proposed paradigm, we develop two classes of RGO models for general single-stage and two-stage optimization problems with separable and higher order hybrid uncertainties, respectively. It is shown that both types RGO models can be equivalently transformed into linear programs or mixed integer linear programs that can be handled efficiently by off-the-shelf solvers. Furthermore, a target-based tradeoff model is developed to enhance the flexibility of the RGO models in balancing the granularity level (or robustness level) and the solution conservativeness. The tradeoff model can also be efficiently solved by a binary search algorithm. Finally, sufficient computational studies are presented, and comparisons with the existing approaches show that the RGO models can bring much higher computational efficiency and scalability without losing much optimality, and the RGO solutions exhibit a stronger resistance to the uncertainty.	binary search algorithm;cobham's thesis;computation;granular computing;linear programming;mathematical optimization;program optimization;programming paradigm;robust optimization;scalability	Shuming Wang;Witold Pedrycz	2015	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2014.2360941	stochastic programming;probabilistic-based design optimization;stochastic process;mathematical optimization;robust optimization;uncertainty;computer science;machine learning;mathematics;continuous optimization;fuzzy set;probabilistic logic;computational model;statistics;robustness	DB	35.80250616765224	1.4337002416034896	107681
083313aa5b31d46a6eaf7f386a39e235785ae627	aspects of the selection of the structure and parameters of controllers using selected population based algorithms		In this paper we propose a new approach for selection of the structure and parameters of the control system. Proposed approach is based on the selected population-based algorithms. In this approach we considered a combination of the genetic algorithm (it is used for selection of structure of the control system) fused with one of the follow- ing algorithms: evolutionary algorithm, firefly algorithm, gravitational search algorithm, bat algorithm and imperialist competitive algorithm (they are all used for the selection of parameters of the control system). In experimental simulations a typical problem of the control process was used.	algorithm	Jacek Szczypta;Krystian Lapa;Zhifei Shao	2014		10.1007/978-3-319-07173-2_38	truncation selection;mathematical optimization;cultural algorithm;artificial intelligence;machine learning;fsa-red algorithm;imperialist competitive algorithm;difference-map algorithm;population-based incremental learning	Robotics	25.408150610676522	-5.91149838655678	108037
44b2a81e083abc9d868cf9189cc7340c13d90a4e	visualization of search process and improvement of search performance in multi-objective genetic algorithm	pareto optimisation;article publisher;genetic operator;self organising feature maps data visualisation genetic algorithms mathematical operators pareto optimisation search problems;mathematical operators;multi objective genetic algorithm;optimization problem;data visualisation;self organising feature maps;non dominated sorting genetic algorithm;genetic algorithms biological cells data visualization genetic mutations multidimensional systems acceleration sorting testing optimization methods displays;genetic algorithms;self organized map;search problems;nondominated sorting genetic algorithm search process visualization search performance improvement multiobjective genetic algorithm genetic operators pareto solution multioptimization problem genetic operation self organizing map	Performance in searching solutions by Multi-Objective Genetic Algorithm (MOGA) depends on genetic operators and/or their parameters. For comparison of the performance with some genetic operators and/or parameters, it has been usually employed the transitions of fitness values through actual applications or the number/performance of acquired Pareto solutions in multi-optimization problems. This paper proposes a visualizing method of search process for MOGA, which can visualize relative distances among chromosomes in search process and give information of not only the performance but also the effects of the genetic operations such as the diversity of chromosomes. This method uses Self-Organizing Map (SOM) for the visualization. This paper applies Non Dominated Sorting Genetic Algorithm-II (NSGA-II) to ZDT2 and FON test functions and shows obtained nondominated solutions and visualization results. This paper also shows that the visualized data enables us to interpret the differences in search processes and to get new information to determine efficient genetic operators and their parameters.	distribution (mathematics);genetic algorithm;genetic operator;mathematical optimization;multi-objective optimization;pareto efficiency;powera;scheduling (computing);self-organizing map;sorting	Daisuke Yamashiro;Tomohiro Yoshikawa;Takeshi Furuhashi	2006	2006 IEEE International Conference on Evolutionary Computation	10.1109/CEC.2006.1688439	quality control and genetic algorithms;optimization problem;mathematical optimization;meta-optimization;genetic algorithm;computer science;artificial intelligence;genetic operator;machine learning;genetic representation;data visualization	Visualization	26.572024380042407	-7.045832931085548	108051
0c5cc034ea2f249182debf0f14d08e9ebc6d0a43	parental guidance suggested: how parental imprinting evolves through sexual selection as an adaptive learning mechanism	imprinting;learning;sexual selection;optimal method;mutation rate;adaptive behavior;speciation;natural selection;adaptive learning;mate choice;simulation model;new specie;evolution	The study of adaptive behavior, including learning, usually centers on the effects of natural selection for individual survival. But because reproduction is evolutionarily more important than survival, sexual selection through mate choice (Darwin, 1871), can also have profound consequences on the evolution of creatures’ bodies and behaviors. This paper shows through simulation models how one type of learning, parental imprinting, can evolve purely through sexual selection, to help in selecting appropriate mates and in tracking changes in the phenotypic makeup of the population across generations. At moderate mutation rates, when populationtracking becomes an important but still soluble problem, imprinting proves more useful and evolves more quickly than at low or high mutation rates. We also show that parental imprinting can facilitate the formation of new species. In reviewing the biological literature on imprinting, we note that these results confirm some previous speculations by other researchers concerning the adaptive functions and evolutionary consequences of imprinting. Finally, we discuss how sexual selection through mate choice may have great scientific implications for our understanding of the interactions between evolution, learning, and behavior, and potentially important engineering applications for increasing the efficiency of evolutionary search and optimization	adaptive behavior;autonomous agent;autonomous robot;coincidence point;computable function;darwin;evolution;genetic representation;interaction;mathematical optimization;parental controls;simulation	Peter M. Todd;Geoffrey F. Miller	1993	Adaptive Behaviour	10.1177/105971239300200102	mutation rate;imprinting;natural selection;sexual selection;speciation;adaptive behavior;evolution;adaptive learning;mate choice	AI	25.622819701846435	-9.042063401647773	108397
311907dfbeec009c55cd623c6c8c98fd62905d93	novel path planning of robots based on bidirectional ant colony algorithm	bidirectional ant colony algorithm;optimal solution;optimisation;convergence;path planning feedback mobile robots optimisation;positive feedback;legged locomotion;path planning;ant colony;path planning optimization legged locomotion convergence automation;mobile robots;optimal solution bidirectional ant colony algorithm robot path planning positive feedback;feedback;ant colony algorithm;robot path planning;reverse ants;descending;global optimization;optimization;positive ants;reverse ants ant colony algorithm path planning descending positive ants;automation	For solving the shortcomings of converging slowly and falling into partial delay easily, a new approach for robot path planning is introduced based on bidirectional ant colony searching the optimal solution at the same time. First of all, the two ant colonies at the original and the terminal run with different strategies. Searching on the two paths at the same time makes it more global. Secondly, the descending strategy is taken to adjust the scale of ant colony, so that the positive ants search paths mainly, the positive feedback is enhanced and the speed of the convergence is faster at the latter of the algorithm. Finally, each path can be optimized locally. According to the observations, redundant paths will be found possibly in a 3*3 grid, and it can be pulled into a straight-line distance. Experimental results show that the algorithm actualizes simply, effects stably, and the global optimal path can be found in short time after numerous running.	algorithm;ant colony optimization algorithms;bidirectional search;motion planning;positive feedback;robot	Yongfen Wu;Lei Shi;Qing Li;Yao Chen	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5583520	mathematical optimization;ant colony optimization algorithms;simulation;any-angle path planning;engineering;artificial intelligence	Robotics	30.16001716515278	-2.870849328475317	108538
2b10ebbe823b0fa82f22c095cb461f883aa68470	new discrete chaotic multiplicative maps based on the logistic map			logistic map	Dorota Aniszewska	2018	I. J. Bifurcation and Chaos	10.1142/S0218127418501183	mathematical analysis;mathematics;statistics;logistic map;multiplicative function;chaotic	Logic	38.6385097972576	-7.384752041379057	108602
aa9fce5841528ff74decbf81d26144667b30cfff	enhancing the robustness/efficiency of local search algorithms for sat	local search algorithm;robustness search methods space exploration artificial intelligence large scale integration optimal control np complete problem formal verification encoding explosions;computability;search methods;satisfiability local search;satisfiability;search problems computability;random walk strategy;sat;random walk;heuristic algorithms;local search algorithms;robustness;planning;search problems;random walk strategy local search algorithms sat walksat like algorithms satisfiability;local search;algorithm design and analysis;noise;walksat like algorithms	Walksat-like algorithms are considered among the most powerful local search methods to solve the satisfiability problem. Such algorithms introduce a diversification mechanism based on a random walk strategy. This one is controlled by a noise parameter for which the optimal value setting is strongly dependent on the treated instance. In this paper, we propose to extend a previous work in order to reduce the sensitivity of such algorithms to this setting. This task is accomplished by taking into account relations between variables and a cooperation with a DPLL-like procedure.	boolean satisfiability problem;dpll algorithm;diversification (finance);local search (optimization);optimization problem;walksat	Djamal Habet	2008	2008 20th IEEE International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2008.121	mathematical optimization;computer science;local search;machine learning;mathematics;algorithm	Robotics	27.49436517298916	-7.346348917453295	108731
7898f44de116e4d1277fe8e1da71175c3546d7bf	research on float-coded genetic algorithm based on wavelet denoising mutation	genetic operator;denoising mutation wavelet float code genetic algorithm;fc noise decomposition;wavelet denoising mutation;float code;wavelet transforms;genetic algorithms noise reduction genetic mutations binary codes convergence signal processing algorithms reflective binary codes biological cells algorithm design and analysis computer science;codes;genetic algorithm;genetic algorithms;denoising mutation;float coded genetic algorithm;wavelet transforms codes genetic algorithms;wavelet;wavelet denoising;fc denoising mutation;fc denoising mutation float coded genetic algorithm wavelet denoising mutation fc noise decomposition	Coding is a difficult subject of research on genetic algorithm (GA). In many codes, float code (FC) is super to other codes in use. But, noise and its influence on GA performance were ignored by researches in genetic operation. Mutation played an important role of improving GA performance. Hence, float-coded genetic algorithm (FCGA) based on wavelet denoising mutation (FCGAWM) was proposed in this paper. Decomposing of FC noise was shown with wavelet in theory. FC denoising mutation was implemented in it. The experiment was made in it. The results of the research and the experiment indicated that the theory was credible and the method was feasible in it. FCGAWM is of active significance to extend application space of FCGA.	code;genetic algorithm;mutation (genetic algorithm);noise reduction;wavelet	Mingyi Cui;Yanli Shangguan	2007	Third International Conference on Natural Computation (ICNC 2007)	10.1109/ICNC.2007.623	mathematical optimization;theoretical computer science;machine learning;mathematics	Robotics	30.867846137763248	-5.061388592472016	108772
b3fbe0e2b804d751d412bcbef16a36304517bef6	incorporating highly explorative methods to improve the performance of variable neighborhood search		Variable Neighborhood Search (VNS) is one of the most recently introduced metaheuristics. Although VNS is successfully applied on various problem domains, there is still some room for it to get improved. While VNS has an efficient exploitation strategy, it suffers from its inefficient solution space exploration. To overcome this limitation, VNS can be joined with explorative methods such as Evolutionary Algorithms (EAs) which are global population-based search methods. Due to its effective search space exploration, Differential Evolution (DE) is a popular EA which is a great candidate to be joined with VNS. In this article, two different DEs are proposed to be combined with VNS. The first DE uses explorative evolutionary operators and the second one is a Multi-Population Differential Evolution (MP-DE). Incorporating a number of sub-populations improves the population diversity and increases the chance of reaching to unexplored regions. Both proposed hybrid methods are evaluated on the classical Job Shop Scheduling Problems. The experimental results reveal that the combination of VNS with more explorative method is more reliable to find acceptable solutions. Furthermore, the proposed methods offer competitive solutions compared to the state-of-the-art hybrid EAs proposed to solve JSSPs.	variable neighborhood search	N. R. Raeesi MohammadR.Raeesi;Ziad Kobti	2013	Trans. Computational Science	10.1007/978-3-642-45318-2_14	mathematical optimization;machine learning;data mining	NLP	25.285203084496942	-3.511852533575023	108779
439fc5f5fbae4c0ab2eacf81a77adad4eddcebf8	hybrid firefly variants algorithm for localization optimization in wsn			algorithm;firefly	P. Sridevi Ponmalar;V. Jawahar Senthil Kumar;R. Harikrishnan	2017	Int. J. Comput. Intell. Syst.	10.2991/ijcis.10.1.85	firefly algorithm;multi-swarm optimization;mathematical optimization;differential evolution;artificial intelligence;machine learning;genetic algorithm;firefly protocol;mathematics;particle swarm optimization	Theory	25.198854436948732	-5.237857144779792	108877
8beba82cc31c6aa60d2fa42e2361e07381b14836	parametric modelling of a flexible plate structure using artificial immune system algorithm	dynamic change;parametric modelling;flexible plate;artificial immune system;mean square;dynamic system;immune system;output error;clonal selection algorithm;genetic algorithm;frequency domain	Parametric modelling of dynamic systems may benefit from advantages of biologically-inspired immune system, which maintains its own system against dynamically changing environments through the interaction between lymphocytes and/or antibodies. In this paper, artificial immune system with clonal selection algorithm and artificial immune network are used to identify the unknown parameters characterising a flexible plate system. The identification is performed on basis of minimising the mean-squared output error and is assessed with correlation tests and in time and frequency domains. The approach is tested with three different disturbance signals. Simulation results demonstrate the potential of artificial immune system as promising technique with fast convergence and less computational time in comparison to binary-coded genetic algorithm.	algorithm;artificial immune system	Salihatun Md. Salleh;M. Osman Tokhi	2009		10.1007/978-3-642-03246-2_28	genetic algorithm;immune system;computer science;artificial intelligence;dynamical system;machine learning;immunology;frequency domain;artificial immune system	Robotics	32.09548836924746	-6.39662719157474	109256
849ec2ebb5d9bedf26e3053fb5629b391ae8325f	development and investigation of biologically inspired algorithms cooperation metaheuristic	swarm intelligence;population size;classification;self tuning;real parameter optimization	Cooperation of biologically inspired algorithms as an optimization meta-heuristic is considered. Its performance evaluation and comparison with component algorithms performance on benchmark optimization problems is fulfilled. Workability of the meta-heuristic is demonstrated with artificial neural networks based classifiers tuned to two real world problems.	algorithm;artificial neural network;benchmark (computing);bio-inspired computing;mathematical optimization;metaheuristic;performance evaluation	Shakhnaz Akhmedova;Andrey Shabalov	2013		10.1145/2464576.2480791	mathematical optimization;multi-swarm optimization;population size;biological classification;swarm intelligence;computer science;artificial intelligence;machine learning;metaheuristic	ML	25.021740638706902	-5.338430868615435	109359
156a17e4ae4a74924ff9bcbd871776dda0e815f8	clause states based configuration checking in local search for satisfiability	cybernetics;stochastic processes computability search problems;clause state based configuration checking two mode stochastic local search focused random walk frw satisfiability problem sat problem two mode sls algorithms clause state based cc cscc strategy two mode sls paradigms two mode frw paradigms random sat benchmarks;input variables;arrays;benchmark testing heuristic algorithms search problems input variables arrays smoothing methods cybernetics;smoothing methods;heuristic algorithms;search problems;computability search problems stochastic processes;benchmark testing;clause states based configuration checking cscc local search satisfiability sat;satisfiability sat clause states based configuration checking cscc local search;random sat benchmarks clause state based configuration checking two mode stochastic local search focused random walk frw satisfiability problem sat problem two mode sls algorithms clause state based cc cscc strategy two mode sls paradigms two mode frw paradigms	Two-mode stochastic local search (SLS) and focused random walk (FRW) are the two most influential paradigms of SLS algorithms for the propositional satisfiability (SAT) problem. Recently, an interesting idea called configuration checking (CC) was proposed to handle the cycling problem in SLS. The CC idea has been successfully used to improve SLS algorithms for SAT, resulting in state-of-the-art solvers. Previous CC strategies for SAT are based on neighboring variables, and prove successful in two-mode SLS algorithms. However, this kind of neighboring variables based CC strategy is not suitable for improving FRW algorithms. In this paper, we propose a new CC strategy which is based on clause states. We apply this clause states based CC (CSCC) strategy to both two-mode SLS and FRW paradigms. Our experiments show that the CSCC strategy is effective on both paradigms. Furthermore, our developed FRW algorithms based on CSCC achieve state-of-the-art performance on a broad range of random SAT benchmarks.	algorithm;boolean satisfiability problem;checking (action);experiment;forty nine;inspiration function;local search (constraint satisfaction);local search (optimization);maximum satisfiability problem;programming paradigm;standard sea level;tumor border configuration:type:pt:specimen:nom:cap cancer protocols	Chuan Luo;Shaowei Cai;Kaile Su;Wei Wu	2015	IEEE Transactions on Cybernetics	10.1109/TCYB.2014.2343242	benchmark;mathematical optimization;combinatorics;discrete mathematics;cybernetics;computer science;artificial intelligence;machine learning;mathematics;algorithm	AI	27.702807001674184	-7.000349667421328	109442
662d3d13480e151b33746e2ae5ace3622c74c4d9	constrained optimization problem solved by dynamic constrained nsga-iii multiobjective optimizational techniques	nsga iii constrained optimization multi objective optimization dynamic constrained handling technology;sorting constraint theory genetic algorithms search problems;integrated circuits benchmark testing;nondominated sorting genetic algorithm multiobjective optimizational techniques nsga iii constraints handling dynamic constrained multiobjective optimization problem dcmop violation objective functions differential evolution evolutionary algorithm global search;integrated circuits;benchmark testing	This paper proposes dynamic constrained version of NSGA-III to handle constraints for constrained optimization problems (COPs). The methodology first constructs a dynamic constrained multi-objective optimization problem (DCMOP) equivalent to the COP by converting the constraints into some violation objective functions and gradually shrinking the initially broadened boundary to the original one. Then a dynamic constrained version of the state-of-the-art NSGA-III is implemented to solve the DCMOP. Differential evolution (DE) is used as the evolutionary algorithm to generate offspring. Experimental results show that it is competitive to peer algorithm referred in this paper, and has better performance on global search.	benchmark (computing);c object processor;constrained optimization;differential evolution;dominating set;evolutionary algorithm;moea framework;mathematical optimization;multi-objective optimization;optimization problem	Xi Li;Sanyou Zeng;Sha Qin;Kunqi Liu	2015	2015 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2015.7257252	benchmark;mathematical optimization;constrained optimization;computer science;machine learning;mathematics;mathematical economics	Vision	25.04659572790088	-3.2984599067715514	109587
20a49687887fdd47ad40127dcbdda3468abcd714	hyperplane initialized local search for maxsat	maxsat;local search;initialization	By converting the MAXSAT problem to Walsh polynomials, we can efficiently and exactly compute the hyperplane averages of fixed order k. We use this fact to construct initial solutions based on variable configurations that maximize the sampling of hyperplanes with good average evaluations. The Walsh coefficients can also be used to implement a constant time neighborhood update which is integral to a fast next descent local search for MAXSAT (and for all bounded pseudo-Boolean optimization problems.) We evaluate the effect of initializing local search with hyperplane averages on both the first local optima found by the search and the final solutions found after a fixed number of bit flips. Hyperplane initialization not only provides better evaluations, but also finds local optima closer to the globally optimal solution in fewer bit flips than search initialized with random solutions. A next descent search initialized with hyperplane averages is able to outperform several state-of-the art stochastic local search algorithms on both random and industrial instances of MAXSAT.	coefficient;hadamard transform;local optimum;local search (optimization);mathematical optimization;maxima and minima;maximum satisfiability problem;polynomial;sampling (signal processing);search algorithm;time complexity	Doug Hains;L. Darrell Whitley;Adele E. Howe;Wenxiang Chen	2013		10.1145/2463372.2463468	initialization;mathematical optimization;combinatorics;computer science;local search;maximum satisfiability problem;machine learning;mathematics	AI	27.93601537200559	-0.42148302981960617	109639
c3fd5d6250b75c75f1ea191a9b98e80a9cc820a5	evolution strategies and threshold selection	adaptability;adaptabilite;analisis estadistico;heuristic method;metodo heuristico;hybridation;adaptabilidad;optimisation combinatoire;sphere;hill climbing method;statistical analysis;analyse statistique;metodo escalada;hybridization;evolution strategy;algorithme evolutionniste;algoritmo evolucionista;esfera;hibridacion;methode heuristique;methode escalade;evolutionary algorithm;combinatorial optimization;optimizacion combinatoria	A hybrid approach that combines the (1+1)-ES and threshold selection methods is developed. The framework of the new experimentalism is used to perform a detailed statistical analysis of the effects that are caused by this hybridization. Experimental results on the sphere function indicate that hybridization worsens the performance of the evolution strategy, because evolution strategies are well-scaled hillclimbers: the additional threshold disturbs the self-adaptation process of the evolution strategy. Theory predicts that the hybrid approach might be advantageous in the presence of noise. This effect could be observed— however, a proper fine tuning of the algorithm’s parameters appears to be advantageous.	algorithm;binary search algorithm;combinatorial optimization;combinatorial search;computability;computer science;distribution (mathematics);evolution strategy;image noise;mathematical optimization;modality (human–computer interaction);pareto efficiency	Thomas Bartz-Beielstein	2005		10.1007/11546245_10	artificial intelligence;calculus;mathematics;algorithm	NLP	27.345439328488375	1.9652284076647837	109766
f00ea4f5367252bc93ce5d6b99af5fa13a3f3fb8	optimization of flow diverters for cerebral aneurysms	cerebral aneurysm;flow diverter;simulated annealing;lattice boltzmann simulations;stent optimization	A modern technique to treat cerebral aneurysms is to insert a flow diverter in the parent artery. In order to produce an optimal design of such devices, we consider a methodology combining simulated annealing optimization and lattice Boltzmann simulations. Our results surpass, in terms of stent efficiency, those obtained in the recent literature with an other optimization method. Although our approach is still in 2D, it demonstrates the potential of the method. We give some hint on how the 3D cases can be investigated.		Hitomi Anzai;Makoto Ohta;Jean-Luc Falcone;Bastien Chopard	2012	J. Comput. Science	10.1016/j.jocs.2011.12.006	mathematical optimization;simulation;simulated annealing;computer science	Theory	34.36754217157385	-3.0834506370837755	109982
d4f17ebb9577cb958995ce7fcc39ba87507d9289	towards billion-bit optimization via a parallel estimation of distribution algorithm	optimal solution;scalability analysis;efficiency enhancement;population size;vectorization;population sizing;estimation of distribution algorithm;billion variable optimization;parallelization;compact genetic algorithm;convergence time;large scale problem;large scale optimization	This paper presents a highly efficient, fully parallelized implementation of the compact genetic algorithm (cGA) to solve very large scale problems with millions to billions of variables. The paper presents principled results demonstrating the scalable solution of a difficult test function on instances over a billion variables using a parallel implementation of cGA. The problem addressed is a noisy, blind problem over a vector of binary decision variables. Noise is added equaling up to a tenth of the deterministic objective function variance of the problem, thereby making it difficult for simple hillclimbers to find the optimal solution. The compact GA, on the other hand, is able to find the optimum in the presence of noise quickly, reliably, and accurately, and the solution scalability follows known convergence theories. These results on noisy problem together with other results on problems involving varying modularity, hierarchy, and overlap foreshadow routine solution of billion-variable problems across the landscape of search problems.	distribution (mathematics);estimation of distribution algorithm;genetic algorithm;loss function;mathematical optimization;optimization problem;parallel programming model;scalability;software release life cycle	Kumara Sastry;David E. Goldberg;Xavier Llorà	2007		10.1145/1276958.1277077	mathematical optimization;population size;estimation of distribution algorithm;computer science;theoretical computer science;machine learning;vectorization	AI	28.89136930325181	0.6370473691108655	109990
fe1c25c5ae1dc644fa5b88d9878e08b4210d5319	improving adaptive differential evolution with controlled mutation strategy	controlled mutation;parameter adaptation;differential evolution;selective pressure	In this paper we have proposed a DE variant, abbreviated by ADE_CM, to improve optimization performance of DE by imposing controlled mutation strategy. We also incorporated the concept of selective pressure to choose the random vectors in the selection of donor vector for each population. Basically we used DE/rand/1 and DE/target-to-best/1 schemes (with modifications using selective pressure) in the selection of donor using controlled mutation. The control parameter for mutation, linearly decreasing with generation, is the complement of the probability of selecting DE/target-to-best/1 in each generation. The algorithm is basically a trade-off between diversity and greediness. To improve diversity scaling factor is made adaptive and also a worst p% scheme is used in the difference vector of donor. ADE_CM is tested on 25 benchmark functions of CEC 2005 in 50 and 100 dimensions. Experimental results show that this algorithm outperforms many popular DE variants on most of the functions.	differential evolution	Sayan Basu Roy;Mainak Dan;Pallavi Mitra	2012		10.1007/978-3-642-35380-2_74	differential evolution;mathematical optimization;computer science;artificial intelligence;mathematics;evolutionary pressure;algorithm	Vision	27.36168834596373	-4.617905607411527	110086
f092bcadfc8db7c15beb348fccbcba54758e7387	properties and numerical testing of a parallel global optimization algorithm	parallel computing;global optimization;random search	In the framework of multistart and local search algorithms that find the global minimum of a real function f(x), $ x \in S\subseteq R^n$ , Gaviano et alias proposed a rule for deciding, as soon as a local minimum has been found, whether to perform or not a new local minimization. That rule was designed to minimize the average local computational cost $eval_1(\cdotp)$ required to move from the current local minimum to a new one. In this paper the expression of the cost $eval_2(\cdotp)$ of the entire process of getting a global minimum is found and investigated; it is shown that $eval_2(\cdotp)$ has among its components $eval_1(\cdotp)$ and can be only monotonically increasing or decreasing; that is, it exhibits the same property of $eval_1(\cdotp)$ . Moreover, a counterexample is given that shows that the optimal values given by $eval_1(\cdotp)$ and $eval_2(\cdotp)$ might not agree. Further, computational experiments of a parallel algorithm that uses the above rule are carried out in a MatLab environment.	algorithmic efficiency;computation;experiment;global optimization;local search (optimization);matlab;mathematical optimization;maxima and minima;numerical analysis;parallel algorithm;search algorithm	Marco Gaviano;Daniela Lera	2012	Numerical Algorithms	10.1007/s11075-012-9590-x	mathematical optimization;combinatorics;discrete mathematics;random search;mathematics;global optimization	ML	27.30520334986064	2.0672557701391785	110159
14fdd0eadc797bfdf3ff072c05c92d5f055d18e7	dynamic local search for the maximum clique problem	maximum clique problem;faculty of science environment engineering and technology;artificial intelligent;performance improvement;280213;stochastic local search;local search;other artificial intelligence	In this paper, we introduce DLS-MC, a new stochastic local search algorithm for the maximum clique problem. DLS-MC alternates between phases of iterative improvement, during which suitable vertices are added to the current clique, and plateau search, during which vertices of the current clique are swapped with vertices not contained in the current clique. The selection of vertices is solely based on vertex penalties that are dynamically adjusted during the search, and a perturbation mechanism is used to overcome search stagnation. The behaviour of DLS-MC is controlled by a single parameter, penalty delay, which controls the frequency at which vertex penalties are reduced. We show empirically that DLSMC achieves substantial performance improvements over state-of-the-art algorithms for the maximum clique problem over a large range of the commonly used DIMACS benchmark instances.	benchmark (computing);clique (graph theory);clique problem;cluster analysis;combinatorial optimization;dls format;degree (graph theory);greedy algorithm;heuristic;incremental backup;iterative method;local search (optimization);mathematical optimization;max;programming paradigm;recursive least squares filter;search algorithm;tabu search;utility functions on indivisible goods;monotone	Wayne J. Pullan;Holger H. Hoos	2006	J. Artif. Intell. Res.	10.1613/jair.1815	mathematical optimization;combinatorics;computer science;artificial intelligence;local search;machine learning;mathematics	AI	26.320041113321718	3.2827119630907466	110200
4af0e65fd50e80bcca7663105ce1897adb8f832f	beam pattern synthesis based on improved biogeography-based optimization for reducing sidelobe level		This study deals with a design problem of linear and circular antenna arrays (LAAs and CAAs, respectively) for suppressing the sidelobe levels (SLLs). By adding a new local search strategy and a selection operator into the normal biogeography-based optimization, this work develops a biogeography-based optimization based on local search (BBOLS) algorithm to determine an optimal set of excitation current values for LAAs and an optimal set of excitation current as well as spacing values for CAAs. Various simulations are performed to examine the effectiveness of the proposed BBOLS algorithm in optimizing the radiation beam patterns of LAAs and CAAs, and the results show that BBOLS algorithm has a better performance in reducing the maximum SLL compared with other algorithms such as firefly algorithm. © 2017 Elsevier Ltd. All rights reserved.	firefly (cache coherence protocol);firefly algorithm;local search (optimization);mathematical optimization;radiation pattern;simulation	Han Li;Yanheng Liu;Geng Sun;Aimin Wang;Shuang Liang	2017	Computers & Electrical Engineering	10.1016/j.compeleceng.2017.01.003	mathematical optimization;electronic engineering;simulation;engineering	EDA	31.559546755696495	-3.891733389070736	110404
9de932e234aee68bd12674ff7ead2aaef8f84313	enhancing particle swarm optimization using generalized opposition-based learning	differential evolution;premature convergence;long tail;optimization problem;particle swarm optimizer;large scale problem	Particle swarm optimization (PSO) has been shown to yield good performance for solving various optimization problems. However, it tends to suffer from premature convergence when solving complex problems. This paper presents an enhanced PSO algorithm called GOPSO, which employs generalized opposition-based learning (GOBL) and Cauchy mutation to overcome this problem. GOBL can provide a faster convergence, and the Cauchy mutation with a long tail helps trapped particles escape from local optima. The proposed approach uses a similar scheme as opposition-based differential evolution (ODE) with opposition-based population initialization and generation jumping using GOBL. Experiments are conducted on a comprehensive set of benchmark functions, including rotated multimodal problems and shifted large-scale problems. The results show that GOPSO obtains promising performance on a majority of the test problems. 2011 Elsevier Inc. All rights reserved.	benchmark (computing);davis–putnam algorithm;differential evolution;experiment;local optimum;long tail;mathematical optimization;maxima and minima;multimodal interaction;optimization problem;particle swarm optimization;phase-shift oscillator;premature convergence;sampling (signal processing)	Hui Wang;Zhijian Wu;Shahryar Rahnamayan;Yong Liu;Mario Ventresca	2011	Inf. Sci.	10.1016/j.ins.2011.03.016	differential evolution;optimization problem;mathematical optimization;multi-swarm optimization;computer science;artificial intelligence;machine learning;mathematics;long tail;premature convergence	AI	26.90199187402891	-3.9752705375065127	110683
c4cb089d23e2642d4f8fa6ca61f24fe95d69c812	vaccine-enhanced artificial immune system for multimodal function optimization	organisms;optimisation;artificial immune system;search space;artificial immune systems immune system pathogens vaccines bones protection cells biology organisms blood plasmas;plasmas;function optimization;vaccines;protection;bones;blood;artificial immune system ais;immune system;algorithms antibody affinity artificial intelligence humans immune system models immunological vaccines;multimodal function optimization;antibodies vaccine enhanced artificial immune system multimodal function optimization problem;vaccine artificial immune system ais multimodal function optimization;artificial immune systems;multimodal function optimization problem;cells biology;optimisation artificial immune systems;vaccine;antibodies;pathogens;vaccine enhanced artificial immune system	This paper emulates a biological notion in vaccines to promote exploration in the search space for solving multimodal function optimization problems using artificial immune systems (AISs). In this method, we first divide the decision space into equal subspaces. The vaccine is then randomly extracted from each subspace. A few of these vaccines, in the form of weakened antigens, are then injected into the algorithm to enhance the exploration of global and local optima. The goal of this process is to lead the antibodies to unexplored areas. Using this biologically motivated notion, we design the vaccine-enhanced AIS for multimodal function optimization, achieving promising performance.	algorithm;artificial immune system;benchmark (computing);emulator;extraction;local optimum;local search (optimization);mathematical optimization;multi-objective optimization;multimodal interaction;randomness	Kumlachew M. Woldemariam;Gary G. Yen	2008	2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)	10.1109/TSMCB.2009.2025504	computer science;artificial intelligence;artificial immune system	Robotics	26.259828904102516	-7.274888662386095	110930
4422af90e135a912f6e67a078c60412a12334f23	neural network processing through energy minimization with learning ability to the multiconstraint zero-one knapsack problem	minimisation;neural nets;activation function;combinatorial optimization problems energy function parameters adjustment energy minimization learning ability multiconstraint zero one knapsack problem neural network nnco adjustpar activation functions;combinatorial optimization problem;operations research;energy function;optimization problem;learning systems;knapsack problem;operations research combinatorial mathematics learning systems minimisation neural nets;neural networks computer networks neurons parallel processing computer science power engineering and energy algorithm design and analysis optimization methods polynomials statistical distributions;energy minimization;near real time;neural network model;combinatorial mathematics;neural network	Defines a neural network model NNCO for the multiconstraint zero-one knapsack problem and presents a methodology to solve this problem approximately in near real-time by use of the characteristic that many neural networks can be shown to minimize an energy function defined for the networks. The authors overcome the difficulty that there is not guidance available as to what values the parameters ought to take by designing an algorithm, ADJUSTPAR, for automatically adjusting the values of the parameters used in the energy function. Moreover, they compare the present methodology with related work and demonstrate its advantages. They simulated the neural network model with several appropriate activation functions to solve approximately a set of 11 relatively large and difficult multiconstraint zero one knapsack optimization problems from the literature with well-known optimum solution. The result of the simulation demonstrates how the methodology can work well for the multiconstraint zero-one knapsack problem and can be easily extended to solve other combinatorial optimization problems. >	artificial neural network;energy minimization;knapsack problem;network processor	Hahn-Ming Lee;Ching-Chi Hsu	1989		10.1109/TAI.1989.65366	continuous knapsack problem;optimization problem;minimisation;mathematical optimization;computer science;artificial intelligence;machine learning;activation function;energy minimization;knapsack problem;artificial neural network	ML	30.26726952549496	3.6495364660712206	110962
31643d24339dc24c4623867cb731b5ce3450f40d	a novel quantum noise image preparation method		Quantum noise image has important role in evaluating quantum image quality and testing processing algorithms. A novel preparation method of quantum Gauss noise image is proposed. Furthermore, the experimental simulation proves the efficiency of the method. The research about quantum noise image is of great significance to evaluate and test the schemes for quantum image authentication and secure communication.	quantum noise	Xianhua Song	2016		10.1007/978-981-10-2053-7_6	image quality;gauss;distributed computing;computer science;quantum noise;theoretical computer science;secure communication;quantum computer;quantum;authentication	Vision	38.71721081270121	-8.888026858389242	110985
62b9c90a1d42b9068782583fadc5a92fa47b4dca	an improved particle swarm optimization algorithm for vehicle routing problem with time windows	search method;search strategy;transport system;particle swarm optimizer;social behavior;vehicle routing problem with time windows;neighboring experience improved particle swarm optimization algorithm vehicle routing problem time windows transportation system distribution system collaborative population based search bird flocking social behavior fish schooling global search method;transportation;particle swarm optimization vehicles routing educational institutions search methods automation transportation collaboration birds marine animals;search problems;numerical experiment;particle swarm optimization algorithm;computational efficiency;transportation distribution strategy particle swarm optimisation search problems;particle swarm optimisation;distribution strategy;local search;particle swarm optimization vehicle routing problem with time windows	Vehicle routing problem with time windows (VRPTW) is of crucial importance in today's industries, accounting for a significant portion of many distribution and transportation systems. In this paper, we present a computational-efficient VRPTW algorithm, which is based on the principles of particle swarm optimization (PSO). PSO follows a collaborative population-based search, which models over the social behavior of bird flocking and fish schooling. PSO system combines local search methods (through self experience) with global search methods (through neighboring experience), attempting to balance exploration and exploitation. We discuss the adaptation and implementation of the PSO search strategy to VRPTW and provide a numerical experiment to show the effectiveness of the heuristic. Experimental results indicate that the new PSO algorithm can effectively and quickly get optimal resolution of VRPTW.	algorithm;computation;exploit (computer security);heuristic;local search (optimization);mathematical optimization;microsoft windows;numerical analysis;particle swarm optimization;population;vehicle routing problem	Qing Zhu;Limin Qian;Yingchun Li;Shanjun Zhu	2006	2006 IEEE International Conference on Evolutionary Computation	10.1109/CEC.2006.1688470	transport;mathematical optimization;simulation;social behavior;artificial intelligence;local search	Robotics	27.169415504699433	-2.8520543801718254	111084
ffd42edc23f661ff430db4dfd39e00c6cec55281	an analysis of the value of information when exploring stochastic, discrete multi-armed bandits		In this paper, we propose an information-theoretic exploration strategy for stochastic, discrete multi-armed bandits that achieves optimal regret. Our strategy is based on the value of information criterion. This criterion measures the trade-off between policy information and obtainable rewards. High amounts of policy information are associated with exploration-dominant searches of the space and yield high rewards. Low amounts of policy information favor the exploitation of existing knowledge. Information, in this criterion, is quantified by a parameter that can be varied during search. We demonstrate that a simulated-annealing-like update of this parameter, with a sufficiently fast cooling schedule, leads to a regret that is logarithmic with respect to the number of arm pulls.	akaike information criterion;computer cooling;information theory;multi-armed bandit;regret (decision theory);simulated annealing	Isaac J. Sledge;José Carlos Príncipe	2018	Entropy	10.3390/e20030155	information theory;mathematical optimization;reinforcement learning;mathematics;logarithm;regret;value of information	ML	36.86982452990679	3.562404255354239	111324
b7cd6533066100c3446992217322e9aaaac31a10	a quantized invasive weed optimization based antenna array synthesis with digital phase control	quantized invasive weed optimization;invasive weed optimization;iwo algorithm;digital phase control;binary particle swarm optimization;proposed algorithm search;antenna array;metaheuristic algorithm;quantized particle swarm optimization;array antenna pattern;proposed algorithm;antenna array synthesis	quantized invasive weed optimization;invasive weed optimization;iwo algorithm;digital phase control;binary particle swarm optimization;proposed algorithm search;antenna array;metaheuristic algorithm;quantized particle swarm optimization;array antenna pattern;proposed algorithm;antenna array synthesis		Ratul Majumdar;Ankur Ghosh;Souvik Raha;Koushik Laha;Swagatam Das	2011		10.1007/978-3-642-27172-4_13	mathematical optimization;multi-swarm optimization;control theory	EDA	31.84653817896397	-4.701403004344458	111326
93ad5a543d1c3f896c9d0d11a3c9391df98d6e50	tackling global optimization problems with a novel algorithm - mouth brooding fish algorithm			genetic algorithm;global optimization;mathematical optimization	Ehsan Jahani;Mohammad Chizari	2018	Appl. Soft Comput.	10.1016/j.asoc.2017.09.035		EDA	25.30276435549305	-5.304296446106558	111335
12299947477e1173bba5624cf9ba56474666c4ef	multi population pattern searching algorithm: a new evolutionary method based on the idea of messy genetic algorithm	pattern search;viruses medical;binary codes;bayesian methods;data exchange;search problems binary codes data handling data structures genetic algorithms;indexing terms;bayesian method;linkage learning;biological cells;bayesian optimization algorithm boa;encoding genetic algorithms bayesian methods data structures viruses medical couplings biological cells;population individual multipopulation pattern searching algorithm evolutionary method messy genetic algorithm evolutionary algorithm messy ga idea binary coding schema muppets real life problem gene pattern idea gene group data exchange;data structures;deceptive functions;evolutionary algorithms;messy ga bayesian optimization algorithm boa deceptive functions evolutionary algorithms gene patterns linkage learning;gene patterns;genetic algorithm;messy ga;genetic algorithms;search problems;selective attention;data handling;evolutionary algorithm;couplings;bayesian optimization algorithm;encoding;data structure	One of the main evolutionary algorithms bottlenecks is the significant effectiveness dropdown caused by increasing number of genes necessary for coding the problem solution. In this paper, we present a multi population pattern searching algorithm (MuPPetS), which is supposed to be an answer to situations where long coded individuals are a must. MuPPetS uses some of the messy GA ideas like coding and operators. The presented algorithm uses the binary coding, however the objective is to use MuPPetS against real-life problems, whatever coding schema. The main novelty in the proposed algorithm is a gene pattern idea based on retrieving, and using knowledge of gene groups which contains genes highly dependent on each other. Thanks to gene patterns the effectiveness of data exchange between population individuals improves, and the algorithm gains new, interesting, and beneficial features like a kind of “selective attention” effect.	analysis of algorithms;binary number;blimey cow;computation;computational problem;computer programming;evolutionary algorithm;fitness function;genepattern;genetic algorithm;mathematical optimization;population;real life;search algorithm;self-tuning;software release life cycle;splice (system call);tails	Halina Kwasnicka;Michal Przewozniczek	2011	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2010.2102038	mathematical optimization;genetic algorithm;data structure;bayesian probability;computer science;bioinformatics;artificial intelligence;machine learning;evolutionary algorithm	DB	26.556573013281362	-7.94972262479617	111443
6904eeaaf1c2560eb99c2ca4aa24fb3edf222c01	an analysis of the role of offspring population size in eas	population size	Evolutionary algorithms (EAs) are general stochastic search heuristics often used to solve complex optimization problems. Unfortunately, EA theory is still somewhat weak with respect to providing a deeper understanding of EAs and guidance for the practitioner. In this paper we improve this situation by extending existing theory on the wellknown (1+1) EA to cover the (1 + ) EA, an EA that maintains an o spring population of size . Our goal is to understand how the value of a ects expected optimization time. We compare the (1 + ) EA with the (1+1) EA and prove that on simple unimodal functions no improvements are obtained for > 1. By contrast there are more complex functions for which sensible values of can decrease the optimization time from exponential to a polynomial of small degree with overwhelming probability. These results shed light on the role of and provide some guidelines for the practitioner.	evolutionary algorithm;heuristic (computer science);like button;mathematical optimization;polynomial;stochastic optimization;time complexity	Thomas Jansen;Kenneth A. De Jong	2002			population size;computer science;artificial intelligence;mathematics;algorithm	AI	28.72857363513903	2.5710419104274	111521
d1d8a8683ca10ca685c88e92cbfd75028f5783d6	efficient modeling of linear discrete filters using ant lion optimizer		In this work, a novel application of ant lion optimizer (ALO) has been presented for adaptive identification of infinite impulse response (IIR) filters. ALO is a nature-inspired, population-based, gradient-free meta-heuristic algorithm. It works based on the interaction between antlions and ants and uses Roulette wheel for selection of fitter antlions for catching ants. During the iterative process of optimization, performance of best antlion in each iteration is compared with elite antlion which ensured an optimum solution. To demonstrate the filter modeling efficacy of ALO, four IIR benchmark systems of different orders have been considered for equal and reduced ordered identifications. Modeling performance has been assessed using mean square error (MSE) between the actual and identified model performances, mean square deviation (MSD) between actual and identified IIR filter coefficients and rate of convergence. ALO outperformed the other two recent meta-heuristic algorithms, i.e., cuckoo search algorithm (CSA) and gravitational search algorithm (GSA), recently used for filter modeling. To further assess the robustness of obtained solutions, fifty independent identification trials were conducted and MSE and MSD values were analyzed statistically for standard deviations and means in addition to the statistical t test on MSE values. ALO offered the least standard deviations indicating the robust solutions. Further, in t test, higher positive t values again indicated the significant superiority of ALO over CSA and GSA for IIR filter modeling.	mathematical optimization	Sreejith S. Nair;K. P. S. Rana;Vineet Kumar;Abhishek Chawla	2017	CSSP	10.1007/s00034-016-0370-z	mathematical optimization;simulation;telecommunications;engineering;artificial intelligence;machine learning;control theory;algorithm;statistics	Logic	31.170753575286255	-6.163098614517336	111543
a33a93b95ba867b119e0dde74fb0e725b771affd	redundant representations in evolutionary computation	optimal solution;theoretical model;genetic operator;neutral theory;building block;neutral networks;population size;004 informatik;330 wirtschaft;redundant representations;genetics;trivial voting mapping;trivial voting mapping redundant representations neutral theory neutral networks synonymously redundant non synonymously redundant link and node biased encoding;a priori information;genetic algorithm;synonymously redundant;neutral network;evolutionary algorithm;non synonymously redundant;link and node biased encoding;evolutionary computing	This paper discusses how the use of redundant representations influences the performance of genetic and evolutionary algorithms. Representations are redundant if the number of genotypes exceeds the number of phenotypes. A distinction is made between synonymously and non-synonymously redundant representations. Representations are synonymously redundant if the genotypes that represent the same phenotype are very similar to each other. Non-synonymously redundant representations do not allow genetic operators to work properly and result in a lower performance of evolutionary search. When using synonymously redundant representations, the performance of selectorecombinative genetic algorithms (GAs) depends on the modification of the initial supply. We have developed theoretical models for synonymously redundant representations that show the necessary population size to solve a problem and the number of generations goes with O(2kr/r), where kr is the order of redundancy and r is the number of genotypic building blocks (BB) that represent the optimal phenotypic BB. As a result, uniformly redundant representations do not change the behavior of GAs. Only by increasing r, which means overrepresenting the optimal solution, does GA performance increase. Therefore, non-uniformly redundant representations can only be used advantageously if a-priori information exists regarding the optimal solution. The validity of the proposed theoretical concepts is illustrated for the binary trivial voting mapping and the real-valued link-biased encoding. Our empirical investigations show that the developed population sizing and time to convergence models allow an accurate prediction of the empirical results.	bundle-branch block;computation (action);concatenation;convergence (action);crossover (genetic algorithm);evolutionary algorithm;evolutionary computation;gallium;genetic algorithm;genetic operator;genotype;phenotype;redundancy (engineering);software release life cycle;theory;trees (plant);benefit	Franz Rothlauf;David E. Goldberg	2003	Evolutionary Computation	10.1162/106365603322519288	mathematical optimization;computer science;neutral network;machine learning;evolutionary algorithm;mathematics;genetics;algorithm	AI	25.15522756142871	-8.93644341844944	111559
11a20eeb2a2c44521694bb9bbbf4fefd7a20417c	combining evolutionary and non-evolutionary methods in tracking dynamic global optima	tracking dynamic global optima;non-evolutionary methods;combining evolutionary	The ability to track dynamic functional optima is important in many practical tasks. Recent research in this area has concentrated on modifying evolutionary algorithms (EAs) by triggering changes in control parameters, ensuring population diversity, or remembering past solutions. A set of results are presented that favourably compare hill climbing with a genetic algorithm, and reasons for the results are suggested. A method is then introduced, Evolutionary Random Search (ERS), that combines crossover and hill climbing mutation in a novel manner. It is assessed against the GA and hill climbing tests, and the encouraging results are discussed.	crossover (genetic algorithm);evolutionary algorithm;genetic algorithm;hill climbing;mathematical optimization;mitchell corporation;question answering;random search;software release life cycle	Simon M. Garrett;Joanne H. Walker	2002			machine learning;mathematical optimization;computer science;artificial intelligence	ML	25.903219379422033	-5.370193710755101	111611
191419ccd5ebb2aaad841d4853ca6ebe9e894a73	on the working set selection in gradient projection-based decomposition techniques for support vector machines	quadratic programs;quadratic program;support vector machines;benchmark problem;decomposition techniques;convergence rate;gradient projection methods;indexation;support vector machine;numerical experiment;gradient projection method;large scale problem;large scale problems	This work deals with special decomposition techniques for the large quadratic program arising in training Support Vector Machines. These approaches split the problem into a sequence of quadratic programming subproblems which can be solved by efficient gradient projection methods recently proposed. By decomposing into much larger subproblems than standard decomposition packages, these techniques show promising performance and are well suited for parallelization. Here, we discuss a crucial aspect for their effectiveness: the selection of the working set, that is the index set of the variables to be optimized at each step through the quadratic programming subproblem. We analyse the most popular working set selections and develop a new selection strategy that improves the convergence rate of the decomposition schemes based on large sized working sets. The effectiveness of the proposed strategy within the gradient projection-based decomposition techniques is shown by numerical experiments on large benchmark problems, both in serial and parallel environments.	ansi c;benchmark (computing);binary number;central processing unit;code;discretization;experiment;gradient;image scaling;iteration;mnist database;message passing interface;multiprocessing;numerical analysis;numerical method;power4;parallel computing;quadratic programming;random-access memory;rate of convergence;run time (program lifecycle phase);selection rule;sparse matrix;supercomputer;support vector machine;web page;working set	Thomas Serafini;Luca Zanni	2005	Optimization Methods and Software	10.1080/10556780500140714	support vector machine;mathematical optimization;combinatorics;machine learning;mathematics;quadratic programming	ML	37.284562054568866	1.2377883106278365	111801
6b79b765b37cc5057ce2c9e30073d14b00335cdb	learning instance-independent value functions to enhance local search	evaluation function;local search algorithm;cost function;reinforcement learning;dial a ride problem;value function;combinatorial optimization;local search	Reinforcement learning methods can be used to improve the performance of local search algorithms for combinatorial optimization by learning an evaluation function that predicts the outcome of search. The evaluation function is therefore able to guide search to low-cost solutions better than can the original cost function. We describe a reinforcement learning method for enhancing local search that combines aspects of previous work by Zhang and Dietterich (1995) and Boyan and Moore (1997, Boyan 1998). In an off-line learning phase, a value function is learned that is useful for guiding search for multiple problem sizes and instances. We illustrate our technique by developing several such functions for the Dial-A-Ride Problem. Our learning-enhanced local search algorithm exhibits an improvement of more then 30% over a standard local search algorithm.	bellman equation;combinatorial optimization;evaluation function;local search (constraint satisfaction);local search (optimization);loss function;mathematical optimization;online and offline;reinforcement learning;search algorithm	Robert Moll;Andrew G. Barto;Theodore J. Perkins;Richard S. Sutton	1998			linear search;beam search;mathematical optimization;beam stack search;combinatorial optimization;tabu search;computer science;artificial intelligence;local search;hill climbing;machine learning;iterated local search;mathematics;incremental heuristic search;best-first search;combinatorial search;line search;reinforcement learning;guided local search;search algorithm	ML	25.336392238614998	2.093356452206831	112089
49f560d4dca4414169fda3a0e9a49e7a201b3292	minimizing and learning energy functions for side-chain prediction	partition function;search method;simulated annealing;energy functions;energy function;lennard jones;graphical models;machine learning;belief propagation;prediction accuracy;conditional random field;protein folding;optimization;approximate inference;side chain prediction;inference	Side-chain prediction is an important subproblem of the gen eral protein folding problem. Despite much progress in side-chain prediction, performance is far from satisfactory. As an example, the ROSETTA protocol that uses simulated annealing to selec t th minimum energy conformations, correctly predicts the first two side-chain angles for appro ximately72% of the buried residues in a standard data set. Is further improvement more likely to com e from better search methods, or from better energy functions? Given that exact minimization of t he energy is NP hard, it is difficult to get a systematic answer to this question. In this paper, we present a novel search method and a novel met hod for learning energy functions from training data that are both based on Tree Reweighted Bel ief Propagation (TRBP). We find that TRBP can find theglobaloptimum of the ROSETTA energy function in a few minutes of com putation for approximately85% of the proteins in a standard benchmark set. TRBP can also eff ectively bound the partition function which enables using the Conditional R ndom Fields (CRF) framework for learning. Interestingly, finding the global minimum does not significa ntly improve side-chain prediction for an energy function based on ROSETTA’s default energy terms ( les than0.1%), while learning new weights gives a significant boost from 72% to 78%. Using a recently modified ROSETTA energy function with a softer Lennard-Jones repulsive term, the gl obal optimum does improve prediction accuracy from77% to 78%. Here again, learning new weights improves side-chain mode ling ven further to80%. Our results suggest that combining machine learning with a pproximate inference can improve the state-of-the-art in side-chain prediction.	benchmark (computing);conditional random field;decibel;jones calculus;machine learning;mathematical optimization;maxima and minima;np (complexity);partition function (mathematics);protein structure prediction;simulated annealing;software propagation;ven (currency)	Chen Yanover;Ora Schueler-Furman;Yair Weiss	2007		10.1007/978-3-540-71681-5_27	protein folding;mathematical optimization;lennard-jones potential;simulated annealing;computer science;bioinformatics;artificial intelligence;machine learning;graphical model;partition function;conditional random field;statistics;belief propagation	Comp.	27.79222061974651	-0.8958089772317449	112137
5b5da3a1bc3fb288abef040e6ba780b9e553ce18	parametric identification with performance assessment of wiener systems using brain storm optimization algorithm		This paper proposes a performance assessment-based system identification of different practically useful open-loop and closed-loop Wiener systems using an evolutionary computational algorithm named as brain storm optimization (BSO) algorithm. Different performance measures of the estimation process in practical scenario, i.e., accuracy; precision; consistency; and computational time, are measured with a properly selected fitness function which is the output mean square error (MSE) between the desired and the estimated outputs. Bias and variance of the output MSE have been found negligible for each plant model to show the accuracy and consistency limits, and the corresponding statistical test results have been shown to establish the consistency of the BSO-based identification approach. Efficient identification of each plant under a noisy environment ensures the robustness and the stability of the proposed evolutionary-based identification approach with BSO. The BSO-based optimum MSE values, corresponding estimated parameter values, computational times and the other statistical information are all compared and are found to be superior to those of the other approaches reported earlier.	algorithm	Partha Sarathi Pal;Rajib Kar;Durbadal Mandal;Sakti Prasad Ghoshal	2017	CSSP	10.1007/s00034-016-0464-7	econometrics;mathematical optimization;engineering;machine learning;control theory;statistics	EDA	31.918949197443855	-6.524198905770244	112242
bfd629a2ac9a06acbb5848046f57ee2d12755313	a new multi-function global particle swarm optimization	search capability;particle swarm optimization pso;search behavior;population density;global convergence capability	In this paper, we introduce the concept of population density in PSO, and accordingly, we discuss the relationship between the search capability of PSO and the population density. From related numerical experiments, we find that the search capability of PSO becomes saturated when the population density exceeds a certain value. Accordingly, we propose a strategy that divides the particles into two parts for different functions. Thus, we propose an approach called multi-function global particle swarm optimization (MFPSO) on the basis of this strategy. Further, we carry out a series of numerical experiments to verify that MFPSO has high global convergence capability, high convergence speed, and highly reliable performance when it is used to solve complex problems.	mathematical optimization;particle swarm optimization	Zhao-Hui Ruan;Yuan Yuan;Qi-Xiang Chen;Chuan-Xin Zhang;Yong Shuai;He-Ping Tan	2016	Appl. Soft Comput.	10.1016/j.asoc.2016.07.034	mathematical optimization;multi-swarm optimization;artificial intelligence;machine learning;population density	EDA	27.719206157298196	-3.69290988391361	112433
15bb8cb89dfa8011aa205ad813cbd0c9721c93a9	a selection model for msns of overlay network based on hybrid algorithm	selection model;local search ability;streaming media transmission;multicast service nodes;cluster algorithm;hybrid k medoids genetic model;probability;streaming media multicast algorithms clustering algorithms stability unicast network servers algorithm design and analysis genetics robustness videoconference;evolutional control strategies;convergent speed;diverse gene reservation;genetics;internet;multicast protocols;hybrid clustering algorithms;media streaming;msn selection model;overlay network;streaming media transmission msn selection model overlay network hybrid clustering algorithms hybrid k medoids genetic model multicast service nodes evolutional control strategies diverse gene reservation evolutionary elite reservation local search ability convergent speed probability internet;genetic algorithms;evolutionary elite reservation;search problems;search problems genetic algorithms internet media streaming multicast protocols probability;local search;hybrid algorithm;control strategy	After analyzing the characteristics of overlay network, a hybrid K-medoids genetic model (HKGM) is proposed based on the hybrid clustering algorithms, which is used to choose the multicast service nodes (MSNs) from network nodes. Compared with the traditional K-medoids model, HKGM not only avoids converging to local minimum value, but also is robust to initialization. Also, during the evolution, according to actual features of MSNs in overlay network, the evolutional control strategies including diverse gene and evolutionary elite reservation are used to enhance the local search ability of model, and to increase the convergent speed.	cluster analysis;global optimization;hybrid algorithm;k-medoids;local search (optimization);mathematical optimization;maxima and minima;medoid;multicast;overlay network;premature convergence;software release life cycle	Deqiang Cheng;Jiansheng Qian	2007	Third International Conference on Natural Computation (ICNC 2007)	10.1109/ICNC.2007.135	computer science;theoretical computer science;distributed computing;computer network	Robotics	29.467767434455887	-3.096391644799848	112442
9d527ea424f98ffa5a9689c8c8aa11ebd578f762	machining condition optimization by genetic algorithms and simulated annealing	machining;unconstrained minimization;ensayo en el banco;optimization technique;gradient method;estudio comparativo;simulated annealing algorithm;optimal method;cutting;programmation stochastique;sequential search;simulated annealing;algoritmo genetico;decoupage;optimization problem;etude comparative;methode gradient;usinage;recuit simule;metodo gradiente;mathematical programming;continuous simulation;comparative study;tâche appariement;algorithme genetique;tarea apareamiento;genetic algorithm;recocido simulado;troquelado;mecanizado;stochastic programming;machine model;programmation mathematique;programacion estocastica;bench test;programacion matematica;matching task;essai banc	Optimal machining conditions are the key to economical machining operations. In this work, some benchmark machining models are evaluated for optimal machining conditions. These machining models are complex because of non-linearities and non-convexity. In this research, we have used Genetic Algorithms and Simulated Annealing as optimization methods for solving the benchmark models. An extension of the Simulated Annealing algorithm, Continuous Simulated Annealing is also used. The results are evaluated and compared with each other as well as with previously published results which used gradient based methods, such as, SUMT (Sequential Unconstrained Minimization Technique), Box's Complex Search, Hill Algorithm (Sequential search technique), GRG (Generalized Reduced Gradient), etc. We conclude that Genetic Algorithms, Simulated Annealing and the Continuous Simulated Annealing which are non-gradient based optimization techniques are reliable and accurate for solving machining optimization problems and offer certain advantages over gradient based methods.	genetic algorithm;mathematical optimization;simulated annealing	Z. Khan;B. Prasad;T. Singh	1997	Computers & OR	10.1016/S0305-0548(96)00077-9	mathematical optimization;simulated annealing;computer science;mathematics;adaptive simulated annealing;algorithm	Robotics	27.834661296519865	1.2369834717433024	112487
7befc5e226a4ac37b0e2b315e3ca6a34e08107ee	intercriteria analysis of multi-population genetic algorithms performance		InterCriteria Analysis approach is here applied for the assessment of promising genetic algorithms optimization techniques. Altogether six multi-population genetic algorithms are here considered, differing in the execution order of main genetic operators selection, crossover and mutation. InterCriteria Analysis approach, based on the apparatuses of index matrices and intuitionistic fuzzy sets, is implemented to assess the performance of multi-population genetic algorithms for the parameter identification of Saccharomyces cerevisiae fed-batch fermentation process. Degrees of “agreement” and “disagreement” between the algorithms outcomes convergence time and model accuracy, from one hand, and model parameters estimations, from the other hand, have been established. Outlined relations are going to lead to an additional exploring of the model, expected to be extraordinary valuable especially in the case of modelling of living systems, such as fermentation processes.	crossover (genetic algorithm);fuzzy concept;fuzzy set;genetic algorithm;genetic operator;icra;living systems;loss function;mathematical optimization;metaheuristic;mutation (genetic algorithm);optimization problem;process modeling	Maria Angelova;Tania Pencheva	2017		10.15439/2017F171	machine learning;data mining;genetic algorithm;artificial intelligence;computer science;population	SE	24.637727062163194	-7.943073627238433	112511
bed11e57346f13588248c943b4f718d8645ebb74	one moea uniformity measurement based on generalized spherical transformation	distortion measurement pareto optimization time measurement mathematics evolutionary computation goniometers euclidean distance computational intelligence security coordinate measuring machines;pareto optimisation;uniformity measurement;evolutionary computation;pf;time measurement;pareto front;pareto optimisation decision making evolutionary computation geometry;geometry;multi objective optimization;moea;space euclidean distance moea uniformity measurement generalized spherical transformation evolutionary algorithms multi objective optimization problems pareto front;distortion measurement;euclidean distance;generalized spherical transformation;multi objective optimization problems;spherical transformation moea pf uniformity measurement;distance measurement;correspondence analysis;evolutionary algorithms;optimization;approximation methods;evolutionary algorithm;moea uniformity measurement;multi objective optimization problem;spherical transformation;space euclidean distance	So far there are a number of evolutionary algorithms (EAs) applied in solving multi-objective optimization problems (MOPs), but it is very hard to evaluate the performance of a multi-objective optimization evolutionary algorithm (MOEA) especially to equably evaluate the Pareto Front (PF) when the dimension of the objective space is greater than 2. This paper has made a corresponding analysis on the existed MOEA and proposed a MOEA uniformity measurement based on generalized spherical transformation, which mapped the space points onto a spherical space by transforming the coordinate to get the corresponding polar angle. And then find out the points distributing in different quadrant around according to the polar angle. Finally, measure the uniformity of the points in the space distribution by calculating the space Euclidean distance. The experiments show that this algorithm can well evaluate the distributing of the PF.	circuit complexity;euclidean distance;evolutionary algorithm;experiment;moea framework;mathematical optimization;multi-objective optimization;pareto efficiency	Xueqiang Li;Hai-lin Liu	2008	2008 International Conference on Computational Intelligence and Security	10.1109/CIS.2008.73	mathematical optimization;combinatorics;computer science;multi-objective optimization;machine learning;evolutionary algorithm;mathematics;geometry	Robotics	30.389475607209384	-1.6883689897771224	112843
29ceea6e22232b3d1277509260d2428c577ad1dc	a particle filtering-based estimation of distribution algorithm for multi-objective optimisation	multi objective optimisation;eda;estimation of distribution algorithm;particle filtering	A novel particle filtering-based estimation of distribution algorithm (EDA) is proposed to address multi-objective optimisation problems. Specifically, the particles drawn from a sampling distribution are considered as the candidate solutions. This sampling distribution is computed recursively based on the performance of the prior particle set and the newly arrived observations. As the iteration progresses, the distribution function gradually concentrates on the promising region(s) of the solution space, indicating higher probabilities to obtain solutions with good performances in terms of the objective values. In order to validate the performance of the proposed algorithm, a case study of an environmental economic load dispatch (EELD) is conducted where the bi-objective EELD optimisation problem is solved via the proposed algorithm, and the performance of the proposed algorithm is benchmarked against several algorithms studied in the literature. Experimental results have revealed that the proposed algori...	estimation of distribution algorithm;mathematical optimization;particle filter	Xiaoran Shi;Nurcin Celik	2016	IJSPM	10.1504/IJSPM.2016.078524	econometrics;mathematical optimization;particle filter;electronic design automation;estimation of distribution algorithm;computer science;engineering;statistics	EDA	29.040455027664827	-4.2692950943410874	112928
8df1ea9606dd86a2be9d6df3590805abb1a0736e	a scalable coevolutionary particle swarm optimizer	evolutionary computation;collaboration;biological system modeling;mutation operator;optimization problem;simulation experiment;large scale;particle swarm optimizer;fast cooperative coevolutioanry particle swarm optimizer;mutation operator scalable coevolutionary particle swarm optimizer fast cooperative coevolutioanry particle swarm optimizer;particle swarm optimization;ieee press;particle swarm optimisation evolutionary computation;optimization;evolutionary algorithm;particle swarm optimization evolutionary computation collaborative work genetic mutations large scale systems conferences computational intelligence computer industry information science information management;particle swarm optimisation;scalable coevolutionary particle swarm optimizer;benchmark testing	Most existing evolutionary algorithms are only effective for optimization problems with no more than one hundred decision variables. However, many optimization problems involve more than several hundreds decision variables, even one thousand. To deal with these problems, a fast cooperative coevolutionary particle swarm optimizer (FCPSO) is proposed, which is constructed based on cooperative coevolutionary framework and particle swarm optimizer with simple mutation operator. Simulation experiments on several benchmark functions from one hundred to one thousand decision variables are presented. FCPSO can solve these unimodal and multimodal benchmark functions while the function evaluations needed only linearly increase with decision variables. Therefore, FCPSO is a competitive optimizer for large scale and complex problems.	benchmark (computing);cooperative coevolution;decision theory;evolution strategy;evolutionary algorithm;experiment;mathematical optimization;multimodal interaction;particle swarm optimization;separable polynomial;simulation	Xiangwei Zheng;Hong Liu;Jie Chen	2008	2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application	10.1109/PACIIA.2008.165	optimization problem;benchmark;mathematical optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm;particle swarm optimization;evolutionary computation;collaboration	ML	25.216178074924066	-6.261600178016594	112953
1ed802afcbb26afda226280074ce89305b521f9e	black-box optimization of noisy functions with unknown smoothness		We study the problem of black-box optimization of a function f of any dimension, given function evaluations perturbed by noise. The function is assumed to be locally smooth around one of its global optima, but this smoothness is unknown. Our contribution is an adaptive optimization algorithm, POO or parallel optimistic optimization, that is able to deal with this setting. POO performs almost as well as the best known algorithms requiring the knowledge of the smoothness. Furthermore, POO works for a larger class of functions than what was previously considered, especially for functions that are difficult to optimize, in a very precise sense. We provide a finite-time analysis of POO’s performance, which shows that its error after n evaluations is at most a factor of √ lnn away from the error of the best known optimization algorithms using the knowledge of the smoothness.	adaptive optimization;algorithm;black box;mathematical optimization;optimization problem	Jean-Bastien Grill;Michal Valko;Rémi Munos	2015			mathematical optimization;combinatorics;machine learning;mathematics	ML	31.21867306756639	0.01186394433747818	112963
b0070b7bea51a969a5fad87bdd27e60e84367c93	path planning based on voronoi diagram and biogeography-based optimization	path planning;bbo;cruise missile;voronoi diagram	In this paper, an approach of cruise missile hierarchical path planning based on Voronoi diagram and Biogeography-Based Optimization (BBO) is proposed. First, based on Voronoi diagram, we establish the threat model to describe the planning environment and generate the initial paths and navigation nodes. Then the Biogeography-Based Optimization (BBO) is utilized to search the optimal path. In order to improve the performance of BBO, we adopt an integer priority-based encoding, analyze and discuss the migration rate model and design the migration, mutation and elite operator. Finally, the simulation results show that this approach is effective in cruise missile path planning.	motion planning;program optimization;voronoi diagram	Ning Huang;Gang Liu;Bing He	2012		10.1007/978-3-642-30976-2_27	mathematical optimization;simulation;voronoi diagram;cruise missile;computer science;motion planning	Robotics	30.389823339213763	-2.483972209314937	112997
c43485f53d38b54d94c16df21fb92b917b55dff7	parallel problem solving from nature - ppsn xii		Optimization of an engineering system or component makes a series of changes in the initial random solution(s) iteratively to form the final optimal shape. When multiple conflicting objectives are considered, recent studies on innovization revealed the fact that the set of Pareto-optimal solutions portray certain common design principles. In this paper, we consider a 14-variable bi-objective design optimization of a MEMS device and identify a number of such common design principles through a recently proposed automated innovization procedure. Although these design principles are found to exist among near-Paretooptimal solutions, the main crux of this paper lies in a demonstration of temporal evolution of these principles during the course of optimization. The results reveal that certain important design principles start to evolve early on, whereas some detailed design principles get constructed later during optimization. Interestingly, there exists a simile between evolution of design principles with that of human evolution. Such information about the hierarchy of key design principles should enable designers to have a deeper understanding of their problems.	mit engineering systems division;mathematical optimization;microelectromechanical systems;pareto efficiency;problem solving;program optimization;simile	Josef Kittler;Moni Naor	2012		10.1007/978-3-642-32964-7	computer science	EDA	32.77764990655975	0.31427468145875637	113040
e752bc36b5ab9961aeac1aa4d0d6a5bbee25139b	improved artificial fish swarm algorithm	convergence speed artificial fish swarm algorithm intelligent optimization;optimisation;marine animals;convergence;probability density function;data mining;artificial fish swarm algorithm;intelligent optimization;convergence speed;optimisation convergence;marine animals convergence robustness ant colony optimization information science artificial intelligence optimization methods animal behavior particle swarm optimization difference equations;clustering algorithms;optimization;signal processing algorithms;optimal algorithm	Artificial Fish Swarm Algorithm (AFSA) is a novel intelligent optimization algorithm. It has many advantages, such as good robustness, global search ability, tolerance of parameter setting, and it is also proved to be insensitive to initial values. However, it has some weaknesses as low optimizing precision and low convergence speed in the later period of the optimization. In this paper, an improved AFSA (IAFSA) is proposed with global information added to the artificial fish position in updating process. The experimental results indicate that the optimization precision and the convergence speed of the proposed method are significantly improved when compared with those of original AFSA.	algorithm;anisotropic filtering;computation;global optimization;mathematical optimization;robustness (computer science);swarm	Mingyan Jiang;Dongfeng Yuan;Yongming Cheng	2009	2009 Fifth International Conference on Natural Computation	10.1109/ICNC.2009.343	mathematical optimization;multi-swarm optimization;meta-optimization;computer science;derivative-free optimization;artificial intelligence;machine learning;particle swarm optimization;metaheuristic	Robotics	28.10299515003179	-5.222066428851311	113279
5bc1bcc89a44320e3ddff3ca209fc30cd4b14ea2	alternative combination of improved particle swarm and back propagation neural network	particle swarm;optimal solution;backpropagation neural network;pso algorithm;neural nets;simulated annealing algorithm;iris recognition;backpropagation;simulated annealing;back propagation neural network;fuzzy link;artificial neural networks;rough prediction;particle swarm optimizer;particle swarm optimization;rough prediction particle swarm optimization backpropagation neural network pso algorithm simulated annealing algorithm fuzzy link;mathematical model;simulated annealing algotithm;optimization;simulated annealing algotithm alternating optimization back propagation neural network particle swarm optimization;artificial neural networks biological neural networks algorithm design and analysis optimization iris recognition particle swarm optimization mathematical model;particle swarm optimisation;simulated annealing backpropagation neural nets particle swarm optimisation;alternating optimization;algorithm design and analysis;biological neural networks;neural network	As the back propagation neural network (the BP neural network) can easily be trapped in the local optimal solutions and have slow convergence and the particle swarm optimization (PSO) is weak on the precision of the convergence, this paper proposes a new method to improve the performance with the combination of the two algorithms. This paper applies both of them in a new alternating optimization of neural networks. Besides, taking into account the drawbacks of the single PSO algorithm, the PSO improved by the simulated annealing algorithm (SA) is also applied. The improved algorithm can be used when building a fuzzy link and making a rough prediction just the same as what traditional neural networks do. But it is far more efficient and the error is smaller. To confirm its superiority, this paper uses three specific datasets to test its performance, with a comparison followed. The results prove that this new model is desirable.	algorithm;artificial neural network;backpropagation;mathematical optimization;particle swarm optimization;simulated annealing;software propagation	Jiangbin Wu;Ji Chen;Lin Gu	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5583127	mathematical optimization;computer science;artificial intelligence;machine learning	Robotics	29.312522236741636	-5.490443457485078	113428
dd2e33fc73cc82025add400bfc845eb5bcbea077	an enhanced quantum-behaved particle swarm optimization based on a novel computing way of local attractor	optimization algorithm;local attractor;global optimum;qpso	Quantum-behaved particle swarm optimization (QPSO), a global optimization method, is a combination of particle swarm optimization (PSO) and quantum mechanics. It has a great performance in the aspects of search ability, convergence speed, solution accuracy and solving robustness. However, the traditional QPSO still cannot guarantee the finding of global optimum with probability 1 when the number of iterations is limited. A novel way of computing the local attractor for QPSO is proposed to improve QPSO’s performance in global searching, and this novel QPSO is denoted as EQPSO during which we can guarantee the particles are diversiform at the early stage of iterations, and have a good performance in local searching ability at the later stage of iteration. We also discuss this way of computing the local attractor in mathematics. The results of test functions are compared between EQPSO and other optimization techniques (including six different PSO and seven different optimization algorithms), and the results found by the EQPSO are better than other considered methods.	algorithm;distribution (mathematics);futures studies;genetic algorithm;global optimization;iteration;mathematical optimization;particle swarm optimization;quantum mechanics;robustness (computer science)	Pengfei Jia;Shukai Duan;Jia Yan	2015	Information	10.3390/info6040633	mathematical optimization;multi-swarm optimization;artificial intelligence;machine learning;mathematics;global optimum	AI	27.785990682559547	-4.761692699507285	113444
d0b2f248f793cb212c5206f68af68c164e9584ef	drive cycle generation for design optimization of electric vehicles	transport control electric vehicles stochastic processes stochastic programming;stochastic processes;hybrid ev hev design optimization drive cycle dc generation driving cycle electric vehicle ev;electric vehicles;transport control;stochastic programming;noise optimization drives acceleration hybrid electric vehicles road transportation;load characteristics drive cycle generation electric vehicle ev controller optimization methodology single cycle optimization strategy stochastic optimization technique stochastical analysis probability function dc generation tool dcgt dc module frequency spectra speed distribution acceleration distribution	The majority of design and controller optimization methodologies for electric vehicles (EVs) are based on single-cycle optimization strategies. It has been shown that design parameters that are optimized for one average-assumed drive cycle (DC) are not necessarily optimal when applied to different DCs or to the entire driving profile of a vehicle. Stochastic optimization techniques that consider a multitude of DCs in their objective function can overcome the suboptimalities associated with this so-called cycle beating but, as a drawback, require a large amount of stochastically representative DC data. This paper presents a novel methodology to generate stochastic DCs for the design and control optimization of EVs. DCs and driving profiles are segmented into modules of similar modes of vehicle operation. The key physical parameters of each module are identified and stochastically analyzed. The obtained probability functions of each key parameter are then implemented in a DC generation tool (DCGT). The DCGT is capable of generating an unlimited amount of DCs by reassembling the DC modules according to their stochastic composition. The results show that DCGT-generated DCs accurately represent the original DC data with respect to the frequency spectra, speed distribution, acceleration distribution, and load characteristics of their correspondent duty cycles.	elegant degradation;loss function;mathematical optimization;optimization problem;parallel computing;programming tool;simulation;stochastic optimization	Volker Schwarzer;Reza Ghorbani	2013	IEEE Transactions on Vehicular Technology	10.1109/TVT.2012.2219889	stochastic programming;control engineering;stochastic process;electronic engineering;engineering;control theory;mathematics;statistics	EDA	35.94082342329654	-2.9317691477566026	113666
e10b592455c1016115447b5ae694c67fb4547670	point representation for local optimization	graph theory;hill climbing point representation local optimization stochastic search ordinal point encoding discretized real numbers arbitrary graphs hamming distances approximate high dimensional gray code variant search algorithm genetic algorithms;hamming codes;stochastic search gray code graph labeling local search genetic algorithms;stochastic processes graph theory gray codes hamming codes search problems;stochastic processes;search problems;gray codes;encoding hamming distance optimization labeling genetic algorithms reflective binary codes adsorption	In the context of stochastic search, once regions of high performance are found, having the property that small changes in the candidate solution correspond to searching nearby neighborhoods provides the ability to perform effective local optimization. To achieve this, Gray Codes are often employed for encoding ordinal points or discretized real numbers. In this paper, we present a method to label similar and/or close points within arbitrary graphs with small Hamming distances. The resultant point labels can be viewed as an approximate high-dimensional variant of Gray Codes. The labeling procedure is useful for any task in which the solution requires the search algorithm to select a small subset of items out of many. A large number of empirical results using these encodings with a combination of genetic algorithms and hill-climbing are presented.	approximation algorithm;code;discretization;genetic algorithm;hamming distance;hill climbing;local search (optimization);mathematical optimization;ordinal data;resultant;search algorithm;stochastic optimization;window function	Shumeet Baluja;Michele Covell	2013	2013 IEEE Congress on Evolutionary Computation	10.1109/CEC.2013.6557661	block code;gray code;mathematical optimization;combinatorics;discrete mathematics;hamming distance;hamming bound;graph theory;hill climbing;machine learning;hamming graph;linear code;hamming code;mathematics;forward error correction;hamming(7,4);statistics	Vision	28.850395101801755	3.218587292995975	113697
736910d9990487fb9948c529eac3f00d9c5bd805	abstract functions and lifetime learning in genetic programming for symbolic regression	genetic program;genetic operator;genetic programming;genetics;symbolic regression;hill climbing;lifetime learning;linear scaling	Typically, an individual in Genetic Programming (GP) can not make the most of its genetic inheritance. Once it is mapped, its fitness is immediately evaluated and it survives only until the genetic operators and its competitors eliminate it. Thus, the key to survival is to be born strong.  This paper proposes a simple alternative to this powerlessness by allowing an individual to tune its internal nodes and going through several evaluations before it has to compete with other individuals.  We demonstrate that this system, Chameleon, outperforms standard GP over a selection of symbolic regression type problems on both training and test sets; that the system works harmoniously with two other well known extensions to GP, that is, linear scaling and a diversity promoting tournament selection method; that it can benefit dramatically from a simple cache; that adding to functions set does not always add to the tuning expense; and that tuning alone can be enough to promote smaller trees in the population. Finally, we touch upon the consequences of ignoring the effects of complexity when focusing on just the tree sizes to induce parsimony pressure in GP populations.	complexity;genetic operator;genetic programming;mathematical optimization;maximum parsimony (phylogenetics);occam's razor;population;symbolic regression;tournament selection	R. Muhammad Atif Azad;Conor Ryan	2010		10.1145/1830483.1830645	genetic programming;mathematical optimization;linear scale;computer science;artificial intelligence;hill climbing;genetic operator;machine learning;mathematics;algorithm	AI	25.33424031212316	-9.1579476334085	113764
a2aad022fd03e744c5d2fe69f940012cd4b06cbd	preliminary study of an intelligent sampling decision scheme for the avm system	metrology semiconductor device modeling production time measurement inspection current measurement semiconductor device measurement;intelligent sampling decision isd scheme automatic virtual metrology avm system;intelligent sampling decision scheme periodic samplings process quality inspection manufacturing process virtual metrology wafers production quality monitoring wafer inspection avm system;semiconductor device manufacture computerised instrumentation inspection production engineering computing quality control	Wafer inspection plays a significant role in monitoring the quality of production wafers. However, it requires measuring tools and additional cycle time to do real metrology, which is costly and time-consuming. Therefore, reducing sampling rate to as low as possible is a high priority for many factories to reduce production cost. The most common way for inspecting process quality is to apply periodic sampling. If a manufacturing process is stable, then virtual metrology (VM) may be applied for monitoring the quality of wafers while real metrology is unavailable. Nevertheless, if a production variation occurs between periodic samplings, no real metrology is available during this period for updating the VM models, which may result in un-reliable VM predictions. The authors have developed the automatic virtual metrology (AVM) system for various VM applications. Therefore, this paper focuses on applying various indices of the AVM system to develop an Intelligent Sampling Decision (ISD) scheme for reducing sampling rate while VM accuracy is still sustained.	algorithm;astronomy visualization metadata;plasma-enhanced chemical vapor deposition;sampling (signal processing);virtual metrology;wafer (electronics)	Chun-Fang Chen;Fan-Tien Cheng;Chu-Chieh Wu;Hsuan-Heng Huang	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907363	electronic engineering;engineering;engineering drawing;manufacturing engineering	Robotics	37.58009071938912	-5.0465868847393205	113778
048a6e8b83e4be8e6f6a3f23d93af6a5973d1f01	crips: critical particle swarm optimisation		Particle Swarm Optimisation (PSO) is a metaheuristic used to solve search tasks and is inspired by the flocking behaviour of birds. Traditionally careful tuning of parameters are required to avoid stagnation. Many animals forage using search strategies that show power law distributions in their motions in the form of Lévy flight random walks. It might be expected that when exploring spaces for optima in the absence of any prior knowledge a similar strategy may be useful. Using feedback from swarm metrics, we engineer modifications to the standard PSO algorithm that induce criticality. Such dynamics show long tail distributions in system event sizes. The presence of large (though few) exploratory steps removes the risk of stagnation. The Critical Particle Swarm (CriPS) can be easily combined with many existing PSO extensions.	algorithm;flocking (behavior);long tail;lévy flight;mathematical optimization;metaheuristic;particle swarm optimization;self-organized criticality	Adam Erskine;J. Michael Herrmann	2015		10.7551/978-0-262-33027-5-ch041	swarm behaviour;machine learning;random walk;computer science;artificial intelligence;metaheuristic;power law;lévy flight;particle swarm optimization	ML	25.6682498146366	-7.910072037879444	113791
a42f0705248cf2ca2d923b9d36d1badf80589550	a hybrid firefly algorithm for continuous optimization problems		The search behavior of firefly algorithm (FA) is determined by the attractions among fireflies. In the standard FA and its most modifications, worse fireflies can move toward other better ones, while better fireflies seldom move to other positions. To enhance the search of better fireflies, this paper presents a hybrid firefly algorithm (HFA), Which employs a local search operator inspired by differential evolution (DE). Moreover, the control parameters are dynamically adjusted during the search process. Experiments are conducted on thirteen continuous optimization problems. Computational results show that HFA achieves better solutions than the standard FA and three other improved FA variants.	continuous optimization;firefly algorithm	Wenjun Wang;Hui Wang;Hui Sun;Xiang Yu;Jia Zhao;Yun Wang;Yunhui Zhang;Jinyong Zheng;Yueping Lu;Qianya Chen;Chuanbo Han;Haoping Xie	2016		10.1007/978-3-319-48674-1_46	firefly algorithm;operator (computer programming);mathematical optimization;differential evolution;continuous optimization;computer science;distributed computing;local search (optimization)	Theory	26.603499201370855	-4.193011901022431	113815
7462570ddb98a31c66a049f304f4487be8466298	evolutionary programming using mutations based on the levy probability distribution	processus gauss;optimisation;levy mutation;evolutionary computation;probability;mean square displacement;algorithm performance;genetic programming genetic mutations probability distribution electronic switching systems evolutionary computation biology computing evolution biology fractals functional programming genetic algorithms;loi probabilite;ley probabilidad;algoritmo adaptativo;programmation evolutionniste;evolutionary programming;loi probabilite levy;mean square displacement evolutionary programming levy probability distribution nonadaptive mutations multivariate functional optimization evolutionary optimization;indexing terms;index terms evolutionary optimization;algoritmo genetico;functional programming;function optimization;empirical evidence;adaptive algorithm;algorithme adaptatif;optimisation probability evolutionary computation;levy probability distribution;resultado algoritmo;probability distribution;performance algorithme;algorithme genetique;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;programmation fonctionnelle;levy distribution;gaussian process;evolutionary algorithm;reseau neuronal;proceso gauss;evolutionary optimization;programacion funcional;local search;red neuronal;recherche locale;neural network	Studies evolutionary programming with mutations based on the Levy probability distribution. The Levy probability distribution has an infinite second moment and is, therefore, more likely to generate an offspring that is farther away from its parent than the commonly employed Gaussian mutation. Such likelihood depends on a parameter /spl alpha/ in the Levy distribution. We propose an evolutionary programming algorithm using adaptive as well as nonadaptive Levy mutations. The proposed algorithm was applied to multivariate functional optimization. Empirical evidence shows that, in the case of functions having many local optima, the performance of the proposed algorithm was better than that of classical evolutionary programming using Gaussian mutation.	algorithm;benchmark (computing);evolutionary computation;evolutionary programming;futures studies;local optimum;mathematical optimization;mutation testing	Chang-Yong Lee;Xin Yao	2004	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2003.816583	evolutionary programming;probability distribution;mathematical optimization;genetic algorithm;empirical evidence;index term;computer science;local search;evolutionary algorithm;probability;gaussian process;mathematics;mean squared displacement;lévy distribution;functional programming;algorithm;statistics;evolutionary computation	AI	27.166552423258988	-7.970610957537126	113924
1c187bffa8c002b6338a04eb6192650c0ba72483	geomagnetic navigation of autonomous underwater vehicle based on multi-objective evolutionary algorithm	bio-inspired navigation;evolutionary algorithm;geomagnetic anomaly;geomagnetic navigation;local optimal	This paper presents a multi-objective evolutionary algorithm of bio-inspired geomagnetic navigation for Autonomous Underwater Vehicle (AUV). Inspired by the biological navigation behavior, the solution was proposed without using a priori information, simply by magnetotaxis searching. However, the existence of the geomagnetic anomalies has significant influence on the geomagnetic navigation system, which often disrupts the distribution of the geomagnetic field. An extreme value region may easily appear in abnormal regions, which makes AUV lost in the navigation phase. This paper proposes an improved bio-inspired algorithm with behavior constraints, for sake of making AUV escape from the abnormal region. First, the navigation problem is considered as the optimization problem. Second, the environmental monitoring operator is introduced, to determine whether the algorithm falls into the geomagnetic anomaly region. Then, the behavior constraint operator is employed to get out of the abnormal region. Finally, the termination condition is triggered. Compared to the state-of- the-art, the proposed approach effectively overcomes the disturbance of the geomagnetic abnormal. The simulation result demonstrates the reliability and feasibility of the proposed approach in complex environments.	accidental falls;anomaly detection;british informatics olympiad;drug vehicle;evolutionary algorithm;experiment;feasible region;filezilla client;horseland;inspiration function;manuscripts;mathematical optimization;maxima and minima;mental suffering;motion planning;natural science disciplines;navigation;neurorobotics;numerous;optimization problem;simulation;funding grant	Hong Li;Mingyong Liu;Feihu Zhang	2017		10.3389/fnbot.2017.00034	computer science;machine learning;artificial intelligence;evolutionary algorithm;simulation;control engineering;underwater;earth's magnetic field;jump	AI	29.85434527759535	-4.773768522487254	114076
63c9b3388f84ad49fa6342bf0f0a05c0d852bc0e	exploring the capability of immune algorithms: a characterization of hypermutation operators	complex function;clonal selection;immune algorithm;probleme np complet;juguete;biologia molecular;intelligence artificielle;algoritmo inmunitario;structure proteine;protein structure;jouet;modelo 2 dimensiones;molecular biology;protein structure prediction;structure prediction;toy;success rate;modele 2 dimensions;artificial intelligence;funcion compleja;clonal selection algorithm;fonction complexe;problema np completo;inteligencia artificial;two dimensional model;np complete problem;biologie moleculaire;algorithme immunitaire	In this paper, an important class of hypermutation operators are discussed and quantitatively compared with respect to their success rate and computational cost. We use a standard Immune Algorithm (IA), based on the clonal selection principle to investigate the searching capability of the designed hypermutation operators. We computed the parameter surface for each variation operator to predict the best parameter setting for each operator and their combination. The experimental investigation in which we use a standard clonal selection algorithm with different hypermutation operators on a complex “toy problem”, the trap functions, and a complex NP-complete problem, the 2D HP model for the protein structure prediction problem, clarifies that only few really different and useful hypermutation operators exist, namely: inversely proportional hypermutation, static hypermutation and hypermacromutation operators. The combination of static and inversely proportional Hypermutation and hypermacromutation showed the best experimental results for the “toy problem” and the NP-complete problem.	algorithmic efficiency;clonal selection algorithm;complete (complexity);computation;computational problem;delimiter;list of code lyoko episodes;np-completeness;premature convergence;protein structure prediction;toy problem	Vincenzo Cutello;Giuseppe Nicosia;Mario Pavone	2004		10.1007/978-3-540-30220-9_22	protein structure;np-complete;computer science;artificial intelligence;complex-valued function;protein structure prediction;mathematics;algorithm	AI	26.847181388630105	1.7378292529523887	114133
1bc1ef48b6837c18e9ca5519b08528cf4d09919f	ealib - a java framework for implementation of evolutionary algorithms	algoritmo paralelo;genetic operator;parallel algorithm;paralelisacion;object oriented programming;algoritmo genetico;classification;genetics;algorithme parallele;parallelisation;parallelization;algorithme genetique;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;evolutionary algorithm;programmation orientee objet;clasificacion	This article gives an overview over eaLib, a framework for the implementation of evolutionary algorithms written in Java. After an introduction the kind of genetic representation used in the toolkit is discussed and provided genetico perators are introduced. Thereafter the concept of breaking up an evolutionary algorithm into components and the definition of interfaces for these components is discussed. On that basis a controller model for flexible and fast creation of algorithms is presented. The paper concludes with a section dealing with issues of parallelization of evolutionary algorithms and gives a short outlook on future work.	evolutionary algorithm;java	Andreas Rummler;Gerd Scarbata	2001		10.1007/3-540-45493-4_14	evolutionary programming;genetic algorithm;biological classification;java evolutionary computation toolkit;computer science;artificial intelligence;theoretical computer science;genetic operator;machine learning;evolutionary algorithm;parallel algorithm;object-oriented programming;algorithm	AI	27.435025112228473	1.0318325181713393	114148
59e7e7d9f5a01a022791f14c8b708c712d07d79d	new algorithms for the spaced seeds	homology search;spaced seed;monte carlo;bioinformatics	The best known algorithm computes the sensitivity of a given spaced seed on a random region with running time O((M +L)|B|), where M is the length of the seed, L is the length of the random region, and |B| is the size of seed-compatible-suffix set, which is exponential to the number of 0’s in the seed. We developed two algorithms to improve this running time: the first one improves the running time to O(|B′|2ML), where B′ is a subset of B; the second one improves the running time to O((M |B|)log(L/M)), which will be much smaller than the original running time when L is large. We also developed a Monte Carlo algorithm which can guarantee to quickly find a near optimal seed with high probability.	monte carlo algorithm;monte carlo method;seed;time complexity;with high probability	Xin Gao;Shuai Cheng Li;Yinan Lu	2007		10.1007/978-3-540-73814-5_5	simulation;computer science;machine learning;statistics	Theory	29.28852705356952	3.344112358869422	114209
127325dbefe437c6380d6cd61c6f6b20d15f05bd	rodes: a robust-design synthesis tool for probabilistic systems		We introduce RODES – a tool for the synthesis of probabilistic systems that satisfy strict reliability and performance requirements, are Pareto-optimal with respect to a set of optimisation objectives, and are robust to variations in the system parameters. Given the design space of a system (modelled as a parametric continuous-time Markov chain), RODES generates system designs with low sensitivity to required tolerance levels for the system parameters. As such, RODES can be used to identify and compare robust designs across a wide range of Paretooptimal tradeo↵s between the system optimisation objectives.	markov chain;mathematical optimization;pareto efficiency;requirement;robustness (computer science)	Radu Calinescu;Milan Ceska;Simos Gerasimou;Marta Z. Kwiatkowska;Nicola Paoletti	2017		10.1007/978-3-319-66335-7_20	computer science;mathematical optimization;theoretical computer science;probabilistic logic;parametric statistics;markov chain	EDA	36.43077545676158	1.989292779943339	114238
4c4e6c75ed4297b1542850ed236dc93a923a9ea7	genetic programming with multiple initial populations generated by simulated annealing	simulated annealing genetic algorithms;simulated annealing;evolutionary computation genetic programming simulated annealing programming;p gap method genetic programming simulated annealing programming gp sap;genetic algorithms;sociology statistics cooling search problems simulated annealing automatic programming	Genetic Programming (GP) and Simulated Annealing Programming (SAP) are typical metaheuristic methods for automatic programming. We propose a new method, Parallel - Genetic and Annealing Programming (P-GAP) which combines GP and SAP. In P-GAP, multiple initial populations are generated by SAP. Respective populations evolve by parallel GP. As the generation proceeds, populations are integrated gradually. To examine the effectiveness, we compared P-GAP with the conventional methods in five test problems. As a result, P-GAP showed better performance than GP and SAP.	automatic programming;genetic programming;metaheuristic;population;simulated annealing	Takuya Mototsuka;Akira Hara;Jun-ichi Kushida;Tetsuyuki Takahama	2013	2013 IEEE 6th International Workshop on Computational Intelligence and Applications (IWCIA)	10.1109/IWCIA.2013.6624797	mathematical optimization;genetic algorithm;simulated annealing;computer science;theoretical computer science;machine learning;adaptive simulated annealing	Robotics	25.916845202214933	-5.420162092021507	114317
0ec52c4b76a4314ed46823d29903c98a0efe9da1	on test functions for evolutionary multi-objective optimization	parallelisme;multiobjective programming;optimum pareto;programmation multiobjectif;optimisation;piecewise linear;algorithm performance;optimizacion;evolutionary multi objective optimization;funcion densidad probabilidad;probability density function;pareto front;benchmark problem;multi objective optimization;fonction objectif;resolucion problema;objective function;fonction densite probabilite;parallelism;paralelismo;linearisation morceau;mathematical programming;biomimetique;resultado algoritmo;parameter space;performance algorithme;linearizacion trozo;algorithme evolutionniste;funcion objetivo;algoritmo evolucionista;optimization;evolutionary algorithm;pareto optimum;optimal algorithm;programmation mathematique;optimo pareto;programacion matematica;piecewise linearization;problem solving;resolution probleme;biomimetics;programacion multiobjetivo	In order to evaluate the relative performance of optimization algorithms benchmark problems are frequently used. In the case of multi- objective optimization (MOO), we will show in this paper that most known benchmark problems belong to a constrained class of functions with piecewise linear Pareto fronts in the parameter space. We present a straightforward way to define benchmark problems with an arbitrary Pareto front both in the fitness and parameter spaces. Furthermore, we introduce a difficulty measure based on the mapping of probability den- sity functions from parameter to fitness space. Finally, we evaluate two MOO algorithms for new benchmark problems.	distribution (mathematics);multi-objective optimization;program optimization	Tatsuya Okabe;Yaochu Jin;Markus Olhofer;Bernhard Sendhoff	2004		10.1007/978-3-540-30217-9_80	mathematical optimization;test functions for optimization;multi-objective optimization;evolutionary algorithm;mathematics;mathematical economics;algorithm	Logic	27.565865368345122	1.245278525438617	114394
8d0cfc1c9f12d27facb225f5fdb7a114e4d910e2	fractional dynamics in particle swarm optimization	system response;evolutionary computation;fourier analysis particle swarm optimization fractional dynamics system response perturbation effect;particle swarm optimization fractional calculus chaos differential equations performance analysis performance evaluation integral equations laplace equations frequency mathematics;fractional dynamics;particle swarm optimizer;particle swarm optimization;fourier analysis;particle swarm optimisation evolutionary computation fourier analysis;perturbation effect;particle swarm optimisation	This paper studies the fractional dynamics during the evolution of a Particle Swarm Optimization (PSO). Some swarm particles of the initial population are randomly changed for stimulating the system response. After the result is compared with a reference situation. The perturbation effect in the PSO evolution is observed in the perspective of the time behavior of the fitness of the best individual position visited by the replaced particles. The dynamics is investigated through the median of a sample of experiments, while adopting the Fourier analysis for describing the phenomena. The influence of the PSO parameters upon the global dynamics is also analyzed by performing several experiments for distinct values.	butterfly effect;experiment;fourier analysis;mathematical optimization;particle swarm optimization;perturbation theory (quantum mechanics);phase-shift oscillator;randomness;software propagation	Eduardo José Solteiro Pires;José António Tenreiro Machado;Paulo B. de Moura Oliveira;Cecília Reis	2007	2007 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2007.4414165	mathematical optimization;multi-swarm optimization;computer science;calculus;mathematics;fourier analysis;particle swarm optimization;metaheuristic;evolutionary computation	Robotics	29.891286132606055	-5.147795481783865	114435
efa41383acf8b868c3cbd0ce3a84cf9bf0d9f007	an adaptive stochastic global optimization algorithm for one-dimensional functions	wiener process;stopping criteria;stopping rule;look ahead;objective function;posterior distribution;random variable;global optimization	In this paper a new algorithm is proposed, based upon the idea of modeling the objective function of a global optimization problem as a sample path from a Wiener process. Unlike previous work in this field, in the proposed model the parameter of the Wiener process is considered as a random variable whose conditional (posterior) distribution function is updated on-line. Stopping criteria for Bayesian algorithms are discussed and detailed proofs on finite-time stopping are provided.	algorithm;global optimization;mathematical optimization	Marco Locatelli;Fabio Schoen	1995	Annals OR	10.1007/BF02096402	random variable;mathematical optimization;combinatorics;optimal stopping;wiener process;stopping time;mathematics;posterior probability;statistics;global optimization	Vision	36.40691230717561	3.661920023748548	114576
7cbcf6ab762040589f961e4fbedf0c7321cc5366	self-adaptive lower confidence bound: a new general and effective prescreening method for gaussian process surrogate model assisted evolutionary algorithms	databases;optimisation evolutionary computation gaussian processes;optimisation;evolutionary computation;gaussian processes;uncertainty;prediction uncertainty self adaptive lower confidence bound alcb prescreening method gaussian process surrogate model assisted evolutionary algorithms optimization problems computational expensive function evaluations;comunicacion de congreso;uncertainty optimization evolutionary computation predictive models databases computational modeling vectors;computational modeling;vectors;predictive models;optimization	Surrogate model assisted evolutionary algorithms are receiving much attention for the solution of optimization problems with computationally expensive function evaluations. For small scale problems, the use of a Gaussian Process surrogate model and prescreening methods has proven to be effective. However, each commonly used prescreening method is only suitable for some types of problems, and the proper prescreening method for an unknown problem cannot be stated beforehand. In this paper, the four existing prescreening methods are analyzed and a new method, called self-adaptive lower confidence bound (ALCB), is proposed. The extent of rewarding the prediction uncertainty is adjusted on line based on the density of samples in a local area and the function properties. The exploration and exploitation ability of prescreening can thus be better balanced. Experimental results on benchmark problems show that ALCB has two main advantages: (1) it is more general for different problem landscapes than any of the four existing prescreening methods; (2) it typically can achieve the best result among all available prescreening methods.	analysis of algorithms;benchmark (computing);evolutionary algorithm;exploit (computer security);gaussian process;local search (optimization);mathematical optimization;online and offline;surrogate model	Bo Liu;Qingfu Zhang;Francisco V. Fernández;Georges G. E. Gielen	2012	2012 IEEE Congress on Evolutionary Computation	10.1109/CEC.2012.6256585	mathematical optimization;uncertainty;computer science;machine learning;gaussian process;mathematics;predictive modelling;computational model;statistics;evolutionary computation	AI	29.12280917283677	-9.518406010937461	114664
f9a51d5f699333e1b49fb9701ebcefa1501786dd	memetic algorithms, domain knowledge, and financial investing	jie;information technology;domain knowledge;and financial investing university of maryland;artificial intelligence memetic algorithms;baltimore county roy rada du	How might domain knowledge constrain a genetic algorithm and systematically impact the algorithm’s traversal of the search space? In particular, in this paper the hypothesis is advanced that a semantic tree of financial knowledge can be used to influence the results of a genetic algorithm for financial investing problems. An algorithm is described, called the “Memetic Algorithm for Domain Knowledge”, and is instantiated in a software system. In mutation experiments, this system chooses financial ratios to use as inputs to a neural logic network which classifies stocks as likely to increase or decrease in value. The mutation is guided by a semantic tree of financial ratios. In crossover experiments, this system solves a portfolio optimization problem in which components of an individual represent weights on stocks; knowledge in the form of a semantic tree of industries determines the order in which components are sorted in individuals. Both synthetic data and real-world data are used. The experimental results show that knowledge can be used to reach higher fitness individuals more quickly. More interestingly, the results show how conceptual distance in the human knowledge can correspond to distance between evolutionary individuals and their fitness. In other words, knowledge might be dynamically used to at times increase the step size in a search algorithm or at times to decrease the step size. These results shed light on the role of knowledge in evolutionary computation and are part of the larger body of work to delineate how domain knowledge might usefully constrain the genetic algorithm.	memetic algorithm	Jie Du;Roy Rada	2012	Memetic Computing	10.1007/s12293-012-0079-x	mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;operations research;information technology;domain knowledge	HPC	25.29260923770681	-9.74647129609539	114989
1fc3e1326e38fe1f0935ec0e1163c8d43116819e	finding multiple solutions with ga in multimodal problems		Traditionally, the Evolutionary Computation (EC) techniques, and more specifically the Genetic Algorithms (GAs) (Goldberg & Wang, 1989), have proved to be efficient when solving various problems; however, as a possible lack, the GAs tend to provide a unique solution for the problem on which they are applied. Some non global solutions discarded during the search of the best one could be acceptable under certain circumstances. The majority of the problems at the real world involve a search space with one or more global solutions and multiple local solutions; this means that they are multimodal problems (Harik, 1995) and therefore, if it is desired to obtain multiple solutions by using GAs, it would be necessary to modify their classic functioning outline for adapting them correctly to the multimodality of such problems. mOTIVATION	evolutionary computation;genetic algorithm;multimodal interaction;software release life cycle	Marcos Gestal;María Paz Gómez-Carracedo	2009			genetic algorithm;crossover;artificial intelligence;mathematical optimization;machine learning;computer science	AI	25.123224346276793	-2.961297399561453	115025
f3e3a694c5d73f4bc6861397589fc4a9ccece698	an improved particle swarm algorithm with immune mechanism for traffic matrix estimation	particle swarm optimization mathematical model newton method sociology statistics entropy junctions;particle swarm optimization pso;intelligent transportation system;genetic algorithm particle swarm optimization algorithm immune mechanism traffic matrix estimation relative distance probability selection formula roulette method population diversity maximum entropy model newton method;newton method;road traffic genetic algorithms maximum entropy methods newton method particle swarm optimisation probability;genetic algorithm ga intelligent transportation system newton method particle swarm optimization pso;genetic algorithm ga	Owing to the shortcoming of local convergence of the particle swarm optimization algorithm, presenting relative distances between particles to enhance probability selection formula, an improved particle swarm optimization with immune theory is introduced. A particle updates its velocity and position not only by individual and global optima,but also by individual optima of a specific particle chosen by roulette method according to certain probability, to maintain population diversity and prevent precocity and stagnation. This method is used to solve the maximum entropy model, estimating OD matrix from traffic flows. By an experiment on a junction in Chongqing City, the results demonstrate that the particle swarm algorithm overcomes the defect of Newton method that strictly relies on initial values, and the improved particle swarm algorithm has much higher optimization capability than the basic particle swarm algorithm and the basic genetic algorithm.	estimation theory;genetic algorithm;lagrange multiplier;local convergence;mathematical optimization;newton's method;particle swarm optimization;principle of maximum entropy;software bug;software release life cycle;velocity (software development)	Changhai Du	2015	2015 11th International Conference on Natural Computation (ICNC)	10.1109/ICNC.2015.7378002	mathematical optimization;multi-swarm optimization;meta-optimization;derivative-free optimization;artificial intelligence;machine learning;mathematics;particle swarm optimization;metaheuristic	Robotics	28.420831795055655	-4.813531781277704	115028
bed68a4a952c8eb67c9ba0c1f4a4070da95c5a7c	immune clonal selection evolutionary strategy for constrained optimization	local search;constrained optimization;evolutionary strategy;artificial immune system;penalty function	Based on the clonal selection theory, a novel artificial immune systems algorithm, immune clonal selection evolutionary strategy for constrained optimization (ICSCES), is put forward. The new algorithm uses the stochastic ranking constraint-handling technique, realizs local search using clonal proliferation and clonal selection, and global search using clonal deletion. The experimental results on ten benchmark problems show, compared with the (µ, λ)evolutionary strategies adopting stochastic ranking technique and dynamic penalty function method, ICSCES has the ability of significantly improving the search performance both in convergence speed and precision.	constrained optimization;mathematical optimization	Wenping Ma;Licheng Jiao;Maoguo Gong;Ronghua Shang	2006		10.1007/11801603_70	mathematical optimization;constrained optimization;combinatorial optimization;computer science;artificial intelligence;evolutionary algorithm;penalty method;mathematics;algorithm	AI	26.302173045404757	-3.7640525472665805	115106
c2fb41e46e22c1f77d1dcc880f638f22efaa7920	fish school search algorithm for constrained optimization		In this work we investigate the effectiveness of the application of niching able swarm metaheuristic approaches in order to solve constrained optimization problems. Sub-swarms are used in order to allow the achievement of many feasible regions to be exploited in terms of fitness function. The niching approach employed was wFSS, a version of the Fish School Search algorithm devised specifically to deal with multi-modal search spaces. A base technique referred as wrFSS was conceived and three variations applying different constraint handling procedures were also proposed. Tests were performed in seven problems from CEC 2010 and a comparison with other approaches was carried out. Results show that the search strategy proposed is able to handle some heavily constrained problems and achieve results comparable to the state-of-the-art algorithms. However, we also observed that the local search operator present in wFSS and inherited by wrFSS makes the fitness convergence difficult when the feasible region presents some specific geometrical features.	constrained optimization;feasible region;fish school search;fitness function;local search (optimization);mathematical optimization;metaheuristic;modal logic;search algorithm;swarm	Joao Batista Monteiro Filho;Isabela Maria Carneiro de Albuquerque;Fernando Buarque de Lima Neto	2017	CoRR		swarm behaviour;machine learning;mathematical optimization;artificial intelligence;operator (computer programming);local search (optimization);constrained optimization;metaheuristic;computer science;feasible region;fitness function;search algorithm	AI	25.584204047217113	-3.6829178508949774	115175
7fa62724f44a352256dbdedd2a365f86b9c3908b	an opposition-based chaotic ga/pso hybrid algorithm and its application in circle detection	ga;chaos;pso;multimodal optimization;circle detection;opposition based learning	An evolutionary circle detection method based on a novel Chaotic Hybrid Algorithm (CHA) is proposed. The method combines the strengths of particle swarm optimization, genetic algorithms and chaotic dynamics, and involves the standard velocity and position update rules of PSOs, with the ideas of selection, crossover and mutation from GA. The opposition-based learning (OBL) is employed in CHA for population initialization. In addition, the notion of species is introduced into the proposed CHA to enhance its performance in solving multimodal problems. The effectiveness of the Species-based Chaotic Hybrid Algorithm (SCHA) is proven through simulations and benchmarking; finally it is successfully applied to solve circle detection problems. To make it more powerful in solving circle detection problems in complicated circumstances, the notion of 'tolerant radius' is proposed and incorporated into the SCHA-based method. Simulation tests were undertaken on several hand drawn sketches and natural photos, and the effectiveness of the proposed method was clearly shown in the test results.	hybrid algorithm;particle swarm optimization;software release life cycle	Na Dong;Chun-Ho Wu;Andrew W. H. Ip;Zengqiang Chen;Ching-Yuen Chan;Kai-Leung Yung	2012	Computers & Mathematics with Applications	10.1016/j.camwa.2012.03.040	mathematical optimization;simulation;artificial intelligence;mathematics;algorithm	Vision	27.297209315899952	-4.655697881296527	115252
e25ebceaf601f972e6a351808555a80f6cdd1108	memetic differential evolution for vehicle routing problem with time windows	differential evolution;vehicle routing problem;optimization;local search	In this paper, an improved memetic differential evolution algorithm with generalized fitness (MDEGF) is proposed for vehicle routing problem with time windows (VRPTW). A generalized fitness strategy is designed to evaluate the quality of source-individuals, which incorporates three simple local search techniques and helps to improve the convergent performance. Experimental results show that the novel algorithm can solve the VRPTW and obtain better solution in short time.	differential evolution;memetics;microsoft windows;vehicle routing problem	Wanfeng Liu;Xu Wang;Xia Li	2012		10.1007/978-3-642-30976-2_43	differential evolution;mathematical optimization;computer science;artificial intelligence;local search;vehicle routing problem;machine learning;mathematics	Theory	25.909090633801828	-3.4298796505086337	115255
811082995cff80a8c3bb0b39c16fcf83a4b789ad	solution to constrained test problems using cohort intelligence algorithm		Most of the real world problems are inherently constrained in nature. There are several nature inspired algorithms being developed; however their performance degenerate when applied solving constrained problems. This paper proposes Cohort Intelligence (CI) approach in which a probability based constrained handling approach is incorporated. This approach is tested by solving four well known test problems. The performance is compared and discussed with regard to the robustness, computational cost, standard deviation and rate of convergence etc. The constrained CI approach is used here to solve few inequality based constrained problems. The solution to these problems indicates that the CI approach can be further efficiently applied to solve a variety of practical/real world problems.	algorithm	Apoorva S. Shastri;Priya S. Jadhav;Anand Jayant Kulkarni;Ajith Abraham	2015		10.1007/978-3-319-28031-8_37	mathematical optimization;artificial intelligence;machine learning	AI	29.799812114361934	-0.6427893331669504	115488
e087da2eb7225b90d3e27bdb2f0c9c76f2da52f0	tchebycheff approximation in gaussian process model composition for multi-objective expensive black box	tchebycheff decomposition;optimisation;gaussian processes;approximation method;tchebycheff approximation;probability density function;multi objective optimization;optimisation chebyshev approximation gaussian processes;tchebycheff decomposition tchebycheff approximation gaussian process model composition multiobjective expensive black box black box expensive function scalar objective optimization multiobjective optimization metamodel moea d framework weighted sum model;moea d framework;multiobjective expensive black box;weighted sum model;black box expensive function;scalar objective optimization;qa75 electronic computers computer science;gaussian process model composition;computational modeling;metamodel;estimation;approximation methods optimization computational modeling mathematical model probability density function gaussian processes estimation;weighted sums;mathematical model;multiobjective optimization;optimization;approximation methods;gaussian process;chebyshev approximation;model composition	Black-box expensive function is ubiquitous in real world problems. Much research has been done on scalar objective optimization for such problems with great success. Comparatively, very little work has been done in multi-objective optimization. In many cases, it is not straightforward to convert methods from scalar objective optimization to multi-objective optimization due to the complexities incurred by Pareto domination. In our pervious research, concept of model composition based on Gaussian Process metamodel and the powerful MOEA/D framework proved to be a successful approach for multi-objective optimization with black-box expensive functions. We derived Weighted-Sum and Tchebycheff model composition for bi-objective problems. However, due to the complexity of Tchebycheff decomposition structure, it is very hard, if not impossible, to extend the method to three or more objective problems in a nature way. In this paper, we propose an approximation method for Tchebycheff model composition which greatly simplify the derivation for three or more objective cases. Experiments show the approximation produces very similar performance as the Weighted-Sum and Tchebycheff without approximation. Thus, the new method enables us to tackle multi-objective problems with black-box expensive functions that could not be tackled effectively so far.	approximation;black box;dominating set;experiment;gaussian process;moea framework;mathematical optimization;metamodeling;multi-objective optimization;pareto efficiency;procedural parameter	Wudong Liu;Qingfu Zhang;Edward P. K. Tsang;Botond Virginas	2008	2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)	10.1109/CEC.2008.4631211	mathematical optimization;combinatorics;multi-objective optimization;gaussian process;mathematics;mathematical economics;statistics	AI	30.44799387980916	1.1847478532294737	115614
ba977231196d14ded1df70de521d098e17cb7797	an efficient algorithm for computing the fitness function of a hydrophobic-hydrophilic model	minimisation;biology computing;relative polarity hp model fitness function improved computation relative distance;relative distance;full search;pre2009 other artificial intelligence;efficient algorithm;faculty of science environment engineering and technology;biology computing proteins computational complexity search problems minimisation;test bed;energy function;proteins amino acids predictive models shape lattices information technology australia electronic mail testing genetics;relative polarity;hp model;proteins;computational complexity;computational complexity fitness function hydrophobic hydrophilic model protein folding minimization search problem;280213;protein folding;search problems;model fitting;fitness function;improved computation	The protein folding problem is a minimization problem in which the energy function is often regarded as the fitness function. There are several models for protein folding prediction including the hydrophobic-hydrophilic (HP) model. Though this model is an elementary one, it is widely used as a test-bed for faster execution of new algorithms. Fitness computation is one of the major computational parts of the HP model. This paper proposes an efficient search (ES) approach for computing the fitness value requiring only O(n) complexity in contrast to the full search (FS) approach that requires O(n/sup 2/) complexity. The efficiency of the proposed ES approach results due to its utilization of some inherent properties of the HP model. The ES approach represents residues in a Cartesian coordinate framework and then uses relative distance and coordinate polarity to reduce complexity.	algorithm;computation;fitness function;mathematical optimization;protein structure prediction;testbed	Tamjidul Hoque;Madhu Chetty;Laurence Dooley	2004	Fourth International Conference on Hybrid Intelligent Systems (HIS'04)	10.1109/ICHIS.2004.19	mathematical optimization;computer science;bioinformatics;machine learning;fitness approximation	Robotics	29.7777081653954	-8.547088572281334	115749
eb9f80aa53ef36cb6b9912261c71e051cbf8b3a3	intelligent control of avr system using ga-bf	modele comportement;behavior model;optimisation;systeme intelligent;algoritmo busqueda;sistema hibrido;optimizacion;bacterie;algorithme recherche;control inteligente;sociologia;sistema inteligente;modelo comportamiento;modelo hibrido;search algorithm;gradiente;optimum global;foraging behavior;intelligence artificielle;gradient;global optimum;algoritmo genetico;modele hybride;intelligent control;hybrid model;conducta social;social behavior;algorithme reparti;intelligent system;hybrid system;algorithme genetique;artificial intelligence;comportement social;algorithme evolutionniste;genetic algorithm;algoritmo repartido;global optimization;algoritmo evolucionista;optimization;commande intelligente;bacteria;inteligencia artificial;evolutionary algorithm;sociologie;optimal algorithm;distributed algorithm;optimo global;sociology;systeme hybride	This paper deals with hybrid system (GA-BF) based on the conventional GA (Genetic Algorithm) and BF (Bacterial Foraging) which is social foraging behavior of bacteria for AVR system. This approach provides us with novel hybrid model based on foraging behavior and with also a possible new connection between evolutionary forces in social foraging and distributed nongradient optimization algorithm design for global optimization over noisy surfaces for AVR system.	algorithm design;atmel avr;brainfuck;genetic algorithm;global optimization;hybrid system;intelligent control;mathematical optimization	Dong Hwa Kim;Jae Hoon Cho	2005		10.1007/11554028_119	behavioral modeling;foraging;distributed algorithm;genetic algorithm;bacteria;social behavior;computer science;artificial intelligence;evolutionary algorithm;global optimum;gradient;algorithm;global optimization;hybrid system;intelligent control;search algorithm	Robotics	27.801551176447383	0.6063744672688454	115943
d413ab52f389b2d8d5d9153bbc6d9756ae0fab36	constrained artificial fish-swarm based area coverage optimization algorithm for directional sensor networks	artificial fish swarm;swarm intelligence;convergence;sensors;area coverage;会议论文;force;wireless sensor networks particle swarm optimisation sensor placement;visualization;fellows;sensor placement;coverage optimization;motion process constrained artificial fish swarm algorithm cafsa area coverage optimization algorithm directional sensor networks tunable sensing orientation sensing centroid food consistence kinematic constraint dynamic constraint;coverage optimization directional sensor networks swarm intelligence artificial fish swarm area coverage;optimization;numerical models;directional sensor networks;particle swarm optimisation;wireless sensor networks;sensors optimization visualization force numerical models fellows convergence	"""In this paper, we explore the area coverage optimization problem by directional sensors with tunable sensing orientations. We firstly introduce the concept of """"sensing centroid"""", which is the geometric center of a sensing sector to simplify the pending problem. Particularly, we regard """"sensing centroid"""" as artificial fish (AF), and search an optimal solution in the solution space by simulating fish swarm behaviors (such as prey, swarm and follow) with a tendency toward high food consistence. Fully considering that AFs have to satisfy both kinematic constraint and dynamic constraint in the process of motion, we propose a Constrained Artificial Fish-Swarm Algorithm (CAFSA), and discuss the control laws to guide the behaviors of AFs with high convergence speed. Finally, we evaluate the effect of some primary parameters on the performance of our solution through extensive simulations."""	algorithm;anisotropic filtering;feasible region;mathematical optimization;optimization problem;prey;sensor;simulation;swarm	Dan Tao;Shaojie Tang;Liang Liu	2013	2013 IEEE 10th International Conference on Mobile Ad-Hoc and Sensor Systems	10.1109/MASS.2013.89	mathematical optimization;wireless sensor network;visualization;convergence;swarm intelligence;computer science;sensor;artificial intelligence;machine learning;force;computer network	Robotics	31.575791128184658	-2.810126820316412	116215
9869e75b38226b24f10e18a15e5cafe9cafe94a1	bandit-based random mutation hill-climbing		The Random Mutation Hill-Climbing algorithm is a direct search technique mostly used in discrete domains. It repeats the process of randomly selecting a neighbour of a best-so-far solution and accepts the neighbour if it is better than or equal to it. In this work, we propose to use a novel method to select the neighbour solution using a set of independent multi-armed bandit-style selection units which results in a bandit-based Random Mutation Hill-Climbing algorithm. The new algorithm significantly outperforms Random Mutation Hill-Climbing in both OneMax (in noise-free and noisy cases) and Royal Road problems (in the noise-free case). The algorithm shows particular promise for discrete optimisation problems where each fitness evaluation is expensive.	climber (beam);decade (log scale);discrete optimization;emoticon;evolution;evolutionary algorithm;experiment;hill climbing;linear function;mathematical optimization;mitchell corporation;multi-armed bandit;multiplicative noise;randomness;resampling (statistics);zhi-li zhang	Jialin Liu;Diego Perez Liebana;Simon M. Lucas	2017	2017 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2017.7969564	mathematical optimization;artificial intelligence;machine learning	AI	27.881907406871495	-0.575957209500458	116416
28821234db2668f9ac67317d845e138805ca397f	optimal selection of robust parameter designs when some of the control-by-noise interactions are important		In robust parameter design, both control factors and noise factors are studied, and the objective is to choose the settings of control factors that are insensitive to the noise factors. Information concerning control-by-noise interactions is particularly useful for achieving this objective. In this paper, we propose and study a method for selecting the optimal robust parameter designs when some of the control-by-noise interactions are important. We then discuss how to search for the best designs according to this method and present some results for designs of 8 and 16 runs.	interaction	Wei-Ming Ke	2007	MASA		econometrics;engineering;control theory;statistics	EDA	31.55485903669026	-6.666899475683428	116634
36d44cd98355f34f3af5fdff8a4ed50d41bd7af8	robust solver based on modified particle swarm optimization for improved solution of diffusion transport through containment facilities	catfish swarm;containment facility;civil engineering;particle swarm optimization;perturbation;diffusion transport	Accurate estimation of mass transport parameters is necessary for overall design and evaluation processes of the waste disposal facilities. The mass transport parameters, such as effective diffusion coefficient, retardation factor and diffusion accessible porosity, are estimated from observed diffusion data by inverse analysis. Recently, particle swarm optimization (PSO) algorithm has been used to develop inverse model for estimating these parameters that alleviated existing limitations in the inverse analysis. However, PSO solver yields different solutions in successive runs because of the stochastic nature of the algorithm and also because of the presence of multiple optimum solutions. Thus the estimated mean solution from independent runs is significantly different from the best solution. In this paper, two variants of the PSO algorithms are proposed to improve the performance of the inverse analysis. The proposed algorithms use perturbation equation for the gbest particle to gain information around gbest region on the search space and catfish particles in alternative iterations to improve exploration capabilities. Performance comparison of developed solvers on synthetic test data for two different diffusion problems reveals that one of the proposed solvers, CPPSO, significantly improves overall performance with improved best, worst and mean fitness values. The developed solver is further used to estimate transport parameters from 12 sets of experimentally observed diffusion data obtained from three diffusion problems and compared with published values from the literature. The proposed solver is quick, simple and robust on different diffusion problems. 2012 Elsevier Ltd. All rights reserved.	algorithm;analysis of algorithms;coefficient;dhrystone;experiment;finite difference method;fitness function;global optimization;iteration;mathematical optimization;numerical partial differential equations;particle swarm optimization;perturbation theory;solver;spreadsheet;synthetic data;synthetic intelligence;test data;thermal oxidation	Tadikonda Venkata Bharat;Puvvadi V. Sivapullaiah;Mehter M. Allam	2012	Expert Syst. Appl.	10.1016/j.eswa.2012.03.013	mathematical optimization;simulation;perturbation;artificial intelligence;particle swarm optimization	AI	34.265031890815045	-3.4880948105942036	117070
bbee23d5b406338db596f09ae9709fe22d363485	a verified optimization technique to locate chaotic regions of hénon systems	computer program;chaos;optimization technique;optimal method;optimization problem;verified optimization method;global optimization;henon map;optimization model	We present a new verified optimization method to find regions for Hénon systems where the conditions of chaotic behaviour hold. The present paper provides a methodology to verify chaos for certain mappings and regions. We discuss first how to check the set theoretical conditions of a respective theorem in a reliable way by computer programs. Then we introduce optimization problems that provide a model to locate chaotic regions. We prove the correctness of the underlying checking algorithms and the optimization model. We have verified an earlier published chaotic region, and we also give new chaotic places located by the new technique.	algorithm;chaos theory;computer program;correctness (computer science);dynamical system;global optimization;hénon map;interval arithmetic;iteration;mathematical optimization;optimization problem;overhead (computing)	Tibor Csendes;Barnabas M. Garay;Balázs Bánhelyi	2006	J. Global Optimization	10.1007/s10898-005-1509-9	optimization problem;mathematical optimization;multi-swarm optimization;test functions for optimization;theoretical computer science;mathematics;vector optimization;algorithm;metaheuristic;global optimization	Theory	32.11121696327039	1.2700445458939176	117208
f87f56c48c0770e5bf401f772005f6d81e350c0e	iterated local search for the linear ordering problem	metaheuristics;linear ordering problem;iterated local search;metaheuristic;local search	This paper addresses the linear ordering problem, which has been solved using different metaheuristics approaches. These algorithms have the common problem of finding a proper balance of the intensification and diversification processes; in this work we propose an iterated local search in which it is incorporated a Becker heuristic strategy for constructing the initial solution, and a search strategy as perturbation process, achieving a better balance between intensification and diversification. The proposed algorithm obtained an improvement greater than 90%, decreasing the average percentage error respect the state of art ILS algorithm. The Wilcoxon nonparametric statistical test shows that the proposed algorithm significantly outperforms the iterated local search solution of the state of the art, ranking it among the top five solutions of the state of the art for the linear ordering problem.	algorithm;approximation error;diversification (finance);donald becker;heuristic;iterated function;iterated local search;iteration;local search (optimization);metaheuristic	V. Mora Guadalupe Castilla GracielaMoraGuadalupeCastilla;Shulamith S. Bastiani Medina	2012	IJCOPI		mathematical optimization;combinatorics;local search;hill climbing;machine learning;iterated local search;mathematics;guided local search	EDA	27.666999407674993	-0.6528272322060582	117246
820c09d1d81301621a5d21409d32aec024e33a05	an evolutionary technique for local microcode compaction	search space;optimal method;simulated evolution;biological evolution;natural selection;parameter tuning;data dependence;list scheduling	Abstract   In this paper we present a variant of the simulated evolution technique for local microcode compaction. Simulated evolution is a general optimization method based on an analogy with the natural selection process in biological evolution. The proposed technique combines simulated evolution with list scheduling, in which simulated evolution is used to determine suitable priorities which lead to a good solution by applying list scheduling as a decoding heuristic. The proposed technique is an effective method that yields good results without problem-specific parameter tuning on test problems of very different sizes and structures. This is achieved by establishing a reasonable balance between exploration of the search space and exploitation of good solutions found in an acceptable CPU time. We demonstrate the effectiveness of our technique by comparing it with the existing microcode compaction techniques for randomly generated data dependency graphs. The proposed scheme offers considerable improvement in the number of microinstructions compared with the existing techniques with comparable CPU time.	data compaction;microcode	Imtiaz Ahmad;Muhammad K. Dhodhi;Kassem Saleh	1995	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(96)82011-4	mathematical optimization;natural selection;computer science;theoretical computer science;algorithm	EDA	25.460897092155758	-1.6868878062446084	117262
e8bb213ecdde78ea6c078cffa713f57727457dae	genetic algorithm solution of the tsp avoiding special crossover and mutation	traveling salesman problem;tsp;travelling salesman problem;permutation representation;crossover;pmx;genetic algorithm;genetic algorithms;partially mapped crossover	Ordinary representations of permutations in Genetic Algorithms (GA) is handicapped with producing offspring which are not permutations at all. The conventional solution for crossover and mutation operations of permutations is to device ‘special’ operators. Unfortunately these operators suffer from violating the nature of crossover. Namely, considering the gene positions on the chromosome, these methods do not allow n-point crossover techniques which are known to favour building-block formations. In this work, an inversion sequence is proposed as the representation of a permutation. This sequence allows repetitive values and hence is robust under ordinary (n-point) crossover. There is a one-to-one mapping from ordinary permutation representation to the inversion sequence representation. The proposed method is used for solving TSPs and is compared to the well known PMX special crossover method. It is observed that this method outperforms PMX in convergence rate by a factor which can be as high as 11.1 times, on a cost of obtaining slightly worse solutions on average.	crossover (genetic algorithm);discrete optimization;genetic algorithm;mathematical optimization;newton's method;one-to-one (data model);pmx (technology);rate of convergence;scheduling (computing);software release life cycle;testbed;whole earth 'lectronic link	Göktürk Üçoluk	2002	Intelligent Automation & Soft Computing	10.1080/10798587.2000.10642829	mathematical optimization;crossover;edge recombination operator;genetic algorithm;computer science;artificial intelligence;machine learning;chromosome;travelling salesman problem;algorithm	Robotics	25.264982764732515	-0.348109307586311	117281
929c657df65d1e82a1525f5a1fba7b801cd59e02	cluster-based differential evolution with heterogeneous influence for numerical optimization	differential evolution;k means;numerical optimization;evolution biology;clustering;heuristic algorithms;pattern clustering evolutionary computation;statistics;clustering algorithms;optimization;clustering algorithms sociology statistics optimization evolution biology benchmark testing heuristic algorithms;k means differential evolution clustering numerical optimization;sociology;benchmark testing;complex optimization problems heterogeneous influence cluster based differential evolution algorithm differential evolution population k means clustering method de best group 1 exp mutation strategy de rand1 exp mutation strategy de rand 1 bin mutation strategy improved mutation strategy complex benchmark functions single objective real parameter numerical optimization	This paper introduces a Cluster-based Differential Evolution Algorithm with Heterogeneous Influence for solving complex optimization problems. The idea behind this combination is to classify the Differential Evolution population into a number of clusters using k-means clustering method and to apply different mutation strategies for the clusters. The number of clusters is changed dynamically in each generation. The proposed algorithm uses three mutation strategies: DE/best-group/ 1/exp, DE/rand1/exp and DE/rand/1/bin. The DE/best-group/ 1/exp is an improved mutation strategy that randomly selects a portion of the population and then chooses the best individual in the group to guide the evolution. The k-means clustering algorithm is used periodically to fine-tune solutions that are generated from DE/best-group/1/exp by producing new clusters. This helps in balancing the exploration and exploitation capabilities by using different mutation strategies for these clusters to enhance diversity. The performance of the proposed approach is tested on 25 complex benchmark functions on single objective real-parameter numerical optimization. Results show that the proposed algorithm exhibits competitive performance when compared to other state-of-the-art algorithms.	algorithm;benchmark (computing);bibliothèque de l'école des chartes;cluster analysis;computer cluster;differential evolution;k-means clustering;mathematical optimization;numerical analysis;randomness	Mostafa Z. Ali;Noor H. Awad;Rehab Duwairi;Jafar Albadarneh;Robert G. Reynolds;Ponnuthurai Nagaratnam Suganthan	2015	2015 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2015.7256917	correlation clustering;mathematical optimization;meta-optimization;computer science;bioinformatics;machine learning;mathematics;evolution strategy;cluster analysis;algorithm	ML	25.382821231574617	-4.906340021507139	117363
e840d24224f373fed11020bd5d1e1c1083d9d245	a memetic algorithm with bucket elimination for the still life problem	experimental tests;estado estacionario;algoritmo busqueda;bucket elimination;algorithme recherche;search algorithm;hombre;hybridation;algoritmo genetico;constraint satisfaction;stationary state;memetic algorithm;enfant;optimisation combinatoire;resolucion problema;satisfaction contrainte;nino;automate cellulaire;human;hybridization;etat stationnaire;child;algorithme genetique;algorithme evolutionniste;genetic algorithm;tabu search;algoritmo evolucionista;hibridacion;satisfaccion restriccion;evolutionary algorithm;combinatorial optimization;cellular automaton;busqueda tabu;recherche tabou;problem solving;resolution probleme;homme;optimizacion combinatoria;automata celular	Bucket elimination (BE) is an exact technique based on variable elimination, commonly used for solving constraint satisfaction problems. We consider the hybridization of BE with evolutionary algorithms endowed with tabu search. The resulting memetic algorithm (MA) uses BE as a mechanism for recombining solutions, providing the best possible child from the parental set. This MA is applied to the maximum density still life problem. Experimental tests indicate that the MA provides optimal or near-optimal results at an acceptable computational cost.	algorithmic efficiency;branch and bound;cobham's thesis;computation;constraint programming;constraint satisfaction problem;crossover (genetic algorithm);evolutionary algorithm;experiment;hybrid algorithm;local consistency;memetic algorithm;memetics;parameterized complexity;tabu search;variable elimination	José E. Gallardo;Carlos Cotta;Antonio J. Fernández	2006		10.1007/11730095_7	mathematical optimization;artificial intelligence;mathematics;algorithm;memetic algorithm	AI	26.393941683958932	1.6397408778674902	117446
92fef73bc7c86aacc93a533fe07dcba985cbf711	multiobjective optimization using an adaptive weighting scheme	direct;mads;numerical analysis;technical report departmental;scientific computing;triangulation;multiple objective programming;surrogates	A new Pareto front approximation method is proposed for multiobjective optimization problems with bound constraints. The method employs a hybrid optimization approach using two derivative free direct search techniques, and intends to solve blackbox simulation based multiobjective optimization problems where the analytical form of the objectives is not known and/or the evaluation of the objective function(s) is very expensive. A new adaptive weighting scheme is proposed to convert a multiobjective optimization problem to a single objective optimization problem. Another contribution of this paper is the generalization of the star discrepancy based performance measure for problems with more than two objectives. The method is evaluated using five test problems from the literature. Results show that the method achieves an arbitrarily close approximation to the Pareto front with a good collection of well-distributed nondominated points for all five test problems.	approximation;computation;computational geometry;constraint (mathematics);design of experiments;discrepancy function;local search (optimization);loss function;low-discrepancy sequence;mathematical optimization;multi-objective optimization;optimization problem;pareto efficiency;rate of convergence;sampling (signal processing);search algorithm;simulation;stellar classification;surrogates;triangulation (geometry);trust region;turing test	Shubhangi G. Deshpande;Layne T. Watson;Robert A. Canfield	2016	Optimization Methods and Software	10.1080/10556788.2015.1048861	optimization problem;mathematical optimization;simulation;triangulation;numerical analysis;multi-objective optimization;mathematics;vector optimization;algorithm	AI	30.167593456800834	-0.13569875733668083	117558
b723071f8628f5926f3562bec668a0521731b44b	optimal design of pida controller for induction motor using spider monkey optimization algorithm		Induction motors are widely used in power system due to their robustness, even though induction motors are highly non-linear and their control is quite complicated. Proportional integral derivative acceleration PIDA controller is used with induction motor for improving its efficiency. But, finding optimal PIDA controller parameters is a complex task and cannot be easily dealt by the available analytical strategies. As the nature inspired algorithms NIAs have shown their accuracy and efficiency to solve such complicated optimization problems, in this paper, a recent NIA, namely Spider Monkey Optimization SMO algorithm is used for finding the optimal PIDA controlleru0027s parameters for controlling the induction motor. As per the best of authors knowledge, it is the first attempt to design optimal PIDA controlleru0027s parameters for induction motor through any swarm intelligence motivated algorithm.	algorithm;optimal design;pida	Ajay Sharma;Harish Sharma;Annapurna Bhargava;Nirmala Sharma	2016	IJMHeur	10.1504/IJMHEUR.2016.10002054	motor control;mathematical optimization;swarm intelligence;computer science;artificial intelligence;optimal design;control theory;induction motor;metaheuristic	EDA	32.37186715628195	-4.989400044223133	117581
2b157b7c36c221b3b4e193dfa05375d36a1995e9	catfish particle swarm optimization	pso algorithms catfish particle swarm optimization catfishpso optimization algorithm linearly decreasing weight particle swarm optimization gbest fitness value search space accelerating convergence benchmark test functions;optimization algorithm;convergence;evolutionary computation;linearly decreasing weight particle swarm optimization;search space;catfishpso;gbest fitness value;particle swarm optimization marine animals acceleration benchmark testing educational institutions usa councils equations iterative algorithms genetic mutations stochastic processes;acceleration;benchmark test functions;particle swarm optimizer;extreme point;particle swarm optimization;search problems artificial life convergence particle swarm optimisation;optimization;search problems;catfish particle swarm optimization;optimal algorithm;particle swarm optimisation;pso algorithms;artificial life;benchmark testing;accelerating convergence	Catfish particle swarm optimization (CatfishPSO) is a novel optimization algorithm proposed in this paper. The mechanism is dependent on the incorporation of a catfish particle into the linearly decreasing weight particle swarm optimization (LDWPSO). The introduced catfish particle improves the performance of LDWPSO. Unlike other ordinary particles, the catfish particles will initialize a new search from the extreme points of the search space when the gbest fitness value (global optimum at each iteration) has not been changed for a given time, which results in further opportunities to find better solutions for the swarm by guiding the whole swarm to promising new regions of the search space, and accelerating convergence. In our experiment, CatfishPSO, LDWPSO and other improved PSO procedures were extensively compared on three benchmark test functions with 10, 20 and 30 different dimensions. Experimental results indicate that CatfishPSO achieves better performance than LDWPSO procedure and other improved PSO algorithms from the literature.	algorithm;benchmark (computing);distribution (mathematics);global optimization;iteration;mathematical optimization;particle swarm optimization;technological convergence	Li-Yeh Chuang;Sheng-Wei Tsai;Cheng-Hong Yang	2008	2008 IEEE Swarm Intelligence Symposium	10.1109/SIS.2008.4668277	mathematical optimization;multi-swarm optimization;artificial intelligence;machine learning;mathematics;particle swarm optimization	EDA	27.96981199207838	-5.392678941538795	117594
5db8eaaa8f8ca48330c4740db05b2c060bccddae	memcomputing implementation of ant colony optimization	memristors;ant colony;adaptive behavior	We report on similarities between memcomputing with memristive networks and ant colony optimization. In particular, we show that one can design memristive networks to solve short-path optimization problems in a way similar to that done by ant-colony optimization algorithms. By employing appropriate memristive elements one can demonstrate an almost one-to-one correspondence between memcomputing and ant colony optimization approaches. However, the memristive network has the capability of finding the solution in one deterministic step, compared to the stochastic multi-step ant-colony optimization. This result is a first step in the direction of implementing in hardware, with nanoscale devices, this and possibly other swarm intelligence algorithms that are presently explored.	algorithm;ant colony optimization algorithms;mathematical optimization;one-to-one (data model);swarm intelligence	Yuriy V. Pershin;Massimiliano Di Ventra	2016	Neural Processing Letters	10.1007/s11063-016-9497-y	mathematical optimization;ant colony optimization algorithms;memristor;computer science;artificial intelligence;ant colony;adaptive behavior;machine learning;metaheuristic	AI	25.759406310760085	-5.934174720226879	118319
6d74cf3fa6bab0996b2b0660baf0d4e1548c74f2	a variant of p systems for optimization	evolutionary computation;membrane computing p systems;p system;dna computation;optimization;dna computing;test function;membrane computing;high efficiency;evolutionary computing	A P system variant for optimization is presented. The system adopts the idea from the standard P systems and exploits some techniques from evolutionary computing. The new variant of the P systems is tested using several benchmark functions. The experiments illuminate that the variant of the P systems is superior to the compared algorithms showing better results, high efficiency and high Crown Copyright & 2008 Published by Elsevier B.V. All rights reserved.	benchmark (computing);code;computable function;crown group;evaluation function;evolutionary computation;experiment;genetic algorithm;mathematical optimization;maxima and minima;multistage interconnection networks;operation time;p system;simulation	Yao Zhang;Liang Huang	2009	Neurocomputing	10.1016/j.neucom.2008.08.016	natural computing;test functions for optimization;computer science;theoretical computer science;machine learning;dna computing;algorithm;evolutionary computation;p system	AI	26.65028781008237	-2.0049979192964567	118332
12a995e90e0ca9303d0e5d98bcc39798bb9652f8	selection and configuration of sorption isotherm models in soils using artificial bees guided by the particle swarm		A precise estimation of isotherm model parameters and selection of isotherms from the measured data are essential for the fate and transport of toxic contaminants in the environment. Nonlinear least-square techniques are widely used for fitting the isotherm model on the experimental data. However, such conventional techniques pose several limitations in the parameter estimation and the choice of appropriate isotherm model as shown in this paper. It is demonstrated in the present work that the classical deterministic techniques are sensitive to the initial guess and thus the performance is impeded by the presence of local optima. A novel solver based on modified artificial bee-colony (MABC) algorithm is proposed in this work for the selection and configuration of appropriate sorption isotherms. The performance of the proposed solver is compared with the other three solvers based on swarm intelligence for model parameter estimation using measured data from 21 soils. Performance comparison of developed solvers on the measured data reveals that the proposed solver demonstrates excellent convergence capabilities due to the superior exploration-exploitation abilities. The estimated solutions by the proposed solver are almost identical to the mean fitness values obtained over 20 independent runs. The advantages of the proposed solver are presented.		Tadikonda Venkata Bharat	2017	Adv. Artificial Intellegence	10.1155/2017/3497652	mathematical optimization;simulation;artificial intelligence;machine learning	Robotics	31.31471986524036	-7.463493130318658	118627
81b97f8cac4d4e40d71afd0b7c5c0c2bfe40f277	a fast hybrid genetic algorithm for the quadratic assignment problem	combinatorial optimization problem;genetic algorithm;genetic algorithms;tabu search;quadratic assignment problem;heuristics;combinatorial optimization;hybrid genetic algorithm	"""Genetic algorithms (GAs) have recently become very popular by solving combinatorial optimization problems. In this paper, we propose an extension of the hybrid genetic algorithm for the well-known combinatorial optimization problem, the quadratic assignment problem (QAP). This extension is based on the """"fast hybrid genetic algorithm"""" concept. An enhanced tabu search is used in the role of the fast local improvement of solutions, whereas a robust reconstruction (mutation) strategy is responsible for maintaining a high degree of the diversity within the population. We tested our algorithm on the instances from the QAP instance library QAPLIB. The results demonstrate promising performance of the proposed algorithm."""	combinatorial optimization;genetic algorithm;mathematical optimization;memetic algorithm;optimization problem;quadratic assignment problem;tabu search;whole earth 'lectronic link	Alfonsas Misevicius	2006		10.1145/1143997.1144194	optimization problem;mathematical optimization;combinatorics;linear bottleneck assignment problem;meta-optimization;genetic algorithm;cross-entropy method;cultural algorithm;combinatorial optimization;tabu search;computer science;generalized assignment problem;machine learning;mathematics;assignment problem;weapon target assignment problem;quadratic assignment problem;population-based incremental learning	AI	24.670385899548847	-1.2601675671307908	118762
a2b0f276b11f22b0ba0503e8cdbed4563609423a	cryptanalysis of a chaos-based encryption scheme		In this article, cryptanalysis of a chaos-based encryption scheme is introduced. An attack system was proposed to explore the security weaknesses of the chaotic encryption scheme. Converging of the attack system to the target chaotic encryption scheme has been proven using master-slave synchronization. Future evaluation of the encryption scheme is derived from a scalar time series in which the only information available is the structure of the encryption scheme and a scalar time series observed from the chaotic system. Simulation and numerical results confirming the feasibility of the cryptanalysis method are given.	chaos theory;cryptanalysis;encryption;numerical analysis;simulation;time series	Salih Ergun	2017	2017 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)	10.1109/ISPACS.2017.8266525	scalar (physics);computer science;time series;control theory;theoretical computer science;encryption;synchronization;cryptanalysis;chaotic	Arch	38.71942090438251	-6.681753103854084	118785
d3218b071698a9e35ce00c9ebd55bec97bd5e79d	human-competitive evolved antennas	evolutionary computation;wire antenna;genetic programming;computational design;design;antenna;spacecraft	We present a case study showing a human-competitive design of an evolved antenna that was deployed on a NASA spacecraft in 2006. We were fortunate to develop our antennas in parallel with another group using traditional design methodologies. This allowed us to demonstrate that our techniques were human-competitive because our automatically designed antenna could be directly compared to a human-designed antenna. The antennas described below were evolved to meet a challenging set of mission requirements, most notably the combination of wide beamwidth for a circularly polarized wave and wide bandwidth. Two evolutionary algorithms were used in the development process: one used a genetic algorithm style representation that did not allow branching in the antenna arms; the second used a genetic programming style tree-structured representation that allowed branching in the antenna arms. The highest performance antennas from both algorithms were fabricated and tested, and both yielded very similar performance. Both antennas were comparable in performance to a hand-designed antenna produced by the antenna contractor for the mission, and so we consider them examples of human-competitive performance by evolutionary algorithms. Our design was approved for flight, and three copies of it were successfully flown on NASA’s Space Technology 5 mission between March 22 and June 30, 2006. These evolved antennas represent the first evolved hardware in space and the first evolved antennas to be deployed.	circular polarization;coat of arms;evolutionary algorithm;evolved antenna;genetic algorithm;genetic programming;programming style;requirement	Jason D. Lohn;Gregory Hornby;Derek S. Linden	2008	AI EDAM	10.1017/S0890060408000164	genetic programming;design;electronic engineering;simulation;computer science;engineering;reconfigurable antenna;electrical engineering;artificial intelligence;conformal antenna;antenna;smart antenna;spacecraft;evolved antenna;evolutionary computation	Networks	32.874279838761055	-2.747417054592199	118951
2dfe943a3797aa540529bc0c4b5e1056f4efc7f0	discrete chaotic gravitational search algorithm for unit commitment problem		This paper presents a discrete chaotic gravitational search algorithm (DCGSA) to solve the unit commitment (UC) problem. Gravitational search algorithm (GSA) has been applied to a wide scope of global optimization problems. However, GSA still suffers from the inherent disadvantages of trap- ping in local minima and the slow convergence rates. The UC problem is a discrete optimization problem and the original GSA and chaos which belong in the realm of continuous space cannot be applied directly. Thus in this paper a data discretization method is implemented after the population initialization to make the improved algorithm available for coping with discrete variables. Two chaotic systems, including logistic map and piece wise linear chaotic map, are used to generate chaotic sequences and to perform local search. The simulation was carried out on small-scale UC problem with six-unit system and ten-unit system. Simulation results show lower fuel cost than other methods such as quadratic model, selective pruning method and iterative linear algorithm, con- firming the potential and effectiveness of the proposed DCGSA for the UC problem.	search algorithm	Sheng Li;Tao Jiang;Huiqin Chen;Dongmei Shen;Yuki Todo;Shangce Gao	2016		10.1007/978-3-319-42294-7_67	mathematical optimization;simulation;artificial intelligence;machine learning;mathematics	NLP	27.155304316866157	-2.810941201522636	118960
b4020c954eb8a8cb6027b76eddcb33c3480e84f1	a gaussian mixture model based local search for differential evolution algorithm		Evolutionary algorithms have been extensively explored and applied in optimization problems. They allow work with multiple solutions simultaneously, with multimodal functions and dynamic problems, and do not require additional information. Several algorithms have been developed over the years for this task. Yet special attention is needed in the area of increasing the convergence speed of evolutionary algorithms. This study is aimed at developing a framework capable of addressing this new line of research in the field of evolutionary computation. We used the Gaussian Mixture Model to do a local search, and generated a new population through the use of Variational Inference. To implement the proposed framework (GMM-Local Search), NSDE both static and dynamic with multiple objectives were used as basic algorithms. Experiments were performed with different test functions for static and dynamic multi-objective optimization problems. The comparison of the algorithms using the proposed framework with the basic algorithms are presented here, thus evidencing that an improvement in the convergence can be achieved.	differential evolution;distribution (mathematics);evolutionary algorithm;evolutionary computation;experiment;google map maker;least squares;local search (optimization);mathematical optimization;mixture model;multi-objective optimization;multimodal interaction;pareto efficiency;run time (program lifecycle phase);variational principle	Elaine Guerrero-Pena;Aluizio F. R. Araújo	2017	2017 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2017.7969531	mixture model;mathematical optimization;artificial intelligence;computer science;evolutionary computation;machine learning;differential evolution;evolutionary algorithm;local search (optimization);dynamic problem;metaheuristic;algorithm;optimization problem	ML	24.88672619116539	-4.411182255335019	119090
4477c7b72260f08cc6708e714653580ea41bdc3e	qos-aware mobile service selection algorithm		For the problem of mobile service selection, this paper gives a context-aware service selection algorithm based on Genetic Algorithm. In this algorithm, a tree encoding method, a fitness function, and a fitness-better strategy were proposed. The tree encoding mode made Genetic Algorithm support selection of various types of service combinations, for example, sequence composition, concurrence composition, probability composition, and loop composition. According to the encoding method, a fitness function was designed specially. The fitness-better strategy gives the direction of population evolution and avoids the degradation of population fitness. Some experiments analyses show that the provided service selection algorithm can get better service composition.	quality of service;selection algorithm	Chengwen Zhang;Lei Zhang;Guanhua Zhang	2016	Mobile Information Systems	10.1155/2016/4968279	simulation;fitness proportionate selection;machine learning;data mining;selection;population-based incremental learning	Mobile	27.52441476427319	-9.462542968260866	119242
894d5d222c2de817f3d385765a54b5c19a487a87	an immune recognition based algorithm for finding non-dominated set in multi-objective optimization	optimal solution;non dominated set;immune recognition multi objective optimization non dominated set;optimisation;complexity theory;sorting;immune recognition;multi objective optimization;construction industry;set theory;set theory computational complexity optimisation;dominating set;computational complexity;immune system;immune recognition based algorithm;multiobjective optimization;optimization;point of view;flowcharts;algorithm design and analysis;computational complexity sorting immune system conferences computational intelligence computer industry flowcharts algorithm design and analysis computational modeling organisms;nondominated set;computational complexity immune recognition based algorithm nondominated set multiobjective optimization	An immune recognition based algorithm is proposed for finding the non-dominated set in multi-objective optimization. In this paper, non-dominated solution is comprehended from a new point of view. Then extra-optimal solution and infra-extra-optimal solution are defined and proved to be non-dominated solutions. After that, flowchart of the algorithm is outlined clearly, correctness of the algorithm is proved in detail, and computational complexity of the algorithm is analyzed theoretically. Compared with the algorithms which have the lowest computational complexity up to the present, experimental results show that when there are less objectives, the efficiency of the method based on immune recognition is almost the same as the method based on arenapsilas principle, and it is much better in the condition of more objectives.	algorithm;computational complexity theory;correctness (computer science);flowchart;mathematical optimization;multi-objective optimization;optimization problem	Xia Zhou;Jiong Shen;Jianxian Shen	2008	2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application	10.1109/PACIIA.2008.235	mathematical optimization;computer science;multi-objective optimization;machine learning;algorithm;population-based incremental learning	EDA	26.000935909859052	0.3420369078002013	119265
5f6a8ed4f9a6aaf6b0ece55f0b475d16cf57d7b1	exploiting mate choice in evolutionary computation: sexual selection as a process of search, optimization, and diversification	mate preference;sexual selection;genetic diversity;natural selection;assortative mating;evolutionary process;mate choice;selection criteria;evolutionary computing	Sexual selection through mate choice is a powerful evolutionary process that has been important in the success of sexually-reproducing animals and flowering plants. Over the short term, mate preferences evolve because they improve the outcome of sexual recombination. Over the long term, assortative mate preferences can help maintain genetic diversity, promote speciation, and facilitate evolutionary search through optimal outbreeding; selective mate preferences can reinforce the speed, accuracy, and efficiency of natural selection, can foster the discovery and propagation of evolutionary innovations, and can function as aesthetic selection criteria. These strengths of sexual selection complement those of natural selection, so using both together may prove particularly fruitful in evolutionary computation. This paper reviews the biological theory of sexual seleetion and some possible applications of sexual selection in evolutionary search, optimization, and diversification. Simulation results are used to illustrate some key points.	assortativity;crossover (genetic algorithm);darwin;diversification (finance);edge of chaos;entity;evolutionary algorithm;evolutionary computation;mathematical optimization;optimizing compiler;patterns of evolution;population;simulation;software propagation	Geoffrey F. Miller	1994		10.1007/3-540-58483-8_6	natural selection;sexual selection;genetic diversity;mate choice;evolutionary computation	ML	25.36286232974405	-8.945044890833643	120026
9ca080e9fb6d78ea3e7e2f9fc9d69073f670c1ca	the chaos artificial immune algorithm and its application to rbf neuro-fuzzy controller design	human immune system;fuzzy controller;fuzzy neural nets;integration chaos artificial life fuzzy neural nets nonlinear systems radial basis function networks neurocontrollers fuzzy control control system synthesis genetic algorithms;chaos;immune algorithm;real time control;real time;fuzzy control;real time control chaos artificial immune algorithm rbf neurofuzzy controller design radial basis function networks human immune system information processing system intelligent computation method function optimization integration artificial immune algorithm inverted pendulum;computational method;integration;function optimization;radial basis function networks;nonlinear systems;control system synthesis;neuro fuzzy;information processing;controller design;genetic algorithm;genetic algorithms;inverted pendulum;neurocontrollers;local search;chaos algorithm design and analysis immune system control systems genetic algorithms cells biology artificial intelligence competitive intelligence space technology plasma simulation;artificial life	The human immune system can be regarded as a complex information processing system, and can provide inspiration for developing intelligent computation method. Many ortificial immune algorithms have been developed and applied to various areas. In this paper, a chaos artificial immune algorithm for function optimizotion problem is proposed by integration of chaotic search and previous artificial immune algorithm. The algorithm uses chaotic variables to pe$orm local search and explore the solution space. The results offunction optimization show that the algorithm is effective. It is further used to design a neuro-fuzzy controller for real-time conhol of an inverted pendulum. Experiment results show that the designed controller can control achial inverted pendulum successful^.	algorithm;combinatorial optimization;computation;feasible region;information processing;information processor;inverted pendulum;local search (optimization);mathematical optimization;neuro-fuzzy;radial basis function;real-time clock	Xing QuanZuo;Shi YongLi	2003		10.1109/ICSMC.2003.1244311	genetic algorithm;information processing;computer science;artificial intelligence;control theory	Robotics	26.824390078584265	-7.481069572373296	120228
17ae9f184277d8838097cdea4721cef688a9db98	hybridizing rrt and variable-length genetic algorithm for smooth path generation	portable document format ieee xplore;genetics;hybrid approach;rapidly exploring random tree;portable document format;genetic algorithm;quality measures;ieee xplore;evolutionary optimization	A smooth path generation scheme based on integrating rapidly-exploring random tree (RRT) with island parallel variable-length genetic algorithm with migration is presented for finding G3-continuous η3-spline paths that minimize a quality measure combining path length and curvature. By injecting RRT solutions into an isolated initial subpopulation and occasional migration to allow the competition and mixture of genetic information between the best individuals of subpopulations whenever feasible paths are discovered in other islands, the hybrid approach discovers smoother path more efficiently while maintaining the diversity of evolutionary optimizer and preventing the premature due to the RRT injection. The simulation results in complex maps demonstrated the advantage of RRT-injection in our implementation, and the hybrid approach is quite flexible and adaptive to generate paths with achievable smoother curvature profile at the expense of a little increased runtime and/or path length.	genetic algorithm;mathematical optimization;rapidly-exploring random tree;simulation	Chun-Hao Wei;Jing-Sin Liu	2011	2011 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2011.6181356	rapidly exploring random tree;mathematical optimization;simulation;genetic algorithm;computer science;artificial intelligence	Robotics	26.598547283770458	-6.675090084692732	120234
18efe133c3338f602c94cb5763f6fc4b5be31e13	stochastic search for signal processing algorithm optimization	large space;search technique;algorithm optimization;evolutionary stochastic search algorithm;search space;large number;signal processing algorithm optimization;evolutionary algorithm;new approach;single signal processing algorithm;search method;security;nodes;performance engineering;algorithms;stochastic processes;asci;evolutionary computation;kerberos;computer architecture;computer science;dynamic programming;grid;signal processing;optimization	This paper presents an evolutionary algorithm for searching for the optimal implementations of signal transforms and compares this approach against other search techniques. A single signal processing algorithm can be represented by a very large number of different but mathematically equivalent formulas. When these formulas are implemented in actual code, unfortunately their running times differ significantly. Signal processing algorithm optimization aims at finding the fastest formula. We present a new approach that successfully solves this problem, using an evolutionary stochastic search algorithm, STEER, to search through the very large space of formulas. We empirically compare STEER against other search methods, showing that it notably can find faster formulas while still only timing a very small portion of the search space.	algorithm;mathematical optimization;signal processing;stochastic optimization	Bryan Singer;Manuela M. Veloso	2001		10.1109/SC.2001.10033	interpolation search;beam search;ascii;mathematical optimization;parallel computing;kerberos;performance engineering;computer science;theoretical computer science;dynamic programming;evolutionary algorithm;signal processing;best-first search;node;programming language;grid;algorithm;evolutionary computation;binary search algorithm;search algorithm	ML	29.113591575175924	0.7220976114923014	120320
7de15c1cd2e7958d4c984e41d2ae022c376bb80c	deterministic agent-based path optimization by mimicking the spreading of ripples	qc physics;qa mathematics;agent based model;path optimization;path optimization agent based model deterministic algorithms ripple spreading algorithm;deterministic algorithms;ripple spreading algorithm	Inspirations from nature have contributed fundamentally to the development of evolutionary computation. Learning from the natural ripple-spreading phenomenon, this article proposes a novel ripple-spreading algorithm (RSA) for the path optimization problem (POP). In nature, a ripple spreads at a constant speed in all directions, and the node closest to the source is the first to be reached. This very simple principle forms the foundation of the proposed RSA. In contrast to most deterministic top-down centralized path optimization methods, such as Dijkstra’s algorithm, the RSA is a bottom-up decentralized agent-based simulation model. Moreover, it is distinguished from other agent-based algorithms, such as genetic algorithms and ant colony optimization, by being a deterministic method that can always guarantee the global optimal solution with very good scalability. Here, the RSA is specifically applied to four different POPs. The comparative simulation results illustrate the advantages of the RSA in terms of effectiveness and efficiency. Thanks to the agent-based and deterministic features, the RSA opens new opportunities to attack some problems, such as calculating the exact complete Pareto front in multiobjective optimization and determining the kth shortest project time in project management, which are very difficult, if not impossible, for existing methods to resolve. The ripple-spreading optimization principle and the new distinguishing features and capacities of the RSA enrich the theoretical foundations of evolutionary computation.		Xiao-Bing Hu;Ming Wang;Mark S. Leeson;Ezequiel A. Di Paolo;Hao Liu	2016	Evolutionary Computation	10.1162/EVCO_a_00156	mathematical optimization;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;mathematical economics;algorithm	Theory	27.28218862503312	-2.125340797637028	120406
f5ad0402ebc11b0446811a292f6d8bb3262c6a2f	a comparison of memetic recombination operators for the traveling salesman problem	traveling salesman problem;generation recombination;memetic algorithm;local search	Several memetic algorithms (MAs) – evolutionary algorithms incorporating local search – have been proposed for the traveling salesman problem (TSP). Much effort has been spent to develop recombination operators for MAs which aim to exploit problem characteristics to achieve a highly effective search. In this paper, several recombination operators for the TSP are compared. For the purpose of identifying the important properties of a recombination operator, a new generic recombination operator (GX) is proposed which is comprised of four phases. These phases can be controlled by parameters reflecting the most important properties of recombination operators. It is shown that GX recombination is superior to MPX and DPX when all common edges are preserved in the offspring.	crossover (genetic algorithm);digital picture exchange;evolutionary algorithm;local search (optimization);memetic algorithm;memetics;the offspring;travelling salesman problem	Peter Merz	2002			2-opt;mathematical optimization;computer science;artificial intelligence;local search;machine learning;mathematics;travelling salesman problem;memetic algorithm	Web+IR	25.0866029017889	-2.6257618913513103	120768
4d2b1887499ccebbac38bd14ddc80623458809fb	an improved quantum-behaved particle swarm optimization algorithm based on linear interpolation	interpolation optimization convergence sociology statistics standards mathematical model;particle swarm optimisation interpolation;search space quantum behaved particle swarm optimization global optimization problems li qpso algorithm model based linear interpolation method objective function	Quantum-behaved particle swarm optimization (QPSO) has shown to be an effective algorithm for solving global optimization problems that are of high complexity. This paper presents a new QPSO algorithm, denoted LI-QPSO, which employs a model-based linear interpolation method to strengthen the local search ability and improve the precision and convergence performance of the QPSO algorithm. In LI-QPSO, linear interpolation is used to approximate the objective function around a pre-chosen point with high quality in the search space. Then, local search is used to generate a promising trial point around this pre-chosen point, which is then used to update the worst personal best point in the swarm. Experimental results show that the proposed algorithm provides some significant improvements in performance on the tested problems.	approximation algorithm;display resolution;global optimization;linear interpolation;local search (optimization);mathematical optimization;optimization problem;particle swarm optimization;quantum	Shouyong Jiang;Shengxiang Yang	2014	2014 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2014.6900354	mathematical optimization;multi-swarm optimization;combinatorics;meta-optimization;derivative-free optimization;machine learning;inverse quadratic interpolation;mathematics;particle swarm optimization;metaheuristic	Vision	28.906607450928163	-3.782590553435388	121340
aed00c7999a2d32d05493c8317536e8c1767d923	local search with probabilistic modeling for learning multiple-valued logic networks	local search;probabilistic model	This paper proposes a probabilistic modeling learning algorithm for the local search approach to the Multiple-Valued Logic (MVL) networks. The learning model (PMLS) has two phases: a local search (LS) phase, and a probabilistic modeling (PM) phase. The LS performs searches by updating the parameters of the MVL network. It is equivalent to a gradient decrease of the error measures, and leads to a local minimum of error that represents a good solution to the problem. Once the LS is trapped in local minima, the PM phase attempts to generate a new starting point for LS for further search. It is expected that the further search is guided to a promising area by the probability model. Thus, the proposed algorithm can escape from local minima and further search better results. We test the algorithm on many randomly generated MVL networks. Simulation results show that the proposed algorithm is better than the other improved local search learning methods, such as stochastic dynamic local search (SDLS) and chaotic dynamic local search (CDLS). key words: multiple-valued logic, network learning, local search, probabilistic modeling, combinatorial optimization problems	algorithm;combinatorial optimization;gradient;least squares;local search (optimization);mathematical optimization;maxima and minima;procedural generation;simulation	Shangce Gao;Qi Ping Cao;Masahiro Ishii;Zheng Tang	2011	IEICE Transactions		beam search;statistical model;mathematical optimization;tabu search;local search;theoretical computer science;hill climbing;machine learning;iterated local search;mathematics;best-first search;line search;algorithm;statistics;guided local search	AI	27.58915103553377	-0.9786597961049086	121460
cc0110ee17d31e59b4101302745e0a341a605dcd	using genetic algorithms to evolve behavior in cellular automata	topology;topologie;algoritmo genetico;topologia;automate cellulaire;algorithme genetique;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;evolutionary algorithm;cellular automata;cellular automaton;automata celular	It is an unconventional computation approach to evolve solutions instead of calculating them. Although using evolutionary computation in computer science dates back to the 1960s, using an evolutionary approach to program other algorithms is not that well known. In this paper a genetic algorithm is used to evolve behavior in cellular automata. It shows how this approach works for different topologies and neighborhood shapes. Some different one dimensional neighborhood shapes are investigated with the genetic algorithm and yield surprisingly good results.	automata theory;cellular automaton;computer science;evolutionary computation;genetic algorithm;iterative and incremental development;network topology;production (computer science);software release life cycle	Thomas Bäck;Ron Breukelaar	2005		10.1007/11560319_1	cellular automaton;genetic algorithm;growcut algorithm;computer science;artificial intelligence;theoretical computer science;genetic representation;mathematics;algorithm	AI	26.89659747602029	1.360476100086993	121552
b4d4f0ccb387e829e3d934ca6ab95e0f69c408d3	dynamic optimization of industrial processes with nonuniform discretization-based control vector parameterization	nonuniform discretizetion based control vector parameterization dynamic optimization hybrid gradient particle swarm optimization;optimization methods computational efficiency numerical simulation mathematical model;hgpso industrial processes nonuniform discretization based control vector parameterization ndcvp dynamic optimization problems dop udcvp hybrid gradient particle swarm optimization;vectors industrial engineering particle swarm optimisation	This paper proposes a novel scheme of nonuniform discretizetion-based control vector parameterization (ndCVP, for short) for dynamic optimization problems (DOPs) of industrial processes. In our ndCVP scheme, the time span is partitioned into a multitude of uneven intervals, and incremental time parameters are encoded, along with the control parameters, into the individual to be optimized. Our coding method can avoid handling complex ordinal constraints. It is proved that ndCVP is a natural generalization of uniform discretization-based control vector parameterization (udCVP). By integrating ndCVP into hybrid gradient particle swarm optimization (HGPSO), a new optimization method, named ndCVP-HGPSO for short, is formed. By application in four classic DOPs, simulation results show that ndCVP-HGPSO is able to achieve similar or even better performances with a small number of control intervals; while the computational overheads are acceptable. Furthermore, ndCVP and udCVP are compared in terms of two situations: given the same number of control intervals and given the same number of optimization variables. The results show that ndCVP can achieve better performance in most cases.	algorithm;computation;discretization;dynamic programming;gradient;mathematical optimization;optimal control;ordinal data;particle swarm optimization;performance;program optimization;simulation	Xu Chen;Wenli Du;Huaglory Tianfield;Rongbin Qi;Wangli He;Feng Qian	2014	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2013.2292582	control engineering;mathematical optimization;multi-swarm optimization;derivative-free optimization;control theory;mathematics;continuous optimization;metaheuristic	Robotics	32.19673414074315	-4.005444603994968	122046
4ff9c50f6d283c92b7b2ce318512fc1dae29e437	artificial bee colony with bidirectional search	bidirectional search;artificial bee colony;optimisation;swarm intelligence;metaheuristics;abc;search strategy;global best individual	Artificial bee colony (ABC) is an efficient meta-heuristic, which has shown good search abilities on many optimisation problems. In the standard ABC, its solution updating equation uses a random weight to control the difference vector between the current food source and another randomly selected one, and the random weight between −1 and 1 determines the search directions. How to select a good search direction is not an easy task. In this paper, we propose a new ABC algorithm called ABC with bidirectional search, which employs a new method to control the search direction of ABC. To verify the effectiveness of the bidirectional search method, we embed it into two ABC variants and test compares their performance with their corresponding parent algorithms. Experimental results on six benchmark functions show that the bidirectional search method can effectively improve the performance of ABC.	artificial bee colony algorithm;bidirectional search	Yong Lu;Ruixiang Li;Sumin Li	2016	IJCSM	10.1504/IJCSM.2016.10002462	mathematical optimization;bidirectional search;swarm intelligence;computer science;artificial intelligence;machine learning	AI	27.102628641335365	-3.7864541829245786	122261
ec3c57cb20f7a0b45d201cb55a46cd19bb3b96cb	an improved pso algorithm with decline disturbance index	convergence;premature;decline disturbance index;stochastic processes;particle swarm optimization	The particle swarm optimization algorithm (PSO) has two typical problems as in other adaptive evolutionary algorithms, which are based on swarm intelligence search. To deal with the problems of the slow convergence rate and the tendency to trap into premature, an improved particle swarm optimization with decline disturbance index (DDPSO) is presented in this paper. The index was added when the velocity of the particle is prone to stagnation in the middle and later evolution periods. The modification improves the ability of particles to explore the global and local optimization solutions, and reduces the probability of being trapped into the local optima. Theoretical analysis, which is based on stochastic processes, proves that the trajectory of particle is a Markov processes and DDPSO algorithm converges to the global optimal solution with mean square merit. Experimental simulations show that the improved algorithm can not only improve the convergence of the algorithm significantly, but also avoid trapping into local optimization solution.	evolutionary algorithm;local optimum;local search (optimization);mathematical optimization;mean squared error;particle swarm optimization;rate of convergence;simulation;stochastic process;swarm intelligence;velocity (software development)	Fuqing Zhao;Jianxin Tang;Jizhe Wang;Chunmiao Wei	2011	JCP	10.4304/jcp.6.4.691-697	stochastic process;mathematical optimization;multi-swarm optimization;meta-optimization;convergence;computer science;artificial intelligence;machine learning;mathematics;particle swarm optimization;metaheuristic	ML	28.075685456732398	-4.88427516264082	122334
46ed41821c571f455a94a59996dec3a9aaf94af2	mutation multiplicity in a panmictic two-strategy genetic algorithm	numerical method;combinatorial optimization problem;multiplicite;probabilistic approach;algoritmo genetico;convergence speed;optimisation combinatoire;combinatorial problem;probleme combinatoire;problema combinatorio;paradigm;metodo numerico;enfoque probabilista;approche probabiliste;multiplicidad;paradigme;algorithme genetique;velocidad convergencia;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;evolutionary algorithm;cumulant;paradigma;combinatorial optimization;vitesse convergence;multiplicity;methode numerique;optimizacion combinatoria	Fitness based selection procedures leave majority of popu- lation individuals idle, that is, they don't take place in any recombina- tion operation although some of them have above average fitness values. Based on this observation, a two-phase two-strategy genetic algorithm using a conventional strategy with multiple mutation operators in the first phase is proposed. In the second phase, those individuals that are not sufficiently recombined in the first phase are reconsidered within a second strategy and recombined using multiple mutation operators only. In the second strategy, mutation operator probabilities are adaptively de- termined based on the cumulative fitness-gain achieved by each mutation operator over a number of generations. The proposed genetic algorithm paradigm is used for the solution of hard numerical and combinatorial optimization problems. The results demonstrate that the proposed ap- proach performs much better than the conventional implementations in terms of solution quality and the convergence speed.	genetic algorithm	Adnan Acan	2004		10.1007/978-3-540-24652-7_1	mathematical optimization;mutation;calculus;mathematics;algorithm	Robotics	26.52955044485561	1.4651048638054531	122364
bec70b5f5ac095838a52b4f50b1f9f6fed873972	unsupervised clustering and multi-optima evolutionary search	clustering algorithms linear programming sociology statistics vectors optimization algorithm design and analysis;convergence speed acceleration unsupervised clustering algorithms multioptima evolutionary search data mining evolutionary computation multiple local optima multiple global optima objective function spatial concentration concentration regions population member positions intuitive approximations;global optimization data mining clustering differential evolution particle swarm optimization;unsupervised learning approximation theory convergence of numerical methods data mining evolutionary computation pattern clustering search problems	This paper pursues a course of investigation of an approach to combine Evolutionary Computation and Data Mining for the location and computation of multiple local and global optima of an objective function. To accomplish this task we exploit the spatial concentration of the population members around the optima of the objective function. Such concentration regions are determined by applying clustering algorithms on the actual positions of the members of the population. Subsequently, the evolutionary search is confined in the interior of the regions discovered. To enable the simultaneous discovery of more than one global and local optima, we propose the use of clustering algorithms that also provide intuitive approximations for the number of clusters. Furthermore, the proposed scheme has often the potential of accelerating the convergence speed of the Evolutionary Algorithm, without the need for extra function evaluations.	approximation;cluster analysis;data mining;evolutionary algorithm;evolutionary computation;local optimum;loss function;optimization problem	Vassilis P. Plagianakos	2014	2014 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2014.6900431	correlation clustering;constrained clustering;mathematical optimization;data stream clustering;canopy clustering algorithm;machine learning;cure data clustering algorithm;data mining;mathematics;cluster analysis;biclustering;affinity propagation;metaheuristic;clustering high-dimensional data	ML	28.23915201733897	-5.990979111019643	122632
0728c95946040f10ecf56dc92a6c262d58e1b555	a new cuckoo search based levenberg-marquardt (cslm) algorithm	levenberg marquardt;cuckoo search algorithm;local minima;back propagation;artificial neural network;qa76 computer software	Back propagation neural network (BPNN) algorithm is a widely used technique in training artificial neural networks. It is also a very popular optimization procedure applied to find optimal weights in a training process. However, traditional back propagation optimized with Levenberg marquardt training algorithm has some drawbacks such as getting stuck in local minima, and network stagnancy. This paper proposed an improved Levenberg-Marquardt back propagation (LMBP) algorithm integrated and trained with Cuckoo Search (CS) algorithm to avoided local minima problem and achieves fast convergence. The performance of the proposed Cuckoo Search Levenberg-Marquardt (CSLM) algorithm is compared with Artificial Bee Colony (ABC) and similar hybrid variants. The simulation results show that the proposed CSLM algorithm performs better than other algorithm used in this study in term of convergence rate and accuracy.	4-bit;artificial neural network;backpropagation;benchmark (computing);color depth;cuckoo search;exclusive or;levenberg–marquardt algorithm;malaysian identity card;mathematical optimization;maxima and minima;rate of convergence;simulation;software propagation;tun (product standard)	Nazri Mohd Nawi;Abdullah Khan;Mohammad Zubair Rehman	2013		10.1007/978-3-642-39637-3_35	mathematical optimization;levenberg–marquardt algorithm;computer science;artificial intelligence;backpropagation;machine learning;maxima and minima;artificial neural network	ML	29.52949984644177	-5.448592402749464	122642
73a03d0d2fe98beafc68709186fe899ca972d43c	a preliminary study of crowding with biased crossover	crowding;genetic algorithms gas;niching;niche	"""This paper proposes a novel crowding method, which is called """"Crowding with Biased Crossover (CBX)"""". The Biased crossover operator begins with two parents. Then two offspring individuals are created, each offspring taking more characteristics from one of the two parents. This is an easy method to perform replacement between parents and offspring individuals. Experimental results showed that CBX is very effective in finding both single global solutions and multiple solutions (niching)."""	crowding	Shigeyoshi Tsutsui;Noriyuki Fujimoto	2013		10.1145/2464576.2480774	crowding;niche;artificial intelligence	HCI	26.36341885321797	-3.7428895664232877	122830
1101e51f8e37d812e9fa72ad218f1259866095b1	optimal time-space tradeoff in probabilistic inference	any-space algorithm;exact inference;important problem;bayesian network;varying amount;optimal caching scheme;memory requirement;cache size;state-of-the-art algorithm;probabilistic inference;optimal time-space tradeoff curve;probabilistic reasoning;floating point	Recursive Conditioning, RC, is an any-space algorithm lor exact inference in Bayesian networks, which can trade space for time in increments of the size of a floating point number. This smooth tradeoff' is possible by varying the algorithm's cache size. When RC is run with a constrained cache size, an important problem arises: Which specific results should be cached in order to minimize the running time of the algorithm? RC is driven by a structure known as a dtree, and many such dtrees exist for a given Bayesian network. In this paper, we examine the problem of searching for an optimal caching scheme for a given dtree, and present some optimal time-space tradeoff curves for given dtrees of several published Bayesian networks. We also compare these curves to the memory requirements of state-of-the-art algorithms based on jointrees. Our results show that the memory requirements of these networks can be significantly reduced with only a minimal cost in time, allowing for exact inference in situations previously impractical. They also show that probabilistic reasoning systems can be efficiently designed to run under varying amounts of memory.	algorithm;bayesian network;cpu cache;cache (computing);reasoning system;recursion (computer science);requirement;space–time tradeoff;time complexity	David Allen;Adnan Darwiche	2002			variable elimination;computer science;floating point;theoretical computer science;machine learning;bayesian network;mathematics;probabilistic logic;statistics	AI	34.503236612720315	2.0043715457313787	123098
575edec1f3512c265d764ac65a3a6e820d69e684	on the convergence of statistical search	machine learning algorithms;minimization;convergence;variable structure;approximation algorithms;random variables;theorem proving;automata;convergence stochastic processes automata performance analysis stochastic systems approximation algorithms random processes machine learning algorithms machine learning;machine learning;stochastic processes;random process;continuous optimization;random processes;performance analysis;optimization;search problems;stochastic systems;convergence in probability;random search	The convergence of statistical (random) search for the minimization of an arbitrary multimodal functional Q(w) is dealt with by using the theorems of convergence of random processes of Braverman and Rozonoer. It is shown that random search can be regarded as a gradient algorithm in the Q-domain. Using this gradient to define the minimum of the functional, the convergence to this minimum is discussed at length. The theorems proved in this paper apply as well to discrete as to continuous optimization problems and as such, the developed technique is competitive with stochastic automata with a variable structure. The optimality of the scheme follows from the convergence in probability of the average performance to the minimum. The freedom in the organization of the search within the boundaries outlined by the conditions of convergence is emphasized. Finally, it is pointed out how various mixed random search and hierarchical search systems fall into the domain of application of the theorems.	algorithm;automata theory;best, worst and average case;continuous optimization;gradient;mathematical optimization;multimodal interaction;random search;stochastic process	Luc Devroye	1976	IEEE Transactions on Systems, Man, and Cybernetics	10.1109/TSMC.1976.5408396	random variable;stochastic process;mathematical optimization;combinatorics;random search;convergence;convergence of random variables;computer science;modes of convergence;compact convergence;proofs of convergence of random variables;machine learning;mathematics;convergence tests;automaton;automated theorem proving;normal convergence;statistics	ML	39.01773583634069	2.7933748288265257	123262
b1d2a95fe0ba320914c47e308b1f0eaa053814e1	a new fuzzy harmony search algorithm using fuzzy logic for dynamic parameter adaptation	fuzzy logic;dynamic parameter adaptation;harmony search	Abstract: In this paper, a new fuzzy harmony search algorithm (FHS) for solving optimization problems is presented. FHS is based on a recent method using fuzzy logic for dynamic adaptation of the harmony memory accepting (HMR) and pitch adjustment (PArate) parameters that improve the convergence rate of traditional harmony search algorithm (HS). The objective of the method is to dynamically adjust the parameters in the range from 0.7 to 1. The impact of using fixed parameters in the harmony search algorithm is discussed and a strategy for efficiently tuning these parameters using fuzzy logic is presented. The FHS algorithm was successfully applied to different benchmarking optimization problems. The results of simulation and comparison studies demonstrate the effectiveness and efficiency of the proposed approach.	benchmark (computing);fuzzy control system;fuzzy logic;hs algorithm;harmony search;iteration;local optimum;mathematical optimization;multilevel model;nonlinear system;rate of convergence;search algorithm;simulation	Cinthia Peraza;Fevrier Valdez;Mario García Valdez;Patricia Melin;Oscar Castillo	2016	Algorithms	10.3390/a9040069	fuzzy logic;mathematical optimization;harmony search;fuzzy classification;computer science;artificial intelligence;fuzzy number;machine learning;mathematics	AI	25.922119880632884	-4.861981867906657	123285
ea1a9eeab82cae242f8ae6a8b0f8a5fe8ba27845	multiobjective evolution of biped robot gaits using advanced continuous ant-colony optimized recurrent neural networks		This paper proposes the optimization of a fully connected recurrent neural network (FCRNN) using advanced multiobjective continuous ant colony optimization (AMO-CACO) for the multiobjective gait generation of a biped robot (the NAO). The FCRNN functions as a central pattern generator and is optimized to generate angles of the hip roll and pitch, the knee pitch, and the ankle pitch and roll. The performance of the FCRNN-generated gait is evaluated according to the walking speed, trajectory straightness, oscillations of the body in the pitch and yaw directions, and walking posture, subject to the basic constraints that the robot cannot fall down and must walk forward. This paper formulates this gait generation task as a constrained multiobjective optimization problem and solves this problem through an AMO-CACO-based evolutionary learning approach. The AMO-CACO finds Pareto optimal solutions through ant-path selection and sampling operations by introducing an accumulated rank for the solutions in each single-objective function into solution sorting to improve learning performance. Simulations are conducted to verify the AMO-CACO-based FCRNN gait generation performance through comparisons with different multiobjective optimization algorithms. Selected software-designed Pareto optimal FCRNNs are then applied to control the gait of a real NAO robot.	amo-1618;add-ons for firefox;algorithm;amo vitrax;ant colony optimization algorithms;artificial neural network;biological evolution;body position;caco-2 cells;central pattern generator;computer simulation;crocus nevadensis;evaluation;experiment;feed forward (control);feedforward neural network;hl7publishingsubsection <operations>;iteration;klk15 gene;mathematical optimization;multi-objective optimization;nao (robot);neural network simulation;neural tube defects;optimization problem;parallel computing;pareto efficiency;poor posture;recurrent neural network;robot leg;sampling (signal processing);solutions;sorting;trajectory optimization;walking speed;weight;yaws	Chia-Feng Juang;Yen-Ting Yeh	2018	IEEE Transactions on Cybernetics	10.1109/TCYB.2017.2718037	mathematical optimization;ant colony optimization algorithms;machine learning;genetic algorithm;ant colony;artificial intelligence;robot;mathematics;gait;recurrent neural network;multi-objective optimization;trajectory	Robotics	30.585361145957997	-3.542924269770325	123299
bc3d92c57af70206a692e04a4118cbac6d37a719	constructing constrained-version of magic squares using selection hyper-heuristics	magic square;qa75 electronic computers computer science;computational design;hyper heuristic;late acceptance;article	A square matrix of distinct numbers in which every row, column and both diagonals has the same total is referred to as a magic square. Constructing a magic square of a given order is considered as a difficult computational problem, particularly when additional constraints are imposed. Hyper-heuristics are emerging high level search methodologies that explore the space of heuristics for solving a given problem. In this study, we present a range of effective selection hyper-heuristics mixing perturbative low level heuristics for constructing the constrained version of magic squares. The results show that selection hyperheuristics, even the non-learning ones deliver an outstanding performance, beating the best known heuristic solution on average.	computation;computational problem;heuristic (computer science);high-level programming language;hyper-heuristic;nam;perturbation theory (quantum mechanics);problem domain;rp (complexity);random permutation	Ahmed Kheiri;Ender Özcan	2014	Comput. J.	10.1093/comjnl/bxt130	mathematical optimization;combinatorics;magic square;computer science;mathematics;hyper-heuristic;algorithm	AI	25.86066639502842	4.052301442040224	123342
a1238eda99955958ce4bf17ead40fbc8635ac1bf	collaborative parallel hybrid metaheuristics on graphics processing unit	parallel computing;gpu;simulated annealing;hybrid metaheuristic;cuda;particle swarm optimization;genetic algorithm	Metaheuristics are nondeterministic optimization algorithms used to solve complex problems for which classic approaches are unsuitable. Despite their e®ectiveness, metaheuristics require considerable computational power and cannot easily be used in time critical applications. Fortunately, those algorithms are intrinsically parallel and have been implemented on shared memory systems and more recently on graphics processing units (GPUs). In this paper, we present highly e±cient parallel implementations of the particle swarm optimization (PSO), the genetic algorithm (GA) and the simulated annealing (SA) algorithm on GPU using CUDA. Our approach exploits the parallelism at the solution level, follows an island model and allows for speedup up to 346 for di®erent benchmark functions. Most importantly, we also present a strategy that uses the generalized island model to integrate multiple metaheuristics into a parallel hybrid solution adapted to theGPU.Our proposed solutionusesOpenMPtoheavily exploit the concurrent kernel execution feature of recent NVIDIA GPUs, allowing for the parallel execution of the di®erent metaheuristics in an asynchronous manner. Asynchronous hybrid metaheuristics has been developed for multicore CPU, but never for GPU. The speedup o®ered by the GPU is far superior and key to the optimization of solutions to complex engineering problems.	benchmark (computing);cuda;central processing unit;computation;computer graphics;genetic algorithm;graphics processing unit;mathematical optimization;metaheuristic;multi-core processor;openmp;parallel computing;particle swarm optimization;phase-shift oscillator;run time (program lifecycle phase);shared memory;simulated annealing;software release life cycle;speedup	Vincent Roberge;Mohamed Tarbouchi;Francis A. Okou	2015	International Journal of Computational Intelligence and Applications	10.1142/S1469026815500029	differential evolution;computational science;mathematical optimization;parallel computing;ant colony optimization algorithms;genetic algorithm;parallel metaheuristic;simulated annealing;computer science;theoretical computer science;particle swarm optimization;metaheuristic	HPC	26.52495125273185	-0.6102322643394367	123624
34a89100bfca6c27eff28160d34a89c808755dd2	competitive swarm optimizer based gateway deployment algorithm in cyber-physical systems	particle swarm optimization pso;geometric k center;covering radius;competitive swarm optimizer cso;cyber physical system;gateway deployment	Wireless sensor network topology optimization is a highly important issue, and topology control through node selection can improve the efficiency of data forwarding, while saving energy and prolonging lifetime of the network. To address the problem of connecting a wireless sensor network to the Internet in cyber-physical systems, here we propose a geometric gateway deployment based on a competitive swarm optimizer algorithm. The particle swarm optimization (PSO) algorithm has a continuous search feature in the solution space, which makes it suitable for finding the geometric center of gateway deployment; however, its search mechanism is limited to the individual optimum (pbest) and the population optimum (gbest); thus, it easily falls into local optima. In order to improve the particle search mechanism and enhance the search efficiency of the algorithm, we introduce a new competitive swarm optimizer (CSO) algorithm. The CSO search algorithm is based on an inter-particle competition mechanism and can effectively avoid trapping of the population falling into a local optimum. With the improvement of an adaptive opposition-based search and its ability to dynamically parameter adjustments, this algorithm can maintain the diversity of the entire swarm to solve geometric K-center gateway deployment problems. The simulation results show that this CSO algorithm has a good global explorative ability as well as convergence speed and can improve the network quality of service (QoS) level of cyber-physical systems by obtaining a minimum network coverage radius. We also find that the CSO algorithm is more stable, robust and effective in solving the problem of geometric gateway deployment as compared to the PSO or Kmedoids algorithms.	accidental falls;anatomic node;anatomy, regional;chief security officer;common scientific outline nci;competitive medical plans;convergence (action);cyber-physical system;deploy;feasible region;local optimum;mathematical optimization;metric k-center;network topology;norm (social);operand forwarding;particle swarm optimization;phase-shift oscillator;population parameter;quality of service;routing;search algorithm;simulation;topology control;topology optimization;web search engine;wireless mesh network	Shuqiang Huang;Ming Tao	2017		10.3390/s17010209	embedded system;mathematical optimization;multi-swarm optimization;simulation;computer science;engineering;artificial intelligence;cyber-physical system	AI	31.442701513747146	-2.784049954543748	123710
2e23c0424214c934f8c46a5498d43dbb99b9b4bb	the robot routing problem for collecting aggregate stochastic rewards		We propose a new model for formalizing reward collection problems on graphs with dynamically generated rewards which may appear and disappear based on a stochastic model. The robot routing problem is modeled as a graph whose nodes are stochastic processes generating potential rewards over discrete time. The rewards are generated according to the stochastic process, but at each step, an existing reward disappears with a given probability. The edges in the graph encode the (unit-distance) paths between the rewards’ locations. On visiting a node, the robot collects the accumulated reward at the node at that time, but traveling between the nodes takes time. The optimization question asks to compute an optimal (or -optimal) path that maximizes the expected collected rewards. We consider the finite and infinite-horizon robot routing problems. For finite-horizon, the goal is to maximize the total expected reward, while for infinite horizon we consider limit-average objectives. We study the computational and strategy complexity of these problems, establish NPlower bounds and show that optimal strategies require memory in general. We also provide an algorithm for computing -optimal infinite paths for arbitrary > 0. 1998 ACM Subject Classification I.2.8 Problem Solving, Control Methods, and Search	aggregate function;algorithm;encode;mathematical optimization;problem solving;robot;routing;stochastic process	Rayna Dimitrova;Ivan Gavran;Rupak Majumdar;Vinayak S. Prabhu;Sadegh Esmaeil Zadeh Soudjani	2017		10.4230/LIPIcs.CONCUR.2017.13	mathematical optimization;computer science;artificial intelligence;machine learning;distributed computing	Theory	37.710021228845825	3.990190208683821	123859
ff118393dba59d2f78039eb1e527e55a21930fb9	a differential-based harmony search algorithm for the optimization of continuous problems	differential evolution;meta heuristics;continuous optimization;evolutionary optimization;harmony search algorithm	We introduced a new harmony memory initialization method.We introduced a new pitch adjustment method based on DE/best/1 mutation strategy.We comprehensively studied the parameter setting of our algorithm.We compared our algorithm with the state of the art variants of HS algorithm.We compared our algorithm with the state of the art variants of DE algorithm. The performance of the Harmony Search (HS) algorithm is highly dependent on the parameter settings and the initialization of the Harmony Memory (HM). To address these issues, this paper presents a new variant of the HS algorithm, which is called the DH/best algorithm, for the optimization of globally continuous problems. The proposed DH/best algorithm introduces a new improvisation method that differs from the conventional HS in two respects. First, the random initialization of the HM is replaced with a new method that effectively initializes the harmonies and reduces randomness. Second, the conventional pitch adjustment method is replaced by a new pitch adjustment method that is inspired by a Differential Evolution (DE) mutation strategy known as DE/best/1. Two sets of experiments are performed to evaluate the proposed algorithm. In the first experiment, the DH/best algorithm is compared with other variants of HS based on 12 optimization functions. In the second experiment, the complete CEC2014 problem set is used to compare the performance of the DH/best algorithm with six well-known optimization algorithms from different families. The experimental results demonstrate the superiority of the proposed algorithm in convergence, precision, and robustness.	harmony search;mathematical optimization;search algorithm	Hosein Abedinpourshotorban;Shafaatunnur Hasan;Siti Mariyam Hj. Shamsuddin;Nur Fatimah As'Sahra	2016	Expert Syst. Appl.	10.1016/j.eswa.2016.05.013	differential evolution;mathematical optimization;meta-optimization;ramer–douglas–peucker algorithm;harmony search;computer science;artificial intelligence;mathematics;continuous optimization;algorithm;population-based incremental learning	Vision	26.72658218094025	-3.9558873788067457	123926
0e5645786481724692576c63ba23efe7af87cfea	a new multilayer optical film optimal method based on deep q-learning		Multi-layer optical film has been found to afford important applications in optical communication, optical absorbers, optical filters, etc. Different algorithms of multi-layer optical film design has been developed, as simplex method, colony algorithm, genetic algorithm. These algorithms rapidly promote the design and manufacture of multi-layer films. However, traditional numerical algorithms often converge to local optimum. This means that these algorithms can not give a global optimal solution to the material researchers. In recent years, due to the rapid development of artificial intelligence, to optimize optical film structure using AI algorithm has become possible. In this paper, we will introduce a new optical film design algorithm based on the deep Q learning. This model can converge the global optimum of the optical thin film structure, this will greatly improve the design efficiency of multi-layer films.		Anqing Jiang;Osamu Yoshie;Liangyao Chen	2018	CoRR			AI	30.934853919812024	2.9640506379270644	124157
506cee4f38719c4affd4373656962010850f452c	an improved vector particle swarm optimization for constrained optimization problems	multi dimensional search algorithm;search algorithm;multi dimensional;real world application;particle swarm optimizer;constrained optimization problems;particle swarm optimization;on the fly;constraint handling;constrained optimization problem	Increasing attention is being paid to solve constrained optimization problems (COP) frequently encountered in real-world applications. In this paper, an improved vector particle swarm optimization (IVPSO) algorithm is proposed to solve COPs. The constraint-handling technique is based on the simple constraint-preserving method. Velocity and position of each particle, as well as the corresponding changes, are all expressed as vectors in order to present the optimization procedure in a more intuitively comprehensible manner. The NVPSO algorithm [30], which uses one-dimensional search approaches to find a new feasible position on the flying trajectory of the particle when it escapes from the feasible region, has been proposed to solve COP. Experimental results showed that searching only on the flying trajectory for a feasible position influenced the diversity of the swarm and thus reduced the global search capability of the NVPSO algorithm. In order to avoid neglecting any worthy position in the feasible region and improve the optimization efficiency, a multi-dimensional search algorithm is proposed to search within a local region for a new feasible position. The local region is composed of all dimensions of the escaped particle's parent and the current positions. Obviously, the flying trajectory of the particle is also included in this local region. The new position is not only present in the feasible region but also has a better fitness value in this local region. The performance of IVPSO is tested on 13 well-known benchmark functions. Experimental results prove that the proposed IVPSO algorithm is simple, competitive and stable.	constrained optimization;mathematical optimization;particle swarm optimization	Chao-Li Sun;Jianchao Zeng;Jeng-Shyang Pan	2011	Inf. Sci.	10.1016/j.ins.2010.11.033	mathematical optimization;multi-swarm optimization;constrained optimization;simulation;meta-optimization;computer science;derivative-free optimization;artificial intelligence;mathematics;particle swarm optimization;metaheuristic;search algorithm	AI	27.78898183810728	-3.663756098115256	124473
083f4da0ca569c48cf67516cefe2c4d9b30f642b	pole-zero system identification using genetic algorithms	system identification;genetic algorithm		genetic algorithm;system identification	Stuart J. Flockton;Michael S. White	1993			quality control and genetic algorithms;meta-optimization	AI	25.072462050378252	-6.1033645189064885	124786
d437dc23efc647406e097caaab52de31b6879a03	darwinian docking		"""The Darwinian model of evolution is an optimization strategy that can be adapted to docking. It differs from the common use of genetic algorithms, primarily in its acceptance of diverse solutions over finding """"global"""" optima. A related problem is selecting compounds using multiple criteria. I discuss these ideas and present the outlines of a protocol for selecting """"hits"""" and """"leads"""" in drug discovery."""		Irwin D. Kuntz	2012	Journal of computer-aided molecular design	10.1007/s10822-011-9503-4		EDA	25.607444349169032	-7.850288230343862	124896
573e5ecf06692d99f8393ecb82c05961b42f7d78	fast feature selection in a gpu cluster using the delta test	general purpose computing on graphics processing units gpgpu;paper;gpu cluster;info eu repo semantics article;cuda;variable selection;big data;nvidia;nvidia geforce 8400 gs;nvidia geforce 9800 gtx;algorithms;nearest neighbour;feature selection;computer science;nvidia geforce gts 450	Feature or variable selection still remains an unsolved problem, due to the infeasible evaluation of all the solution space. Several algorithms based on heuristics have been proposed so far with successful results. However, these algorithms were not designed for considering very large datasets, making their execution impossible, due to the memory and time limitations. This paper presents an implementation of a genetic algorithm that has been parallelized using the classical island approach, but also considering graphic processing units to speed up the computation of the fitness function. Special attention has been paid to the population evaluation, as well as to the migration operator in the parallel genetic algorithm (GA), which is not usually considered too significant; although, as the experiments will show, it is crucial in order to obtain robust results.	computation;experiment;feasible region;feature selection;fitness function;gpu cluster;genetic algorithm;graphical user interface;graphics processing unit;heuristic (computer science);parallel computing;supercomputer	Alberto Guillén;Maribel García Arenas;Mark van Heeswijk;Dusan Sovilj;Amaury Lendasse;Luis Javier Herrera;Héctor Pomares;Ignacio Rojas	2014	Entropy	10.3390/e16020854	parallel computing;computer science;theoretical computer science;feature selection;computer graphics (images)	AI	26.0374914007729	-0.504917501567059	125248
6eeb379fa5193367623082ff5fc4529a8a4e18f3	steganalysis using color model conversion		The major threat in cyber crime for digital forensic examiner is to identify, analyze and interpret the concealed information inside digital medium such as image, audio and video. There are strong indications that hiding information inside digital medium has been used for planning criminal activities. In this way, it is important to develop a steganalysis technique which detects the existence of hidden messages inside digital medium. This paper focuses on universal image steganalysis method which uses RGB to HSI colour model conversion. Any Universal Steganalysis algorithm developed should be tested with various stegoimages to prove its efficiency. The developed Universal Steganalysis algorithm is tested in stego-image database which is obtained by implementing various RGB Least Significant Bit Steganographic algorithms. Though there are many stego-image sources available on the internet it lacks in the information such as how many rows has been infected by the steganography algorithms, how many bits have been modified and which channel has been affected. These parameters are important for Steganalysis algorithms and it helps to rate its efficiency. Proposed Steganalysis using Colour Model has been tested with our Image Database and the results were affirmative.	algorithm;cybercrime;horizontal situation indicator;integrated information theory;least significant bit;steganalysis;steganography	P. Thiyagarajan;G. Aghila;V. Prasanna Venkatesan	2011	CoRR		steganalysis;mathematics;internet privacy;world wide web;computer security	Graphics	37.51764549776251	-9.170852256768688	125443
6e6d425993aa04c0da2d04a1bed34ed8f0fa0e1a	real-coded genetic algorithm identification of a flexible plate system	real coded genetic algorithm	Parametric modelling deals with determination of model parameters of a system. Parametric modelling of systems may benefit from advantages of real coded genetic algorithms (RCGAs), as they do not suffer from loss of precision during the processes of encoding and decoding compared with Binary Coded Genetic Algorithm. In this paper, RCGA is used to identify the best model order and associated parameters characterising a thin plate system. The performance of the approach is assessed on basis mean-squared error, time and frequency domain response of the developed model in characterising the system. A comparative assessment of the approach with binary coded GA is also provided. Simulation results signify the advantages of RCGA over two further algorithms in modelling the plate system are also provided.	genetic algorithm;mean squared error;simulation;software release life cycle;tun (product standard)	Salihatun Md. Salleh;M. Osman Tokhi;Siti Fauziah Toha	2009			meta-optimization;computer science	AI	32.22139266422003	-6.48926915620009	125527
292c260ea387d35b8dde532ef4bcccf732c64b80	a good nodes set evolution strategy for constrained optimization	constrained optimization;rate of convergence;evolutionary computation;search space;set theory constraint theory evolutionary computation number theory;benchmark problem;evolutionary algorithm good nodes set evolution strategy constrained optimization problem number theory crossover operator;set theory;number theory;orthogonal design;constraint theory;evolution strategy;evolutionary algorithm;constrained optimization problem;constraint optimization evolutionary computation	Good Nodes Set(GNS) is a concept in number theory. To overcome the deficiency of orthogonal design to handle constrained optimization problems(COPs), this paper presents a method that incorporate GNS principle to enhance the crossover operator of the evolution strategy (ES) can make the resulting evolutionary algorithm more robust and statically sound. In order to gain the rapid and stable rate of converging to the feasible region, traditional crossover operator is split into two steps. GNS initialization methods is applied to ensure the initial population span evenly in relatively large search space and reliably locate the good points for further exploration in subsequent iterations. The proposed method achieves the same sound results just as the orthogonal method does, but its precision is not confined by the dimension of the space. The simplex selected and diversity mechanism similar to Carlos's SMES is used to enrich the exploration and exploitation abilities of the approach proposed. Experiment results on a set of benchmark problems show the efficiency of our methods.	angular defect;benchmark (computing);constrained optimization;evolution strategy;evolutionary algorithm;feasible region;iteration;mathematical optimization	Chixin Xiao;Zixing Cai;Yong Wang	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424571	mathematical optimization;constrained optimization;combinatorics;number theory;principle of orthogonal design;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;evolution strategy;rate of convergence;algorithm;evolutionary computation;set theory	AI	26.767684633616728	-2.4170338438146697	125848
b459451b0d0758c3e1649c76e6a66f245cfea8b8	a timed-based approach for genetic algorithm: theory and applications	genetic algorithm;population;random search;time to live;premature convergence;genetic algorithms;time unit;generator	In this paper, a new algorithm called TGA is introduced which defines the concept of time more naturally for the first time. A parameter called TimeToLive is considered for each chromosome, which is a time duration in which it could participate in the process of the algorithm. This will lead to keeping the dynamism of algorithm in addition to maintaining its convergence sufficiently and stably. Thus, the TGA guarantees not to result in premature convergence or stagnation providing necessary convergence to achieve optimal answer. Moreover, the mutation operator is used more meaningfully in the TGA. Mutation probability has direct relation with parent similarity. This kind of mutation will decrease ineffective mating percent which does not make any improvement in offspring individuals and also it is more natural. Simulation results show that one run of the TGA is enough to reach the optimum answer and the TGA outperforms the standard genetic algorithm.	genetic algorithm	Amir Mehrafsa;Alireza Sokhandan;Ghader Karimian	2011	IEICE Transactions		genetic algorithm;information processing;information theory;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;algorithm	SE	26.126032793232163	-7.757967387563227	126038
f162db2ebd21476e20ae61b7cb1dfc2b07132e6f	improving the efficiency of psovina for protein-ligand docking by two-stage local search	drugs;convergence;proteins;optimization;search problems;algorithm design and analysis	Protein-ligand docking programs are valuable tools in the modern drug discovery process for predicting the complex structure of a small molecule ligand and the target protein. Often, the configurational search algorithm in the docking tool consists of global search and local search. The former is to explore widely for promising regions in the search space and the latter is to optimize a candidate solution to a local optimum. However, accurate local search methods such as gradient-based Newton methods are very costly. In this investigation, we present a new approach to enhance the time efficiency of a docking program by introducing a two-stage local search method. Given a candidate solution, a rough local search is performed in the first stage to determine the potentiality of the solution. Only if the solution is promising, the second stage with a full local search will be performed. Our method has been realized in the PSOVina docking program and tested on two data sets. The experimental results show that two-stage local search achieves almost 2x speedup to conventional one-stage method, it also enhances the prediction performance of the docking method in terms of increased success rate and RMSD.	docking (molecular);gradient;local optimum;local search (optimization);newton;newton's method;protein data bank;protein–ligand docking;search algorithm;speedup	Hio Kuan Tai;Hang Lin;Shirley Weng In Siu	2016	2016 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2016.7743869	beam search;algorithm design;mathematical optimization;convergence;computer science;bioinformatics;local search;machine learning	AI	29.86903605961501	-7.913599208389878	126070
8649333ae7b6d824040562e2a861bef02aea9c6f	multiscale quantum harmonic oscillator algorithm for multimodal optimization		This paper presents a variant of multiscale quantum harmonic oscillator algorithm for multimodal optimization named MQHOA-MMO. MQHOA-MMO has only two main iterative processes: quantum harmonic oscillator process and multiscale process. In the two iterations, MQHOA-MMO only does one thing: sampling according to the wave function at different scales. A set of benchmark test functions including some challenging functions are used to test the performance of MQHOA-MMO. Experimental results demonstrate good performance of MQHOA-MMO in solving multimodal function optimization problems. For the 12 test functions, all of the global peaks can be found without being trapped in a local optimum, and MQHOA-MMO converges within 10 iterations.	algorithm;benchmark (computing);conflict (psychology);distribution (mathematics);evolutionary multimodal optimization;experiment;global optimization;iteration;local optimum;mathematical optimization;multi-function printer;multimodal interaction;name;oscillator device component;primulina sp. 2 moeller mmo 07-1164;quantum harmonic oscillator;sampling (signal processing);test case	Peng Wang;Kun Cheng;Yan Huang;Bo Li;XingGui Ye;Xiuhong Chen	2018		10.1155/2018/8430175	local optimum;genetic algorithm;sampling (statistics);computer science;algorithm;particle swarm optimization;quantum harmonic oscillator;optimization problem	EDA	28.103822047804872	-4.099515225377947	126095
8145d69ec948990dcb8d2b975fd297e3b6b0e443	hybrid co-evolutionary particle swarm optimization and noising metaheuristics for the delay constrained least cost path problem	shortest path;noising metaheuristics;delay constrained least cost;encoding decoding;constrained shortest path;particle swarm optimizer;optimal path;particle swarm optimization;delay constrained least cost path;hybrid algorithm;shortest path problem;lagrangian relaxation	"""This paper presents a co-evolutionary particle swarm optimization (PSO) algorithm, hybridized with noising metaheuristics, for solving the delay constrained least cost (DCLC) path problem, i.e., shortest-path problem with a delay constraint on the total """"cost"""" of the optimal path. The proposed algorithm uses the principle of Lagrange relaxation based aggregated cost. It essentially consists of two concurrent PSOs for solving the resulting minimization-maximization problem. The main PSO is designed as a hybrid PSO-noising metaheuristics algorithm for efficient global search to solve the minimization part of the DCLC-Lagrangian relaxation by finding multiple shortest paths between a source-destination pair. The auxiliary/second PSO is a co-evolutionary PSO to obtain the optimal Lagrangian multiplier for solving the maximization part of the Lagrangian relaxation problem. For the main PSO, a novel heuristics-based path encoding/decoding scheme has been devised for representation of network paths as particles. The simulation results on several networks with random topologies illustrate the efficiency of the proposed hybrid algorithm for the constrained shortest path computation problems."""	mathematical optimization;metaheuristic;particle swarm optimization	Ammar W. Mohemmed;Nirod Chandra Sahoo;Tan Kim Geok	2010	J. Heuristics	10.1007/s10732-009-9109-3	mathematical optimization;combinatorics;constrained shortest path first;lagrangian relaxation;computer science;machine learning;yen's algorithm;mathematics;shortest path problem;k shortest path routing;shortest path faster algorithm	EDA	26.30681475037225	-0.927732796621638	126251
aa60835425d371afe39230b139f9e110d13bb161	a high performance genetic algorithm using bacterial conjugation operator (hpga)	real time;population size;optimization problem;particle swarm optimizer;simple genetic algorithm;genetic algorithm;evolutionary algorithm;high performance	In this paper an efficient evolutionary algorithm is proposed which could be applied to real-time problems such as robotics applications. The only parameter of the proposed algorithm is the “Population Size” which makes the proposed algorithm similar to parameter-less algorithms, and the only operator applied during the algorithm execution is the bacterial conjugation operator, which makes using and implementation of the proposed algorithm much easier. The procedure of the bacterial conjugation operator used in this algorithm is different from operators of the same name previously used in other evolutionary algorithms such as the pseudo bacterial genetic algorithm or the microbial genetic algorithm. For a collection of 23 benchmark functions and some other well-known optimization problems, the experimental results show that the proposed algorithm has better performance when compared to particle swarm optimization and a simple genetic algorithm.	adaptive algorithm;benchmark (computing);evolutionary algorithm;genetic algorithm;mathematical optimization;particle swarm optimization;phase-shift oscillator;real-time clock;real-time computing;real-time transcription;robotics;system global area	Amir Mehrafsa;Alireza Sokhandan;Ghader Karimian	2013	Genetic Programming and Evolvable Machines	10.1007/s10710-013-9185-x	optimization problem;mathematical optimization;population size;meta-optimization;genetic algorithm;hybrid algorithm;cultural algorithm;computer science;artificial intelligence;genetic operator;machine learning;evolutionary algorithm;bees algorithm;fsa-red algorithm;imperialist competitive algorithm;dinic's algorithm;freivalds' algorithm;algorithmics;nondeterministic algorithm;algorithm;difference-map algorithm;output-sensitive algorithm;population-based incremental learning	AI	26.395882360192196	-1.259056915625297	126303
0985e1248493af32134a3a584b12645ff1bdc560	comparing global and local mutations on bit strings	evolutionary computation;randomized local search;polynomial time;analysis;evolutionary algorithm;local search;mutation;fitness function;evolutionary computing	Evolutionary algorithms operating on bit strings usually employ a global mutation where each bit is flipped independently with some mutation probability. Most often the mutation probability is set fixed in a way that on average exactly one bit is flipped in a mutation. A seemingly very similar concept is a local one realized by an operator that flips exactly one bit chosen uniformly at random.  Most known results indicate that the global approach leads to run-times at least as good as the local approach. The draw-back is that the global approach is much harder to analyze. It would therefore be highly useful to derive general principles of when and how results for the local operator extend to the global ones.  In this paper, we show that there is little hope for such general principles, even under very favorable conditions. We show that there is a fitness function such that the local operator from each initial search point finds the optimum in small polynomial time, whereas the global operator for almost all initial search points needs a weakly exponential time.	evolutionary algorithm;fitness function;heuristic (computer science);like button;local optimum;local search (optimization);polynomial;randomized algorithm;recursive least squares filter;search algorithm;time complexity	Benjamin Doerr;Thomas Jansen;Christiane Neumann	2008		10.1145/1389095.1389274	mutation;time complexity;mathematical optimization;mutation;computer science;artificial intelligence;local search;machine learning;analysis;mathematics;fitness function;algorithm;evolutionary computation	Theory	28.116958429350465	-0.2680810730218381	126357
1d82d7ce2967c7d46b132f872c79fedca296300a	swarming along the evolutionary branches sheds light on genome rearrangement scenarios	ant colony optimization;genome rearrangement;large scale;evolutionary branching;exact algorithm	A genome rearrangement scenario describes a series of chromosome fusion, fission, and translocation operations that suffice to rewrite one genome into another. Exact algorithmic methods for this important problem focus on providing one solution, while the set of distance-wise equivalent scenarios is very large. Moreover, no criteria for filtering for biologically plausible scenarios is currently proposed. We present an original metaheuristic method that uses Ant Colony Optimization to randomly explore the space of optimal and suboptimal rearrangement scenarios. It improves on the state of the art both by permitting large-scale enumeration of optimal scenarios, and by labeling each with metrics that can be used for post-processing filtering based on biological constraints.	ant colony optimization algorithms;hybrid genome assembly;metaheuristic;randomness;rewrite (programming);singlet fission;video post-processing	Nikolay Vyahhi;Adrien Goëffon;Macha Nikolski;David James Sherman	2009		10.1145/1569901.1569935	mathematical optimization;ant colony optimization algorithms;computer science;bioinformatics	Comp.	28.369298295195634	-0.012325501425732908	126533
92365e51c766c415acda8e11d2b4901d60e0b85d	multi-robot task allocation based on the modified particle swarm optimization algorithm	robocup 2d soccer robot system multirobot task allocation modified particle swarm optimization algorithm utility values matrix robotic utility value linear decrease mechanism inertia weight adjustment operator adjustment sequence;robocup 2d soccer robot system;resource management robots algorithm design and analysis particle swarm optimization convergence optimization genetic algorithms;convergence;utility;inertia weight;particle swarm optimisation multi robot systems;multi robot task allocation;resource manager;resource management;utility values matrix;multi robot system;modified particle swarm optimization;adjustment operator;robotic utility value;multirobot task allocation;particle swarm optimizer;particle swarm optimization;soccer robot;robots;multi robot systems;linear decrease mechanism;genetic algorithm;genetic algorithms;optimization;particle swarm optimization algorithm;particle swarm optimisation;algorithm design;algorithm design and analysis;modified particle swarm optimization algorithm;soccer robot particle swarm optimization algorithm multi robot system task allocation utility;adjustment sequence;task allocation;basic particle swarm optimization	Task allocation is one of the research focuses of multi-robot system. On the base of presenting the utility values matrix of robots relative to tasks and analyzing the characteristics of multi-robot task allocation, we build the multi-robot task allocation model based on robotic utility value. In order to prevent the basic particle swarm optimization (PSO) algorithm from converging on local optimum, this paper proposes a modified particle swarm optimization (MPSO) algorithm by introducing the linear decrease mechanism of inertia weight and the concept of adjustment operator and adjustment sequence. With the evolution of velocity in the MPSO algorithm, particle not only studies from the historical optimum individual of itself and population, but also studies from the other stochastic individuals with some probability. Finally, the MPSO algorithm is used to solve the task allocation problem of RoboCup 2D soccer robot system, the efficiency of this modified algorithm is proved through simulation results.	algorithm;continuous optimization;discrete optimization;global optimization;integer programming;linear programming;local optimum;mathematical optimization;optimization problem;particle swarm optimization;phase-shift oscillator;rate of convergence;robot;simulation;software release life cycle;velocity (software development)	Jianping Chen;Yimin Yang;Yunbiao Wu	2011	2011 Seventh International Conference on Natural Computation	10.1109/ICNC.2011.6022303	mathematical optimization;multi-swarm optimization;simulation;engineering;artificial intelligence	Robotics	30.25928105537197	-3.6116240430435598	126639
1cf56d71c0054097815846ea0cf86faa4a687a94	an analytical approach to global optimization	computer experiment;analytical method;analytical methods;global optimization;combinatorial optimization;branch and bound;computer algebra	Global optimization problems with a few variables and constraints arise in numerous applications but are seldom solved exactly. Most often only a local optimum is found, or if a global optimum is detected no proof is provided that it is one. We study here the extent to which such global optimization problems can he solved exactly using analytical methods. To this effect, we propose a series of tests, similar to those of combinatorial optimization, organized in a branch-and-bound framework. The first complete solution of two difficult test problems illustrates the efficiency of the resulting algorithm. Computational experience with the program BAGOP, which uses the computer algebra system MACSYMA, is reported on. Many test problems from the compendiums of Hock and Schittkowski and others sources have been solved.	algorithm;branch and bound;combinatorial optimization;computation;computer algebra system;global optimization;local optimum;macsyma;mathematical optimization	Pierre Hansen;Brigitte Jaumard;Shi-Hui Lu	1991	Math. Program.	10.1007/BF01582889	discrete optimization;optimization problem;mathematical optimization;multi-swarm optimization;combinatorics;test functions for optimization;computer experiment;combinatorial optimization;computer science;analytical technique;mathematics;continuous optimization;l-reduction;branch and bound;metaheuristic;global optimization	ML	28.24447934288423	1.940665507400728	127343
e3ada0acc3bdfe6da4a71d1e09426d53b9bc77bc	a study of control parameters affecting online performance of genetic algorithms for function optimization	function optimization		genetic algorithm;mathematical optimization;program optimization	J. David Schaffer;Rich Caruana;Larry J. Eshelman;Rajarshi Das	1989			quality control and genetic algorithms;multi-swarm optimization;test functions for optimization;meta-optimization;metaheuristic	AI	25.215631116125778	-4.809256362933462	127530
3d70f129829fb0a2ab6a22bc04f65f3cfe54b3d1	a hybrid approach based on tissue p systems and artificial bee colony for iir system identification		This paper presents a hybrid approach for infinite impulse response (IIR) system identification, called ABC-PS, that combines artificial bee colony (ABC) and tissue P systems. A tissue P system with fully connected structure of cells has been considered as its computing framework. A modification of ABC was developed as evolution rules for objects according to fully connected structure and communication mechanism. With the control of the object’s evolution-communication mechanism, the tissue P system designed can effectively and efficiently identify the optimal filter coefficients for an IIR system. The performance of ABC-PS was compared with artificial bee colony and several other evolutionary algorithms. Simulation results show that ABC-PS is superior or comparable to the other algorithms for the employed examples and can be efficiently used for IIR system identification.	artificial bee colony algorithm;benchmark (computing);coefficient;computer graphics;embedded system;evolutionary algorithm;experiment;extensibility;filter design;fitness function;graphics processing unit;infinite impulse response;loss function;mathematical optimization;optimization problem;p system;parallel computing;simulation;supercomputer;system identification	Hong Peng;Jun Wang	2016	Neural Computing and Applications	10.1007/s00521-016-2201-3	artificial intelligence	AI	26.922233207349656	-1.4883417786943387	127649
0b90a3c41a6113781c5ed6b3436544eee84acb59	global minimum structure searches via particle swarm optimization	particle swarm optimizer;particle swarm optimization;global minimum search	Novel implementation of the evolutionary approach known as particle swarm optimization (PSO) capable of finding the global minimum of the potential energy surface of atomic assemblies is reported. This is the first time the PSO technique has been used to perform global optimization of minimum structure search for chemical systems. Significant improvements have been introduced to the original PSO algorithm to increase its efficiency and reliability and adapt it to chemical systems. The developed software has successfully found the lowest-energy structures of the LJ(26) Lennard-Jones cluster, anionic silicon hydride Si(2)H(5) (-), and triply hydrated hydroxide ion OH(-) (H(2)O)(3). It requires relatively small population sizes and demonstrates fast convergence. Efficiency of PSO has been compared with simulated annealing, and the gradient embedded genetic algorithm.		Seth T. Call;Dmitry Yu. Zubarev;Alexander I. Boldyrev	2007	Journal of computational chemistry	10.1002/jcc.20621	mathematical optimization;multi-swarm optimization;particle swarm optimization;physics;metaheuristic	Comp.	30.210726691889427	-8.150613963751493	127736
4d79d48d4293e01be2e87f6fc5c1ca0f836655ad	a two-stage quantum-behaved particle swarm optimization with skipping search rule and weight to solve continuous optimization problem		Quantum-behaved particle swarm optimization (QPSO) is a recently developed heuristic method by particle swarm optimization (PSO) algorithm based on quantum mechanics, which outperforms the search ability of original PSO. But as many other PSOs, it is easy to fall into the local optima for the complex optimization problems. Therefore, we propose a two-stage quantum-behaved particle swarm optimization with a skipping search rule and a mean attractor with weight. The first stage uses quantum mechanism, and the second stage uses the particle swarm evolution method. It is shown that the improved QPSO has better performance, because of discarding the worst particles and enhancing the diversity of the population. The proposed algorithm (called ‘TSQPSO’) is tested on several benchmark functions and some real-world optimization problems and then compared with the PSO, SFLA, RQPSO and WQPSO and many other heuristic algorithms. The experiment results show that our algorithm has better performance than others.	algorithm;benchmark (computing);continuous optimization;heuristic;local optimum;mathematical optimization;optimization problem;particle swarm optimization;quantum mechanics	Deyu Tang;Shoubin Dong;Xianfa Cai;Jie Zhao	2015	Neural Computing and Applications	10.1007/s00521-015-2014-9	mathematical optimization;multi-swarm optimization;meta-optimization;derivative-free optimization;artificial intelligence;machine learning;mathematics;imperialist competitive algorithm;particle swarm optimization;metaheuristic	AI	26.82935903195994	-3.9885399505787413	127990
39ae2f1d8ab8e8ab3286a06153f63552cea4093d	massively parallel genetic algorithms.	parallel genetic algorithm	The genetic algorithm is an iterative random search technique for nonlinear or combi-natorial problems. In this contribution, rst the development from the classical genetic algorithm (GA) via the parallel genetic algorithm (PGA) to the massively parallel genetic algorithm (MPGA) is described. Then experimental results with an implementation of the MPGA on the array processor MasPar MP-1 are displayed, which exemplify robustness and adaptive behavior of the algorithm. The observed properties of the MPGA are nally combined for an improved method of mapping load onto a massively parallel hardware.	adaptive behavior;array processing;central processing unit;computation;computer;data parallelism;exemplification;genetic algorithm;iterative method;loss function;maspar;nonlinear system;optimization problem;partial evaluation;population;random search;vector processor	Markus Schwehm	1994		10.1016/B978-0-444-81784-6.50064-6	parallel computing;computer science;theoretical computer science;distributed computing;parallel algorithm;population-based incremental learning	Robotics	27.074677974386187	0.07849193468824922	128011
a6756d1f02bf615c3c845a54bf172be8473dcabf	automated wire antennas design using dynamic dominance evolutionary algorithm	constrained optimization;evolutionary computation;dynamic dominance evolutionary algorithm;wire antenna;benchmark problem;multi objective problems antenna design constrained optimization;antenna design;satisfiability;microwave antenna arrays;wire algorithm design and analysis evolutionary computation computer science geology testing helical antennas frequency design optimization nasa;wire;heuristic algorithms;success rate;genetic algorithms;global optimization;multiobjective optimization problem;wire antennas;computer science;evolutionary algorithm;multi objective optimization problem;multi objective problems;st5 antenna design;st5 antenna design wire antenna dynamic dominance evolutionary algorithm multiobjective optimization problem;wire antennas evolutionary computation	Antenna design problems are complex multi-objective optimization problems. It is difficult to solve such problems using traditional methods. This paper creates a new model to solve antenna problems. In this new model, antennas' requirements are reflected not only in problems' constraints, but also in their objectives. It means feasible solutions are solutions that satisfy antennas' requirements. So if we find out a feasible solution, antenna design problems would have been solved. After that, with the evolution going on, feasible solution would be optimized, and global optimal solution would be found out. This paper uses a new algorithm, dynamic dominances evolutionary algorithm (DDEA), to solve antenna problems. DDEA has been tested by 22 benchmark problems. DDEA can consistently find the global optimum of all test problems with success rate 100%, while any other algorithm can't achieve such high success rate. This paper takes lower earth orbit ST5 antenna designed problem as a real world test problem. The experimental result shows: using this new model and DDEA, ST5 antenna design problem can be solved effectively. In addition the simulation result shows our evolved antennas are quite competitive with NASA's.	benchmark (computing);evolutionary algorithm;global optimization;mathematical optimization;multi-objective optimization;optimization problem;requirement;simulation;smart antenna	Yang Yang;Sanyou Zeng;Haoqiu Long;Zu Yan;Danpin Yu;Lishan Kang	2009	2009 NASA/ESA Conference on Adaptive Hardware and Systems	10.1109/AHS.2009.7	mathematical optimization;constrained optimization;simulation;genetic algorithm;computer science;machine learning;evolutionary algorithm;global optimization;evolutionary computation;satisfiability	EDA	25.047450742857777	-1.646427797842356	128181
fb67845ac52995d5fa746919a6a27c6b6b74bb53	process visualization to solve the travelling salesman problem	traveling salesman problem;approximate algorithm;distance measure;tsp;travelling salesman problem;interactive visualization;combinatorial optimization problem;visualization;interactive animation;genetic algorithm;optimization;genetic parameter	The Traveling Salesman Problem (TSP) is one of the well studied combinatorial optimization problems. Multiple approximation algorithms are derived for solving the distance measure TSP that determines the shortest route through a given set of points or cities. In this paper, we visualize the process of genetic parameters and explain the solution converges. It deals with interactive animation to understand the progress view of the solutions obtained. A Java-based FX and interactive visualization (TSP-ViZ) is alo developed using Java FX and optimization results are discussed.	approximation algorithm;combinatorial optimization;genetic algorithm;interactive visualization;java;javafx;mathematical optimization;travelling salesman problem;whole earth 'lectronic link	J. Joshua Thomas;Choy Chee Ken	2010		10.1145/1865841.1865858	optimization problem;extremal optimization;2-opt;mathematical optimization;christofides algorithm;cross-entropy method;interactive visualization;combinatorial optimization;computer science;lin–kernighan heuristic;machine learning;travelling salesman problem;algorithm;3-opt;bottleneck traveling salesman problem;quadratic assignment problem	Visualization	24.6218045311906	-0.4109938043597779	128621
e007a07ef7999ecd2bc2738f969e51e428dfbe2d	adaptive ∈-ranking on mnk-landscapes	multiobjecttve evolutionary algorithms;pareto optimisation;evolutionary computation;mnk landscapes;probability density function;random sampling;population size;randomized sampling;data mining;objective evolutionary optimization algorithms;ieee;nsga ii;adaptive method;evolutionary optimization;multiobjecttve evolutionary algorithms adaptive isin ranking mnk landscapes objective evolutionary optimization algorithms randomized sampling nsga ii;pareto optimisation evolutionary computation;pareto optimization sampling methods;adaptive isin ranking	This work proposes an adaptive ∈-ranking method to enhance Pareto based selection, aiming to develop effective many objective evolutionary optimization algorithm. ∈-ranking fine grains ranking of solutions after they have been ranked by Pareto dominance, using a randomized sampling procedure combined with ∈-dominance to favir a good distribution of the samples. In essence, sampled solutions keep their initial rank and solutions located within the virtually expanded dominance reions of the sampled solutions are demoted to an inferior rank. The parameter ∈ that determines the expanded regions of dominance of the sampled solutions is adapted to each generation so that the number of highest ranked solutions is kept close to a desired number expressed as a fraction of the population size. We enhanced NSGA-II with the proposed method and verify its performance on MNK-Landscapes. Experimented results show that the adaptive method works effectively and that convergence and diversity of the solutions found can improve remarkably on MNK-Landscapes with 3 ≤ M ≤ 10 objectives.	mathematical optimization;multi-objective optimization;pareto efficiency;randomized algorithm;sampling (signal processing)	Hernán E. Aguirre;Kiyoshi Tanaka	2009	2009 IEEE Symposium on Computational Intelligence in Multi-Criteria Decision-Making(MCDM)	10.1109/MCDM.2009.4938835	sampling;mathematical optimization;probability density function;population size;computer science;machine learning;mathematics;statistics;evolutionary computation	Embedded	26.446220999907773	-6.255113975008377	128656
8cc4802ad8a7b0224db9899df77d0e567d2ae7be	an improved particle swarm optimizer with momentum	second order;oscillations;learning algorithm;particle swarm optimisation backpropagation difference equations neural nets;neural nets;difference equation;backpropagation;particle swarm optimizer;difference equations;second order difference equation particle swarm optimization momentum back propagation learning algorithm neural networks lowpass filter;particle swarm optimization algorithm;particle swarm optimization neural networks difference equations acceleration filters robustness birds marine animals educational institutions cultural differences;particle swarm optimisation;back propagation;neural network	In this paper, an improved particle swarm optimization algorithm with momentum (mPSO) is proposed based on inspiration from the back propagation (BP) learning algorithm with momentum in neural networks. The momentum acts as a lowpass filter to relieve excessive oscillation and also extends the PSO velocity updating equation to a second-order difference equation. Experimental results are shown to verify its superiority both in robustness and efficiency.	algorithm;artificial neural network;backpropagation;benchmark (computing);experiment;iteration;low-pass filter;mathematical optimization;maxima and minima;particle swarm optimization;phase-shift oscillator;rate of convergence;recurrence relation;software propagation;the superficial;velocity (software development)	Tao Xiang;Jun Wang;Xiaofeng Liao	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424903	mathematical optimization;multi-swarm optimization;computer science;artificial intelligence;backpropagation;machine learning;mathematics;particle swarm optimization;artificial neural network	Robotics	29.490910612403628	-5.6383122164926975	129097
fb0aab34a89e6269c1b317b3e0b26f5ac6a4c0e2	functional dependency and degeneracy: detailed analysis of the gauge system	conference publication;functional dependency;grammatical evolution;genetic algorithm;genetic algorithms	This paper explores the mapping process of the GAuGE system, a recently introduced position-independent genetic algorithm, that encodes both the positions and the values of individuals at the genotypic level. A mathematical formalisation of its mapping process is presented, and is used to characterise the functional dependency feature of the system. An analysis of the effect of degeneracy in this functional dependency is then performed, and a mathematical theorem is given, showing that the introduction of degeneracy reduces the position specification bias of individuals. Experimental results are given, that backup these findings.		Miguel Nicolau;Anne Auger;Conor Ryan	2003		10.1007/978-3-540-24621-3_2	computer science;artificial intelligence;operations research;algorithm	SE	24.953986182863307	-9.189293942764783	129127
dc793f2c311d0ad637240786f6e194997f9100e8	a harmony search algorithm comparison with genetic algorithms		We describe in this paper a Harmony Search (HS) Algorithm and their areas of application, variants and comparison with other existing algorithms. HS is a metaheuristic music inspired algorithm used to solve a wide range of optimization problems applied to different areas, which has been very successful as indicated by the literature. A comparison with genetic algorithms was performed to evaluate the advantages of HS.	genetic algorithm;harmony search;search algorithm	Cinthia Peraza;Fevrier Valdez;Oscar Castillo	2015		10.1007/978-3-319-10960-2_7	quality control and genetic algorithms;cultural algorithm;best-first search;search algorithm	AI	25.146569439022965	-4.256216995814669	129360
2d626a609f65d6bc95d509828f91d5a4a99c5d32	the hopfield neural network applied to the quadratic assignment problem	assignment problem;hopfield model;modele hopfield;afectacion cuadratica;modelo hopfield;hopfield neural network;communication cost;quadratic assignment problem;reseau neuronal;red neuronal;neural network;quadratic assignment;affectation quadratique	The Hopfield neural network is proposed as a method for solving the Quadratic Assignment Problem. The study involves determining the relevant parameter constraints, and provides a comparison of the performance of the Hopfield model with that of a conventional approach.	artificial neural network;hopfield network;quadratic assignment problem	Carlos Bousoño-Calzón;M. R. W. Manning	1995	Neural Computing & Applications	10.1007/BF01421958	mathematical optimization;computer science;artificial intelligence;machine learning;assignment problem;hopfield network;artificial neural network;quadratic assignment problem	AI	29.6816847296927	4.044224578023492	129373
6c13456f16c159cebc2039fbb92b5545c04534d1	maintaining population diversity by maintaining family structures	diversity;family structure;selection;tree structure;evolutionary strategy;fitness function	The selection event algorithm introduced an interesting method of creating offspring from parents in a multi-generational manner with a period of fitness neutrality followed by an intense selection event. This algorithm did not have a focus on maintaining diversity in the population, so it had all of the same pitfalls as other algorithms lacking such a focus. However, due to the novel multi-generational growth structure a natural family tree is created in the population, allowing for an equally natural diversity maintenance to be implemented which does not require any artificial diversity constraints to be placed on the fitness function. Instead, diversity is maintained (and encouraged) in the population through the growth dynamics of each family.	algorithm;family tree;fitness function	John Nicholson;Mark White	2008		10.1145/1389095.1389198	selection;computer science;artificial intelligence;machine learning;tree structure;evolution strategy;fitness function	ML	25.497599591295213	-8.786829897143798	129433
12e8f668f85ead2ae835fb5292758e2ad7c16a5f	a hybrid tabu search based clustering algorithm	cluster algorithm;genetics;sum of squares;k means algorithm;tabu search;local search	The clustering problem under the criterion of minimum sum of squares clustering is a nonconvex program which possesses many locally optimal values, resulting that its solution often falls into these traps. In this paper, a hybrid tabu search based clustering algorithm called KT-Clustering is developed to explore the proper clustering of data sets. Based on the framework of tabu search, KT-Clustering gathers the optimization property of tabu search and the local search capability of K-means algorithm together. Moreover, mutation operation is adopted to establish the neighborhood of KT-Clustering. Its superiority over K-means algorithm, a genetic clustering algorithm and another tabu search based clustering algorithm is extensively demonstrated for experimental data sets.	algorithm;cluster analysis;tabu search	Yongguo Liu;Yan Liu;Libin Wang;Kefei Chen	2005		10.1007/11552451_25	beam search;correlation clustering;constrained clustering;mathematical optimization;determining the number of clusters in a data set;combinatorics;data stream clustering;k-medians clustering;tabu search;flame clustering;hill climbing;canopy clustering algorithm;machine learning;cure data clustering algorithm;mathematics;best-first search;cluster analysis;guided local search;binary search algorithm;search algorithm;clustering high-dimensional data	AI	28.34091483901113	-5.995963038973917	129598
e18e4fb765da0568930c98df83fe45fcce7b13c6	an improved genetic algorithm for network nodes clustering	vivaldi;network nodes clustering;improved genetic algorithm;k medoids	Nodes clustering is a useful way to construct an effective network infrastructure for large-scale distributed network applications. In this paper, network nodes are clustered by the K-medoids clustering algorithm according to their coordinates. The coordinates of network nodes are gained by Vivaldi which is a simple and lightweight network coordinates system. But K-medoids algorithm is sensitive to the initial cluster centers and easy to get stuck at the local optimal solutions. In order to improve the performance of K-medoids algorithm, KCIGA(K-medoids clustering based on improved genetic algorithm) is presented in this paper. The improved genetic algorithm that uses self-adaptive genetic operator, dynamically adjusting the crossover rate and mutation rate, can avoid premature and slow convergence phenomenon in SGA(standard genetic algorithm). Experimental results show KCIGA has good reliability and expansibility, and it is effective for clustering network nodes.	genetic algorithm	Yong Li;Zhenwei Yu	2011		10.1007/978-3-642-25255-6_51	correlation clustering;mathematical optimization;data stream clustering;k-medians clustering;canopy clustering algorithm;machine learning;hierarchical network model;cure data clustering algorithm;data mining;mathematics;cluster analysis;community structure;hierarchical clustering of networks;population-based incremental learning	AI	29.407466546940256	-3.015137095105239	129643
11741fc644ad933f08c5fcd50d9c7a9afdc2545e	reducing premature convergence problem in genetic algorithm: application on travel salesman problem		Genetic algorithm (GA) is based on Darwin’s natural selection theory and is used extensively in combinatorial problems as these problems are demanding in terms of computational time. GA shows very good results in terms of both computational time and quality of solution for combinatorial problems as GAs have some traits that make them one of the best evolutionary algorithms (EAs). The use of both mutation and crossover operators make them, relative to other EAs, highly immune to be trapped in a local optima and thus less vulnerable to premature convergence problem. Traditionally, the solution for premature convergence problem is to maintain a certain degree of diversity of the GA’s population without affecting the convergence process itself. In this paper, this concept has been practiced where Frequency Crossover strategy (FC) along with nine different mutation strategies have been proposed and applied to travel salesman problem (TSP) to reduce the effect of premature convergence problem. Three sets of benchmark data have been used to test the effectiveness of this GA. The results showed that both the nine mutation types and the FC are essential for the proposed GA to perform well. While this GA has been applied on TSP in this paper, it is also believed that it is applicable on any problem that has an Order-Based chromosome representation.	benchmark (computing);computation;darwin;evolutionary algorithm;genetic algorithm;local optimum;mutation testing;premature convergence;software release life cycle;time complexity;travelling salesman problem	Saleem Zeyad Ramadan	2013	Computer and Information Science	10.5539/cis.v6n1p47	mathematical optimization;artificial intelligence;machine learning;mathematics;algorithm;premature convergence	AI	25.43909184797007	-3.0514666845455034	129717
9573219757086dea814c32d9f17e8c682b523887	multi-strategy ensemble particle swarm optimization for dynamic optimization	differential mutation;dynamic environment;real world application;particle swarm optimizer;gaussian local search;particle swarm optimization;catching up;particle swarm optimization algorithm;optimal algorithm;multi strategy ensemble;local search;dynamic optimization problem;dynamic optimization	Optimization in dynamic environments is important in real-world applications, which requires the optimization algorithms to be able to find and track the changing optimum efficiently over time. Among various algorithms for dynamic optimization, particle swarm optimization algorithms (PSOs) are attracting more and more attentions in recent years, due to their ability of keeping good balance between convergence and diversity maintenance. To tackle the challenges of dynamic optimization, several strategies have been proposed to enhance the performance of PSO, and have gained success on various dynamic optimization problems. But there still exist some issues in dynamic optimization which need to be studied carefully, i.e. the robustness of the algorithm to problems of various dynamic features. In this paper, a new multistrategy ensemble particle swarm optimization (MEPSO) for dynamic optimization is proposed. In MEPSO, all particles are divided into two parts, denoted as part I and part II, respectively. Two new strategies, Gaussian local search and differential mutation, are introduced into these two parts, respectively. Experimental analyses reveal that the mechanisms used in part I can enhance the convergence ability of the algorithm, while mechanisms used in part II can extend the searching area of the particle population to avoid being trapped into the local optimum, and can enhance the ability of catching up with the changing optimum in dynamic environments. The whole algorithm has few parameters that need to be tuned, and all of them are not sensitive to problems. We compared MEPSO with other PSOs, including MQSO, PHPSO and Standard PSO with re-initialization, on moving peaks Benchmark and dynamic Rastrigin function. The experimental results show that MEPSO has pretty good performance on almost all testing problems adopted in this paper, and outperforms other algorithms when the dynamic environment is unimodal and changes severely, or has a great number of local optima as dynamic Rastrigin function does. 2008 Elsevier Inc. All rights reserved.	algorithm;benchmark (computing);dynamic programming;local optimum;local search (optimization);mathematical optimization;multimodal interaction;particle swarm optimization;program optimization;rastrigin function;requirement	Weilin Du;Bin Li	2008	Inf. Sci.	10.1016/j.ins.2008.01.020	mathematical optimization;multi-swarm optimization;simulation;test functions for optimization;meta-optimization;computer science;derivative-free optimization;local search;machine learning;rastrigin function;particle swarm optimization;random optimization;metaheuristic	AI	26.701552612541597	-3.9818083872451884	129899
77c15b6b1c2b0b202719b48ad18e97e0ad36ed34	a novel hybrid multi-objective population migration algorithm	multi objective optimization;good point set;co evolutionary;pareto dominated;mutation;population migration algorithm	This paper presents a multi-objective co-evolutionary population migration algorithm based on Good Point Set (GPSMCPMA) for multi-objective optimization problems (MOP) in view of the characteristics of MOPs. The algorithm introduces the theory of good point set (GPS) and dynamic mutation operator (DMO) and adopts the entire population co-evolutionary migration, based on the concept of Pareto nondomination and global best experience and guidance. The performance of the algorithm is tested through standard multi-objective functions. The experimental results show that the proposed algorithm performs much better in the convergence, diversity and solution distribution than SPEA2, NSGA-II, MOPSO and MOMASEA. It is a fast and robust multi-objective evolutionary algorithm (MOEA) and is applicable to other MOPs.	algorithm	Aijia Ouyang;Keqin Li;Xiongwei Fei;Xu Zhou;Mingxing Duan	2015	IJPRAI	10.1142/S0218001415590016	mutation;mathematical optimization;simulation;artificial intelligence;multi-objective optimization;mathematics;population-based incremental learning	AI	26.283536378410865	-4.344973779762853	130051
00fd92fbc196942d706ea2844f973d96c3888731	hybrid optimization using direct, ga, and sqp for global exploration	quadratic programming;sequential quadratic programming hybrid optimization global exploration local search broad search global landscape dividing rectangles genetic algorithms;search problems genetic algorithms quadratic programming;optimization methods design optimization algorithm design and analysis genetic algorithms quadratic programming simulated annealing constraint optimization convergence;optimal method;sequential quadratic programming;genetic algorithm;genetic algorithms;search problems;numerical experiment;optimal algorithm;hybrid algorithm	This paper presents a new hybrid optimization approach, which combines multiple optimization algorithms. To develop an efficient hybrid optimization algorithm, it is necessary to determine how the optimization process is performed. This paper focuses on the balance between local and broad searches, and multiple optimization methods are controlled to derive both the optimum point and the information of the landscape. By this approach, we can describe the global landscape after derivation of optimization. To achieve the proposed optimization strategy, three distinguished optimization algorithms are introduced: DIRECT (Dividing RECTangles), GAs (Genetic Algorithms), and SQP (Sequential Quadratic Programming). To integrate these three algorithms, each algorithm, especially DIRECT, was modified and developed. The performance of the proposed hybrid algorithm was examined through numerical experiments. From these experiments, not only the optimum point but also the information of the landscape was determined. The information of the landscape verified the reliability of optimization results.	experiment;genetic algorithm;hybrid algorithm;mathematical optimization;numerical analysis;sequential quadratic programming;software release life cycle	Satoru Hiwa;Tomoyuki Hiroyasu;Mitsunori Miki	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424679	quality control and genetic algorithms;probabilistic-based design optimization;mathematical optimization;multi-swarm optimization;test functions for optimization;meta-optimization;genetic algorithm;estimation of distribution algorithm;combinatorial optimization;computer science;derivative-free optimization;multi-objective optimization;machine learning;quadratically constrained quadratic program;mathematics;sequential quadratic programming;active set method;continuous optimization;vector optimization;quadratic programming;algorithm;random optimization;metaheuristic;global optimization;quadratic assignment problem	EDA	26.014442832085468	-1.787767862481365	130079
d6bfed0bfc30d8267e6b4dd84d20a6089fdde8be	local search based on genetic algorithms	search space;genetic algorithm;high performance;local search	Genetic Algorithms have been seen as search procedures that can quickly locate high performance regions of vast and complex search spaces, but they are not well suited for fine-tuning solutions, which are very close to optimal ones. However, genetic algorithms may be specifically designed to provide an effective local search as well. In fact, several genetic algorithm models have recently been presented with this aim. In this chapter, we call these algorithms Local Genetic Algorithms. In this chapter, first, we review different instances of local genetic algorithms presented in the literature. Then, we focus on a recent proposal, the Binary-coded Local Genetic Algorithm. It is a Steady-state Genetic Algorithm that applies a crowding replacement method in order to keep, in the population, groups of chromosomes with high quality in different regions of the search space. In addition, it maintains an external solution (leader chromosome) that is crossed over with individuals of the population.These individuals are selected by using Positive AssortativeMating, which ensures that these individuals are very similar to the leader chromosome. The main objective is to orientate the search in the nearest regions to the leader chromosome. We show an empirical study comparing a Multi-start Local Search based on the binary-coded local genetic algorithmwith other instances of thismetaheuristic based on local search procedures presented in the literature. The results show that, for a wide range of problems, the multi-start local search based on the binary-coded local genetic algorithm consistently outperforms multi-start local search instances based on the other local search approaches.	crowding;display resolution;genetic algorithm;local search (constraint satisfaction);local search (optimization);population	Carlos García-Martínez;Manuel Lozano	2008		10.1007/978-3-540-72960-0_10	quality control and genetic algorithms;beam search;cultural algorithm;tabu search;local search;genetic representation;iterated local search;incremental heuristic search;iterative deepening depth-first search;best-first search;combinatorial search;fringe search;guided local search;search algorithm	AI	25.50886073637886	-3.1548112309346155	130314
4f40667e315b8444bd97c71d912b8d8c1906f05d	an improved ant colony algorithm based on dynamic weight of pheromone updating	heuristic algorithms cities and towns educational institutions computers convergence algorithm design and analysis polymers;travelling salesman problems ant colony optimisation;tsp;basic ant colony algorithm;tsp basic ant colony algorithm dynamic weight pheromone updating;iteration best solutions improved ant colony algorithm global pheromone updating local pheromone updating dynamic adaptive weight traveling salesman problems tsp;pheromone updating;dynamic weight	To effectively overcome the defects of local and global pheromone updating for the basic Ant Colony Algorithm, this paper has proposed a new improved Ant Colony Algorithm based on the dynamic adaptive weight in the pheromone updating strategy. The proposed algorithm can update pheromone dynamically and adaptively according to the pheromone density and the quality of iteration-best solutions. By the simulation of several typical Traveling Salesman Problems(TSP), the proposed algorithm is clearly better than several other typically Ant Colony Algorithms in the solution quality and convergence speed. The simulation reflects its effectiveness and feasibility to some extent.	algorithm;ant colony optimization algorithms;iteration;simulation;travelling salesman problem	Guiqing Liu;Dengxu He	2013	2013 Ninth International Conference on Natural Computation (ICNC)	10.1109/ICNC.2013.6818027	mathematical optimization;ant colony optimization algorithms;computer science;artificial intelligence;machine learning	EDA	28.159502323726805	-3.6882528971441833	130425
a6f45e8f47f9b1c2310f1d353b815fc5370c420e	an extension of hill-climbing with learning applied to a symbolic regression of boolean functions	boolean functions;symbolic regression;hill climbing with learning	In this paper we discuss an application of simple stochastic optimization algorithm called <i>the hill climbing with learning</i> (HCwL) for a study of symbolic regression. A fundamental role in this approach plays the so-called probability vector <i>w</i> = (<i>w</i><sub>1</sub>, <i>w</i><sub>2</sub>, ..., <i>w</i><sub>n</sub>) where an entry 0 ≤ <i>w</i>+<sub>i</sub> ≤1 specifies a probability that an <i>i</i>-th component of solution (e. g. a bit in binary representation) has a binary 1 value. An integral part of HCwL is a mutation process, where from a current solution <i>x<sub>old</sub></i> is created a new solution <i>x<sub>new</sub></i> by a stochastic mutation process. The used probability vector <i>w</i> (considered here as a special type of collective memory) serves as an auxiliary device for a construction of new mutated solution <i>x<sub>new</sub></i>; in particular, it predicts promising directions during its creation that are specified by the previous history of adaptation process.	algorithm;binary number;floor and ceiling functions;hill climbing;mathematical optimization;stochastic optimization;symbolic regression	Vladimir Kvasnicka;Ladislav Clementis;Jiri Pospichal	2013		10.1145/2464576.2466803	mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;boolean function;algorithm	ML	27.734296549272862	-8.14273121719345	130598
5d2e9d02abca59a33a2fa1a9edbd7c2868fed0d3	cuckoo search algorithm with lévy flights for global-support parametric surface approximation in reverse engineering		This paper concerns several important topics of the Symmetry journal, namely, computer-aided design, computational geometry, computer graphics, visualization, and pattern recognition. We also take advantage of the symmetric structure of the tensor-product surfaces, where the parametric variables u and v play a symmetric role in shape reconstruction. In this paper we address the general problem of global-support parametric surface approximation from clouds of data points for reverse engineering applications. Given a set of measured data points, the approximation is formulated as a nonlinear continuous least-squares optimization problem. Then, a recent metaheuristics called Cuckoo Search Algorithm (CSA) is applied to compute all relevant free variables of this minimization problem (namely, the data parameters and the surface poles). The method includes the iterative generation of new solutions by using the Lévy flights to promote the diversity of solutions and prevent stagnation. A critical advantage of this method is its simplicity: the CSA requires only two parameters, many fewer than any other metaheuristic approach, so the parameter tuning becomes a very easy task. The method is also simple to understand and easy to implement. Our approach has been applied to a benchmark of three illustrative sets of noisy data points corresponding to surfaces exhibiting several challenging features. Our experimental results show that the method performs very well even for the cases of noisy and unorganized data points. Therefore, the method can be directly used for real-world applications for reverse engineering without further pre/post-processing. Comparative work with the most classical mathematical techniques for this problem as well as a recent modification of the CSA called Improved CSA (ICSA) is also reported. Two nonparametric statistical tests show that our method outperforms the classical mathematical techniques and provides equivalent results to ICSA for all instances in our benchmark.	approximation;benchmark (computing);computational geometry;computer graphics;computer-aided design;cuckoo search;data point;free variables and bound variables;international computer security association;iterative method;least squares;lévy flight;mathematical optimization;metaheuristic;nonlinear system;optimization problem;pattern recognition;reverse engineering;search algorithm;signal-to-noise ratio;video post-processing	Andrés Iglesias;Akemi Gálvez;Patricia Suárez;Mikio Shinya;Norimasa Yoshida;César Otero Gonzalez;Cristina Manchado del Val;Valentin Gomez-Jauregui	2018	Symmetry	10.3390/sym10030058	parametric surface;data point;computational geometry;nonlinear system;metaheuristic;parametric statistics;algorithm;nonparametric statistics;mathematics;optimization problem	Vision	32.1562322415031	-9.354797191427416	130826
c0450546397cc26a359b42404e83774b0cd2b359	distributed adaptive control: beyond single-instant, discrete control variables		In extensive form noncooperative game theory, at each instant t, each agent i sets its state Xi independently of the other agents, by sampling an associated distribution, qi{xi). The coupling between the agents arises in the joint evolution of those distributions. Distributed control problems can be cast the same way. In those problems the system designer sets aspects of the joint evolution of the distributions to try to optimize the goal for the overall system. Now information theory tells us what the separate qi of the agents are most likely to be if the system were to have a particular expected value of the objective function G{x\,X2, ...)• So one can view the job of the system designer as speeding an iterative process. Each step of that process starts with a specified value of E{G), and the convergence of the qi to the most likely set of distributions consistent with that value. After this the target value for Eq{G) is lowered, and then the process repeats. Previous work has elaborated many schemes for implementing this process when the underlying variables xi all have a finite number of possible values and G does not extend to multiple instants in time. That work also is based on a fixed mapping from agents to control devices, so that the the statistical independence of the agents' moves means independence of the device states. This paper also extends that work to relax all of these restrictions. This extends the applicability of that work to include continuous spaces and Reinforcement Learning. This paper also elaborates how some of that earlier work can be viewed as a first-principles justification of evolution-based search algorithms.	distributed control system;game theory;information theory;iteration;loss function;optimization problem;regular language description for xml;reinforcement learning;sampling (signal processing);search algorithm;systems design	David H. Wolpert;Stefan Bieniawski	2004		10.1007/3-540-32370-8_3	independence (probability theory);information theory;adaptive control;mathematics;expected value;reinforcement learning;extensive-form game;iterative and incremental development;mathematical optimization;product distribution	AI	37.25907954788723	3.7523550366717795	130868
700e0e3e0bd86d381622848c00b7b13868b0ad7f	a study on an efficiency of new exponential evolutionary programming	programming convergence optimization sociology statistics algorithm design and analysis standards;evolutionary computation;fitness mutation valution of individual strategy parameter;search problems evolutionary computation;termination conditions exponential evolutionary programming optimization problems optimum point searching strategy parameter searching;search problems	In this paper, we investigate performances of Evolutionary Programming (EP) for optimization problems. An individual of EPs has searching optimum points and strategy parameters. The procedures of EP are consists of an initialization, a mutation, an evaluation of the individual and a selection. These processes are repeated while termination conditions are not satisfied. Experimental results show an efficiency of various types of EP.	evolutionary programming;expectation propagation;mathematical optimization;mutation (genetic algorithm);performance;time complexity	Kohei Mukaihara;Hirotaka Inoue	2013	2013 IEEE 7th International Conference on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS)	10.1109/IDAACS.2013.6662693	evolutionary programming;mathematical optimization;genetic algorithm;interactive evolutionary computation;human-based evolutionary computation;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;evolutionary computation	Robotics	27.21757937922385	-5.964657705585026	131231
1b19e51889094989ba682c3f1e81277c7fc9ce74	search for common minima in joint optimization of multiple cost functions		We present a novel optimization method, named the Combined Optimization Method (COM), for the joint optimization of two or more cost functions. Unlike the conventional joint optimization schemes, which try to find minima in a weighted sum of cost functions, the COM explores search space for common minima shared by all the cost functions. Given a set of multiple cost functions that have qualitatively different distributions of local minima with each other, the proposed method finds the common minima with a high success rate without the help of any metaheuristics. As a demonstration, we apply the COM to the crystal structure prediction in materials science. By introducing the concept of data assimilation, i.e., adopting the theoretical potential energy of the crystal and the crystallinity, which characterizes the agreement with the theoretical and experimental X-ray diffraction patterns, as cost functions, we show that the correct crystal structures of Si diamond, low quartz, and low cristobalite can be predicted with significantly higher success rates than the previous methods.	crystal structure prediction;data assimilation;mathematical optimization;maxima and minima;metaheuristic;monte carlo method;program optimization;weight function	Daiki Adachi;Naoto Tsujimoto;Ryosuke Akashi;Synge Todo;Shinji Tsuneyuki	2018	CoRR		mathematical optimization;metaheuristic;crystallinity;crystal structure prediction;maxima and minima;cristobalite;crystal structure;potential energy;data assimilation;mathematics	ML	30.07714719924588	-7.820343342607343	131291
0f46d2a4a28e234ccab89421717c59ab029b3f64	application of wolf group hierarchy optimization algorithm to fault section estimation in power systems	field test data wolf group hierarchy optimization algorithm wgho algorithm fault section estimation power systems wolf society bionic intelligence;power system parameter estimation biocybernetics fault diagnosis group theory optimisation power system faults;circuit breakers circuit faults estimation power systems linear programming optimization relays;wolf group hierarchy optimization algorithm fault section estimation bionic intelligence	This paper proposes a wolf group hierarchy optimization (WGHO) algorithm to solve the fault section estimation problem in power systems. The method mimics the substitution behavior observed in the wolf society, in which only the wolf owing the strongest environment adaptability is qualified to lead the group of wolves. By applying this bionic intelligence in the problem considered, it provides a systematic way of finding the solution. Through the field test data, this method has been compared with published techniques.	algorithm;energy systems language;ibm power systems;mathematical optimization;substitution (logic);test data	Shyh-Jier Huang;Xian-Zong Liu;Wei-Fu Su;Shih-Chieh Tsai;Chao-Ming Liao	2014	2014 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2014.6865347	control engineering;electronic engineering;engineering;artificial intelligence	EDA	34.642693875986055	-4.794510287123867	131375
19a3588e537fb2e4b16c4c0bc1b54cb39ea4474e	improving the performance of weighted lagrange-multiplier methods for nonlinear constrained optimization	nonlinear integer programming;constrained optimization;oscillations;qmf filter bank design;filter bank;nonlinear programming;lagrange multiplier method;multiplierless filter bank design;multiplierers filter bank design;lagrange multiplier;operations research;satisfiability;dynamic control;artificial intelligent;adaptive weights;objective function;gradient descent;lagrangian method;constrained optimization problem;nonlinear constrained optimization	Nonlinear constrained optimization problems in discrete and continuous spaces are an important class of problems studied extensively in arti®cial intelligence and operations research. These problems can be solved by a Lagrange-multiplier method in continuous space and by an extended discrete Lagrange-multiplier method in discrete space. When constraints are satis®ed, these methods rely on gradient descents in the objective space to ®nd high-quality solutions. On the other hand, when constraints are violated, these methods rely on gradient ascents in the Lagrange-multiplier space in order to increase the penalties on unsatis®ed constraints and to force the constraints into satisfaction. The balance between gradient descents and gradient ascents depends on the relative weights between the objective function and the constraints, which indirectly control the convergence speed and solution quality of the Lagrangian method. To improve convergence speed without degrading solution quality, we propose an algorithm to dynamically control the relative weights between the objective and the constraints. Starting from an initial weight, the algorithm automatically adjusts the weights based on the behavior of the search progress. With this strategy, we are able to eliminate Information Sciences 124 (2000) 241±272 www.elsevier.com/locate/ins * Corresponding author. Fax: +1-573 882-8318. E-mail addresses: wah@manip.crhc.uiuc.edu (B.W. Wah), wangtao@manip.crhc.uiuc.edu (T. Wang), yshang@risc1.ecn.missouri.eduhttp://manip.crhc.uiuc.edu (Y. Shang), zhewu@manip. crhc.uiuc.edu (Z. Wu). 0020-0255/00/$ see front matter Ó 2000 Elsevier Science Inc. All rights reserved. PII: S 0 0 2 0 0 2 5 5 ( 9 9 ) 0 0 0 8 1 X divergence, reduce oscillation, and speed up convergence. We show improved convergence behavior of our proposed algorithm on both nonlinear continuous and discrete problems. Ó 2000 Elsevier Science Inc. All rights reserved.	algorithm;constrained optimization;fax;gradient descent;lagrange multiplier;lamina emergent mechanism;like button;mathematical optimization;nonlinear programming;nonlinear system;operations research;optimization problem;personally identifiable information;quadrature mirror filter;requirement;sequential quadratic programming;speedup;vergence	Benjamin W. Wah;Tao Wang;Yi Shang;Zhe Wu	2000	Inf. Sci.	10.1016/S0020-0255(99)00081-X	mathematical optimization;constrained optimization;nonlinear programming;control theory;mathematics;lagrange multiplier	ML	29.406901524332152	-0.9311340997638171	132267
87cdce7ba5340cc212a0b284cdf0ea67cb3a6bc6	core problems in knapsack algorithms	expected hardness;applied to knapsack problem;analysis of algorithms;integer;knapsack problem;cluster analysis;statistics;algorithms;programming	Since Balas and Zemel in the 1980s introduced the so-called core problem as an efficient tool for solving the Knapsack Problem, all the most successful algorithms have applied this concept. Balas and Zemel proved that if the weights in the core are uniformly distributed then there is a high probability for finding an optimal solution in the core. Items outside the core may be fathomed because of reduction rules. This paper demonstrates that generally it is not reasonable to assume a uniform distribution of the weights in the core, and it is experimentally shown that the heuristic proposed by Balas and Zemel does not find as good solutions as expected. Also, other algorithms that solve some kind of core problem may be stuck by difficult cores. This behavior has apparently not been noticed before because of unsufficient testing. Capacities leading to difficult problems are identified for several categories of instance types, and it is demonstrated that the hitherto applied test instances are easier than the average. As a consequence we propose a series of new randomly generated test instances and show how recent algorithms behave when applied to these problems.	algorithm	David Pisinger	1999	Operations Research	10.1287/opre.47.4.570	integer;continuous knapsack problem;programming;mathematical optimization;combinatorics;computer science;analysis of algorithms;mathematics;cluster analysis;knapsack problem;algorithm	Theory	25.634246728945737	4.001088115974814	132270
5798165c9883651e79b7e58d1ca1d6b4033d6520	an informed operator approach to tackle diversity constraints in evolutionary search	optimal solution;diversity constraints;elitism;informed operator approach;population diversity;genetic operator;state space methods;evolutionary computation;search problems genetic algorithms;genetic algorithms information technology space technology benchmark testing evolutionary computation state space methods encoding;search space;information technology;local convergence;evolutionary search;elitism informed operator approach diversity constraints evolutionary search population diversity convergence characteristics benchmark test functions genetic algorithm ga implementation;benchmark test functions;ga implementation;genetic algorithm;genetic algorithms;informed genetic operation search space;search problems;space technology;information operations;encoding;benchmark testing;convergence characteristics	As the evolutionary search progresses, it is important to avoid reaching a state where the genetic operators can no longer produce superior offspring, prematurely. This is likely to occur when the search space reaches a homogeneous or near-homogeneous configuration converging to a local optimal solution. Maintaining a certain degree of population diversity is widely believed to help curb this problem. The proposed technique presented here, uses informed genetic operations to reach promising, but un/under-explored areas of the search space, while discouraging local convergence. Elitism is used at a different level aiming at convergence. The proposed technique's improved performance in terms solution precision and convergence characteristics is observed on a number of benchmark test functions with a genetic algorithm (GA) implementation.	benchmark (computing);distribution (mathematics);emoticon;evolutionary computation;exploit (computer security);genetic algorithm;genetic operator;local convergence;multimodal interaction;population;requirement;search algorithm;software release life cycle	Maumita Bhattacharya	2004	International Conference on Information Technology: Coding and Computing, 2004. Proceedings. ITCC 2004.	10.1109/ITCC.2004.1286656	mathematical optimization;machine learning;mathematics;algorithm	Robotics	27.038511445009878	-5.978054606503375	132364
9268b3ce97ea2854853734d9477a2187eb8dc0f6	hybrid algorithm based on particle swarm optimization and artificial fish swarm algorithm	artificial fish swarm algorithm;function optimization;particle swarm optimization;hybrid algorithm	A hybrid algorithm based on particle swarm optimization(PSO) and artificial fish swarm algorithm(AFSA) is proposed. It combines the advantages of PSO and AFSA. The improved AFSA is introduced into PSO at the iteration. The following behavior and swarming behavior of AFSA are performed on two sub-swarms simultaneously. The proposed algorithm increases the variety of the population and improves the accuracy of the solution.	hybrid algorithm;particle swarm optimization	Jingqing Jiang;Yuling Bo;Chuyi Song;Lanying Bao	2012		10.1007/978-3-642-31346-2_68	mathematical optimization;multi-swarm optimization;hybrid algorithm;swarm intelligence;computer science;firefly algorithm;machine learning;particle swarm optimization	Robotics	26.74801124594662	-4.478781076792306	132561
9c805611a1d334db6e020e915b6f511df6a249e8	qdds: a novel quantum swarm algorithm inspired by a double dirac delta potential		In this paper a novel Quantum Double Delta Swarm (QDDS) algorithm modeled after the mechanism of convergence to the center of attractive potential field generated within a single well in a double Dirac delta well setup has been put forward and the preliminaries discussed. Theoretical foundations and experimental illustrations have been incorporated to provide a first basis for further development, specifically in refinement of solutions and applicability to problems in high dimensional spaces. Simulations are carried out over varying dimensionality on four benchmark functions, viz. Rosenbrock, Rastrigrin, Griewank and Sphere as well as the multidimensional Finite Impulse Response (FIR) Filter design problem with different population sizes. Test results illustrate the algorithm yields superior results to some related reports in the literature while reinforcing the need of substantial future work to deliver near-optimal results consistently, especially if dimensionality scales up. Keywords— Quantum Particle Swarm; Swarm Intelligence; Double Delta Potential Well; Quantum Mechanics; Optimization	algorithm;benchmark (computing);computer simulation;delta potential;dirac delta function;filter design;finite impulse response;program optimization;quantum mechanics;refinement (computing);swarm intelligence;viz: the computer game	Saptarshi Sengupta;Sanchita Basak;Richard Alan Peters	2018	CoRR		computer science;swarm behaviour;curse of dimensionality;algorithm;finite impulse response;population;particle swarm optimization;convergence (routing);filter design;dirac delta function	AI	28.865249152305346	-3.7059763425465926	133124
aef039c56b1b694cd4e10dbea350974bd6363487	an optimization design method of integrated radar and jammer signal modulated by bi-phase sequences of chaos	optimization design method bi phase sequences of chaos integrated signal chaos genetic algorithm;chaos genetic algorithm;jamming radar optimization encoding spatiotemporal phenomena genetic algorithms;jamming;optimization design method;integrated signal;genetic algorithms;bi phase sequences of chaos;radar signal processing;chaos generators;jammer signal optimization design method integrated radar signal biphase sequence generation chaos modulated signal chaos genetic algorithm spatiotemporal chaos system adaptive choice strategy;radar signal processing chaos generators genetic algorithms jamming	An optimization design method of the integrated signal in modern radar and jammer integration system is presented based on improved chaos genetic algorithm. The bi-phase sequences are generated based on the spatiotemporal chaos system and the optimization model of bi-phase sequences of chaos is constituted based on the design principles of the integrated signal. Then, the improved chaos genetic algorithm based on adaptive choice strategy is applied to solve the model and the calculation steps are presented in detail. Finally, the idiographic examples are analyzed and the simulation results have shown that the improved chaos genetic algorithm is valid and applicable for the optimization design of integrated radar and jammer signal and meanwhile the acquired bi-phase encoding signal of chaos possesses fine resolution for power and jamming characteristics.	genetic algorithm;international computer games association;mathematical optimization;modulation;program optimization;radar;radio jamming;simulation;synthetic genetic array	Guoxi Han;Jun He;Jianqing Qi	2012	2012 Eighth International Conference on Computational Intelligence and Security	10.1109/CIS.2012.18	genetic algorithm;computer science;artificial intelligence;machine learning	EDA	32.02465932762319	-4.329991791596381	133220
fa7e0b94e76aea8c70433b6a59d16a2d2e021e51	root growth model: a novel approach to numerical function optimization and simulation of plant root system	geologic models;root growth;simulation;higher dimensional;soils;期刊论文;algorithms;optimization;numerical function optimization;computer simulation	This paper presents a general optimization model gleaned ideas from root growth behaviours in the soil. The purpose of the study is to investigate a novel biologically inspired methodology for complex system modelling and computation, particularly for optimization of higherdimensional numerical function. For this study, a mathematical framework and architecture are designed to model root growth patterns of plant. Under this architecture, the interactions between the soil and root growth are investigated. A novel approach called “root growth algorithm” (RGA) is derived in the framework and simulation studies are undertaken to evaluate this algorithm. The simulation results show that the proposed model can reflect the root growth behaviours of plant in the soil and the numerical results also demonstrate RGA is a powerful search and optimization technique for higher-dimensional numerical function optimization.	algorithm;combinatorial optimization;complex system;computation;image;interaction;mathematical optimization;numerical analysis;phase-shift oscillator;population dynamics;simulation;software release life cycle	Hao Zhang;Yunlong Zhu;Hanning Chen	2014	Soft Comput.	10.1007/s00500-013-1073-z	computer simulation;simulation;computer science;soil water	EDA	28.658200786410568	-8.631696966696127	133509
29daf167aa53132cda658df632584e4c52f8abcb	iterated function system based adaptive differential evolution algorithm	global optimization algorithm iterated function system adaptive differential evolution algorithm benchmark functions;optimisation;differential evolution;iterated function system;convergence;adaptive differential evolution algorithm;evolution biology;adaptive systems;chromium;benchmark functions;global optimization algorithm;chromium evolution biology convergence benchmark testing noise proposals adaptive systems;proposals;benchmark testing;noise	In this paper, we propose a new adaptive Differential Evolution algorithm, in which a simple mechanism based on Iterated Function System is applied to the control parameters F and CR. The performance is reported on a set of benchmark functions, which shows that our algorithm is better than, or at least comparable to the standard DE algorithm and the other adaptive versions of DE algorithm.	algorithm;benchmark (computing);differential evolution;iterated function system	Ya-Liang Li;Fei Ding;Yu-Xuan Wang	2008	2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)	10.1109/CEC.2008.4630962	differential evolution;mathematical optimization;chromium;convergence;computer science;noise;artificial intelligence;adaptive system;machine learning;mathematics;iterated function system;algorithm	Vision	27.497557439604527	-5.670030291979374	133526
f4d2df50d42fa871e670a02b7289b356c58da85b	evolutionary algorithms for finding short addition chains: going the distance		The problem of finding the shortest addition chain for a given exponent is of great relevance in cryptography, but is also very difficult to solve since it is an NP-hard problem. In this paper, we propose a genetic algorithm with a novel representation of solutions and new crossover and mutation operators to minimize the length of the addition chains corresponding to a given exponent. We also develop a repair strategy that significantly enhances the performance of our approach. The results are compared with respect to those generated by other metaheuristics for instances of moderate size, but we also investigate values up to 2 − 3. For those instances, we were unable to find any results produced by other metaheuristics for comparison, and three additional strategies were adopted in this case to serve as benchmarks. Our results indicate that the proposed approach is a very promising alternative to deal with this problem.	as-easy-as;benchmark (computing);cartesian closed category;cryptography;evolutionary algorithm;genetic algorithm;genetic programming;graph (discrete mathematics);heuristic (computer science);metaheuristic;np-hardness;reference work;relevance;software release life cycle	Stjepan Picek;Carlos A. Coello Coello;Domagoj Jakobovic;Nele Mentens	2016		10.1007/978-3-319-30698-8_9	mathematical optimization;combinatorics;machine learning	AI	26.049518770149408	2.985630779315219	133733
15630ab140f21f58a02a12b8e0e7c5c0faaa0713	a mixed-coding genetic algorithm and its application on gear reducer optimization		Because of the nature of discrete and continuous variables are widely existed in many practice engineering, traditional genetic algorithm can not solve this kind optimization problem, so a new mixed coding scheme of genetic algorithm is proposed, which is call as mixed-coding genetic algorithm. In this mixed-coding genetic algorithm, integer and float coding are adopted to encode discrete and continuous variables respectively. The length of mixed coding is equal to number of design variables, and the scheme will raise the convergence speed. Surrogate reproduction is adopted to select good individual to mating pool; two-point crossover and bit mutation are used for integer coding; heuristic crossover and non-uniform mutation are used for float coding. New population is generated by competing between offspring and parent population. Based on the above research, the algorithm is applied to optimize helical and cylindrical gear reducer. By examples calculating and comparing with different methods, the feasible and effective of the proposed algorithm are verified, and it is able to solve the problem with different types of variables, especially adaptive to the problems with discrete and continuous variables.	genetic algorithm;program optimization	Qing-ke Yuan;Shi-jie Li;Ling-lian Jiang;Wen-yan Tang	2009		10.1007/978-3-642-03664-4_82	coding (social sciences);mathematical optimization;genetic algorithm;artificial intelligence;machine learning;crossover;reducer;computer science;heuristic;mating pool;population;optimization problem	EDA	26.523360288226364	-2.73968021140014	133791
a9c4a76921f841ac080235fac8a67644f8a6fcc2	using evolutionary algorithms incorporating the augmented lagrangian penalty function to solve discrete and continuous constrained non-linear optimal control problems	constrained optimization;non linear optimization;control problem;evolutionary algorithm;augmented lagrangian;penalty function	Constrained Optimal Control Problems are notoriously difficult to solve accurately. Preliminary investigations show that Augmented Lagrangian Penalty functions can be combined with an Evolutionary Algorithm to solve these functional optimisation problems. Augmented Lagrangian Penalty functions are able to overcome the weaknesses of using absolute and quadratic penalty functions within the framework of an Evolutionary Algorithm.	augmented lagrangian method;evolutionary algorithm;optimal control;penalty method	Stephen Smith	2001		10.1007/3-540-46033-0_24	mathematical optimization;combinatorics;mathematical analysis;augmented lagrangian method;lagrangian relaxation;penalty method;mathematics	AI	29.65418326765404	-0.659802541325665	133833
93e8c1870ba2e09638cdcc29291585625362eeee	a concurrent-hybrid evolutionary algorithms with multi-child differential evolution and guotao algorithm based on cultural algorithm framework	differential evolution;hybrid evolutionary algorithm;guotao algorithm based on variable searching subspace;differential evolutionary algorithm;multi child differential evolutionary algorithm;concurrent hybrid evolutionary algorithm;evolutionary algorithm;numerical experiment;cultural algorithm	This paper proposes a multi-child differential evolutionary algorithm (MCDE), and forms a concurrent-hybrid evolutionary algorithm by integrating the MCDE algorithm and Guotao algorithm based on variable searching subspace(VSSGT) into the culture algorithm framework. Numerical experiment results indicate that the performance of the proposed algorithm is better than that of MCDE, Differential Evolution algorithm(DE) and VSSGT, and better than that of the DE with double trial vectors based on Boltzmann mechanism.	cultural algorithm;differential evolution;evolutionary algorithm	Xia Li;Kunqi Liu;Lixiao Ma;Huanzhe Li	2010		10.1007/978-3-642-16493-4_13	evolutionary programming;mathematical optimization;interactive evolutionary computation;cultural algorithm;bioinformatics;machine learning;evolutionary algorithm;mathematics;difference-map algorithm;population-based incremental learning	Vision	26.0158227514046	-4.589204142122579	133843
37241951a620713d14b6c76ec0c2a411fd36ac19	an improved bean optimization algorithm for solving tsp	swarm intelligence;discrete optimization;tsp;population migration;bean optimization algorithm;priori information	Inspired by the transmission of beans in nature, a novel swarm intelligence algorithm-Bean Optimization Algorithm (BOA) is proposed. In the area of continuous optimization problems solving, BOA has shown a good performance. In this paper, an improved BOA is presented for solving TSP, a typical discrete optimization problem. Two novel evolution mechanisms named population migration and priori information cross-sharing are proposed to improve the performance of BOA. The improved BOA algorithm maintains the basic idea of BOA and overcomes the shortcoming that BOA with continuous distribution function can not be applied to solve the discrete optimization problems. The experimental results of TSP show that the improved BOA algorithm is suit for solving discrete optimization problems with high efficiency.	algorithm;combinatorial optimization	Xiaoming Zhang;Kang Jiang;Hailei Wang;Wenbo Li;Bing-Yu Sun	2012		10.1007/978-3-642-30976-2_31	teaspoon;discrete optimization;mathematical optimization;swarm intelligence;computer science;artificial intelligence;machine learning;mathematics;algorithm	Logic	26.362054449429426	-4.174649839452537	133921
d0906633c5bac653b27f103134882b98c99faa1b	a population-based approach for hard global optimization problems based on dissimilarity measures	optimisation;metodo monte carlo;methode essai;particle cluster;energie minimale;optimizacion;stochastic method;dissimilarity measure;heuristic method;methode monte carlo;optimum global;metodo heuristico;molecular conformation problems;multistart;enjambre particula;metodo deformacion;global optimum;busca local;large scale;mathematical programming;structure moleculaire;monte carlo method;robustesse;amas particule;deformation method;basin hopping;methode stochastique;algorithme evolutionniste;large scale global optimization;robustness;global optimization;algoritmo evolucionista;optimization;methode deformation;methode heuristique;evolutionary algorithm;test method;energia minima;escala grande;efficiency measurement;estructura molecular;programmation mathematique;local search;optimo global;programacion matematica;recherche locale;population based approaches;robustez;echelle grande;minimum energy;metodo ensayo;molecular structure;metodo estocastico	When dealing with extremely hard global optimization problems, i.e. problems with a large number of variables and a huge number of local optima, heuristic procedures are the only possible choice. In this situation, lacking any possibility of guaranteeing global optimality for most problem instances, it is quite difficult to establish rules for discriminating among different algorithms. We think that in order to judge the quality of new global optimization methods, different criteria might be adopted like, e.g.: 1. efficiency – measured in terms of the computational effort necessary to obtain the putative global optimum 2. robustness – measured in terms of “percentage of successes”, i.e. of the number of times the algorithm, re-started with different seeds or starting points, is able to end up at the putative global optimum 3. discovery capability – measured in terms of the possibility that an algorithm discovers, for the first time, a putative optimum for a given problem which is better than the best known up to now. Of course the third criterion cannot be considered as a compulsory one, as it might be the case that, for a given problem, the best known putative global optimum is indeed the global one, so that no algorithm will ever be able to discover a better one. In this paper we present a computational framework based on a population-based stochastic method in which different candidate A. Grosso · M. Locatelli Dipartimento di Informatica, Università di Torino, Torino, Italy e-mail: grosso@di.unito.it M. Locatelli e-mail: locatelli@di.unito.it F. Schoen (B) Dipartimento di Sistemi e Informatica, Università di Firenze, Firenze, Italy e-mail: fabio.schoen@unifi.it	algorithm;computation;computer cluster;email;experiment;global optimization;heuristic;local optimum;mathematical optimization;maxima and minima;open research;overhead (computing);population	Andrea Grosso;Marco Locatelli;Fabio Schoen	2007	Math. Program.	10.1007/s10107-006-0006-3	mathematical optimization;molecule;local search;evolutionary algorithm;calculus;mathematics;global optimum;test method;algorithm;robustness;global optimization;monte carlo method	ML	27.253762273726043	1.995608330040345	134017
90328e7b6c8626a44ae99908bbe6ef36ed7baee6	evolutionary programming techniques for constrained optimization problems	constrained optimization;global solution;nonlinear programming;optimal method;exact solution;evolutionary programming;lagrange multiplier;indexing terms;satisfiability;objective function;augmented lagrangian method;violated constraints evolutionary programming methods ep methods nonlinear constrained optimization problems hybrid ep heavily constrained optimization problems computational efficiency two phase ep tpep augmented lagrangian method lagrange multipliers;computational complexity;constraint theory;genetic algorithms;computational efficiency;constrained optimization problem;genetic programming constraint optimization lagrangian functions optimization methods evolutionary computation linear programming robustness computational efficiency computational modeling guidelines;computational complexity genetic algorithms constraint theory nonlinear programming	Two evolutionary programming (EP) methods are proposed for handling nonlinear constrained optimization problems. The first, a hybrid EP, is useful when addressing heavily constrained optimization problems both in terms of computational efficiency and solution accuracy. But this method offers an exact solution only if both the mathematical form of the objective function to be minimized/maximized and its gradient are known. The second method, a two-phase EP (TPEP), removes these restrictions. The first phase uses the standard EP, while an EP formulation of the augmented Lagrangian method is employed in the second phase. Through the use of Lagrange multipliers and by gradually placing emphasis on violated constraints in the objective function whenever the best solution does not fulfill the constraints, the trial solutions are driven to the optimal point where all constraints are satisfied. Simulations indicate that the TPEP achieves an exact global solution without gradient information, with less computation time than the other optimization methods studied here, for general constrained optimization problems.	augmented lagrangian method;computation;computer simulation;constrained optimization;evolutionary programming;expectation propagation;gradient descent;lagrange multiplier;mathematical optimization;nonlinear system;optimization problem;time complexity;two-phase locking	Jong-Hwan Kim;Hyun Myung	1997	IEEE Trans. Evolutionary Computation	10.1109/4235.687880	evolutionary programming;mathematical optimization;constrained optimization;combinatorics;genetic algorithm;index term;augmented lagrangian method;nonlinear programming;computer science;mathematics;mathematical economics;lagrange multiplier;computational complexity theory;satisfiability	AI	29.552195221334966	-0.7331845895860788	134186
7b0ab1b911d082ae3550c200a520a986a61e2cf6	linear antenna array synthesis with modified invasive weed optimisation algorithm	metaheuristics;side lobe suppression;invasive weeds optimisation;null control;antenna array	Linear antenna array design is one of the most important electromagnetic optimisation problems of current interest. This article describes the application of modified version of a recently developed metaheuristic algorithm, known as the invasive weed optimisation (IWO), to optimise the spacing between the elements of the linear array to produce a radiation pattern with minimum side lobe level and null placement control. IWO is a novel ecologically inspired algorithm that mimics the process of weeds colonisation and distribution and is capable of solving general multi-dimensional, linear and non-linear optimisation problems with appreciable efficiency. For this application, we modified the classical IWO by introducing a more explorative routine of changing the mutation step-size with iterations. Three design examples are presented that illustrate the use of the IWO algorithm, and the optimisation goal in each example is easily achieved. The results of the modified IWO algorithm have been shown to meet or beat the results obtained using other state-of-the-art metaheuristics like the classical IWO, genetic algorithm (GA), particle swarm optimisation (PSO), memetic algorithms (MA), and tabu search (TS) in a statistically meaningful way.	algorithm;mathematical optimization	Siddharth Pal;Aniruddha Basak;Swagatam Das	2011	IJBIC	10.1504/IJBIC.2011.041147	mathematical optimization;computer science;artificial intelligence;machine learning;antenna array;metaheuristic	EDA	31.35106760746628	-4.099604294023845	134380
fb5d1d334df36740c1b9610573671388f9634af5	cuckoo search inspired hybridization of the nelder-mead simplex algorithm applied to optimization of photovoltaic cells		A new hybridization of the Cuckoo Search (CS) is developed an pplied to optimize multicell solar systems; namely multi-junction and split spectr um cells. The new approach consists of combining the CS with the Nelder-Mead method. More precis ely, instead of using single solutions as nests for the CS, we use the concept of a simplex w hich is used in the NelderMead algorithm. This makes it possible to use the flip operati on introduces in the Nelder-Mead algorithm instead of the Levy flight which is a standard part o f the CS. In this way, the hybridized algorithm becomes more robust and less sensitive to paramet er tuning which exists in CS. The goal of our work was to optimize the performance of multi-cel l solar systems. Although the underlying problem consists of the minimization of a functi on of a relatively small number of parameters, the di fficulty comes from the fact that the evaluation of the function is complex and only a small number of evaluations is possible. In our tes t, we show that the new method has a better performance when compared to similar but more co mpex hybridizations of NelderMead algorithm using genetic algorithms or particle swarm o ptimization on standard benchmark functions. Finally, we show that the new method outperforms some standard meta-heuristics for the problem of interest.	analysis of algorithms;benchmark (computing);cuckoo search;display resolution;expectation–maximization algorithm;experiment;feasible region;genetic algorithm;heuristic (computer science);local search (optimization);lévy flight;mathematical optimization;multi-junction solar cell;nelder–mead method;no man's sky;particle swarm optimization;simplex algorithm;software release life cycle;swarm;unified model	Raka Jovanovic;Sabre Kais;Fahhad H. Alharbi	2014	CoRR	10.18576/amis/100314	mathematical optimization;artificial intelligence;mathematics;algorithm	AI	25.604282486297063	-3.816184098878868	134509
43f0a1422c967f538f040974a8e7c7733a43ea4c	scalable mean rate signal encoding analog neural network	cmos analogue integrated circuits;analogue processing circuits;analogue storage;backpropagation;encoding;feedforward neural nets;neural chips;pulse frequency modulation;signal representation;3-parity problem solution;pfm signal representation;analog uv-programmable floating gate memories;analog neural network;micropower feedforward neural network;modified backpropagation algorithm;pulse frequency modulation;scalable mean rate signal encoding;standard cmos;weight storage	A micropower feedforward neural network implementation in standard CMOS using pulse frequency modulated signal representation is presented in this paper. The implementation includes a modified backpropagation algorithm using analog UV-programmable floating gate memories for weight storage. Measurements of a 3-6-2 layered feedforward neural network implementation solving the 3-parity problem are shown	artificial neural network	Yngvar Berg;Jon-Erik Ruth;Tor Sverre Lande	1995			control engineering;electronic engineering;computer science;backpropagation;machine learning;time delay neural network;artificial neural network	ML	38.6005977848652	-2.008255814514824	134612
30733fcb3157fbe8c5c4ef54c7e3bd996c448069	a fuzzy logic approach for dynamic adaptation of parameters in galactic swarm optimization	heuristic algorithms;particle swarm optimization;clustering algorithms;optimization;algorithm design and analysis;fuzzy systems;benchmark testing	In this article we propose the use of fuzzy systems for dynamic adjustment of parameters in the galactic swarm optimization (GSO) method. This algorithm is inspired by the movement of stars, galaxies and superclusters of galaxies under the force of gravity. GSO uses various cycles of exploration and exploitation phases to achieve a trade-off between the exploration of new solutions and exploitation of existing solutions. In this paper we proposed distinct fuzzy systems for the dynamic adaptation of the c3 and c4 parameters to measure the performance of the algorithm with 17 benchmark functions with different number of dimensions. In this paper a comparison was made between different variants to prove the efficacy of the method in optimization problems.	algorithm;benchmark (computing);experiment;fuzzy control system;fuzzy logic;galaxy;mathematical optimization;metaheuristic;optimization problem;swarm	Emer Bernal;Oscar Castillo;José Soria	2016	2016 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2016.7850266	mathematical optimization;multi-swarm optimization;simulation;artificial intelligence;physics;metaheuristic	Embedded	26.223934958095303	-4.957515961762315	134730
0a65cc80ec217993619392b3c967d8e50bbf50e9	distance based parameter adaptation for differential evolution		This paper proposes a simple, yet effective, modification to scaling factor and crossover rate adaptation in Success-History based Adaptive Differential Evolution (SHADE), which can be used as a framework to all SHADE-based algorithms. The performance impact of the proposed method is shown on the CEC2015 benchmark set in 10 and 30 dimensions for both SHADE and L-SHADE (SHADE with linear decrease of population size) algorithms.	algorithm;benchmark (computing);differential evolution;image scaling;shade 3d	Adam Viktorin;Roman Senkerik;Michal Pluhacek;Tomas Kadavy;Ales Zamuda	2017	2017 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2017.8280959	population size;differential evolution;scale factor;mathematical optimization;crossover;linear programming;convergence (routing)	Embedded	25.93405280004381	-4.557321159386241	134873
83beadc67aae5e8647d6ed7b1dd28ef49e581ba9	a new real-coded genetic algorithm for implicit constrained black-box function optimization	sampling methods constraint handling genetic algorithms;constraint handling;genetic algorithms;sampling methods;evaluation values real coded genetic algorithm rcga implicit constrained black box function optimization constraint violations preference order resampling technique implicit constraint handling arex jgg;sociology statistics optimization linear programming benchmark testing algorithm design and analysis evolutionary computation	In this paper, we propose a new real-coded genetic algorithm (RCGA) for implicit constrained black-box function optimization. On implicit constrained problems, there often exist active constraints of which the optima lie on the boundaries, which makes the problem more difficult. Almost all of conventional constraint-handling techniques cannot be applied to implicit constrained black-box function optimization because we cannot get quantities of constraint violations and preference order of infeasible solutions. The resampling technique may be the only available choice to handle the implicit constraint. AREX/JGG is one of the most powerful RCGAs for non-constrained problems. However, AREX/JGG with resampling technique deteriorates on implicit constrained problems because few individuals are generated near the boundaries of active constraints and, thus, a population cannot approach the boundaries quickly. In order to find these optima, we believe that it is necessary to locate the mode of a distribution for generating new individuals nearer the boundaries. Since solutions around the optima on boundaries of active constraints may have better evaluation values, our proposed method employs the weighted mean of the best half individuals in a population as the mode of the distribution. We assess the proposed method through experiments with some benchmark problems and the results show the proposed method succeeds in finding the optimum with about 40-85% of function evaluations compared to AREX/JGG with resampling technique.	arexx;active set method;benchmark (computing);black box;experiment;genetic algorithm;mathematical optimization	Kento Uemura;Naotoshi Nakashima;Yuichi Nagata;Isao Ono	2013	2013 IEEE Congress on Evolutionary Computation	10.1109/CEC.2013.6557920	sampling;mathematical optimization;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;algorithm;statistics	AI	27.52380822151809	-6.046236227963047	135025
428b1665093f970b6b87c01d323e52faef91f606	the chc adaptive search algorithm: how to have safe search when engaging in nontraditional genetic recombination	search algorithm;genetics	This paper describes and analyzes CHC, a nontraditional genetic algorithm which combines a conservative selection strategy that always preserves the best individuals found so far with a radical (highly disruptive) recombination operator that produces offspring that are maximally different from both parents. The traditional reasons for preferring a recombination operator with a low probability of disrupting schemata may not hold when such a conservative selection strategy is used. On the contrary, certain highly disruptive crossover operators provide more effective search. Empirical evidence is provided to support these claims.	search algorithm	Larry J. Eshelman	1990		10.1016/B978-0-08-050684-5.50020-3	computer science;artificial intelligence;mathematics;genetics;algorithm;search algorithm	AI	25.81673801244383	-8.570266866731203	135059
868321c4ac5b15ccb274bb24314da71d757b3af7	the importance of being structured: a comparative study on multi stage memetic approaches	algorithm design and analysis memetics optimization benchmark testing space exploration minimization vectors;optimisation;search problems genetic algorithms;meta heuristics;conference;algorithmic design;genetic algorithms;search problems;memetic computing;powell methods multistage memetic approach memetic computing mc optimization algorithms algorithmic design basic sequential structure three stage optimal memetic exploration 3some algorithm decision space middle distance exploration search radius short distance exploration mc structure 3some structure deterministic local search rosenbrock methods	Memetic Computing (MC) is a discipline which studies optimization algorithms and sees them as structures of operators, the memes. Although the choice of memes is crucial for an effective algorithmic design, special attention should be paid also to the coordination amongst the memes. This paper presents a study on a basic sequential structure, namely Three Stage Optimal Memetic Exploration (3SOME). The 3SOME algorithm is composed of three operators (or memes) which progressively perturbs a single solution. The first meme, long distance exploration is characterized by a long search radius and is supposed to detect promising areas of the decision space. The second meme, middle distance exploration, is characterized by a moderate search radius and is supposed to focus the search in the the most promising basins of attraction. The third meme, short distance exploration, is characterized by a short search radius and had the role of performing the local optimal search in the areas detected by the first two memes. To assess the importance of the structure within MC we compare the performance of 3SOME with two modified versions of it over two complete benchmarks. In both cases, while retaining the 3SOME structure, we replace one of the three original components (short distance exploration) with an alternative deterministic local search, respectively Rosenbrock and Powell methods. Numerical results show that, regardless of the choice of the specific memes, as far as the 3SOME structure contains memes which perform long, middle, and short distance explorations a similar performance is achieved. These results remark that besides the intuitive finding that a proper choice of operators is fundamental for the algorithmic success, the structure composing them also plays a crucial role.	fitness function;local search (optimization);mathematical optimization;meme;memetics;numerical linear algebra;powell's method	Fabio Caraffini;Giovanni Iacca;Ferrante Neri;Ernesto Mininno	2012	2012 12th UK Workshop on Computational Intelligence (UKCI)	10.1109/UKCI.2012.6335768	mathematical optimization;artificial intelligence;machine learning;mathematics	Web+IR	27.272777597421424	-6.060039701756171	135074
dd2a4cc474063688200c012447672eddd97965d3	impact of crossover bias in genetic programming	root parent;genetic programming;sub tree crossover;crossover bias;crossover asymmetry	In tree-based genetic programming (GP) with sub-tree crossover, the parent contributing the root portion of the tree (the root parent) often contributes more to the semantics of the resulting child than the non-root parent. Previous research demonstrated that when the root parent had greater fitness than the non-root parent, the fitness of the child tended to be better than if the reverse were true. Here we explore the significance of that asymmetry by introducing the notion of crossover bias, where we bias the system in favor of having the more fit parent as the root parent.  In this paper we apply crossover bias to several problems. In most cases we found that crossover bias either improved performance or had no impact. We also found that the effectiveness of crossover bias is dependent on the problem, and significantly dependent on other parameter choices.  While this work focuses specifically on sub-tree crossover in tree-based GP, artificial and biological evolutionary systems often have substantial asymmetries, many of which remain understudied. This work suggests that there is value in further exploration of the impacts of these asymmetries.	crossover (genetic algorithm);evolutionary systems;genetic programming;small-bias sample space	Nicholas Freitag McPhee;M. Kirbie Dramdahl;David Donatucci	2015		10.1145/2739480.2754778	genetic programming;computer science;artificial intelligence;machine learning	HCI	25.454949883195557	-9.053747127914356	135180
e224f0feadc4247cbad23f00225628657ec5cf05	ant colony optimization based model checking extended by smell-like pheromone		Model Checking is a technique for automatically checking the model representing software or hardware about whether they satisfy the corresponding specifications. Traditionally, the model checking uses deterministic algorithms, but the deterministic algorithms have a fatal problem. They are consuming too many computer resources. In order to mitigate the problem, an approach based on the Ant Colony Optimization (ACO) was proposed. Instead of performing exhaustive checks on the entire model, the ACO based approach statistically checks a part of the model through movements of ants (ant-like software agents). Thus the ACO based approach not only suppresses resource consumption, but also guides the ants to reach the goals efficiently. The ACO based approach is known to generate shorter counter examples too. This article presents an improvement of the ACO based approach. We employ a technique that further suppresses futile movements of ants while suppressing the resource consumption by introducing a smell-like pheromone. While ACO detects the semishortest path to food by putting pheromones on the trails of ants, the smell-like pheromone diffuses differently from the traditional pheromone. In our approach, the smell-like pheromone diffuses from food, and guides ants to the food. Thus our approach not only makes the ants reach the goals farther and more efficiently but also generates much shorter counter examples than those of the traditional approaches. In order to demonstrate the effectiveness of our approach, we have implemented our approach on a practical model checker, and conducted numerical experiments. The experimental results show that our approach is effective for improving execution efficiency and the length of counter examples. Received on 17 January, 2016; accepted on 11 April, 2016; published on 21 April, 2016	algorithm;ant colony optimization algorithms;experiment;model checking;numerical analysis;software agent	Tsutomu Kumazawa;Chihiro Yokoyama;Munehiro Takimoto;Yasushi Kambayashi	2015	EAI Endorsed Trans. Indust. Netw. & Intellig. Syst.	10.4108/eai.21-4-2016.151156	simulation;engineering;artificial intelligence;operations management	SE	27.809784259100397	-1.3294576876670525	135188
91d4c8023a1c3a346739ae76122628f2e1dd7e5a	a quasi-gradient and cluster-based artificial immune system for dynamic optimization	dynamic programming;pattern clustering;clustering artificial immune system dynamic optimization;search problems artificial immune systems dynamic programming gradient methods pattern clustering;memory mechanism quasi gradient cluster based artificial immune system dynamic optimization problems dynamic environments gradient based mechanism;immune system optimization cloning sociology statistics heuristic algorithms redundancy;gradient methods;search problems;artificial immune systems	This paper presents an artificial immune system for solving dynamic optimization problems. For effectively solving optimization problems in dynamic environments, search population should be able to fast converge in each environment and redistribute when change occurs and subsequently track the change. This paper presents three modifications made to the basic artificial immune system to meet these requirements. The first one is the modified gradient-based mechanism called quasi-gradient which is beneficial to speed up the convergence of population. The second one is clustering strategy which is adopted to effectively distribute the population. Memory mechanism is the last one which takes advantage of the historical information from the last scenario preparing for the upcoming new environment. Applications on classic simple test-case generator and moving peak problem validate the performance of the proposed algorithm.	algorithm;artificial immune system;benchmark (computing);cluster analysis;converge;dynamic programming;gradient;local search (optimization);mathematical optimization;requirement	Weiwei Zhang;Gary G. Yen	2013	2013 IEEE Congress on Evolutionary Computation	10.1109/CEC.2013.6557844	mathematical optimization;computer science;artificial intelligence;machine learning;dynamic programming	AI	27.104197612978428	-4.377972001305597	135467
d0125ae58e53d1ec7f8cbe03f25a2c9efa5c4550	computational complexity and evolutionary computation	randomized algorithm;ant colony optimization;evolutionary computation;general randomized search heuristics;evolutionary algorithm;nature-inspired search heuristics;analytical method;computational complexity;search heuristics;combinatorial optimization;expected optimization time	"""Evolutionary algorithms and other nature-inspired search heuristics like ant colony optimization have been shown to be very successful when dealing with real-world applications or problems from combinatorial optimization. In recent years, analyses have shown that these general randomized search heuristics can be analyzed like """"ordinary"""" randomized algorithms and that such analyses of the expected optimization time yield deeper insights in the functioning of evolutionary algorithms in the context of approximation and optimization. This is an important research area where a lot of interesting questions are still open.  The tutorial enables attendees to analyze the computational complexity of evolutionary algorithms and other search heuristics in a rigorous way. An overview of the tools and methods developed within the last 15 years is given and practical examples of the application of these analytical methods are presented."""	analysis of algorithms;ant colony optimization algorithms;approximation;black box;combinatorial optimization;computational complexity theory;evolutionary algorithm;evolutionary computation;heuristic (computer science);markov chain;mathematical optimization;nfl;randomized algorithm;social inequality	Thomas Jansen;Frank Neumann	2010		10.1145/1830761.1830914		AI	29.886390214286305	2.115215832754287	135670
a42b2fa02bc4157e003b3ffa11a0fc16996c1fe7	a food source-updating information-guided artificial bee colony algorithm		Artificial bee colony algorithm simulates the foraging behavior of honey bees, which has shown good performance in many application problems and large-scale optimization problems. To model the bees foraging behavior more accurately, a food source-updating information-guided artificial bee colony algorithm is proposed in this paper. In this algorithm, some food source-updating information obtained during optimizing time is introduced to redefine the foraging strategies of artificial bees. The proposed algorithm has been tested on a set of test functions with dimension 30, 100, 1000 and compared with some recently proposed related algorithms. The experimental results show that the performance of artificial bee colony algorithm is significantly improved for both rotated problems and large-scale problems. Compared with the related algorithms, the proposed algorithm can achieve better or competitive performance on most test functions and greatly better performance on parts of test functions.	artificial bee colony algorithm;distribution (mathematics);genetic algorithm;mathematical optimization	Jiaxu Ning;Tingting Liu;Changsheng Zhang;Bin Zhang	2016	Neural Computing and Applications	10.1007/s00521-016-2687-8	artificial intelligence;machine learning;bees algorithm;artificial bee colony algorithm	HPC	26.546400135594265	-3.939429615374268	135686
5113d4554332139ab18f5338120d5303c405e66b	using flower pollination algorithm and atomic potential function for shape matching		Visual shape matching has been a hot research topic. As a relatively new branch, atomic potential matching (APM) model is inspired by potential field attractions. Compared to the conventional edge potential function (EPF) model, APM has been verified to be less sensitive to intricate backgrounds in the test image and far more cost-effective in the computation process. The optimization process of shape matching can be regarded as a numerical optimization problem, which is disposed by flower pollination algorithm (FPA). This study comprehensively investigates the convergence performances of FPA and the other algorithms in shape matching problem based on APM model. Experimental results of three realistic examples show that FPA is able to provide very competitive results and to outperform the other algorithms.	advanced power management;algorithm;bioinformatics;computation;eclipse process framework;list of metaphor-based metaheuristics;mathematical optimization;numerical analysis;optimization problem;performance;phase-shift oscillator;standard test image	Yongquan Zhou;Sen Zhang;Qifang Luo;Chunming Wen	2016	Neural Computing and Applications	10.1007/s00521-016-2524-0	computer vision;simulation;mathematics	EDA	24.647274194041007	-4.247053545540025	135831
718783f4c103b068176bb3de6d7166734bf96f8a	solving unbounded knapsack problem using an adaptive genetic algorithm with elitism strategy	adaptive genetic algorithm;convergence rate;knapsack problem;genetic algorithm;np complete problem	With the popularity of sensor networks, solving the knapsack problem has become important in selecting the best combination of sensor nodes. Many methods have been proposed to solve the Knapsack problem, but few of them have used the genetic algorithm, especially in unbounded Knapsack problems. In this paper, we use the genetic algorithm to solve the unbounded Knapsack problem. We combine an elite strategy and a self adapting system into the genetic algorithm. Using the elite strategy overcomes the problem of the slow convergence rate of the general genetic algorithm. The elite strategy retains good chromosomes and ensures that they are not eliminated through the mechanism of crossover and mutation, ensuring that the features of the offspring chromosomes are at least as good as their parents. The system automatically adapts the number of the initial population of chromosomes and the number of runs to be executed in the genetic algorithm. It will obtain the best value from the chromosomes of each run executed, and retain the values in an elite group. The optimal value is then taken from the elite group and adopted as the real solution. Experimental results have shown that our method rapidly discovers the best solution of the problem.	crossover (genetic algorithm);experiment;genetic algorithm;greedy algorithm;knapsack problem;mutation (genetic algorithm);optimization problem;rate of convergence;selection (user interface);the offspring	Rung Ching Chen;Cheng-Huei Jian	2007		10.1007/978-3-540-74767-3_21	continuous knapsack problem;mathematical optimization;polynomial-time approximation scheme;genetic algorithm;np-complete;computer science;generalized assignment problem;cutting stock problem;change-making problem;rate of convergence;knapsack problem;algorithm	AI	27.61045144337081	-2.5203992497150676	135838
31758e4fa922bf73a4d37f8b9c26e152d1b11584	search space pruning and global optimization of multiple gravity assist trajectories with deep space manoeuvres	cluster algorithm;optimisation;differential evolution search space pruning global optimization multiple gravity assist trajectories deep space manoeuvres clustering algorithm;differential evolution;motor vehicles aeronautics astronautics;mechanical engineering and machinery;search space;gravity;endnotes;space vehicles celestial mechanics gravity optimisation;global optimization;pubications;celestial mechanics;local minima;gravity optimization methods space vehicles space missions computational efficiency fuels design optimization standards development sampling methods leg;space vehicles	This paper deals with the design of optimal multiple gravity assist trajectories with deep space manoeuvres. A pruning method which considers the sequential nature of the problem is presented. The method locates feasible vectors using local optimization and applies a clustering algorithm to find reduced bounding boxes which can be used in a subsequent optimization step. Since multiple local minima remain within the pruned search space, the use of a global optimization method, such as Differential Evolution, is suggested for finding solutions which are likely to be close to the global optimum. Two case studies are presented.	algorithm;cluster analysis;differential evolution;global optimization;local search (optimization);mathematical optimization;maxima and minima	Victor M. Becerra;Slawomir J. Nasuto;J. Anderson;Matteo Ceriotti;C. Bombardelli	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424573	differential evolution;celestial mechanics;mathematical optimization;gravity;maxima and minima;mathematics;geometry;global optimization	EDA	27.167535437468167	-1.1603019059405357	135841
6dd00d3582d3e5af56af210435324543610a653d	particle swarm optimization with simd-oriented fast mersenne twister on the cell broadband engine	cell broadband engine;optimization problem;particle swarm optimizer;numerical simulation	We introduce a processing performance of Particle Swarm Optimization with SIDM-oriented Fast Mersenne Twister on the Cell Broadband Engine. Extreme-high processing performance is demanded for solving very complex optimization problem in a small amount of time. In this research, we verified the effectiveness of employing SIMD-oriented Fast Mersenne Twister on the Cell Broadband Engine for the processing of Particle Swarm Optimization by numerical simulations.	cell (microprocessor);mersenne twister;particle swarm optimization;simd	Jun Igarashi;Satoshi Sonoh;Takanori Koga	2008		10.1007/978-3-642-03040-6_129	computer simulation;optimization problem;multi-swarm optimization;real-time computing;simulation;computer science;theoretical computer science	HPC	31.83700109669121	-0.11237994074970989	135862
752ef8a39ea70054b7a0c312f49d60c806adaede	improving convergence of cma-es through structure-driven discrete recombination	cma es;problem structure;evolution strategies	Evolutionary Strategies (ES) are a class of continuous optimization algorithms that have proven to perform very well on hard optimization problems. Whereas in earlier literature, both intermediate and discrete recombination operators were used, we now see that most ES, e.g. CMA-ES, use only intermediate recombination. While CMA-ES is considered state-of-the-art in continuous optimization, we believe that reintroducing discrete recombination can improve the algorithms’ ability to escape local optima. Specifically, we look at using information on the problem’s structure to create building blocks for recombination. In evolutionary computation, a population of candidate solutions is evolved by applying mutation and recombination. Mutation alters elements of a single solution, while recombination combines elements from different individuals to create a new candidate solution. A typical recombination operator is the crossover operator, where a new solution is produced by essentially copying parts from different parents and glueing them together. When performed randomly, this process of crossover can disrupt optimized substructures present in a parent by only inheriting part of the substructure into the offspring. In the domain of GAs (genetic algorithms), research into detecting and using a problem’s structure to improve the performance of crossover recombination is ongoing (Harik, Lobo, and Sastry 2006; Thierens and Bosman 2011; Pelikan, Hauschild, and Thierens 2011). On the other hand, in Evolutionary Strategies (ES) (Bäck, Hoffmeister, and Schwefel 1991; Beyer and Schwefel 2002), research has moved away from the concept of crossover or discrete recombination. See for example the state of the art Covariance Matrix Adaptation Evolution Strategy (CMA-ES)(Hansen 2006), which only uses intermediate recombination in its optimization, calculating the point of gravity (weighted average) of the best current candidate solutions. When investigating infinite-valued SAT, or satisfiability in infinite-valued logics, which can be modelled as a continuous optimization problem over the domain [0, 1], with n the number of variables, we applied the standard CMA-ES Copyright c © 2012, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. as a solver and have significantly improved upon the state of the art (Schockaert, Janssen, and Vermeir 2012) (our results are to be published). Still, on a number of instances, the algorithm regularly fails to converge to the global optimum.We hypothesise – and initial experiments confirm this – that such infinite-valued SAT problems have an inherent structure to them that could be used to improve the likelihood of convergence to the global optimum. We aim to incorporate a more informed discrete recombination operator into CMA-ES, by explicitly detecting correlations between variables and creating clusters of variables that can be exchanged between candidate solutions, improving the algorithms’ ability to escape local optima. In the next sections, we explain how this structure can be derived from the covariance matrix used in CMA-ES and used in recombination. Clustering variables The CMA-ES algorithm relies on the adaptation of the covariance matrix of a multi-variate normal search distribution, from which new individuals are sampled. The covariance matrix is adapted to fit the search distribution to the contour lines of the function to be minimized. Thus, in this covariance matrix is captured an estimation of the correlations between variables, which can be used to derive a clustering of variables to be used in discrete recombination. The first step to achieve this clustering is building a weighted graph that represents the structure of the problem. For that, we use the eigendecomposition of the covariance matrix, which is already calculated within the CMA-ES. The correlation between two variables is determined by looking at the magnitudes of the corresponding components in each eigenvector. For each eigenvector, we take the product of the magnitudes of the two components in question. These products are summed, each product weighted by the eigenvalue of the eigenvector. The result of this method is that variables that have a relatively large magnitude in the same, important eigenvectors, will be assigned a larger weight in the structure graph. Pseudocode is shown in Algorithm 1. The weights need to be normalized so that, if represented as a matrix, elements on the diagonal equal 1, i.e. full auto-correlation for variables. Normalization is performed as follows: weightx,y = weightx,y √ weightx,x ∗ √ weighty,y (1) Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence	artificial intelligence;autocorrelation;cma-es;cluster analysis;continuous optimization;contour line;converge;crossover (genetic algorithm);evolution strategy;evolutionary computation;experiment;genetic algorithm;global optimization;local optimum;mathematical optimization;mutation (genetic algorithm);optimization problem;pseudocode;randomness;sensor;solver;the offspring	Tim Brys;Ann Nowé	2012			mathematical optimization;cma-es;computer science;artificial intelligence	AI	27.469218187207957	-1.8494179457664799	135962
40c2f691d842e3fd53e83b0c1b256f7b8a5776ca	"""""""intuition"""" operator: providing genomes with reason"""		In this contribution, the use of a new genetic operator is proposed. The main advantage of using this operator is that it is able to assist the evolution procedure to converge faster towards the optimal solution of a problem. This new genetic operator is called “intuition” operator. Generally speaking, one can claim that this operator is a way to include any heuristic or any other local knowledge, concerning the problem, that cannot be embedded in the fitness function. Simulation results show that the use of this operator increases significantly the performance of the classic Genetic Algorithm by increasing the convergence speed of its population. Keywords—Genetic Algorithms, “Intuition” operator, Reasonable genomes, Complex search space, Non linear fitness functions.	converge;distribution (mathematics);embedded system;fitness function;genetic algorithm;genetic operator;heuristic;np-hardness;simulation;software release life cycle;travelling salesman problem	Grigorios N. Beligiannis;Georgios A. Tsirogiannis;Panayiotis E. Pintelas	2004				AI	25.04307000809328	-2.3014819782958034	136169
38797928e031d7e3cfbd0112d2c736ac9aea344c	clustering-based crossover in an evolutionary algorithm for the vehicle routing problem with time windows		This paper addresses the Vehicle Routing Problem with Time Windows (VRPTW). A crossover operator which uses the information gathered by a clustering procedure is described. In the proposed approach, a hierarchical clustering procedure is applied to the customers' spatial data. The crossover procedure creates a new solution by removing and reinserting customers and uses the clusters to identify the most promising reinsertion locations. Thus, the proposed operator avoids exhaustive search. Computational experiments show the effectiveness of the proposed operator, that produces competitive solutions and improves the overall performance of the evolutionary algorithm when compared against an approach based on exhaustive search.	brute-force search;cb unix;cluster analysis;computation;computer cluster;evolutionary algorithm;experiment;heuristic (computer science);hierarchical clustering;local search (optimization);microsoft windows;recommender system;run time (program lifecycle phase);search algorithm;vehicle routing problem	Daniel Bustos Coral;Maristela Oliveira Santos;Claudio Fabiano Motta Toledo	2017	2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)	10.1109/ICTAI.2017.00130	artificial intelligence;evolutionary computation;genetic algorithm;machine learning;evolutionary algorithm;crossover;cluster analysis;brute-force search;vehicle routing problem;hierarchical clustering;computer science	Robotics	25.49267538120866	-1.4089206369296994	136203
cb8b306fcce8b03229a1d5a9d62fa717256cdae7	study on idle slot availability prediction for wlan using a probabilistic neural network		We have recently proposed a multi-band wireless local area network (WLAN) system as a solution to the increasingly crowded frequency space. Efficiency can be improved by an agile transceiver that transmits on an idle channel on either or both bands concurrently, and a busy/idle (B/I) predictor will form part of the sensing unit for such a system. A probabilistic neural network (PNN) is studied here for predicting upcoming WLAN B/I status based on pattern matching and classification of previous state patterns. IEEE 802.11 wireless data frames were captured at two hot-spots on multiple channels and the B/I status estimated. The prediction performance is compared for two different locations, channels, prediction matrix dimensions, B/I vs channel occupancy ratio (COR) input types, and frequency of retraining. Results show that the PNN has good potential to estimate the number of idle slots in the upcoming 20 slots and the performance improves with regular retraining.	agile software development;artificial neural network;chain-of-responsibility pattern;kerrison predictor;pattern matching;probabilistic neural network;transceiver	Julian Webber;Abolfazl Mehbodniya;Yafei Hou;Kazuto Yano;Tomoaki Kumagai	2017	2017 23rd Asia-Pacific Conference on Communications (APCC)	10.23919/APCC.2017.8304030	computer network;real-time computing;computer science;artificial neural network;pattern matching;transceiver;probabilistic logic;probabilistic neural network;wi-fi;idle;communication channel	HPC	36.39755805199334	-1.2138972404855017	136228
423ed7224386e793db5ab50ecd18e04f0ab5486a	improving multi-objective random one-bit climbers on mnk-landscapes	adaptive e ranking;landscape model;mnk landscapes;multi objective optimization;stochastic processes random processes search problems;many objective optimization;random bit climbers;stochastic processes;many objective optimization multiobjective random one bit climbers morbc mnk landscapes stochastic local search based algorithms reference population multiobjective optimization problems tabu moves;random processes;search problems;stochastic local search;multi objective optimization problem;adaptive e ranking multi objective optimization many objective optimization random bit climbers mnk landscapes	Multi-objective random one-bit climbers (moRBCs) are one class of stochastic local search-based algorithms that maintain a reference population of solutions to guide their search. They have been shown to perform well in solving multi-objective optimization problems. In this work, we further enhance the moRBCs by introducing tabu moves to improve their efficiency and search for more promising solutions. We also improve the selection to update the reference population and archive using a procedure that provides better mechanism to preserve diversity among the solutions. We use several MNK-landscape models to study the behavior of the modified moRBCs.	algorithm;archive;fractal landscape;interaction;local search (optimization);mathematical optimization;multi-objective optimization;run time (program lifecycle phase);sampling (signal processing);tabu search	Joseph M. Pasia;Hernán E. Aguirre;Kiyoshi Tanaka	2010	2010 Second World Congress on Nature and Biologically Inspired Computing (NaBIC)	10.1109/NABIC.2010.5716343	stochastic process;mathematical optimization;simulation;stochastic optimization;multi-objective optimization;machine learning;mathematics;metaheuristic;statistics	AI	26.94452928084124	-5.7118612567916385	136319
3dd6c10c2b729dae99b8957ddc4ef5bc0c90cd93	a spin-orbit torque based cellular neural network (cnn) architecture	cellular neural network;spin orbit torque;domainwall	In this paper, we propose a differential Spin Hall Effect(SHE) assisted domain wall synapse, which can generate either positive or negative synaptic weighting values without the significant cost of multiple power supply voltages, supply rails, or computationally-intensive digital hardware. The architecture of the proposed synapse utilizes reading currents flowing through two oppositely-oriented devices as weighted by device conductance. The conductance is used to encode synaptic weight and programmed by domain wall position through writing current. The ability to set the current as positively or negatively weighted results in highly-configurable functionality within a compact synapse design. The synapses are used with a soft-limiting nonlinear neuron to employ the relationship between positions and input current magnitude. We show through micro-magnetic simulation how the non-volatile physical characteristic of the domain wall calibrated synapse is used to implement a numerical integration function to realize a Cellular Neural Network(CNN). The performance of the proposed CNN design for isolated letter denoising at 0ns to 4ns demonstrates noise filtering functionality with total energy consumption during sensing of 24fJ. This compares favorably to existing spin CNN cell designs to provide a promising design approach for intrinsic neural computation.	artificial neural network;cellular neural network;computation;conductance (graph);digital electronics;encode;neuron;noise reduction;non-volatile memory;nonlinear system;numerical analysis;numerical integration;power supply;simulation;spin hall effect;synapse;synaptic weight;torque	Yu Bai;Sharon Hu;Ronald F. DeMara;Mingjie Lin	2017		10.1145/3060403.3060472	control engineering;embedded system;electronic engineering;cellular neural network;computer science	EDA	38.86448315375642	-0.3114885936115614	136529
40301ee74201b1e36bc86fbf7ca4ba9db213b0c7	an evolutionary algorithm for some cases of the single-source constrained plant location problem	location problem;warehouse location;plant location;discrete mathematics;capacitated;permutation coding;evolutionary algorithm;control method;problem solving;single source;facility location	An evolutionary algorithm for some instances of the single-source capacitated plant location problem encodes candidate solutions in two permutations, one of plant locations and a second of customers, with an integer that indicates the number of open locations. A greedy decoder identifies the solution such a genotype represents, and the EA searches for good solutions using only selection and mutation. In tests on 36 problem instances, the EA is competitive with a recent algorithm, though two superficially promising heuristic extensions do not improve its performance. The results support the general effectiveness of permutation codings in EAs that search for optimum subsets.	bit-reversal permutation;evolutionary algorithm;greedy algorithm;heuristic	Bryant A. Julstrom	2008		10.1145/1389095.1389215	single source publishing;mathematical optimization;combinatorics;computer science;facility location problem;machine learning;evolutionary algorithm;mathematics;1-center problem	AI	24.794219642557184	2.323868223887459	136950
310da12a287e55ae0b7ecaeea99e7fa813eeece0	on the effects of locality in a permutation problem: the sudoku puzzle	uniform swap crossover operators;evolutionary computation;game theory;fitness distance correlation permutation problem sudoku puzzle evolutionary computation permutation based crossover operators one cycle crossover multicycle crossover partially matched crossover uniform swap crossover uniform swap crossover operators;multicycle crossover;one cycle crossover;data mining;genetics;mathematical operators;partially matched crossover;statistical analysis;fitness distance correlation;games;permutation problem;statistical analysis evolutionary computation game theory mathematical operators search problems;search problems;correlation;sudoku puzzle;permutation based crossover operators;evolutionary computation evolution biology computer applications user centered design books;uniform swap crossover;gallium;evolutionary computing	We present an analysis of an application of Evolutionary Computation to the Sudoku Puzzle. In particular, we are interested in understanding the locality of the search operators employed, and the difficulty of the problem landscape. Treating the Sudoku puzzle as a permutation problem we analyse the locality of four permutation-based crossover operators, named One Cycle Crossover, Multi-Cycle Crossover, Partially Matched Crossover (PMX) and Uniform Swap Crossover. These were analysed using different crossover rates. Experimental evidence is found to support the hypothesis that PMX and Uniform Swap Crossover operators have better properties of locality relative to the other operators examined regardless of the crossover rates used. Fitness distance correlation, a well-known measure of hardness, is used to analyse problem difficulty and the results are consistent with the difficulty levels associated with the benchmark Sudoku puzzles analysed.	benchmark (computing);evolutionary algorithm;evolutionary computation;locality of reference;multimodal interaction;pmx (technology);principle of locality;programming paradigm;sudoku	Edgar Galván López;Michael O'Neill	2009	2009 IEEE Symposium on Computational Intelligence and Games	10.1109/CIG.2009.5286491	games;crossover;computer science;artificial intelligence;machine learning;gallium;correlation;algorithm;evolutionary computation	AI	27.15949603407394	-8.00799404965057	137098
7488ab26c3e0bd3db22dc64dfc94fa2e1f48eec2	selection strategies for gravitational constant g in artificial physics optimisation based on analysis of convergence properties	physicomimetics;global optimisation;artificial physics optimisation;gravitational force;virtual force;newton s law;apo;proof of convergence	The gravitational constant G is a particularly important parameter in artificial physics optimisation (APO) because it influences the algorithm's convergence. APO is a population-based heuristic whose swarm at each step can be divided into two distinct subsets: a divergent subset, and a convergent subset, the former containing all individuals exhibiting divergent behaviour, and the latter all others exhibiting convergent behaviour. How APO's population is apportioned between the divergent and convergent subsets is largely determined by the value of G. Two strategies for assigning its value were studied: a constant G, and an adaptive G. The disadvantage of the constant G case is mitigated by adaptive G by tuning the swarm's distribution between the two subsets. These strategies for selecting G were tested against several benchmark functions, and the results show that APO with an adaptive G outperforms APO with a constant G.	mathematical optimization	Liping Xie;Jianchao Zeng;Richard A. Formato	2012	IJBIC	10.1504/IJBIC.2012.051412	mathematical optimization;newton's law of universal gravitation;artificial intelligence;physicomimetics;mathematics	ML	28.698954535351703	-5.0562734885452665	137132
7c6fc08e5c76fd2843731c4da3353997f9c0ecf8	hybrid adaptive heuristic critic architectures for learning in mazes with continuous search spaces	search space;adaptive heuristic critic;radial basis function;rbf neural network;evolutionary strategy;hybrid architecture;genetic algorithm;evolutionary algorithm;temporal difference learning;internal model	We present the first results obtained from two implementations of a hybrid architecture which balances exploration and exploitation to solve mazes with continuous search spaces. In both cases the critic is based around a Radial Basis Function (RBF) Neural Network which uses Temporal Difference learning to acquire a continuous valued internal model of the environment through interaction with it. Also in both cases an Evolutionary Algorithm is employed in the search policy for each movement. In the first implementation a Genetic Algorithm (GA) is used, and in the second an Evolutionary Strategy (ES). Over successive trials the maze solving agent learns the V-function, a mapping between real numbered positions in the maze and the value of being at those positions.	heuristic;spaces	Anthony G. Pipe;Terence C. Fogarty;Alan F. T. Winfield	1994		10.1007/3-540-58484-6_291	temporal difference learning;mathematical optimization;radial basis function;internal model;genetic algorithm;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;evolution strategy	ML	25.265513770707322	-7.081415882427188	137218
61c0bc178cece9bfbb23b639b43c05d8a8cfb6cf	an adaptive approach for solving dynamic scheduling with time-varying number of tasks — part ii	optimisation;time varying;evolutionary computation;time change;availability;portfolios;indexes;task id number dynamic scheduling time varying task number nondominated solution centroid multiobjective evolutionary algorithm;biological cells schedules indexes equations strips availability computer science;biological cells;schedules portfolios mathematical model algorithm design and analysis indexes principal component analysis equations;principal component analysis;indexation;problem solving adaptive scheduling dynamic scheduling evolutionary computation optimisation principal component analysis;schedules;mathematical model;adaptive scheduling;strips;computer science;dynamic adaptation;principal component analysis adaptive approach dynamic scheduling solving time varying number centroid based adaptation multiobjective optimization evolutionary algorithm cba problem solving mapping task id;algorithm design;algorithm design and analysis;problem solving;dynamic scheduling;evolutionary computation dynamic scheduling	Changes in environment are common in daily activities and can introduce new problems. To be adaptive to these changes, new solutions are to be found every time change occur. This two-part paper employs a technique called Centroid-Based Adaptation (CBA) which utilize centroid of non-dominated solutions found through Multi-objective Optimization with Evolutionary Algorithm (MOEA) from previous environmental change. This centroid will become part of MOEA's initial population to find the solutions for the current change. The first part of our paper deals mainly on the extension of CBA, called Mapping Task IDs for CBA (McBA), to solve problems resulting from time-varying number of tasks. This second part will show the versatility of McBA over a portfolio of algorithms with respect to the degree of changes in environment. This demonstration was accomplished by finding a model relating the degree of changes to the performance of McBA using Nonlinear Principal Component Analysis. From this model, the degree of change at which McBA's performance becomes unacceptable can be found. Results showed that McBA, and its variant called Random McBA, can withstand larger environmental changes than those of other algorithms in the portfolio.	autonomous robot;evolutionary algorithm;experiment;holon (philosophy);human factors and ergonomics;moea framework;multi-objective optimization;principal component analysis;proactive parallel suite;scheduling (computing);simulation	Manuel Blanco Abello;Lam Thu Bui;Zbigniew Michalewicz	2011	2011 IEEE Congress of Evolutionary Computation (CEC)	10.1109/CEC.2011.5949821	algorithm design;mathematical optimization;computer science;artificial intelligence;theoretical computer science;machine learning;algorithm;evolutionary computation	Embedded	25.422379717113014	-2.8043032660654363	137220
2028a03af24c5c3a3f745dca84232c2219a0fa1e	behavior of finite population variable length genetic algorithms under random selection	finite population;empirical evidence;variable length;random selection;genetic algorithm	In this work we provide empirical evidence that shows how a variable-length genetic algorithm (GA) can naturally evolve shorter average size populations. This reduction in chromosome length appears to occur in finite population GAs when 1) selection is absent from the GA (random) or 2) when selection focuses on some other property not influenced by the length of individuals within a population.	crossover (genetic algorithm);experiment;genetic algorithm;population;randomness	Hal Stringer;Annie S. Wu	2005		10.1145/1068009.1068213	sampling;econometrics;genetic algorithm;empirical evidence;computer science;selection;effective population size;statistics	NLP	26.52574013340672	-9.14348882598366	137278
461b0b86cb4adcd2f75bf9eb54c77b996ba7de6d	quantum-behaved particle swarm optimization using mapreduce		Quantum-behaved particle swarm optimization (short in QPSO) is an improved version of particle swarm particle (short in PSO), and the performance is superior. But for now, it may not always satisfy the situations. Nowadays, problems become larger and more complex, most serial optimization algorithms cannot deal with the problem or need plenty of computing cost. In this paper, we implement QPSO on MapReduce model, propose MapReduce quantum-behaved particle swarm optimization (short in MRQPSO), and realize QPSO parallel and distributed, which the MapReduce model is a parallel computing programming model. In the experiments, the test results show that MRQPSO is more advanced both on performance of solution and time than QPSO.	mapreduce;particle swarm optimization;quantum	Yangyang Li;Zhenghan Chen;Yang Wang;Licheng Jiao	2016		10.1007/978-981-10-3614-9_22	multi-swarm optimization;metaheuristic	DB	26.36994192677419	-0.619928841253231	137297
d5e3ac3f8328be60435ec6de78b3d8068f4a15d7	backtracking biogeography-based optimization for numerical optimization and mechanical design problems	backtracking biogeography based optimization;migration operator;evolutionary algorithm;memory	As a novel Evolutionary Algorithm (EA), Biogeography-Based Optimization (BBO), inspired by the science of biogeography, draws much attention due to its significant performance in both numerical simulations and practical applications. In BBO, the features in poor solutions have a large probability to be replaced by the features in good solutions. The replacement operator is termed migration. However, the replacement causes a loss of the features in poor solutions, breaks the diversity of population and may lead to a local optimal solution. To overcome this, we design a novel migration operator to propose Backtracking BBO (BBBO). In BBBO, besides the regular population, an external population is employed to record historical individuals. The size of external population is the same as the size of regular population. The external population and regular population are used together to generate the next population. After that, the individuals in external population are randomly selected to be updated by the individuals in current population. In this way, the external population in BBBO can be considered as a memory to take part in the evolutionary process. The memory takes into account both current and historical data to generate next population, which enhances algorithm’s ability in exploring searching space. In numerical simulation, 14 classical benchmarks are employed to test BBBO’s performance and several classical nature inspired algorithms are use in comparison. The results show that the strategy in BBBO is feasible and very effective to enhance algorithm’s performance. In addition, we apply BBBO to mechanical design problems which involve constraints in optimization. The comparison results also exhibit that BBBO is very competitive in solving practical optimization problems.	backtracking;benchmark (computing);black bag operation;evolutionary algorithm;mathematical optimization;numerical analysis;numerical weather prediction;population;randomness;simulation;system migration	Weian Guo;Ming Chen;Lei Wang;Qidi Wu	2015	Applied Intelligence	10.1007/s10489-015-0732-4	mathematical optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm;memory;algorithm	AI	27.01951528951637	-4.34109192840174	137443
197249ff2e6327957dec7f4a4786f0f9e4c6f4b1	nonlinear channel equalizer design using directional evolutionary multi-objective optimization	utilisation information;multiobjective programming;programmation multiobjectif;optimisation;uso informacion;communication system;non linear programming;egalisation;optimizacion;information use;evolutionary multi objective optimization;programacion no lineal;distorsion non lineaire;fonction base radiale;multi objective optimization;distorsion no lineal;equalization;programmation non lineaire;algoritmo genetico;endnotes;nonlinear distortion;igualador;radial basis function;gradient descent;igualacion;equalizer;non linear distortion;channel equalization;algorithme genetique;evolutionary algorithms;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;optimization;pubications;evolutionary algorithm;computational efficiency;funcion radial base;rbf network;computer simulation;egaliseur;generalization capability;programacion multiobjetivo	In this paper, a new equalizer learning scheme is introduced based on the algorithm of the directional evolutionary multi-objective optimization (EMOO). Whilst nonlinear channel equalizers such as the radial basis function (RBF) equalizers have been widely studied to combat the linear and nonlinear distortions in the modern communication systems, most of them do not take into account the equalizers’ generalization capabilities. In this paper, equalizers are designed aiming at improving their generalization capabilities. It is proposed that this objective can be achieved by treating the equalizer design problem as a multi-objective optimization (MOO) problem, with each objective based on one of several training sets, followed by deriving equalizers with good capabilities of recovering the signals for all the training sets. Conventional EMOO which is widely applied in the MOO problems suffers from disadvantages such as slow convergence speed. Directional EMOO improves the computational efficiency of the con...	equalization (communications);mathematical optimization;multi-objective optimization;nonlinear programming	N. Zong;Xia Hong	2005	Int. J. Systems Science	10.1080/00207720500218908	gradient descent;mathematical optimization;nonlinear distortion;radial basis function;equalizer;genetic algorithm;equalization;computer science;artificial intelligence;equalization;multi-objective optimization;machine learning;evolutionary algorithm;control theory;mathematics;communications system	EDA	28.432957320875385	0.5702769835607053	137794
6cdb1e3c50eacc206d54335d74737c43b037ce49	on the supply of superior order-1 building blocks for a class of periodical fitness functions	cardinality of coding alphabet;building block;genetic algorithm;genetic algorithms;periodical function;linear weighted coding;fitness function	In addition to GA-deception, the lack of fitness differences among low-order schemata can also degrade GA’s search. Therefore, a coding should present adequate superior low-order building blocks at the early stage of search. This paper aims to reveal the inherent periodicity in the search process of a genetic algorithm, and to show how to make use of this periodicity in the design of representation for fitness functions with periods of the reciprocals of positive integers so as to ensure the effective supply of superior order-1 building blocks. Finally, simulations are given to illustrate the effectiveness of the proposed method.	fitness function;genetic algorithm;quasiperiodicity;simulation;software release life cycle	Hongqiang Mo;Zhongqiao Li;Jin Bae Park;Young Hoon Joo	2009	Int. J. Comput. Intell. Syst.	10.1080/18756891.2009.9727643	mathematical optimization;combinatorics;discrete mathematics;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;fitness approximation;fitness function;algorithm	AI	25.07817327998398	-8.764378173192616	137972
d120da3b48950c50578e393cd82dad9eecd3f961	performance comparison of two evolutionary schemes	optimisation;stochastic algorithm;convergence;evolutionary computation;probability;search space;convergence of numerical methods;binary codes;performance comparison;random variables;polynomials;area under the curve;deterministic algorithm;stochastic processes;computational complexity;performance analysis;genetic algorithms;search problems;convergence deterministic algorithm computational complexity evolutionary algorithm probability characteristic polynomial search space stochastic algorithm optimisation;evolutionary algorithm;characteristic polynomial;evolutionary computation convergence polynomials random variables stochastic processes computational complexity binary codes probability performance analysis	The performance of a deterministic algorithm is judged by its computational complexity. But an evolutionary algorithm being probabilistic in nature, its convergence has some probability associated with it. In the present paper, we try to locate the parameters that control the performance of an evolutionary algorithm. In this formulation, we make some assumptions, under which the performance comparison is possible. Moreover we propose a notion of characteristic polynomial which gives a measure of the performance of an evolutionary scheme. The area under the curve of the characteristic polynomial over the range 0 to 1 is equivalently shown to represent the performance criterion.	characteristic polynomial;computational complexity theory;deterministic algorithm;erewhon;evolutionary algorithm;performance tuning	Paramartha Dutta;D. Dutta Majumder	1996		10.1109/ICPR.1996.547647	random variable;mathematical optimization;binary code;combinatorics;discrete mathematics;genetic algorithm;convergence;area under the curve;computer science;deterministic algorithm;evolutionary algorithm;probability;mathematics;characteristic polynomial;computational complexity theory;statistics;polynomial;evolutionary computation	Vision	28.229467282014483	-7.470877402145259	138023
c4e6e402f93834d7e0cf99305e3b33e09b8e51af	sports scheduling search space connectivity: a riffle shuffle driven approach	graph theory;sport scheduling;riffle shuffle;canonical method	The canonical method is widely used to build single round robin schedules for sports competitions. Certain properties of the canonical method may entrap local search procedures. In this paper, we study the connectivity of one of the most used neighborhood structures in local search heuristics for single round robin scheduling and characterize the conditions in which this entrapment happens. This characterization brings to light a relation between the connectivity of the analyzed neighborhood and the riffle shuffle, a method of shuffling playing cards. © 2016 Elsevier B.V. All rights reserved.	fisher–yates shuffle;heuristic (computer science);local search (optimization);round-robin scheduling;scheduling (computing)	Tiago Januario;Sebastián Urrutia;Dominique de Werra	2016	Discrete Applied Mathematics	10.1016/j.dam.2016.04.018	mathematical optimization;combinatorics;graph theory;theoretical computer science;mathematics;distributed computing;shuffling;algorithm	AI	27.166860712943187	3.894911432082183	138106
b22a8d7ed69faac44760bdd5361c7cbd23fde498	an artificial fish swarm algorithm based on chaos search	optimisation;marine animals;convergence;chaos;chaos search;global convergence;global optimum;artificial fish swarm algorithm;stability;function optimization;accuracy;visualization;marine animals chaos convergence random number generation educational institutions control engineering petroleum electronic mail stochastic processes logistics;search problems optimisation;random optimization algorithm;global optimum artificial fish swarm algorithm chaos search function optimization;optimization;search problems;stability artificial fish swarm algorithm chaos search random optimization algorithm convergence;optimal algorithm	Artificial fish swarm algorithm is a new random optimization algorithm based on simulation of fish swarm behavior. Preliminary study shows that it has many features such as good global convergence and high convergence speed. However, it may be trapped in local optimum in the later evolution period and it has the low search accuracy. An artificial fish swarm algorithm based on chaos search is proposed, which can not only overcome the disadvantage of easily getting into the local optimum in the later evolution period, but also keep the rapidity of the previous period. Finally, the basic artificial fish swarm algorithm is compared with this method using four benchmark test functions. The experiment results demonstrate that the new algorithm proposed is better than the basic artificial fish swarm algorithm in the aspects of convergence and stability.	algorithm;benchmark (computing);distribution (mathematics);experience;local convergence;local optimum;mathematical model;mathematical optimization;nonlinear system;random optimization;simulation;swarm	Hai Ma;Yanjiang Wang	2009	2009 Fifth International Conference on Natural Computation	10.1109/ICNC.2009.148	mathematical optimization;multi-swarm optimization;artificial intelligence;machine learning;mathematics;particle swarm optimization	Robotics	28.098457941961588	-5.349277843453999	138561
280a5fe10b72e47e132975ab3d823d750062e819	an mdac synapse for analog neural networks	random access memory;weight storage;linearity;multiplying circuits neural chips digital analogue conversion analogue integrated circuits;multiplying circuits;neural networks;1 5 micron;semiconductor device measurement;transconductance;synapse circuit;neural chips;analogue integrated circuits;neural networks circuits digital analog conversion linearity capacitors analog memory nonvolatile memory random access memory transconductance semiconductor device measurement;capacitors;nonvolatile memory;1 5 micron mdac synapse analog neural networks synapse circuit weight storage multiplying digital to analog converter;analog neural networks;analog memory;circuits;mdac synapse;recurrent neural network;digital analogue conversion;digital analog conversion;neural network;multiplying digital to analog converter	Efficient weight storage and multiplication are important design challenges which must be addressed in analog neural network implementations. Many schemes which treat storage and multiplication separately have been previously reported for implementation of synapses. We present a synapse circuit that integrates the weight storage and multiplication into a single, compact multiplying digital-to-analog converter (MDAC) circuit. The circuit has a small layout area (5400 /spl mu/m/sup 2/ in a 1.5-/spl mu/m process) and exhibits good linearity over its entire input range. We have fabricated several synapses and characterize their responses. Average maximum INL and DNL values of 0.2 LSB and 0.4 LSB, respectively, have been measured. We also report on the performance of an analogue neural network which uses these synapses.	artificial neural network;digital-to-analog converter;least significant bit;noise reduction;synapse	Ryan J. Kier;Reid R. Harrison;Randall D. Beer	2004	2004 IEEE International Symposium on Circuits and Systems (IEEE Cat. No.04CH37512)	10.1109/ISCAS.2004.1329917	electronic circuit;electronic engineering;capacitor;non-volatile memory;telecommunications;computer science;electrical engineering;recurrent neural network;machine learning;linearity;artificial neural network	Arch	38.6962317438248	-1.9559600756909954	138679
a349e26956faac6af81d82144994875e5150b0c5	study of preferential vector of particle swarm with hierarchical reinforcement	inertia weight;pso;adaptive;preferential vector;particle swarm optimisation;hierarchical reinforcement learning	A preferential vector algorithm of particle swarm with hierarchical reinforcement learning is proposed to solve the balance problem of global searching range and local searching precision, and the problem of fixedly adjusting strategy of inertia weight. Firstly, the preferential particle position with crossover operation was introduced on the standard particle swarm algorithm. The sequential adding operations on single step of particle position were divided into the seeking of middle particles. The operations of crossover and mutation were combined to keep the elite particle swarm. Secondly, the adjusting strategies of inertia weight were treated as the actions. The hierarchical learning was executed in every iteration of particle swarm and the strategy with maximal discounted profit was selected. The experiment proved the validity of the algorithm.	algorithm;crossover (genetic algorithm);emergent;humanoid robot;interlaced video;iteration;maximal set;motion planning;multi-objective optimization;mutation (genetic algorithm);optimization problem;particle swarm optimization;reinforcement learning;software bug	Wende Ke	2016	IJWMC	10.1504/IJWMC.2016.077232	mathematical optimization;multi-swarm optimization;artificial intelligence;adaptive behavior;machine learning;particle swarm optimization	Robotics	30.216158423913345	-3.5358591392967393	138904
6f4827e6258e3ac755e25f2b5c0f62064c561fdf	the chaos-based shuffled frog leaping algorithm and its application	reservoirs;optimal solution;hydroelectric power generation;cascade hydropower stations;hydroelectric power stations;optimisation;evolutionary computation;chaos;combinatorial optimization chaos based shuffled frog leaping algorithm meta heuristic evolutionary algorithm cascade hydropower stations;water resources;optimisation combinatorial mathematics evolutionary computation hydroelectric power stations;chaos based shuffled frog leaping algorithm;meta heuristic evolutionary algorithm;chaos hydroelectric power generation diversity reception testing partitioning algorithms evolutionary computation bridges assembly food technology water resources;evolution biology;optimization;evolutionary algorithm;numerical experiment;combinatorial optimization;combinatorial mathematics;high efficiency;algorithm design and analysis	Shuffled Frog Leaping Algorithm (SFLA) is a new meta-heuristic evolutionary algorithm with simple algorithm structure and fast calculation speed. In this paper, a novel algorithm based on SFLA and chaos search is presented. This algorithm uses chaos search to generate neighborhoods of extremum so as to maintain solution diversity and get rid of local optimal solution when the individual stops evolution. The numerical experiments results show it outperforms standard SFLA. Finally, the proposed algorithm is used to solve the problem of mid-long term optimal operation of cascade hydropower stations and is compared with other two algorithms. The operation results show its feasibility and high efficiency.	blue frog;continuous optimization;davis–putnam algorithm;evolutionary algorithm;experiment;heuristic;mathematical optimization;maxima and minima;numerical analysis;numerical method	Yinghai Li;Jianzhong Zhou;Junjie Yang;Li Liu;Hui Qin;Lei Yang	2008	2008 Fourth International Conference on Natural Computation	10.1109/ICNC.2008.242	mathematical optimization;engineering;artificial intelligence;algorithm	Robotics	26.19476559597223	-1.964320834762528	138939
81c07282a1b6a7fc0d3ffef6482d403a74f11c60	new approach to hot electron effects in si-mosfets based on an evolutionary algorithm using a monte carlo like mutation operator	evolutionary algorithm;monte carlo	We introduce a new approach to hot electron effects in Si-MOSFETs, based on a mixture of evolutionary optimization algorithms and Monte Carlo technique. The Evolutionary Algorithm searchs for electron distributions which fit a given goal, for example a measured substrate current and in this way can calculate backwards electron distributions from measurement results. The search of the Evolutionary Algorithm is directed toward physically correct distributions by help of a Monte Carlo like mutation operator. Results for bulk-Si demonstrate the correctness of the physical model in the Monte Carlo like mutation operator and the backward calculation ability of the Evolutionary Algorithm. First results for Si-MOSFETs are qualitatively comparable to results of a Full Band Monte Carlo simulation.	electron;evolutionary algorithm;hot-carrier injection;monte carlo method	Jürgen Jakumeit;Umberto Ravaioli;Karl Hess	1998	VLSI Design	10.1155/1998/81023	quantum monte carlo;monte carlo method in statistical physics;quasi-monte carlo method;mathematical optimization;diffusion monte carlo;dynamic monte carlo method;simulation;hybrid monte carlo;particle filter;markov chain monte carlo;computer science;monte carlo molecular modeling;mathematics;kinetic monte carlo;rejection sampling;monte carlo integration;monte carlo algorithm;statistics;monte carlo method	EDA	31.4754093705801	-7.755232295498137	139025
f386a88894b90107e9f1a7765cd885e46135059f	artificial physics optimisation algorithm guided by diversity	population diversity;physicomimetics;global optimisation;artificial physics optimisation;dissipative structure theory	In order to avoid the stagnation evolution of APO population, the thinking of dissipative structure theory and population diversity are combined in APO. Firstly, a chaos factor is introduced to judge whether the individuals doing dissipative movement or not, which is defined in a dissipation rule. However, the behaviour of an individual decided by the dissipation rule has blindness. Hence, population diversity is used to guide individual's movement. Then a diversity factor is introduced to judge whether population diversity is good or bad. If population diversity is worse than the diversity factor, individuals will do dissipative movement according to dissipation rule. The proposed algorithm is called APO algorithm guide by diversity APOD. Simulation results show APOD algorithm can improve the population diversity and global search capability of APO algorithm.	algorithm;mathematical optimization	Gangjun Yang;Liping Xie;Ying Tan;Zhihua Cui	2013	IJCAT	10.1504/IJCAT.2013.053428	simulation;artificial intelligence;physicomimetics	ML	27.901101761584407	-4.337871531878764	139169
39b228b7f334f3c2f8e19bde56325cbf1456fb86	evolution strategies: an alternative evolutionary algorithm	evolution strategy;evolutionary algorithm	In this paper, evolution strategies (ESs) | a class of evolutionary algorithms using normally distributed mutations, recombination, deterministic selection of the > 1 best oospring individuals, and the principle of self-adaptation for the collective on-line learning of strategy parameters | are described by demonstrating their diierences to genetic algorithms. By comparison of the algorithms, it is argued that the application of canonical genetic algorithms for continuous parameter optimization problems implies some diiculties caused by the encoding of continuous object variables by binary strings and the constant mutation rate used in genetic algorithms. Because they utilize a problem-adequate representation and a suitable self-adaptive step size control guaranteeing linear convergence for strictly convex problems, evolution strategies are argued to be more adequate for continuous problems. The main advantage of evolution strategies, the self-adaptation of strategy parameters, is explained in detail, and further components such as recombination and selection are described on a rather general level. Concerning theory, recent results regarding convergence velocity and global convergence of evolution strategies are brieey summarized, especially including the results for (,)-ESs with recombination. It turns out that the theoretical ground of ESs provides many more results about their behavior as optimization algorithms than available for genetic algorithms , and that ESs have all properties required for global optimization methods. The paper concludes by emphasizing the necessity for an appropriate step size control and the recommendation to avoid encoding mappings by using a problem-adequate representation of solutions within evolutionary algorithms. In contrast to the title and the overall intention of this article to provide an overview of evolution strategies (ESs) 35, 36, 40, 44] (and, to make the reader curious of reading more about them), I take the freedom to start with a brief look at the global optimization problem and those evolutionary algorithms which are widely used to approximately solve this problem: Genetic algorithms (GAs) 21, 25]. Although these two diierent, independently developed branches of evolutionary computation are known since more than thirty years, genetic algorithms have gained much more interest during the past ten years than evolution strategies	adaptive stepsize;convex function;convex optimization;crossover (genetic algorithm);evolution strategy;evolutionary algorithm;evolutionary computation;genetic algorithm;global optimization;local convergence;mathematical optimization;online and offline;online machine learning;optimization problem;rate of convergence;velocity (software development)	Thomas Bäck	1995		10.1007/3-540-61108-8_27	evolutionary programming;genetic algorithm;interactive evolutionary computation;human-based evolutionary computation;cultural algorithm;java evolutionary computation toolkit;evolutionary algorithm;evolutionary acquisition of neural topologies;evolution strategy;imperialist competitive algorithm;evolutionary computation	AI	26.254346532318255	-6.641799280256333	139285
0b1f9db5a055ab6f6826684c2bd8961a7bda453a	a simplified electromagnetism-like mechanism algorithm for tool path planning in 5-axis flank milling	machining;path planning;simplified electromagnetism like mechanism algorithm different processing surface parameter selection pso algorithm oem algorithm original em machining error 5 axis flank milling tool path planning;manufacturing processes;milling machines;electromagnetism;particle swarm optimisation;parameter selection electromagnetism like mechanism tool path planning machining error;path planning optimization linear programming force milling encoding;path planning electromagnetism machining manufacturing processes milling machines particle swarm optimisation	In 5-axis flank milling, tool path planning is of great significance since the machining error can be systematically reduced by optimization of tool path planning. Therefore, various optimization methods for tool path planning have been developed. This paper proposes a simplified electromagnetism-like mechanism (EM) algorithm to optimize the tool path planning. Based on the experimental results, we can see that the proposed method owns excellent performance compared with original EM (OEM) algorithm and PSO algorithm. Moreover, we also study the parameter selection of EM algorithm according to different processing surface.	expectation–maximization algorithm;global optimization;local search (optimization);mathematical optimization;motion planning;optimization problem;particle swarm optimization;the times	Qing Wu;Xinyu Li;Liang Gao;Ying Li	2013	Proceedings of the 2013 IEEE 17th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2013.6581000	electromagnetism;machining;computer science;machine learning;motion planning	Robotics	30.62330267480741	-2.9736393495383777	139295
cdaec18bf3efc1f27029f82ab27513f1c6822de0	an optimized grey wolf optimizer based on a mutation operator and eliminating-reconstructing mechanism and its application		Due to its simplicity and ease of use, the standard grey wolf optimizer (GWO) is attracting much attention. However, due to its imperfect search structure and possible risk of being trapped in local optima, its application has been limited. To perfect the performance of the algorithm, an optimized GWO is proposed based on a mutation operator and eliminating-reconstructing mechanism (MR-GWO). By analyzing GWO, it is found that it conducts search with only three leading wolves at the core, and balances the exploration and exploitation abilities by adjusting only the parameter a, which means the wolves lose some diversity to some extent. Therefore, a mutation operator is introduced to facilitate better searching wolves, and an eliminating- reconstructing mechanism is used for the poor search wolves, which not only effectively expands the stochastic search, but also accelerates its convergence, and these two operations complement each other well. To verify its validity, MR-GWO is applied to the global optimization experiment of 13 standard continuous functions and a radial basis function (RBF) network approximation experiment. Through a comparison with other algorithms, it is proven that MR-GWO has a strong advantage.	algorithm;approximation;closing (morphology);global optimization;local optimum;mathematical optimization;multimodal interaction;radial (radio);radial basis function network;stochastic optimization;usability;wolf cms	Xiao-qing Zhang;Zhengfeng Ming	2017	Frontiers of Information Technology & Electronic Engineering	10.1631/FITEE.1601555	global optimization;mathematical optimization;swarm intelligence;local optimum;computer science;operator (computer programming);continuous function;convergence (routing);radial basis function network	AI	27.599702168111598	-4.291538285289244	139428
167ed36967ce19d5c152080645fab49f279e89e5	the comparative research of solving problems of equilibrium and optimizing multi-resources with ga and pso	rate of convergence;resources equilibrium;convergence;scheduling resources;optimization methods geology convergence design optimization computational intelligence security genetic algorithms particle swarm optimization evolutionary computation job shop scheduling;optimal method;maintenance engineering;pso;genetics;intelligence optimizing method equilibrium optimizing multi resources pso genetic algorithm particle swarm optimization evolutionary algorithm scheduling resources;comparative research;biological cells;particle swarm optimizer;particle swarm optimization;optimizing multi resources;genetic algorithm;genetic algorithms;optimization;equilibrium;evolutionary algorithm;particle swarm optimisation genetic algorithms;encoding;particle swarm optimisation;intelligence optimizing method;resources equilibrium genetic algorithm particle swarm optimization;gallium	Genetic algorithm and particle swarm optimization both belong to the evolutionary algorithms; they have much in common, but also have some differences. The paper set out from optimizing many resources, discussed the method of utilizing GA and PSO in detail, in order to equilibrium and optimize the problem of scheduling resources which are limited separately. Through analysis of comparative experiment, two kinds of intelligence-optimizing methods made very good results when solved a same problem, but in most cases, PSO has a faster rate of convergence than GA.	crossover (genetic algorithm);encode;evolutionary algorithm;genetic algorithm;mathematical optimization;mutation (genetic algorithm);one-way function;optimizing compiler;particle swarm optimization;random search;rate of convergence;scheduling (computing);software release life cycle	Xiang Li;Yanli Li;Li Zhu	2008	2008 International Conference on Computational Intelligence and Security	10.1109/CIS.2008.43	maintenance engineering;mathematical optimization;genetic algorithm;computer science;artificial intelligence;machine learning;evolutionary algorithm	Robotics	25.201118992856422	-5.482913042057017	139794
f824f25a3dfb451f590f38bda7ba1b55969e7695	global optimal solution to slam problem with unknown initial estimates		The paper presents a practical approach for finding the globally optimal solution to SLAM. Traditional methods are based upon local optimization based strategies and are highly susceptible to local minima due to non-convex nature of the SLAM problem. We employed the nonlinear global optimization based approach to SLAM by exploiting the theoretical limit on the numbers of local minima. Our work is not reliant on good initial guess, whereas existing approaches in SLAM literature assume good starting point to avoid local minima problem. The paper presents experimental results on different datasets to validate the robustness of the approach, finding the global basin of attraction with unknown initial guess.	dynamic language runtime;emoticon;exponential integrate-and-fire;grasp;global optimization;local convergence;local search (optimization);map;mathematical optimization;maxima and minima;nonlinear system;open-source software;optimization problem;robustness (computer science);simultaneous localization and mapping;the australian	Usman Qayyum;Jonghyuk Kim	2012			greedy randomized adaptive search procedure;mathematical optimization;combinatorics;calculus;mathematics;data set;statistics	Robotics	30.249084073572124	-0.5051119391896216	140035
ce462b8525eb2a42b33d6f760a503644592a9b7b	the polar evolution strategy	evolutionary algorithm polar evolution strategy squared norm gaussian mutation operator unit vector complex nonlinear equality constraint curvilinear coordinate spam filtering problem credit card approval problem search problem genetic algorithm;gaussian processes;mathematical operators;spam filtering;search problems gaussian processes genetic algorithms mathematical operators;evolution strategy;genetic algorithms;polar coordinate;search problems;genetic mutations evolutionary computation filtering credit cards genetic algorithms genetic programming robot kinematics orbital robotics pattern recognition principal component analysis;credit cards	We show in this paper that the squared norm of an individual subject to Gaussian mutation in an evolution strategy will grow on average linearly with the number of generations. Although we prove this result in the absence of selection, experimental evidence is provided showing that the result also holds in a full fledged evolution strategy applied to the search for projections. This phenomenon implies that regions farther and farther away from the origin are explored as the number of generations increases. This becomes crucial when searching for unit vectors or projections, whose norm should be kept fixed. In order to meet this constraint we propose to change to polar coordinates and use a constrained mutation operator which only mutates angles and keeps the radius constant. Likewise, more complex non-linear equality constraints could be handled by means of general curvilinear coordinates. As an illustrative application, our polar evolution strategy (PES) is applied to a spam filtering problem and a credit card approval problem. The new algorithm is shown to perform as well as other state of the art alternatives.	algorithm;anti-spam techniques;email filtering;evolution strategy;linear equation;nonlinear system;potential energy surface	Alejandro Sierra;Alejandro Echeverría	2006	2006 IEEE International Conference on Evolutionary Computation	10.1109/CEC.2006.1688592	mathematical optimization;polar coordinate system;genetic algorithm;computer science;artificial intelligence;machine learning;gaussian process;mathematics;evolution strategy;algorithm;statistics	Robotics	29.23679747595162	-7.311752796694421	140176
fd4da8b13f35aaaebf5676f30cbb3e0cb18d9ffe	a parallelized gpu-based simulating annealing algorithm for intensity modulated radiation therapy optimization		Intensity modulated radiation therapy (IMRT) exhibits the ability to deliver the prescribed dose to the planning target volume (PTV), while minimizing the delivered dose to the organs at risk (OARs). Metaheuristic algorithms, among them the simulating annealing algorithm (SAA), have been proposed in the past for optimization of IMRT. Despite the advantage of the SAA to be a global optimizer, IMRT optimization is an extensive computational task due to the large scale of the optimization variables. Therefore stochastic algorithms, such as the SAA, require significant computational resources. In an effort to elucidate the performance improvement of the SAA in highly dimensional optimization tasks, such as the IMRT optimization, we introduce for the first time to our best knowledge a parallel graphic processing unit (GPU)-based SAA developed in MATLAB platform and compliant with the computational environment for radiotherapy research (CERR) for IMRT treatment planning. Our strategy was firstly to identify the major “bottlenecks” of our code and secondly to parallelize those on the GPU accordingly. Performance tests were conducted on four different GPU cards in comparison to a serial version of the algorithm executed on a CPU. Our studies have shown a gradual increase of the speedup factor as a function of the number of beamlets for all four GPUs. Particularly, a maximum speedup factor of ∼33 was achieved when the K40m card was utilized.	algorithm;bottleneck (software);central processing unit;computational resource;graphics processing unit;matlab;mathematical optimization;metaheuristic;modulation;parallel computing;simulated annealing;simulation;speedup	Panagiota Galanakou;Theodora Leventouri;Alexandros Georgakilas;Georgios Kalantzis	2017	2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)	10.1109/SNPD.2017.8022754	matlab;parallel computing;performance improvement;metaheuristic;computer science;speedup;intensity-modulated radiation therapy;radiation treatment planning;algorithm	HPC	31.928534582651537	-0.080253159436034	140377
d5194fe287ff50c76577c7ee3a88fe077c5b13d8	integrated optimization based on successive adaptive approximation	modeling and simulation;optimization technique;benchmark problem;radial basis function networks adaptive systems approximation theory particle swarm optimisation;approximation theory;radial basis function networks;optimization computational modeling sociology adaptation model;adaptive algorithm;numerical simulation integrated optimization system real system modeling technology simulation technology computational efficiency particle swarm optimization radial basis function network;computational modeling;adaptation model;particle swarm optimizer;adaptive systems;radial basis function network;particle swarm optimization;radial basis function network optimization particle swarm optimization modeling adaptive algorithm;optimization;computational efficiency;modeling;particle swarm optimisation;sociology;numerical simulation	In order to meet the high requirement of practical optimization, it is essential to construct an integrated optimization system for real systems, which is a new paradigm of optimization system based on combining optimization technique with modeling and simulation technologies. From the viewpoint of optimality and computational efficiency, this paper examines some strategies for arranging sample points adaptively in an integrated optimization system that combines Particle Swarm Optimization and Radial Basis Function Network. The proposed strategies for arranging sample points are examined through numerical simulations using four types of typical benchmark problems.	approximation algorithm;benchmark (computing);computer simulation;mathematical optimization;numerical analysis;particle swarm optimization;program optimization;programming paradigm;radial basis function network	Tomoyuki Tanaka;Kenichi Tamura;Keiichiro Yasuda	2010	2010 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2010.5642206	probabilistic-based design optimization;discrete optimization;optimization problem;mathematical optimization;multi-swarm optimization;constrained optimization;engineering optimization;test functions for optimization;meta-optimization;systems modeling;computer science;derivative-free optimization;artificial intelligence;stochastic optimization;multi-objective optimization;machine learning;modeling and simulation;continuous optimization;vector optimization;particle swarm optimization;computational model;radial basis function network;random optimization;metaheuristic;global optimization;approximation theory	Robotics	28.87913191181127	-1.5821915885679612	140498
1940fb81bb62106543c2ffda0283787420f20bca	combinatorial optimization with use of guided evolutionary simulated annealing	near optimum solution combinatorial optimization guided evolutionary simulated annealing np complete problems gesa function optimization search problem traveling salesman problem benchmark problem;traveling salesman problem;optimal solution;neural networks;probleme np complet;benchmark problem;simulated annealing;simulated evolution;simulated annealing computational modeling traveling salesman problems genetic algorithms search problems engineering management operations research computer science np complete problem associative memory;function optimization;algorithme;optimisation combinatoire;recuit simule;computational complexity;travelling salesman problems;algorithms;problema np completo;search problems;combinatorial mathematics simulated annealing travelling salesman problems search problems computational complexity;reseau neuronal;combinatorial optimization;local minima;combinatorial mathematics;np complete problem;optimizacion combinatoria	Feasible approaches to the task of solving NP-complete problems usually entails the incorporation of heuristic procedures so as to increase the efficiency of the methods used. We propose a new technique, which incorporates the idea of simulated annealing into the practice of simulated evolution, in place of arbitrary heuristics. The proposed technique is called guided evolutionary simulated annealing (GESA). We report on the use of GESA approach primarily for combinatorial optimization. In addition, we report the case of function optimization, treating the task as a search problem. The traveling salesman problem is taken as a benchmark problem in the first case. Simulation results are reported. The results show that the GESA approach can discover a very good near optimum solution after examining an extremely small fraction of possible solutions. A very complicated function with many local minima is used in the second case. The results in both cases indicate that the GESA technique is a practicable method which yields consistent and good near optimal solutions, superior to simulated evolution.	benchmark (computing);combinatorial optimization;heuristics;karp's 21 np-complete problems;mathematical optimization;maxima and minima;radiotherapy, image-guided;search problem;simulated annealing;simulation;solutions;travelling salesman problem;travel	Percy P. C. Yip;Yoh-Han Pao	1995	IEEE transactions on neural networks	10.1109/72.363466	mathematical optimization;np-complete;simulated annealing;combinatorial optimization;computer science;machine learning;maxima and minima;mathematics;travelling salesman problem;computational complexity theory;artificial neural network;algorithm	Embedded	26.31256197054431	2.187247042878858	140794
d7893acbc9f0efda440e47adaa6fa49295636c0a	comparison of performance between genetic algorithm and breeding algorithm for global optimization of continuous functions	genetic algorithms optimization methods chemical engineering chemical technology sampling methods evolutionary computation computational efficiency cost function design optimization stochastic processes;optimized production technology;convergence;probability;probability characteristic genetic algorithm breeding algorithm global optimization continuous functions;barium;comparison;continuous functions;accuracy;comparison global optimization genetic algorithm breeding algorithm convergence;probability characteristic;genetic algorithm;genetic algorithms;global optimization;optimization;breeding algorithm;probability genetic algorithms;local search;gallium	This paper indicates a practical way and conditions for the algorithms to achieve global optimization according to its probability characteristic. Based on this, the convergence performances of conventional genetic algorithm (GA) and breeding algorithm (BA) are estimated and compared according to the globability, accuracy and computation cost. The results show that the conventional GA can not perform not only effective global search but also the accurate local search. For the same probability of global optimization, BA can achieve more accurate computation at about half cost of that of conventional GA. Furthermore, the computation accuracy of BA can be controlled by the length of binary strings. This study reveals the pitfalls existing in conventional GA and designates a reasonable direction for the choice and improvement of the strategies of global optimization.	business architecture;computation;cooperative breeding;genetic algorithm;global optimization;local search (optimization);mathematical optimization;monte carlo method;performance;sampling (signal processing);software release life cycle	Zheng Xiao-ping;Huang Shi-zhao;Ding Xin-wei	2008	2008 Fourth International Conference on Natural Computation	10.1109/ICNC.2008.758	mathematical optimization;theoretical computer science;machine learning;mathematics	EDA	28.088847258423066	-6.194152887047929	141067
198fa82273a28fb3f79e9949bf1878be64f8c110	introducing lifetime parameter in selection based particle swarm optimization for improved performance			mathematical optimization;particle swarm optimization	K. K. Aggarwal;Shakti Kumar;Arun Khosla;Jagatpreet Singh	2003			machine learning;computer science;artificial intelligence;metaheuristic;multi-swarm optimization;particle swarm optimization	EDA	24.892580403267267	-5.081975798911136	141076
64c45d0d0792a10be4d5cbf737a84369c629b881	a new competitive learning approach based on an equidistortion principle for designing optimal vector quantizers	data compression;selection mechanism;design optimization;competitive learning;vector quantization;clustering;vector quantizer;equidistortion principle	A new competitive learning approach is presented for optimal vector quantizer design. First, it is shown that the original  CL  algorithm is equivalent to the traditional nonconnectionist  VQ  design algorithm called the  LBG  algorithm. Then, it is shown that the conventional conscience principle or equiprobable principle is not optimal from the standpoint of the minimization of the expected distortion. Next, a basic principle called the equidistortion principle for the design of optimal vector quantizers is theoretically derived by using Gersho's asymptotic theory. This paper proposes a new competitive learning algorithm with a selection mechanism, called the  CSL  (competitive and selective learning) algorithm, which is based on the equidistortion principle. Because the selection mechanism enables the system to escape from local minima, the proposed algorithm can obtain better performance without a particular initialization procedure even when the input data cluster in a number of regions in the input vector space. Simulation results comparing the performance of the  CSL  algorithm with other conventional algorithms for synthetic and real-world data show that the  CSL  algorithm, in spite of its simplicity, always produces the best quantizers with the least distortion, regardless of the initial codes. The optimality of the proposed  CSL  algorithm is also verified through a synthetic one-dimensional quantizer problem.	competitive learning	Naonori Ueda;Ryohei Nakano	1994	Neural Networks	10.1016/0893-6080(94)90003-5	data compression;competitive analysis;mathematical optimization;discrete mathematics;multidisciplinary design optimization;computer science;machine learning;mathematics;cluster analysis;competitive learning;linde–buzo–gray algorithm;vector quantization	ML	29.30981667665421	-6.6812966237367615	141107
045d717c9373673503fa8443ccc612e91ccf10ad	the use of tail inequalities on the probable computational time of randomized search heuristics	probable computational time pct;computational complexity;expected running time;tail inequalities;randomized search heuristics rshs;evolutionary algorithms eas	For the purpose of analyzing the time cost of evolutionary algorithms (EAs) or other types of randomized search heuristics (RSHs) with certain requirements on the probability of obtaining a target solution, this paper proposes a new index, called the probable computational time (PCT), which complements expected running time analysis. Using simple tail inequalities, such as Markov's inequality and Chebyshev's inequality, we also provide basic properties of PCT, explicitly exhibiting the general relationships between the expected running time and the PCT. To present deeper estimations of the PCT for specific RSHs and problems, we demonstrate a new inequality that is based on the general form of the Chernoff inequality and previous methods such as ''fitness-based partitions'' and ''potential functions'', which have been used to analyze the expected running time of RSHs. The precondition of the new inequality is that the total running time can be described as the sum of a linear combination of some independent geometrically distributed variables and a constant term. The new inequality always provides meaningful upper bounds for the PCT under such circumstances. Some applications of the new inequality for simple EAs, ant colony optimization (ACO) and particle swarm optimization (PSO) algorithms on simple pseudo-Boolean functions are illustrated in this paper.	computation;heuristic (computer science);randomized algorithm;time complexity	Dong Zhou;Dan Luo;Ruqian Lu;Zhangang Han	2012	Theor. Comput. Sci.	10.1016/j.tcs.2012.01.010	mathematical optimization;combinatorics;computer science;calculus;mathematics;computational complexity theory;algorithm;statistics	Theory	28.280899817331598	3.306133605044524	141444
47368b0e030c65a53c02676ed5d21f7f5004425d	a multi-objective genetic algorithm based on quick sort	multiobjective programming;optimum pareto;programmation multiobjectif;time complexity;benchmark problem;algoritmo genetico;dominating set;multi objective genetic algorithm;complexite temps;theoretical analysis;algorithme genetique;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;evolutionary algorithm;complejidad tiempo;pareto optimum;optimo pareto;multi objective optimization problem;programacion multiobjetivo	The Multi-objective Genetic Algorithms (MOGA) based on Pareto Optimum have been widely applied to solve multi-objective optimal problems, mainly because of their ability to find a set of candidate solutions within a single run. In MOGAs, a non-dominated set is a set of candidate solutions, so it is very important to construct the non-dominated set efficiently. In this paper, the relation of individuals and their related features are discussed. It is proved that the individuals of an evolutionary population can be sorted by quick sort. We construct the non-dominated set of the evolutionary population with quick sort, and the time complexity of the construction is O(nlogn), compared to the previous best result of O(n 2 ) described in the popular NSGA-II [Deb, 2002]. We further propose a multi-objective genetic algorithm based on quick sort, and two benchmark problems are experimented. We show that the results of the experiments match to our theoretical analysis.	genetic algorithm;quicksort	Jinhua Zheng;Charles X. Ling;Zhongzhi Shi;Juan Xue;Xuyong Li	2004		10.1007/978-3-540-24840-8_13	adaptive sort;time complexity;mathematical optimization;counting sort;genetic algorithm;selection sort;dominating set;computer science;artificial intelligence;machine learning;sorting algorithm;evolutionary algorithm;comparison sort;tournament sort;mathematics;tree sort;algorithm;stooge sort	AI	25.826408393833393	1.2105103708162244	141465
49ac63072ab49e8fd3bcf8d6798415bfc333d476	design and analysis of maximum hopfield networks	lyapunov methods;convergence analysis;optimisation;convergence;computation time maximum hopfield networks binary maximum neuron model combinatorial optimization local minimum convergence maximum neural network convergence analysis energy function descent maximum neuron model optimal competitive hopfield model ochom lyapunov energy function n queens problem bipartite subgraph problem;neural networks neurons computer networks hopfield neural networks convergence computational modeling telecommunication computing helium minimization integrated circuit interconnections;hopfield network;combinatorial optimization problem;hopfield neural nets;energy function;computational complexity;large classes;neural network;computational complexity hopfield neural nets optimisation convergence lyapunov methods	Since McCulloch and Pitts presented a simplified neuron model (1943), several neuron models have been proposed. Among them, the binary maximum neuron model was introduced by Takefuji et al. and successfully applied to some combinatorial optimization problems. Takefuji et al. also presented a proof for the local minimum convergence of the maximum neural network. In this paper we discuss this convergence analysis and show that this model does not guarantee the descent of a large class of energy functions. We also propose a new maximum neuron model, the optimal competitive Hopfield model (OCHOM), that always guarantees and maximizes the decrease of any Lyapunov energy function. Funabiki et al. (1997, 1998) applied the maximum neural network for the n-queens problem and showed that this model presented the best overall performance among the existing neural networks for this problem. Lee et al. (1992) applied the maximum neural network for the bipartite subgraph problem showing that the solution quality was superior to that of the best existing algorithm. However, simulation results in the n-queens problem and in the bipartite subgraph problem show that the OCHOM is much superior to the maximum neural network in terms of the solution quality and the computation time.	algorithm;artificial neural network;biological neural networks;biological neuron model;central processing unit;combinatorial optimization;computation;convergence (action);descent;graph - visual representation;heuristic (computer science);heuristics;hopfield network;iteration;large;lyapunov fractal;mathematical optimization;maxima and minima;maximum cut;neural network simulation;parallel computing;rate of convergence;small;solutions;synchronization (computer science);time complexity;walter pitts	Gloria Galán Marín;José Muñoz-Pérez	2001	IEEE transactions on neural networks	10.1109/72.914527	mathematical optimization;convergence;types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;machine learning;computational complexity theory;hopfield network;artificial neural network	ML	30.636155618093028	3.8171266855071377	141699
04a467c121fedbf15b1dd7ca01c2a5248a3e400b	following the leader - particle dynamics in constricted pso	convergence;particle swarm optimization;stability analysis	We consider particle swarm optimization algorithm with a constriction coefficient and investigate particle dynamics without stagnation assumptions. We propose differential models of a particle following the swarm leader, while global best and personal best position are changing. We introduce three qualitative kinds of particles - a leader, a lazy follower and a sedulous follower with equations allowing quantitative investigation of parameter influence. This analysis constitutes an attempt to understand PSO dynamics and the choice of swarm parameters and inspires parameters adaptation.	particle swarm optimization	Jacek Kabzinski	2011		10.1007/978-3-642-23938-0_47	mathematical optimization;multi-swarm optimization;von neumann stability analysis;simulation;convergence;computer science;particle swarm optimization	Robotics	29.192171733274936	-4.8991296069785895	141808
4e774ea04dfc0ced9dd95ef343e15e3a2a65b08a	improving ant swarm optimization with embedded vaccination for optimum reducts generation	differential evolution;ant colony optimisation;classification algorithm;ant colony optimization;optimization technique;immune algorithm;rough set theory;differential evolution variant embedded vaccination optimum reduct generation particle swarm optimization hybrid ant swarm optimization algorithm pso aco algorithm classification accuracy np hard problem immune algorithm attribute reduction fitness value;particle swarm optimization optimization classification algorithms accuracy immune system genetic algorithms ant colony optimization;attribute reduction;np hard problem;accuracy;immunity;particle swarm optimizer;ant swarm optimization;computational complexity;particle swarm optimization;classification algorithms;immune system;genetic algorithm;genetic algorithms;optimization;classification accuracy;optimal algorithm;rough set theory ant colony optimisation artificial immune systems computational complexity particle swarm optimisation;particle swarm optimisation;artificial immune systems;ant swarm optimization rough reducts particle swarm optimization ant colony optimization immunity;rough reducts;hybrid algorithm	Ant Swarm Optimization refers to the hybridization of Particle Swarm Optimization (PSO) and Ant Colony Optimization (ACO) algorithms to enhance optimization performance. It is used in rough reducts calculation for identifying optimally significant attributes set. This paper proposes a hybrid ant swarm optimization algorithm by using immunity to discover better fitness value in optimizing rough reducts set. Unlike a conventional PSO/ACO algorithm, this hybrid algorithm shows improvement of the classification accuracy in its generated rough reducts to solve NP-Hard problem. This paper has evaluated the immune algorithm in 12 common benchmark dataset to evaluate the performance of rough reducts-based on attribute reduction. The results show that immune ant swarm algorithm is very competitive in terms of fitness value, number of iterations, and classification accuracy to produce a better optimization technique and more accurate results in rough reducts generation. The results also show that immune ant swarm optimization provides a slight increase in accuracy when compared to the differential evolution variant.	ant colony optimization algorithms;benchmark (computing);differential evolution;embedded system;hybrid algorithm;iteration;mathematical optimization;np-hardness;particle swarm optimization;phase-shift oscillator;program optimization;rough set	Lustiana Pratiwi;Yun-Huoy Choo;Azah Kamilah Muda;Noor Azilah Muda	2011	2011 11th International Conference on Hybrid Intelligent Systems (HIS)	10.1109/HIS.2011.6122147	mathematical optimization;multi-swarm optimization;meta-optimization;artificial intelligence;machine learning;mathematics;metaheuristic	AI	26.181759351619313	-2.722821091473434	141879
be4f402e47f3b4c1e9839320606d80d944dfe831	constrained multiobjective optimization immune algorithm: convergence and application	comparative analysis;convergence;immune regulation;clonal selection;optimization technique;immune algorithm;humoral immunity;constrained multiobjective optimization;constraint handling;multiobjective optimization;humoral immune;immune optimization algorithm;pareto optimal solution;optimal algorithm;pareto optimality	A new optimization technique, multiobjective optimization immune algorithm for constrained nonlinear multiobjective optimization problems is designed based on immune metaphors of humoral immune and Pareto optimality, especially, some interactive metaphors between antigen population and antibody population. It includes four main mechanisms:(1)constraint-handling operation that provides an alternative feasible solution set for rapidly finding Pareto optimal solutions; (2)antibody evolution associated with clonal selection principle and ideas of immune regulation; competition and update of antigens that induces evolution of antibody populations; (3)memory pool used for collecting the best solutions of evolving antibody populations. Convergence is proven through Markov theory as well as demonstrated by the experiment results. Comparative analysis and applications illustrate that it is effective and valuable.	algorithm;multi-objective optimization;optimization problem	Zhuhong Zhang	2006	Computers & Mathematics with Applications	10.1016/j.camwa.2006.10.016	qualitative comparative analysis;mathematical optimization;convergence;multi-objective optimization;mathematics;mathematical economics	EDA	26.333992918058737	-6.228404904271579	142144
a8442eab6d0ac42c223d5476e2b4156155cc5862	learning cooperative tsk-0 fuzzy rules using fast local search algorithms	evolutionary fuzzy systems;fuzzy modeling	This paper presents an adaptation of the COR methodology to derive the rule base in TSK-type linguistic fuzzy rule-based systems. In particular, the work adapts an existing local search algorithm for Mamdani rules which was shown to find the best solutions, whilst reducing the number of evaluations in the learning process.	chain-of-responsibility pattern;fuzzy rule;local search (optimization);rule-based system;search algorithm;while	Javier Cózar;Luis de la Ossa;Jose Miguel Puerta	2011		10.1007/978-3-642-25274-7_36	fuzzy logic;defuzzification;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy classification;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;data mining;mathematics;fuzzy associative matrix;fuzzy set operations	AI	25.075928467533117	-7.420644654368503	142183
6d00ae5461ee1c68994d631f3edd7b9db4a816a5	selection of reduction parameters for complex plant mimo lti models using the evolutionary algorithm	frequency domain fd;frequency weighted fw;evolutionary algorithm;model order reduction	This paper discusses the optimal selection of reduction parameters for complex plant models for the Frequency Weighted and the Frequency Domain method together with the Evolutionary Algorithm. The algorithms presented here enable precise reduction of linear time invariant (LTI), multi-input and multi-output (MIMO) models and are particularly useful for models in which the individual channels differ significantly from each other and are characterized by a specific scope of adequacy for the frequency domain. A two-level reduction algorithm was introduced in order to shorten the computation time of the reduction of very high-order models. The algorithms are then applied to the reduction of the models of the BP-1150 steam boiler subsystems.	evolutionary algorithm;mimo	Marek Rydel;Wlodzimierz Stanislawski	2017	Mathematics and Computers in Simulation	10.1016/j.matcom.2017.03.005	mathematical optimization;evolutionary algorithm;control theory	NLP	32.81083611282678	-6.103412375258602	142500
a7e3ed3efc665126d02468976a9b0d49f97a3133	a geometric approach to anytime constraint solving for tcsps	algoritmo busqueda;algorithm analysis;algorithme recherche;efficient algorithm;exact solution;search algorithm;constraint satisfaction;geometric approach;resolucion problema;satisfaction contrainte;temporal constraints;approximate solution;raisonnement temporel;algorithme evolutionniste;constraint solving;algoritmo evolucionista;analyse algorithme;satisfaccion restriccion;evolutionary algorithm;analisis algoritmo;problem solving;resolution probleme;temporal reasoning	Temporal constraint satisfaction problems (TCSPs) are typically modelled as graphs or networks. Efficient algorithms are only available to find solutions for problems with limited topology. In this paper, we propose constraint geometry as an alternative approach to modeling TCSPs. Finding solutions to a TCSP is transformed into a search problem in the corresponding n-dimensional space. Violations of constriants can be measured in terms of spatial distances. As a result, approximate solutions can be identified when it is impossible or impractical to find exact solutions. A real-numbered evolutionary algorithm with special mutation operators has been designed to solve the general class of TCSPs. It can render approximate solutions at any time and improve the solution quality if given more time. Experiments on hundreds of randomly generated problems with representative parameters showed that the algorithm is more efficient and robust in comparison with the path-consistency algorithm.	anytime algorithm;constraint satisfaction problem	Hong-ming Yeh;Jane Yung-jen Hsu;Han-Shen Huang	1998		10.1007/BFb0095284	mathematical optimization;combinatorics;constraint satisfaction;computer science;artificial intelligence;evolutionary algorithm;mathematics;algorithm;search algorithm	AI	26.77253913215258	3.1740515564964213	142685
fdb477f2721a8af2283e351f8e11dba095e75eb3	global optimization of multimodal deceptive functions		Local search algorithms operating in high-dimensional and multimodal search spaces often suffer from getting trapped in a local optima, therefore requiring many restarts. Even with multiple restarts, their search efficiency critically depends on the choice of the neighborhood structure. In this paper we propose an approach in which the need for the restarts is exploited to improve the neighborhood definitions. Namely, a graph clustering based linkage detection method is used to mine the information from several runs, in order to extract variable dependencies and update the neighborhood structure, variation operators accordingly. We show that the adaptive neighborhood structure approach enables the efficient solving of challenging global optimization problems that are both deceptive and multimodal.	global optimization;multimodal interaction	David Iclanzan	2014		10.1007/978-3-662-44320-0_13	operator (computer programming);local optimum;quantum annealing;multimodal search;mathematical optimization;global optimization;simulated annealing;local search (optimization);clustering coefficient;computer science	NLP	25.01802449453605	-3.596343392588728	142722
7b3111686e8401f2d5e222a3dbd1652da08f9175	rrt*-quick: a motion planning algorithm with faster convergence rate		This paper proposes RRT*-Quick as an improved version of Rapidly-exploring Random Tree Star (RRT*). The proposed RRT*-Quick utilizes one of the characteristics of RRT* that nodes in local area tend to share common parents. It uses the ancestor nodes to efficiently enlarge the pool of parent candidates for a faster convergence rate. Branch-and-bound, one of the key extensions of RRT*, prunes the unuseful nodes from the tree to help the search algorithm focus on improving solutions. Since the proposed algorithm generates the initial solution with a lower cost, it can prune unuseful nodes earlier than the conventional RRT*.	algorithm;automated planning and scheduling;motion planning	In-Bae Jeong;Seung-Jae Lee;Jong-Hwan Kim	2014		10.1007/978-3-319-16841-8_7	random tree;computer science;rate of convergence;motion planning;algorithm;search algorithm;ancestor	Robotics	29.839328401478973	-2.5245964938591228	143024
5078cab87125e3ef6f00360f4f293fbdf3fb6982	computational methods for the innovative design of electrical devices		Integrated Computer Models of 3-D Comb Drive Electrostatic MEMS Structures .-Multiobjective Design Optimization of Slotless PM Motors Using Genetic.- Algorithms based on Analytical Field Calculation.- The FEM parallel simulation with look up tables applied to the brushless DC motor optimization.- Fast algorithms for the design of complex-shape devices in electromechanics.- Optimization of Wound Rotor Synchronous Generators based on Genetic Algorithms.- Simple and Fast Algorithms for the Optimal Design of Complex Electrical Machines.-The flock of starlings optimization: influence of topological rules on the collective behavior of swarm intelligence.- Multilevel Data Classification and Function Approximation Using Hierarchical Neural Networks.- Parametric identification of a three-phase machine with genetic algorithms.- Ridge Polynomial Neural Network for Non-Destructive Eddy Current Evaluation.- Structural-Systematic Approach in Magnetic Separators Design.- Weight Reduction of Electromagnet in Magnetic Levitation System for Contactless Delivery Application.- Genetic algorithm algorithm applied in optimal design of PM disc motor using specific power as objective.- Magnetically Nonlinear Iron Core Characteristics of Transformers Determined by Differential Evolution.- Different Methods for Computational Electromagnetics: their Characteristics and Typical Pratical Applications.-Methods of homogenization of laminated structures.-Application examples.	computation		2011		10.1007/978-3-642-16225-1	control engineering;electronic engineering;engineering;electrical engineering	HCI	34.006581703269774	-4.974012278099535	143089
0dbf5b54e8ae1d4f12cd302412e2e1c4b1486e95	multiagent visual area coverage using a new genetic algorithm selection scheme	multiagent system;visual areas;exploracion visual;problema np duro;algoritmo genetico;np hard problem;probleme recouvrement;recherche visuelle;problema recubrimiento;probleme np difficile;scheduling;visual search;multiagent;algorithme genetique;genetic algorithm;visual area;covering problems;covering problem;sistema multiagente;ordonnancement;reglamento;systeme multiagent	Using genetic algorithms (GA) for solving NP-hard problems is becoming more and more frequent. This paper presents a use of GA with a new selection approach called the queen GA. The main idea is not to select both parents from the entire population, but to create a subgroup of better solutions (the queen cohort), and to use at least one of its members in each performed crossover. We demonstrate the use of the queen GA for the problem of repositioning observers across a polygonal area with obstacles in order to maximize the visual area coverage for a given time horizon. The queen GA gives superior results over a GA with different selection methods (i.e. proportion, ranking and tournament) at the 0.01 significance level. These comparative results were duplicated when elitism was included.	agent-based model;algorithm selection;genetic algorithm	Helman Stern;Yoash Chassidim;Moshe Zofi	2006	European Journal of Operational Research	10.1016/j.ejor.2005.02.078	mathematical optimization;genetic algorithm;visual search;covering problems;computer science;artificial intelligence;np-hard;operations research;scheduling;algorithm	Robotics	25.436781731129187	1.4574631566146545	143117
deea4dc81ff1a200f91c6d6c05b9b6618d02f31b	multimodal estimation of distribution algorithms	estimation theory gaussian distribution optimisation statistical analysis;multimodal optimization estimation of distribution algorithm eda cluster sizing strategy gaussian distribution cauchy distribution probability;sensitivity;probability multimodal optimization estimation of distribution algorithm eda cluster sizing strategy gaussian distribution cauchy distribution;estimation;heuristic algorithms;statistics;clustering algorithms;optimization;sociology statistics optimization estimation clustering algorithms heuristic algorithms sensitivity;niching estimation of distribution algorithm eda multimodal optimization multiple global optima;sociology;statistical analysis estimation theory gaussian distribution optimisation;estimation of distribution algorithm eda multimodal optimization multiple global optima niching	Taking the advantage of estimation of distribution algorithms (EDAs) in preserving high diversity, this paper proposes a multimodal EDA. Integrated with clustering strategies for crowding and speciation, two versions of this algorithm are developed, which operate at the niche level. Then these two algorithms are equipped with three distinctive techniques: 1) a dynamic cluster sizing strategy; 2) an alternative utilization of Gaussian and Cauchy distributions to generate offspring; and 3) an adaptive local search. The dynamic cluster sizing affords a potential balance between exploration and exploitation and reduces the sensitivity to the cluster size in the niching methods. Taking advantages of Gaussian and Cauchy distributions, we generate the offspring at the niche level through alternatively using these two distributions. Such utilization can also potentially offer a balance between exploration and exploitation. Further, solution accuracy is enhanced through a new local search scheme probabilistically conducted around seeds of niches with probabilities determined self-adaptively according to fitness values of these seeds. Extensive experiments conducted on 20 benchmark multimodal problems confirm that both algorithms can achieve competitive performance compared with several state-of-the-art multimodal algorithms, which is supported by nonparametric tests. Especially, the proposed algorithms are very promising for complex problems with many local optima.	benchmark (computing);cluster analysis;crowding;estimation of distribution algorithm;evolutionary multimodal optimization;existential quantification;experiment;exploit (computer security);local optimum;local search (optimization);mathematical optimization;multimodal interaction;name;niche blogging;normal statistical distribution;plant seeds;probability;the offspring;version;elongin;statistical cluster	Qiang Yang;Wei-neng Chen;Yun Li;C. L. Philip Chen;Xiang-Min Xu;Jun Zhang	2017	IEEE Transactions on Cybernetics	10.1109/TCYB.2016.2523000	mathematical optimization;estimation;estimation of distribution algorithm;sensitivity;machine learning;mathematics;cluster analysis;statistics	DB	28.508372849218702	-6.988992613493097	143137
ce46df7943831b4aef12ecabcbe5b136c7897ebb	a multiagent quantum evolutionary algorithm for global numerical optimization	evolutionary programming;numerical optimization;optimization problem;quantum computer;global optimization;evolutionary algorithm	In this paper, a novel kind of algorithm, multiagent quantum evolutionary algorithm (MAQEA), is proposed based on multiagent, evolutionary programming and quantum computation. An agent represents a candidate solution for optimization problem. All agents are presented by quantum chromosome, whose core lies on the concept and principles of quantum computing, live in table environment. Each agent competes and cooperates with its neighbors in order to increase its competitive ability. Quantum computation mechanics is employed to accelerate evolution process. The result of experiments shows that MAQEA has a strong ability of global optimization and high convergence speed.	agent-based model;evolutionary algorithm;mathematical optimization;quantum	Chaoyong Qin;Jianguo Zheng;Jiyu Lai	2007		10.1007/978-3-540-74771-0_43	evolutionary programming;mathematical optimization;meta-optimization;interactive evolutionary computation;human-based evolutionary computation;artificial intelligence;theoretical computer science;evolutionary algorithm;mathematics;imperialist competitive algorithm;metaheuristic;evolutionary computation	EDA	26.240412940424182	-5.472370900152288	143308
76e0b66b716cddfa353709a53e50415703dcb736	an effective chaos-based image watermarking scheme using fractal coding	initial condition;image watermarking	The image watermarking technology is a technique of embedding hidden data in an original image. In this paper, a new watermarking method for embedding watermark bits based on Chaos-Fractal Coding is given. A chaotic signal is defined as being deterministic, pseudo periodic and presenting sensitivity to initial conditions. Combining a chaos system with Fractal Coding plays an important role in the security, invisibility and capacity of the proposed scheme. The main idea of the new proposed algorithm for coding is to determine a set of selective blocks for steady embedding. Simulation results show that the CFC algorithm (Chaos-Fractal Coding) has a confident capacity. The embedding technique that proposed in this paper is quite general, and can be applied to the extracting scheme with demanded changes.	arnold;arnold's cat map;authentication;deterministic algorithm;digital watermarking;encryption;fractal;image processing;initial condition;pixel;public-key cryptography;simulation	Mohammad Reza Keyvanpour;Farnoosh Merrikh-Bayat	2011		10.1016/j.procs.2010.12.016	computer vision;discrete mathematics;computer science;theoretical computer science;mathematics;initial value problem	EDA	38.65472895340637	-8.576857703706587	143359
3b57b1ff62f63e327f3c2e5fd9aa91d268c67da6	when ants attack: ant algorithms for constraint satisfaction problems	ant algorithm;constraint satisfaction problems;ant algorithms;constraint satisfaction problem;state transition;evolutionary computing	We describe an ant algorithm for solving constraint problems (Solnon 2002, IEEE Transactions on Evolutionary Computation 6(4): 347–357). We devise a number of variants and carry out experiments. Our preliminary results suggest that the best way to deposit pheromone and the best heuristics for state transitions may differ from current practice	algorithm;ant colony optimization algorithms;constraint graph;constraint satisfaction;cryptographic service provider;encode;experiment;heuristic (computer science);ieee transactions on evolutionary computation;infinite loop;java;local search (optimization);pentium 4;programmer;random-access memory;solver;vehicle routing problem;word lists by frequency	Finbarr Tarrant;Derek G. Bridge	2005	Artificial Intelligence Review	10.1007/s10462-005-9005-7	mathematical optimization;ac-3 algorithm;constraint satisfaction;constraint learning;computer science;constraint graph;theoretical computer science;machine learning;constraint satisfaction dual problem;complexity of constraint satisfaction;constraint satisfaction problem;hybrid algorithm;local consistency;backtracking;evolutionary computation	AI	24.71331101397609	1.1657419231718895	143632
6bac3282b338f22be07f9d22d20aad32267f2065	noisy source recognition in multi noise plants by differential evolution	optimisation;evolutionary computation;noise genetic algorithms vectors statistics optimization monitoring;noisy source recognition swl sound power level minimized variation square method monitoring points exact spl trial sound pressure level trail noise technique multinoise plants noisy source location identification real life optimization problems de algorithm differential evolution algorithm;industrial plants;source separation evolutionary computation industrial plants noise abatement optimisation;noise abatement;noise identification differential evolution mutation multi noise plants;source separation	Since last few decades differential evolution algorithm (DE) has been successfully applied for solving many real life optimization problems. In this paper DE is applied to identifying the location of noisy sources in a multi noise plants. A trail noise technique is used to obtain the variation between trial sound pressure level (SPL) and exact SPL at monitoring points and then DE is employed in conjunction with the method of minimized variation square in seeking for the best locations and sound power level (SWLs). The results reveal that the significant locations and SWLs of noises can be precisely identified by DE.	algorithm;differential evolution;mathematical optimization;real life	Pravesh Kumar Tomar;Millie Pant	2013	2013 IEEE Symposium on Swarm Intelligence (SIS)	10.1109/SIS.2013.6615189	electronic engineering;speech recognition;engineering;noise measurement;machine learning	Logic	33.1383317668507	-3.920995998939922	143640
8217f953605c46af62245998bd293853f9643ccd	efficient player selection strategy based diversified particle swarm optimization algorithm for global optimization		Sport is one of the activities of human being where cooperative, competitive, self-learning and interactive environment helps in the overall improvement of the performance. These learning processes are very effective to regulate the players in a good direction as well as to enhance their capability of exploring the new techniques. Particle Swarm Optimization (PSO) is a popular stochastic optimization algorithm, used for solving real-world engineering problems. However, it usually suffers from local confinement and easily loses its diversity. In this paper, we have integrated the properties of sports with PSO algorithm and proposed an efficient player selection strategy based diversified PSO (EPS-dPSO), which improves the fitness and robustness of the technique without compromising the computational complexity of the algorithm. The properties of player selection is adopted to enhance the diversity within the search phase as well as to incorporate intense searching of the space. We have comprehensively evaluated the performance of proposed EPS-dPSO by applying it on standard benchmark problems. Experimental result shows that it not only tracks the global optimum within the small search interval but also able to obtain good result for large and asymmetrical search space and also insensitive to initialization of the problems. Further, tests are carried out on the benchmark functions from CEC2005, the large dimensional problems of CEC2008 and some real world problems from CEC2011. All the experimental results indicate the effectiveness and efficiency of the proposed EPS-dPSO compared to other traditional algorithms. ∗Corresponding authors Email address: sumitra.mu@gmail.comb ( Sumitra Mukhopadhyayb) Preprint submitted to Journal of LTEX Templates February 17, 2017	algorithm;benchmark (computing);computational complexity theory;email;encapsulated postscript;global optimization;mathematical optimization;particle swarm optimization;program optimization;stochastic optimization	Prativa Agarwalla;Sumitra Mukhopadhyay	2017	Inf. Sci.	10.1016/j.ins.2017.02.027	mathematical optimization;multi-swarm optimization;simulation;artificial intelligence;machine learning	AI	26.770360284887026	-3.5561942397910418	143668
04ca377cb04c935710ebcf7c45d211306594d4f8	reduction of artificial bee colony algorithm for global optimization	metaheuristics;reduction;artificial bee colony algorithm;global optimization	This paper presents a reduction of artificial bee colony algorithm for global optimization. Artificial bee colony algorithm is an optimization technique which refers to the behavior of honeybee swarms, and a multi-point search approach which finds a best solution using multiple bees. For avoiding local minima, a number of bees are initially prepared and their positions are updated by artificial bee colony algorithm. Bees sequentially reduce to reach a predetermined number of them grounded in the evaluation value and artificial bee colony algorithm continues until the termination condition is met. In order to show the effectiveness of the proposed algorithm, we examine the best value by using test functions compared to existing algorithms. Furthermore the influence of best value on the initial number of bees for our algorithm is discussed. & 2014 Elsevier B.V. All rights reserved.	artificial bee colony algorithm;distribution (mathematics);global optimization;mathematical optimization;maxima and minima;swarm intelligence	Michiharu Maeda;Shinya Tsuda	2015	Neurocomputing	10.1016/j.neucom.2012.06.066	mathematical optimization;reduction;computer science;artificial intelligence;machine learning;bees algorithm;artificial bee colony algorithm;metaheuristic;global optimization	AI	27.38103090367601	-3.3809009913825987	143904
96fde554168294d7132df448ece49ce8d2f0aa31	optimization of fuzzy reasoning by genetic algorithm using variable bit-selection probability	genetic algorithm	Genetic algorithms (GA) are known as optimization algorithms that can avoid convergence to local solutions by global search in solution space. However, especially in the field of control, when fuzzy reasoning is to be optimized, global optimal solutions are not necessarily required. In many cases, local solutions obtained at low cost are preferable. For this purpose, GAs are used in combination with other optimization algorithms, for example, steepest descent or pattern search. In so doing, however, there is a problem of differently representing the parameters to be optimized. Besides, complicated software is required to implement such combined methods. A method is proposed in this paper to provide locality in search space by varying the bit-selection probability in GA-based mutations in accord with learning progress. This makes possible local search in the vicinity of good solutions found in the course of optimization, resulting in rapid finding of local optimal solutions. © 1999 Scripta Technica, Syst Comp Jpn, 30(6): 5463, 1999	approximation;autonomous robot;digi-comp i;feasible region;fitness function;genetic algorithm;gradient descent;local search (optimization);locality of reference;mathematical optimization;mobile robot;pattern search (optimization);software release life cycle	Makoto Ohki;Toshiaki Moriyama;Masaaki Ohkita	1999	Systems and Computers in Japan	10.1002/(SICI)1520-684X(19990615)30:6%3C54::AID-SCJ6%3E3.0.CO;2-3	meta-optimization;genetic algorithm;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;fuzzy set operations;population-based incremental learning	AI	27.60610918790384	-4.340238101733253	144051
2250175acdcccf85b5e5ae441828b3b9718eb884	useful diversity via multiploidy	hamming codes genetic algorithms;hamming codes;lost material recovery diversity multiploid genetic algorithm gene candidates genotype dominance mechanism encoded choice phenotype attractive suboptima hamming distance;genetics;genetic algorithm;genetic algorithms;biological cells diversity reception testing artificial intelligence genetic algorithms convergence costs computer science organisms genetic mutations	AbstTactA multiploid genetic algorithm (GA) incorporates several candidates for each gene within a single genotype, and uses some form of dominance mechanism (most simply, an encoded choice) to decide which choice of each gene is active in the phenotype. We explore a simple multiploid model. Investigation with two simplified test problems is reported, respectively suggesting certain strengths and weaknesses of employing multiploidy. In particular, multiploidy appears useful in cases where attractive suboptima are profoundly Hamming distant from the true optimum, thus requiring a GA to recover substantial lost material in order to recover from suboptima. This is distinct from cases where a GA’s difficulty in solving a problem is, for example, more concerned with appropriately combining genetic material than finding it.	genetic algorithm;norm (social);software release life cycle;window function	Emma Collingwood;David W. Corne;Peter Ross	1996		10.1109/ICEC.1996.542705	biology;bioinformatics;artificial intelligence;genetics	NLP	26.57362889554147	-8.766396768645972	144188
f18640b6bdfb9ea58692f61de3fa44d95cfbff16	prediction of short-term voltage instability using a digital faster than real-time replica		Predictive analysis of post fault system dynamic behavior can be a vital resource for better control and reliability improvement of the overall system. This article presents methods for predictive analysis of Fault Induced Dynamic Voltage Recovery (FIDVR) event using a faster than real-time digital replica of a power system. The methods proposed include use of quick algorithms for detection of FIDVR events and metrics for predicting dynamic behavior of the power system impacted by the detected FIDVR event. We show that, using a digital faster than real-time replica, the FIDVR event can be detected in required time and that the transient voltage deviation index (TVDI) can be quickly calculated.		Arun Joseph;Milos Cvetkovic;Peter Palensky	2018	IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2018.8592818		Robotics	36.250509345126034	0.18165160359033244	144417
f789e0f663b2359b7c9c3a5571893ef2ccd5776f	an energy-aware algorithm for large scale foraging systems		The foraging task is one of the canonical testbeds for cooperative robotics, in which a collection of coordinated robots have to find and transport one or more objects to one or more specific storage points. Swarm robotics has been widely considered in such situations, due to its strengths such as robustness, simplicity and scalability. Typical multi-robot foraging systems currently consider tens to hundreds of agents. This paper presents a new algorithm called Energy-aware Cooperative Switching Algorithm for Foraging (EC-SAF) that manages thousands of robots. We investigate therefore the scalability of EC-SAF algorithm and the parameters that can affect energy efficiency overtime. Results indicate that EC-SAF is scalable and effective in reducing swarm energy consumption compared to an energy-aware version of the reference well-known c-marking algorithm (Ec-marking).	algorithm;item unique identification;performance;proposed directive on the patentability of computer-implemented inventions;pseudorandomness;robot;scalability;shortest path problem;store and forward;swarm robotics	Ouarda Zedadra;Hamid Seridi;Nicolas Jouandeau;Giancarlo Fortino	2015	Scalable Computing: Practice and Experience		swarm robotics;simulation;engineering;artificial intelligence;communication	Robotics	31.845356438508027	-2.717486165083689	144507
98549a99b78ef549b1040951bbe5538695e5f3e6	color image encryption using three-dimensional sine icmic modulation map and dna sequence operations		Derived from Sine map and iterative chaotic map with infinite collapse (ICMIC), a three-dimensional hyperchaotic Sine ICMIC modulation map (3D-SIMM) is proposed based on a close-loop modulation coupling (CMC) method. Based on this map, a novel color image encryption algorithm is designed by employing a hybrid model of multidirectional circular permutation and deoxyribonucleic acid (DNA) masking. In this scheme, the pixel positions of image are scrambled by multidirectional circular permutation, and the pixel values are substituted by DNA sequence operations. The simulation results and security analysis show that the algorithm has good encryption effect and strong key sensitivity, and can resist brute-force, statistical, differential, known-plaintext and chosen-plaintext attacks.	color image;encryption;modulation	Wenhao Liu;Kehui Sun;Yi He;Mengyao Yu	2017	I. J. Bifurcation and Chaos	10.1142/S0218127417501711	mathematics;control theory;modulation;pixel;color image;encryption;masking (art);sine	ML	38.64261322491103	-8.694287317029003	144519
586bef03a036956581b1e319fabecad2b1b70481	impact of commutative and non-commutative functions on symbolic regression with acgp	adaptable constrained gp methodology;evolutionary computation;parent children heuristics;pruned nonuniform search commutative functions noncommutative functions symbolic regression genetic programming evolutionary methods constrained gp methodology position fixed heuristics position independent heuristics adaptable constrained gp methodology parent child heuristics parent children heuristics acgp methodology low order local heuristics evolutionary search;low order local heuristics;genetic programming;evolutionary search;position fixed heuristics;acgp methodology;constrained gp methodology;commutative functions;search problems evolutionary computation genetic algorithms regression analysis;sociology statistics labeling search problems probabilistic logic equations genetic programming;heuristics genetic programming symbolic regression;statistics;position independent heuristics;evolutionary methods;symbolic regression;genetic algorithms;regression analysis;search problems;heuristics;probabilistic logic;noncommutative functions;parent child heuristics;pruned nonuniform search;sociology;labeling	Genetic Programming, as other evolutionary methods, uses selection to drive its search toward better solutions, but its search operators are uninformed and perform uniform search. Constrained GP methodology changes this exploration to pruned non-uniform search, skipping some representation subspaces and giving preferences to others, according to provided heuristics. The heuristics are position-fixed or position-independent and are just preferences on some specific labeling. Adaptable Constrained GP ACGP is a methodology for discovery of such useful heuristics. Both methodologies have previously demonstrated their surprising capabilities using only parent-child and parent-children heuristics. This paper illustrates how the ACGP methodology applies to symbolic regression; demonstrate the power of low-order local heuristics, while also exploring the differences in evolutionary search between commutative and non-commutative functions.	evolutionary algorithm;genetic programming;heuristic (computer science);position-independent code;symbolic regression	Cezary Z. Janikow;John W. Aleshunas	2013	2013 IEEE Congress on Evolutionary Computation	10.1109/CEC.2013.6557842	genetic programming;mathematical optimization;labeling theory;combinatorics;genetic algorithm;computer science;artificial intelligence;social heuristics;heuristics;machine learning;mathematics;probabilistic logic;regression analysis;evolutionary computation	AI	27.803744019621956	-7.314735841118282	144618
edc5e000ff33366e5ae38bca2623a1e7faa18199	optimized parameter settings of binary bat algorithm for solving function optimization problems		The bat algorithm (BA) is a new bionic intelligent optimization algorithm to simulate the foraging behavior and the echolocation principle of the bats. The parameter initialization of the discussed binary bat algorithm (BBA) has important influence on the convergence speed, convergence precision, and good global searching ability of the BBA. The convergence speed and algorithm searching precision are determined by the pulse of loudness and pulse rate. The simulation experiments are carried out by using the six typical test functions to discuss this influence. The simulation results show that the convergence speed of the BBA is relatively sensitive to the setting of the algorithm parameters. The convergence precision reduces when increasing the rate of bat transmitted pulse alone and the convergence speed increases the launch loudness alone. The proper combination of BBA parameters (the rate of bat transmitted pulse and the launch loudness) can flexibly improve the algorithm’s convergence velocity and improve the accuracy of the searched solutions.	bat algorithm;program optimization	Xiao-Xu Ma;Jie-Sheng Wang	2018	J. Electrical and Computer Engineering	10.1155/2018/3847951	electronic engineering;bat algorithm;mathematical optimization;initialization;loudness;pulse (signal processing);binary number;human echolocation;computer science;optimization problem;convergence (routing)	Theory	30.318587706291414	-4.287682068216372	144746
1d7d7c8be22f53e0b1d777b3ec85da0249ebb51e	optimal design of fir fractional order differentiator using cuckoo search algorithm	levy flight;meta heuristics;fractional order differentiator;cuckoo search algorithm;genetic algorithm	A novel weighted least square (WLS) fitness function is adopted.The proposed method outperforms the GA in terms magnitude and phase error.The proposed method is superior to the interpolation based methods.Fast convergence rate is achieved. In this paper, a new meta-heuristic optimization algorithm, called cuckoo search algorithm (CSA) is applied to determine the optimal coefficients of the finite impulse response-fractional order differentiator (FIR-FOD) problem. CSA is based on lifestyle and unique parasitic behavior in egg laying and breeding of some cuckoo species along with Levy flight behavior of some birds and fruit flies. The CSA is capable of solving linear and nonlinear optimization problems. The proposed CSA method prevents the local minima problem encountered in conventional FIR-FOD design method. A novel weighted least square (WLS) fitness function is adopted to improve the response of the FOD to a great extent. The proposed CSA based method has alleviated from inherent drawbacks of premature convergence and stagnation unlike genetic algorithm (GA). To verify the effectiveness of the proposed FIR-FOD based on the cuckoo search algorithm, different set of initial population is tested by simulation. Simulation results affirm that the proposed fractional order differentiator design approach using CSA outperforms the genetic algorithm in terms design accuracy (magnitude and phase error), fast convergence rate and optimal solution. The simulation results confirmed that the proposed FOD using CSA outperforms the FOD designed using evolutionary algorithm like GA and conventional FOD design methods such as radial basis function (RBF) interpolation method and DCT interpolation method.	cuckoo search;differentiator;finite impulse response;optimal design;search algorithm	Manjeet Kumar;Tarun Kumar Rawat	2015	Expert Syst. Appl.	10.1016/j.eswa.2014.12.020	mathematical optimization;genetic algorithm;lévy flight;computer science;artificial intelligence;control theory;mathematics;metaheuristic	ML	31.03698631834995	-4.938244402629283	145016
d4877cf88638646f81cca64668f33c9a16232da3	the particle swarm differential evolution algorithm for ecological sensor network coverage optimization	differential evolution;ecological sensor network;particle swarm optimization;coverage optimization;hybrid algorithm	The problem of coverage optimization is the challengingly important and key part in the research and application of ecology sensor network related with the ecological monitoring of Poyang Lake. A modified differential evolution algorithm (PSI-DE) combined with particle swarm intelligence is proposed to solve the coverage optimization problem. First, an improved version of the mutation rule combined with self-cognitive and social-cognitive items is introduced. Then, the influence on the coverage optimization performance of the PSI-DE algorithm brought by the five factors – namely, population size, number of iterations, sensing radius size, raster size, and number of nodes – is discussed and analyzed. The statistical results about the best coverage rate, average coverage rate, worst coverage rate, and variance are respectively obtained through a lot of simulation experiments. A series of the coverage rate curves, the line chart, and the node layout are drawn in this paper, and finally, the figures and the statistical results are proven to confirm each other.	algorithm;differential evolution;ecology;experiment;iteration;mathematical optimization;optimization problem;particle swarm optimization;simulation;swarm intelligence	Xing Xu;Na Hu;Weiqin Ying;Yu Wu;Yang Zhou	2016	J. Intelligent Systems	10.1515/jisys-2014-0133	mathematical optimization;multi-swarm optimization;meta-optimization;imperialist competitive algorithm;metaheuristic	Mobile	28.757179193195004	-3.0399013463953803	145036
b66d384ee8c3c295f371c09f0ae609b72b063332	universal prediction of individual binary sequences in the presence of noise	individual sequence;binary sequence;noise binary sequences prediction theory reviews probability;probability;additive noise;prediction theory;probability binary sequences universal prediction noisy observations performance evaluation general loss function data corrupting noise process binary valued process bitwise xor real valued additive noise past sequence incomplete information experts;loss function;binary sequences;reviews;noise	The problem of predicting the next outcome of an individual binary sequence, based on noisy observations of the past, is considered. The goal of the predictor is to perform, for each individual sequence, “almost” as well as the best in a set of experts, where performance is evaluated using a general loss function. A comprehensive approach to prediction in this noisy setting is presented and proven generally efficient under appropriate conditions. As an illustration of the applicability of the approach suggested for concrete situations, two important special cases are explicitly treated. The first is the case where the data-corrupting noise process is binary-valued (where the observed bit is the bitwiseXOR of the clean bit and the noise bit). The second case is that of real-valued additive noise. It is shown that even in this more challenging situation, where the information available to the predictor regarding the past sequence is incomplete, a predictor can be guaranteed to successfully compete with a whole set of experts in considerably strong senses.	additive white gaussian noise;binary data;bitstream;kerrison predictor;loss function;utility functions on indivisible goods	Tsachy Weissman;Neri Merhav	2001	IEEE Trans. Information Theory	10.1109/18.945240	noise;machine learning;probability;data mining;pseudorandom binary sequence;mathematics;statistics;loss function	Theory	36.694096258222736	-0.39520996529933405	145131
90269df988a60b4db8f98ebcdfa089954ed0d635	curvature flight path for particle swarm optimisation	geometry;multi dimensional ellipsoid;curvature flight path;particle swarm optimisation	An optimisation is a process of finding maxima or minima of the objective function. Particle Swarm Optimisation (PSO) is a nature-inspired, meta-heuristic, black box optimisation algorithm used to search for global minimum or maximum in the solution space. The sampling strategy in this algorithm mimics the flying pattern of a swarm, where each sample is generated randomly according to uniform distribution among three different locations, which marks the current particle location, the individual best found location, and the best found location for the entire swam over all generation. The PSO has known disadvantage of premature convergence in problems with high correlated design variables (high epistatis). However, there is limited research conducted in finding the main reason why the algorithm fails to locate better solutions in these problems. In this paper, we propose to change the traditional triangular flight trajectory of PSO to an elliptical flight path. The new flying method is tested and compared with the traditional triangular flight trajectory of PSO on five high epistatis benchmark problems. Our results show that the samples generated from the elliptical flight path are generally better than the traditional triangular flight trajectory of PSO in term of average fitness and the fitness of best found solution.	algorithm;benchmark (computing);black box;feasible region;heuristic;loss function;mathematical optimization;maxima and minima;optimization problem;particle swarm optimization;premature convergence;randomness;sampling (signal processing)	Cheng Wai Kheng;Day Chyi Ku;Hui Fuang Ng;Mahmoud Khattab;Siang Yew Chong	2016		10.1145/2908812.2908840	mathematical optimization;simulation;mathematics;geometry	AI	29.251549037451902	-3.3419438974257587	145175
c6aacb107b0d5b0e13493ccdad22e81301c715f8	expensive multiobjective optimization by moea/d with gaussian process model	modelizacion;processus gauss;gaussian processes evolutionary computation;multiobjective programming;optimum pareto;programmation multiobjectif;optimisation;gaussian process model;single objective optimization subproblems;evolutionary computation;stochastic process;gaussian processes stochastic processes pareto optimization optimization methods predictive models acoustic testing physics computing computer simulation computational efficiency design optimization;optimizacion;multiple testing;gaussian processes;batch production;qa mathematics;multiobjective evolutionary algorithm decomposition expensive multiobjective optimization moea d method gaussian process model predictive model single objective optimization subproblems;procede discontinu;metric;design optimization;pareto optimization;physics computing;expensive multiobjective optimization;modelisation;acoustic testing;expensive optimization;qa75 electronic computers computer science;produccion por lote;stochastic processes;gaussian stochastic processes;mathematical programming;pareto optimality evolutionary algorithm expensive optimization gaussian stochastic processes multiobjective optimization;production par lot;batch process;processus stochastique;algorithme evolutionniste;multiobjective optimization;procedimiento discontinuo;metrico;predictive models;algoritmo evolucionista;optimization;multiobjective evolutionary algorithm decomposition;prediction model;gaussian process;evolutionary algorithm;proceso estocastico;proceso gauss;computational efficiency;pareto optimum;modeling;programmation mathematique;computer simulation;optimo pareto;programacion matematica;moea d method;pareto optimality;metrique;predictive model;optimization methods;programacion multiobjetivo	In some expensive multiobjective optimization problems (MOPs), several function evaluations can be carried out in a batch way. Therefore, it is very desirable to develop methods which can generate multipler test points simultaneously. This paper proposes such a method, called MOEA/D-EGO, for dealing with expensive multiobjective optimization. MOEA/D-EGO decomposes an MOP in question into a number of single-objective optimization subproblems. A predictive model is built for each subproblem based on the points evaluated so far. Effort has been made to reduce the overhead for modeling and to improve the prediction quality. At each generation, MOEA/D is used for maximizing the expected improvement metric values of all the subproblems, and then several test points are selected for evaluation. Extensive experimental studies have been carried out to investigate the ability of the proposed algorithm.	algorithm;ego;gaussian process;moea framework;mathematical optimization;multi-objective optimization;overhead (computing);predictive modelling;turing test	Qingfu Zhang;Wudong Liu;Edward P. K. Tsang;Botond Virginas	2010	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2009.2033671	stochastic process;mathematical optimization;computer science;artificial intelligence;machine learning;gaussian process;mathematics;predictive modelling;statistics	SE	28.11857354187454	1.3003679465245583	145377
fc3a26a424ff3fba16a92b3f46289784b115913e	a distribution network reconfiguration algorithm based on hopfield neural network	reconfiguration;hopfield neural network distribution power network reconfiguration;distributed networks;distribution networks;power systems;hopfield neural nets;power system dynamics;satisfiability;power engineering computing distribution networks genetic algorithms hopfield neural nets;energy function;hopfield neural network;distribution power network;power engineering computing;hopfield neural networks;hopfield neural networks switches power supplies power system reliability voltage mathematical model artificial intelligence equations computer networks distributed computing;heuristic algorithms;substations;mathematical model;genetic algorithm;distribution network reconfiguration algorithm;genetic algorithms;complex genetic algorithm;switches;target function;differential function;differential function distribution network reconfiguration algorithm hopfield neural network target function complex genetic algorithm	On the base of Hopfield neural network, the minimum of feeder looses is treated as the target function. Because the distribution network is radical, we put forward a method for deciding each node's in-degree by using Hopfield neural network. According to each node's in-degree, it can be easily determined whether the line will be used or not. So the state of switch and the scheme of reconfiguration can be decided correspondingly. The energy function of Hopfield neural network is given in this paper. The problems of satisfying the restriction of radial supplying and minimizing the feeder power looses are considered in the energy function simultaneously. The energy function even takes the problem that some lines may have no switches into consideration. By calculating an IEEE distribution network with three power sources, it can be found that the calculated result of Hopfield neural network is somewhat similar to the result obtained by the more complex genetic algorithm. Since the former is to calculate a group of differential function, so the calculation time needed is comparatively less.	artificial neural network;directed graph;genetic algorithm;hopfield network;mathematical optimization;network switch;radial (radio)	Weixin Gao;Nan Tang;Xiangyang Mu	2008	2008 Fourth International Conference on Natural Computation	10.1109/ICNC.2008.147	computer science;artificial intelligence;recurrent neural network;theoretical computer science;machine learning;hopfield network	Robotics	30.819745643204563	3.953678691693661	145496
321e868c86d2a3c86003ac7aebe374c1eab25b81	robotic path planning using hybrid genetic algorithm particle swarm optimisation	robotic path planning;momentum;information technology;robotics;hgapso;evolutionary algorithms;diversity preservation;hybrid genetic algorithm particle swarm optimisation	The problem of robotic path planning has always attracted the interests of a significantly large number of researchers due to the various constraints and issues related to it. The optimization in terms of time and path length and validity of the non-holonomic constraints, especially in large sized maps of high resolution, pose serious challenges for the researchers. In this paper we propose Hybrid Genetic Algorithm Particle Swarm Optimization (HGAPSO) algorithm for solving the problem. Diversity preservation measures are introduced in this applied evolutionary technique. The novelty of the algorithm is threefold. Firstly the algorithm generates paths of increasing complexity along with time. This ensures that the algorithm generates the best path for any type of map. Secondly the algorithm is efficient in terms of computational time which is done by introducing the concept of momentum based exploration in its fitness function. The indicators contributing to fitness function can only be measured by exploring the path represented. This exploration is vague at start and detailed at the later stages. Thirdly the algorithm uses a multi-objective optimization technique to optimize the total path length, the distance from obstacle and the maximum number of turns. These multi-objective parameters may be altered according to the robot design.	computation;fitness function;genetic algorithm;image resolution;map;mathematical optimization;motion planning;multi-objective optimization;particle swarm optimization;robot;time complexity;vagueness	Rahul Kala;Anupam Shukla;Ritu Tiwari	2012	IJICT	10.1504/IJICT.2012.048756	mathematical optimization;computer science;artificial intelligence;machine learning;robotics;information technology;momentum	AI	30.800424811284564	-2.8581186791715214	145533
25e2eef362a945c001d1e821b8ea5dad7bc8e6f5	reinforcement learning based power management for hybrid electric vehicles	power management;algorithms;power system management;design;electric motors;higher fuel economy;performance analysis and design aids;reinforcement learning;hev power management policy;electric motor;learning (artificial intelligence);air pollution control;hybrid electric vehicles;lower pollution emission;hybrid electric vehicle;ice;power engineering computing;management;energy consumption;internal combustion engines;driving cycle stochastic knowledge;hybrid electric vehicle (hev);electric propulsion;fuel economy;performance;hybrid electric vehicle em;lower fuel consumption;reinforcement learning technique;internal combustion engine;hybrid propulsion system;learning artificial intelligence;gears	Compared to conventional internal combustion engine (ICE) propelled vehicles, hybrid electric vehicles (HEVs) can achieve both higher fuel economy and lower pollution emissions. The HEV consists of a hybrid propulsion system containing one ICE and one or more electric motors (EMs). The use of both ICE and EM increases the complexity of HEV power management, and therefore requires advanced power management policies to achieve higher performance and lower fuel consumption. Towards this end, our work aims at minimizing the HEV fuel consumption over any driving cycle (without prior knowledge of the cycle) by using a reinforcement learning technique. This is in clear contrast to prior work, which requires deterministic or stochastic knowledge of the driving cycles. In addition, the proposed reinforcement learning technique enables us to (partially) avoid reliance on complex HEV modeling while coping with driver specific behaviors. To our knowledge, this is the first work that applies the reinforcement learning technique to the HEV power management problem. Simulation results over real-world and testing driving cycles demonstrate the proposed HEV power management policy can improve fuel economy by 42%.	advanced power management;deterministic algorithm;reinforcement learning;simulation	Xue Lin;Yanzhi Wang;Paul Bogdan;Naehyuck Chang;Massoud Pedram	2014	2014 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)		simulation;gear;computer science;engineering;automotive engineering;reinforcement learning;hybrid power;mechanical engineering	EDA	36.52422156226772	-5.375918995506465	145748
0c2f71d39c121ae0c4a5095f55ba1b2f5a9b3081	finite adaptability in multistage linear optimization	model design;dynamic programming;optimisation;air traffic control;multistage;static robust formulation;uncertainty;computational geometry;bridges;fully adaptable formulation;robust control;operations research;air traffic control finite adaptability multistage linear optimization stochastic control operations research robust optimization discrete second stage variables static robust formulation fully adaptable formulation continuous linear optimization;robust optimization;discrete second stage variables;optimization problem;continuous linear optimization;stochastic processes;dynamics;uncertainty stochastic processes robustness dynamic programming operations research robust control bridges computational geometry air traffic control decision making;linear optimization;stochastic control;robustness;robustness dynamics multistage optimization;optimization;stochastic processes air traffic control optimisation;multistage linear optimization;finite adaptability	In multistage problems, decisions are implemented sequentially, and thus may depend on past realizations of the uncertainty. Examples of such problems abound in applications of stochastic control and operations research; yet, where robust optimization has made great progress in providing a tractable formulation for a broad class of single-stage optimization problems with uncertainty, multistage problems present significant tractability challenges. In this paper we consider an adaptability model designed with discrete second stage variables in mind. We propose a hierarchy of increasing adaptability that bridges the gap between the static robust formulation, and the fully adaptable formulation. We study the geometry, complexity, formulations, algorithms, examples and computational results for finite adaptability. In contrast to the model of affine adaptability proposed in, our proposed framework can accommodate discrete variables. In terms of performance for continuous linear optimization, the two frameworks are complementary, in the sense that we provide examples that the proposed framework provides stronger solutions and vice versa. We prove a positive tractability result in the regime where we expect finite adaptability to perform well, and illustrate this claim with an application to Air Traffic Control.	algorithm;cobham's thesis;complexity;contingency plan;information;linear programming;mathematical optimization;mind;multistage amplifier;numerical method;operations research;robust optimization;stochastic control	Dimitris Bertsimas;Constantine Caramanis	2010	IEEE Transactions on Automatic Control	10.1109/TAC.2010.2049764	robust control;control engineering;optimization problem;mathematical optimization;dynamics;robust optimization;uncertainty;stochastic control;computational geometry;computer science;air traffic control;dynamic programming;control theory;mathematics;robustness	ML	36.166012090623695	1.659660507158431	145813
b630e7344ebd9d7e1386cb08c9e9fc03c910380c	differential evolution: a survey of the state-of-the-art	multiobjective programming;minimization;algoritmo aleatorizado;programmation multiobjectif;optimisation;optimization chromium heuristic algorithms evolution biology minimization particle swarm optimization;differential evolution;metaheuristics;evolutionary computation;loi probabilite;ley probabilidad;particle swarm optimization pso derivative free optimization differential evolution de direct search evolutionary algorithms eas genetic algorithms gas metaheuristics;particle swarm optimization pso;programmation stochastique;differential evolution de;algorithme randomise;stochastic processes evolutionary computation optimisation random processes;genetic algorithms gas;evolution biology;particle swarm optimizer;stochastic processes;mathematical programming;chromium;heuristic algorithms;particle swarm optimization;probability distribution;large scale uncertain optimization stochastic real parameter optimization algorithm evolutionary algorithm differential evolution random selection multiobjective optimization constrained optimization;random processes;randomized algorithm;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;optimization;derivative free optimization;evolutionary algorithm;direct search;stochastic programming;programmation mathematique;programacion estocastica;programacion matematica;heuristic algorithm;programacion multiobjetivo;evolutionary algorithms eas	Differential evolution (DE) is arguably one of the most powerful stochastic real-parameter optimization algorithms in current use. DE operates through similar computational steps as employed by a standard evolutionary algorithm (EA). However, unlike traditional EAs, the DE-variants perturb the current-generation population members with the scaled differences of randomly selected and distinct population members. Therefore, no separate probability distribution has to be used for generating the offspring. Since its inception in 1995, DE has drawn the attention of many researchers all over the world resulting in a lot of variants of the basic algorithm with improved performance. This paper presents a detailed review of the basic concepts of DE and a survey of its major variants, its application to multiobjective, constrained, large scale, and uncertain optimization problems, and the theoretical studies conducted on DE so far. Also, it provides an overview of the significant engineering applications that have benefited from the powerful nature of DE.	computation;differential evolution;evolutionary algorithm;mathematical optimization;optimization problem;perturbation theory;randomness;the offspring	Swagatam Das;Ponnuthurai Nagaratnam Suganthan	2011	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2010.2059031	differential evolution;stochastic programming;probability distribution;stochastic process;mathematical optimization;chromium;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;randomized algorithm;particle swarm optimization	Visualization	27.75298110677909	1.2611802690531997	146031
f8ea19bb7a2ef40f62bee6e39fabbce57fdbb1e8	a hybrid model for isomorphism identification in mechanism design based on intelligent manufacturing	hnns;modelizacion;graph theory;hopfield model;hybrid neural genetic model;ajustamiento modelo;modele hopfield;gas;enumeration;teoria grafo;enumeracion;teoria cinematica;modelo hopfield;etude experimentale;sintesis mecanismo;modelo hibrido;cinematica;hopfield neural nets;synthese mecanisme;algoritmo genetico;theorie graphe;modele hybride;kinematics;isomorphism;hybrid model;isomorfismo;identificacion sistema;graph isomorphism;ajustement modele;modelisation;kinematic structure enumeration;hopfield neural networks;red neuronal de hopfield;system identification;reseau neuronal hopfield;model matching;cinematique;algorithme genetique;genetic algorithm;genetic algorithms;isomorphisme;mechanism synthesis;reseau neuronal;theorie cinematique;mechanism design;kinematic theory;modeling;estudio experimental;red neuronal;identification systeme;intelligent manufacturing;neural network	Isomorphism discernment of graphs is an important and complicate problem. The problem is vital for graph theory based kinematic structures enumeration. To solve the problem, a Genetic Algorithm (GA) model and a Hopfield Neural Networks (HNNs) model are developed respectively, and some operators are improved to prevent premature convergence. By a comparative study, the advantages and limitations of the two approaches for graph isomorphism problem are discussed. Based on above, a hybrid Neural-Genetic algorithm is proposed. Numerical experiments demonstrate the performance of the hybrid algorithm is more successful compared with the approach applying GA or HNN simply.	computation;experiment;genetic algorithm;graph (discrete mathematics);graph isomorphism problem;graph theory;hopfield network;hybrid algorithm;line code;neural networks;numerical method;premature convergence;software release life cycle	Liao Ningbo;Yang Ping	2009	IJMTM	10.1504/IJMTM.2009.026384	genetic algorithm;computer science;artificial intelligence;graph theory;machine learning;mathematics;maximum common subgraph isomorphism problem;algorithm	AI	31.730858384380735	2.786499563501715	146032
62154096d1ba2513e3a2bf9cc65c98ccb28528b7	solving inverse kinematics with vector evaluated particle swarm optimization		Inverse kinematics (IK) is an optimization problem solving the path or trajectory a multi-jointed body should take for an extremity to reach a specified target location. When also considering the flow of movement, IK becomes a multi-objective optimization problem (MOP). This study proposes the use of the vector evaluated particle swarm optimization (VEPSO) algorithm to solve IK. A 3D character arm, with 7 degrees of freedom, is used during experimentation. VEPSO’s results are compared to single-objective optimizers, as well as an optimizer that uses weighted aggregation to solve MOPs. Results show that the weighted aggregation approach can outperform IK-VEPSO if the correct weight combination (that is problem dependent) has been selected. However, IK-VEPSO produces a set of possible solutions.	inverse kinematics;particle swarm optimization;program optimization	Zühnja Riekert;Mardé Helbig	2017		10.1007/978-3-319-61824-1_25	computer science;mathematical optimization;multi-swarm optimization;inverse kinematics;trajectory;particle swarm optimization;optimization problem	Robotics	30.88375004853442	-3.008303096153666	146172
006c7748581e670fe9219598c37419f56a5362ed	a hybrid of differential evolution and genetic algorithm for constrained multiobjective optimization problems	optimisation sous contrainte;constrained optimization;multiobjective programming;programmation multiobjectif;differential evolution;search strategy;intelligence artificielle;algoritmo genetico;optimizacion con restriccion;dominating set;mathematical programming;strategie recherche;algorithme genetique;artificial intelligence;algorithme evolutionniste;multiobjective optimization;genetic algorithm;algoritmo evolucionista;inteligencia artificial;evolutionary algorithm;programmation mathematique;programacion matematica;hybrid algorithm;estrategia investigacion;programacion multiobjetivo	Two novel schemes of selecting the current best solutions for multiobjective differential evolution are proposed in this paper. Based on the search biases strategy suggested by Runarsson and Yao, a hybrid of multiobjective differential evolution and genetic algorithm with (N+N) framework for constrained MOPs is given. And then the hybrid algorithm adopting the two schemes respectively is compared with the constrained NSGA-II on 4 benchmark functions constructed by Deb. The experimental results show that the hybrid algorithm has better performance, especially in the distribution of non-dominated set.	benchmark (computing);differential evolution;dynamic energy budget;genetic algorithm;human-based genetic algorithm;hybrid algorithm;mathematical optimization;optimization problem;software release life cycle;yao graph	Min Zhang;Huantong Geng;Wenjian Luo;Linfeng Huang;Xufa Wang	2006		10.1007/11903697_41	differential evolution;mathematical optimization;constrained optimization;genetic algorithm;dominating set;hybrid algorithm;computer science;artificial intelligence;multi-objective optimization;evolutionary algorithm;mathematics;algorithm	AI	26.3050047074533	0.8686921241714443	146236
c2a61353cb7489fcf6802bc8fdadd5c9aac5ea84	transgenic: an evolutionary algorithm operator	elitism;transgenic operator;interdisciplinar;genetically modified organisms;classification task;genetic algorithms	Traditionally, many evolutionary algorithm operators have biological inspiration. Genetics has contributed to the proposal of a number of different evolutionary operators, such as haploid crossover, mutation, diploid, inversion, gene doubling, deletion, and others. In the present study, we propose a new geneticinspired evolutionary operator, named Transgenic, which was specially designed for Genetic Algorithms (GA). The proposed operator is inspired by genetically modified organisms (GMOs), where important features are artificially introduced into their genome. Transgenic can be used to artificially insert relevant characteristics in the chromosome of individuals, thus converging to better results faster than traditional GAs. When relevant characteristics are known a prior, then, Transgenic simply forces the presence of such characteristics in part of the population (in an elitism-based approach). Whenever there is no a priori knowledge available, Transgenic automatically identifies relevant features (based on historical information) to perform the elitism approach. The GA, used in this study was designed to allow the discovery of concise, yet accurate, high-level rules (from synthetic and real biological databases) which can be used as a classification system. The empirical results have shown that Transgenic is capable of generating better results than traditional rule classification methods, such as J48, Single Conjunctive Rule Learner, One R and PART, using synthetic datasets. & 2013 Elsevier B.V. All rights reserved.	biological database;evolutionary algorithm;genetic algorithm;high- and low-level;mutation (genetic algorithm);period-doubling bifurcation;software release life cycle;synthetic intelligence	Laurence Rodrigues do Amaral;Estevam R. Hruschka	2014	Neurocomputing	10.1016/j.neucom.2013.08.037	genetically modified organism;genetic algorithm;computer science;bioinformatics;artificial intelligence;machine learning;mathematics	AI	24.8792223267314	-9.488286373134393	146407
369514238f549d5873242e71371d47fdfa106067	fitness sharing and niching methods revisited	optimal solution;fitness sharing;genetic algorithms fitness sharing niching methods multimodal optimization evolutionary computation;search space;genetic algorithms evolutionary computation optimization methods standards development ecosystems animals testing shape;indexing terms;optimization problem;genetic algorithm;genetic algorithms;ge netic algorithm;autre;fitness function;evolutionary computing	Interest in multimodal optimization function is expanding rapidly since real-world optimization problems often require the location of multiple optima in the search space. In this context, fitness sharing has been used widely to maintain population diversity and permit the investigation of many peaks in the feasible domain. This paper reviews various strategies of sharing and proposes new recombination schemes to improve its efficiency. Some empirical results are presented for high and a limited number of fitness function evaluations. Finally, the study compares the sharing method with other niching techniques.	cluster analysis;crossover (genetic algorithm);crowding;denial-of-service attack;evolutionary multimodal optimization;fitness function;image scaling;local optimum;mathematical optimization;multimodal interaction;multimodal learning;niche blogging;premature convergence;selection (user interface);software release life cycle;sorting algorithm;tournament selection	Bruno Sareni;Laurent Krähenbühl	1998	IEEE Trans. Evolutionary Computation	10.1109/4235.735432	mathematical optimization;genetic algorithm;interactive evolutionary computation;cultural algorithm;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;fitness approximation;fitness function;evolutionary computation	ML	26.32539960142737	-5.838529672276591	146734
dc84900797373535044928175bb5a98bfc7069b0	hybridization of stochastic tunneling with (quasi)-infinite time-horizon tabu search		Stochastic Tunneling (STUN) is an optimization heuristic whose basic mechanism is based on reducing barriers for its search process between local optima via a non-linear transformation. Here, we hybridize STUN with the idea of Tabu Search (TS), namely, the avoidance of revisiting previously assessed solutions. This prevents STUN from inefficiently scan areas of the search space whose objective function values have already been “transformed away”. We introduce the novel idea of using a probabilistic data structure (Bloom filters) to store a (quasi-)infinite tabu history. Empirical results for a combinatorial optimization problem show superior performance. An analysis of the tabu list statistics shows the importance of this hybridization idea.		Kay Hamacher	2019		10.1007/978-3-030-05983-5_9	tabu search;local optimum;probabilistic logic;combinatorial optimization;stochastic tunneling;mathematical optimization;stun;time horizon;heuristic;computer science	AI	26.835388059256086	-2.1050115995279475	146954
70b7e939dcc09b0fdb11b6d769a6ed1ca3e35c93	non-refreshing analog neural storage tailored for on-chip learning	analogue storage;5 bit nonrefreshing analog neural storage on chip learning analog weights back propagation signals binary weighted voltage references voltage adder up down counter analog graded error signal pulse streams error signal modular synaptic body scaleable analog vlsi neural networks recall operations learning operations;adders digital control voltage control registers counting circuits pulse generation signal generators pulse circuits very large scale integration neural networks;analog learning;backpropagation;chip;neural chips;vlsi;analog vlsi;on chip learning neural networks;non refreshing static storage;analogue processing circuits;digital number;back propagation;neural network;analogue processing circuits analogue storage neural chips vlsi backpropagation	In this research, we devised a new simple technique for statically holding analog weights, which does not require periodic refreshing. It further contains a mechanism to locally update the weights from the analog back-propagation signals for fast on-chip learning. In this circuit, the weight is stored as a 5-bit digital number, which controls the gates of five pass transistors allowing five binary-weighted (1,2,4,8,16) voltage references to integrate at a voltage adder. The output of the voltage adder is the analog weight. The 5-bit register is designed as an up/down counter so that every pulse on the up/down input will increase/decrease the weight by one level out of 32 possible levels. The learning circuit takes the analog graded error signal and generates two pulse streams for up/down counting depending on the sign of the error signal. The duration of the pulse stream is proportional to the magnitude of the error signal. This complete modular synaptic body (storage and learning technique) is appropriate for large scaleable analog VLSI neural networks because it handles recall and learning operations at the same speed with full parallelism.		Bassem A. Alhalabi;Qutaibah M. Malluhi;Rafic A. Ayoubi	1998		10.1109/GLSV.1998.665220	analog device;embedded system;electronic engineering;computer hardware;analog signal;computer science;electrical engineering;backpropagation;theoretical computer science;artificial neural network;analog multiplier	ML	38.844926499585824	-1.8222724572196463	147095
989123ca1b276524e9e3ed97326d4d894cc10bf3	technology independent circuit sizing for standard cell based design using neural networks	computer aided design;neural networks;multilayer perceptron;vlsi design;input output;circuit simulation;general regression neural network;digital integrated circuits;delay time;neural network	This paper presents a neural network (NN) approach for modeling the time characteristics of fundamental gates of digital integrated circuits that include inverter, NAND, NOR, and XOR gates. The modeling approach presented here is technology independent, fast, and accurate, which makes it suitable for circuit simulators. Firstly transient simulations were done in order to obtain delay times for different transistor sizes and different load capacitances using AMIS 1.5 @mm, TSMC 0.25 @mm and TSMC 0.18 @mm technology parameters with HSPICE. These delay time results constitute the inputs of NN while the outputs are transistor sizes. Then, two neural network structures, multilayer perceptron (MLP) and general regression neural network (GRNN), were compared to estimate the transistor sizes. MLP achieved 91 acceptable results through 120 test data where GRNN had 77. The important thing is that the NN is able to generalize the input-output mapping and estimates the outputs for new data which were not applied to the NN for training before. As a conclusion, fundamental gates used for standard cell based VLSI design can be sized for desired delay times using neural networks without knowing SPICE technology parameters.	artificial neural network;standard cell	Nihan Kahraman;Tülay Yildirim	2009	Digital Signal Processing	10.1016/j.dsp.2008.11.009	input/output;computer science;machine learning;very-large-scale integration;multilayer perceptron;artificial neural network	ML	38.348601993262676	-2.8990627874485906	147187
3e2b22609287ba3163f1d719dd024584d1cc6408	neuro-fuzzy system with high-speed low-power analog blocks	fuzzy set;circuito y;funcion no lineal;linear function;circuito analogico;non linear function;fonction lineaire;conjunto difuso;ensemble flou;sistema complejo;minimizacion funcion;linear functionals;algorithme centroide;centriod algorithm;analog circuits;analog circuit;low power;sistema analogico;systeme complexe;function minimization;complex system;fonction appartenance;neuro fuzzy system;membership function;fonction non lineaire;systeme analogique;and circuit;sistema difuso;systeme flou;funcion pertenencia;circuit et;high speed;cmos;fuzzy system;defuzzification;circuit analogique;analog system;minimisation fonction	This paper proposes several improved CMOS analog circuits for neuro-fuzzy system, including Gaussian-like membership function circuit, minimization circuit, and a centroid algorithm defuzzification circuit not using division. A two-input/one-output neuro-fuzzy system composed of these circuits is implemented and testified for non-linear function approximating. All the circuits have been fabricated in SMIC 0.18m Mixed-signal CMOS technology. Experiment results show that all the proposed circuits provide characteristics of high operation capacity, high speed, and simple structures. They are very suitable for rapid implementation of high-speed complex neuro-fuzzy system. © 2006 Elsevier B.V. All rights reserved.	algorithm;analogue electronics;cmos;circuit minimization for boolean functions;defuzzification;fuzzy control system;linear function;low-power broadcasting;matlab;mixed-signal integrated circuit;neuro-fuzzy;nonlinear system	Weizhi Wang;Dongming Jin	2006	Fuzzy Sets and Systems	10.1016/j.fss.2006.07.001	equivalent circuit;mixed-signal integrated circuit;complex systems;analogue electronics;computer science;artificial intelligence;control theory;mathematics;algorithm;fuzzy control system	EDA	38.31510958015899	-3.7039552883977644	147542
0b9f29488e27271622e45544d6a58bdb163ae487	performance analysis for genetic quantum circuit synthesis	optimal solution;genetic operator;statistical significance;genetics;quantum circuits;performance analysis;genetic algorithm	Genetic algorithms have proven their ability in detecting optimal or closed-to-optimal solutions to hard combinational problems. However, determining which crossover, mutation or selector operator is best for a specific problem can be cumbersome. The possibilities for enhancing genetic operators are discussed herein, starting with an analysis of their run-time performance. The contribution of this paper consist of analyzing the performance gain from the dynamic adjustment of the genetic operators, with respect to overall performance, as applied for the task of quantum circuit synthesis. We provide experimental results demonstrating the effectiveness of the approach by comparing our results against a traditional GA, using statistical significance measurements.	profiling (computer programming);quantum circuit	Cristian Ruican;Mihai Udrescu;Lucian Prodan;Mircea Vladutiu	2010		10.1007/978-3-642-13232-2_25	mathematical optimization;genetic algorithm;computer science;artificial intelligence;genetic operator;machine learning;genetic representation;mathematics;statistical significance;algorithm	Logic	26.790846552247295	-7.107781898991184	147602
c5de89c29554ce6d3a4de6bd2f6c38b28f43e22f	a new image crypto-compression system spiht-pscs	pscs chaos logistic map tent map spiht dwt ezw haar;correlation image coding encryption chaos logistics entropy;image coding cryptography data compression;data security image crypto compression system spiht pscs high speed confidential data transmission set partitioning in hierarchical trees encryption scheme parametric switching chaotic system compression quality	In this paper, a new algorithm combined compression and image encryption is presented. The proposed algorithm can be used in the field of high-speed confidential data transmission where security is required. The compression is based on a hierarchical structure called SPIHT(Set Partitioning in Hierarchical Trees). This compression is followed by an encryption scheme PSCS (Parametric Switching Chaotic System). The performances of this technique were evaluated in terms of compression quality and data security. Simulation results have shown the effectiveness of this technique, and thereafter, it is ready for a hardware implementation.	algorithm;chaos theory;confidentiality;cryptanalysis;cryptosystem;data security;encryption;peak signal-to-noise ratio;performance;set partitioning in hierarchical trees;simulation	Tarek Hadjem;Mohamed Salah Azzaz;Camel Tanougast;Said Sadoudi	2014	2014 International Conference on Control, Decision and Information Technologies (CoDIT)	10.1109/CoDIT.2014.6996983	computer vision;telecommunications;theoretical computer science;mathematics	EDA	38.913690373640186	-9.085136829422693	147675
0d28f14333b61ef4bf0ad94b24c4f80e2234f574	optimization simulation: the case of multi-stage stochastic decision models	stochastic linear program;stochastic decomposition;multi-stage stochastic programming;algorithmic process;new algorithm;new approach;multi-stage stochastic decision model;sampling-based algorithm;approximate dynamic programming;optimization simulation;dynamic programming;stochastic processes;stochastic programming;stochastic process;optimization;simulation;modeling;linear approximation;linear programming;linear program;function approximation;decision models	In this paper we present a new approach to solving multi-stage stochastic decision models in the presence of constraints. The models themselves are stochastic linear programs (SLP), but we presume that their deterministic equivalent problems are too large to be solved exactly. We seek an asymptotically optimum solution by simulating the stochastic decomposition (SD) algorithmic process, originally designed for two-stage SLPs. When SD is implemented in a time-staged manner the algorithm begins to take the flavor of a simulation leading to what we refer to as optimization simulation. Among its major advantages, it can work directly with sample paths, and this feature makes the new algorithm much easier to integrate within a simulation. We also overcome certain limitations such as a stage-wise independence assumption required by other sampling-based algorithms for multi-stage stochastic programming. Finally, we also discuss how these methods can be interpreted as close relatives of approximate dynamic programming.	approximation algorithm;dynamic programming;mathematical optimization;sampling (signal processing);simulation;stochastic programming;successive linear programming	Suvrajeet Sen;Zhihong Zhou	2011	Proceedings of the 2011 Winter Simulation Conference (WSC)		stochastic programming;stochastic process;mathematical optimization;decision model;systems modeling;continuous-time stochastic process;function approximation;linear programming;theoretical computer science;stochastic optimization;machine learning;dynamic programming;mathematics;linear approximation	AI	30.902157493736784	1.6670310389776382	147702
53897b107e4cbdae261d9cc1d2b54411272b7507	controlling population size and mutation strength by meta-es under fitness noise	population size;meta es;mutation strength;fitness noise;adaptation;evolution strategies;sphere model	This paper investigates strategy parameter control by Meta-ES using the noisy sphere model. The fitness noise considered is normally distributed with constant noise variance. An asymptotical analysis concerning the mutation strength and the population size is presented. It allows for the prediction of the Meta-ES dynamics. An expression describing the asymptotical growth of the normalized mutation strength is calculated. Finally, the theoretical results are evaluated empirically.	algorithm;approximation;asymptote;cma-es;experiment;mathematical optimization;microsoft outlook for mac;optimization problem;steady state	Hans-Georg Beyer;Michael Hellwig	2013		10.1145/2460239.2460242	population size;genetics;statistics;adaptation	ML	28.72657687695287	-8.480199332164485	148035
b332d41297f7d086cc75a317a33d918e8ec99350	extracting stellar population parameters of galaxies from photometric data using evolution strategies and locally weighted linear regression	linear regression;stellar population;optimization problem;evolution strategy;hybrid algorithm	There is now a huge amount of high quality photometric data available in the literature whose analysis is bound to play a fundamental role in studies of the formation and evolution of structure in the Universe. One important problem that this large amount of data generates is the definition of the best procedure or strategy to achieve the best result with the minimum of computational time. Here we focus on the optimization of methods to obtain stellar population parameters (ages, proportions, redshift and reddening) from photometric data using evolutionary synthesis models. We pose the problem as an optimization problem and we solve it with Evolution Strategies (ES). We also test a hybrid algorithm combining Evolution Strategies and Locally Weighted Linear Regression (LWLR). The experiments show that the hybrid algorithm achieves greater accuracy, and faster convergence than evolution strategies. On the other hand the performance of ES and ESLWLR is similar when noise is added to the input data.	best practice;computation;display resolution;evolution strategy;evolutionary algorithm;experiment;galaxy;hybrid algorithm;iteration;linear model;mathematical optimization;optimization problem;redshift;stellar (payment network);time complexity	Luis Álvarez;Olac Fuentes;Roberto Terlevich	2004		10.1007/978-3-540-30134-9_53	mathematical optimization;astronomy;astrophysics;physics	ML	31.102283914282243	-9.429676997195909	148059
104cb16e35b8dd9aeabfc7b4869e4f6517f65331	a population-based simulated annealing algorithm for global optimization	simulated annealing;statistics;genetic algorithms;sociology;benchmark testing;cooling	Simulated annealing (SA) is a solo-search algorithm, trying to simulate the cooling process of molten metals through annealing to find the optimum solution in an optimization problem. SA selects a feasible starting solution, produces a new solution at the vicinity of it, and makes a decision by some rules to move to the new solution or not. However, the results found by SA depend on the selection of the starting point and the decisions SA makes. In this paper, in order to ameliorate the drawbacks of the algorithm, a population-based simulated annealing (PSA) algorithm is proposed. PSA uses the population's ability to seek different parts of the search space, thus hedging against bad luck in the initial solution or the decisions. A set of benchmark functions was used in order to evaluate the performance of PSA algorithm. Simulation results accentuate the superior capability of PSA in comparison with the other optimization algorithms.	benchmark (computing);computer cooling;global optimization;mathematical optimization;optimization problem;polar surface area;search algorithm;simulated annealing;simulation;structure of observed learning outcome	Alireza Askarzadeh;Leandro dos Santos Coelho;Carlos Eduardo Klein;Viviana Cocco Mariani	2016	2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2016.7844961	benchmark;mathematical optimization;simulation;genetic algorithm;simulated annealing;computer science;hill climbing;adaptive simulated annealing;statistics	Robotics	28.154619915015342	-5.788521542704857	148371
66e5817d8d171ffe982fe378247ef408051433a4	on the solution of the steiner tree np-hard problem via physarum bionetwork	organisms;steiner trees veins organisms biological processes communication networks;communication networks;bionetworks;steiner trees;physarum polycephalum;veins;trees mathematics cellular biophysics computational complexity optimisation telecommunication networks;steiner tree biological networks bionetworks physarum polycephalum;biological networks;steiner tree;biological processes;exponential convergence rate physarum bionetwork steiner tree problem np hard problem biological process bio inspired algorithms smart adaptive communication network computer architectures living organisms unicellular organism physarum polycephalum slime mold	In the last several years, many algorithms trying to mimic biological processes have been proposed to enhance the performance of communication networks. However, the bio-inspired algorithms represent only the very first step toward the design of a smart adaptive communication network since: 1) they model only a limited set of the rules underlying the biological processes, thus, omitting fundamental functionalities; 2) they are executed on traditional computer architectures, thus, failing to achieve the intrinsic parallelism exhibited by biological processes. To overcome these issues, in this paper, the BioNetwork paradigm is proposed, a novel communication network paradigm in which the traditional network nodes are replaced by living organisms. The BioNetwork paradigm provides very attractive features over traditional network paradigms, such as efficiency, adaptivity, reliability, self-organization, and scalability. Moreover, it has a huge potential since it can be adopted in many different applications, such as health and military ones. In the paper, this potential is shown by proving that a BioNetwork can solve one of the most fundamental NP-hard problems in networks, i.e., the Steiner tree problem. To this aim, a BioNetwork constituted by a unicellular organism, the Physarum polycephalum slime mold, is designed. Throughout the paper, it is proven that a Physarum BioNetwork can solve the Steiner tree problem with an exponential convergence rate toward the optimal solution. The theoretical solutions are validated through a case study.	algorithm;british informatics olympiad;computer architecture;failure;np-hardness;parallel computing;programming paradigm;rate of convergence;slime;scalability;self-organization;steiner tree problem;telecommunications network;time complexity	Marcello Caleffi;Ian F. Akyildiz;Luigi Paura	2015	IEEE/ACM Transactions on Networking	10.1109/TNET.2014.2317911	combinatorics;steiner tree problem;computer science;algorithm	HPC	33.15212639492259	-1.974794532832801	148394
483ddbd7bff3b139c9bd30daa6dcd49fd970fa2a	understanding differential evolution: a poisson law derived from population interaction network		Differential evolution (DE) is one of evolutionary algorithms to effectively handle optimization problems. We propose a population interaction network (PIN) to investigate the relationship constituted by populations. The cumulative distribution function (CDF) of degree in PIN is analyzed by five fitting models on twelve benchmark functions. The goodness of fit is used to measure the fitting results. The experimental results demonstrate the CDF meets cumulative poisson distribution. Besides, the number of nodes in PIN and the rate parameter λ in the fitted poisson distribution are further studied using different control parameters of DE, which exhibits the effect and characteristic of the population interaction.	benchmark (computing);differential evolution;evolutionary algorithm;interaction network;mathematical optimization;population	Shangce Gao;Yirui Wang;Jiahai Wang;Jiujun Cheng	2017	J. Comput. Science	10.1016/j.jocs.2017.06.007	mathematical optimization;goodness of fit;differential evolution;cumulative distribution function;evolutionary algorithm;poisson distribution;population;interaction network;optimization problem;mathematics	Vision	29.0757538979685	-8.609158768644726	148395
940747daaa41ab17f2555af9a591b4a3c944a504	analytical and scalable analysis of transient tandem markovian finite capacity queueing networks	urban traffic signal control;queueing networks;markovian networks;joint distribution	This paper proposes an analytical model to approximate the transient aggregate joint queue-length distribution of tandem finite (space) capacity Markovian networks. The methodology combines ideas from transient aggregation-disaggregation techniques as well as transient network decomposition methods. The complexity of the proposed method is linear in the number of queues and is independent of the space capacities of the individual queues. This makes it a suitable approach for the analysis of large-scale networks. The transient joint distributions are validated versus simulation estimates. The model is then used to describe urban traffic dynamics and to address a dynamic traffic signal control problem. The signal plan analysis shows the added value of using joint distributional information, and more generally spatial-temporal between-link dependency information, to enhance urban traffic operations. The online appendix is available at https://doi.org/10.1287/trsc.2015.0629.	aggregate data;algorithm;approximation;ct scan;cobham's thesis;computation;fo (complexity);institute for operations research and the management sciences;marginal model;mathematical optimization;nl (complexity);network topology;queueing theory;scalability;simulation;simulation-based optimization;stationary process;time complexity	Carolina Osorio;Jana Yamani	2017	Transportation Science	10.1287/trsc.2015.0629	mathematical optimization;operations management;scalability;joint probability distribution;markov process;queueing theory;added value;queue;computer science	Metrics	38.23259279500767	2.9777315558749584	148802
0e1a6576ee670b4cb63d221e5c8586956279fe10	a solution for combinational optimization problems using a two-layer random field model-mean-field approximation	traveling salesman problem;deterministic annealing;two layer random field model;optimization problem;mean field approximation;neural network;random field	Abstract#R##N##R##N#In the solution of the combinational optimization problem such as the traveling salesman problem, the usual approach is to define the energy function, which consists of the term representing the cost to be minimized and the terms representing the constraint for the solution. It is important at this stage to define adequately the weight coefficients for the constraint terms. For this purpose, a solution method based on the two-layer random field model has already been proposed.#R##N##R##N##R##N##R##N#However, it is desirable from the viewpoint of the processing speed to apply the deterministic annealing to the analog neuron system obtained by the mean-ield approximation, rather than to apply directly the simulated annealing to the binary neuron system. In his case, it is important also to define adequately the weight coefficients in the energy function.#R##N##R##N##R##N##R##N#This paper considers the already proposed method which automatically adjusts the weight coefficients using the two-layer random field model. An elaboration is presented which applies the method to the search of the optimal solution by the deterministic nnealing. In this study, the connection machine CM-2), which is a SIMD-type parallel computer, is used to handle the relatively large-scale problem composed of 64 cities.	approximation;combinational logic;mathematical optimization	Harukazu Igarashi	1994	Systems and Computers in Japan	10.1002/scj.4690250806	optimization problem;mathematical optimization;combinatorics;random field;computer science;artificial intelligence;mean field theory;machine learning;mathematics;travelling salesman problem;artificial neural network;algorithm;statistics	Robotics	30.355921139082454	3.2060481577489055	148810
89f1c6d442c031f531d1bb07b8cdec9fa2b4770f	chaotic evolution: fusion of chaotic ergodicity and evolutionary iteration for optimization	chaotic evolution;evolutionary computation;chaos;fusion technology;ergodicity	We propose a novel population-based optimization algorithm, Chaotic Evolution (CE), which uses ergodic property of chaos to implement exploration and exploitation functions of an evolutionary algorithm. CE introduces a mathematical mechanism into an iterative process of evolution and simulates ergodic motion in a search space with a simple principle. A control parameter, direction factor rate, is proposed to guide search direction in CE. It is easy to extend its search capability by using different chaotic system in CE algorithm framework. The scalability of CE is higher than that of some other evolutionary computation algorithms. A series of comparative evaluations and investigations is conducted to analyse characteristics of the proposal. Our proposal can obtain better optimization performance by comparing with differential evolution and some of its variants. We point out that the chaos theory is used not only to describe and explain a non-linear system, but also to implement a variety of optimization algorithms based on its ergodic property.	chaos theory;differential evolution;ergodic theory;ergodicity;evolutionary algorithm;evolutionary computation;iteration;linear system;mathematical optimization;nonlinear system;scalability;simulation	Yan Pei	2013	Natural Computing	10.1007/s11047-013-9409-2	mathematical optimization;fusion power;ergodicity;computer science;artificial intelligence;theoretical computer science;mathematics;synchronization of chaos;evolution strategy;quantum mechanics;evolutionary computation	AI	27.16091851215699	-5.453377319841292	149462
11d52f8a6e781e78ce8615114968a216e0bc93fa	optimising a complex discrete event simulation model using a genetic algorithm	simulation ordinateur;modelizacion;optimisation;optimizacion;productique;algoritmo genetico;genetics;modelisation;inverse problem;algorithme genetique;robotica;genetic algorithm;optimization;simulacion computadora;modeling;computer integrated manufacturing;simulation model;computer simulation;real coded genetic algorithm;discrete event simulation	A steelworks model is selected as representative of the stochastic and unpredictable behaviour of a complex discrete event simulation model. The steel-works has a number of different entity or object types. Using the number of each entity type as parameters, it is possible to find better and worse combinations of parameters for various management objectives. A simple real-coded genetic algorithm is presented that optimises the parameters, demonstrating the versatility that genetic algorithms offer in solving hard inverse problems.	entity;genetic algorithm;simulation	Ray J. Paul;Tomas S. Chanev	1997	Neural Computing & Applications	10.1007/BF01501509	computer simulation;simulation;systems modeling;genetic algorithm;computer science;inverse problem;artificial intelligence;discrete event simulation;simulation modeling;computer-integrated manufacturing;algorithm	AI	28.357870080060046	1.2016253327834427	149556
10dd0893926a37ce9435618a0e4b6c039e868aae	shape and size optimization of truss structures considering dynamic constraints through modern metaheuristic algorithms	engineering design;nonlinear dynamic optimization problems;firefly algorithm;harmony search;frequency constraints	Mass optimization on shape and sizing with multiple natural frequency constraints are highly nonlinear dynamic optimization problems. Multiple natural frequency constraints normally cause difficult dynamic sensitivity analysis and, in addition, two different types of design variables, nodal coordinates and crosssectional areas, often lead to divergence. Thus, the choice of the appropriated method to solve this kind of problem is of paramount importance. Within this context, in this paper two of the most recent metaheuristic algorithms developed in the last decade, Harmony Search (HS) and Firefly Algorithm (FA), are used, for the first time here, to solve truss shape and sizing optimization with multiple natural frequency constraints. Since these metaheuristic algorithms are not a gradient-based search, they avoid most of the pitfalls of any gradient-based search algorithms. The effectiveness of Harmony Search and Firefly Algorithm is demonstrated through four benchmark structural optimization problems for solving shape and sizing optimization of trusses with multiple frequency constraints. The results showed that both metaheuristic algorithms reached, in a relatively low computational time, better results than the literature in three of the four examples considered, and in the other example the structure is approximately equal to the best one found, emphasizing the excellent capacity of both methods. 2012 Elsevier Ltd. All rights reserved.	approximation;benchmark (computing);computation;dynamic programming;firefly algorithm;gradient;harmony search;mathematical optimization;metaheuristic;nonlinear system;search algorithm;shape optimization;time complexity	Letícia Fleck Fadel Miguel;Leandro Fleck Fadel Miguel	2012	Expert Syst. Appl.	10.1016/j.eswa.2012.02.113	mathematical optimization;parallel metaheuristic;tabu search;harmony search;computer science;artificial intelligence;firefly algorithm;mathematics;algorithm;engineering design process;metaheuristic	ML	29.0461861199645	-2.3759154007685006	149646
a0ae49d82382b372baecac19b01dcdc1f6531433	enhancing distributed differential evolution with multicultural migration for global numerical optimization	numerical optimization;multicultural migration;distributed differential evolution;article	Differential evolution (DE) is a prominent stochastic optimization technique for global optimization. After its original definition in 1995, DE frameworks have been widely researched by computer scientists and practitioners. It is acknowledged that structuring a population is an efficient way to enhance the algorithmic performance of the original, single population (panmictic) DE. However, only a limited amount of work focused on Distributed DE (DDE) due to the difficulty of designing an appropriate migration strategy. Since a proper migration strategy has a major impact on the performance, there is a large margin of improvement for the DDE performance. In this paper, an enhanced DDE algorithm is proposed for global numerical optimization. The proposed algorithm, namely DDE with Multicultural Migration (DDEM) makes use of two migration selection approaches to maintain a high diversity in the subpopulations, Target Individual Based Migration Selection (TIBMS) and Representative Individual Based Migration Selection (RIBMS), respectively. In addition, the diversity amongst the individuals is controlled by means of the proposed Affinity Based Replacement Strategy (ABRS) mechanism. Numerical experiments have been performed on 34 diverse test problems. The comparisons have been made against DDE algorithms using classical migration strategies and three popular DDE variants. Experimental results show that DDEM displays a better or equal performance with respect to its competitors in terms of the quality of solutions, convergence, and statistical tests. 2013 Elsevier Inc. All rights reserved.	algorithm;computer scientist;differential evolution;dynamic data exchange;experiment;global optimization;mathematical optimization;numerical analysis;numerical method;processor affinity;stochastic optimization	Jixiang Cheng;Gexiang Zhang;Ferrante Neri	2013	Inf. Sci.	10.1016/j.ins.2013.06.011	mathematical optimization;simulation;artificial intelligence;algorithm	AI	25.078467716984687	-4.736024317264336	149813
510a3cc3967d1747004ca311befb4291d7c8e4d6	an improved species based genetic algorithm and its application in multiple template matching for embroidered pattern inspection	species based genetic algorithm sbga;bounded partial correlation bpc;statistical test;optimization problem;partial correlation;improved genetic algorithm;multimodal optimization;genetic algorithm;pattern inspection;template matching	This paper describes an improved genetic algorithm (GA) using the notion of species in order to solve an embroidery inspection problem. This inspection problem is actually a multiple template matching problem which can be formulated as a multimodal optimization problem. In many cases, the run time of the multiple template matching problem is dominated by repeating the similarity calculations and moving the templates over the source image. To cope with this problem, the proposed species based genetic algorithm (SbGA) is capable to determine its neighborhood best values for solving multimodal optimization problems. The SbGA has been statistically tested and compared with other genetic algorithms on a number of benchmark functions. After proving its effectiveness, it is integrated with multi-template matching method, namely SbGA–MTM method to solve the embroidery inspection problem. Furthermore, the notion of bounded partial correlation (BPC) is also adopted as an acceleration strategy, which enhances the overall efficiency. Experimental results indicate that the SbGA–MTM method is proven to solve the inspection problem efficiently and effectively. With the proposed method, the embroidered patterns can be identified and checked automatically. 2011 Elsevier Ltd. All rights reserved.	benchmark (computing);c++;computation;evolutionary multimodal optimization;genetic algorithm;mathematical optimization;midwoofer-tweeter-midwoofer;multimodal interaction;optimization problem;pixel;run time (program lifecycle phase);simulation;software bug;software release life cycle;systems engineering;template matching;time complexity	Na Dong;Chun-Ho Wu;Andrew W. H. Ip;Zengqiang Chen;Ching-Yuen Chan;Kai-Leung Yung	2011	Expert Syst. Appl.	10.1016/j.eswa.2011.05.085	optimization problem;mathematical optimization;statistical hypothesis testing;genetic algorithm;template matching;computer science;partial correlation;machine learning;mathematics;algorithm;statistics	AI	25.84656796663713	-2.1591782408252853	150134
05a5a8f801200b11153e77d44abfe8cf5043d52b	fast generation of optimal music playlists using local search	music retrieval;formal model;interactive music;simulated annealing;constraint satisfaction;automatic generation;local search;penalty function	We present an algorithm for use in an interactive music system that automatically generates music playlists that fit the music preferences given by a user. To this end, we introduce a formal model, define the problem of automatic playlist generation (APG) and indicate its NP-hardness. We use a local search (LS) procedure based on simulated annealing (SA) to solve the APG problem. In order to employ this LS procedure, we introduce an optimization variant of the APG problem, which includes the definition of penalty functions and a neighborhood structure. To improve upon the performance of the standard SA algorithm, we incorporated three heuristics referred to as song domain reduction, partial constraint voting, and two-level neighborhood structure. In tests, LS performed better than a constraint satisfaction (CS) solution in terms of run time, scalability and playlist quality.	algorithm;compiler;constraint satisfaction;download;dynamic music;embedded system;formal language;heuristic (computer science);least squares;local search (optimization);mathematical optimization;np-hardness;optimization problem;podcast;prototype;run time (program lifecycle phase);scalability;simulated annealing	Steffen Pauws;Wim Verhaegh;Mark Vossen	2006			simulation;simulated annealing;constraint satisfaction;computer science;artificial intelligence;local search;machine learning;penalty method	AI	25.152858876214218	2.553184916418659	150492
c8cfeff7458eae21ca2d372ba36d5d85b9caac38	constrained single-objective optimization using particle swarm optimization	optimal method;particle swarm optimisation behavioural sciences;fish schools constrained single objective optimization particle swarm optimization social groups bird flocks;particle swarm optimizer;constraint optimization particle swarm optimization testing evolutionary computation switches equations optimization methods birds marine animals educational institutions;behavioural sciences;constraint handling;social groups;particle swarm optimisation;parameter optimization	Particle Swarm Optimization (PSO) is an optimization method that is derived from the behavior of social groups like bird flocks or fish schools. In this work PSO is used for the optimization of the constrained test suite of the special session on constrained real parameter optimization at CEC06. Constraint-handling is done by modifying the procedure for determining personal and neighborhood best particles. No additional parameters are needed for the handling of constraints. Numerical results are presented, and statements are given about which types of functions have been successfully optimized and which features present difficulties.	constraint (mathematics);flocking (behavior);mathematical optimization;numerical method;particle swarm optimization;program optimization;test suite	Karin Zielinski;Rainer Laur	2006	2006 IEEE International Conference on Evolutionary Computation	10.1109/CEC.2006.1688343	social group;mathematical optimization;multi-swarm optimization;constrained optimization;test functions for optimization;meta-optimization;behavioural sciences;derivative-free optimization;artificial intelligence;machine learning;imperialist competitive algorithm;particle swarm optimization;metaheuristic	Robotics	27.82601454758506	-5.807426262676417	150810
d4594d620c0cc9cdb2cb574b9884f71da16d8f54	parametric optimisation in a 2-d cellular automata model of fundamental seismic attributes with the use of genetic algorithms	earthquake;lc analogue;dynamic system;potential;genetic algorithm;genetic algorithms;cellular automata	A two-dimensional (2-D) cellular automata (CA) dynamic system constituted of cells-charges has been proposed for the simulation of the earthquake process. In this paper, the study is focused on the optimal parameterisation of the model introducing the use of genetic algorithm (GA). The optimisation of the CA model parameterisation, by applying a standard GA, extends its ability to study various hypotheses concerning the seismicity of the region under consideration. The GA evolves an initially random population of candidate solutions of model parameters, such that in time appropriate solutions to emerge. The quality criterion is realised by taking into account the extent that the simulation results match the Gutenberg–Richter (GR) law derived from recorded data of the area under test. The simulation results presented here regard regions of Greece with different seismic and geophysical characteristics. The results found are in good quantitative and qualitative agreement with the GR scaling relations. 2011 Elsevier Ltd. All rights reserved.	automata theory;cellular automaton;computation;contour line;display resolution;dynamical system;extrapolation;focal (programming language);genetic algorithm;graphical user interface;image scaling;mathematical optimization;olami–feder–christensen model;precondition;simulation;software release life cycle;three-dimensional integrated circuit	Ioakeim G. Georgoudas;Georgios Ch. Sirakoulis;E. M. Scordilis;Ioannis Andreadis	2011	Advances in Engineering Software	10.1016/j.advengsoft.2011.04.003	cellular automaton;mathematical optimization;simulation;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;algorithm	Robotics	34.0473872852117	-7.020764363571164	151077
27d1544b80f44f9efc4ca8c77925408d759c8b91	solving influence diagrams using hugin, shafer-shenoy and lazy propagation	optimal policy;influence diagram	In this paper we present three different architec­ tures for the evaluation of influence diagrams: HUGIN, Shafer-Shenoy (S-S), and Lazy Prop­ agation (LP). HUGIN and LP are two new ar­ chitectures introduced in this paper. The compu­ tational complexity using the three architectures are compared on the same structure, the Limited Memory Influence Diagram (LIMID), where on­ ly the requisite information for the computation of optimal policies is depicted. Because the req­ uisite information is explicitly represented in the diagram, the evaluation procedure can take ad­ vantage of it. Previously, it has been shown that significant savings in computational time can be obtained by performing the calculation on the LIMID rather than on the traditional influence diagram. In this paper we show how the ob­ tained savings is considerably increased when the computations are performed according to the LP scheme.	computation;hugin;influence diagram;lazy evaluation;software propagation;time complexity	Anders L. Madsen;Dennis Nilsson	2001			influence diagram;computer science;theoretical computer science;mathematics;algorithm	AI	34.53616523749095	1.9864974847569439	151440
51185164a4123a3b67aea122f0c45d0b39afd801	approximation of digital curves using a multi-objective genetic algorithm	exploration algorithm digital curves approximation multiobjective genetic algorithm digital planar curve approximation optimization algorithm;optimization algorithm;approximation error;approximation method;computational geometry;genetic algorithms approximation theory computational geometry curve fitting;multi objective genetic algorithm;approximation theory;digital planar curve approximation;genetic algorithms optimization methods approximation algorithms approximation error pattern recognition approximation methods image processing shape extremities simulated annealing;digital curves approximation;genetic algorithms;curve fitting;exploration algorithm;multiobjective genetic algorithm	In this paper, a digital planar curve approximation method based on a multi-objective genetic algorithm is proposed. In this method, the optimization/exploration algorithm locates breakpoints on the digital curve by minimizing simultaneously the number of breakpoints and the approximation error. Using such an approach, the algorithm proposes a set of solutions at its end. The user may choose his own solution according to its objective. The proposed approach is evaluated on curves issued from the literature and compared successfully with many classical approaches	approximation error;breakpoint;genetic algorithm;mathematical optimization	Hervé Locteau;Romain Raveaux;Sébastien Adam;Yves Lecourtier;Pierre Héroux;Éric Trupin	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.276	mathematical optimization;approximation error;combinatorics;polynomial-time approximation scheme;meta-optimization;genetic algorithm;ramer–douglas–peucker algorithm;computational geometry;machine learning;mathematics;minimax approximation algorithm;approximation algorithm;statistics;curve fitting;approximation theory	Robotics	30.25105937113726	-1.6644602857008608	151993
58ec61f885f0299e0964394a658881ce76053d8b	drift analysis and linear functions revisited	drift analysis;optimization drift analysis evolutionary algorithm arbitrary linear pseudo boolean function unique global optimum;evolutionary computation;boolean functions;helium;random variables;runtime;linear functionals;upper bound;optimization evolutionary computation helium runtime random variables upper bound markov processes;genetic algorithms boolean functions;genetic algorithms;optimization;markov processes;evolutionary algorithm;pseudo boolean;arbitrary linear pseudo boolean function;lower bound;unique global optimum	We regard the classical problem how the (1+1) Evolutionary Algorithm optimizes an arbitrary linear pseudo-Boolean function. We show that any such function is optimized in time (1 + o(1)) 1.39en ln (n), where n is the length of the bit string. We also prove a lower bound of (1 −o(1))en ln(n), which in fact holds for all functions with a unique global optimum. This shows that for linear functions, even though the optimization behavior might differ, the resulting runtimes are very similar. Our experimental results suggest that the true optimization times are even closer than what the theoretical guarantees promise.	bit array;evolutionary algorithm;global optimization;like button;linear function;mathematical optimization;newton's method;pseudo-boolean function;rice's theorem;yao graph	Benjamin Doerr;Daniel Johannsen;Carola Doerr	2010	IEEE Congress on Evolutionary Computation	10.1109/CEC.2010.5586097	mathematical optimization;combinatorics;discrete mathematics;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;upper and lower bounds;statistics;evolutionary computation	Theory	29.39274905692367	1.8457884633803936	152072
ca8faa4c804fec616edfb59d04c54bff31abef46	a two-stage hybrid ant colony algorithm for the cvrp	minimisation;two stage hybrid ant colony algorithm;meta heuristic;transition probability capacitated vehicle routing problem two stage hybrid ant colony algorithm combinatorial optimization problem meta heuristic travel cost minimization iterated local search randomized algorithm;probability;approximation algorithms;routing;transition probability;iterated local search;ant colony;benchmark problem;capacitated vehicle routing problem;combinatorial optimization problem;randomised algorithms;randomized algorithm ant colony system capacitated vehicle routing problem combinatorial optimization iterated local search;iterative methods;travel cost minimization;travel cost;ant colony system;ant colony algorithm;transportation;randomized algorithm;transportation combinatorial mathematics iterative methods minimisation probability randomised algorithms search problems;cities and towns;optimization;routing costs ant colony optimization traveling salesman problems computational intelligence security sun intelligent vehicles power generation economics scattering;search problems;vehicles;probabilistic logic;combinatorial optimization;combinatorial mathematics;algorithm design and analysis	Capacitated vehicle routing problem(CVRP) is an important combinatorial optimization problem which has received considerable attention in the last decades. The Ant Colony system (ACS) is a metaheuristic which is inspired by the trail following behavior of real ant colonies. This paper proposes a two-stage hybrid ACS algorithm for CVRP. The algorithm first minimizes the number of vehicles using ACS and then minimizes travel cost using iterated local search(ILS). In first stage, we revised the ACS algorithm with randomized algorithm(RA) to compute the transition probability. Experimental results for partial benchmark problems demonstrate the effectiveness of the algorithm.	ant colony optimization algorithms;benchmark (computing);combinatorial optimization;computation;display resolution;experiment;iterated local search;iteration;local search (optimization);markov chain;mathematical optimization;metaheuristic;optimization problem;randomized algorithm;vehicle routing problem	Chengming Qi;Shoumei Cui;Yunchuan Sun	2008	2008 International Conference on Computational Intelligence and Security	10.1109/CIS.2008.209	algorithm design;minimisation;transport;markov chain;mathematical optimization;routing;ant colony optimization algorithms;combinatorial optimization;computer science;artificial intelligence;ant colony;machine learning;probability;iterated local search;mathematics;iterative method;probabilistic logic;randomized algorithm	Robotics	25.7831809950662	-0.8614527718443838	152534
106d9ed2a528d1db39b5eb41980a577a92973b4f	the way of improving pso performance: medical imaging watermarking case study		Particle Swarm Optimization (PSO) and Genetic Algorithms (GA) are population based heuristic search techniques which can be used to solve the optimization problems modeled on the concept of evolutionary approach. In this paper we incorporate PSO with GA in hybrid technique called GPSO. This paper proposes the use of GPSO in designing an adaptive medical watermarking algorithm. Such algorithm aim to enhance the security, confidentiality , and integrity of medical images transmitted through the Internet. The experimental results show that the proposed algorithm yields a watermark which is invisible to human eyes and is robust against a wide variety of common attacks.	medical imaging;particle swarm optimization	Mona M. Soliman;Aboul Ella Hassanien;Hoda M. Onsi	2012		10.1007/978-3-642-32115-3_28	computer vision;simulation;engineering;multimedia	HPC	36.56076841450283	-8.934532740955214	152579
1b28e29e934bbb758ff57d1c9ac71d86c224ea06	feature-based aggregation and deep reinforcement learning: a survey and some new implementations		In this paper we discuss policy iteration methods for approximate solution of a finite-state discounted Markov decision problem, with a focus on feature-based aggregation methods and their connection with deep reinforcement learning schemes. We introduce features of the states of the original problem, and we formulate a smaller “ aggregate ” Markov decision problem, whose states relate to the features. We discuss properties and possible implementations of this type of aggregation, including a new approach to approximate policy iteration. In this approach the policy improvement operation combines feature-based aggregation with feature construction using deep neural networks or other calculations. We argue that the cost function of a policy may be approximated much more accurately by the nonlinear function of the features provided by aggregation, than by the linear function of the features provided by neural network-based reinforcement learning, thereby potentially leading to more effective policy improvement.		Dimitri P. Bertsekas	2019	IEEE/CAA Journal of Automatica Sinica		implementation;control engineering;feature extraction;artificial neural network;decision problem;reinforcement learning;linear function;nonlinear system;mathematics;artificial intelligence;markov chain	ML	35.376304638697796	-6.7812557008383765	152598
e1189330a5c0dc1fd9640b071fe733b5508af92b	solving tsp problems with hybrid estimation of distribution algorithms		In this paper, a hybrid Estimation of Distribution Algorithms is proposed to solve traveling salesman problem, and a greedy algorithm is used to improve the quality of the initial population. It sets up a Bayes probabilistic model of the TSP. The roulette method is adopted to generate the new population. In order to prevent falling into local optimum, the mutation and limit were proposed to enhance the exploitation ability. At the same time, three new neighborhood search strategies and the second element optimization method are presented to enhance the ability of the local search. The simulation results and comparisons based on benchmarks validate the efficiency of the proposed algorithm.	estimation of distribution algorithm	Xiaoxia Zhang;Yunyong Ma	2014		10.1007/978-3-319-09333-8_9	mathematical optimization;machine learning;mathematics;algorithm	Theory	26.556820593737317	-3.3317577053861145	152799
83bec11fcdf3c42bdb0919eec42b7dc0c3030113	particle swarm with equilibrium strategy of selection for multi-objective optimization	particle swarm;multicriteria analysis;multiobjective programming;programmation multiobjectif;swarm intelligence;particle swarm equilibrium strategy of selection multi objective optimization preference ordering;intelligence en essaim;optimizacion pso;relacion orden;equilibrium strategy of selection;multi objective optimization;multi objective evolutionary algorithm;ordering;algoritmo genetico;relation ordre;hierarchical classification;multi objective particle swarm optimization;particle swarm optimization;preferencia;algorithme genetique;classification hierarchique;optimisation pso;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;preference;analisis multicriterio;analyse multicritere;evolutionary algorithm;preference ordering;inteligencia de enjambre;clasificacion jerarquizada;programacion multiobjetivo	A new ranking scheme based on equilibrium strategy of selection is proposed for multi-objective particle swarm optimization (MOPSO), and the preference ordering is used to identify the best compromise in the ranking stage. This scheme increases the selective pressure, especially when the number of objectives is very large. The proposed algorithm has been compared with other multi-objective evolutionary algorithms (MOEAs). The experimental results indicate that our algorithm produces better convergence performance.	mathematical optimization;multi-objective optimization;particle swarm optimization	Yujia Wang;Yupu Yang	2010	European Journal of Operational Research	10.1016/j.ejor.2008.12.026	mathematical optimization;multi-swarm optimization;swarm intelligence;computer science;artificial intelligence;evolutionary algorithm;mathematics;mathematical economics;particle swarm optimization	AI	26.57255539922336	0.907916887013843	152971
0c24e3ab0e4def4bf783583c844e9e5c7cbe9c16	algorithm 909: nomad: nonlinear optimization with the mads algorithm	constrained optimization;blackbox optimization;mesh adaptive direct search;mads mesh adaptive direct search;optimization software;nonlinear optimization	NOMAD is software that implements the Mesh Adaptive Direct Search (MADS) algorithm for blackbox optimization under general nonlinear constraints. Blackbox optimization is about optimizing functions that are usually given as costly programs with no derivative information and no function values returned for a significant number of calls attempted. NOMAD is designed for such problems and aims for the best possible solution with a small number of evaluations. The objective of this article is to describe the underlying algorithm, the software’s functionalities, and its implementation.	algorithm;mathematical optimization;nonlinear programming;nonlinear system	Sébastien Le Digabel	2011	ACM Trans. Math. Softw.	10.1145/1916461.1916468	mathematical optimization;constrained optimization;simulation;derivative-free optimization;theoretical computer science;mathematics	Graphics	29.933153053032807	-0.5909628305015886	153032
aadd2d35d6041002da44807be463eaaec1e15b67	design of bio-inspired heuristic techniques hybridized with sequential quadratic programming for joint parameters estimation of electromagnetic plane waves	direction of arrival;genetic algorithms;memetic computing;sequential quadratic programming;parameters estimations	In this study, intelligent hybrid computing techniques are developed using variants of genetic algorithms (GAs) to estimate jointly direction of arrival and amplitude of electromagnetic planewaves.Fitness evaluation function is formulated for parameter estimationmodelbyexploiting the approximation theory in mean square sense based on error between the desired and estimated responses.Optimization of designvariables of themodel is carried outwith hybrid schemes through variant of GAs integrated with sequential quadratic programming for rapid refinement. Proposed schemes are applied to number of electromagnetic plane waves impinging on uniform linear array from different directions with different amplitudes. Comparison of the results is done with true parameters of the system in order to evaluate the performance of the algorithms. Monte-Carlo simulations for the design approaches are carried out to analyze their strength in terms of estimation accuracy, robustness against noise, convergence and proximity effects. Electronic supplementary material The online version of this article (doi:10.1007/s11277-017-4251-y) contains supplementary material, which is available to authorized users. Sadiq Akbar, Muhammad Asif Zahoor Raja, Fawad Zaman, Tariq Mehmood and Muhammd Abdul Rehman Khan have contributed equally to this work. & Muhammad Asif Zahoor Raja rasifzahoor@yahoo.com Sadiq Akbar sadiqakbar@upesh.edu.pk Fawad Zaman fawad@ciit-attock.edu.pk Tariq Mehmood ftexplore@gmail.com Muhammd Abdul Rehman Khan mohakhan@yahoo.com 1 Department of Electronics, University of Peshawar, Peshawar, Pakistan 2 Department of Electrical Engineering, COMSATS Institute of Information Technology, Attock Campus, Attock, Pakistan 123 Wireless Pers Commun DOI 10.1007/s11277-017-4251-y	approximation theory;authorization;direction of arrival;electrical engineering;estimation theory;evaluation function;genetic algorithm;heuristic;mean squared error;refinement (computing);sequential quadratic programming;simulation	Sadiq Akbar;Raja Muhammad Asif Zahoor;Fawad Zaman;Tariq Mehmood;Muhammad Abdul Rehman Khan	2017	Wireless Personal Communications	10.1007/s11277-017-4251-y	genetic algorithm;computer science;theoretical computer science;quadratic programming;sequential quadratic programming;mathematical optimization;heuristic;plane wave;direction of arrival	Robotics	31.030733396755515	-4.908469167758192	153360
556cf651832c6f637d8c226f3a062923cbc4d493	asymptotic behavior of minimal-exploration allocation policies: almost sure, arbitrarily slow growing regret		The purpose of this paper is to provide further understandin g into the structure of the sequential allocation (“stochastic multi-armed bandit”, or MAB) problem by establishing probability one finite horizon bounds and convergence rates for the sampl e (or “pseudo”) regret associated with two simple classes of allocation policies π . For any slowly increasing function g, subject to mild regularity constraints, we construct two policies (theg-Forcing, and theg-Inflated Sample Mean) that achieve a measure of regret of orderO(g(n)) almost surely asn→ ∞, bound from above and below. Additionally, almost sure upper and lower bounds on the remainder term are establi shed. In the constructions herein, the functiong effectively controls the “exploration” of the classical “e xploration/exploitation” tradeoff.	multi-armed bandit;regret (decision theory)	Wesley Cowan;Michael N. Katehakis	2015	CoRR		mathematical optimization;combinatorics;mathematics	ML	36.94403514989266	3.7040335673253013	153569
3e3f56d52bcb9135f96b839a1f1b82f8b046d3e7	solution of fuzzy relational equation by real-valued ga	computers;genetic algorithms fuzzy set theory;fuzzy relational equation;fuzzy relation;exact solution;max product composition;fuzzy set theory;fuzzy sets;real valued ga;approximate solution;mathematical model;max product composition fuzzy relational equation real valued ga genetic algorithm;equations genetic algorithms intelligent systems fuzzy systems matrix decomposition fuzzy sets;genetic algorithm;genetic algorithms;gallium;noise	Solving fuzzy relational equation (F.R.E) is a very important research topic because many practical problems end up with F.R.E. Most theoretical results on F.R.E. strongly rely on an assumption that the family of exact solutions is nonempty. However, it's quite common that F.R.E. have no solutions. Therefore, this paper uses the real-valued genetic algorithm to solve an approximate solution for the F.R.E based on the max-product composition. An example will be illustrated for the proposed method.	approximation algorithm;genetic algorithm;software release life cycle	Leh Luoh	2008	2008 Eighth International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2008.297	mathematical optimization;discrete mathematics;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;fuzzy set	Robotics	35.690885228057105	0.824394334519463	153819
f5bb5bc6a078cc466a0574f4ea4312343b6f78ad	research on network-on-chip automatically generate method based on hybrid optimization mapping		To solve underperforming particle swarm optimization algorithm for the optimization problem of discrete and easy to fall into local optimum problem in network on chip mapping algorithm, a hybrid optimization mapping Algorithm based on particle swarm optimization and genetic algorithm is proposed. It will implement separately GA and PSO operations by the two groups, by the superior individuals from GA algorithm instead of the initial random particles from PSO algorithm, which not only maintains the diversity of the group but also improves search efficiency. Simulation results based on NS-2 show that the Network-on-Chip from the automatic generation tools based on hybrid optimization mapping algorithm have a good performance in network latency, throughput, and link bandwidth optimization comparing the results of the random mapping under the same amount of computation scale.	network on a chip;program optimization	Chao Li;Yuqiang Chen	2016		10.1007/978-981-10-3614-9_31	mathematical optimization;throughput;local optimum;genetic algorithm;machine learning;artificial intelligence;computation;hybrid algorithm;computer science;network on a chip;optimization problem;particle swarm optimization	EDA	26.365901205972406	-4.280641553830728	153835
91e5a2d925fa8f7de2b2658b988474d517802809	differential evolution with an individual-dependent mechanism	manufacturing systems;electronic mail;differential evolution de;materials;global numerical optimization;logistics;parameter setting differential evolution global numerical optimization individual dependent mutation strategy;individual dependent;vectors evolutionary computation optimisation search problems;parameter setting;article;materials educational institutions logistics electronic mail benchmark testing laboratories manufacturing systems;benchmark testing;fitness values differential evolution de individual dependent mechanism optimization algorithm perturb base vectors idp setting individual dependent mutation strategy idm strategy mutation operators searching characteristics;mutation strategy	Differential evolution (DE) is a well-known optimization algorithm that utilizes the difference of positions between individuals to perturb base vectors and thus generate new mutant individuals. However, the difference between the fitness values of individuals, which may be helpful to improve the performance of the algorithm, has not been used to tune parameters and choose mutation strategies. In this paper, we propose a novel variant of DE with an individual-dependent mechanism that includes an individual-dependent parameter (IDP) setting and an individual-dependent mutation (IDM) strategy. In the IDP setting, control parameters are set for individuals according to the differences in their fitness values. In the IDM strategy, four mutation operators with different searching characteristics are assigned to the superior and inferior individuals, respectively, at different stages of the evolution process. The performance of the proposed algorithm is then extensively evaluated on a suite of the 28 latest benchmark functions developed for the 2013 Congress on Evolutionary Computation special session. Experimental results demonstrate the algorithm's outstanding performance.	algorithm;benchmark (computing);code;continuation;differential evolution;distribution (mathematics);evolutionary computation;experiment;integrated development environment;iteration;matlab;mathematical optimization;mutation testing;no free lunch theorem;performance;population	Lixin Tang;Yun Dong;Jiyin Liu	2015	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2014.2360890	logistics;benchmark;mathematical optimization;simulation;computer science;artificial intelligence;machine learning;evolutionary algorithm;algorithm	Visualization	27.086734953041343	-5.599970143659561	153910
3d96dd37b7dbf9899977b79d2a955eadacf0d38b	exploration and exploitation without mutation: solving the jump function in \vartheta (n) time		A number of modern hybrid genetic algorithms do not use mutation. Instead, these algorithms use local search to improve intermediate solutions. This same strategy of combining local search and crossover is also used by stochastic local algorithms, such the LKH heuristic for the Traveling Salesman Problem. We prove that a simple hybrid genetic algorithm that uses only local search and a form of deterministic “voting crossover” can solve the well known Jump Function in (varTheta (n)) time where the jump distance is log(n).		L. Darrell Whitley;Swetha Varadarajan;Rachel Hirsch;Anirban Mukhopadhyay	2018		10.1007/978-3-319-99259-4_5	genetic algorithm;mathematical optimization;machine learning;artificial intelligence;travelling salesman problem;computer science;local search (optimization);crossover;heuristic;jump	Crypto	26.692810409524082	-2.2985863651542817	153979
2a9de693920e4db19ef46479da569ab156c56807	methods for evolving robust programs	genetic program;fitness sharing;search space;random sampling;coevolution;ge netic programming;evolutionary computing	Many evolutionary computation search spaces require fitness assessment through the sampling of and generalization over a large set of possible cases as input. Such spaces seem particularly apropos to Genetic Programming, which notionally searches for computer algorithms and functions. Most existing research in this area uses ad-hoc approaches to the sampling task, guided more by intuition than understanding. In this initial investigation, we compare six approaches to sampling large training case sets in the context of genetic programming representations. These approaches include fixed and random samples, and adaptive methods such as coevolution or fitness sharing. Our results suggest that certain domain features may lead to the preference of one approach to generalization over others. In particular, coevolution methods are strongly domain-dependent. We conclude the paper with suggestions for further investigations to shed more light onto how one might adjust fitness assessment to make various methods more effective.	4-bit;approximation algorithm;evolutionary computation;genetic programming;hoc (programming language);multiplexer;multitier architecture;overfitting;parity bit;problem domain;sampling (signal processing);sequence read archive;symbolic regression	Liviu Panait;Sean Luke	2003		10.1007/3-540-45110-2_66	sampling;mathematical optimization;coevolution;computer science;artificial intelligence;machine learning;mathematics;fitness function;evolutionary computation	ML	24.63065748114884	-8.872959421734487	153984
623c3e4bcff7164a2aaefff53222551ff6a5bec3	improving particle swarm optimization using co-optimization of particles and acceleration constants		Particle swarm optimization exhibits effective performance for solving difficulties in real-world problems. However, the determination of acceleration constants, which influence the performance of PSO significantly and varies between different problems, is hard to tune. This paper presents a co-optimization strategy of particles and acceleration constants, which incorporates the optimization of parameters into the basic framework of optimization and extends the dimension of particles and embeds the acceleration constants at the additional part. Experiment results manifest that the proposed algorithm shows satisfactory performance.	mathematical optimization;particle swarm optimization;program optimization	Lin Wang;Bo Yang;Zhenxiang Chen	2016		10.1007/978-3-319-52941-7_57	mathematical optimization;acceleration;particle swarm optimization;physics	EDA	28.079884714505294	-4.091500179305396	154315
51387d8f2f6e05bf41c657458e22fbda96a8d085	differential evolution with polymorphic schemes	adaptive scheme changing symbols;histograms;evolutionary computation space technology cybernetics usa councils histograms sampling methods differential equations genetic mutations organisms computer viruses;differential evolution;evolutionary computation;polymorphic symbol;scheme selection problem polymorphic schemes evolutionary algorithm polymorphic differential evolution adaptive scheme changing symbols roulette wheel sampling;scheme selection problem;probability density function;polymorphic differential evolution;adaptive scheme;polymorphic equation;data mining;scheme selection;polymorphic schemes;indexes;chromium;scheme selection differential evolution adaptive scheme polymorphic scheme polymorphic equation polymorphic symbol;polymorphism;evolutionary algorithm;sampling methods;polymorphic scheme;roulette wheel sampling;sampling methods evolutionary computation;benchmark testing	In recent years a new evolutionary algorithm for optimization in continuous spaces called Differential Evolution (DE) has developed. If one wants to apply DE one has to specify several parameters as well as to select a scheme. Several schemes being widely used can be found in literature. This raises the question, which one fits best to your application at hand. To get rid of this scheme selection problem, a new concept called Polymorphic Differential Evolution (PolyDE) is proposed. PolyDE generalizes the standard schemes by a polymorphic scheme. The mathematical expression of this polymorphic scheme can be changed on symbolic level. This polymorphic scheme is an adaptive scheme changing symbols based on accumulative histograms and roulette-wheel sampling. PolyDE is applied to four typical benchmark functions known from literature and its performance is ranked between the top and middle region compared to all standard DE schemes. Since PolyDE performs not worse than the other schemes it can be used as alternative to them solving this way the scheme selection problem. The best performance is obtained for the multimodal functions.	benchmark (computing);definition;differential evolution;evolutionary algorithm;fits;mathematical optimization;multimodal interaction;sampling (signal processing);selection algorithm;v-optimal histograms	Christian Veenhuis;Mario Köppen	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346652	differential evolution;polymorphism;mathematical optimization;probability density function;chromium;discrete mathematics;computer science;evolutionary algorithm;mathematics;algorithm;statistics;evolutionary computation	Vision	27.510008268776442	-7.230424485071797	154769
f524c6cae94aa8334a9c7562e9edd7ed3c926cb4	momentum coefficient for promoting accuracy and convergence speed of evolutionary programming	momentum coefficient evolutionary programming;evolutionary programming;gathering point;mean value	Many practical problems culminate with solving optimization problems. Thus, many methods have been introduced for solving these types of problems. The need for algorithms that are fast and more accurate at finding global minimums is ever increasing. One of the promising methods is a heuristic and iterative method called Evolutionary Programming (EP). It is one of the computational methods used in optimization that is implemented for many practical applications. Many papers have shown the capability of this algorithm for addressing a variety of optimization problems. These studies have opened a vast new and interesting field of research. Recently, many methods have been proposed for promoting the performance of EP when finding the optimum point of functions or applications; however, EP has some shortcomings that cause slow convergence on some functions, especially multimodal functions. By overcoming these shortcomings, EP could be more effective in the optimization research field. This paper introduces new methods for overcoming these disadvantages and promoting the performance of EP. One of these methods, which has the best results on cost functions, changes the searching procedure by adding a new factor to produce offspring and pulling offspring toward a gathering point (the mean value of the parents). This method was tested on 50 well-known test functions discussed in the literature and was compared with state-of-the-art algorithms on twenty-two new cost functions. Finally, a hybrid method of CEP and MCEP (Momentum Coefficient Evolutionary Programming) called IMCEP (Improved Momentum Coefficient Evolutionary Programming) is introduced. The results of the calculations reported here show the efficiency of MCEP and IMCEP.	coefficient;evolutionary programming	Yousef Alipouri;Javad Poshtan;Yagub Alipouri;Mohammad Reza Alipour	2012	Appl. Soft Comput.	10.1016/j.asoc.2012.01.010	evolutionary programming;mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;algorithm;statistics;mean	Robotics	28.68451303083838	-3.174550314593116	154930
3c094d09acc724f615933c6198822b9ac4e616ac	genetic programming algorithms for dynamic environments		Evolutionary algorithms are a family of stochastic search heuristics that include Genetic Algorithms (GA) and Genetic Programming (GP). Both GAs and GPs have been successful in many applications, mainly with static scenarios. However, many real world applications involve dynamic environments (DE). Many work has been made to adapt GAs to DEs, but only a few efforts in adapting GPs for this kind of environments. In this paper we present novel GP algorithms for dynamic environments and study their performance using three dynamic benchmark problems, from the areas of Symbolic Regression, Classification and Path Planning. Furthermore, we apply the best algorithm we found in the navigation of an Erratic Robot through a dynamic Santa Fe Ant Trail and compare its performance to the standard GP algorithm. The results, statistically validated, are very promising.	algorithm;genetic programming	João Macedo;Ernesto Costa	2016		10.1007/978-3-319-31153-1_19	quality control and genetic algorithms;genetic programming;genetic representation	PL	25.134091647498245	-4.798944777881996	154940
b4abf4266cefa3796781207a85e4776feb4fa9a7	a novel method for real parameter optimization based on gene expression programming	computer program;expression tree;computational complexity;indexation;symbolic regression;genetic algorithm;gene structure;floating point;gene expression programming;real parameter optimization;evolutionary algorithm;parameter optimization;evolutionary computing	Gene Expression Programming (GEP) is a new technique of evolutionary algorithm that implements genome/phoneme representation in computing programs. Due to its power in global search, it is widely applied in symbolic regression. However, little work has been done to apply it to real parameter optimization yet. This paper proposes a real parameter optimization method named Uniform-Constants based GEP (UC-GEP). In UC-GEP, the constant domain directly participates in the evolution. Our research conducted extensive experiments over nine benchmark functions from the IEEE Congress on Evolutionary Computation 2005 and compared the results to three other algorithms namely Meta-Constants based GEP (MC-GEP), Meta-Uniform-Constants based GEP (MUC-GEP), and the Floating Point Genetic Algorithm (FP-GA). For simplicity, all GEP methods adopt a one-tier index gene structure. The results demonstrate the optimal performance of our UC-GEP in solving multimodal problems and show that at least one GEP method outperforms FP-GA on all test functions with higher computational complexity. 2008 Elsevier B.V. All rights reserved.	benchmark (computing);computational complexity theory;distribution (mathematics);evolutionary algorithm;experiment;fp (complexity);gene expression programming;genetic algorithm;ieee congress on evolutionary computation;mathematical optimization;message understanding conference;multimodal interaction;multitier architecture;software release life cycle;symbolic regression;uc browser	Kaikuo Xu;Yintian Liu;Rong Tang;Jie Zuo;Jun Zhu;Changjie Tang	2009	Appl. Soft Comput.	10.1016/j.asoc.2008.09.007	mathematical optimization;genetic algorithm;binary expression tree;computer science;floating point;artificial intelligence;theoretical computer science;machine learning;evolutionary algorithm;gene;gene expression programming;computational complexity theory;algorithm	AI	25.80661608341085	-6.187110280281564	155125
019c9c25703bd1aa4f4864f92807f9cc32bf9b39	optimization planning based on improved ant colony algorithm for robot	optimization rules;randomness;comprehensive assessment of path;core area	As the ant colony algorithm has the defects in robot optimization path planning such as that low convergence cause local optimum, an improved ant colony algorithm is proposed to apply to the planning of path finding for robot. This algorithm uses the search way of exhumation ant to realize the complementation of advantages and accelerate the convergence of algorithm. The experimental result shows that the algorithm of this paper make the optimization planning of robot more reasonable.	algorithm;ant colony optimization algorithms;deadlock;local optimum;mathematical optimization;motion planning;pathfinding;robot;way to go	Xin Zhang;Zhanwen Wu	2014	JNW	10.4304/jnw.9.6.1542-1549	mathematical optimization;ant colony optimization algorithms;meta-optimization;computer science;artificial intelligence;machine learning;randomness;metaheuristic;statistics	Robotics	29.764380629376898	-2.6938448219104645	155193
a8bd593a6df1aeeb6301cc366c1cf02f3b7d1b2b	roach infestation optimization	particle swarm;optimization algorithm;ant colony optimization;cockroach;cockroach like robot roach infestation optimization function optimization algorithm hungry particle swarm optimization ant colony optimization cockroach social behavior individual agent behavior;radiation detectors;individual agent behavior;mobile robots;presentation;cockroach social behavior;particle swarm optimisation mobile robots multi robot systems;function optimization;collective behavior;roach infestation optimization;particle swarm optimizer;roach;aggregates particle swarm optimization ant colony optimization testing robots usa councils computational intelligence societies problem solving biological system modeling;social behavior;aggregates;particle swarm optimization;robots;multi robot systems;hungry particle swarm optimization;mathematical model;particle swarm cockroach optimization;optimization;cockroach like robot;particle swarm optimisation;function optimization algorithm	There are many function optimization algorithms based on the collective behavior of natural systems - Particle Swarm Optimization (PSO) and Ant Colony Optimization (ACO) are two of the most popular. This paper presents a new adaptation of the PSO algorithm, entitled Roach Infestation Optimization (RIO), that is inspired by recent discoveries in the social behavior of cockroaches. We present the development of the simple behaviors of the individual agents, which emulate some of the discovered cockroach social behaviors. We also describe a ldquohungryrdquo version of the PSO and RIO, which we aptly call Hungry PSO and Hungry RIO. Comparisons with standard PSO show that Hungry PSO, RIO, and Hungry RIO are all more effective at finding the global optima of a suite of test functions.	algorithm;ant colony optimization algorithms;distribution (mathematics);global illumination;mathematical optimization;optimizing compiler;particle swarm optimization;program optimization;shadow volume	Timothy C. Havens;Christopher J. Spain;Nathan G. Salmon;James M. Keller	2008	2008 IEEE Swarm Intelligence Symposium	10.1109/SIS.2008.4668317	simulation;engineering;artificial intelligence;ecology	Theory	25.997948913713007	-5.64271053745313	155351
858359fde18a4129ff717e62668e87bda973c29c	quantum ant colony algorithm-based emergency evacuation path choice algorithm	ant colony optimisation;convergence;emergency management;quantum theory ant colony optimisation convergence disasters emergency management network theory graphs;q bit quantum ant colony algorithm based emergency evacuation path choice algorithm evacuation path optimization disaster area human harm reduction social harm reduction qaca global optimal solution;quantum theory;path choice emergency evacuation quantum ant colony algorithm;network theory graphs;optimization logic gates convergence mathematical model sociology statistics quantum computing;disasters	The evacuation path optimization in the disaster area plays an important role in reducing the human and social harm and saving aid time. In this paper, a novel algorithm for emergency evacuation path choice based on quantum ant colony algorithm (QACA) is proposed, and it avoids premature convergence and speeds up the convergence to the global optimal solution. In the proposed algorithm, Q-bit is used to represent the pheromone, and the rotation gate is used to update the pheromone. Simulation results show that the proposed algorithm is feasible and effective.	algorithm;ant colony optimization algorithms;mathematical optimization;premature convergence;quantum;simulation	Feng Zhang;Min Liu;Zhuo Zhou;Weiming Shen	2013	Proceedings of the 2013 IEEE 17th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2013.6581025	disaster;ant colony optimization algorithms;simulation;convergence;computer science;artificial intelligence;emergency management	EDA	29.21965046792229	-2.5751856588361943	155711
b224d6f94e874df9cee324d1e085c5d130d0acf8	quantum immune algorithm and its application in collision detection	non linear programming;immune algorithm;collision detection;extreme value;quantum genetic algorithm;genetic algorithm;virtual environment	Collision detection is very important to improve the truth and immersion in the virtual environment. Firstly the paper analyzes the problems that exist in traditional algorithms. There is no algorithm suitable to every situation, and the more complex the situations are, the more rapidly the efficiency declines. Secondly the paper analyses the problem of collision detection in theory, and then converts the problem of the collision detection to the non-linear programming problem with restricted conditions. In this paper, the definition of the distance between two objects and for which the quantum coding is given. Through the steps, such as quantum clone, quantum variation, the problem of collision detection is solved. Finally, the simulation test shows that the quantum-inspired immune algorithm has much more effective impact on solving the extreme-value problem compared to the traditional genetic algorithm. It is feasible to use the algorithm in collision detection.	algorithm;collision detection;quantum	Jue Wu;Lingxi Peng;Lixue Chen;Lei Yang	2010		10.1007/978-3-642-15597-0_16	mathematical optimization;genetic algorithm;nonlinear programming;computer science;virtual machine;artificial intelligence;theoretical computer science;extreme value theory;mathematics;collision detection;algorithm;quantum phase estimation algorithm;statistics	Robotics	27.97728376354222	-2.5410654318767363	155792
6397e563306612a5456b73cfbe8456bc5131c013	impact of crossover probability on symmetric travel salesman problem efficiency	genetic algorithm;crossover;tsp;mutation	Genetic algorithm (GA) is a powerful evolutionary searching technique that is used successfully to solve and optimize problems in different research areas. Genetic Algorithm (GA) considered as one of optimization methods used to solve Travel salesman Problem (TSP). The feasibility of GA in finding TSP solution is dependent on GA operators; encoding method, population size, number of generations in general. In specific, crossover and its probability play a significant role in finding possible solution for Symmetric TSP (STSP). In addition, crossover should be determined and enhanced in term reaching optimal or at least near optimal. In This paper, we spot the light on using modified crossover method called Modified sequential constructive crossover and its impact on reaching optimal solution. To justify the relevance of parameters value in solving TSP, a set comparative analysis conducted on different crossover methods values.		Wafa' Alsharafat;Suhila Farhan Abu-owida	2015	iJIM		mutation;mathematical optimization;crossover;genetic algorithm;computer science;artificial intelligence;algorithm	AI	26.097242854298113	-3.1530879294802925	155882
7411b8f25aaf3a408b5f2b0870609ad864a29786	application of artificial bee colony algorithm to topology optimization for dynamic stiffness problems	finite element method;topology optimization;natural frequency;artificial bee colony algorithm;stochastic search method	The artificial bee colony algorithm (ABCA) was first adopted in topology optimization for dynamic problems. The objective was to obtain a structure with the highest fundamental natural frequency in a certain amount of material, based on the contributed structural sensitivity of each element calculated by the waggle index and eigenvalue. The waggle index update rule, evaluation method of fitness values, and changing filtering size scheme are suggested for obtaining a stable and robust optimal topology based on the ABCA. Examples are provided to examine the applicability and effectiveness of the ABCA compared to bi-directional evolutionary structural optimization (BESO). The following conclusions are obtained through the results of examples based on the ABCA; (1) the ABCA, using the three suggested methods, is very applicable and effective in topology optimization for obtaining a stable and robust optimal layout. (2) It is found that the natural frequencies of the ABCA are always higher than those of the BESO, and average convergence rates of the ABCA are similar or faster than those of the BESO. (3) The optimal topology from the ABCA is nearly obtained in a half stage of the convergence iteration, since volume constraint is applied from the beginning.	artificial bee colony algorithm;mathematical optimization;topology optimization	Ji-Yong Park;Seog-Young Han	2013	Computers & Mathematics with Applications	10.1016/j.camwa.2013.05.030	natural frequency;mathematical optimization;topology optimization;artificial intelligence;finite element method;mathematics;artificial bee colony algorithm	HPC	29.178208152084	-2.4504936863474085	155996
9ebb5d3fcd885602232da299f6fa5f4a12419245	an efficient evolutionary algorithm applied to the design of two-dimensional iir filters	differential evolution;iir filter;constrained minimization;digital filter;filter design;particle swarm optimizer;design method;particle swarm optimization;genetic algorithm;evolutionary algorithm	This paper presents an efficient technique of designing two-dimensional IIR digital filters using a new algorithm involving the tightly coupled synergism of particle swarm optimization and differential evolution. The design task is reformulated as a constrained minimization problem and is solved by our newly developed PSO-DV (Particle Swarm Optimizer with Differentially perturbed Velocity) algorithm. Numerical results are presented. The paper also demonstrates the superiority of the proposed design method by comparing it with two recently published filter design methods.	differential evolution;digital filter;evolutionary algorithm;filter design;infinite impulse response;mathematical optimization;numerical method;particle swarm optimization;velocity	Swagatam Das;Amit Konar;Uday Kumar Chakraborty	2005		10.1145/1068009.1068364	differential evolution;mathematical optimization;multi-swarm optimization;meta-optimization;genetic algorithm;digital filter;design methods;computer science;evolutionary algorithm;control theory;mathematics;filter design;particle swarm optimization;infinite impulse response	EDA	31.212200870289692	-4.340414057246647	156160
d97a9d46d31d9ec772919b03430bf323644e43ca	efficient micro immune optimization approach solving constrained nonlinear interval number programming	nonlinear programming;immune optimization;optimal valued interval;interval number;interval analysis	This work investigates a possibility degree-based micro immune optimization approach to seek the optimal solution of nonlinear interval number programming with constraints. Such approach is designed under the guideline of the theoretical results acquired in the current work, relying upon interval arithmetic rules, interval order relation and immune theory. It involves in two phases of optimization. The first phase, based on a new possibility degree approach, assumes searching efficient solutions of natural interval extension optimization. This executes five modules - constraint bound handling, population division, dynamic proliferation, mutation and selection, with the help of a varying threshold of interval bound. The second phase collects the optimal solution(s) from these efficient solutions after optimizing the bounds of their objective intervals, in terms of the theoretical results. The numerical experiments illustrated that such approach with high efficiency performs well over one recent nested genetic algorithm and is of potential use for complex interval number programming.	experiment;genetic algorithm;interval arithmetic;mathematical optimization;nonlinear system;numerical analysis	Zhuhong Zhang;Juan Tao	2014	Applied Intelligence	10.1007/s10489-014-0639-5	mathematical optimization;nonlinear programming;interval arithmetic	AI	30.980371783671877	-3.806521349507386	156279
99829cffd59d325c06d69608e2a85ad6500e3757	an adaptive brain storm optimization algorithm for multiobjective optimization problems	mutation method;multiobjective optimization;brain storm optimization;clustering operation	Brain Storm Optimization BSO algorithm is a new swarm intelligence method that arising from the process of human beings problem-solving. It has been well validated and applied in solving the single objective problem. In order to extend the wide applications of BSO algorithm, a modified Self-adaptive Multiobjective Brain Storm Optimization SMOBSO algorithm is proposed in this paper. Instead of the $$k$$k-means clustering of the traditional algorithm, the algorithm adopts the simple clustering operation to increase the searching speed. At the same time, the open probability is introduced to avoid the algorithm trapping into local optimum, and an adaptive mutation method is used to give an uneven distribution on solutions. The proposed algorithm is tested on five benchmark functions; and the simulation results showed that the modified algorithm increase the diversity as well as the convergence successfully. The conclusions could be made that the SMOBSO algorithm is an effective BSO variant for multiobjective optimization problems.	algorithm;multi-objective optimization;optimization problem;program optimization	Xiaoping Guo;Yali Wu;Lixia Xie;Shi Cheng;Jing Xin	2015		10.1007/978-3-319-20466-6_39	mathematical optimization;multi-swarm optimization;meta-optimization;computer science;artificial intelligence;multi-objective optimization;fsa-red algorithm;algorithm;population-based incremental learning	ML	27.041577928010685	-4.668402611939507	156352
7bbb959b3c4209463d1a6995ddd7d4db4637d609	parameter estimation of bilinear systems based on an adaptive particle	adaptive particle swarm optimization;inertia weight;bilinear systems;particle swarm optimizer;bilinear system;genetic algorithm;optimization algorithms;parameter estimation;nonlinear system;particle swarm optimization algorithm;optimal algorithm;large classes;basic particle swarm optimization	Bilinear models can approximate a large class of nonlinear systems adequately and usually with considerable parsimony in the number of coefficients required. This paper presents the application of Particle Swarm Optimization (PSO) algorithm to solve both offline and online parameter estimation problem for bilinear systems. First, an Adaptive Particle Swarm Optimization (APSO) is proposed to increase the convergence speed and accuracy of the basic particle swarm optimization to save tremendous computation time. An illustrative example for the modeling of bilinear systems is provided to confirm the validity, as compared with the Genetic Algorithm (GA), Linearly Decreasing Inertia Weight PSO (LDW-PSO), Nonlinear Inertia Weight PSO (NDW-PSO) and Dynamic Inertia Weight PSO (DIW-PSO) in terms of parameter accuracy and convergence speed. Second, APSO is also improved to detect and determine varying parameters. In this case, a sentry particle is introduced to detect any changes in system parameters. Simulation results confirm that the proposed algorithm is a good promising particle swarm optimization algorithm for online parameter estimation.		Hamidreza Modares;Alireza Alfi;Mohammad-Bagher Naghibi Sistani	2010	Eng. Appl. of AI	10.1016/j.engappai.2010.05.003	mathematical optimization;multi-swarm optimization;meta-optimization;genetic algorithm;nonlinear system;computer science;derivative-free optimization;machine learning;estimation theory;imperialist competitive algorithm;particle swarm optimization;metaheuristic;statistics	AI	31.11599875119579	-6.293589719110762	156386
363297423fc42d4fd7f2a634b6a62c9057e04e90	the efficient frontier in randomized social choice		Since the celebrated Gibbard-Satterthwaite impossibility results and Gibbard’s 1977 extension for randomized rules, it is known that strategyproofness imposes severe restrictions on the design of social choice rules. In this paper, we employ approximate strategyproofness and the notion of score deficit to study the possible and necessary trade-offs between strategyproofness and efficiency in the randomized social choice domain. In particular, we analyze which social choice rules make optimal trade-offs, i.e., we analyze the efficient frontier. Our main result is that the efficient frontier consists of two building blocks: (1) we identify a finite set of ‘‘manipulability bounds’’ B and the rules that are optimal at each of them; (2) for all other bounds not in B, we show that the optimal rules at those bounds are mixtures of two rules that are optimal at the two nearest manipulability bounds from B. We provide algorithms that exploit this structure to identify the entire efficient frontier for any given scoring function. Finally, we provide applications of our results to illustrate the structure of the efficient frontier for the scoring functions v p1, 0, 0q and v p1, 1, 0q.	approximation algorithm;randomized algorithm;scoring functions for docking	Timo Mennle;Sven Seuken	2015	CoRR		mathematical optimization;mathematics;mathematical economics;welfare economics;statistics	AI	36.83575794713979	3.554099384401387	156518
868fa9f4d4e73a1d91e6ef2d5bab7fb69cbbbd7a	mine blast algorithm: a new population based algorithm for solving constrained engineering optimization problems	constrained optimization;engineering design problems;constraint handling;global optimization;mine blast algorithm;school of engineering sciences;metaheuristic	A novel population-based algorithm based on the mine bomb explosion concept, called the mine blast algorithm (MBA), is applied to the constrained optimization and engineering design problems. A comprehensive comparative study has been carried out to show the performance of the MBA over other recognized optimizers in terms of computational effort (measured as the number of function evaluations) and function value (accuracy). Sixteen constrained benchmark and engineering design problems have been solved and the obtained results were compared with other well-known optimizers. The obtained results demonstrate that, the proposed MBA requires less number of function evaluations and in most cases gives better results compared to other considered algorithms.	algorithm;mathematical optimization	Ali Sadollah;Ardeshir Bahreininejad;Hadi Eskandar;Mohd Hamdi	2013	Appl. Soft Comput.	10.1016/j.asoc.2012.11.026	mathematical optimization;constrained optimization;engineering optimization;computer science;artificial intelligence;algorithm;metaheuristic;global optimization	Logic	25.27198594183608	-2.907284126568693	156524
2d70b394983be9df26075ee418b45776695d7fee	exploring position independent initialisation in grammatical evolution	grammar;genetics;biological cells;shape;statistics;production;sociology	Initialisation in Grammatical Evolution (GE) is a topic that remains open to debate on many fronts. The literature falls between two mainstay approaches: random and sensible initialisation. These methods are not without their drawbacks with the type of trees generated. This paper tackles this problem by extending these traditional operators to incorporate position independence in the initialisation process in GE. This new approach to initialisation is shown to provide a viable alternative to the commonly used approaches, whilst avoiding the common pitfalls of traditional approaches to initialisation.	grammatical evolution;position-independent code;while	David Fagan;Michael Fenton;Michael O'Neill	2016	2016 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2016.7748331	shape;artificial intelligence;machine learning;grammar;algorithm;statistics	SE	26.663394234671557	-8.955846895994853	156575
643ce67891dff6bad29a4da437a68f1b389730ba	a novel approach for the elimination of artefacts from eeg signals employing an improved artificial immune system algorithm	artificial immune system;improved artificial immune system;electroocculogram;electroencephalogram;adaptive neuro fuzzy inference system;electrocardiogram	A novel approach for the elimination of artefacts from EEG signals employing an improved Artificial Immune System algorithm S. Suja Priyadharsini, S. Edward Rajan & S. Femilin Sheniha To cite this article: S. Suja Priyadharsini, S. Edward Rajan & S. Femilin Sheniha (2015): A novel approach for the elimination of artefacts from EEG signals employing an improved Artificial Immune System algorithm, Journal of Experimental & Theoretical Artificial Intelligence, DOI: 10.1080/0952813X.2015.1020571 To link to this article: http://dx.doi.org/10.1080/0952813X.2015.1020571	adaptive neuro fuzzy inference system;algorithm;artificial immune system;electroencephalography;electromyography;electrooculography;journal of experimental and theoretical artificial intelligence;mathematical optimization;software release life cycle;switch statement	S. Suja Priyadharsini;S. Edward Rajan;S. Femilin Sheniha	2016	J. Exp. Theor. Artif. Intell.	10.1080/0952813X.2015.1020571	speech recognition;adaptive neuro fuzzy inference system;computer science;artificial intelligence;machine learning;artificial immune system	AI	32.27902455890497	-5.295101264056197	156789
fab9e8869545841b8216a7210f90ec6082d28bbb	constrained real parameter optimization with an ecologically inspired algorithm	parameter free penalty function;optimisation;ecologically inspired algorithm;convergence;search space;probability density function;simulated ecology;invasive weed optimization algorithm;constrained real parameter optimization problems;biology;data mining;parameter free penalty function ecologically inspired algorithm search space invasive weed optimization algorithm constrained real parameter optimization problems;optimization problem;particle swarm optimizer;search problems optimisation;constraint optimization particle swarm optimization benchmark testing intelligent robots shape biological system modeling environmental factors lagrangian functions optimization methods genetics;particle swarm optimization;constraint handling;optimization;search problems;invasive weed optimization;simulated ecology constraint handling penalty function invasive weed optimization particle swarm optimization;benchmark testing;parameter optimization;penalty function	Most optimization problems have constraints of different types (e.g., physical, time, geometric, etc.), which modify the shape of the search space. We propose an ecologically inspired Invasive Weed Optimization (IWO) algorithm to solve the constrained real-parameter optimization problems. Central to our approach is a parameter-free penalty function that we introduce. The adaptive nature of the penalty function makes the results of the algorithm mostly insensitive to low values of the penalty parameter. The proposed approach is compared with a state-of-the-art variant of Particle Swarm Optimization (PSO) over 20 carefully chosen benchmarks from the test-suite of CEC 2006 competition on constrained real parameter optimization. The results indicate that in majority of the cases our approach was able to meet or beat the PSO-variant in a statistically meaningful way.	algorithm;ecology;mathematical optimization;particle swarm optimization;penalty method	Siddharth Pal;Aniruddha Basak;Swagatam Das	2009	2009 World Congress on Nature & Biologically Inspired Computing (NaBIC)	10.1109/NABIC.2009.5393757	optimization problem;benchmark;mathematical optimization;multi-swarm optimization;constrained optimization;probability density function;meta-optimization;convergence;computer science;derivative-free optimization;artificial intelligence;machine learning;penalty method;mathematics;particle swarm optimization	AI	27.366546422555857	-6.33497273773746	156818
8a26eed2dc829e99d6949b77abcd7f1b63a6aa80	resolution of industrial problems by a simple and universal new method	cybernetics;optimization technique;general techniques;operations research;optimization problem;general methods;functional analysis;optimization techniques;global optimization;operational research;optimal control problem;design methodology	Purpose – The purpose of this paper is to describe a general method for solving all problems arising in industrial processes and more generally in operational research.Design/methodology/approach – The paper's aim is to present a new method based on α‐dense curves first developed at the beginning of the 1980s by Yves Cherruault and Arthur Guillez. This technique allows to solve all problems of operational research in a simple way. For instance, industrial problems leading to optimization or optimal control problems can be easily and precisely solved by this very general technique. The main idea consists in expressing n variables by means of a single one.Findings – This new method, based on “alpha‐dense curves” allows to express n variables in function of a single variable. One of the most important applications is related to global optimization. Multivariable optimization problems can be quickly and easily solved, even for great numbers of variables and for integer or boolean variables. Every problem (lin...		Yves Cherruault	2009	Kybernetes	10.1108/03684920910962588	functional analysis;stochastic programming;probabilistic-based design optimization;optimization problem;mathematical optimization;multi-swarm optimization;engineering optimization;cybernetics;design methods;computer science;artificial intelligence;multi-objective optimization;mathematics;continuous optimization;l-reduction;bilevel optimization;algorithm;global optimization	Theory	32.122965220861694	1.4157901003426363	156897
7ff0d8417370989ab264334a48b34d1e467008e8	cognitive radio adaptation using particle swarm optimization	cognitive radio;particle swarm optimization;genetic algorithm	One of the basic capabilities of cognitive radio is to adapt the radio parameters according to the changing environment and user needs. This paper proposes a new adaptation method which uses particle swarm optimization (PSO) to optimize cognitive radio parameters given a set of objectives. The procedure of the proposed method is presented and multicarrier system is used for simulation analysis. Experimental results show that the proposed method performs far better than genetic algorithm (GA)-based adaptation method in terms of convergence speed, converged fitness values, and stability. The proposed method can also provide the tradeoffs of the objective functions, and the resulting parameter configuration is consistent with the weights of the objective functions. Copyright © 2008 John Wiley & Sons, Ltd.	cognitive radio;mathematical optimization;particle swarm optimization	Zhijin Zhao;Shiyu Xu;Shilian Zheng;Junna Shang	2009	Wireless Communications and Mobile Computing	10.1002/wcm.633	biomimetics;cognitive radio;simulation;genetic algorithm;telecommunications;computer science;artificial intelligence;software-defined radio;rate of convergence;particle swarm optimization	Mobile	29.698459528407504	-4.328994217573339	156898
bb8284ce32a17db3c01bbabbe0e0654bcfd19532	on-line static voltage security risk assessment based on markov chain model and svm for wind integrated power system		With the increase of wind power penetration rate, the effect of large-scale wind power influence on static voltage security of power grid is gradually significant. The fluctuation of wind power output will lead to the possibility of voltage instability. To deal with static voltage security risk caused by wind power, this paper proposes an online assessment method. Firstly, the relationship between security limitation and power flow status is trained offline through GA-SVM from continuation power flow (CPF) sample. Secondly, wind power probabilistic forecasting carry out online through fluctuation variation Markov Chain model. Finally, static voltage security risk is assessed online by calculating operation status probability and distance to security limitation. The validity of proposed method is proved by IEEE 9 bus system.	coalition for patent fairness;continuation;instability;markov chain;online and offline;quantum fluctuation;risk assessment;software release life cycle	Zhihao Yun;Qiong Zhou;Ying Feng;Donglei Sun;Jingwen Sun;Dong Yang	2017	2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)	10.1109/FSKD.2017.8393162	risk management;electric power system;wind power;mathematical optimization;continuation;voltage;computer science;control theory;probabilistic forecasting;instability;markov chain	EDA	35.67756618864321	0.061947994073829164	156954
21e1a491d7f432f5c64fefcf53e3b50f0cdda886	reactive memory model for ant colony optimization and its application to tsp	convergence;history;ant colony optimization;exploitation mechanism ant colony optimization reactive search exploration mechanism;computational modeling;optimization history mathematical model ant colony optimization computational modeling convergence algorithm design and analysis;mathematical model;tsplib95 data swarm intelligent systems aco stochastic algorithms search history reactive memory model ant colony optimization variants max min ant system rmmas;optimization;travelling salesman problems ant colony optimisation minimax techniques search problems swarm intelligence;algorithm design and analysis;qa76 computer software	Ant colony optimization is one of the most successful examples of swarm intelligent systems. The exploration and exploitation are the main mechanisms in controlling search within the ACO. Reactive search is a framework for automating the exploration and exploitation in stochastic algorithms. Restarting the search with the aid of memorizing the search history is the soul of reaction. It is to increase the exploration only when needed. This paper proposes a reactive memory model to overcome the limitation of the random exploration after restart because of losing the previous history of search. The proposed model is utilized to record the previous search regions to be used as reference for ants after restart. The performances of six (6) ant colony optimization variants were evaluated to select the base for the proposed model. Based on the results, Max-Min Ant System has been chosen as the base for the modification. The modified algorithm called RMMAS, was applied to TSPLIB95 data and results showed that RMMAS outperformed the standard MMAS.	algorithm;ant colony optimization algorithms;exploit (computer security);mathematical optimization;memory model (programming);performance;soul;swarm	Rafid Sagban;Ku Ruhana Ku-Mahamud;Muhamad Shahbani Abu Bakar	2014	2014 IEEE International Conference on Control System, Computing and Engineering (ICCSCE 2014)	10.1109/ICCSCE.2014.7072736	extremal optimization;mathematical optimization;ant colony optimization algorithms;meta-optimization;parallel metaheuristic;swarm intelligence;engineering;artificial intelligence;machine learning;metaheuristic	Robotics	27.976604596530443	-5.288004160391859	157057
57965633bdea549cf813530b03926d994e0ae221	a mutation hybrid algorithm of particle swarm optimization	evaluation function;mutate algorithm;statistical distributions particle swarm optimisation search problems;pso;local searching capability;satisfiability;traversal capability;optimization problem;statistical distributions;particle swarm optimizer;multi mutation pso;particle swarm optimization;probability distribution;optimization;search problems;multi mutation pso mutation hybrid algorithm particle swarm optimization global searching capability local searching capability traversal capability probability distribution;mutation hybrid algorithm;mutate algorithm pso evaluation function;particle swarm optimisation;local search;hybrid algorithm;global searching capability	Many mutation functions of particle positions are discussed in this paper. It is discussed the global searching capability, the local searching capability and the traversal capability of these mutation functions. And a mutation hybrid algorithm of particle swarm optimization is brought out in this paper. In each iteration, the position of particles which is satisfied the mutation condition are mutated with many kind of mutation functions, and each mutation function is endowed a probability. The probability distribution is relied on the specific optimization problem. Some experiments results of standard PSO, single mutation PSO and multi-mutation PSO are contrasted. It indicates that if the probability distribution of mutation functions set is well formed, the multi-mutation PSO will search the global best value more quickly and effectively.	hybrid algorithm;mathematical optimization;particle swarm optimization	Qingwei Ye;Zhimin Feng	2010		10.1109/BICTA.2010.5645307	mathematical optimization;mutation;artificial intelligence;machine learning;mathematics	Vision	28.350611286160333	-5.962735679292852	157159
05142aa65a4b3f84903c6181c52e4c0cdeaa1695	a genetic algorithm with elite crossover and dynastic change strategies	comportement rendez vous;premature convergence;chino;algoritmo genetico;conducta cita;general population;algorithme genetique;genetic algorithm;dating behavior;chinois;chinese	This paper proposes an elite crossover strategy together with a dynastic change strategy for genetic algorithms. These strategies are applied to the elites, with a different crossover operation applied to the general population. This multi-crossover operation approach is different from the traditional genetic algorithms where the same crossover strategy is used on both elites and general population. The advantage of adopting a multi-crossover operation approach is faster convergence. Additionally, by adopting a dynastic change strategy in the elite crossover operation, the problem of premature convergence does not need to be actively corrected. The inspiration for the dynastic change strategy comes from ancient Chinese history where royal members of a dynasty undertake intermarriages with other royal members in order to enhance their ascendancy. The central thesis of our elite crossover strategy is that a dynasty can never be sustained forever in a society that changes continuously with its environment. A set of 8 benchmark functions is selected to investigate the effectiveness and efficiency of the proposed genetic algorithm.	genetic algorithm	Yuanpai Zhou;Ray P. S. Han	2005		10.1007/11539902_32	demography;genetic algorithm;computer science;artificial intelligence;chinese;premature convergence	NLP	26.590692595696684	-5.881693062608892	157339
2a09bb90c5def63a97dae5e5a1cdbec618db63fb	splitting method for spatio-temporal sensors deployment in underwater systems	gibbs sampler;stochastic optimization;genetic algorithm;evolutionary algorithm;generalized splitting	In this paper, we present a novel stochastic optimization algorithm based on the rare events simulation framework for sensors deployment in underwater systems. More precisely, we focus on finding the best spatio-temporal deployment of a set of sensors in order to maximize the detection probability of an intelligent and randomly moving target in an area under surveillance. Based on generalized splitting technique with a dedicated Gibbs sampler, our approach does not require any state-space discretization and rely on the evolutionary framework.		Mathieu Chouchane;Sébastien Paris;François Le Gland;Mustapha Ouladsine	2012		10.1007/978-3-642-29124-1_21	mathematical optimization;engineering;artificial intelligence;machine learning	Robotics	32.82580876274854	-8.630090275534494	157425
3199f3390d0433d151eb35ae479f733bfd666bc3	snap-drift cuckoo search: a novel cuckoo search optimization algorithm	levy flights;nonparametric tests;global numerical optimization;parameter sensitivity;cuckoo search	Cuckoo search (CS) is one of the well-known evolutionary techniques in global optimization. Despite its efficiency and wide use, CS suffers from premature convergence and poor balance between exploration and exploitation. To address these issues, a new CS extension namely snap-drift cuckoo search (SDCS) is proposed in this study. The proposed algorithm first employs a learning strategy and then considers improved search operators. The learning strategy provides an online trade-off between local and global search via two snap and drift modes. In snap mode, SDCS tends to increase global search to prevent algorithm of being trapped in a local minima; and in drift mode, it reinforces the local search to enhance the convergence rate. Thereafter, SDCS improves search capability by employing new crossover and mutation search operators. The accuracy and performance of the proposed approach are evaluated by well-known benchmark functions. Statistical comparisons of experimental results show that SDCS is superior to CS, modified CS (MCS), and state-of-the-art optimization algorithms in terms of convergence speed and robustness.	algorithm;cuckoo search;mathematical optimization	Hojjat Rakhshani;Amin Rahati	2017	Appl. Soft Comput.	10.1016/j.asoc.2016.09.048	nonparametric statistics;mathematical optimization;lévy flight;computer science;artificial intelligence;machine learning;cuckoo search;statistics	Robotics	27.38127568596649	-4.4192890908278555	157437
b6be4c44a378d84147b95a4e738b66433a8d0546	investigations of wilson's and traulsen's group selection models in evolutionary computation	wilson s trait group selection model;evolutionary computation;the evolution of cooperation;traulsen s group selection model	Evolving cooperation by evolutionary algorithms is impossible without introducing extra mechanisms. Group selection theory in biology is a good candidate as it explains the evolution of cooperation in nature. Two biological models, Wilson’s trait group selection model and Traulsen’s group selection model are investigated and compared in evolutionary computation. Three evolutionary algorithms were designed and tested on an n-player prisoner’s dilemma problem; two EAs implement the original Wilson and Traulsen models respectively, and one EA extends Traulsen’s model. Experimental results show that the latter model introduces high between-group variance, leading to more robustness than the other two in response to parameter changes such as group size, the fraction of cooperators and selection pressure.	evolutionary algorithm;evolutionary computation;prisoner's dilemma;the evolution of cooperation	Shelly Xiaonan Wu;Wolfgang Banzhaf	2009		10.1007/978-3-642-21314-4_1	evolutionary programming;biology;interactive evolutionary computation;human-based evolutionary computation;computer science;artificial intelligence;evolutionary algorithm;evolutionary computation;evolutionary biology	AI	25.35090469895455	-8.815670357714762	157738
293125e246f06286f69ed451eec5d8df8e26ca9b	on convergence of differential evolution over a class of continuous functions with unique global optimum	lyapunov stability;convergence analysis;differential evolution;probability density functions pdfs asymptotic stability convergence differential evolution de lyapunov stability theorems numerical optimization;convergence;evolutionary computation;probability;lyapunov function;probability density function;differential evolution de;lyapunov stability theorems;random variables;numerical optimization;asymptotic stability;objective function;optimization problem;random variable;mathematical model;optimization;search problems;lyapunov functional differential evolution convergence continuous functions global optimum stochastic real parameter optimization algorithms de algorithm time recursive relationship probability density function de type mutation crossover mechanisms selection mechanisms lyapunov stability theorems dirac delta distribution population pdf asymptotic convergence behavior;convergence random variables search problems algorithm design and analysis optimization mathematical model probability density function;stochastic programming;stochastic programming evolutionary computation probability;probability density functions pdfs;computer simulation;algorithm design;algorithm design and analysis;algorithms computer simulation models statistical stochastic processes;parameter optimization;others	Differential evolution (DE) is arguably one of the most powerful stochastic real-parameter optimization algorithms of current interest. Since its inception in the mid 1990s, DE has been finding many successful applications in real-world optimization problems from diverse domains of science and engineering. This paper takes a first significant step toward the convergence analysis of a canonical DE (DE/rand/1/bin) algorithm. It first deduces a time-recursive relationship for the probability density function (PDF) of the trial solutions, taking into consideration the DE-type mutation, crossover, and selection mechanisms. Then, by applying the concepts of Lyapunov stability theorems, it shows that as time approaches infinity, the PDF of the trial solutions concentrates narrowly around the global optimum of the objective function, assuming the shape of a Dirac delta distribution. Asymptotic convergence behavior of the population PDF is established by constructing a Lyapunov functional based on the PDF and showing that it monotonically decreases with time. The analysis is applicable to a class of continuous and real-valued objective functions that possesses a unique global optimum (but may have multiple local optima). Theoretical results have been substantiated with relevant computer simulations.	algorithm;arabic numeral 0;behavior;biological evolution;computer simulation;converge;crossover (genetic algorithm);differential evolution;dirac delta function;dynamical system;global optimization;iteration;kind of quantity - equilibrium;local optimum;lyapunov fractal;mathematical optimization;maxima and minima;multimodal interaction;mutation;nonlinear system;optimization problem;population parameter;portable document format;probabilistic analysis of algorithms;probability density;recursion;settling time;solutions;time complexity;exponential	Sayan Ghosh;Swagatam Das;Athanasios V. Vasilakos;Kaushik Suresh	2012	IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)	10.1109/TSMCB.2011.2160625	computer simulation;random variable;algorithm design;mathematical optimization;combinatorics;mathematical analysis;computer science;control theory;mathematics;statistics;evolutionary computation	ML	28.40803094718293	-8.299347325080587	157814
eb39cc521173f36684c39351e5b11519b00b68e8	comparing lbest pso niching algorithms using different position update rules	topology;evolutionary computation;atmospheric measurements;particle measurements;topology gaussian distribution equations atmospheric measurements particle measurements space exploration evolutionary computation;genetic adaptive position update rule multimodal optimization evolutionary computation ibest pso niching algorithm ring topology cauchy distribution based pso gaussian distribution based pso;ibest pso niching algorithm;genetic adaptive;space exploration;2 dimensional;position update rule;multimodal optimization;cauchy distribution based pso;particle swarm optimisation;topology evolutionary computation gaussian distribution particle swarm optimisation;gaussian distribution;ring topology;gaussian distribution based pso;evolutionary computing	Niching is an important technique for multimodal optimization in Evolutionary Computation. Most existing niching algorithms are evaluated using only 1 or 2 dimensional multimodal functions. However, it remains unclear how these niching algorithms perform on higher dimensional multimodal problems. This paper compares several schemes of PSO update rules, and examines the effects of incorporating these schemes into a lbest PSO niching algorithm using a ring topology. Subsequently a new Cauchy and Gaussian distributions based PSO (CGPSO) is proposed. Our experiments suggest that CGPSO seems to be able to locate more global peaks than other PSO variants on multimodal functions which typically have many global peaks but very few local peaks.	algorithm;evolutionary computation;evolutionary multimodal optimization;experiment;mathematical optimization;multimodal interaction;niche blogging;particle swarm optimization;phase-shift oscillator;ring network;sampling (signal processing)	Xiaodong Li;Kalyanmoy Deb	2010	IEEE Congress on Evolutionary Computation	10.1109/CEC.2010.5586317	normal distribution;ring network;mathematical optimization;two-dimensional space;computer science;artificial intelligence;theoretical computer science;space exploration;machine learning;mathematics;evolutionary computation	AI	28.258997764619675	-6.618820213878277	157915
2efd0029d5122f8a2e46c164ce38f8a204b896c7	a hybrid quantum inspired harmony search algorithm for 0-1 optimization problems	computacion informatica;knapsack problems;ciencias basicas y experimentales;matematicas;hybrid algorithms;grupo a;quantum computing;harmony search algorithm	This paper presents a new hybrid natural algorithm based on Harmony Search Algorithm (HSA) and Quantum Computing (QC). The main features of the proposed algorithm called Quantum Inspired Harmony Search Algorithm (QIHSA) is the integration of quantum representation scheme in the basic harmony search algorithm that allows applying successfully some quantum inspired operators like measurement and interference. This hybridization between quantum inspired computing and harmony search algorithm has led to an efficient hybrid framework which achieves better balance between the exploration of HS algorithm and the exploitation capabilities of the quantum inspired computing. Experiments on knapsack problems show the effectiveness of the proposed framework and its ability to achieve good quality solutions.	harmony search;mathematical optimization;search algorithm	Abdesslem Layeb	2013	J. Computational Applied Mathematics	10.1016/j.cam.2013.04.004	mathematical optimization;harmony search;mathematics;quantum computer;algorithm;quantum mechanics	Theory	26.069871885467194	-3.4321858329589414	157950
a092ac4e021aebdb7a2435bd998142c9757c5bd1	approximations in stochastic optimization and their applications			approximation;program optimization;stochastic optimization	Eva Mrázková	2010			stochastic optimization;mathematical optimization;stochastic programming;monte carlo method;mathematics	ML	33.63259919352069	3.519452987613909	158129
f2f46d60980159cb7972f9e10a82496301dbc136	exhaustive versus randomized searches for nonlinear optimization in 21st century computing: solar application	solar cells;errors;central processing units;nonlinear programming;inequalities;polynomials;mathematical models;algorithms;random numbers;multivariate statistical analysis	We present a simple multi-dimensional exhaustive search method to obtain, in a reasonable time, the optimal solution of a nonlinear programming problem. It is more relevant in the present day non-mainframe computing scenario where an estimated 95% computing resources remains unutilized and computing speed touches petaflops. While the processor speed is doubling every 18 months, the band width is doubling every 12 months, and the hard disk space is doubling every 9 months. A randomized search algorithm or, equivalently, an evolutionary search method is often used instead of an exhaustive search algorithm. The reason is that a randomized approach is usually polynomial-time, i.e., fast while an exhaustive search method is exponential-time i.e., slow. We discuss the increasing importance of exhaustive search in optimization with the steady increase of computing power for solving many real-world problems of reasonable size. We also discuss the computational error and complexity of the search algorithm focusing on the fact that no measuring device can usually measure a quantity with an accuracy greater than 0.005%. We stress the fact that the quality of solution of the exhaustive search - a deterministic method - is better than that of randomized search. In 21st century computing environment, exhaustive search cannot be left aside as an untouchable and it is not always exponential. We also describe a possible application of these algorithms in improving the efficiency of solar cells - a real hot topic - in the current energy crisis. These algorithms could be excellent tools in the hands of experimentalists and could save not only large amount of time needed for experiments but also could validate the theory against experimental results fast.	mathematical optimization;nonlinear programming;nonlinear system;randomized algorithm;randomized rounding	Syamal K. Sen;Gholam Ali Shaykhian	2010	Neural Parallel & Scientific Comp.		beam search;mathematical optimization;theoretical computer science;mathematics;algorithm	HPC	25.978352765880018	3.9853329077055384	158389
a577a65e40294942cea5e6a10f24ef21af9b6447	a hardware/software partitioning algorithm based on artificial immune principles	artificial immune system;hardware software codesign;negative selection;embedded system;hardware software partitioning;immune system;evolutionary algorithm	Hardware/software codesign is the main approach to designing the embedded systems. One of the primary steps of the hardware/software codesign is the hardware/software partitioning. A good partitioning scheme is a tradeoff of some constraints, such as power, size, performance, and so on. Inspired by both negative selection model and evolutionary mechanism of the biological immune system, an evolutionary negative selection algorithm for hardware/software partitioning, namely ENSA-HSP, is proposed in this paper. This ENSA-HSP algorithm is proved to be convergent, and its ability to escape from the local optimum is also analyzed. The experimental results demonstrate that ENSA-HSP is more efficient than traditional evolutionary algorithm. # 2007 Elsevier B.V. All rights reserved.	computer performance;directed acyclic graph;embedded system;evolutionary algorithm;hosted service provider;local optimum;microsoft windows;selection algorithm	Yiguo Zhang;Wenjian Luo;Zeming Zhang;Bin Li;Xufa Wang	2008	Appl. Soft Comput.	10.1016/j.asoc.2007.03.003	computer architecture;real-time computing;immune system;computer science;artificial intelligence;theoretical computer science;machine learning;evolutionary algorithm;hardware architecture;negative selection;artificial immune system	EDA	26.311906391507303	-1.2110745020814961	158581
23bc5dceea8d671a637c6d482f2b378800dc34c0	hybrid fuzzy clustering methods based on improved self-adaptive cellular genetic algorithm and optimal-selection-based fuzzy c-means		With an aim to overcome low efficiency and improve the performance of fuzzy clustering, two novel fuzzy clustering algorithms based on improved self-adaptive cellular genetic algorithm (IDCGA) are proposed in this paper. The new dynamic crossover and entropy-based two-combination mutation operations are constructed to prevent the convergence of the algorithms to a local optimum by adaptively modifying the probabilities of crossover and mutation as well as mutation step size according to dynamic adjusting strategies and judging criterions. Arnold cat map is employed to initialize population for the purpose of overcoming the sensitivity of the algorithms to initial cluster centers. A modified evolution rule is introduced to build a dynamic environment so as to explore the search space more effectively. Then a new IDCGA that combined these three processes is used to optimize fuzzy c-means (FCM) clustering (IDCGA-FCM). Furthermore, an optimal-selection-based strategy is presented by the golden section method and then a hybrid fuzzy clustering method (IDCGA2-FCM) is developed by automatically integrating IDCGA with optimal-selection-based FCM according to the variation of population entropy. Experiments were performed with six synthetic datasets and seven real-world datasets to compare the performance of our IDCGA-based clustering algorithms with FCM, other GA-based and PSO-based clustering methods. The results showed that the presented algorithms have high efficiency and accuracy.	arnold's cat map;automatic identification and data capture;cellular evolutionary algorithm;cluster analysis;crossover (genetic algorithm);experiment;fuzzy clustering;fuzzy cognitive map;genetic algorithm;global optimization;local optimum;local search (optimization);mathematical optimization;mutation (genetic algorithm);particle swarm optimization;population;software release life cycle;synthetic intelligence	Lilin Jie;Weidong Liu;Zheng Sun;Shasha Teng	2017	Neurocomputing	10.1016/j.neucom.2017.03.068	correlation clustering;k-medians clustering;fuzzy clustering;flame clustering;computer science;artificial intelligence;canopy clustering algorithm;machine learning;cure data clustering algorithm;data mining;cluster analysis	AI	27.19478322907759	-5.087182531081051	158614
024cf2e33260617a182915c62ee3d5e68aac9fe4	a multi-objective artificial bee colony algorithm based on division of the searching space	friedman test;multi objective optimization;pareto dominance;multi colony model;multi objective artificial bee colony algorithm	This paper presents a new multi-objective artificial bee colony algorithm called dMOABC by dividing the whole searching space S into two independent parts S 1 and S 2. In this algorithm, two ”basic” colonies are assigned to search potential solutions in regions S 1 and S 2, while the so-called ”synthetic” colony explores in S. This multi-colony model could enable the good diversity of the population, and three colonies share information in a special way. A fixed-size external archive is used to store the non-dominated solutions found so far. The diversity over the archived solutions is controlled by utilizing a self-adaptive grid. For basic colonies, neighbor information is used to generate new food sources. For the synthetic colony, besides neighbor information, the global best food source gbest selected from the archive, is also adopted to guide the flying trajectory of both employed and onlooker bees. The scout bees are used to get rid of food sources with poor qualities. The proposed algorithm is evaluated on a set of unconstrained multi-objective test problems taken from CEC09, and is compared with 11 other state-of-the-art multi-objective algorithms by applying Friedman test in terms of four indicators: HV, SPREAD, EPSILON and IGD. It is shown by the test results that our algorithm significantly surpasses its competitors.	adaptive mesh refinement;archive;artificial bee colony algorithm;experiment;internet gateway device protocol;local optimum;mathematical optimization;multi-objective optimization;parallel algorithm;synthetic intelligence	Yu-bin Zhong;Yi Xiang;Hai-Lin Liu	2014	Applied Intelligence	10.1007/s10489-014-0555-8	artificial intelligence;multi-objective optimization;bees algorithm;artificial bee colony algorithm;operations research;friedman test;statistics	AI	26.38118411128674	-3.8231828569533497	158810
62b7fc0a44c0ff86adf4889d46586808840201cd	combinatorial disambiguation	standard combinatorial search optimizations;combinatorial disambiguation;machine translation project;single global optimizer;numerical weight;specific type;individual decision procedure;simpler code;combinatorial problem;traditional disambiguation heuristics;natural language system	The disambiguation of sentences is a combinatorial problem. This paper describes a method for treating it as such, directly, by adapting standard combinatorial search optimizations. Traditional disambiguation heu-ristics are applied but, instead of being embedded in individual decision procedures for specific types of ambiguities, they contribute to numerical weights that are considered by a single global optimizer. The result is increased power and simpler code. The method is being implemented for a machine translation projecl, but could be adapted to any natural language system.	combinatorial search;embedded system;machine translation;mathematical optimization;natural language;numerical analysis;word-sense disambiguation	Paula S. Newman	1988			natural language processing;computer science;machine learning;algorithm	NLP	25.676812508047757	3.1174581945482314	159055
13bd65570c0c74e5538ef79d4b94615d6cb0f7ee	solving the economic dispatch in power system by genetic particle evolutionary swarm optimization	stochastic processes genetic algorithms load dispatching particle swarm optimisation power system economics;genetic particle evolutionary swarm optimization;differential evolution;generators;convergence;premature convergence;load dispatching;power system economics power generation economics power systems particle swarm optimization genetic mutations power generation power system simulation cost function convergence power system reliability;power systems;gpeso;genetics;particle swarm optimizer;stochastic processes;stochastic ranking algorithm power system economic dispatch genetic particle evolutionary swarm optimization gpeso genetic reproduction mechanism differential evolution search performance;power system;particle swarm optimization;power system economics;stochastic ranking algorithm;differential evolution search performance;genetic particle swarm optimization;ranking algorithm;constraint handling;genetic algorithms;optimization;economics;economic dispatch;particle swarm optimisation;genetic particle swarm optimization differential evolution economic dispatch;power system economic dispatch;genetic reproduction mechanism	This paper introduced a genetic particle evolutionary swarm optimization (GPESO) for solving the economic dispatch (ED) in power systems. GPESO is based on the genetic particle swarm optimization (GPSO). GPSO was derived from the original particle swarm optimization (OPSO), which was incorporated with the genetic reproduction mechanisms, namely crossover and mutation. To enhance the search performance of GPSO, the differential evolution (DE) was incorporated to GPSO as a perturbation to fight premature convergence and poor diversity issues observed in GPSO implementations. Constraint handling was based on the stochastic ranking algorithm. GPESO was implemented to a 6 units system and the simulation results showed that GPESO outperformed other PSO algorithms.	program optimization;swarm	Peng Chen;Zhiming Liu	2008		10.1109/CSSE.2008.1052	stochastic process;mathematical optimization;multi-swarm optimization;simulation;computer science;electric power system;mathematical economics	AI	27.298963035210477	-6.0450325417913975	159101
2777eaec7f1d7073663b02362e0d172a78f5eb25	decmo2: a robust hybrid and adaptive multi-objective evolutionary algorithm	evolutionary computation;adaptive allocation of fitness evaluations;performance analysis methodology for moops;coevolution;hybrid multi objective optimization	We describe a hybrid and adaptive coevolutionary optimization method that can efficiently solve a wide range of multi-objective optimization problems (MOOPs) as it successfully combines positive traits from three main classes of multi-objective evolutionary algorithms (MOEAs): classical approaches that use Paretobased selection for survival criteria, approaches that rely on differential evolution, and decomposition-based strategies. A key part of our hybrid evolutionary approach lies in the proposed fitness sharing mechanism that is able to smoothly transfer information between the coevolved subpopulations without negatively impacting the specific evolutionary process behavior that characterizes each subpopulation. The proposed MOEA also features an adaptive allocation of fitness evaluations between the coevolved populations in order to increase robustness and favor the evolutionary search strategy that proves more successful for solving the MOOP at hand. Apart from the new evolutionary algorithm, this paper also contains the description of a new hypervolume and racing-based methodology aimed at providing practitioners from the field of multi-objective optimization with a simple means of analyzing/reporting the general comparative run-time performance of multiobjective optimization algorithms over large problem sets. A.-C. Zăvoianu · E. Lughofer · E. P. Klement Department of Knowledge-based Mathematical Systems/Fuzzy Logic Laboratory Linz-Hagenberg, Johannes Kepler University of Linz, Austria A.-C. Zăvoianu · G. Bramerdorfer · W. Amrhein · E. P. Klement LCM, Linz Center of Mechatronics, Linz, Austria G. Bramerdorfer · W. Amrhein Institute for Electrical Drives and Power Electronics, Johannes Kepler University of Linz, Austria	benchmark (computing);converge;differential evolution;evaluation function;evolutionary algorithm;fuzzy logic;iterative and incremental development;kepler (microarchitecture);latent class model;moea framework;mathematical optimization;mechatronics;models of dna evolution;multi-objective optimization;pareto efficiency;population;power electronics;real life;smoothing;steady state	Alexandru-Ciprian Zavoianu;Edwin Lughofer;Gerd Bramerdorfer;Wolfgang Amrhein;Erich-Peter Klement	2015	Soft Comput.	10.1007/s00500-014-1308-7	evolutionary programming;mathematical optimization;interactive evolutionary computation;human-based evolutionary computation;coevolution;computer science;artificial intelligence;machine learning;evolutionary algorithm;fitness approximation;evolutionary computation	AI	24.706048766178604	-4.969007546601334	159743
065f6a5cf2d1a236388b27fb121b255ee1cf44b5	cuckoo search via lévy flights and a comparison with genetic algorithms		The purpose of this paper is to present a brief literature review of the cuckoo search algorithm (CS) and analyze its behavior by applying it to a set of benchmark mathematical functions. CS is a stochastic algorithm, inspired by the nature of a family bird called Cuckoo. CS algorithms are reinforced with Levy flights to analyze the search space in a successful manner. We performed a comparison of Cuckoo Search (CS) and Genetic Algorithm (GA), these algorithms were tested on five mathematical functions for analysis.	cuckoo search;genetic algorithm;lévy flight	Maribel Guerrero;Oscar Castillo;Mario García Valdez	2015		10.1007/978-3-319-10960-2_6	genetic algorithm;mathematical optimization;cuckoo search;mathematics;lévy flight;cuckoo	AI	25.347651486783338	-5.365953363524917	159937
23f781df880ef8e4852b45ec438a6d54b67adf91	volterra filter modeling of a nonlinear discrete-time system based on a ranked differential evolution algorithm	identification problem;premature convergence;ranked differential evolution;volterra filter model;de xuan zou li qun gao steven li volterra filter modeling of a nonlinear discrete time system based on a ranked differential evolution algorithm;nonlinear discrete time systems	This paper presents a ranked differential evolution (RDE) algorithm for solving the identification problem of non-linear discrete-time systems based on a Volterra filter model. In the improved method, a scale factor, generated by combining a sine function and randomness, effectively keeps a balance between the global search and the local search. Also, the mutation operation is modified after ranking all candidate solutions of the population to help avoid the occurrence of premature convergence. Finally, two examples including a highly nonlinear discrete-time rational system and a real heat exchanger are used to evaluate the performance of the RDE algorithm and five other approaches. Numerical experiments and comparisons demonstrate that the RDE algorithm performs better than the other approaches in most cases.	differential evolution;discrete-time signal;evolutionary algorithm;experiment;local search (optimization);loss function;mean squared error;nonlinear system identification;numerical method;optimization problem;premature convergence;randomness	Dexuan Zou;Liqun Gao;Steven Li	2014	Journal of Zhejiang University SCIENCE C	10.1631/jzus.C1300350	mathematical optimization;parameter identification problem;artificial intelligence;machine learning;mathematics;algorithm;statistics;premature convergence	ML	32.47367147158984	-5.925449259210943	159990
5f95e545f8ce23258e877184d4dcc2eb6afb5441	parego: a hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems	multiobjective programming;optimum pareto;programmation multiobjectif;optimisation;nondominated sorting genetic algorithm ii nsga ii;evolutionary computation;optimizacion;krigeage;gaussian processes;design and analysis of computer experiments dace;optimum global;calcul evolutionniste;global optimum;approximation algorithms performance evaluation evolutionary computation testing pareto optimization search methods optimization methods instruments gaussian processes pareto analysis;algoritmo genetico;response surfaces;surface reponse;search problems optimisation evolutionary computation design of experiments gaussian processes;design of experiments;metamodel;metamodele;mathematical programming;metamodelo;search landscape parego online landscape approximation expensive multiobjective optimization problems nsga ii multiobjective evolutionary algorithm single objective efficient global optimization algorithm design of experiments gaussian processes model;efficient global optimization ego;metamodels;superficie respuesta;test suites design and analysis of computer experiments dace efficient global optimization ego expensive black box functions kriging landscape approximation metamodels multiobjective optimization nondominated sorting genetic algorithm ii nsga ii pareto optima performance assessment response surfaces;algorithme genetique;algorithme evolutionniste;multiobjective optimization;genetic algorithm;global optimization;algoritmo evolucionista;optimization;value function;search problems;gaussian process;pareto optima;evolutionary algorithm;kriging;pareto optimum;response surface;programmation mathematique;test suites;optimo global;random search;optimo pareto;expensive black box functions;programacion matematica;hybrid algorithm;landscape approximation;performance assessment;programacion multiobjetivo;design of experiment	This paper concerns multiobjective optimization in scenarios where each solution evaluation is financially and/or temporally expensive. We make use of nine relatively low-dimensional, nonpathological, real-valued functions, such as arise in many applications, and assess the performance of two algorithms after just 100 and 250 (or 260) function evaluations. The results show that NSGA-II, a popular multiobjective evolutionary algorithm, performs well compared with random search, even within the restricted number of evaluations used. A significantly better performance (particularly, in the worst case) is, however, achieved on our test set by an algorithm proposed herein-ParEGO-which is an extension of the single-objective efficient global optimization (EGO) algorithm of Jones et al. ParEGO uses a design-of-experiments inspired initialization procedure and learns a Gaussian processes model of the search landscape, which is updated after every function evaluation. Overall, ParEGO exhibits a promising performance for multiobjective optimization problems where evaluations are expensive or otherwise restricted in number.	approximation;best, worst and average case;design of experiments;distribution (mathematics);ego;evolutionary algorithm;experiment;fitness function;gaussian process;global optimization;hybrid algorithm;iteration;jones calculus;moea framework;mathematical optimization;multi-objective optimization;online and offline;optimization problem;pareto efficiency;random search;temporal logic;test set	J. Knowles	2006	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2005.851274	mathematical optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm;gaussian process;mathematics;design of experiments;statistics;global optimization;evolutionary computation	AI	27.859712020250566	1.4205237181639077	160224
0e513c9e293b51e77d59c53192370730419f76c3	classification rule discovery with ant colony optimization	optimisation;classification algorithm;ant colony optimization data mining databases delta modulation humans artificial intelligence particle swarm optimization intelligent agent educational institutions computer science;ant colony optimization;combinatorial optimization problem;data mining;combinatorial mathematics data mining multi agent systems optimisation artificial life pattern classification;knowledge discovery classification rule discovery ant colony optimization ant based algorithm combinatorial optimization data mining classification algorithm ant miner algorithm;multi agent systems;classification rules;pattern classification;combinatorial mathematics;artificial life	Ant-based algorithms or ant colony optimization (ACO) algorithms have been applied successfully to combinatorial optimization problems. More recently, Parpinelli and colleagues applied ACO to data mining classification problems, where they introduced a classification algorithm called Ant_Miner. In this paper, we present an improvement to Ant_Miner (we call it Ant_Miner3). The proposed version was tested on two standard problems and performed better than the original Ant_Miner algorithm.	algorithm;ant colony optimization algorithms;combinatorial optimization;data mining;mathematical optimization;program optimization	Bo Liu;Hussein A. Abbass;Robert I. McKay	2003	IEEE Intelligent Informatics Bulletin	10.1109/IAT.2003.1241052	ant colony optimization algorithms;meta-optimization;parallel metaheuristic;engineering;artificial intelligence;machine learning;data mining;metaheuristic	ML	25.218675574551895	-2.0713806231208243	160397
4d7b1aec4cd79b0ae956e2d594e5a00b953ad242	fuzzy adaptive search method for parallel genetic algorithm tuned by evolution degree based on diversity measure	parallel genetic algorithm;fuzzy reasoning;mutation rate;search method;genetic algorithm;genetic parameter;computer simulation	Generally, as for Genetic Algorithms (GAs), it is not always optimal search efficiency, because genetic parameters (crossover rate, mutation rate and so on) are fixed. For this problem, we have already proposed Fuzzy Adaptive Search Method for GA (FASGA) that is able to tune the genetic parameters according to the search stage by the fuzzy reasoning. On the other hand, in order to improve the solution quality of GA, Parallel Genetic Algorithm (PGA) based on the local evolution in plural sub-populations (islands) and the migration of individuals between islands has been researched.#R##N##R##N#In this research, Fuzzy Adaptive Search method for Parallel GA (FASPGA) combined FASGA with PGA is proposed. Moreover as the improvement method for FASPGA, Diversity Measure based Fuzzy Adaptive Search method for Parallel GA (DM-FASPGA) is also proposed. Computer simulation was carried out to confirm the efficiency of the proposed method and the simulation results are also reported in this paper.	genetic algorithm	Yoichiro Maeda;Qiang Li	2007		10.1007/978-3-540-72950-1_67	computer simulation;mutation rate;mathematical optimization;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics	Robotics	26.54840572177192	-5.2326110075832375	160584
04fc96f22422cd0565354c54aeec8f43d00be268	two-dimensional equilibrium constraint layout using simulated annealing	layout optimization;gradient method;simulated annealing algorithm;simulated annealing;packing problem;optimization problem;np hard problem;global optimization;neighborhood search;local search;equilibrium constraint	This paper studies the layout optimization problem with equilibrium constraint. It is a two-dimensional packing problem with the industrial background of simplified satellite module layout design, and is known as NP-hard problem. By incorporating the heuristic neighborhood search mechanism and the adaptive gradient method into the simulated annealing procedure, a heuristic simulated annealing algorithm is put forward for this problem. The special neighborhood search mechanism can avoid the disadvantage of blind search in the simulated annealing algorithm, and the adaptive gradient method is used to execute local search and speed up finding the global optimal solution. Numerical examples are illustrated to verify the effectiveness of the proposed algorithm.	simulated annealing	Jingfa Liu;Gang Li;Duanbing Chen;Wenjie Liu;Yali Wang	2010	Computers & Industrial Engineering	10.1016/j.cie.2010.06.009	local optimum;mathematical optimization;combinatorics;simulated annealing;tabu search;computer science;local search;hill climbing;machine learning;mathematics;line search;adaptive simulated annealing;metaheuristic;global optimization;guided local search	Robotics	26.2813034406781	-1.4307069801429022	160841
bdce3c5c8a66dd27418149bce82622da350d1adb	single phase multi-group teaching learning algorithm for computationally expensive numerical optimization (cec 2016)	evolutionary computation;chemical engineering;statistics;optimization;algorithm design and analysis;sociology	In this work, a Single Phase Multi-Group Teaching Learning Optimization strategy is proposed which is a variant of the Teaching Learning Based Optimization algorithm. The proposed strategy has been used to solve the fifteen single objective, bound constrained, computationally expensive benchmark functions that have been provided as part of one of the competition in IEEE Congress on Evolutionary Computation 2016. The proposed strategy has been designed specifically to handle computationally intensive problems and hence provides competitive results and has relatively low time complexity.	algorithm;analysis of algorithms;benchmark (computing);ieee congress on evolutionary computation;mathematical optimization;numerical analysis;program optimization;time complexity	Remya Kommadath;Chinta Sivadurgaprasad;Prakash Kotecha	2016	2016 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2016.7744167	algorithm design;mathematical optimization;computer science;artificial intelligence;machine learning;statistics;evolutionary computation	Vision	25.52622527561792	-2.7067445425911276	161087
c29d1f9033d4faca2a631facf0f86ddeefe6a30c	genetic learning automata for function optimization	automatic control;rate of convergence;global optimization properties;convergence;stopping rule;real valued function optimization problems;convergence of numerical methods;h670 robotics and cybernetics;bit based function optimization;biological system modeling;h650 systems engineering;learning automata;genetics;function optimization;optimization problem;learning systems;h990 engineering not elsewhere classified;phenotype properties;stochastic processes;stochastic automata;genetic algorithm;genetic algorithms;global optimization;value function;search process;genetic learning automata;stochastic systems;genotype properties;learning automata convergence optimization methods biological system modeling genetic algorithms automatic control stochastic systems learning systems power system control stochastic processes;bit based function optimization stochastic learning automata genetic learning automata genetic algorithms global optimization properties convergence genotype properties phenotype properties stopping rule real valued function optimization problems search process;power system control;stochastic learning automata;optimization methods;convergence of numerical methods learning automata genetic algorithms stochastic automata	Stochastic learning automata and genetic algorithms (GAs) have previously been shown to have valuable global optimization properties. Learning automata have, however, been criticized for having a relatively slow rate of convergence. In this paper, these two techniques are combined to provide an increase in the rate of convergence for the learning automata and also to improve the chances of escaping local optima. The technique separates the genotype and phenotype properties of the GA and has the advantage that the degree of convergence can be quickly ascertained. It also provides the GA with a stopping rule. If the technique is applied to real-valued function optimization problems, then bounds on the range of the values within which the global optima is expected can be determined throughout the search process. The technique is demonstrated through a number of bit-based and real-valued function optimization examples.	automata theory;convergence (action);gallium;genetic algorithm;global optimization;learning automata;local optimum;mathematical optimization;rate of convergence;software release life cycle	M. N. Howell;T. J. Gordon;F. V. Brandao	2002	IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society	10.1109/TSMCB.2002.1049614	mathematical optimization;genetic algorithm;computer science;artificial intelligence;theoretical computer science;machine learning;automatic control;mathematics;global optimization	Embedded	27.964635236454185	-8.235278583251537	161646
5c1de3617ffc1804ef7c8a31c82a1b7fe57537d0	comparing multifractality among czech, hungarian and russian stock exchanges	singularity spectrum;multifractality;renyi exponent;generalised hurst exponent	In this paper, we analyse multifractality among Czech, Hungarian and Russian stock exchanges. For this end we perform a method titled multifractal detrended fluctuation analysis (MF-DFA) to investigate the multifractal properties of PX, BUX and RTS indices. By applying the MF-DFA method we first calculate the generalised Hurst exponents, we then deduce the Rényi exponents as well as the singularity spectrum of these indices. Furthermore, we perform shuffling and surrogate techniques to detect the sources of multifractality. We also compute the contribution of two major sources of multifractality that are long-range temporal correlations and fat-tail distribution. This study shows that the Czech, Hungarian and Russian stock exchanges are neither efficient nor fractals, but they are multifractal markets. By comparing spectrum width of these indices, we also find which index has the richer multifractal feature.	cross-correlation;detrended fluctuation analysis;fractal;hurst exponent;knowledge spillover;memory effect;multifractal system;nonlinear system;pixel;quantum fluctuation;singularity spectrum;spectrum analyzer;technological singularity;turbulence	Marwane El Alaoui;Saâd Benbachir	2013	IJADS	10.1504/IJADS.2013.056864	financial economics;calculus;mathematics;statistics	DB	36.96455571442537	-4.049964209268119	161696
f1a45a311fee085007a0b5ebdb536342e269d5e6	genetic algorithms and communication link speed design: constraints and operators	genetic algorithm		genetic algorithm	Susan Coombs;Lawrence Davis	1987			quality control and genetic algorithms;mathematical optimization;meta-optimization;cultural algorithm;theoretical computer science;genetic operator;machine learning;genetic representation;mathematics;population-based incremental learning	EDA	24.714323955586867	-1.9421257749409366	161705
5ee7ed0d76b9c9476a6a87dee6431c2ee53903f2	particle swarm optimization using sobol mutation	search domain particle swarm optimization sobol mutation systematic mutation operator basic particle swarm optimization mutation operators random probability distribution;mutation operators;evolutionary computation;probability;paper technology;random sequences;sobol sequence particle swarm optimization mutation low discrepancy sequence;space exploration;mathematical operators;systematic mutation operator;particle swarm optimizer;birds;random sequences particle swarm optimization benchmark testing probability distribution optimization space exploration equations;particle swarm optimization;probability distribution;samarium;sobol sequence;optimization;genetic mutations;search domain;quality of service;probability mathematical operators particle swarm optimisation;random probability distribution;particle swarm optimisation;low discrepancy sequences;low discrepancy sequence;benchmark testing;mutation;sobol mutation;basic particle swarm optimization	In this paper, we present a new mutation operator called the systematic mutation (SM) operator for enhancing the performance of basic particle swarm optimization (BPSO) algorithm. The SM operator unlike most of its contemporary mutation operators do not use the random probability distribution for perturbing the swarm population, but uses a quasi random Sobol sequence to find new solution vectors in the search domain. The comparison of SM-PSO is made with BPSO and some other variants of PSO. The empirical results show that SM operator significantly improves the performance of PSO.	algorithm;benchmark (computing);mathematical optimization;mutation testing;particle swarm optimization;phase-shift oscillator	Millie Pant;Radha Thangaraj;Ved Pal Singh;Ajith Abraham	2008	2008 First International Conference on Emerging Trends in Engineering and Technology	10.1109/ICETET.2008.35	mathematical optimization;combinatorics;machine learning;mathematics	DB	27.844805333764697	-7.170879234945493	162071
36f7d73c93e9a6b22795db8023fd9edb191c66d4	test-based extended finite-state machines induction with evolutionary algorithms and ant colony optimization	ant colony optimization;crossover;extended finite state machine induction;extended finite state machine;evolutionary strategy;genetic algorithm;evolutionary algorithm;ant colony optimization algorithm	In this paper we consider the problem of extended finite-state machines induction. The input data for this problem is a set of tests. Each test consists of two sequences - an input sequence and a corresponding output sequence. We present a new method of Extended Finite-State Machines (EFSM) induction based on an Ant Colony Optimization algorithm (ACO) and a new meaningful test-based crossover operator for EFSMs. New algorithms are compared with a genetic algorithm (GA) using a traditional crossover, a (1+1) evolutionary strategy and a random mutation hill climber. This comparison shows that the use of test-based crossover greatly improves performance of GA. GA on average also significantly outperforms the hill climber and evolutionary strategy. ACO outperforms GA, and the difference between average performance of ACO and GA hybridized with hill climber is insignificant.	ant colony optimization algorithms;best, worst and average case;climber (beam);evolutionary algorithm;finite-state machine;genetic algorithm;like button;mathematical optimization;software release life cycle	Daniil S. Chivilikhin;Vladimir I. Ulyantsev;Fedor Tsarev	2012		10.1145/2330784.2330883	extended finite-state machine;mathematical optimization;crossover;ant colony optimization algorithms;genetic algorithm;computer science;artificial intelligence;machine learning;evolutionary algorithm;evolution strategy	AI	27.072555855106476	-2.0089151596127155	162077
20fabded09bca923631bad91814e2d48c87847f5	combinatorial optimization method with search strategy based on hierarchical interpretation of solution space		"""A """"basin of attraction"""" is a set of solutions arriving at the same local optimal solution by Best-improvement Local Search. By utilizing the concept of basin of attraction in the solution space of combinatorial optimization problem, the solution space is interpreted as a higher structure, which is a set of basin of attraction, and a lower structure, which is a set of solutions, in this paper. Based on the hierarchical interpretation of the solution space, which consists of the higher structure and the lower structure, and basic strategy in metaheuristics, an optimization method with search strategy to find a basin of attraction to which superior local optimal solution belongs is proposed. The search performance of this method was evaluated through numerical experiments using benchmark problems. In addition, the search situation and influence on search by parameter of this method are considered."""	benchmark (computing);combinatorial optimization;diversification (finance);experiment;feasible region;local search (constraint satisfaction);mathematical optimization;metaheuristic;numerical analysis;optimization problem	Masatoshi Hashimoto;Kenichi Tamura;Junichi Tsuchiya;Keiichiro Yasuda	2017	2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2017.8122888	machine learning;artificial intelligence;computer science;metaheuristic;combinatorial optimization;local search (optimization);linear programming;benchmark (computing);attraction	Robotics	24.852514244060167	-0.06793939903120527	162123
4244617e95b4b90fc78247117941469b0120a137	a study of constraint-handling techniques in brain storm optimization	silicon;storms;particle swarm optimization;linear programming;clustering algorithms;optimization;algorithm design and analysis	A study on three BSO algorithm versions: Brain Storm Optimization Algorithm (BSO), Modified Brain Storm Optimization Algorithm (MBSO) and Simple Modified Brain Storm Optimization Algorithm (SMBSO), for constrained numerical optimization problems is presented in this paper. The aim of the study is to know the performance of this recent Swarm Intelligence (SI) algorithm on constrained search spaces. The feasibility rules, ε-constrained method, and stochastic ranking are used as constraint-handling techniques. The performance of each version is analysed by solving 24 well-known benchmark problems. The final results suggest MBSO and the ε-constrained method as a good option to deal with constrained problems.	algorithm;benchmark (computing);experiment;feasible region;optimization problem;program optimization;scalability;swarm intelligence	Adriana Cervantes-Castillo;Efrén Mezura-Montes	2016	2016 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2016.7744263	probabilistic-based design optimization;algorithm design;mathematical optimization;multi-swarm optimization;constrained optimization;meta-optimization;computer science;linear programming;derivative-free optimization;artificial intelligence;machine learning;continuous optimization;cluster analysis;silicon;imperialist competitive algorithm;particle swarm optimization;storm;metaheuristic	AI	25.19094709002457	-3.057859172806872	162125
51d80fd6879656653a4f62cdfc91c342c3d83464	application of firefly algorithm and anfis for optimisation of functionally graded beams	optimisation;anfis;firefly algorithm;functionally graded beams	Volume fraction optimisation of functionally graded beams is studied for maximising the fundamental natural frequency by applying a new meta-heuristic nature-inspired algorithm called firefly algorithm (FA) which is based on the flashing behaviour of fireflies. Nature-inspired algorithms are among the most powerful algorithms for optimisation of engineering problems. The primary optimisation variables are the three parameters in the power-law distribution. Since the search space is large, the optimisation processes becomes so complicated and too much time consuming. Thus, a suitable Adaptive Neuro-Fuzzy Inference System (ANFIS) that is based on Takagi–Sugeno fuzzy inference system is combined with FA to reproduce the behaviour of the structure in free vibration. The ANFIS improves the speed of optimisation process by a considerable amount. The results are compared with those obtained by imperialist competitive algorithm, genetic algorithm and Artificial Neural Networks proposed in our previous work. Resul...	adaptive neuro fuzzy inference system;firefly algorithm;mathematical optimization	Saeed Kamarian;Mohammad Hosein Yas;Amin Pourasghar;M. Daghagh	2014	J. Exp. Theor. Artif. Intell.	10.1080/0952813X.2013.813978	mathematical optimization;adaptive neuro fuzzy inference system;computer science;artificial intelligence;firefly algorithm	AI	25.72803755755859	-6.560422667406688	162532
3d5ce7f62afb7cc2caec5b0332a6a6e62b4f60fc	application of evolution strategies to the design of tracking filters with a large number of specifications	signal image and speech processing;multicriteria optimization;air traffic control;quantum information technology spintronics;radar tracking filters;evolution strategies;parameter space;evolution strategy;global optimization;figure of merit;fitness function;evolutionary computing	This paper describes the application of Evolution Strategies to the design of Interacting Multiple Mode (IMM) tracking filters in order to fulfill a large table of performance specifications. These specifications define the desired filter performance in a thorough set of selected test scenarios, for different figures of merit and input conditions, imposing hundreds of performance goals. The design problem is stated as a numeric search in the filter parameters space to attain all specifications or at least minimize in a compromise the excess over some specifications as much as possible, applying global optimization techniques coming from Evolutionary Computation field. Besides, it is proposed a new methodology to integrate specifications in a fitness function able to effectively guide the search to suitable solutions. The method has been applied to the design of an IMM tracker for a real-world civil air traffic control application: the accomplishment of specifications defined for the future European ARTAS system. 1.Introduction A tracking filter has the double goal of reducing measurement noise and consistently predicting future values of signal. This kind of problems has efficient solutions in the case of stationary signals, but solutions for non-stationary problems are not so consolidated yet. This is the case in the field we are dealing with in this paper, tracking aircraft trajectories from radar measurements in air traffic control (ATC) applications. The design of tracking filters for the ATC problem demands complex algorithms, like the modern Interactive Multiple Model filter (IMM) [1]. These algorithms depend on a high number of parameters (seven in the IMM design presented here) which must be adjusted in order to achieve as much as possible the desired tracking filter performance. IMM has proven certainly satisfactory performance for tracking manoeuvring targets, in relation with previous approaches. However, the relation between its input parameters and final performance is far from clear, due to strongly non-linear interactions among all parameters. Therefore, no direct design methodology has been proposed to generate the best solution for a specific application to date, apart from manual parameterisation and evaluation with simulation. Besides, real-world applications of tracking filters for ATC usually address performance specifications defined over a exhaustive set of realistic operational scenarios and covering a number of conflicting figures of merit. These two characteristics, large table of specifications and application of complex algorithms, make the design of modern tracking filter a very complex problem. In this paper, the authors expose a new methodology to design and adjust tracking filters for ATC applications based on the use of Evolution Strategies as an optimisation problem over a customised cost function (fitness function). The method has been demonstrated with the design	activity tracker;advanced tactical center;advanced transportation controller;algorithm;evolution strategy;evolutionary computation;fitness function;global optimization;interaction;loss function;mathematical optimization;monte carlo method;nonlinear system;offset binary;radar;simulation;solver;stationary process;steady state	Jesús García Herrero;Juan A. Besada;Antonio Berlanga;José M. Molina López;Gonzalo de Miguel Vela;José R. Casar	2003	EURASIP J. Adv. Sig. Proc.	10.1155/S1110865703302057	figure of merit;simulation;telecommunications;computer science;electrical engineering;artificial intelligence;air traffic control;machine learning;mathematics;evolution strategy;parameter space;fitness function;algorithm;global optimization	Robotics	34.144453204792946	-2.404850673162798	162755
0d4c2685b26d0282080f348bcf83c8b3507aac8f	data fitting with a spline using a real-coded genetic algorithm	bayes information criterion;spline;non linear programming;ajustamiento curva;esplin;programacion no lineal;probleme non lineaire;localization;programmation non lineaire;localizacion;algoritmo genetico;nonlinear problems;optimization problem;aproximacion esplin;localisation;spline approximation;approximation spline;algorithme genetique;geometric modeling;ajustement courbe;genetic algorithm;knot placement;geometric model;curve fitting;data fitting;real coded genetic algorithm	To obtain a good approximation for data fitting with a spline, frequently we have to deal with knots as variables. The problem to be solved then becomes a continuous nonlinear and multivariate optimization problem with many local optima. Therefore, it is difficult to obtain the global optimum. In this paper, we propose a method for solving this problem by using a real-coded genetic algorithm. Our method can treat not only data with a smooth underlying function, but also data with an underlying function having discontinuous points and/or cusps. We search for the best model among candidate models by using the Bayes Information Criterion (BIC). With this, we can appropriately determine the number and locations of knots automatically and simultaneously. Five examples of data fitting are given to show the performance of our method.	curve fitting;genetic algorithm;spline (mathematics)	Fujiichi Yoshimoto;Toshinobu Harada;Yoshihide Yoshimoto	2003	Computer-Aided Design	10.1016/S0010-4485(03)00006-X	mathematical optimization;nonlinear programming;computer science;geometric modeling;mathematics;geometry;statistics;curve fitting	EDA	33.513256827776594	0.537039075914826	162837
522f5a8bbe48256ff4676690cd4888213f69501f	searching vaccination strategy with surrogate-assisted evolutionary computing		Agent-based stochastic simulation is an established approach to study infectious diseases. Its advantage is the flexibility to incorporate important concepts. The effect of various mitigation strategies has been demonstrated using simulation models. Most of the previous studies compared a few options with a few selected scenarios. We propose to use genetic algorithms to search for the best vaccination strategy for a given scenario with the simulation program as fitness scorer. Vaccination efficacy varies significantly. Therefore, the real challenge is to find a good strategy without the knowledge of it. The simulation software is efficient, yet still takes three minutes to complete a simulation run with Taiwan population. We use surrogate to speed up the search about 1000 times. The surrogate has the average of the absolute value of error around 0.284 percent and the rank correlation coefficient is greater than 0.98 for all the scenarios except one. The optimal solution with surrogate has fitness value very close to use simulations. The difference is generally less than one percent. We envision that an autonomous software searches through the huge scenario space with the help of surrogate function and adaptively executes simulation program to revise the surrogate function to produce higher fidelity surrogate and better search results.	autonomous robot;coefficient;evolutionary computation;genetic algorithm;simulation software	Zong-De Jian;Tsan-sheng Hsu;Da-Wei Wang	2016	2016 6th International Conference on Simulation and Modeling Methodologies, Technologies and Applications (SIMULTECH)		bioinformatics	SE	30.44249609705187	-7.3171418550268434	163098
aa1fc02507a814a7fc37356dcc9cbba0b3cc95a5	particle swarm optimization using dimension selection methods	deterministic particle swarm optimization;particle swarm optimization pso;randomness;journal;deterministic dimension selection;random dimension selection	Particle swarm optimization (PSO) has undergone many changes since its introduction in 1995. Being a stochastic algorithm, PSO and its randomness present formidable challenge for the theoretical analysis of it, and few of the existing PSO improvements have make an effort to eliminate the random coefficients in the PSO updating formula. This paper analyzes the importance of the randomness in the PSO, and then gives a PSO variant without randomness to show that traditional PSO cannot work without randomness. Based on our analysis of the randomness, another way of using randomness is proposed in PSO with random dimension selection (PSORDS) algorithm, which utilizes random dimension selection instead of stochastic coefficients. Finally, deterministic methods to do the dimension selection are proposed, and the resultant PSO with distance based dimension selection (PSODDS) algorithm is greatly superior to the traditional PSO and PSO with heuristic dimension selection (PSOHDS) algorithm is comparable to traditional PSO algorithm. In addition, using our dimension selection method to a newly proposed modified particle swarm optimization (MPSO) algorithm also gets improved results. The experiment results demonstrate that our analysis about the randomness is correct and the usage of deterministic dimension selection method is very helpful. 2012 Elsevier Inc. All rights reserved.	algorithm;coefficient;distribution (mathematics);heuristic;mathematical optimization;particle swarm optimization;randomness;resultant;theory	Xin Jin;Yongquan Liang;Dongping Tian;Fuzhen Zhuang	2013	Applied Mathematics and Computation	10.1016/j.amc.2012.11.020	mathematical optimization;artificial intelligence;machine learning;mathematics;randomness;statistics	AI	28.112538893993136	-4.122565934393767	163200
293fe8dcb505bfbdeae8d444f1efd63684336d35	force-imitated particle swarm optimization using the near-neighbor effect for locating multiple optima	near neighbor effect;multimodal optimization problem;particle swarm optimization;force imitated particle dynamics;article	Multimodal optimization problems pose a great challenge of locating multiple optima simultaneously in the search space to the particle swarm optimization (PSO) community. In this paper, the motion principle of particles in PSO is extended by using the near-neighbor effect in mechanical theory, which is a universal phenomenon in nature and society. In the proposed near-neighbor effect based force-imitated PSO (NN-FPSO) algorithm, each particle explores the promising regions where it resides under the composite forces produced by the “near-neighbor attractor” and “near-neighbor repeller”, which are selected from the set of memorized personal best positions and the current swarm based on the principles of “superior-and-nearer” and “inferior-and-nearer”, respectively. These two forces pull and push a particle to search for the nearby optimum. Hence, particles can simultaneously locate multiple optima quickly and precisely. Experiments are carried out to investigate the performance of NN-FPSO in comparison with a number of state-of-the-art PSO algorithms for locating multiple optima over a series of multimodal benchmark test functions. The experimental results indicate that the proposed NN-FPSO algorithm can efficiently locate multiple optima in multimodal fitness landscapes.	4d film;algorithm;benchmark (computing);distribution (mathematics);evolutionary multimodal optimization;expectation propagation;experiment;iteration;map (parallel pattern);mathematical optimization;mobile robot;motion planning;multimodal interaction;particle swarm optimization	Lili Liu;Shengxiang Yang;Dingwei Wang	2012	Inf. Sci.	10.1016/j.ins.2010.11.013	mathematical optimization;multi-swarm optimization;computer science;artificial intelligence;machine learning;mathematics;particle swarm optimization	AI	27.725949087254282	-4.1325155153723285	163274
d4f2a398ffe9081974b6fc35b89cd09632cfda3a	estimation of a contaminant source in an estuary with an inverse problem approach	pollutant transport;inverse problem;golden section;determination of sources;stochastic methods	A great challenge today is conciliation of water resources utilization with the expansion of cities and human activities. Considering that the water quality of a given water body is necessarily evaluated through the analysis of some biological, physical and chemical parameters, mathematical and computational models able to describe the behavior of such parameters can be a useful tool, given their ability to generate scenarios and, as a consequence, the possibility to support decisions regarding water resources management. In this work Inverse Problems techniques are applied to estimate the source parameters (location and intensity) of a hypothetical conservative pollutant released in estuarine waters. The case study considered here is the Macaé River estuary, located in the Brazilian southeast coast. The pollutant transport was modeled by the advection–diffusion equation. For the source location estimation were used the Luus–Jaakola (LJ), the particle collision algorithm (PCA) and the ant colony optimization (ACO) methods, and to estimate the source intensity was used the golden section (GS) method. In this study, synthetic sampling data of concentrations with and without noise were used. For the noiseless data, all methods have successfully achieved the objective function target low value in more than 95% of executions. On the other hand, for the data with ±5% of noise level, that happened only in 80% of the runs. Considering the number of different estimated points on the location and also the computational cost, the method LJ-GS showed the best performance. The results of this study demonstrated the feasibility of the inverse problem approach to estimate with satisfactory accuracy the location and intensity of a given pollutant source released in estuarine environments, which can also contribute to possible environmental liabilities identification. © 2015 Elsevier Inc. All rights reserved.	algorithm;ant colony optimization algorithms;computation;computational complexity theory;computational model;lightweight java;loss function;luus–jaakola;mathematical optimization;noise (electronics);optimization problem;roland gs;sampling (signal processing);synthetic intelligence	Radael de Souza Parolin;Antônio José da Silva Neto;Pedro Paulo Gomes Watts Rodrigues;Orestes Llanes-Santiago	2015	Applied Mathematics and Computation	10.1016/j.amc.2015.03.054	mathematical optimization;inverse problem;mathematics;golden ratio;statistics	AI	33.945408796235476	-3.995898011487308	163281
299bcc2f903cea557f96a270779e02a2e4680b63	artificial bee colony algorithm for optimal design of power system stabilizer	eigenvalues and eigenfunctions;damping;oscillations;ant colony optimisation;selected works;time domain analysis ant colony optimisation damping eigenvalues and eigenfunctions oscillations power system dynamic stability;time domain analysis;power system dynamic stability artificial bee colony algorithm optimal design power system stabilizer heuristic global optimization algorithm simultaneous coordinated tuning multimachine power system abc population based optimization algorithm foraging bee colony behavior robustness damping stabilizer eigenvalue analysis nonlinear time domain simulation power system low frequency oscillation;power system dynamic stability;bepress;low frequency oscillation artificial bee colony algorithm power system stabilizer tuning	A newly developed heuristic global optimization algorithm, artificial bee colony (ABC) algorithm, is applied for simultaneous coordinated tuning of the power system stabilizers (PSSs) in the multi-machine power system. ABC is a population based optimization algorithm inspired by the foraging behavior of bee colony and proven its superior capabilities, such as faster convergence and better global minimum achievement. To investigate the robustness and ability of the proposed algorithm in damping stabilizers design, a 2-area 4-machine system under different operating conditions is considered. The performance of the proposed ABC is compared with the genetic algorithm (GA) through eigenvalue analysis and nonlinear time-domain simulation. The simulation studies show that the stabilizers designed by ABC perform better than those by GA in damping the power system low-frequency oscillations and enhance greatly the dynamic stability of the power system.	artificial bee colony algorithm;genetic algorithm;global optimization;heuristic;mathematical optimization;maxima and minima;nonlinear system;optimal design;population;simulation;software release life cycle	Mahdiyeh Eslami;Hussain Shareef	2012	2012 10th International Power & Energy Conference (IPEC)	10.1109/ASSCC.2012.6523229	control engineering;mathematical optimization;engineering;control theory	EDA	32.64485722405023	-5.263796397081293	163599
bd203150c1aa235f8f73968282182a72c9c1d6eb	numerical optimization using synergetic swarms of foraging bacterial populations	high dimensionality;optimization technique;curse of dimensionality;numerical optimization;optimization problem;particle swarm optimization algorithm;evolutionary optimization;optimal algorithm	The bacterial foraging optimization (BFO) algorithm is a popular stochastic, population-based optimization technique that can be applied to a wide range of problems. Two are the major issues the BFO algorithm is confronted with: first, the foraging mechanism of BFO might in some cases induce the attraction of bacteria gathered near the global optimum by bacteria gathered to local optima, thus slowing down the whole population convergence. Second, BFO is susceptible to the curse-of-dimensionality, which makes it significantly harder to find the global optimum of a high-dimensional problem, compared to a low-dimensional problem with similar topology. In this paper, we introduce a novel BFO-based optimization algorithm aiming to address these issues, the synergetic bacterial swarming optimization (SBSO) algorithm. Our novel approach consists of: (i) the introduction of the swarming dynamics of the particle swarm optimization algorithm in the context of BFO, in order to ameliorate the convergence issues of the BFO bacteria foraging mechanism; and (ii) the utilization of multiple populations to optimize different components of the solution vector cooperatively, so as to mitigate the curse-of-dimensionality issues of the algorithm. We demonstrate the efficacy of our approach on several benchmark optimization	algorithm;basic formal ontology;benchmark (computing);curse of dimensionality;global optimization;local optimum;mathematical optimization;particle swarm optimization;population;stochastic process;swarm robotics;synergetics (haken);synergy	Sotirios P. Chatzis;Spyros Koukas	2011	Expert Syst. Appl.	10.1016/j.eswa.2011.06.031	optimization problem;mathematical optimization;multi-swarm optimization;simulation;meta-optimization;curse of dimensionality;computer science;derivative-free optimization;machine learning;metaheuristic	AI	26.219759609837027	-5.140086953229407	163683
7236013fb574139ccab8a155ced23f8acaf1cfad	a hybrid particle swarm evolutionary algorithm for constrained multi-objective optimization	particle swarm;multi objective optimization;particle swarm optimization;constrained multi objective optimization;evolutionary algorithm	In this paper, a hybrid particle swarm evolutionary algorithm is proposed for solving constrained multi-objective optimization. Firstly, in order to keep some particles with smaller constraint violations, a threshold value is designed, the updating strategy of particles is revised based on the threshold value; then in order to keep some particles with smaller rank values, an infeasible elitist preservation strategy is proposed in order to make the infeasible elitists act as bridges connecting disconnected feasible regions. Secondly, in order to find a set of diverse and well-distributed Pareto-optimal solutions, a new crowding distance function is designed for bi-objective optimization problems. It can assign larger crowding distance function values not only for the particles located in the sparse region but also for the particles located near to the boundary of the Pareto front. In this step, the reference points are given, and the particles which are near to the reference points are kept no matter how crowded these points are. Thirdly, a new mutation operator with two phases is proposed. In the first phase, the total force is computed first, then it is used as a mutation direction, searching along this direction, better particles will be found. The comparative study shows the proposed algorithm can generate widely spread and uniformly distributed solutions on the entire Pareto front.	evolutionary algorithm;multi-objective optimization;swarm	J. Wei;Yue Wang;Huaqing Wang	2010	Computing and Informatics		mathematical optimization;multi-swarm optimization;simulation;computer science;machine learning;evolutionary algorithm;mathematics;particle swarm optimization;metaheuristic	AI	27.33669244009726	-3.2998166980324206	163761
9d69d96543972ffef19764fdf4ef17a1c793ab51	effects of initial search bound on the performance of self-adaptive evolutionary computation methods		Self-adaptive evolutionary computation methods are widely used for finding global optimum in varieties of problem domains. One of the major de- merits of these methods is premature convergence that stuck the search process at one of the local minimum. This paper examines this issue through an ex- haustive study on the possible effects of initial search bound on the overall per- formance of the evolutionary computation methods.	evolutionary computation	Anjan Kumar Swain	2010		10.1007/978-3-642-12035-0_31	mathematical optimization;interactive evolutionary computation;human-based evolutionary computation;artificial intelligence;algorithm	AI	26.596888813450786	-5.344730948818762	163883
86cecadf32920f9f62d2dcc2cc9c6d99d1c04f79	convergence analysis of gene expression programming based on maintaining elitist	convergence analysis;convergence;gep;population size;convergence speed;global optimization;gene expression programming;markov chain	This paper analyzes the convergence of Gene Expression Programming based on maintaining elitist(ME-GEP).It is proved that ME-GEP algorithm will converge to the global optimal solution. The convergence speed of ME-GEP algorithm is estimated by the properties of transition matrices. The result hinges on four factors: population size, minimal transposition, mutation and selection probabilities.	algorithm;converge;gene expression programming;java platform, micro edition;markov chain;mutation (genetic algorithm)	Xin Du;Lin Xin Ding;Chen Wang Xie;Xing Xu;Shen wen Wang;Li Chen	2009		10.1145/1543834.1543952	markov chain;mathematical optimization;population size;convergence;computer science;theoretical computer science;mathematics;gene expression programming;algorithm;statistics;global optimization	Theory	29.078915477592943	-6.973998790246214	163912
187f11d09451caf95a745e1e6813637caf458a03	an efficient and improved particle swarm optimization algorithm for swarm robots system	particle swarm optimization;simulation analysis;swarm robots	In recent years, the number of researches in which swarm intelligence shown by individual communication in swarm robots is increasing. As one of the representative algorithms in swarm intelligence, particle swarm optimization has been applied to many fields because of its simple concept, easy realizing and good optimization characteristics. However, it still has some disadvantages such as easy falling in the local best situation and solving the discrete optimization problems poor. In this paper, genetic algorithm has been integrated with particle swarm optimization to improve the performance of the algorithm; the simple particle swarm optimization algorithm has been simulated in the Player/Stage and compared with the particle swarm optimization. The simulation shows that the algorithm is faster and more efficient. © Springer-Verlag Berlin Heidelberg 2013.	algorithm;particle swarm optimization;robot	Zhiguo Shi;Xiaomeng Zhang;Jun Tu;Zhiyong Yang	2013		10.1007/978-3-642-37502-6_40	multi-swarm optimization;swarm intelligence;particle swarm optimization;metaheuristic	Robotics	27.19476613467168	-3.9459809574838838	163942
c3524de264edd456bba6544bac0d59efeb41be1a	a novel image encryption algorithm based on improved 3d chaotic cat map	encryption of image chaos 3d cat map henon map logistic map;image encryption;sequences;security analysis;image coding;chaos;sequences chaos cryptography image coding;cryptography chaos chaotic communication security logistics pixel software algorithms internet educational institutions resists;logistic map;3d cat map;encryption of image;logistics;exhaustive attack;cipher text only attack;three dimensional displays;cryptography;pixel;cipher text only attack image encryption algorithm 3d chaotic cat map henon map chaotic sequence 2d logistic map sequence statistical attack exhaustive attack;3d chaotic cat map;henon map;henon map chaotic sequence;image encryption algorithm;security;algorithm design and analysis;statistical attack;2d logistic map sequence	In this paper, an image encryption algorithm based on improved 3D cat map is proposed. The new algorithm employs Henon map chaotic sequence to generate control parameters of shuffling and uses improved 2D Logistic map sequence to substitute grey values. It cannot only effectively encrypt images, but also can resist cipher analyzers' attack by periodicity of cat map. Experimental results and security analysis show that the algorithm can be easily implemented and its encryption effect is satisfactory. Moreover, the algorithm possesses high security in terms of the resistance to exhaustive attack, statistical attack and cipher-text-only attack..	algorithm;arnold;arnold's cat map;cipher;encryption;hénon map;key space (cryptography);logistic map;pixel;quasiperiodicity;text-based user interface	Hongjuan Liu;Zhiliang Zhu;Huiyan Jiang;Beilei Wang	2008	2008 The 9th International Conference for Young Computer Scientists	10.1109/ICYCS.2008.449	logistics;discrete mathematics;watermarking attack;logistic map;computer science;cryptography;information security;theoretical computer science;mathematics;security analysis;computer security;algorithm;pixel	EDA	38.476777708168754	-8.824090574690514	164045
0dfff7bbda77380083d49194ed3ca1c59422212d	the deprioritised approach to prioritised algorithms		Randomised algorithms are an effective method of attacking computationally intractable problems. A simple and fast randomised algorithm may produce results to an accuracy sufficient for many purposes, especially in the average case. In this thesis we consider average case analyses of heuristics for certain NP-hard graph optimisation problems. In particular, we consider algorithms that find dominating sets of random regular directed graphs. As well as providing an average case analysis, our results also determine new upper bounds on domination numbers of random regular directed graphs. The algorithms for random regular directed graphs considered in this thesis are known as prioritised algorithms. Each prioritised algorithm determines a discrete random process. This discrete process may be continuously approximated using differential equations. Under certain conditions, the solutions to these differential equations describe the behaviour of the prioritised algorithm. Applying such an analysis to prioritised algorithms directly is difficult. However, we are able to use prioritised algorithms to define new algorithms, called deprioritised algorithms, that can be analysed in this fashion. Defining a deprioritised algorithm based on a given prioritised algorithm, and then analysing the deprioritised algorithm, is called the deprioritised approach. The initial theory describing the deprioritised approach was developed by Wormald and has been successfully applied in many cases. However not all algorithms are covered by Wormald’s theory: for example, algorithms for random regular directed graphs. The main contribution of this thesis is the extension of the deprioritised approach to a larger class of prioritised algorithms. We demonstrate the new theory by applying it to two algorithms which find dominating sets of random regular directed graphs.	approximation algorithm;best, worst and average case;computational complexity theory;directed graph;dominating set;effective method;heuristic (computer science);mathematical optimization;np-hardness;nick wormald;randomized algorithm;stochastic process	Stephen Howe	2008			mathematical analysis;theoretical computer science;mathematics	Theory	28.810961641266537	3.4203037501961644	164124
5ffec9816318714832d9195c4d1294f8e9a3536b	the effect of selection on the development of mutational robustness	optimal solution;random sampling;robust optimization;point mutation;genetic algorithm;genetic algorithms;geerational genetic algorithm mutational robustness tournament method fitness proportionate method ranking method;robustness genetic algorithms genetic mutations evolution biology evolutionary computation surface acoustic waves military computing biological systems computer science design optimization	This paper investigates the role of selection in the acquisition of mutational robustness for two test problems: rONEMAX and SAW. Three different selection methods: tournament, fitness proportionate, and ranking, were implemented in a geerational genetic algorithm and applied to both problems. The effect of altering the selection pressure for the tournament selection method was investigated by varying the tournament size. For the rONEMAX problem the tournament and ranking selection based algorithms found optimal solutions which were significantly more robust to point mutation than those found by either the fitness proportionate selection algorithm or random sampling of the optimal solution space. Altering the selection pressure had no significant effect on the robustness of the solutions located by tournament selection algorithm for the rONEMAX problem. For the SAW problem, however, tournament selection with a tournament size of four found solutions which were significantly more robust than those located by larger tournament sizes. For the majority of the problem variants explored here the tournament and ranking selection methods proved more effective at locating robust optimal solutions than fitness proportionate selection.	feasible region;fitness proportionate selection;genetic algorithm;robustness (computer science);sampling (signal processing);selection (genetic algorithm);selection algorithm;tournament selection	Justin Schonfeld;Sushil J. Louis	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4425090	truncation selection;mathematical optimization;tournament selection;robust optimization;genetic algorithm;fitness proportionate selection;computer science;bioinformatics;artificial intelligence;genetic operator;machine learning;mathematics;selection	AI	26.251576410537346	-6.687460435136382	164286
3bd6c99b6f8a5bd1575df0b826f6820288dab4b7	learning of bayesian networks by a local discovery ant colony algorithm	databases;belief networks;bayesian network;learning algorithm;evolutionary computation;pediatrics;ant colony optimization;learning;hybrid bayesian network learning algorithm;greedy search;uncertainty;optimal method;bayesian methods;greedy algorithms;random variables;simulated annealing;skeleton;artificial intelligent;minimax techniques;simulated annealing belief networks greedy algorithms learning artificial intelligence minimax techniques search problems;simulated annealing local discovery ant colony algorithm knowledge representation artificial intelligence greedy search hybrid bayesian network learning algorithm max min parents and children;local discovery ant colony algorithm;ant colony algorithm;bayesian methods skeleton optimization probabilistic logic pediatrics benchmark testing evolutionary computation;random variable;artificial intelligence;inference algorithms;optimization;search problems;max min parents and children;probabilistic logic;learning artificial intelligence;knowledge representation;benchmark testing;approaches to learning;optimization methods	Bayesian networks (BNs) are knowledge representation tools capable of representing dependence or independence relationships among random variables that compose a problem domain. Bayesian networks learned from data sets are receiving increasing attention within the community of researchers of uncertainty in artificial intelligence, due to their capacity to provide good inference models and to discover the structure of complex domains. One approach to learning BNs from data is to use a scoring metric to evaluate the fitness of any given candidate network for the database, and apply an optimization procedure to explore the set of candidate networks. Among the most frequently used optimization methods for this purpose is greedy search, either deterministic or stochastic. This article proposes a hybrid Bayesian network learning algorithm MMACO, based on the local discovery algorithm max-min parents and children (MMPC) and ant colony optimization (ACO). MMPC is used to construct the skeleton of the Bayesian network and then ACO is used to orientate its edges, thus returning the final structure. We apply MMACO (max-min ACO) to several sets of benchmark networks and show that it outperforms greedy search (GS) and simulated annealing (SA) algorithms.	ant colony optimization algorithms;artificial intelligence;bayesian network;benchmark (computing);greedy algorithm;knowledge representation and reasoning;mathematical optimization;maxima and minima;problem domain;reactive planning;roland gs;search algorithm;simulated annealing	Pedro C. Pinto;Andreas Nägele;Mathäus Dejori;Thomas A. Runkler;João Miguel da Costa Sousa	2008	2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)	10.1109/CEC.2008.4631166	random variable;mathematical optimization;greedy algorithm;ant colony optimization algorithms;computer science;artificial intelligence;machine learning;data mining;statistics;evolutionary computation	AI	27.780416281886836	-8.518858496725132	164652
dc25dc02e948a32d95c1f7137818522678e4223e	feedback-control operators for improved pareto-set description: application to a polymer extrusion process	evolutionary computation;multiobjective optimization;genetic algorithms;polymer extrusion;local search	This paper presents a new class of operators for multiobjective evolutionary algorithms that are inspired on feedback-control techniques. The proposed operators, the archive-set reduction and the surface-filling crossover, have the purpose of enhancing the quality of the description of the Pareto-set in multiobjective optimization problems. They act on the Pareto-estimate sample set, performing operations that eliminate archive points in the most crowded regions, and generate new points in the less populated regions, leading to a dynamic equilibrium that tends to generate a uniform sampling of the efficient solution set. The internal parameters of those operators are coordinated by feedback-control inspired techniques, which ensure that the desired equilibrium is attained. Numerical experiments in some benchmark problems and in a real problem of optimization of a single screw extrusion system for polymer processing show that the proposed methodology is able to generate more detailed descriptions of Pareto-optimal fronts than the ones produced by usual algorithms. & 2014 Elsevier Ltd. All rights reserved.	archive;benchmark (computing);evolutionary algorithm;experiment;mathematical optimization;multi-objective optimization;numerical method;pareto efficiency;polymer;population;sampling (signal processing)	Eduardo G. Carrano;Dayanne Gouveia Coelho;António Gaspar-Cunha;Elizabeth F. Wanner;Ricardo H. C. Takahashi	2015	Eng. Appl. of AI	10.1016/j.engappai.2014.10.016	mathematical optimization;genetic algorithm;computer science;local search;multi-objective optimization;plastics extrusion;evolutionary computation	AI	28.35885255022916	-1.7280417374277974	164957
b1de7de588efd820f939b1213b02547b8afc4f82	multiobjective differential evolution based on fuzzy performance feedback	spacing;hypervolume;differential evolution;maximum spread;multiobjective performance metrics;fuzzy logic	Differential evolution is often regarded as one of the most efficient evolutionary algorithms to tackle multiobjective optimization problems. The key to success of any multiobjective evolutionary algorithms MOEAs is maintaining a delicate balance between exploration and exploitation throughout the evolution process. In this paper, the authors propose a Fuzzy-based Multiobjective Differential Evolution FMDE that uses performance metrics, specifically hypervolume, spacing, and maximum spread, to measure the state of the evolution process. The authors apply the fuzzy inference rules to these metrics in order to dynamically adjust the associated control parameters of a chosen mutation strategy used in this algorithm. One parameter controls the degree of greedy or exploitation, while another regulates the degree of diversity or exploration of the reproduction phase. Therefore, the authors can appropriately adjust the degree of exploration and exploitation through performance feedback. The performance of FMDE is evaluated on well-known ZDT and DTLZ test suites. The results validate that the proposed algorithm is competitive with respect to chosen state-of-the-art MOEAs.	differential evolution	Chatkaew Jariyatantiwait;Gary G. Yen	2014	IJSIR	10.4018/ijsir.2014100104	fuzzy logic;differential evolution;mathematical optimization;computer science;artificial intelligence;machine learning;mathematics	Vision	24.782104238428026	-6.277500819914335	165202
52d60f9304eadcd5ecb46ba527ed86b1d9b455ac	the control of dominance area in particle swarm optimization algorithms for many-objective problems	silicon;control of dominance area of solutions;empirical study;pareto optimisation;evolutionary computation;approximation algorithms;statistical test;multi objective evolutionary algorithm;algorithm design and analysis silicon lead optimization approximation algorithms particle swarm optimization approximation methods;control of dominance area of solutions particle swarm optimization many objective optimization;quality indicator;multi objective particle swarm optimization;particle swarm optimizer;many objective optimization;lead;particle swarm optimisation evolutionary computation pareto optimisation;particle swarm optimization;optimization;approximation methods;particle swarm optimization algorithm;statistical test dominance area particle swarm optimization many objective problem multiobjective evolutionary algorithm search ability pareto dominance moea cooperative based framework quality indicator;particle swarm optimisation;algorithm design and analysis	Multi-objective evolutionary algorithms (MOEA) are particulary suitable to solve real life problems, but they have some limitations when dealing with problems with many objectives, typically more than three. Recently, some many-objective techniques were proposed to avoid the deterioration of the search ability of Pareto dominance based MOEA for many-objective problems. This work applies the control of dominance area in two different Multi-objective Particle Swarm Optimization algorithms and investigates the influence of this technique in a cooperative-based framework. Besides, an empirical study is performed to identify if the many-objective technique increases the quality of the PSO algorithms for many-objective problems. The experimental results are compared applying some quality indicators and statistical test.	approximation;evolutionary algorithm;experiment;moea framework;pareto efficiency;particle swarm optimization;phase-shift oscillator;real life	Andre B. de Carvalho;Aurora Trinidad Ramirez Pozo	2010	2010 Eleventh Brazilian Symposium on Neural Networks	10.1109/SBRN.2010.32	algorithm design;mathematical optimization;statistical hypothesis testing;multi-swarm optimization;lead;computer science;artificial intelligence;machine learning;mathematics;silicon;empirical research;particle swarm optimization;evolutionary computation	AI	24.849678222515696	-3.8053489312148296	165260
6f1537d2694a0bd5df9065a0aed454b89345ce00	a stability analysis based parameter setting method for spiral optimization	optimisation;search problems convergence optimisation;convergence;spirals optimization convergence stability analysis analytical models asymptotic stability equations;spo model stability analysis based parameter setting method metaheuristics method continuous optimization problems spiral phenomena analogy spiral optimization convergence rate rotation rate search performance search dynamics dynamic equilibrium point stability;search problems	In recent years, the authors proposed an effective metaheuristics method for continuous optimization problems based on analogy of spiral phenomena in nature which is called Spiral Optimization (SPO). The SPO has two setting parameters: the convergence rate and the rotation rate. Their values affect the search performance depending on computational and/or problem conditions. However, their effective setting methods without trial and error have not studied so far including analyses of its search dynamics which are needed for making such methods. This paper especially focuses on the convergence rate and proposes 1 its effective setting method from analyzing stability of dynamic equilibrium point of the SPO model. The effectiveness of the proposed method is confirmed thorough simulation for some benchmark functions and comparison with other representative metaheuristics methods.	benchmark (computing);computation;continuous optimization;experiment;iteration;mathematical optimization;metaheuristic;numerical analysis;pareto efficiency;particle swarm optimization;rate of convergence;simulation;usability	Kenichi Tamura;Keiichiro Yasuda	2013	2013 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/SMC.2013.667	mathematical optimization;simulation;convergence;computer science;mathematics;mathematical economics	Robotics	28.900547292408653	-5.181129581268929	165428
6a4b2a89fe6f343d8c5a2bbdded3800a15ec232a	performance analysis of derandomized evolution strategies in quantum control experiments	second order;cma es;experimental quantum control;optimal method;pulse shaping;first order;performance analysis;evolution strategy;laser pulse shaping;genetic algorithm;derandomized evolution strategies;laboratory experiment;quantum control;covariance matrix	Genetic Algorithms (GAs) are historically the most commonly used optimization method in Quantum Control (QC) experiments. We transfer specific Derandomized Evolution Strategies (DES) that have performed well on noise-free theoretical Quantum Control calculations, including the Covariance Matrix Adaptation (CMA-ES) algorithm, into the noisy environment of Quantum Control experiments. We study the performance of these DES variants in laboratory experiments, and reveal the underlying strategy dynamics of first- versus second-order landscape information.  It is experimentally observed that global maxima of the given QC landscapes are located when only first-order information is used during the search. We report on the disruptive effects to which DES are exposed in these experiments, and study covariance matrix learning in noisy versus noise-free environments. Finally, we examine the characteristic behavior of the algorithms on the given landscapes, and draw some conclusions regarding the use of DES in QC laboratory experiments.	cma-es;coherent control;evolution strategy;experiment;first-order predicate;fractal landscape;genetic algorithm;mathematical optimization;maxima;profiling (computer programming);quantum;randomized algorithm;strategy dynamics	Ofer M. Shir;Jonathan Roslund;Thomas Bäck;Herschel A Rabitz	2008		10.1145/1389095.1389193	covariance matrix;mathematical optimization;pulse shaping;simulation;genetic algorithm;cma-es;computer science;artificial intelligence;machine learning;first-order logic;mathematics;evolution strategy;second-order logic;algorithm	ML	28.914734411800936	-7.2842254208824455	165616
9d640062e9aaf4d723a9425a9324c91d71606bc7	attraction based pso with sphere search for dynamic constrained multi-objective optimization problems	constrained optimization;efficient algorithm;pareto front;multi objective optimization;particle swarm optimizer;particle swarm optimization;dynamic multi objective optimization;pareto optimal solution;local search;multi objective optimization problem	Developing efficient algorithms for dynamic constrained multi-objective optimization problems (DCMOPs) is very challenging. This paper describes an attraction based particle swarm optimization (PSO) algorithm with sphere search for such problems. A dynamic constrained multi-objective optimization problem is transformed into a series of static constrained multi-objective optimization problems by dividing the time period into several equal intervals. To speed up optimization process and reuse the information of Pareto optimal solutions obtained from previous time, a new method based on sphere search is proposed to generate the initial swarm for the next time interval. To deal with the transformed problem effectively, a new particle comparison strategy is proposed for handling constraints in the problem. A local search operator based on the concept of attraction is introduced for finding good search directions of the particles. The results show that the proposed algorithm can effectively track the varying Pareto fronts with time.	algorithm;constraint (mathematics);local search (optimization);mathematical optimization;multi-objective optimization;optimization problem;pareto efficiency;particle swarm optimization	Jingxuan Wei;Mengjie Zhang	2011		10.1145/2001858.2001904	probabilistic-based design optimization;optimization problem;mathematical optimization;multi-swarm optimization;constrained optimization;test functions for optimization;meta-optimization;derivative-free optimization;local search;multi-objective optimization;machine learning;mathematics;continuous optimization;mathematical economics;vector optimization;particle swarm optimization;random optimization;3-opt;metaheuristic	AI	27.076657499633303	-2.8872618617306034	165715
c2e42c797f6a163963d87f814f26b2adb8ca34bd	a genetic algorithm based approach for the uncapacitated continuous location-allocation problem	ga heuristic;location;continuous space;genetic algorithm;h social sciences	A GA-based approach is introduced to address the continuous location–allocation problem. Selection and removal procedures based on groups of chromosomes instead of individual chromosomes are put forward and specific crossover and mutation operators that rely on the impact of the genes are proposed. A new operator that injects once in a while new chromosomes into the population is also introduced. This provides diversity within the search and attempts to avoid early convergence. This approach is tested on existing data sets using several runs to evaluate the robustness of the proposed GA approach.	genetic algorithm;location-allocation	Said Salhi;M. D. H. Gamal	2003	Annals OR	10.1023/A:1026131531250	mathematical optimization;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;location	Robotics	25.539818154279423	-3.3238468287134557	165926
4d9fd62f11e75e356064341bc67fbbf77d6b1777	a diversity-guided heuristic-based genetic algorithm for triangulation of bayesian networks	belief networks;heuristics bayesian networks triangulation genetic algorithm;stagnation;representative benchmarks;population diversity;bayesian network;swarm intelligence;convergence;search procedure;heuristic programming;robustness diversity guided heuristic based genetic algorithm triangulation bayesian networks optimization dhga mutation operation population diversity stagnation convergence search procedure representative benchmarks;bayesian methods;diversity guided heuristic based genetic algorithm;optimization problem;mutation operation;genetic algorithm;robustness;genetic algorithms;optimization;search problems;heuristics;triangulation;search problems belief networks genetic algorithms heuristic programming;dhga;bayesian networks	For the optimization problem about triangulation of Bayesian networks, a novel genetic algorithm, DHGA, is proposed in this paper. DHGA employs a heuristic-based mutation operation. Moreover, it uses population diversity to identify stagnation and convergence as well as to guide the search procedure. Experiments on representative benchmarks show that DHGA posses better performance and robustness than other swarm intelligence methods.	bayesian network;experiment;genetic algorithm;heuristic (computer science);mathematical optimization;optimization problem;swarm intelligence	Xuchu Dong;Haihong Yu;Dantong Ouyang;Yuxin Ye;Yonggang Zhang	2010	The 6th International Conference on Networked Computing and Advanced Information Management		mathematical optimization;genetic algorithm;swarm intelligence;computer science;artificial intelligence;machine learning;bayesian network	Robotics	25.89271230775564	-2.408810654402175	166005
b5fcfccf31ab2fc32789c48ac81c45c0ec2cc6c2	a novel image encryption based on lorenz equation, gingerbreadman chaotic map and s8 permutation		Internet is used as the main source of communication throughout the world. However due to public nature of internet data are always exposed to different types of attacks. To address this issue many researchers are working in this area and proposing data encryption techniques. Recently a new substitution box has been proposed for image encryption using many interesting properties like gingerbread-man chaotic map and S8 permutation. But there are certain weaknesses in aforesaid technique which does not provide sufficient security. To resolve the security issue an enhanced version of existing technique is proposed in this paper. Lorenz chaotic map based confusion and diffusion processes in existing technique are employed. Lorenz map is used to remove strong correlation among the plain text image pixels. In diffusion stage a random matrix is generated through lorenz chaotic map and XORed with shuffled image. It the end, existing gingerbread-man chaotic map based S-box is applied to extract the final cipher text image. The proposed enhanced scheme is analysed by statistical analysis, key space analysis, information entropy analysis and differential analysis. In order to ensure the robustness and higher security of proposed scheme, results via Number of Pixel Rate Change (NPRC)and Unified Average Change Intensity (UACI) tests are also validated. 9	ascii art;chaos theory;cipher;ciphertext;confusion and diffusion;encryption;entropy (information theory);exclusive or;internet;key space (cryptography);lorenz system;pixel;random permutation;s-box	Fadia Ali Khan;Jameel Ahmed;Jan Sher Khan;Jawad Ahmad;Muazzam A. Khan	2017	Journal of Intelligent and Fuzzy Systems	10.3233/JIFS-17656		ML	38.40076253640664	-8.798421265835646	166072
1a99701dc2897232f9d7ca52f05f8316dd0ba0c2	micro genetic algorithm with spatial crossover and correction schemes for constrained three-dimensional reader network planning	spatial crossover;micro genetic algorithm;radio frequency identification rfid;correction scheme;rfid reader network planning	Due to the fast growing electronic commerce, the constrained three-dimensional reader network planning (C3DRNP) of the radio frequency identification (RFID) system for large warehouses is a subject that is worthy of study. A micro genetic algorithm (mGA) with novel spatial crossover and correction schemes is proposed to cope with this C3DRNP problem. The proposed algorithm is computationally efficient, which allows a frequent replacement of the RFID readers in the network to account for the fast turnaround time of the stored objects in the warehouse, and guarantees 100% tag coverage to avoid missing the records of the objects. The proposed algorithm is tested and compared with the existing methods such as the particle swarm optimization (PSO) method and the conventional GA (CGA) on solving several C3DRNP problems with various network sizes. The comparison results demonstrate the computational efficiency of the mGA and the effectiveness of the novel spatial crossover and correction schemes in searching the solution. © 2015 Elsevier Ltd. All rights reserved.	algorithmic efficiency;computation;e-commerce;genetic algorithm;mathematical optimization;particle swarm optimization;radio frequency;radio-frequency identification;tag cloud	Shin-Yeu Lin;Hsing-Fang Tsai	2016	Expert Syst. Appl.	10.1016/j.eswa.2015.08.046	artificial intelligence;data mining	AI	32.720447541090586	-1.812691603884781	166387
012ed20f02c470422f1e88c7ec0214ede7474b5b	when is a swarm necessary?	gaussian processes;gaussian landscape generators particle swarm optimization state diagrams;particle swarm optimizer;state space;state diagram;particle swarm optimisation gaussian processes;optimal algorithm;particle swarm optimisation	This paper compares the performance of particle swarm optimization (PSO) to other optimization algorithms over a continuum of problems. This approach is inspired by state diagrams used in physics. The state space is spanned by the problem parameters, and phases of the diagram are regions where a particular algorithm is more effective. These problems are created by landscape generators. In this report, we generate state diagrams for four optimization algorithms, including PSO, and two types of landscape. The stability of the state diagrams is also tested by varying the number of function evaluations, number of particles (for PSO), and number of dimensions.	algorithm;amoeba;biological system;cooperative mimo;gradient descent;mathematical optimization;maxima and minima;particle swarm optimization;phase-shift oscillator;problem domain;random search;state diagram;state space;triune continuum paradigm;visual guide	Toby J. Richer;Tim M. Blackwell	2006	2006 IEEE International Conference on Evolutionary Computation	10.1109/CEC.2006.1688482	mathematical optimization;multi-swarm optimization;combinatorics;state diagram;computer science;state space;machine learning;gaussian process;mathematics;particle swarm optimization;metaheuristic;statistics	Robotics	28.625393506218984	-8.630894701474501	166578
6b817e90e0bbe56edf27b488ddef220772262bb2	fir digital filters design based on quantum-behaved particle swarm optimization	quantum behaved particle swarm optimization;stochastic search technique;fir digital filter;particle swarm optimizer;stochastic processes;finite impulse response filter digital filters particle swarm optimization design optimization genetic algorithms convergence sun algorithm design and analysis frequency high performance computing;stochastic processes fir filters particle swarm optimisation quantum computing search problems;fir digital filter design;multiparameter optimization;genetic algorithm;search problems;fir filters;quantum computing;optimal algorithm;particle swarm optimisation;stochastic search technique fir digital filter design quantum behaved particle swarm optimization multiparameter optimization qpso;qpso;parameter optimization;stochastic search	FIR digital filters design involves multi-parameter optimization, on which the existing optimization algorithm doesn't work efficiently. This paper focuses on employing the proposed quantum-behaved particle swarm optimization (QPSO) to design FIR digital filters. QPSO is a global stochastic searching technique that can find out the global optima of the problem more rapidly than original PSO. After describing the origin and development of QPSO, we present how to use it in FIR digital filters design. It has been demonstrated by experiment results that QPSO outperforms the PSO and genetic algorithm (GA) for the problem	digital filter;finite impulse response;genetic algorithm;mathematical optimization;particle swarm optimization;program optimization;quantum;software release life cycle	Wei Fang;Jun Sun;Wenbo Xu;Jing Liu	2006	First International Conference on Innovative Computing, Information and Control - Volume I (ICICIC'06)	10.1109/ICICIC.2006.77	stochastic process;mathematical optimization;multi-swarm optimization;genetic algorithm;computer science;machine learning;finite impulse response;control theory;mathematics;quantum computer;statistics	EDA	28.30482335369961	-6.149530633976966	166594
7d34676e26c03495e53f50c50fd4314ea656edb4	genetic programming using the best individuals of genealogies for maintaining population diversity	standards;genealogical elite individuals evolutionary optimization method tree structural program generation population diversity gpbig method genetic programming using the best individuals of genealogies genealogy concept;genealogy genetic programming evolutionary computation diversity;genetic programming;statistics;genetic algorithms;search problems;sociology statistics search problems standards genetic programming next generation networking;next generation networking;sociology	Genetic Programming (GP) is an evolutionary optimization method for generating tree structural programs. It is important to maintain the population diversity for preventing GP search from falling into local optima. For this purpose, we propose a new method which introduces a concept of genealogy into the population. We call the method Genetic Programming using the Best Individuals of Genealogies (GPBIG). Information on genealogy is assigned to each individual, and the best-so-far individuals in respective genealogies are preserved as the genealogical elite individuals. The population is reconstituted every generation by selecting the individuals from the pool of the genealogical elite individuals. In addition, the search property shifts from global to local search gradually by extinguishing unnecessary genealogies. We examined the effectiveness of our method by comparing with the standard GP in search performance in three kinds of benchmark problems.	benchmark (computing);genetic programming;local optimum;local search (optimization);mathematical optimization;premature convergence;simplified perturbations models;the offspring	Akira Hara;Takuya Mototsuka;Jun-ichi Kushida;Tetsuyuki Takahama	2015	2015 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/SMC.2015.470	genetic programming;genetic algorithm;computer science;bioinformatics;artificial intelligence;machine learning;genetic representation;statistics	Robotics	27.628731947517654	-6.0312190710068805	166664
5cad12693961f05d1321b9636b0f10dc72f267a1	the k-coloring fitness landscape	fitness landscape;color space;time series;local structure;graph coloring problem;time series analysis;k coloring;local search;distance;distribution of solutions	This paper deals with the fitness landscape analysis of the k-coloring problem. We study several standard instances extracted from the second DIMACS benchmark. Statistical indicators are used to investigate both global and local structure of fitness landscapes. An approximative distance on the k-coloring space is proposed to perform these statistical measures. Local search operator trajectories on various landscapes are then studied using the time series analysis. Results are used to better understand the behavior of metaheuristics based on local search when dealing with the graph coloring problem.	approximation algorithm;benchmark (computing);cluster analysis;fitness function;graph coloring;graph partition;jenkins;local search (constraint satisfaction);local search (optimization);metaheuristic;polynomial;thinking outside the box;time series	Hend Bouziri;Khaled Mellouli;El-Ghazali Talbi	2011	J. Comb. Optim.	10.1007/s10878-009-9249-2	mathematical optimization;combinatorics;machine learning;time series;mathematics;fitness approximation	AI	25.66532747124278	-0.4680051058631715	166953
a6b26d7961ba2678b1c772700da02ec1f723c89e	boosting indicator-based selection operators for evolutionary multiobjective optimization algorithms	optimisation evolutionary computation;optimisation;convergence;evolutionary computation;training;evolutionary multiobjective optimization;optimization problem;quality indicator;evolutionary multiobjective optimization algorithms;optimization problem boosting indicator based selection operator evolutionary multiobjective optimization algorithm dominance ranking quality indicator convergence velocity;boosting;quality indicators;boosting evolutionary multiobjective optimization algorithms quality indicators;aggregates;genetic algorithm;robustness;genetic algorithms;optimization;boosting training convergence optimization aggregates robustness genetic algorithms	Various evolutionary multiobjective optimization algorithms (EMOAs) have adopted indicator-based selection operators that augment or replace dominance ranking with quality indicators. A quality indicator measures the goodness of each solution candidate. Many quality indicators have been proposed with the intention to capture different preferences in optimization. Therefore, indicator-based selection operators tend to have biased selection pressures that evolve solution candidates toward particular regions in the objective space. An open question is whether a set of existing indicator based selection operators can create a single operator that outperforms those existing ones. To address this question, this paper studies a method to aggregate (or boost) existing indicator-based selection operators. Experimental results show that a boosted selection operator outperforms exiting ones in optimality, diversity and convergence velocity. It also exhibits robustness against different characteristics in different optimization problems and yields stable performance to solve them.	aggregate data;boosting (machine learning);evolutionary algorithm;evolutionary computation;mathematical optimization;multi-objective optimization;operator overloading;velocity (software development)	Dung H. Phan;Junichi Suzuki	2011	2011 IEEE 23rd International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2011.49	mathematical optimization;genetic algorithm;computer science;machine learning;pattern recognition;mathematics;evolutionary computation	DB	25.018418055878232	-3.776077119076972	166970
adb199cb204cd5ca9d2dc5effb0711d1956cb1bf	optimization of convolutional neural network using microcanonical annealing algorithm		Convolutional neural network (CNN) is one of the most prominent architectures and algorithm in Deep Learning. It shows a remarkable improvement in the recognition and classification of objects. This method has also been proven to be very effective in a variety of computer vision and machine learning. As in other deep learning, however, training this approach is interesting yet challenging. Recently, some metaheuristic algorithms have been used to optimize CNN using Genetic Algorithm, Particle Swarm Optimization, Simulated Annealing and Harmony Search. In this paper, another type of metaheuristic algorithms with different strategy has been proposed, i.e. Microcanonical Annealing to optimize Convolutional Neural Network. The performance of the proposed method is tested using the MNIST and CIFAR-10 datasets. Although experiment results of MNIST dataset indicate the increase in computation time (1.02x–1.38x), nevertheless this proposed method can considerably enhance the performance of the original CNN (up to 4.60%). On the CIFAR10 dataset, currently, state of the art is 96.53% using fractional pooling, while this proposed method achieves 99.14%.	artificial neural network;benchmark (computing);computation;computer vision;convolutional neural network;deep learning;genetic algorithm;graphics processing unit;harmony search;imagenet;iteration;keras;mnist database;machine learning;metaheuristic;multi media interface;particle swarm optimization;simulated annealing;tensorflow;theano (software);time complexity;torch	Vina Ayumi;L. M. Rasdi Rere;Mohamad Ivan Fanany;Aniati Murni Arymurthy	2016	2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)		annealing;simulated annealing;computer science;artificial intelligence;theoretical computer science;machine learning;pattern recognition;kinetic energy;deep learning;convolution	AI	31.423973567875034	-8.6257998727627	166979
0674d1754fae77eb2ba9fdfc31acd65ae8bd97a9	an evolutionary approach to contrast compensation for dichromat users		In this paper, we are focusing on web accessibility, more precisely on improving web accessibility for Color Vision Deficiency (CVD) users. The contrast optimization problem for dichromat users can be modeled as a mono objective function which at minimum provides a suitable solution to the problem. The function aims to compensate the loss and maintains simultaneously a minimum change in the original color. The CMA-ES method is used to minimize the function. Experiments were conducted on real and artificial data in order to assess the approach efficiency for different set of parameters. The results showed that it is likely that the method performs better when the loss is important. The approach produces satisfying results on both real and artificial data for the set of tested parameters.		Alina Mereuta;Sebastien Aupetit;Nicolas Monmarché;Mohamed Slimane	2013		10.1007/978-3-319-11683-9_10	machine learning;color vision;artificial intelligence;cma-es;web accessibility;computer science;dichromacy;optimization problem	NLP	30.557559558336727	-5.99321461680596	166992
6c408cf66c98c9050f0a2de4574e348efb314141	a hopfield neural network based algorithm for haplotype assembly from low-quality data	minimum error correction model hopfield neural network hnhap haplotype assembly problem low quality data single nucleotide polymorphism fragments snp fragments combinatorial optimization problem;optimisation bioinformatics combinatorial mathematics error correction genetics hopfield neural nets;assembly neurons hopfield neural networks error analysis optimization modeling biological cells	The objective of the haplotype assembly problem is to conclude a pair of haplotypes from a set of aligned single nucleotide polymorphism (SNP) fragments from a single individual. Errors in the SNP fragments, which are inevitable in the real-world application, severely increase the difficulty of the problem. As a result, most methods could not get accurate haplotypes on the data with high error rate. In this paper, we introduce a Hopfield neural network based method, named HNHap, to solve the haplotype assembly problem. Hopfield neural network is a very promising and effective approach to solve the combinatorial optimization problem. The stochastic optimal competitive Hopfield network model that has the mechanism to escape from the local optimum is a great improvement for the original model. Thus we map the haplotype assembly problem onto the stochastic optimal competitive Hopfield network model, in which a group of neurons correspond to an SNP fragment and the states of neurons denote the classification of the fragment. We also design a proper energy function based on the minimum error correction model for the haplotype assembly problem. We compare HNHap with other algorithms and the experiment results show that HNHap is an effective method to solve the haplotype assembly problem, especially on data with high error rate.	algorithm;artificial neural network;combinatorial optimization;effective method;error correction model;hopfield network;local optimum;mathematical optimization;network model;optimization problem;personalization;serial digital video out	Xiao Chen;Qinke Peng;LiBin Han;Xiao Wang	2014	2014 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2014.6889588	computer science;bioinformatics;theoretical computer science;machine learning	ML	27.537989496503943	-9.613986289289379	167086
3d4c4acf2d69e4dd474168354437ce1f77009d10	cooperative co-evolutionary algorithm for dynamic multi-objective optimization based on environmental variable grouping		This paper presents a cooperative co-evolutionary dynamic multi-objective optimization algorithm, i.e., DNSGAII-CO for solving DMOPs based on environmental variable grouping. In this algorithm, a new method of grouping decision variables is first presented, in which all the decision variables are divided into two subcomponents according to whether they are interrelated with or without environment parameters. Then, when cooperatively optimizing the two subcomponents by using two populations, two prediction methods, i.e., differential prediction and Cauchy mutation, are employed to initialize them, respectively. The proposed algorithm is applied to a benchmark DMOPs, and compared with two state-of-the-art algorithms. The experimental results demonstrate that the proposed algorithm outperforms the compared algorithms in terms of convergence and distribution.	environment variable;evolutionary algorithm;multi-objective optimization;xslt/muenchian grouping	Biao Xu;Yong Zhang;Dun-Wei Gong;Miao Rong	2016		10.1007/978-3-319-41000-5_56	computer science;mathematical optimization;machine learning;cauchy distribution;artificial intelligence;multi-objective optimization;environment variable;evolutionary algorithm;convergence (routing)	EDA	25.827192172146624	-4.425096291964807	167146
c8eb14945413dbe14beff4c7fd4ed6faca6016d0	shortest component path generation of c2-style architecture using improved a* algorithm	software architecture	There are always more than one shortest paths between two components in software architecture, and in the application of path selection with additional constraints, several optimal or near optimal paths are desired. Traditional A algorithm has been successfully used in software testing activities such as finding the shortest path, selecting test suites and test suites prioritization. Little work has been specifically targeted towards the shortest component path of software architecture applications. In this paper, we propose an improved A algorithm, and combine with an example to explain the algorithm solving process. Finally, we implement the A algorithm and the improved A algorithm, and the results are compared. It is shown that the shortest component path using improved A algorithm is completely feasible and effective.	a* search algorithm;inscriptiones graecae;shortest path problem;simulation;software architecture;software testing;test case	Lijun Lun;Lin Zhang;Xin Chi;Hui Xu	2014	JSW		private network-to-network interface;software architecture;online algorithm;mathematical optimization;suurballe's algorithm;canadian traveller problem;widest path problem;constrained shortest path first;longest path problem;floyd–warshall algorithm;pathfinding;machine learning;yen's algorithm;johnson's algorithm;shortest path problem;k shortest path routing;shortest path faster algorithm	SE	24.618795032132724	2.9240896560234595	167219
59559d0ea60e71e626e7bff3c2b119c78536c378	stable gait optimization for small-sized humanoid robot using cfo		This paper proposes a new way to optimize the gait design for human robots that allows stable stepping with preset foot-lifting magnitude. The novel Central Force Optimization (CFO) algorithm is used to optimize the gait parameters to help humanoid robot walk steadily. The efficiency of the proposed method is compared with the GA-Genetic Algorithm, PSO-Particle Swarm Optimization and improved differential evolution algorithm (MDE-Modified Differential Evolution). The simulated and experimental results applied on the small-sized humanoid robot show that the newly proposed algorithm offers an efficient and stable gait for humanoid robots with accurate foot-lifting magnitude.		Tran Thien Huan;Khuu Bach Thy;Nguyen Ho Hieu Trung;Ho Pham Huy Anh	2018	2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)	10.1109/ICARCV.2018.8581188	differential evolution;control theory;swarm behaviour;humanoid robot;gait;computer science;stable gait;central force	Robotics	30.26728345140707	-4.163954829301508	167354
90335c21c40e7dc69515e1a5c0f3e3a87e355b32	mesh partitioning: a multilevel ant-colony-optimization algorithm	finite element methods;optimisation;evolutionary computation;parallel algorithm;concurrent computing;ant colony optimization;mesh partitioning;information science;application software;optimization technique;ant colony;maco algorithm mesh partitioning multilevel ant colony optimization algorithm nature inspired metaheuristic metaheuristic search technique finite element methods fe methods parallel algorithm;multilevel algorithm;optimization problem;network topology;iterative methods;maco algorithm;metaheuristic search technique;partitioning algorithms concurrent computing optimization methods iterative methods ant colony optimization network topology costs information science application software evolutionary computation;problem solving evolutionary computation optimisation mesh generation search problems parallel algorithms;multilevel ant colony optimization algorithm;fe methods;search problems;mesh generation;nature inspired metaheuristic;ant colony optimization algorithm;problem solving;partitioning algorithms;optimization methods;parallel algorithms	Mesh partitioning is an important problem that has extensive applications in many areas. Multilevel algorithms are a successful class of optimization techniques which addresses the mesh partitioning problem. In this paper we present an enhancement of the technique that uses nature inspired metaheuristic to achieve higher quality partitions. We apply and study a multilevel ant-colony (MACO) optimization, which is a relatively new metaheuristic search technique for solving optimization problems. The MACO algorithm performed very well and is superior to classical kMETIS and Chaco algorithms. Furthermore, it is even comparable to combined evolutionary/multilevel scheme used in JOSTLE evolutionary algorithm. Our MACO algorithm returned also some solutions that are better then currently available solutions in the Graph Partitioning Archive.	ant colony optimization algorithms;apache ant (another neat tool);archive;binary space partitioning;combinatorial optimization;daemon (computing);domain decomposition methods;evaporation;evolutionary algorithm;experiment;graph partition;horner's method;kernighan–lin algorithm;load balancing (computing);mathematical optimization;metaheuristic;minimum cut;partition problem;program optimization;vertex (graph theory);way to go	Peter Korosec;Jurij Silc;Borut Robic	2003		10.1109/IPDPS.2003.1213278	mathematical optimization;parallel computing;concurrent computing;information science;computer science;theoretical computer science;machine learning;parallel algorithm;evolutionary computation	EDA	25.794988991227257	-1.6045519239856325	167417
07da472d366ec16bf29b9188a96ed2e178e70a4c	efficiently packing circles into a larger containing circle	circle packing;surface deformation;power optimization;global optimization;energy landscape	The circles packing problem consists in placing a set of circles into a larger containing circle without overlap. The objective is to determine the smallest radius of the containing circle as well as the coordinates of the center of each given circle. Lacking powerful optimization method is the key obstacle to solve this problem. A novel heuristic global optimization method, energy landscape paving (ELP) which combines core ideas from energy surface deformation and taboo search, is introduced. By giving some critical revisions to the ELP method and incorporating new configuration update strategy into it, an improved energy landscape paving (IELP) algorithm is put forward for the circles packing problem. The effectiveness of the algorithm is demonstrated through a set of typical instances taken from the literature.		Jingfa Liu;Yali Wang;Jinji Pan	2009		10.1007/978-3-642-11842-5_34	mathematical optimization;packing problems;circle packing;energy landscape;power optimization;global optimization	Robotics	26.84999625655132	-0.8729795814895798	167462
55e64d9711c5197faa8914eb729e4c6a1a431bdd	a clustering based niching ea for multimodal search spaces	search space;evolutionary algo rithm	We propose a new niching method for Evolutionary Algorithms which is able to identify and track global and local optima in a multimodal search space. To prevent the loss of diversity we replace the global selection pressure within a single population by local selection of a multi-population strategy. The sub-populations representing species specialized on niches are dynamically identified using standard clustering algorithms on a primordial population. With this multi-population strategy we are able to preserve diversity within the population and to identify global/local optima directly without further post-processing.	cluster analysis;evolutionary algorithm;local optimum;multimodal interaction;population;spaces;video post-processing	Felix Streichert;Gunnar Stein;Holger Ulmer;Andreas Zell	2003		10.1007/978-3-540-24621-3_24	genetic algorithm;biological classification;computer science;artificial intelligence;local search;machine learning;evolutionary algorithm;cluster analysis;algorithm	ML	26.5098130315324	-5.433852410616509	167468
81bd7a1de088f8f9b1f3c0b7332322bd45447d01	elitensga-iii: an improved evolutionary many-objective optimization algorithm	evolutionary computation;elitensga iii evolutionary computation large dimension many objective optimization reference point based computation non dominated sorting nsga iii;elite population preserving elitensga iii evolutionary many objective optimization algorithm population based algorithms single objective optimization problems multi objective optimization problems selection pressure pareto front reference point based nsga ii;pareto optimisation evolutionary computation	Evolutionary algorithms are the most studied and successful population-based algorithms for solving single- and multi-objective optimization problems. However, many studies have shown that these algorithms fail to perform well when handling many-objective (more than three objectives) problems due to the loss of selection pressure to pull the population towards the Pareto front. As a result, there has been a number of efforts towards developing evolutionary algorithms that can successfully handle many-objective optimization problems without deteriorating the effect of evolutionary operators. A reference-point based NSGA-II (NSGA-III) is one such algorithm designed to deal with many-objective problems, where the diversity of the solution is guided by a number of well-spread reference points. However, NSGA-III still has difficulty preserving elite population as new solutions are generated. In this paper, we propose an improved NSGA-III algorithm, called EliteNSGA-III to improve the diversity and accuracy of the NSGA-III algorithm. EliteNSGA-III algorithm maintains an elite population archive to preserve previously generated elite solutions that would probably be eliminated by NSGA-III's selection procedure. The proposed EliteNSGA-III algorithm is applied to II many-objective test problems with three to I5 objectives. Experimental results show that the proposed EliteNSGA-III algorithm outperforms the NSGA-III algorithm in terms of diversity and accuracy of the obtained solutions, especially for test problems with higher objectives.	archive;evolutionary algorithm;mathematical optimization;multi-objective optimization;pareto efficiency	Amin Ibrahim;Shahryar Rahnamayan;Miguel Vargas Martin;Kalyanmoy Deb	2016	2016 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2016.7743895	evolutionary programming;mathematical optimization;genetic algorithm;interactive evolutionary computation;human-based evolutionary computation;cultural algorithm;computer science;artificial intelligence;multi-objective optimization;machine learning;evolutionary algorithm;mathematics;imperialist competitive algorithm;algorithm;evolutionary computation;population-based incremental learning	AI	25.256354706135525	-3.597053142711048	167703
5b21af719381fe95e430fdf8fcf8758043b1364e	a method of genetic algorithm optimized extended kalman particle filter for nonlinear system state estimation	nonlinear filters;resampling scheme;nonlinear tracking problem;target tracking genetic algorithms kalman filters nonlinear filters nonlinear systems state estimation;genetic particle filter;re sampling process extended kalman particle filter genetic algorithm particle deprivation;kalman filters;genetic algorithms optimization methods kalman filters particle filters nonlinear systems state estimation filtering algorithms target tracking particle tracking genetic mutations;nonlinear system state estimation;state estimation;suboptimal filtering algorithm;genetics;nonlinear systems;genetic particle filter genetic algorithm extended kalman particle filter suboptimal filtering algorithm nonlinear system state estimation nonlinear tracking problem resampling scheme target tracking mutation system;target tracking mutation system;particle filter;heuristic algorithms;particle deprivation;mathematical model;genetic algorithm;genetic algorithms;particle filters;target tracking;nonlinear system;extended kalman particle filter;signal processing algorithms;re sampling process	A new method of genetic algorithm (GA) optimized the extended kalman particle filter (EKPF) is proposed in this paper. The algorithm of extended kalman particle filter is a suboptimal filtering algorithm with good performance for target tracking and non-linear tracking problem. In the implementation of the extended kalman particle filter, a re-sampling scheme is used to decrease the degeneracy phenomenon and improve estimation performance. However, the target tracking mutation system status has poorer filtering precision. In order to overcome the problem of the extended kalman particle filter, a novel filtering method called the genetic particle filter (GA-EKPF) is proposed in this paper. The genetic mechanism provides an important guiding ideology to solve the deprivation of particles. The proposed algorithm overcomes the deprivation of particles and enhances the filtering precision. Experimental results show that the performance of modified extended kalman particle filter superiors to the standard particle filter (PF) and some other modified PFs.	degeneracy (graph theory);genetic algorithm;kalman filter;nonlinear system;particle filter;sampling (signal processing);simulation;software release life cycle	Shuying Yang;Wenjuan Huang;Qin Ma	2009	2009 Fifth International Conference on Natural Computation	10.1109/ICNC.2009.600	control engineering;monte carlo localization;mathematical optimization;invariant extended kalman filter;ensemble kalman filter;kernel adaptive filter;auxiliary particle filter;fast kalman filter;filtering problem;control theory;mathematics;extended kalman filter;moving horizon estimation;filter design;alpha beta filter;simultaneous localization and mapping	Robotics	31.82588975821522	-5.284836373740712	167721
4d25f3ab30af3be68f03d681820578777a625c80	robust parameter design optimization using kriging, rbf and rbfnn with gradient-based and evolutionary optimization techniques	robust parameter design rpd;surrogate models;multi objective optimization genetic algorithms moga;kriging;dual response surface	The dual response surface methodology is one of the most commonly used approaches in robust parameter design to simultaneously optimize the mean value and keep the variance minimum. The commonly used meta-model is the quadratic polynomial regression. For highly nonlinear input/output relationship, the accuracy of the fitted model is limited. Many researchers recommended to use more complicated surrogate models. In this study, three surrogate models will replace the second order polynomial regression, namely, ordinary Kriging, radial basis function approximation (RBF) and radial basis function artificial neural network (RBFNN). The results show that the three surrogate model present superior accuracy in comparison with the quadratic polynomial regression.#R##N##R##N#The mean squared error (MSE) approach is widely used to link the mean and variance in one cost function. In this study, a new approach has been proposed using multi-objective optimization. The new approach has two main advantages over the classical method. First, the conflicting nature of the two objectives can be efficiently handled. Second, the decision maker will have a set of Pareto-front design points to select from.	evolutionary algorithm;gradient;kriging;mathematical optimization;radial basis function	Khairy Elsayed;Chris Lacor	2014	Applied Mathematics and Computation	10.1016/j.amc.2014.03.082	econometrics;mathematical optimization;machine learning;surrogate model;mathematics;kriging;statistics	EDA	31.872591614788988	-6.983814563879684	167894
280f5713b7414eb2edbc4bf2aa3904628a7c4dc8	an iterative approach for makespan-minimized multi-agent path planning in discrete space	path planning;drntu engineering computer science and engineering;journal article;guided local search;multiple agents	Makespan-minimized multi-agent path planning (MAPP) seeks to minimize the time taken by the slowest of n agents to reach its destination and this is essentially a minimax-constrained optimization problem. In this work, an iterative max-min improvement (IMMI) algorithm is proposed to approximate the optimal solution of the makespan-minimized MAPP problem. At each iteration, a linear maximization problem is solved using a simplex method followed by a computationally hard MAPP minimization problem that is solved using a local search approach. To keep the local search from being trapped in an unfeasible solution, a Guided Local Search technique is proposed. Comparative results with other MAPP algorithms suggest that the proposed IMMI algorithm strikes a good tradeoff between the ability to find feasible solutions that can be traversed quickly and the computational time incurred in determining these paths.	anytime algorithm;approximation algorithm;computation;computational complexity theory;constrained optimization;constraint (mathematics);entropy maximization;expectation–maximization algorithm;generalized least squares;guided local search;iteration;iterative method;local search (constraint satisfaction);local search (optimization);makespan;mathematical optimization;maxima and minima;minimax;motion planning;multi-agent system;online and offline;optimization problem;simplex algorithm;time complexity	Wenjie Wang;Wooi-Boon Goh	2014	Autonomous Agents and Multi-Agent Systems	10.1007/s10458-014-9259-z	mathematical optimization;computer science;artificial intelligence;motion planning;guided local search	AI	25.565587793340576	2.0441353928922017	167906
168274000aeb06eb3617b5ee663ee62b3e5f2a37	evolutionary canonical particle swarm optimizer - a proposal of meta-optimization in model selection	canonical particle swarm optimization;model selection;swarm intelligence;evolutionary particle swarm optimization;temporally cumulative fitness;benchmark problem;optimization problem;particle swarm optimizer;cumulant;real coded genetic algorithm;fitness function;evolutionary computing	We proposed Evolutionary Particle Swarm Optimization (EPSO) which provides a new paradigm of meta-optimization for model selection in swarm intelligence. In this paper, we extend the technique of online evolutionary computation of EPSO to Canonical Particle Swarm Optimizer (CPSO), and propose Evolutionary Canonical Particle Swarm Optimizer (ECPSO) for optimizing CPSO. In order to effectually evaluate the performance of CPSO, a temporally cumulative fitness function of the best particle is adopted in ECPSO as the behavioral representative for entire swarm. Applications of the proposed method to a suite of 5-dimensional benchmark problems well demonstrate the effectiveness. Our experimental results clearly indicate that (1) the proper parameter sets in CPSO for solving various optimization problems are not unique; (2) the values of parameters in them are quite different from that of the original CPSO; (3) the search performance of the optimized CPSO is superior to that of the original CPSO, and to that of RGA/E except for the result to the Rastrigin's benchmark problem.	mathematical optimization;meta-optimization;model selection;swarm	Hong Zhang;Masumi Ishikawa	2008		10.1007/978-3-540-87536-9_49	optimization problem;mathematical optimization;multi-swarm optimization;swarm intelligence;computer science;artificial intelligence;machine learning;mathematics;particle swarm optimization;fitness function;model selection;statistics;cumulant	ML	24.836310054496256	-4.54727302561488	167947
c6a9f82e61856f51e874e4ff9faf44b0fb61f423	an hybrid neural/genetic approach to continuous multi-objective optimization problems	multiobjective programming;optimum pareto;densite probabilite;programmation multiobjectif;optimisation;evaluation fonction;mensonge;probability density;optimizacion;sorting;mentira;evolutionary multi objective optimization;search space;pareto front;tria;probabilistic approach;algoritmo genetico;genetics;lying;densidad probabilidad;probabilistic model;estimation of distribution algorithm;hierarchical classification;function evaluation;non dominated sorting genetic algorithm;enfoque probabilista;approche probabiliste;triage;philosophy;algorithme genetique;classification hierarchique;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;optimization;evolutionary algorithm;evolutionary process;filosofia;pareto optimum;clasificacion jerarquizada;philosophie;performance optimization;optimo pareto;multi objective optimization problem;programacion multiobjetivo	Evolutionary algorithms perform optimization using the information derived from a population of sample solution points. Recent developments in this field regard optimization as the evolutionary process of an explicit, prob- abilistic model of the search space. The algorithms derived on the basis of this new philosophy maintain every feature of the classic evolutionary algorithms, but are able to overcome some drawbacks. In this paper an evolutionary multi- objective optimization tool based on an estimation of distribution algorithm is proposed. It uses the ranking method of non-dominated sorting genetic algo- rithm-II and the Parzen estimator to approximate the probability density of solu- tions lying on the Pareto front. The proposed algorithm has been applied to dif- ferent types of test case problems and results show good performance of the overall optimization procedure in terms of the number of function evaluations.	multi-objective optimization;program optimization	Mario Costa;Edmondo A. Minisci;Eros Pasero	2003		10.1007/978-3-540-45216-4_6	statistical model;mathematical optimization;probability density function;genetic algorithm;estimation of distribution algorithm;lying;computer science;sorting;artificial intelligence;multi-objective optimization;machine learning;evolutionary algorithm;mathematics;continuous optimization;algorithm;metaheuristic;statistics;evolutionary computation	SE	28.09252705435648	0.9166744781719266	167982
4a267ff4008a5c230990daf8f83319b4d65d24a2	exploring divergence in soft robot evolution		Divergent search is a recent trend in evolutionary computation that does not reward proximity to the objective of the problem it tries to solve. Traditional evolutionary algorithms tend to converge to a single good solution, using a fitness proportional to the quality of the problem's solution, while divergent algorithms aim to counter convergence by avoiding selection pressure towards the ultimate objective. This paper explores how a recent divergent algorithm, surprise search, can affect the evolution of soft robot morphologies, comparing the performance and the structure of the evolved robots.	converge;evolutionary algorithm;evolutionary computation;robot	Daniele Gravina;Antonios Liapis;Georgios N. Yannakakis	2017		10.1145/3067695.3076072	evolutionary computation;artificial intelligence;genetic algorithm;mathematical optimization;machine learning;divergence;evolutionary algorithm;artificial life;computer science;robot;evolutionary robotics;convergence (routing)	AI	26.019337598804253	-7.526942847674637	167989
c40657317c55be34697a97a72a4817d5740b8b3c	reconfigurable hardware architecture of the spatial pooler for hierarchical temporal memory	xilinx virtex iv fpga fabric reconfigurable hardware architecture scalable spatial pooler architecture hierarchical temporal memory self learning hardware system spatio temporal task time based online learning algorithm;spatial pooler;neocortex hierarchical temporal memory htm cortical learning algorithm cla spatial pooler;hierarchical temporal memory htm;computer architecture microprocessors hardware field programmable gate arrays neurons architecture;unsupervised learning field programmable gate arrays memory architecture reconfigurable architectures;neocortex;cortical learning algorithm cla	Self-learning hardware systems, with high-degree of plasticity, are critical in performing spatio-temporal tasks in next-generation computing systems. To this end, hierarchical temporal memory (HTM) offers time-based online-learning algorithms that store and recall temporal and spatial patterns. One of the key building blocks in HTM is the spatial pooler. In this paper, we propose a reconfigurable and scalable spatial pooler architecture that is ported onto a Xilinx Virtex-IV FPGA fabric. The concept of synthetic synapses is proposed for dynamic interconnections. The spatial pooler architecture is verified for two different datasets, MNIST and EU numberplate font, with ≈ 91% and ≈ 90% accuracy respectively. Moreover, the proposed hardware model offers speed up of 4817X over the software realization. These results indicate that the proposed architecture can serve as a core to build the HTM in hardware and eventually as a standalone self-learning hardware system.	algorithm;dhrystone;field-programmable gate array;html;hierarchical temporal memory;mnist database;machine learning;scalability;speedup;virtex (fpga)	Abdullah M. Zyarah;Dhireesha Kudithipudi	2015	2015 28th IEEE International System-on-Chip Conference (SOCC)	10.1109/SOCC.2015.7406930	embedded system;parallel computing;real-time computing;computer science;theoretical computer science;operating system	EDA	38.51490585576657	-1.0002116947397335	167997
450abcd8bfda8231602c9f2db77b67190471979c	a hybrid evolutionary algorithm to quadratic three-dimensional assignment problem with local search for many-core graphics processors	optimal solution;assignment problem;premature convergence;difference operator;hybrid evolutionary algorithm;search space;three dimensional;stochastic optimization;adaptive management;graphics processors;quadratic assignment problem;evolutionary algorithm;local search	This paper concerns the quadratic three-dimensional assignment problem (Q3AP), an extension of the quadratic assignment problem (QAP), and proposes an efficient hybrid evolutionary algorithm combining stochastic optimization and local search with a number of crossover operators, a number of mutation operators and an auto-adaptation mechanism. Auto-adaptation manages the pool of evolutionary operators applying different operators in different computation phases to better explore the search space and to avoid premature convergence. Local search additionally optimizes populations of candidate solutions and accelerates evolutionary search. It uses a many-core graphics processor to optimize a number of solutions in parallel, which enables its incorporation into the evolutionary algorithm without excessive increases in the computation time. Experiments performed on benchmark Q3AP instances derived from the classic QAP instances proposed by Nugent et al. confirmed that the proposed algorithm is able to find optimal solutions to Q3AP in a reasonable time and outperforms best known results found in the literature.	assignment problem;evolutionary algorithm;local search (optimization)	Piotr Lipinski	2010		10.1007/978-3-642-15381-5_42	evolutionary programming;three-dimensional space;mathematical optimization;combinatorics;computer science;generalized assignment problem;local search;stochastic optimization;machine learning;evolutionary algorithm;mathematics;assignment problem;memetic algorithm;premature convergence;quadratic assignment problem;guided local search	Theory	24.851500421324882	-1.301040667760681	168006
20235f837c14b64192cd07acc2a033776cfb9a97	extending population-based incremental learning to continuous search spaces	learning algorithm;algoritmo busqueda;algorithm performance;search space;algorithme recherche;population based incremental learning;search algorithm;algorithme apprentissage;optimisation combinatoire;resolucion problema;resultado algoritmo;performance algorithme;algorithme evolutionniste;algoritmo evolucionista;evolutionary algorithm;combinatorial optimization;artificial evolution;algoritmo aprendizaje;problem solving;resolution probleme;optimizacion combinatoria	An alternative to Darwinian-like artiicial evolution is ooered by Population-Based Incremental Learning (PBIL): this algorithm memorizes the best past individuals and uses this memory as a distribution, to generate the next population from scratch. This paper extends PBIL from boolean to continuous search spaces. A Gaussian model is used for the distribution of the population. The center of this model is constructed as in boolean PBIL. Several ways of deening and adjusting the variance of the model are investigated. The approach is validated on several large-sized problems.	algorithm;population-based incremental learning;spaces	Michèle Sebag;Antoine Ducoulombier	1998		10.1007/BFb0056884	mathematical optimization;computer science;artificial intelligence;evolutionary algorithm;mathematics;algorithm;search algorithm	AI	26.753034549096856	1.4369201066861201	168059
7c0bddf6cdc10805a635b1f75988b9c42c0f9ada	on population size and neutrality: facilitating the evolution of evolvability	search space;population size;genotypic variation	The role of population size is investigated within a neutrality induced local optima free search space. Neutrality decouples genotypic variation in evolvability from fitness variation. Population diversity and neutrality work in conjunction to facilitate evolvability exploration whilst restraining its loss to drift, ultimately facilitating the evolution of evolvability. The characterising dynamics and implications are discussed.	local optimum;steady state;while	Richard Mark Downing	2007		10.1007/978-3-540-71605-1_17	population size	ML	25.588984058022067	-8.669058863717996	168237
d8c1141abcc5dad21d135316a788e08f94c3da2d	approximate reliability of multi-state two-terminal networks by stochastic analysis				Peican Zhu;Yangming Guo;Fabrizio Lombardi;Jie Han	2017	IET Networks	10.1049/iet-net.2017.0033	mathematical optimization;stochastic geometry models of wireless networks;stochastic process;computer science	ML	38.86352843832614	4.0839808859904165	168473
96c58d01232849ec6789cd193a10d9e1421c582c	an enhanced firefly algorithm with orthogonal centroid opposition-based learning		The firefly algorithm (FA) is one of the swarm intelligence algorithms for which opposition-based learning (OBL) is an efficient method for improving performance. In most of the existing OBL schemes, the opposite solution is calculated simultaneously for all dimensions of the original solution. However, the opposite solution does not always offer a better value in every dimension than the original solution. This paper develops a new scheme by utilizing the orthogonal experiment design method to select a subset of elements of the individual to be changed into opposite values by the centroid opposition, while the rest remain unchanged. Useful information about the original individual and its opposite can be found by this method. This new scheme is named orthogonal centroid opposition-based learning (OCOBL) and is incorporated into FA to obtain an orthogonal centroid opposition-based firefly algorithm (OCOFA). OCOFA is tested on the CEC's 2013 benchmark suite and compared with state-of-the-art FA variants. The experimental results demonstrate the effectiveness of OCOBL and an improved performance for the proposed OCOFA.	benchmark (computing);design of experiments;firefly algorithm;swarm intelligence	Lingyun Zhou;Lixin Ding;Yunwen Lei	2018	2018 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2018.8477696	machine learning;swarm intelligence;design of experiments;artificial intelligence;mathematical optimization;computer science;firefly algorithm;opposition (planets);centroid;convergence (routing);particle swarm optimization;benchmark (computing)	AI	26.51056867539859	-3.514153805005749	168658
d8538cc83d9aebe7fd52464894f7ada3e29ae843	probability models in global optimization		This paper reviews the interplay between global optimization and probability models, concentrating on a class of deterministic optimization algorithms that are motivated by probability models for the objective function. Some complexity results are described for the univariate and multivariate cases.	algorithm;global optimization;loss function;mathematical optimization;optimization problem;optimizing compiler	James M. Calvin	2016	Informatica, Lith. Acad. Sci.		mathematical optimization;random optimization;global optimization	Vision	30.978333974265322	1.5625622699610844	168969
854efa4be0847292fe1900b5aca304a3fb11df2c	probabilistic incremental program evolution	genetic program;programming language;population based incremental learning;stochastic program search;partially observable environments;genetic programming;probabilistic programming languages;probability distribution;doctoral thesis;probabilistic incremental program evolution;partial observation;stochastic programming;partially observable environments probabilistic incremental program evolution probabilistic programming languages stochastic program search population based incremental learning genetic programming	Probabilistic incremental program evolution (PIPE) is a novel technique for automatic program synthesis. We combine probability vector coding of program instructions, population-based incremental learning, and tree-coded programs like those used in some variants of genetic programming (GP). PIPE iteratively generates successive populations of functional programs according to an adaptive probability distribution over all possible programs. Each iteration, it uses the best program to refine the distribution. Thus, it stochastically generates better and better programs. Since distribution refinements depend only on the best program of the current population, PIPE can evaluate program populations efficiently when the goal is to discover a program with minimal runtime. We compare PIPE to GP on a function regression problem and the 6-bit parity problem. We also use PIPE to solve tasks in partially observable mazes, where the best programs have minimal runtime.	automatic programming;biological evolution;genetic programming;increment;iteration;parity bit;partially observable system;population;population-based incremental learning;program synthesis	Rafal Salustowicz;Jürgen Schmidhuber	1997	Evolutionary Computation	10.1162/evco.1997.5.2.123	stochastic programming;probability distribution;genetic programming;mathematical optimization;computer science;machine learning;mathematics;inductive programming;algorithm;statistics	PL	27.685059067628412	-8.971328185548058	169164
d9a56d5e857f84715cfed1bf02850624e9a732c8	multiple choice strategy based pso algorithm with chaotic decision making - a preliminary study		In this paper, it is proposed the utilization of chaotic pseudo random number generators based on six selected discrete chaotic maps to enhance the performance of newly proposed multiple choice strategy based PSO algorithm. This research represents a continuation of previous successful experiments with the fusion of the PSO algorithm and chaotic systems. The performance of proposed algorithm is tested on a set of four test functions. Obtained promising results are presented, discussed and compared against the basic PSO strategy with inertia weight.	algorithm;particle swarm optimization	Michal Pluhacek;Roman Senkerik;Ivan Zelinka	2013		10.1007/978-3-319-01854-6_3	mathematical optimization;artificial intelligence;machine learning;mathematics	ML	26.962895142959795	-3.2001624418301984	169487
f6553b93d346b66724230b6193ff74c61a921967	application of multi-zero artificial neural network to the design of an m-valued digital multiplier	multi zero neural networks;connection matrix;n bit analog input vector;many valued logics;multiplying circuits;n bit m valued digital vector;neural nets;nonlinear amplifier;multi zero artificial neural network;n bit m valued digital vector multi zero artificial neural network m valued digital multiplier m ary digital multiplier multi zero neural networks elementary analog arithmetic units feedback artificial neural system nonlinear amplifier input output response function polynomial function nonlinear feedback connection matrix n bit analog input vector;m valued digital multiplier;nonlinear feedback;polynomials;output feedback;input output;neural nets many valued logics multiplying circuits;artificial neural networks;neural system;artificial neural networks neurons neurofeedback digital systems voltage nonlinear equations resistors polynomials output feedback multivalued logic;response function;input output response function;m ary digital multiplier;digital systems;voltage;resistors;nonlinear equations;neurons;elementary analog arithmetic units;neurofeedback;feedback system;multivalued logic;polynomial function;feedback artificial neural system;artificial neural network;neural network	The multi-zero neural network is a feedback artificial neural system consisting of N neurons. Each neuron is a nonlinear amplifier with input-output response function equal to a polynomial function containing 2M+1 real zeros. A very unique property possessed by this nonlinear feedback system is that if the connection matrix is programmed correctly, any N-bit ANALOG input vector will always be converged to an N-bit M-valued DIGITAL vector at the output. This output will be locked-in in place (or it can be MEMORIZED) even when the input is	amplifier;artificial neural network;frequency response;neuron;nonlinear system;polynomial	Chia-Lun J. Hu	1991		10.1109/ISMVL.1991.130701	resistor;control engineering;input/output;electronic engineering;voltage;computer science;machine learning;control theory;neurofeedback;feedback;mathematics;artificial neural network;polynomial	ML	39.145500567859514	-3.728657333825825	169991
5d2bcbb916a10755147f2825733d4d2a1b018b4b	evolving players that use selective game-tree search with genetic programming	evaluation function;alpha beta search;genetic program;genetic programming;games;game tree search;board games	We present the application of genetic programming (GP) to evolving game-tree search in board games. Our work expands previous results in evolving board-state evaluation functions for multiple board games, now evolving a search-guiding evaluation function alongside it. Our system implements strongly typed GP trees, explicitly defined introns, and a selective directional crossover method.	evaluation function;genetic programming;tree traversal	Amit Benbassat;Moshe Sipper	2012		10.1145/2330784.2330894	genetic programming;games;simulation;computer science;artificial intelligence;machine learning;evaluation function;monte carlo tree search;alpha–beta pruning	AI	25.102970666459427	-9.100740748189192	170332
f991b5ffe96620bb268d8ead22fa9efd31e1f0e3	an improved particle swarm optimization algorithm based on simulated annealing	searching efficiency particle swarm optimization algorithm particle swarm based simulated annealing method annealing schedule cooling rate sa metropolis acceptance rule ipso b sa searching quality;optimization annealing convergence algorithm design and analysis schedules mathematical model cooling;acceptance rule particle swarm optimization population diversity anealing;simulated annealing particle swarm optimisation search problems	This paper proposes an improved particle swarm-based-simulated annealing method by combine simulate annealing algorithm and swarm particle optimization. An improved annealing schedule is introduced to enhance the performance of particle swarm optimization. The cooling rate is higher at the beginning than at the end of the search process. In this way, the algorithm can explore for solutions in more paths, increasing the probability that the global optima is found. At the same time, particle swarm-based-simulated annealing method introduces the SA metropolis acceptance rule. The metropolis determines whether to accept the new position or recalculate another candidate position according to the fitness function difference between the new and old positions. This enables the solution to jump out of local optimal value, and the vibration is decreased when the searching process is near the end. Experiment results and comparisons with the standard PSO and SA show that the IPSO-B-SA can effectively enhance the searching efficiency and greatly improve the searching quality.	algorithm;computer cooling;fitness function;ipso alliance;mathematical optimization;optimization problem;particle swarm optimization;phase-shift oscillator;simulated annealing;simulation	Huafen Yang;You Yang;Zuyuan Yang;Lihui Zhang	2014	2014 10th International Conference on Natural Computation (ICNC)	10.1109/ICNC.2014.6975891	mathematical optimization;multi-swarm optimization;parallel metaheuristic;artificial intelligence;machine learning;adaptive simulated annealing;metaheuristic	Robotics	28.112422418152715	-3.691452533360518	170525
5c31ad2e6e688ba64d02d39ffebc0adffdb240b8	analysis of reactive search optimisation techniques for the maximum clique problem and applications	inf 01 informatica	This thesis introduces analysis tools for improving the current state of the art of heuristics for the Maximum Clique (MC) problem. The analysis focusses on algorithmic building blocks, on their contribution in solving hard instances of the MC problem, and on the development of new tools for the visualisation of search landscapes. As a result of the analysis on the algorithmic building blocks, we re-engineer an existing Reactive Local Search heuristic for the Maximum Clique (RLS–MC). We propose implementation and algorithmic improvements over the original RLS–MC aimed at faster restarts and greater diversification. The newly designed algorithm (RLS–LTM) is one order of magnitude faster than the original RLS–MC on some benchmark instances; but the proposed algorithmic changes impact also on the dynamically adjusted tabu tenure, which grows wildly on some hard instances. A more in depth analysis of the search dynamics of RLS–MC and RLS–LTM reveals the reasons behind the tabu tenure explosion and sheds some new light on the reactive mechanism. We design and implement RLS–fast which cures the issues with the tabu tenure explosion in RLS–LTM while retaining the performance improvement over RLS–MC. Moreover, building on the knowledge gained from the analysis, we propose a new hyper-heuristic which defines the new state of the art, and a novel supervised clustering technique based on a clique-finding component.	algorithm;benchmark (computing);clique (graph theory);clique problem;cluster analysis;diversification (finance);heuristic (computer science);hyper-heuristic;mathematical optimization;recursive least squares filter;tabu search	Franco Mascia	2010	4OR	10.1007/s10288-011-0176-6	mathematical optimization;artificial intelligence;mathematics;algorithm	Web+IR	26.2007542104791	3.3620040191005334	170777
ef5bffce1b764fc7c50fde21f087acc169750a3e	truncated expected hypervolume improvement: exact computation and application	electronic mail;robust pid parameter tuning expected hypervolume improvement truncated normal distribution efficient global optimization;approximation algorithms;optimization gaussian distribution linear programming approximation algorithms computer science electronic mail algorithm design and analysis;pareto optimisation gaussian processes;linear programming;optimization;computer science;robust proportional integral derivative controller optimization truncated expected hypervolume improvement exact computation black box evaluations gaussian processes kriging infill criterion predictive mean variance multiobjective optimization hypervolume indicator pareto front approximation unbounded objective space objective function values multiobjective efficient global optimization a priori knowledge robust pid controller optimization;algorithm design and analysis;gaussian distribution	In optimization with expensive black box evaluations, the expected improvement algorithm (also called efficient global optimization) is a commonly applied method. It uses Gaussian Processes (or Kriging) to build a model of the objective function and uses the expected improvement as an infill criterion, taking into account both - predictive mean and variance. It has been generalized to multi-objective optimization using the expected hypervolume improvement, which measures the expected gain in the hypervolume indicator of a Pareto front approximation. However, this criterion assumes an unbounded objective space even if it is often known a-priori that the objective function values are within a prescribed range, e.g., lower bounded by zero. To take advantage of such a-priori knowledge, this paper introduces the truncated expected hypervolume improvement and a multiobjective efficient global optimization method that is based on it. In this paper it is shown how to compute the truncated expected hypervolume improvement exactly and efficiently. Then it is tested as an infill criterion in efficient global optimization. It is shown that it can effectively make use of a-priori knowledge and achieve better results in cases where such knowledge is given. The usefulness of the new approach is demonstrated in benchmark examples and applications from robust PID (proportional-integral-derivative) controller optimization. The empirical studies in this paper are confined to the bi-objective case.	approximation;benchmark (computing);black box;ego;evolutionary algorithm;gaussian process;global optimization;gradient;ieee congress on evolutionary computation;kriging;loss function;mathematical optimization;multi-objective optimization;optimization problem;pid;pareto efficiency;surrogate model	Kaifeng Yang;André H. Deutz;Zhiwei Yang;Thomas Bäck;Michael T. M. Emmerich	2016	2016 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2016.7744343	normal distribution;algorithm design;mathematical optimization;combinatorics;computer science;linear programming;machine learning;mathematics	DB	29.262075348467224	-9.671503441673048	170808
7134ef647d2742c07d473b878a35266d4ea2fcea	a modified roach infestation optimization	function problems cockroach infestation optimization social behaviours partial differential equation crossover and mutation methods;mathematical model dispersion sociology statistics optimization benchmark testing equations;multidimensional functions modified roach infestation optimization swarm intelligence algorithms mrio algorithm social cockroach behaviours partial differential equation crossover method mutation method global optima;partial differential equations optimisation	Swarm intelligence algorithms are candidate solutions to complex problems. This paper proposes a modified roach infestation optimization (MRIO) algorithm that is absolutely tied to social cockroach behaviours. MRIO improves the performance of the existing roach infestation optimization (RIO) using partial differential equation, crossover and mutation methods. The existing RIO models, made up of three components is modified and two new components are added. Simulation studies were conducted on the proposed algorithm with established benchmarks, the obtained result were compared with the results of the existing roach infestation optimization and hungry roach infestation optimization. The comparison results clearly show that the proposed algorithm outperforms the existing algorithms; and finds global optima of multi-dimensional functions.	algorithm;benchmark (computing);mathematical optimization;mutation (genetic algorithm);real life;simulation;swarm intelligence	Ibidun C. Obagbuwa;Aderemi Oluyinka Adewumi	2014	2014 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology	10.1109/CIBCB.2014.6845498	mathematical optimization;control theory;mathematics;ecology	EDA	27.349348740038355	-5.0451706623010395	170905
ffdc53ab63d17d390265bea0e9246866232b961d	a hill-shift learning algorithm of hopfield network for bipartite subgraph problem	tecnologia electronica telecomunicaciones;learning algorithm;hopfield network;hopfield neural network;bipartite subgraph problem;tecnologias;grupo a;hill shift learning;np complete problem	In this paper, we present a hill-shift learning method of the Hopfield neural network for bipartite subgraph problem. The method uses the Hopfield neural network to get a near-maximum bipartite subgraph, and shifts the local minimum of energy function by adjusts the balance between two terms in the energy function to help the network escape from the state of the near-maximum bipartite subgraph to the state of the maximum bipartite subgraph or better one. A large number of instances are simulated to verify the proposed method with the simulation results showing that the solution quality is superior to that of best existing parallel algorithm.	algorithm;hopfield network;maximum cut	Rong Long Wang;Kozo Okazaki	2006	IEICE Transactions	10.1093/ietfec/e89-a.1.354	np-complete;computer science;artificial intelligence;machine learning;subgraph isomorphism problem;mathematics;induced subgraph isomorphism problem;hopfield network;algorithm	ML	30.44471238609498	3.7416262877937236	171549
b5e6d7000c2b4b91dfb0466a41eec47c7058f8f5	computer graphics with lines of variable thickness	computer graphic	Abstract A FORTRAN subroutine is presented which efficiently draws a bundle of lines that follow a given set of points creating the impression of a thick line of uniform width following the points.	computer graphics;fortran;subroutine;thickness (graph theory)	P. Senn	1986	Computers & Chemistry	10.1016/0097-8485(86)80014-6	biology;chemistry;computer hardware;computer science;computer graphics (images)	Theory	35.61176149096057	2.611030625122744	171887
cb344eeaef080ef1c330db944a0d8c55694440d0	global optimization of functions with the interval genetic algorithm		A new evolut ionary method for the global optimizat ion of fun ctions wit h cont inuous vari ab les is proposed . This algorit hm can be viewed as an efficient par allelization of the simula ted annealing technique , although a suitable interval coding shows a close ana logy between real-coded genet ic algorit hms and the pr oposed meth od , called int erval genetic algorithm . Some well-defined genet ic operators allow a considera ble improvement in reliability and efficiency with respect to conventional simula ted annealing even on a sequential compute r. Results of simulations on Rosenbrock valleys and cost functi ons wit h fla t ar eas or fine-grain ed local min ima are repor ted. Furthermore, tests on classical pr ob lems in the field of neur al networks are presented . They show a possible practical application of th e interval genetic algor ithm.	ana (programming language);genetic algorithm;global optimization;maxima and minima;simula;simulated annealing;simulation	Marco Muselli;Sandro Ridella	1992	Complex Systems		global optimization;artificial intelligence;genetic algorithm;mathematics;machine learning;multi-swarm optimization;cultural algorithm;genetic representation;population-based incremental learning;meta-optimization;metaheuristic	EDA	26.214745539085808	-5.967062907386119	172019
4d99f3883508a897b5e61f50ea77cca659416f69	a compact programmable analog classifier using a vmm + wta network	winner take all compact programmable analog classifier vmm wta structure low power architecture compact architecture programmable classifier architecture 2 layer perceptron event driven systems nonlinear classifier structures xor function 1 layer vmm wta classifier;analogue computers;artificial neural networks speech recognition logic gates signal processing neurons hardware;programmable analog computing classifiers analog signal processing;logic gates;signal processing;signal processing analogue computers logic gates	We present the VMM+WTA structure as a general-purpose, low-power, compact, programmable classifier architecture and demonstrate its equivalence to a 2-layer perceptron. The classifier generates event outputs and is suitable for integration with event-driven systems. We present measured data from simple linear and non-linear classifier structures on a 0.35μm chip and demonstrate the implementation of an XOR function using a 1-layer VMM+WTA classifier.	event-driven programming;exclusive or;general-purpose modeling;linear classifier;low-power broadcasting;nonlinear system;perceptron;turing completeness;virtual machine manager;weapon target assignment problem	Shubha Ramakrishnan;Jennifer Hasler	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6638113	computer vision;logic gate;computer science;theoretical computer science;machine learning;signal processing	Robotics	38.36189738485829	-1.892625802849284	172358
8c126a12fded73ce2d2f60377ea9df5c8729d59e	on acceleration of evolutionary algorithms taking advantage of a posteriori error analysis	constrained optimization;calculations efficiency increase;a posteriori error estimation;evolutionary algorithms	A variety of important engineering and scientific tasks may be formulated as non-linear, constrained optimization problems. Their solution often demands high computational power. It may be reached by means of appropriate hardware, software or algorithm improvements. The Evolutionary Algorithms (EA) approach to solution of such problems is considered here. The EA are rather slow methods; however, the main advantage of their application is observed in the case of non-convex problems. Particularly high efficiency is demanded in the case of solving large optimization problems. Examples of such problems in engineering include analysis of residual stresses in railroad rails and vehicle wheels, as well as the Physically Based Approximation (PBA) approach to smoothing experimental and/or numerical data. Having in mind such analysis in the future, we focus our current research on the significant EA efficiency increase. Acceleration of the EA is understood here, first of all, as decreasing the total computational time required to solve an optimization problem. Such acceleration may be obtained in various ways. There are at least two gains from the EA acceleration, namely i) saving computational time, and ii) opening a possibility of solving larger optimization problems, than it would be possible with the standard EA. In our recent research we have preliminarily proposed several new speed-up techniques based on simple concepts. In this paper we mainly develop acceleration techniques based on simultaneous solutions averaging well supported by a non-standard application of parallel calculations, and a posteriori solution error analysis. The knowledge about the solution error is used to EA acceleration by means of appropriately modified standard evolutionary operators like selection, crossover, and mutation. Efficiency of the proposed techniques is evaluated using several benchmark tests. These tests On Acceleration of EA Taking Advantage of A Posteriori Error Analysis 155 indicate significant speed-up of the involved optimization process. Further concepts and improvements are also currently being developed and tested.	approximation;benchmark (computing);computation;computer hardware;constrained optimization;crossover (genetic algorithm);error analysis (mathematics);evolutionary algorithm;level of measurement;mathematical optimization;mind;mutation (genetic algorithm);nonlinear system;norm (social);numerical analysis;optimization problem;ruby on rails;selection (genetic algorithm);smoothing;speedup;time complexity;wheels	Janusz Orkisz;Maciej Glowacki	2014	Computing and Informatics		mathematical optimization;constrained optimization;computer science;artificial intelligence;machine learning;mathematics;algorithm;statistics	AI	29.639633898611166	-1.4018750338555062	172648
79a54d07202a07d4a7759578ae6df2143fa349c4	a hybrid quantum-inspired genetic algorithm for flow shop scheduling	raisonnement base sur cas;razonamiento fundado sobre caso;genetic operator;mise a jour;heuristic method;flow shop scheduling;metodo heuristico;intelligence artificielle;probabilistic approach;algoritmo genetico;permutation;actualizacion;quantum computation;quantum gate;scheduling;enfoque probabilista;approche probabiliste;permutacion;algorithme genetique;artificial intelligence;genetic algorithm;methode heuristique;inteligencia artificial;case based reasoning;calcul quantique;atelier monogamme;calculo cuantico;ordonnancement;flow shop;updating;reglamento	This paper is the first to propose a hybrid quantum-inspired genetic algorithm (HQGA) for flow shop scheduling problems. In the HQGA, Q-bit based representation is employed for exploration in discrete 0-1 hyperspace by using updating operator of quantum gate as well as genetic operators of Q-bit. Then, the Q-bit representation is convened to random key representation. Furthermore, job permutation is formed according to the random key to construct scheduling solution. Moreover, as a supplementary search, a permutation-based genetic algorithm is applied after the solutions are constructed. The HQGA can be viewed as a fusion of micro-space based search (Q-bit based search) and macro-space based search (permutation based search). Simulation results and comparisons based on benchmarks demonstrate the effectiveness of the HQGA. The search quality of HQGA is much better than that of the pure classic GA, pure QGA and famous NEH heuristic.	flow shop scheduling;genetic algorithm;quantum;scheduling (computing)	Ling Wang;Hao Wu;Fang Tang;Da-Zhong Zheng	2005		10.1007/11538356_66	beam search;mathematical optimization;flow shop scheduling;computer science;artificial intelligence;mathematics;best-first search;algorithm	HPC	25.8786748428714	1.460801401532377	172666
5321fbc17b6d48e6a60986344da432ea6edd5857	new a priori and a posteriori probabilistic bounds for robust counterpart optimization: ii. a priori bounds for known symmetric and asymmetric probability distributions	probabilistic bounds;optimization under uncertainty;mathematical modeling;robust counterpart optimization	When optimization problems contain uncertain parameters, their nominal solutions may prove to be overly optimistic or even rendered infeasible given the actual parameter realizations. The application of probabilistic bounds in constructing the robust counterpart formulation of a model under uncertainty can greatly reduce the conservatism of traditional worst-case robust optimization. In Part I, we derived new  a priori  and  a posteriori  bounds on the probability of constraint violation for constraints with uncertain parameters whose distributions were unknown. Here, we first present new  a priori  bounds applicable to uncertain constraints with linearly participating uncertain parameters whose distributions are known or conservatively approximated. We then extend the robust counterpart optimization methodology by allowing attributed known distributions to be symmetric or asymmetric. The new methods greatly reduce the conservatism and significantly augment the performance and applicability of robust counterpart optimization. A mixed-integer linear optimization example and a multiperiod planning problem demonstrate the improvements of the new  a priori  bounds relative to existing bounds.	mathematical optimization	Yannis A. Guzman;Logan R. Matthews;Christodoulos A. Floudas	2017	Computers & Chemical Engineering	10.1016/j.compchemeng.2016.07.002	probabilistic-based design optimization;mathematical optimization;machine learning;mathematical model;mathematics;statistics	Theory	36.377887728726286	2.070235791513765	172944
056697d0459454882b33740d916b9081de304f22	on the runtime analysis of the opt-ia artificial immune system		We present a time complexity analysis of the Opt-IA artificial immune system (AIS). We first highlight the power and limitations of its distinguishing operators (i.e., hypermutations with mutation potential and ageing) by analysing them in isolation. Recent work has shown that ageing combined with local mutations can help escape local optima on a dynamic optimisation benchmark function. We generalise this result by rigorously proving that ageing leads to considerable speed-ups (compared to evolutionary algorithms (EAs)) on the standard Cliff benchmark function both when using local and global mutations. Unless the stop at first constructive mutation (FCM) mechanism is applied, we show that hypermutations require exponential expected runtime to optimise any function with a polynomial number of optima. If instead FCM is used, the expected runtime is at most a linear factor larger than the upper bound achieved for any random local search algorithm using the artificial fitness levels method. Nevertheless, we prove that algorithms using hypermutations can be considerably faster than EAs at escaping local optima. An analysis of the complete Opt-IA reveals that it is efficient on the previously considered functions and highlights problems where the use of the full algorithm is crucial.	analysis of algorithms;artificial immune system;benchmark (computing);evolutionary algorithm;fuzzy cognitive map;linear function;local optimum;local search (optimization);mathematical optimization;polynomial;search algorithm;time complexity	Dogan Corus;Pietro Simone Oliveto;Donya Yazdani	2017		10.1145/3071178.3079194	machine learning;operator (computer programming);mathematical optimization;artificial intelligence;time complexity;ageing;evolutionary algorithm;artificial immune system;local optimum;local search (optimization);polynomial;mathematics	AI	26.781986398911872	-5.621462784965258	172973
758784ed0df79a0828a08c89af7ae38a079e1292	an analysis of selection methods in memory consideration for harmony search	selection methods;selection pressure;evolutionary algorithms;harmony search	This paper presents an analysis of some selection methods used in memory consideration of Harmony search (HS) Algorithm. The selection process in memory consideration entails selecting the value of the decision variable from any solution in the Harmony memory (HM). Quite recently, there has been a tendency to adopt novel selection methods that mimic the natural phenomena of the 'survival of the fittest' to replace the random selection method in memory consideration. Consequently, the value of decision variable selected using memory consideration is chosen from the higher promising solutions in HM. The adopted selection methods include: proportional, tournament, linear rank, and exponential rank. It has been demonstrated that experimenting with any of these methods in memory consideration directly affects the performance of HS. However, the success of these methods is based on choosing the optimal parameter value of each. The wrong parameter settings might affect the balance between exploration and exploitation of the search space. Accordingly, this paper studies the effect of the selection method parameters in order to show their effect on HS behavior. The evaluation is conducted using standard mathematical functions used in the literature for HS adoptions. The results suggest that the optimal setting of the selection method parameters is crucial to improve the HS performance.	harmony search	Mohammed Azmi Al-Betar;Ahamad Tajudin Abdul Khader;Zong Woo Geem;Iyad Abu Doush;Mohammed A. Awadallah	2013	Applied Mathematics and Computation	10.1016/j.amc.2013.04.053	mathematical optimization;harmony search;artificial intelligence;evolutionary algorithm;evolutionary pressure	ML	28.447838833313362	-4.605200648867824	173014
4c387b6823e6b86e25dd36e7b79db23427ed7427	an improved particle swarm optimization algorithm for fir filter design	convergence;search space particle swarm optimization algorithm fir filter design inertia weight mechanism;particle swarm optimization linear programming algorithm design and analysis finite impulse response filters convergence design methodology;finite impulse response filters;particle swarm optimization;linear programming;particle swarm optimisation fir filters integrated circuit design;algorithm design and analysis;design methodology	In this paper, an Improved Particle Swarm Optimization algorithm is introduced. Compared with conventional PSO, a new inertia weight mechanism is used to ensure the coverage and convergence at a better extent, considering the suboptimal solutions generated by conventional PSO when dealing with complex problems with lots of local minimas. The new mechanism divide the particles into two parts to enlarge coverage of search space and apply new decreasing algorithm to guarantee convergence. FIR filter design, whose results are very sensitive to parameters, is used to illustrate the effective impact of the new inertia weight mechanism.	algorithm;filter design;finite impulse response;ipso alliance;maxima and minima;particle swarm optimization;requirement;vergence	Yuanhai Xia	2013	2013 IEEE 20th International Conference on Electronics, Circuits, and Systems (ICECS)	10.1109/ICECS.2013.6815404	control engineering;mathematical optimization;multi-swarm optimization;control theory;mathematics;particle swarm optimization;metaheuristic	Robotics	28.26845586388873	-4.566173888320951	173054
f8f895f516a8f957aba80828aa584e46b9b524de	improved pso algorithm with harmony search for complicated function optimization problems	function optimization;particle swarm optimization;harmony search	Improved particle swarm optimization algorithm with harmony search (IHPSO) is proposed in this paper. This algorithm takes particle swarm search direction estimation mechanism and harmony search (HS) approach to particle swarm optimization (PSO) algorithm, which increases the search capability of PSO algorithm considerably. The proposed algorithm initializes a new search with harmony pitch adjusting or random selection when PSO search direction is estimated incorrectly. This can provide further opportunities of finding better solutions for the particle swarm by guiding the entire particle swarm to promising new regions of the search space and accelerating the search. PSO, HPSO and IHPSO, as well as other advanced PSO procedures from the literature were compared on several benchmark test functions extensively. Statistical analyses of the experimental results indicate that the performance of IHPSO is better than the performance of PSO and HPSO.	algorithm;harmony search;particle swarm optimization;program optimization	Jian Yu;Ping Guo	2012		10.1007/978-3-642-31346-2_70	mathematical optimization;multi-swarm optimization;harmony search;computer science;artificial intelligence;machine learning;mathematics;particle swarm optimization;metaheuristic	ML	27.04418678224602	-4.222081760283709	173126
06c1626a83cc8c4d648faba99dc42f360b682597	enhanced particle swarm optimization based on principal component analysis and line search	swarm intelligence;line search;qa75 electronic computers computer science;principal component analysis;particle swarm optimization;期刊论文;velocity diversity;information accumulation	Particle swarm optimization (PSO) guides its search direction by a linear learning strategy, in which each particle updates its velocity through a linear combination among its present status, historical best experience and the swarm best experience. The current position of each particle can be seen as a velocity accumulator. Such a storage strategy is easy to achieve, however, it is inefficient when searching in a complex space and has a great restriction on the achieved heuristic information for the promising solutions. Therefore, a new PSO searching mechanism (PCA-PSO) is proposed based on principal component analysis (PCA) and Line Search (LS), in which PCA is mainly used to efficiently mine population information for the promising principal component directions and then LS strategy is utilized on them. PCA-PSO can inherit most of the velocity information of all the particles to guide them to the most promising directions, which have great difference in learning mechanism with usual PSOs. Experimental results and extensive comparisons with hybrid PSOs, pPSA, PCPSO, CLPSO, GL-25, and CoDE show that PCA-PSO consistently and significantly outperforms some PSO variants and is competitive for other state-of-the-art algorithms.	accumulator (computing);algorithm;converge;experiment;heuristic;line search;mathematical optimization;particle swarm optimization;phase-shift oscillator;principal component analysis;velocity (software development)	Xinchao Zhao;Wenqiao Lin;Qingfu Zhang	2014	Applied Mathematics and Computation	10.1016/j.amc.2013.12.068	mathematical optimization;multi-swarm optimization;swarm intelligence;artificial intelligence;machine learning;mathematics;line search;particle swarm optimization;principal component analysis	Robotics	27.14853997911673	-3.7590474552870203	173306
100586bd116c266045725218a3f74905a46a62c0	an afsa-tsgm based wavelet neural network for power load forecasting	power load forecasting;wavelet neural network;wavelet neural networks;genetics;load forecasting;tabu search algorithm;tabu search;afsa;evolutionary learning;optimal algorithm;genetic mutation operator;hybrid algorithm	An intelligent methodology for power load forecasting was developed. In this forecasting system, wavelet neural network techniques were used in combination with a new evolutionary learning algorithm. The new evolutionary learning algorithm introduced the Tabu Search Algorithm and Genetic Mutation Operator into Artificial Fish Swarm Algorithm (AFSA) to construct a hybrid optimizing algorithm, and is thus called ASFA-TSGM. The hybrid algorithm can greatly improve the ability of searching the global excellent result and the convergence property and accuracy. The effectiveness of the ASFA-TSGM based WNN was demonstrated through the power load forecasting. The simulated results show its feasibility and validity.	artificial neural network;wavelet	Dongxiao Niu;Zhihong Gu;Yunyun Zhang	2009		10.1007/978-3-642-01513-7_114	mathematical optimization;hybrid algorithm;tabu search;computer science;artificial intelligence;machine learning;population-based incremental learning	ML	25.7975085028787	-6.0890875217749905	173321
8f9681937c89d3c3d26ed645a49068c02f3f61bc	chaotic image encryption using bézier curve in dct domain scrambling	bézier curve;chaotic maps;dct domain;image encryption	In this paper, an extended sequence using chaotic map and Bernstein form Bézier curve to improve the chaotic key sequence is presented. Based on this sequence, we perform the scrambling in DCT domain with variable control parameters. To further enforce the security, the gray values of image pixels are diffused using keystream extracted from the extended key sequence of the chaotic map and the plainimage. As a result, the algorithm resists the chosenplaintext/chosen-ciphertext/known-plaintext attacks, as diffusion depends on the plainimage. Moreover, experimental results and analysis confirm a high security level using the proposed scheme.	algorithm;bernstein polynomial;bézier curve;chaos theory;chosen-ciphertext attack;ciphertext;discrete cosine transform;encryption;known-plaintext attack;pixel;plaintext	Ahmed A. Abd El-Latif;Xiamu Niu;Ning Wang	2011		10.1007/978-3-642-22603-8_3	keystream;scrambling;bézier curve;discrete mathematics;encryption;discrete cosine transform;pixel;security level;chaotic;mathematics	ML	38.709928689824665	-8.772956133594803	173324
72e2cededf72a5a05e208c0436ad48c49feecf0e	solving constraint satisfaction problems using a genetic/systematic search hybrid that realizes when to quit	genetics;constraint satisfaction problem		constraint satisfaction	James Bowen;Gerry V. Dozier	1995			mathematical optimization;constraint satisfaction;constraint learning;artificial intelligence;machine learning;constraint satisfaction dual problem;mathematics;constraint satisfaction problem;hybrid algorithm;backtracking	AI	24.823640509525532	1.2190463216230105	173998
923ee036b06c45099e27725d5ae2d70ff5a0a621	efficient mutation strategies embedded in laplacian-biogeography-based optimization algorithm for unconstrained function minimization		Biogeography-Based optimization (BBO) is a nature inspired optimization technique that has excellent exploitation ability but the exploration ability needs to be improved to make it more robust. With this objective in mind, Garg and Deep proposed Laplacian BBO (LX-BBO) based on the Laplace Crossover which is a Real Coded Genetic Crossover Operator. It was concluded that LX- BBO outperforms its competitors. A natural question is to incorporate real coded mutation strategies into LX-BBO in order to improve its diversity. Therefore, in this paper, the exploring ability of LX-BBO is further investigated by using six different types of mutation operators present in literature. Gaussian, Cauchy, Levy, Power, Polynomial and Random mutation are used to test which mutation works best for LX-BBO. The performance of all these versions of BBO are measured on the benchmark problem set proposed in CEC 2014. On the basis of the criteria lay down by CEC, analysis of numerical and graphical results and statistical tests it is concluded that LX-BBO works best with Random and Cauchy Mutation.	algorithm	Vanita Garg;Kusum Deep	2016	IJAEC	10.4018/IJAEC.2016040102	mathematical optimization;artificial intelligence;machine learning;mathematics;algorithm	EDA	24.904480636122365	-4.769844786088426	174008
3497ece736346863c066b4c502572354853cae7b	hybrid particle guide selection methods in multi-objective particle swarm optimization	topology;queensland micro and nanotechnology centre;optimisation;hybrid intelligent systems;engineering drawings;conference output;distributed computing;230118;testing;particle swarm optimization optimization methods testing hybrid intelligent systems informatics engineering drawings robustness statistical analysis distributed computing topology;robust optimization;multi objective particle swarm optimization;statistical analysis;hybrid method;faculty of engineering and information technology;particle swarm optimization;robustness;informatics;optimal algorithm;optimization methods	"""This paper presents quantitative comparison of the performance of different methods for selecting the guide particle for multi-objective particle swarm optimization (MOPSO). Two principal methods are compared: the recently described Sigma method, and a new """"Centroid"""" method. Drawing on the different dominant behaviors exhibited by the different selection methods, a variety of hybridizations of these is proposed to develop a more robust optimization algorithm. Statistical analysis of the hybrid methods demonstrates their contribution to improved performance of the optimization algorithm."""	hybrid algorithm;mathematical optimization;particle swarm optimization;robust optimization	David Ireland;Andrew Lewis;Sanaz Mostaghim;Junwei Lu	2006	2006 Second IEEE International Conference on e-Science and Grid Computing (e-Science'06)	10.1109/E-SCIENCE.2006.86	mathematical optimization;multi-swarm optimization;robust optimization;meta-optimization;computer science;derivative-free optimization;artificial intelligence;machine learning;software testing;particle swarm optimization;informatics;metaheuristic;robustness	Robotics	24.704829756406504	-5.780228114603941	174256
174b298d83b29d5e36acea22a459a809a1242d8c	finding the differential characteristics of block ciphers with neural networks	cost function;hopfield network;block cipher;differential operators;simulated annealing;differential operation model;directed graph;differential cryptanalysis;boltzmann machine;recurrent neural network;local minima;chaotic hopfield;chaotic boltzmann machine;neural network	We have developed a model to represent the differential operation of block ciphers in order to help finding differential characteristics. Through this model, the whole space of differential characteristics for a block cipher is represented by a multi-level weighted directed graph. In this way, the problem of finding the best differential characteristic for a block cipher reduces to the problem of finding the minimum-weight multi-branch path between two known nodes in the proposed graph. In this paper, we use recurrent neural networks to find such a path in the differential operation graph of a block cipher. The path is found through minimization of the network cost function. We use the Hopfield network and the Boltzmann machine with and without chaos to minimize the cost function. Chaos is introduced to assist the network to escape from the local minima of the cost function. Experimental results indicate the usefulness of the approach and comparison of the performance of the used techniques shows that the Boltzmann machine algorithm incorporating simulated annealing produces the best result. 2008 Elsevier Inc. All rights reserved.	algorithm;artificial neural network;block cipher;boltzmann machine;differential cryptanalysis;directed graph;hopfield network;loss function;maxima and minima;recurrent neural network;simulated annealing	Abbas Ghaemi Bafghi;Reza Safabakhsh;Babak Sadeghiyan	2008	Inf. Sci.	10.1016/j.ins.2008.02.016	boltzmann machine;differential operator;block cipher;mathematical optimization;differential cryptanalysis;directed graph;simulated annealing;computer science;recurrent neural network;theoretical computer science;machine learning;maxima and minima;mathematics;hopfield network;artificial neural network	ML	30.727707974576177	3.6132638048462677	174320
340a528f1e37ec89cfa5a092c7b3bfea1c04e199	the fitness map scheme: application to interactive multifractal image denoising	fractals;evolutionary computation;user interactions fitness map interactive multifractal image denoising interactive evolutionary algorithms;iea;fractals image denoising interactive systems evolutionary computation;image denoising;evolutionary algorithm;user interaction;interactive systems;fractals image denoising noise reduction image texture analysis discrete wavelet transforms information analysis humans evolutionary computation image converters optimization methods	"""Interactive evolutionary algorithms (IEA) often suffer from what is called the """"user bottleneck"""". In this paper, we propose and analyze a method to limit the user interactions, while still providing sufficient informations for the EA to converge. The method has been currently developed on a multifractal image denoising application: a multifractal denoising method is adapted to complex images, but depends on a set of parameters that are quite difficult to tune by hand. A simple IEA has been developed for this purpose in a previous work. We now experiment an approximation of the user judgment, via a """"fitness map"""", that helps to reduce the number of user-interactions. The method is easily extensible to other interactive, or computationally expensive, evolutionary schemes."""	analysis of algorithms;approximation;converge;download;evolutionary algorithm;fractal compression;image analysis;interaction;interactivity;international ergonomics association;multifractal system;noise reduction;signal processing;standalone program	Evelyne Lutton;Mario Pilz;Jacques Lévy Véhel	2005	2005 IEEE Congress on Evolutionary Computation	10.1109/CEC.2005.1554978	computer vision;mathematical optimization;evolutionary music;fractal;interactive evolutionary computation;computer science;artificial intelligence;theoretical computer science;machine learning;evolutionary algorithm;mathematics;evolutionary computation	Vision	26.672889981273684	-7.823031612152821	174382
a502e54a148216171c4fa510696effc5faece9ef	a hybrid particle swarm optimization for high-dimensional dynamic optimization		High-Dimensional Dynamic Optimization Problems (HDDOPs) commonly exist in real-world applications. In evolutionary computation field, most of existing benchmark problems, which could simulate HDDOPs, are non-separable. Thus, we give a novel benchmark problem, called high-dimensional moving peaks benchmark to simulate separable, partially separable, and non-separable problems. Moreover, a hybrid Particle Swarm Optimization algorithm based on Grouping, Clustering and Memory strategies, i.e. GCM-PSO, is proposed to solve HDDOPs. In GCM-PSO, a differential grouping method is used to decompose a HDDOP into a number of sub-problems based on variable interactions firstly. Then each sub-problem is solved by a species-based particle swarm optimization, where the nearest better clustering is adopted as the clustering method. In addition, a memory strategy is also adopted in GCM-PSO. Experimental results show that GCM-PSO performs better than the compared algorithms in most cases.	particle swarm optimization;program optimization	Wenjian Luo;Bin Yang;Chenyang Bu;Xin Lin	2017		10.1007/978-3-319-68759-9_81	machine learning;multi-swarm optimization;evolutionary computation;mathematical optimization;cluster analysis;metaheuristic;separable space;optimization problem;computer science;artificial intelligence;particle swarm optimization	EDA	26.093238820680146	-4.09134346887629	174470
9003290893065fdf291d4549b51fb16b0064fb2c	pre-scheduled colony size variation in dynamic environments	conference	The performance of the MAX -MIN ant system (MMAS) in dynamic optimization problems (DOPs) is sensitive to the colony size. In particular, a large colony size may waste computational resources whereas a small colony size may restrict the searching capabilities of the algorithm. There is a trade off in the behaviour of the algorithm between the early and later stages of the optimization process. A smaller colony size leads to better performance on shorter runs whereas a larger colony size leads to better performance on longer runs. In this paper, pre-scheduling of varying the colony size of MMAS is investigated in dynamic environments.	algorithm;ant colony optimization algorithms;computational resource;dynamic programming;expectation propagation;experiment;mathematical optimization;max;scheduling (computing);stationary process;test case	Michalis Mavrovouniotis;Anastasia Ioannou;Shengxiang Yang	2017		10.1007/978-3-319-55792-2_9	computer science;artificial intelligence;world wide web	DB	27.69209624684422	-2.449703959148872	174659
ea0dbb2f8b087db3f038d3824180e3b579dacfbc	halton based initial distribution in artificial bee colony algorithm and its application in software effort estimation	multi-agent systems;optimisation;statistical distributions;halton based initial distribution;nasa software project dataset;artificial bee colony algorithm;cost model parameter;honey bee swarm;intelligent behaviour;nonuniform distribution;optimum location;software effort estimation;artificial bee colony;halton distribution;nasa software;multi agent systems;uniform distribution	"""Artificial Bee Colony (ABC) is an optimization algorithm that simulates the foraging behavior of honey bees. It is a population based search technique whose performance depends largely on the distribution of initial population. Generally, uniform distributions are preferred since they best reflect the lack of knowledge about the optimum’s location. Moreover, these are easy to generate as most of the programming languages have an inbuilt function for generating uniformly distributed random numbers. However, in case of a population dependent optimization algorithm like that of ABC, random numbers having uniform probability distribution may not be a good choice as they may not be able exploit the search space fully. This paper uses quasi random numbers based on Halton sequence for the initial distribution and have compared the simulation results with initial population generated using uniform distribution. The proposed variant, termed as Halton based ABC (H-ABC), is validated on a set of 15 standard benchmark problems, 6 nontraditional shifted benchmark functions proposed at the special session of CEC2008, and has been used for solving the real life problem of estimating the cost model parameters. Numerical results indicate the competence of the proposed algorithm. DOI: 10.4018/jncr.2012040105 International Journal of Natural Computing Research, 3(2), 86-106, April-June 2012 87 Copyright © 2012, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. showed that ABC is more effective than the other methods in several optimization problems (Kang et al., 2009; Karaboga, 2009; Singh, 2009).The main advantage of ABC algorithm lies in the fact that it conducts local search in each iteration, thus the probability of finding the optimal results is significantly increased. Artificial Bee Colony (ABC) simulates the foraging behaviour that a swarm of bees perform. In this algorithm the foraging labor is divided over three groups of bees, the employed bees (bees that determines the food source (possible solutions) from a prespecified set of food sources and share this information (waggle dance) with the other bees in the hive, the onlookers bees (gets the information of food sources from the employed bees in the hive and select one of the food source to gathers the nectar) and the scout bees (responsible for finding new food sources). A brief overview of the algorithm is given. ABC, however, like its counterpart population based search algorithms suffers from some inherent drawbacks like slow or premature convergence while dealing with certain complex models (Karaboga & Akay, 2009). In order to further improve the performance of ABC, several modifications are available in literature (Akay & Karaboga, 2010; Alatas, 2010; Baykasoglu, Ozbakir & Tapkan, 2007; Coelho & Alotto, 2011; Gao & Liu, 2012; Haijun & Qingxian, 2009; Kang, Li & Ma, 2011; Quan & Shi, 2008; Sharma & Pant, 2011a; Sharma et al., 2011; Tsai et al., 2009; Zhu & Kwong, 2010). The recently comprehensive literature survey of ABC can be found in (Karaboga et al., 2012). In the present study, we propose an improved solution search space by initializing the initial population using Halton sequence. Generation of initial population is a crucial task in a population based search technique. In case no a priori information about the solution is available, random initialization is the most popular method of generating the initial population. This is also an easier method to generate the random numbers as most of the programming languages have an in-built random number generator based on uniform probability distribution. However, pragmatically speaking this may not be the best form of distribution. What we need in a population based search technique is a distribution with the help of which we are able to extract the domain knowledge more efficiently. Instead of using random numbers, if we use quasi random numbers, the performance of an optimization algorithm may improve. This has also been shown in some previous studies (Bratley & Bennett, 1988; Morokoff & Caftisch, 1994; Pant & Thangaraj, 2009; Uy et al., 2007). In the present study we propose Halton distribution, a quasi random distribution for generating the initial population of ABC. Here we would like to mention that a preliminary version of this work has been presented in a conference (Sharma & Pant, 2011b). However, in this study we present its elaborated version. Here we provide a comprehensive set of experimental verifications of the proposed H-ABC. The remaining of the paper is organized as follows; in the next section we give a brief overview of the basic ABC algorithm. In the next section, proposed algorithm is described. Next, the Benchmark Problems are defined. Parameter settings and simulation results are given. Software effort estimation is discussed. Experimental results are given and finally the paper concludes. A BRIEF OVERVIEW OF ABC ALGORITHM ABC is one of the newest algorithms based on the foraging behavior of insects. It tries to model natural behavior of real honey bees in food foraging. Honey bees use several mechanisms like waggle dance to optimally locate food sources and to search new ones. Waggle dance is a means of communication among bees by which the successful foragers share the information not only about the direction and distance of the food sources but also about the amount of nectar available to the other foragers. This information exchange among bees helps 19 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/halton-based-initial-distributionartificial/73015?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Medicine, Healthcare, and Life Science. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""	2-satisfiability;abc (stream cipher);analysis of algorithms;apache hive;artificial bee colony algorithm;benchmark (computing);corner detection;cost estimation in software engineering;granular computing;information exchange;information science;iteration;librarian;local search (optimization);mathematical optimization;natural computing;numerical method;optimization problem;population;premature convergence;programming language;random number generation;real life;search algorithm;sharma speaker;simulation;software development effort estimation;swarm;web page;word lists by frequency	Tarun Kumar Sharma;Millie Pant	2012	IJNCR	10.4018/jncr.2012040105	mathematical optimization;artificial intelligence	AI	27.383806407230686	-2.9063098433326284	174709
a7adb0b0e63a90c4736487380a210360147f99f1	a new dynamic population variation in genetic programming	exponential pivot function;instruction matrix;computational effort;evolutionary algorithm;dynamic population variation	A dynamic population variation (DPV) in genetic programming (GP) with four innovations is proposed for reducing computational effort and accelerating convergence during the run of GP. Firstly, we give a new stagnation phase definition and the characteristic measure for it. Secondly, we propose an exponential pivot function (EXP) in conjunction with the new stagnation phase definition. Thirdly, we propose an appropriate population variation formula for EXP. Finally, we introduce a scheme using an instruction matrix for producing new individuals to maintain diversity of the population. The efficacy of these innovations in our DPV is examined using four typical benchmark problems. Comparisons among the different characteristic measures have been conducted for regression problems and the proposed measure performed best in all characteristic measures. It is demonstrated that the proposed population variation scheme is superior to fixed and proportion64 Y. Tao, M. Li, J. Cao ate population variation schemes for sequence induction. It is proved that the new DPV has the capacity to provide solutions at a lower computational effort compared with previously proposed population variation methods and standard genetic programming in most problems.	benchmark (computing);delegated path validation;exptime;genetic programming;scheme;time complexity	Yanyun Tao;Minglu Li;Jian Cao	2013	Computing and Informatics		mathematical optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;algorithm;statistics	ML	28.491134913195026	-4.0746091142565275	175112
d27f30a5b25c15e865b1e98ca8470662366765f3	training passive photonic reservoirs with integrated optical readout		As Moore's law comes to an end, neuromorphic approaches to computing are on the rise. One of these, passive photonic reservoir computing, is a strong candidate for computing at high bitrates (>10 Gb/s) and with low energy consumption. Currently though, both benefits are limited by the necessity to perform training and readout operations in the electrical domain. Thus, efforts are currently underway in the photonic community to design an integrated optical readout, which allows to perform all operations in the optical domain. In addition to the technological challenge of designing such a readout, new algorithms have to be designed in order to train it. Foremost, suitable algorithms need to be able to deal with the fact that the actual on-chip reservoir states are not directly observable. In this paper, we investigate several options for such a training algorithm and propose a solution in which the complex states of the reservoir can be observed by appropriately setting the readout weights, while iterating over a predefined input sequence. We perform numerical simulations in order to compare our method with an ideal baseline requiring full observability as well as with an established black-box optimization approach (CMA-ES).	algorithm;baseline (configuration management);black box;cma-es;computation (action);foremost;gigabyte;hl7publishingsubsection <operations>;mathematical optimization;moore's law;neuromorphic engineering;norm (social);numerical analysis;observable;reservoir device component;reservoir computing;simulation;benefit	Matthias Freiberger;Andrew Katumba;Peter Bienstman;Joni Dambre	2018	IEEE transactions on neural networks and learning systems	10.1109/TNNLS.2018.2874571	machine learning;artificial intelligence;energy consumption;reservoir computing;observability;real-time computing;computer science;photonics;neuromorphic engineering;observable	Visualization	38.20733443735781	0.2219523374981132	175448
5d2860ab508eb8901cd8de44c6dc116eb1a59182	image encryption algorithm based on s-boxes substitution and chaos random sequence	image encryption;chaos;random sequences;random sequences chaos cryptography error statistics image sequences;data mining;gray scale;polynomials;computational modeling;cryptography;cryptography chaos random sequences polynomials mathematical model educational institutions computational modeling computer simulation computer science computer security;random sequence;error statistics;anti errors proliferation image encryption algorithm s box substitution chaos random sequence;algorithm design and analysis;image sequences	The purpose of this paper is to improve the security and the anti-errors-proliferation character of image encryption. Based on the theory of S-box in AES, we put forward a new standard algorithm. After that, by introducing the chaos random sequence, two improved image encryption algorithms were created. The method used by the first one was that a variety of S-boxes were selected for the substitution of each byte. The method used by the second one was that the encryption included multiple rounds of S-boxes substitution. In addition, the sequences of S-boxes in two algorithms were both decided by the chaos random sequence. Afterwards, we applied the three algorithms to the specific examples in order to testify the strength and the anti-errors-proliferation character of the encryption. Consequently, we have a conclusion that the new improved image encryption algorithms could effectively improve the inefficiency and the anti-errors-proliferation character of image encryption algorithm and be easy to implement.	algorithm;anti-aliasing filter;byte;encryption;s-box	De Wang;Yuan-Biao Zhang	2009	2009 International Conference on Computer Modeling and Simulation	10.1109/ICCMS.2009.26	discrete mathematics;computer science;cryptography;theoretical computer science;random sequence;mathematics;deterministic encryption;probabilistic encryption;algorithm;statistics	Vision	38.492293646878366	-8.82868768413478	175517
18a331fac0b6597b048a9f068d604d181ad7e11e	linkgauge: tackling hard deceptive problems with a new linkage learning genetic algorithm	genetic algorithm	A novel approach to obtaining a tight linkage between genes in a genetic algorithm is described, and a new system based on that approach, LINKGAUGE, is proposed. Experiments presented draw a comparison between the standard messy genetic algorithm and LINKGAUGE, and show that the latter avoids deceptive traps and early convergence, with minimal computational cost. The scalability potential of the new approach is illustrated with results for two hard deceptive problems.	algorithmic efficiency;experiment;genetic algorithm;linkage (software);scalability	Miguel Nicolau;Conor Ryan	2002			genetic algorithm;computer science;artificial intelligence;machine learning;algorithm;population-based incremental learning	NLP	24.680266280511443	-2.0828675173742957	175573
abc5efe58e01a642985a054dfc83237d2f14713e	incorporating radial basis functions in pattern search methods: application to beam angle optimization in radiotherapy treatment planning	radiotherapy;beam angle optimization;pattern search methods;imrt;radial basis functions	The global optimization of black-box functions with many local minima occurs in many branches of science and engineering. There are many methods and heuristics to address this type of problems. However, for problems with expensive black-box functions, both in terms of cost or time, the number of function evaluations required by most of the methods or heuristics is prohibitive. The pattern search methods framework is suited to address this type of problems since it requires few function value evaluations to converge and have the ability to avoid local entrapment. The ability of this class of methods to obtain global minima depends on the incorporation of methods or heuristics for global optimization on their, so called, search step. We propose the use of radial basis functions both to influence the quality of the local minimizer found by the method and also to obtain a better coverage of the search space. Our approach is tailored for addressing the beam angle optimization (BAO) problem in intensity modulated radiation therapy treatment planning, but can be easily extended for other general problems. The BAO problem is quite difficult, and yet to be solved in a satisfactory way, since it is a highly non-convex optimization problem with many local minima. A couple of retrospective treated cases of head-and-neck tumors at the Portuguese Institute of Oncology of Coimbra is used to discuss the benefits of using our approach in the optimization of the BAO problem.		Humberto Rocha;Joana Matos Dias;Brigida C. Ferreira;Maria do Carmo Lopes	2012		10.1007/978-3-642-31137-6_1	pattern search;mathematical optimization;radiation therapy;radial basis function;computer science;machine learning;mathematics;geometry	AI	29.60954166962743	-0.2262975028282479	175581
1a95feb613c720bdb84a1cf01de0cc3045458def	an improved artificial bee colony algorithm applied to engineering optimization problems		This work proposes an improved artificial bee colony (ABC) algorithm, called the rank-based ABC algorithm, which includes a rank-based selection mechanism in the onlooker bees phase and a modified abandonment mechanism in the scout bees phase for solving unconstrained and constrained optimization problems. In the onlooker bees phase, the probability that an onlooker bee selects a food source is determined using a nonlinear selective pressure function, which is based on a ranking of fitness instead of proportional total fitness values. A nectar source with a superior fitness rank has a large probability of being selected by onlooker bees as new solutions and so yields a similar “best solution pool,” which often comprises the best and several good solutions, therefore, the exploitation capability for searching good solution is enhanced for the basic ABC algorithm. Moreover, the modified abandonment mechanism is used in the scout bees phase to increase the exploration capability for searching good solution. Accordingly, this work makes the two modifications to the basic ABC algorithm, resulting in well-balanced exploitation and exploration capabilities. Nine benchmark unconstrained problems that involve low-, midand high-dimensional optimization functions, are evaluated to compare the computational performance of the proposed rank-based ABC, the basic ABC, a crossover type ABC (CABC), a new ABC (NABC), and a Gbest-guided ABC (GABC) algorithms. Furthermore, the proposed rank-based ABC that is applied to constrained optimization problems is obtained by adding a dynamic penalty function and Deb’s constraint handling rules to the unconstrained version of ABC algorithm. Five widely used engineering design problems are solved using the five aforementioned ABC algorithms. The optima of the objective function and their standard deviations that are obtained using the proposed rank-based ABC algorithm are compared with those obtained using the four ABC algorithms mentioned above and other evolutionary algorithms.	approximation algorithm;artificial bee colony algorithm;benchmark (computing);computation;constrained optimization;constraint handling rules;dynamic energy budget;engineering design process;evolutionary algorithm;fitness function;genetic algorithm;heuristic;mathematical optimization;nonlinear system;optimal design;optimization problem;penalty method;profile-guided optimization;program optimization;scalability;software release life cycle	Jenn-Long Liu;Chung-Chih Li	2016	J. Inf. Sci. Eng.		artificial bee colony algorithm;engineering optimization;computer science;machine learning;artificial intelligence	AI	25.334481223413544	-3.9955950475829356	175635
f87c24db84786198abfc84db0dc16627ed8a71f0	application of binary particle swarm optimization in cryptanalysis of des		Feistel cipher based cryptographic algorithms like DES are very hard for the cryptanalysts as their internal structures are based on high nonlinearity and low autocorrelation. It has been shown that the traditional and brute-force type attacks are insignificant for the cryptanalysis of this type of algorithms. Swarm intelligence is an exciting new research field and shown their effectiveness, robustness to solve a wide variety of complex problems. Therefore, in this paper, Binary Particle Swarm Optimization (BPSO) strategy is used for cryptanalysis of DES symmetric key cryptographic algorithm. The reported results show that it is very promising to solve block cipher based cryptographic optimization problem through meta heuristic techniques.	autocorrelation;block cipher;cryptanalysis;cryptography;encryption;feistel cipher;fractal dimension;heuristic;mathematical optimization;metaheuristic;nonlinear system;optimization problem;parameter (computer programming);particle swarm optimization;shape factor (image analysis and microscopy);swarm intelligence;symmetric-key algorithm	Shimpi Singh Jadon;Harish Sharma;Etesh Kumar;Jagdish Chand Bansal	2011		10.1007/978-81-322-0487-9_97	mathematical optimization;multi-swarm optimization;theoretical computer science;algorithm	Crypto	36.75408286290072	-7.6714437128927955	175708
79216586a5a522ef0ae712c05b767e296a19ea00	evolutionary design automation for control systems with practical constraints	t technology general;qa75 electronic computers computer science	The aim of this work is to explore the potential and to enhance the capability of evolutionary computation in the development of novel and advanced methodologies that enable control system structural optimisation and design automation for practical applications. Current design and optimisation methods adopted in control systems engineering are in essence based upon conventional numerical techniques that require derivative information of performance indices. These techniques lack robustness in solving practical engineering problems, which are often of a multi-dimensional, multi-modal nature. Using those techniques can often achieve neither global nor structural optimisation. In contrast, evolutionary mechanism learning tools have the ability to search in a multi-dimensional, multi-modal space, but they can not approach a local optimum as a conventional calculusbased method. The first objective of this research is to develop a reliable and effective evolutionary algorithm for engineering applications. In this thesis, a globally optimal evolutionary methodology and environment for control system structuring and design automation is developed, which requires no design indices to be differentiable. This is based on the development of a hybridised GA search engine, whose local tuning is tremendously enhanced by the incorporation of Hill-Climbing (HC), Simulated Annealing (SA) and Simplex techniques to improve the performance in search and design. A Lamarckian inheritance technique is also developed to improve crossover and mutation operations in GAs. Benchmark tests have shown that the enhanced hybrid GA is accurate, and reliable. Based on this search engine and optimisation core, a linear and nonlinear control system design automation suite is developed in a Java based platform-independent format, which	automation;benchmark (computing);control engineering;control system;evolutionary algorithm;evolutionary computation;hill climbing;java;lazy inheritance;local optimum;mathematical optimization;maxima and minima;modal logic;nonlinear system;numerical analysis;robustness (computer science);simulated annealing;software release life cycle;systems design;systems engineering;web search engine	Wenyuan Feng	2000			control engineering;simulation;engineering;computer-automated design;control theory	EDA	31.129951952576338	-5.641964744764111	175823
4b32186a7b33a58cd2ec1df7ea0c63531f9254a8	simulation and evolutionary optimization of electron-beam lithography with genetic and simplex-downhill algorithms	dimensionalidad;microwave circuit;litografia;lithographie;electronic circuit;topology;lithography hemts modfets laboratories electromagnetic fields microwave technology electrons genetic algorithms optical device fabrication frequency;structure optimization;algoritmo busqueda;high dimensionality;simulation evolutionary optimization electron beam lithography genetic algorithms simplex downhill algorithms microwave electronic circuits search space sd algorithm trial and error steps;search space;lithographie faisceau electron;algorithme recherche;simulation;search algorithm;topologie;dimensionality;simplex downhill algorithm;circuito electronico;indexing terms;algoritmo genetico;genetics;topologia;optimization problem;litografia haz electron;lithography;hybrid approach;circuito hiperfrecuencia;circuit hyperfrequence;electron beam lithography;microwave circuits;dimensionnalite;algorithme genetique;electronic engineering computing electron beam lithography genetic algorithms microwave circuits search problems;algorithme evolutionniste;genetic algorithm;genetic algorithms;algoritmo evolucionista;optimization;search problems;electronic engineering computing;evolutionary algorithm;evolutionary optimization;circuit electronique;fitness function	Genetic and simplex-downhill (SD) algorithms were used for the optimization of the electron-beam lithography (EBL) step in the fabrication of microwave electronic circuits. The definition of submicrometer structures involves complex exposure patterns that are cumbersome to determine experimentally and very difficult to optimize with linear search algorithms due to the high dimensionality of the search space. A SD algorithm was first used to solve the optimization problem. The large number of parameters and the complex topology of the search space proved too difficult for this algorithm, which could not yield satisfactory patterns. A hybrid approach using genetic algorithms (GAs) for global search, and a SD algorithm for further local optimization, was unable to drastically improve the structures optimized with GAs alone. A carefully studied fitness function was used. It contains mechanisms for reduced dependence on process tolerances. Several methods were studied for the selection, crossover, mutation, and reinsertion operators. The GA was used to predict scanning patterns for 100-nm T-gates and gate profiles with asymmetric recess and the structures were fabricated successfully. The simulation and optimization tool can help shorten response times to alterations of the EBL process by suppressing time-consuming experimental trial-and-error steps.	and gate;crossover (genetic algorithm);electron beam tomography;electronic circuit;evolutionary algorithm;experiment;explanation-based learning;fitness function;genetic algorithm;linear search;mathematical optimization;microwave;mutation (genetic algorithm);nor gate;optimization problem;search algorithm;selection (genetic algorithm);simplex algorithm;simulation;software release life cycle	F. Robin;A. Orzati;Esteban Moreno Soriano;Otte Jakob Homan;W. Bachtold	2003	IEEE Trans. Evolutionary Computation	10.1109/TEVC.2002.806166	lithography;mathematical optimization;meta-optimization;genetic algorithm;computer science;artificial intelligence;machine learning;evolutionary algorithm;algorithm;metaheuristic	AI	27.559001896097147	3.3858875696146855	175910
bd495d2c71f53b8a7ae4f7a67c2dcef354ce6ffd	cryptanalysis and improvement of a chaotic image encryption by first-order time-delay system		This paper found that a novel hyper-chaotic based image encryption scheme is vulnerable to chosen plaintext attack. By performing permutation before the vector partition and adding two-round crossover diffusion at the end of the encryption, the security of the original scheme has been greatly improved.		Ming Li;Haiju Fan;Yong Xiang;Yang Li;Yushu Zhang	2018	IEEE MultiMedia	10.1109/MMUL.2018.112142439	human–computer interaction;computer science;encryption;permutation;partition (number theory);crossover;chosen-plaintext attack;cognitive neuroscience of visual object recognition;algorithm;cryptanalysis;chaotic	Crypto	38.596434013421	-8.375171345580153	176175
c9341814f44befb42334b0a58954fac0fd18460b	parallel recombinative simulated annealing: a genetic algorithm	algoritmo paralelo;evaluation performance;empirical distribution;convergence;parallel algorithm;shared memory;performance evaluation;multiprocessor;implementation;memoria compartida;evaluacion prestacion;population size;performance results;global convergence;simulated annealing;algoritmo genetico;parallel recombinative simulated annealing;algorithme parallele;ejecucion;cm 5;convergencia;recuit simule;boltzmann distribution;algorithme genetique;genetic algorithm;recocido simulado;implementation features;multiprocesador;memoire partagee;shared memory multiprocessor;multiprocesseur	Abstract   This paper introduces and analyzes a parallel method of simulated annealing. Borrowing from genetic algorithms, an effective combination of simulated annealing and genetic algorithms, called  parallel recombinative simulated annealing , is developed. This new algorithm strives to retain the desirable asymptotic convergence properties of simulated annealing, while adding the populations approach and recombinative power of genetic algorithms. The algorithm iterates a population of solutions rather than a single solution, employing a binary recombination operator as well as a unary neighborhood operator. Proofs of global convergence are given for two variations of the algorithm. Convergence behavior is examined, and empirical distributions are compared to Boltzmann distributions. Parallel recombinative simulated annealing is amenable to straightforward implementation on SIMD, MIMD, or shared-memory machines. The algorithm, implemented on the CM-5, is run repeatedly on two  deceptive  problems to demonstrate the added  implicit parallelism  and faster convergence which can result from larger population sizes.	genetic algorithm;simulated annealing	Samir W. Mahfoud;David E. Goldberg	1995	Parallel Computing	10.1016/0167-8191(94)00071-H	empirical distribution function;shared memory;mathematical optimization;parallel computing;population size;multiprocessing;genetic algorithm;convergence;simulated annealing;boltzmann distribution;computer science;operating system;parallel algorithm;implementation;adaptive simulated annealing;algorithm	HPC	27.770781641436926	1.5430234459335535	176376
fabde70825772ead0bb8512dc9015d25ee67089b	a configurable generalized artificial bee colony algorithm with local search strategies	infinite horizon configurable generalized artificial bee colony algorithm local search strategies learning based real parameter optimization competition evolutionary computation abc x algorithm configurable algorithm framework algorithm re design general continuous optimization problem;statistics;mathematical model;algorithm design and analysis optimization mathematical model benchmark testing sociology statistics search problems;optimization;search problems;search problems learning artificial intelligence optimisation;algorithm design and analysis;sociology;benchmark testing	In this paper, we apply a generalized artificial bee colony (ABC-X) algorithm to the learning-based real-parameter optimization competition at the 2015 Congress on Evolutionary Computation. The main idea underlying the ABC-X algorithm is to provide a flexible, freely configurable framework for artificial bee colony (ABC) algorithms. From this framework, one can not only instantiate known ABC algorithms but also configure new, previously unseen ABC algorithms that may perform even better than known ABC algorithms. One key advantage of a configurable algorithm framework is that it is adaptable to many different specific problems without requiring necessarily an algorithm re-design. This is relevant if in the application problem repeatedly instances of the problem need to be solved regularly. This situation arises in many practical settings e.g. in power control or other application areas: Routinely a sequence of specific instances of a more general continuous optimization problem arise and these instances have to be solved repeatedly (possibly for an infinite horizon) in the future: in this case the instances of the problem in the sequence will share similarities as they arise from a same source. This is also the situation that is targeted by the learning-based real-parameter optimization competition and which we have also described in our own earlier research.	artificial bee colony algorithm;benchmark (computing);continuous optimization;control theory;evolutionary computation;least squares;local search (optimization);mathematical optimization;optimization problem	Dogan Aydin;Thomas Stützle	2015	2015 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2015.7257008	algorithm design;benchmark;mathematical optimization;computer science;artificial intelligence;machine learning;mathematical model;metaheuristic;statistics;population-based incremental learning	Theory	27.30527477022824	-6.51443221296141	176531
839b14f56847f2672fca5685e7249720fe7cd6df	gaussian adaptation as a unifying framework for continuous black-box optimization and adaptive monte carlo sampling	sampling methods covariance matrices maximum entropy methods monte carlo methods normal distribution optimisation;stopping criteria;continuous black box optimization;search heuristic;optimisation;maximum entropy methods;convergence;covariance matrix adaptation;restart mechanisms;monte carlo sampling;normal distribution;adaptive proposal algorithm gaussian adaptation unifying framework continuous black box optimization adaptive monte carlo sampling continuous optimization search heuristic maximum entropy method covariance matrix adaptation evolution strategy multivariate normal distribution adaptive random walk monte carlo sampler sample point selection parameter settings stopping criteria restart mechanisms metropolis acceptance criterion;metropolis hastings;adaptive monte carlo sampling;covariance matrices;continuous optimization;random walk;multivariate normal distribution;optimization covariance matrix benchmark testing gaussian distribution convergence proposals monte carlo methods;maximum entropy method;evolution strategy;unifying framework;optimization;gaussian adaptation;parameter settings;sampling methods;monte carlo;covariance matrix adaptation evolution strategy;adaptive random walk monte carlo sampler;metropolis acceptance criterion;proposals;gaussian distribution;benchmark testing;monte carlo methods;covariance matrix;sample point selection;adaptive proposal algorithm	We present a unifying framework for continuous optimization and sampling. This framework is based on Gaussian Adaptation (GaA), a search heuristic developed in the late 1960's. It is a maximum-entropy method that shares several features with the (1+1)-variant of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES). The algorithm samples single candidate solutions from a multivariate normal distribution and continuously adapts the first and second moments. We present modifications that turn the algorithm into both a robust continuous black-box optimizer and, alternatively, an adaptive Random Walk Monte Carlo sampler. In black-box optimization, sample-point selection is controlled by a monotonically decreasing, fitness-dependent acceptance threshold. We provide general strategy parameter settings, stopping criteria, and restart mechanisms that render GaA quasi parameter free. We also introduce Metropolis GaA (M-GaA), where sample-point selection is based on the Metropolis acceptance criterion. This turns GaA into a Monte Carlo sampler that is conceptually similar to the seminal Adaptive Proposal (AP) algorithm. We evaluate the performance of Restart GaA on the CEC 2005 benchmark suite. Moreover, we compare the efficacy of M-GaA to that of the Metropolis-Hastings and AP algorithms on selected target distributions.	benchmark (computing);black box;cma-es;continuous optimization;evolution strategy;gaussian adaptation;heuristic;markov chain monte carlo;mathematical optimization;metropolis;metropolis–hastings algorithm;monte carlo method;principle of maximum entropy;sampling (signal processing)	Christian L. Müller;Ivo F. Sbalzarini	2010	IEEE Congress on Evolutionary Computation	10.1109/CEC.2010.5586491	normal distribution;econometrics;mathematical optimization;mathematics;continuous optimization;statistics;monte carlo method	Vision	29.05730220725553	-9.095329381628241	177332
cca7b003987098739658326c9abcf6bfe7334343	bayesian control for concentrating mixed nuclear waste	nuclear waste	A control algorithm for batch processing of mixed waste is proposed based on conditional Gaussian Bayesian networks. The network is compiled during batch staging for real-time re­ sponse to sensor input.	algorithm;batch processing;bayesian network;compiler;disk staging;intelligent control;real-time clock	Robert L. Welch;Clayton Smith	1999			computer science;radioactive waste	ML	38.29006872779537	2.2339283992237386	177387
c8abf75c7a149bf835d0896ba0bf34d4b5137dc7	the comparison of the stochastic algorithms for the filter parameters calculation		In this article the stochastic algorithms (particle swarm algorithm, simulated annealing algorithm, and genetic selection algorithm) applied to the problem of an adaptive calculation of the low pass filter parameters are compared. The data used for the filtration were obtained from the sensor (accelerometer) by implementing the software package for recording a human walking motion. For the algorithms comparison, the math library was implemented. The purpose of the study was to obtain optimum characteristics of moving average method by means of the algorithms described in this paper. The results of numerical experiments have shown that the best results have been obtained using the particle swarm algorithm and the genetic selection algorithm.	algorithm;algorithmic composition	Valeriy Rogoza;Alexey Sergeev	2013		10.1007/978-3-319-01857-7_23	adaptive filter	ML	31.012946176787025	-5.661804720071461	177495
81781d027cd0e860797e5549fc783cb714706025	multi-objective optimization using teaching-learning-based optimization algorithm	multi objective optimization;nondominated sorting;crowding distance;teaching learning based optimization	Two major goals in multi-objective optimization are to obtain a set of nondominated solutions as closely as possible to the true Pareto front (PF) and maintain a well-distributed solution set along the Pareto front. In this paper, we propose a teaching-learning-based optimization (TLBO) algorithm for multi-objective optimization problems (MOPs). In our algorithm, we adopt the nondominated sorting concept and the mechanism of crowding distance computation. The teacher of the learners is selected from among current nondominated solutions with the highest crowding distance values and the centroid of the nondominated solutions from current archive is selected as the Mean of the learners. The performance of proposed algorithm is investigated on a set of some benchmark problems and real life application problems and the results show that the proposed algorithm is a challenging method for multi-objective algorithms.	algorithm;mathematical optimization;multi-objective optimization	Feng Zou;Lei Wang;Xinhong Hei;Debao Chen;Bin Wang	2013	Eng. Appl. of AI	10.1016/j.engappai.2012.11.006	mathematical optimization;artificial intelligence;multi-objective optimization;machine learning	AI	25.28460085166494	-3.140001649250511	177522
f09836cd860fc68bba2a63f9a302b6330e64cb67	unbiased geometry optimisation of morse atomic clusters	minimisation;clusters;089999;minimization;morse;morse global geometry optimisation clusters lennard jones;lattices;putative global minima;cluster optimisation algorithms;faculty of science environment engineering and technology;cambridge cluster database;population based search;search methods;maintenance engineering;directed mutation;mathematical operators;lennard jones;cut operators;global geometry optimisation;morse atomic clusters;pbs algorithm;optimization clustering algorithms lattices maintenance engineering potential energy search methods minimization;larger cluster optimisation unbiased geometry optimisation morse atomic clusters population based search putative global minima cambridge cluster database pbs algorithm cluster optimisation algorithms cut operators paste operators structure niching directed optimisation directed mutation;morse potential;unbiased geometry optimisation;directed optimisation;morse potential atomic clusters mathematical operators minimisation;clustering algorithms;optimization;larger cluster optimisation;paste operators;structure niching;potential energy;information and computing sciences;atomic clusters	This paper presents the results obtained using an unbiased Population Based Search (PBS) for optimising Morse atomic clusters. PBS is able to repeatedly obtain all putative global minima for Morse clusters in the range 5 ≤ N ≤ 80, N = 147,ρ = 3,6,10, 14, as reported in the Cambridge Cluster Database. In addition, putative global minima have been established for Morse clusters in the range 81 ≤ N ≤ 146,ρ = 14. The PBS algorithm incorporates and extends key techniques that have been developed in other cluster optimisation algorithms over the last decade. Of particular importance are the use of cut and paste operators, structure niching and a new operator, Directed Optimisation, which extends the previous concept of directed mutation. In addition, PBS is able to operate in a parallel mode for optimising larger clusters.	algorithm;cut, copy, and paste;local search (optimization);mathematical optimization;maxima and minima;two-phase locking	Wayne Pullan	2010	IEEE Congress on Evolutionary Computation	10.1109/CEC.2010.5586213	maintenance engineering;minimisation;mathematical optimization;combinatorics;lennard-jones potential;computer science;theoretical computer science;potential energy;directed mutagenesis;lattice;mathematics;morse code;cluster analysis;statistics	Vision	29.552471572583773	-7.12952507147794	177788
41d05a042c3bef05b21a0d42cf722b098f458e53	a similarity-based mating scheme for evolutionary multiobjective optimization	pareto front;evolutionary multiobjective optimization;knapsack problem;computer experiment	This paper proposes a new mating scheme for evolutionary multiobjective optimization (EMO), which simultaneously improves the convergence speed to the Pareto-front and the diversity of solutions. The proposed mating scheme is a two-stage selection mechanism. In the first stage, standard fitness-based selection is iterated for selecting a pre-specified number of candidate solutions from the current population. In the second stage, similarity-based tournament selection is used for choosing a pair of parents among the candidate solutions selected in the first stage. For maintaining the diversity of solutions, selection probabilities of parents are biased toward extreme solutions that are different from prototypical (i.e., average) solutions. At the same time, our mating scheme uses a mechanism where similar parents are more likely to be chosen for improving the convergence speed to the Paretofront. Through computational experiments on multi-objective knapsack problems, it is shown that the performance of recently proposed well-known EMO algorithms (SPEA and NSGA-II) can be improved by our mating scheme.	algorithm;experiment;fitness function;iteration;mathematical optimization;multi-objective optimization;pareto efficiency;tournament selection	Hisao Ishibuchi;Youhei Shibata	2003		10.1007/3-540-45105-6_116	mathematical optimization;computer experiment;computer science;artificial intelligence;multi-objective optimization;machine learning;mathematics;knapsack problem	Web+IR	25.854915212542707	-3.76027615979871	177840
bb74a267e0f48b9a5b0243eeead3935ae4ffe5b0	a reinforcement learning based neural multiagent system for control of a combustion process	intelligent control learning artificial intelligence combustion multi agent systems power plants function approximation;air consumption reinforcement learning based neural multiagent system combustion process industrial hard coal combustion process power plant environmental protection nitrogen oxides emission neural function approximators;multi agent system;reinforcement learning;intelligent control;environmental protection;power plant;multi agent systems;power plants;function approximation;process parameters;visual flame observation;learning combustion power generation process control control systems industrial control state estimation power engineering and energy protection nitrogen;nitrogen oxide;learning artificial intelligence;combustion process;combustion	We present a control scheme based on reinforcement learning for an industrial hard-coal combustion process in a power plant. To comply with the great demands on environmental protection, the plant operator is interested in a minimization of the nitrogen oxides emission, while other process parameters have to be kept within predefined limits. To cope with both the tremendous action and situation space of the power plant, we present a multiagent reinforcement system consisting of 4 agents, which are realized by relatively simple neural function approximators. We demonstrate, that our multiagent system was able to significantly reduce the overall air consumption of the real combustion process of the power plant.		Volker Stephan;Klaus Debes;Horst-Michael Groß;F. Wintrich;H. Wintrich	2000		10.1109/IJCNN.2000.859399	power station;simulation;computer science;artificial intelligence;multi-agent system	ML	36.43245009636357	-5.425545853709589	177897
d8cfa05a9319274c75f49b1d5ee288188e19b29b	a hybrid elastic net method for solving the traveling salesman problem	traveling salesman problem;self organization map;elastic net	The purpose of this paper is to present a new hybrid Elastic Net (EN) algorithm, by integrating the ideas of the Self Organization Map (SOM) and the strategy of the gradient ascent into the EN algorithm. The new hybrid algorithm has two phases: an EN phase based on SOM and a gradient ascent phase. We acquired the EN phase based on SOM by analyzing the weight between a city and its converging and non-converging nodes at the limit when the EN algorithm produces a tour. Once the EN phase based on SOM stuck in local minima, the gradient ascent algorithm attempts to fill up the valley by modifying parameters in a gradient ascent direction of the energy function. These two phases are repeated until the EN gets out of local minima and produces the short or better tour through cities. We test the algorithm on a set of TSP. For all instances, the algorithm is showed to be capable of escaping from the EN local minima and producing more meaningful tour than the EN.	elastic map;elastic net regularization;gradient descent;hybrid algorithm;mathematical optimization;maxima and minima;self-organization;times ascent;travelling salesman problem	Wendong Zhang;Yanping Bai	2005	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194005002233	mathematical optimization;computer science;artificial intelligence;travelling salesman problem;algorithm;elastic net regularization	ML	28.558981499525526	-2.4859590257648683	178022
d8fec413c3f9886161794ccf7142f507fe1c2ef5	a novel bat algorithm based on collaborative and dynamic learning of opposite population		As a new kind of swarm intelligence algorithms, bat algorithm is inspired by the bat's echolocation model to search an optimization solution. In this paper, we propose a novel bat algorithm based on collaborative and dynamic learning of opposite population. The proposed algorithm adapts a collaborative strategy to generate the opposite population. Therefore more possible opposite individuals can be dynamically learned and added to the population. We also present elite choices for the current and the opposite population. In this way, the search diversity and search intensity can be achieved. The experimental results of 8 typical test functions show that the proposed algorithm has the characteristics of fast convergence and avoiding falling into local optimal solution.	bat algorithm;distribution (mathematics);mathematical optimization;population;swarm intelligence	Jiashi Yong;Fazhi He;Haoran Li;Weiqing Zhou	2018	2018 IEEE 22nd International Conference on Computer Supported Cooperative Work in Design ((CSCWD))	10.1109/CSCWD.2018.8464759	swarm intelligence;distributed computing;bat algorithm;population;human echolocation;computer science;artificial intelligence;particle swarm optimization;convergence (routing)	Vision	26.785882835183024	-3.940190839899943	178126
b8852a6018dc037f2e58709872794d690406508d	evaluating the mean-variance mapping optimization on the ieee-cec 2014 test suite	optimization shape search problems linear programming convergence heuristic algorithms algorithm design and analysis;offspring creation stage mean variance mapping optimization mvmo sh ieee cec 2014 competition test suite single objective real parameter numerical optimization swarm intelligence scheme multiparent crossover embedded local search strategy;search problems optimisation;swarm intelligence heuristic optimization mean variance mapping optimization single objective optimization	This paper provides a survey on the performance of the hybrid variant of the Mean-Variance Mapping Optimization (MVMO-SH) when applied for solving the IEEE-CEC 2014 competition test suite on Single Objective RealParameter Numerical Optimization. MVMO-SH adopts a swarm intelligence scheme, where each particle is characterized by its own solution archive and mapping function. Besides, multi-parent crossover is incorporated into the offspring creation stage in order to force the particles with worst fitness to explore other sub-regions of the search space. In addition, MVMO-SH can be customized to perform with an embedded local search strategy. Experimental results demonstrate the search ability of MVMO-SH for effectively tackling a variety of problems with different dimensions and mathematical properties.	archive;embedded system;lib sh;local search (optimization);mathematical optimization;swarm intelligence;test suite;the offspring	István Erlich;José L. Rueda;Sebastian Wildenhues;Fekadu Shewarega	2014	2014 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2014.6900516	discrete optimization;extremal optimization;mathematical optimization;multi-swarm optimization;test functions for optimization;meta-optimization;computer science;derivative-free optimization;theoretical computer science;machine learning;continuous optimization;metaheuristic;global optimization	AI	25.18882084788388	-3.3580585584264253	178286
927431342c07456491cc05ed39a485769e1d7ef0	a novel quantum evolutionary algorithm for quadratic knapsack problem	graph theory;optimal solution;evolutionary computation;quadratic knapsack problem;knapsack problems;search space;probability density function;knapsack problems evolutionary computation graph theory;clique quantum evolutinary algorithms quadratic knapsack;operations research;data mining;quantum evolutionary algorithm;undirected graph;objective function;undirected graph quadratic knapsack problem quantum evolutionary algorithm;arrays;knapsack problem;logic gates;quantum;evolutinary algorithms;evolutionary computation upper bound cybernetics usa councils lagrangian functions radar;evolutionary algorithm;quantum computing;quadratic knapsack;clique	The Quadratic Knapsack Problem (QKP) deals with maximizing a quadratic objective function subject to given constraints on the capacity of the Knapsack. We assume all coefficients to be non-negative and all variables to be binary. Solution to QKP generalizes the problem of finding whether a graph contains a clique of given size. We propose in this paper a Novel Quantum Evolutionary Algorithm (NQEA) for QKPs. These algorithms are general enough and can be used for similar subsection of problems. We report in this paper solutions which lie in less than 1% of the optimal solutions. We also show that our algorithm is scalable to much larger problem sizes and is capable of exploiting the search space to its maximum.	coefficient;evolutionary algorithm;knapsack problem;optimization problem;quadratic function;quantum;scalability	Apurva Narayan;Chellapilla Patvardhan	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346276	clique;continuous knapsack problem;mathematical optimization;probability density function;combinatorics;discrete mathematics;logic gate;quantum;computer science;graph theory;change-making problem;evolutionary algorithm;mathematics;quantum computer;knapsack problem;evolutionary computation	Theory	25.106729343877035	1.2034375074593897	178506
30d2e68c469762499b155771475b4267ce53ea27	psw statistical lsb image steganalysis		Steganography is the art and science of producing covert communications by concealing secret messages in apparently innocent media, while steganalysis is the art and science of detecting the existence of these. This manuscript proposes a novel blind statistical steganalysis technique to detect Least Significant Bit (LSB) flipping image steganography. It shows that the technique has a number of major advantages. First, a novel method of pixel color correlativity analysis in Pixel Similarity Weight (PSW). Second, filtering out image pixels according to their statistically detected suspiciousness, thereby excluding neutral pixels from the steganalysis process. Third, ranking suspicious pixels according to their statistically detected suspiciousness and determining the influence of such pixels based on the level of detected anomalies. Fourth, the capability to classify and analyze pixels in three pixel classes of flat, smooth and edgy, thereby enhancing the sensitivity of the steganalysis. Fifth, achieving an extremely high efficiency level of 98.049% in detecting 0.25bpp stego images with only a single dimension analysis.	baillie–psw primality test;least significant bit;pixel;sensor;steganalysis;steganography	Saman Shojae Chaeikar;Mazdak Zamani;Azizah Bt Abdul Manaf;Akram M. Zeki	2016	Multimedia Tools and Applications	10.1007/s11042-016-4273-6	computer vision;internet privacy;computer security	ML	37.82370991977615	-9.050915835734452	178887
a396189a39f3f433725940eaaad0003424579e0d	quadratic unconstrained binary optimization (qubo) on neuromorphic computing system		The problems of Artificial intelligence (AI) naturally maps to NP-hard optimization problems. This trend has significance to achieve human-level computation capability from machines. This computational ability can be achieved by developing evolutionary algorithms or mapping those evolutionary algorithms onto new generation computing systems: Quantum or Neuromorphic hardware. In this paper, we implemented the NP-hard optimization problem called Quadratic Unconstrained Binary Optimization (QUBO) problem for the solution of graph problems on the IBM's Neurosynaptic TrueNorth System. We have experimented on different types of graph problems with different levels of complexities and achieved encouraging results on IBM's Neuromorphic TrueNorth chip. Moreover, there are a set of potential applications have been discussed based on this proposed QUBO solution. Along with the QUBO on quantum annealing, it is the important first step towards the solutions of QUBO on Neuromorphic computing systems.	artificial intelligence;chemical similarity;computation;evolutionary algorithm;graph theory;map;mathematical optimization;np-hardness;neuromorphic engineering;optimization problem;program optimization;prospective search;quadratic unconstrained binary optimization;quantum annealing;simulated annealing;truenorth	Md. Zahangir Alom;Brian Van Essen;Adam T. Moody;David Peter Widemann;Tarek M. Taha	2017	2017 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2017.7966350	machine learning;artificial intelligence;quadratic unconstrained binary optimization;quantum annealing;theoretical computer science;computer science;evolutionary algorithm;computation;recurrent neural network;truenorth;optimization problem;neuromorphic engineering	AI	26.102976034840367	-0.049706182508173304	178959
6a8d67ef8855aed9a7fb73e580697a2c71d1c585	mgpc based on hopfield network and its application in a thermal power unit load system	hopfield model;quadratic programming;predictive control;modele hopfield;optimisation;entrada salida;inertie;commande multivariable;control predictiva;systeme multivariable;optimizacion;reseau electrique;hopfield network;programmation quadratique;modelo hopfield;electrical network;defecto;unidad control;red electrica;commande predictive;hopfield neural nets;intelligence artificielle;unite controle;arithmetique;generalized predictive control;hopfield neural network;potencia termica;input output;carga termica;multivariable control;control proceso;inercia;control multivariable;aritmetica;thermal load;arithmetics;reseau neuronal hopfield;defect;sistema multivariable;retard;control unit;process control;multivariable system;defaut;artificial intelligence;thermal power;programacion cuadratica;optimization;inteligencia artificial;thermal power plant;carga electroenergetica;charge thermique;reseau neuronal;retraso;constrained optimization problem;charge electroenergetique;red neuronal;commande processus;puissance thermique;inertia;neural network;entree sortie;power system load	Multivariable General Predictive Control (MGPC) is an effective application in the control of plant with inertia and delay. But it has some defects such as requiring a large amount of computation online and poor treatment of constraints. This paper introduces Hopfield neural network into MGPC. Firstly, the MGPC was decomposed into several multi-input and single-output systems, then they were converted into several quadratic constrained optimizing problems. Several Hopfield networks were used to solve each quadratic constrained optimizing problem respectively. The Hopfield network has the merits of simple arithmetic and rapid computation. The combination of the two methods can overcome the defects of MGPC. Then the new method was applied to the control of a unit load system in a thermal power plant that is a 2x2 multivariable plant with coupling and constraints. Simulation proved that the new method has effective control performance.	hopfield network	Peng Guo;Taihua Chang	2005		10.1007/11739685_82	inertia;computer science;artificial intelligence;thermal power station;machine learning;process control;control theory;quadratic programming;artificial neural network	HPC	38.287612296593075	-3.800888739482758	179115
49a48300a2bfc6b962e6042f7957e2c31c24a397	a scatter search algorithm for the automatic clustering problem	optimal solution;invertebrata;solution optimale;analyse amas;base donnee;scatter search;algoritmo busqueda;arthropoda;insecto social;algorithme k moyenne;algorithme recherche;search algorithm;database;base dato;prior knowledge;data mining;classification;data clustering;aleatorizacion;cluster analysis;fouille donnee;aculeata;insecta;solucion optima;randomisation;algorithme evolutionniste;algoritmo k media;k means algorithm;global optimization;analisis cluster;algoritmo evolucionista;hymenoptera;insecte social;social insect;evolutionary algorithm;diversification;formicoidea;randomization;diversificacion;busca dato;clasificacion;hybrid algorithm	We present a new hybrid algorithm for data clustering. This new proposal uses one of the well known evolutionary algorithms called Scatter Search. Scatter Search operates on a small set of solutions and makes only a limited use of randomization for diversification when searching for globally optimal solutions. The proposed method discovers automatically cluster number and cluster centres without prior knowledge of a possible number of class, and without any initial partition. We have applied this algorithm on standard and real world databases and we have obtained good results compared to the K-means algorithm and an artificial ant based algorithm, the Antclass algorithm.	cluster analysis;database;diversification (finance);evolutionary algorithm;hybrid algorithm;k-means clustering;local optimum;maxima and minima;randomized algorithm;sql server compact;search algorithm;whole earth 'lectronic link	Rasha Shaker Abdule-Wahab;Nicolas Monmarché;Mohamed Slimane;Moaid A. Fahdil;Hilal H. Saleh	2006		10.1007/11790853_28	ramer–douglas–peucker algorithm;computer science;artificial intelligence;canopy clustering algorithm;machine learning;evolutionary algorithm;data mining;mathematics;fsa-red algorithm;best-first search;cluster analysis;k-medoids;algorithm;difference-map algorithm;global optimization;search algorithm	AI	26.101429514109814	1.3591775747743704	179422
4c28e5fd03f1df7bbb7b0e4e3f7a016e90ea3e6a	convergence analysis of an elitist non-homogeneous genetic algorithm with mutation probability adjusted by a fuzzy controller	probability;genetic algorithms convergence sociology statistics markov processes optimization fuzzy sets;convergence of numerical methods;fuzzy control;probability convergence of numerical methods fuzzy control genetic algorithms;numeric simulations convergence analysis elitist nonhomogeneous genetic algorithm mutation probability fuzzy controller canonical genetic algorithm;genetic algorithms	In recent years, several attempts to improve the efficiency of the Canonical Genetic Algorithm have been presented. The advantage of the elitist non-homogeneous genetic algorithm is that variation of the mutation probabilities permits the algorithm to broaden its search space at the start and restrict it later on, however the way in which the mutation probabilities vary is defined before the algorithm is initiated. To solve this problem various types of controller can be used to adjust such changes. This work presents an elitist non-homogeneous genetic algorithm where the mutation probability is adjusted by a fuzzy controller. Although there are some studies in which fuzzy controllers have been used to adjust the parameters of a genetic algorithm, the goal of this work is that it describes the conditions needed so that a fuzzy controller can provide guaranteed convergence of the genetic algorithm. A generalized example illustrates that the conditions of convergence can be readily achieved. And finally, numeric simulations are used to compare the proposed algorithm with the canonical genetic algorithm.	computer simulation;fuzzy concept;genetic algorithm;iteration;simulation	Andre G. C. Pereira;Jose Arnaldo Frutuoso Roveda;Luiz Amorim Carlos;Viviane Simioli Medeiros Campos;Sandra R. M. Masalskiene Roveda	2013	2013 Joint IFSA World Congress and NAFIPS Annual Meeting (IFSA/NAFIPS)	10.1109/IFSA-NAFIPS.2013.6608368	mathematical optimization;meta-optimization;cultural algorithm;machine learning;genetic representation;mathematics;algorithm;population-based incremental learning	AI	27.681339945282975	-6.6894508250924885	179569
38900c31448e113d20984386bef5a4a95e8503e2	make fast evolutionary programming robust by search step control	sistema activo;search space;strain control;evolutionary programming;robust control;systeme actif;calcul analogique;active system;busca local;local optimum;control robusta;algorithme evolutionniste;algoritmo evolucionista;evolutionary algorithm;optimo local;controle deformation mecanique;coarse grained;commande robuste;local search;recherche locale;optimum local;analog calculus;calculo analogico	It has been found that both evolutionary programming (EP) and fast EP (FEP) could get stuck in local optima on some test functions. Although a number of methods have been developed to solve this problem, nearly all have focused on how to adjust search step sizes. This paper shows that it is not enough to change the step sizes alone. Besides step control, the shape of search space should be changed so that the search could be driven to other unexplored regions without getting stuck in the local optima. A two-level FEP with deletion is proposed in this paper to make FEP robust on finding better solutions in function optimisation. A coarse-grained search in the upper level could lead FEP to generate a diverse population, while a fine-grained search in the lower level would help FEP quickly find a local optimum in a region. After FEP could not make any progress after falling in a local optimum, deletion would be applied to change the search space so that FEP could start a new fine-grained search from the points generated by the coarse-grained search.	evolutionary programming	Yong Huan Liu;Xin Yao	2006		10.1007/11881070_107	evolutionary programming;robust control;local optimum;mathematical optimization;computer science;local search;evolutionary algorithm;calculus;mathematics;algorithm	ML	27.640119338698593	0.6838517302171402	179912
e3077db4c13ac8534ac911bf2636a145d5c8b06b	an evolutionary optimization approach for bulk material blending systems	chevron stacking;bulk material blending;multi objective evolutionary algorithms	Bulk material blending systems still mostly implement static and nonreactive material blending methods like the well-known Chevron stacking. The optimization potential in the existing systems which can be made available using quality analyzing methods as online X-ray fluorescence measurement is inspected in detail in this paper using a multi-objective optimization approach based on steady state evolutionary algorithms. We propose various Baldwinian and Lamarckian repair algorithms, test them on real world problem data and deliver optimized solutions which outperform the standard techniques.	alpha compositing;evolutionary algorithm;hoc (programming language);learning classifier system;mathematical optimization;multi-objective optimization;parameter (computer programming);scalability;simulation;stacking;steady state;whole earth 'lectronic link	Michael P. Cipold;Pradyumn Kumar Shukla;Claus C. Bachmann;Kaibin Bao;Hartmut Schmeck	2012		10.1007/978-3-642-32937-1_48	steady state;computer science;mathematical optimization;evolutionary algorithm	EDA	31.87462981447524	-8.249179024821922	180076
4b83cc0d3130d770a16b0d0667877950d7bbd874	single seekers society (sss): bringing together heuristic optimization algorithms for solving complex problems		Abstract This paper introduces a new metaheuristic, Single Seekers Society (SSS) algorithm, for solving unconstrained and constrained continuous optimization problems. The proposed algorithm aims to simulate the behaviour of a group of people living together, both individually and holistically. The SSS algorithm brings together several single-solution based search algorithms, single seekers, while realizing an information sharing mechanism based on the superposition principle and the reproduction procedure. Each single seeker tries to improve one single solution by using randomly generated parameter set until the stopping condition is reached. Then, the SSS algorithm exchanges partial information between the best solutions identified by the single seekers via the reproduction process. This characteristic generates new solutions to set as the starting point of the single seekers for their next run and provides a satisfactory level of diversification for the SSS algorithm. Additionally, the SSS algorithm determines a target point via the superposition principle at each iteration to make the single seekers to direct their discovery towards this target point. Thus, the SSS algorithm has the feature providing to share the information produced by the single seekers through the reproduction and the superposition principle. The performance of the proposed SSS algorithm is tested on the well-known unconstrained and constrained continuous optimization problems through a set of computational studies. This paper compares SSS algorithm against 27 and 17 different search algorithms on unconstrained and constrained problems, respectively. The experimental results indicate the stability and the effectiveness of the SSS algorithm in terms of quality of produced results, achieved level of convergence and the capability of coping with trapping in local optima and stagnation problems.		Adil Baykasoglu;Alper Hamzadayi;Sener Akpinar	2019	Knowl.-Based Syst.	10.1016/j.knosys.2018.11.016	machine learning;continuous optimization;local optimum;metaheuristic;artificial intelligence;heuristic;search algorithm;computer science;algorithm;superposition principle;sss*;convergence (routing)	DB	27.145321217081914	-3.3754413444095683	180686
c061bcaea6e92e2860e1952c1d716cf6f5ca5230	quantum inspired social evolution (qse) algorithm for 0-1 knapsack problem	qiea;gqa;quantum inspired evolutionary algorithms;social evolution	Social Evolution (SE) algorithm (Pavithr, 2014   [10]  ) is inspired by human interactions and their bias. Generally, human bias influences with whom individuals interact and how they interact. The individual bias may also influence the outcome of interactions to be decisive or indecisive. When the interactions are decisive, the individuals may completely adopt the change. When the interactions are indecisive, individual may consult for a second opinion to further evaluate the indecisive interaction before adopting the change to emerge and evolve (Pavithr, 2014   [10]  ). In the last decade, with the integration of emerging quantum computing with the traditional evolutional algorithms, quantum inspired evolutionary algorithm is evolved (Han and Kim, 2000   [2]  ). Inspired by Q-bit representation and parallelism and the success of the quantum inspired evolutionary algorithms, in this paper, a quantum inspired Social Evolution algorithm (QSE) is proposed by hybridizing Social evolution algorithm with the emerging quantum inspired evolutionary algorithm. The proposed QSE algorithm is studied on a well known 0-1 knapsack problem and the performance of the algorithm is compared with various evolutionary, swarm and quantum inspired evolutionary algorithm variants. The results indicate that, the performance of QSE algorithm is better than or comparable with the different evolutionary algorithmic variants tested with. An experimental study is also performed to investigate the impact and importance of human bias in selection of individuals for interactions, the rate of individuals seeking for second opinion and the influence of selective learning on the overall performance of Quantum inspired Social Evolution algorithm (QSE).	algorithm;knapsack problem;quantum	R. S. Pavithr;G. S. Gursaran	2016	Swarm and Evolutionary Computation	10.1016/j.swevo.2016.02.006	mathematical optimization;artificial intelligence;machine learning;evolutionary algorithm;mathematics	Theory	24.69786607157978	-7.272408727824402	180743
02752583b2c05cc1ad49ff6f6d77af147d264f1c	homogeneous spiking neuromorphic system for real-world pattern recognition	memristor;spiking neural network brain inspired computing machine learning memristor neuromorphic resistive memory silicon neuron spike timing dependent plasticity;brain inspired computing;bepress selected works;neurons memristors neuromorphics cmos integrated circuits computer architecture biological neural networks silicon;neuromorphic;machine learning;brain inspired computing machine learning memristor neuromorphic resistive memory silicon neuron;silicon neuron;resistive memory	A neuromorphic chip that combines CMOS analog spiking neurons and memristive synapses offers a promising solution to brain-inspired computing, as it can provide massive neural network parallelism and density. Previous hybrid analog CMOS-memristor approaches required extensive CMOS circuitry for training, and thus eliminated most of the density advantages gained by the adoption of memristor synapses. Further, they used different waveforms for pre and post-synaptic spikes that added undesirable circuit overhead. Here we describe a hardware architecture that can feature a large number of memristor synapses to learn real-world patterns. We present a versatile CMOS neuron that combines integrate-and-fire behavior, drives passive memristors and implements competitive learning in a compact circuit module, and enables in situ plasticity in the memristor synapses. We demonstrate handwritten-digits recognition using the proposed architecture using transistor-level circuit simulations. As the described neuromorphic architecture is homogeneous, it realizes a fundamental building block for large-scale energy-efficient brain-inspired silicon chips that could lead to next-generation cognitive computing.	artificial neural network;asynchronous i/o;biological neuron model;cmos;cognitive computing;competitive learning;computer architecture;crossbar switch;electronic circuit;gnu nano;integrated circuit;memristor;neuromorphic engineering;operational amplifier;overhead (computing);parallel computing;pattern recognition;semiconductor;simulation;synapse;synapse;synaptic package manager;transistor	Xinyu Wu;Vishal Saxena;Kehan Zhu	2015	IEEE Journal on Emerging and Selected Topics in Circuits and Systems	10.1109/JETCAS.2015.2433552	electronic engineering;memristor;resistive random-access memory;computer science;memistor;theoretical computer science;machine learning;neuromorphic engineering	ML	39.157364476112555	-0.9135280468545923	180963
6c72ec3956a3de0c17196c3bd3722c36f706b5f0	analog vlsi neural networks: implementation issues and examples in optimization and supervised learning	tratamiento paralelo;offset voltages;neural network application;optimisation;learning algorithm;cmos technology;analog vlsi neural networks;aplicacion;traitement parallele;neural networks;optimizacion;learning;supervised learning;neural nets;metodo descenso;gradient method;very large scale integration;implementation;circuito analogico;circuit vlsi;time critical neural nets;temps critique;feedforward networks analog vlsi neural networks time critical neural nets optimization supervised learning cmos vlsi dynamic range offset voltages noise sources gradient descent learning algorithms;gradient descent learning algorithms;vlsi electronic engineering computing learning artificial intelligence neural nets optimisation;critical time;tecnologia mos complementario;aprendizaje;methode gradient;ejecucion;analog circuit;apprentissage;very large scale integration neural networks neural network hardware time factors throughput cmos technology dynamic range voltage noise reduction optimization methods;cmos vlsi;vlsi circuit;time factors;metodo gradiente;gradient descent;feedforward networks;noise reduction;voltage;dynamic range;noise sources;vlsi;analog vlsi;neural network hardware;optimization;electronic engineering computing;circuito vlsi;learning artificial intelligence;reseau neuronal;descent method;technologie mos complementaire;application;hardware implementation;red neuronal;parallel processing;circuit analogique;complementary mos technology;methode descente;neural network;throughput;optimization methods	Many time-critical neural network applications require fully parallel hardware implementations for maximal throughput. We first survey the rich array of technologies that are being pursued, then focus on the analog CMOS VLSI medium. Although analog VLSI holds great promise for implementing dense neural networks in a fully parallel manner, the medium is “messy” in that limited dynamic range, offset voltages, and noise sources all conspire to reduce precision. Many traditional neural models may be difficult to implement in analog technology. In this paper, we examine how neqral networks may be directly implemented in analog VLSI, giving examples of approaches that have been pursued to date. Two important application areas are highlighted Optimization, because neural hardware may offer a speed advantage of orders of magnitude over other methods, and supervised learning, because of the widespread use and generality of gradient-descent learning algorithms as applied to feedforward networks.	algorithm;artificial neural network;cmos;dynamic range;feedforward neural network;gradient descent;machine learning;mathematical optimization;maximal set;program optimization;semantic network;supervised learning;throughput;very-large-scale integration;window of opportunity	Silvio P. Eberhardt;Raoul Tawel;Timothy X. Brown;Taher Daud;Anil Thakoor	1992	IEEE Trans. Industrial Electronics	10.1109/41.170975	electronic engineering;computer science;electrical engineering;artificial intelligence;machine learning;very-large-scale integration;artificial neural network	ML	37.42699391744483	-2.1285287899696983	181061
3d0cc6b0183859a3ebbe1608faf0e6517111f8fb	a dynamic penalty function for constrained optimization		Penalty function methods have been widely used for handling constraints, but it’s still a challenge about how to set the penalty parameter effectively though many related methods have been proposed. In this paper, the penalty parameter is firstly analyzed systematically by introducing four rules. Based on this analysis, a new Dynamic Penalty Function (DyPF) is proposed by adjusting penalty parameter in three different situations during the evolution (i.e., the infeasible situation, the semi-feasible situation, and the feasible situation). The experiments are designed to verify the effectiveness of our newly proposed DyPF. The results show that DyPF presents a better overall performance than other five dynamic or adaptive state-of-the-art methods in the community of constrained evolutionary optimization.	constrained optimization;penalty method;program optimization	Chengyong Si;Jianqiang Shen;Xuan Zou;Yashuai Duo;Lei Wang;Qidi Wu	2015		10.1007/978-3-319-20472-7_28	constrained optimization;augmented lagrangian method;penalty method	ML	24.800005931923	-3.451432573049958	181123
337bef95eb3608f5956ee485b179b83b3ed6568f	a novel coral reefs optimization algorithm for multi-objective problems		In this paper we detail a new algorithm for multi-objective optimization, the Multi-Objective Coral Reefs Optimization (MO-CRO) algorithm. The algorithm is based on the simulation of the coral reefs processes, including corals’ reproduction and fight for the space in the reef. The adaptation to multi-objective problems is an easy process based on domination or non-domination during the process of fight for the space in the reef. The final MO-CRO is an easily implementing and fast algorithm, quite simple, but able to keep diversity in the population of corals (solutions) in a natural way. Experiments in different multi-objective benchmark problems have shown the good performance of the proposed approach in cases with limited computational resources, where we have compared it with the well known NSGA-II algorithm as reference.	benchmark (computing);computation;computational resource;distribution (mathematics);dominating set;evolutionary algorithm;experiment;genetic algorithm;modca;mathematical optimization;multi-objective optimization;optimization problem;simulation;whole earth 'lectronic link	Sancho Salcedo-Sanz;Á. Pastor-Sánchez;D. Gallo-Marazuela;José Antonio Portilla-Figueras	2013		10.1007/978-3-642-41278-3_40	machine learning;coral reef;computer science;algorithm;artificial intelligence;reef;population	AI	25.64712931848328	-4.120696924169076	181582
678d5842a5a82f1155aae65b9dbe57f3f973b5df	a model reference adaptive search method for global optimization	modele reference;modelizacion;cross entropy;estimacion sesgada;metodo adaptativo;optimisation;entropia;convergence;algoritmo busqueda;optimizacion;algorithme recherche;reference model;search algorithm;grupo de excelencia;optimum global;global convergence;methode adaptative;nonlinear;probabilistic approach;global optimum;modelisation;probabilistic model;nondifferentiable;convergencia;estimation of distribution algorithm;ciencias basicas y experimentales;programacion no diferenciable;enfoque probabilista;approche probabiliste;matematicas;entropie;adaptive method;modele probabiliste;global optimization;optimization;programming nondifferentiable;entropy;grupo a;combinatorial optimization;modeling;programming;biased estimation;optimo global;estimation biaisee;cross entropy method;non differentiable programming;programmation non differentiable;modelo probabilista;model reference adaptive search;modelo referencia	Model reference adaptive search (MRAS) for solving global optimization problems works with a parameterized probabilistic model on the solution space and generates at each iteration a group of candidate solutions. These candidate solutions are then used to update the parameters associated with the probabilistic model in such a way that the future search will be biased toward the region containing high-quality solutions. The parameter updating procedure in MRAS is guided by a sequence of implicit probabilistic models we call reference models. We provide a particular algorithm instantiation of the MRAS method, where the sequence of reference models can be viewed as the generalized probability distribution models for estimation of distribution algorithms (EDAs) with proportional selection scheme. In addition, we show that the model reference framework can also be used to describe the recently proposed cross-entropy (CE) method for optimization and to study its properties. Hence, this paper can also be seen as a study on the effectiveness of combining CE and EDAs. We prove global convergence of the proposed algorithm in both continuous and combinatorial domains, and we carry out numerical studies to illustrate the performance of the algorithm.	cross entropy;estimation of distribution algorithm;feasible region;future search;global optimization;iteration;local convergence;mathematical optimization;numerical analysis;statistical model;universal instantiation	Jiaqiao Hu;Michael C. Fu;Steven I. Marcus	2007	Operations Research	10.1287/opre.1060.0367	entropy;mathematical optimization;estimation of distribution algorithm;combinatorial optimization;calculus;mathematics;algorithm;global optimization	ML	30.71957804268087	0.9116624110169695	181681
136929ee5abf65fbf1c68806c961de0ce7e990cb	novel evolutionary methods in engineering optimization - towards robustness and efficiency			evolutionary algorithm;mathematical optimization	István Selek	2009				DB	24.68018574464724	-5.214440357708573	181750
2dd92daa930d676270a25a0891ae95d657c6cc20	parallel bioinspired algorithms in optimization of structures	parallel evolutionary algorithm;artificial immune system	The parallel versions of bioinspired algorithms are presented in the paper. The parallel evolutionary algorithms and artificial immune systems are described. The applications of bioinspired algorithms to optimization of mechanical structures are shown. The numerical tests presented in the paper were computed with use of grid based on Alchemi framework.	algorithm;program optimization	Waclaw Kus;Tadeusz Burczynski	2007		10.1007/978-3-540-68111-3_136	computer science;bioinformatics;theoretical computer science;machine learning;artificial immune system	EDA	26.11028133888268	-0.826519397306477	182008
d8104f760593a9292e94b03e4f52ab6e6ac9c78b	the evolutionary process of image transition in conjunction with box and strip mutation		Evolutionary algorithms have been used in many ways to generate digital art. We study how evolutionary processes are used for evolutionary art and present a new approach to the transition of images. Our main idea is to define evolutionary processes for digital image transition, combining different variants of mutation and evolutionary mechanisms. We introduce box and strip mutation operators which are specifically designed for image transition. Our experimental results show that the process of an evolutionary algorithm in combination with these mutation operators can be used as a valuable way to produce unique generative art.	digital image;evolutionary algorithm;evolutionary art;fitness function;mathematical optimization;stochastic process;whole earth 'lectronic link	Aneta Neumann;Bradley Alexander;Frank Neumann	2016		10.1007/978-3-319-46675-0_29	evolutionary programming;evolutionary music;interactive evolutionary computation;human-based evolutionary computation;java evolutionary computation toolkit;bioinformatics;artificial intelligence;machine learning;evolutionary algorithm	AI	24.63453967504413	-8.404655856554179	182235
34149502ac9dff532f70a8d2a8f389b8dd00caaf	robust modified abc variant (ja-abc5b) for solving economic environmental dispatch (eed)		Artificial bee colony (ABC) algorithm has been widely used to solve various optimization problems due to its simplicity and flexibility besides showing outrageous results in comparison to other optimization algorithms. Nevertheless, ABC has been found to suffer from few limitations such as slow convergence rates and premature convergence tendency. With the motivation to overcome the problem, this work proposes a modified ABC variant referred to as JA-ABC5b with the aim of robust and faster convergence. The proposed ABC variant has been compared with the standard ABC and other existing ABC variants on 27 benchmarks functions and to solve economic environmental dispatch (EED) problem. The results have shown that JA-ABC5b has the best performance in comparison to the standard ABC and selected existing ABC variants in terms of convergence speed as well as the global optimum achievement besides exhibiting robust performance in solving complex real-world optimization problem.		Noorazliza Sulaiman;Junita Mohamad-Saleh;Abdul Ghani Abro	2016		10.1007/978-3-319-42706-5_5	machine learning;artificial intelligence;computer science;global optimum;premature convergence;convergence (routing);optimization problem	AI	26.467981444039292	-4.700215788393108	182301
4c96877741b90e5fd4a9a1ba0dab11398e88a8ab	chinese postman problem in stochastic networks	transportation stochastic processes telecommunication networks;stochastic networks;travel time;chinese postman problem;expected value stochastic networks chinese postman problem euler circuit;transport system;stochastic network;expected value;stochastic processes;transportation;euler circuit;sncpp algorithm chinese postman problem stochastic network transportation system theoretical foundation euler circuit;theoretical foundation;sncpp algorithm;transportation system;telecommunication networks;intelligent networks stochastic processes transportation circuits polynomials stochastic systems legged locomotion roads traveling salesman problems dynamic programming	Transportation systems can be represented by networks with travel times that are stochastic, which motivates the need for widely research on Chinese postman problem in stochastic networks. This paper first gives stochastic networks model and the description of Chinese postman problem in stochastic networks. Next, this paper presents the theoretical foundation of Chinese postman problem in stochastic networks, which justifies the correctness of the algorithm (SNCPP algorithm). The calculation of expected value of Euler circuit and SNCPP algorithm are given. Finally, this paper also illustrates how the algorithm can be implemented	algorithm;correctness (computer science);euler;eulerian path;route inspection problem;stochastic neural network;stochastic process	Guozhen Tan;Xiaoting Cui;Yong Zhang	2005	Joint International Conference on Autonomic and Autonomous Systems and International Conference on Networking and Services - (icas-isns'05)	10.1109/ICAS-ICNS.2005.31	stochastic process;transport;mathematical optimization;simulation;route inspection problem;expected value;statistics;eulerian path	Robotics	31.554329085039488	3.903126078789299	182343
8fde3322906a48e4aed58bc3b315e3649bea633a	symbolic bucket elimination for piecewise continuous constrained optimization		Bucket elimination and its approximation extensions have proved to be effective techniques for discrete optimization. This paper addresses the extension of bucket elimination to continuous constrained optimization by leveraging the recent innovation of the extended algebraic decision diagram (XADD). XADDs support symbolic arithmetic and optimization operations on piecewise linear or univariate quadratic functions that permit the solution of continuous constrained optimization problems with a symbolic form of bucket elimination. The proposed framework is an efficient alternative for solving optimization problems with low tree-width constraint graphs without using a big-M formulation for piecewise, indicator, or conditional constraints. We apply this framework to difficult constrained optimization problems including XOR’s of linear constraints and temporal constraint satisfaction problems with “repulsive” preferences, and show that this new approach significantly outperforms Gurobi. Our framework also enables symbolic parametric optimization whose closed-form solution cannot be computed with tools like Gurobi, where we demonstrate a final novel application to parametric optimization of learned Relu-based deep neural networks.	approximation;artificial neural network;constrained optimization;constraint graph;constraint satisfaction problem;deep learning;discrete optimization;exclusive or;fetch-and-add;gurobi;heuristic;influence diagram;local consistency;mathematical optimization;piecewise linear continuation;quadratic function;treewidth	Zhijiang Ye;Buser Say;Scott Sanner	2018		10.1007/978-3-319-93031-2_42	mathematical optimization;discrete mathematics;piecewise;constraint graph;constrained optimization;piecewise linear function;computer science;discrete optimization;influence diagram;constraint satisfaction problem;optimization problem	AI	35.35476935118381	-6.705372974543349	182772
0a5216aa3eac0c1c87726771fdd7439cb4dfd6a8	genetic algorithms in application to the geometry optimization of nanoparticles	nanoparticles;genetic algorithm;genetic algorithms;atomic clusters	Applications of genetic algorithms to the global geometry optimization problem of nanoparticles are reviewed. Genetic operations are investigated and importance of phenotype genetic operations, considering the geometry of nanoparticles, are mentioned. Other efficiency improving developments such as floating point representation and local relaxation are described broadly. Parallelization issues are also considered and a recent parallel working single parent Lamarckian genetic algorithm is reviewed with applications on carbon clusters and SiGe core-shell structures.	automatic parallelization;energy minimization;genetic algorithm;linear programming relaxation;mathematical optimization;optimization problem;parallel computing;silicon-germanium	Nazim Dugan;Sakir Erkoç	2009	Algorithms	10.3390/a2010410	mathematical optimization;meta-optimization;genetic algorithm;computer science;bioinformatics;theoretical computer science;machine learning	HPC	30.645214832512696	-8.25749737877431	182827
caab79718667a3d633a8a30966a03ff178700cb3	fractal intelligent privacy protection in online social network using attribute-based encryption schemes		While the online social network (OSN) has brought much convenience to users, there are still some serious problems, such as personal privacy leaks. Today, OSN security and privacy protection are one of the most important focuses of the research. In this paper, we present an intelligent privacy protection approach to solve problems of security and privacy protection in OSNs. First, the proposed algorithm combines a neural network with a hybrid hierarchy genetic algorithm and radial basis function, which is used to construct a prediction model of OSN security. Then, a support vector machine is applied to preprocess information of the OSN, and the attribute-based encryption scheme is adopted to encrypt the OSN information. Finally, a particle swarm optimization algorithm is used to improve OSN security and privacy protection. The experimental results demonstrate the effectiveness of the proposed method.	artificial neural network;attribute-based encryption;cipher;ciphertext;cluster analysis;coefficient;computation;entropy (information theory);fractal;genetic algorithm;graphical user interface;information privacy;mathematical optimization;particle swarm optimization;preprocessor;radial (radio);radial basis function network;social network;spectral leakage;support vector machine;the matrix	Wei Wei;Shuai Liu;Wenjia Li;Dingzhu Du	2018	IEEE Transactions on Computational Social Systems	10.1109/TCSS.2018.2855047	genetic algorithm;artificial intelligence;machine learning;encryption;support vector machine;artificial neural network;computer science;hierarchy;social network;attribute-based encryption;particle swarm optimization	Security	36.7479213449192	-7.992901964613031	182837
d6e5ce8ca23cd584c8bd2897a7fb273c7521fb75	selection intensity in asynchronous cellular evolutionary algorithms	generic model;evolutionary algorithm	This paper presents a theoretical study of the selection pressure in asynchronous cellular evolutionary algorithms (cEAs). This work is motivated by the search for a general model for asynchronous update of the individuals in a cellular EA, and by the necessity of better accuracy beyond what existing models of selection intensity can provide. Therefore, we investigate the differences between the expected and actual values of the selection pressure induced by several asynchronous update policies, and formally characterize the update dynamics of each variant of the algorithm. New models for these two issues are proposed, and are shown to be more accurate (lower fit error) than previous ones.	cellular evolutionary algorithm;windows update	Mario Giacobini;Enrique Alba;Marco Tomassini	2003		10.1007/3-540-45105-6_107	mathematical optimization;simulation;computer science;artificial intelligence;theoretical computer science;machine learning;evolutionary algorithm	AI	26.832856261538808	-7.924111691488956	183001
6d65770516063ef12a65aca7bb61e40fd27b3397	modern metaheuristics for function optimization problem	artificial immune system;function optimization;objective function;particle swarm optimizer;genetic algorithm	This paper compares the behaviour of three metaheuristics for the function optimization problem on a set of classical functions handling a large number of variables and known to be hard. The first algorithm to be described is Particle Swarm Optimization (PSO). The second one is based on the paradigm of Artificial Immune System (AIS). Both algorithms are then compared with a Genetic Algorithm (GA). New insights on how these algorithms behave on a set of difficult objective functions with a large number of variables are provided.	artificial immune system;genetic algorithm;mathematical optimization;metaheuristic;optimization problem;particle swarm optimization;programming paradigm;software release life cycle	Marek Pilski;Pascal Bouvry;Franciszek Seredynski	2005		10.1007/3-540-32392-9_54	biogeography-based optimization;mathematical optimization;multi-swarm optimization;ant colony optimization algorithms;meta-optimization;genetic algorithm;parallel metaheuristic;computer science;derivative-free optimization;artificial intelligence;machine learning;artificial immune system;metaheuristic	ML	25.285395377240523	-4.775904088672564	183534
dac4ff069fee3c971d9beabafeae35a0f2f7c0a7	chaotic image encryption system using phase-magnitude transformation and pixel substitution	image encryption;chaotic image encryption;phase magnitude transformation;pixel substitution;bernoulli and tent map;single domain;time domain;frequency domain;correlation coefficient;computer simulation	We proposed an algorithm to encrypt an image in hybrid domain, frequency and time domains. The proposed method is a private key encryption system with two main units, chaotic phase-magnitude transformation unit and chaotic pixel substitution unit. Chaotic phase-magnitude transformation unit works in frequency domain and a 2-D DFT is performed on the plain image to change the domain. A chaotic function, the tent map, is used to generate the pseudo random image, which are combined with the plain image in frequency domain. Chaotic pixel substitution unit works in time domain Bernoulli map is applied to produce another pseudo random image that is mixing with the encrypted image nonlinearly. The performance of the proposed chaotic image encryption system is analysed using a computer simulation. The distribution of histogram of encrypted image is uniform. Chi-square value for encrypted image of our proposed method is considerably low. The MSE of the proposed encrypted image is big enough. The correlation coefficients of the proposed encrypted image in all three directions are sufficiently small. The total key length is large enough to resist the proposed system against any brute-force attack. The proposed scheme is robust against chosen plaintext attacks too. The proposed chaotic image encryption system, which is used frequency and time domain together, is S. Etemadi Borujeni ( ) Computer Engineering Department, Faculty of Engineering, University of Isfahan, 8174673441 Isfahan, Iran e-mail: etemadi@eng.ui.ac.ir M. Eshghi Computer Engineering Department, Faculty of Computer and Electrical Engineering, Shahid Beheshti University, Evin, 1983963113 Tehran, Iran e-mail: m-eshghi@sbu.ac.ir more secure than most of single domain image encryption systems.	algorithm;bernoulli polynomials;brute-force attack;chi;circuit complexity;coefficient;computer engineering;computer simulation;digital image;dyadic transformation;electrical engineering;email;encryption;key (cryptography);key size;key space (cryptography);matlab;mean squared error;nonlinear system;pixel;plaintext;pseudorandomness;public-key cryptography;tent map;time series	Shahram Etemadi Borujeni;Mohammad Eshghi	2013	Telecommunication Systems	10.1007/s11235-011-9458-8	computer simulation;single domain;computer vision;feature detection;discrete mathematics;time domain;computer science;theoretical computer science;mathematics;frequency domain	Vision	38.83008050936078	-8.736829934545272	183635
1c1260abdbe8edfe2cc129652df37d2ac2a23254	an ancestor based extension to differential evolution (ancde) for single-objective computationally expensive numerical optimization	evolutionary computation;standards;vectors evolutionary computation numerical analysis;intergeneration difference vector differential evolution ancestror archive;genetics;sociology statistics standards genetics optimization evolutionary computation java;stochastic rates ancestral differential evolution algorithm ancde algorithm inter generational difference vectors cec2015 bound constrained single objective computationally expensive numerical optimization problems ancde best 1 bin local optima global optimum ancestral cache;statistics;optimization;computer science;sociology;java	This paper presents the Ancestral Differential Evolution (AncDE) algorithm, which extends the standard Differential Evolution (DE) algorithm by adding an archive of recently discarded ancestors. AncDE adds the ability to occasionally compute difference vectors between current and archived solutions, using these inter-generational difference vectors in place of traditional difference vectors. Results for AncDE are presented for the CEC2015 Bound Constrained Single-Objective Computationally Expensive Numerical Optimization Problems using AncDE/best/1/bin. Summary results are included for standard DE for comparison purposes and these show that AncDE generally outperforms standard DE. These results suggest that the inter-generational difference vectors can help overcome some local optima, leading to faster convergence towards the global optimum. AncDE involves the very small overhead of storing and updating the ancestral cache. This paper introduces two empirically determined stochastic rates; one for updating the ancestral cache and the other for using an ancestral difference vector in place of the normal difference vector.	algorithm;archive;baseline (configuration management);cpu cache;differential evolution;gene regulatory network;global optimization;local optimum;mathematical optimization;maxima and minima;overhead (computing)	Rushikesh Sawant;Donagh Hatton;Diarmuid P. O'Donoghue	2015	2015 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2015.7257293	mathematical optimization;computer science;bioinformatics;artificial intelligence;machine learning;mathematics;java;algorithm;statistics;evolutionary computation	Vision	27.8787423219245	-6.418981353730935	183683
ce640045b7e23467e8484e93a147bc9336165bfb	hybrid particle swarm optimization with biased mutation applied to load flow computation in electrical power systems	evolutionary computation;particle swarm optimization;load flow;electrical power systems;artificial intelligence	This paper presents the implementation of a Hybrid Particle Swarm Optimization with Biased Mutation (HPSOBM) algorithm to solve the load flow computation in electrical power systems. The load flow study obtains the system status in the steady-state and it is widely used in the power system operation, planning and control. The proposed methodology is applied in a different computational model, which is based on the minimization of the power mismatches in the system buses. This new model searches for a greater convergence, and also a larger application in comparison with traditional numerical methods. In order to illustrate the proposed algorithm some simulations were conducted using the IEEE 14 bus system.	algorithm;computation;computational model;ibm power systems;numerical method;particle swarm optimization;simulation;steady state	Camila Paes Salomon;Maurilio Pereira Coutinho;Germano Lambert-Torres;Cláudio Lima Ferreira	2011		10.1007/978-3-642-21515-5_70	mathematical optimization;multi-swarm optimization;power-flow study;computer science;artificial intelligence;theoretical computer science;electric power system;particle swarm optimization;evolutionary computation	EDA	33.60664475623109	-5.049003720201282	183972
e0345369c80e66cdf4297021839a65e3f2d1b529	an ant algorithm for the conformational analysis of flexible molecules	conformational analysis;ant algorithm;continuous search spaces;optimization	Originally, the ant system was developed for optimization in discrete search spaces such as the traveling salesman problem. We detail our adaptation of the algorithm to optimization in the continuous search space of conformational analysis. The parameters of the algorithm were tuned using a simple test molecule, undecane, and a drug molecule, imatinib. The algorithm is further tested on four more drug or drug-like molecules, on vitamin A and on alanine tetrapeptide.		Frits Daeyaert;Marc R. de Jonge;Lucien M. H. Koymans;H. Maarten Vinkers	2007	Journal of computational chemistry	10.1002/jcc.20595	chemistry;mathematical optimization;molecule;travelling salesman problem;ant;tetrapeptide;algorithm;undecane	ML	29.854780643926954	-8.29467761187259	184259
28d96e8c222500683482ab71ef1b42f2f32dd64b	a double-module immune algorithm for multi-objective optimization problems	differential evolution;immune algorithm;multi objective optimization;double module framework;期刊论文	The framework of the proposed algorithm with two evolutionary modules. A novel multi-objective immune algorithm with double modules is presented.The first module is aimed at enhancing each objective independently.The second module strengthens all the objectives simultaneously.The double modules are cooperatively evolved to tackle MOPs. Multi-objective optimization problems (MOPs) have become a research hotspot, as they are commonly encountered in scientific and engineering applications. When solving some complex MOPs, it is quite difficult to locate the entire Pareto-optimal front. To better settle this problem, a novel double-module immune algorithm named DMMO is presented, where two evolutionary modules are embedded to simultaneously improve the convergence speed and population diversity. The first module is designed to optimize each objective independently by using a sub-population composed with the competitive individuals in this objective. Differential evolution crossover is performed here to enhance the corresponding objective. The second one follows the traditional procedures of immune algorithm, where proportional cloning, recombination and hyper-mutation operators are operated to concurrently strengthen the multiple objectives. The performance of DMMO is validated by 16 benchmark problems, and further compared with several multi-objective algorithms, such as NSGA-II, SPEA2, SMSEMOA, MOEA/D, SMPSO, NNIA and MIMO. Experimental studies indicate that DMMO performs better than the compared targets on most of test problems and the advantages of double modules in DMMO are also analyzed.	algorithm;mathematical optimization;multi-objective optimization	Zhengping Liang;Ruizhen Song;Qiuzhen Lin;Zhihua Du;Jianyong Chen;Zhong Ming;Jianping Yu	2015	Appl. Soft Comput.	10.1016/j.asoc.2015.06.022	differential evolution;mathematical optimization;simulation;artificial intelligence;multi-objective optimization;mathematics	Logic	24.612550386418498	-3.70510762827922	184599
774dfa33d23f360fdb224fc9ba5a81a577587301	mh-moea: a new multi-objective evolutionary algorithm based on the maximin fitness function and the hypervolume indicator		In this paper, we propose an approach that combines a modified version of the maximin fitness function and the hypervolume indicator for selecting individuals into a Multi-Objective Evolutionary Algorithm (MOEA). Our proposed selection mechanism is incorporated into a MOEA which adopts the crossover and mutation operators of the Nondominated Sorting Genetic Algorithm-II (NSGA-II), giving rise to the so-called “Maximin-Hypervolume Multi-Objective Evolutionary Algorithm (MH-MOEA)”. Our proposed MH-MOEA is validated using standard test problems taken from the specialized literature, using from three to six objectives. Our results are compared with respect to those produced by MC-MOEA (which is based on the maximin fitness function and a clustering technique), MOEA/D using Penalty Boundary Intersection (PBI), which is based on decomposition and iSMS-EMOA (which is based on the hypervolume indicator). Our preliminary results indicate that our proposed MH-MOEA is a good alternative to solve multi-objective optimization problems having both low dimensionality and high dimensionality in objective function space.	evolutionary algorithm;fitness function;moea framework;minimax;modified huffman coding	Adriana Menchaca-Mendez;Carlos A. Coello Coello	2014		10.1007/978-3-319-10762-2_64	fitness approximation	AI	24.75800661749951	-4.441095393755687	184738
c28204754e16d949f0b41e3b4c8700d18c25d590	colony optimization algorithm applied to simplification of closed linear objects	ant colony optimisation;map generalization closed linear objects ant colony optimization simplification;forest land closed linear objects map generalization ant colony optimization algorithm automated simplification long term taboo list tabu search algorithm;optimization vectors linear programming ant colony optimization algorithm design and analysis educational institutions search problems;cartography;search problems;search problems ant colony optimisation cartography	In map generalization, it is important to simplify closed linear objects. In fact, an area object can be represented by its boundary in vector, such as lakes, land use, etc. So shape simplification of area objects can make full use of the algorithms for simplifying closed linear objects. According to the purpose of simplification for boundary line of land use, the standards on map production and basic principles of ant colony optimization algorithm, the simplification of closed linear objects is explained as a kind of combinatorial optimization problem. The algorithm of automated simplification using ant colony optimization algorithm is put forward and the key steps are given. The algorithm not only sets up objective function, constraints, heuristic information, pheromones and so on, but also introduces long-term taboo list with the idea of tabu search algorithm is merged into the simplification of linear objects. In order to demonstrate that the proposed algorithm to the automatic simplification of closed linear objects is feasible and effective, the algorithm will be tested for boundary line of forest land, and the results will be compared with the Douglas algorithm.	ant colony optimization algorithms;cartographic generalization;combinatorial optimization;contour line;evolutionary algorithm;heuristic (computer science);level of detail;mathematical optimization;optimization problem;positive feedback;robustness (computer science);search algorithm;shortest path problem;symbolic computation;tabu search	Huake Hu;Chunyan Zheng;Huiqiong Xia	2013	2013 21st International Conference on Geoinformatics	10.1109/Geoinformatics.2013.6626118	mathematical optimization;ant colony optimization algorithms;meta-optimization;artificial intelligence;machine learning;mathematics;metaheuristic	Robotics	26.228979358616478	0.45473151501755654	184831
61fd1a7872b526002c704c9a905b1f08794f7e29	a simplex method-based salp swarm algorithm for numerical and engineering optimization		Salp Swarm Algorithm (SSA) is a novel meta-inspired optimization algorithm. The main inspiration of this algorithm is the swarming behavior of salps when navigating and foraging in the ocean. This algorithm has already displayed the strong ability in solving some engineering design problems. This paper proposes an improved salp swarm algorithm based on simplex method named as simplex method-based salp swarm algorithm (SMSSA). The simplex method is a stochastic variant strategy, which increases the diversity of the population and enhances the local search ability of the algorithm. This approach helps to achieve a better trade-off between the exploration and exploitation ability of the SSA and makes SSA more robust and faster. The proposed algorithm is compared with other four meta-inspired algorithms on 4 benchmark functions. The proposed algorithm is also applied to one real-life constrained engineering design problems. The experimental results have demonstrated the MSSSA performs better than the other competitive meta-inspired algorithms.	numerical method;program optimization;simplex algorithm;swarm	Dengyun Wang;Yongquan Zhou;Shengqi Jiang;Xin Liu	2018		10.1007/978-3-030-00828-4_16	swarm behaviour;global optimization;engineering optimization;salp;engineering design process;local search (optimization);algorithm;population;computer science;simplex algorithm	DB	26.299979899451834	-4.18433972016513	185141
af4ecd34cec78f08c43e601857f4f461ebfe0746	towards heuristic web services composition using immune algorithm	mutation method;heuristic web services composition;convergence;clonal selection;immune algorithm;natural computing;heuristic programming;web services encoding convergence heuristic algorithms application software concrete genetic mutations vaccines telecommunication computing immune system;natural computing methods;web service;web service composition;conference paper;evolution biology;heuristic algorithms;web services;web services heuristic programming;optimization;mutation method heuristic web services composition immune algorithm natural computing methods;quality of service;encoding	One of the main benefits of web services is the dynamic composability, however how to achieve this is one of the current research challenges. Web service composition has been studied and, amongst other methods, the use of natural computing methods has been proposed previously. In this paper, we address the need for a fast response when computing the most suitable sequence of services. In particular, we propose a novel heuristic immune algorithm with an efficient encoding and mutation method. The algorithm involves two steps: an immune selection operation, which is maintaining antibody population diversity and a clonal selection. The use of a vaccine during the evolution provides heuristic information that accelerates the convergence. Our experimental results illustrate that the proposed heuristic immune algorithm is very effective in improving the convergence speed.	algorithm;experiment;heuristic;heuristic (computer science);mathematical optimization;np-completeness;natural computing;service composability principle;web service	Jiuyun Xu;Stephan Reiff-Marganiec	2008	2008 IEEE International Conference on Web Services	10.1109/ICWS.2008.16	web service;computer science;bioinformatics;theoretical computer science;law;world wide web	Robotics	27.599884384564252	-9.388920713886662	185247
35cd8c14ea0d88e3d850012711980da84492d864	influence of the crossover operator in the performance of the hybrid taguchi ga	evolutionary computation;genetic algorithms arrays algorithm design and analysis statistical analysis optimization biological cells evolutionary computation;arrays;biological cells;statistical analysis;statistical analysis crossover operator hybrid taguchi ga hybrid taguchi genetic algorithm continuous optimization numerical optimization problem binary representation chromosomes;genetic algorithms;optimization;taguchi methods genetic algorithms statistical analysis;taguchi methods;algorithm design and analysis	This paper investigates the influence of different crossover operators on the efficiency of the hybrid Taguchi genetic algorithm and aims to provide guidelines for algorithm's usage in continuous optimization. We examine the hybrid Taguchi genetic algorithm (HTGA) with 8 different crossover operators and apply it to 15 benchmark numerical optimization problems. The implementation uses binary representation which maps chromosomes to values in real domain with arbitrary precision. Different crossover operators are used with the HTGA and a detailed statistical analysis is performed to evaluate their performance. The results indicate that the HTGA obtains better results with crossover operators different than the ones commonly reported in literature.	approximation algorithm;arbitrary-precision arithmetic;benchmark (computing);binary number;continuous optimization;experiment;fitness proportionate selection;genetic algorithm;map;mathematical optimization;numerical analysis;optimization problem;taguchi methods	Stjepan Picek;Marin Golub;Domagoj Jakobovic	2012	2012 IEEE Congress on Evolutionary Computation	10.1109/CEC.2012.6256530	algorithm design;mathematical optimization;meta-optimization;taguchi methods;genetic algorithm;computer science;artificial intelligence;machine learning;statistics;evolutionary computation	AI	26.80722153931478	-7.055306792484604	185822
85f3c177677ec1cc1de07e91c5db6a27fb9145b1	exploring extended particle swarms: a genetic programming approach	particle swarm;fitness landscape;optimal solution;swarm intelligence;genetic program;genetic programming;automatic generation;particle swarm optimisation	Particle Swarm Optimisation (PSO) uses a population of particles that fly over the fitness landscape in search of an optimal solution. The particles are controlled by forces that encourage each particle to fly back both towards the best point sampled by it and towards the swarm's best point, while its momentum tries to keep it moving in its current direction.Previous research started exploring the possibility of evolving the force generating equations which control the particles through the use of genetic programming (GP).We independently verify the findings of the previous research and then extend it by considering additional meaningful ingredients for the PSO force-generating equations, such as global measures of dispersion and position of the swarm. We show that, on a range of problems, GP can automatically generate new PSO algorithms that outperform standard human-generated as well as some previously evolved ones.	algorithm;genetic programming;mathematical optimization;particle swarm optimization;phase-shift oscillator;population	Riccardo Poli;Cecilia Di Chio;William B. Langdon	2005		10.1145/1068009.1068036	genetic programming;mathematical optimization;multi-swarm optimization;simulation;fitness landscape;swarm intelligence;computer science;artificial intelligence;machine learning;particle swarm optimization	Graphics	27.743274559608313	-3.873329500067072	185940
c3999f47269e3969798e8181256188da40975de5	non-dominated sorting moth flame optimization (ns-mfo) for multi-objective problems	multi objective optimization;moth flame optimization algorithm;multi objective engineering design problems	This paper proposes an effective non-dominated moth-flame optimization algorithm (NS-MFO) method for solving multi-objective problems. Most of the multi-objective optimization algorithms use different search techniques inspired by different optimization techniques such as genetic algorithms, differential evolutions, particle swarm optimization, cuckoo search etc., but search techniques of recently developed metaheuristics have hardly been investigated. Non-dominated moth-flame optimization algorithm (NS-MFO) is based on the search technique of moth-flame optimization algorithm (MFO) algorithm and utilizes the elitist non-dominated sorting and crowding distance approach for obtaining different non domination levels and to preserve the diversity among the optimal set of solutions respectively. The effectiveness of the method is measured by implementing it on multi-objective benchmark problems and multi-objective engineering design problems with distinctive features. It is shown in this paper that this method effectively generates the Pareto front and also, this method is easy to implement and algorithmically simple.	mathematical optimization;sorting	Vimal J. Savsani;Mohamed A. Tawhid	2017	Eng. Appl. of AI	10.1016/j.engappai.2017.04.018	mathematical optimization;engineering optimization;artificial intelligence;multi-swarm optimization;imperialist competitive algorithm;machine learning;computer science;metaheuristic;meta-optimization;probabilistic-based design optimization;multi-objective optimization;test functions for optimization	AI	25.24097829678152	-4.127422983880361	185946
6155d367dbcb2a5f878929b1eb7229c8ef4fb649	a rollout algorithm framework for heuristic solutions to finite-horizon stochastic dynamic programs	dynamic programming;approximate dynamic programming;rollout algorithm;stochastic dynamic programming	Rollout algorithms have enjoyed success across a variety of domains as heuristic solution procedures for stochastic dynamic programs (SDPs). However, because most rollout implementations are closely tied to specific problems, the visibility of advances in rollout methods is limited, thereby making it difficult for researchers in other fields to extract general procedures and apply them to different areas. We present a rollout algorithm framework to make recent advances in rollout methods more accessible to researchers seeking heuristic policies for large-scale, finite-horizon SDPs. We formalize rollout variants exploiting the preand postdecision state variables as a means of overcoming computational limitations imposed by large state and action spaces. We present a unified analytical discussion, generalizing results from the literature and introducing new results that relate the performance of the rollout variants to one another. Relative to the literature, our policy-based approach to presenting and proving results makes a closer connection to the underpinnings of dynamic programming. Finally, we illustrate our framework and analytical results via application to a dynamic and stochastic multi-compartment knapsack problem.	computation;decision problem;dynamic programming;greedy algorithm;heuristic (computer science);knapsack problem;multi-compartment model;semiconductor industry;vehicle routing problem	Justin C. Goodson;Barrett W. Thomas;Jeffrey W. Ohlmann	2017	European Journal of Operational Research	10.1016/j.ejor.2016.09.040	stochastic programming;mathematical optimization;computer science;theoretical computer science;dynamic programming;mathematics;management science	AI	31.15673628868356	1.8356814784672635	186209
d63e18210ba37375aec05b0845edc090cd6eafe3	solving radial topology constrained problems with evolutionary algorithms	optimisation sous contrainte;constrained optimization;information structure;algorithm analysis;search space;genetics;optimisation combinatoire;optimizacion con restriccion;resolucion problema;network topology;large scale;planification reseau;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;analyse algorithme;evolutionary algorithm;combinatorial optimization;analisis algoritmo;problem solving;resolution probleme;optimizacion combinatoria	We report key algorithmic specific features involved in the evolutionary radial network problem solution. We focus on the dimensionality problem of large-scale networks and on the singularities of the radial topology search space. We (1) report the difficulties of the canonical genetic algorithm in handling network topology constraints, and (2) present both the genotype information structure and the recombination operator to overcome such difficulties. The proposed recombination operator processes genetic information as meaningful topological structures, and turns radiality and connectivity into genetic transmissible properties. Results are presented to illustrate the difference between the canonical approach and the approach taken.	evolutionary algorithm;radial (radio)	Pedro M. S. Carvalho;Luis A. F. M. Ferreira;Luis M. F. Barruncho	1998		10.1007/3-540-48873-1_9	mathematical optimization;constrained optimization;combinatorics;genetic algorithm;combinatorial optimization;computer science;evolutionary algorithm;mathematics;extension topology;network topology;algorithm	Theory	26.660381007388562	1.853727183847273	186570
18d9d77b399a7d15b70514932e18d000066d9a22	fast building block assembly by majority vote crossover	vertex cover;majority vote crossover;jump;island model;run time analysis;evolutionary algorithm	Different works have shown how crossover can help with building block assembly. Typically, crossover might get lucky to select good building blocks from each parent, but these lucky choices are usually rare. In this work we consider a crossover operator which works on three parent individuals. In each component, the offspring inherits the value present in the majority of the parents; thus, we call this crossover operator majority vote. We show that, if good components are sufficiently prevalent in the individuals, majority vote creates an optimal individual with high probability. Furthermore, we show that this process can be amplified: as long as components are good independently and with probability at least 1/2+δ, we require only O(log 1/δ + log log n) successive stages of majority vote to create an optimal individual with high probability!  We show how this applies in two scenarios. The first scenario is the Jump test function. With sufficient diversity, we get an optimization time of O(n log n) even for jump sizes as large as O(n(1/2-ε)). Our second scenario is a family of vertex cover instances. Majority vote optimizes this family efficiently, while local searches fail and only highly specialized two-parent crossovers are successful.	crossover (genetic algorithm);distribution (mathematics);fitness function;genetic algorithm;global optimization;local search (optimization);mv-algebra;mathematical optimization;maxima and minima;randomness;the offspring;vertex cover;with high probability	Tobias Friedrich;Timo Kötzing;Martin S. Krejca;Samadhi Nallaperuma;Frank Neumann;Martin Schirneck	2016		10.1145/2908812.2908884	simulation;vertex cover;computer science;artificial intelligence;evolutionary algorithm;mathematics;algorithm	ML	28.238679095892017	-0.19686907112297736	186685
ac77617f2da1d0a2ea5da04436a192431b9492e4	an adaptive prudent-daring evolutionary algorithm for noise handling in on-line pmsm drive design	evolutionary computation;synchronous motor drives control system synthesis evolutionary computation machine control optimal control permanent magnet motors;noisy data;permanent magnet synchronous motor;statistical test;permanent magnet motors;machine control;optimal control;control system synthesis;evolutionary computation algorithm design and analysis working environment noise optimal control permanent magnet motors magnetic sensors noise measurement magnetic analysis laboratories noise robustness;laboratory experiment;evolutionary algorithm;synchronous motor drives;cooperative competitive survivor selection schemes adaptive prudent daring evolutionary algorithm noise handling online pmsm drive design optimal control design permanent magnet synchronous motor drives	This paper studies the problem of the optimal control design of permanent magnet synchronous motor (PMSM) drives taking into account the noise due to sensors and measurement devices. The problem is analyzed by means of an experimental approach which considers noisy data returned by the real plant (on-line). In other words, each fitness evaluation does not come from a computer but from a real laboratory experiment. In order to perform the optimization notwithstanding presence of the noise, this paper proposes an Adaptive Prudent- Daring Evolutionary Algorithm (APDEA). The APDEA is an evolutionary algorithm with a dynamic parameter setting. Furthermore, the APDEA employs a dynamic penalty term and two cooperative-competitive survivor selection schemes. The numerical results show that the APDEA robustly executes optimization in the noisy environment. In addition, comparison with other meta-heuristics shows that behavior of the APDEA is very satisfactory in terms of convergence velocity. A statistical test confirms the effectiveness of the APDEA.	evolutionary algorithm;heuristic (computer science);mathematical optimization;numerical analysis;online and offline;optimal control;selection (genetic algorithm);sensor;signal-to-noise ratio;velocity (software development)	Ferrante Neri;Giuseppe Leonardo Cascella;Nadia Salvatore;Silvio Stasi	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424523	statistical hypothesis testing;simulation;optimal control;computer science;artificial intelligence;machine learning;evolutionary algorithm;control theory;evolutionary computation	Embedded	30.74534196445191	-6.149811443921255	186699
48460abcf0231bd238ce12cd3d05249000c4abcb	population size control for efficiency and efficacy optimization in population based metaheuristics		This paper proposes a mechanism of dynamic adjustment of the population size of population based metaheuristics in order to balance its efficacy and efficiency. In this approach, an external trajectory based metaheuristic (MH) is used to dynamically adjust the population size of an inner population based metaheuristic. A Particle Swarm Optmization (PSO) implemented for a Compute Unified Device Architecture platform (CUDA), called CUDA-PSO, is used as inner MH, while a sequential Simulated Annealing (SA) is used as an external one. The main objective of this paper is to evaluate the SA capabilities of finding a good balance between efficiency and efficacy during the CUDA-PSO execution and to assess its adaptability to different hardwares without any prior information about the computing platform. The results show that the new approach was able to find a good balance in most cases. Also, it was observed that this approach is able to adapt its operation to different hardwares.	algorithm;benchmark (computing);cuda;computer;hyper-heuristic;metaheuristic;modified huffman coding;particle swarm optimization;phase-shift oscillator;simulated annealing	Marcelo Gomes Pereira de Lacerda;Mohit Rawat;Teresa Bernarda Ludermir;Herbert Kuchen;Fernando Buarque de Lima Neto	2018	2018 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2018.8477792	kernel (linear algebra);mathematical optimization;population size;simulated annealing;adaptability;computer science;cuda;metaheuristic;population;particle swarm optimization	DB	26.544907103155975	-4.5210523322710365	186707
8e790ca184a963b86be81732ca283e7748f46a7b	discrete invasive weed optimization algorithm: application to cooperative multiple task assignment of uavs	unmanned aerial vehicles stochastic processes evolutionary computation adaptive control vehicle dynamics routing military computing process control intelligent control humans;evolutionary computation;stochastic method;unmanned aerial vehicle;mobile robots;remotely operated vehicles;data mining;stochastic optimization;stochastic processes;aerospace robotics;monte carlo simulations stochastic optimization algorithm weed colonization time cost trade off problem evolutionary algorithms discrete invasive weed optimization algorithm unmanned aerial vehicles genetic algorithms uav task assignment problem deterministic method stochastic method;genetic algorithm;stochastic processes aerospace robotics aircraft combinatorial mathematics genetic algorithms mobile robots monte carlo methods remotely operated vehicles;genetic algorithms;optimization;task assignment;evolutionary algorithm;monte carlo simulation;optimal algorithm;encoding;combinatorial mathematics;unmanned aerial vehicles;monte carlo methods;aircraft	This paper presents a novel discrete population based stochastic optimization algorithm inspired from weed colonization. Its performance in a discrete benchmark, time-cost trade-off (TCT) problem, is evaluated and compared with five other evolutionary algorithms. Also we use our proposed discrete invasive weed optimization (DIWO) algorithm for cooperative multiple task assignment of unmanned aerial vehicles (UAVs) and compare the solutions with those of genetic algorithms (GAs) which have shown satisfactory results in the previous works. UAV task assignment problem is of great interest among researchers and many deterministic and stochastic methods have been devised to come up with the problem. Monte Carlo simulations show successful results that verify better performance of DIWO compared to GAs in both optimality of the solutions and computational time.	activity selection problem;aerial photography;assignment problem;benchmark (computing);computation;evolutionary algorithm;genetic algorithm;make:;mathematical optimization;monte carlo method;simulation;stochastic optimization;the coroner's toolkit;time complexity;unmanned aerial vehicle	Mohsen Ramezani Ghalenoei;Hossein Hajimirsadeghi;Caro Lucas	2009	Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference	10.1109/CDC.2009.5400938	control engineering;mathematical optimization;simulation;genetic algorithm;computer science;generalized assignment problem;engineering;stochastic optimization;evolutionary algorithm;mathematics;statistics;monte carlo method;evolutionary computation	Robotics	32.72713436647426	-8.549653233734439	186727
799799718aa99acd80c870d923b123ef639960c0	a new subpopulation model for evolutionary multimodal optimization	optimisation;evolutionary computation;stability convergence computer science lungs humans genetic algorithms evolutionary computation turning scientific computing robustness;stability;stability evolutionary computation optimisation search problems;search problems;stability measure subpopulation model evolutionary multimodal optimization roaming optimization migration search operator	A new evolutionary technique for multimodal optimization called roaming optimization (RO) is presented. Multiple optima are detected using subpopulations evolving in isolation. A new search operator called migration is introduced. A stability measure is defined for subpopulations by which they are characterized as stable or unstable. Stable subpopulations are considered to contain local optima. An external population called the archive is used to store the optima detected. After a number of generations the archive contains all local optima. Experimental results prove the efficiency of the algorithm.	archive;control theory;evolutionary algorithm;evolutionary multimodal optimization;local optimum;mathematical optimization;multimodal interaction;numerical method;population;system migration	Rodica Ioana Lung;Dumitru Dumitrescu	2005	Seventh International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC'05)	10.1109/SYNASC.2005.11	mathematical optimization;stability;interactive evolutionary computation;human-based evolutionary computation;computer science;artificial intelligence;machine learning;mathematics;statistics;evolutionary computation	Arch	27.404284858272117	-6.055714241028098	186728
d40399eb5f5c55182bbed45dd6274332206676cb	a small perturbation based optimization approach for the frequency placement of high aspect ratio wings	atmospheric science;homeland security;design process;constitutive law;perturbation theory;modal optimization;conceptual model;natural frequency;functional response;high aspect ratio;design space;timoshenko beam;conceptual design;aerospace engineering a small perturbation based optimization approach for the frequency placement of high aspect ratio wings georgia institute of technology dimitri n mavris goltsch;natural frequencies;small perturbation theory;dissertation;high altitude;cross section;global optimization;mandy;structural integrity;direct search;structural redesign;optimal algorithm;dimensional reduction;beam dimensional reduction		mathematical optimization	Mandy Goltsch	2009			structural engineering;engineering;engineering drawing;mechanical engineering	EDA	35.22564113729531	-0.4154417588830835	186869
74f396741be143661c4f39b45b46050f7582fa1c	a comparative study of ba, apso, gsa, hybrid psogsa and spso in dual channel speech enhancement	bat algorithm;adaptive noise cancellation;hybrid psogsa;speech enhancement;gravitational search algorithm;particle swarm optimization;accelerated particle swarm optimization	The present paper focuses on the suppression of background noise in speech signal by utilizing a powerful heuristic optimization algorithm called Bat algorithm (BA) for adaptive filtering in dual channel enhancement systems. Bat algorithm is a recently developed population based meta heuristic approach which is inspired by the hunting behavior of the bats. It is developed by Yang (2010). As a novel feature Bat algorithm is based on the echo location behavior of micro bats. BA uses the frequency tuning technique to increase the diversity of the solutions in the population, while at the same time it uses the automatic zooming and tries to balance the exploration and exploitation. A few studies have been carried out on the use of heuristics for ANC in speech enhancement by using standard particle swarm optimization (SPSO) and some of its variants till 2010. In order to extend these heuristic approaches to speech, accelerated particle swarm optimization (APSO) based enhancement approach has been proposed (Prajna et al. in Int J Speech Technol 17(4):341---351, 2014a; Prajna et al. in IJISA 6(4):1---10, 2014b, doi:10.5815/ijisa.2014.04.01; Prajna et al. in IEEE international conference on communications and signal processing (ICCSP), April 2014, pp 1457---1461, 2014c, doi:10.1109/ICCSP.2014.6950090). To overcome the problem of poor exploitation ability of APSO, another approach is proposed based on gravitational search algorithm (GSA) (Prajna et al. 2014a, b, c). To combine both the abilities of PSO and GSA algorithms, Hybrid PSOGSA algorithm is also proposed to ANC (Prajna et al. 2014a, b, c). To further improve the efficiency of adaptive filtering in ANC, by providing a dynamic balance between exploration and exploitation, BA is proposed to speech enhancement. This paper intends to present the Bat algorithm as an improved approach to ANC in speech enhancement when compared with that of SPSO, APSO, GSA and Hybrid PSOGSA based speech enhancement algorithms. The performance of all the algorithms is evaluated by computing four objective measures SNRI, PESQ, FAI and WSS, in two real world noise conditions Babble and Factory, at three different input SNR levels set at ?10, 0 and 5 dB. Simulation results prove that BA is the most successful algorithm of all the algorithms studied in this work, to suppress the background noise more effectively.	business architecture;global storage architecture;multi-channel memory architecture;speech enhancement	K. Prajna;K. V. V. S. Reddy;G. Sasi Bhushana Rao;R. Uma Maheswari	2015	I. J. Speech Technology	10.1007/s10772-015-9308-2	simulation;speech recognition;bat algorithm;computer science;artificial intelligence;machine learning;particle swarm optimization	NLP	30.754241874134983	-4.8427322144209555	187019
1e7d34ccd81f0e5eb5b003fb805950c9dd82301b	mutation-selection algorithm: a large deviation approach		We consider a two-operator mutation-selection algorithm designed to optimize a tness function on the space of xed length binary strings. Mutation acts as in classical genetic algorithms, while the tness-based selection operates through a Gibbs measure (Boltzmann selection). The selective pressure is controlled by a temperature parameter. We provide a mathematical analysis of the convergence of the algorithm, based on the probabilistic theory of large deviations. In particular, we obtain convergence to optimum tness by resorting to an annealing process, which makes the algorithm asymptotically equivalent to simulated annealing.	extreme value theory;genetic algorithm;selection algorithm;simulated annealing	Paul Albuquerque;Christian Mazza	2000		10.1016/B978-155860734-7/50095-0	mathematical optimization;combinatorics;fitness proportionate selection;machine learning;mathematics;adaptive simulated annealing	AI	28.349066014069614	-6.794088999848129	187195
c61f6b2efecc7848549acdd2e216bd07156ade13	adaptive operator probabilities in a genetic algorithm that applies three operators	genetic operator;rectilinear steiner problem;adaptive operator probabilities;more than two operators;genetic algorithm;steady state	"""The probabilities with which a genetic algorithm applies its operators have sometimes been set adaptively; information derived from the algorithm's performance has been used to revise the probabilities as the GA runs. This paper reviews one such mechanism, which assigns probabilities to crossover and mutation, and extends it to assign probabilities to three or more operators. The extension guarantees that no operator will be excluded, even if it has recently been ineffective. Several versions of the extended mechanism are tested in a steady-state GA for the rectilinear Steiner problem, in which we seek a tree of minimum length, made up of horizontal and vertical line segments, that connects a set of given points. The coding chosen for the trees gives rise to three genetic operators, a crossover and two mutations. The operator probabilities develop in interesting ways, but the algorithm itself never identifies trees shorter than those found by the same GA with fixed operator probabilities. This raises questions about how information available to a GA as it runs can be used to adjust its parameters and improve its performance. 1. I N T R O D U C T I O N The probabilities with which a genetic algorithm applies its operators have sometimes been set adaptively; information derived from the algorithm's performance has been used to revise the probabilities as the GA runs [1, 2, 9, 10]. This paper reviews and extends one such mechanism, called Adaptive Operator Probabilities (ADOPP) [7]. As originally described, ADOPP assigns operator probabilities in a steady-state GA that applies """"Pcrn3ission to make digital or hard copies of part or all of this work for ~crsonal or classroom use is granted without fee provided that copies are not nade or distributed tbr profit or commercial advantage and that copies bear his notice and the full citation on the first page. Copyrights for components ffthis work owned by others than ACM must bc honored. Abstracting with ;redit is permitted. To copy otherwise, to republish, to post on servers or to -edistribute to lists, requires prior specific permission and/or a fee."""" 1997 ACM 0-89791-850-9 97 0002 3.50 exactly two operators (conventionally crossover and mutation). The extension applies ADOPP to more than two operators, and it guarantees that no operator will ever be shut out. In the rectilinear Steiner problem, we seek a tree of minimum length, made up of horizontal and vertical line segments, that connects a set of given points. A particular coding of such trees gives rise in a natural way to three genetic operators, a crossover and two mutations; a GA for this problem is thus an appropriate test bed for the extended ADOPP mechanism. The GA, with several versions of ADOPP, was run repeatedly on several randomly generated problems of 50 given points. These trials revealed interesting developments of the operator probabilities, but none of the versions identified shorter trees in general than did the GA with the operator probabilities fixed at plausible values. This raises questions about the information available as a GA runs; these must be answered to make an effective ADOPP-like mechanism. In what follows, this paper (1) reviews the ADOPP mechanism and extends it to three or more operators; (2) summarizes the rectilinear Steiner problem; (3) describes a steady-state genetic algorithm for the rectilinear Steiner problem; (4) describes the performance of the GA, with several versions of ADOPP, on a test problem; and (5) discusses issues the tests raise. 2. A D A P T I V E O P E R A T O R P R O B A B I L I T I E S The ADOPP mechanism sets the probabilities with which a steady-state genetic algorithm applies its operators. ADOPP has been described for GAs that apply two operators [7, 8]. Under ADOPP, each operator's probability is always proportional to the contribution it has recently made to building chromosomes more fit than the population median; such chromosomes are called ira. proved. ADOPP updates the operator probabilities after the generation of every new chromosome, improved or not. When the GA applies an operator to build a new chromosome, the operators that created it and its"""	crossover (genetic algorithm);genetic algorithm;genetic operator;mutation (genetic algorithm);procedural generation;regular grid;software release life cycle;steady state;steiner tree problem;testbed;vertical bar	Bryant A. Julstrom	1997		10.1145/331697.331746	multiplication operator;mathematical optimization;operator theory;operator;genetic algorithm;semi-elliptic operator;operator norm;computer science;artificial intelligence;genetic operator;machine learning;shift operator;steady state;algorithm	Theory	31.07191063241201	-1.9538216364146639	187227
c25b065e0d8a32784574ca3b169a89b04ea7b5f7	memetic approach for irremediable ill-conditioned parametric inverse problems*		The paper introduces a new taxonomy of ill-posed parametric inverse problems, formulated as global optimization ones. It systematizes irremediable problems, which appear quite often in the real life but cannot be solved using the regularization method. The paper also shows a new way of solving irremediable inverse problems by a complex memetic approach including: genetic computation with adaptive accuracy, random sample clustering and a sophisticated local approximation of misfit plateau regions. Finally, we use a benchmark function featuring cross-shaped plateau to discuss some factors that influence the quality of plateau shape approximation.	approximation;benchmark (computing);cluster analysis;computation;condition number;global optimization;mathematical optimization;memetics;real life;well-posed problem	Marcin Los;Jakub Sawicki;Maciej Smolka;Robert Schaefer	2017		10.1016/j.procs.2017.05.007	artificial intelligence;mathematical optimization;machine learning;global optimization;computation;computer science;parametric statistics;inverse problem;cluster analysis;regularization (mathematics)	AI	31.974244521766064	-9.336544596298692	188093
11acda037cdeb55763e2696c2e780591d6758176	particle swarm optimization with varying bounds	benchmark optimization functions particle swarm optimization evolutionary algorithms probabilistic models search space properties population based incremental learning;evolutionary computation;probability;search space;population based incremental learning;particle swarm optimization equations optimization methods stochastic processes birds evolutionary computation electronic design automation and methodology educational institutions marine animals genetic algorithms;probability evolutionary computation learning artificial intelligence particle swarm optimisation;probabilistic model;particle swarm optimizer;evolutionary algorithm;learning artificial intelligence;particle swarm optimisation	Particle Swarm Optimization (PSO) is a stochastic approach that was originally developed to simulate the behavior of birds and was successfully applied to many applications. In the field of evolutionary algorithms, researchers attempted many techniques in order to build probabilistic models that capture the search space properties and use these models to generate new individuals. Two approaches have been recently introduced to incorporate building a probabilistic model of the promising regions in the search space into PSO. This work proposes a new method for building this model into PSO, which borrows concepts from population-based incremental learning (PBIL) . The proposed method is implemented and compared to existing approaches using a suite of well-known benchmark optimization functions.	benchmark (computing);evolutionary algorithm;mathematical optimization;particle swarm optimization;population-based incremental learning;simulation;statistical model;stochastic process	Mohammed El-Abd;Mohamed S. Kamel	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4425096	probabilistic-based design optimization;statistical model;mathematical optimization;multi-swarm optimization;parallel metaheuristic;estimation of distribution algorithm;swarm intelligence;computer science;derivative-free optimization;artificial intelligence;machine learning;evolutionary algorithm;probability;mathematics;imperialist competitive algorithm;particle swarm optimization;metaheuristic;statistics;evolutionary computation	AI	27.808636749600577	-8.007501684305861	188099
eb70fa86abe2d1c9aa3b01a35e5692054c97cc2c	reference point based constraint handling method for evolutionary algorithm	constraint handling techniques;evolutionary strategy;constrained optimization problem	Many evolutionary algorithms have been proposed to deal with Constrained Optimization Problems COPs. Penalty functions are widely used in the community of evolutionary optimization when coming to constraint handling. To avoid setting up penalty term, we introduce a new constraint handling method, in which a reference point selection mechanism and a population ranking process based on the distances to the selected reference point are proposed. The performance of our method is evaluated on 24 benchmark instances. Experimental results show that our method is competitive when compared with the state-of-the-art approaches and has improved the solution and the optima value of instance g22.	evolutionary algorithm	Jinlong Li;Aili Shen;Guanzhou Lu	2015		10.1007/978-3-319-20466-6_32	mathematical optimization;binary constraint;computer science;machine learning;penalty method;mathematics;evolution strategy;algorithm	Robotics	25.13752789061769	-3.50792502116114	188127
15abbd72a9150aa7f1bf9fd775165794c98b6489	a rebuilt clone elastic net algorithm for traveling salesman problem	traveling salesman problem;optimal solution;rebuilt clone elastic net algorithm;convergence;rubber;cities and towns heuristic algorithms rubber convergence cloning traveling salesman problems tuning;convergence speed rebuilt clone elastic net algorithm traveling salesman problem parameter tuning strategies nearest neighbor method;nearest neighbor method;cloning;convergence speed;travelling salesman problems convergence;elastic net;tuning;parameter tuning;heuristic algorithms;travelling salesman problems;network algorithm;cities and towns;traveling salesman problems;parameter tuning strategies	In this paper, we analyze the relationships between solution qualities and the number of initial dynamic points in elastic net algorithm, and propose a rebuilt clone elastic network algorithm(ReBCEN) for traveling salesman problem(TSP) according to the analysis results. For solving traveling salesman problem, firstly our algorithm initializes less dynamic points to produce a general accessing path of solution which is similar with that of optimal solutions. Then by using our novel parameter tuning strategies and nearest neighbor method, our algorithm performs a rebuilt cloning process to insert cloned dynamic points into the rubber band of elastic net and adjust accessing path to find the optimal solutions. As it utilizes less dynamic points in every epoch and unmatched cities in TSP are reduced gradually, ReBCEN can obtain faster convergence speed than the original elastic net and some other modified elastic nets. ReBCEN was simulated on some random TSPs and TSPLIB instances to verify its performance by comparison with other algorithms.	algorithm;elastic map;elastic net regularization;nearest neighbor search;travelling salesman problem	Gang Yang;Junyan Yi;Xiaofeng Meng	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596625	natural rubber;nearest neighbour algorithm;mathematical optimization;combinatorics;convergence;computer science;machine learning;cloning;mathematics;travelling salesman problem;elastic net regularization	EDA	28.967652640177874	-2.9813327920388186	188549
cda044921f3dd15854732965681004ff30516847	application of particle filter algorithm in nonlinear constraint optimization problems	optimization algorithm;constraint optimization;nonlinear programming;particle filtering numerical methods constraint theory nonlinear programming;optimal method;multi dimensional function;function optimization;particle filters constraint optimization mathematical model probability density function algorithm design and analysis heuristic algorithms;constraint optimization problem;multi dimensional;particle filter;mathematical model;constraint theory;nonlinear constraint optimization particle filter optimization algorithm multi dimensional function;mathematical model particle filter algorithm nonlinear constraint optimization problem optimization algorithm function optimization problem;optimal algorithm;particle filtering numerical methods;nonlinear constraint optimization	To overcome the shortcomings of low solution precision of the nonlinear constraint optimization problems, a new optimization algorithm based on the particle filter, which is used to solve nonlinear constraint optimization problems, is brought forward in this paper. And the model and mechanism of particle filter are combined in this optimization algorithm. Firstly, the basic principle of the particle filter algorithm is systematically introduced. Secondly, a new optimization method based on particle filter is enunciated in detail and its design idea and operation steps are given. Moreover, the nonlinear constraint optimization problems are converted into function optimization problems, and a mathematical model of the particle filter optimization algorithm for solving nonlinear constraint optimization problems is established. Finally, the simulation examples are finished to prove the validity of the new algorithm. The simulation results have shown that the new optimization method based on particle filter can solve the nonlinear constraint optimization problems effectively and accurately, which also provides a new method for the nonlinear constraint optimization research.	constrained optimization;mathematical model;mathematical optimization;nonlinear system;particle filter;peterson's algorithm;simulation	Xinjie Wu;Guoxing Huang	2012	2012 8th International Conference on Natural Computation	10.1109/ICNC.2012.6234587	adaptive filter;probabilistic-based design optimization;discrete optimization;optimization problem;mathematical optimization;multi-swarm optimization;combinatorics;binary constraint;test functions for optimization;meta-optimization;nonlinear programming;derivative-free optimization;machine learning;mathematics;continuous optimization;imperialist competitive algorithm;vector optimization;l-reduction;difference-map algorithm;random optimization;metaheuristic;global optimization	Robotics	29.025850622921357	-1.6298326971333996	188622
540d723a3329689ff42d226df439776f5d9c806a	a new probabilistic visual secret sharing scheme for color images	color image reconstruction gray scale pixel cryptography probabilistic logic image color analysis;boolean operations;single bitmap btc;random like grayscale images probabilistic visual secret sharing color images boolean operations binary images single bitmap btc image reconstruction;boolean functions;binary image;random like grayscale images;color;color images probabilistic visual secret sharing shamir s scheme gsbtc technique 2 n probvss scheme;search algorithm;visual secret sharing;gray scale;boolean operation;color images;computational complexity;image color analysis;image colour analysis;cryptography;image reconstruction;pixel;binary images;gsbtc technique;n probvss scheme;image reconstruction boolean functions image colour analysis;probabilistic visual secret sharing;probabilistic logic;secret sharing scheme;2;shamir s scheme;color image	In 2007, Wang et al. proposed two visual secret sharing (VSS) schemes based on Boolean operations. The first one is a probabilistic (2, n) secret sharing scheme called (2, n) ProbVSS scheme for binary images. The other is a deterministic (n, n) secret sharing scheme for grayscale images. Although Wang et al.psilas two schemes solve the problems of computational complexity and pixel expansion at the same time; they cannot be applied to color images. To expand core concept of Wang et al.psilas (2, n) ProbVSS scheme to color images, in this paper, we combine Shamirpsilas scheme and Chang and Wupsilas gradual search algorithm for a single bitmap BTC (GSBTC) to design a new (2, n) ProbVSS scheme for color images. Experimental results confirm that our proposed scheme not only generates reconstructed color images with high quality, reduces successfully shadow size but also gives random-like grayscale images as shadows for color images.	binary image;bitmap;block truncation coding;computational complexity theory;display resolution;grayscale;pixel;search algorithm;shamir's secret sharing	Chin-Chen Chang;Chia-Chen Lin;T. Hoang Ngan Le;Hoai Bac Le	2008	2008 International Conference on Intelligent Information Hiding and Multimedia Signal Processing	10.1109/IIH-MSP.2008.140	computer vision;binary image;computer science;theoretical computer science;mathematics;algorithm;computer graphics (images)	Vision	38.69810516899873	-9.447402119234516	188707
0fedd63061cc21e3f84fb4804bc3611ee08d0fff	social emotional optimisation algorithm for reactive power optimisation	human social networks;simulation;social emotional optimisation;local search strategy;human emotions;reactive power optimisation	The reactive power optimisation plays an important role in the security and economy of power systems. In this paper, a social emotional optimisation algorithm is provided to solve the reactive power problem. Social emotional optimisation algorithm simulates the human social network, in which human emotion influences decisions in human social life. It does well in solving high-dimensional problems. Moreover, this paper adds the simplex method to improve the local search ability of the algorithm. Then, with the improved algorithm, this paper solves the reactive power problem. In order to show the validity of the improved algorithm used to solve the reactive power problem, simulation experiments were done with standard IEEE57 bus power system and IEEE118 bus power system. The results of the experiment show that the algorithm can effectively solve the reactive power optimisation problem.	algorithm;mathematical optimization	Zhan-Hong Wei;Yu Liu;Guo-Xin Zhao;Yu-Bao Song	2016	IJWMC	10.1504/IJWMC.2016.078205	simulation;emotion;computer science;artificial intelligence;machine learning	EDA	28.71121900835794	-2.5258195350768964	188798
aa278841456759b8fcba777113ea37b8ad02fd98	an rgb image encryption using diffusion process associated with chaotic map	block cipher;logistic map;key processor;cryptography;diffusion;image encryption and decryption	Image encryption and decryption are essential for securing images from various types of security attacks. In this paper, we have proposed a new algorithm for RGB image encryption and decryption using diffusion method with a combination of chaotic maps. We have formulated a new algorithm for the entire possible range to choose keys for encrypting and decrypting RGB image. Computer simulation with two standard examples and results are given to analyse the capability of the proposed approach. Several important analysis like key space, key sensitivity, NPCR, UACI, MSE and PSNR analysis are performed. Results of various analysis and computer simulation confirm that the new algorithm offers high security and is suitable for practical image encryption.	chaos theory;encryption	Manish Kumar;Pradeep Powduri;Avinash Reddy	2015	J. Inf. Sec. Appl.	10.1016/j.jisa.2014.11.003	multiple encryption;block cipher;40-bit encryption;logistic map;computer science;cryptography;theoretical computer science;link encryption;filesystem-level encryption;diffusion;internet privacy;deterministic encryption;computer security;probabilistic encryption;attribute-based encryption	Vision	38.697770168083345	-9.0290853779174	188960
2f4d6fec04ef2aec1d6498de9d8ac2ccefe34498	neutral fitness landscape in the cellular automata majority problem	fitness landscape;majority;problem;fitness;paysage;vector space;paisaje;solucion particular;automata;automate cellulaire;espace vectoriel;landscape;plurality problem;problema pluralidad;cellular automata;espacio vectorial;probleme pluralite;cellular automaton;solution particuliere;particular solution;neutral;evolutionary computing;automata celular;cellular	We study in detail the fitness landscape of a difficult cellular automata computational task: the majority problem. Our results show why this problem landscape is so hard to search, and we quantify the large degree of neutrality found in various ways. We show that a particular subspace of the solution space, called the ”Olympus”, is where good solutions concentrate, and give measures to quantitatively characterize	automata theory;cellular automaton;feasible region;majority problem (cellular automaton)	Sébastien Vérel;Philippe Collard;Marco Tomassini;Leonardo Vanneschi	2006		10.1007/11861201_31	cellular automaton;method of undetermined coefficients;fitness landscape;vector space;computer science;artificial intelligence;mathematics;automaton;landscape;algorithm	ECom	27.141276513607984	1.626389546816825	189134
b0c0d36fe69021a350ed438470462a7ccc559b27	optical encryption for large-sized images using random phase-free method		We propose an optical encryption framework that can encrypt and decrypt large-sized images beyond the size of the encryp ted image using our two methods: random phase-free method and scaled d iffraction. In order to record the entire image information on the encryp ted image, the large-sized images require the random phase to widely diffu se the object light over the encrypted image; however, the random phase gi ves r se to the speckle noise on the decrypted images, and it may be difficult to recognize the decrypted images. In order to reduce the speckle noise, w e apply our random phase-free method to the framework. In addition, we e mploy scaled diffraction that calculates light propagation between pla nes with different sizes by changing the sampling rates. © 2015 Optical Society of America OCIS codes: (090.1760) Computer holography; (090.2870) Holographic d isplay; (090.5694) Real-time holography. References and links 1. A. Alfalou and C. Brosseau, “Optical image compression an d e cryption methods,” Adv. Opt. Photon. 1, 589– 636 (2009). 2. S. Liu, C. Guo, and J. T. Sheridan, “A review of optical imag e encryption techniques,” Opt. Laser Technol. 57, 327–342 (2014). 3. P. Refregier and B. Javidi, “Optical image encryption bas ed on input plane and Fourier plane random encoding,” Opt. Lett.20, 767–769 (1995). 4. G. Situ and J. Zhang, “Double random-phase encoding in the Fresnel domain,” Opt. Lett. 29, 1584–1586 (2004). 5. T. Nomura and B. Javidi, “Optical encryption system with a binary key code,” Appl. Opt. 39, 4783–4787 (2000). 6. Z. Liu, S. Liu, “Double image encryption based on iterativ e fractional Fourier transform,” Opt. Commun. 275, 324–329 (2007). 7. J. Chen, Z. Zhu, Z. Liu, C. Fu, L. Zhang, H. Yu, “A novel doubl e-image encryption scheme based on cross-image pixel scrambling in gyrator domains,” Opt. Express 22, 7349–7361(2014). 8. P. W. M. Tsang, T.-C. Poon, and K. W. K. Cheung, “Fast numeri cal generation and encryption of computergenerated Fresnel holograms,” Appl. Opt. 50, B46–B52 (2011). 9. P. Clemente, V. Durán, V. T.-Company, E. Tajahuerce, and J. Lancis, “Optical encryption based on computational ghost imaging,” Opt. Lett. 35, 2391–2393 (2010). 10. O. Matoba and B. Javidi, “Encrypted optical memory syste m using three-dimensional keys in the Fresnel domain,” Opt. Lett.24, 762–764 (1999). 11. H. Kim, D. -H. Kim, and Y. Lee, “Encryption of digital holo gram of 3-D object by virtual optics,” Opt. Express 12, 4912–4921 (2004). 12. J. F. Barrera, A. Mira, and R. Torroba, “Optical encrypti on and QR codes: Secure and noise-free information retrieval,” Opt. Express21, 5373–5378 (2013). 13. Y. Qin and Q. Gong,“Optical information encryption base d on incoherent superposition with the help of the QR code,” Opt. Commun. 310 69–74 (2014). 14. T. Shimobaba and T. Ito,“ Random phase-free computer-ge nerated hologram, ” ArXiv (2015). 15. R. P. Muffoletto, J. M. Tyler, and J. E. Tohline, “Shifted Fresnel diffraction for computational holography,” Opt. Express15, 5631–5640 (2007). 16. T. Shimobaba, T. Kakue, N. Okada, M. Oikawa, Y. Yamaguchi , and T. Ito, “Aliasing-reduced Fresnel diffraction with scale and shift operations,” J. Opt. 15, 075405 (2013). 17. B. Javidi, T. Nomura, “Securing information by use of dig ital holography,” Opt. Lett.25 28–30 (2000). 18. E. Tajahuerce, B. Javidi, “Encrypting three-dimension al i formation with digital holography,” Appl. Opt. 39, 6595–6601 (2000). 19. X. Peng, L. Yu, and L. Cai, “Double-lock for image encrypt ion with virtual optical wavelength,” Opt. Express 10, 41–45 (2002). 20. X. Peng, Z. Cui, and T. Tan,“Information encryption with virtual-optics imaging system, ” Opt. Commun. 212, 235–245 (2002). 21. H. Kim, D. -H. Kim, and Y. Lee,“Encryption of digital holo gram of 3-D object by virtual optics, ” Opt. Express 12, 4912–4921 (2004). 22. T. Shimobaba, J. Weng, T. Sakurai, N. Okada, T. Nishitsuj i, N. Takada, A. Shiraki, N. Masuda and T. Ito, “Computational wave optics library for C++: CWO++ library,” Com put. Phys. Commun. 183, 1124–1138 (2012).	aliasing;c++;computation;computer-generated holography;density matrix;digital holography;double image backup;encryption;entity–relationship model;execution unit;fractional fourier transform;ghost imaging;gyrator;image compression;image resolution;image scaling;information retrieval;n-gram;numerical analysis;passive optical network;pixel;qr code;real-time transcription;sigmod edgar f. codd innovations award;sampling (signal processing);software propagation;tyler oakley	Tomoyoshi Shimobaba;Takashi Kakue;Yutaka Endo;Ryuji Hirayama;Daisuke Hiyama;Satoki Hasegawa;Yuki Nagahama;Marie Sano;Takashige Sugie;Tomoyoshi Ito	2015	CoRR		optics	Vision	38.684514686529845	-8.16543651551484	189243
3c31be8b94ce6c3776f5955650d593d3fa2a68f6	octonion-valued bidirectional associative memories		Over the last few years, neural networks with values in multidimensional domains have been intensely studied. This paper introduces octonion-valued bidirectional associative memories, for which the states, outputs, weights and thresholds are all octonions. The octonion algebra represents a non-associative normed division algebra which generalizes the complex and quaternion algebras and doesn't fall into the category of Clifford algebras, which are associative. After giving the definition of these networks, an expression for an energy function is provided, together with the proof that it is indeed an energy function for the proposed network.	artificial neural network;bidirectional associative memory;content-addressable memory;mv-algebra;mathematical optimization	Calin-Adrian Popa	2017	2017 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2017.7965931	quaternion;algebra representation;bidirectional associative memory;clifford algebra;octonion;associative property;division algebra;octonion algebra;algebra;mathematics	EDA	39.113131614805056	1.5147510817490963	189345
1398e1410a3f61f481601cfe956061de54085f43	dynamic representations and escaping local optima: improving genetic algorithms and local search	dynamic change;gray code;local search algorithm;structural change;improved genetic algorithm;genetic algorithm;tabu search;local search;parameter optimization	Local search algorithms often get trapped in local optima. Algorithms such as tabu search and simulated annealing ’escape’ local optima by accepting nonimproving moves. Another possibility is to dynamically change between representations; a local optimum under one representation may not be a local optimum under another. Shifting is a mechanism which dynamically switches between Gray code representations in order to escape local optima. Gray codes are widely used in conjunction with genetic algorithms and bit-climbing algorithms for parameter optimization problems. We present new theoretical results that substantially improve our understanding of the shifting mechanism, on the number of Gray codes accessible via shifting, and on how neighborhood structure changes during shifting. We show that shifting can significantly improve the performance of a simple hill-climber; it can also help to improve one of the best genetic algorithms currently available.	climber (beam);code;distribution (mathematics);genetic algorithm;hill climbing;local optimum;mathematical optimization;network switch;search algorithm;simulated annealing;tabu search;test suite	Laura Barbulescu;Jean-Paul Watson;L. Darrell Whitley	2000			local optimum;mathematical optimization;tabu search;computer science;artificial intelligence;local search;hill climbing;machine learning;iterated local search;guided local search	AI	26.636518304276844	-2.2251255922889723	189362
fd2434426de0672128fa4dc69a0397e76c1d8020	affinity genetic algorithm	selection degree;good genes;population diversity;individual flowing;genetic algorithm;global optimization;local search	Based on some phenomena from human society and nature, we propose a binary affinity genetic algorithm (aGA) by adopting the following strategies: the population is adaptively updated to avoid stagnation; the newly generated individuals will be ensured to survive for some generations in order for them to have time to show their good genes; new individuals and the old ones are balanced to have the advantages of both. In order to quantitatively analyze the selective pressure, the concept of selection degree and a simple linear control equation are introduced. We can maintain the diversity of the evolutionary population by controlling the value of the selection degree. Performance of aGA is further enhanced by incorporating local search strategies.	genetic algorithm;processor affinity	Xinchao Zhao;Xiao-Shan Gao	2007	J. Heuristics	10.1007/s10732-006-9005-z	mathematical optimization;genetic algorithm;computer science;bioinformatics;artificial intelligence;local search;mathematics;global optimization	AI	26.888823868798983	-5.147618624414298	189724
2ccc7c3f42656a805014775ef8a05bdaa453f4a3	runtime analysis of a simple ant colony optimization algorithm	optimal solution;runtime analysis;algoritmo aleatorizado;invertebrata;solution optimale;swarm intelligence;algoritmo busqueda;ant colony optimization;intelligence en essaim;algorithm analysis;004;arthropoda;insecto social;algorithme recherche;heuristic method;search algorithm;metodo heuristico;algorithme randomise;journal article;phase transition;aculeata;insecta;randomized search heuristics;solucion optima;borne inferieure;transition phase;randomized algorithm;phase transitions;evaporation;algorithme evolutionniste;transicion fase;algoritmo evolucionista;analyse algorithme;hymenoptera;methode heuristique;insecte social;social insect;evolutionary algorithm;formicoidea;theoretical foundation;inteligencia de enjambre;evaporacion;random search;analisis algoritmo;lower bound;ant colony optimization algorithm;cota inferior	Ant Colony Optimization (ACO) has become quite popular in recent years. In contrast to many successful applications, the theoretical foundation of this randomized search heuristic is rather weak. Building up such a theory is demanded to understand how these heuristics work as well as to come up with better algorithms for certain problems. Up to now, only convergence results have been achieved showing that optimal solutions can be obtained in finite time. We present the first runtime analysis of an ACO algorithm, which transfers many rigorous results with respect to the runtime of a simple evolutionary algorithm to our algorithm. Moreover, we examine the choice of the evaporation factor, a crucial parameter in ACO algorithms, in detail. By deriving new lower bounds on the tails of sums of independent Poisson trials, we determine the effect of the evaporation factor almost completely and prove a phase transition from exponential to polynomial runtime.	analysis of algorithms;ant colony optimization algorithms;evaporation;evolutionary algorithm;heuristic (computer science);polynomial;program optimization;randomized algorithm;tails;time complexity	Frank Neumann;Carsten Witt	2006	Algorithmica	10.1007/s00453-007-9134-2	phase transition;mathematical optimization;swarm intelligence;computer science;artificial intelligence;evolutionary algorithm;mathematics;algorithm	Theory	28.050979528246625	2.624789941353556	189860
bebefd03534ee2bca812b47fc4288fe712e39a06	a crossover improved genetic algorithm and its application in non-uniform linear antenna arrays		Genetic Algorithm (GA) is a widely used optimization technique with multitudinous applications. Improving the performance of the GA would further augment its functionality. This paper presents a Crossover Improved GA (CIGA) that emulates the motion of fireflies employed in the Firefly Algorithm (FA). By employing this mimicked crossover operation, the overall performance of the GA is greatly enhanced. The CIGA is tested on 14 benchmark functions conjointly with the other existing optimization techniques to establish its superiority. Finally, the CIGA is applied to the practical optimization problem of synthesizing non-uniform linear antenna arrays with low side lobe levels (SLL) and low beam width, both requirements being incompatible. However, the proposed CIGA applied for the synthesis of a 12 element array yields an SLL of −29.2dB and a reduced beam width of 19.1∘.	genetic algorithm	Bhargav Appasani;Rahul Pelluri;Vijay Kumar Verma;Nisha Gupta	2017	International Journal of Computational Intelligence and Applications	10.1142/S1469026817500274	algorithm;genetic algorithm;pattern recognition;computer science;firefly algorithm;artificial intelligence;side lobe;beam diameter;crossover;optimization problem	Arch	31.561424583118793	-3.9120101064288937	189921
a2995711596369c7d87628acbd571d0188d9fad1	symbolic regression via genetic programming	creation;genetic program;probability;tree like structures;read s linear code;crossover;linear codes;genetic programming;computational experiments symbolic regression genetic programming tree like structures read s linear code creation crossover mutation random coefficients;vectors;computer experiment;linear code;biological information theory;symbolic regression;predictive models;genetic algorithms;genetic mutations;tree searching;tree searching linear codes genetic algorithms probability;mutation;computational experiments;genetic programming linear code genetic mutations vectors predictive models genetic algorithms biological information theory;random coefficients	Presents an implementation of symbolic regression which is based on genetic programming (GP). Unfortunately, standard implementations of GP in compiled languages are not usually the most efficient ones. The present approach employs a simple representation for tree-like structures by making use of Read's linear code, leading to more simplicity and better performance when compared with traditional GP implementations. Creation, crossover and mutation of individuals are formalized. An extension allowing for the creation of random coefficients is presented. The efficiency of the proposed implementation was confirmed in computational experiments which are summarized in the paper.	genetic programming;symbolic regression	Douglas Adriano Augusto;Helio J. C. Barbosa	2000		10.1109/SBRN.2000.889734	mutation;genetic programming;crossover;genetic algorithm;computer experiment;computer science;artificial intelligence;theoretical computer science;machine learning;probability;linear code;predictive modelling;algorithm;statistics	AI	27.735659641092738	-7.960381383447867	190123
7e1408666e2dee0f9dfb9a65d7cc001a45ea00ca	using fuzzy logic to tune an evolutionary algorithm for dynamic optimization of chemical processes	fuzzy logic;process control;evolutionary algorithm;parameter setting;evolutionary optimization;dynamic optimization	Dynamic optimization of chemical processes can be carried out with evolutionary algorithms that involve many parameters. These parameters need to be given appropriate values for the algorithms to perform efficiently. This paper proposes parameter setting methods based on factorial experimentation and fuzzy logic, aimed at balancing convergence speed, robustness (consistent performance for each problem) and versatility (applicability to many different problems). The methods were tested on an existing dynamic optimisation method with at least nine tuneable parameters. The test problem set turned out to be quite demanding due to one particular problem behaving in opposite direction to the rest with respect to the most influential factor, population size. It is probable that no single tuning would be possible that will satisfy all problems. However, for the other problems, the Fuzzy Logic tuning method proposed in this paper proves to be a very promising approach.	dynamic programming;evolutionary algorithm;fuzzy logic;mathematical optimization	Q. T. Pham	2012	Computers & Chemical Engineering	10.1016/j.compchemeng.2011.08.003	fuzzy logic;control engineering;mathematical optimization;computer science;artificial intelligence;fuzzy number;machine learning;evolutionary algorithm;process control;control theory;mathematics	Logic	24.824673509357247	-6.747598357453556	190193
514e37298121e7c54691af2455ecbb0a5200318a	investigation of mutation schemes in real-parameter genetic algorithms	polynomial mutation operator;different mutation scheme;long-suggested mutation clock operator;real-parameter genetic algorithm;extensive simulation study;mutation clock implementation;valuable mutation operator;different problem;study signifies;parametric study	In this paper, we investigate the effect of five different mutation schemes for real-parameter genetic algorithms (RGAs). Based on extensive simulation studies, it is observed that a mutation clock implementation is computationally quick and also efficient in finding a solution close to the optimum on four different problems used in this study. Moreover, parametric studies on the polynomial mutation operator identify a working range of values of these parameters. This study signifies that the long-suggested mutation clock operator should be considered as a valuable mutation operator for RGAs.	fastest;genetic algorithm;mutation (genetic algorithm);mutation testing;polynomial;run time (program lifecycle phase);simulation;software release life cycle	Debayan Deb;Kalyanmoy Deb	2012		10.1007/978-3-642-35380-2_1	mathematical optimization;simulation;mutation;bioinformatics;mathematics	DB	31.06981536982193	-3.9907443171703534	190247
28f8209e9cc7804d22d97b2c04693902028c8233	application of neuron mos in multiple-valued logic	a d converter;experimental design;coupling;neurone;calcul neuronal;diseno circuito;neural computation;capacitancia;aplicacion;neuron mos transistor;seuil;05bxx;floating gate;circuit design;plan experiencia;threshold;circuito logico;couplage;threshold logic;neural circuit;neurona;low power;62k99;plan experience;circuit logique;acoplamiento;weighted sums;logica umbral;puissance faible;mos transistor;conception circuit;capacitance;umbral;logique seuil;reseau neuronal;multiple valued;application;logic circuit;low power consumption;red neuronal;computacion neuronal;transistor mos;neuron;multiple valued a d converter;capacite electrique;neural network;multiple valued d a converter;multiple valued logic;potencia debil;circuit neuronal	A novel Neuron MOS transistor has come into being recently due to the characteristic of controlling the weighted sum of multiple-input gate and capacitance coupling effect in floating gate, as well as the function of saving the data in the floating gate. The Neuron MOS transistor can be used to replace complex operation on threshold in multiple-valued logic. Based on these characteristics, this paper proposes a new method for designing the multiple-valued D/A and A/D converter. The PSPICE simulation suggests that the designed circuit has correctly operational logic function and is characterized in low power consumption.	analog-to-digital converter;artificial neuron;boolean algebra;digital-to-analog converter;lambda calculus;simulation;transistor;weight function	Wang Pengjun;Lu Jingang;Xu Jian	2007	Neural Computing and Applications	10.1007/s00521-007-0082-1	logic gate;machine learning;circuit design;pass transistor logic;mathematics;and gate;capacitance;coupling;design of experiments;or gate;artificial neural network;algorithm;models of neural computation	EDA	38.298285140256546	-3.6051069921217196	190263
98464c649ba045360887e7ccd7c3e76f6ef41bfe	ranking methods for many-objective optimization	high dimensionality;multiple objectives;comparative study;multiobjective optimization;evolutionary algorithm	An important issue with Evolutionary Algorithms (EAs) is the way to identify the best solutions in order to guide the search process. Fitness comparisons among solutions in single-objective optimization is straightforward, but when dealing with multiple objectives, it becomes a non-trivial task. Pareto dominance has been the most commonly adopted relation to compare solutions in a multiobjective optimization context. However, it has been shown that as the number of objectives increases, the convergence ability of approaches based on Pareto dominance decreases. In this paper, we propose three novel fitness assignment methods for many-objective optimization. We also perform a comparative study in order to investigate how effective are the proposed approaches to guide the search in high-dimensional objective spaces. Results indicate that our approaches behave better than six state-of-the-art fitness assignment methods.	converge;distribution (mathematics);evolutionary algorithm;experiment;fitness function;gigabyte;interplanet;linear algebra;mathematical optimization;multi-objective optimization;pf (firewall);pareto efficiency;scalability	Mario Garza-Fabre;Gregorio Toscano Pulido;Carlos A. Coello Coello	2009		10.1007/978-3-642-05258-3_56	mathematical optimization;computer science;artificial intelligence;multi-objective optimization;machine learning;evolutionary algorithm;comparative research;mathematics;management science;fitness approximation	AI	24.926560752722718	-3.7067618823670623	190306
036e9e0b104b5bd40e4d35ed6a873f3ff304c70a	efficient multi-start strategies for local search algorithms	qa75 electronic computers computer science szamitastechnika;szamitogeptudomany	Local search algorithms applied to optimization problems often suffer from getting trapped in a local optimum. The common solution for this deficiency is to restart the algorithm when no progress is observed. Alternatively, one can start multiple instances of a local search algorithm, and allocate computational resources (in particular, processing time) to the instances depending on their behavior. Hence, a multi-start strategy has to decide (dynamically) when to allocate additional resources to a particular instance and when to start new instances. In this paper we propose multi-start strategies motivated by works on multi-armed bandit problems and Lipschitz optimization with an unknown constant. The strategies continuously estimate the potential performance of each algorithm instance by supposing a convergence rate of the local search algorithm up to an unknown constant, and in every phase allocate resources to those instances that could converge to the optimum for a particular range of the constant. Asymptotic bounds are given on the performance of the strategies. In particular, we prove that at most a quadratic increase in the number of times the target function is evaluated is needed to achieve the performance of a local search algorithm started from the attraction region of the optimum. Experiments are provided using SPSA (Simultaneous Perturbation Stochastic Approximation) and kmeans as local search algorithms, and the results indicate that the proposed strategies work well in practice, and, in all cases studied, need only logarithmically more evaluations of the target function as opposed to the theoretically suggested quadratic increase.	angular defect;computation;computational resource;computer simulation;converge;experiment;global optimization;k-means clustering;local optimum;local search (optimization);mathematical optimization;maxima and minima;multi-armed bandit;rate of convergence;search algorithm;simultaneous perturbation stochastic approximation	András György;Levente Kocsis	2011	J. Artif. Intell. Res.	10.1613/jair.3313	local optimum;mathematical optimization;computer science;artificial intelligence;local search;machine learning;iterated local search;mathematics;algorithm;guided local search	AI	28.379162833757338	-0.3010623159436393	190696
d33fa7dcbb971f9dbc7f364c36aee5d6f470387d	parameters optimization of support vector machine based on simulated annealing and genetic algorithm	generalization error;kernel;probability;premature convergence;support vector machines;simulated annealing algorithm;kernel parameters;support vector machines simulated annealing genetic algorithms kernel cooling support vector machine classification scheduling electron optics educational institutions algorithm design and analysis;simulated annealing;optimization problem;heuristic search;search method parameters optimization support vector machine simulated annealing genetic algorithm probability;analytical method;support vector machines genetic algorithms probability search problems simulated annealing;schedules;genetic algorithm;genetic algorithms;optimization;search problems;support vector machine;algorithm design and analysis;parameter optimization;optimization simulated annealing genetic algorithm support vector machine kernel parameters;cooling	The generalization error of Support Vector Machine usually depends on its kernel parameters, but there is no analytic method to choose kernel parameters for SVM. In order to choose the kernel parameters for SVM, the Simulated Annealing Algorithm and Genetic Algorithm are combined, which is called Simulated Annealing Genetic Algorithm (SA-GA), to choose the SVM kernel parameters. SA-GA makes use of encoding method, reproduction, crossover and mutation in the SA when generate new solution. In this way, the characteristic of SA that can accept a worse solution in a certain extent of probability can solve premature convergence of GA, and the heuristic search method of GA can make SA robust to the parameters of cooling schedule. So the combined algorithm has better performance than SA or GA, and it can get a better solution for optimization problem. At last, SA-GA has been used to choosing the kernel parameters of SVM. The results of simulation show that the performance of the method that proposed in this paper was more efficient than SA and GA for choosing kernel parameters of SVM.	computer cooling;generalization error;genetic algorithm;heuristic;kernel (operating system);mathematical optimization;online and offline;optimization problem;premature convergence;simulated annealing;simulation;support vector machine	Qilong Zhang;Ganlin Shan;Xiusheng Duan;Zining Zhang	2009	2009 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2009.5420717	support vector machine;mathematical optimization;genetic algorithm;heuristic;radial basis function kernel;simulated annealing;computer science;machine learning;pattern recognition;variable kernel density estimation;adaptive simulated annealing	Robotics	28.569402065097908	-6.01785534473102	190707
aef9c06b6710092088198e1ec328c5db5df98806	a hybrid evidence-genetic method for the identification of multiple structural damages	damage detection strategy;structural engineering beams structures cantilevers genetic algorithms;cantilever beam hybrid evidence genetic method multiple structural damage identification damage detection strategy natural frequencies;genetic algorithms shape measurement civil engineering structural beams performance analysis search methods frequency measurement size measurement frequency conversion;evidence theory;natural frequency;genetics;damage detection;hybrid evidence genetic method;natural frequencies;simple genetic algorithm;structural engineering;improved genetic algorithm;beams structures;genetic algorithm;genetic algorithms;cantilever beam;damage identification;multiple structural damage identification;cantilevers	A hybrid evidence-genetic method of determining the location and extent of multiple structural damages by using genetic algorithms is presented. The method makes use of the combination information of natural frequencies and mode shapes. First the damage detection strategy is to localize the damage sites by using an evidence theory, which can perfectly integrate the damage identification information coming from both natural frequencies and mode shapes; then, an improved genetic algorithm is proposed to determine the damage extent. A cantilever beam is analyzed as a numerical example to compare the performance of the proposed method with other methods. Simulation results show that identification results of the evidence theory are better than those both of the frequency MDLAC method and the mode shape MDLAC method, and the improved genetic algorithm is also more accurate and effective than the simple genetic algorithms. Therefore, the hybrid evidence-genetic method is very effective for the identification of multiple structural damages.	genetic algorithm;in-game advertising;normal mode;numerical analysis;simulation;software release life cycle	Huiyong Guo;Zhengliang Li	2007	Third International Conference on Natural Computation (ICNC 2007)	10.1109/ICNC.2007.47	structural engineering;engineering;forensic engineering;engineering drawing	Robotics	35.19429068404187	-4.088344648754488	190711
8395bf1d02af59cf16db98c774f5681f49e87a58	performance assessment of the hybrid archive-based micro genetic algorithm (amga) on the cec09 test problems	distributed algorithms;quadratic programming;evolutionary multi objective optimization algorithm;convergence;history;performance evaluation;constraint optimization;non convex optimization;evolutionary multi objective optimization;benchmark problem;gradient based single objective optimization algorithm;quadratic programming distributed algorithms genetic algorithms gradient methods performance evaluation;simulation;multi objective optimization;bound constrained test problem;performance comparison;search strategy;data mining;reference point;genetics;mutation operator;genetic variation;gradient based optimizer;sequential quadratic programming;optimization problem;mechanical engineering;genetic algorithms genetic mutations system testing constraint optimization algorithm design and analysis encoding switches mechanical engineering writing history;nonconvex optimization problem;bound constrained test problem performance assessment hybrid archive based micro genetic algorithm cec09 test problems bound constrained synthetic test problems gradient based single objective optimization algorithm evolutionary multi objective optimization algorithm gradient based optimizer fast local search sequential quadratic programming global optimizer scalarization scheme nonconvex optimization problem mutation operator evolutionary algorithm genetic mutation gradient based mutation global search strategy;cec09 test problems;global optimizer;fast local search;computational complexity;genetic mutation;bound constrained synthetic test problems;gradient methods;writing;system testing;genetic algorithm;genetic algorithms;global optimization;optimization;genetic mutations;nearest neighbor search;computer analysis;hybrid archive based micro genetic algorithm;evolutionary algorithm;global search strategy;switches;optimal algorithm;encoding;multi objective optimization problem;algorithm design and analysis;performance assessment;gradient based mutation;scalarization scheme	In this paper, the performance assessment of the hybrid Archive-based Micro Genetic Algorithm (AMGA) on a set of bound-constrained synthetic test problems is reported. The hybrid AMGA proposed in this paper is a combination of a classical gradient based single-objective optimization algorithm and an evolutionary multi-objective optimization algorithm. The gradient based optimizer is used for a fast local search and is a variant of the sequential quadratic programming method. The Matlab implementation of the SQP (provided by the fmincon optimization function) is used in this paper. The evolutionary multi-objective optimization algorithm AMGA is used as the global optimizer. A scalarization scheme based on the weighted objectives is proposed which is designed to facilitate the simultaneous improvement of all the objectives. The scalarization scheme proposed in this paper also utilizes reference points as constraints to enable the algorithm to solve non-convex optimization problems. The gradient based optimizer is used as the mutation operator of the evolutionary algorithm and a suitable scheme to switch between the genetic mutation and the gradient based mutation is proposed. The hybrid AMGA is designed to balance local versus global search strategies so as to obtain a set of diverse non-dominated solutions as quickly as possible. The simulation results of the hybrid AMGA are reported on the bound-constrained test problems described in the CEC09 benchmark suite.	amga;archive;benchmark (computing);convex optimization;evolutionary algorithm;genetic algorithm;gradient;local search (optimization);matlab;mathematical optimization;multi-objective optimization;sequential quadratic programming;simulation;synthetic intelligence	Santosh Tiwari;Georges Fadel;Patrick Koch;Kalyanmoy Deb	2009	2009 IEEE Congress on Evolutionary Computation	10.1109/CEC.2009.4983177	mathematical optimization;genetic algorithm;computer science;machine learning;evolutionary algorithm;mathematics;sequential quadratic programming;quadratic programming;algorithm;global optimization	AI	27.302992248872417	-5.94081348215683	190753
baf0982b0372d7cc6a589a19546c0481f25d9ac9	application of the impulsive control of piecewisedeterministic processes to multi‐item single machinestochastic scheduling	cost function;quasi variational inequalities;production system;satisfiability;boundary condition;lipschitz continuity;impulse control	In this work, we study the optimization of a production system comprising a multi-item single machine with piecewise deterministic demands. We present a theoretical characterization of the solution of the problem as the limit of penalized problems. We prove that the solution of the penalized problem is a Lipschitz continuous function that satisfies a generalized quasi-variational inequality with boundary conditions. We describe a numerical procedure to compute this penalized optimal cost function.	apple a4;apple a9;approximation algorithm;bellman equation;calculus of variations;experiment;inventory control;iterative method;loss function;mathematical optimization;numerical analysis;optimization problem;production system (computer science);rate of convergence;scheduling (computing);scott continuity;smoothing;social inequality;state space;truncation;variational inequality	Alain Jean-Marie;Mabel M. Tidball	1999	Annals OR	10.1023/A:1018970011223	mathematical optimization;mathematical analysis;discrete mathematics;boundary value problem;mathematics;production system;lipschitz continuity;satisfiability	ML	34.89117232896269	3.696716105584614	190793
9ddc1d5d40345400c2d97b70393d1dced2ecca62	an improved lga for protein-ligand docking prediction	drugs;convergence;hydrogen;autodock;autodock improved lga computational cost structure based protein ligand docking prediction drugs high performance search algorithm drug design lamarckian genetic algorithm pattern reduction tabu search search diversity simulator platform;pharmaceutical technology;lamarckian genetic algorithm;proteins;lamarckian genetic algorithm protein ligand docking prediction autodock;heuristic algorithms;proteins drugs genetic algorithms heuristic algorithms convergence algorithm design and analysis hydrogen;genetic algorithms;search problems;search problems drugs genetic algorithms pharmaceutical technology proteins;protein ligand docking prediction;algorithm design and analysis	Since the high computational cost of the structure-based protein-Ligand docking prediction is one of the major problems in designing new drugs, many researchers keep looking for a high performance search algorithm to find the workable directions to drug design as well as a simulator platform being able to test and verify the new drugs. In this paper, an improved version of Lamarckian genetic algorithm (ILGA) is first presented for enhancing the performance of LGA by using pattern reduction to reduce the computation cost and using tabu search to increase the search diversity to further find the better results. In addition, the proposed algorithm is also applied to a well-known simulator platform (AutoDock) to evaluate the performance of the proposed algorithm. The simulation results show that the proposed algorithm can enhance the performance of ILGA in terms of convergence performance especially for highly flexible ligands.	algorithmic efficiency;autodock;computation;docking (molecular);gene prediction;genetic algorithm;land grid array;macromolecular docking;protein structure prediction;protein–ligand docking;search algorithm;simulation;tabu search	Chun-Wei Tsai;Jui-Le Chen;Chu-Sing Yang	2012	2012 IEEE Congress on Evolutionary Computation	10.1109/CEC.2012.6256513	algorithm design;hydrogen;genetic algorithm;convergence;computer science;bioinformatics;artificial intelligence;machine learning	HPC	29.971171941519472	-8.140790549326997	190909
a23012a68dbd6053dbc3f85bdd64b2096141b776	multi-objective design of state feedback controllers using reinforced quantum-behaved particle swarm optimization	swarm intelligence;quantum behaved particle swarm optimization qpso;multi objective optimization moo;optimal control;linear quadratic regulator lqr	In this paper, a novel and generic multi-objective design paradigm is proposed which utilizes quantum-behaved PSO(QPSO) for deciding the optimal configuration of the LQR controller for a given problem considering a set of competing objectives. There are three main contributions introduced in this paper as follows. (1) The standard QPSO algorithm is reinforced with an informed initialization scheme based on the simulated annealing algorithm and Gaussian neighborhood selection mechanism. (2) It is also augmented with a local search strategy which integrates the advantages of memetic algorithm into conventional QPSO. (3) An aggregated dynamic weighting criterion is introduced that dynamically combines the soft and hard constraints with control objectives to provide the designer with a set of Pareto optimal solutions and lets her to decide the target solution based on practical preferences. The proposed method is compared against a gradient-based method, seven meta-heuristics, and the trial-and-error method on two control benchmarks using sensitivity analysis and full factorial parameter selection and the results are validated using one-tailed T-test. The experimental results suggest that the proposed method outperforms opponent methods in terms of controller effort, measures associated with transient response and criteria related to steady-state.	approximation error;futures studies;gradient;heuristic (computer science);inverted pendulum;local convergence;local search (optimization);mathematical optimization;memetic algorithm;memetics;metaheuristic;online optimization;overshoot (signal);pareto efficiency;particle swarm optimization;phase-shift oscillator;programming paradigm;quantum;settling time;simulated annealing;software release life cycle;steady state	Kaveh Hassani;Won-Sook Lee	2016	Appl. Soft Comput.	10.1016/j.asoc.2015.12.024	mathematical optimization;optimal control;swarm intelligence;computer science;control theory;mathematics	AI	30.6136815082544	-6.102761415591006	190957
4603cc3c0a7ebd4cd4a89470a3087a29a9d8014f	the cloud-based framework for ant colony optimization	fuzzy membership function;ant colony optimization;search space;ant colony system;theoretical analysis;cloud model;membership function	How to keep the balance between exploration in search space regions and exploitation of the search experience gathered so far is one of the most important issues in Ant Colony Optimization (ACO). By using a variety of effective exploitation mechanisms and elite strategies, researchers proposed many sophisticated ACO algorithms, and obtains better results in experiments. In this paper, a new framework for implementing ACO algorithms called the cloud-based framework for ACO is proposed, which uses cloud model as the fuzzy membership function and constructs a self-adaptive mechanism with cloud model. By using the self-adaptive mechanism and the pheromone updating rule of suboptimal solutions which is determined by the membership function uncertainly, the cloud-based framework can make ACO algorithm explorer search space more effectively. Theoretical analysis on the cloud-based framework for ACO indicate that the framework is convergent, and the simulation results show that the framework can improve the ACO algorithms evidently.	algorithm;ant colony optimization algorithms;cloud computing;experiment;iteration;mathematical optimization;simulation	Zhiyong Li;Yong Wang;Kouassi K. S. Olivier;Jun Chen;Keqin Li	2009		10.1145/1543834.1543872	ant colony optimization algorithms;simulation;membership function;computer science;artificial intelligence;data mining	AI	27.035771921832843	-4.808671938408309	191269
629e09f5c193396bd275c65bddedce0963060510	an adaptive local search with prioritized tracking for dynamic environments		Dynamic Optimization Problems (DOPs) have attracted a growing interest in recent years. This interest is mainly due to two reasons: their closeness to practical real conditions and their high complexity. The majority of the approaches proposed so far to solve DOPs are population-based methods, because it is usually believed that their higher diversity allows a better detection and tracking of changes. However, recent studies have shown that trajectory-based methods can also provide competitive results. This work is focused on this last type of algorithms. Concretely, it proposes a new adaptive local search for continuous DOPs that incorporates a memory archive. The main novelties of the proposal are two-fold: the prioritized tracking, a method to determine which solutions in the memory archive should be tracked first; and an adaptive mechanism to control the minimum step-length or precision of the search. The experimentation done over the Moving Peaks Problem (MPB) shows the benefits of the prioritized tracking and the adaptive precision mechanism. Furthermore, our proposal obtains competitive results with respect to state-of-the-art algorithms for the MPB, both in terms of performance and tracking ability.	algorithm;archive;benchmark (computing);centrality;francis;genetic algorithm;local optimum;local search (optimization);online and offline;population;program optimization;whole earth 'lectronic link	Antonio D. Masegosa;Enrique Onieva;Pedro López-García;Eneko Osaba;Asier Perallos	2015	Int. J. Comput. Intell. Syst.	10.1080/18756891.2015.1113736	artificial intelligence;mathematical optimization;mathematics;machine learning;local search (optimization)	AI	25.05521865722024	-4.78907737848266	191332
cf7cb68d280052311994289d47ef04b6bfbac74c	an iterative greedy algorithm for hardware/software partitioning	heuristic;software hardware partitioning algorithms software algorithms signal processing algorithms greedy algorithms algorithm design and analysis;iterative greedy search;search problems artificial immune systems evolutionary computation greedy algorithms hardware software codesign;hardware software partitioning;iterative greedy search hardware software partitioning heuristic local search;local search;iterative greedy algorithm destruction method artificial immune principles evolutionary algorithm local search method hardware software codesign hardware software partitioning	Hardware/software partitioning is one of the most important problems in hardware/software codesign. This paper proposes an iterative greedy algorithm for solving hardware/software partitioning. The proposed algorithm iteratively refines a solution by a local search method, a destruction method and a construction method. We show computational results on four benchmarks from the literature. Comparisons with a traditional evolutionary algorithm and an algorithm based on artificial immune principles demonstrate the efficacy of the proposed algorithm in terms of solution quality.	benchmark (computing);computation;evolutionary algorithm;greedy algorithm;iteration;iterative method;local search (optimization)	Geng Lin	2013	2013 Ninth International Conference on Natural Computation (ICNC)	10.1109/ICNC.2013.6818080	greedy randomized adaptive search procedure;mathematical optimization;greedy algorithm;computer science;theoretical computer science;machine learning;best-first search	EDA	25.6858073734759	-1.6415176089083585	191591
3f105819b03999a328107b8ceb5d8b43ac596464	a policy iteration algorithm for markov decision processes skip-free in one direction	markov decision process;different technique;matrix analytic methods;stochastic models;policy iteration algorithm;loss rate;skip-free in one direction;new algorithm;fdl buffer;larger system;optical buer;comparative study;computation time;fibre delay line	In this paper we present a new algorithm for policy iteration for Markov decision processes (MDP) skip-free in one direction. This algorithm, which is based on matrix analytic methods, is in the same spirit as the algorithm of White (Stochastic Models, 21:785-797, 2005) which was limited to matrices that are skip-free in both directions. Optimization problems that can be solved using Markov decision processes arise in the domain of optical buffers, when trying to improve loss rates of fibre delay line (FDL) buffers. Based on the analysis of such an FDL buffer we present a comparative study between the different techniques available to solve an MDP. The results illustrate that the exploitation of the structure of the transition matrices places us in a position to deal with larger systems, while reducing the computation times.	algorithm;analog delay line;computation;gnu free documentation license;iteration;iterative method;markov chain;markov decision process;program optimization	Joke Lambert;Benny Van Houdt;Chris Blondia	2007		10.1145/1345263.1345360	matrix analytic method;markov decision process;optimization problem;mathematical optimization;partially observable markov decision process;computer science;stochastic modelling;operations management;comparative research;mathematics;distributed computing;markov model;statistics	ML	32.90167618329451	2.8642117560283573	191646
da148bf5e89f469762d094583f49e93c11c44aac	a mean-variance criterion for economic model predictive control of stochastic linear systems	open loop simulations mean variance criterion economic model predictive control stochastic linear systems empc monte carlo approach convex relaxation optimal control problem power management certainty equivalence strategy;cost function stochastic processes noise standards economics trajectory;stochastic systems convex programming linear systems monte carlo methods open loop systems optimal control predictive control	Stochastic linear systems arise in a large number of control applications. This paper presents a mean-variance criterion for economic model predictive control (EMPC) of such systems. The system operating cost and its variance is approximated based on a Monte-Carlo approach. Using convex relaxation, the tractability of the resulting optimal control problem is addressed. We use a power management case study to compare different variations of the mean-variance strategy with EMPC based on the certainty equivalence principle. The certainty equivalence strategy is much more computationally efficient than the mean-variance strategies, but it does not account for the variance of the uncertain parameters. Open-loop simulations suggest that a single-stage mean-variance approach yields a significantly lower operating cost than the certainty equivalence strategy. In closed-loop, the single-stage formulation is overly conservative, which results in a high operating cost. For this case, a two-stage extension of the mean-variance approach provides the best trade-off between the expected cost and its variance. It is demonstrated that by using a constraint back-off technique in the specific case study, certainty equivalence EMPC can be modified to perform almost as well as the two-stage mean-variance formulation. Nevertheless, we argue that the mean-variance approach can be used both as a strategy for evaluating less computational demanding methods such as the certainty equivalence method, and as an individual control strategy when heuristics such as constraint back-off do not perform well.	algorithmic efficiency;approximation algorithm;computation;control theory;heuristic (computer science);linear programming relaxation;linear system;monte carlo method;optimal control;power management;simulation;stochastic control;turing completeness	Leo Emil Sokoler;Bernd Dammann;Henrik Madsen;John Bagterp Jørgensen	2014	53rd IEEE Conference on Decision and Control	10.1109/CDC.2014.7040314	econometrics;mathematical optimization;mathematics;mathematical economics	Robotics	36.32757769859342	1.6921345087557664	192050
a35cea2585a1bdc7faf177f9fd9dd91b92d3d5d7	randomized directed neighborhoods with edge migration in particle swarm optimization	directed graphs;topology;optimisation;evolutionary computation;particle swarm optimization topology mathematics computer science algorithm design and analysis design optimization insects convergence lattices;information sharing;information flow;particle swarm optimizer;topology optimisation evolutionary computation directed graphs;directed graph;inertia weight pso randomized directed neighborhoods edge migration particle swarm optimization fitness information particle neighborhood neighborhood structure randomly generated graph structures directed graph structures random dynamic topology;particle swarm optimization algorithm	A key feature of particle swarm optimization algorithms is that fitness information shared with individuals in a particle's neighborhood. The kind of neighborhood structure that is used affects the rate at which information is disseminated throughout the population. Existing work has studied global and simple local topologies, as well as more complex, but fixed neighborhood structures. This paper looks at randomly generated, directed graph structures in which information flows in one direction only, and also outgoing edges randomly migrate from one source node to another. Experimental evidence indicates that this random dynamic topology, when used with an inertia weight PSO, performs competitively with some existing methods and outperforms others.	directed graph;mathematical optimization;particle swarm optimization;procedural generation;randomized algorithm;randomness	Arvind S. Mohais;Christopher Ward;Christian Posthoff	2004	Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753)	10.1109/CEC.2004.1330905	mathematical optimization;multi-swarm optimization;combinatorics;directed graph;computer science;machine learning;mathematics;metaheuristic;evolutionary computation	Vision	27.26473297215572	-2.373926564656043	192272
3780a2af011a7cef8b2dee7386a265f3c9a31d12	preserving diversity through diploidy and meiosis for improved genetic algorithm performance in dynamic environments	algoritmo genetico;genetic diversity;optimisation combinatoire;dynamic environment;knapsack problem;improved genetic algorithm;algorithme genetique;cell division;genetic algorithm;combinatorial optimization;optimizacion combinatoria	Genetic algorithms have been applied to a diverse field of problems with promising results. Using genetic algorithms modified to various degrees for tackling dynamic problems has attracted much attention in recent years. The main reason classical genetic algorithms do not perform well in such problems is that they converge and lose their genetic diversity. However, to be able to adapt to a change in the environment, diversity must be maintained in the gene pool of the population. One approach to the problem involves a diploid representation of individuals. Using this representation with a dynamic dominance map mechanism and meiotic cell division helps preserve diversity. In this paper, the effects of using diploidy and meiosis with such a dominance mechanism are explored. Experiments are carried out using a variation of the 0-1 knapsack problem as a testbed to determine the effects of the different aspects of the approach on population diversity and performance. The results obtained show promising enhancements.	converge;experiment;gene pool;genetic algorithm;knapsack problem;testbed	A. Sima Etaner-Uyar;A. Emre Harmanci	2002		10.1007/3-540-36077-8_32	genetic algorithm;combinatorial optimization;computer science;genetic operator;genetic representation;knapsack problem;cell division;genetic diversity	AI	24.996384940989213	-3.582742087652424	192372
48228e74aae78a82c6a172353715b2fe8d915fba	improving the efficiency and efficacy of stochastic trust-region response-surface method for simulation optimization	convergence mathematical model charge coupled devices computational modeling optimization algorithm design and analysis response surface methodology;response surface methodology;convergence;strong xg stochastic trust region response surface method simulation optimization probability;charge coupled devices;computational modeling;design of experiment response surface methodology simulation optimization strong;stochastic processes optimisation probability response surface methodology;mathematical model;optimization;algorithm design and analysis	Stochastic Trust-Region Response-Surface method (STRONG) is a new response-surface-based framework for simulation optimization. The appeal of STRONG lies in that it preserves the advantages, yet eliminates the disadvantages, of traditional response surface methodology (RSM) that has been used for more than 50 years. Specifically, STRONG does not require human involvement in the search process and can guarantee to converge to the true optimum with probability one (w.p.1). In this paper, we propose an improved framework, called STRONG-X, that enhances the efficiency and efficacy of STRONG to widen its applicability to more practical problems. For efficiency improvement, STRONG-X includes a newly-developed experimental scheme that consists of construction of optimal simulation designs and an assignment strategy for random number streams to obtain computational gains. For efficacy improvement, a new variant, called STRONG-XG, is developed to achieve convergence under generally-distributed responses, as opposed to STRONG and STRONG-X where convergence is guaranteed only when the response is normal. An extensive numerical study is conducted to evaluate the efficiency and efficacy of STRONG-X and STRONG-XG. Moreover, two illustrative examples are provided to show the viability of STRONG-X and STRONG-XG in practical settings.	computation;converge;mathematical optimization;numerical analysis;random number generation;response surface methodology;sensor;simulation;trust region;yamaha xg	Kuo-Hao Chang	2015	IEEE Transactions on Automatic Control	10.1109/TAC.2014.2374831	algorithm design;econometrics;mathematical optimization;response surface methodology;simulation;convergence;computer science;mathematical model;mathematics;computational model;statistics	Embedded	29.819607007143183	-6.375439753354677	192454
a598162fc46526f7a2de0d30d0ff0acc246a2e99	learning building block structure from crossover failure	building block;crossover disruption;smart operators;building blocks;genetic algorithm;genetic algorithms;linkage discovery	"""In the classical binary genetic algorithm, although crossover within a building block (BB) does not always cause a decrease in fitness, any decrease in fitness results from the destruction of some building blocks, in problems where such structures are well defined, such as those considered here. Those crossovers that cause both offspring to be worse, or one to be worse and one unchanged, are here designated as failed crossovers. Counting the failure frequency of single-point crossovers performed at each locus reveals something of the BB structure. Guided by the failure record, GA operators could choose appropriate points for crossover, in order to work moreefficiently and effectively. Experiments on test functions RoyalRoad R1 and R2, Holland's Royal Road Challenge function and H-IFF functions show that such a guided operator improves performance. While many methods exist to discover building blocks, this """"quick-and-dirty"""" method can sketch the linkage nearly """"for free"""", requiring very little extra computation."""	audio crossover;computation;distribution (mathematics);experiment;flexos;genetic algorithm;locus;linkage (software);software release life cycle	Zhenhua Li;Erik D. Goodman	2007		10.1145/1276958.1277202	crossover;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;algorithm	Robotics	26.133109761297973	-7.796744151704945	192961
589706cd83e3303eed545c6fc6cc3c0bc43e3a6d	the memetic self-organizing map approach to the vehicle routing problem	neural network application;vehicle routing problem;noisy data;operations research;self organizing map;self organization;self organized map;evolutionary algorithm;neural network	The paper presents an extension of the selforganizing map (SOM) by embedding it into an evolutionary algorithm to solve the Vehicle Routing Problem (VRP). We call it the memetic SOM. The approach is based on the standard SOM algorithm used as a main operator in a population based search. This operator is combined with other derived operators specifically dedicated for greedy insertion moves, a fitness evaluation and a selection operator. The main operators have a similar structure based on the closest point findings and local moves performed in the plane. They can be interpreted as performing parallels and massive insertions, simulating the behavior of agents which interact continuously, having localized and limited abilities. This self-organizing process is intended to allow adaptation to noisy data as well as to confer robustness according to demand fluctuation. Selection is intended to guide the population based search toward useful solution compromises. We show that the approach performs better, with respect to solution quality and/or computation time, than other neural network applications to the VRP presented in the literature. As well, it substantially reduces the gap to classical Operations Research heuristics, specifically on the large VRP instances with time duration constraint.	artificial neural network;computation;evolutionary algorithm;graph (discrete mathematics);greedy algorithm;heuristic (computer science);memetics;multiprocessing;operations research;organizing (structure);parallel computing;parallels desktop for mac;quantum fluctuation;self-organization;self-organizing map;signal-to-noise ratio;simulation;time complexity;vehicle routing problem	Jean-Charles Créput;Abder Koukam	2008	Soft Comput.	10.1007/s00500-008-0281-4	mathematical optimization;self-organization;self-organizing map;computer science;artificial intelligence;vehicle routing problem;machine learning;evolutionary algorithm;mathematics;artificial neural network	AI	25.185893739460756	0.3576706006705445	192964
f23ab09e5317dac869a9904bfee215cef8c730e9	μ-synthesis with dynamic d-scalings using quantum particle swarm optimization	robust control control system synthesis particle swarm optimisation;mu synthesis μ synthesis problem dynamic d scalings quantum particle swarm optimization meta heuristic robust performance controllers flexible plant control problem;robustness uncertainty particle swarm optimization optimization stability analysis periodic structures convergence	This paper proposes to revisit the μ-synthesis problem with a recent and efficient meta-heuristic called Quantum Particle Swarm Optimization (QPSO). This algorithm allows optimizing dynamic (or static) D-scalings without fitting them, which leads to robust performance controllers. This method has been applied successfully to a classical flexible plant control problem with a reasonable computation time.	algorithm;computation;heuristic (computer science);particle swarm optimization;quantum;time complexity	Philippe Feyel;Gilles Duc;Guillaume Sandou	2014	2014 European Control Conference (ECC)	10.1109/ECC.2014.6862395	control engineering;mathematical optimization;multi-swarm optimization;control theory;mathematics;particle swarm optimization;metaheuristic	Robotics	30.941769216535526	-5.661745329276101	193022
7015818c5f2007143ab5d7eab0ff66231dfb5c57	a comparison of simulated annealing with a simple evolutionary algorithm on pseudo-boolean functions of unitation	heuristique;06e30;fonction booleenne;optimisation;optimizacion;heuristica;performance;65kxx;boolean function;optimization method;analyse temporelle;simulated annealing;analisis temporal;metodo optimizacion;68wxx;time analysis;49xx;recuit simule;theoretical analysis;funcion booliana;informatique theorique;methode optimisation;evolutionary algorithms;superficie;timing analysis;algorithme evolutionniste;area;recocido simulado;algoritmo evolucionista;optimization;heuristics;run time analysis;evolutionary algorithm;rendimiento;landscape analysis;pseudo boolean;local search;random search;computer theory;informatica teorica	The development in the area of randomized search heuristics has shown the importance of a rigorous theoretical analysis of the performance of these heuristics. Unfortunately, the analysis of the expected optimization time of a specific algorithm has in general no implications on the behaviour of other algorithms - even if they differ only in some aspects. Indeed, small differences may imply large differences in the optimization time. Hence, it is an important issue to compare fundamental heuristics and to find out for which problems they behave in such a similar way that results on one heuristic can be transferred to the other one and to describe problems where they behave quite differently. Such an approach is performed here to the simple and well-known (1+1) EA, which is based on elitist selection and a global search operator, and simulated annealing, which is based on nonelitist selection and a local search operator.	evolutionary algorithm;pseudo-boolean function;simulated annealing	Thomas Jansen;Ingo Wegener	2007	Theor. Comput. Sci.	10.1016/j.tcs.2007.06.003	mathematical optimization;random search;simulated annealing;performance;computer science;artificial intelligence;local search;heuristics;evolutionary algorithm;mathematics;area;boolean function;static timing analysis;algorithm	Theory	27.848161568261034	2.3476927378636074	193042
678dac034373c5140429e0471475c40441c1c94d	scenario-based mpc with gradual relaxation of output constraints	uncertainty;random variables;robustness optimization stochastic processes reactive power uncertainty random variables predictive models;relaxation open loop systems predictive control;stochastic processes;robustness;predictive models;optimization;nonconservative open loop problem formulation scenario based mpc output constraints relaxation model predictive control conditional value at risk cvar;reactive power	Handling of uncertainty in Model Predictive Control (MPC) has received increasing attention the last decade. The robust open-loop approach often leads to overly conservative solutions, because constraints have to be satisfied for all possible realizations of the stochastic variables, over the entire prediction horizon. In this paper, we present a novel scenario-based approach, where the constraints are gradually relaxed over the prediction horizon. The concept of Conditional Value at Risk (CVaR) is employed for the relaxation, resulting in a computational tractable non-conservative open-loop problem formulation. The formulation is illustrated with a simple numerical example, and compared to a more traditional robust approach.	cvar;cobham's thesis;computation;control theory;lagrangian relaxation;linear programming relaxation;numerical analysis;value at risk	Kristian G. Hanssen;Bjarne Foss	2015	2015 54th IEEE Conference on Decision and Control (CDC)	10.1109/CDC.2015.7403248	control engineering;random variable;stochastic process;mathematical optimization;uncertainty;control theory;mathematics;predictive modelling;ac power;statistics;robustness	Vision	36.3276641258684	1.6529396458960683	193051
e457e0afc5768a352a0077130ea8984888e40225	heuristic and exact solutions to the inverse power index problem for small voting bodies	320 politikwissenschaft;local search algorithm;510 mathematik;exact solution;004 informatik;power distribution;inverse problem;simple games;indexation;electoral systems;penrose banzhaf index;institutional design;hill climbing;square root rule;electoral system;weighted voting games;simple game;power indices;limit theorem;integer linear program;penrose limit theorem	Power indices are mappings that quantify the influence of the members of a voting body on collective decisions a priori. Their nonlinearity and discontinuity makes it difficult to compute inverse images, i.e., to determine a voting system which induces a power distribution as close as possible to a desired one. The paper considers approximations to this inverse problem for the Penrose-Banzhaf index by hill-climbing algorithms and exact solutions which are obtained by enumeration and integer linear programming techniques. They are compared to the results of three simple solution heuristics. The heuristics perform well in absolute terms but can be improved upon very considerably in relative terms. The findings complement known asymptotic results for large voting bodies and may improve termination criteria for local search algorithms.	approximation;computation;critical section;domain-specific language;heuristic (computer science);integer programming;linear programming;local optimum;local search (optimization);mathematical optimization;maxima and minima;mike lesser;nonlinear system;numerical analysis;reflections of signals on conducting lines;search algorithm	Sascha Kurz;Stefan Napel	2014	Annals OR	10.1007/s10479-012-1293-0	mathematical optimization;combinatorics;economics;inverse problem;local search;hill climbing;mathematics;mathematical economics;penrose method;statistics	AI	28.32191682518183	3.7246868234913872	193465
af9655d6a9b5f7229738ee96e970eb0662af97d6	on the analysis of hpso improvement by use of the volitive operator of fish school search		Swarm Intelligence algorithms have been extensively applied to solve optimization problems. However, in some domains even well-established techniques such as Particle Swarm Optimization (PSO) may not present the necessary ability to generate diversity during the process of the swarm convergence. Indeed, this is the major difficulty to use PSO to tackle dynamic problems. Many efforts to overcome this weakness have been made. One of them is through the hybridization of the PSO with other algorithms. For example, the Volitive PSO is a hybrid algorithm that presents as good performance on dynamic problems by applying a very interesting feature, the collective volitive operator, which was extracted from the Fish School Search algorithm and embedded into PSO. In this paper, the authors investigated further hybridizations in line with the Volitive PSO approach. This time they used the Heterogeneous PSO instead of the PSO, and named this novel approach Volitive HPSO. In the paper, the authors investigate the influence of the collective volitive operator (of FSS) in the HPSO. The results show that this operator significantly improves HPSO performance when compared to the non-hybrid approaches of PSO and its variations in dynamic environments. DOI: 10.4018/jsir.2013010103 International Journal of Swarm Intelligence Research, 4(1), 62-77, January-March 2013 63 Copyright © 2013, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. algorithms; all of them conceived based on collective behaviors of simple entities. In general, swarm algorithms are inspired in groups of animals, such as flocks of birds, schools of fish, hives of bees, colonies of ants, etc. Even though a lot of swarm-based algorithms were already proposed, just a few designed to tackle dynamic problems. Particle Swarm Optimization (PSO) is among the most used swarm intelligence algorithms. Despite the fast convergence capability, the standard version of the PSO cannot tackle dynamic optimization problems. This occurs because the entire swarm often increases the exploitation around a good region of the search space, reducing the overall diversity of the population. In order to remedy that, some variations of the PSO have been created in order to increase the capacity of escaping from regions of the search space where the global optimum is not located anymore or where the previous global optimum is now a local optimum (Bentley et al., 2002; Ebadzadeh et al., 2008; Engelbrecht et al., 2008). Another swarm intelligence algorithm proposed in 2008 by Bastos-Filho and Lima Neto, the Fish School Search algorithm (FSS) (Bastos-Filho et al., 2008; Bastos-Filho et al., 2009a; Bastos-Filho et al., 2009b), presents a very interesting feature that is thought to be very useful for dynamic environments. That is, among its operators, FSS presents one, called volitive operator, which is capable of auto-regulating the exploration-exploitation trade-off during execution. Since the PSO algorithm has a fast convergence and the FSS algorithm, as explained, can self-adapt the granularity of the search, Cavalcanti-Junior, Bastos-Filho and Lima-Neto (2011) proposed of joining these features to tackle dynamic problems. Then, they develop a hybrid algorithm based on PSO and the FSS operator, which was called Volitive PSO. This approach presented good capacity of dealing with dynamic problems and overcomes results produced by PSO, FSS and Charged PSO (Blackwell & Bentley, 2002) that is a PSO variation proposed for dealing with dynamic optimization tasks. The Volitive PSO uses the standard PSO with inertia factor (Inertia PSO), which is one of the formers PSO approaches, proposed by Shi and Eberhart (1998). But, other PSO variations were proposed since the inertia PSO, one of them is HPSO (Heterogeneous PSO) (Engelbrecht, 2010) than overcame many PSO variations in static problems optimization because it was initially thought as a mechanism to generate diversity. Based on the good performance of the HPSO, we propose in this paper to substitute the inertia PSO (as the basis for the hybridization in the Volitive PSO) with the HPSO, calling this approach Volitive HPSO. Following that we investigate the improvement of the volitive operator on PSO and HPSO in benchmark dynamic optimization problems. This paper is organizer as follows. The second section provides the background on PSO, FSS, Charged PSO, HPSO and Volitive PSO. The third section compares the dynamics of the PSO and the Volitive PSO in dynamic environment, and shows the difficulties of PSO to tackle dynamic problems. The fourth section describes our proposal: the FSS-HPSO hybrid algorithm. The fifth and sixth sections present simulation setup and results, respectively. Finally, in the last section we produce our conclusions and present some ideas for future works.	benchmark (computing);blackwell (series);carlos cirne lima;dynamic problem (algorithms);dynamic programming;embedded system;entity;fish school search;flocking (behavior);flying-spot scanner;global optimization;hybrid algorithm;image organizer;kepler engelbrecht;local optimum;mathematical optimization;particle swarm optimization;russell c. eberhart;search algorithm;simulation;swarm intelligence	George M. Cavalcanti-Júnior;Fernando Buarque de Lima Neto;Carmelo J. A. Bastos Filho	2013	IJSIR	10.4018/jsir.2013010103	mathematical optimization;artificial intelligence;machine learning	AI	26.760865258115402	-3.6860808414268007	193469
107971a12550051421d4c570b3e9f285df09d6a8	approximation algorithms	scientific community;supplementary text;lucid explanation;discrete mathematician;computer science;approximation algorithms;operations researcher;numerous illustration;basic undergraduate;approximation algorithm;latest research work;operation research;basic technique;graduate course;critical example;key result;new insight;intuitive proof;discrete mathematics	There are many variations of local search: Hill-climbing: The name for the basic method described above. Metropolis: Pick a random y ∈ N(x). If f(y) < f(x), set x = y. If f(y) > f(x), set x = y with some probability. Simulated annealing: Like Metropolis, but where the probability of moving to a higher-cost neighbor decreases over time. Tabu search: Like the previous two, but with memory in order to avoid getting stuck in suboptimal regions or in plateaus (“taboo” areas). Parallel search: Do more than one search, and occasionally replace versions that are doing poorly with copies of versions that are doing well. Genetic algorithm: Keep a population of searches that changes over time via “breeding” of the best-performing searches.	approximation algorithm;cooperative breeding;genetic algorithm;hill climbing;local search (optimization);metropolis;simulated annealing;tabu search	Vijay V. Vazirani	2001		10.1007/978-3-662-04565-7	approximation algorithm	Theory	31.069789576200456	-1.981491600200608	193495
156930c06811ca0253d8b4f10cb06110943de88f	self-provisioning of network services with quantum-inspired reinforcement learning and adaptation	configural processing;reinforcement strategy;electronic mail;probability;operations support systems;network operations support systems;learning;next generation network;network services selfprovisioning;reinforcement learning;graphic nodes;network service configuration process;quantum inspired adaptation;located elements network services selfprovisioning quantum inspired reinforcement learning algorithm quantum inspired adaptation qirl algorithm selfconfiguring network services next generation networks network operations support systems probabilistic action selection policy reinforcement strategy amplitude amplification quantum computation network service configuration process managed elements graphic nodes network elements;action selection;quantum computation;dynamic environment;selfconfiguring network services;optimal path;quantum computer;electronic mail learning optimization genetic algorithms bandwidth quantum computing robustness;located elements;managed elements;network elements;bandwidth;genetic algorithm;robustness;genetic algorithms;optimization;quantum inspired reinforcement learning algorithm;amplitude amplification;learning artificial intelligence;network services;qirl algorithm;quantum computing;next generation networks;quantum computing learning artificial intelligence next generation networks probability;probabilistic action selection policy	In this paper, a quantum-inspired reinforcement learning (QiRL) algorithm is proposed for self-configuring network services in next generation networks. A new learning and adaptation scheme based on QiRL facilitates the optimal operation for multiple classes of managed elements on a network Operations Support Systems (OSSs). QiRL algorithm adopts a probabilistic action selection policy and a new reinforcement strategy inspired by amplitude amplification in quantum computation. It is also characterized by learning and adaptation capabilities against dynamic environment changes and uncertainties. The algorithm is adapted to be suitable for the network service configuration process, which is simply redefined as: the managed elements represented as graphic nodes, and aware of the environment, select nodes with the minimum cost constraints until the eligible network elements are located along near-optimal paths; the located elements are those needed for the configuration or activation of a particular product and service. The results demonstrate the effectiveness of the proposed method.	action selection;algorithm;amplitude amplification;assignment problem;autonomic computing;combinatorial optimization;computation;definition;hoc (programming language);machine learning;mathematical optimization;motion planning;naruto shippuden: clash of ninja revolution 3;next-generation network;provisioning;quantum computing;reinforcement learning;robotic mapping;service-level agreement;vehicle routing problem	Frank Jiang;Daoyi Dong;Michael R. Frater	2012	Proceedings of 2012 9th IEEE International Conference on Networking, Sensing and Control	10.1109/ICNSC.2012.6204911	mathematical optimization;genetic algorithm;computer science;artificial intelligence;theoretical computer science;machine learning;quantum computer;reinforcement learning;computer network	Robotics	31.802279634805387	-1.368389224094125	193592
b0ce0c347c1f70100caf98126b386b4781474d92	discrete particle swarm optimization for tsp: theoretical results and experimental evaluations	continuous optimization problem;experimental evaluation;new approach;new notion;particle swarm optimization;pso-like behavior;theoretical result;discrete particle swarm optimization;new method;convergence behavior;convergence rate;discrete pso algorithm;discrete optimization problem	Particle swarm optimization (PSO) is a nature-inspired technique originally designed for solving continuous optimization problems. There already exist several approaches that use PSO also as basis for solving discrete optimization problems, in particular the Traveling Salesperson Problem (TSP). In this paper, (i) we present the first theoretical analysis of a discrete PSO algorithm for TSP which also provides insight into the convergence behavior of the swarm. In particular, we prove that the popular choice of using “sequences of transpositions” as the difference between tours tends to decrease the convergence rate. (ii) In the light of this observation, we present a new notion of difference between tours based on “edge exchanges” and a new method to combine differences by computing their “centroid.” This leads to a more PSO-like behavior of the algorithm and avoids the observed slow down effect. (iii) Then, we investigate implementations of our methods and compare them with previous implementations showing the competitiveness of our new approaches.	algorithm;competitive analysis (online algorithm);continuous optimization;discrete optimization;experiment;mathematical optimization;particle swarm optimization;rate of convergence;travelling salesman problem	Matthias Hoffmann;Moritz Mühlenthaler;Sabine Helwig;Rolf Wanka	2011		10.1007/978-3-642-23857-4_40	mathematical optimization;multi-swarm optimization;artificial intelligence;mathematics;algorithm	ML	27.499884933334684	-3.9551284335613053	193630
cad9887278b49220fc2b320fa3b33a086c99bd1e	repository and mutation based particle swarm optimization (rmpso): a new pso variant applied to reconstruction of gene regulatory network		Abstract Particle Swarm Optimization (PSO) is a meta-heuristic approach based on swarm intelligence, which is inspired by the social behaviour of bird flocking or fish schooling. The main disadvantage of the basic PSO is that it suffers from premature convergence. To prevent the process of search from premature convergence as well as to improve the exploration and exploitation capability as a whole, here, in this paper, a modified variant, named Repository and Mutation based PSO (RMPSO) is proposed. In RMPSO variant, apart from applying five-staged successive mutation strategies for improving the swarm best as referred in Enhanced Leader PSO (ELPSO), two extra repositories have been introduced and maintained to store personal best and global best solutions having same fitness values. In each step, the personal and global best solutions are chosen randomly from their respective repositories which enhance exploration capability further, retaining the exploitation capability. The computational experiment on benchmark problem instances shows that in most of the cases, RMPSO performs better than other algorithms in terms of the statistical metrics taken into account. Moreover, the performance of the proposed algorithm remains consistent in most of the cases when the dimension of the problem is scaled up. RMPSO is further applied to a practical scenario: the reconstruction of Gene Regulatory Networks (GRN) based on Recurrent Neural Network (RNN) model. The experimental results ensure that the RMPSO performs better than the state-of-the-art methods in the synthetic gene data set (gold standard) as well as real gene data set.		Biswajit Jana;Suman Mitra;Sriyankar Acharyya	2019	Appl. Soft Comput.	10.1016/j.asoc.2018.09.027	machine learning;artificial intelligence;mathematical optimization;swarm intelligence;swarm behaviour;gene regulatory network;mathematics;recurrent neural network;premature convergence;particle swarm optimization	Theory	26.910180021216078	-3.6648739773556502	193675
bbad3dbf5c1d4c5ec5030395be62de66bbf5af07	salp swarm algorithm: a bio-inspired optimizer for engineering design problems		A novel optimization algorithm called Salp Swarm Optimizer (SSA) is proposed.Multi-objective Salp Swarm Algorithm (MSSA) is proposed to solve multi-objective problems.Both algorithms are tested on several mathematical optimization functions.Two challenging engineering design problems are solved: airfoil design and marine propeller design.The qualitative and quantitative results prove the efficiency of SSA and MSSA. This work proposes two novel optimization algorithms called Salp Swarm Algorithm (SSA) and Multi-objective Salp Swarm Algorithm (MSSA) for solving optimization problems with single and multiple objectives. The main inspiration of SSA and MSSA is the swarming behaviour of salps when navigating and foraging in oceans. These two algorithms are tested on several mathematical optimization functions to observe and confirm their effective behaviours in finding the optimal solutions for optimization problems. The results on the mathematical functions show that the SSA algorithm is able to improve the initial random solutions effectively and converge towards the optimum. The results of MSSA show that this algorithm can approximate Pareto optimal solutions with high convergence and coverage. The paper also considers solving several challenging and computationally expensive engineering design problems (e.g. airfoil design and marine propeller design) using SSA and MSSA. The results of the real case studies demonstrate the merits of the algorithms proposed in solving real-world problems with difficult and unknown search spaces.	algorithm;british informatics olympiad;engineering design process;mathematical optimization;swarm	Seyed Mohammad Mirjalili;Amir Hossein Gandomi;Seyedeh Zahra Mirjalili;Shahrzad Saremi;Hossam Faris	2017	Advances in Engineering Software	10.1016/j.advengsoft.2017.07.002	mathematical optimization;swarm behaviour;computer science;genetic algorithm;multi-swarm optimization;meta-optimization;metaheuristic;multi-objective optimization;algorithm;particle swarm optimization;optimization problem	SE	26.185493320030798	-4.331887734296304	193799
265db78d34f120c38885069f4ba865fe4412cb1b	the $$(1+1)$$ (1+1) elitist black-box complexity of leadingones		One important goal of black-box complexity theory is the development of complexity models allowing to derive meaningful lower bounds for whole classes of randomized search heuristics. Complementing classical runtime analysis, black-box models help us to understand how algorithmic choices such as the population size, the variation operators, or the selection rules influence the optimization time. One example for such a result is the $$\varOmega (n \log n)$$ Ω(nlogn) lower bound for unary unbiased algorithms on functions with a unique global optimum (Lehre and Witt in Algorithmica 64:623–642, 2012), which tells us that higher arity operators or biased sampling strategies are needed when trying to beat this bound. In lack of analyzing techniques, such non-trivial lower bounds are very rare in the existing literature on black-box optimization and therefore remain to be one of the main challenges in black-box complexity theory. With this paper we contribute to our technical toolbox for lower bound computations by proposing a new type of information-theoretic argument. We regard the permutation- and bit-invariant version of LeadingOnes and prove that its $$(1+1)$$ (1+1) elitist black-box complexity is $$\varOmega (n^2)$$ Ω(n2) , a bound that is matched by $$(1+1)$$ (1+1) -type evolutionary algorithms. The $$(1+1)$$ (1+1) elitist complexity of LeadingOnes is thus considerably larger than its unrestricted one, which is known to be of order $$n\log \log n$$ nloglogn (Afshani et al. in Lecture notes in computer science, vol 8066, pp 1–11. Springer, New York, 2013). The $$\varOmega (n^2)$$ Ω(n2) lower bound does not rely on the fact that elitist black-box algorithms are not allowed to make use of absolute fitness values. In contrast, we show that even if absolute fitness values are revealed to the otherwise elitist algorithm, it cannot significantly profit from this additional information. Our result thus shows that for LeadingOnes the memory-restriction, together with the selection requirement, has a substantial impact on the best possible performance.	algorithmica;analysis of algorithms;black box;computation;computational complexity theory;evolutionary algorithm;global optimization;heuristic (computer science);information theory;lecture notes in computer science;like button;mathematical optimization;randomized algorithm;sampling (signal processing);selection rule;springer (tank);unary operation	Carola Doerr;Johannes Lengler	2017	Algorithmica	10.1007/s00453-017-0304-6	mathematical optimization;combinatorics;computer science;mathematics;geometry;algorithm;statistics	Theory	29.021376719218363	2.0829666740527975	193810
ab590425f181cd2b820122761da3fccef8ddfe55	group recommender system based on rank aggregation an evolutionary approach	kendall tau distance;edge recombination operator;genetic sequencing operator;group recommender systems;mutation	Recommender systems (RSs) have emerged as a remarkable tool that very effectively handle information overload problem caused by unprecedented growth of resources available on the www. RSs research has mainly focused on algorithms for recommending items for individual users. However, Group recommender systems (GRSs) provide recommendations to group of persons i.e. they take all individual group members' preferences into account and try to satisfy them optimally. The well known Kemeny optimal aggregation generates an aggregated list that minimizes the average Kendall tau Distance from the input lists; however such aggregation is NP-Hard. In this work, we design and develop a novel approach to GRS based on Kemeny optimal aggregation using genetic algorithm (GA). We have employed edge recombination operator (ERO) and scramble sub-list mutation as genetic sequencing operators. Experimental results clearly demonstrate that proposed GA approach to rank aggregation (RA) based GRS, GA-RA-GRS outperforms the well known GRS techniques.		Ritu Meena;Kamal K. Bharadwaj	2013		10.1007/978-3-319-03844-5_65	simulation;artificial intelligence;machine learning;mathematics	ML	25.37469054090486	0.716252355329368	194025
d8a550b0fe83bddce0c6d548787f2757eb60df3f	a new bats echolocation-based algorithm for single objective optimisation	adaptive bats sonar algorithm;bats echolocation;bats sonar algorithm;optimisation;reciprocal altruism	Bats sonar algorithm (BSA) as a swarm intelligence approach utilises the concept of echolocation of bats to find prey. However, the algorithm is unable to achieve good precision and fast convergence rate to the optimum solution. With this in mind, an adaptive bats sonar algorithm is introduced with new paradigms of real bats echolocation behaviour. The performance of the algorithm is validated through rigorous tests with several single objective optimisation benchmark test functions. The obtained results show that the proposed scheme outperforms the BSA in terms of accuracy and convergence speed and can be efficiently employed to solve engineering problems.	algorithm;bat algorithm;benchmark (computing);brown fat;business architecture;chiroptera;convergence (action);distribution (mathematics);echolocation;license;mathematical optimization;numerical linear algebra;numerous;physiological sexual disorders;prey;rate of convergence;sonar (symantec);simulation;swarm intelligence	Nafrizuan Mat Yahya;M. Osman Tokhi;Hyreil Anuar Kasdirin	2016		10.1007/s12065-016-0134-5	simulation;artificial intelligence;machine learning	ML	29.456055839966368	-4.1689848219154415	194635
611e0872043da163d702cd4866ce94b8e323a1df	clustr: a program for structuring design problems	computer program;structural design	CLUSTR is a computer program which assists the designer in finding the structure inherent in his design problem. The designer supplies the list of elements which define the design problem, and then decides which of these elements are related. The computer decomposes the problem into subsets in which each element is related to every other element. In theory each of these subsets represents the smallest “structural” component of the problem: a coherent functional or behavioral sub-system. The most closely related subsets are then combined into larger clusters. This process continues until all clusters have been recombined. The computer then draws a diagram to show how these subsets are combined to form the final problem structure. The computer also identifies the dominant elements at each node in the structure to assist the designer in finding the solutions to each sub-problem.	coherence (physics);computer program;crossover (genetic algorithm);diagram	Murray A. Milne	1971		10.1145/800158.805078	computer science;engineering drawing;algorithm	Theory	34.40177356032871	-0.10847323933043532	194804
2d54e2e37d430798f5cad563b4856e22d654daf0	multiobjective gain-impedance optimization of yagi–uda antenna design using different bbo migration variants		Biogeography is the study of distribution of biological species, over space and time, among random habitats. Recently developed Biogeography-Based Optimization (BBO) is a technique in which solutions of the problem under consideration are named habitats; just as there are chromosomes in genetic algorithms (GAs) and particles in Particle Swarm Optimization (PSO). Feature sharing among various habitats in other words, exploitation, is made to occur because of the migration operator, whereas exploration of new SIV values, similar to that of GAs, is accomplished with the mutation operator. In this study, the nondominated sorting BBO (NSBBO) and various migration variants of the BBO algorithm, reported to date, are investigated for multiobjective optimization of six-element Yagi–Uda antenna designs to optimize two objectives, viz., gain and impedance, simultaneously. The results obtained with these migration variants are compared, and the best and the average results are presented in the concluding sections of...		Etika Mittal;Satvir Singh	2015	Applied Artificial Intelligence	10.1080/08839514.2014.962280	mathematical optimization;artificial intelligence;algorithm	AI	25.20608684905927	-4.422244762351785	194823
a909d34ec46204d13087786c0513b71c5c981901	a selection method for evolutionary algorithms based on the golden section		Abstract During millions of years, nature has developed patterns and processes with interesting characteristics. They have been used as inspiration for a significant number of innovative models that can be extended to solve complex engineering and mathematical problems. One of the most famous patterns present in nature is the Golden Section (GS). It defines an especial proportion that allows the adequate formation, selection, partition, and replication in several natural phenomena. On the other hand, Evolutionary algorithms (EAs) are stochastic optimization methods based on the model of natural evolution. One important process in these schemes is the operation of selection which exerts a strong influence on the performance of their search strategy. Different selection methods have been reported in the literature. However, all of them present an unsatisfactory performance as a consequence of the deficient relations between elitism and diversity of their selection procedures. In this paper, a new selection method for evolutionary computation algorithms is introduced. In the proposed approach, the population is segmented into several groups. Each group involves a certain number of individuals and a probability to be selected, which are determined according to the GS proportion. Therefore, the individuals are divided into categories where each group contains individual with similar quality regarding their fitness values. Since the possibility to choose an element inside the group is the same, the probability of selecting an individual depends exclusively on the group from which it belongs. Under these conditions, the proposed approach defines a better balance between elitism and diversity of the selection strategy. Numerical simulations show that the proposed method achieves the best performance over other selection algorithms, in terms of its solution quality and convergence speed.	evolutionary algorithm;selection (genetic algorithm)	Erik Valdemar Cuevas Jiménez;Luis Enríquez;Daniel Zaldivar;Marco A. Pérez Cisneros	2018	Expert Syst. Appl.	10.1016/j.eswa.2018.03.064	evolutionary computation;stochastic optimization;mathematical problem;machine learning;artificial intelligence;mathematical optimization;evolutionary algorithm;computer science;golden ratio;population;elitism;convergence (routing)	Robotics	26.667783856071217	-5.284168693104547	194967
9bc4d23b14f27a72be16aef665cb9adb4c12fb75	a modified intellects-masses optimizer for solving real-world optimization problems		Abstract The Intellects-Masses Optimizer (IMO) is a recently-proposed cultural algorithm, which is easy to understand, use, and implement. IMO requires (almost) no parameter tuning and has successfully been used to tackle unconstrained continuous optimization problems. A modified variant of IMO, called MIMO, is proposed in this paper. The proposed method uses improved update equations, a self-adaptive scaling factor, duplicates removal, and a local search to improve the performance of IMO. The MIMO method is tested on the 22 IEEE CEC 2011 real-world benchmark problems and is compared with 14 state-of-the-art algorithms. The results demonstrate the outperformance of the proposed method and its superiority compared to the original IMO algorithm.	intellect;mathematical optimization	Mahamed G. H. Omran;Salah Al-Sharhan;Maurice Clerc	2018	Swarm and Evolutionary Computation	10.1016/j.swevo.2018.02.015	mimo;continuous optimization;mathematical optimization;cultural algorithm;local search (optimization);computer science;optimization problem	AI	25.76302591499067	-3.6425009223370814	195145
8537d652e1efdac1293004806d2a69898d0a07c5	tabu learning method for multiuser detection in cdma systems	multiuser detection;optimization problem;learning methods;tabu search;combinatorial optimization;computer simulation;tabu learning;neural network	In this letter, considering the multiuser detection from a combinatorial optimization viewpoint, we propose a multiuser detector based on the tabu learning method, which applies the concept of tabu search to neural networks for solving optimization problems. The performance of the proposed detector is demonstrated through computer simulations. c © 2002 Elsevier Science B.V. All rights reserved.	artificial neural network;combinatorial optimization;computer simulation;mathematical optimization;multi-user;tabu search	Chunguang Li;Xiaofeng Liao;Juebang Yu	2002	Neurocomputing	10.1016/S0925-2312(02)00636-7	computer simulation;optimization problem;mathematical optimization;combinatorial optimization;tabu search;computer science;theoretical computer science;machine learning;artificial neural network;metaheuristic	AI	30.488033248820347	-3.775910362101181	195171
4602e74f0c8c4277d49668da1b10d465dd6b112b	optimal parameter settings for bat algorithm	experimental design;optimisation;bat algorithm;orthogonal arrays;simulation;cec 2013 competition problems;optimal parameter settings	Bat algorithm is a swarm intelligent algorithm inspired by the echolocation behaviour of bats. Recently, there are many research works focus on this algorithm, however, most of them are with different parameter settings when dealing with un-constrained numerical problems. In this paper, one optimal parameter setting for bat algorithm is discussed with orthogonal experimental design, and tested on CEC 2013 competition problems. To test the performance, the optimal setting is used to compare with other four bat algorithms. Simulation results show the validity.		Fei Xue;Yongquan Cai;Yang Cao;Zhihua Cui;Feixiang Li	2015	IJBIC	10.1504/IJBIC.2015.069304	mathematical optimization;simulation;bat algorithm;machine learning;design of experiments;orthogonal array;statistics	AI	24.86206619012264	-5.342849705573897	195212
63456bc7813565be2a543a643ec1f8e7447687ae	deviation-tolerant floating gate structures as a way to design an on-chip learning neural networks	floating gate;chip;power dissipation;hardware implementation;artificial neural network;neural network;design methodology	Hardware implementation of artificial neural networks (ANN) based on MOS transistors with floating gate (Neuron MOS or νMOS) is discussed. Choosing analog approach as a weight storage rather than digital improves learning accuracy, minimizes chip area and power dissipation. However, since weight value can be represented by any voltage in the range of supplied voltage (e.g. from 0 to 3.3 V), minimum difference of two values is very small, especially in the case of using neuron with large sum of weights. This implies that ANN using analog hardware approach is weak against Vdd deviation. The purpose of this paper is to investigate main parts of analog ANN circuits (synapse and neuron) that can compensate all kinds of deviation and to develop their design methodologies.	artificial neural network	Rafail Lashevsky;Yohey Sato	2002	Soft Comput.	10.1007/s00500-001-0162-6	chip;design methods;computer science;dissipation;machine learning;artificial neural network	EDA	38.53963436406098	-2.5701025458283593	195318
a0bd66f21fecd33ece1215d9ffe193d50b395500	beehive: routing algorithms inspired by honey bee behavior				Horst F. Wedde;Muddassar Farooq	2005	KI		artificial bee colony algorithm;machine learning;honey bee;artificial intelligence;beehive;computer science	ECom	24.64734019784769	-5.744239144787621	195388
8bcde49b9512d4bc79597cedd63dfb0c028f8a46	energy-efficient design of the secure better portable graphics compression architecture for trusted image communication in the iot	image communications;image coding;image coding internet of things computer architecture graphics video coding hardware energy consumption;internet of things iot;internet of things;video coding;computer architecture;energy consumption;trusted computing cameras cryptography data protection digital rights management image coding image watermarking internet of things;power consumption reduction energy efficient design trusted image communication iot energy consumption secure better portable graphics compression architecture internet of things energy efficient sbpg architecture encryption task watermarking task double layer protection data privacy data security digital rights management secure digital camera pattern independent method current values voltage values simulink peak signal to noise ratio;energy efficient design;energy efficient design internet of things iot image communications vlsi architecture secure better portable graphics compression sbpg;secure better portable graphics compression sbpg;graphics;hardware;vlsi architecture	Energy consumption has become a major concern in portable applications. This paper proposes an energy-efficient design of the Secure Better Portable Graphics Compression (SBPG) Architecture. The architecture proposed in this paper is suitable for imaging in the Internet of Things (IoT) as the main concentration is on the energy efficiency. The novel contributions of this paper are divided into two parts. One is the energy efficient SBPG architecture, which offers encryption and watermarking, a double layer protection to address most of the issues related to privacy, security and digital rights management. The other novel contribution is the Secure Digital Camera integrated with the SBPG architecture. The combination of these two gives the best quality imaging in an energy efficient way without compromising security. To estimate the power in the proposed architecture a pattern-independent method has been adopted where many simulations run in the design with different inputs and the average of the power dissipated is considered. The current and voltage values are considered from the output of the design, in order to calculate power. This is achieved with the help of sensor and power blocks available in Simulink. From the results obtained, it was observed that with the same peak signal to noise ratio, the power consumption is substantially reduced, up to 19%.	better portable graphics;digital camera;digital rights management;digital watermarking;encryption;internet of things;secure digital;signal-to-noise ratio;simulation;simulink	Umar Albalawi;Saraju P. Mohanty;Elias Kougianos	2016	2016 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)	10.1109/ISVLSI.2016.21	embedded system;space-based architecture;computer science;theoretical computer science;computer security	Arch	36.9807449859842	-9.748950248735154	195457
7d6786e9dde9fa06de52f1bf192c1f01b553d32b	binary-state bacterial foraging optimization based on network topology and its application	binary state;small world networks;controller design;von neumann topology;bacterial foraging optimization	Bacterial foraging optimization (BFO) inspired by the foraging behavior of E.coli has been used to solve optimization problems. This paper presents a novel binary-state bacterial foraging optimization based on network topology (BBFO-NT). In the proposed BBFO-NT, a binary-state bacterial foraging strategy, which makes the bacteria to have mutual learning mechanism, is introduced. The two behavioral states include an explorative state based on Von Neumann topology and an exploitative state based on small-world networks. The bacteria co-evolve during the optimization process under the two states. Experiments on a set of benchmark functions validate the effectiveness of the improved algorithm. BFO and some other intelligent optimization algorithms are employed for comparison. The simulations show that the proposed BBFO-NT offers significant improvements than BFO. On this basis, the new algorithm has been successfully applied to the docking control. The experiments indicate that the improved algorithm is effective in controller design.	algorithm;basic formal ontology;benchmark (computing);docking (molecular);experiment;mathematical optimization;network topology;simulation;windows nt	Sunan Wang;Shenli Wu;Xiaohu Li;Chenlong Kang	2017	Intelligent Automation & Soft Computing	10.1080/10798587.2016.1205823	topology optimization;computer science;artificial intelligence;machine learning;small-world network	EDA	25.00748019608824	-6.134053779735188	195494
539db382e99458ad5c831c7fb647f1be3383b4cb	adaptive mutation in dynamic environments	genetic algorithms;cga adaptive mutation dynamic environments nature inspired optimization dynamic optimization compact genetic algorithm;heuristic algorithms optimization vectors sociology statistics genetic algorithms standards	The interest in nature inspired optimization in dynamic environments has been increasing constantly over the past years. This trend implies that many real world problems experience dynamic changes and it is important to develop an efficient algorithm capable of tackling these problems. Several techniques have been developed over the past two decades for solving dynamic optimization problems. Among these techniques, the hypermutation scheme has proved to be beneficial in solving some of the dynamic optimization problems but requires that the mutation factors be picked a priori. This paper investigates a new mutation and change detection scheme for compact genetic algorithm (cGA), where the degree of change regulates the mutation rate (i.e. mutation rate is directly proportional to the degree of change). The experimental results shows that the mutation and change detection scheme has an impact on the performance of the cGA in dynamic environments and that the effect of the proposed scheme depends on the dynamics of the environment.	dynamic programming;emoticon;experiment;genetic algorithm;mathematical optimization;norm (social);optimization problem	Chigozirim J. Uzor;Mario A. Góngora;Simon Coupland;Benjamin N. Passow	2014	2014 14th UK Workshop on Computational Intelligence (UKCI)	10.1109/UKCI.2014.6930175	mathematical optimization;simulation;computer science;artificial intelligence	AI	25.850730810357973	-5.214538323273487	195551
956810d4820b0704d6e719ba41159138d7ec1367	robust estimation of reactive power for an active distribution system		Increasing distributed energy resources (DERs) may result in reactive power imbalance in a transmission power system (TPS). An active distribution power system (DPS) having DERs reportedly can work as a reactive power prosumer to help balance the reactive power in the TPS. The reactive power potential (RPP) of a DPS, which is the range between the maximal inductive and capacitive reactive power the DPS can reliably provide, should be accurately estimated. However, an accurate estimation is difficult because of the network constraints, mixed discrete and continuous variables, and the nonnegligible uncertainty in the DPS. To solve this problem, this paper proposes a robust RPP estimation method based on two-stage robust optimization, where the uncertainty in DERs and the boundary-bus voltage is considered. In this two-stage robust model, the RPP is pre-estimated in the first stage and its robust feasibility for any possible instance of the uncertainty is checked via a tractable problem in the second stage. The column-and-constraint generation algorithm is adopted, which solves this model in finite iterations. Case studies show that this robust method excels in yielding a completely reliable RPP, and also that a DPS, even under the uncertainty, is still an effective reactive power prosumer for the TPS.	algorithm;cobham's thesis;iteration;kernel density estimation;mathematical optimization;maximal set;pictbridge;robust optimization	Zhengshuo Li;Jianhui Wang;Hongbin Sun;Feng Qiu;Qinglai Guo	2018	CoRR		engineering;control theory;electric power system;capacitive sensing;robust optimization;distributed generation;voltage;ac power;prosumer	EDA	35.12829622295017	1.6170469534171534	195626
1b5260fb6392eb4680118c1f9b92175390130492	swarm optimization based dual transform algorithm for secure transaction of medical images		Modern healthcare systems are based on managing diagnostic information of patients through e-health. e-health refers to the internet enabled healthcare applications involving transacting personal health records and other internet based services including e-pharmacy etc. This paper introduces a hybrid algorithm which efficiently combines DWT-DCT-PSO for copyright protection and authentication of medical images. Particle swarm optimization is applied on the host image to find the intensities for embedding the watermark bits by gbest solution from objective function and the fitness function. The embedding strategy is adopted with intensity level, so the technique falls under robust blind watermarking technique. The simulation results shows that the proposed scheme yields good results when tested for different images and subjected to various attacks.	algorithm;swarm	Anusudha Krishnamurthi;N. Venkateswaran;J. Valarmathi	2014		10.1007/978-3-319-12012-6_53	multi-swarm optimization;computer science;artificial intelligence;theoretical computer science;algorithm	Vision	36.57574860691388	-8.965786243981976	195745
97b1abed000a0ca05f1c3312af72af094286a868	an efficient immune-based symbiotic particle swarm optimization learning algorithm for tsk-type neuro-fuzzy networks design	engineering;optimal solution;global solution;solution optimale;network design;learning algorithm;convergence;fuzzy set;procesamiento informacion;learning;49j30;05bxx;immune algorithm;skin color detection;65kxx;conjunto difuso;optimization method;ensemble flou;global convergence;algorithme apprentissage;metodo optimizacion;ingenierie;symbiotic evolution;aprendizaje;49xx;convergencia;apprentissage;computational science and engineering;particle swarm optimizer;solucion optima;particle swarm optimization;neuro fuzzy;37a25;problem complexity;information processing;methode optimisation;ingenieria;global optimization;sistema difuso;solution globale;systeme flou;49k30;traitement information;tsk type neuro fuzzy networks;algoritmo aprendizaje;prediction;solucion global;fuzzy system	In this paper, we propose a new learning algorithm that can be used to design TSK-type neuro-fuzzy networks. Though there has been a great deal of interest in the use of immune algorithms (IAs) for computer science and engineering, in terms of fundamental methodologies, they are not dramatically different from other algorithms. In order to enhance the IA performance, we propose the immune-based symbiotic particle swarm optimization (ISPSO) for use in TSK-type neuro-fuzzy networks for solving the prediction and skin color detection problems. The proposed ISPSO embeds the symbiotic evolution scheme in an IA and utilizes particle swarm optimization (PSO) to improve the mutation mechanism. In order to avoid trapping in a local optimal solution and to ensure the search capability of a near global optimal solution, mutation plays an important role. Therefore, we employed the advantages of PSO to improve the mutation mechanism and used a method that introduces chaotic mapping with certainty, ergodicity and the stochastic property into PSO to improve global convergence. Unlike the IA that uses each individual in a population as a full solution to a problem, symbiotic evolution assumes that each individual in a population represents only a partial solution to a problem. Complex solutions combine several individuals in the population. © 2008 Elsevier B.V. All rights reserved.	algorithm;computer science;ergodicity;local convergence;mathematical optimization;mutation (genetic algorithm);neuro-fuzzy;particle swarm optimization;population	Cheng-Jian Lin	2008	Fuzzy Sets and Systems	10.1016/j.fss.2008.01.020	mathematical optimization;network planning and design;convergence;prediction;information processing;computer science;artificial intelligence;computational science and engineering;neuro-fuzzy;mathematics;fuzzy set;particle swarm optimization;algorithm;fuzzy control system;global optimization	AI	30.80491605807863	-0.350304626825	195955
548c07673b05786af5ba97ef4108558ce6d0fae9	solving traveling salesman problem by using a local evolutionary algorithm	traveling salesman problem;evolutionary computation;problem solving travelling salesman problems evolutionary computation search problems;traveling salesman problems evolutionary computation cities and towns search methods application software iterative algorithms optimization methods robustness printed circuits very large scale integration;problem solving local evolutionary algorithm traveling salesman problem local search method;travelling salesman problems;search problems;evolutionary algorithm;traveling salesman problem evolutionary algorithm local search;neighborhood search;local search;problem solving	This paper introduces a new local evolutionary algorithm (LEA) and uses it to solve the traveling salesman problem. The algorithm incorporates speediness of local search methods in neighborhood search with robustness of evolutionary methods in global search in order to obtain global optimum. The experimental results show that the algorithm is of potential to obtain global optimum or more accurate solutions than other evolutionary methods for the TSP.	evolutionary algorithm;global optimization;local search (optimization);travelling salesman problem	Wang Xuan;Yuanxiang Li	2005	2005 IEEE International Conference on Granular Computing	10.1109/GRC.2005.1547294	traveling purchaser problem;2-opt;mathematical optimization;greedy algorithm;christofides algorithm;cross-entropy method;combinatorial optimization;tabu search;computer science;local search;hill climbing;machine learning;evolutionary algorithm;mathematics;travelling salesman problem;algorithm;3-opt;memetic algorithm;bottleneck traveling salesman problem;guided local search;evolutionary computation	Robotics	25.95007095101195	-1.5455144550021325	196038
2bef3de66c53f3e1f95bf5dead10ac814977f8ae	harmonic estimation of distorted power system signals employing two hybrid strategies	harmonic estimation;kalman filter;kf;mga;modified genetic algorithm;bfo;bacterial foraging optimisation	This paper deals with two hybrid strategies for harmonic estimation of distorted power system signal. Harmonics estimation for a signal distorted with additive noise is an important aspect while dealing with power quality. For this reason, the two proposed methods, Kalman filter-modified genetic algorithm (KF-modified GA) and Kalman filter-bacterial foraging optimisation (KF-BFO), are employed for promoting the efficiency in estimation of harmonics. Simulation results are presented and compared in order to exemplify the effectiveness and robustness of the proposed approach. Improvement in both convergences for solution as well as processing time is demonstrated from algorithm.	two-hybrid screening	Gayadhar Panda;Pravat Kumar Ray;Pratap Sekhar Puhan	2014	IJMIC	10.1504/IJMIC.2014.063873	kalman filter;control engineering;beat frequency oscillator;mathematical optimization;computer science;engineering;machine learning;control theory	HCI	32.593345698151076	-5.4462434440667655	196046
eb5f1434b0aa8f959c8297db4c434427d0b97ced	particle swarm with extended memory for multiobjective optimization	particle swarm;pareto optimisation;evolutionary computation;dnpso algorithm dynamic neighborhood particle swarm optimization multiobjective optimization problems particle memory updating one dimension optimization extended memory global pareto optimal solutions computation time;search problems evolutionary computation pareto optimisation;global pareto optimal solutions;random number generation;particle swarm optimization optimization methods evolutionary computation equations biomedical engineering benchmark testing stochastic processes random number generation;one dimension optimization;dynamic neighborhood particle swarm optimization;dnpso algorithm;multiple objectives;particle swarm optimizer;biomedical engineering;stochastic processes;particle swarm optimization;extended memory;multiobjective optimization;multiobjective optimization problems;search problems;particle memory updating;computation time;pareto optimal solution;benchmark testing;optimization methods	This paper presents a modified dynamic neighborhood particle swarm optimization (DNPSO) algorithm for multiobjective optimization problems. PSO is modified by using a dynamic neighborhood strategy, new particle memory updating, and one-dimension optimization to deal with multiple objectives. An extended memory is introduced to store global Pareto optimal solutions to reduce computation time. Several benchmark cases were tested and the results show that the modified DNPSO is much more efficient than the original DNPSO and other multiobjective optimization techniques.	extended memory;mathematical optimization;multi-objective optimization;swarm	Xiaohui Hu;Russell C. Eberhart;Yuhui Shi	2003		10.1109/SIS.2003.1202267	mathematical optimization;multi-swarm optimization;meta-optimization;derivative-free optimization;theoretical computer science;machine learning;mathematics;metaheuristic	EDA	28.058348267420026	-5.840338978830472	196083
c713d4c4ea53ce5f55a78a55b0e66906165a717c	optical multi-image encryption scheme based on discrete cosine transform and nonlinear fractional mellin transform		A new multi-image encryption scheme with an optical implementation based on the nonlinear fractional Mellin transform is proposed, which could avoid the vulnerability of the linear encryption systems and encrypt multiple images simultaneously. In the proposed scheme, the original images are transformed into spectra by the discrete cosine transform, then the spectra are incised and spliced into a composite spectrum, and finally the composite spectrum is performed by the nonlinear fractional Mellin transform to obtain the final encrypted image. After the processing of the fractional Mellin transform, amplitude encoding and phase encoding are adopted. The orders of the fractional Mellin transform are the main keys of this multi-image encryption scheme. Simulation results demonstrate the validity and the security of the proposed scheme.	algorithm;chosen-ciphertext attack;ciphertext;ciphertext-only attack;computer simulation;discrete cosine transform;encryption;known-plaintext attack;nonlinear system;plaintext	Shu Min Pan;Ru Hong Wen;Zhihong Zhou;Nan Run Zhou	2015	Multimedia Tools and Applications	10.1007/s11042-015-3209-x	s transform;modified discrete cosine transform;fractional fourier transform;discrete cosine transform;two-sided laplace transform;mellin transform	Crypto	39.00695350227786	-9.002789279349148	196142
2579ba33f72002aa1060d807a812cf9abe89a8e1	evaluating evolutionary algorithms and differential evolution for the online optimization of fermentation processes	differential evolution;online optimization;process optimization;graceful degradation;model development;mathematical model;fermentation process;fermentation processes;evolutionary algorithm;optimal algorithm;real valued evolutionary algorithms	Although important contributions have been made in recent years within the field of bioprocess model development and validation, in many cases the utility of even relatively good models for process optimization with current state-of-the-art algorithms (mostly offline approaches) is quite low. The main cause for this is that open-loop fermentations do not compensate for the differences observed between model predictions and real variables, whose consequences can lead to quite undesirable consequences. In this work, the performance of two different algorithms belonging to the main groups of Evolutionary Algorithms (EA) and Differential Evolution (DE) is compared in the task of online optimisation of fed-batch fermentation processes. The proposed approach enables to obtain results close to the ones predicted initially by the mathematical models of the process, deals well with the noise in state variables and exhibits properties of graceful degradation. When comparing the optimization algorithms, the DE seems the best alternative, but its superiority seems to decrease when noisier settings are considered.	differential evolution;elegant degradation;evolutionary algorithm;experiment;fault tolerance;mathematical model;mathematical optimization;online and offline;online optimization;process optimization;simulation	Miguel Rocha;José P. Pinto;Isabel Rocha;Eugénio C. Ferreira	2007		10.1007/978-3-540-71783-6_23	differential evolution;mathematical optimization;fault tolerance;computer science;machine learning;process optimization;evolutionary algorithm;mathematical model;fermentation;evolutionary computation	AI	31.086376907638968	-6.701366031464695	196747
9a965ffd616db933c55ab97786c4b002dabd6aca	the immune and the chemical crossover	engineering;immune algorithms;diversity;biochemistry biocybernetics evolutionary computation optimisation graphs;ga simplex;metodo adaptativo;optimisation;genetic program;evolutionary computation;cell system;cell population;genetic systems;immune systems;optimization technique;search space;sistema inmunitario;reaccion quimica;distributed computing;selective pressure;genie chimique;methode adaptative;genetic programming;schemata pool immune algorithms chemical crossover evolutionary algorithms engineering genetic systems immune systems chemical systems recombination mechanisms algorithmic mechanisms irm algorithm ga simplex step algorithm search space fitness values diversity adaptive capability recruitment test selective pressure cell population chemical reactions computational graphs genetic algorithms genetic programming immunology optimization techniques information exploitation;recruitment test;irm algorithm;algoritmo genetico;schemata pool;graphs;inmunologia;chemical systems;genetics;diversity reception;chemical engineering;systeme cellulaire;biocybernetics;adaptive capability;information exploitation;sistema celular;chemical elements;immunologie;adaptive method;optimization techniques;chemistry;immune system;algorithmic mechanisms;algorithme genetique;evolutionary algorithms;system testing;chemical crossover;algorithme evolutionniste;genetic algorithm;genetic algorithms;algoritmo evolucionista;chemical reactions;ingenieria quimica;evolutionary algorithm;fitness values;reaction chimique;recombination mechanisms;chemical reaction;immune system chemical elements chemistry evolutionary computation genetics chemical engineering diversity reception recruitment system testing distributed computing;computational graphs;step algorithm;biochemistry;systeme immunitaire;recruitment;immunology	Among the different mechanisms employed by evolutionary algorithms, it can be argued that recombination, or crossover, is the most original, intuitively appealing and useful in an engineering perspective. It is a simple, but natural trick to combine elements of two good individuals in the hopes of generating a better one and, in particular, by combining the elements that make these solutions good in isolation. The trick of recombination can be seen not only in genetic systems, but also in immune and chemical systems as well. This paper describes and explains these latter recombination mechanisms, first from a biological or chemical perspective, then from an engineering perspective. With regard to crossover in immune systems, several algorithmic mechanisms have already been proposed (e.g. IRM, GA-Simplex, STEP) and these are reviewed. Their basic functionality in each case is the same: new individuals are created in a zone of the search space that is shaped by the position of the current solutions, together with their fitness values. When the immune system proposes a new cell, the profile of this new candidate evidences a huge diversity, providing its adaptive capability, but this is subject to a subsequent recruitment test under the selective pressure of the current population of cells. With regard to crossover in chemical reactions, these can be viewed as a combination of computational graphs coupled with the distribution of the fitness values assigned to components in the graphs, as is already evidenced in particular instances of genetic algorithms and genetic programming. The benefits that these new features allow are discussed, along with other possible positive influences that come from chemistry. Finally, the paper shows how chemistry and immunology converge to this same basic message, which is in line with classical optimization techniques: exploit the information contained in the current population of solutions better before proposing a new candidate to be evaluated.	genetic algorithm	Hugues Bersini	2002	IEEE Trans. Evolutionary Computation	10.1109/TEVC.2002.1011543	genetic algorithm;immune system;chemical reaction;computer science;bioinformatics;artificial intelligence;machine learning;evolutionary algorithm;mathematics;algorithm	Embedded	29.749541404214497	-8.648648370295353	197177
bd96f944af7e25a3b41aa92d2ca7a45570fbdf6f	combinatorial optimization for weighing matrices with the ordering messy genetic algorithm	competent metaheuristics;messy genetic algorithm;combinatorial optimization problem;combinatorial design;weighing matrices;genetic algorithm;optimization;combinatorial optimization;ordering messy genetic algorithm	In this paper, we demonstrate that the search for weighing matrices constructed from two circulants can be viewed as a permutation problem. To solve it a set of two competent genetic algorithms (CGAs) are used to locate common integers in two sorted arrays. The motivation to deal with the messy genetic algorithm (mGA) is given from the pioneering results of Goldberg, regarding the ability of the mGA to put tight genes together in a solution which points directly to structural patterns in weighing matrices. In order to take into advantage a recent formalism on the support of two sequences with zero autocorrelation we use an adaptation of the ordering messy GA (OmeGA) where we combine the fast mGA with random keys to represent permutations of the two sequences under investigation. This transformation of the weighing matrices problem to an instance of a combinatorial optimization problem seems to be promising since we illustrate that our framework is capable to solve open cases for weighing matrices as these are listed in the second edition of the Handbook of Combinatorial Designs.	combinatorial optimization;genetic algorithm	Christos Koukouvinos;Dimitris E. Simos	2011		10.1007/978-3-642-20662-7_13	optimization problem;mathematical optimization;combinatorial design;combinatorics;genetic algorithm;combinatorial optimization;computer science;mathematics;algorithm	NLP	25.88620115572248	4.0134388270189385	197219
b6d3bbb8680567b0e9dcce125f02ac6487708081	approximate implementations of pure random search in the presence of noise	macquarie university institutional repository;researchonline;digital repository;pure random search;macquarie university;sequential analysis;global optimisation;objective function;random noise;noisy objective function;random search	We discuss the noisy optimisation problem, in which function evaluations are subject to random noise. Adaptation of pure random search to noisy optimisation by repeated sampling is considered. We introduce and exploit an improving bias condition on noise-affected pure random search algorithms. Two such algorithms are considered; we show that one requires infinite expected work to proceed, while the other is practical.	event loop;global optimization;iteration;mathematical optimization;noise (electronics);random search;sampling (signal processing);search algorithm	David L. J. Alexander;David W. Bulger;James M. Calvin;H. Edwin Romeijn;Ryan L. Sherriff	2005	J. Global Optimization	10.1007/s10898-004-9970-4	mathematical optimization;random field;digital library;random search;computer science;sequential analysis;machine learning;random function;data mining;mathematics;statistics	ML	30.849053218948832	0.7224921579956306	197909
c6dfe46ac260990443301c41ea7c4da174bbbd66	extremal optimization with local search for the circular packing problem	optimisation;gradient method;combinatorial optimization problem;heuristic nature inspired algorithm;energy function;circular packing problem;containers optimization methods gradient methods biological system modeling computer science heuristic algorithms runtime computational modeling elasticity physics;search problems combinatorial mathematics optimisation;discrete combinatorial optimization problems;extremal optimization;global optimization;search problems;global optimization extremal optimization local search circular packing problem heuristic nature inspired algorithm discrete combinatorial optimization problems;physical model;local minima;combinatorial mathematics;local search;lower bound	optimization (EO) is a heuristic nature-inspired algorithm and has been applied to solve some discrete combinatorial optimization problems. In this paper, a continuous version of EO, called EO with local search (EOLS), is presented to solve the problem of packing unequal circles into a larger circular container. First, an equivalent physical model of the problem is adopted to handle the constraints. In order to optimize the continuous energy function of the model, EOLS performs an additional local search procedure after every update step of the original EO. The approach combines the power of conventional gradient method to find local minima and that of EO method in global optimization. The computational results on some problem instances taken from the previous literatures show that the proposed approach produces high-quality solutions within reasonable runtime. It should be noted that for all but two instances we found new lower bounds missed in previous papers.	algorithm;combinatorial optimization;computation;extremal optimization;global optimization;gradient method;heuristic;least squares;local search (optimization);mathematical optimization;maxima and minima;search algorithm;set packing;time complexity;windows update	Wenqi Huang;Jian Liu	2007	Third International Conference on Natural Computation (ICNC 2007)	10.1109/ICNC.2007.368	mathematical optimization;combinatorics;machine learning;mathematics	Vision	29.71174444141719	-1.6641699515821535	198064
f01422c598bd066c4e9c73f41f233260b2e6f42c	a novel particle swarm algorithm for multi-objective optimisation problem	multi objective optimisation;adaptive parameter;particle swarm optimisation;dynamical inertia weight	To maintain the diversity and convergence of Pareto optimal solutions for multi-objective problem, an improved particle swarm optimisation algorithm based on dynamical changed inertia weight is proposed to improve algorithm’s ability of exploitation and exploration. By this method, if a particle finds a better solution then more energy is given onto the current velocity to speed up exploitation, and vice versa. The computer simulations for three well-known benchmark functions taken from the multi-objective optimisation literature are used to evaluate the performance of the proposed approach. Numerical experiments have been performed to evaluate the efficiency of the algorithm.	algorithm;mathematical optimization;swarm	Jian-de Zhang;Chenrong Huang;Jinbao Xu;Jin-gui Lu	2013	IJMIC	10.1504/IJMIC.2013.053544	mathematical optimization;simulation;machine learning;mathematics;particle swarm optimization	ML	27.353365817636952	-4.194061538231252	198081
4f0b59ffae10d845ef13ff7c916672666aaa2a6e	a modified particle swarm optimization with differential evolution mutation	differential evolution;convergence;evolutionary computation;probability;evolutionary computation technique;mpso;multimodal optimization problems;modified particle swarm optimization;probability of trapping;optimization problem;indexes;particle swarm optimizer;chromium;particle swarm optimization;optimization;search problems;search process;optimal algorithm;particle swarm optimisation;differential evolution mutation;mutation;evolutionary computing	Particle swarm optimization (PSO) is a new evolutionary computation technique. The advantage of the PSO over many of the other optimization algorithms is its relative simplicity and quick convergence. But those particles collapse so quickly that it exits a potentially dangerous property: stagnation, which state would make it impossible to arrive at the global optimum, even a local optimum. Under this consideration, a modified particle swarm optimization (MPSO) with differential evolution operator mutations is introduced to eliminate stagnation and avoid premature in this paper. The Probability of trapping at the local optimum during the searching process can be reduced using MPSO. The testing of two multimodal optimization problems shows that MPSO is effective.	algorithm;differential evolution;evolutionary computation;evolutionary multimodal optimization;global optimization;local optimum;mathematical optimization;multimodal interaction;particle swarm optimization	Xiaoxia Zheng	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5583273	mathematical optimization;multi-swarm optimization;artificial intelligence;machine learning;mathematics;metaheuristic	Robotics	28.039816184444312	-5.360744872137274	198114
a4b5b011995a093371cab99c9184abe23e69a544	a fuzzy adaptive neighborhood search for function optimization	heuristic programming optimisation functional analysis search problems fuzzy logic;optimisation;fans decision support systems scheduling algorithm fuzzy systems processor scheduling system testing genetic algorithms simulated annealing fuzzy sets statistics;schedulers;processor scheduling;heuristic programming;search algorithm;behavioural adaptation;simulated annealing;decision maker;fuzzy sets;software components;function optimization;fuzzy logic;difference scheme;scheduling algorithm;decision procedure;functional analysis;fans algorithm;decision support systems;statistics;system testing;genetic algorithms;search problems;heuristic rules;decision procedures;fuzzy adaptive neighbourhood search algorithm;software components fuzzy adaptive neighbourhood search algorithm function optimization fans algorithm heuristic rules decision procedures schedulers behavioural adaptation;neighborhood search;fuzzy systems;fans	A Fuzzy Adaptive Neighborhood Search for Function Optimization David A. Pelta Armando Blanco Jose-L. Verdegay Depto. de Ciencias de la Computaci6n e Inteiigencia Artificial. Universidad de Granada, Granada, Spain {dpelta,armando ,verdegay}@ugr . es Neighborhood based search algorithms have been applied with success in the optimization field. In this work, a Fuzzy Adaptive Neighborhood Search algorithm which uses fuzzy concepts and heuristic rules in the decision procedures together with several schedulers to adapt its behaviour as proposed. The conceptual and practical design of FANS in components allows decision makers the testing of different schemes and alternatives.	fuzzy concept;fuzzy control system;granada;heuristic;heuristic (computer science);linear algebra;local search (optimization);mathematical optimization;numerical analysis;search algorithm;springer (tank);systems theory	David A. Pelta;Armando Blanco;José L. Verdegay	2000		10.1109/KES.2000.884118	mathematical optimization;theoretical computer science;machine learning;mathematics	AI	25.594177686205256	-7.1208986215918735	198138
be7194eda875ec3f6bf14280c2cb061c7631adc6	knowledge-based cooperative particle swarm optimization	diversity;learning process;analisis numerico;swarm intelligence;convergence;matematicas aplicadas;premature convergence;complex function;mathematiques appliquees;learning;social learning;optimization technique;65kxx;optimization method;metodo optimizacion;journal;analyse numerique;experimental result;algorithme;aprendizaje;49xx;optimization problem;algorithm;cooperative behavior;convergencia;apprentissage;numerical analysis;particle swarm optimizer;mathematical programming;particle swarm optimization;cooperative evolution;methode optimisation;resultado experimental;funcion compleja;fonction complexe;global optimization;resultat experimental;applied mathematics;programmation mathematique;programacion matematica;algoritmo;knowledge base	Particle swarm optimization is a novel swarm-intelligence-based algorithm and a valid optimization technique. However, the algorithm suffers from the premature convergence problem when facing to complex optimization problem. In order to keep the balance between the global exploration and the local exploitation validly, the paper develops a knowledge-based cooperative particle swarm optimization (KCPSO). KCPSO mainly simulates the self-cognitive and self-learning process of evolutionary agents in special environment, and introduces a knowledge billboard to record varieties of search information. Moreover, KCPSO takes advantage of multi-swarm to maintain the swarm diversity and tries to guide their evolution by the shared information. Under the guide of the shared information, KCPSO manipulates each sub-swarm to go on with local exploitation in different local area, in which every particle follows a social learning behavior mode; at the same time, KCPSO carries out the global exploration through the escaping behavior and the cooperative behavior of the particles in different sub-swarms. KCPSO can maintain appropriate swarm diversity and alleviate the premature convergence validly. The proposed model was applied to some well-known benchmarks. The relative experimental results show KCPSO is a robust global optimization method for the complex multimodal functions.	mathematical optimization;particle swarm optimization	Jing Jie;Jianchao Zeng;Chongzhao Han;Qinghua Wang	2008	Applied Mathematics and Computation	10.1016/j.amc.2008.05.100	optimization problem;mathematical optimization;knowledge base;multi-swarm optimization;social learning;simulation;meta-optimization;convergence;numerical analysis;swarm intelligence;computer science;artificial intelligence;complex-valued function;mathematics;particle swarm optimization;metaheuristic;global optimization;premature convergence	Robotics	27.58430428002556	0.2878970170477214	198224
d3f58d341b282ce8ca99ecf3f5d55c37ff6355b0	robust encryption of quantum medical images		Security of medical media is important for patient safety and confidentiality. This paper proposes a framework for the chaos-based quantum encryption of healthcare images. In the framework, healthcare staff in one location send cipher images to the cloud. The healthcare staff in another location receives the images from the cloud. By decrypting the content of the images, the healthcare staff can assist users in a secure manner. This paper also proposes a novel approach for the efficient quantum image encryption of healthcare media. The proposed algorithm utilizes gray code and a chaotic map. The quantum image is scrambled by quantum gray code. Then, the scrambled quantum image is encrypted using a quantum XOR operation based on a key generator controlled by the logistic-sine map. The circuits of the proposed encryption/decryption algorithm are devised based on an NEQR quantum image representation. Numerical and simulation analyses show that the proposed quantum image encryption approach is robust, realizable, and has high efficiency compared with its classical counterpart.	algorithm;chaos theory;cipher;confidentiality;encryption;exclusive or;key generator;quantum key distribution;simulation	Ahmed A. Abd El-Latif;Bassem Abd-El-Atty;Muhammad Talha	2018	IEEE Access	10.1109/ACCESS.2017.2777869	cipher;encryption;theoretical computer science;computer science;distributed computing;cloud computing;quantum cryptography;quantum;quantum computer;gray code;key generator	EDA	38.289752098772176	-9.357481113580059	198268
a3f5db1ea7106f3724568def4db8b3f18f6f330e	study of migration topology in island model parallel hybrid-ga for large scale quadratic assignment problems	quadratic programming;topology;random topology migration topology island model parallel hybrid ga large scale quadratic assignment problems migration process one way ring topology;search problems computational complexity genetic algorithms quadratic programming topology combinatorial mathematics;large scale;computational complexity;genetic algorithms;quadratic assignment problem;search problems;topology large scale systems genetic algorithms distributed computing electronics packaging erbium hybrid intelligent systems power generation economics environmental economics costs;combinatorial mathematics;evaluation studies;hybrid genetic algorithm	This paper extends our previous work on the island model parallel hybrid-genetic algorithm (PHGA) for large scale quadratic assignment problems (QAPs). Some issues on the control parameters of the migration process and how they affect the quality of the solutions and the efficiency of algorithm deserve further evaluative study. In this paper, we investigate the effect of migration topology on the performance of the PHGA. Two topologies, one-way ring topology and random topology, are studied and analyzed. The empirical results show that the PHGA with ring topology is better able to achieve an appropriate tradeoff between exploration and exploitation and hence more helpful to improve the performance of PHGA for solving large scale QAPs.	computation;genetic algorithm;memetic algorithm;network topology;one-way function;premature convergence;pseudorandom number generator;quadratic assignment problem;rand tablet;rand index;ring network;scalability;software release life cycle;time complexity	Jing Tang;Meng-Hiot Lim;Yew-Soon Ong;Meng Joo Er	2004	ICARCV 2004 8th Control, Automation, Robotics and Vision Conference, 2004.	10.1109/ICARCV.2004.1469788	mathematical optimization;combinatorics;computational topology;genetic algorithm;computer science;theoretical computer science;mathematics;computational complexity theory;quadratic programming;quadratic assignment problem	HPC	25.03213286837777	-0.21003059094186183	198436
1cda0c5aac7a06d43812142b4df79f2d464e46d5	cryptanalysis of a chaotic image encryption scheme based on permutation-diffusion structure		Chaos-based image encryption algorithms have been widely studied since the permutation-diffusion structure (PDS) was proposed. However, the PDS is not secure from attacks, which may lead to security vulnerabilities of PDS based chaotic cryptosystems. In this study, the security problems of PDS are investigated. Then, a new PDS based chaotic image encryption scheme is cryptanalyzed. In the original scheme, a 3D bit matrix permutation was used to address the intrinsic deficiencies of traditional pixel/bit level permutation of image encryption. The double random position permutation provides a high security level. However, it is not unattackable. In this study, a novel attack method will be introduced where all the chaotic mappings or parameters which are functionally equivalent to the keys used in the permutation and diffusion stages of the original cryptosystem can fully be revealed. The encrypted images can then be completely recovered without knowing the secret keys. Both mathematical analysis and experimental results are given to illustrate the effectiveness of the proposed method.	algorithm;arnold's cat map;attack model;bit-level parallelism;coefficient;cost per action;cryptanalysis;cryptosystem;encryption;entity–relationship model;intrinsic dimension;linear function;modulo operation;new foundations;pixel;vulnerability (computing);zk-crypt	Ming Li;Yuzhu Guo;Jie Huang;Yang Li	2018	Sig. Proc.: Image Comm.	10.1016/j.image.2018.01.002	theoretical computer science;permutation;cryptosystem;pixel;encryption;computer science;chaotic;security level;cryptanalysis;matrix (mathematics)	Crypto	38.638383085996075	-8.521743479547242	198488
458c79d76c0dfb7967a883620ed39216d90e53a2	observing the state of a smart grid using bilevel programming	mixed integer linear program;bilevel program;monitoring electrical network;pmu placement problem	Monitoring an electrical network is an important and challenging task. Phasor measurement units are measurement devices that can be used for a state estimation of this network. In this paper we consider a PMU placement problem without conventional measurements and with zero injection nodes for a full observability of the network. We propose two new approaches to model this problem, which take into account a propagation rule based on Ohm’s and Kirchoff’s law. The natural binary linear programming description models an iterative observability process. We remove the iteration by reformulating its fixed point conditions to a bilevel program, which we then further reformulate to a single-level mixed-integer linear program. We also present a bilevel algorithm to solve directly the proposed bilevel model. We implemented and tested our models and algorithm: the results show that the bilevel algorithm is better in terms of running time and size of instances which can be solved.	algorithm;bilevel optimization;downtime;fixed point (mathematics);fixed-point iteration;iteration;iterative and incremental development;iterative method;linear programming;mathematical model;multi-level cell;network topology;phasor;potential energy surface;power management unit;procedural generation;software propagation;time complexity	Sonia Toubaline;Pierre-Louis Poirion;Claudia D'Ambrosio;Leo Liberti	2015		10.1007/978-3-319-26626-8_27	mathematical optimization;simulation;computer science;bilevel optimization	AI	35.07824314351403	1.617923640727921	198646
83e59088a261d99b1296e4a8a71912d75711c758	robust parallel genetic algorithms with re-initialisation	parallelisme;parallel genetic algorithm;algoritmo paralelo;comportement rendez vous;parallel algorithm;cost function;fonction reguliere;algoritmo genetico;algorithme parallele;conducta cita;resolucion problema;parallelism;paralelismo;biomimetique;algorithme genetique;genetic algorithm;funcion regular;dating behavior;problem solving;resolution probleme;smooth function;biomimetics	The influence of different parallel genetic algorithm (PGA) architectures on the GA convergence properties is analysed. Next, two proposed versions of these PGA architectures are compared – homogenous and heterogeneous. Finally the effect of re-initialisation in some partial populations on the PGA convergence has been analysed. The proposed PGA modifications are useful mainly in case of non-smooth cost function optimisation.	genetic algorithm;loss function;mathematical optimization;population;software release life cycle	Ivan Sekaj	2004		10.1007/978-3-540-30217-9_42	biomimetics;smoothness;mathematical optimization;genetic algorithm;computer science;artificial intelligence;machine learning;mathematics;parallel algorithm;algorithm	ML	27.41639952052259	1.297728217952629	198702
d0b509a538b4807e1d291eb50adf1ac165bc4505	design of induction motors using a mixed-variable approach	induction motor;derivative free methods;induction motors;optimal design;settore mat 09 ricerca operativa;mixed variable optimization;nonlinear optimization	In this paper we are concerned with the problem of optimally designing three-phase induction motors. This problem can be formulated as a mixed variable programming problem. Two different solution strategies have been used to solve this problem. The first one consists in solving the continuous nonlinear optimization problem obtained by suitably relaxing the discrete variables. On the opposite, the second strategy tries to manage directly the discrete variables by alternating a continuous search phase and a discrete search phase. The comparison between the numerical results obtained with the above two strategies clearly shows the fruitfulness of taking directly into account the presence of both continuous and discrete variables. Copyright Springer-Verlag Berlin/Heidelberg 2005		Giampaolo Liuzzi;Stefano Lucidi;Veronica Piccialli;Marco Villani	2005	Comput. Manag. Science	10.1007/s10287-005-0024-2	discrete optimization;optimization problem;mathematical optimization;nonlinear programming;control theory;induction motor;mathematics;continuous optimization	Logic	32.924010502732656	1.3559123181802637	198832
5914d2b86dea02155de399c203a712a27f7ac054	an approach to polygonal approximation of digital curves based on discrete particle swarm algorithm	particle swarm;polygonal approximation;fitness function	An approach to polygonal approximation of regular digital curves based on PSO algorithm is presented. In this paper, each particle corresponds to a candidate solution to the polygonal approximation problem, which is represented as a binary vector. The offset error of centroid between the original curve and the approximation polygon, and the variance of distance error for each approximation segment are adopted in the fitness function to evaluate the feasibility degree of the candidate solution. The sigmoid function of iteration times is used as the acceleration factors instead of the constant factors to improve the global searching characteristics. Experimental results show that the proposed approach can get suitable approximation results for preserving the features of original curves.	approximation algorithm;bit array;fitness function;iteration;mathematical optimization;optimization problem;particle swarm optimization;phase-shift oscillator;sigmoid function	Fangmin Dong;Renbin Xiao;Yifang Zhong;Yong Liu	2007	J. UCS	10.3217/jucs-013-10-1449	mathematical optimization;approximation error;computer science;fitness approximation;particle swarm optimization;minimax approximation algorithm;fitness function	Robotics	30.13527631951218	-2.0729917284891846	198870
e7be40a6ae7434674eda475b230ddce57138d479	a multistage solution of the template-layout problem	sampling methods human factors cost function optimal control shape costing decision making process control cybernetics extrapolation;cybernetics;cost function;costing;dynamic programming algorithm;extrapolation;higher order;objective function;optimal control;human factors;shape;process control;sampling methods;exhaustive search	The template-layout problem is to determine how to cut irregular-shaped two-dimensional pieces out of given stock sheets in an optimum manner without making an exhaustive search of all possible arrangements of the pieces. An algorithm is described for solving template-layout problems with a digital computer. The method of solution requires that the irregular shapes be enclosed, singly or in combination, in minimum area rectangles called modules. Individual modules will contain from one to perhaps eight optimally fitted irregular pieces. The modules are then packed into the given stock sheet(s) so as to optimize a specified objective function. The packing is carried out with a dynamic programming algorithm, which converts the multivariable problem into a multistage one. Successive iterations of the algorithm are used to determine whether higher order modules (containing more irregular-shaped pieces) improve the solution. A detailed description of the algorithm is given. An illustrative example is included and its computer solution is described. The paper concludes with an extension of the algorithm to an improved version which can be expected to yield solutions more closely approaching the true optimum.	multistage amplifier	Murray J. Haims;Herbert Freeman	1970	IEEE Trans. Systems Science and Cybernetics	10.1109/TSSC.1970.300290	sampling;mathematical optimization;higher-order logic;optimal control;cybernetics;shape;computer science;dynamic programming;process control;brute-force search;control theory;mathematics;extrapolation;algorithm;activity-based costing;statistics	Embedded	32.78660394180978	1.4112466498230982	198950
e761f0c4564a792a660ca617048aead2c3def110	a hybrid artificial bee colony for optimizing a reverse logistics network system		This paper proposes a hybrid discrete artificial bee colony (HDABC) algorithm for solving the location allocation problem in reverse logistics network system. In the proposed algorithm, each solution is represented by two vectors, i.e., a collection point vector and a repair center vector. Eight well-designed neighborhood structures are proposed to utilize the problem structure and can thus enhance the exploitation capability of the algorithm. A simple but efficient selection and update approach is applied to the onlooker bee to enhance the exploitation process. A scout bee applies different local search methods to the abandoned solution and the best solution found so far, which can increase the convergence and the exploration capabilities of the proposed algorithm. In addition, an enhanced local search procedure is developed to further improve the search capability. Finally, the proposed algorithm is tested on sets of large-scale randomly generated benchmark instances. Through the analysis of experimental results, the highly effective performance of the proposed HDBAC algorithm is shown against several efficient algorithms from the literature.	artificial bee colony algorithm;logistics	Jun-Qing Li;Ji-dong Wang;Quan-Ke Pan;Pei-Yong Duan;Hongyan Sang;Kai-Zhou Gao	2017	Soft Comput.	10.1007/s00500-017-2539-1	computer science;artificial intelligence;artificial bee colony algorithm;mathematical optimization;machine learning;local search (optimization);reverse logistics;location-allocation;convergence (routing)	OS	25.427310749963876	-2.031011359860565	199083
0f0c709e019c6fa8ae025247d12c9cb7188f34f4	comparison of simulated annealing and mean field annealing as applied to the generation of block designs	performance measure;block design;evaluation performance;optimisation;performance evaluation;cost function;complexite calcul;stochastic method;methode mesure;systeme discret;etude experimentale;temperatura critica;estudio comparativo;plan equilibre;evaluacion prestacion;articulo;aproximacion campo medio;metodo medida;optimization method;simulated annealing;metodo optimizacion;funcion coste;approche deterministe;plan bloc;higher order;experimental result;deterministic approach;etude comparative;plan bloque;mean field;complejidad computacion;stochastic optimization;recuit simule;balanced incomplete block design;plan bloc incomplet;computational complexity;conexion;raccordement;plan equilibrado;comparative study;enfoque determinista;methode optimisation;resultado experimental;neural cost functions;methode stochastique;fonction cout;block designs;recocido simulado;the critical temperature;higher order connections;incomplete block design;approximation champ moyen;temperature critique;measurement method;sistema discreto;reseau neuronal;mean field approximation;resultat experimental;experimental comparison;connection;estudio experimental;critical temperature;red neuronal;mean field annealing;energy landscape;plan bloque incompleto;discrete system;neural network;balanced design;metodo estocastico	This paper describes an experimental comparison between a discrete stochastic optimization procedure (Simulated Annealing, SA) and a continuous deterministic one (Mean Field Annealing), as applied to the generation of Balanced Incomplete Block Designs (BIBDs). A neural cost function for BIBD generation is proposed with connections of arity four, and its continuous counterpart is derived, as required by the mean field formulation. Both strategies are optimized with regard to the critical temperature, and the expected cost to the first solution is used as a performance measure for the comparison. The results show that SA performs slightly better, but the most important observation is that the pattern of difficulty across the 25 problem instances tried is very similar for both strategies, implying that the main factor to success is the energy landscape, rather than the exploration procedure used.	artificial neural network;best, worst and average case;biological neural networks;loss function;mfa message structure;master of fine arts;mathematical optimization;mean field annealing;quantum field theory;simulated annealing;smoothing (statistical technique);stochastic optimization;subgroup;sulfanilamide	Pau Bofill;Roger Guimerà;Carme Torras	2003	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2003.07.003	block design;computer science;artificial intelligence;mean field theory;stochastic optimization;machine learning;calculus;mathematics;adaptive simulated annealing;artificial neural network;algorithm	ML	27.95857181102465	1.8671939838047706	199164
30c0fdb6cc54e09f1432878b81e8d0510649d45a	a novel immune clonal algorithm for mo problems	pareto optimisation;convergence;evolutionary computation;immune system vectors cloning optimization measurement convergence heuristic algorithms;artificial immune system;measurement;clonal selection;multiobjective optimization mo;cloning;performance metric;vectors;performance metric artificial immune system ais multiobjective optimization mo pareto optimal front;pareto optimal front;heuristic algorithms;artificial immune system ais;artificial immune systems novel immune clonal algorithm mo problems multiobjective optimization intelligent computation evolutionary algorithm antibody population nica pareto optimal solutions;immune system;multiobjective optimization;optimization;evolutionary algorithm;pareto optimal solution;artificial immune systems;pareto optimality;heuristic algorithm;pareto optimisation artificial immune systems evolutionary computation	Research on multiobjective optimization (MO) becomes one of the hot points of intelligent computation. Compared with evolutionary algorithm, the artificial immune system used for solving MO problems (MOPs) has shown many good performances in improving the convergence speed and maintaining the diversity of the antibody population. However, the simple clonal selection computation has some difficulties in handling some more complex MOPs. In this paper, the simple clonal selection strategy is improved and a novel immune clonal algorithm (NICA) is proposed. The improvements in NICA are mainly focus on four aspects. 1) Antibodies in the antibody population are divided into dominated ones and nondominated ones, which is suitable for the characteristic of one multiobjective optimization problem has a series Pareto-optimal solutions. 2) The entire cloning is adopted instead of different antibodies having different clonal rate. 3) The clonal selection is based on the Pareto-dominance and one antibody is selected or not depending on whether it is a nondominated one, which is different from the traditional clonal selection manner. 4) The antibody population updating operation after the clonal selection is adopted, which makes antibody population under a certain size and guarantees the convergence of the algorithm. The influences of the main parameters are analyzed empirically. Compared with the existed algorithms, simulation results on MOPs and constrained MOPs show that NICA in most problems is able to And much better spread of solutions and better convergence near the true Pareto-optimal front.	artificial immune system;computation;evolutionary algorithm;genetic algorithm;mathematical optimization;multi-objective optimization;optimization problem;pareto efficiency;performance;simulation	Ronghua Shang;Licheng Jiao;Fang Liu;Wenping Ma	2012	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2010.2046328	mathematical optimization;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;artificial immune system;evolutionary computation	ML	26.49110843104428	-4.716478958901012	199390
37fdfd649024f8ce2bb0ea926759d60a07ac69f7	experimental assessment of differential evolution with grid-based parameter adaptation			differential evolution	Vasileios A. Tatsis;Konstantinos E. Parsopoulos	2018	International Journal on Artificial Intelligence Tools	10.1142/S0218213018600047	differential evolution;grid;artificial intelligence;machine learning;computer science	Robotics	25.07322283008891	-5.4594802241128	199566
1134b5456c3214378ca325ff7b9142d34ef732ee	single parent generalization of cellular automata rules	evolutionary computation;history;standards;cloning;arrays;automata;image color analysis;progenitor automata single parent generalization evolutionary computation apoptotic cellular automata rule generalization automata time history size crossover parameter tuning;generalisation artificial intelligence cellular automata;generalisation artificial intelligence;cellular automata;automata history evolutionary computation arrays cloning image color analysis standards	Generalization is a perennial issue in evolutionary computation. The ability of evolution to find excellent special-purpose solutions to a problem means that, in some cases, evolutionary techniques generalize poorly. In this study we demonstrate a system that generalizes apoptotic cellular automata rules from a small evaluation arena to a larger one. The generalization preserves many of the features of the cellular automata while increasing the size of the automata's time-history. The fidelity of the appearance of the generalized rules to their progenitors is high but varies for different progenitors. The generalization is attained by use of single parent techniques. These techniques employ a set of one or more immortal progenitors that are available for crossover but do not otherwise participate in the population. The form of single parent technique used here is novel and the study includes parameter tuning for its use.	automata theory;cellular automaton;evolutionary computation;performance tuning;the immortal	Daniel A. Ashlock;Sharon McNicholas	2012	2012 IEEE Congress on Evolutionary Computation	10.1109/CEC.2012.6256126	stochastic cellular automaton;continuous spatial automaton;growcut algorithm;quantum finite automata;computer science;nested word;artificial intelligence;quantum cellular automaton;machine learning;automata theory;ω-automaton;cloning;mathematics;automaton;mobile automaton;algorithm;evolutionary computation	Comp.	25.799390525982677	-9.392516611504472	199673
bc122ac152ea68bcff4f93efc55ca7866ecda9d6	on population variance and explorative power of invasive weed optimization algorithm	optimisation;evolutionary computation;exploratice power;approximation algorithms;search problems evolutionary computation mathematical analysis optimisation;efficient algorithm;biology;data mining;mathematical analysis;algorithm design and analysis mathematical analysis power generation design optimization dna computing space exploration intelligent robots recommender systems mimo encoding;inter generation variance;theoretical analysis;antennas;evoluionary computation;optimization;search problems;invasive weed optimization;evoluionary computation invasive weed optimization inter generation variance exploratice power;optimal algorithm;mimics;algorithm design and analysis;mathematical analysis population variance invasive weed optimization mataheuristic algorithm explorative search behavior weeds colonization weeds distribution	Theoretical analysis of mataheuristic algorithms is believed to be very important for understanding their internal search mechanism and thus to develop more efficient algorithms. In this article we present a simple mathematical analysis of the explorative search behavior of a recently developed metaheuristic algorithm called Invasive Weed Optimization (IWO). IWO is a novel ecologically inspired algorithm that mimics the process of weeds colonization and distribution. This work analyses the evolution of the population-variance over successive generations in IWO and thereby draws some important conclusions regarding the explorative power of the same. Experimental results have been provided to validate the theoretical treatment.	algorithm;ecology;mathematical optimization;metaheuristic	Prithwish Chakraborty;Gourab Ghosh Roy;Swagatam Das;Bijaya Ketan Panigrahi	2009	2009 World Congress on Nature & Biologically Inspired Computing (NaBIC)	10.1109/NABIC.2009.5393699	algorithm design;mathematical optimization;simulation;computer science;machine learning;antenna;evolutionary computation	AI	27.39884505409587	-6.636646211985799	199760
