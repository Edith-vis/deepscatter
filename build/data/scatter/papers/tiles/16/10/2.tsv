id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
9ca2aca349ed70d77297374326e900cd50467ec0	robust automatic calcium scoring for ct coronary angiography		Currently, an increased number of studies are being performed in order to evaluate the clinical value of calcium scoring on contrast enhanced computed tomography coronary angiography images. One major finding is the increased diagnosis time and manual effort required to accurately segment calcified lesions in the contrast enhanced data. In this paper, a novel approach for the fully automatic segmentation and quantification of calcified lesions in coronary computed tomography angiography is presented. The algorithm includes a robust segmentation threshold determination based on an automatically generated vessel-tree histogram. Thereby, lesions can be accurately segmented and scores can be determined without user interaction. Validation against manual scores obtained by a radiologist yielded a very high correlation, which indicates the clinical value of the presented method.	algorithm;ct scan;computed tomography angiography;radiology	Matthias Tessmann;Fernando Vega Higuera;Bernhard Bischoff;Jörg Hausleiter;Günther Greiner	2010			computed tomography angiography;computed tomography;histogram;angiography;radiology;computer science	Vision	38.17923873302665	-79.95617536121522	47652
e92e0881a3755e227dc8cc596107254199f77b90	3d surface texture analysis for early malignant melanoma diagnosis	surface direction disruption;true 2d centroid;6 light photometric stereo;surface texture;3d skin texture;malignant melanoma;surface magnitude disruption	Malignant melanoma (MM) is a life-threatening dermatological disease, the successful treatment of which relies heavily on early recovery and diagnosis. It is proposed that early MMs tend to have larger 3D topological magnitude and direction disruptions than benign lesions. With a view to capturing these 3D indications, a 6 light photometric stereo device has been developed to recover reliable 3D skin texture in the form of surface gradients. In order to characterise the 3D skin texture, two separate numerical methods have been proposed which quantify surface direction and magnitude disruption. A true 2D centroid which is the projection of the real 3D centroid on the image plane has been used to determine the reference angles and the surface direction disruption using minimum error estimation. This is a more accurate method than the conventionally defined centroid which is susceptible to intensity distortions. Preliminary studies on 30 lesions (of which 5 are MMs) have resulted in 80% specificity. This is better than those achieved through analysis of 2D skin line patterns 56% specificity providing the same sensitivity. This demonstrates the proposed 3D texture analysis can provide potentially very useful MM indicators in addition to existing 2D features.		Yan Ding;L. Smith	2007			computer vision;geography;optics;engineering drawing	Vision	38.76378730121705	-77.00416661038663	47958
79acd526a54ea8508bc80f64f5f4d7ac44f1f53b	tumornet: lung nodule characterization using multi-view convolutional neural network with gaussian process		Characterization of lung nodules as benign or malignant is one of the most important tasks in lung cancer diagnosis, staging and treatment planning. While the variation in the appearance of the nodules remains large, there is a need for a fast and robust computer aided system. In this work, we propose an end-to-end trainable multi-view deep Convolutional Neural Network (CNN) for nodule characterization. First, we use median intensity projection to obtain a 2D patch corresponding to each dimension. The three images are then concatenated to form a tensor, where the images serve as different channels of the input image. In order to increase the number of training samples, we perform data augmentation by scaling, rotating and adding noise to the input image. The trained network is used to extract features from the input image followed by a Gaussian Process (GP) regression to obtain the malignancy score. We also empirically establish the significance of different high level nodule attributes such as calcification, sphericity and others for malignancy determination. These attributes are found to be complementary to the deep multi-view CNN features and a significant improvement over other methods is obtained.	concatenation;convolutional neural network;disk staging;end-to-end principle;gaussian process;high-level programming language;image scaling	Sarfaraz Hussein;Robert Gillies;Kunlin Cao;Qi Song;Ulas Bagci	2017	2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)	10.1109/ISBI.2017.7950686	computer vision;machine learning	Vision	31.247546278235138	-76.4207386726164	48056
41dd5cd8d13c0c6172bf1e8cb368539c145c8693	multiscale and multilevel wavelet analysis of mammogram using complex neural network	multiscale wavelet analysis;phase encoded complex extreme learning machine;mammogram analysis;complex neural network;breast cancer	Mammography is an effective tool for early detection of breast cancer. The various abnormalities such as Microcalcification, Clusters, Masses, Spiculated lesions, Asymmetry and Architectural distortions are strong markers of breast cancer. Efficient diagnoses of these abnormalities from mammograms rely heavily on the kind of features extracted and the selection of classifier. In this paper, a novel methodology for microcalcification detection using multilevel wavelet analysis and Phase Encoded Complex Extreme Learning Machine is proposed. Generally, complex neural network operates only on complex features for classification. However, PECELM enables transforming the real-valued features to the complex domain to exploit the orthogonal decision boundaries of complex-valued classifiers for solving real-valued classification problems. This proposed methodology based on multiscale and multilevel Wavelet analysis on complex domain achieves an average efficiency of 95.41% and a maximum efficiency of 100%.	artificial neural network;wavelet transform	E. Malar;A. Kandaswamy;M. Gauthaam	2013		10.1007/978-3-319-03756-1_59	computer vision;computer science;breast cancer;machine learning;pattern recognition	ML	34.01863775935198	-74.15311913372047	48068
45997201df0eb636c4c35390a32012b40a1def5c	improved automatic exposure control using morphology-based disturbance recognition	medical image processing biological tissues diagnostic radiography dosimetry image recognition medical control systems;automatic exposure control morphology based disturbance recognition medical x ray imaging signal to noise ratio tissue scatter radiation effect morphology based filter;morphology based filtering dose control scatter x ray;detectors x ray imaging image segmentation robustness metals real time systems gray scale	In medical X-ray imaging, the detector intensity heavily influences the signal-to-noise ratio, and thus the image quality [1]. Consequently, image quality and patient dose are dependent on the performance of the Automatic Exposure Control. Introducing large opaque objects to the image, which can be considered disturbances for the dose control, leads to a loss of image quality (overexposed tissue) as well as an increased patient dose. The effect of scatter-radiation makes it difficult to exclude these disturbances from the image using simple thresholding. In this work, a morphology-based filter is proposed as a pre-processing step for the Automatic Exposure Control leading to a superior disturbance exclusion. The algorithm has been verified in a real-time environment and it is shown to be robust against large disturbances in the X-ray images.	algorithm;galaxy morphological classification;image quality;mathematical morphology;preprocessor;radiography;real-time clock;signal-to-noise ratio;thresholding (image processing);x-ray (amazon kindle)	Rolf Gaasbeek;Rick van der Maas;Mark den Hartog;Bram de Jager	2014	2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2014.6868108	computer vision;nuclear medicine;medical physics	Vision	37.66708191310134	-76.1030217726654	48503
643392c30d42a5e88606e3cab7ff98f24f28667a	improving the generalization of disease stage classification with deep cnn for glioma histopathological images	histopathology	In the field of histopathology, computer-assisted diagnosis systems are important in obtaining patient-specific diagnosis for various diseases and help define precision medicine. Therefore, many studies on automatic analysis methods for digital pathology images have been reported. One of the severe brain tumors is the Glioma can provide unique insights into identifying and grading disease stages. However, the number of tissue samples to be examined is enormous, and is a burden to pathologists because of the tedious manual evaluation required for efficient decision-making and diagnosis. Therefore, there is a strong demand for quick and automatic analysis to do that. In this study, we consider feature extraction and disease stage classification for Glioma images using automatic image analysis methods with deep learning techniques. By devising a custom made deep convolutional neural network (CNN) for disease stage classification we apply it on image data available on the cancer genome atlas for brain glioma in histopathology.	artificial neural network;convolutional neural network;deep learning;feature extraction;gene expression programming;image analysis;precision medicine	Asami Yonekura;Hiroharu Kawanaka;V. B. Surya Prasath;Bruce J. Aronow;Haruhiko Takase	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217831	glioma;computer science;machine learning;artificial intelligence;deep learning;convolutional neural network;precision medicine;digital pathology;feature extraction;medical imaging;disease	Vision	32.10086903872841	-75.7120270950571	48523
b7430efaa7058637238df2ea93eeb1fe186989f8	automatic segmentation of tumor-laden lung volumes from the lidc database	databases;tissues;computer aided diagnosis;volume rendering;lung;algorithms;chest;radiometric corrections	The segmentation of the lung parenchyma is often a critical pre-processing step prior to application of computer-aided detection of lung nodules. Segmentation of the lung volume can dramatically decrease computation time and reduce the number of false positive detections by excluding from consideration extra-pulmonary tissue. However, while many algorithms are capable of adequately segmenting the healthy lung, none have been demonstrated to work reliably well on tumor-laden lungs. Of particular challenge is to preserve tumorous masses attached to the chest wall, mediastinum or major vessels. In this role, lung volume segmentation comprises an important computational step that can adversely affect the performance of the overall CAD algorithm. An automated lung volume segmentation algorithm has been developed with the goals to maximally exclude extra-pulmonary tissue while retaining all true nodules. The algorithm comprises a series of tasks including intensity thresholding, 2-D and 3-D morphological operations, 2-D and 3-D floodfilling, and snake-based clipping of nodules attached to the chest wall. It features the ability to (1) exclude trachea and bowels, (2) snip large attached nodules using snakes, (3) snip small attached nodules using dilation, (4) preserve large masses fully internal to lung volume, (5) account for basal aspects of the lung where in a 2-D slice the lower sections appear to be disconnected from main lung, and (6) achieve separation of the right and left hemi-lungs. The algorithm was developed and trained to on the first 100 datasets of the LIDC image database.© (2012) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.		Walter G. O'Dell	2012		10.1117/12.911379	volume rendering	Vision	38.05569988279647	-79.09413333042184	48863
cd683f3e831d3f1706f860dfbbf9501561f3e77f	wall-based measurement features provides an improved ivus coronary artery risk assessment when fused with plaque texture-based features during machine learning paradigm	atherosclerosis;cardiovascular disease;carotid artery;coronary arteries;ultrasound imaging	BACKGROUND Planning of percutaneous interventional procedures involves a pre-screening and risk stratification of the coronary artery disease. Current screening tools use stand-alone plaque texture-based features and therefore lack the ability to stratify the risk.   METHOD This IRB approved study presents a novel strategy for coronary artery disease risk stratification using an amalgamation of IVUS plaque texture-based and wall-based measurement features. Due to common genetic plaque makeup, carotid plaque burden was chosen as a gold standard for risk labels during training-phase of machine learning (ML) paradigm. Cross-validation protocol was adopted to compute the accuracy of the ML framework. A set of 59 plaque texture-based features was padded with six wall-based measurement features to show the improvement in stratification accuracy. The ML system was executed using principle component analysis-based framework for dimensionality reduction and uses support vector machine classifier for training and testing-phases.   RESULTS The ML system produced a stratification accuracy of 91.28%, demonstrating an improvement of 5.69% when wall-based measurement features were combined with plaque texture-based features. The fused system showed an improvement in mean sensitivity, specificity, positive predictive value, and area under the curve by: 6.39%, 4.59%, 3.31% and 5.48%, respectively when compared to the stand-alone system. While meeting the stability criteria of 5%, the ML system also showed a high average feature retaining power and mean reliability of 89.32% and 98.24%, respectively.   CONCLUSIONS The ML system showed an improvement in risk stratification accuracy when the wall-based measurement features were fused with the plaque texture-based features.		Sumit K. Banchhor;Narendra D. Londhe;Tadashi Araki;Luca Saba;Petia Radeva;John R. Laird;Jasjit S. Suri	2017	Computers in biology and medicine	10.1016/j.compbiomed.2017.10.019	coronary artery disease;coronary arteries;support vector machine;computer science;principal component analysis;pattern recognition;dimensionality reduction;machine learning;artificial intelligence;classifier (linguistics);risk assessment;artery	ML	32.42388422064784	-78.26867764625214	48925
f73ae9158e7dbb5ae41965771425a85fb6139356	cytomorphometry of fine needle biopsy material from the breast cancer	nonparametric density estimation;digital image analysis;feature space;medical image;feature extraction;region growing;breast cancer	A computer system has been developed for evaluating the morphometrical feature extraction. The features are derived directly from a digital scan of breast fine needle biopsy slides. First the background elimination by thresholding hue component is applied, then the actual segmentation is done with region growing technique. The quality of feature space is measured with classifier based on nonparametric density estimation. The automatic system of malignancy classification was applied on a set of medical images with promising results.	computation;computer;experiment;feature extraction;feature vector;morphometrics;preprocessor;region growing;statistical classification;thresholding (image processing)	Andrzej Marciniak;Andrzej Obuchowicz;Roman Monczak;Mariusz Kolodzinski	2005		10.1007/3-540-32390-2_71	computer vision;feature vector;feature extraction;computer science;breast cancer;machine learning;pattern recognition;region growing	Vision	35.35632972428691	-75.41601970914654	48995
8e3dfb503a5df5ad7c9e44e1bc6a021f1f8be8b1	learning to detect blue-white structures in dermoscopy images with weak supervision		We propose a novel approach to identify one of the most significant dermoscopic criteria in the diagnosis of cutaneous Melanoma: the blue-whitish structure (BWS). In this paper, we achieve this goal in a Multiple Instance Learning (MIL) framework using only image-level labels indicating whether the feature is present or not. To this aim, each image is represented as a bag of (non-overlapping) regions where each region may or may not be identified as an instance of BWS. A probabilistic graphical model [1] is trained (in MIL fashion) to predict the bag (image) labels. As output, we predict the classification label for the image (i.e., the presence or absence of BWS in each image) and as well we localize the feature in the image. Experiments are conducted on a challenging dataset with results outperforming state-of-the-art techniques, with BWS detection besting competing methods in terms of performance. This study provides an improvement on the scope of modelling for computerized image analysis of skin lesions. In particular, it propounds a framework for identification of dermoscopic local features from weakly-labelled data.	dermatologic disorders;dermoscopy;graphical model;image analysis;multiple instance learning;silo (dataset);vasculitis, leukocytoclastic, cutaneous	Ali Madooei;Mark S. Drew;Hossein Hajimirsadeghi	2018	IEEE journal of biomedical and health informatics	10.1109/JBHI.2018.2835405	computer vision;pattern recognition;artificial intelligence;labeled data;feature extraction;computer science;probabilistic logic;image segmentation;text mining;graphical model	Vision	32.18091784052807	-75.51017739399686	49247
38233fd28c5a7a5b54fbaf325ff7f79e6ab7e347	automatic emphysema detection using weakly labeled hrct lung images		PURPOSE A method for automatically quantifying emphysema regions using High-Resolution Computed Tomography (HRCT) scans of patients with chronic obstructive pulmonary disease (COPD) that does not require manually annotated scans for training is presented.   METHODS HRCT scans of controls and of COPD patients with diverse disease severity are acquired at two different centers. Textural features from co-occurrence matrices and Gaussian filter banks are used to characterize the lung parenchyma in the scans. Two robust versions of multiple instance learning (MIL) classifiers that can handle weakly labeled data, miSVM and MILES, are investigated. Weak labels give information relative to the emphysema without indicating the location of the lesions. The classifiers are trained with the weak labels extracted from the forced expiratory volume in one minute (FEV1) and diffusing capacity of the lungs for carbon monoxide (DLCO). At test time, the classifiers output a patient label indicating overall COPD diagnosis and local labels indicating the presence of emphysema. The classifier performance is compared with manual annotations made by two radiologists, a classical density based method, and pulmonary function tests (PFTs).   RESULTS The miSVM classifier performed better than MILES on both patient and emphysema classification. The classifier has a stronger correlation with PFT than the density based method, the percentage of emphysema in the intersection of annotations from both radiologists, and the percentage of emphysema annotated by one of the radiologists. The correlation between the classifier and the PFT is only outperformed by the second radiologist.   CONCLUSIONS The presented method uses MIL classifiers to automatically identify emphysema regions in HRCT scans. Furthermore, this approach has been demonstrated to correlate better with DLCO than a classical density based method or a radiologist, which is known to be affected in emphysema. Therefore, it is relevant to facilitate assessment of emphysema and to reduce inter-observer variability.	bank (environment);ct pulmonary angiogram;ct scan;carbon monoxide diffusing capability test;chronic obstructive airway disease;conceptualization (information science);data curation;digital curation;expiration, function;extraction;filter bank;heart rate variability;high-resolution computed tomography;inter-rater reliability;large;lung diseases, obstructive;lung diseases;moderate response;multiple instance learning;normal statistical distribution;pino;pagyris ulla;pathological accumulation of air in tissues;patients;pulmonary emphysema;pulmonary function test/forced expiratory volume 1;pulmonary function tests;radiology;scanning;silo (dataset);spatial variability;structure of parenchyma of lung;tracer;version;bentiromide	Isabel Pino Peña;Veronika Cheplygina;Sofia Paschaloudi;Morten Vuust;Jesper Carl;Ulla Møller Weinreich;Lasse Riis Østergaard;Marleen de Bruijne	2018		10.1371/journal.pone.0205397	computed tomography;labeled data;diffusing capacity;mathematics;pulmonary function testing;radiology;lung;dlco;copd	ML	33.379181448536656	-79.43322210436288	49397
1c2b05dbf3b41201c858ae8c21a4ae37195e4471	fsed - feature selective edge detection	tissue specificity;image features;medical and health sciences;computed tomography;medical images;edge filter;medicin och halsovetenskap;convolution;edge detection;tissue specific edges;filters;biomedical imaging;gray levels;channel representation;gray scale;channel values;computer vision;engineering and technology;mr imaging;teknik och teknologier;medical image;image edge detection;medical image processing;magnetic resonance imaging;mr image;maximum likelihood detection;medicine;feature selection;convolution biomedical mri medical image processing edge detection;computer vision image edge detection gray scale filters laboratories biomedical imaging computed tomography magnetic resonance imaging maximum likelihood detection convolution;normalized convolution;medicin;mr image feature selective edge detection gray levels channel representation normalized convolution channel values edge filter tissue specific edges medical images;biomedical mri;feature selective edge detection	5 Previous Employment Associate Professor, January 1986 June 2000, Linköping University, Department of Electrical Engineering, Division of Computer Vision. Visiting Professor, September 1998 December 1998, Technical University of Denmark, Department of Mathematical Modeling, Section for Image Analysis. Acting Professor, July 1990 July 1991, Department of Electrical Engineering, Division of Computer Vision. Postdoctoral Fellow, September 1984 December 1985, The Rockefeller University, Laboratory of Neurobiology (Headed by Nobel Laureate Torsten Wiesel), New York. Research Assistant, January 1976 September 1984, Linköping University, Department of Electrical Engineering, Division of Computer Vision. Image Processing Consultant (50% employment), January 1984 September 1984 and January 1986 April 1986, Context Vision AB, Linköping. (50% leave of absence from Linköping University.)	computer vision;edge detection;electrical engineering;image analysis;image processing	Magnus Borga;Helge Malmgren;Hans Knutsson	2000		10.1109/ICPR.2000.905309	computer vision;edge detection;computer science;magnetic resonance imaging;pattern recognition;convolution;feature selection;feature;grayscale;computer graphics (images)	Vision	37.92355152556478	-73.12850764438394	49627
0ba2ff512899a96fc839c2075b9a26bdc3149fed	stafflines pattern detection using the swarm intelligence algorithm	binarization step;developed algorithm;stafflines pattern detection;optimization algorithm;handwritten music score;digital image;different subject;optical music recognition;state-of-the-art algorithm;swarm intelligence algorithm;swarm intelligence;preprocessing stage	binarization step;developed algorithm;stafflines pattern detection;optimization algorithm;handwritten music score;digital image;different subject;optical music recognition;state-of-the-art algorithm;swarm intelligence algorithm;swarm intelligence;preprocessing stage	algorithm;swarm intelligence	Weronika Piatkowska;Leszek Nowak;Marcin Piotr Pawlowski;Maciej Ogorzalek	2012		10.1007/978-3-642-33564-8_67	multi-swarm optimization;speech recognition;computer science;artificial intelligence;machine learning	Vision	28.774694065212024	-66.4166553482488	49718
420767168f337d195a186022887bcc12e5837836	breast ultrasound image classification and segmentation using convolutional neural networks		Due to the shortage and uneven distribution of medical resources all over the world, breast cancer diagnosis and treatment is a fundamental but vital problem, especially in developing countries. Breast ultrasound image classification and segmentation method by using Convolutional Neural Networks (CNN) can be a new efficient solution in early analysis and diagnosis. What’s more, the diagnosing of diversity of cancers is challenge in itself and the training of data-driven based CNN model also highly relay on dataset. In this paper, we first build a breast ultrasound dataset (with 1418 normal and 1182 cancerous samples) labeled by three radiologists from XiangYa Hospital of Hunan Province. And then, we propose a two-stage Computer-Aided Diagnosis (CAD) system to diagnose the breast cancer automatically. Firstly, the system utilize a pre-trained ResNet generated with transfer learning approach to excluded normal candidates, and then use an improved Mask R-CNN model for the accurate tumor segmentation. Experimental results show that the proposed system can achieve 98.72% precision and 98.05% recall for classification, and 85% (1.2% improvement) mAP and 82.7% (3.1% improvement) F1-Measure than the original Mask R-CNN model.	convolutional neural network;neural networks	Xiaozheng Xie;Faqiang Shi;Jianwei Niu;Xiaolan Tang	2018		10.1007/978-3-030-00764-5_19	convolutional neural network;breast cancer;transfer of learning;cad;economic shortage;computer science;artificial intelligence;pattern recognition;contextual image classification;breast ultrasound;segmentation	Vision	32.245946074966334	-75.74854357866315	49818
63d7200abe839b10cd60cc548101a88fd1313c75	abnormal gastric cell segmentation based on shape using morphological operations	image processing;abnormal cell detection;morphological operation;segmentation;stomach;roundness	Cancer is the fourth leading cause of death among medically certified deaths in Malaysia. The most reliable diagnostic method to diagnose gastric adenocarcinoma is by inspecting the microscopic images of samples obtained through biopsy. These images are analyses by pathologist to identify the presence of cancer. However the process is time consuming and the interpretation varies with different pathologist. The application of image analysis techniques can assist pathologist towards a more efficient and faster diagnosis. Thus, this paper introduces an image analysis framework to automatically recognize and distinguished between normal gastric and gastric adenocarcinoma cells. The framework consist of the three phases of image analysis; preprocessing phase where the color tone issues are solved by component separation; processing phase which includes the thresholding and morphological techniques to segment the cells; post processing to identify the perimeter, area and roundness of the cells. This study shows that it is possible to automatically recognize and differentiate images with normal and abnormal cells.		Noor Elaiza Abdul Khalid;Nurnabilah Samsudin;Rathiah Hashim	2012		10.1007/978-3-642-31075-1_54	computer vision;image processing;computer science;roundness;segmentation	Vision	37.27444621610621	-75.91892723771748	49883
497fa41b81cf25b33c45901f5635be01fbc8b4fa	characterization of pulmonary nodules: effects of size and feature type on reported performance	databases;evaluation performance;nodule;performance evaluation;pulmonary nodule;evaluacion prestacion;performance;pulmon;poumon;compte rendu;logistic regression;effet dimensionnel;system performance;three dimensional;lung;report;nodulo;size effect;nearest neighbor;characterization;subset selection;roc curve;rendimiento;efecto dimensional;caracterisation;caracterizacion;informe	Di erences in the size distribution of malignant and benign pulmonary nodules in databases used for training and testing characterization systems have a signi cant impact on the measured performance. The magnitude of this e ect and methods to provide more relevant performance results are explored in this paper. Twoand three-dimensional features, both including and excluding size, and two classi ers, logistic regression and distance-weighted nearest-neighbors (dwNN), were evaluated on a database of 178 pulmonary nodules. For the full database, the area under the ROC curve (AUC) of the logistic regression classi er for 2D features with and without size was 0.721 and 0.614 respectively, and for 3D features with and without size, 0.773 and 0.737 respectively. In comparison, the performance using a simple size-threshold classi er was 0.675. In the second part of the study, the performance was measured on a subset of 46 nodules from the entire subset selected to have a similar size-distribution of malignant and benign nodules. For this subset, performance of the size-threshold was 0.504. For logistic regression, the performance for 2D, with and without size, were 0.578 and 0.478, and for 3D, with and without size, 0.671 and 0.767. Over all the databases, logistic regression exhibited better performance using 3D features than 2D features. This study suggests that in systems for nodule classi cation, size is responsible for a large part of the reported performance. To address this, system performance should be reported with respect to the performance of a size-threshold classi er.	baseline (configuration management);database;logistic regression;randomness;receiver operating characteristic;space: above and beyond	Artit C. Jirapatnakul;Anthony P. Reeves;Tatiyana V. Apanasovich;Alberto M. Biancardi;David F. Yankelevitz;Claudia I. Henschke	2008		10.1117/12.770514	three-dimensional space;speech recognition;performance;computer performance;logistic regression;k-nearest neighbors algorithm;receiver operating characteristic	DB	34.012801084164145	-78.06951492420578	49903
1d17bc574dea057db55f216120a1b1e69a8db44b	3d case-based retrieval for interstitial lung diseases	lung tissue;clinical parameter;similar case;mean average retrieval precision;case distance measure;algorithmic side;hrct data;diagnosis workup;interstitial lung disease;automated lung tissue categorization;3 dimensional	In this paper, a computer–aided diagnosis (CAD) system that retrieves similar cases affected with an interstitial lung disease (ILDs) to assist the radiologist in the diagnosis workup is presented and evaluated. The multimodal inter–case distance measure is based on a set of clinical parameters as well as automatically segmented 3–dimensional regions of lung tissue in high–resolution computed tomography (HRCT) of the chest. A global accuracy of 75.1% of correct matching among five classes of lung tissues as well as a mean average retrieval precision at rank 1 of 71% show that automated lung tissue categorization in HRCT data is complementary to case–based retrieval both from the user’s viewpoint and also on the	ct scan;categorization;computer-aided design;high-resolution computed tomography;interstitial webpage;multimodal interaction;radiology	Adrien Depeursinge;Alejandro Vargas;Alexandra Platon;Antoine Geissbühler;Pierre-Alexandre Poletti;Henning Müller	2009		10.1007/978-3-642-11769-5_4	radiology;medicine;pathology;biological engineering	Vision	35.061369016970964	-78.52955793926509	49968
157460b130dc8c7d1b0c009dedebb9076b2306fd	incremental learning to segment micrographs	image labelling;microscopy;segmentation;microstructure;incremental learning;image analysis	An incremental approach to annotation of images is demonstrated for segmentation.Density functions from training mimic those output by traditional annotation methods.Less burdensome for microscopists and allows correction and control on the result.The rationale of manual annotation is more easily accepted with this method. Supervised learning approaches to image segmentation receive considerable interest due to their power and flexibility. However, the training phase is not painless, often being long and tedious. Accurate image labelling can take several hours of expert operators' valuable time. User interfaces are often specifically designed to assist the user for the task at hand. This is clearly unfeasible for most application domains.We propose a simple segmentation framework based on classification and supervised incremental learning. A statistical model of pixel classes is learnt by incrementally adding new sample image patches to automatically-learned probability functions. Learning is iterated and refined in a number of steps rather than being executed in a one-shot training phase. We show that one-shot training and incremental labelling tend to produce similar statistical models, as the number of iterations grows. Comparable classification results are thus obtained with considerably less human effort.		Gaetano Impoco;L. Tuminello	2015	Computer Vision and Image Understanding	10.1016/j.cviu.2015.03.007	computer vision;image analysis;microstructure;computer science;microscopy;machine learning;pattern recognition;segmentation	Vision	29.946553898442613	-72.54043619725239	50041
e42b667097b2241d2f25a3828053ff05dda2cdd5	secure arabic handwritten captcha generation using ocr operations	handwriting recognition;image segmentation;optical character recognition software;distortion;text recognition;captchas;context	Handwritten CAPTCHAs can be generated from pre-written or synthesized words, with added distortions and noise to survive OCR attacks. This paper takes a different approach for generating CAPTCHAs: use OCR operations themselves to secure the CAPTCHAs. Therefore, we utilize a number of operations found in many handwriting recognition systems (like, segmentation, baseline detection, etc.) to distort a pre-written word image itself, so that breaking the resulting CAPTCHA becomes more difficult. These OCR operations are in addition to the global image distortions that are generally done on the CAPTCHAs. The proposed method is reported for Arabic handwritten words as the cursive script of Arabic allows various OCR operations on it. To the best of our knowledge, this work is the first to generate Arabic handwritten CAPTCHAs. We evaluate our method on KHATT database of offline Arabic handwritten text. In terms of usability, we have achieved 88% to 90% accuracy. Security evaluation is done using holistic word recognition with accuracy less than 0.5%. Lexicon based attack is made difficult by working at Arabic sub-word level and then randomly selecting sub-words to build a CAPTCHA.	baseline (configuration management);captcha;distortion;handwriting recognition;holism;lexicon;online and offline;optical character recognition;randomness;usability	Suliman A. Alsuhibany;Mohammad Tanvir Parvez	2016	2016 15th International Conference on Frontiers in Handwriting Recognition (ICFHR)	10.1109/ICFHR.2016.0035	natural language processing;speech recognition;distortion;computer science;intelligent word recognition;machine learning;pattern recognition;captcha;handwriting recognition;image segmentation	Vision	31.82308705601315	-66.89564477423077	50320
44fa64188fbf03946870dd15368c541919cdd1e2	chromosome image recognition with local band patterns		To make a visual examination of a chromosome image for various chromosome abnormalities, individual chromosome regions have to be determined in the subject image and classified into the distinct chromosome types. We propose a subregion based method to improve this process. The proposed method regards each chromosome region as a series of subregions (local band patterns), and iterates a search for subregions in the image consecutively.	computer vision;experiment;iteration	Toru Abe;Chieko Hamada;Tetsuo Kinoshita	2009			computer vision;bioinformatics	Vision	38.01824594468223	-72.41236823413148	50358
eeac823e7287179c3517be1779be2152eddcfa4e	artificial intelligence based diagnosis for cervical lymph node malignancy using the point-wise gated boltzmann machine		This paper aims to build an artificial intelligence (AI) architecture for automated extraction of learned-from-data image features from contrast-enhanced ultrasound (CEUS) videos and to evaluate the AI architecture for classification between benign and malignant cervical lymph nodes. An AI architecture for CEUS feature extraction and classification was constructed by using the point-wise gated Boltzmann machine (PGBM). The PGBM consisted of task-relevant and task-irrelevant hidden units for both feature learning and feature selection, and the task-relevant units were connected to the support vector machine (SVM) to yield the likelihood for classification. The synthetic minority over-sampling technique was used to improve the classification ability for an unbalanced data set. Experimental evaluation was performed with the five-fold cross validation on a database of 127 lymph nodes (39 benign and 88 malignant) from 88 patients. The SVM likelihood exhibited a significant difference between benign and malignant cervical lymph nodes (0.74 ± 0.21 versus 0.33 ± 0.28,  $p< 0.001$ ). On the test set, the accuracy, precision, sensitivity, specificity, and Youden’s index of the AI architecture were 82.55%, 89.58%, 84.75%, 77.56%, and 62.32%, respectively. The AI architecture using the PGBM shows promising classification results, and it may be potentially used in clinical diagnosis for cervical lymph node malignancy.	artificial intelligence;boltzmann machine;cross-validation (statistics);feature extraction;feature learning;feature selection;oversampling;relevance;sampling (signal processing);sensitivity and specificity;support vector machine;synthetic intelligence;test set;unbalanced circuit	Qi Zhang;Yue Liu;Hong Han;Jun Shi;Wenping Wang	2018	IEEE Access	10.1109/ACCESS.2018.2873043	feature (computer vision);support vector machine;computer science;architecture;feature selection;feature extraction;cervical lymph nodes;artificial intelligence;test set;feature learning	AI	31.481599002331897	-77.05793955607197	50408
0fddce14a2ffac61eace0da74d7ce3fc6e8cdbe3	automatic feature point detection using deep convolutional networks for quantitative evaluation of facial paralysis	convolution;training;active appearance model;feature extraction;face;active shape model;tracking	Feature point detection is an important pre-processing step for quantitative evaluation of facial paralysis. Since the conventional methods such as active shape model (ASM) or active appearance model (AAM) are trained by using normal face and they are not possible to detect the feature points accurately for the face with paralysis. In this paper, we propose an automatic and accurate feature point detection method for quantitative evaluation of facial paralysis using deep convolutional neural networks (DCNN). The proposed method consists of two steps. We first use AAM for initial feature point detection. In the second step, a patch with the detected point at the center is used as an input of DCNN for refinement. Experiments demonstrated that the proposed method can significantly improve the detection accuracy of the conventional AAM.	active appearance model;active shape model;artificial neural network;automatic acoustic management;convolutional neural network;facial recognition system;preprocessor;refinement (computing)	Hiroki Yoshihara;Masataka Seo;Truc Hung Ngo;Naoki Matsushiro;Yen-Wei Chen	2016	2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)	10.1109/CISP-BMEI.2016.7852821	active shape model;face;computer vision;active appearance model;feature extraction;computer science;machine learning;pattern recognition;mathematics;tracking;convolution	Vision	36.23445899540714	-70.96385331322918	50692
5b185e1bf7a1b06dc3e846172d192f5ee6cf2c6a	semi-supervised outcome prediction for a type of human brain tumour using partially labeled mrs information	magnetic resonance spectroscopy;geodesic distance;generative topographic mapping;measurement technique;human brain	The diagnosis and prognosis of human brain tumours, especially when they are aggresive, are sensitive clinical tasks that usually require non-invasive measurement techniques. Outcome information for aggressive tumours, in particular, is usually scarce. In this paper, we aim to gauge the capability of a novel semi-supervised model, SS-Geo-GTM, to infer outcome stages from a very limited amount of available stage labels and Magnetic Resonance Spectroscopy (MRS) data corresponding to Glioblastoma, which is an aggressive tumor type. This model stems from a geodesic distance-based extension of Generative Topographic Mapping (Geo-GTM) that prioritizes neighbourhood relationships along a generated manifold embedded in the observed data space.	minimal recursion semantics;semiconductor industry	Raúl Cruz-Barbosa;Alfredo Vellido	2009		10.1007/978-3-642-04394-9_21	nuclear magnetic resonance spectroscopy;computer vision;geodesic;artificial intelligence	ML	28.676226026398833	-78.31844608120136	50712
eebc578ce4799a1e9473548eab6c1e4b7974c5dd	the grading of prostatic cancer in biopsy image based on two stages approach	gleason grading system;skeleton set;fractal dimension;estimation error;support vector machine;prostatic cancer;leave one out;prostate cancer	Prostatic biopsies provide the information for the determined diagnosis of prostatic cancer. Computer-aid investigation of biopsies can reduce the loading of pathologists and also inter- and intra-observer variability as well. In this paper, we proposed a two stages approach for prostatic cancer grading according to Gleason grading system. The first stage classifies biopsy images into clusters based on their Skeleton-set (SK-set), so that images in the same cluster consist of the similar two-tone texture. In the second stage, we analyzed the fractal dimension of sub-bands derived from the images of prostatic biopsies. We adopted the Support Vector Machines as the classifier and using the leaving-one-out approach to estimate error rate. The present experimental results demonstrated that 92.1% of accuracy for a set of 1000 pathological prostatic biopsy images.		Shao-Kuo Tai;Cheng-Yi Li;Yee-Jee Jan;Shu-Chuan Lin	2010		10.1007/978-3-642-16732-4_26	support vector machine;computer science;machine learning;fractal dimension	Robotics	34.92803471631017	-75.81863699028945	50847
20c08fab73e0efb77b7d53915739191dac3bd932	the handwritten sundanese palm leaf manuscript dataset from 15th century		In order to preserve the Sundanese palm leaf manuscripts, some digitization campaigns have been done recently. Then, for further access in education and research, the handwritten Sundanese palm leaf manuscript dataset called Lontar Sunda dataset has been created. The dataset was constructed from 66 pages of 27 collections of Sundanese palm leaf manuscripts from the 15th century. The dataset has been carried out with manuscripts from Garut, West Java, Indonesia. This paper presents the Sundanese dataset which is publicly available for scientific use. The groundtruth includes binarized images, annotations at word level and annotations at character level. The Sundanese dataset provides useful data to test word spotting, character/symbol recognition and binarization methods, and will facilitate the evaluation of developed methods.	international conference on document analysis and recognition;java;optical character recognition	Mira Suryani;Erick Paulus;Setiawan Hadi;Undang A. Darsa;Jean-Christophe Burie	2017	2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)	10.1109/ICDAR.2017.135	artificial intelligence;computer science;information retrieval;pattern recognition;image segmentation;spotting;digitization;symbol;palm;java;text mining	Vision	29.562003460087244	-67.59892956675569	51032
260ebc07910f15347f7ad1bbfb99ab596161a053	multiplexed wavelet transform technique for detection of microcalcification in digitized mammograms	breast cancer detection;breast neoplasms;female;edge detection;detection efficiency;parent child relationship;radiographic image enhancement;signal processing computer assisted;wavelet transform;automatic detection;image sequence;algorithms;humans;mammography;false positive;breast cancer;calcinosis	Wavelet transform (WT) is a potential tool for the detection of microcalcifications, an early sign of breast cancer. This article describes the implementation and evaluates the performance of two novel WT-based schemes for the automatic detection of clustered microcalcifications in digitized mammograms. Employing a one-dimensional WT technique that utilizes the pseudo-periodicity property of image sequences, the proposed algorithms achieve high detection efficiency and low processing memory requirements. The detection is achieved from the parent–child relationship between the zero-crossings [Marr-Hildreth (M-H) detector] /local extrema (Canny detector) of the WT coefficients at different levels of decomposition. The detected pixels are weighted before the inverse transform is computed, and they are segmented by simple global gray level thresholding. Both detectors produce 95% detection sensitivity, even though there are more false positives for the M-H detector. The M-H detector preserves the shape information and provides better detection sensitivity for mammograms containing widely distributed calcifications.	algorithm;arabic numeral 0;breast microcalcification;canny edge detector;chamaecyparis lawsoniana;coefficient;deriche edge detector;detectors;edge detection;grayscale;mammography;marr-family transcriptional regulatory protein, mycobacterium;marr prize;maxima and minima;multiplexing;physiologic calcification;pixel;processing (action);pseudo brand of pseudoephedrine;quasiperiodicity;requirement;smear - instruction imperative;smear campaign;thresholding (image processing);wavelet transform	M. G. Mini;V. P. Devassia;Tessamma Thomas	2004	Journal of Digital Imaging	10.1007/s10278-004-1020-8	computer vision;edge detection;medicine;pathology;type i and type ii errors;computer science;breast cancer;wavelet transform	Vision	37.900640820205474	-75.42157880563163	51089
d0c7cfd4109591fec665bb9b16317a83a3355a04	computerized analysis of lesions in 3d mr breast images	contrast enhanced;tissues;volume of interest;rule based;breast;three dimensional;breast imaging;indexation;thin plate spline	In this paper, a novel method is used for computerized lesion detection and analysis in three-dimensional(3D) contrast enhanced MR breast images. The automatic analysis involves three steps: 1) alignment between series; 2) extraction of suspicious regions; and 3) application of feature classification to each region. Assuming that there are only small geometric deformations after global registration, we adopted a 3D thin-plate spline based registration method, in which the control points are determined using 3D gradient and local correlation. Experiments show superior correlation between neighboring slices with 3D alignment as compared to a previous two-dimensional(2D) method. After registration, a new series named enhancement rate images(ERIs) are created. Suspicious volumes-of-interest(VOIs) are identified by 3D region labeling after thresholding the ERIs. Since carcinomas can typically be characterized by irregular borders and rapid and high uptake of contrast followed by a washout, a set of morphological features(irregularity, spiculation index, etc) and enhancement features(small volume enhancement rate, slope of average rate, etc) are calculated for selected VOIs and evaluated in a rule-based classifier to identify malignant lesions from benign lesions or normal tissues.© (2001) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Junyu Wang;Bin Zheng;Walter F. Good;Xiao Hui Wang	2001		10.1117/12.431064	computer vision;pathology;geography;biological engineering	Vision	38.85218419741289	-77.91842969465519	51191
4a7c166d444e9397b130547d1d4f7151b71847f1	machine learning for clinical diagnosis from functional magnetic resonance imaging	brain;image classification;clinical diagnosis;drug addiction;machine learning clinical diagnosis magnetic resonance imaging brain machine learning algorithms humans magnetic analysis learning systems boosting information analysis;feature extraction biomedical mri brain image sequences learning artificial intelligence image classification;patient self report clinical diagnosis functional magnetic resonance imaging human brain image sequence 3d brain images brain activations fmri analysis machine learning;machine learning;feature extraction;functional magnetic resonance images;drug use;brain imaging;brain activation;learning artificial intelligence;side information;human brain;biomedical mri;image sequences	Functional magnetic resonance imaging (fMRI) has enabled scientists to look into the active human brain. FMRI provides a sequence of 3D brain images with intensities representing brain activations. Standard techniques for fMRI analysis traditionally focused on finding the area of most significant brain activation for different sensations or activities. In this paper, we explore a new application of machine learning methods to a more challenging problem: classifying subjects into groups based on the observed 3D brain images when the subjects are performing the same task. Here we address the separation of drug-addicted subjects from healthy non-drug-using controls. In this paper, we explore a number of classification approaches. We introduce a novel algorithm that integrates side information into the use of boosting. Our algorithm clearly outperformed well-established classifiers as documented in extensive experimental results. This is the first time that machine learning techniques based on 3D brain images are applied to a clinical diagnosis that currently is only performed through patient self-report. Our tools can therefore provide information not addressed by traditional analysis methods and substantially improve diagnosis.	algorithm;artificial neural network;boosting (machine learning);causality;demarcation point;feature selection;heart rate variability;machine learning;pattern recognition;resonance	Lei Zhang;Dimitris Samaras;Dardo Tomasi;Nora D. Volkow;Rita Z. Goldstein	2005	2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)	10.1109/CVPR.2005.219	computer vision;contextual image classification;feature extraction;computer science;artificial intelligence;machine learning;neuroimaging	Vision	25.20531386190059	-77.99325857528547	51290
bc88d04da184dd982eac587c5402221b193f04b2	accelerometer-based gait recognition by sparse representation of signature points with clusters	biomedical monitoring;pedestrian safety;poison control;sensors;injury prevention;safety literature;gait recognition;traffic safety;injury control;probes;acceleration;home safety;injury research;safety abstracts;human factors;occupational safety;safety;safety research;sparse representation accelerometers biometrics gait dataset gait recognition signature points sps;accident prevention;violence prevention;acceleration gait recognition accelerometers probes biomedical monitoring sensors educational institutions;bicycle safety;signature points sparse representation accelerometer based gait recognition biometric equal error rate step cycles classifier sp phase propinquity multiscale sp extraction method;signal representation accelerometers biometrics access control feature extraction gait analysis pattern clustering signal classification;poisoning prevention;accelerometers;falls;ergonomics;suicide prevention	Gait, as a promising biometric for recognizing human identities, can be nonintrusively captured as a series of acceleration signals using wearable or portable smart devices. It can be used for access control. Most existing methods on accelerometer-based gait recognition require explicit step-cycle detection, suffering from cycle detection failures and intercycle phase misalignment. We propose a novel algorithm that avoids both the above two problems. It makes use of a type of salient points termed signature points (SPs), and has three components: 1) a multiscale SP extraction method, including the localization and SP descriptors; 2) a sparse representation scheme for encoding newly emerged SPs with known ones in terms of their descriptors, where the phase propinquity of the SPs in a cluster is leveraged to ensure the physical meaningfulness of the codes; and 3) a classifier for the sparse-code collections associated with the SPs of a series. Experimental results on our publicly available dataset of 175 subjects showed that our algorithm outperformed existing methods, even if the step cycles were perfectly detected for them. When the accelerometers at five different body locations were used together, it achieved the rank-1 accuracy of 95.8% for identification, and the equal error rate of 2.2% for verification.	access control;algorithm;biometrics;code;collections (publication);cycle detection;gait analysis;neural coding;regular expression;sephs1 gene;sense of identity (observable entity);silo (dataset);smart device;sparse approximation;sparse matrix;verification of theories;wearable computer;accelerometers	Yuting Zhang;Gang Pan;Kui Jia;Minlong Lu;Yueming Wang;Zhaohui Wu	2015	IEEE Transactions on Cybernetics	10.1109/TCYB.2014.2361287	acceleration;simulation;computer science;suicide prevention;sensor;human factors and ergonomics;injury prevention;data mining;computer security;accelerometer	Vision	26.116109804475975	-68.74186615922916	51308
79cebff06ad3f71193645af403b6563d0786eeb6	retinal vessel detection in wide-field fluorescein angiography with deep neural networks: a novel training data generation approach		Retinal blood vessel detection is a crucial step in automatic retinal image analysis. Recently, deep neural networks have significantly advanced the state of the art for retinal blood vessel detection in color fundus (CF) images. Thus far, similar gains have not been seen in fluorescein angiography (FA) because the FA modality is entirely different from CF and annotated training data has not been available for FA imagery. We address retinal vessel detection in wide-field FA images with generative adversarial networks (GAN) via a novel approach for generating training data. Using a publicly available dataset that contains concurrently acquired pairs of CF and fundus FA images, vessel maps are detected in CF images via a pre-trained neural network and registered with fundus FA images via parametric chamfer matching to a preliminary FA vessel detection map. The co-aligned pairs of vessel maps (detected from CF images) and fundus FA images are used as ground truth labeled data for de novo training of a deep neural network for FA vessel detection. Specifically, we utilize adversarial learning to train a GAN where the generator learns to map FA images to binary vessel maps and the discriminator attempts to distinguish generated vs. ground-truth vessel maps. We highlight several important considerations for the proposed data generation methodology. The proposed method is validated on VAMpIRE dataset that contains high-resolution wide-field FA images and manual annotation of vessel segments. Experimental results demonstrate that the proposed method achieves an estimated ROC AUC of 0.9758.		Li Ding;Ajay E Kuriyan;Rajeev Ramchandran;Gaurav Sharma	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451482	labeled data;computer vision;fluorescein angiography;angiography;artificial neural network;training set;pattern recognition;artificial intelligence;computer science;ground truth;fundus (eye)	Vision	32.000991814166866	-75.5350210027783	51367
0ed981a0596b0e419e64bdcb7a471a1455b7e42b	simultaneous segmentation of leukocyte and erythrocyte in microscopic images using a marker-controlled watershed algorithm		The density or quantity of leukocytes and erythrocytes in a unit volume of blood, which can be automatically measured through a computer-based microscopic image analysis system, is frequently considered an indicator of diseases. The segmentation of blood cells, as a basis of quantitative statistics, plays an important role in the system. However, many conventional methods must firstly distinguish blood cells into two types (i.e., leukocyte and erythrocyte) and segment them in independent procedures. In this paper, we present a marker-controlled watershed algorithm for simultaneously extracting the two types of blood cells to simplify operations and reduce computing time. The method consists of two steps, that is, cell nucleus segmentation and blood cell segmentation. An image enhancement technique is used to obtain the leukocyte marker. Two marker-controlled watershed algorithms are based on distance transformation and edge gradient information to acquire blood cell contour. The segmented leukocytes and erythrocytes are obtained simultaneously by classification. Experimental results demonstrate that the proposed method is fast, robust, and efficient.		Huisi Miao;Changyan Xiao	2018		10.1155/2018/7235795	computer vision;blood cell;artificial intelligence;software design;watershed;computer science;segmentation	ML	38.58550990899493	-76.12111460793912	51555
d225540e353172347dfbb94e8580444b5d6a3bc7	the design of intelligent transfusion system based on computer vision	computers;temporal difference;image segmentation;liquid level detection;drug delivery systems;image matching;intelligent systems computer vision image segmentation optical sensors algorithm design and analysis computational intelligence competitive intelligence image motion analysis paper technology hardware;noise resistant ability intelligent transfusion system computer vision image segmentation liquid level detection template matching;computer vision;projection analysis liquid level temporal difference accumulative difference;optical imaging;accumulative difference;automatic detection;intelligent transfusion system;image segmentation computer vision drug delivery systems image matching;artificial intelligence;projection analysis;optical sensors;noise resistant ability;liquid level;template matching;algorithm design and analysis	This paper discusses a type of intelligent transfusion system based on computer vision, which key is the algorithm of image segmentation and liquid level detection. The template matching is adopted for image segmentation, and a fast and efficient automatic detection algorithm is proposed to detect liquid level by designing temporal difference, accumulative difference and projection analysis to realize automatic detect liquid level. The algorithm has the advantages of stability noise-resistant ability, rapid and simple, etc. Experimental results of the algorithm show that the algorithm is effective and feasible.	algorithm;computer vision;image segmentation;template matching;temporal difference learning	Huasheng Zhu	2009	2009 Second International Symposium on Computational Intelligence and Design	10.1109/ISCID.2009.140	temporal difference learning;algorithm design;computer vision;simulation;template matching;computer science;machine learning;optical imaging;image segmentation	Vision	38.46861758955983	-68.68498629916992	51632
8bf0b2801fc412a7add3a125633af0eb181bebc2	effect of spider-web-plot in mr brain image classification	spider web plot;classification;machine learning;magnetic resonance imaging	"""This letter researched on the effect of spider-web-plot, which was proposed in the literature """"M. Saritha, K.P. Joseph, A.T. Mathew, Classification of MRI brain images using combined wavelet entropy based spider web plots and probabilistic neural network, Pattern Recognit. Lett. 34 (2013) 2151-2156"""". We found it was unnecessary to use spider-web-plot as feature transform method. In addition, our simulation results showed that removing the procedure of spider-web-plot yielded the same classification accuracy of 100%."""	computer vision	Yudong Zhang;Zhengchao Dong;Genlin Ji;Shuihua Wang	2015	Pattern Recognition Letters	10.1016/j.patrec.2015.04.016	biological classification;computer science;artificial intelligence;magnetic resonance imaging;machine learning;data mining	Vision	33.299863091716794	-73.00714164180862	51692
387e4f3dd2892ec65847e9f1ca8542c31003ae89	breast cancer histopathological image classification via deep active learning and confidence boosting		Classify image into benign and malignant is one of the basic image processing tools in digital pathology for breast cancer diagnosis. Deep learning methods have received more attention recently by training with large-scale labeled datas, but collecting and annotating clinical data is professional and time-consuming. The proposed work develops a deep active learning framework to reduce the annotation burden, where the method actively selects the valuable unlabeled samples to be annotated instead of random selecting. Besides, compared with standard query strategy in previous active learning methods, the proposed query strategy takes advantage of manual labeling and auto-labeling to emphasize the confidence boosting effect. We validate the proposed work on a public histopathological image dataset. The experimental results demonstrate that the proposed method is able to reduce up to 52% labeled data compared with random selection. It also outperforms deep active learning method with standard query strategy in the same tasks.		Baolin Du;Qi Qi;Han Zheng;Yue Huang;Xinghao Ding	2018		10.1007/978-3-030-01421-6_11	image processing;boosting (machine learning);breast cancer;machine learning;pattern recognition;active learning;deep learning;digital pathology;contextual image classification;annotation;computer science;artificial intelligence	Vision	31.751357381126	-73.93525137247077	51759
dcdeefd86efce020663db8130d760329a6aa3d7c	comparison of the task performances with the multi-display computer	data hiding;statistical analysis data encapsulation digital signatures feature extraction handwritten character recognition;biometric authentication;binary image;biometric authentication methods handwritten signature authentication scheme integrated statistical analysis bi color images data hiding data extraction binary images;digital signatures;data encapsulation;authentication statistical analysis watermarking data encapsulation computer science data mining signal processing protection robustness image generation;bi color images;statistical analysis;digital media;biometric authentication methods;data extraction;feature extraction;integrated statistical analysis;binary images;user authentication;handwritten character recognition;color image;handwritten signature authentication scheme	For this study we are going to apply a type of computer tasks which are used in an actual control room. Subjects are supposed to perform the primary task (typing task watching the main monitor) and the secondary task (clicking targets with the mouse, which appear randomly in the sub-monitor) at the same time. The secondary tasks were differentiated with three different task intensities. During the experiment, the primary and secondary tasks were measured and evaluated depending on the intensities of the subtasks and the locations of the sub-monitors. Followings are the conclusions which were obtained after the evaluation: 1) The higher the task intensity is, the lower the task performance. 2) Regardless of the task intensity, the task performance of the subtask is high in the center of the monitor. When the task intensity is low, the center section of the monitor becomes the starting point for searching. 3) When the task intensity is high, the task performance in the left section of the monitor becomes low.	performance;randomness	Keun-Sang Park;Young-deog Yun;Chang-Han Kim;Seoung Soo Lee	2007	2007 International Conference on Computational Science and its Applications (ICCSA 2007)	10.1109/ICCSA.2007.44	binary image;computer science;data mining;internet privacy;world wide web	Robotics	30.86270628465586	-69.18407345005525	51760
25c465079e4483471f9562cdb06ac103283af0ef	tumor localization in tissue microarrays using rotation invariant superpixel pyramids	histograms;biological tissues;tumours cancer image classification medical image processing;image segmentation;rotation invariant spatial pyramid tumor classification superpixels spatial bag of words;superpixels;superpixel classification technique tumor localization tissue microarray histopathology image analysis breast cancer histopathology tumor region superpixel representation visual structure cellular compartment connective tissue lumen fatty tissue semantic segmentation rotation invariant spatial pyramid representation bags of superpixel oestrogen receptor stained tma spot;visualization;feature extraction;rotation invariant spatial pyramid;tumors;tumor classification;image analysis;spatial bag of words;tumors biological tissues histograms visualization image segmentation feature extraction image analysis	Tumor localization is an important component of histopathology image analysis; it has yet to be reliably automated for breast cancer histopathology. This paper investigates the use of superpixel classification to localize tumor regions. A superpixel representation retains information about visual structures such as cellular compartments, connective tissue, lumen and fatty tissue without having to commit to semantic segmentation at this level. In order to localize tumor in large images, a rotation invariant spatial pyramid representation is proposed using bags-of-superpixels. The method is evaluated on expert-annotated oestrogen-receptor stained TMA spots and compared to other superpixel classification techniques. Results demonstrate that it performs favorably.	image analysis;logical connective;microarray;pyramid (image processing);tower mounted amplifier	Shazia Akbar;Lee Jordan;Alastair M. Thompson;Stephen J. Mckenna	2015	2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2015.7164111	computer vision;image analysis;visualization;pathology;feature extraction;computer science;pattern recognition;histogram;image segmentation	Vision	36.29206000769413	-74.05766532583955	51868
e28b013007a689a9a02a46637bced115e2c8f043	automated non-mass enhancing lesion detection and segmentation in breast dce-mri		Non-mass enhancing lesions (NME) constitute a diagnostic challenge in dynamic contrast enhanced magnetic resonance imaging (DCE-MRI) of the breast. Computer Aided Diagnosis (CAD) systems provide physicians with advanced tools for analysis, assessment and evaluation that have a significant impact on the diagnostic performance. Here, we propose a new approach for the specific problem of NME detection and segmentation, by taking advantage of independent component analysis (ICA) to extract a data-driven dynamic characterization of tissue. A set of independent sources was obtained from a dataset of patients, and the dynamic behavior of the different tissues was described by multiple dynamic curves, together with a set of eigenimages describing the scores for each voxel. A new test image is projected onto the independent source space using the unmixing matrix, and each voxel is classified by a support vector machine (SVM) that has already been trained with manually delineated data. A solution to the high false positive rate problem is proposed by controlling the SVM hyperplane location. The CAD system is trained and validated, reaching a DSC coefficient of 0.7215 for NME segmentation.	coefficient;computer-aided design;contrast ratio;independent computing architecture;independent component analysis;mathematical optimization;resonance;sensitivity and specificity;standard test image;supervised learning;support vector machine;voxel	Ignacio Álvarez;Javier Ramírez;Juan Manuel Górriz;Katja Pinker-Domenig;Anke Meyer-Bäse	2018	CoRR		false positive rate;voxel;support vector machine;computer-aided diagnosis;independent component analysis;pattern recognition;computer science;enhancing lesion;artificial intelligence;segmentation;standard test image	ML	34.22351922904379	-76.76914353111471	51991
c977e087d1ded8bfce620d5ca670ddad6112ae9b	prognostic reporting of p53 expression by image analysis in glioblastoma patients: detection and classification		In this paper, we present a computer aided diagnosis system focusing on one important diagnostic branchpoint in clinical decision-making: prognostic reporting of p53 expression in glioblastoma patients. Studies in other tumor pa- radigms have shown that the staining intensity correlates with TP53 mutation status, and that gliomas show inter-tumoral heterogeneity in p53 mutation status. Increasing diagnostic accuracy by computer-aided image analysis algorithms would deliver an objective assessment of such prognostic biomark- ers. We proposed a method for the detection and classification of positive and negative cells in digitized p53-stained images by means of a novel adaptive thresholding for the detection, and two-step rule based on weighted color and intensity for the classification. The proposed thresholding technique is able to correctly locate both positive and negative cells by effectively addressing the closely connected cells problem, and records a promising 85% average precision and 88% average recall rate. On the other hand, the proposed two- step rule achieves 81% classification accuracy, which is comparable with neu- ropathologists' markings.	image analysis	Mohammad Faizal Ahmad Fauzi;Hamza N. Gokozan;Christopher R. Pierson;José Javier Otero;Metin Nafi Gürcan	2015		10.1007/978-3-319-19156-0_17	medicine;pathology;bioinformatics;data mining	Vision	35.10728651052867	-76.26613915412898	52321
ef1d10f40474bdf9eb76ed6a37aed308cae04615	stochastic segment modeling for offline handwriting recognition	handwritten character image;handwriting recognition;image segmentation;stochastic processes handwriting recognition hidden markov models image segmentation character recognition character generation training data image recognition feature extraction data mining;support vector machines;structural feature extraction;hidden markov model;image matching;optical character recognition;training;character segmentation;text analysis feature extraction handwriting recognition handwritten character recognition hidden markov models image classification image matching image segmentation learning artificial intelligence;hmm;image classification;text analysis;handwritten arabic document;offline handwriting recognition;hidden markov models stochastic segment modeling optical character recognition;hidden markov models;machine learning;stochastic processes;structural matching;feature extraction;text analysis offline handwriting recognition hidden markov modeling hmm image segmentation handwritten character image connected component machine learning structural feature extraction stochastic character segment image classification structural matching handwritten arabic document;mathematical model;hidden markov modeling;learning artificial intelligence;connected component;stochastic segment modeling;handwritten character recognition;stochastic character segment	In this paper, we present a novel approach for incorporating structural information into the hidden Markov Modeling (HMM) framework for offline handwriting recognition. Traditionally, structural features have been used in recognition approaches that rely on accurate segmentation of words into smaller units (sub-words or characters). However, such segmentation based approaches do not perform well on real-world handwritten images, because breaks and merges in glyphs typically create new connected components that are not observed in the training data. To mitigate the problem of having to derive accurate segmentation from connected components, we present a novel framework where the HMM based recognition system trained on shorter-span features is used to generate the 2-D character images (the “Stochastic Segments”), and then another classifier that uses structural features extracted from the stochastic character segments generates a new set of scores. Finally, the scores from the HMM system and from structural matching are used in combination to generate a hypothesis that is better than the results from either the HMM or from structural matching alone. We demonstrate the efficacy of our approach by reporting experimental results on a large corpus of handwritten Arabic documents.	connected component (graph theory);glyph;handwriting recognition;markov chain;online and offline;text corpus	Premkumar Natarajan;Krishna Subramanian;Anurag Bhardwaj;Rohit Prasad	2009	2009 10th International Conference on Document Analysis and Recognition	10.1109/ICDAR.2009.278	support vector machine;contextual image classification;speech recognition;connected component;feature extraction;computer science;machine learning;pattern recognition;mathematical model;image segmentation;optical character recognition;hidden markov model	AI	32.89928043462662	-66.51199611579915	52690
0c7e410552ab459ea5049534ca18dfb1d8c2de8f	segmentation of head and neck organs-at-risk in longitudinal ct scans combining deformable registrations and convolutional neural networks		Automated segmentation of organs-at-risk (OAR) in follow-up images of the patient acquired during the course of treatment could greatly facilitate adaptive treatment planning in radiotherapy. Instead of segmenting each image separately, the segmentation could be improved by making use of the additional information provided by longitudinal data of previously segmented images of the same patient. We propose a tool for automated segmentation of longitudinal data that combines deformable image registration (DIR) and convolutional neural networks (CNN). The segmentation propagated by DIR from a previous image onto the current image and the segmentation obtained by a separately trained cross-sectional CNN applied to the current image, are given as input to a longitudinal CNN, together with the images itself, that is trained to optimally predict the manual ground truth segmentation using all available information. Despite the fairly limited amount of training data available in this study, a significant improvement of the segmentations of four different OAR in head and neck CT scans was found compared to both the results of DIR and the cross-sectional CNN separately.	ct scan;convolutional neural network;neural networks	Liesbeth Vandewinckele;David Robben;Wouter Crijns;Frederik Maes	2018		10.1007/978-3-030-00889-5_17	market segmentation;convolutional neural network;computer vision;training set;image registration;ground truth;radiation treatment planning;computer science;artificial intelligence;segmentation	Vision	30.60297002240551	-74.9251704532514	52694
227f48cf61c41c7c3efc895276fb5e34c21cfe3c	molecular biological characteristics based hierarchical mumford-shah vector-model for the delineation of biological target volumes corresponding to head and neck tumors	image segmentation;tumours image segmentation medical image processing molecular biophysics positron emission tomography radiation therapy;clinical target volume molecular biological characteristics hierarchical mumford shah vector model biological target volumes delineation head and neck tumors positron emission tomography petguided radiotherapy treatment planning hmsmv image contrast image busyness image standard uptake value level set flow adaptive volume growing algorithm radiation oncologists gross target volume sensitivity specificity similarity planning target volume;tumours;positron emission tomography;positron emission tomography tumors computed tomography biology planning image segmentation educational institutions;medical image processing;molecular biophysics;radiation therapy	To more accurately and precisely delineate a biologic target volume (BTV) for the positron emission tomography (PET)-guided radiotherapy treatment planning, we proposed a novel Hierarchical Mumford-Shah Vector Model (HMSMv), where the image-vector was composed of the molecular biological characteristics such as contrast, busyness and the standard uptake value (SUV) of tumors. The BTV was delineated via the propagation of the level set flow of the proposed HMSMv. The propagation took place inside a ring-volume of interest (VOI) which was defined by an adaptive volume-growing algorithm based on the PET SUV, contrast and busyness of a tumor. Four patient studies were assessed and visually inspected by two radiation oncologists (Suyu Zhu and Zaijie Huang). Compared the resulting BTV with the gross target volume (GTV) of one patient study, the sensitivity, specificity and similarity were 92.28%, 87.29%, 79.28% respectively. Moreover, all of four BTVs were between the corresponding GTV and planning target volume (PTV). Most of the BTVs were between the GTV and the clinical target volume (CTV). The results demonstrated that the proposed method can delineate the BTVs of nasopharyngeal carcinomas more accurately and precisely than the manual delineation and also the threshold segmentation method with SUV of 2.5 as the threshold. The GTV, CTV, and PTV were manually delineated by the two radiation oncologists based on PET, CT and MRI images for the intensity modulated radiotherapy (IMRT) planning of the four patients.	brake to vacate;ct scan;carcinoma;clinical target volume;ephedra sinica;gross target volume;head and neck structure;high-intensity interval training;modulation;nasopharyngeal neoplasms;nasopharynx;neck neoplasms;occur (action);pet/ct scan;patients;planning target volume;polyethylene terephthalate;positron-emission tomography;positrons;radiotherapy, intensity-modulated;region of interest;segmentation action;sensitivity and specificity;software propagation;standardized uptake value;x-ray computed tomography;algorithm;biology (field);wu zhu yu extract	Guocai Liu;Weili Yang;Suyu Zhu;Qiu Huang;Zaijie Huang;Haiyan Wu;Min Liu;Wenlin Huang;Bin Liu;Jinguang Liu;Bingqiang Hu;Yi Mo;Jiutang Zhang;Biao Zeng;Yuan Yuan;Xiang Peng;Ke Liu;Jumei Zhou	2013	2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2013.6610255	radiation therapy;radiology;medicine;computer science;image segmentation;nuclear medicine;medical physics;molecular biophysics	Visualization	38.9848129557859	-78.43686325514018	52989
19944dac254ecb30b8cfd1a376c2edda72df6aca	accurate and high throughput cell segmentation method for mouse brain nuclei using cascaded convolutional neural network		Recent innovations in tissue clearing and light sheet microscopy allow rapid acquisition of three-dimensional micron resolution images in fluorescently labeled brain samples. These data allow the observation of every cell in the brain, necessitating an accurate and high-throughput cell segmentation method in order to perform basic operations like counting number of cells within a region; however, large computational challenges given noise in the data and sheer number of features to identify. Inspired by the success of deep learning technique in medical imaging, we propose a supervised learning approach using convolution neural network (CNN) to learn the non-linear relationship between local image appearance (within an image patch) and manual segmentations (cell or background at the center of the underlying patch). In order to improve the segmentation accuracy, we further integrate high-level contextual features with low-level image appearance features. Specifically, we extract contextual features from the probability map of cells (output of current CNN) and train the next CNN based on both patch-wise image appearance and contextual features, extending previous methods into a cascaded approach. Using (a) high-level contextual features extracted from the cell probability map and (b) the spatial information of cell-to-cell locations, our cascaded CNN progressively improves the segmentation accuracy. We have evaluated the segmentation results on mouse brain images, and compared conventional image processing approaches. More accurate and robust segmentation results have been achieved with our cascaded CNN method, indicating the promising potential of our proposed cell segmentation method for use in large tissue cleared images. © Springer International Publishing AG 2017 G. Wu et al. (Eds.): Patch-MI 2017, LNCS 10530, pp. 55–62, 2017. DOI: 10.1007/978-3-319-67434-6_7	artificial neural network;brain implant;cell (microprocessor);chapel;computation;convolution;convolutional neural network;deep learning;emoticon;high- and low-level;high-throughput computing;ibm notes;image processing;lecture notes in computer science;medical imaging;multiple encryption;nonlinear system;springer (tank);supervised learning;throughput	Qian Wang;Shaoyu Wang;Xiaofeng Zhu;Tianyi Liu;Zachary Humphrey;Vladimir Ghukasyan;Mike Conway;Erik Scott;Giulia Fragola;Kira Bradford;Mark J. Zylka;Ashok Krishnamurthy;Jason L. Stein;Guorong Wu	2017		10.1007/978-3-319-67434-6_7	computer science;pattern recognition;light sheet fluorescence microscopy;computer vision;convolutional neural network;image processing;supervised learning;spatial analysis;deep learning;medical imaging;artificial intelligence;segmentation	Vision	30.54267088611488	-74.27260999569604	53164
2f9a403568543f0dd153a3525df81676ac340107	andriod device-based cervical cancer screening for resource-poor settings	android device-based cervical cancer screening;automated cervical cancer detection;low-resource cervical cancer screening	Visual inspection with acetic acid (VIA) is an effective, affordable and simple test for cervical cancer screening in resource-poor settings. But considerable expertise is needed to differentiate cancerous lesions from normal lesions, which is lacking in developing countries. Many studies have attempted automation of cervical cancer detection from cervix images acquired during the VIA process. These studies used images acquired through colposcopy or cervicography. However, colposcopy is expensive and hence is not feasible as a screening tool in resource-poor settings. Cervicography uses a digital camera to acquire cervix images which are subsequently sent to experts for evaluation. Hence, cervicography does not provide a real-time decision of whether the cervix is normal or not, during the VIA examination. In case the cervix is found to be abnormal, the patient may be referred to a hospital for further evaluation using Pap smear and/or biopsy. An android device with an inbuilt app to acquire images and provide instant results would be an obvious choice in resource-poor settings. In this paper, we propose an algorithm for analysis of cervix images acquired using an android device, which can be used for the development of decision support system to provide instant decision during cervical cancer screening. This algorithm offers an accuracy of 97.94%, a sensitivity of 99.05% and specificity of 97.16%.	acetic acids;android;attempt;cns disorder;cervix carcinoma;colposcopy;decision support system;digital camera;neck;neoplasms;patients;real-time transcription;sensitivity and specificity;smear - instruction imperative;smear campaign;visual inspection;algorithm;early detection of cervical cancer	Vidya Kudva;Keerthana Prasad;Shyamala Guruvare	2018	Journal of digital imaging	10.1007/s10278-018-0083-x	obstetrics gynaecology;radiology;colposcopy;decision support system;cervicography;cervical cancer;visual inspection;cervix;computer science	HCI	34.90264559098895	-79.86421599021452	53213
ba220594bea532f55ad80bbcccdd5c5dffab30a5	improving the information in medical image by adaptive fusion technique		Image fusion plays a huge role in many fields, especially in medical image processing because the visual interpretation of the image can enhance by using the fusion technique. The result shows the important detail which is very useful for doctor to diagnose health problems. In the paper, we proposed a method for image fusion. The guided filter is used to enhance the detail of the input image and then the cross bilateral filter is applied to extract detail image from the enhanced image. The image result is made by weighted average using the weights calculated from the detailed images. The experimental results showed that the proposed method can work well with medical image as well as other kinds of image. In addition, our result is better than the other recent methods based on compared objective performance measures.		Nguyen Mong Hien;Nguyen Thanh Binh;Ngo Quoc Viet;Pham Bao Quoc	2018		10.1007/978-3-030-03192-3_32	image processing;computer vision;fusion;bilateral filter;weighted arithmetic mean;computer science;image fusion;artificial intelligence	Vision	38.49802952073313	-73.83644672001728	53252
31f018068c70c7953f720d149262e15171158ff9	research on target detection and automatic extraction of region of interest in infrared serial images		Infrared imaging guidance is a research hotspot in accurate terminal guidance field now. An idea on automatic extraction of region (ROI) of interest in infrared serial images is proposed in order to treat intelligently infrared serial images which are captured. The target detection algorithm of target is researched and the applying scene of the target detection algorithm is confirmed based on analysis for the features of infrared serial images. According to differences of detection algorithm for infrared serial images between static and dynamic scenes, the corresponding detection and extraction algorithm of ROI is discussed respectively. The algorithms are all simulated in real scene. A new stepwise approaching and recurring threshold search algorithm based on two-dimensional maximum entropy principle was proposed by studying recurring formulation optimized of two-dimensional maximum entropy in order to realize to detect target and extract ROI of serial images under complex background. The algorithm above realizes automatic extraction of ROI in Infrared serial images. The results improve the efficiency of accurate terminal guidance and they have good application value by practicing.	experiment;java hotspot virtual machine;principle of maximum entropy;region of interest;search algorithm;stepwise regression;trust region	Guang Hu;Shengzhi Yuan	2011	JSW	10.4304/jsw.6.2.225-232	computer vision;simulation;computer science;data mining	Vision	38.79722970407876	-69.15013470231992	53383
59d84a371d1bb758538687979118470b061e8ea5	a framework for large-scale evaluation of deep learning for eeg		EEG is the most common signal source for noninvasive BCI applications. For such applications, the EEG signal needs to be decoded and translated into appropriate actions. A recently emerging EEG decoding approach is deep learning with Convolutional or Recurrent Neural Networks (CNNs, RNNs) with many different architectures already published. Here we present a novel framework for the large-scale evaluation of different deep-learning architectures on different EEG datasets. This framework comprises (i) a collection of EEG datasets currently comprising 100 examples (recording sessions) from six different classification problems, (ii) a collection of different EEG decoding algorithms, and (iii) a wrapper linking the decoders to the data as well as handling structured documentation of all settings and (hyper-) parameters and statistics, designed to ensure transparency and reproducibility. As an applications example we used our framework by comparing three publicly available CNN architectures: the Braindecode Deep4 ConvNet, Braindecode Shallow ConvNet, and EEGNet. We also show how our framework can be used to study similarities and differences in the performance of different decoding methods across tasks. We argue that the deep learning EEG framework as described here could help to tap the full potential of deep learning for BCI applications.	algorithm;brain–computer interface;convolutional neural network;decoding methods;deep learning;documentation;electroencephalography;recurrent neural network	Felix A. Heilmeyer;Robin Tibor Schirrmeister;Lukas Dominique Josef Fiederer;Martin Völker;Joos Behncke;Tonio Ball	2018	CoRR		documentation;machine learning;deep learning;decoding methods;recurrent neural network;transparency (graphic);electroencephalography;computer science;artificial intelligence	ML	28.768544514359412	-75.99340636378966	53456
9e24a4f1c72e3cad4a6b284048fa0de512c9003c	skin lesion analysis by multi-target deep neural networks		Automatic skin lesion analysis involves two critical steps: lesion segmentation and lesion classification. In this work, we propose a novel multi-target deep convolutional neural network (DCNN) to simultaneously tackle the problem of segmentation and classification. Based on U-Net and GoogleNet, a single model is constructed with three different targets of both lesion segmentation and two independent binary lesion classifications (i.e., melanoma detection and seborrheic keratosis identification), aiming to explore the differences and commonalities over different target models. We conduct experiments on dermoscopic images from the International Skin Imaging Collaboration (ISIC) 2017 Challenge. Results of our multi-target DCNN model demonstrates superiority over single model with one target only (such as U-net or GoogleNet), indicating its learning efficiency and potential for application in automatic skin lesion diagnosis. To the best of our knowledge, this work is the first demonstration for a single end-to-end deep neural network model that simultaneously handle both segmentation and classification in the field of skin lesion analysis.	artificial neural network;biological neural networks;categories;classification;convolutional neural network;deep learning;embedded system;embedding;end-to-end principle;ephrin type-b receptor 1, human;experiment;network model;numerous;overfitting;seborrheic keratosis;silo (dataset);biologic segmentation;triangulation	Xulei Yang;Hangxing Li;Li Wang;Si Yong Yeo;Yi Su;Zeng Zeng	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8512488	convolutional neural network;lesion;computer vision;image segmentation;seborrheic keratosis;artificial intelligence;feature extraction;artificial neural network;computer science;segmentation	Vision	31.48774873549608	-75.02579025579658	53572
9706bf608cfd24b819fdadd3e04d8f03403e2c93	context enhanced graphical model for object localization in medical images	new graphical model;object localization method;interest-region potential;interest-region detector;song et;different medical application;different medical imaging application;object localization;additional contrast;medical image;graphical model	Object localization is an important step common to many different medical applications. In this Chapter, we will review the challenges and recent approaches tackling this problem, and focus on the work by Song et.al. [20]. In [20], a new graphical model with additional contrast and interest-region potentials is designed, encoding the higherorder contextual information between regions, on the global and structural levels. A discriminative sparse-coding based interest-region detector is also integrated as one of the context prior in the graphical model. This object localization method is generally applicable to different medical imaging applications, in which the objects can be distinguished from the background mainly based on feature differences. Successful applications on two different medical imaging applications – lesion dissimilarity on thoracic PET-CT images and cell segmentation on microscopic images – are demonstrated in the experimental results.	ct scan;conditional random field;dictionary;emoticon;graphical model;medical imaging;neural coding;region of interest;sparse matrix	Yang Song;Tom Weidong Cai;Heng Huang;Yue Wang;David Dagan Feng	2012		10.1007/978-3-642-36620-8_19	computer vision;computer science;machine learning;pattern recognition	ML	32.490453812372046	-73.79951105984829	53663
1260196adf93047efb376e60fb68b98d9bd310f5	classification of breast masses on contrast-enhanced magnetic resonance images through log detrended fluctuation cumulant-based multifractal analysis	clinical course breast mass classification contrast enhanced magnetic resonance images log detrended fluctuation cumulant multifractal analysis multiscale automated model suspicious malignancy dynamic contrast enhanced magnetic resonance feature extraction multifractal scaling exponent log cumulants lesion texture biopsy recommended case classification supervised classification receiver operating characteristic roc feature classification techniques radiologists;multiscale breast cancer computer aided diagnosis cad dynamic contrast enhanced feature extraction magnetic resonance imaging mri multifractal analysis;fractals lesions breast magnetic resonance imaging feature extraction kinetic theory cancer;radiology biomedical mri feature extraction image classification image texture medical image processing	This paper proposes a multiscale automated model for the classification of suspicious malignancy of breast masses, through log detrended fluctuation cumulant-based multifractal analysis of images acquired by dynamic contrast-enhanced magnetic resonance. Features for classification are extracted by computing the multifractal scaling exponent for each of the 70 clinical cases and by quantifying the log-cumulants reflecting multifractal information related with texture of the enhanced lesions. The output is compared with the radiologist diagnosis that follows the Breast Imaging-Reporting and Data System (BI-RADS). The results suggest that the log-cumulant C2 can be effective in classifying typically biopsy-recommended cases. The performance of a supervised classification was evaluated by receiver operating characteristic (ROC) with an area under the curve of 0.985. The proposed multifractal analysis can contribute to novel feature classification techniques to aid radiologists every time there is a change in the clinical course, namely, when biopsy should be considered.	bi-rads;contrast ratio;dce/rpc;data system;decision support system;image analysis;image scaling;machine learning;multifractal system;quantum fluctuation;radiology;receiver operating characteristic;resonance;statistical classification;supervised learning	Filipe Soares;Filipe Janela;Manuela Pereira;João Seabra;Mário M. Freire	2014	IEEE Systems Journal	10.1109/JSYST.2013.2284101	computer vision;computer science;pattern recognition	SE	34.890684523526886	-77.13715303690991	53678
406c71fbcc62134593522dbff15f9228c9209d4f	thresholding the courtesy amount of brazilian bank checks using a local methodology		This paper presents a new thresholding methodology for complex background images with an application to the courtesy amount of Brazilian bank checks. Courtesy amount images present a complex background and the pro- posal of an automatic thresholding process brings benefits to other steps in bank check clearance, such as the Optical Character Recognition (OCR). Experi- mental results showed that the proposed methodology yields good results, with average accuracy over 95 %, superior to standard methods from the literature.	thresholding (image processing)	Rafael Felix;Leandro Augusto da Silva;Leandro Nunes de Castro	2015		10.1007/978-3-319-19033-4_18	speech recognition;engineering;data mining;cartography	EDA	37.54024182627428	-70.34580515949582	53712
d9fa848b0dec6ec06b5a28544447a646d28528c0	predicting glaucoma progression using multi-task learning with heterogeneous features	visual field prediction;matrix completion;multi task learning;similarity matrix;glaucoma	We consider the prediction of glaucomatous visual field loss based on patient datasets. It is critically important to predict how rapidly the disease is progressing in an individual patient. However, the number of measurements for each patient is so small that a reliable predictor cannot be constructed from the data of a single patient alone. In this paper, we propose a novel multi-task learning approach to this issue. Patient data consist of three features: patient ID, 74-dimensional visual loss values, and inspection time. We reduce the prediction problem into one of matrix completion for these features. Specifically, by assuming heterogeneity in the three features, we introduce similarity measures that reflect the unique statistical nature of the respective features to solve a specific type of matrix decomposition problem. For example, we employ Gaussian kernels as a similarity measure for visual field loss and a linear regression-type relation for the time feature. We empirically demonstrate that our proposed method works significantly better than the existing methods.	color gradient;computer multitasking;gaussian blur;kerrison predictor;linear function;multi-task learning;similarity measure	Shigeru Maya;Kai Morino;Kenji Yamanishi	2014	2014 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2014.7004241	computer vision;computer science;machine learning;data mining	ML	26.36164762300531	-77.58030730711083	53865
7b3b2912c1d7a70839bc71a150e33f8634d0fff3	convolutional neural network-based embarrassing situation detection under camera for social robot in smart homes	convolutional neural networks;privacy detection;smart home;social robot	Recent research has shown that the ubiquitous use of cameras and voice monitoring equipment in a home environment can raise privacy concerns and affect human mental health. This can be a major obstacle to the deployment of smart home systems for elderly or disabled care. This study uses a social robot to detect embarrassing situations. Firstly, we designed an improved neural network structure based on the You Only Look Once (YOLO) model to obtain feature information. By focusing on reducing area redundancy and computation time, we proposed a bounding-box merging algorithm based on region proposal networks (B-RPN), to merge the areas that have similar features and determine the borders of the bounding box. Thereafter, we designed a feature extraction algorithm based on our improved YOLO and B-RPN, called F-YOLO, for our training datasets, and then proposed a real-time object detection algorithm based on F-YOLO (RODA-FY). We implemented RODA-FY and compared models on our MAT social robot. Secondly, we considered six types of situations in smart homes, and developed training and validation datasets, containing 2580 and 360 images, respectively. Meanwhile, we designed three types of experiments with four types of test datasets composed of 960 sample images. Thirdly, we analyzed how a different number of training iterations affects our prediction estimation, and then we explored the relationship between recognition accuracy and learning rates. Our results show that our proposed privacy detection system can recognize designed situations in the smart home with an acceptable recognition accuracy of 94.48%. Finally, we compared the results among RODA-FY, Inception V3, and YOLO, which indicate that our proposed RODA-FY outperforms the other comparison models in recognition accuracy.	algorithm;artificial neural network;biological neural networks;computation;convolutional neural network;deploy;disabled persons;experiment;feature extraction;home automation;iteration;kidney papillary necrosis;minimum bounding box;object detection;real-time clock;reverse polish notation;social robot;time complexity;wilmagate;mental health	Guanci Yang;Jing Yang;Weihua Sheng;Francisco Erivaldo Fernandes;Shaobo Li	2018		10.3390/s18051530	social robot;software deployment;electronic engineering;redundancy (engineering);convolutional neural network;engineering;home automation;feature extraction;object detection;machine learning;artificial neural network;artificial intelligence	HCI	26.153131191113147	-70.08043439282402	53937
1cca90b572ffea41cb34d94f4317c55f2421d2b7	parallel weight consolidation: a brain segmentation case study		Collecting the large datasets needed to train deep neural networks can be very difficult, particularly for the many applications for which sharing and pooling data is complicated by practical, ethical, or legal concerns. However, it may be the case that derivative datasets or predictive models developed within individual sites can be shared and combined with fewer restrictions. Training on distributed datasets and combining the resulting networks is often viewed as continual learning, but these methods require networks to be trained sequentially. In this paper, we introduce parallel weight consolidation (PWC), a continual learning method to consolidate the weights of neural networks trained in parallel on independent datasets. We perform a brain segmentation case study using PWC to consolidate several dilated convolutional neural networks trained in parallel on independent structural magnetic resonance imaging (sMRI) datasets from different sites. We found that PWC led to increased performance on held-out test sets from the different sites, as well as on a very large and completely independent multi-site dataset. This demonstrates the feasibility of PWC for combining the knowledge learned by networks trained on different datasets.	artificial neural network;convolutional neural network;deep learning;predictive modelling;resonance;semiconductor consolidation;test set	Patrick McClure;Charles Y. Zheng;Francisco Pereira;Jakub Kaczmarzyk;John Rogers-Lee;Dylan M Nielson;Peter A. Bandettini	2018	CoRR		artificial neural network;convolutional neural network;consolidation (soil);machine learning;pooling;brain segmentation;computer science;artificial intelligence	ML	29.29412120519541	-75.31329030587787	54078
c861df3f98c2b856c2a8e7bec5aaa722b2535e08	automatic detection of clustered microcalcifications in digital mammograms using an svm classifier	false positive;statistical test;multiresolution analysis;wavelet transform	In this paper we investigate the performance of a Computer Aided Diagnosis (CAD) system for the detection of clustered microcalcifications in mammograms. Our detection algorithm consists on the combination of two different methods. The first one, based on difference-image techniques and gaussianity statistical tests, finds out the most obvious signals. The second one is able to discover more subtle microcalcifications by exploiting a multiresolution analysis by means of the wavelet transform. In the falsepositive reduction step we separate false signals from microcalcifications by means of an SVM classifier. Our algorithm yields a sensitivity of 94.6% with 0.6 false positive cluster per image on the 40 images of the Nijmegen database.	algorithm;computer-aided design;multiresolution analysis;wavelet transform	Armando Bazzani;Alessandro Bevilacqua;Dante Bollini;Rosa Brancaccio;Renato Campanini;Nico Lanconelli;Alessandro Riccardi;Davide Romani;Gianluca Zamboni	2000			machine learning;wavelet transform;multiresolution analysis;artificial intelligence;statistical hypothesis testing;pattern recognition;support vector machine;classifier (linguistics);computer vision;computer-aided diagnosis;computer science	Vision	35.05169999604154	-75.09921763490927	54128
a41fecca2bc505489ca70f9bcfa8c75d8d81fce1	recognition of handwritten hindi text using middle region of the words	segmentation;recognition rate;text recognition;middle zone of words;topological features	Offline handwritten Hindi text recognition is a very tedious task. In this paper, a novel method using middle region of the words for recognition of handwritten Hindi text is proposed. A segmentation based approach is used for recognition. Although many efforts have been made to recognize isolated characters and words, a little work has been done to recognize the offline handwritten Hindi text by segmenting the sentences into lines and lines into words. The uniqueness of this approach lies in the fact that many of the commonly used words can be recognized by matching all the characters in the middle zone even by ignoring the upper modifiers, lower modifiers and half characters. Another advantage is that it is not word specific i.e. any number of words can be added to the list to be recognized. Topological features are used for recognition of characters and efforts are made to correctly extract the features. Results obtained with the proposed technique are very challenging.		Naresh Kumar Garg;Lakhwinder Kaur;M. K. Jindal	2015	IJSI	10.4018/IJSI.2015100105	natural language processing;speech recognition;computer science;intelligent word recognition;communication	NLP	34.537162338704796	-66.76483826147741	54406
93b0997e830d225de7722507cf2cd4cbc71bd0ae	divergence analysis by sparse neighborhood nets for detection of abnormality in image of skin	kernel;image segmentation;skin;lesions;image color analysis;robustness;lighting	Early detection of abnormality in image of skin is now considered the crucial contributor for successful treatment. We explored how constructing a sparse neighborhood net of pixels and distinction of patches in the image feature analysis play a role for diagnostic ability of lesion segmentation. Since image patches are considered like circumstance of many factors including skin tone, skin aberrations and lighting conditions, a robust patch-based feature detector is proposed for image segmentation in the combination with post-processing to predict the presence of irregular regions. Experiments show that the results are very competitive for lesion segmentation and demonstrate robustness with respect to the lighting condition, variations in terms of color, texture and shape. Our major contributions are the application of sparse net of neighborhood pixels for the distinction detection filter based on the patches mismatch and a new efficient algorithm for detection of skin irregular region.	algorithm;experiment;feature (computer vision);image segmentation;pixel;sparse matrix;video post-processing	Dao Nam Anh	2016	2016 Eighth International Conference on Knowledge and Systems Engineering (KSE)	10.1109/KSE.2016.7758033	image texture;computer vision;feature detection;kernel;computer science;machine learning;pattern recognition;lighting;mathematics;region growing;skin;image segmentation;programming language;scale-space segmentation;robustness	Vision	37.64937171454043	-73.80122140877124	54646
b9ded11dedbcfc1c7a9adcdae51ca2ab1d796e9e	mmfnet: a multi-modality mri fusion network for segmentation of nasopharyngeal carcinoma.		Segmentation of nasopharyngeal carcinoma (NPC) from Magnetic Resonance Images (MRI) is a crucial step in NPC radiotherapy. However, manually segmenting of NPC is a time-consuming and labor-intensive task. Additionally, single-modality MRI generally cannot provide enough information for the accurate delineation of NPC. Therefore, a multi-modality MRI fusion network (MMFNet) based on three modalities of MRI (T1, T2 and contrast-enhanced T1) is proposed to complete accurate segmentation of NPC. In the MMFNet, the backbone is designed as a multi-encoder-based network, consisting of several modality-specific encoders and one single decoder. It can be used to well learn both low-level and high-level features used implicitly for NPC segmentation in each modality of MRI. A fusion block is proposed in the MMFNet to effectively fuse low-level features from multi-modality MRI. It firstly recalibrates features captured from multi-modality MRI, which will highlight informative features and regions of interest. Then, a residual fusion block is utilized to fuse weighted features before merging them with features from decoder to keep balance between high-level and low-level features. Moreover, a training strategy named self-transfer is proposed to initialize encoders for multi-encoder-based network. It can stimulate encoders to make full mining of modality-specific MRI. The proposed method can effectively make use of information in multi-modality MRI. Its effectiveness and advantages are validated by many experiments and comparisons with the related methods.		H Chen;Yuxiao Qi;Yong Yin;Tengxiang Li;Guanzhong Gong;Lisheng Wang	2018	CoRR		encoder;fuse (electrical);pattern recognition;nasopharyngeal carcinoma;artificial intelligence;fusion;computer science;magnetic resonance imaging;segmentation	Vision	30.91266562276788	-75.49511083421018	54720
540212427fb36429edfdbf46e71728a73582512a	three-dimensional ct image segmentation by combining 2d fully convolutional network with 3d majority voting		We propose a novel approach for automatic segmentation of anatomical structures on 3D CT images by voting from a fully convolutional network (FCN), which accomplishes an end-to-end, voxel-wise multiple-class classification to map each voxel in a CT image directly to an anatomical label. The proposed method simplifies the segmentation of the anatomical structures (including multiple organs) in a CT image (generally in 3D) to majority voting for the semantic segmentation of multiple 2D slices drawn from different viewpoints with redundancy. An FCN consisting of “convolution” and “de-convolution” parts is trained and re-used for the 2D semantic image segmentation of different slices of CT scans. All of the procedures are integrated into a simple and compact all-in-one network, which can segment complicated structures on differently sized CT images that cover arbitrary CT scan regions without any adjustment. We applied the proposed method to segment a wide range of anatomical structures that consisted of 19 types of targets in the human torso, including all the major organs. A database consisting of 240 3D CT scans and a humanly annotated ground truth was used for training and testing. The results showed that the target regions for the entire set of CT test scans were segmented with acceptable accuracies (89 % of total voxels were labeled correctly) against the human annotations. The experimental results showed better efficiency, generality, and flexibility of this end-to-end learning approach on CT image segmentations comparing to conventional methods guided by human expertise.	ct scan;image segmentation	Xiangrong Zhou;Takaaki Ito;Ryosuke Takayama;Song Wang;Takeshi Hara;Hiroshi Fujita	2016		10.1007/978-3-319-46976-8_12	data mining;scale-space segmentation	Vision	35.73812768115792	-79.33138310684252	54859
5c7e65bd2c5ddc4b2026d6952d604064de04b811	a convolutional neural network approach to brain tumor segmentation		We consider the problem of fully automatic brain focal pathology segmentation, in MR images containing low and high grade gliomas and ischemic stroke lesion. We propose a Convolutional Neural Network (CNN) approach which is amongst the top performing methods while also being extremely computationally efficient, a balance that existing methods have struggled to achieve. Our CNN is trained directly on the image modalities and thus learns a feature representation directly from the data. We propose a cascaded architecture with two pathways: one which focuses on small details in gliomas and one on the larger context. We also propose a two-phase patch-wise training procedure allowing us to train models in a few hours. Fully exploiting the convolutional nature of our model also allows us to segment a complete brain image in 25 s to 3 min. Experimental results on BRain Tumor Segmentation challenges (BRATS’13, BRATS’15) and Ischemic Stroke Lesion Segmentation challenge (ISLES’15) reveal that our approach is among the most accurate in the literature, while also being computationally very efficient.	convolutional neural network	Mohammad Havaei;Francis Dutil;Christopher Joseph Pal;Hugo Larochelle;Pierre-Marc Jodoin	2015		10.1007/978-3-319-30858-6_17	lesion;convolutional neural network;architecture;artificial intelligence;stochastic gradient descent;pattern recognition;segmentation;stroke;computer science;brain tumor	ML	31.053379261804135	-75.08616059273396	55411
be28bd92de57c6d3eaa37dc1d5b0cab78d81858f	peripheral nerves segmentation in ultrasound images using non-linear wavelets and gaussian processes		Regional anesthesia is carried out using a technique called peripheral nerve blocking (PNB), which involves the administration of an anesthetic nearby the nerve. Ultrasound images have been widely used for PNB procedure due to their low cost and because they are non-invasive. However, the segmentation of nerve structures in ultrasound images is a challenging task for the specialists since the images are affected by echo perturbations and speckle noise. Automatic or semi-automatic segmentation systems can be developed in order to aid the specialist for locating nerves structures accurately. In this paper we propose a methodology for the semi-automatic segmentation of nerve structures in ultrasound images. We use non-linear Wavelets transform in the feature extraction step and for the classification stage we use a Gaussian Processes classifier. Experimental results show that the implemented methodology can segment nerve structures accurately.	gaussian process;peripheral;wavelet	Julián Gil González;Mauricio A. Álvarez;Álvaro Orozco	2015		10.1007/978-3-319-19390-8_68	computer vision	ML	38.110014465207065	-79.08679878403689	55473
efc327f448fdc63e8ea2121d5b508fcb006b8699	dual-pass feature extraction on human vessel images	software;sensitivity and specificity;radiographic image enhancement;radiography interventional;artifacts;angiography;image interpretation computer assisted;reproducibility of results;algorithms;pattern recognition automated;humans;tomography x ray computed	We present a novel algorithm for the extraction of cavity features on images of human vessels. Fat deposits in the inner wall of such structure introduce artifacts, and regions in the images captured invalidating the usual assumption of an elliptical model which makes the process of extracting the central passage effectively more difficult. Our approach was designed to cope with these challenges and extract the required image features in a fully automated, accurate, and efficient way using two stages: the first allows to determine a bounding segmentation mask to prevent major leakages from pixels of the cavity area by using a circular region fill that operates as a paint brush followed by Principal Component Analysis with auto correction; the second allows to extract a precise cavity enclosure using a micro-dilation filter and an edge-walking scheme. The accuracy of the algorithm has been tested using 30 computed tomography angiography scans of the lower part of the body containing different degrees of inner wall distortion. The results were compared to manual annotations from a specialist resulting in sensitivity around 98 %, false positive rate around 8 %, and positive predictive value around 93 %. The average execution time was 24 and 18 ms on two types of commodity hardware over sections of 15 cm of length (approx. 1 ms per contour) which makes it more than suitable for use in interactive software applications. Reproducibility tests were also carried out with synthetic images showing no variation for the computed diameters against the theoretical measure.	approximation;blood vessel;body cavities;ct scan;commodity computing;computed tomography angiography;diameter (qualifier value);dilation (morphology);distortion;dual;enclosure device component;feature extraction;greater than;morphologic artifacts;pathological dilatation;pixel;platelet glycoprotein 4, human;positive predictive value of diagnostic test;principal component analysis;run time (program lifecycle phase);synthetic data;x-ray computed tomography;algorithm;angiogram	Wenndy Hernandez;S. Grimm;R. Andriantsimiavona	2013	Journal of Digital Imaging	10.1007/s10278-013-9646-z	computer vision;simulation;radiology;computer science	Vision	38.64077258491522	-79.37713424071806	55684
ef9058cca069db170102527558f364d154ea507e	multiple k-nearest neighbor classifier and its application to tissue characterization of coronary plaque		In this paper we propose a novel classification method for the multiple k-nearest neighbor (MkNN) classifier and show its practical application to medical image processing. The proposed method performs fine classification when a pair of the spatial coordinate of the observation data in the observation space and its corresponding feature vector in the feature space is provided. The proposed MkNN classifier uses the continuity of the distribution of features of the same class not only in the feature space but also in the observation space. In order to validate the performance of the present method, it is applied to the tissue characterization problem of coronary plaque. The quantitative and qualitative validity of the proposed MkNN classifier have been confirmed by actual experiments. key words: acute coronary syndromes (ACS), coronary plaque tissue characterization, intravascular ultrasound (IVUS) method, multiple k-nearest neighbor (MkNN) classifier	experiment;feature vector;image processing;k-nearest neighbors algorithm;medical imaging;medical ultrasound;naive bayes classifier;nearest neighbour algorithm;scott continuity	Eiji Uchino;Ryosuke Kubota;Takanori Koga;Hideaki Misawa;Noriaki Suetake	2016	IEICE Transactions		computer science;artificial intelligence;pattern recognition;classifier (linguistics);k-nearest neighbors algorithm	DB	34.34607719884122	-75.49573673716688	55812
dc299b4b6d9121ec43b7db65b4bc6611a20afea0	an effective occipitomental view enhancement based on adaptive morphological texture analysis	diagnosis apparatus maxillary sinusitis occipitomental view radiography enhancement texture analysis;feature extraction x ray imaging kernel informatics histograms computed tomography diagnostic radiography	This paper aims to present an algorithm that specifically enhances maxillary sinuses using a novel contrast enhancement technique based on the adaptive morphological texture analysis for occipitomental view radiographs. First, the skull X-ray (SXR) is decomposed into rotational blocks (RBs). Second, each RB is rotated into various directions and processed using morphological kernels to obtain the dark and bright features. Third, a gradient-based block segmentation decomposes the interpolated feature maps into feature blocks (FBs). Finally, the histograms of FBs are equalized and overlaid locally to the input SXR. The performance of the proposed method was evaluated on an independent dataset, which comprises of 145 occipitomental view-based human SXR images. According to the experimental results, the proposed method is able to increase the diagnosis accuracy by 83.45% compared with the computed tomography modality as the gold standard.	ct scan;computed tomography scanning systems;gradient;interpolation;map;maxillary sinus;modality (human–computer interaction);nr1i2 wt allele;nasal sinus;radiography;silo (dataset);sphenopalatine ganglion block;x-ray (amazon kindle);x-ray computed tomography;algorithm;biologic segmentation	Peter Chondro;Hao-Chun Hu;Hsuan-Yen Hung;Shin-Yuan Chang;Lieber Po-Hung Li;Shanq-Jang Ruan	2017	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2016.2593455	pattern recognition;computer vision;computed tomography;computer science;artificial intelligence;feature extraction;radiography;histogram	Vision	34.849311089062326	-75.53276727687214	55949
85132604e911efb7c8e1e46f69080345bbe21ee4	smartphone-based wound assessment system for patients with diabetes	wound healing status smartphone based wound assessment system patient diabetic foot ulcers health issue visual examination wound size quantitative examination method cost effective examination method caregivers daily wound care healthcare expense reduction high resolution digital camera chronic foot ulcers wound image analysis system android smartphone image capture box wound segmentation accelerated mean shift algorithm foot outline skin color wound boundary simple connected region detection method red yellow black color evaluation model trend analysis umass memorial health center wound clinic institutional review board approved protocol;wounds biomedical communication biomedical optical imaging diseases health care image colour analysis image segmentation medical image processing patient care skin smart phones;image segmentation;diabetes;foot;wounds;vectors;image color analysis;wounds foot image color analysis algorithm design and analysis image segmentation diabetes vectors;algorithm design and analysis	Diabetic foot ulcers represent a significant health issue. Currently, clinicians and nurses mainly base their wound assessment on visual examination of wound size and healing status, while the patients themselves seldom have an opportunity to play an active role. Hence, a more quantitative and cost-effective examination method that enables the patients and their caregivers to take a more active role in daily wound care potentially can accelerate wound healing, save travel cost and reduce healthcare expenses. Considering the prevalence of smartphones with a high-resolution digital camera, assessing wounds by analyzing images of chronic foot ulcers is an attractive option. In this paper, we propose a novel wound image analysis system implemented solely on the Android smartphone. The wound image is captured by the camera on the smartphone with the assistance of an image capture box. After that, the smartphone performs wound segmentation by applying the accelerated mean-shift algorithm. Specifically, the outline of the foot is determined based on skin color, and the wound boundary is found using a simple connected region detection method. Within the wound boundary, the healing status is next assessed based on red-yellow-black color evaluation model. Moreover, the healing status is quantitatively assessed, based on trend analysis of time records for a given patient. Experimental results on wound images collected in UMASS-Memorial Health Center Wound Clinic (Worcester, MA) following an Institutional Review Board approved protocol show that our system can be efficiently used to analyze the wound healing status with promising accuracy.	android;diabetic ketoacidosis;digital camera;foot ulcer;image analysis;image resolution;mean shift;patients;review board;skin pigmentation;smartphone;wound healing;wound infection;algorithm	Lei Wang;Peder C. Pedersen;Diane M. Strong;Bengisu Tulu;Emmanuel Agu;Ronald Ignotz	2015	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2014.2358632	algorithm design;medicine;pathology;computer science;biological engineering;image segmentation;surgery;foot	Vision	37.750300933679384	-76.57954613179444	56470
a14e88e41a727737171f0c02e28555112445ad6a	consistent partition and labelling of text blocks	performance measure;document structure;hidden markov model;image database;statistical method	This paper presents a text block extraction algorithm that takes as its input a set of text lines of a given document, and partitions the text lines into a set of text blocks, where each text block is associated with a set of homogeneous formatting attributes, e.g. text-alignment, indentation. The text block extraction algorithm described in this paper is probability based. We adopt an engineering approach to systematically characterising the text block structures based on a large document image database, and develop statistical methods to extract the text block structures from the image. All the probabilities are estimated from an extensive training set of various kinds of measurements among the text lines, and among the text blocks in the training data set. The off-line probabilities estimated in the training then drive all decisions in the on-line text block extraction. An iterative, relaxation-like method is used to find the partitioning solution that maximizes the joint probability. To evaluate the performance of our text block extraction algorithm, we used a three-fold validation method and developed a quantitative performance measure. The algorithm was evaluated on the UW-III database of some 1600 scanned document image pages. The text block extraction algorithm identifies and segments 91% of text blocks correctly.	algorithm;block cipher;entity;iterative method;linear programming relaxation;online and offline;partition problem;test set;text mode	Jisheng Liang;Ihsin T. Phillips;Robert M. Haralick	2000	Pattern Analysis & Applications	10.1007/s100440070023	computer science;document structure description;machine learning;pattern recognition;data mining;hidden markov model	NLP	36.13186851071069	-67.2651797264382	56581
ca88af9828a7113d363415fa76524dae16844bcc	hidden markov random field based approach for off-line handwritten chinese character recognition	isolated handwritten chinese characters off line handwritten chinese character recognition hidden markov mesh random field hmm hmmrf statistical observation sequences character stroke adjustment binary image nonlinear shape normalization scheme stroke width stroke length stroke correlation model parameters state sequence decoding algorithms;feature extraction handwritten character recognition hidden markov models statistical analysis correlation theory;correlation theory;binary image;hidden markov random field;handwritten chinese character recognition;hidden markov models character recognition handwriting recognition feature extraction speech recognition writing parameter estimation speech analysis image segmentation signal processing;hidden markov models;statistical analysis;feature extraction;handwritten character recognition;random field	This paper presents a Hidden Markov Mesh Random Field (HMMRF) based approach for off-line handwritten Chinese characters recognition using statistical observation sequences embedded in the strokes of a character. Due to a large set of Chinese characters and many different writing styles, the recognition of handwritten Chinese characters is very challenging. In our approach, the binary image is first normalized by a nonlinear shape normalization scheme to adjust the width, length, and the correlation of strokes. Two types of stroke-based features are then extracted to represent the observation sequence. The estimation of model parameters and state sequence decoding algorithms are also discussed in the paper. Experimental results on 470 isolated hand-written Chinese characters demonstrate the effectiveness of our approach.	algorithm;binary image;embedded system;hidden markov model;hidden markov random field;markov chain;nonlinear system;online and offline	Qing Wang;Rongchun Zhao;Zheru Chi;David Dagan Feng	2000		10.1109/ICPR.2000.906084	random field;speech recognition;binary image;feature extraction;computer science;machine learning;pattern recognition;hidden markov model;statistics	AI	32.318198900985315	-66.6105497579899	56749
a0798a0a422520241cc02282946882dd1ef853cd	full quantification of left ventricle via deep multitask learning network respecting intra- and inter-task relatedness		Cardiac left ventricle (LV) quantification is among the most clinically important tasks for identification and diagnosis of cardiac diseases, yet still a challenge due to the high variability of cardiac structure and the complexity of temporal dynamics. Full quantification, i.e., to simultaneously quantify all LV indices including two areas (cavity and myocardium), six regional wall thicknesses (RWT), three LV dimensions, and one cardiac phase, is even more challenging since the uncertain relatedness intra and inter each type of indices may hinder the learning procedure from better convergence and generalization. In this paper, we propose a newly-designed multitask learning network (FullLVNet), which is constituted by a deep convolution neural network (CNN) for expressive feature embedding of cardiac structure; two followed parallel recurrent neural network (RNN) modules for temporal dynamic modeling; and four linear models for the final estimation. During the final estimation, both intraand inter-task relatedness are modeled to enforce improvement of generalization: (1) respecting intra-task relatedness, group lasso is applied to each of the regression tasks for sparse and common feature selection and consistent prediction; (2) respecting inter-task relatedness, three phase-guided constraints are proposed to penalize violation of the temporal behavior of the obtained LV indices. Experiments on MR sequences of 145 subjects show that FullLVNet achieves high accurate prediction with our intraand inter-task relatedness, leading to MAE of 190 mm, 1.41 mm, 2.68 mm for average areas, RWT, dimensions and error rate of 10.4% for the phase classification. This endows our method a great potential in comprehensive clinical assessment of global, regional and dynamic cardiac function.	artificial neural network;computer multitasking;convolution;feature selection;lasso;linear model;logical volume management;mac os x 10.4 tiger;random neural network;recurrent neural network;sparse matrix;spatial variability;the wall street journal	Wufeng Xue;Andrea Lum;Ashley Mercado;Mark Landis;James Warrington;Shuo Li	2017		10.1007/978-3-319-66179-7_32	linear model;pattern recognition;word error rate;lasso (statistics);artificial intelligence;machine learning;convolutional neural network;computer science;regression;feature selection;recurrent neural network;multi-task learning	ML	28.74812144103629	-77.87856156928933	56762
b49eefa626778da7c31ef5d11b81ede9c50bc042	off-line handwritten character recognition by svm based on the virtual examples synthesized from on-line characters	character recognition support vector machines support vector machine classification databases character generation data engineering information science handwriting recognition machine learning text analysis;support vector machines;handwritten japanese hiragana character classification off line handwritten character recognition support vector machines virtual examples online character database affine transformation augmented training samples;learning from examples;affine transformation;very large databases handwritten character recognition support vector machines pattern classification;pattern classification;very large databases;character recognition;handwritten character recognition	This paper proposes a method to improve the off-line character classifiers which are learned from examples by using the virtual examples synthesized from on-line character database. To obtain the good classifiers, usually a large database which contains enough number of variations of handwritten characters is required. However, in practice collecting enough number of data is time-consuming and costly. In this paper, we propose a method to train SVM for off-line character recognition based on the artificially augmented examples using on-line characters. In our method, a virtual example is synthesized from an on-line character by applying affine transformation to each stroke. SVM classifiers are trained by using the artificially generated patterns. To reject inappropriate artificial examples, a preliminary SVM is learned from the original set of samples, and then used for data selection. Using the augmented training samples, the final SVM is obtained. We examine the effectiveness of the proposed method by experiments of handwritten Japanese Hiragana character classification.	database;experiment;handwriting recognition;online and offline;optical character recognition	Hidetoshi Miyao;Minoru Maruyama;Yasuaki Nakano;Toshihiro Hananoi	2005	Eighth International Conference on Document Analysis and Recognition (ICDAR'05)	10.1109/ICDAR.2005.170	support vector machine;speech recognition;document processing;intelligent character recognition;computer science;intelligent word recognition;machine learning;pattern recognition;affine transformation	Robotics	31.904057519926234	-66.17774673812615	56907
72aff1b5f4fb05a3c75b3fb5edfeb21b6999a6af	deep supervision with additional labels for retinal vessel segmentation task		Automatic analysis of retinal blood images is of vital importance in diagnosis tasks of retinopathy. Segmenting vessels accurately is a fundamental step in analysing retinal images. However, it is usually difficult due to various imaging conditions, low image contrast and the appearance of pathologies such as micro-aneurysms. In this paper, we propose a novel method with deep neural networks to solve this problem. We utilize U-net with residual connection to detect vessels. To achieve better accuracy, we introduce an edge-aware mechanism, in which we convert the original task into a multi-class task by adding additional labels on boundary areas. In this way, the network will pay more attention to the boundary areas of vessels and achieve a better performance, especially in tiny vessels detecting. Besides, side output layers are applied in order to give deep supervision and therefore help convergence. We train and evaluate our model on three databases: DRIVE, STARE, and CHASEDB1. Experimental results show that our method has a comparable performance with AUC of 97.99% on DRIVE and an efficient running time compared to the state-of-the-art methods.	artificial neural network;database;deep learning;pixel;sensor;time complexity	Yishuo Zhang;Albert C. S. Chung	2018		10.1007/978-3-030-00934-2_10	residual;computer science;pattern recognition;artificial intelligence;computer vision;market segmentation;artificial neural network;retinal;convergence (routing);segmentation;fundus (eye)	Vision	31.98144012227401	-75.47784031492922	56937
81d86cf4ed85ecf2ddfced2662edbd6a02d707cf	combining gabor filter and fft for fingerprint enhancement based on a regional adaption method and automatic segmentation		Fingerprints are the best biometric identity mark due to the consistency during life time and uniqueness. To increase the classification accuracy of fingerprint images, it is necessary to improve image quality which is a key role for correct recognition. In other words, enhancing the fingerprint images leads us to obtain better results in classification of fingerprint images. Although Gabor filter and fast Fourier transform (FFT) are used to enhance fingerprint images, Gabor filter acts better than FFT in detection of incorrect ridge endings and ridge bifurcation, while FFT tries to connect broken ridges together and fill the created holes. This paper tries to enhance gray-scale fingerprint images by combining the Gabor filter and FFT in order to get benefit from the advantages of each enhancing filter (Gabor filter and FFT). A method is proposed for fingerprint image segmentation based on the image histogram and density. By employing the proposed method which enhances the fingerprint images using the better enhancing filter in each part, the experimental results show that the whole finger print is better enhanced, and consequently, it leads to a better recognition rate.	fast fourier transform;fingerprint;gabor filter	Morteza Zahedi;Ozra Rostami Ghadi	2015	Signal, Image and Video Processing	10.1007/s11760-013-0436-3	computer vision;speech recognition;computer science;pattern recognition	Vision	38.995676338169815	-66.29589495603169	56952
13a4c445c0eb400b984f17b99e15d4a742cfeab5	robust cerebrovascular segmentation in 4d asl mra images		Cerebrovascular diseases are one of the main causes of disability and death in the world. Methods for segmentation of the cerebral blood vessels can help clinicians to visualize the cerebrovascular system, determine age-related normal values, and diagnose and study cerebrovascular diseases. A common problem for these methods is the precise delineation of small vessels, due to different artifacts depending on the medical imaging modality. In this work, we present an automatic segmentation method for four dimensional arterial spin labeling magnetic resonance angiography (4D ASL MRA) images of the brain, which allows an improved segmentation of small vessels, reaching an average Dice similarity coefficient (DSC) of 0.946 based on an evaluation of five datasets from healthy subjects. The results show that the proposed method is able to account for the magnetic labeling decay and flow related artifacts, which considerably reduce the contrast of small vessels present in the image, leading to improved segmentation results.	artifact (software development);coefficient;medical imaging;modality (human–computer interaction);resonance	Renzo Phellan;Thomas Lindner;Michael Helle;Alexandre X. Falcão;Nils Daniel Forkert	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363821	computer vision;artificial intelligence;angiography;computer science;medical imaging;magnetic resonance angiography;segmentation	Vision	38.82768499453362	-79.960605340045	57259
a963d4e37850702cf396e13c58af375784183731	a method for the detection and classification of diabetic retinopathy using structural predictors of bright lesions	exudates;features extraction;classification;gabor filter;diabetic retinopathy	Diabetic burden around the world with a consequence of diabetic retinopathy can lead to permanent blindness in patients. Exudates detection in fundus images through an automated method is a vital task that has many applications in diabetic retinopathy screening. Realizing it important, a system being proposed in this paper automatically classifies exudates and non-exudates regions in retinal images. Presented technique is based on pre-processing for candidate lesion extraction, features extraction and classification. In pre-processing, Gabor filter is applied to the gray scale image which makes it useful for lesion enhancement. Segmentation of candidate lesion is based on mathematical morphology. A features set is selected for each candidate lesion using a combination of statistical and geometric features. Presented method is evaluated via publicly accessible datasets with the help of performance parameters such as true positive, false positive and area under curve for statistical analysis. Publicly available datasets such as e-ophtha, HRIS, MESSIDOR, DIARETDB1, VDIS, DRIVE, HRF and one local dataset are used to test the suggested system. The achieved results show an average AUC of 0.98 and accuracy as high as 98.58% which are substantially higher than the existing methods.		Javeria Amin;Muhammad Majid Sharif;Mussarat Yasmin;Hussam Ali;Steven Lawrence Fernandes	2017	J. Comput. Science	10.1016/j.jocs.2017.01.002	computer vision;biological classification	Theory	35.056531773265625	-75.92415552407225	57294
01d1e9866112c4e584f54c038c378710e7e5d8df	the diagnosis of alzheimer's disease based on voxel-based morphometry and support vector machine	alzheimer s disease ad;support vector machines biomedical mri brain diseases learning artificial intelligence medical computing neurophysiology;healthy control;brain;support vector machines;clinical application;training;pca alzheimer s disease ad magnetic reso nance imaging voxel based morphometry support vector machine;kernel function;magnetic resonance image;medical computing;early diagnosis;accuracy;training set;gray matter loss;disease diagnosis;voxel based morphometry;alzheimer s disease support vector machines magnetic resonance imaging support vector machine classification dementia artificial neural networks principal component analysis aging atrophy information science;principal component analysis;magnetic resonance imaging;imaging;svm classifier;gray matter;training set alzheimer disease disease diagnosis voxel based morphometry support vector machine gray matter loss magnetic resonance imaging principal component analysis feature dimensionality reduction linear kernel function svm classifier;diseases;support vector machine;neurophysiology;learning artificial intelligence;alzheimer disease;dimensional reduction;pca;magnetic reso nance imaging;linear kernel function;biomedical mri;feature dimensionality reduction	The purpose of this study was to explore the automatic method of detecting the gray matter loss of Alzheimerpsilas disease (AD) patients with magnetic resonance imaging (MRI). In this paper, voxel-based morphometry (VBM) and support vector machine (SVM )were combined and introduced to diagnose Alzheimer's disease(AD) for clinical applications. Firstly, with the VBM method, 20 features were obtained from the accurate structure imaging of possible AD and the controls, and then the principal component analysis (PCA) was used for feature dimensionality reduction to improve the efficiency. Then, a SVM classifier with linear kernel function was used to distinguish AD from healthy controls. Finally, the performance of SVM was evaluated. The accuracy of classifier is proportional to the number of training samples. With 18 training samples, the predictive capability of SVM could reach 100%. And the results will be slightly better under the process of PCA with fewer features. In conclusion, the results of this study confirmed that the method of combining VBM with SVM could be used as an automatic tool for the early diagnosis of AD.	alzheimer's disease neuroimaging initiative;dimensionality reduction;morphometrics;principal component analysis;resonance;sensor;support vector machine;voxel	Jin Zhang;Bin Yan;Xin Huang;Pengfei Yang;Chengzhong Huang	2008	2008 Fourth International Conference on Natural Computation	10.1109/ICNC.2008.804	psychology;artificial intelligence;machine learning;pattern recognition	ML	29.871245122665112	-78.09171034958696	58012
6db682d10a949530aa3fbc872723217fa960ecef	learning beyond human expertise with generative models for dental restorations		Computer vision has advanced significantly that many discriminative approaches such as object recognition are now widely used in real applications. We present another exciting development that utilizes generative models for the mass customization of medical products such as dental crowns. In the dental industry, it takes a technician years of training to design synthetic crowns that restore the function and integrity of missing teeth. Each crown must be customized to individual patients, and it requires human expertise in a time-consuming and laborintensive process, even with computer assisted design software. We develop a fully automatic approach that learns not only from human designs of dental crowns, but also from natural spatial profiles between opposing teeth. The latter is hard to account for by technicians but important for proper biting and chewing functions. Built upon a Generative Adversarial Network architecture (GAN), our deep learning model predicts the customized crown-filled depth scan from the crown-missing depth scan and opposing depth scan. We propose to incorporate additional space constraints and statistical compatibility into learning. Our automatic designs exceed human technicians’ standards for good morphology and functionality, and our algorithm is being tested for production use.		Jyh-Jing Hwang;Sergei Azernikov;Alexei A. Efros;Stella X. Yu	2018	CoRR		machine learning;discriminative model;generative grammar;network architecture;deep learning;computer science;mass customization;cognitive neuroscience of visual object recognition;software;dental crowns;artificial intelligence	AI	29.95867899360132	-75.36209579559447	58033
92e4c3d3bb13e83dc4f23c1f6ff7c43c9004eab4	a technique for extraction of diagnostic data from cytological specimens	analisis imagen;methode echelle multiple;metodo escala multiple;image bruitee;imagen sonora;image generation;scale space;imagen borrosa;b cell;blurred image;noisy image;image analysis;multiscale method;image floue;analyse image;espace echelle	In this paper, a possibility of developing a new criterion for diagnostics of hematopoietic tumors, such as chronic B-cell lymphatic leukemia, transformation of chronic B-cell lymphatic leukemia into lymphosarcoma, and primary B-cell lymphosarcoma, from images of cell nuclei of lymphatic nodes is considered. A method for image analysis of lymphatic node specimens is developed on the basis of the scale space approach. A diagnostically important criterion is defined as a total amount of points of spatial intensity extrema in the families of blurred images generated by the given image of a cell nucleus. The procedure for calculating criterion values is presented.		Igor B. Gurevich;Andrei Khilkov;Dmitry Murashov	2003		10.1007/978-3-540-24586-5_33	computer vision;scale space;image analysis;computer science;calculus	NLP	37.535484306326296	-74.74257322705607	58146
55804f7dfbf5dd05991d91e9b961c5b17259ebea	intravascular ultrasound images vessel characterization using adaboost	ensemble method;supervised learning;feature space;ultrasound imaging;medical image;feature selection;coronary artery;intravascular ultrasound	This paper presents a method for accurate location of the vessel borders based on boosting of classifiers and feature selection. Intravascular Ultrasound Images (IVUS) are an excellent tool for direct visualization of vascular pathologies and evaluation of the lumen and plaque in coronary arteries. Nowadays, the most common methods to separate the tissue from the lumen are based on gray levels providing non-satisfactory segmentations. In this paper, we propose and analyze a new approach to separate tissue from lumen based on an ensemble method for classification and feature selection. We perform a supervised learning of local texture patterns of the plaque and lumen regions and build a large feature space using different texture extractors. A classifier is constructed by selecting a small number of important features using AdaBoost. Feature selection is achieved by a modification of the AdaBoost. A snake is set to deform to achieve continuity on the classified image. Different tests on medical images show the advantages.	adaboost;data descriptor;feature extraction;feature selection;feature vector;grayscale;medical imaging;pioneer plaque;real-time computing;scott continuity;supervised learning	Oriol Pujol;Misael Rosales;Petia Radeva;Eduard Fernández-Nofrerías	2003		10.1007/3-540-44883-7_25	computer vision;engineering;machine learning;pattern recognition	ML	34.095051407151075	-75.32292295207034	58284
5771df56f16bd9bb363d546829962ee16b334538	hand motion recognition based on forearm deformation measured with a distance sensor array	robot sensing systems;support vector machines;wrist;motion measurement;sensor arrays;muscles	Studies of upper limb motion analysis using surface electromyogram (sEMG) signals measured from the forearm plays an important role in various applications, such as human interfaces for controlling robotic exoskeletons, prosthetic hands, and evaluation of body functions. Though the sEMG signals have a lot of information about the activities of the muscles, the signals do not have the activities of the deep layer muscles. We focused on forearm deformation, since hand motion brings the muscles, tendons, and skeletons under the skin. The reason why we focus is that we believe the forearm deformation delivers information about the activities of deep layer muscles. In this paper, we propose a hand motion recognition method based on the forearm deformation measured with a distance sensor array. The method uses the support vector machine. Our method achieved a mean accuracy of 92.6% for seven hand motions. Because the accuracy of the pronation and the supination are high, the distance sensor array has the potential to estimate the activities of deep layer muscles.	electromyography;forearm;hepatitis b surface antigens;motion;muscle;pronation;robot;robotic exoskeleton;sensor;skeleton;supination;support vector machine;tendon structure;under the skin;upper extremity	Sung-Gwi Cho;Masahiro Yoshikawa;Kohei Baba;Kazunori Ogawa;Jun Takamatsu;Tsukasa Ogasawara	2016	2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2016.7591839	support vector machine;computer vision;computer science;engineering;machine learning;anatomy;surgery	Robotics	25.783094815117916	-67.45765249856322	58445
a9dfb06a6c07564c8e657eec322d5739ed16b74f	one-class classification of mammograms using trace transform functionals	support vector machines cancer feature extraction gaussian processes image classification mammography medical image processing radon transforms;trace transform cancer mammogram one class classification texture;radon transforms;support vector machines;cancer;gaussian processes;image classification;singapore anti tuberculosis association commhealth one class classification mammography trace transform functionals breast cancer prescreening breast cancer detection interobserver variations intraobserver variations mammographic screening image quality diagnostic procedures breast cancer image grading image classification two class classification problem one class outlier identification problem radon transform feature extraction linear discriminant classifier quadratic discriminant classifier nearest mean classifier support vector machine gaussian mixture model gmm automated diagnosis;feature extraction;medical image processing;mammography;transforms feature extraction breast cancer design automation support vector machines pipelines	Mammography is one of the first diagnostic tests to prescreen breast cancer. Early detection of breast cancer has been known to improve recovery rates to a great extent. In most medical centers, experienced radiologists are given the responsibility of analyzing mammograms. But, there is always a possibility of human error. Errors can frequently occur as a result of fatigue of the observer, resulting in interobserver and intraobserver variations. The sensitivity of mammographic screening also varies with image quality. To offset different kinds of variability and to standardize diagnostic procedures, efforts are being made to develop automated techniques for diagnosis and grading of breast cancer images. This paper presents a one-class classification pipeline for the classification of breast cancer images into benign and malignant classes. Because of the sparse distribution of abnormal mammograms, the two-class classification problem is reduced to a one-class outlier identification problem. Trace transform, which is a generalization of the Radon transform, has been used to extract the features. Several new functionals specific to mammographic image analysis have been developed and implemented to yield clinically significant features. Classifiers such as the linear discriminant classifier, quadratic discriminant classifier, nearest mean classifier, support vector machine, and the Gaussian mixture model (GMM) were used. For automated diagnosis, the classification pipeline was tested on a set of 313 mammograms provided by the Singapore Anti-Tuberculosis Association CommHealth. A maximum accuracy rate of 92.48% has been obtained using GMMs.	data mining;framing (world wide web);google map maker;human error;image analysis;image quality;linear discriminant analysis;medical image computing;medical imaging;mixture model;one-class classification;radiology;sparse matrix;spatial variability;support vector machine;virtual screening	Karthikeyan Ganesan;U. Rajendra Acharya;Chua Kuang Chua;Choo Min Lim;K. Thomas Abraham	2014	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2013.2278562	support vector machine;computer vision;contextual image classification;quadratic classifier;feature extraction;computer science;machine learning;linear classifier;pattern recognition;gaussian process;mathematics;cancer	ML	34.02539560338229	-76.45003581980072	58559
06a24a55b8423e03683eabef4f9a0ca97c921afd	new algorithm for the transcription of arabic manuscripts	arabic manuscript;handwriting recognition;holy qur an new algorithm arabic manuscripts transcription handwritten arabic offline manuscripts images arab islamic language exquisite language;image segmentation integrated circuits manuals image recognition artificial neural networks multimedia communication;global approach;arabic manuscript offline recognition global approach;natural language processing handwriting recognition;natural language processing;offline recognition	This paper presents a system for recognizing handwritten Arabic offline, single-writer without word segmentation. The system aims to transcribe the manuscripts images to enable their operations and accelerate the search for content. It has set an objective, scan, analyze, make available to the public archive content Arab-Islamic language and bring out an exquisite language: Arabic, the most authentic language of the universe, the language of precious divine books, that the Holy Qur'an.	algorithm;archive;book;online and offline;printing;text segmentation;transcription (software)	Lamiae Dounas;Mostafa Idrissi Azzouzi;Noureddine Rais	2012	2012 Colloquium in Information Science and Technology	10.1109/CIST.2012.6388068	natural language processing;speech recognition;art;linguistics	NLP	32.7715697738833	-66.69401878747932	58776
be4c4ecef59c213d90c98e32f5f647b2b7c24f0c	a novel method for automatic segmentation of brain tumors in mri images		The brain tumor segmentation on MRI images is a very difficult and important task which is used in surgical and medical planning and assessments. If experts do the segmentation manually with their own medical knowledge, it will be time-consuming. Therefore, researchers propose methods and systems which can do the segmentation automatically and without any interference. In this article, an unsupervised automatic method for brain tumor segmentation on MRI images is presented. In this method, at first in the preprocessing level, the extra parts which are outside the skull and don't have any helpful information are removed and then anisotropic diffusion filter with 8-connected neighborhood is applied to the MRI images to remove noise. By applying the fast bounding box(FBB) algorithm, the tumor area is displayed on the MRI image with a bounding box and the central part is selected as sample points for training of a One Class SVM classifier. A database is also provided by the Zanjan MRI Center. The MRI images are related to 10 patients who have brain tumor. 100 T2-weighted MRI images are used in this study. Experimental results show the high precision and dependability of the proposed algorithm. The results are also highly helpful for specialists and radiologists to easily estimate the size and position of a tumor. Keywordstumor segmentation; brain tumor; fast bounding box; anisotropic diffusion filter; support vector machine(SVM); magnetic resonance imaging (MRI)	algorithm;anisotropic diffusion;dependability;fast fourier transform;interference (communication);minimum bounding box;pixel connectivity;preprocessor;radiology;resonance;support vector machine	Saeid Fazli;Parisa Nadirkhanlou	2013	CoRR		computer vision;real-time mri;computer science;data mining;scale-space segmentation	Vision	37.04795815560552	-77.30001494592682	58912
1705429b738f3e50966e54e3f86ed5bc7cc52b45	classification of benign and malignant brain tumor ct images using wavelet texture parameters and neural network classifier	computed tomography ct;support vector machine svm;discrete wavelet transform dwt;probabilistic neural network pnn;receiver operating characteristic roc analysis	Computational methods are useful for medical diagnosis because they provide additional information that cannot be obtained by simple visual interpretation. As a result, an enormous amount of computer vision research effort has been targeted at achieving automated medical image analysis. In this paper, we present the combination of wavelet statistical texture features (WST) obtained from two-level discrete wavelet-transformed (DWT) images and wavelet co-occurrence texture features (WCT) obtained from twolevel DWT detail images for the classification of abnormal brain tissues into benign, malignant tumor of CT images. Our proposed system consists of four phases: (1) segmentation of region of interest, (2) discrete wavelet decomposition, (3) feature extraction and feature selection, and (4) classification and evaluation. The support vector machine is employed to segment the shape of tumor information. A combination of both WST and WCT texture features is extracted from tumor region of two-level discrete wavelet-transformed images. Genetic algorithm (GA) is used to select the optimal texture features from the set of extracted features. The probabilistic neural network classifier (PNN) is built to classify the abnormal brain tissues into benign, malignant tumor images and evaluate the performance of classifier by comparing the classification results of the PNN classifier with linear vector quantization (LVQ) neural network classifier, back propagation neural network (BPN) classifier. The results of PNN, LVQ, BPN classifiers for the texture analysis methods are evaluated using statistical analysis and receiver operating characteristic analysis. From the experimental results, it is inferred that the best classification performance is achieved by PNN than LVQ and BPN classifiers. The system has been tested with real data of 80 benign, malignant CT brain tumor images and has achieved satisfactory results.	artificial neural network;backpropagation;business process network;ct scan;computation;computer vision;discrete wavelet transform;feature extraction;feature selection;genetic algorithm;image analysis;learning vector quantization;medical image computing;medical imaging;probabilistic neural network;radiology;receiver operating characteristic;region of interest;sensitivity and specificity;software propagation;software release life cycle;support vector machine	A. Padma Nanthagopal;R. Sukanesh Rajamony	2013	J. Visualization	10.1007/s12650-012-0153-y	speech recognition;machine learning;pattern recognition	ML	34.69962933173995	-74.59032066339309	59197
f05aa8b0ea5bb1f585cf78d0b6931fc1b59880cc	adrenal tumor segmentation method for mr images	adrenal tumor segmentation;cad system;hybrid approach;mr images	BACKGROUND AND OBJECTIVE Adrenal tumors, which occur on adrenal glands, are incidentally determined. The liver, spleen, spinal cord, and kidney surround the adrenal glands. Therefore, tumors on the adrenal glands can be adherent to other organs. This is a problem in adrenal tumor segmentation. In addition, low contrast, non-standardized shape and size, homogeneity, and heterogeneity of the tumors are considered as problems in segmentation.   METHODS This study proposes a computer-aided diagnosis (CAD) system to segment adrenal tumors by eliminating the above problems. The proposed hybrid method incorporates many image processing methods, which include active contour, adaptive thresholding, contrast limited adaptive histogram equalization (CLAHE), image erosion, and region growing.   RESULTS The performance of the proposed method was assessed on 113 Magnetic Resonance (MR) images using seven metrics: sensitivity, specificity, accuracy, precision, Dice Coefficient, Jaccard Rate, and structural similarity index (SSIM). The proposed method eliminates some of the discussed problems with success rates of 74.84%, 99.99%, 99.84%, 93.49%, 82.09%, 71.24%, 99.48% for the metrics, respectively.   CONCLUSIONS This study presents a new method for adrenal tumor segmentation, and avoids some of the problems preventing accurate segmentation, especially for cyst-based tumors.		Mücahid Barstugan;Rahime Ceylan;Semih Asoglu;Hakan Cebeci;Mustafa Koplay	2018	Computer methods and programs in biomedicine	10.1016/j.cmpb.2018.07.009	sørensen–dice coefficient;adaptive histogram equalization;artificial intelligence;computer vision;image processing;radiology;active contour model;thresholding;computer science;segmentation;region growing;magnetic resonance imaging	Vision	38.2647713724865	-78.41904011954406	59659
e2834682877408e1b86b482c2e55f77e33ad4f6e	independent component analysis-based classification of alzheimer’s disease from segmented mri data		An accurate and early diagnosis of the Alzheimer’s disease (AD) is of fundamental importance to improve diagnosis techniques, to better understand this neurodegenerative process and to develop effective treatments. In this work, a novel classification method based on independent component analysis (ICA) and supervised learning methods is proposed to be applied on segmented brain magnetic resonance imaging (MRI) from Alzheimer’s disease neuroimaging initiative (ADNI) participants for automatic classification task. The ICA-based method is composed of three step. First, MRI are normalized and segmented by the Statistical Parametric Mapping (SPM8) software. After that, average image of normal (NC), mild cognitive impairment (MCI) or AD subjects are computed. Then, FastICA is applied to these different average images for extracting a set of independent components (IC) which symbolized each class characteristics. Finally, each brain image from the database was projected onto the space spanned by this independent components basis for feature extraction, a support vector machine (SVM) is used to manage the classification task. A 87.5% accuracy in identifying AD from NC, with 90.4% specificity and 84.6% sensitivity is obtained. According to the experimental results, we can see that this proposed method can successfully differentiate AD, MCI and NC subjects. So, it is suitable for automatic classification of sMRI images.		Laila Khedher;Javier Ramírez;Juan Manuel Górriz;Abdelbasset Brahim;Ignacio Álvarez	2015		10.1007/978-3-319-18914-7_9	artificial intelligence;support vector machine;supervised learning;computer science;statistical parametric mapping;machine learning;normalization (statistics);computer-aided diagnosis;feature extraction;independent component analysis;fastica	ML	31.12752178647826	-78.16571079140977	59777
1d5f5ff5dd682efcca48799218271bf0679b5383	hierarchical conditional random fields for detection of gad-enhancing lesions in multiple sclerosis	lesion level;feature-specific lesion;multiple sclerosis;relapsing-remitting ms patient;crf model;average false positive count;gad-enhancing lesion;candidate lesion voxel;brain image;brain mri;lesion candidate;hierarchical conditional random field	The detection of gad-enhancing lesions in brain MRI of Multiple Sclerosis (MS) patients is of great interest since they are important markers of disease activity. However, many of the enhancing voxels are associated with normal structures (i.e. blood vessels) or noise in the MRI, making the detection of gad-enhancing lesions a challenging task. Furthermore, these lesions are typically small and in close proximity to vessels. In this paper, we present an automatic, probabilistic Hierarchical Conditional Random Field (HCRF) framework for detection of gad-enhancing lesions in brain images of patients with MS. In the first level, a CRF with unary and pairwise potentials is used to identify candidate lesion voxel. In the second level, these lesion candidates are grouped based on anatomical and spatial features, and feature-specific lesion based CRF models are designed for each group. This lesion level CRF incorporates higher order potentials which account for shape, group intensities and symmetries. The proposed algorithm is trained on 92 multimodal clinical datasets acquired from Relapsing-Remitting MS patients during multicenter clinical trials and is evaluated on 30 independent cases. The experimental results show a sensitivity of 98%, a positive predictive value of 66% and an average false positive count of 1.55, outperforming the CRF and MRF frameworks proposed in.	blood vessel;conditional random field;generalized anxiety disorder;markov random field;multimodal interaction;multiple sclerosis;patients;positive predictive value of diagnostic test;unary operation;voxel;algorithm	Zahra Karimaghaloo;Douglas L. Arnold;D. Louis Collins;Tal Arbel	2012	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-33418-4_47	computer vision;pathology;machine learning;mathematics	Vision	31.902496615271318	-78.38879598189726	59927
832dd11c8a77fb23f346ce2922f80966920a2f25	active learning for interactive 3d image segmentation	novel method;plane suggestion;interactive input;query plane;image segmentation;user study;active learning strategy;image domain;active learning;random plane selection	"""We propose a novel method for applying active learning strategies to interactive 3D image segmentation. Active learning has been recently introduced to the field of image segmentation. However, so far discussions have focused on 2D images only. Here, we frame interactive 3D image segmentation as a classification problem and incorporate active learning in order to alleviate the user from choosing where to provide interactive input. Specifically, we evaluate a given segmentation by constructing an """"uncertainty field"""" over the image domain based on boundary, regional, smoothness and entropy terms. We then calculate and highlight the plane of maximal uncertainty in a batch query step. The user can proceed to guide the labeling of the data on the query plane, hence actively providing additional training data where the classifier has the least confidence. We validate our method against random plane selection showing an average DSC improvement of 10% in the first five plane suggestions (batch queries). Furthermore, our user study shows that our method saves the user 64% of their time, on average."""	active learning (machine learning);algorithm;batch processing;choose (action);image segmentation;maximal set;question (inquiry);statistical classification;usability testing;weight;biologic segmentation	Andrew Top;Ghassan Hamarneh;Rafeef Abugharbieh	2011	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-23626-6_74	computer vision;computer science;machine learning;segmentation-based object categorization;data mining;image segmentation;scale-space segmentation	Vision	29.912003207595635	-72.44783091405185	60021
f4537216c80153da420d11342e3bf26f3952c899	full-fingerprint volumetric subsurface imaging using fourier-domain optical coherence tomography	wavelength measurement;sensors;two dimensional displays;interference;three dimensional displays;sweat glands	Despite the long history of automated fingerprint recognition, the state-of-the-art 2D sensors still struggle with abraded, dry, wet or greasy fingers, as well as extra-soft skin of the infant fingerprints. But above all, the current sensors suffer from vulnerabilities to presentation attacks, which greatly limits their applicability in unsupervised scenarios such as border control. Optical Coherence Tomography (OCT) represents an alternative approach with a high potential to address the existing challenges. In this paper, we present a novel fingerprint sensor based on Fourier Domain Optical Coherence Tomography (FD-OCT), capable of capturing a 3D volumetric full fingerprint scan from a 2×2cm area, along with subsurface details such as sweat glands and the internal fingerprint. The novelty of our setup lies in the ability of FD-OCT-scanning a full 3D volumetric fingerprint at high-resolution at speeds that demonstrate the usability of 3D OCT in real-world applications.	experiment;fingerprint recognition;general-purpose markup language;image resolution;image segmentation;microelectromechanical systems;optical fiber;sensor;tomography;unsupervised learning;usability	Ctirad Sousedik;Ralph Breithaupt	2017	2017 5th International Workshop on Biometrics and Forensics (IWBF)	10.1109/IWBF.2017.7935082	computer vision;telecommunications;engineering;optics	Vision	28.20258212396253	-69.08858127579741	60140
dac72614b2c903d9238df0976e17112a0c1df8fe	classification on adhd with deep learning	fmri;training;fmri data adhd discrimination attention deficit hyperactivity disorder imaging functional biomarkers public health american psychiatric association deep learning method adhd 200 frequency features datasets imbalance classification;deep belief network adhd fmri deep learning;deep belief network;learning systems;accuracy;brain modeling;adhd;deep learning;magnetic resonance;feature extraction;pattern classification learning artificial intelligence medical computing medical disorders;data models;training accuracy data models learning systems feature extraction brain modeling magnetic resonance	Effective discrimination of attention deficit hyperactivity disorder (ADHD) using imaging and functional biomarkers would have fundamental influence on public health. In usual, the discrimination is based on the standards of American Psychiatric Association. In this paper, we modified one of the deep learning method on structure and parameters according to the properties of ADHD data, to discriminate ADHD on the unique public dataset of ADHD-200. We predicted the subjects as control, combined, inattentive or hyperactive through their frequency features. The results achieved improvement greatly compared to the performance released by the competition. Besides, the imbalance in datasets of deep learning model influenced the results of classification. As far as we know, it is the first time that the deep learning method has been used for the discrimination of ADHD with fMRI data.	auditory processing disorder;bayesian network;deep belief network;deep learning;statistical classification	Deping Kuang;Lianghua He	2014	2014 International Conference on Cloud Computing and Big Data	10.1109/CCBD.2014.42	data modeling;speech recognition;feature extraction;computer science;machine learning;accuracy and precision;deep learning;deep belief network	ML	27.29149147750883	-77.22087492030033	60365
fdc4af8accfb8fca3d9cae9011ada733aae785da	fuzzy patterns and classification of functional brain images for the diagnosis of alzheimer's disease	patient diagnosis;radiology;fuzzy patterns;fuzzy reasoning;support vector machines diseases fuzzy reasoning fuzzy set theory image classification medical image processing patient diagnosis single photon emission computed tomography;support vector machines;radiology fuzzy patterns image classification functional brain images patient diagnosis alzheimer disease chronic degenerative disease central nervous system single photon emission computed tomography hypoperfusion quantitatively automatic analysis characteristic point based fuzzy inference classifier constrained minimizations nearest neighbor method support vector machine characteristic points;image classification;hypoperfusion;constrained minimization;chronic degenerative disease;nearest neighbor method;fuzzy set theory;information embedding;brain alzheimer s disease support vector machines support vector machine classification positron emission tomography biomedical imaging medical diagnostic imaging degenerative diseases central nervous system computed tomography;medical image processing;characteristic points;functional brain images;fuzzy inference;single photon emission computed tomography;diseases;error rate;constrained minimizations;quantitatively automatic analysis;characteristic point based fuzzy inference classifier;support vector machine;alzheimer disease;functional brain imaging;central nervous system	Alzheimer's disease is a chronic degenerative disease of the central nervous system. Most common regional abnormalities for Alzheimer's disease are symmetric or asymmetric bilateral temporal or parietal hypoperfusion. Single-photon emission computed tomography (SPECT) is a useful tool in analyzing hypoperfusion in patients with Alzheimer's disease. The aim of this research is to provide a quantitatively automatic analysis of the SPECT scans for the diagnosis of Alzheimer's disease. A characteristic-point-based fuzzy inference classifier (CPFIC) is proposed to perform two-class classification. The closeness matrix is defined to determine the closeness between training samples, and constrained minimizations are used to systematically train the CPFIC. For comparison, experiments on nearest neighbor method and support vector machine (SVM) were also performed. In error rates, the proposed CPFIC is better than nearest neighbor method, but worse than SVM method. Although the CPFIC did not perform better than SVM in error rates, the summarizing information embedded in the patterns on characteristic points can complement SVM to provide more information to radiologists	bilateral filter;ct scan;centrality;constrained conditional model;embedded system;ensemble learning;experiment;fuzzy logic;learning rule;least squares support vector machine;logic programming;nearest neighbor search;principal component analysis;radiology;support vector machine;tomography	Tang-Kai Yin;Nan-Tsing Chiu	2005	The 14th IEEE International Conference on Fuzzy Systems, 2005. FUZZ '05.	10.1109/FUZZY.2005.1452386	support vector machine;computer vision;computer science;machine learning;pattern recognition;mathematics	ML	29.689995342954955	-78.23898517181485	60409
cd1aa8d1f31e6ef0b9cb3084532cc2c7f9906d65	a tool supported approach for brightness preserving contrast enhancement and mass segmentation of mammogram images using histogram modified grey relational analysis		Mammography is a tool that uses X-rays to create mammograms. This tool is mainly used to find early signs of breast cancer. Usually, mammogram image contains region with low contrast and complicated structured background. This may cause difficulties in detection of infected cells in their early stage. Using contrast enhancement of mammogram image we can increase the detection rate of early breast cancer. In this paper we propose a tool supported method named histogram modified grey relational analysis, based on HE with local contrast enhancement for mammogram images. This method enhances local as well as global contrast of given mammogram image and segments breast region in order to obtain better visual interpretation, analysis, and classification of mammogram masses to assist radiologists in making more accurate decisions. The main contribution of this work is to show that better breast-region segmentation results can be achieved from simple breast-region segmentation method if the input image has sufficient contrast with good interpretation of local details. We tested proposed method for MIAS mammogram images. To evaluate effectiveness of proposed method we choose three widely used metrics absolute mean brightness error, structural similarity index measure and peak signal to noise ratio for all 322 images of MIAS mammogram images database.		Bhupendra Gupta;Mayank Tiwari	2017	Multidim. Syst. Sign. Process.	10.1007/s11045-016-0432-1	computer vision;machine learning;pattern recognition	Vision	38.744100683019504	-75.28629939017436	60503
580b2e42525b66061f8635828557deb04ea0d31d	random forest feature selection approach for image segmentation	databases;brain cancer;image segmentation;feature selection	In the field of image segmentation, discriminative models have shown promising performance. Generally, every such model begins with the extraction of numerous features from annotated images. Most authors create their discriminative model by using many features without using any selection criteria. A more reliable model can be built by using a framework that selects the important variables, from the point of view of the classification, and eliminates the unimportant once. In this article we present a framework for feature selection and data dimensionality reduction. The methodology is built around the random forest (RF) algorithm and its variable importance evaluation. In order to deal with datasets so large as to be practically unmanageable, we propose an algorithm based on RF that reduces the dimension of the database by eliminating irrelevant features. Furthermore, this framework is applied to optimize our discriminative model for brain tumor segmentation.	feature selection;image segmentation;random forest	László Lefkovits;Szidónia Lefkovits;Simina Emerich;Mircea-Florin Vaida	2016		10.1117/12.2268694	image texture;computer vision;feature detection;machine learning;segmentation-based object categorization;pattern recognition;region growing;image segmentation;scale-space segmentation;feature	Vision	33.58237702643045	-74.33957987985274	60519
072abf172299446a77457fc811b7e5483c73ae35	iterative sub-image binarization for document images	optimisation;background noise computed tomography statistical distributions pixel feature extraction gray scale histograms interference elimination writing statistical analysis;prior knowledge;statistical model;feature extraction document image processing handwritten character recognition optimisation;feature extraction;document image processing;handwritten character recognition;feature extraction iterative sub image binarization document images statistical model handwritten characters optimisation	Existing binarization methods are categorized as either global or local. In this paper we present a new category, where the image is considered as a collection of subimages. Each suhimage provides a statistical model for the handwritten characters that will be used to optimize the binarization of other suhimages. This method can be applied to different types of documents and doesn't require any prior knowledge about the noisiness of the subimages. 1 I N T R O D U C T I O N Existing binarization techniques can be categorized into two classes: global arid local thresholding. Global thresholding algorithnls use a single threshold, while ICcal thresholding algorithms compute a separate threshold for each pixel based on a neighhorhood of the pixel. Many binarization methods were proposed over the last 20 years. Sahoo et. al 141 compared the performance of more than 20 global thresholding algorithms using uniformity or sha,pe measures. Trier and Jain 161 evaluated the performance of 11 well-established local thresholding algorithms. Dawoud and Kame1 [a] p r e posed model-based binarization algorithm. We propose a new category of image binarization where the image is divided into subimages. Let us assume that a document image is divided into s u b images: Image(l), Image(2), ..., Image(M), where A4 is the total number of suhimages. Figure 1 shows an example of such a document image that contains five suhimages, M = 5. 'The objective of our approach is to find an optimal global threshold for each subimage that would eliminate the background noise, while p r o serving as much handwritten stroke data as possible. 2 NEW A L G O R I T H M We will use Figure 2 as an example to demonstrate the application of steps of the algorithm. As a p r e processing step, non-character structures, like baselines and frame boxes, are cropped. These structures usu. ally have differelit gray-level and stroke-run diaracteristics than those of the handwritten characters; therefore, they should be cropped so that they don't be confused with handwritten strokes. This preprocess ing step, as shown in Figure 2, is performed before doing the iterative feature extraction. The subimages are binarized at a sequence of Candidate Thresholds, CT,, where CTl is the lowest possible threshold in thc gray-scale histogram. The difference between two successive Cl's was chosen to be 8 gray-levels, which we found to be satisfactory. As the iteration number, i, increases the handwritten strokes become thicker and more connected, but a t the same time there will be a higher risk of background noise interference, because the CT, will also be closer to the background region of the gray-scale histogram. 2.1 Feature extraction: Notice that CT, in Figure 2 failed to eliminate the background noise in Image(]). We want to infer such failure hy comparing features of the binarized Image( 1) with those of the other sub-images. We used the graylevel and stroke-run features, which mainly retlect the underlying characteristics of the pen used in writing, and are invariant to handwriting style or content. Now, because CT7 failed to eliminate Image(1) noise, we conclude that the CTg (the one that precedes the failure) is the optimal threshold; it preserved as much handwriting stroke data as possible without allowing the background noise interference. 2.1.1 Gray-level feature We will show how to optimize the binarization of Image(y) using information from another suhimage, Image(z). Suppose that all subimages are binarized at a, CT,. If the bina,rized subimage Image(x) is noise free, then its gray-level statistics of the extracted pixels (pixels with gray-level lower than CT, only) ca,n he used to estimate the parameters of a Gaussian distribution N, (pz,uz) . If the binarized sub-image Image(y) is noise free also, then we expect that its gray-level statistics of its extracted pixels (py) to be similar to N,. When CT, fails to eliminate Image(y) noise, thcse statistics will become different from N,. So, by testing the following null and alternative hypotheses, we can infer whether a CT, eliminated background noise from 0-7803-7750-8/03/$17.00 02003 IEEE I 553 Figiire 1: Document image containing five subimages	algorithm;bina48;baseline (configuration management);binary image;categorization;circuit complexity;document;feature extraction;grayscale;inferring horizontal gene transfer;interference (communication);iteration;iterative method;pixel;preprocessor;statistical model;thresholding (image processing)	Amer Dawoud;Mohamed S. Kamel	2003		10.1109/ICIP.2003.1247021	statistical model;computer vision;speech recognition;feature extraction;computer science;pattern recognition;mathematics;statistics	Vision	38.16156944988327	-66.63269966662757	60557
afc6849a2eaf0e0159d56ed6d8e95cd5d0a54c10	semicca: a new semi-supervised probabilistic cca model for keyword spotting		In this paper we present a semi-supervised, attribute-based model suitable for keyword spotting (KWS) in document images. Our model can take advantage of available non-annotated segmented word images, as well as string annotations without a matching word image. We build our model by extending on the probabilistic interpretation of Canonical Correlation Analysis (CCA), solved using Expectation-Maximization (EM). On test-time, we back-project the query and database images to the embedded space by calculating the embedding space posterior density given the observations. Keyword spotting is then efficiently performed by computing query nearest neighbours in the embedded Euclidean space. We validate that our model offers superior performance given the presence of partially-labelled data, with keyword spotting trials on the Bentham and George Washington datasets.	embedded system;expectation–maximization algorithm;semi-supervised learning;semiconductor industry	Giorgos Sfikas;Basilios Gatos;Christophoros Nikou	2017	2017 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2017.8296453	keyword spotting;euclidean space;probabilistic logic;pattern recognition;artificial intelligence;canonical correlation;image segmentation;data modeling;embedding;computer science	Vision	28.604395168457447	-67.05734032030506	60691
7a5d2ed2a9d7a9915355d1ff34fff1824c265824	pattern recognition for cache management in distributed medical imaging environments		Traditionally, medical imaging repositories have been supported by indoor infrastructures with huge operational costs. This paradigm is changing thanks to cloud outsourcing which not only brings technological advantages but also facilitates inter-institutional workflows. However, communication latency is one main problem in this kind of approaches, since we are dealing with tremendous volumes of data. To minimize the impact of this issue, cache and prefetching are commonly used. The effectiveness of these mechanisms is highly dependent on their capability of accurately selecting the objects that will be needed soon. This paper describes a pattern recognition system based on artificial neural networks with incremental learning to evaluate, from a set of usage pattern, which one fits the user behavior at a given time. The accuracy of the pattern recognition model in distinct training conditions was also evaluated. The solution was tested with a real-world dataset and a synthesized dataset, showing that incremental learning is advantageous. Even with very immature initial models, trained with just 1 week of data samples, the overall accuracy was very similar to the value obtained when using 75 % of the long-term data for training the models. Preliminary results demonstrate an effective reduction in communication latency when using the proposed solution to feed a prefetching mechanism. The proposed approach is very interesting for cache replacement and prefetching policies due to the good results obtained since the first deployment moments.	artificial neural network;cpu cache;cloud computing;decision trees;decision tree;deploy;elegant degradation;fits;financial cost;illness behavior;increment;machine learning;medical imaging;outsourcing;pattern recognition;physical object;policy;programming paradigm;repository;rule (guideline);schedule;silo (dataset);trees (plant)	Carlos Viana-Ferreira;Luís S. Ribeiro;Sérgio Matos;Carlos Costa	2015	International Journal of Computer Assisted Radiology and Surgery	10.1007/s11548-015-1272-4	real-time computing;simulation;computer science;data mining	ML	28.670719165403476	-74.176994906253	60832
c0ce1dadfe4592df698663878e608c17d04c4393	vehicle classification using an imbalanced dataset based on a single magnetic sensor	anisotropic magnetoresistive sensor;imbalanced dataset;intelligent transport system;vehicle classification	This paper aims to improve the accuracy of automatic vehicle classifiers for imbalanced datasets. Classification is made through utilizing a single anisotropic magnetoresistive sensor, with the models of vehicles involved being classified into hatchbacks, sedans, buses, and multi-purpose vehicles (MPVs). Using time domain and frequency domain features in combination with three common classification algorithms in pattern recognition, we develop a novel feature extraction method for vehicle classification. These three common classification algorithms are the k-nearest neighbor, the support vector machine, and the back-propagation neural network. Nevertheless, a problem remains with the original vehicle magnetic dataset collected being imbalanced, and may lead to inaccurate classification results. With this in mind, we propose an approach called SMOTE, which can further boost the performance of classifiers. Experimental results show that the k-nearest neighbor (KNN) classifier with the SMOTE algorithm can reach a classification accuracy of 95.46%, thus minimizing the effect of the imbalance.	artificial neural network;backpropagation;biological neural networks;categories;checking (action);classification;data acquisition;discrete fourier transform;drug vehicle;f1 score;feature extraction;global positioning system;gray platelet syndrome;image sensor;k-nearest neighbors algorithm;lithium;manuscripts;multi-purpose viewer;numerous;pattern recognition;pattern recognition;principal component analysis;revision procedure;silo (dataset);single linkage cluster analysis;software propagation;spectroscopy, fourier transform infrared;support vector machine;support vector machine;time series;type signature;magnetometers;nonmetastatic childhood soft tissue sarcoma;sensor (device)	Chang Xu;Yingguan Wang;Xinghe Bao;Fengrong Li	2018		10.3390/s18061690	engineering;artificial neural network;electronic engineering;support vector machine;frequency domain;feature extraction;statistical classification;time domain;pattern recognition;artificial intelligence	ML	31.3750263222405	-71.58024304767484	61200
d6357f082e4fca9fd46d3a232e1af4481496b5cb	analysis of medical images: registration, segmentation and classification		A large number of medical examinations involve images in some way. Images can be used for diagnostics, follow-up studies and treatment planning. In this thesis mathematical methods have been developed and adapted in order to analyze medical images. Several applications for different imaging modalities have been studied and the usefulness of such methods is demonstrated. A complete system for detection and diagnosis of kidney lesions in scintigraphy images has been developed. We segment the kidneys with the use of an active shape model. The uptake of a biological molecule is then compared to the uptake in a healthy kidney and potential lesions are detected. A number of properties of the potential lesions are gathered and the lesions are classified as healthy or unhealthy with a linear classifier. We are able to correctly classify 86 % of the lesions. Ultrasound images have also been studied. In the first case for the purpose of segmenting the left heart ventricle, which can be used for computing the ejection fraction. This was done using a region based snake with anchor points at each side of the cardiac valve. The second application in ultrasound images is also of the heart but with patients that, due to heart failure, have had a mechanical pump implanted. The septum wall between the ventricles is segmented using a shortest path approach and a measure of how much the septum bulges towards either of the ventricles is obtained. By studying this measure a more objective indication is given on whether the speed of the pump is correct for a patient than by only visually study the images. In computed tomography (CT) whole-body images, several organs have been segmented using a multi-atlas approach. The fused labels are refined with a random forest classifier and a final graph cut segmentation. This method was evaluated in the VISCERAL Grand Anatomy Challenge and achieved the highest Dice		Matilda Landgren	2016				Vision	38.12632716233673	-79.64881125862088	61396
2e9af5b3c6f3081dd1ffabdf59763ca4f90d83a9	characterizing populations and searching for diagnostics via elastic registration of mri images	statistical significance;discriminant function;corpus callosum;magnetic resonance imaging;diagnostics	Given image data from two distinct populations and a family of functions, we find the scalar discriminant function which best discriminates between the populations. The goals are two-fold: first, to construct a discriminant function which can accurately and reliably classify subjects via the image data. Second, the best discriminant allows us to see which features in the images distinguish between the populations; these features can guide us to finding characteristic differences between the two groups even if these differences are not sufficient to perform classification. We apply our method to mid-sagittal MRI sections of the corpus callosum from 34 males and 52 females. While we are not certain of the ability of the derived discriminant function to perform sex classification, we find that regions in the anterior of the corpus callosum do appear to be more important for the discriminant function than other regions. This indicates there may be significant differences in the relative size of the splenium in males and females, as has been reported elsewhere. More notably, we applied previous methods which support this view on our larger data set, but found that these methods no longer show statistically significant differences between the male and female splenium.© (2001) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	elastic matching;population	David J. Pettey;James C. Gee	2001		10.1117/12.431049	computer vision;machine learning;pattern recognition;mathematics	Vision	32.63240034779747	-79.22455238091393	61504
a4e90398d1bcfda01867086427d22566964a450e	memristive pulse coupled neural network with applications in medical image processing	memristor;image de noising;image edge extraction;pulse coupled neural network;medical image fusion	Medical imaging has become an integral part of modern medical technology increasingly. The image information provided by multimode imaging technology can complement each other. Fusing computed tomography (CT) and magnetic resonance imaging (MRI) images can combine their unique information to diagnose brain diseases by radiation therapy. And medical imaging process is easy to produce noise, which will impact doctors on diagnosis. So the medical image de-noising has important significance. In addition, the image edge extraction is helpful to the clinical diagnosis. So this paper constructs a memristive pulse coupled neural network (M-PCNN) for medical image processing. The memristance of Gale memristor decays exponentially with time, which can be used to adjust the threshold of pulse coupled neural network (PCNN) online. Integrating the memorability of memristor into PCNN makes the network have biological function. And the introduction of nanoscale memristor can also significantly reduce the scale of PCNN, which may promote the development of neural network hardware implementation. Numerical simulation verifies that the superiority of using this network in medical image fusion, image de-noising and image edge extraction.	algorithm;artificial neural network;ct scan;constant current;current source;floor and ceiling functions;function (biology);image fusion;image processing;imaging technology;iteration;medical imaging;memristor;networking hardware;noise reduction;nonlinear system;pulse-coupled networks;resonance;simulation;tomography	Song Zhu;Lidan Wang;Shukai Duan	2017	Neurocomputing	10.1016/j.neucom.2016.07.068	computer vision;memristor;image processing;computer science;artificial intelligence;machine learning	ML	29.558844862712675	-76.74213353037516	61512
622fb5f9c297d9cc706c99ce4b9a131389a69ea7	a new tongue colorchecker design by space representation for precise correction	statistical analysis biological organs greedy algorithms image classification image colour analysis medical image processing;biological organs;image classification;greedy algorithms;statistical analysis;image color analysis tongue color accuracy training imaging matrix converters;image colour analysis;medical image processing;tongue color space optimal color selection precise color correction tongue colorchecker;tongue colorchecker design greedy selection method clustering based selection method tongue colorchecker generation correction task color selection method optimal color objective function optimal color selection criteria minimum color number colorchecker minimum sufficient color number high correction performance nontongue color visible color classification tongue database space based colorchecker tongue color space munsell colorchecker tongue color correction accuracy precise correction space representation;color databases factual female humans image processing computer assisted male tongue	In order to improve the correction accuracy on tongue colors by use of a Munsell colorchecker, this research aims to design a new colorchecker by aid of tongue color space. Three essential issues leading to the development of this space-based colorchecker are elaborately investigated in this study. First, based on a large and comprehensive tongue database, tongue color space is established by which all visible colors can be classified as tongue or nontongue colors. Hence, colors of the designed tongue colorchecker are selected from tongue colors to achieve high correction performance. Second, the minimum sufficient number of colors involved in a colorchecker is yielded by comparing the correction accuracy when different number (ranged from 10 to 200) of colors are contained. Thereby, 24 colors are included because the obtained minimum number of colors is 20. Finally, criteria for optimal color selection and its corresponding objective function are presented. Two color selection methods, i.e., greedy and clustering-based selection method, are proposed to solve the objective function. Experimental results show that clustering-based one outperforms its counterpart to generate the new tongue colorchecker. Compared to a Munsell colorchecker, this proposed space-based colorchecker can greatly improve the correction accuracy by 48%. Further experimental results on more correction task also validate its effectiveness and superiority.	classification;cluster analysis;color space;contain (action);dermatology field;farnsworth-munsell 100 hue test;food coloring agents;greedy algorithm;loss function;mathematical optimization;optimization problem;population parameter;schematic;selection (genetic algorithm);statistical cluster	Xingzheng Wang;David Zhang	2013	IEEE Journal of Biomedical and Health Informatics	10.1109/TITB.2012.2226736	color histogram;computer vision;contextual image classification;greedy algorithm;speech recognition;computer science;artificial intelligence;mathematics;color balance;statistics	AI	37.0254342520292	-72.52828174929076	61742
4e1f41088015c8e4ca3c714b0db09f678295a8ab	automated determination of watermelon ripeness based on image color segmentation and rind texture analysis	nondestruvtive inspection;image processing;watermelon ripeness;color segmentation;edge detectoin	Watermelons are popularly grown and consumed in most tropical areas of agricultural countries especially in the Asian countries. Quality control is important to standardize the production especially the procedure of automatic system based on computer vision. In this paper, therefore, we objectively investigated the ripeness of watermelon based on color segmentation using k-means clustering and rind texture analysis using Laplacian of Gaussian (LoG) filter. We captured each image of 20 watermelons (Kinnaree variety), which are divided into ten ripe and unripe groups by an experienced farmer. Different experimental conditions were compared to achieve the optimal outcome. The experimental results showed that the proposed features could extract different ripeness levels statistically with p < 0.001.	blob detection;cluster analysis;computer vision;electrical engineering;image segmentation;k-means clustering;mobile app;real-time transcription	Montri Phothisonothai;Suchada Tantisatirapong;Apinan Aurasopon	2016	2016 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)	10.1109/ISPACS.2016.7824766	computer vision;engineering;horticulture;cartography	Robotics	37.417268394900816	-70.35791612613178	62009
3eb32e9d8ff6e6f3e7a3bf7ad8ed775c920172df	modeling surround suppression in v1 neurons with a statistically derived normalization model	second order;classical receptive field;natural images;primary visual cortex;higher order statistics;statistical properties;linear process;principal component analysis;sensory system;steady state	"""Odelia Schwartz Center for Neural Science New York University odelia@cns.nyu.edu We examine the statistics of natural monochromatic images decomposed using a multi-scale wavelet basis. Although the coefficients of this representation are nearly decorrelated, they exhibit important higher-order statistical dependencies that cannot be eliminated with purely linear proc~ssing. In particular, rectified coefficients corresponding to basis functions at neighboring spatial positions, orientations and scales are highly correlated. A method of removing these dependencies is to divide each coefficient by a weighted combination of its rectified neighbors. Several successful models of the steady -state behavior of neurons in primary visual cortex are based on such """"divisive normalization"""" computations, and thus our analysis provides a theoretical justification for these models. Perhaps more importantly, the statistical measurements explicitly specify the weights that should be used in computing the normalization signal. We demonstrate that this weighting is qualitatively consistent with recent physiological experiments that characterize the suppressive effect of stimuli presented outside of the classical receptive field. Our observations thus provide evidence for the hypothesis that early visual neural processing is well matched to these statistical properties of images. An appealing hypothesis for neural processing states that sensory systems develop in response to the statistical properties of the signals to which they are exposed [e.g., 1, 2]. This has led many researchers to look for a means of deriving a model of cortical processing purely from a statistical characterization of sensory signals. In particular, many such attempts are based on the notion that neural responses should be statistically independent. The pixels of digitized natural images are highly redundant, but one can always find a linear decomposition (i.e., principal component analysis) that eliminates second-order corResearch supported by an Alfred P. Sloan Fellowship to EPS, and by the Sloan Center for Theoretical Neurobiology at NYU. 154 E. P Simoncelli and 0. Schwartz relation. A number of researchers have used such concepts to derive linear receptive fields similar to those determined from physiological measurements [e.g., 16,20]. The principal components decomposition is, however, not unique. Because of this, these early attempts required additional constraints, such as spatial locality and/or symmetry, in order to achieve functions approximating cortical receptive fields. More recently, a number of authors have shown that one may use higher-order statistical measurements to uniquely constrain the choice of linear decomposition [e.g., 7, 9]. This is commonly known as independent components analysis. Vision researchers have demonstrated that the resulting basis functions are similar to cortical receptive fields, in that they are localized in spatial position, orientation and scale [e.g., 17, 3]. The associated coefficients of such decompositions are (second-order) decorrelated, highly kurtotic, and generally more independent than principal components. But the response properties of neurons in primary visual cortex are not adequately described by linear processes. Even if one chooses to describe only the mean firing rate of such neurons, one must at a minimum include a rectifying, saturating nonlinearity. A number of authors have shown that a gain control mechanism, known as divisive normalization, can explain a wide variety of the nonlinear behaviors of these neurons [18, 4, II, 12,6]. In most instantiations of normalization, the response of each linear basis function is rectified (and typically squared) and then divided by a uniformly weighted sum of the rectified responses of all other neurons. PhYSiologically, this is hypothesized to occur via feedback shunting inhibitory mechanisms [e.g., 13, 5]. Ruderman and Bialek [19] have discussed divisive normalization as a means of increasing entropy. In this paper, we examine the joint statistics of coefficients of an orthonormal wavelet image decomposition that approximates the independent components of natural images. We show that the coefficients are second-order decorrelated, but not independent. In particular, pairs of rectified responses are highly correlated. These pairwise dependencies may be eliminated by dividing each coefficient by a weighted combination of the rectified responses of other neurons, with the weighting determined from image statistics. We show that the resulting model, with all parameters determined from the statistics of a set of images, can account for recent physiological observations regarding suppression of cortical responses by stimuli presented outside the classical receptive field. These concepts have been previously presented in [21, 25]. 1 Joint Statistics of Orthonormal Wavelet Coefficients Multi-scale linear transforms such as wavelets have become popular for image representation. 'TYpically, the basis functions of these representations are localized in spatial position, orientation, and spatial frequency (scale). The coefficients resulting from projection of natural images onto these functions are essentially uncorrelated. In addition, a number of authors have noted that wavelet coefficients have significantly non-Gaussian marginal statistics [e.g., 10,14]. Because of these properties, we believe that wavelet bases provide a close approximation to the independent components decomposition for natural images. For the purposes of this paper, we utilize a typical separable decomposition, based on symmetric quadrature mirror filters taken from [23]. The decomposition is constructed by splitting an image into four subbands (lowpass, vertical, horizontal, diagonal), and then recursively splitting the lowpass subband. Despite the decorrelation properties of the wavelet decomposition, it is quite evident that wavelet coefficients are not statistically independent [26, 22]. Large-magnitude coefficients (either positive or negative) tend to lie along ridges with orientation matching that of the subband. Large-magnitude coefficients also tend to occur at the same relative spatiallocations in subbands at adjacent scales, and orientations. To make these statistical relationships"""	approximation;basis (linear algebra);basis function;coefficient;computation;decorrelation;experiment;independent component analysis;locality of reference;low-pass filter;marginal model;monochrome;neuron;nonlinear system;pixel;principal component analysis;rectifier (neural networks);recursion;scene statistics;stationary wavelet transform;steady state;weight function;zero suppression	Eero P. Simoncelli;Odelia Schwartz	1998			sensory system;computer vision;computer science;machine learning;mathematics;steady state;second-order logic;statistics;principal component analysis	ML	24.93651968044049	-74.2170379106796	62194
ac97803bb24481b2af41d16af7c21476990395d0	real time burning image classification using support vector machine		Burning image classification is critical and attempted problems in medical image processing. This paper has proposed the real time image classification for burning image to automatically identify the degrees of burns in three levels: II, III, and IV. The proposed model uses the multi-colour channels extraction and binary based on adaptive threshold. The proposed model uses One-class Support Vector Machine instead of traditional Support Vector Machine (SVM) because of unbalanced degrees of burns images database. The classifying precision 77.78% shows the feasibility of our proposed model.	computer vision;image processing;medical imaging;real-time business intelligence;support vector machine;unbalanced circuit	Tran Son Hai;L. M. Triet;Le Hoang Thai;Thuy Thanh Nguyen	2017	EAI Endorsed Trans. Context-aware Syst. & Appl.	10.4108/eai.6-7-2017.152760	structured support vector machine;support vector machine;contextual image classification;artificial intelligence;pattern recognition;computer science	AI	34.70665173329186	-74.29950184595891	62222
6d954db630fc48847360b329a54bee51a8cfc7ca	modeling alzheimer’s disease progression with fused laplacian sparse group lasso		Alzheimer’s disease (AD), the most common type of dementia, not only imposes a huge financial burden on the health care system, but also a psychological and emotional burden on patients and their families. There is thus an urgent need to infer trajectories of cognitive performance over time and identify biomarkers predictive of the progression. In this article, we propose the multi-task learning with fused Laplacian sparse group lasso model, which can identify biomarkers closely related to cognitive measures due to its sparsity-inducing property, and model the disease progression with a general weighted (undirected) dependency graphs among the tasks. An efficient alternative directions method of multipliers based optimization algorithm is derived to solve the proposed non-smooth objective formulation. The effectiveness of the proposed model is demonstrated by its superior prediction performance over multiple state-of-the-art methods and accurate identification of compact sets of cognition-relevant imaging biomarkers that are consistent with prior medical studies.	algorithm;cognition;color gradient;computer multitasking;experiment;graph (discrete mathematics);image-line fl studio;lasso;mathematical optimization;matrix regularization;multi-task learning;optimization problem;predictive modelling;sparse matrix	Xiaoli Liu;Peng Cao;André R. Goncalves;Dazhe Zhao;Arindam Banerjee	2018	TKDD	10.1145/3230668	lasso (statistics);machine learning;laplacian matrix;artificial intelligence;disease;multi-task learning;cognition;dementia;computer science;laplace operator;graph	ML	26.05490822491886	-77.68913795567292	62280
b33e63e5116e12606307fccc4a2a8016cced5cd7	automatic machine interactions for content-based image retrieval using a self-organizing tree map architecture	unsupervised learning;image retrieval content based retrieval radio frequency information retrieval unsupervised learning proposals optimization methods feedback performance evaluation image analysis;optimisation;user participation;digital library;image database;indexing terms;interactive systems image retrieval content based retrieval self organising feature maps unsupervised learning relevance feedback optimisation radial basis function networks;radial basis function networks;radial basis function;self organising feature maps;interactive system;compressed image databases automatic machine interactions self organizing tree map architecture unsupervised learning network self learning capability automated recursive content based image retrieval sotm relevance feedback method optimization single radial basis function based rf method semiautomatic version user subjectivity image similarity robust performance cbir uncompressed image databases;content based image retrieval;interactive systems;relevance feedback;content based retrieval;nonlinear model;image retrieval;image similarity	In this paper, an unsupervised learning network is explored to incorporate a self-learning capability into image retrieval systems. Our proposal is a new attempt to automate recursive content-based image retrieval. The adoption of a self-organizing tree map (SOTM) is introduced, to minimize the user participation in an effort to automate interactive retrieval. The automatic learning mode has been applied to optimize the relevance feedback (RF) method and the single radial basis function-based RF method. In addition, a semiautomatic version is proposed to support retrieval with different user subjectivities. Image similarity is evaluated by a nonlinear model, which performs discrimination based on local analysis. Experimental results show robust and accurate performance by the proposed method, as compared with conventional noninteractive content-based image retrieval (CBIR) systems and user controlled interactive systems, when applied to image retrieval in compressed and uncompressed image databases.	blood glucose self-monitoring;content-based image retrieval;database;interaction;interactivity;nonlinear system;organizing (structure);radial (radio);radial basis function;radio frequency;recursion;relevance feedback;self-organization;treemapping;unsupervised learning	Paisarn Muneesawang;Ling Guan	2002	IEEE transactions on neural networks	10.1109/TNN.2002.1021883	unsupervised learning;computer vision;radial basis function;visual word;digital library;index term;image retrieval;computer science;machine learning;automatic image annotation;information retrieval	Vision	29.69830566312907	-68.91577891418098	62342
415b13c109aec48ffb9a24ab0ec3600b981969b7	detection of prostate cancer using temporal sequences of ultrasound data: a large clinical feasibility study	cancer diagnosis;deep belief network;deep learning;prostate cancer;temporal ultrasound data	This paper presents the results of a large study involving fusion prostate biopsies to demonstrate that temporal ultrasound can be used to accurately classify tissue labels identified in multi-parametric magnetic resonance imaging (mp-MRI) as suspicious for cancer. We use deep learning to analyze temporal ultrasound data obtained from 255 cancer foci identified in mp-MRI. Each target is sampled in axial and sagittal planes. A deep belief network is trained to automatically learn the high-level latent features of temporal ultrasound data. A support vector machine classifier is then applied to differentiate cancerous versus benign tissue, verified by histopathology. Data from 32 targets are used for the training, while the remaining 223 targets are used for testing. Our results indicate that the distance between the biopsy target and the prostate boundary, and the agreement between axial and sagittal histopathology of each target impact the classification accuracy. In 84 test cores that are 5 mm or farther to the prostate boundary, and have consistent pathology outcomes in axial and sagittal biopsy planes, we achieve an area under the curve of 0.80. In contrast, all of these targets were labeled as moderately suspicious in mp-MR. Using temporal ultrasound data in a fusion prostate biopsy study, we achieved a high classification accuracy specifically for moderately scored mp-MRI targets. These targets are clinically common and contribute to the high false-positive rates associated with mp-MRI for prostate cancer detection. Temporal ultrasound data combined with mp-MRI have the potential to reduce the number of unnecessary biopsies in fusion biopsy settings.	area under curve;bayesian network;cardiomyopathies;deep belief network;deep learning;high- and low-level;histopathology;mri ultrasound fusion guided biopsy;magnetic resonance imaging;moderate response;numerous;prostatic neoplasms;sagittal plane;score;support vector machine;tracer	Shekoofeh Azizi;Farhad Imani;Sahar Ghavidel;Amir M. Tahmasebi;Jin Tae Kwak;Sheng Xu;Baris Turkbey;Peter L. Choyke;Peter L Choyke;Bradford J. Wood;Parvin Mousavi;Purang Abolmaesumi	2016	International Journal of Computer Assisted Radiology and Surgery	10.1007/s11548-016-1395-2	radiology;medicine;pathology;medical physics	HCI	31.540736453546934	-76.97425688489554	62388
76f13730e2af5eff07ff17ccd94c25211bb17385	detection of conversion from mild cognitive impairment to alzheimer's disease using longitudinal brain mri	svm classification;non rigid registration;mri;alzheimer s disease;parallel transport;mild cognitive impairment mci;conversion;stationary velocity field svf	Mild Cognitive Impairment (MCI) is an intermediate stage between healthy and Alzheimer's disease (AD). To enable early intervention it is important to identify the MCI subjects that will convert to AD in an early stage. In this paper, we provide a new method to distinguish between MCI patients that either convert to Alzheimer's Disease (MCIc) or remain stable (MCIs), using only longitudinal T1-weighted MRI. Currently, most longitudinal studies focus on volumetric comparison of a few anatomical structures, thereby ignoring more detailed development inside and outside those structures. In this study we propose to exploit the anatomical development within the entire brain, as found by a non-rigid registration approach. Specifically, this anatomical development is represented by the Stationary Velocity Field (SVF) from registration between the baseline and follow-up images. To make the SVFs comparable among subjects, we use the parallel transport method to align them in a common space. The normalized SVF together with derived features are then used to distinguish between MCIc and MCIs subjects. This novel feature space is reduced using a Kernel Principal Component Analysis method, and a linear support vector machine is used as a classifier. Extensive comparative experiments are performed to inspect the influence of several aspects of our method on classification performance, specifically the feature choice, the smoothing parameter in the registration and the use of dimensionality reduction. The optimal result from a 10-fold cross-validation using 36 month follow-up data shows competitive results: accuracy 92%, sensitivity 95%, specificity 90%, and AUC 94%. Based on the same dataset, the proposed approach outperforms two alternative ones that either depends on the baseline image only, or uses longitudinal information from larger brain areas. Good results were also obtained when scans at 6, 12, or 24 months were used for training the classifier. Besides the classification power, the proposed method can quantitatively compare brain regions that have a significant difference in development between the MCIc and MCIs groups.	align (company);alzheimer's disease;anatomic structures;area under curve;baseline (configuration management);cognition disorders;comparison sort;cross-validation (statistics);dimensionality reduction;electrophoresis, gel, pulsed-field;experiment;feature vector;kernel principal component analysis;large;limited stage (cancer stage);mild cognitive disorder;muscle rigidity;patients;population parameter;sensitivity and specificity;serial vector format;silo (dataset);smoothing (statistical technique);stationary process;statistical classification;support vector machine;synapomorphy;velocity;registration - actclass;triangulation	Zhuo Sun;Martijn van de Giessen;Boudewijn P. F. Lelieveldt;Marius Staring	2017		10.3389/fninf.2017.00016	psychology;computer vision;parallel transport;artificial intelligence;magnetic resonance imaging;machine learning	ML	31.05673450564814	-79.38024608145362	62407
5c4bdacddb1983e9fc7aa5ba8ae8f552c613e86b	breast cancer detection using transfer learning in convolutional neural networks		In the U.S., breast cancer is diagnosed in about 12 % of women during their lifetime and it is the second leading reason for women's death. Since early diagnosis could improve treatment outcomes and longer survival times for breast cancer patients, it is significant to develop breast cancer detection techniques. The Convolutional Neural Network (CNN) can extract features from images automatically and then perform classification. To train the CNN from scratch, however, requires a large number of labeled images, which is infeasible for some kinds of medical image data such as mammographic tumor images. A promising solution is to apply transfer learning in CNN. In this paper, we firstly tested three training methods on the MIAS database: 1) trained a CNN from scratch, 2) applied the pre-trained VGG-16 model to extract features from input mammograms and used these features to train a Neural Network (NN)-classifier, 3) updated the weights in several final layers of the pre-trained VGG-16 model by back-propagation (fine-tuning) to detect abnormal regions. We found that method 2) is ideal for study because the classification accuracy of fine-tuning model was just 0.008 higher than that of feature extraction model but time cost of feature extraction model was only about 5% of that of the fine-tuning model. Then, we used method 2) to classify regions: benign vs. normal, malignant vs. normal and abnormal vs. normal from the DDSM database with 10-fold cross validation. The average validation accuracy converged at about 0.905 for abnormal vs. normal cases, and there was no obvious overfitting. This study shows that applying transfer learning in CNN can detect breast cancer from mammograms, and training a NN-classifier by feature extraction is a faster method in transfer learning.	artificial neural network;backpropagation;breast cancer detection research;cessation of life;classification;convolutional neural network;early diagnosis;feature extraction;mammary neoplasms;mammography;medical image;neural networks;overfitting;patients;scratch (programming language);software propagation;tracer;weight;anatomical layer;triangulation	Shuyue Guan;Murray H. Loew	2017	2017 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)	10.1109/AIPR.2017.8457948	transfer of learning;convolutional neural network;overfitting;cross-validation;feature extraction;deep learning;computer-aided diagnosis;artificial neural network;computer science;pattern recognition;artificial intelligence	ML	32.629487477591084	-75.67421696774272	62411
8ff67b8bb53883f2e1c30990bdf44ec2d8b502b9	word spotting and recognition with embedded attributes	word spotting;attribute based representation;histograms;image recognition;natural images word spotting embedded attributes word recognition query word word image dictionary lexicon text strings vectorial subspace label embedding attributes learning common subspace regression cast recognition retrieval tasks nearest neighbor problem public datasets handwritten documents;training;text analysis document image processing handwritten character recognition query processing;image recognition hidden markov models text recognition histograms character recognition handwriting recognition nearest neighbor searches;hidden markov models;word recognition;text recognition;word image representation;character recognition;handwritten text;scene text	This paper addresses the problems of word spotting and word recognition on images. In word spotting, the goal is to find all instances of a query word in a dataset of images. In recognition, the goal is to recognize the content of the word image, usually aided by a dictionary or lexicon. We describe an approach in which both word images and text strings are embedded in a common vectorial subspace. This is achieved by a combination of label embedding and attributes learning, and a common subspace regression. In this subspace, images and strings that represent the same word are close together, allowing one to cast recognition and retrieval tasks as a nearest neighbor problem. Contrary to most other existing methods, our representation has a fixed length, is low dimensional, and is very fast to compute and, especially, to compare. We test our approach on four public datasets of both handwritten documents and natural images showing results comparable or better than the state-of-the-art on spotting and recognition tasks.	addresses (publication format);consistency model;dictionary [publication type];embedding;fifty nine;histogram;identity management;image;lambda lifting;large;lexicon;metrorrhagia;nearest neighbor search;personality character;query by example;question (inquiry);silo (dataset);single linkage cluster analysis;string (computer science);transcription (software);transcription, genetic;unified framework;cell transformation;research grants	Jon Almazán;Albert Gordo;Alicia Fornés;Ernest Valveny	2014	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2014.2339814	natural language processing;computer vision;speech recognition;document processing;feature;word recognition;intelligent character recognition;word error rate;computer science;intelligent word recognition;pattern recognition;histogram;hidden markov model;statistics	Vision	28.693351692136293	-67.0398750778418	62481
70f239238cef04754d2e2b08737826dd94799e7d	document image analysis for a major indic script bangla - advancement and scope		Bangla is one of the most popular script from eastern part of India with a demographic distribution of 212 million of population, used in languages like Bengali, Assamese, Manipuri etc. There are several works reported in literature considering Bangla script in the areas of Bangla OCR, postal automation, writer verification, online document analysis, script identification etc. They need more attention from the researchers as almost all of the mentioned topics are yet far from getting maturity. In this paper, a study on the advancement of those techniques with emphasis on Bangla script is presented. Also, some future directions in this field will be discussed.	image analysis	Kaushik Roy	2016		10.1007/978-981-10-4859-3_12	natural language processing;speech recognition;computer science;engineering drawing	AI	30.654297173495014	-67.88828776847072	62536
6286463c41ac8e19cbaacf2629085618e6eceec9	identification of products on shop-racks by morphological preprocessing and feature-based detection		In this paper we describe the method allowing the identification of products on the shop-racks. This method consists of two steps: morphological preprocessing where the image of the rack is segmented in order to find the split-lines between products; and recognition step where, based on the segmentation results, the feature-point approach is used to identify the products. In the proposed method, thanks to novel preprocessing step, we reduce the search-space to possible locations obtained as results of segmentation.	preprocessor	Marcin Iwanowski;Bartlomiej Zielinski;Grzegorz Sarwas;Sebastian Stygar	2014		10.1007/978-3-319-11331-9_35	computer vision;computer science;convex hull;artificial intelligence;preprocessor;pattern recognition;segmentation	NLP	35.371935350271144	-66.21622752110886	63110
a35fb1b16264161a5ae167f3d340c287999f1ea0	a multistage approach to improve performance of computer-aided detection of pulmonary embolisms depicted on ct images: preliminary investigation	free response receiver operating characteristic;aide diagnostic;faux positif;traitement signal;concepcion asistida;receiver;evaluation performance;computer aided design;diseno circuito;fusion methods;methode section divisee;cad scheme;pathologie de l appareil circulatoire;respiratory disease;image segmentation;algorithms artificial intelligence humans pulmonary embolism roc curve radiographic image interpretation computer assisted radiography thoracic tomography x ray computed;performance evaluation;computed tomography;vaso sanguineo patologia;circuito multipiso;genie biomedical;lung disease;evaluacion prestacion;lungs;coronary arteriosclerosis;false positive fp reduction;circuit design;receptor;tomographie numerique;aparato respiratorio patologia;free response receiver operating characteristics froc analysis;indexing terms;algoritmo genetico;2d detected features;falso positivo;lung;tobogganing region;multistage circuit;computer vision;scoring methods;pathologie des vaisseaux sanguins;pul monary embolism;aparato circulatorio patologia;tobogganing computer aided detection cad false positive fp reduction feature selection free response receiver operating characteristics froc analysis genetic algorithm ga pulmonary embolism;artificial neural networks;biomedical engineering;lesions;computed tomography lesions coronary arteriosclerosis lungs artificial neural networks genetic algorithms diseases feature extraction object detection computer vision;cardiovascular disease;lung diseases;feature extraction;medical image processing;signal processing;multifeature based k nearest neighbor;pathologie de l appareil respiratoire;recepteur;vascular disease;computerised tomography;computer aided detection cad;embolie pulmonaire;algorithme genetique;conception assistee;artificial neural net work;diseases;computer aided detection;algorithme evolutionniste;genetic algorithm;k nearest neighbor;genetic algorithms;feature selection;ingenieria biomedica;algoritmo evolucionista	This study developed a computer-aided detection (CAD) scheme for pulmonary embolism (PE) detection and investigated several approaches to improve CAD performance. In the study, 20 computed tomography examinations with various lung diseases were selected, which include 44 verified PE lesions. The proposed CAD scheme consists of five basic steps: 1) lung segmentation; 2) PE candidate extraction using an intensity mask and tobogganing region growing; 3) PE candidate feature extraction; 4) false-positive (FP) reduction using an artificial neural network (ANN); and 5) a multifeature-based k-nearest neighbor for positive/negative classification. In this study, we also investigated the following additional methods to improve CAD performance: 1) grouping 2-D detected features into a single 3-D object; 2) selecting features with a genetic algorithm (GA); and 3) limiting the number of allowed suspicious lesions to be cued in one examination. The results showed that 1) CAD scheme using tobogganing, an ANN, and grouping method achieved the maximum detection sensitivity of 79.2%; 2) the maximum scoring method achieved the superior performance over other scoring fusion methods; 3) GA was able to delete “redundant” features and further improve CAD performance; and 4) limiting the maximum number of cued lesions in an examination reduced FP rate by 5.3 times. Combining these approaches, CAD scheme achieved 63.2% detection sensitivity with 18.4 FP lesions per examination. The study suggested that performance of CAD schemes for PE detection depends on many factors that include 1) optimizing the 2-D region grouping and scoring methods; 2) selecting the optimal feature set; and 3) limiting the number of allowed cueing lesions per examination.	artificial neural network;ct scan;computer-aided design;feature extraction;gallium;genetic algorithm;k-nearest neighbors algorithm;lung diseases;multistage amplifier;pulmonary embolism;pulmonary valve insufficiency;region growing;score;sensitivity and specificity;sensor;single linkage cluster analysis;software release life cycle;structure of parenchyma of lung;x-ray computed tomography;xslt/muenchian grouping	Sang-Cheol Park;Brian E. Chapman;Bin Zheng	2011	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2010.2063702	computer vision;genetic algorithm;pathology;computer science;engineering;artificial intelligence;machine learning;artificial neural network	Robotics	36.57711164223663	-74.7452535515167	63167
95321c7aba4f0ad07e45bfc2195b563ff506829d	medical images analysis in cancer diagnostic		Neural networks have been known for a long time as a tool for different types of classification, but only just in the last decade they have showed their entire power. Along with appearing of hardware that is capable to support demanding matrix operations and parallel algorithms, the neural network, as a universal function approximation framework, turns out to be the most successful classification method widely used in all fields of science. On the other side, multifractal (MF) approach is an efficient way for quantitative description of complex structures [1] such as metastatic carcinoma, which recommends this method as an accurate tool for medical diagnostics. The only part that is missing is classification method. The goal of this research is to describe and apply a feed-forward neural network as an auxiliary diagnostic method for classification of multifractal parameters in order to determine primary cancer.	multifractal system	Jelena Vasiljevic;Ivica Milosavljević;Vladimir Krstic;Natasa Zivic;Lazar Berbakov;Heng-Bo Jiang;Dhinaharan Nagamalai;Milutin Cerovic	2018	CoRR	10.5121/csit.2018.80107	function approximation;artificial neural network;multifractal system;matrix multiplication;parallel algorithm;machine learning;computer science;artificial intelligence	ML	29.001600412823837	-76.60933835977241	63372
1d374b10fad6d4debc262dd3541cc9257a188ad0	automated captcha solving: an empirical comparison of selected techniques	completely automated public turing test to tell computers and humans apart automated captcha solving multimedia content computer security text based captcha schemes classification vector space model optical character recognition engine ocr engine vsm theory vector space image recognizer vsir;image recognition;vsm;vectors image classification multimedia systems optical character recognition;ocr;captcha;ocr captcha image recognition semantic context extraction vsm;semantic context extraction;captchas optical character recognition software engines computers image segmentation noise accuracy	CAPTCHAs exploit the gap in the ability between a human and a machine to understand the semantics of specific multimedia content, with vast applications in computer security. In this paper we compare two techniques in automated CAPTCHA solving for text-based CAPTCHA schemes, i.e., Classification based on the Vector Space Model (VSM) versus a popular Optical Character Recognition (OCR) engine. For each technique, we build a CAPTCHA solver and give it specific sets of text-based challenges to break. From our results we draw conclusions whether it is efficient to create a CAPTCHA solver by applying parts of the VSM theory and implementing a Vector Space Image Recognizer (VSIR).	captcha;computer security;finite-state machine;optical character recognition;solver;text-based (computing);viable system model	Michalis Korakakis;Emmanouil Magkos;Phivos Mylonas	2014	2014 9th International Workshop on Semantic and Social Media Adaptation and Personalization	10.1109/SMAP.2014.29	computer vision;speech recognition;computer science;world wide web	Security	31.40876881735676	-67.07554983673315	63446
2ce697940b2d78cfd1bba6ddfbf2e7fa44d0cebc	a temporal constraint satisfaction technique for nonlinear planning	image segmentation;multi modal;regions;artificial neural networks;temporal constraints;unsupervised competitive learning;2d 3d medical imaging		constraint satisfaction	Chung-Ming Cheng;Cheng-Seen Ho	1995			computer vision;computer science;machine learning;multimodal interaction;pattern recognition;image segmentation;artificial neural network	AI	33.43149313276729	-70.13242844653581	63456
cb2db05af72d0d60d1a09534b458d3426dad0aef	regression and classification based distance metric learning for medical image retrieval	medical image retrieval;classification image retrieval distance metric regression sparsity;distance metric learning;clinical pet ct images regression based distance metric learning classification based distance metric learning medical image retrieval medical imaging databases reference dataset diagnosis learning based distance metric design weight learning approach similar dissimilar data samples optimization sparsity constraint regression algorithm feature selection;measurement;lungs;training;medical image databases;image classification;biomedical imaging;measurement training vectors image retrieval biomedical imaging optimization lungs;classification;positron emission tomography;visual databases computerised tomography feature extraction image classification image retrieval learning artificial intelligence medical image processing positron emission tomography regression analysis;performance improvement;regression;sparsity;vectors;feature extraction;medical image processing;classification image;computerised tomography;distance metric;feature selection;regression analysis;optimization;learning artificial intelligence;visual databases;image retrieval	Better utilizing the vast amount of valuable information stored in the medical imaging databases is always an interesting research area, and one way is to retrieve similar images as a reference dataset to assist the diagnosis. Distance metric is a core component in image retrieval; and in this paper, we propose a new learning-based distance metric design, based on regression and classification techniques. We design a weight learning approach by classifying the similar-dissimilar data samples, and a further optimization with a sparsity-constraint regression algorithm for feature selection. The learned distance metric is generally applicable for medical image retrievals. We evaluate the proposed method on clinical PET-CT images, and demonstrate clear performance improvements.	algorithm;ct scan;database;feature selection;image retrieval;mathematical optimization;medical imaging;polyethylene terephthalate;sparse matrix	Tom Weidong Cai;Yang Song;David Dagan Feng	2012	2012 9th IEEE International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2012.6235925	computer vision;contextual image classification;regression;metric;feature extraction;biological classification;image retrieval;computer science;machine learning;pattern recognition;mathematics;sparsity-of-effects principle;feature selection;regression analysis;measurement	Vision	27.334389657353476	-77.62924510030611	63727
04b304c48f984995553e3e26ec55b51de24eeb23	triagem virtual de imagens de imuno-histoquímica usando redes neurais artificiais e espectro de padrões		The importance of organizing medical images according to their nature, application and relevance is increasing. Furhermore, a previous selection of medical images can be useful to accelerate the task of analysis by pathologists. Herein this work we propose an image classifier to integrate a CBIR (Content-Based Image Retrieval) selection system. This classifier is based on pattern spectra and neural networks. Feature selection is performed using pattern spectra and principal component analysis, whilst image classification is based on multilayer perceptrons and a composition of self-organizing maps and learning vector quantization. These methods were applied for content selection of immunohistochemical images of placenta and newdeads lungs. Results demonstrated that this approach can reach reasonable classification performance.	artificial neural network;computer vision;content-based image retrieval;feature selection;learning vector quantization;map;medical imaging;multilayer perceptron;organizing (structure);principal component analysis;relevance;self-organization;while	Higor Neto Lima;Wellington Pinheiro dos Santos;Mêuser Jorge Silva Valença	2017	CoRR		artificial neural network;pattern recognition;artificial intelligence;machine learning;perceptron;learning vector quantization;image retrieval;computer science;principal component analysis;contextual image classification;feature selection;classifier (linguistics)	Vision	33.62401293782595	-73.3245229024007	63771
0553568f43bbbdd6e8e13f561801144a1f62f2ec	an automatic segmentation approach of epithelial cells nuclei		Histology images are used to identify biological structures present in living organisms — cells, tissues, organs, and parts of organs. E-Learning systems can use images to aid teaching how morphological features relate to function and understanding which features are most diagnostic of organs. The structure of cells varies according to the type and function of the cell. Automatic cell segmentation is one of the challenging tasks in histology image processing. This problem has been addressed using morphological gradient, region-based methods and shape-based method approaches, among others. In this paper, automatic segmentation of nuclei of epithelial cells is addressed by including morphological information. Image segmentation is commonly evaluated in isolation. This is either done by observing results, via manual segmentation or via some other goodness measure that does not rely on ground truth images. Expert criteria along with images manually segmented are used to validate automatic segmentation results. Experimental results show that the proposed approach segments epithelial cells in a close way to expert manual segmentations. An average sensitivity of 76% and an average specificity of 77% were obtained on a selected set of images.		Claudia Mazo;María P. Trujillo;Liliana Salazar	2012		10.1007/978-3-642-33275-3_70	pattern recognition;computer vision;structure tensor;artificial intelligence;image processing;ground truth;image segmentation;morphological gradient;computer science;segmentation	NLP	36.1064272751143	-76.53551066853282	63852
de60df51272ad2d4fda1c2b739171023a045b4dc	quantitative detection of cirrhosis: towards the development of computer-assisted detection method	liver cirrhosis;sensitivity and specificity;radiology;liver;computed tomography;computer aided diagnosis;quantification;area under curve;image interpretation computer assisted;observer variation;reproducibility of results;roc curve;humans;cirrhosis;computer assisted image interpretation;tomography x ray computed	There are distinct morphologic features of cirrhosis on CT examinations; however, such impressions may be subtle or subjective. The purpose of this study is to build a computer-aided diagnosis (CAD) method to help radiologists with this diagnosis. One hundred sixty-seven abdominal CT examinations were randomly divided into training (n = 88) and validation (n = 79) sets. Livers were analyzed for morphological markers of cirrhosis and logistic regression models were created. Using the area under curve (AUC) for model performance, the best model had 0.89 for the training set and 0.85 for the validation set. For radiology reports, sensitivity of reporting cirrhosis was 0.45 and specificity 0.99. Using the predictive model adjunctively, radiologists’ sensitivity increased to 0.63 and specificity slightly decreased to 0.97. This study demonstrates that quantifying morphological features in livers may be utilized for diagnosing cirrhosis and for developing a CAD method for it.	area under curve;ct scan;computer assisted diagnosis;computer-aided design;fibrosis;liver cirrhosis;logistic regression;predictive modelling;radiology;randomness;sensitivity and specificity;seventy nine;test set;impression (attitude)	Hannu Huhdanpaa;Peng Zhang;Venkataramu N. Krishnamurthy;Chris Douville;Binu Enchakolody;Chris Chou;Sampathkumar Ethiraj;Stewart C. Wang;Grace L. Su	2014	Journal of Digital Imaging	10.1007/s10278-014-9696-x	integral;radiology;medicine;pathology;computed tomography;receiver operating characteristic	EDA	34.40987888074387	-78.3813634615	63886
681c90413523ee57ef4b25b7a3107d858a4da8b5	associative memory for early detection of breast cancer	criblage;memoire associative;seuil;screening;mammary gland;threshold;selection automatique;glandula mamaria;prototipo;seleccion automatica;breast cancer screening;depistage;descubrimiento;associative memory;cernido;memoria asociativa;glande mammaire;medical screening;umbral;reseau neuronal;prototype;early detection;breast cancer;red neuronal;automatic selection;neural network	We present a new associative neural network design espe- cially indicated for the early detection of malignant lesions in breast cancer screening. It is a BAM in which we have made some changes to the functioning of its neurons, and for which we have developed an automatic selection algorithm for the prototypes used to calculate the thresholds of the neurons conforming the input layer. The result is a structure that, while considerably reduced, is highly effective in identifying the images that indicate the presence of malignant tumours in screening for breast cancer. We endowed the network with a special pre-processing stage for the treatment of this kind of radiographic image. This pre-processing yields a more detailed analysis of possible signs of tumours.		Francisco Javier López Aligué;Isabel Acevedo;Carlos J. García Orellana;Miguel Macías Macías;Horacio M. González Velasco	2003		10.1007/978-3-540-44871-6_51	computer science;artificial intelligence;breast cancer;prototype;artificial neural network	Logic	33.94164341978724	-76.8985405658832	64078
4061198377029d7b211ec568692951b645b84810	textural approach for mass abnormality segmentation in mammographic images		Mass abnormality segmentation is a vital step for the medical diagnostic process and is attracting more and more the interest of many research groups. Currently, most of the works achieved in this area have used the Gray Level Co-occurrence Matrix (GLCM) as texture features with a region-based approach. These features come in previous phase for segmentation stage or are using as inputs to classification stage. The work discussed in this paper attempts to experiment the GLCM method under a contour-based approach. Besides, we experiment the proposed approach on various tissues densities to bring more significant results. At this end, we explored some challenging breast images from BIRADS medical Data Base. Our first experimentations showed promising results with regard to the edges mass segmentation methods. This paper discusses first the main works achieved in this area. Sections 2 and 3 present materials and our methodology. The main results are showed and evaluated before concluding our paper.	bi-rads;co-occurrence matrix	Khamsa Djaroudib;Abdelmalik Taleb-Ahmed;Abdelmadjid Zidani	2013	CoRR		computer vision;scale-space segmentation	Vision	33.746276620116014	-75.0516584962065	64413
d45197ba81871c061a887509c219e2b3c9c96556	a comparison of various mri feature types for characterizing whole brain anatomical differences using linear pattern recognition methods	diffeomorphism;gaussian process;model selection;pattern recognition;scalar momentum;structural mri;vbm	There is a widespread interest in applying pattern recognition methods to anatomical neuroimaging data, but so far, there has been relatively little investigation into how best to derive image features in order to make the most accurate predictions. In this work, a Gaussian Process machine learning approach was used for predicting age, gender and body mass index (BMI) of subjects in the IXI dataset, as well as age, gender and diagnostic status using the ABIDE and COBRE datasets. MRI data were segmented and aligned using SPM12, and a variety of feature representations were derived from this preprocessing. We compared classification and regression accuracy using the different sorts of features, and with various degrees of spatial smoothing. Results suggested that feature sets that did not ignore the implicit background tissue class, tended to result in better overall performance, whereas some of the most commonly used feature sets performed relatively poorly.	alignment;body mass index;brain–computer interface;gaussian process;human body weight;lewy body disease;machine learning;neuroimaging;normal statistical distribution;pattern recognition;preprocessor;silo (dataset);smoothing (statistical technique)	Gemma C. Monté-Rubio;Carles Falcón;Edith Pomarol-Clotet;John Ashburner	2018		10.1016/j.neuroimage.2018.05.065	feature (computer vision);smoothing;model selection;psychology;gaussian process;pattern recognition;artificial intelligence	ML	30.91619839718239	-79.46861439130458	64606
40be6e89c52dc1972e10bbb04e69b013114e3f38	automated tracking, segmentation and trajectory classification of pelvic organs on dynamic mri	atmospheric measurements;hidden markov models;trajectory;bladder;magnetic resonance imaging;tracking	Pelvic organ prolapse is a major health problem in women where pelvic floor organs (bladder, uterus, small bowel, and rectum) fall from their normal position and bulge into the vagina. Dynamic Magnetic Resonance Imaging (DMRI) is presently used to analyze the organs' movements from rest to maximum strain providing complementary support for diagnosis. However, there is currently no automated or quantitative approach to measure the movement of the pelvic organs and their correlation with the severity of prolapse. In this paper, a two-stage method is presented to automatically track and segment pelvic organs on DMRI followed by a multiple-object trajectory classification method to improve the diagnosis of pelvic organ prolapse. Organs are first tracked using particle filters and K-means clustering with prior information. Then, they are segmented using the convex hull of the cluster of particles. Finally, the trajectories of the pelvic organs are modeled using a new Coupled Switched Hidden Markov Model (CSHMM) to classify the severity of pelvic organ prolapse. The tracking and segmentation results are validated using Dice Similarity Index (DSI) whereas the classification results are compared with two manual clinical measurements. Results demonstrate that the presented method is able to automatically track and segment pelvic organs with a DSI above 82% for 26 out of 46 cases and DSI above 75% for all 46 tested cases. The accuracy of the trajectory classification model is also better than current manual measurements.	bladder tissue;cluster analysis;computation;convex hull;diffusion spectrum imaging;earth bulge;hidden markov model;intestines;intestines, small;k-means clustering;magnetic resonance imaging;markov chain;movement;multiple organ failure;particle filter;pedal keyboard;pelvic diaphragm;pelvic inflammatory disease;pelvic organ prolapse;pelvic viscus;ptosis;rectum;segmentation action;small intestinal wall tissue;urinary bladder;biologic segmentation;statistical cluster	Iman Nekooeimehr;Susana K. Lai-Yuen;Paul Bao;Alfredo Weitzenfeld;Stuart Hart	2016	2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2016.7591214	radiology;pathology;computer science;engineering;trajectory;magnetic resonance imaging;tracking;physics;anatomy;quantum mechanics;surgery	Vision	38.467331916609695	-79.2358201487968	64668
c1b1560921c1a335aa2a0a0b7baa91e57057210e	automated pavement distress detection using advanced image processing techniques	advanced image processing techniques;image segmentation;image resolution;search algorithm;automated pavement distress detection;image classification;data mining;image processing wavelet transforms inspection image segmentation filtering sun remuneration civil engineering robustness statistics;wavelet transforms;break points extraction;feature extraction;pixel;crack classification;image processing methods;break points connection;image processing techniques;road building;road building feature extraction image classification image resolution object detection;crack identification automated pavement distress detection advanced image processing techniques break points connection break points extraction crack classification crack pixels;crack identification;algorithm design and analysis;crack pixels;object detection;noise	In this paper, a novel, fast and self-adaptive image processing method is proposed for the extraction and connection of break points of cracks in pavement images. The algorithm first finds the initial point of a crack and then determines the crack's classification into transverse, longitudinal and alligator types. Different search algorithms are used for different types of cracks. Then the algorithm traces along the crack pixels to find the break point and then connect the identified crack point to the nearest break point in the particular search area. The nearest point then becomes the new initial point and the algorithm continues the process until reaching the end of the crack. The experimental results show that this connection algorithm is very effective in maximizing the accuracy of crack identification.	distress (novel);image processing;pixel;search algorithm;tracing (software);transverse wave	Y. Sun;Ezzatollah Salari;Eddie Y. Chou	2009	2009 IEEE International Conference on Electro/Information Technology	10.1109/EIT.2009.5189645	algorithm design;computer vision;contextual image classification;simulation;speech recognition;image resolution;feature extraction;computer science;engineering;noise;machine learning;image segmentation;pixel;wavelet transform;search algorithm	Robotics	38.882147210561875	-68.4126221852703	64674
0b6d02329947f39696874c569ac13cafa2565823	fractal analysis for computer-aided diagnosis of diffuse pulmonary diseases in hrct images	support vector machine classification lungs diseases feature extraction computed tomography energy measurement fractals;hrct image classification rates computer aided diagnosis diffuse pulmonary disease diagnosis high resolution computed tomography images region of interest preprocessing radiographic pattern representation first order statistics gray level distribution haralick texture feature extraction laws texture feature extraction roi discrete fourier transforms fractal dimension values k nearest neighbor classifier;statistical distributions biodiffusion computerised tomography discrete fourier transforms diseases feature extraction fractals image classification image resolution image texture lung medical image processing;diffuse pulmonary diseases fractal analysis texture analysis computer aided diagnosis high resolution computed tomography	The purpose of this article is to propose the use of fractal and texture analysis for computer-aided diagnosis (CAD) of diffuse pulmonary diseases (DPDs) in high-resolution computed tomography (HRCT) images. We propose multiple techniques to extract features from preprocessed regions of interest (ROIs) selected to represent five radiographic patterns useful in the differential diagnosis of DPDs, as well as normal cases. First-order statistics of gray-level distribution, Haralick's and Laws' texture features, statistical information extracted from the ROIs' discrete Fourier transforms, and their fractal dimension values were used as attributes. The features were used as inputs for a k-nearest neighbor classifier (k=5). With a dataset of 3252 ROIs, correct classification rates of up to 82.62% were achieved.	ct scan;computer-aided design;first-order predicate;fractal analysis;fractal dimension;high-resolution computed tomography;image resolution;k-nearest neighbors algorithm;nearest neighbour algorithm;radiography;region of interest;robert haralick	Lucas Calabrez Pereyra;Rangaraj M. Rangayyan;Marcelo Ponciano-Silva;Paulo Mazzoncini de Azevedo Marques	2014	2014 IEEE International Symposium on Medical Measurements and Applications (MeMeA)	10.1109/MeMeA.2014.6860105	computer vision;pattern recognition;mathematics;computer graphics (images)	Vision	36.81749851568292	-74.49745919778474	64846
2a0ba8d853f0357d16b0abe8d524f2c72e593d86	sigma - a malaysian signatures’ database	online signature collection;visual databases handwriting recognition;genuine signature sample sigma malaysian signature database static signature feature database forgery skilled forgery signature verification system;handwriting recognition;sigma malaysian signature database;static signature feature;database forgery;genuine signature sample;forged signature sample;skilled forgery;skilled forgery offline signature collection online signature collection genuine signature sample forged signature sample;forgery image databases handwriting recognition ink information technology spatial databases signal resolution gray scale educational institutions design optimization;offline signature collection;visual databases;signature verification system	This poster presents a database of Malaysian signatures named SIGMA describing the strategies adopted in compiling it and its technical details. The database consists of over 6,000 genuine signature samples and over 2,000 forged signature samples of Malaysian nationals. The signature samples are collected simultaneously in both online and offline mode thereby eliminating the variation which is inevitable if the two modes are done at different times. This is particularly appealing to studies which are aimed at exploring the co-relationships between static signature features and their dynamic counterparts (that are derived from offline and online signature samples respectively). Furthermore, all forgeries in the database are 'skilledforgeries'. The collection of only Malaysian signatures makes the database very useful for designing a signature verification system that is optimized to verify Malaysian signatures.	airplane mode;antivirus software;compiler;digital signature;online and offline	Sharifah Mumtazah Syed Ahmad;Asma Shakil;Abdul Rahim Ahmad;Mustafa Agil Muhamad Balbed;Rina Bt. Md. Anwar	2008	2008 IEEE/ACS International Conference on Computer Systems and Applications	10.1109/AICCSA.2008.4493644	computer science;machine learning;data mining;handwriting recognition;internet privacy;world wide web;signature recognition	Vision	29.426709370147307	-67.60421174662591	64958
56ceb178918e09502d850b5a4a6eec0a1553a86e	skin disease recognition using deep saliency features and multimodal learning of dermoscopy and clinical images		Skin cancer is the most common cancer world-wide, among which Melanoma the most fatal cancer, accounts for more than 10,000 deaths annually in Australia and United States. The 5-year survival rate for Melanoma can be increased over 90% if detected in its early stage. However, intrinsic visual similarity across various skin conditions makes the diagnosis challenging both for clinicians and automated classification methods. Many automated skin cancer diagnostic systems have been proposed in literature, all of which consider solely dermoscopy images in their analysis. In reality, however, clinicians consider two modalities of imaging; an initial screening using clinical photography images to capture a macro view of the mole, followed by dermoscopy imaging which visualizes morphological structures within the skin lesion. Evidences show that these two modalities provide complementary visual features that can empower the decision making process. In this work, we propose a novel deep convolutional neural network (DCNN) architecture along with a saliency feature descriptor to capture discriminative features of the two modalities for skin lesions classification. The proposed DCNN accepts a pair images of clinical and dermoscopic view of a single lesion and is capable of learning single-modality and cross-modality representations, simultaneously. Using one of the largest collected skin lesion datasets, we demonstrate that the proposed multi-modality method significantly outperforms single-modality methods on three tasks; differentiation between 15 various skin diseases, distinguishing cancerous (3 cancer types including melanoma) from non-cancerous moles, and detecting melanoma from benign cases.	multimodal learning	Zongyuan Ge;Sergey Demyanov;Rajib Chakravorty;Adrian Bowling;Rahil Garnavi	2017		10.1007/978-3-319-66179-7_29	convolutional neural network;artificial intelligence;computer science;pattern recognition;modalities;discriminative model;cancer;computer vision;salience (neuroscience);skin cancer;multimodal learning;melanoma	Vision	32.29274236299968	-75.65373535858478	64962
ace3a819feaf6bad98b702d3140c3ee92f67582b	a transfer-learning approach for accelerated mri using deep neural networks.		Neural network based architectures have recently been proposed for reconstruction of undersampled MR acquisitions. A deep network containing many free parameters is typically trained using a relatively large set of fully-sampled MRI data, and later used for on-line reconstruction of undersampled data. Ideally network performance should be optimized by drawing the training and testing data from the same domain. In practice, however, large datasets comprising hundreds of subjects scanned under a common protocol are rare. Here, we propose a transfer-learning approach to address the problem of data scarcity in training deep networks for accelerated MRI. The proposed approach trains neural networks using thousands of samples from a public dataset of natural images (ImageNet). The network is then fine-tuned using only few tens of MR images acquired in the testing domain (T1or T2weighted MRI). The ImageNet-trained network yields nearly identical reconstructions to networks trained directly in the testing domain using thousands of MR images, and it outperforms conventional compressed sensing reconstructions in terms of image quality. The proposed approach might facilitate the use of neural networks for MRI reconstruction without the need for collection of extensive imaging datasets.	artificial neural network;compiler;compressed sensing;deep learning;image quality;imagenet;network performance;neural network software;online and offline	Salman Ul Hassan Dar;Tolga Çukur	2017	CoRR		transfer of learning;compressed sensing;machine learning;artificial intelligence;artificial neural network;computer science;image quality;test data;network performance	ML	29.821910863889002	-74.73069030098974	65118
59c9f598605b42c83cc37e452294f012b3cb628f	a fuzzy rule-based system for handwritten chinese characters recognition based on radical extraction	fuzzy rule based system;handwriting recognition;theorie ensemble flou;fuzzy rules;rule based system;sistema informatico;image database;computer system;chino;juego caracter;fuzzy set theory;handwritten chinese character recognition;character set;reconnaissance ecriture;reconnaissance caractere;jeu caractere;pattern recognition;radical extraction;systeme informatique;reconnaissance forme;reconocimiento patron;chinois;chinese;character recognition;fuzzy system;reconocimiento caracter;preclassification	Abstract   In this paper, a fuzzy rule-based system for handwritten Chinese characters recognition (HCCR) based on radical extraction is proposed. Since the writings of handwritten Chinese characters vary a lot, we adopt fuzzy set theory to deal with the recognition of these fuzzy patterns. Candidates of strokes are provided with confidence values to obtain more reliable and accurate results. Furthermore, hierarchical fuzzy rule sets that represent the character structures are used to combine the extracted strokes into compound strokes or radicals. The flexible expansion ability thus provided is very promising. Also, since the number of rules in a fuzzy system is much less than that in a general rule-based system, the computation effort is not difficult. An average of 99.63% recognition rate of 542 test categories that are selected from the 100th sample set of HCCRBASE (character image database provided by CCL, ITRI, Taiwan) is obtained. The experimental results not only verify the feasibility of the proposed system, but also suggest that applying fuzzy set theory to HCCR is an efficient and promising approach.	fuzzy rule;rule-based system	Hahn-Ming Lee;Chiung-Wei Huang;Chung-Chieh Sheu	1998	Fuzzy Sets and Systems	10.1016/S0165-0114(97)00148-6	speech recognition;defuzzification;fuzzy classification;computer science;artificial intelligence;fuzzy number;machine learning;handwriting recognition;chinese;algorithm;fuzzy control system	AI	33.651102168895186	-67.66444331907688	65378
9b0a255291574fdfbb7021b72e948be09ddb98a3	machine learning techniques for prostate ultrasound image diagnosis	fuzzy set;decision tree;ultrasound;computational intelligence;discriminant analysis;ultrasound imaging;hybrid approach;machine learning;region of interest;ultra sound;fuzzy c means clustering;classification accuracy;rough set;neural network;prostate cancer	Estimation of prostate location and volume is essential in determin- ing a dose plan for ultrasound-guided brachytherapy, a common prostate cancer treatment. However, manual segmentation is difficult, time consuming and prone to variability. In this chapter, we present a machine learning scheme, employ- ing a combination of fuzzy sets, wavelets and rough sets, for analyzing pros- trate ultrasound images in order diagnose prostate cancer. To address the image noise problem we first utilize an algorithm based on type-II fuzzy sets to enhance the contrast of the ultrasound image. This is followed by performing a modified fuzzy c-mean clustering algorithm in order to detect the boundary of the prostate pattern. Then, a wavelet features are extracted and normalized, followed by ap- plication of a rough set analysis for discrimination of different regions of inter- est to determine whether they represent cancer or not. The experimental results obtained, show that the overall classification accuracy offered by the employed rough set approach is high compared with other machine learning techniques in- cluding decision trees, discriminant analysis, rough neural networks, and neural networks.	machine learning;radiology	Aboul Ella Hassanien;Hameed Al-Qaheri;Václav Snásel;James F. Peters	2010		10.1007/978-3-642-05177-7_19	computer science;artificial intelligence;machine learning;pattern recognition	Vision	35.053984946368374	-75.13249789126334	65485
390e54b4e8cd9f4c33d734cd1a31d6e6dbcafca8	scleroderma capillary pattern identification using texture descriptors and ensemble classification	biological tissues;image classification;image texture;patient diagnosis scleroderma capillary pattern identification texture descriptors ensemble classification connective tissue diseases blood capillaries finger nailfold disease diagnosis raynaud phenomenon nailfold capillaroscopy scleroderma pattern nailfold capillaroscopy images texture feature extraction;feature extraction;medical image processing;blood;diseases;medical image processing biological tissues blood diseases feature extraction image classification image texture;diseases feature extraction diversity reception connective tissue biomedical imaging standards accuracy	Various connective tissue diseases lead to morphological alternations of blood capillaries. Consequently, observation of the capillaries at the finger nailfold - nailfold capillaroscopy (NC) - is a standard method for diagnosing diseases such as scleroderma or Raynaud's phenomenon. This is typically performed through manual inspection by an expert to lead to a determination of one of the established NC scleroderma patterns (early, active, and late). In this paper, we present an automated method of analysing nailfold capillaroscopy images and categorising them into NC patterns. For this purpose, we extract a carefully chosen set of texture features from the images and employ an ensemble classification approach to arrive at decisions for each captured finger which are then aggregated to form a diagnosis for the patient. Experimental results on a set of 60 NC images from 16 subjects demonstrate the accuracy and usefulness of our presented approach.	blood capillaries;classification;connective tissue diseases;decision making;ensemble learning;finger tree;large;logical connective;microscopic angioscopy;nailfold capillaroscopy;patients;raynaud phenomenon;silo (dataset);systemic scleroderma	Gerald Schaefer;Bartosz Krawczyk;Niraj P. Doshi;Arcangelo Merla	2013	2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2013.6610788	image texture;computer vision;contextual image classification;medicine;pathology;feature extraction;computer science;biological engineering	Vision	35.97362412170817	-77.92746368034065	65556
b8c7982659f3eba7396075fd6e9860709a12f955	computerized detection of lung nodules by means of “virtual dual-energy” radiography	support vector machines bone cad computerised tomography diagnostic radiography feature extraction filtering theory image classification medical image processing neural nets sensitivity statistical analysis;radiography thoracic;statistical analysis computerized detection lung nodules virtual dual energy radiography computer aided detection cad chest radiographs ribs frequent false positives sensitivity massive training artificial neural networks ann clavicle opacities soft tissue opacity morphologic filtering technique gray level based feature extraction nonlinear support vector classifier image classification computed tomography examinations;support vector machines;neural nets;cad;image classification;lung;algorithms case control studies databases factual humans lung lung neoplasms radiographic image interpretation computer assisted radiography thoracic ribs;sensitivity;statistical analysis;lungs ribs feature extraction bones image segmentation training databases;feature extraction;medical image processing;case control studies;bone;computerised tomography;ribs;algorithms;humans;virtual dual energy vde chest radiography cxr computer aided diagnosis cad lung cancer rib suppression;databases factual;radiographic image interpretation computer assisted;lung neoplasms;filtering theory;diagnostic radiography	Major challenges in current computer-aided detection (CADe) schemes for nodule detection in chest radiographs (CXRs) are to detect nodules that overlap with ribs and/or clavicles and to reduce the frequent false positives (FPs) caused by ribs. Detection of such nodules by a CADe scheme is very important, because radiologists are likely to miss such subtle nodules. Our purpose in this study was to develop a CADe scheme with improved sensitivity and specificity by use of “virtual dual-energy” (VDE) CXRs where ribs and clavicles are suppressed with massive-training artificial neural networks (MTANNs). To reduce rib-induced FPs and detect nodules overlapping with ribs, we incorporated the VDE technology in our CADe scheme. The VDE technology suppressed rib and clavicle opacities in CXRs while maintaining soft-tissue opacity by use of the MTANN technique that had been trained with real dual-energy imaging. Our scheme detected nodule candidates on VDE images by use of a morphologic filtering technique. Sixty morphologic and gray-level-based features were extracted from each candidate from both original and VDE CXRs. A nonlinear support vector classifier was employed for classification of the nodule candidates. A publicly available database containing 140 nodules in 140 CXRs and 93 normal CXRs was used for testing our CADe scheme. All nodules were confirmed by computed tomography examinations, and the average size of the nodules was 17.8 mm. Thirty percent (42/140) of the nodules were rated “extremely subtle” or “very subtle” by a radiologist. The original scheme without VDE technology achieved a sensitivity of 78.6% (110/140) with 5 (1165/233) FPs per image. By use of the VDE technology, more nodules overlapping with ribs or clavicles were detected and the sensitivity was improved substantially to 85.0% (119/140) at the same FP rate in a leave-one-out cross-validation test, whereas the FP rate was reduced to 2.5 (583/233) per image at the same sensitivity level as the original CADe scheme obtained (Difference between the specificities of the original and the VDE-based CADe schemes was statistically significant). In particular, the sensitivity of our VDE-based CADe scheme for subtle nodules (66.7% = 28/42) was statistically significantly higher than that of the original CADe scheme (57.1% = 24/42). Therefore, by use of VDE technology, the sensitivity and specificity of our CADe scheme for detection of nodules, especially subtle nodules, in CXRs were improved substantially.	acceptance testing;artificial neural network;bone structure of clavicle;bone structure of rib;ct scan;cross reactions;cross-validation (statistics);dockable entertainment featuringgame boy advance;dual;dual-energy x-ray absorptiometry;extraction;nodule;nonlinear system;radiography;radiology;sdha wt allele;sensitivity and specificity;support vector machine;vma1 protein, s cerevisiae;virtual distributed ethernet;x-ray computed tomography;violaxanthin de-epoxidase activity	Sheng Chen;Kenji Suzuki	2013	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2012.2226583	support vector machine;contextual image classification;case-control study;radiology;pathology;sensitivity;feature extraction;computer science;engineering;machine learning;cad;nuclear medicine;rib cage;artificial neural network	Visualization	36.90046886031706	-77.2573515958628	65601
f7aa2e3112247a4d39e2f7273bbd5993fb97d92f	brain morphometric analysis on alzheimer's disease magnetic resonance images			morphometrics;resonance	B. S. Mahanand;M. Aswatha Kumar	2011			computer science;pattern recognition;artificial intelligence;magnetic resonance imaging	Vision	30.36980486967544	-79.11297174347142	65831
696959c01283232c68cee097c51eb86f181c6e3d	tissue type differentiation for brain glioma using non-negative matrix factorization	sista	The purpose of this paper is to introduce a hierarchical Non-negative Matrix Factorization (NMF) approach, customized for the problem of blindly separating brain glioma tumor tissue types using short-echo time proton magnetic resonance spectroscopic imaging (H MRSI) signals. The proposed algorithm consists of two levels of NMF, where two constituent spectra are computed in each level. The first level is able to correctly detect the spectral profile corresponding to the most predominant tissue type, i.e., normal tissue, while the second level is optimized in order to detect two ‘abnormal’ spectral profiles so that the 3 recovered spectral profiles are least correlated with each other. The two-level decomposition is followed by the reestimation of the overall spatial distribution of each tissue type via standard Non-negative Least Square (NNLS). This method is demonstrated on in vivo short-TE H MRSI brain data of a glioblastoma multiforme patient and a grade II-III glioma patient. The results show the possibility of differentiating normal tissue, tumor tissue and necrotic tissue in the form of recovered tissue-specific spectra with accurate spatial distributions.	algorithm;non-negative least squares;non-negative matrix factorization;resonance;test engineer;video-in video-out	Yuqian Li;Diana Maria Sima;Sofie Van Cauter;Uwe Himmelreich;Yiming Pi;Sabine Van Huffel	2012			computer science	Vision	26.81002844963707	-78.42890340037503	65972
747c10b67f94e224b8561f8f8033f076bb0674c8	context-sensitive model learning for lung nodule detection	computers;classification computer aided diagnosis cad chest radiograph lung cancer bone suppression;design automation;image segmentation;lungs;orthopaedics bone diagnostic radiography image classification image segmentation learning artificial intelligence lung medical image processing;solid modeling;benchmark set context sensitive model learning lung nodule detection chest radiography computer aided diagnosis cad supervised classification task nodule segments discriminative model lung tissue bone rib segmentation context sensitive way;diagnostic radiography;solid modeling lungs diagnostic radiography computers design automation image segmentation	Nodule detection in chest radiographs is a main component of current Computer Aided Diagnosis (CAD) systems. The problem is usually approached as a supervised classification task of candidate nodule segments. To this end, a discriminative model is learnt from predefined set of features. A key concern with this approach is the fact that some normal tissues are also imaged and these regions can overlap with the lung tissue as to hide the nodules. These overlaps may reduce the discriminative ability of extracted features and increase the number of false positives accordingly. In this study, we offer to learn distinct models for bone and normal tissue regions following to the segmentation of ribs, which are often the major reason for false positives. Thus, the nodule candidates in bone and normal tissue regions can be assessed in context-sensitive way. The experiments on a common benchmark set determine that the proposed approach can significantly rescue the false positives while preserving the sensitivity of detections.	benchmark (computing);computer-aided design;context-sensitive grammar;discriminative model;experiment;machine learning;radiography;sensor;supervised learning	B. Buket Ogul;Hasan Ogul;Emre Sümer	2016	2016 24th Signal Processing and Communication Application Conference (SIU)	10.1109/SIU.2016.7496041	computer vision;radiology;medicine;pathology	AI	33.095178671122305	-75.8656595972304	66034
cc15e87e9a6e5d2037867ca7a46cb4f100bd524b	automated polyp detection in colon capsule endoscopy	receiver operator characteristic roc curve capsule endoscopy colorectal cancer polyp detection;biological tissues video sequences image color analysis endoscopes classification algorithms kernel educational institutions	Colorectal polyps are important precursors to colon cancer, a major health problem. Colon capsule endoscopy is a safe and minimally invasive examination procedure, in which the images of the intestine are obtained via digital cameras on board of a small capsule ingested by a patient. The video sequence is then analyzed for the presence of polyps. We propose an algorithm that relieves the labor of a human operator analyzing the frames in the video sequence. The algorithm acts as a binary classifier, which labels the frame as either containing polyps or not, based on the geometrical analysis and the texture content of the frame.We assume that the polyps are characterized as protrusions that are mostly round in shape. Thus, a best fit ball radius is used as a decision parameter of the classifier. We present a statistical performance evaluation of our approach on a data set containing over 18 900 frames from the endoscopic video sequences of five adult patients. The algorithm achieves 47% sensitivity per frame and 81% sensitivity per polyp at a specificity level of 90%. On average, with a video sequence length of 3747 frames, only 367 false positive frames need to be inspected by an operator.	binary classification;colon carcinoma;colon classification;colorectal neoplasms;curve fitting;digital camera;frame (physical object);ingestion;intestinal wall tissue;patients;performance evaluation;physical examination;population parameter;sensitivity and specificity;algorithm;polyps	Alexander V. Mamonov;Isabel N. Figueiredo;Pedro N. Figueiredo;Yen-Hsi Richard Tsai	2014	IEEE Transactions on Medical Imaging	10.1109/TMI.2014.2314959	computer vision;medicine;pathology;computer science	Vision	37.01796888887091	-76.80007152025165	66348
6241789eb67b6c9cadb3230868646ccdadac1dfd	melanosome tracking by bayes theorem and estimation of movable region		This paper proposes a melanosome tracking method using Bayes theorem and estimation of movable region of melanosome candidates. Melanosomes in intracellular images are tracked manually now to investigate the cause of disease, and automatic tracking method is desired. Since there are little automatic recognition methods for intracellular images, we can not know which features and classifiers are effective for them. Thus, we try to develop the melanosome tracking using Bayes theorem of melanosome candidates detected by Scale-Invariant Feature Transform (SIFT). However, SIFT can not detect the center of melanosome because melanosome is too small in images. Therefore, SIFT detector is adopted after image size is enlarged by Lanczos resampling. However, there are still many melanosome candidates. Thus, we estimate the movable region of the target melanosome in next frame and eliminate melanosome candidates. After the posterior probability of each candidate is computed by Bayes theorem, and the melanosome with the maximum probability is tracked. Experimental results using the melanosome images of normal and Griscelli syndrome show the effectiveness of our method.	binary image;c date and time functions;icpram;image processing;image resolution;lanczos resampling;movable type;newton's method;pattern recognition;scale-invariant feature transform;supervised learning	Toshiaki Okabe;Kazuhiro Hotta	2012			computer vision;econometrics;statistics	AI	39.16268684764203	-70.46211702379408	66730
6ce591aaf2ac57e1b15651c1dc7e7359773ce9e6	deep learning with ultrasound physics for fetal skull segmentation		2D ultrasound (US) is still the preferred imaging method for fetal screening. However, 2D biometrics are significantly affected by the inter/intra-observer variability and operator dependence of a traditionally manual procedure. 3DUS is an alternative emerging modality with the potential to alleviate many of these problems. This paper presents a new automatic framework for skull segmentation in fetal 3DUS. We propose a two-stage convolutional neural network (CNN) able to incorporate additional contextual and structural information into the segmentation process. In the first stage of the CNN, a partial reconstruction of the skull is obtained, segmenting only those regions visible in the original US volume. From this initial segmentation, two additional channels of information are computed inspired by the underlying physics of US image acquisition: an angle incidence map and a shadow casting map. These additional information channels are combined in the second stage of the CNN to provide a complete segmentation of the skull, able to compensate for the fading and shadowing artefacts observed in the original US image. The performance of the new segmentation architecture was evaluated on a dataset of 66 cases, obtaining an average Dice coefficient of 0.83 ± 0.06. Finally, we also evaluated the clinical potential of the new 3DUS-based analysis framework for the assessment of cranial deformation, significantly outperforming traditional 2D biometrics (100% vs. 50% specificity, respectively).	artificial neural network;biometrics;convolutional neural network;deep learning;incidence matrix;inter-rater reliability;modality (human–computer interaction);sensitivity and specificity;spatial variability;sørensen–dice coefficient;x86 memory segmentation	Juan J. Cerrolaza;Matthew Sinclair;Yuanwei Li;Alberto Gómez;Enzo Ferrante;Jacqueline Matthew;Chandni Gupta;Caroline L. Knight;Daniel Rueckert	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363639	convolutional neural network;sørensen–dice coefficient;computer vision;biometrics;artificial intelligence;pattern recognition;fading;deep learning;segmentation;computer science;fetal skull;shadow	Vision	31.317535498331612	-76.57599903564295	66853
a0b4decc6a7e605e221689d230c709878065776e	examining changes in image segmented arteries in response to blood occlusion		The world's expanding and aging population has created a demand for unobtrusive, automated healthcare solutions. Thermal imaging aids in the development of these solutions by enabling the extraction of physiological signals in an unobtrusive manner. This paper aims to examine the potential for thermal video in conjunction with image segmentation methods to quantitatively describe the behavior of blood vessels as blood flow is occluded and relieved. Thermal video of a subject's arm wearing a wireless blood pressure cuff was captured as the cuff operated. Each frame of the thermal video was subjected to three methods of image segmentation (to identify the arteries); basic thresholding, watershed method and level set method. Results from each method were compared; all methods resulted in successful segmentation, but varied in region identification performance. The basic method resulted in the least accurate segmentations, the level set method resulted in the smoothest boundaries and most accurate shape, and the watershed method resulted in a crude shape but best identified the correct areas. When the segmentation results were quantified in terms of region area and examined over time, all methods indicated a smaller area when blood had been occluded, and a larger area both initially and during vascular recovery. The watershed method best characterized the vascular behaviour, while being computationally inexpensive. These results suggest that thermal video in conjunction with image segmentation methods, particularly watershed method, can be used to indicate blood flow through a segmented vessel.	image segmentation;smoothing;thresholding (image processing);unobtrusive javascript;watershed (image processing)	Stephanie L. Bennett;Rafik A. Goubran;Frank Knoefel	2017	2017 IEEE International Symposium on Medical Measurements and Applications (MeMeA)	10.1109/MeMeA.2017.7985909	occlusion;thresholding;computer vision;image segmentation;watershed;artificial intelligence;segmentation;level set method;computer science	Vision	38.74023214957434	-77.1641837062347	66981
124f55bc3ce2f82d5317a59cff107a3e5d40885f	orientation regression in hand radiographs: a transfer learning approach		Most radiologists prefer an upright orientation of the anatomy in a digital X-ray image for consistency and quality reasons. In almost half of the clinical cases, the anatomy is not upright orientated, which is why the images must be digitally rotated by radiographers. Earlier work has shown that automated orientation detection results in small error rates, but requires specially designed algorithms for individual anatomies. In this work, we propose a novel approach to overcome time-consuming feature engineering by means of Residual Neural Networks (ResNet), which extract generic low-level and high-level features, and provide promising solutions for medical imaging. Our method uses the learned representations to estimate the orientation via linear regression, and can be further improved by fine-tuning selected ResNet layers. The method was evaluated on 926 hand X-ray images and achieves a state-of-the-art mean absolute error of 2.79°.	radiography	Ivo M. Baltruschat;Axel Saalbach;Mattias P. Heinrich;Hannes Nickisch;Sascha Jockel	2018		10.1117/12.2291620	residual;transfer of learning;artificial neural network;deep learning;feature engineering;linear regression;regression;medical imaging;pattern recognition;computer science;artificial intelligence	NLP	30.461431259136575	-75.12539644491571	67062
ebb1076559d63dca55b4c393b7bd2f7a73b86efc	extraction of retinal blood vessel using curvelet transform and fuzzy c-means	fuzzy c means algorithm;fuzzy c means algorithm retinal image segmentation vessel detection curvelet transform matched filter;vessel detection;vein recognition blood vessels curvelet transforms feature extraction fuzzy set theory matched filters object detection;curvelet transform;retina biomedical imaging blood vessels image edge detection kernel wavelet transforms;blood vessel extraction methodology retinal blood vessel extraction curvelet transform automatic blood vessel detection matched filtering integrated system design platform image visual quality image contrast retinal vasculature enhancement fuzzy c means algorithm vessel silhouette extraction drive database;retinal image segmentation;matched filter	This paper addresses the automatic blood vessel detection problem in retinal images using matched filtering in an integrated system design platform that involves curve let transform and fuzzy c-means. Although noise is kept constant in medical CCD cameras, due to a number of factors, the contrast between the background and the blood vessels in retinal images and consequently the visual quality of the images looks very poor. Some form of pre-processing operation is therefore essential for the accurate extraction of these blood vessels. Since curve let transform can represent lines, edges and curvatures very well as compared to other multi-resolution techniques, this paper uses curve let transform to enhance the retinal vasculature. Matched filtering is then used to intensify the blood vessels which is further employed by fuzzy c-means algorithm to extract the vessel silhouette from the background. Performance is evaluated on publicly available DRIVE database and is compared with the existing blood vessel extraction methodology that uses curve let transform. Simulation results demonstrate that the proposed method is very much efficient in detecting long and thick as well as short and thin vessels, wherein the existing methods fail to extract tiny and thin vessels.	algorithm;charge-coupled device;curvelet;edge enhancement;fuzzy cognitive map;matched filter;preprocessor;sensor;simulation;systems design	Sudeshna Sil Kar;Santi Prasad Maity	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.584	computer vision;computer science;matched filter;computer graphics (images)	Vision	37.813130505599126	-73.01509496173131	67097
d9c5bd1746fe3e641695e1e002c27f31f196a119	neonatal brain mri segmentation	automatic segmentation algorithms;biological patents;intracranial segmentation;biomedical journals;text mining;europe pubmed central;neonatal brain;citation search;citation networks;research articles;tissue classification;abstracts;magnetic resonance imaging;open access;life sciences;clinical guidelines;brain atlas;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	This review paper focuses on the neonatal brain segmentation algorithms in the literature. It provides an overview of clinical magnetic resonance imaging (MRI) of the newborn brain and the challenges in automated tissue classification of neonatal brain MRI. It presents a complete survey of the existing segmentation methods and their salient features. The different approaches are categorized into intracranial and brain tissue segmentation algorithms based on their level of tissue classification. Further, the brain tissue segmentation techniques are grouped based on their atlas usage into atlas-based, augmented atlas-based and atlas-free methods. In addition, the research gaps and lacunae in literature are also identified.	atlases;categorization;cervical atlas;infant, newborn;magnetic resonance imaging;algorithm;biologic segmentation;brain segmentation	Chelli N. Devi;Anupama Chandrasekharan;V. K. Sundararaman;Zachariah C. Alex	2015	Computers in biology and medicine	10.1016/j.compbiomed.2015.06.016	text mining;medical research;radiology;medicine;computer science;bioinformatics;data science;magnetic resonance imaging;data mining	Vision	38.76688475090223	-79.52748938543198	67297
e16638ac07790b29c8f114ff919d47aa972d38bc	a modality-adaptive method for segmenting brain tumors and organs-at-risk in radiation therapy planning		In this paper we present a method for simultaneously segmenting brain tumors and an extensive set of organs-at-risk for radiation therapy planning of glioblastomas. The method combines a contrast-adaptive generative model for whole-brain segmentation with a new spatial regularization model of tumor shape using convolutional restricted Boltzmann machines. We demonstrate experimentally that the method is able to adapt to image acquisitions that differ substantially from any available training data, ensuring its applicability across treatment sites; that its tumor segmentation accuracy is comparable to that of the current state of the art; and that it captures most organs-at-risk sufficiently well for radiation therapy planning purposes. The proposed method may be a valuable step towards automating the delineation of brain tumors and organs-at-risk in glioblastoma patients undergoing radiation therapy.	experiment;generative model;restricted boltzmann machine	Mikael Agn;Per Munck af Rosenschöld;Oula Puonti;Michael J. Lundemann;Laura Mancini;Anastasia Papadaki;Steffi Thust;John Ashburner;Ian Law;Koenraad Van Leemput	2018	CoRR		generative model;market segmentation;pattern recognition;artificial intelligence;computer vision;mathematics;radiation treatment planning;training set;radiation therapy;boltzmann machine;regularization (mathematics);segmentation	Vision	30.382548006771284	-74.66781651644862	67455
42ab98e6dddea52f5a84a4b8d631f8186b7e5169	optical character recognition for hindi language using a neural-network approach	pre processing;language use;optical character recognition;segmentation;classification;feature vector;ocr;artificial neural network ann;neural network	Hindi is the most widely spoken language in India, with more than 300 million speakers. As there is no separation between the characters of texts written in Hindi as there is in English, the Optical Character Recognition (OCR) systems developed for the Hindi language carry a very poor recognition rate. In this paper we propose an OCR for printed Hindi text in Devanagari script, using Artificial Neural Network (ANN), which improves its efficiency. One of the major reasons for the poor recognition rate is error in character segmentation. The presence of touching characters in the scanned documents further complicates the segmentation process, creating a major problem when designing an effective character segmentation technique. Preprocessing, character segmentation, feature extraction, and finally, classification and recognition are the major steps which are followed by a general OCR. The preprocessing tasks considered in the paper are conversion of gray scaled images to binary images, image rectification, and segmentation of the document ́s textual contents into paragraphs, lines, words, and then at the level of basic symbols. The basic symbols, obtained as the fundamental unit from the segmentation process, are recognized by the neural classifier. In this work, three feature extraction techniques-: histogram of projection based on mean distance, histogram of projection based on pixel value, and vertical zero crossing, have been used to improve the rate of recognition. These feature extraction techniques are powerful enough to extract features of even distorted characters/symbols. For development of the neural classifier, a back-propagation neural network with two hidden layers is used. The classifier is trained and tested for printed Hindi texts. A performance of approximately 90% correct recognition rate is achieved. Keywords—OCR, Pre-processing, Segmentation, Feature Vector, Classification, Artificial Neural Network (ANN)	artificial neural network;backpropagation;binary image;categorization;feature extraction;feature vector;image rectification;null character;optical character recognition;pixel;preprocessor;printing;software propagation;statistical classification;zero crossing	Divakar Yadav;Sonia Sánchez-Cuadrado;Jorge Morato	2013	JIPS	10.3745/JIPS.2013.9.1.117	natural language processing;speech recognition;feature vector;biological classification;intelligent character recognition;computer science;machine learning;pattern recognition;optical character recognition;segmentation;artificial neural network	AI	33.67474376779843	-66.65298968437936	67472
11d9eff32a71ed852a8508a4c849903fbd4e7cce	a comparison of different gabor feature extraction approaches for mass classification in mammography	mass detection;gabor filter bank;directional features;digital mammography;feature transformation and reduction;sel weighted svm;pca;lda	We investigate the performance of six different approaches for directional feature extraction for mass classification problem in digital mammograms. These techniques use a bank of Gabor filters to extract the directional textural features. Directional textural features represent structural properties of masses and normal tissues in mammograms at different orientations and frequencies. Masses and micro-calcifications are two early signs of breast cancer which is a major leading cause of death in women. For the detection of masses, segmentation of mammograms results in regions of interest (ROIs) which not only include masses but suspicious normal tissues as well (which lead to false positives during the discrimination process). The problem is to reduce the false positives by classifying ROIs as masses and normal tissues. In addition, the detected masses are required to be further classified as malignant and benign. The feature extraction approaches are evaluated over the ROIs extracted from MIAS database. Successive Enhancement Learning based weighted Support Vector Machine (SELwSVM) is used to efficiently classify the generated unbalanced datasets. The average accuracy ranges from 68 to 100 % as obtained by different methods used in our paper. Comparisons are carried out based on statistical analysis to make further recommendations.	computation;dataspaces;experiment;feature extraction;feature vector;fitness function;gabor filter;genetic algorithm;mathematical optimization;preprocessor;region of interest;support vector machine;unbalanced circuit	Salabat Khan;Hatim A. Aboalsamh;George Bebis	2015	Multimedia Tools and Applications	10.1007/s11042-015-3017-3	computer vision;pattern recognition;data mining	DB	34.610259501538536	-74.40257185045922	67735
78fdc50265519d99516dd469f2053829859ca361	a two stage contour evolution approach for the measurement of choroid thickness in edi-oct images		High resolution images of the choroid can be obtained using Enhanced Depth Imaging Optical Coherence Tomography (EDI-OCT). The thickness of the choroid can be measured from these images and is used widely in clinical application for diagnosing various eye related diseases. But analysis of the choroidal thickness is presently done manually which varies with the observer and is a time consuming task. In this paper we propose a two stage contour evolution approach using chan vese method for the segmentation of choroidal layers in EDI OCT images. First the EDI OCT image is prefiltered using Rotating Kernel Transformation (RKT) to reduce the effect of speckle noise. This is followed by first stage of contour evolution which effectively identifies the upper boundary, the Bruchs Membrane (BM). The second level of segmentation delineates the lower boundary of the choroid, the Choroid Sclera Interface (CSI). The choroid thickness measured as the distance between BM and CSI are compared with the manually segmented results by an ophthalmologist. Results show good consistency with the proposed method.	contour line;electronic data interchange;thickness (graph theory)	George Neetha;C. V. Jiji	2017		10.1007/978-981-13-0020-2_38	kernel (linear algebra);bruchs membrane;observer (quantum physics);computer vision;sclera;artificial intelligence;pattern recognition;segmentation;optical coherence tomography;computer science;speckle noise;choroid	Vision	39.0635945406311	-76.85486257920651	67915
0f7f4f081e4f505e056fc15b0db63c14ff3c10cd	automatic segmentation of mr brain tumor images using support vector machine in combination with graph cut		This work focuses the attention on the automatic segmentation of meningioma from multispectral brain Magnetic Resonance imagery. The Authors address the segmentation task by proposing a fully automatic method hierarchically structured in two phases. The preliminary unsupervised phase is based on Graph Cut framework. In the second phase, preliminary segmentation results are refined using a supervised classification based on Support Vector Machine. The overall segmentation procedure is conceived fully automatic and tailored to non-volumetric data characterized by poor inter-slice spacing, in an attempt to facilitate the insertion in clinical practice. The results obtained in this preliminary study are encouraging and prove that the segmentation benefits from the allied use of Graph Cut and Support Vector Machine	algorithm;cut (graph theory);image segmentation;machine learning;multispectral image;resonance;supervised learning;support vector machine	Elisabetta Binaghi;Massimo Omodei;Valentina Pedoia;Sergio Balbi;Desiree Lattanzi;Emanuele Monti	2014		10.5220/0005068501520157	computer vision;machine learning;pattern recognition	Vision	31.381521360668692	-74.17427150487168	67932
bba2f6742d8ae6cfad3ab7529ff8bb3b42cd4fe9	objective function design for mce-based combination of on-line and off-line character recognizers for on-line handwritten japanese text recognition	databases;string recognition;classifier combination;on line recognition;handwriting recognition;character rcognition;text analysis genetic algorithms handwritten character recognition parameter estimation;training;text analysis;character recognition handwriting recognition training text recognition feature extraction databases;tuat kondate database objective function design online character recognizers offline character recognizers online handwritten japanese text recognition nonlinear function mce criterion k means method genetic algorithm parameter estimation sigmoid function parameter;feature extraction;genetic algorithms;parameter estimation;character rcognition classifier combination on line recognition string recognition;text recognition;character recognition;handwritten character recognition	This paper describes effective object function design for combining on-line and off-line character recognizers for on-line handwritten Japanese text recognition. We combine on-line and off-line recognizers using a linear or nonlinear function with weighting parameters optimized by the MCE criterion. We apply a k-means method to cluster the parameters of all character categories into groups so that the categories belonging to the same group have the same weight parameters. Moreover, we apply a genetic algorithm to estimate super parameters such as the number of clusters, initial learning rate and maximum learning times as well as the sigmoid function parameter for MCE optimization. Experimental results on horizontal text lines extracted from the TUAT Kondate database demonstrate the superiority of our method.	finite-state machine;genetic algorithm;k-means clustering;linuxmce;loss function;mathematical optimization;nonlinear system;online and offline;optical character recognition;parameter (computer programming);sigmoid function;tinymce	Bilan Zhu;Jinfeng Gao;Masaki Nakagawa	2011	2011 International Conference on Document Analysis and Recognition	10.1109/ICDAR.2011.125	speech recognition;genetic algorithm;feature extraction;computer science;machine learning;pattern recognition;handwriting recognition;estimation theory	Vision	32.215752365261	-66.3850105088491	68185
3e9caec7c37161bdb64f3f57438c377452ad33af	spatial interaction analysis with graph based mathematical morphology for histopathology		Exploring the spatial interactions between tumor and the inflammatory microenvironment using digital pathology image analysis can contribute to a better understanding of the immune function and tumor heterogeneity. We address this by providing tools able to reveal various metrics describing spatial relationships in the cancer ecosystem. The approach comprises nuclei segmentation and classification, using supervised learning algorithm, to detect lymphoid aggregates and tumor patterns, and spatial distribution quantification using sparse sets' mathematical morphology. Tumor patterns were classified into three groups: surrounded by lymphocytes, close to lymphoid aggregates or distant and might be protected from immune attack. The approach provides statistical assessment and comprehensive visual representation of the inflammatory tumor microenvironment.	algorithm;ecosystem;habitat;image analysis;interaction;mathematical morphology;sparse matrix;supervised learning	Bassem Ben Cheikh;Nicolas Elie;Benoît Plancoulaine;Catherine Bor-Angelier;Daniel Racoceanu	2017	2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)	10.1109/ISBI.2017.7950642	supervised learning;artificial intelligence;computer science;pattern recognition;spatial distribution;computer vision;tumor microenvironment;digital pathology;image segmentation;mathematical morphology;bioinformatics;graph	Visualization	28.722826437483114	-78.79792468128153	68249
d2486d4da36c51c8272f51b571dbd9b6ac6d2be9	a sequential search-space shrinking using cnn transfer learning and a radon projection pool for medical image retrieval		Closing the semantic gap in medical image analysis is critical. Access to large-scale datasets might help to narrow the gap. However, large and balanced datasets may not always be available. On the other side, retrieving similar images from an archive is a valuable task to facilitate better diagnosis. In this work, we concentrate on forming a search space, consisting of the most similar images for a given query, to be used for a similarity-based search technique in a retrieval system. We propose a two-step hierarchical shrinking search space when local binary patterns are used. Transfer learning via convolutional neural networks is utilized for the first stage of search space shrinking, followed by creating a selection pool using Radon transform for further reduction. The difference between two orthogonal Radon projections is considered in the selection pool to extract more information. The IRMA dataset, from ImageCLEF initiative, containing 14,400 X-ray images, is used to validate the proposed scheme. We report a total IRMA error of 168.05 (or 90.30% accuracy) which is the best result compared with existing methods in the literature for this dataset when real-time processing is considered. © 2018 Elsevier Ltd. All rights reserved.	archive;artificial neural network;closing (morphology);convolutional neural network;image analysis;image retrieval;irma board;linear search;local binary patterns;medical image computing;medical imaging;real-time transcription	Seyed Amin Khatami;Morteza Babaie;Hamid R. Tizhoosh;Abbas Khosravi;Thanh Nguyen;Saeid Nahavandi	2018	Expert Syst. Appl.	10.1016/j.eswa.2018.01.056	convolutional neural network;semantic gap;local binary patterns;radon transform;machine learning;deep learning;content-based image retrieval;linear search;computer science;image retrieval;artificial intelligence	AI	33.003901684945205	-74.41369311353175	68473
09b3bfc3e63a2ae09376e1e50a61b9f3b838ff3a	the optical character recognition of urdu-like cursive scripts	optical character recognition;character;ligature	We survey the optical character recognition (OCR) literature with reference to the Urdu-like cursive scripts. In particular, the Urdu, Pushto, and Sindhi languages are discussed, with the emphasis being on the Nasta'liq and Naskh scripts. Before detaining the OCR works, the peculiarities of the Urdu-like scripts are outlined, which are followed by the presentation of the available text image databases. For the sake of clarity, the various attempts are grouped into three parts, namely: (a) printed, (b) handwritten, and (c) online character recognition. Within each part, the works are analyzed par rapport a typical OCR pipeline with an emphasis on the preprocessing, segmentation, feature extraction, classification, and	ascii art;database;emoticon;feature extraction;optical character recognition;preprocessor;printing	Saeeda Naz;Khizar Hayat;Muhammad Imran Razzak;Muhammad Waqas Anwar;Sajjad Ahmad Madani;Samee Ullah Khan	2014	Pattern Recognition	10.1016/j.patcog.2013.09.037	natural language processing;computer vision;speech recognition;computer science;intelligent word recognition;optical character recognition;character	Vision	34.128253678526534	-67.03387335319005	68710
dae0ebe2674c08cf898d1976a19e7d71755b320d	template matching algorithm for exudates detection from retinal fundus images	retinal exudates;retinopathy diagnosis;connected components;image segmentation;edge detection;retinal fundus images;diabetes;retinal images;blindness;dss;diabetic retinopathy;decision support systems;visual impairment;image analysis;template matching;retinopathy screening	Diabetic retinopathy is one of the most common causes of blindness in the working-age population. Screening for diabetic retinopathy represents a good clinical practice and cost-effective healthcare. Early detection and treatment of retinopathy has been shown to be effective in preventing visual impairment. This paper provides an automated system for the identification of exudates for early diagnosis of diabetic retinopathy. The grey scale version of colour retinal fundus image was first produced. It was then enhanced using pre-processing techniques. The template matching (TM) algorithm was proposed to segment the exudates regions from diabetic retinopathy retinal images. This was experimented with a dataset, DIARETDB0 which consists of 130 colour retinal fundus images. The sensitivity and specificity achieved were 99.45% and 95.68%, respectively. It had shown 98.72% accuracy.	algorithm;connected component (graph theory);connected-component labeling;grayscale;overhead (computing);population;preprocessor;sensitivity and specificity;template matching	M. Tamilarasi;K. Duraiswamy	2013	IJCAT	10.1504/IJCAT.2013.056020	computer vision;template matching;connected component;edge detection;decision support system;computer science;image segmentation	Vision	36.697002149986666	-75.69610875517945	68741
3970adba1270ab5aa9bd5e0cc2a46e870f369956	apleaf: an efficient android-based plant leaf identification system	plant identification;期刊论文;feature fusion;android application;image retrieval	To automatically identify plant species is very useful for ecologists, amateur botanists, educators, and so on. The Leafsnap is the first successful mobile application system which tackles this problem. However, the Leafsnap is based on the IOS platform. And to the best of our knowledge, as the mobile operation system, the Android is more popular than the IOS. In this paper, an Android-based mobile application designed to automatically identify plant species according to the photographs of tree leaves is described. In this application, one leaf image can be either a digital image from one existing leaf image database or a picture collected by a camera. The picture should be a single leaf placed on a light and untextured background without other clutter. The identification process consists of three steps: leaf image segmentation, feature extraction, and species identification. The demo system is evaluated on the ImageCLEF2012 Plant Identification database which contains 126 tree species from the French Mediterranean area. The outputs of the system to users are the top several species which match the query leaf image the best, as well as the textual descriptions and additional images about plant leaves, flowers, etc. Our system works well with state-of-the-art identification performance.	android;automated species identification;clutter;digital image;ecology;feature extraction;image segmentation;mobile app;operating system	Zhong-Qiu Zhao;Lin-Hai Ma;Yiu-ming Cheung;Xindong Wu;Yuan Yan Tang;C. L. Philip Chen	2015	Neurocomputing	10.1016/j.neucom.2014.02.077	computer vision;simulation;image retrieval;computer science	AI	29.537188576325644	-67.53219778821317	68759
e5375ae8f2ee84591774f9e87947d18544624a10	toward real-time tumor margin identification in image-guided robotic brain tumor resection	robotic surgery;brain;brain cancer;image segmentation;tissues;cancer;indocyanine green;luminescence;near infrared;magnetic resonance imaging;endoscopes;scanning	For patients with malignant brain tumors (glioblastomas), a safe maximal resection of tumor is critical for annincreased survival rate. However, complete resection of the cancer is hard to achieve due to the invasive naturenof these tumors, where the margins of the tumors become blurred from frank tumor to more normal brain tissue,nbut in which single cells or clusters of malignant cells may have invaded. Recent developments in fluorescencenimaging techniques have shown great potential for improved surgical outcomes by providing surgeonsnintraoperative contrast-enhanced visual information of tumor in neurosurgery. The current near-infrared (NIR)nfluorophores, such as indocyanine green (ICG), cyanine5.5 (Cy5.5), 5-aminolevulinic acid (5-ALA)-inducednprotoporphyrin IX (PpIX), are showing clinical potential to be useful in targeting and guiding resections of suchntumors. Real-time tumor margin identification in NIR imaging could be helpful to both surgeons and patients bynreducing the operation time and space required by other imaging modalities such as intraoperative MRI, and hasnthe potential to integrate with robotically assisted surgery. In this paper, a segmentation method based on thenChan-Vese model was developed for identifying the tumor boundaries in an ex-vivo mouse brain from relativelynnoisy fluorescence images acquired by a multimodal scanning fiber endoscope (mmSFE). Tumor contours werenachieved iteratively by minimizing an energy function formed by a level set function and the segmentationnmodel. Quantitative segmentation metrics based on tumor-to-background (T/B) ratio were evaluated. Resultsndemonstrated feasibility in detecting the brain tumor margins at quasi-real-time and has the potential to yieldnimproved precision brain tumor resection techniques or even robotic interventions in the future.	real-time clock;robot	Danying Hu;Evgenii Belykh;Yuanzheng Gong;Mark C. Preul;Blake Hannaford;Eric J. Seibel	2017		10.1117/12.2255417	near-infrared spectroscopy;robotic surgery;magnetic resonance imaging;image segmentation;physics;luminescence;cancer;medical physics	Robotics	36.19903247291612	-79.48855395665512	69196
e5eca9e4ac12b1ead2f5cc09523515ba906f0b93	risk stratification of lung nodules using 3d cnn-based multi-task learning		Risk stratification of lung nodules is a task of primary importance in lung cancer diagnosis. Any improvement in robust and accurate nodule characterization can assist in identifying cancer stage, prognosis, and improving treatment planning. In this study, we propose a 3D Convolutional Neural Network (CNN) based nodule characterization strategy. With a completely 3D approach, we utilize the volumetric information from a CT scan which would be otherwise lost in the conventional 2D CNN based approaches. In order to address the need for a large amount for training data for CNN, we resort to transfer learning to obtain highly discriminative features. Moreover, we also acquire the task dependent feature representation for six high-level nodule attributes and fuse this complementary information via a Multi-task learning (MTL) framework. Finally, we propose to incorporate potential disagreement among radiologists while scoring different nodule attributes in a graph regularized sparse multi-task learning. We evaluated our proposed approach on one of the largest publicly available lung nodule datasets comprising 1018 scans and obtained state-of-the-art results in regressing the malignancy scores.	ct scan;computer multitasking;convolutional neural network;high- and low-level;multi-task learning;sparse matrix	Sarfaraz Hussein;Kunlin Cao;Qi Song;Ulas Bagci	2017		10.1007/978-3-319-59050-9_20	convolutional neural network;transfer of learning;discriminative model;machine learning;lung cancer;artificial intelligence;pattern recognition;deep learning;computer science;radiation treatment planning;multi-task learning;graph	AI	31.549211998479798	-76.51768461502527	69511
8cd6946b99aaa9ed9c57ae506f048d1219cd8e12	fuzzy rule-based segmentation of ct brain images of hemorrhage for compression	hemorrhage;fuzzy rule based system;jpeg 2000 encoder;computed tomography	This paper presents segmentation of hemorrhage from the computed tomography image. Fuzzy rule-based technique constituting three parameters namely mean difference, mode difference and grey level intensity is used. These parameters are fuzzified into four fuzzy regions with trapezoidal membership functions. The segmented arbitrary shaped region of interest information is employed in JPEG2000 encoder while encoding the image. It encodes ROI with highest priority in allocating bits as well as in transmission. 15 CT image slices with hemorrhage were used in the experiment. Experimental results shows good segmentation of hemorrhage region from CT images and allows encoding image at any desired bit rate, while maintaining lossless in ROI and lossy/lossless in non-ROI.	fuzzy rule;logic programming	V. K. Sudha;R. Sudhakar;Valentina Emilia Balas	2012	IJAIP	10.1504/IJAIP.2012.052069	computer vision;theoretical computer science;computed tomography	Vision	37.90145591857601	-71.76201397728522	69566
35f26d887a39872f5e43cbf589b9d63e5f7a55b5	segmentation and classification of skin cancer melanoma from skin lesion images		Melanoma, one type of skin cancer is considered o the most dangerous form of skin cancer occurred in humans. However it is curable if the person detects early. To minimize the diagnostic error caused by the complexity of visual interpretation and subjectivity, it is important to develop a technology for computerized image analysis. This paper presents a methodological approach for the classification of pigmented skin lesions in dermoscopic images. Firstly, the image of the skin to remove unwanted hair and noise, and then the segmentation process is performed to extract the affected area. For detecting the melanoma skin cancer, the meanshift algorithm that segments the lesion from the entire image is used in this study. Feature extraction is then performed by underlying ABCD dermatology rules. After extracting the features from the lesion, feature selection algorithm has been used to get optimized features in order to feed for classification stage. Those selected optimized features are classified using kNN, decision tree and SVM classifiers. The performance of the system was tested and compare those accuracies and get promising results.	abcd schema;decision tree;feature extraction;feature selection;humans;image analysis;k-nearest neighbors algorithm;selection algorithm;sensor;support vector machine	Nay Chi Lynn;Zin Mar Kyu	2017	2017 18th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT)	10.1109/PDCAT.2017.00028	lesion;real-time computing;support vector machine;image segmentation;feature selection;feature extraction;skin cancer;decision tree;computer science;segmentation;pattern recognition;artificial intelligence	Vision	35.182434155094725	-74.74257630695485	69649
1d902b57083e080c89c763fc4d231e0d4af5f2ca	automatic identification of music notations	multiple signal classification computer graphics testing image analysis history image processing data mining couplings information technology databases;image matching;digital music;feature extraction;image analysis;digital music notation matching automatic identification music notations historical music scores automated image analysis institute for musicology university of rostock recognition computer aided assistance notation graphic features;image matching music feature extraction;music	The music scores of 18th century and early were produced only in manual way. The important problem of the current registration of old historical music scores lays in the identification of corresponding writer, that means to estimate who did the notation write or draw. We are developing an efficient identification of a writer’s hand. This identification is based on the automated image analysis approach. The theoretical manual identification is been developing at the Institute for Musicology at the University of Rostock. First tests of an analogue approach were applied on chosen music notations. These tests indicate that the recognition problem can be sufficiently solved only by computeraided assistance. Our research activities are concentrated on the development of an automated identification of writers by analysing of notation graphic features. In our article we describe an approach for the automated image analysis and understanding as applied to digitised music scores. This approach is aimed to solve the automated identification of writers as a result of digital music notation matching.	analog signal;automatic identification and data capture;closing (morphology);digital image;image analysis;rapid prototyping;system testing;web	Nailja Luth	2002		10.1109/WDM.2002.1176212	natural language processing;speech recognition;computer science;multimedia	AI	30.701490629093264	-68.10041983698645	69767
ade34dd39a5761cc4cebceba9d27f1ebb4434389	offline signature verification and quality characterization using poset-oriented grid features	signature quality;grid features;ordered powerset;off line signature verification	This paper proposes a novel grid-based template matching scheme for off-line signature analysis and verification. At the heart of the new method lies the efficient encoding of the signature's fine geometric structure by grid templates, appropriately partitioned in subsets. Features represent the detection of ordered transitions using lattice shaped probing structures shaped on 5×5 pixel window binary masks. The verification performance of the method is evaluated on four different signature datasets producing state of the art results. Additionally, quality characterization of genuine signatures by means of complexity, stability and overall complexity-quality is also carried out. It is shown that both complexity and overall complexity measures correlate strongly with the corresponding opinions expressed by four forensic handwriting experts using the Spearman ranking test. Examination of the verification results provides evidence that the probability of correctly classifying a questioned signature is significantly enhanced when the genuine samples of a signer exhibit higher quality. We model off-line signature by measuring ordered grid transitions.We develop three quality measures for genuine off-line signatures.Quality measures and opinions from forensic experts are significantly correlated.	online and offline	Elias N. Zois;Linda Alewijnse;George Economou	2016	Pattern Recognition	10.1016/j.patcog.2016.01.009	computer science;theoretical computer science;pattern recognition;data mining	Vision	35.53913744834047	-70.48057920246195	69769
3a8d6567185b52de3b58d0e4507edd3ad8844eb0	interactive volume exploration for feature detection and quantification in industrial ct data	interactive industrial ct volume exploration;building materials;automotive engineering;feature detection;non destructive testing;computed tomography;engineering graphics;transfer functions;index terms non destructive testing;volume rendering;construction industry;cast metal part;image classification;index terms 8212;manufacturing industries;indexing terms;inspection;rendering computer graphics computerised tomography data visualisation engineering graphics feature extraction flaw detection image classification inspection production engineering computing;production engineering computing;computer vision;computer vision computed tomography metals industry data visualization transfer functions nondestructive testing construction industry manufacturing industries automotive engineering building materials;multi dimensional;data visualisation;metals industry;transfer function;flaw detection;index terms multi dimensional transfer functions;feature extraction;visualization driven approach;data visualization;parameter space;computerised tomography;rendering computer graphics;multi dimensional transfer functions;region growing;feature classification;nondestructive testing;3d transfer function;defect detection;volume rendering index terms 8212 non destructive testing multi dimensional transfer functions region growing;defect detection interactive industrial ct volume exploration feature detection cast metal part feature classification visualization driven approach region growing 3d transfer function nondestructive testing volume rendering;algorithms 0 0 0 0 0 0 0 1 computer graphics 0 0 0 0 0 0 0 1 equipment failure analysis 0 0 0 0 0 0 0 1 imaging three dimensional 0 0 0 0 0 0 0 1 industry 0 0 0 0 0 0 0 1 materials testing 0 0 0 0 0 0 0 1 pattern recognition automated 0 0 0 0 0 0 0 1 tomography x ray computed 0 0 0 0 0 0 0 1 user computer interface 0 0 0 0 0 0 0 1	This paper presents a novel method for interactive exploration of industrial CT volumes such as cast metal parts, with the goal of interactively detecting, classifying, and quantifying features using a visualization-driven approach. The standard approach for defect detection builds on region growing, which requires manually tuning parameters such as target ranges for density and size, variance, as well as the specification of seed points. If the results are not satisfactory, region growing must be performed again with different parameters. In contrast, our method allows interactive exploration of the parameter space, completely separated from region growing in an unattended pre-processing stage. The pre-computed feature volume tracks a feature size curve for each voxel over time, which is identified with the main region growing parameter such as variance. A novel 3D transfer function domain over (density, feature.size, time) allows for interactive exploration of feature classes. Features and feature size curves can also be explored individually, which helps with transfer function specification and allows coloring individual features and disabling features resulting from CT artifacts. Based on the classification obtained through exploration, the classified features can be quantified immediately.	adaptive sampling;ct scan;cations;class;classification;data drilling;feature detection (web development);feature model;fundamental fysiks group;graph coloring;imagery;interactivity;justicieae sp. daniel 6737;morphologic artifacts;population parameter;precomputation;preprocessor;quantitation;region growing;sample variance;sampling (signal processing);sensor;siegfried selberherr;software bug;specification;subject-matter expert;track (course);transfer function;venue (sound system);voxel;acetate:cation symporter activity	Markus Hadwiger;Laura Fritz;Christof Rezk-Salama;Thomas Höllt;Georg Geier;Thomas Pabel	2008	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2008.147	computer vision;nondestructive testing;computer science;transfer function;data visualization;statistics;computer graphics (images)	Visualization	38.32150355687952	-74.55828482148003	69823
83fde8359cd3f724fa2ec1dee48304cc3ad6afdd	lesion detection and classification in breast cancer: evaluation of approaches based on morphological features, tracer kinetic modelling and semi-quantitative parameters in mr functional imaging (dce-mri)			functional imaging;semiconductor industry	Roberta Fusco	2013				Vision	30.617942693015486	-79.17013595790755	69834
38f235b78d616762a422983b1ae66252b73fd964	a novel approach to segment and classify regional lymph nodes on computed tomography images	sensitivity and specificity;support vector machines;normal distribution;models theoretical;image processing computer assisted;nonlinear dynamics;reproducibility of results;roc curve;algorithms;humans;lymphatic metastasis;neoplasms;diffusion;prognosis;lymph nodes;computer simulation;tomography x ray computed	Morphology of lymph nodal metastasis is critical for diagnosis and prognosis of cancer patients. However, accurate prediction of lymph node type based on morphological information is rarely available due to lack of pathological validation. To obtain correct morphological information, lymph nodes must be segmented from computed tomography (CT) image accurately. In this paper we described a novel approach to segment and predict the status of lymph nodes from CT images and confirmed the diagnostic performance by clinical pathological results. We firstly removed noise and preserved edge details using a revised nonlinear diffusion equation, and secondly we used a repulsive-force-based snake method to segment the lymph nodes. Morphological measurements for the characterization of the node status were obtained from the segmented node image. These measurements were further selected to derive a highly representative set of node status, called feature vector. Finally, classical classification scheme based on support vector machine model was employed to simulate the prediction of nodal status. Experiments on real clinical rectal cancer data showed that the prediction performance with the proposed framework is highly consistent with pathological results. Therefore, this novel algorithm is promising for status prediction of lymph nodes.	anatomic node;biologic preservation;ct scan;cellular automaton;feature vector;forecast of outcome;lymphadenopathy;mathematical morphology;neoplasms;nonlinear system;patients;rectal carcinoma;revision procedure;simulation;support vector machine;tube,rectal,24fr,plastic b#6510;x-ray computed tomography;algorithm;lymph nodes	Hongmin Cai;Chunyan Cui;Haiying Tian;Min Zhang;Li Li	2012		10.1155/2012/145926	normal distribution;computer simulation;support vector machine;medicine;pathology;computer science;machine learning;diffusion;receiver operating characteristic;surgery;statistics	ML	38.227901680371204	-78.00902010140364	69923
0aed34e17d7131f66e4109541ca115226fa01ee4	shaving diffusion tensor images in discriminant analysis: a study into schizophrenia	white matter;diffusion tensor images;linear discriminate analysis;discriminant analysis;schizophrenia;corpus callosum;principal component analysis;region of interest;comparative study;fractional anisotropy;diffusion tensor imaging;shaving;linear discriminant analysis	A technique called 'shaving' is introduced to automatically extract the combination of relevant image regions in a comparative study. No hypothesis is needed, as in conventional pre-defined or expert selected region of interest (ROI)-analysis. In contrast to traditional voxel based analysis (VBA), correlations within the data can be modeled using principal component analysis (PCA) and linear discriminant analysis (LDA). A study into schizophrenia using diffusion tensor imaging (DTI) serves as an application. Conventional VBA found a decreased fractional anisotropy (FA) in a part of the genu of the corpus callosum and an increased FA in larger parts of white matter. The proposed method reproduced the decrease in FA in the corpus callosum and found an increase in the posterior limb of the internal capsule and uncinate fasciculus. A correlation between the decrease in the corpus callosum and the increase in the uncinate fasciculus was demonstrated.	anterior descending branch of left coronary artery;body of uterus;diffusion tensor imaging;fascicle - nerve fibers;fractional anisotropy;internal capsule of brain;knee;large;linear discriminant analysis;principal component analysis;region of interest;schizophrenia;structure of genu of corpus callosum;visual basic for applications;voxel;white matter	Matthan W. A. Caan;Koen A. Vermeer;Lucas J. van Vliet;Charles B. L. M. Majoie;Bart Peters;Gerard J. den Heeten;Frans Vos	2006	Medical image analysis	10.1016/j.media.2006.07.006	speech recognition;radiology;computer science;artificial intelligence;machine learning;schizophrenia;linear discriminant analysis;fractional anisotropy;principal component analysis;region of interest	ML	30.87401021698951	-79.83749907571199	70041
589f419078560fa263e7298a569db22629eac5cd	learning spatial grammars for drawn documents using genetic algorithms	dna;two dimensional parsing engine;genomics;object recognition;supervised learning;spatial grammars;search space;genetic al gorithm;production dna supervised learning genetic algorithms genomics bioinformatics encoding;drawn documents spatial grammar learning object recognition spatial organisation two dimensional parsing engine genetic algorithm learning routine supervised learning routine background features;spatial organisation;supervised learning routine;grammars;spatial grammar learning;hierarchical object recognition;hierarchical object recognition genetic algorithms spatial grammars;document image processing;background features;production;drawn documents;genetic algorithm;genetic algorithms;learning artificial intelligence;encoding;object recognition document image processing genetic algorithms grammars learning artificial intelligence;ge netic algorithm;genetic algorithm learning routine;bioinformatics	The problem of object recognition may be cast into a spatial grammar framework. The system comprises three novel elements: a spatial organisation of line features, an efficient two dimensional parsing engine, and a genetic algorithm learning routine that induces spatial grammars. Labelling the spatial organisation of feature pairs allows the terminal symbols of the spatial grammar to be defined, and constrains the search space of the feature parser. A genetic algorithm approach is then used to induce appropriate grammars using a supervised learning routine. Early results show that similar foreground and background features can be discriminated using this approach.	feature detection (computer vision);feature detection (web development);fitness function;genetic algorithm;high- and low-level;hough transform;loss function;outline of object recognition;parsing;product binning;spatial reference system;supervised learning	Simon J. Hickinbotham;Anthony G. Cohn	2008	2008 Eighth International Conference on Hybrid Intelligent Systems	10.1109/HIS.2008.54	natural language processing;l-attributed grammar;parsing expression grammar;computer science;machine learning;pattern recognition	Robotics	32.42686977723843	-67.81380079503758	70318
4afd5467bf69a64cec8fdfb622a9c2e31368a6d6	associative classification of mammograms using weighted rules	health research;uk clinical guidelines;biological patents;europe pubmed central;rule based;citation search;image classification;uk phd theses thesis;association rule;region of interest;life sciences;rule discovery;uk research reports;medical journals;mammograms;europe pmc;biomedical research;bioinformatics	In this paper, we present a novel method for the classification of mammograms using a unique weighted association rule based classifier. Images are preprocessed to reveal regions of interest. Texture components are extracted from segmented parts of the image and discretized for rule discovery. Association rules are derived between various texture components extracted from segments of images, and employed for classification based on their intra- and inter-class dependencies. These rules are then employed for the classification of a commonly used mammography dataset, and rigorous experimentation is performed to evaluate the rules' efficacy under different classification scenarios. The experimental results show that this method works well for such datasets, incurring accuracies as high as 89%, which surpasses the accuracy rates of other rule based classification techniques.		Sumeet Dua;Harpreet Singh;Hilary W. Thompson	2009	Expert systems with applications	10.1016/j.eswa.2008.12.050	rule-based system;contextual image classification;association rule learning;computer science;artificial intelligence;data science;machine learning;classification rule;data mining;information retrieval;region of interest	ML	33.648759126450905	-74.44249998579947	70817
935d4ab427e4643f94eb8e55d4593ea1fe2dcc20	viewpoint recognition in cardiac ct images		Position and orientation information is often lacking in DICOM datasets. This creates a need for human involvement or computationally expensive 3D processing for any analytical tool, such as a software-based cognitive assistant, to determine the viewpoint of an input 2D image. We report a solution for cardiac CT viewpoint recognition to identify the desired images for a specific view and subsequent processing and anatomy recognition. We propose a new set of features to describe the global binary pattern of cardiac CT images characterized by the highly attenuating components of the anatomy in the image. We also use five classic image texture and edge feature sets and devise a classification approach based on SVM classification, class likelihood estimation, and majority voting, to classify 2D cardiac CT images into one of six viewpoint categories that include axial, sagittal, coronal, two chamber, four chamber, and short axis views. We show that our approach results in an accuracy of 99.4 % in correct labeling of the viewpoints.	ct scan;computed tomography of the heart;viewpoint	Mehdi Moradi;Noel C. F. Codella;Tanveer F. Syeda-Mahmood	2015		10.1007/978-3-319-20309-6_21	computer vision;sagittal plane;local binary patterns;support vector machine;binary pattern;dicom;random forest;software;image texture;artificial intelligence;computer science	Vision	35.901265395919566	-76.87177929261279	70843
88c4b812e6705ef98598e671f7470faaf50d8eb6	the development of fast cellular pattern transformation algorithms using virtual boundaries	fast cellular pattern transformation;virtual boundary	In [1,2,4] it is shown that the development of (fast) d-dimensional cellular pattern transformation algorithms can be done  by reducing the pattern transformation problem to an appropriate language recognition problem where a new type of d-dimensional  words and languages with an appropriate recognition process is introduced. Unfortunately, the resulting languages often are  not very well suited to the application of well known and (meanwhile) standardized cellular techniques. Here we present a  systematic method, how additional information can be added to the words to be recognized in order to facilitate the application  of these techniques. The with-additional-information recognizing process can be converted algorithmically into a without-additional-information  recognizing one.  		Josef Pecht	1981		10.1007/BFb0105118	computer vision;theoretical computer science;machine learning	Vision	32.09459392756199	-68.24105844894736	71097
7887db5a187f545f6b984a7505fb38a35542a32f	vision-based absence seizure detection	image classification;medical disorders;c4 5 decision tree vision based absence seizure detection epilepsy diagnosis neurologists equal assessment performance electroencephalogram diagnostic precision leveraging clinical image assessment procedure facial expression features absence seizure detection absence seizure quantification feature extraction time varying signal analysis computer vision techniques dense optical flow computation face detection background subtraction video sequences classification performance;computer vision;child child preschool female humans image interpretation computer assisted male seizures sensitivity and specificity signal processing computer assisted video recording;image enhancement;face recognition;feature extraction;medical image processing;epilepsy mouth feature extraction accuracy medical diagnostic imaging computer vision;neurophysiology computer vision electroencephalography face recognition feature extraction image classification image enhancement image sequences medical disorders medical image processing;neurophysiology;electroencephalography;image sequences	In order to diagnose epilepsy, neurologists rely on their experience, performing an equal assessment of the electroencephalogram and the clinical image. Since misdiagnosis reaches a rate of 30% and more than one-third of all epilepsies are poorly understood, a need for leveraging diagnostic precision is obvious. With the aim at enhancing the clinical image assessment procedure, this paper evaluates the suitability of certain facial expression features for detecting and quantifying absence seizures. These features are extracted by means of time-varying signal analysis from signals that are gained by applying computer vision techniques, such as face detection, dense optical flow computation and averaging background subtraction. For the evaluation, video sequences of four patients with absence seizures are used. The classification performance of a C4.5 decision tree shows accuracies of up to 99.96% with a worst percentage of incorrectly classified instances of 0.14%.	background subtraction;c4.5 algorithm;cns disorder;childhood absence epilepsy;classification;computation;computer vision;decision support system;decision tree;divergence-from-randomness model;electroencephalography;evaluation procedure;face detection;feature extraction;gain;obstruction;optical flow;patients;seizures;sensor;signal processing	Matthew Pediaditis;Manolis Tsiknakis;Lefteris Koumakis;M. Karachaliou;Spyridon Voutoufianakis;Pelagia Vorgia	2012	2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2012.6345872	computer vision;contextual image classification;speech recognition;electroencephalography;feature extraction;computer science;communication;neurophysiology	Vision	32.177272290546746	-78.16400302149297	71163
fbde9a6c740d693bcae561865c874ef414dfbf49	a file fragment classification method based on grayscale image	digital forensic;grayscale image;file fragment classification	File fragment classification is an important and difficult problem in digital forensics. Previous works in this area mainly relied on specific byte sequences in file headers and footers, or statistical analysis and machine learning algorithms on data from the middle of the file. This paper introduces a new approach to classify file fragment based on grayscale image. The proposed method treats a file fragment as a grayscale image, and uses image classification method to classify file fragment. Furthermore, two models based on file-unbiased and type-unbiased are proposed to verify the validity of the proposed method. Compared with previous works, the experimental results are promising. An average classification accuracy of 39.7% in file-unbiased model and 54.7% in type-unbiased model are achieved on 29 file types.	algorithm;byte;computer vision;grayscale;machine learning;statistical classification	Tantan Xu;Ming Xu;Yizhi Ren;Jian Xu;Haiping Zhang;Ning Zheng	2014	JCP	10.4304/jcp.9.8.1863-1870	computer science;theoretical computer science;digital forensics;database;image file formats;grayscale;computer graphics (images)	EDA	34.165975584888365	-69.41406315373509	71200
1b00f168295b1cce63e40fd87996b40ff7a2c0ef	right ventricle segmentation in cardiac mr images using u-net with partly dilated convolution		Segmentation of anatomical structures in cardiac MR images is an important problem because it is necessary for evaluation of morphology of these structures for diagnostic purposes. Automatic segmentation algorithm with near-human accuracy would be extremely helpful for a medical specialist. In this paper we consider such structures as endocardium and epicardium of right ventricle. We compare the performance of the best existing neural networks such as U-Net and GridNet, and propose our own modification of U-Net which implies replacement of every second convolution layer with dilated (atrous) convolution layer. Evaluation on benchmark dataset RVSC demonstrated that the proposed algorithm allows to improve the segmentation accuracy up to 6% both for endocardium and epicardium compared to original U-Net. The algorithm also overperforms GridNet for both segmentation problems.	convolution	Gregory Borodin;Olga V. Senyukova	2018		10.1007/978-3-030-01421-6_18	pattern recognition;artificial neural network;endocardium;ventricle;artificial intelligence;extremely helpful;convolution;computer science;segmentation	Vision	31.49992400957769	-75.65886105172575	71248
65e9f833e6c73e033c0adf01023f0bfa38c3b1e0	a new segmentation algorithm for handwritten word recognition	learning image segmentation handwritten word recognition cursive words feature extraction neural network;handwriting recognition image segmentation character recognition artificial neural networks telephony testing information technology gold postal services australia;feature detection;image segmentation;neural nets;institute for integrated and intelligent systems;point location;feature extraction;handwritten word recognition;learning artificial intelligence;learning artificial intelligence handwritten character recognition feature extraction image segmentation neural nets;handwritten character recognition;artificial neural network	An algorithm for segmenting unconstrained printed and cursive words is proposed. The algorithm initially oversegments handwritten word images (for training and testing) using heuristics and feature detection. An Artificial Neural Network (ANN) is then trained with global features extracted from segmentation points found in words designated for training. Segmentation points located in “test” word images are subsequently extracted and verified using the trained ANN. Two major sets of experiments were conducted, resulting in segmentation accuracies of 75.06% and 76.52%. The handwritten words used for experimentation were taken from the CEDAR CD-ROM. The results obtained for segmentation can easily be used for comparison with other researchers using the same benchmark database.	algorithm;artificial neural network;benchmark (computing);cd-rom;experiment;feature detection (computer vision);feature detection (web development);heuristic (computer science);image segmentation;mesa;printing	Michael Blumenstein;Brijesh Verma	1999		10.1109/IJCNN.1999.833544	speech recognition;feature extraction;intelligent character recognition;computer science;intelligent word recognition;machine learning;segmentation-based object categorization;point location;pattern recognition;feature detection;image segmentation;scale-space segmentation;neocognitron;artificial neural network	Vision	33.34316187903813	-66.35667893962875	71460
b5067433770eab31ef715b62ce1764d24010681e	a real time object tracking system for contrast media injection	analytical models;video object;meanshift algorithm;tracking system;computed tomography;video tracking;site effect;canny operator;monitoring system;computational modeling;medical services;monitoring;edge;target tracking computerised tomography diagnostic radiography medical image processing object detection;medical image processing;object tracking;computerised tomography;contrast media;edge tracking visual tracking canny operator meanshift algorithm;robustness;area based detection method real time system contrast media injection ct angiography hospital video object tracking system meanshift algorithm injection site;target tracking;visual tracking;high speed;ct angiography;diagnostic radiography;tracking;object detection;computed tomography tracking robustness monitoring analytical models medical services computational modeling	Contrast media is widely used in hospital for a better imaging of CT angiography. However, emergencies (such as needle eruption and capillary hemorrhage) may exist due to the extreme high speed of injection. A video-object-tracking system is implemented in this paper which can keep track of the patient's progress and sound an alarm in the event of danger. The MeanShift algorithm for real-time object tracking determines the location of the injection site. An area based detection method is presented to check whether the injection site is bleeding. Experiment results show that the video-tracking-and-monitoring system could track the injection site effectively and achieve a high tracking accuracy.	algorithm;ct scan;computed tomography angiography;real-time clock;tracking system;video tracking	Zhelong Wang;Chuan Dai;Hongyu Zhao	2010	2010 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2010.5641832	computer vision;simulation;computer science;artificial intelligence;video tracking;computed tomography;computer graphics (images)	Robotics	37.81778344722058	-76.74341886922507	71974
1e70cf00d249dbd383b8c54f9886a09f8596d988	multimodal entity coreference for cervical dysplasia diagnosis	computers;diseases cervical cancer lesions sensitivity visualization computers;patient case retrieval cervical dysplasia cervical image analysis disease classification entity coreference;multimodal entity coreference single information source gradient based approaches disease classification disease diagnosis comprehensive algorithmic framework hpv test pap tests normal tissue low grade lesions high grade cervical lesions texture color data driven computer algorithm resource poor regions cervical cancer screening cervix images pap smear screening programs cervical dysplasia diagnosis;sensitivity;visualization;lesions;cervical cancer;diseases;medical image processing biological organs biomedical optical imaging cancer image classification image colour analysis image texture	Cervical cancer is the second most common type of cancer for women. Existing screening programs for cervical cancer, such as Pap Smear, suffer from low sensitivity. Thus, many patients who are ill are not detected in the screening process. Using images of the cervix as an aid in cervical cancer screening has the potential to greatly improve sensitivity, and can be especially useful in resource-poor regions of the world. In this paper, we develop a data-driven computer algorithm for interpreting cervical images based on color and texture. We are able to obtain 74% sensitivity and 90% specificity when differentiating high-grade cervical lesions from low-grade lesions and normal tissue. On the same dataset, using Pap tests alone yields a sensitivity of 37% and specificity of 96%, and using HPV test alone gives a 57% sensitivity and 93% specificity. Furthermore, we develop a comprehensive algorithmic framework based on Multimodal Entity Coreference for combining various tests to perform disease classification and diagnosis. When integrating multiple tests, we adopt information gain and gradient-based approaches for learning the relative weights of different tests. In our evaluation, we present a novel algorithm that integrates cervical images, Pap, HPV, and patient age, which yields 83.21% sensitivity and 94.79% specificity, a statistically significant improvement over using any single source of information alone.	adjunctive orthodontic procedure;algorithmic efficiency;binary classification;body tissue;calibration;cervix carcinoma;christ-siemens-touraine syndrome;combinatory logic;computation;data sources;data mining;eighty;extraction;gradient;histopathologic grade;image analysis;information gain in decision trees;information source;kidney function tests;kullback–leibler divergence;multimodal interaction;neck;neoplasms;pap smear;papaverine;patients;sensitivity and specificity;sensor;silo (dataset);smear campaign;weight;algorithm;disease classification;early detection of cervical cancer	Dezhao Song;Edward Kim;Xiaolei Huang;Joseph Patruno;Hector Muñoz-Avila;Jeff Heflin;L. Rodney Long;Sameer K. Antani	2015	IEEE Transactions on Medical Imaging	10.1109/TMI.2014.2352311	computer vision;visualization;medicine;pathology;sensitivity;computer science;gynecology	Vision	34.99909100982327	-77.90942269536073	71993
8fec4f0fa5c4cdfd1986c2a0a73ce501886602e9	segmentation of blood vessels in color fundus images based on optimal multi-threshold method	optimal multi threshold fundus images blood vessels non uniform enhancement grid division;image segmentation;image segmentation abstracts blood diabetes;image colour analysis;medical image processing;medical image processing blood vessels image colour analysis image segmentation;gray images blood vessels segmentation color fundus images optimal multi threshold method clinicians;blood vessels	Blood vessels in fundus images contain large number of important diagnosis information, while it is too tedious for clinicians to distinguish. This paper proposes a method to segment blood vessels efficiently. Firstly, non-uniform enhancement was used to balance the non-uniform background induced by light. Then the image was divided into grids. Secondly, optimal threshold was selected for each grid. Finally, blood vessels were segmented in gray images. The experimental results show that the extracted blood vessels have well continuity and accurate center-line which provides useful information support to clinicians.	grid computing;scott continuity	Faling Yi;Wenhua Xu	2012	2012 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2012.6359014	computer vision;computer science;image segmentation	Robotics	38.08965570501364	-75.78468380529658	72057
616922d39cd0465835e1897e9be323c0f8b66e76	automatic detection of axillary lymphadenopathy on ct scans of untreated chronic lymphocytic leukemia patients	computer aided diagnosis;blob detection;lung;receivers;leukemia;medical diagnostics	Patients with chronic lymphocytic leukemia (CLL) have an increased frequency of axillary lymphadenopathy. Pretreatment CT scans can be used to upstage patients at the time of presentation and post-treatment CT scans can reduce the number of complete responses. In the current clinical workflow, the detection and diagnosis of lymph nodes is usually performed manually by examining all slices of CT images, which can be time consuming and highly dependent on the observer's experience. A system for automatic lymph node detection and measurement is desired. We propose a computer aided detection (CAD) system for axillary lymph nodes on CT scans in CLL patients. The lung is first automatically segmented and the patient's body in lung region is extracted to set the search region for lymph nodes. Multi-scale Hessian based blob detection is then applied to detect potential lymph nodes within the search region. Next, the detected potential candidates are segmented by fast level set method. Finally, features are calculated from the segmented candidates and support vector machine (SVM) classification is utilized for false positive reduction. Two blobness features, Frangi's and Li's, are tested and their free-response receiver operating characteristic (FROC) curves are generated to assess system performance. We applied our detection system to 12 patients with 168 axillary lymph nodes measuring greater than 10 mm. All lymph nodes are manually labeled as ground truth. The system achieved sensitivities of 81% and 85% at 2 false positives per patient for Frangi's and Li's blobness, respectively.© (2012) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	ct scan	Jiamin Liu;Jeremy Hua;Vivek Chellappa;Nicholas Petrick;Berkman Sahiner;Mohammed Farooqui;Gerald Marti;Adrian Wiestner;Ronald M. Summers	2012		10.1117/12.911836	blob detection	ML	35.916570393278775	-78.40035053740394	72098
75464c66e6947f3c4b50bcc806484b70e51dec0b	applying best practices from digital control systems to bmi implementation	decoding;gaussian processes;kernel bandwidth estimation decoding smoothing methods neurons brain modeling;continuous time system digital control system brain machine interface algorithm population vector decoder neural spike rate estimation bin width selection sampling rate real time rate estimation gaussian filter optimization offline rate estimation autoregressive decoding algorithm neural signal processing smoothing filter discrete time decoder representation;smoothing methods autoregressive processes brain computer interfaces continuous time systems decoding digital control gaussian processes medical signal processing;continuous time systems;smoothing methods;autoregressive processes;digital control;brain computer interfaces;action potentials algorithms animals brain computer interfaces extremities macaca models neurological movement normal distribution signal processing computer assisted;medical signal processing	Many brain-machine interface (BMI) algorithms, such as the population vector decoder, must estimate neural spike rates before transforming this information into an external output signal. Often, rate estimation is performed via the selection of a bin width corresponding to the effective sampling rate of the decoding algorithm. Here, we implement real-time rate estimation by extending prior work on the optimization of Gaussian filters for offline rate estimation. We show that higher sampling rates result in improved spike rate estimation. We further show that the choice of sampling rate need not dictate the number of parameters which must be used in an autoregressive decoding algorithm. Multiple studies in other neural signal processing contexts suggest that BMI performance could be improved substantially via careful choice of smoothing filter, discrete-time decoder representation, and sampling rate. Together, these ensure minimal deviation from the behavior of the modeled continuous-time systems.	algorithm;apricot kernel oil;autoregressive model;best practice;bin;brain neoplasms;brain–computer interface;choice behavior;control system;decoder device component;electroencephalography;hertz (hz);mathematical model;mathematical optimization;normal statistical distribution;nyquist rate;online and offline;population vector;real-time clock;requirement;sampling (signal processing);sampling - surgical action;seamless3d;signal processing;smoothing (statistical technique);width	Charles Matlack;Chet T. Moritz;Howard Jay Chizeck	2012	2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2012.6346275	brain–computer interface;neuroscience;speech recognition;digital control;computer science;theoretical computer science;machine learning;gaussian process;mathematics;statistics	EDA	24.667297213122076	-72.63434293108095	72186
1fe400f150ac8555f9f3b24acc0914809c8d501e	relevance segmentation of laparoscopic videos	fuzzy classification;irrelevant scene detection video segmentation endoscopic video fuzzy classification segment composition;segment composition;image segmentation;video signal processing;storage management;irrelevant scene detection;video retrieval;image classification;video segmentation;fuzzy set theory;feature extraction;medical image processing;endoscopic video;video signal processing feature extraction fuzzy set theory image classification image segmentation information retrieval systems medical image processing object detection regression analysis storage management surgery video retrieval;surgery;videos endoscopes surgery laparoscopes image color analysis training predictive models;information retrieval systems;storage space saving relevance segmentation laparoscopic videos video footage laparoscopic surgery video archives storage capacity relevant scene retrieval visual feature extraction method irrelevance indicators irrelevant segments prediction model nonlinear regression generalized logistic function segment composition algorithm fuzzy frame classification segment boundary detection;regression analysis;object detection	In recent years, it became common to record video footage of laparoscopic surgeries. This leads to large video archives that are very hard to manage. They often contain a considerable portion of completely irrelevant scenes which waste storage capacity and hamper an efficient retrieval of relevant scenes. In this paper we (1) define three classes of irrelevant segments, (2) propose visual feature extraction methods to obtain irrelevance indicators for each class and (3) present an extensible framework to detect irrelevant segments in laparoscopic videos. The framework includes a training component that learns a prediction model using nonlinear regression with a generalized logistic function and a segment composition algorithm that derives segment boundaries from the fuzzy frame classifications. The experimental results show that our method performs very good both for the classification of individual frames and the detection of segment boundaries in videos and enables considerable storage space savings.	algorithm;archive;feature extraction;gaussian blur;interactivity;nonlinear system;relevance;sensor;user interface	Bernd Münzer;Klaus Schöffmann;László Böszörményi	2013	2013 IEEE International Symposium on Multimedia	10.1109/ISM.2013.22	computer vision;contextual image classification;feature extraction;fuzzy classification;computer science;machine learning;pattern recognition;fuzzy set;image segmentation;regression analysis	Vision	35.13985561723354	-72.6293820828848	72553
8a392e0b688ba5e3fcbd479a4a8517d01f46d5d2	automated visual inspection of imprint quality of pharmaceutical tablets	modeling;pharmaceutical tablets;automatic visual inspection;imprint quality	Visual appearance is an important quality factor of pharmaceutical tablets. Moreover, it plays a key role in identification of tablets, which is needed to prevent mix-ups among various types of tablets. Since identification of tablets is most frequently done by imprints, good imprint quality, a property that makes the imprint readable, is of utmost importance in preventing mix-ups among the tablets. In this paper, we propose a novel method for automated visual inspection of tablets. Besides defect detection, imprint quality inspection is also considered. Performance of the method was evaluated on three different real tablet image databases of imprinted tablets. A “gold standard” was established by manually classifying tablets into a good and a defective class. The receiver operating characteristics (ROC) analysis indicated that the proposed method yields better sensitivity and specificity than the previous defect detection method.	database;human-readable medium;receiver operating characteristic;sensitivity and specificity;software bug;tablet computer;visual inspection	Miha Mozina;Dejan Tomazevic;Franjo Pernus;Bostjan Likar	2011	Machine Vision and Applications	10.1007/s00138-011-0366-4	computer vision;computer science;artificial intelligence;receiver operating characteristic;visual inspection;visual appearance	Vision	35.747816133154906	-74.81638296356842	73034
d44ff3de1bcb8cdd0d1ef8f94667531c019fe8ca	classification of 3d face shape in 22q11.2 deletion syndrome	biomedical measurements;shape facial features principal component analysis ultrasonic variables measurement genetics biomedical measurements linear discriminant analysis pediatrics magnetic heads ultrasonic imaging;stereo image processing cellular biophysics computer vision feature extraction genetics image classification medical image processing mesh generation;image classification;data mining;genetics;computer vision;medical expert systems;accuracy;genetic condition;ear;general population;medical expert system;medical information systems;three dimensional displays;shape based morphological differences;stereo imaging;feature extraction;medical image processing;principal component analysis;medical information system;stereo image processing;biomedical image processing;facial features;face;face shape classification;labeled 3d meshes;mesh generation;heads;22q11 2 deletion syndrome;medical information systems biomedical image processing biomedical measurements medical expert systems;genetic condition face shape classification three dimensional face shape 22q11 2 deletion syndrome labeled 3d meshes stereo imaging heads computer vision shape based morphological differences facial features;cellular biophysics;three dimensional face shape	Given a set of labeled 3D meshes acquired from stereo imaging of heads, the goal of this research is to develop a successful methodology for discriminating between individuals with 22q11.2 deletion syndrome and the general population. Although many approaches for such discrimination exist in the medical and computer vision literature, the goal is to develop methods that focus on shape-based morphological differences of facial features.	computer vision	Katarzyna Wilamowska;Linda G. Shapiro;Carrie L Heike	2009	2009 IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2009.5193102	face;mesh generation;computer vision;contextual image classification;speech recognition;feature extraction;computer science;machine learning;pattern recognition;mathematics;accuracy and precision;principal component analysis	Vision	38.161915591850956	-74.2947437622421	73046
792db41e231a74ff450e7728a5d71210c0c030bf	optimal computer based analysis for detecting malarial parasites		Malaria poses a serious global health problem and it requires a rapid, accurate diagnosis to control the disease. An image processing algorithm for accurate and rapid automation in the diagnosis of malaria in blood images is developed in this research paper. The image classification system to identify the malarial parasites positively present in thin blood smears is designed, and differentiated into the various species and stages of malaria - falciparum and vivax prevalent in India. Method implemented presents a new approach to image processing in which the detection experiments employed the KNN rule, along with other algorithms such as ANN (Artificial Neural Networks), Zack’s thresholding and Linear Programming and Template matching to find out the optimal classifier for detection and classification of malarial parasites with its stages.	sensor	S. T. Khot;R. K. Prasad	2014		10.1007/978-3-319-11933-5_9	malaria;image processing;artificial neural network;thresholding;classifier (linguistics);diagnosis of malaria;template matching;artificial intelligence;contextual image classification;computer science;pattern recognition	Crypto	35.270502854605446	-74.77629720563236	73287
c96bdf7c7802246a1c768bf7a3477a435e99c86a	pathologic region detection algorithm for prostate ultrasonic image based on pcnn	image segmentation;pseudo color;region of interest;detection algorithm;prostate ultrasonic image;quantitative analysis;region growing;pulse coupled neural network;close binaries	It is quite important and difficult for doctors to detect pathologic regions of prostate ultrasonic images. An automated region detection algorithm is proposed to solve this problem, especially for ultrasonic images containing all kinds of noise and speckle. First, all the pixels of an ultrasonic image are fired by Pulse Coupled Neural Network (PCNN). Then after being processed by morphological closing, binary reversing and region labeling, the seeds are detected automatically using PCNN, by which the region of interest (ROI) of the ultrasonic image is detected by Region Growing. In the end, we code the ROI by pseudo-color. Detected pathologic regions can be used for further clinical inspection and quantitative analysis of ultrasonic images.	algorithm;pulse-coupled networks	Beidou Zhang;Yide Ma;Dongmei Lin;Liwen Zhang	2007		10.1007/978-3-540-73814-5_23	computer vision;pathology;geography;optics	Vision	37.530362099260344	-75.81212001115954	73504
76e2036bca2d45748ff3ba0932e3d264eb386244	quick detection of brain tumors and edemas: a bounding box method using symmetry	brain tumor;bhattacharya coefficient;edema;brain tumor detection	A significant medical informatics task is indexing patient databases according to size, location, and other characteristics of brain tumors and edemas, possibly based on magnetic resonance (MR) imagery. This requires segmenting tumors and edemas within images from different MR modalities. To date, automated brain tumor or edema segmentation from MR modalities remains a challenging, computationally intensive task. In this paper, we propose a novel automated, fast, and approximate segmentation technique. The input is a patient study consisting of a set of MR slices, and its output is a subset of the slices that include axis-parallel boxes that circumscribe the tumors. Our approach is based on an unsupervised change detection method that searches for the most dissimilar region (axis-parallel bounding boxes) between the left and the right halves of a brain in an axial view MR slice. This change detection process uses a novel score function based on Bhattacharya coefficient computed with gray level intensity histograms. We prove that this score function admits a very fast (linear in image height and width) search to locate the bounding box. The average dice coefficients for localizing brain tumors and edemas, over ten patient studies, are 0.57 and 0.52, respectively, which significantly exceeds the scores for two other competitive region-based bounding box techniques.	active contour model;anomaly detection;apache axis;approximation algorithm;archive;axis vertebra;brain neoplasms;circumscribe (action);cluster analysis;coefficient;contour line;database;edema;graph cuts in computer vision;grayscale;guided imagery;heuristic;heuristics;histogram;hospital admission;image registration;indexes;informatics (discipline);jaccard index;machine learning;mean shift;medial graph;medical records systems, computerized;minimum bounding box;optic axis of a crystal;patients;real-time computing;resonance;segmentation action;subgroup;unsupervised learning;biologic segmentation;funding grant;statistical cluster;width	Baidya Nath Saha;Nilanjan Ray;Russell Greiner;Albert Murtha;Hong Zhang	2012	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2011.06.001	simulation;speech recognition;computer science;artificial intelligence	ML	36.145300901363	-77.55650628384596	73785
88a6892ef63b57555ac2481e0fffeda25e52c305	automated detection and classification of liver fibrosis stages using contourlet transform and nonlinear features	computer-aided diagnosis;contourlet transform;liver fibrosis;probabilistic neural network;texture features	BACKGROUND AND OBJECTIVE Liver fibrosis is a type of chronic liver injury that is characterized by an excessive deposition of extracellular matrix protein. Early detection of liver fibrosis may prevent further growth toward liver cirrhosis and hepatocellular carcinoma. In the past, the only method to assess liver fibrosis was through biopsy, but this examination is invasive, expensive, prone to sampling errors, and may cause complications such as bleeding. Ultrasound-based elastography is a promising tool to measure tissue elasticity in real time; however, this technology requires an upgrade of the ultrasound system and software. In this study, a novel computer-aided diagnosis tool is proposed to automatically detect and classify the various stages of liver fibrosis based upon conventional B-mode ultrasound images.   METHODS The proposed method uses a 2D contourlet transform and a set of texture features that are efficiently extracted from the transformed image. Then, the combination of a kernel discriminant analysis (KDA)-based feature reduction technique and analysis of variance (ANOVA)-based feature ranking technique was used, and the images were then classified into various stages of liver fibrosis.   RESULTS Our 2D contourlet transform and texture feature analysis approach achieved a 91.46% accuracy using only four features input to the probabilistic neural network classifier, to classify the five stages of liver fibrosis. It also achieved a 92.16% sensitivity and 88.92% specificity for the same model. The evaluation was done on a database of 762 ultrasound images belonging to five different stages of liver fibrosis.   CONCLUSIONS The findings suggest that the proposed method can be useful to automatically detect and classify liver fibrosis, which would greatly assist clinicians in making an accurate diagnosis.		U. Rajendra Acharya;U. Raghavendra;Joel E. W. Koh;Kristen M. Meiburger;Edward J. Ciaccio;Yuki Hagiwara;Filippo Molinari;Wai Ling Leong;Anushya Vijayananthan;Nur Adura Yaakup;Mohd Kamil Bin Mohd Fabell;Chai Hong Yeong	2018	Computer methods and programs in biomedicine	10.1016/j.cmpb.2018.10.006	artificial intelligence;cirrhosis;computer vision;contourlet;pattern recognition (psychology);elastography;computer science;fibrosis;probabilistic neural network;liver injury;kernel fisher discriminant analysis	SE	34.931944867820654	-76.66736663785929	73945
2443ff5c1e95f000cc2206da6c661944a535cdd8	paediatric frontal chest radiograph screening with fine-tuned convolutional neural networks		Within developing countries, there is a realistic need for technologies that can assist medical practitioners in meeting the increasing demand for patient screening and monitoring. To this end, computer aided diagnosis (CAD) based approaches to chest radiograph screening can be utilised in areas where there is a high burden of diseases such as tuberculosis and pneumonia. In this work, we investigate the efficacy of a purely data-driven approach to chest radiograph classification through the use of fine-tuned convolutional neural networks (CNN). We use two popular CNN models that are pre-trained on a large natural image dataset and two distinct datasets containing paediatric and adult radiographs respectively. Evaluation is performed using a 5-fold cross-validation analysis at an image level. The promising results, with top AUC metrics of 0.87 and 0.84 for the respective datasets, along with several characteristics of our data-driven approach motivate for the use of fine-tuned CNN models within this application of CAD.	convolutional neural network;neural networks;radiography	Jonathan Gerrand;Quentin Williams;Dalton Lunga;Adam Pantanowitz;Shabir A Madhi;Nasreen Mahomed	2017		10.1007/978-3-319-60964-5_74	fine-tuning;computer vision;convolutional neural network;chest radiograph;computer-aided diagnosis;speech recognition;artificial intelligence;medicine	ML	32.08879942115242	-76.34647814488058	74218
10c8a5375ebbf041f747db3baabeb98c1a1afb62	melanoma recognition using extended set of descriptors and classifiers	signal image and speech processing;biometrics;pattern recognition;image processing and computer vision	The paper presents a novel method of melanoma recognition on the basis of dermoscopic images. We use color images of skin lesions, advanced image processing, and different classifiers to distinguish melanoma from the other non-melanoma lesions. Different families of descriptors are used for generation of the image diagnostic features for final pattern recognition. To increase the efficiency of the system, we apply different selection procedures to find the best set of features and different solutions of classifier. The numerical results concerning the accuracy of the proposed recognition system have confirmed good accuracy of the proposed method and high sensitivity in melanoma recognition.	color;image processing;numerical analysis;pattern recognition;statistical classification	Michal Kruk;Bartosz Swiderski;Stanislaw Osowski;Jaroslaw Kurek;Monika Slowinska;Irena Walecka	2015	EURASIP J. Image and Video Processing	10.1186/s13640-015-0099-9	computer vision;speech recognition;feature;computer science;archaeology;pattern recognition;three-dimensional face recognition;biometrics	Vision	34.42227763281297	-74.04604317274666	74382
a27a15c210457643f32d4c57689ffb3e5e3319da	improvement on predicting employee behaviour through intelligent techniques	academic firms;convolution neural network;decision tree;naive bayes;employee performance;fr nearest neighbours;cnn classifiers;kurdistan iraq;fuzzy rough set theory;frnn classifiers;employee behaviour prediction;frnn;value on returns;intelligent techniques;feature selection method	In recent times, there has been increasing awareness of employee behaviour prediction in healthcare, trade, and industry systems worldwide and its value on returns and profits of these systems. Nevertheless, determining the top employees with capacities and endorsing them for promotion is depending more or less on features which are dynamic and serving these systems’ interest. The current structure in organising and academic firms in Kurdistan-Iraq is non-systematic and manually performed; thus, the evaluation of employees’ behaviours is carried out by the directors at different branches, sections, and subsections; as a result, in some cases the outcomes of employees’ performance cause a low level of acceptance among staffs who believe that most of these cases are falsely assessed. This study suggests an intelligent and vigorous structure to examine performance of employees. It aims at presenting a solution to employee behaviour prediction through a joint effective feature selection method, then fuzzy rough (FR) set theory is used to select relevant features, next the classification task is conducted via FR nearest neighbours (FRNNs), decision tree, Naive Bayes, and convolution neural network (CNN). FRNN and CNN classifiers have the best classification accuracy rate.		Tarik A. Rashid;Asia L. Jabar	2016	IET Networks	10.1049/iet-net.2015.0106	engineering;artificial intelligence;machine learning;data mining	Robotics	32.969685175505596	-76.26859860351603	74388
8d113b6960b2664db0382a3ff3c96f7ce47bf1ff	alveolar bone-loss area detection in periodontitis radiographs using hybrid of intensity and texture analyzed based on fbm model	biomedical imaging;radiography abstracts biomedical imaging bones;radiography;bones;leave one out cross validation periapical radiograph alveolar bone loss fbm model periodontitis receiver operating characteristics curve;abstracts;otsu auto thresholding alveolar bone loss area detection fbm model dental periapical radiographs abl ifbm fractal brownian motion model fbm model receiver operating characteristics curve roc curve leave one out cross validation mechanism periodontitis radiograph images feature image segmentation histogram near bimodal distribution;statistical distributions brownian motion dentistry diagnostic radiography fractals image segmentation medical image processing sensitivity analysis	Automatic detection of alveolar bone-loss areas in dental periapical radiographs is a very challenging task because of the common uneven illumination problem of dental radiographs and complex topology of bone-loss areas. In this paper, we propose an effective automatic detection method ABL-IfBm, which uses weighted average of both the intensity and the texture measured by the H-value of fractal Brownian motions (fBm) model. The weights are trained with receiver operating characteristics (ROC) curve based on leave-one-out cross validation mechanism and the principle of the minimum area under the ROC curve (AUC). Through the weighted average of both features, radiograph images are transformed into feature images with the histogram near bimodal distribution. Finally, feature images are segmented into normal and bone-loss regions by Otsu's auto-thresholding. We test on eight periodontitis radiograph images using the proposed ABL-IfBm, the methods with only the feature of fBm-H or the intensity, and a method based on level set segmentation, respectively. Experimental results showed that among all the test methods, our proposed ABL-IfBm has the highest average TPVF and the lowest average FPVF, when compared with the ground truth (GT) provided by dentists.	brownian motion;fractal;ground truth;openedge advanced business language (abl);otsu's method;radiography;receiver operating characteristic;thresholding (image processing)	Po-Whei Huang;Po-Ying Huang;Phen-Lan Lin;Hui-Chieh Hsu	2014	2014 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2014.7009656	medical imaging;computer vision;radiography	Robotics	36.204666976016064	-76.13714500093404	74450
16b4709aacce2eb58e4eb1ea868322c7ec8961f7	analyzing the evolution of breast tumors through flow fields and strain tensors		Breast cancer is one of the most perilous diseases that annually attack thousands of women. Physicians usually monitor the breast tumor changes during the course of a chemotherapy treatment. Computer programs may help physicians to predict the pathological response in order to adjust the medical treatment to produce the intended effects. This paper proposes a method for quantifying and visualizing the changes of breast tumors of cases undergoing medical treatment through strain tensors. The proposed method determines the displacement fields between each follow-up mammogram and its baseline. To compute the displacement fields, we evaluated the performance of eight robust and recent optical flow methods through landmark-based error and statistical analysis. Since, there is no ground truth to evaluate the optical flow methods when they are applied to mammograms, we propose to aggregate the best optical flow methods using ordered weighted averaging operators. The aggregated optical flow methods using the ‘as many as possible’ operator yields the smallest landmark-based error among three aggregation approaches analyzed with the proposed algorithm. The resulting optical flow is then used to estimate the strain tensors. The proposed method provides a good quantification and visualization for breast tumor changes and that helps physicians to plan treatment for their patients. c © 2016 Elsevier Ltd. All rights reserved.	aggregate data;algorithm;baseline (configuration management);centrality;charge trap flash;displacement mapping;elastography;emoticon;error detection and correction;ground truth;image registration;median filter;nl (complexity);optical flow;preprocessor;super-resolution imaging;valence bond programs	Mohamed Abdel-Nasser;Antonio Moreno;Hatem A. Rashwan;Domenec Puig	2017	Pattern Recognition Letters	10.1016/j.patrec.2016.11.003	simulation	Vision	37.31217801945517	-80.08799669415491	74535
31882ade372c9ea233237b4c2e6502657b1981f0	detection of brain tumor margins using optical coherence tomography		In brain cancer surgery, it is critical to achieve extensive resection without compromising adjacent healthy, non-cancerous regions. Various technological advances have made major contributions in imaging, including intraoperative magnetic imaging (MRI) and computed tomography (CT). However, these technologies have pros and cons in providing quantitative, real-time and three-dimensional (3D) continuous guidance in brain cancer detection. Optical Coherence Tomography (OCT) is a non-invasive, label-free, cost-effective technique capable of imaging tissue in three dimensions and real time. The purpose of this study is to reliably and efficiently discriminate between non-cancer and cancer-infiltrated brain regions using OCT images. To this end, a mathematical model for quantitative evaluation known as the Blind End- Member and Abundances Extraction method (BEAE). This BEAE method is a constrained optimization technique which extracts spatial information from volumetric OCT images. Using this novel method, we are able to discriminate between cancerous and non-cancerous tissues and using logistic regression as a classifier for automatic brain tumor margin detection. Using this technique, we are able to achieve excellent performance using an extensive cross-validation of the training dataset (sensitivity 92.91% and specificity 98.15%) and again using an independent, blinded validation dataset (sensitivity 92.91% and specificity 86.36%). In summary, BEAE is well-suited to differentiate brain tissue which could support the guiding surgery process for tissue resection.	tomography	Ronald M. Juarez-Chambi;Carmen Kut;Jesus Rico-Jimenez;Daniel U. Campos-Delgado;Alfredo Quinones-Hinojosa;Xingde Li;Javier A. Jo	2018		10.1117/12.2293599	image-guided surgery;computer vision;computed tomography;optical coherence tomography;resection;brain tumor;computer science;artificial intelligence	ML	36.14651590196839	-79.03092486234564	74737
d0ab856e11e3314384fee03fd93b8968be274577	automatic recognition and validation of the common carotid artery wall segmentation in 100 longitudinal ultrasound images: an integrated approach using feature selection, fitting and classification	integrated approach;human interaction;imt;ultrasound;arteries;training;linear discriminator;segmentation;classification;geometric feature;common carotid artery;ultrasound imaging;carotid artery;feature extraction;region of interest;computing systems;algorithms;feature selection;ground truth;ultrasonography	Most of the algorithms for the common carotid artery (CCA) segmentation require human interaction. The aim of this study is to show a novel accurate algorithm for the computer-based automated tracing of CCA in longitudinal B-Mode ultrasound images. One hundred ultrasound B-Mode longitudinal images of the CCA were processed to delineate the region of interest containing the artery. The algorithm is based on geometric feature extraction, line fitting, and classification. Output of the algorithm is the tracings of the near and far adventitia layers. Performance of the algorithm was validated against human tracings (ground truth) and benchmarked with a previously developed automated technique. Ninety-eight images were correctly processed, resulting in an overall system error (with respect to ground truth) equal to 0.18 ± 0.17 mm (near adventitia) and 0.17 ± 0.24 mm (far adventitia). In far adventitia detection, our novel technique outperformed the current standard method, which showed overall system errors equal to 0.07 ± 0.07 mm and 0.49 ± 0.27 mm for near and far adventitia, respectively. We also showed that our new technique is quite insensitive to noise and has performance independent on the subset of images used for training the classifiers. Superior architecture of this methodology could constitute a general basis for the development of completely automatic CCA segmentation strategies.	algorithm;benchmark (computing);feature extraction;feature selection;ground truth;image noise;line fitting;region of interest	Filippo Molinari;Guang Zeng;Jasjit S. Suri	2010		10.1117/12.843979	computer vision;interpersonal relationship;speech recognition;ground truth;feature extraction;biological classification;ultrasound;feature selection;segmentation;region of interest	Vision	34.355123514412746	-76.86969704686638	75012
1c8c522567f0e8091cd9dbb5ed6a57373c55f3fb	multiple subject learning for inter-subject prediction	pattern classification biomedical mri data analysis learning artificial intelligence;data shuffling procedure multiple subject learning multivoxel pattern analysis neuroimaging data analysis behavioral variable imaging patterns intersubject prediction task fmri data single subject kernels multiple kernel learning classifier;kernel training probabilistic logic static var compensators predictive models vectors accuracy	Multi-voxel pattern analysis has become an important tool for neuroimaging data analysis by allowing to predict a behavioral variable from the imaging patterns. However, standard models do not take into account the differences that can exist between subjects, so that they perform poorly in the inter-subject prediction task. We here introduce a model called Multiple Subject Learning (MSL) that is designed to effectively combine the information provided by fMRI data from several subjects; in a first stage, a weighting of single-subject kernels is learnt using multiple kernel learning to produce a classifier; then, a data shuffling procedure allows to build ensembles of such classifiers, which are then combined by a majority vote. We show that MSL outperforms other models in the inter-subject prediction task and we discuss the empirical behavior of this new model.	multiple kernel learning;pattern recognition;voxel	Sylvain Takerkart;Liva Ralaivola	2014	2014 International Workshop on Pattern Recognition in Neuroimaging	10.1109/PRNI.2014.6858548	computer science;machine learning;pattern recognition;data mining	ML	24.719067164172184	-77.24185879935324	75043
44baae6c5cfe3584f8c5ea1eb44521752450dbf0	nuclei detection and segmentation of fluorescence microscopy images using three dimensional convolutional neural networks		Recent advance in fluorescence microscopy enables acquisition of 3D image volumes with better quality and deeper penetration into tissue. In this paper, we describe a 3D method which can detect and segment nuclei in fluorescence microscopy images using convolutional neural networks (CNN). For nuclei detection, a 3D adaptive histogram equalization, a 3D distance transform, and a 3D classification CNN are used to find centers of nuclei. For nuclei segmentation, a 3D segmentation CNN is used which is trained from automatically generated synthetic microscopy volumes and their synthetic ground truth volumes. Our method outperforms other 3D segmentation methods and can detect nuclei successfully on multiple data sets.	adaptive histogram equalization;artificial neural network;convolutional neural network;distance transform;ground truth;synthetic intelligence	David Joon Ho;Chichen Fu;Paul Salama;Kenneth W. Dunn;Edward J. Delp	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363606	adaptive histogram equalization;fluorescence microscope;convolutional neural network;computer vision;microscopy;pattern recognition;artificial intelligence;distance transform;ground truth;segmentation;computer science	Vision	31.259609639212353	-74.94553077057323	75060
bd62b335f92de41362cf7ccecd4aa60835b9727f	automatic segmentation of brain tissue andwhitematter lesions in mri	lesion segmentation;radiology;biological tissues;brain;white matter lesions;white matter;senior citizens;proton density sequences;image segmentation;automatic segmentation;proton density;image classification;brain lesions magnetic resonance imaging image segmentation protons radiology biomedical informatics magnetic resonance senior citizens dementia;indexing terms;inversion recovery sequences;magnetic resonance image;lesions;magnetic resonance;fluid attenuated sequences;k nearest neighbour classifier;medical image processing;magnetic resonance imaging;fluid attenuated inversion recovery;gray matter;brain imaging;dementia;similarity indices;k nearest neighbour;t1 weighted sequences;brain images;brain tissue;biomedical informatics;medical image processing biological tissues biomedical mri brain image classification image segmentation image sequences;lesion segmentation automatic segmentation brain tissue white matter lesions magnetic resonance imaging cerebrospinal fluid gray matter white matter brain images proton density sequences t1 weighted sequences fluid attenuated sequences inversion recovery sequences k nearest neighbour classifier similarity indices;protons;biomedical mri;image sequences;cerebrospinal fluid	A method to automatically segment cerebrospinal fluid, gray matter, white matter and white matter lesions is presented. The method uses magnetic resonance brain images from proton density. T1-weighted and fluid-attenuated inversion recovery sequences. The method is based on an automatically trained k-nearest neighbour classifier extended with an additional step for the segmentation of white matter lesions. On six datasets, segmentations are quantitatively compared with manual segmentations, which have been carried out by two expert observers. For the tissues, similarity indices between method and observers approximate those between manual segmentations. Reasonably good lesion segmentation results are obtained compared to interobserver variability	approximation algorithm;inter-rater reliability;k-nearest neighbors algorithm;naive bayes classifier;resonance;spatial variability	Renske de Boer;Fedde van der Lijn;Henri A. Vrooman;Meike W. Vernooij;M. Arfan Ikram;Monique M. B. Breteler;Wiro J. Niessen	2007	2007 4th IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2007.356936	computer vision;contextual image classification;index term;radiology;medicine;pathology;magnetic resonance imaging;image segmentation;fluid-attenuated inversion recovery;nuclear medicine;proton	Vision	38.373829899343924	-79.76294779371881	75173
53aba37dce3a4053208d6fcc87451dfc1ce3fd59	automatic diagnosis of pulmonary nodules using a hierarchical extreme learning machine model		To effectively improve the diagnosis of pulmonary nodules, this paper proposes a new automatic diagnosis method for pulmonary nodules based on a new hierarchical extreme learning machine (H-ELM) that can automatically carry out feature extraction, model training and pulmonary nodule detection. In our method, an adaptive histogram equalisation is used first to enhance contrast of the original pulmonary nodule image. The processed images are then input into an extreme learning machine (ELM)-based unsupervised multilayer auto-encoder to obtain more compact and meaningful high-level features of the pulmonary nodule image. Finally, supervised feature classification, which uses these high-level features of the pulmonary nodule as input data, is implemented using the ELM classifier. In the experiments, 2,800 pulmonary nodule images are used to validate the proposed method, and compared with existing pulmonary nodule diagnosis methods, our proposed method is more accurate and less time consuming and effectively a...		Rui Hao;Zilin Qiang;Yan Qiang;Lei Ge;Juanjuan Zhao	2018	IJBIC	10.1504/IJBIC.2018.10012978	artificial intelligence;machine learning;computer-aided diagnosis;feature extraction;extreme learning machine;equalization;mathematics;classifier (linguistics);histogram	AI	32.58326308869743	-74.78226973335464	75495
7b9a37e9fcccd90f11814724d29c841e0305f471	progression detection of glaucoma from polarimetric images	retinal nerve fiber layer;global change	Detecting glaucoma progression is crucial for assessing the effectivity of the treatment. This paper describes three methods for detecting progression related changes in polarimetric images of the retinal nerve fiber layer (NFL), both on a global and on a local scale. Detecting global changes proved not to be feasible due to poor reproducibility of the measurements at the pixel level. Local progression on the other hand could be detected. A distribution based approach did not work, but locating specific areas with minimum size and minimum NFL decrease did give relevant results. The described algorithm yielded a TPR of 0.42 and an FPR of 0.095 on our datasets. It proved to be able to outline suspect areas that show NFL reduction.	algorithm;coherence (physics);color gradient;film-type patterned retarder;ground truth;nfl;pixel;polarimetry;randomness;sensor	Koen A. Vermeer;N. J. Reus;Frans Vos;Hans G. Lemij;Albert M. Vossepoel	2003		10.1007/978-3-540-39903-2_75	computer vision;computer science;global change	ML	36.5217471167958	-76.70811262039729	75698
fda579ec1a8a22b10e1ca159906fb731ccb34c80	unsupervised caries detection in non-standardized bitewing dental x-rays		In recent years dental image processing has become a useful tool in aiding healthcare professionals diagnose patients. Despite advances in the field, accurate diagnoses are still problematic due to the non-uniform nature of dental X-rays. This is attributed to current systems utilizing a supervised learning model for their deterministic algorithm when identifying caries. This paper presents a method for the detection of caries across a variety of non-uniform X-ray images using an unsupervised learning model. This method aims to identify potential caries hallmarks within a tooth without comparing against a set of criteria learned from a database of images. The results show the viability of an unsupervised learning approach and the effectiveness of the method when compared to the supervised approaches.		Darren Osterloh;Serestina Viriri	2016		10.1007/978-3-319-50835-1_58	computer science;artificial intelligence;image processing;pattern recognition;supervised learning;thresholding;unsupervised learning;deterministic algorithm;active contour model	Vision	32.08365092639466	-74.65479806134623	75826
f479ea1b81f8908e5b1e1bb729e1312bb943659d	classification and numbering of teeth in multi-slice ct images using wavelet-fourier descriptor	feed forward neural network;forensic medicine;level set;morphological operation;teeth segmentation;variational level set;feature vector;fourier descriptors;dental ct;feature extraction;wavelet fourier descriptors;medical application;teeth classification;multi resolution;automatic classification	Teeth arrangement is essential in face ergonomics and healthiness. In addition, they play key roles in forensic medicine. Various computer-assisted procedures for medical application in quantitative dentistry require automatic classification and numbering of teeth in dental images. In this paper, we propose a multi-stage technique to classify teeth in multi-slice CT (MSCT) images. The proposed algorithm consists of the following three stages: segmentation, feature extraction and classification. We segment the teeth by employing several techniques including Otsu thresholding, morphological operations, panoramic re-sampling and variational level set. In the feature extraction stage, we follow a multi-resolution approach utilizing wavelet-Fourier descriptor (WFD) together with a centroid distance signature. We compute the feature vector of each tooth by employing the slice associated with largest tooth tissues. The feature vectors are employed for classification in the third stage. We perform teeth classification by a conventional supervised classifier. We employ a feed- forward neural network classifier to discriminate different teeth from each other. The performance of the proposed method was evaluated in the presence of 30 different MSCT data sets including 804 teeth. We compare classification results of the WFD technique with Fourier descriptor (FD) and wavelet descriptor (WD) techniques. We also investigate the invariance properties of the WFD technique. Experimental results reveal the effectiveness of the proposed method. We provided an integrated solution for teeth classification in multi-slice CT datasets. In this regard, suggested segmentation technique was successful to separate teeth from each other. The employed WFD approach was successful to discriminate and numbering of the teeth in the presence of missing teeth. The solution is independent of anatomical information such as knowing the sequence of teeth and the location of each tooth in the jaw.	approximation algorithm;artificial neural network;biological neural networks;body tissue;ct scan;calculus of variations;coefficient;crown group;dental arch structure;experience;feature extraction;feature vector;feedforward neural network;forensic medicine;generic drugs;hl7publishingsubsection <operations>;human factors and ergonomics;image scaling;machine learning;mathematical morphology;numerous;odontogenic tissue;otsu's method;overall well being;prostheses, dental, fixed, crown, total, temporary;sampling (signal processing);sampling - surgical action;spectroscopy, fourier transform infrared;stage level 3;statistical classification;test scaling;thresholding (image processing);tooth loss;variational principle;wavelet analysis;algorithm;biologic segmentation;cell transformation;science of ergonomics	Mohammad Hosntalab;Reza Aghaeizadeh Zoroofi;Ali Abbaspour Tehrani-Fard;Gholamreza Shirani	2009	International Journal of Computer Assisted Radiology and Surgery	10.1007/s11548-009-0389-8	computer vision;feedforward neural network;feature vector;feature extraction;computer science;level set;machine learning;pattern recognition;mathematics;dentistry;forensic science	Vision	35.79394293721556	-75.93055228922566	76510
74edcb64ead97308c4d49642f29ef58ef8e1f3da	extraction and application of deformation-based feature in medical images	segmentation;deformation;medical image;feature extraction;mri;pattern recognition	One of the most challenging issues that hinder the development of accurate medical image segmentation system is the insufficiency of features which are relevant to actual anatomical meaning from the images. Although deformation of normal structures caused by compression from abnormal structures has usually been considered as undesired or even a problem to be tackled in medical image segmentation tasks, it is actually relevant to the correlation between normal and pathological structures. With the objective of investigating the feasibility of extracting and applying deformation-based features of such type, we propose an approach to estimate feature from the correlation between brain lateral ventricular (LaV) deformation and tumor and apply the extracted feature for computerized magnetic resonance (MR) image tumor segmentation. Experimental results on feature extraction show the relevancy between LaV deformation and location of tumor; comparative experiments on tumor segmentation suggest that, in most cases, tumor segmentation accuracy improves when the extracted feature is applied.	medical imaging	Kai Xiao;Alei Liang;Haibing Guan;Aboul Ella Hassanien	2013	Neurocomputing	10.1016/j.neucom.2012.08.054	computer vision;feature extraction;computer science;magnetic resonance imaging;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation;segmentation;deformation;feature	Vision	36.96799436587305	-78.75077042607975	76967
c6011844ea9e25debac7321e50574881bccc76a2	tear film classification using phylogenetic diversity indexes as texture descriptor		Dry eye is a common disease that affects the tear film and the ocular surface causing a great variety of symptoms impairing the patient daily activities. The diagnosis of this disease requires a number of tests to evaluate different physiological characteristics. One of the tests captures the appearance of the tear film using the Doane interferometer, which generates images that can be categorized into five groups: strong fringes, coalescing strong fringes, line fringes, coalescing line fringes, and debris. The images can be manually classified by specialists into one of these five groups. The use of automatic systems for the diagnosis of dry eye can assist experts in the classification of these images, contributing to more accurate exams. Therefore, this work presents a method for automatic classification of images from the the lipid layer of the tear film using phylogenetic diversity indexes to extract texture features of the images. The proposed method presents promising results, reaching accuracy rates higher than 96%.	categorization;phylogenetics	L Cruz;Jose Denes Lima Araujo;Johnatan Carvalho Souza;Jefferson Alves de Sousa;João Dallyson Sousa de Almeida;Geraldo Braz Junior;Aristófanes Corrêa Silva;Anselmo Cardoso de Paiva	2018	2018 IEEE Symposium on Computers and Communications (ISCC)	10.1109/ISCC.2018.8538580	distributed computing;feature extraction;texture descriptor;computer science;pattern recognition;phylogenetic diversity;artificial intelligence	Vision	35.29670907522221	-75.89044358397432	77054
30827ddb56400cf998df79667b4d798b24eba334	integration of results from recognition algorithms applied to the uranium deposits	uranium deposit;k nn algorithm;post processing stage;machine learning;artificial neural network		algorithm	Ravil I. Muhamediyev;Yedilkhan Amirgaliyev;Syrymbet Kh. Iskakov;Yan I. Kuchin;Elena Muhamediyeva	2014	JACIII	10.20965/jaciii.2014.p0347	computer science;artificial intelligence;machine learning;data mining;artificial neural network	AI	27.380769208025203	-69.298715759777	77330
468d9769b0bbe3ea4ea0dfea7166ac437cc27f1b	fast background removal in 3d fluorescence microscopy images using one-class learning		With the recent advances of optical tissue clearing technology, current imaging modalities are able to image large tissue samples in 3D with single-cell resolution. However, the severe background noise remains a significant obstacle to the extraction of quantitative information from these high-resolution 3D images. Additionally, due to the potentially large sizes of 3D image data (over 1011 voxels), the processing speed is becoming a major bottleneck that limits the applicability of many known background correction methods. In this paper, we present a fast background removal algorithm for large volume 3D fluorescence microscopy images. By incorporating unsupervised one-class learning into the percentile filtering approach, our algorithm is able to precisely and efficiently remove background noise even when the sizes and appearances of foreground objects vary greatly. Extensive experiments on real 3D datasets show our method has superior performance and efficiency comparing with the current state-of-the-art background correction method and the rolling ball algorithm in ImageJ.		Lin Yang;Yizhe Zhang;Ian H. Guldner;Siyuan Zhang;Danny Ziyi Chen	2015		10.1007/978-3-319-24574-4_35	computer vision	Vision	30.579972877683918	-71.58176379678764	77343
3fef4ae2eb6271e70eadb73ab447e8533c1a919d	partial dependence of breast tumor malignancy on ultrasound image features derived from boosted trees	image features;decision tree;computer aided diagnosis;cancer;ultrasound;breast;receiver operating characteristic curve;ultrasound imaging;medical image;feature extraction;medical image processing;pattern recognition;ultrasonography	Various computerized features extracted from breast ultrasound images are useful in assessing the malignancy of breast tumors. However, the underlying relationship between the computerized features and tumor malignancy may not be linear in nature. We use the decision tree ensemble trained by the cost-sensitive boosting algorithm to approximate the target function for malignancy assessment and to reflect this relationship qualitatively. Partial dependence plots are employed to explore and visualize the effect of features on the output of the decision tree ensemble. In the experiments, 31 image features are extracted to quantify the sonographic characteristics of breast tumors. Patient age is used as an external feature because of its high clinical importance. The area under the receiver-operating characteristic curve of the tree ensembles can reach 0.95 with sensitivity of 0.95 (61/64) at the associated specificity 0.74 (77/104). The partial dependence plots of the four most important features are demonstrated to show the influence of the features on malignancy, and they are in accord with the empirical observations. The results can provide visual and qualitative references on the computerized image features for physicians, and can be useful for enhancing the interpretability of computer-aided diagnosis systems for breast ultrasound.	gradient boosting	Wei Yang;Su Zhang;Wenying Li;Yaqing Chen;Hongtao Lu;Wufan Chen;Yazhu Chen	2010	J. Electronic Imaging	10.1117/1.3385763	computer vision;feature extraction;computer science;ultrasonography;machine learning;decision tree;ultrasound;feature;receiver operating characteristic;cancer	ML	32.72588853389107	-78.13921541987058	77407
43121f7dc23c8dcaa5d802b1919d3f51c01e4615	automated analysis for retinopathy of prematurity by deep neural networks		Retinopathy of Prematurity (ROP) is a retinal vasproliferative disorder disease principally observed in infants born prematurely with low birth weight. ROP is an important cause of childhood blindness. Although automatic or semi-automatic diagnosis of ROP has been conducted, most previous studies have focused on “plus” disease, which is indicated by abnormalities of retinal vasculature. Few studies have reported methods for identifying the “stage” of the ROP disease. Deep neural networks have achieved impressive results in many computer vision and medical image analysis problems, raising expectations that it might be a promising tool in the automatic diagnosis of ROP. In this paper, convolutional neural networks with a novel architecture are proposed to recognize the existence and severity of ROP disease per-examination. The severity of ROP is divided into mild and severe cases according to the disease progression. The proposed architecture consists of two sub-networks connected by a feature aggregate operator. The first sub-network is designed to extract high-level features from images of the fundus. These features from different images in an examination are fused by the aggregate operator, then used as the input for the second sub-network to predict its class. A large data set imaged by RetCam 3 is used to train and evaluate the model. The high classification accuracy in the experiment demonstrates the effectiveness of the proposed architecture for recognizing the ROP disease.		Junjie Hu;Yuanyuan Chen;Jie Zhong;Rong Ju;Zhang Yi	2018	IEEE Transactions on Medical Imaging	10.1109/TMI.2018.2863562		Vision	32.3543930068614	-76.12592504799655	77485
a483205ec1f7922f82cfaedfaac8462b9a851127	automated adaptive brightness in wireless capsule endoscopy using image segmentation and sigmoid function	wireless capsule endoscopy adaptive illumination automatic brightness control pulse width modulation sigmoid function;image segmentation;mirocam automated adaptive brightness wireless capsule endoscopy image segmentation gastrointestinal disease diagnosis image capturing human small intestine frame rate image quality illumination system light source light emitting diodes led brightness power consumption optimized brightness level adaptive sigmoid function capsule prototype pillcam;light emitting diodes;brightness;brightness light emitting diodes lighting endoscopes image segmentation power demand hardware;endoscopes;lighting;power demand;medical image processing biological organs biomedical optical imaging brightness diseases endoscopes image segmentation light emitting diodes low power electronics;hardware	Wireless capsule endoscopy (WCE) plays an important role in the diagnosis of gastrointestinal (GI) diseases by capturing images of human small intestine. Accurate diagnosis of endoscopic images depends heavily on the quality of captured images. Along with image and frame rate, brightness of the image is an important parameter that influences the image quality which leads to the design of an efficient illumination system. Such design involves the choice and placement of proper light source and its ability to illuminate GI surface with proper brightness. Light emitting diodes (LEDs) are normally used as sources where modulated pulses are used to control LED's brightness. In practice, instances like under- and over-illumination are very common in WCE, where the former provides dark images and the later provides bright images with high power consumption. In this paper, we propose a low-power and efficient illumination system that is based on an automated brightness algorithm. The scheme is adaptive in nature, i.e., the brightness level is controlled automatically in real-time while the images are being captured. The captured images are segmented into four equal regions and the brightness level of each region is calculated. Then an adaptive sigmoid function is used to find the optimized brightness level and accordingly a new value of duty cycle of the modulated pulse is generated to capture future images. The algorithm is fully implemented in a capsule prototype and tested with endoscopic images. Commercial capsules like Pillcam and Mirocam were also used in the experiment. The results show that the proposed algorithm works well in controlling the brightness level accordingly to the environmental condition, and as a result, good quality images are captured with an average of 40% brightness level that saves power consumption of the capsule.	adaptive algorithm;algorithm;capsule endoscopy;diode;display resolution;duty cycle;gastrointestinal hemorrhage;illumination (image);image quality;image segmentation;immunoglobulin kappa-chains;low-power broadcasting;modulation;population parameter;prototype;real-time computing;real-time locating system;sigmoid colon;sigmoid function;small intestinal wall tissue;biologic segmentation;brightness;capsule (pharmacologic)	Ravi Shrestha;Shahed Khan Mohammed;Md. Mehedi Hasan;Xuechao Zhang;Khan A. Wahid	2016	IEEE Transactions on Biomedical Circuits and Systems	10.1109/TBCAS.2016.2546838	computer vision;computer science;engineering;electrical engineering;optoelectronics;lighting;image segmentation;optics;brightness;physics;light-emitting diode	Vision	38.99818016988296	-75.50741863965105	78281
96d630c8e12d5bcebbf415cca5c85ec1758e9f58	cracked tongue recognition based on deep features and multiple-instance svm		Cracked tongue can provide valuable diagnostic information for traditional Chinese Medicine doctors. However, due to similar model of real and fake tongue crack, cracked tongue recognition is still challenging. The existing methods make use of handcraft features to classify the cracked tongue which leads to inconstant performance when the length or width of crack is various. In this paper, we pay attention to localized cracked regions of the tongue instead of the whole tongue. We train the Alexnet by using cracked regions and non-cracked regions to extract deep feature of cracked region. At last, cracked tongue recognition is considered as a multiple instance learning problem, and we train a multiple-instance Support Vector Machine (SVM) to make the final decision. Experimental results demonstrate that the proposed method performs better than the method extracting handcraft features.		Yushan Xue;Xiaoqiang Li;Qing Cui;Lu Wang;Pin Wu	2018		10.1007/978-3-030-00767-6_59	support vector machine;computer vision;feature extraction;artificial intelligence;computer science;tongue;pattern recognition	Vision	33.15808991363814	-74.79500414464943	78538
fd4acadc885c76ad661d7b39773993e7fc5b8eb3	tumor segmentation from a multispectral mri images by using support vector machine classification	biological tissues;brain;tumor region extraction tumor segmentation multispectral mri images support vector machine classification t1 mri t2 mri proton density fluid attenuated inversion recovery;image segmentation;tumours biomedical mri image classification image segmentation support vector machines;support vector machines;tumor segmentation;proton density;tumours;image classification;fuzzy logic;multispectral mri images;magnetic resonance imaging;t1 mri;tumor region extraction;fluid attenuated inversion recovery;support vector machine classification;robustness;neoplasms image segmentation magnetic resonance imaging support vector machine classification support vector machines biological tissues robustness brain fuzzy logic protons;support vector machine;neoplasms;t2 mri;protons;biomedical mri	The goal of this paper is to present a supervised system aimed at tracking the tumor volume during a therapeutic treatment from multispectral MRI volumes. Four types of MRI are used in our study: T1, T2, proton density (PD) and fluid attenuated inversion recovery (FLAIR). For decreasing the processing time, the proposed method employs a multi-scale scheme to identify firstly the abnormal field and extract then the tumor region. Both steps use support vector machines (SVMs). The training is carried out only on the first MRI examination (at the beginning of the treatment). The tracking process at the time point t takes the tumor region obtained in the examination at t-1 as its initialization. Only the second step is performed for others examinations to extract the tumor region. The results obtained show that the proposed system achieves promising results in terms of effectiveness and time consuming.	multispectral image;supervised learning;support vector machine	Su Ruan;Stéphane Lebonvallet;Abderrahim Merabet;Jean-Marc Constans	2007	2007 4th IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2007.357082	support vector machine;computer vision;computer science;magnetic resonance imaging;machine learning;pattern recognition	Vision	35.068821441111375	-75.99480837069011	78709
372477e0630601d69a3c1e374fa0a72e6d07489d	automatic bifurcation detection in coronary ivus sequences	sensitivity and specificity;female;intravascular ultrasound sequence;support vector machines;bifurcation;middle aged;lesion automatic bifurcation detection coronary ivus sequences intravascular ultrasound sequence two level classification scheme textural feature extraction image sequence discriminative classifier adaboost random forest support vector machine branching detection task contextual information multiscale stacked sequential learning scheme pullback sequences;arteries;training;male;image classification;contextual information;trees mathematics;texture features;coronary vessels;texture analysis contextual classification coronary bifurcations intravascular ultrasound ivus;lesion;ultrasonography interventional;multiscale stacked sequential learning scheme;image texture;coronary artery disease;image enhancement;texture analysis;two level classification scheme;image interpretation computer assisted;feature extraction;medical image processing;adult;blood;catheters;image sequence;random forest;pullback sequences;random processes;adult aged aged 80 and over algorithms artificial intelligence coronary artery disease coronary vessels echocardiography female humans image enhancement image interpretation computer assisted male middle aged pattern recognition automated reproducibility of results sensitivity and specificity subtraction technique ultrasonography interventional;reproducibility of results;adaboost;branching detection task;trees mathematics bifurcation biomedical ultrasonics blood vessels cardiovascular system image classification image sequences image texture learning artificial intelligence medical image processing random processes support vector machines;echocardiography;artificial intelligence;algorithms;a priori information;textural feature extraction;pattern recognition automated;cardiovascular system;humans;support vector machine;subtraction technique;coronary ivus sequences;coronary bifurcations;learning artificial intelligence	In this paper, we present a fully automatic method which identifies every bifurcation in an intravascular ultrasound (IVUS) sequence, the corresponding frames, the angular orientation with respect to the IVUS acquisition, and the extension. This goal is reached using a two-level classification scheme: first, a classifier is applied to a set of textural features extracted from each image of a sequence. A comparison among three state-of-the-art discriminative classifiers (AdaBoost, random forest, and support vector machine) is performed to identify the most suitable method for the branching detection task. Second, the results are improved by exploiting contextual information using a multiscale stacked sequential learning scheme. The results are then successively refined using a-priori information about branching dimensions and geometry. The proposed approach provides a robust tool for the quick review of pullback sequences, facilitating the evaluation of the lesion at bifurcation sites. The proposed method reaches an F-Measure score of 86.35%, while the F-Measure scores for inter- and intraobserver variability are 71.63% and 76.18%, respectively. The obtained results are positive. Especially, considering the branching detection task is very challenging, due to high variability in bifurcation dimensions and appearance.	adaboost;anatomic bifurcation;anatomical orifice;angularjs;automatic identification and data capture;bifurcation theory;blood vessel tissue;cellular automaton;dimensions;discriminative model;extraction;f1 score;frame (physical object);hydrodynamics;incidence matrix;intravascular ultrasound;pattern recognition;random forest;senile plaques;spatial variability;stent, device;support vector machine;transmitter power output;x-ray (amazon kindle)	Marina Alberti;Simone Balocco;Carlo Gatta;Francesco Ciompi;Oriol Pujol;Joana Silva;Xavier Carrillo;Petia Radeva	2012	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2011.2181372	stochastic process;support vector machine;computer vision;speech recognition;computer science;machine learning;pattern recognition	Vision	35.43900387513961	-78.20214220804031	78804
72f54f0b8f9c5527e5d3c05f309c15a0a927306b	adaptive compression of dicom-image data	dicom-format;jpeg;vector quantization;classification;wavelet transformation;image;compression;spectrum;java;wavelets;region of interest;digital imaging;high frequency;modeling;image classification;algorithms;bits per pixel;numerical method;digital image;wavelet transform	In this article a method to classify digital images into three categories based on a provisional analysis of the image content and a subsequent compression with the help of a suitable algorithm of compression is proposed. To classify the images two parameters are used. The first parameter carries the frequency information about the image. It represents the mean of the absolute amplitude of the Wavelet coeff icients in the high frequency parts of the spectrum. The second parameter is an indicator concerning information about the structure of the image. The second parameter is constituted through the entropy of the length of the segments in one line and the entropy of the length of the segments in one column. In this article the results for the check of those classification rules for DICOM images are given as a confirmation of the effectivness of the method proposed. The implementation of the image classification algorithm an the compression algorithms in the modelli ng process is performed in JAVA	adaptive compression;algorithm;computer vision;dicom;data compression;digital image;java;wavelet	Sergei Hludov;Thomas Engel;Christoph Meinel	1998			computer vision;speech recognition;theoretical computer science;mathematics	Vision	35.65863758487964	-70.97300868402507	78886
24a6e4abfe03887db80eae165f3169f6425f9509	hierarchical and binary spatial descriptors for lung nodule image retrieval	visual databases binary codes cancer data mining feature extraction hierarchical systems image classification information retrieval lung medical image processing medical information systems tumours;lungs biomedical imaging support vector machines image retrieval educational institutions feature extraction robustness;hierarchical spatial descriptor elcap public access database descriptor evaluation rotation invariance lung tumor retrieval domain specific feature descriptor disease tracking content based image retrieval techniques cancer diagnosis cancer staging image data lung nodule image retrieval binary spatial descriptor	With the increasing amount of image data available for cancer staging and diagnosis, it is clear that content-based image retrieval techniques are becoming more important to assist physicians in making diagnoses and tracking disease. Domain-specific feature descriptors have been previously shown to be effective in the retrieval of lung tumors. This work proposes a method to improve the rotation invariance of the hierarchical spatial descriptor, as well as presents a new binary descriptor for the retrieval of lung nodule images. The descriptors were evaluated on the ELCAP public access database, exhibiting good performance overall.	ct scan;content-based image retrieval;diagnostic neoplasm staging;disk staging;domain-specific language;exhibits as topic;feature model;feature vector;hamming distance;local binary patterns;lung neoplasms;medical imaging;nodule;sensor;speeded up robust features;string (computer science);visual descriptor	Gillian Ng;Yang Song;Tom Weidong Cai;Yun Zhou;Sidong Liu;David Dagan Feng	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6945108	computer vision;visual word;computer science;pattern recognition;automatic image annotation;information retrieval	Vision	32.90689531482441	-71.86700979683813	78896
0484ebecf61f93028b4ffd4aba30920ced008aaf	alzheimer disease classification based on tsvm and kernel svm		Alzheimer disease (AD) is the most general cause of dementia, creates significant socioeconomic and health problems. It is the disease of progressive neurodegenerative disorder which causes the structural change in the brain, affects behavioral problems, cognitive acts, and memory despair. Structural brain imaging plays very important role to identify structural change inside brain associated with AD. We present a novel automated approach for classifying AD from HC (Healthy Controls) using dual-tree complex wavelet transforms (DTCWT) principal coefficients from the transaxial slices of MR images, kernel support vector machine, and twin support vector machine. The stratification result we have obtained using proposed method are similar or higher than those achieved by various conventional AD classification approaches mentioned in the paper.	alzheimer's disease neuroimaging initiative;auditory processing disorder;coefficient;kernel (operating system);support vector machine;wavelet transform	Samar Alam;Moonsoo Kang;Goo-Rak Kwon	2017	2017 Ninth International Conference on Ubiquitous and Future Networks (ICUFN)	10.1109/ICUFN.2017.7993852	progressive neurodegenerative disorder;support vector machine;kernel (linear algebra);wavelet transform;computer science;alzheimer's disease;neuroimaging;cognition;machine learning;artificial intelligence;dementia	Robotics	29.807003090428527	-78.42511730049563	79014
99b28cfb48fd2f0d5982c9eb32544a738cc66dcd	discriminative generalized hough transform for object localization in medical images		Purpose   This paper proposes the discriminative generalized Hough transform (DGHT) as an efficient and reliable means for object localization in medical images. It is meant to give a deeper insight into the underlying theory and a comprehensive overview of the methodology and the scope of applications. Methods   The DGHT combines the generalized Hough transform (GHT) with a discriminative training technique for the GHT models to obtain more efficient and robust localization results. To this end, the model points are equipped with individual weights, which are trained discriminatively with respect to a minimal localization error. Through this weighting, the models become more robust since the training focuses on common features of the target object over a set of training images. Unlike other weighting strategies, our training algorithm focuses on the error rate and allows for negative weights, which can be employed to encode rivaling structures into the model. The basic algorithm is presented here in conjunction with several extensions for fully automatic and faster processing. These include: (1) the automatic generation of models from training images and their iterative refinement, (2) the training of joint models for similar objects, and (3) a multi-level approach. Results   The algorithm is tested successfully for the knee in long-leg radiographs (97.6 % success rate), the vertebrae in C-arm CT (95.5 % success rate), and the femoral head in whole-body MR (100 % success rate). In addition, it is compared to Hough forests (Gall et al. in IEEE Trans Pattern Anal Mach Intell 33(11):2188–2202, 2011) for the task of knee localization (97.8 % success rate). Conclusion   The DGHT has proven to be a general procedure, which can be easily applied to various tasks with high success rates.	algorithm;bone structure of spine;comstock–needham system;discriminative model;encode (action);familial generalized lipodystrophy;forests;generalised hough transform;head of femur;iteration;iterative refinement;numerous;physical object;radiography;refinement (computing);weight	Heike Ruppertshofen;Cristian Lorenz;Georg Rose;Hauke Schramm	2013	International Journal of Computer Assisted Radiology and Surgery	10.1007/s11548-013-0817-7	computer vision;simulation;machine learning;mathematics;statistics	Vision	31.20257507476172	-74.1679421604582	79049
d2bdacd1e1a4e88af1a1980e4537e8b2b3fdcbfc	classification using multi-valued pulse coupled neural network	pcnn pulse coupled neural network;multi valued pcnn;pulse waves;classification;2 dimensional;pulse coupled neural network	This paper introduces how to use multi-valued PCNN (Pulse Coupled Neural Network) proposed in this paper to do classification. 2-dimensional data can be projected onto two-dimensional PCNN locally laterally linked. Different pulse waves generated by training data label different regions corresponding to different classes. The same pulse wave labels the region corresponding to the same class. Meeting of different pulse waves obtains the separatrixes of different classes. In order to differentiate different pulse waves, outputs of neurons in PCNN should be multi-valued. We call networks composed of these neurons multi-valued PCNNs. The number of classes determines the number of output value of each neuron.  N -valued PCNN can be used to classify  N-1 different classes. Experimental results of the 2-dimensional salmon-weever classification show that the correct recognition rate of test set is 98.11% (3477/3544) when training samples are only 10% of all samples.	artificial neural network	Xiaodong Gu	2007		10.1007/978-3-540-69162-4_57	two-dimensional space;biological classification;artificial intelligence;machine learning;mathematics	ML	32.50299977677169	-69.61111824709593	79402
868f3dcb39dab2d55ebf12b67615c2c147e95651	svm-based framework for the robust extraction of objects from histopathological images using color, texture, scale and geometry	image color analysis support vector machines shape kernel breast cancer hospitals;probability;support vector machines;cancer;object detection and extraction;tumours;digital histopathology;breast cancer grading;image texture;computer vision;marked point process;stochastic processes;breast cancer grading support vector machine marked point process computer vision object detection and extraction digital histopathology;image colour analysis;medical image processing;breast cancer grading svm object extraction histopathological image color texture scale geometry haematoxylin stained biopsies eosin stained biopsies high grade tumor malignant tumor low grade cancer high grade cancer cell nuclei extraction histological grade support vector machine probabilistic image modality mark point process stochastic method machine learning computer vision;support vector machine;tumours cancer computer vision image colour analysis image texture medical image processing probability stochastic processes support vector machines	The extraction of nuclei from Haematoxylin and Eosin (H&E) stained biopsies present a particularly steep challenge in part due to the irregularity of the high-grade (most malignant) tumors. To your best knowledge, although some existing solutions perform adequately with relatively predictable low-grade cancers, solutions for the problematic high-grade cancers have yet to be proposed. In this paper, we propose a method for the extraction of cell nuclei from H&E stained biopsies robust enough to deal with the full range of histological grades observed in daily clinical practice. The robustness is achieved by combining a wide range of information including color, texture, scale and geometry in a multi-stage, Support Vector Machine (SVM) based framework to replace the original image with a new, probabilistic image modality with stable characteristics. The actual extraction of the nuclei is performed from the new image using Mark Point Processes (MPP), a state-of-the-art stochastic method. An empirical evaluation on clinical data provided and annotated by pathologists shows that our method greatly improves detection and extraction results, and provides a reliable solution with high grade cancers. Moreover, our method based on machine learning can easily adapt to specific clinical conditions. In many respects, our method contributes to bridging the gap between the computer vision technologies and their actual clinical use for breast cancer grading.	bridging (networking);computer vision;goodyear mpp;image texture;machine learning;modality (human–computer interaction);supervised learning;support vector machine;unified framework	Antoine Veillard;Stéphane Bressan;Daniel Racoceanu	2012	2012 11th International Conference on Machine Learning and Applications	10.1109/ICMLA.2012.21	stochastic process;support vector machine;computer vision;computer science;machine learning;pattern recognition;statistics	Vision	32.49904118726336	-74.70048501022802	79417
9ee75775870463519ebff9355c2ed48409710d40	a first approach for the contactless acquisition and automated detection of toolmarks on pins of locking cylinders using 3d confocal microscopy	digital forensics;crime scene forensics;lockpicking;region of interest;pattern recognition;true positive;toolmarks;confocal microscopy;texture recognition	Lockpicking forensics is currently a completely manual process, which requires a lot of skill as well as training and is therefore time-consuming as well as expensive. In this paper we make a first move to transfer the most crucial part of this specific forensic process, the contactless aquisition and analysis of traces on locking pins, into the domain of digitized forensics. To do so, we introduce a new five stage processing methodology for semi- or fully-automated lockpicking forensics. Our methodology consists of: trace positioning, acquisition, detection of traces with segmentation (or region of interest determination), determination of the trace type and the determination of the used opening methods. Within this pipeline the last three stages constitute a hierarchy of pattern recognition (PR) problems. In this paper we propose a solution approach for the Trace Positioning, Contacless Acquisition and the first of the three PR problems - the detection of traces with segmentation (or region of interest determination) on which the other two are depending. To implement this segmentation, we use texture recognition with gray-level-co-occurrence matrices to blockwisely describe the texture imposed by toolmarks with adequate features. By that we are able to distinguish between regions including potential traces and regions without relevant traces. With our presented approaches for an automated contactless acquisition and trace detection, we support and improve the classical manual forensic investigation in the field of lockpicking forensics in regards of effort, objectivity and reliability. Additionally, it creates a solid base for future work dealing with trace type determination and opening method classification. We evaluate our approach with a physical test set of 15 lock pins, from locks opened with three different opening methods. On this limited test set our approach achieves True Positive Rates of up to 85% for the detection of potentially trace wielding regions. This first result, although it still leaves room for improvement, constitutes and shows a positive tendency for a seminal first step towards semi- or fully-automated lockpicking forensics.	computer vision;contactless smart card;lock (computer science);objectivity/db;pattern recognition;region of interest;test set;tracing (software)	Eric Clausing;Christian Krätzer;Jana Dittmann;Claus Vielhauer	2012		10.1145/2361407.2361416	computer vision;engineering;forensic engineering;computer security	Vision	36.15861977087556	-70.22827520497948	79748
5572b4e046fb8eebadc20ac67192e611a249e818	computer-aided detection of bladder mass within contrast-enhanced region of ctu	image segmentation;computer aided diagnosis;biopsy;bladder cancer;bladder;malignancy;feature selection;ct urography	We are developing a computer-aided detection system for bladder cancer on CTU. The bladder was automatically segmented with our Conjoint Level set Analysis and Segmentation System (CLASS). In this preliminary study, we developed a system for detecting mass within the contrast-enhanced (C) region of the bladder. The C region was delineated from the segmented bladders using a method based on maximum intensity projection. The bladder wall of the C region was extracted using thresholding to remove the contrast material. The wall on each slice was transformed into a wall profile. Morphology and voxel intensity along the profile were analyzed and suspicious locations were labeled as lesion candidates. The candidates were segmented and 20 morphological features were extracted from each candidate. A data set of 35 patients with 45 biopsy-proven bladder lesions within the C region was used for system evaluation. Stepwise feature selection with simplex optimization and leave-one-case-out method was used for training and validation. For each partition in the leave-one-case-out method, features were selected from the training cases and a linear discriminant (LDA) classifier was designed to merge the selected features into a single score for classification of the lesion candidates into bladder lesions and normal findings in the left-out case. A single score was generated for each lesion candidate. The performance of the CAD system was evaluated by FROC analysis. At an FP rate of 2.5 FPs/case, the system achieved a sensitivity of 82%, while at 1.7 FPs/case, a sensitivity of 71%. © (2015) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	coding tree unit	Kenny H. Cha;Lubomir M. Hadjiiski;Heang-Ping Chan;Elaine M. Caoili;Richard H. Cohan;Chuan Zhou	2015		10.1117/12.2081472	image segmentation;feature selection	Vision	35.5857020404825	-77.50466122379535	79832
60818d482a4042eb07ca375987a0d003b7701737	identification of breast vascular calcium deposition in digital mammography by linear structure analysis	linear structure analysis method breast vascular calcium deposition identification digital mammography computerized detection vascular calcium depositions cardiovascular diseases bright railway pattern;detectors;manuals;rail transportation;periodic structure;medical image processing blood vessels diagnostic radiography diseases mammography;breast;calcium;digital mammography;calcium breast periodic structures rail transportation detectors diseases manuals;cardiovascular disease;medical image processing;periodic structures;diseases;breast vascular calcification;vascular calcification;linear structure analysis breast vascular calcification mammography;mammography;false positive;diagnostic radiography;blood vessels;structure analysis;linear structure analysis	Computerized detection of vascular calcium depositions in mamagraphy is a new research topics, which is driven by the clinical hypothesis of the association with many related cardiovascular diseases. In several previous studies [7, 9], calcification cue plays a very important role in the computerized analysis. We observe that vascular calcium depositions can be identified with high confidence if they appear in a bright railway pattern. Accordingly, a linear structure analysis method is introduced in this study to detect most true calcifications and also keep the false positives as little as possible. The proposed method is tested with 40 mammograms and achieves performance of 93.8±1.3% in sensitivity and 84.7±3.9% in specificity. The output of this linear structure analysis may provide more reliable calcification cue for the subsequent vessel tracking process, which will be investigated in the future.	physical vapor deposition;sensitivity and specificity	Jie-Zhi Cheng;Chung-Ming Chen;Dinggang Shen	2012	2012 9th IEEE International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2012.6235500	radiology;medicine;calcium;pathology	Arch	37.23482859195182	-77.86350530136244	80089
365eb9ccf468c1a883433cad4d2872cfa7adfe89	comparison of class separability, forward sequential search and genetic algorithms for feature selection in the classification of individual and clustered microcalcifications in digital mammograms	feedforward neural network;sensitivity and specificity;sequential search;genetic algorithm;feature selection;breast cancer	The presence of microcalcification clusters in digital mammograms is a primary indicator of early stages of malignant types of breast cancer and its detection is important to prevent the disease. This paper uses a procedure for the classification of microcalcification clusters in mammograms using sequential Difference of Gaussian filters (DoG) and feedforward Neural Networks (NN). Three methods using class separability, forward sequential search and genetic algorithms for feature selection are compared. We found that the use of Genetic Algorithms (GAs) for selecting the features from microcalcifications and microcalcification clusters that will be the inputs of a feedforward Neural Network (NN) results mainly in improvements in overall accuracy, sensitivity and specificity of the classification.	backpropagation;computation;database;difference of gaussians;feature selection;feedforward neural network;genetic algorithm;image moment;linear search;linear separability;neural network software;sensitivity and specificity;software release life cycle	Rolando R. Hernández-Cisneros;Hugo Terashima-Marín;Santiago E. Conant-Pablos	2007		10.1007/978-3-540-74260-9_81	linear search;feedforward neural network;genetic algorithm;computer science;breast cancer;machine learning;pattern recognition;data mining;feature selection	AI	34.711536649676106	-74.41548292524084	80120
9227fbc52cbacb0b4729ac0ac5b51d911b7b6ca2	comparison of brain–computer interface decoding algorithms in open-loop and closed-loop control	linear estimation;brain computer interface;bayesian inference;prosthetics;closed loop control;off line reconstruction;neural decoding;on line control;cortical neurons	Neuroprosthetic devices such as a computer cursor can be controlled by the activity of cortical neurons when an appropriate algorithm is used to decode motor intention. Algorithms which have been proposed for this purpose range from the simple population vector algorithm (PVA) and optimal linear estimator (OLE) to various versions of Bayesian decoders. Although Bayesian decoders typically provide the most accurate off-line reconstructions, it is not known which model assumptions in these algorithms are critical for improving decoding performance. Furthermore, it is not necessarily true that improvements (or deficits) in off-line reconstruction will translate into improvements (or deficits) in on-line control, as the subject might compensate for the specifics of the decoder in use at the time. Here we show that by comparing the performance of nine decoders, assumptions about uniformly distributed preferred directions and the way the cursor trajectories are smoothed have the most impact on decoder performance in off-line reconstruction, while assumptions about tuning curve linearity and spike count variance play relatively minor roles. In on-line control, subjects compensate for directional biases caused by non-uniformly distributed preferred directions, leaving cursor smoothing differences as the largest single algorithmic difference driving decoder performance.	algorithm;bayesian network;binary decoder;brain–computer interface;compiler;control theory;cursor (databases);decoder device component;departure - action;directional coronary atherectomy;interface device component;largest;linear iga bullous dermatosis;neuroprosthetics;online and offline;population vector;sample variance;smoothing (statistical technique);version	Shinsuke Koyama;Steven M. Chase;Andrew S. Whitford;Meel Velliste;Andrew B. Schwartz;Robert E. Kass	2009	Journal of Computational Neuroscience	10.1007/s10827-009-0196-9	psychology;brain–computer interface;neuroscience;simulation;neural decoding;computer science;theoretical computer science;machine learning;bayesian inference;statistics	ML	24.62162445073783	-72.66467819940446	80269
55d4dbf4d2ebce484eed12b96adab926d6e22a9e	detection of breast lesions in medical digital imaging using neural networks	neural nets;objeto de conferencia;diagnostico por imagen;ciencias informaticas;architectures;digital image;neural network	The purpose of this article is to present an experimental application for the detection of possible breast lesions by means of neural networks in medical digital imaging. This application broadens the scope of research into the creation of different types of topologies with the aim of improving existing networks and creating new architectures which allow for improved detection.	digital imaging;network topology;neural networks	Gustavo Ferrero;Paola Britos;Ramón García-Martínez	2006		10.1007/978-0-387-34749-3_1	computer vision;geography;artificial intelligence;cartography	ML	32.99331614529734	-73.80109799655818	80444
3ac0d086e5a40d23d09746a8d732431132c86ac0	rnn based online handwritten word recognition in devanagari script		Devanagari script is the most popular script in India. But, very little recognized works have been done in this script towards development of online handwritten text recognition systems. The existence of large number of symbols and symbol order variations in this script, has led to low recognition rates for even the best existing recognition system. Most of the existing studies in Devanagari script have relied upon the same Hidden Markov Model (HMM) which has been used for so many years in handwriting recognition, despite of its familiar shortcomings. This article proposes a novel approach for online handwritten word recognition in Devanagari script based on two recently developed models of Recurrent Neural Network (RNN), termed as Long-Short Term Memory (LSTM) and Bidirectional Long-Short Term Memory (BLSTM), specifically designed for sequential data where the segmentation of data into basic unit level is very difficult. Analysis shows that words are written in non-cursive fashion in Devanagari script. The proposed approach considers the local zone wise analysis of each basic stroke of a word to extract various features from each basic stroke. In this local zone wise feature extraction approach, dominant points are detected from strokes using slope angles, to find the local features. These features are then studied using both LSTM and BLSTM versions of RNN. Most of the existing word recognition systems in this script have followed the typical holistic approach whereas the proposed system has been developed in analytical scheme with a total of 10K words in lexicon. An exhaustive experiment on large datasets has been performed to evaluate the performance of the proposed recognition approach using both LSTM and BLSTM to make a comparative performance analysis. Experimental results show that the proposed system outperforms existing HMM based systems in the literature.		Pooja Keshri;Prabhat Kumar;Rajib Ghosh	2018	2018 16th International Conference on Frontiers in Handwriting Recognition (ICFHR)	10.1109/ICFHR-2018.2018.00096	artificial intelligence;machine learning;word recognition;devanagari;feature extraction;pattern recognition;symbol;recurrent neural network;hidden markov model;computer science;lexicon;handwriting recognition	AI	32.45052075712117	-66.78785139214125	80474
6c4617fdc8aa39f81013af472aafc0537ea4f292	image processing strategies for automatic detection of common gastroenterological diseases		The analysis of Confocal Laser Endomicroscopy (CLE) is one of the techniques used for diagnosing gastroenterological diseases. However, the manual analysis of such images requires training and experience and will often lead to wrong diagnostics. This work explores the use of attributes taken from classic texture description techniques, gray level co-occurrence matrices (GLCM) and local binary patterns (LBP), as inputs for classifiers to separate images from 3 common gastroenterological diseases, with 262 images. A baseline classifier was trained for the 10 smaller groups and two others were trained using GLCM and LBP attributes. Overall, the benefits of using texture analysis techniques and attributes can be observed as an increase in accuracy and consistency of the results.	baseline (configuration management);conformal loop ensemble;endomicroscopy;grayscale;image processing;local binary patterns	Rafael Neujahr Copstein;Vicenzo Abichequer Sangalli;Matheus Cruz Andrade;Lucas Almeida Machado;Evandro Rodrigues;Leonardo Pavanatto Soares;Márcio Sarroglia Pinho	2018	2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)	10.1109/COMPSAC.2018.00090	image processing;real-time computing;local binary patterns;endomicroscopy;computer science;artificial intelligence;pattern recognition	Vision	33.5784342977008	-75.59941388375245	80501
5bc2dfca7608868fc924aa4d80041698aeb6bb2a	learning sparse kernels from 3d surfaces for heart wall motion abnormality detection	wall motion	Coronary heart disease (CHD) is a global epidemic that is the leading cause of death worldwide. CHD can be detected by measuring and scoring the regional and global motion of the left ventricle (LV) of the heart. This project describes a novel automatic technique which can detect the regional wall motion abnormalitie, of the LV from echocardiograms. Given a sequence of endocardial contours extracted from LV ultrasound images, the sequence of contours moving through time can be interpreted as a three-dimensional (3D) surface. From the 3D surfaces, we compute several geometry-based features (shape-index values, curvedness, surface normals, etc.) to obtain histograms-based similarity functions that are optimally combined using a mathematical programming approach to learn a kernel function designed to classify normal vs. abnormal heart wall motion. In contrast with other state-of-the-art methods, our formulation also generates sparse kernels. Kernel sparsity is directly related to the computational cost of the kernel evaluation, which is an important factor when designing classifiers that are part of a real-time system. Experimental results on a set of echocardiograms collected in routine clinical practice at one hospital demonstrate the potential of the proposed approach.		Glenn Fung;Sriram Krishnan;R. Bharat Rao;Hui Chen	2008			computer vision;mathematical optimization;simulation;computer science	Vision	39.17119390917397	-78.81281056191443	80712
3ed4684f54b7b8ffe6e75c612ea00678607a0aed	detection of vertebral degenerative disc disease based on cortical shell unwrapping	spine;bone;diseases and disorders	Degenerative disc disease (DDD) can be identified as hyperdense regions of bone and osseous spur formation in the spine that become more prevalent with age. These regions can act as confounding factors in the search for alternative hyperdense foci such as neoplastic processes. We created a preliminary CAD system that detects DDD in the spine on CT images. After the spine is segmented, the cortical shell of each vertebral body is unwrapped onto a 2D map. Candidates are detected from the 2D map based on their intensity and gradient. The 2D detections are remapped into 3D space and a level set algorithm is applied to more fully segment the 3D lesions. Features generated from the unwrapped 2D map and 3D segmentation are combined to train a support vector machine (SVM) classifier. The classifier was trained on 20 cases with DDD, which were marked by a radiologist. The pre -SVM program detected 164/193 ground truth lesions. Preliminary results showed 69.65% sensitivity with a 95% confidence interval of (64.47%, 73.92%), at an average of 9.8 false positives per patient. Keywords: degenerative disc disease, osteophytes, computer -aided detection		Hector E. Muñoz;Jianhua Yao;Joseph E. Burns;Ronald M. Summers	2013		10.1117/12.2008063	spine	ML	36.045920123837014	-79.22798646442517	80716
8d26d34cdd192dc8fcdf517c64c36db89ac4bdbb	supervised texture classification using a probabilistic neural network and constraint satisfaction model	analisis imagen;texture;probability;supervised texture classification;neural networks;neural nets;texture classification;neural nets image texture image classification constraint handling probability;optimal classification supervised texture classification probabilistic neural network constraint satisfaction model texture class feature label interaction constraint gaussian mixture model;biological system modeling;optimal classification;image classification;gabor filters;indexing terms;constraint satisfaction;image texture;fuzzy logic;feature vector;satisfaction contrainte;qa75 electronic computers computer science;gabor filter;gaussian mixture model;retroaccion;stochastic processes;retroaction;neural net work;pixel;textura;filtre gabor;feedback regulation;autoorganizacion;constraint handling;self organization;image analysis;self organized map;humans;constraint satisfaction problem;texture class;image texture analysis;satisfaccion restriccion;neurofeedback;classification automatique;reseau neuronal;constraint satisfaction model;automatic classification;feature label interaction constraint;probabilistic neural network;clasificacion automatica;analyse image;human perception;neural networks humans knowledge based systems pixel fuzzy logic biological system modeling stochastic processes neurofeedback gabor filters image texture analysis;red neuronal;autoorganisation;knowledge based systems;neural network	In this paper, the texture classification problem is projected as a constraint satisfaction problem. The focus is on the use of a probabilistic neural network (PNN) for representing the distribution of feature vectors of each texture class in order to generate a feature-label interaction constraint. This distribution of features for each class is assumed as a Gaussian mixture model. The feature-label interactions and a set of label-label interactions are represented on a constraint satisfaction neural network. A stochastic relaxation strategy is used to obtain an optimal classification of textures in an image. The advantage of this approach is that all classes in an image are determined simultaneously, similar to human perception of textures in an image.	artificial neural network;assumed;biological neural networks;class;constraint satisfaction problem;interaction;linear programming relaxation;mixture model;normal statistical distribution;probabilistic neural network;projections and predictions;texture mapping;perineuronal net (cell component)	P. P. Raghu;Bayya Yegnanarayana	1998	IEEE transactions on neural networks	10.1109/72.668893	fuzzy logic;image texture;computer vision;contextual image classification;probabilistic neural network;self-organization;index term;feature vector;constraint satisfaction;computer science;machine learning;pattern recognition;probability;mixture model;constraint satisfaction dual problem;neurofeedback;mathematics;texture;perception;constraint satisfaction problem;artificial neural network;hybrid algorithm;pixel	Vision	33.51431269739379	-69.71486202445116	80833
7236b7acb7c495c027e1f91e8d019971d93460aa	extraction and quantitative analysis of aneurysmal aorta for aiding endovascular stent grafting	blood flow borderline;stent grafting;quantitative analysis;endovascular stent grafting;extracted blood vessel;medial axis;aortal shape;aneurysmal aorta;shape characteristic;three-dimensional shape;blood vessel;blood flow area;intervention;cta	In performing interventions including stent grafting, the suitability for stent grafting must be checked and the devices to be used must be designed preoperatively. For these purposes, the three-dimensional shapes of the blood vessels in lesions or the paths of device placement must be measured accurately and quickly. In this paper, a method for measuring the aortal shape from CT angiogram (CTA) and for detecting lesions from the shape characteristics of these is presented. Specifically, this method extracts the blood flow area of the aorta by using a three-dimensional edge-preserving smoothing filter and a region growing method. Extracted blood vessels are classified by using their anatomical characteristics. After initial setting of the medial axis in a blood vessel, it determines the aneurysmal area based on the diameter of the blood vessel and modifies the medial axis. In addition, it detects lesions such as thrombi and calcifications near the blood flow borderline. Application of the method to 30 clinical cases has confirmed that the proposed method is effective in obtaining the shape of blood vessels. © 2004 Wiley Periodicals, Inc. Syst Comp Jpn, 35(3): 58–67, 2004; Published online in Wiley InterScience (). DOI 10.1002&sol;scj.10223		Hiroshi Imamura;Naozo Sugimoto;Shigeru Eiho;Shin-ichi Urayama;Katsuya Ueno;Kanji Inoue	2004	Systems and Computers in Japan	10.1002/scj.10223	medial axis;quantitative analysis;intervention;geometry	Logic	38.43350955617492	-79.32524938595623	80972
6714a62e878ab5a74a907e641421efd2db99e88f	a deep convolutional neural network for lung cancer diagnostic		In this paper, we examine the strength of deep learning technique for diagnosing lung cancer on medical image analysis problem. Convolutional neural networks (CNNs) models become popular among the pattern recognition and computer vision research area because of their promising outcome on generating high-level image representations. We propose a new deep learning architecture for learning high-level image representation to achieve high classification accuracy with low variance in medical image binary classification tasks. We aim to learn discriminant compact features at beginning of our deep convolutional neural network. We evaluate our model on Kaggle Data Science Bowl 2017 (KDSB17) data set, and compare it with some related works proposed in the Kaggle competition.	artificial neural network;binary classification;ct scan;computer vision;convolutional neural network;data science;deep learning;discriminant;high- and low-level;image analysis;medical image computing;medical imaging;network architecture;pattern recognition	Mehdi Fatan Serj;Bahram Lavi;Gabriela Hoff;Domenec Puig Valls	2018	CoRR		machine learning;convolutional neural network;pattern recognition;computer science;architecture;deep learning;artificial intelligence;binary classification	ML	31.98188022667591	-75.33407849111614	81056
f3c35e6d3dd9f7f0719795ab6287ef53facf8258	imitation of hand gestures classified by principal component analysis with fluid particles	smoothed particle hydrodynamics imitation learning hand gesture imitation;robots principal component analysis electronic mail hydrodynamics markov processes human robot interaction fluids;image classification;matrix algebra;fluid parameter human hand gesture classification principal component analysis fluid particle dynamics imitation learning imitator demonstrator particle colony smoothing particle hydrodynamics sph hand image collection pca dimension reduction dimension equalization test image classification weight matrix training data set test data set;flow visualisation;smoothing methods;principal component analysis;data reduction;learning artificial intelligence;gesture recognition;smoothing methods data reduction flow visualisation gesture recognition image classification learning artificial intelligence matrix algebra principal component analysis	In imitation learning, the correspondence problem, which is caused by the dynamical differences between imitator and the demonstrator, is applied on imitation of human hand gestures with a particle colony which is modeled by using fluid dynamics. In this work, firstly human hand gestures which are collected from different human groups are classified by using Principal Component Analysis (PCA) and then these hand gestures are imitated with fluid particles which are modeled by Smoothing Particle Hydrodynamics (SPH). Since the dimension of the collected hand images are huge and different from each other, PCA is used for dimension reduction and also dimension equalization. For classification of the test images, the distance between weight matrices of the training data set and test data set is measured. After that the fluid parameters which belongs to that class are applied to the particle colony and finally human hand gestures are imitated. Moreover, in this work, the effect of the number of principal components on the classification and average consumed time during training and testing steps are analyzed.	correspondence problem;dimensionality reduction;particle swarm optimization;principal component analysis;smoothed-particle hydrodynamics;smoothing;test data;test set	Umut Tilki;Ismet Erkmen;Aydan M. Erkmen	2013	2013 21st Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2013.6531249	computer vision;contextual image classification;data reduction;computer science;machine learning;gesture recognition;statistics;principal component analysis	ML	26.243739242030173	-66.81500896423921	81274
4e712f5aa4a213d670e7637c4766d5a6f2d60390	a strategy to abstract wce video clips based on lda	automation antennas;video signal processing data visualisation endoscopes feature extraction image segmentation medical image processing object detection;image segmentation;video signal processing;data visualisation;lda algorithm wireless capsule endoscopy visualization gastrointestinal tract small intestine wce video clip abstraction linear discriminant analysis feature extraction frame difference video clip segmentation nonparametric key point detection algorithm most representative frame;feature extraction;medical image processing;endoscopes;antennas;object detection;automation	Wireless Capsule Endoscopy (WCE) is a novel technique that allows visualization of the whole gastrointestinal (GI) tract especially the small intestine in a comfortable, non-invasive and efficacious way. The main disadvantage of WCE is that physicians need to examine a video of over 55,000 frames which is a time-consuming and labor intensive task. To address the problem, a strategy of WCE video clip abstraction based on linear discriminant analysis (LDA) is proposed in this paper. We extract multiple features based on which the frame differences are measured. Then the video clips are segmented using a non-parametric key-point detection algorithm and finally the most representative frames (MRFs) are extracted based on LDA algorithm. Experimental results demonstrate the proposed strategy achieves promising performances.	algorithm;color;corner detection;frame language;linear discriminant analysis;performance;tract (literature);video clip	Qian Zhao;Max Q.-H. Meng	2011	2011 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2011.5979891	computer vision;speech recognition;feature extraction;computer science;automation;antenna;video tracking;multimedia;image segmentation;data visualization	Robotics	36.94231893794183	-73.57547859520587	81292
5a7b38357fb3ed0f74859e477cfb565f57c65f04	analysis of mammogram classification using a wavelet transform decomposition	mammogram classification;wavelet feature selection;wavelet transform;supervised wavelet transform classifier;feature selection	In order to fully achieve automated mammogram analysis one has to tackle two problems: classification of radial, circumscribed, microcalcifications, and normal samples; and classification of benign, malign, and normal ones. How to extract and select the best features from the images for classification is a very difficult task, since all of those classes are basically irregular textures with a wide visual variety inside each class. Besides there is a lack of tested solutions for these problems in the literature. In this paper we propose to construct and evaluate a supervised classifier for these two problems, by transforming the data of the images in a wavelet basis, and then using special sets of the coefficients as the features tailored towards separating each of those classes. We have realized that this is a suitable solution worth further exploration. For the experiments we have used samples of images labeled by physicians. Results shown are very promising, and the paper describes possible lines for future directions.	wavelet transform	Cristiane Bastos Rocha Ferreira;Díbio Leandro Borges	2003	Pattern Recognition Letters	10.1016/S0167-8655(02)00221-0	computer vision;computer science;machine learning;pattern recognition;mathematics;feature selection;wavelet transform	Vision	34.07257817454968	-74.53402244279299	81376
063cfff6652b2f0a15b973fd106e4f74c62cf95a	a novel approach for efficient extrication of overlapping chromosomes in automated karyotyping		Since the introduction of the automated karyotyping systems, segmentation and classification of touching and overlapping chromosomes in the metaphase images are major challenges. The earlier reported techniques for disentangling the chromosome overlaps have limited success and use only color information in case of multispectral imaging. Most of them are restricted to separation of single overlap of two chromosomes. This paper introduces a novel algorithm to extricate overlapping chromosomes in a metaphase image. The proposed technique uses Delaunay triangulation to automatically identify the number of overlaps in a cluster followed by the detection of the appropriate cut-points. The banding information on the overlapped region further resolves the set of overlapping chromosomes with the identified cut-points. The proposed algorithm has been tested with four data sets of 60 overlapping cases, obtained from publically available databases and private genetic labs. The experimental results provide an overall accuracy of 75–100 % for resolving the cluster of 1–6 overlaps.	chromosomes;colour banding;database;delaunay triangulation;karyotype;mitotic metaphase;multispectral imaging;algorithm	Mousami Munot;Jayanta Mukherjee;Madhuri Joshi	2013	Medical & Biological Engineering & Computing	10.1007/s11517-013-1105-y	biology;bioinformatics;genetics	ML	38.490181375668044	-72.32797438042633	81817
e1fd7ccf9be9ff5995b9af04e7ee3714e641ae78	characterization of vascular tree architecture using the tokunaga taxonomy	cardiovascular disorders;computed tomography;vascular diseases;angiography;medical diagnostics;taxonomy;magnetic resonance angiography;blood vessels	The diagnosis of cardiovascular disease is usually assisted by resonance angiography (MRA) or computed tomography angiography (CTA) imaging. The identification of abnormal vascular architecture from angiographic three-dimensional images is therefore crucial to the diagnosis of cardiovascular disease. Automated detection and quantification of vascular structure and architecture thus holds significant clinical value. In this work, we employ a Lindenmayer system to represent vascular trees from angiographic images and describe a quantitative measure based on the Tokunaga taxonomy to differentiate vascular architectures. Synthetic vessel architectures with varying bifurcation patterns were compared and results showed that this architectural measure is proportional to the level of branching. In real MRA images, this measure was able to differentiate between normal and abnormal intracerebral vasculature containing an aneurysm. Hence, this methodology not only allows for compact representation of vascular architectures but also provides a quantitative metric of bifurcation complexity, which has the potential to characterize different types of vascular abnormalities. © (2015) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.		Miguel A. Galarreta-Valverde;Jihan M. Zoghbi;Fabricio Pereira;Jean-Paul Beregi;Choukri Mekkaoui;Marcel P. Jackowski	2015		10.1117/12.2080854	medical diagnosis;taxonomy	NLP	35.80188922807378	-78.27558955724054	82069
e07cd6532c48bcf6c26c0b9ff818e52e1ac9c1f3	determining correspondence in stereovision images of patients with faulty posture	patient diagnosis;computers;graph theory;patients;image segmentation;photogram metric method;graphs;distance measurement;faulty posture diagnosing;medical image processing;stereo image processing;pattern recognition;joining processes;stereovision images;patient treatment;stereo image processing graph theory medical image processing patient diagnosis patient treatment;clinical research;computer science image processing fuzzy systems materials science and technology biomedical computing testing biomedical image processing image matching algorithm design and analysis image analysis;algorithm design and analysis;graphs stereovision images patients faulty posture diagnosing photogram metric method;gallium	In the paper we present an algorithm for finding the correspondence between stereo pairs acquired during diagnosing faulty posture using the photogram-metric method. The coordinates of markers from images constitute the vertices of graphs, between which isomorphism is searched for. The paper proposes a method for finding graph correspondence and for determining similarity between graphs. The precision of the algorithm was verified for various patients' positions of patients as well as for dummy graph vertices, generated for test purposes. The developed algorithm is employed in clinical research, as an automatic system for faulty posture diagnosing using two stereovision images.	algorithm;dummy variable (statistics);poor posture;stereopsis;vertex (graph theory)	Robert Koprowski;Zygmunt Wróbel	2008	2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2008.554	clinical research;algorithm design;computer vision;computer science;graph theory;theoretical computer science;machine learning;image segmentation;graph;gallium	Robotics	38.39197923766501	-78.39238719315362	82149
a05b7a206c86b3928746cce935f6f85d534a43cd	automated pathogenesis-based diagnosis of lumbar neural foraminal stenosis via deep multiscale multitask learning	deep learning;multiscale learning;multitask learning;neural foraminal stenosis	Pathogenesis-based diagnosis is a key step to prevent and control lumbar neural foraminal stenosis (LNFS). It conducts both early diagnosis and comprehensive assessment by drawing crucial pathological links between pathogenic factors and LNFS. Automated pathogenesis-based diagnosis would simultaneously localize and grade multiple spinal organs (neural foramina, vertebrae, intervertebral discs) to diagnose LNFS and discover pathogenic factors. The automated way facilitates planning optimal therapeutic schedules and relieving clinicians from laborious workloads. However, no successful work has been achieved yet due to its extreme challenges since 1) multiple targets: each lumbar spine has at least 17 target organs, 2) multiple scales: each type of target organ has structural complexity and various scales across subjects, and 3) multiple tasks, i.e., simultaneous localization and diagnosis of all lumbar organs, are extremely difficult than individual tasks. To address these huge challenges, we propose a deep multiscale multitask learning network (DMML-Net) integrating a multiscale multi-output learning and a multitask regression learning into a fully convolutional network. 1) DMML-Net merges semantic representations to reinforce the salience of numerous target organs. 2) DMML-Net extends multiscale convolutional layers as multiple output layers to boost the scale-invariance for various organs. 3) DMML-Net joins a multitask regression module and a multitask loss module to prompt the mutual benefit between tasks. Extensive experimental results demonstrate that DMML-Net achieves high performance (0.845 mean average precision) on T1/T2-weighted MRI scans from 200 subjects. This endows our method an efficient tool for clinical LNFS diagnosis.	aortic valve stenosis;bone structure of spine;computer multitasking;dendritic spine;ephrin type-b receptor 1, human;esophageal stenosis;histopathologic grade;information retrieval;intervertebral disc degeneration;intervertebral disc structure;manuscripts;medicine, east asian traditional;natural science disciplines;numerous;organ;pet/ct scan;python;schedule (document type);silo (dataset);source data;spinal diseases;structural complexity (applied mathematics);supravalvular aortic stenosis;tensorflow;workload;anatomical layer;interest	Zhongyi Han;Benzheng Wei;Stephanie Leung;Ilanit Ben Nachum;David T. Laidley;Shuo Li	2018	Neuroinformatics	10.1007/s12021-018-9365-1	stenosis;machine learning;lumbar;deep learning;pathogenesis;computer science;schedule;multi-task learning;artificial intelligence	ML	30.22154334881096	-76.22542072421946	82701
c62b644413538a43796a4d2ba6ddc78a52cb3db3	semiautomatic classification of secondary healing ulcers in multispectral images	multispectral imaging wounds surgery optical reflection image color analysis laboratories scientific computing image processing shape measurement biochemistry;image processing system computerised pattern recognition medical computing secondary healing ulcers multispectral images binary image digital picture wound photographs pascal imtec epsilon;digital picture;image processing;optical reflection;binary image;image processing system;computerised pattern recognition;shape measurement;medical computing;wounds;wound photographs;image color analysis;multispectral images;imtec epsilon;surgery;scientific computing;pascal;photographic applications biomedical measurement computerised pattern recognition medical computing;biomedical measurement;biochemistry;photographic applications;multispectral imaging;secondary healing ulcers	Close-up color photographs of the wounds were used as imput. The interesting areas were marked by the operator, creating a binary image. According to the severity of the wound, one of the trained classifiers was selected. The digital picture was classified and combined with the binary image, giving the qualitative (proportion necroses/fibrin and granulation) and the quantitative (wound size) parameters. In this way the time for analyzing a large number of wound photographs was substantially reduced. The method has been programmed in Pascal on the IMTEC Epsilon image processing system. >	multispectral image	J. Arnqvist;J. Hellgren;J. Vincent	1988		10.1109/ICPR.1988.28266	multispectral image;computer vision;image processing;computer science;computer graphics (images)	Vision	37.01089233697642	-75.3620069182639	82829
39581d855ecfd28c382a3d98677ce7dffd51f071	multi-modal brain tumor segmentation using stacked denoising autoencoders		Accurate Segmentation of Gliomas from Magnetic Resonance Images (MRI) is required for treatment planning and monitoring disease progression. As manual segmentation is time consuming, an automated method can be useful, especially in large clinical studies. Since Gliomas have variable shape and texture, automated segmentation is a challenging task and a number of techniques based on machine learning algorithms have been proposed. In the recent past, deep learning methods have been tested on various image processing tasks and found to outperform state of the art techniques. In our work, we consider stacked denoising autoencoder (SDAE), a deep neural network that reconstructs its input. We trained a three layer SDAE where the input layer was a concatenation of fixed size 3D patches (11(,times ,)11(,times ,)3 voxels/neurons) from multiple MRI sequences. The 2nd, 3rd and 4th layers had 3000, 1000 and 500 neurons respectively. Two different networks were trained one with high grade glioma (HGG) data and other with a combination of high grade and low grade gliomas (LGG). Each network was trained with 35 patients for pre-training and 21 patients for fine tuning. The predictions from the two networks were combined based on maximum posterior probability. For HGG data, the whole tumor dice score was .81, tumor core was .68 and active tumor was .64 ((n=220) patients). For LGG data, the whole tumor dice score was .72, tumor core was .42 and active tumor was .29 ((n=54) patients).	autoencoder;modal logic;noise reduction	Kiran Vaidhya;Subramaniam Thirunavukkarasu;Alex Varghese;Ganapathy Krishnamurthi	2015		10.1007/978-3-319-30858-6_16	autoencoder;image processing;voxel;supervised learning;artificial neural network;deep learning;unsupervised learning;artificial intelligence;segmentation;pattern recognition;computer science	NLP	30.90240211244016	-75.54501617729095	83361
e0be79cb938d4bd560bf2c03422448cd68825017	computer-aided detection and quantification of intracranial aneurysms		. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Razširjen povzetek† . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 P.1 Intrakranialne anevrizme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 P.2 Filtri za ojačitev žilnih struktur . . . . . . . . . . . . . . . . . . . . . . . . . . 8 P.3 Računalniško podprta zaznava anevrizem . . . . . . . . . . . . . . . . . . . . 9 P.4 Računalniško podprta kvantifikacija anevrizem . . . . . . . . . . . . . . . . . 10 P.5 Izvirni prispevki k znanosti . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 P.5.1 Razvoj in vrednotenje izvirnega večnivojskega filtra za ojačitev žilnih struktur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 P.5.2 Razvoj in vrednotenje izvirnih postopkov za računalniško podprto zaznavo intrakranialnih anevrizem . . . . . . . . . . . . . . . . . . . . . 12 P.5.3 Razvoj in vrednotenje izvirnih postopkov za računalniško podprto kvantifikacijo intrakranialnih anevrizem . . . . . . . . . . . . . . . . . . . . 13		Tim Jerman;Franjo Pernus;Bostjan Likar;Ziga Spiclin	2015		10.1007/978-3-319-24571-3_1	computer-aided;computer science;computer vision;artificial intelligence;pattern recognition;normalized frequency (unit);random forest;saccular aneurysms;aneurysm;growcut algorithm;false positive paradox;segmentation	Vision	35.328860288011754	-78.61294554289064	83535
2bd75a75603d2c7f40f2c5304add602a8de1d225	a dynamic fuzzy classifier for detecting abnormalities in mammograms	cancer detection;breast self examination;image segmentation;edge detection;lakes;indexing terms;european community;digital mammography;medical image;image edge detection;detection algorithm;tumors;diseases;transition zone;computer science;mammography;neoplasms;signal to noise ratio;mammography breast cancer image edge detection tumors neoplasms diseases computer science lakes cancer detection signal to noise ratio;breast cancer;public health;x rays;fuzzy classifier	One of the most important steps in digital mammography is an adequate segmentation of possible abnormalities. This obviously minimizes errors in further stages such as in classification. However, several factors affect the proper segmentation of mammograms. Mammograms contain low signal to noise ratio (low contrast) and a complicated structured background.In this article we are describing a generic approach for detecting patterns of architectural distortions in mammograms that is both complete and uncommitted to any type of training. Our detection algorithm dynamically updates the pixels intensities by following their neighboring transition zone. Such approach proved to be effective for detecting the edges of all types of breast abnormalities including the Stellate.	algorithm;distortion;pixel;sensor;signal-to-noise ratio;statistical classification	Sabah Mohammed;Lei Yang;Jinan Fiaidhi	2004	First Canadian Conference on Computer and Robot Vision, 2004. Proceedings.	10.1109/CCCRV.2004.1301441	computer vision;edge detection;index term;public health;computer science;breast cancer;transition zone;image segmentation;signal-to-noise ratio	Vision	37.343777661632814	-75.6830451523727	83669
2f2c74915db40c1a32d8c61bd119bb695cda7ece	removal of background patterns and signatures for magnetic ink character recognition of checks	stroke tracing;optical character recognition;character separation;stroke tracing ocr micr character separation;micr;image colour analysis;feature extraction;image color analysis optical character recognition software correlation ink image segmentation character recognition degradation;optical character recognition feature extraction image colour analysis magnetic fluids;ocr;magnetic ink character recognition magnetic ink character extraction ocr micr colorful background pattern removal overlapped signatures micr characters binarization labeling sign strokes circulated bankchecks seiko epson;character recognition;magnetic fluids	This paper describes a method to extract the magnetic ink characters (MICR E-13B font) printed on bank-checks for the purpose of using OCR as supporting MICR. In the case of OCR, the colorful background patterns and the overlapped signatures on MICR characters make it difficult to extract characters respectively by using simple binarization and labeling. Our method estimates the color and pitch of MICR characters in order to separate the characters in contact with sign strokes, then the remaining sign strokes are removed by tracing them. In the experiment, we use circulated bank-checks and samples provided by SEIKO EPSON and show the performance of our method.	antivirus software;electronic signature;elegant degradation;heuristic;magnetic ink character recognition;optical character recognition;printing;type signature	Keiichiro Shirai;Masashi Akita;Masayuki Okamoto;Kazuya Tanikawa;Takaaki Akiyama;Tetsuji Sakaguchi	2012	2012 10th IAPR International Workshop on Document Analysis Systems	10.1109/DAS.2012.75	computer vision;magnetic ink character recognition;speech recognition;feature extraction;computer science;optical character recognition;computer graphics (images)	Graphics	37.01212341665374	-66.30729560520885	83746
3beafa68d9de18326f932715cfee8d26cd244d1b	simulation of trans-nasal endoscopy of the middle ear for visualization of cholesteatoma	virtual endoscope trans nasal endoscopy cholesteatoma visualization benign lesions patient care surgical removal clinical approach trans aural approach patient diagnosis patient treatment monitoring surface area middle ear segmentation ct volumes;patient diagnosis;patient treatment monitoring;image segmentation;computed tomography;benign lesions;ct volumes;endoscope simulation;trans nasal endoscopy;middle ear segmentation;medical image processing biomedical optical imaging computerised tomography ear endoscopes image segmentation;patient care;eustachian tube;virtual endoscope;visualization;ear;cholesteatoma visualization;medical image processing;endoscopes;data visualization;eustachian tube cholesteatoma middle ear segmentation endoscope simulation;computerised tomography;surgery;trans aural approach;clinical approach;surgical removal;biomedical optical imaging;endoscopes ear visualization computed tomography image segmentation data visualization surgery;surface area;cholesteatoma	Cholesteatomas are benign lesions that form in the middle ear (ME). The standard of care is surgical removal. The traditional clinical approach for identifying cholesteatomas, visualization via a trans-aural approach, must be done in the operating room. This constraint complicates early diagnosis and treatment monitoring. Trans-nasal endoscopy of the ME may permit less invasive visualization as it could potentially be done in an outpatient setting. In this work, we propose a technique to quantitatively analyze the effectiveness of a trans-nasal endoscope for identifying cholesteatomas. Our approach is to quantify the surface area of MEs segmented in 6 CT volumes that is visible from a virtual endoscope inserted trans-nasally. Our preliminary results indicate that cholesteatomas located in certain sub-regions of the ME could indeed be well-visualized with a trans-nasal endoscope. Such an approach could have significant impact by facilitating earlier diagnosis and more frequent post-treatment monitoring of cholesteatomas.	ct scan;simulation;source-to-source compiler	Dongqing Zhang;Marc L. Bennett;Robert F. Labadie;Jack H. Noble	2015	2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2015.7164141	visualization;radiology;medicine;pathology;computer science;surface area;mathematics;image segmentation;data visualization;surgery	Visualization	39.15445891410271	-80.20398532837854	83882
a1f0e3d73c4e5328bc8c4b4360220968e5ad7eef	decision support system for the glaucoma using gabor transformation	t technology general;ta engineering general civil engineering general	Increase in intraocular pressure (IOP) is one of the causes of glaucoma which can lead to blindness if not detected and treated at an early stage. Glaucoma symptoms are not always obvious; hence patients seek treatment only when the condition progressed significantly. Early detection and treatment will decrease the chances of vision loss due to glaucoma. This paper proposes a novel automated glaucoma diagnosis method using various features extracted from Gabor transform applied on digital fundus images. In this work, we have used 510 images to classify into normal and glaucoma classes. Various features namely mean, variance, skewness, kurtosis, energy, and Shannon, Rényi, and Kapoor entropies are extracted from the Gabor transform coefficients. These extracted features are subjected to principal component analysis (PCA) to reduce the dimensionality of the features. Then these features are ranked using various ranking methods namely: Bhattacharyya space algorithm, t-test, Wilcoxon test, Receiver Operating Curve (ROC), and entropy. In this work, t-test ranking method yielded the highest performance with an average accuracy of 93.10%, sensitivity of 89.75% and specificity of 96.20% using 23 features with Support Vector Machine (SVM) classifier. Also, we have proposed a Glaucoma Risk Index (GRI) developed using principal components to classify the two classes using just one number. © 2014 Elsevier Ltd. All rights reserved.	algorithm;coefficient;decision support system;gri;principal component analysis;receiver operating characteristic;sensitivity and specificity;shannon (unit);support vector machine	U. Rajendra Acharya;E. Y. K. Ng;Wei Jie Eugene Lim;Kevin Noronha;Choo Min Lim;K. Prabhakar Nayak;Sulatha V. Bhandary	2015	Biomed. Signal Proc. and Control	10.1016/j.bspc.2014.09.004	computer vision;speech recognition;computer science;machine learning;mathematics;statistics	ML	33.76194075082299	-74.41680952076887	83968
7b0501c93fc83ce4eebaa020e13e2fcfb90854b7	an efficient method of detecting exudates in diabetic retinopathy: using texture edge features	exudates;gabor filter;region growing algorithm;optic disc	Ophthalmologists analyze fundus images of eye extensively as a non invasive diagnosis tool for various internal eye defects. Diabetic retinopathy is an eye complication specially seen in diabetic patients, causing damage to retina which may lead to blindness. The major symptoms of this disorder is the presence of exudates, a pus like fluid oozed from damaged blood vessels due to high blood sugar. This hardens on the retina of patient, leading to blindness. In this paper, we propose a methodology for automatic detection of exudates. We remove the non exudates like optic disc, blood vessels, and blood clots in two phases using Gradient Vector Flow Snake algorithm and region growing segmentation algorithm. This improves efficiency of detection by masking false exudates. Then, we detect exudates using Gabor filter texture edge detection based segmentation algorithm. To reduce computational complexity, only Gabor filters tuned to two higher frequencies and four orientations are used. We have implemented the proposed methodology on 850 test images. We have obtained a high efficiency of 87% true exudates.	algorithm;computational complexity theory;edge detection;gabor filter;region growing;sensor	Priyadarshini Patil;Pooja Shettar;Prashant Narayankar;Mayur Patil	2016	2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2016.7732206	computer vision;optics	Robotics	36.88099657734602	-76.247376825483	84027
9a1836f24cc6e2ab3058f55ab8a81d277d25b008	advanced ridge flux analysis for fingerprint minutiae detection	computation time reduction fingerprint minutiae detection processing time ridge thinning process advanced ridge flux analysis method computational time detection accuracy ridge contour curvature;object detection fingerprint identification;fingerprint recognition fcc bifurcation vectors silicon accuracy image restoration;fingerprint identification;object detection	This paper presents new fingerprint minutiae detection by the advanced ridge flux analysis. The considerable processing time taken by the conventional approaches, most of which use the ridge thinning process with a rather large calculation time, is a problem that has recently attracted increased attention. Though Ridge flux analysis method without using thinning process is proposed in order to reduce the computational time, there still remains a problem with low detection accuracy. The proposed approach is applied to detect minutiae by analyzing the curvature of ridge contours to achieve both of the computation time reduction and higher detection accuracy. The experimental results show that the proposed approach can achieve a reduction in calculation time, while achieving the same success detection rate as that of the conventional approaches.	computation;fingerprint;minutiae;thinning;time complexity	Tomohiko Ohtsuka	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		fingerprint;computer vision;speech recognition;computer science;machine learning	Robotics	39.006400814406156	-68.12096048562076	84463
41ea18ec2eb13408cec18d3e568b4b8ffb7a2ef1	fractal analysis of tumor in brain mr images	image recognition;fractal geometry;magnetic resonance image;brain tumor;fractal dimension;mr imaging;cumulative histogram;mri;pattern recognition;image analysis;tumor imaging;fractal analysis;surface area	 Abstract. The purpose of this study is to discuss existing fractal-based algorithms and propose novel improvements of these algorithms to identify tumors in brain magnetic-response (MR) images. Considerable research has been pursued on fractal geometry in various aspects of image analysis and pattern recognition. Magnetic-resonance images typically have a degree of noise and randomness associated with the natural random nature of structure. Thus, fractal analysis is appropriate for MR image analysis. For tumor detection, we describe existing fractal-based techniques and propose three modified algorithms using fractal analysis models. For each new method, the brain MR images are divided into a number of pieces. The first method involves thresholding the pixel intensity values; hence, we call the technique piecewise-threshold-box-counting (PTBC) method. For the subsequent methods, the intensity is treated as the third dimension. We implement the improved piecewise-modified-box-counting (PMBC) and piecewise-triangular-prism-surface-area (PTPSA) methods, respectively. With the PTBC method, we find the differences in intensity histogram and fractal dimension between normal and tumor images. Using the PMBC and PTPSA methods, we may detect and locate the tumor in the brain MR images more accurately. Thus, the novel techniques proposed herein offer satisfactory tumor identification.	algorithm;box counting;fractal analysis;fractal dimension;image analysis;image noise;pattern recognition;pixel;randomness;resonance;three-dimensional integrated circuit;thresholding (image processing)	Khan M. Iftekharuddin;Wei Jia;Ronald Marsh	2003	Machine Vision and Applications	10.1007/s00138-002-0087-9	computer vision;fractal;fractal analysis;computer science;artificial intelligence;magnetic resonance imaging;surface area;mathematics;geometry;fractal dimension	Vision	37.266736675400274	-75.63925455394825	84884
1488a73f5bb2009d1076f3f00313d77604cb3bc5	joint sparse and low-rank regularized multi-task multi-linear regression for prediction of infant brain development with incomplete data		Studies involving dynamic infant brain development has received increasing attention in the past few years. For such studies, a complete longitudinal dataset is often required to precisely chart the early brain developmental trajectories. Whereas, in practice, we often face missing data at different time point(s) for different subjects. In this paper, we propose a new method for prediction of infant brain development scores at future time points based on longitudinal imaging measures at early time points with possible missing data. We treat this as a multi-dimensional regression problem, for predicting multiple brain development scores (multi-task) from multiple previous time points (multi-linear). To solve this problem, we propose an objective function with a joint ℓ1 and low-rank regularization on the mapping weight tensor, to enforce feature selection, while preserving the structural information from multiple dimensions. Also, based on the bag-of-words model, we propose to extract features from longitudinal imaging data. The experimental results reveal that we can effectively predict the brain development scores assessed at the age of four years, using the imaging data as early as two years of age.	algorithm;bag-of-words model;baseline (configuration management);computer multitasking;convergence (action);feature selection;fingerprint (computing);linear iga bullous dermatosis;loss function;low-rank approximation;mathematical optimization;missing data;numerous;optimization problem;regression analysis;silo (dataset);sparse;sparse matrix;brain development	Ehsan Adeli;Yu Meng;Gang Li;Weili Lin;Dinggang Shen	2017	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-319-66182-7_5	computer science;missing data;tensor;pattern recognition;artificial intelligence;linear regression;multiple time dimensions;feature selection;regularization (mathematics);chart;machine learning	ML	26.196255853950397	-77.62092156160031	84987
4c93130b5353c14922f57d63028e5b72adbec6ae	direct detection of pixel-level myocardial infarction areas via a deep-learning algorithm		Accurate detection of the myocardial infarction (MI) area is crucial for early diagnosis planning and follow-up management. In this study, we propose an end-to-end deep-learning algorithm framework (OF-RNN) to accurately detect the MI area at the pixel level. Our OFRNN consists of three different function layers: the heart localization layers, which can accurately and automatically crop the region-of-interest (ROI) sequences, including the left ventricle, using the whole cardiac magnetic resonance image sequences; the motion statistical layers, which are used to build a time-series architecture to capture two types of motion features (at the pixel-level) by integrating the local motion features generated by long short-term memory-recurrent neural networks and the global motion features generated by deep optical flows from the whole ROI sequence, which can effectively characterize myocardial physiologic function; and the fully connected discriminate layers, which use stacked auto-encoders to further learn these features, and they use a softmax classifier to build the correspondences from the motion features to the tissue identities (infarction or not) for each pixel. Through the seamless connection of each layer, our OF-RNN can obtain the area, position, and shape of the MI for each patient. Our proposed framework yielded an overall classification accuracy of 94.35% at the pixel level, from 114 clinical subjects. These results indicate the potential of our proposed method in aiding standardized MI assessments.	algorithm;artificial neural network;deep learning;encoder;end-to-end principle;long short-term memory;pixel;random neural network;recurrent neural network;region of interest;resonance;seamless3d;softmax function;time series	Chenchu Xu;Lei Xu;Zhifan Gao;Shen Zhao;Heye Zhang;Yanping Zhang;Xiuquan Du;Shu Zhao;Dhanjoo N. Ghista;Shuo Li	2017		10.1007/978-3-319-66179-7_28	artificial intelligence;pattern recognition;computer vision;computer science;pixel;architecture;artificial neural network;deep learning;algorithm;softmax function	Vision	30.904996890312756	-75.8051176196599	85322
b787e173daa384ebc8de78916de2d2283dd1cc47	multi-template tensor-based morphometry: application to analysis of alzheimer's disease	female;healthy control;sample size;brain;middle aged;adni;male;image processing computer assisted;multi atlas;mr imaging;brain mapping;non rigid registration;magnetic resonance;tensor based morphometry;alzheimer s disease;algorithms;regression analysis;humans;mild cognitive impairment;databases factual;diffusion tensor imaging;classification accuracy;alzheimer disease;data classification;aged;aged 80 and over;multi template;cognition disorders	In this paper methods for using multiple templates in tensor-based morphometry (TBM) are presented and compared to the conventional single-template approach. TBM analysis requires non-rigid registrations which are often subject to registration errors. When using multiple templates and, therefore, multiple registrations, it can be assumed that the registration errors are averaged and eventually compensated. Four different methods are proposed for multi-template TBM. The methods were evaluated using magnetic resonance (MR) images of healthy controls, patients with stable or progressive mild cognitive impairment (MCI), and patients with Alzheimer's disease (AD) from the ADNI database (N=772). The performance of TBM features in classifying images was evaluated both quantitatively and qualitatively. Classification results show that the multi-template methods are statistically significantly better than the single-template method. The overall classification accuracy was 86.0% for the classification of control and AD subjects, and 72.1% for the classification of stable and progressive MCI subjects. The statistical group-level difference maps produced using multi-template TBM were smoother, formed larger continuous regions, and had larger t-values than the maps obtained with single-template TBM.	alzheimer's disease;assumed;classification;clinical use template;cognition disorders;image registration;large;map;mild cognitive disorder;morphometric analysis;morphometrics;mucin 5ac;muscle rigidity;numerous;patients;resonance;template method pattern;registration - actclass	Juha Koikkalainen;Jyrki Lötjönen;Lennart Thurfjell;Daniel Rueckert;Gunhild Waldemar;Hilkka Soininen	2011	NeuroImage	10.1016/j.neuroimage.2011.03.029	psychology;sample size determination;diffusion mri;neuroscience;developmental psychology;radiology;medicine;pathology;artificial intelligence;magnetic resonance imaging;brain mapping;regression analysis	ML	30.374339274592735	-79.44858173216868	85439
acf67fbc8fffa13e5c8229d4472f4c49f2f98a8c	risk detection of malignant tumors in mammograms using unconventional computing		In this paper, we propose the use of Alpha-Beta associative approach as an Unconventional Computing method in the pre-diagnosis of malignant tumors of breast cancer, obtaining an accurate result in a simple way; trying to avoid invasive diagnostic methods like biopsies, as far as possible. This proposal provides for the Alpha-Beta Support Vector Associative Machine created in 2008 and tested for classification of binary images. The results show that the classification model to detect malignancy is very competitive compared to others of the best known classification methods, having an accuracy of 81.85%.	algorithm;binary image;binary pattern (image generation);computation;feature extraction;feature selection;naive bayes classifier;unconventional computing	Jesús Emmanuel Velázquez-Cruz;Itzamá López-Yáñez;Amadeo José Argüelles-Cruz;Cornelio Yáñez-Márquez	2014	Research in Computing Science		pathology;computer science;data mining;biological engineering	AI	33.465763336073664	-75.58137957834067	85453
d87ba2483a09beed1311d74fbf8e94df3fa0555f	an experimental procedure for handwritten character recognition	handwriting recognition;weather forecasting;experimental procedure;segmentation;correlation coefficient handwritten character recognition intensity of marking pattern recognition reconstruction grammer segmentation;automatic speech recognition;reconstruction grammer;pattern recognition;writing;speech recognition;intensity of marking;correlation coefficient;character recognition;standardization;medical diagnosis;handwritten character recognition	Most of the work done so far on recognition of handwritten script uses curve tracing techniques. The present paper describes a recognition scheme which is independent of the dynamics of writing and is suitable both for on-line and off-line systems. New recognition criteria, namely, the distribution of intensity of marking along and perpendicular to the direction of writing are used. Methods for correcting the inclination of script, determination of zonal limits and segmentation of the continuous script into a set of curve elements have been developed. The method of correlation is used for classification of the curve-elements. A simple grammer for the reconstruction of letters from classified segments is presented. A significant recognition has been found.	handwriting recognition;item unique identification;online and offline	A. K. Dutta	1974	IEEE Transactions on Computers	10.1109/T-C.1974.223978	computer vision;speech recognition;weather forecasting;computer science;medical diagnosis;pattern recognition;handwriting recognition;writing;segmentation;standardization	Vision	33.38516043685402	-66.20227410822416	85484
4077d9d3eca409a55ac9ff92642cef835597daf4	detection of nuclei in h&e stained sections using convolutional neural networks	image segmentation;cancer;convolution;training;computer architecture;image color analysis;feature extraction	Detection of nuclei is an important step in phenotypic profiling of histology sections that are usually imaged in bright field. However, nuclei can have multiple phenotypes, which are difficult to model. It is shown that convolutional neural networks (CNN)s can learn different phenotypic signatures for nuclear detection, and that the performance is improved with the feature-based representation of the original image. The feature-based representation utilizes Laplacian of Gaussian (LoG) filter, which accentuates blob-shape objects. Several combinations of input data representations are evaluated to show that by LoG representation, detection of nuclei is advanced. In addition, the efficacy of CNN for vesicular and hyperchromatic nuclei is evaluated. In particular, the frequency of detection of nuclei with the vesicular and apoptotic phenotypes is increased. The overall system has been evaluated against manually annotated nuclei and the F-Scores for alternative representations have been reported.	active galactic nucleus;artificial neural network;blob detection;convolutional neural network;electronic signature;experiment;log-space reduction;neural network simulation;normal statistical distribution;phenotype	Mina Khoshdeli;Richard Cong;Bahram Parvin	2017	2017 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)	10.1109/BHI.2017.7897216	computer vision;computer science;theoretical computer science;machine learning	Robotics	36.142042278971815	-74.33458720408798	85509
3a6c4cfda92e4ed300fbc51f14952deadcf9b33f	computer-aided diagnostic system for pulmonary nodules using helical ct images	lung cancer;computer aided diagnostic;pulmonary nodule;blood vessel;fuzzy clustering	In this paper, we present a computer assisted automatic diagnostic system for lung cancer that detects nodule candidates at  an early stage from helical CT images of the thorax. Our diagnostic system consists of analytic and diagnostic procedures.  In the analysis procedure, we extract the lung and the blood vessel regions using the fuzzy clustering algorithm, then we  analyze the features of these regions. In the diagnosis procedure, we define diagnostic rules utilizing the extracted features  which support the determination of the candidate nodule locations.  	ct scan	Keizo Kanazawa;Yoshiki Kawata;Noboru Niki;Hitoshi Satoh;Hironobu Ohmatsu;Ryutaro Kakinuma;Masahiro Kaneko;Kenji Eguchi;Noriyuki Moriyama	1998		10.1007/BFb0056230	radiology;pathology;fuzzy clustering;computer science;machine learning;nuclear medicine	Robotics	36.123472293982594	-77.99029315950372	85772
8cff4e270d9ac95dde6e751ee63b2ed5866e9780	suppression of moiré patterns in scanned halftone images by double scans with grid movements	printing;moire pattern;screened pictures;fourier analysis;scanning;article;suppression	Moir6 patterns often appear in images obtained from scanning printings on magazines or newspapers. The patterns do not exist in the original printings but come from alias sampling of the screened halftone pictures. A new method of scanning is proposed to suppress the moir6 patterns. First, the Fourier analyses of both screening and scanning are presented, from which the new moir6 suppression scanning method is derived. The method employs a double-scan process. In the second scan, the scan position is shifted by half of the sampling grid distance of the first scan in either or both of the horizontal and vertical directions. Then by averaging the images of the two scans, most of the moir6 fringes can be removed. Some experimental results are shown to demonstrate the feasibility of the proposed approach. © 1997 Published by Elsevier Science B.V.	aliasing;fourier analysis;image compression;image scanner;printing;projection screen;sampling (signal processing);zero suppression	James Ching-Yu Yang;Wen-Hsiang Tsai	1997	Pattern Recognition Letters	10.1016/S0167-8655(97)00011-1	computer vision;computer science;mathematics;fourier analysis;moiré pattern;computer graphics (images)	Graphics	39.04844855256929	-66.39556666704718	85782
2264bbf912dd0c0d3fef9a094ef8085fd29c3f50	blood vessel segmentation of fundus images by major vessel extraction and subimage classification	image segmentation;high pass filter;fundus images;biomedical imaging;morphological reconstruction;classification;training data;image segmentation biomedical imaging blood vessels feature extraction retina image reconstruction training data;mixture models biomedical optical imaging blood vessels eye feature extraction gaussian processes high pass filters image classification image enhancement image reconstruction image segmentation medical image processing;retina;feature extraction;image reconstruction;feature selection;peripapillary vessel;vessel segmentation;blood vessels;chase_db1 dataset blood vessel segmentation fundus images major vessel extraction subimage classification fundus photographs high pass filtering binary image morphologically reconstructed enhanced image gaussian mixture model classifier gmm features extraction pixel neighborhood first order gradient images second order gradient images drive dataset stare dataset	This paper presents a novel three-stage blood vessel segmentation algorithm using fundus photographs. In the first stage, the green plane of a fundus image is preprocessed to extract a binary image after high-pass filtering, and another binary image from the morphologically reconstructed enhanced image for the vessel regions. Next, the regions common to both the binary images are extracted as the major vessels. In the second stage, all remaining pixels in the two binary images are classified using a Gaussian mixture model (GMM) classifier using a set of eight features that are extracted based on pixel neighborhood and first and second-order gradient images. In the third postprocessing stage, the major portions of the blood vessels are combined with the classified vessel pixels. The proposed algorithm is less dependent on training data, requires less segmentation time and achieves consistent vessel segmentation accuracy on normal images as well as images with pathology when compared to existing supervised segmentation methods. The proposed algorithm achieves a vessel segmentation accuracy of 95.2%, 95.15%, and 95.3% in an average of 3.1, 6.7, and 11.7 s on three public datasets DRIVE, STARE, and CHASE_DB1, respectively.	binary image;blood vessel tissue;classification;extraction;fundus;google map maker;gradient;hematological disease;mixture model;normal statistical distribution;pixel;stage level 1;stage level 2;algorithm;biologic segmentation;photograph	Sohini Roychowdhury;Dara Koozekanani;Keshab K. Parhi	2015	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2014.2335617	iterative reconstruction;computer vision;training set;feature extraction;biological classification;computer science;machine learning;pattern recognition;image segmentation;high-pass filter;scale-space segmentation;feature selection;computer graphics (images)	Vision	37.026529507059315	-74.98349327686923	85953
a59b5a2801806e0184dd85889c1a32d3960fb826	automated collagen proportional area extraction in liver biopsy images using a novel classification via clustering algorithm		Diagnosis and staging of liver diseases are essential for the therapeutic efficacy of medication and treatment strategies. Measuring the Collagen Proportional Area (CPA) in liver biopsies recently becomes an effective tool for the assessment of fibrosis in liver tissues. State of the art image processing techniques are employed to analyze biopsy images, providing objective assessment of diseases severity. In current work a novel modification of K-means clustering is proposed for image segmentation of liver biopsies. More specifically, supervised restriction of centroids movement is utilized. In the first stage, a training set of images are employed to extract a hypercube for each class. Then, one centroid is initialized inside each hypercube and during the iterations of the clustering is allowed to move only inside the hypercube. For the evaluation of the proposed method 8 liver biopsy images are employed and classification results along with CPA values are computed for each image.	algorithm;cluster analysis;disk staging;image processing;image segmentation;iteration;k-means clustering;olap cube;test set	Dimosthenis C. Tsouros;Panagiotis N. Smyrlis;Markos G. Tsipouras;Dimitrios G. Tsalikakis;Nikolaos Giannakeas;Alexandros T. Tzallas;Pinelopi Manousou	2017	2017 IEEE 30th International Symposium on Computer-Based Medical Systems (CBMS)	10.1109/CBMS.2017.99	computer vision;artificial intelligence;computer science;image processing;cluster analysis;biopsy;hypercube;training set;statistical classification;image segmentation;liver biopsy	Vision	35.20364780446534	-76.00366613399666	86022
0b31a4b558cc876b0f3f48de9a3083d89b7fc777	spatio-temporal covariance model for medical images sequences: application to functional mri data	temporal correlation;nuclear magnetic resonance imaging;medical imagery;image numerique;imagineria rmn;covariancia;aplicacion medical;event related fmri;image processing;robust estimator;functional mri;time variation;hemodynamique;procesamiento imagen;spatial variation;hombre;covariance;statistical method;variation temporelle;encefalo;traitement image;statistical model;data analysis;hemodynamics;medical image;random process;encephale;variacion espacial;imagen numerica;human;modele statistique;imagineria medica;hemodinamica;imagerie medicale;variation spatiale;error processing;evaluation;modelo estadistico;imagerie rmn;medical application;digital image;evaluacion;variacion temporal;multivariate regression;homme;application medicale;imagerie fonctionnelle;brain vertebrata	Spatial and temporal correlations which affect the signal measured in functional MRI (fMRI) are usually not considered simultaneously (i.e., as non-independent random processes) in statistical methods dedicated to detecting cerebral activation. We propose a new method for modeling the covariance of a stationary spatio-temporal random process and apply this approach to fMRI data analysis. For doing so, we introduce a multivariate regression model which takes simultaneously the spatial and temporal correlations into account. We show that an experimental variogram of the regression error process can be fitted to a valid nonseparable spatio-temporal covariance model. This yields a more robust estimation of the intrinsic spatio-temporal covariance of the error process and allows a better modeling of the properties of the random fluctuations affecting the hemodynamic signal. The practical relevance of our model is illustrated using real event-related fMRI experiments.	experiment;general linear model;hemodynamics;relevance;sensor;software regression;stationary process;stochastic process	Habib Benali;Mélanie Pélégrini-Issac;Frithjof Kruggel	2001		10.1007/3-540-45729-1_20	estimation of covariance matrices;statistical model;robust statistics;spatial variability;multivariate statistics;image processing;artificial intelligence;evaluation;covariance;hemodynamics;mathematics;data analysis;digital image;statistics;covariance function	ML	24.766022581230523	-76.24509199184648	86185
f3764136c7344a64e3f5ed6e72618dae299cbd54	facial paralysis modeling based on image morphing	image morphing;splines mathematics shape transforms face approximation methods feature extraction educational institutions;virtual reality;face recognition;medical image processing;affine transforms;diseases;piecewise affine transform facial paralysis modeling image morphing disease facial nerve treatment yanagihara method facial paralysis measurement doctor sample expression facial images educations image warping virtual expression image b spline warping;neurophysiology;piece wise affine facial paralysis expression image b spline transformation;virtual reality affine transforms diseases face recognition image morphing medical image processing neurophysiology	Facial Paralysis is a serious disease that involves the paralysis of any structures innervated by the facial nerve and requires immediate treatment. Yanagihara method is a popular method for the measurement of facial paralysis in Japan. In this method, the patient is asked to make 10 different expressions and the doctor applies the score to each expression. Typical sample expression facial images for different scores are important for educations and references. Since it is not possible to use patient's images as typical sample images, we propose a facial paralysis modeling method based on image warping to generate a virtual expression image of facial paralysis as same as real expression of facial paralysis. We transform the movement or expression of the patient to an average facial image by using both B-spline warping and piece-wise affine transform.	b-spline;facial recognition system;image warping;morphing	Mayu Hakata;Masataka Seo;Yen-Wei Chen;Naoki Matsushiro	2013	2013 6th International Conference on Biomedical Engineering and Informatics	10.1109/BMEI.2013.6747051	computer vision;speech recognition;computer science;virtual reality;neurophysiology;face hallucination	Vision	28.677026617641456	-70.73746025826499	86380
40be36c52e34ce4747b8726a092a392cd173bc05	ccd-based skinning injury recognition on potato tubers (solanum tuberosum l.): a comparison between visible and biospeckle imaging	visible imaging;biospeckle imaging;potato;recognition;skinning injury	Skinning injury on potato tubers is a kind of superficial wound that is generally inflicted by mechanical forces during harvest and postharvest handling operations. Though skinning injury is pervasive and obstructive, its detection is very limited. This study attempted to identify injured skin using two CCD (Charge Coupled Device) sensor-based machine vision technologies, i.e., visible imaging and biospeckle imaging. The identification of skinning injury was realized via exploiting features extracted from varied ROIs (Region of Interests). The features extracted from visible images were pixel-wise color and texture features, while region-wise BA (Biospeckle Activity) was calculated from biospeckle imaging. In addition, the calculation of BA using varied numbers of speckle patterns were compared. Finally, extracted features were implemented into classifiers of LS-SVM (Least Square Support Vector Machine) and BLR (Binary Logistic Regression), respectively. Results showed that color features performed better than texture features in classifying sound skin and injured skin, especially for injured skin stored no less than 1 day, with the average classification accuracy of 90%. Image capturing and processing efficiency can be speeded up in biospeckle imaging, with captured 512 frames reduced to 125 frames. Classification results obtained based on the feature of BA were acceptable for early skinning injury stored within 1 day, with the accuracy of 88.10%. It is concluded that skinning injury can be recognized by visible and biospeckle imaging during different stages. Visible imaging has the aptitude in recognizing stale skinning injury, while fresh injury can be discriminated by biospeckle imaging.	aptitude;attempt;barium;brain injuries;business architecture;charge-coupled device;classification;color;cumulative trauma disorders;dimensions;exploit (computer security);extraction;fractal dimension;frame (physical object);hl7publishingsubsection <operations>;handling (psychology);imaging techniques;least squares;least-squares analysis;logistic regression;machine vision;pervasive informatics;pixel;recognition (psychology);region of interest;sodium starch glycolate type a potato;solanum tuberosum;stale pointer bug;support vector machine;the superficial	Yingwang Gao;Jinfeng Geng;Xiuqin Rao;Yibin Ying	2016		10.3390/s16101734	computer vision;engineering;forensic engineering	Vision	28.531659485456036	-71.87244476178631	86422
9979cf7ace6e7802d8a5afc8b51a54ed04a86d7f	automated feature extraction in brain tumor by magnetic resonance imaging using gaussian mixture models	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	This paper presents a novel method for Glioblastoma (GBM) feature extraction based on Gaussian mixture model (GMM) features using MRI. We addressed the task of the new features to identify GBM using T1 and T2 weighted images (T1-WI, T2-WI) and Fluid-Attenuated Inversion Recovery (FLAIR) MR images. A pathologic area was detected using multithresholding segmentation with morphological operations of MR images. Multiclassifier techniques were considered to evaluate the performance of the feature based scheme in terms of its capability to discriminate GBM and normal tissue. GMM features demonstrated the best performance by the comparative study using principal component analysis (PCA) and wavelet based features. For the T1-WI, the accuracy performance was 97.05% (AUC = 92.73%) with 0.00% missed detection and 2.95% false alarm. In the T2-WI, the same accuracy (97.05%, AUC = 91.70%) value was achieved with 2.95% missed detection and 0.00% false alarm. In FLAIR mode the accuracy decreased to 94.11% (AUC = 95.85%) with 0.00% missed detection and 5.89% false alarm. These experimental results are promising to enhance the characteristics of heterogeneity and hence early treatment of GBM.	area under curve;body tissue;brain neoplasms;consent forms;flair (product);feature extraction;fluid attenuated inversion recovery;glioblastoma;google map maker;hl7publishingsubsection <operations>;intention - mental process;magnetic resonance imaging;mathematical morphology;mesa;mixture model;normal statistical distribution;patients;policy;principal component analysis;radiology;regulation;wavelet;algorithm;biologic segmentation;interest	Ahmad Chaddad	2015		10.1155/2015/868031	text mining;medical research;speech recognition;computer science;bioinformatics;data science;data mining	Vision	37.38487736629846	-78.58444261913387	86424
08761672c6d5cd5d0718d1ccdf73157bb4a55bd4	evaluation of rarity of fingerprints in forensics		A method for computing the rarity of latent fingerprints repr sented by minutiae is given. It allows determining the probability of finding a m atch for an evidence print in a database of n known prints. The probability of random correspondence between evidence and database is determined in three proced u al steps. In the registration stepthe latent print is aligned by finding its core point; which is done using a procedure based on a machine learning approach based on Gaussian processes. In thevidence probability evaluation step a generative model based on Bayesian networks is used to determine the probability of th e evidence; it takes into account both the dependency of each minutia on nearby mi nutiae and the confidence of their presence in the evidence. In the specific probability of random correspondence step the evidence probability is used to determine the probabili ty of match amongn for a given tolerance; the last evaluation is similar to the b irthday correspondence probability for a specific birthday. The generative model is validated using a goodness-of-fit test evaluated with a stan dard database of fingerprints. The probability of random correspondence for sever al latent fingerprints are evaluated for varying numbers of minutiae.	acoustic fingerprint;align (company);bayesian network;computation;fingerprint;gaussian process;generative model;machine learning;minutiae;random graph;real life;stan	Chang Su;Sargur N. Srihari	2010			computer science;machine learning;pattern recognition;data mining;generative model;statistics	ML	27.164474428571665	-67.22502319108018	86449
fd66e2e3a5e2ee676bc039afdf3f00b1e1e604df	a word extraction algorithm for machine-printed documents using a 3d neighborhood graph model	image tridimensionnelle;image recognition;reconocimiento imagen;vision ordenador;document analysis;image segmentation;image processing;image understanding;procesamiento imagen;caracter impreso;image frequency;printed character;text extraction;classification;traitement image;computer vision;connected graph;image interpretation;vecino mas cercano;analyse documentaire;automatic recognition;reconnaissance caractere;interpretacion imagen;traitement document;reconnaissance image;pattern recognition;frequence image;mot isole;palabra aislada;tridimensional image;analisis documental;plus proche voisin;nearest neighbour;vision ordinateur;positional information;document processing;interpretation image;reconnaissance forme;graph model;isolated word;reconocimiento patron;connected component;caractere imprime;graphe connexe;character recognition;clasificacion;frecuencia imagen;reconocimiento caracter;imagen tridimensional;reconocimiento automatico;reconnaissance automatique;tratamiento documento;grafo conexo	Automatic character recognition and image understanding of a given paper document are the main objectives of the computer vision field. For these problems, a basic step is to isolate characters and group words from these isolated characters. In this paper, we propose a new method for extracting characters from a mixed text/graphic machine-printed document and an algorithm for distinguishing words from the isolated characters. For extracting characters, we exploit several features (size, elongation, and density) of characters and propose a characteristic value for classification using the run-length frequency of the image component. In the context of word grouping, previous works have largely been concerned with words which are placed on a horizontal or vertical line. Our word grouping algorithm can group words which are on inclined lines, intersecting lines, and even curved lines. To do this, we introduce the 3D neighborhood graph model which is very useful and efficient for character classification and word grouping. In the 3D neighborhood graph model, each connected component of a text image segment is mapped onto 3D space according to the area of the bounding box and positional information from the document. We conducted tests with more than 20 English documents and more than ten oriental documents scanned from books, brochures, and magazines. Experimental results show that more than 95% of words are successfully extracted from general documents, even in very complicated oriental documents.	ascii art;algorithm;book;computer vision;connected component (graph theory);constraint logic programming;document processing;experiment;image embossing;image segmentation;intersection (euclidean geometry);minimum bounding box;optical character recognition;printing;run-length encoding;vertical bar;xslt/muenchian grouping	Hwan-Chul Park;Se-Young Ok;Young-Jung Yu;Hwan-Gue Cho	2001	International Journal on Document Analysis and Recognition	10.1007/PL00010903	computer vision;speech recognition;connected component;document processing;image processing;biological classification;computer science;artificial intelligence;connectivity;image segmentation	Vision	35.807796946306595	-67.20387073138835	86528
282af9fa6d3e85429d51d72a1674f82e5e201841	a neural network architecture for automatic segmentation of fluorescence micrographs	automatic segmentation;segmentation;cell shape;fluorescence microscopy;recurrent neural network;contour grouping;neural network;functional proteomics	A system for the automatic segmentation of fluorescence micrographs is presented. In a first step positions of fluorescent cells are detected by a fast learning neural network, which acquires the visual knowledge from a set of training cell-image patches selected by the user. Guided by the detected cell positions the system extracts in the second step the contours of the cells. For contour extraction a recurrent neural network model is used to approximate the cell shapes. Even though the micrographs are noisy and the fluorescent cells vary in shape and size, the system detects at minimum of the cells.	approximation algorithm;artificial neural network;high-throughput computing;human reliability;network architecture;network model;recurrent neural network;throughput	Tim W. Nattkemper;Heiko Wersing;Walter Schubert;Helge J. Ritter	2000	Neurocomputing	10.1016/S0925-2312(01)00642-7	fluorescence microscope;computer vision;computer science;recurrent neural network;machine learning;pattern recognition;segmentation;artificial neural network	ML	30.990161102674048	-73.79344995253729	86595
1cbf7d60ab3e74185fa2c11676c1a0704b9d3ecc	segmentation of burn images using the l*u*v* space and classification of their depths by color and texture imformation	texture;classification algorithm;fuzzy artmap;image segmentation;neural networks;automatic assessment;color space;color difference;skin;neural network classifier;euclidean distance;burn depth;medical diagnostics;success rate;neural network;color image segmentation	In this paper a burn color image segmentation and classification algorithm is proposed. The aim of the algorithm is to separate the burn wounds from healthy skin, and the different types of burns (burn depths) among themselves. We use digital color photographs. The system is based on the color and texture information, as these are the characteristics observed by physicians in order to give a diagnosis. We use a perceptually uniform color space (L*u*v*), since Euclidean distances calculated in this space correspond to perceptually color differences. After the burn is segmented, some color and texture descriptors features are calculated and they are the inputs to a Fuzzy-ARTMAP neural network. The neural network classifies them into three types of burns: superficial dermal, depth dermal and full thickness. We get an average classification success rate of 88.89%.© (2002) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Begoña Acha;Carmen Serrano;José Ignacio Acha	2002		10.1117/12.467117	color histogram;computer vision;geography;machine learning;pattern recognition	Vision	36.01661252795467	-75.55841710263213	86724
0abafa60ecca19fbe40e7abe1a4aaa3116cb8bfc	a novel cumulative level difference mean based gldm and modified abcd features ranked using eigenvector centrality approach for four skin lesion types classification	cumulative level-difference mean;feature ranking;modified-abcd feature vector;skin lesion classification;support vector machine	BACKGROUND AND OBJECTIVE Melanoma is one of the major death causes while basal cell carcinoma (BCC) is the utmost incident skin lesion type. At their early stages, medical experts may be confused between both types with benign nevus and pigmented benign keratoses (BKL). This inspired the current study to develop an accurate automated, user-friendly skin lesion identification system.   METHODS The current work targets a novel discrimination technique of four pre-mentioned skin lesion classes. A novel proposed texture feature, named cumulative level-difference mean (CLDM) based on the gray-level difference method (GLDM) is extracted. The asymmetry, border irregularity, color variation and diameter are summed up as the ABCD rule feature vector is originally used to classify the melanoma from benign lesions. The proposed method improved the ABCD rule to also classify BCC and BKL by using the proposed modified-ABCD feature vector. In the modified set of ABCD features, each border feature, such as compact index, fractal dimension, and edge abruptness is considered a separate feature. Then, the composite feature vector having the pre-mentioned features is ranked using the Eigenvector Centrality (ECFS) feature ranking method. The ranked features are then classified by a cubic support vector machine for different numbers of selected features.   RESULTS The proposed CLDM texture features combined with the ranked ABCD features achieved outstanding performance to classify the four targeted classes (melanoma, BCC, nevi and BKL). The results report 100% outstanding performance of the sensitivity, accuracy and specificity per each class compared to other features when using the highest seven ranked features.   CONCLUSIONS The proposed system established that Melanoma, BCC, nevus and BKL are efficiently classified using cubic SVM with the new feature set. In addition, the comparative studies proved the superiority of the cubic SVM to classify the four classes.	abcd schema;basal (phylogenetics);basal cell carcinoma;benign melanocytic nevus;cessation of life;class;classes - encounter;classification;confusion;cubic function;diameter (qualifier value);eigenvector centrality;electronic case filing system;extraction;feature vector;fractal dimension;giant lock;inspiration function;klb protein, human;keratosis;name;sensitivity and specificity;support vector machine;usability;melanoma	Maram A. Wahba;Amira S. Ashour;Yanhui Guo;Sameh A. Napoleon;Mustafa Abd-Elnaby	2018	Computer methods and programs in biomedicine	10.1016/j.cmpb.2018.08.009	computer vision;eigenvector centrality;benign nevus;support vector machine;feature vector;nevus;computer science;ranking;lesion types;artificial intelligence;lesion identification;pattern recognition	ML	35.3703715987368	-75.24294994642541	87026
5d2001b6843f310bfce1952e4ca44a0a9ce1c15f	a robust and accurate approach to automatic blood vessel detection and segmentation from angiography x-ray images using multistage random forests	detection and tracking algorithms;angiography;algorithms;blood vessels;x rays	In this paper we propose a novel approach based on multi-stage random forests to address problems faced by traditional vessel segmentation algorithms on account of image artifacts such as stitches organ shadows etc.. Our approach consists of collecting a very large number of training data consisting of positive and negative examples of valid seed points. The method makes use of a 14× 14 window around a putative seed point. For this window three types of feature vectors are computed viz. vesselness, eigenvalue and a novel effective margin feature. A random forest RF is trained for each of the feature vectors. At run time the three RFs are applied in succession to a putative seed point generated by a naiive vessel detection algorithm based on vesselness. Our approach will prune this set of putative seed points to correctly identify true seed points thereby avoiding false positives. We demonstrate the effectiveness of our algorithm on a large dataset of angio images.	algorithm;feature vector;heuristic;machine learning;multistage amplifier;naivety;radio frequency;radiography;random forest;run time (program lifecycle phase);succession;visual artifact;viz: the computer game	Vipin Gupta;Amit Kale;Hari Sundar	2012		10.1117/12.910649	computer vision;simulation;computer science;data mining	Vision	36.1316633431222	-74.99582933116609	87045
353e822c4f4580f344e55bcc471168ec89a72af8	automatic localization of iaslc-defined mediastinal lymph node stations on ct images using fuzzy models	lung cancer;radiology;object recognition;computed tomography;cancer;algorithms;modeling;chest;diseases and disorders	Lung cancer is associated with the highest cancer mortality rates among men and women in the United States. The accurate and precise identification of the lymph node stations on computed tomography (CT) images is important for staging disease and potentially for prognosticating outcome in patients with lung cancer, as well as for pretreatment planning and response assessment purposes. To facilitate a standard means of referring to lymph nodes, the International Association for the Study of Lung Cancer (IASLC) has recently proposed a definition of the different lymph node stations and zones in the thorax. However, nodal station identification is typically performed manually by visual assessment in clinical radiology. This approach leaves room for error due to the subjective and potentially ambiguous nature of visual interpretation, and is labor intensive. We present a method of automatically recognizing the mediastinal IASLC-defined lymph node stations by modifying a hierarchical fuzzy modeling approach previously developed for body-wide automatic anatomy recognition (AAR) in medical imagery. Our AAR-lymph node (AAR-LN) system follows the AAR methodology and consists of two steps. In the first step, the various lymph node stations are manually delineated on a set of CT images following the IASLC definitions. These delineations are then used to build a fuzzy hierarchical model of the nodal stations which are considered as 3D objects. In the second step, the stations are automatically located on any given CT image of the thorax by using the hierarchical fuzzy model and object recognition algorithms. Based on 23 data sets used for model building, 22 independent data sets for testing, and 10 lymph node stations, a mean localization accuracy of within 1-6 voxels has been achieved by the AAR-LN system. © (2014) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	ct scan;fuzzy concept	Monica M. S. Matsumoto;Niha G. Beig;Jayaram K. Udupa;Steven Archer;Drew A. Torigian	2014		10.1117/12.2044333	systems modeling;cognitive neuroscience of visual object recognition;computed tomography;cancer	Robotics	36.000778502420765	-80.16805214183186	87158
305fc3f8e3261776ecc9ba7b8487cc3daa6dc99b	color-based bird image classification using support vector machine		The classification and identification of the bird species from the visual image is complex compared by using audio song. The knowledge of the features species type is very important as to ensure it is classified to the correct species. Color-based feature extraction is one of the procedure in extracting the color properties from the bird which to represent the species of the bird. However, it is a challenging task due to the environment problems which is from the background with natural habitat of the bird images. It is also difficult when the bird images come into view of different angles and sizes. Therefore, this paper proposed a solution to consumer electronic which field-portability, cost-effectiveness and easy-to-use interface that experimented on the segmented bird images as to ensure the accurate results of classification is produced. This paper investigated on nine color-based features of mean, standard deviation and skewness of each plane of red, green and blue (RGB) from the bird images. All these features are experimented on 100 images for each species of snowy owl and toucan. The bird classification using Support Vector Machine algorithm is identified as a promising method in bird classification which produced 97.14% accuracy rate for training data and 98.33% for testing data.	algorithm;color;computer vision;feature extraction;habitat;software portability;support vector machine	Rosniza Roslan;Nur Amalina Nazery;Nursuriati Jamil;Raseeda Hamzah	2017	2017 IEEE 6th Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2017.8229492	skewness;support vector machine;standard deviation;feature extraction;image segmentation;test data;rgb color model;contextual image classification;pattern recognition;artificial intelligence;computer science	AI	36.154639071225425	-69.05591456191837	87413
a25bfeab790904b4a002d22847fed1f901d69418	survey on segmentation and classification approaches of optic cup and optic disc for diagnosis of glaucoma		Abstract Over the past years, use of the retinal fundus images has increased for diagnosis of retinal diseases. Glaucoma is a disease which causes damage to the optic nerve of the eye resulting in deteriorated vision. Once diagnosed, the disease cannot be treated completely, but timely detection can further control the effect of glaucoma. Detection is usually performed by analyzing the optic disc followed by optic cup present on an exit of ganglion cells in the eye. Using retinal fundus images and image processing approaches, various research studies have been published till date, but the problem of accurate segmentation of disc and cup is still a major concern. This paper aims to analyze various segmentation approaches used by different researchers for optic disc followed by the optic cup and its classification for diagnosis of glaucoma. Also, the paper addresses various research gaps and challenges which need to be dealt with for improving the accuracy of segmentation and classification.		Niharika Thakur;Mamta Juneja	2018	Biomed. Signal Proc. and Control	10.1016/j.bspc.2018.01.014	optic cup (anatomical);image processing;computer vision;artificial intelligence;optic disc;optic nerve;mathematics;glaucoma;fundus (eye);segmentation	ML	35.618290073733675	-76.30823213262907	87510
a85a0f82a5cf7d83318c0f112e1d8ffaa0fb582a	intelligent computing theories and applications		Mass classification is an important problem in breast cancer diagnosis. In this paper, we investigated the classification of masses with feature selection. Based on the initial contour guided by radiologist, level set algorithm is used to deform the contour and achieves the final segmentation. Morphological features are extracted from the boundary of segmented regions. Then, important features are extracted based on mutual information criterion. Linear discriminant analysis and support vector machine are investigated for the final classification. Mammography images from DDSM were used for experiment. The method achieved an accuracy of 86.6% with mutual information based feature selection and SVM classifier. The experimental result shows that mutual information based feature selection is useful for the diagnosis of masses.	algorithm;feature selection;linear discriminant analysis;mutual information;radiology;support vector machine	LNAI Founding	2012		10.1007/978-3-642-31576-3		ML	34.942769358830766	-74.79178507023208	87519
3077b42832bd30c5db4b0acf837aa1396a6a1f66	contrast optimization in clinical contrast-enhanced digital mammography images	contrast enhanced digital mammography;contrast medium;breast imaging;angiogenesis;cedm;image subtraction;dual energy	We performed a study to assess the potential value of absolute and relative measures of area and volumetric breast density in predicting breast cancer risk. A case-control study was performed. The raw mediolateral-oblique (MLO) view digital mammography (DM) images of 106 women with unilateral breast cancer and 318 age-matched controls were retrospectively analyzed. The unaffected breast of the cancer cases was used as a surrogate of higher cancer risk. For each image, area and volumetric breast density measures were estimated using fully-automated software. The performance of the density metrics to distinguish between cancer cases and controls was assessed using linear discriminant and ROC curve analysis. Absolute measures of dense tissue content had stronger discriminatory capacity (AUCs=0.65-0.67) than percent density (AUCs=0.57). Shape-location features also showed modest discriminatory power (AUC=0.56-0.65). A combined area-volumetric model was able to outperform (AUC=0.70) any single-feature model. Absolute measures of fibroglandular tissue content were seen to be more discriminative than percent density estimates, indicating that total fibroglandular tissue content may be more reflective of cancer risk than relative measures of density. Our results suggest that area and volumetric breast density measures could be complementary in breast cancer risk assessment.	feature model;linear discriminant analysis;oblique projection;receiver operating characteristic;risk assessment;volume mesh	Juan-Pablo Cruz-Bastida;Iván Rosado-Méndez;Héctor Pérez-Ponce;Yolanda Villaseñor;Héctor A. Galván;Flavio E. Trujillo-Zamudio;Luis Benítez-Bribiesca;María-Ester Brandan	2012		10.1007/978-3-642-31271-7_3	computer vision;radiology;medicine;medical physics	ML	32.1220608721154	-78.95596744645691	87536
f93cb39b676f1888ce3696cdba791fbf97dfbbfd	fuzzy logic color detection: blue areas in melanoma dermoscopy images	blue area;dysplastic nevi;melanoma;fuzzy logic;dermoscopy;image analysis	Fuzzy logic image analysis techniques were used to analyze three shades of blue (lavender blue, light blue, and dark blue) in dermoscopic images for melanoma detection. A logistic regression model provided up to 82.7% accuracy for melanoma discrimination for 866 images. With a support vector machines (SVM) classifier, lower accuracy was obtained for individual shades (79.9-80.1%) compared with up to 81.4% accuracy with multiple shades. All fuzzy blue logic alpha cuts scored higher than the crisp case. Fuzzy logic techniques applied to multiple shades of blue can assist in melanoma detection. These vector-based fuzzy logic techniques can be extended to other image analysis problems involving multiple colors or color shades.		Mounika Lingala;R. Joe Stanley;Ryan K. Rader;Jason R. Hagerty;Harold S. Rabinovitz;Margaret Oliviero;Iqra Choudhry;William V. Stoecker	2014	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2014.03.007	fuzzy logic;computer vision;image analysis;computer science;artificial intelligence;mathematics;optics	Vision	35.81510117096791	-75.02017976042214	87547
0c85856efd976ec2dffde0d8a4e2129f9ce56a46	study and development of a computer-aided diagnosis system for classification of chest x-ray images using convolutional neural networks pre-trained for imagenet and data augmentation		Convolutional neural networks (ConvNets) are the actual standard for image recognizement and classification. On the present work we develop a Computer Aided-Diagnosis (CAD) system using ConvNets to classify a x-rays chest images dataset in two groups: Normal and Pneumonia. The study uses ConvNets models available on the PyTorch platform: AlexNet, SqueezeNet, ResNet and Inception. We initially use three training styles: complete from scratch using random initialization, using a pre-trained ImageNet model training only the last layer adapted to our problem (transfer learning) and a pre-trained model modified training all the classifying layers of the model (fine tuning). The last strategy of training used is with data augmentation techniques that avoid over fitting problems on ConvNets yielding the better results on this study.	artificial neural network;computation;computational resource;computer-aided design;convolutional neural network;epoch (reference date);imagenet;overfitting;radiography	Vinicius Pavanelli Vianna	2018	CoRR		convolutional neural network;overfitting;pattern recognition;transfer of learning;machine learning;artificial intelligence;initialization;computer-aided diagnosis;scratch;cad;computer science;residual neural network	ML	30.303989830191888	-74.95119056960193	87592
e5e2eb0aa8deff4d6c4a010eee48df772d738ef7	segmentation of the main structures in hematoxylin and eosin images		Pathologists conduct a biopsy on a tissue when a carcinoma case for a patient is suspected. They stain the cells on that tissue using some biochemical materials that react with a certain cell element. They put stained cells onto a slide and examine the cells by using an optical microscope device. In our case, we will focus on Hu0026E stained breast tissue samples. Pathologists keep track of a standard process to determine the patientu0027s condition by focusing on the structures in Hu0026E stained images such as epithelium, lumen, and nuclei. They employ scoring methods with quantitative and qualitative inferences in this decision process. Those inferences contain mitotic nuclei activity, number of the nucleus, lumen region distribution, epithelium area size and so on. Each factor has a score for the patientu0027s carcinoma case. In this paper a novel image processing algorithm is developed to enable the pathologists to make decisions easily by segmenting epithelium, lumen and nuclei structures. Actual microscopic images could show some degenerated cell structures because of staining variability and some artifacts. Our algorithm demonstrates the structures clearly while colorizing them with distinctive colors considering their transparency.	active galactic nucleus;algorithm;color;image processing;spatial variability	Sercan Cayir;Ercan Alp Serteli;Samet Ayalti;Sukru Burak Cetin;Gokhan Hatipoglu;Mustafa E. Kamasak;Cisem Yazici;Salar Razavi;Fariba D. Khameneh;Imam Samil Yetik;Ekrem Cihad Cetin	2018	2018 26th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2018.8404814	artificial intelligence;computer vision;nucleus;epithelium;image segmentation;h&e stain;image processing;computer science;carcinoma;staining;biopsy	ML	37.13731733011852	-77.00321921596704	87712
a106e79ce8a65b289cbe9a99099a4ddd1d4de486	cellular and subcellular so-localisations of immunologic expression patterns revised by boolean feature operators		Modern Confocal Laser Scan Microscopy is a sophist icated technique allowing acquisition of information from different fluoresce nce markers in the same tissue by separating them into different confocal channels. For an adequ ate interpretation of these multidimensional images advanced image processing techniques are req uired. In this study, we introduce an automated image analysis based on Boolean logic wor king with features instead of single pixels. Feature based image analysis preserves the ori ginal morphology of the objects and allows the unlimited identification of co-localisations. W e demonstrate the practicability of our feature-based algorithm on triple-immuno fluorescence stained neural cells of the auditory cortex of gerbils.	algorithm;boolean algebra;image analysis;image processing;logical connective;mathematical morphology;pixel	Silke Kreitz;Werner Zuschratter;Rainer Pielot;Andreas Hess	2002				ML	37.87333380081981	-70.98102986390242	87826
aa781ff1cec52a1e78b6e673480abefd7b79568d	development of cad prototype system for crohn's disease	crohn s disease;ct image;computer aided diagnosis;endoscopy;digestive system;intestine;medical diagnostics;gastrointestinal tract;displays;endoscopes;abdomen;vu;virtual unfolding;region growing;diseases and disorders;extraction method;structure analysis	ABSTRACT The purpose of this paper is to present a CAD prototype system for Crohns disease. Crohns disease causesinammation or ulcers of the gastrointestinal tract. The number of patients of Crohns disease is increasingin Japan. Symptoms of Crohns disease include intestinal stenosis, longitudinal ulcers, and stulae. Opticalendoscope cannot pass through intestinal stenosis in some cases. We propose a new CAD system using abdominalfecal tagging CT images for ecient diagnosis of Crohns disease. The system displays virtual unfolded (VU),virtual endoscopic, curved planar reconstruction, multi planar reconstruction, and outside views of both smalland large intestines. To generate the VU views, we employ a small and large intestines extraction method followedby a simple electronic cleansing method. The intestine extraction is based on the region growing process, whichuses a characteristic that tagged uid neighbor air in the intestine. The electronic cleansing enables observationof intestinal wall under tagged uid. We change the height of the VU views according to the perimeter of theintestine. In addition, we developed a method to enhance the longitudinal ulcer on views of the system. Weenhance concave parts on the intestinal wall, which are caused by the longitudinal ulcer, based on local intensitystructure analysis. We examined the small and the large intestines of eleven CT images by the proposed system.The VU views enabled ecient observation of the intestinal wall. The height change of the VU views helpsnding intestinal stenosis on the VU views. The concave region enhancement made longitudinal ulcers clear onthe views.Keywords: CT image, Crohns disease, intestine, computer aided diagnosis, virtual unfolding	computer-aided design;prototype	Masahiro Oda;Takayuki Kitasaka;Kazuhiro Furukawa;Osamu Watanabe;Takafumi Ando;Hidemi Goto;Kensaku Mori	2010		10.1117/12.844590	digestion;structural analysis;region growing	Robotics	38.20353869022975	-78.4932304024988	87936
bfd7853d77704c1fb45dc56061ad89bbdd5240e0	chest radiograph pathology categorization via transfer learning	computer aided diagnosis;deep learning;disease categorization;chest radiographs;feature selection;cnn	The goal of this chapter is to give an overview of the research we have been conducting in automated X-ray pathology detection for the past 10 years, from bag-of-visual-words (BoVW) models to the Convolutional Neural Network (CNN) Deep Learning schemes. Our study was one of the first to suggest the possibility of using non-medical training, using transfer learning from the general imagery to the medical domain. In this chapter we explore deep features that are extracted from intermediate CNN layers in comparison to a set of classical shallow features, including GLCM, PHOG, GABOR, GIST and the more recent, state-of-the-art BoVW model. We investigate the possible benefits of using feature selection techniques on the Deep CNN feature layers. Average AUC results of close to 90% are shown for categorization of 6 different pathologies in a dataset of more than 600 radiographs. This study shows the strength and robustness of the CNN features. We conclude that deep learning with large scale non-medical image databases may be a good substitute, or addition, to domain specific representations which are yet to be available for general medical image recognition tasks. With the BoW schemes, our method won first place in ImageClef competitions. With the DL architectures, we are now able to use the system in real clinical settings.	categorization;radiography	Idit Diamant;Yaniv Bar;Ofer Geva;Lior Wolf;Gali Zimmerman-Moreno;Sivan Lieberman;Eli Konen;Hayit Greenspan	2017		10.1016/B978-0-12-810408-8.00018-3	computer vision;computer science;artificial intelligence;machine learning	Vision	32.19896853917454	-75.03410120128864	88261
6ff5e8f0e1791317c127ff93a0172c03f241f42e	computerized classification can reduce unnecessary biopsies in bi-rads category 4a lesions	interventional procedure	The objective of the study was to assess the potential of a CAD device with computer aided classification capabilities to reduce interventional procedures for BI-RADS category 4A lesions. 113 such lesions (17 masses, 96 clusters), forwarded for biopsy (103 benign) were analyzed retrospectively by a CAD device that generated descriptors. The device extracted quantitative features characterizing the lesions by shape, margins, size and distribution. Descriptors taken from the BI-RADS lexicon for the appearance of the lesion were generated based on the values of the quantitative features. A paradigm based on the computer generated descriptors was developed to assist in assigning a level of suspicion. The paradigm deemed malignant, all 10 malignant cases of the study (100% sensitivity) and correctly classified 38 of the 103 benign lesions. The CAD-generated descriptors, thus, eliminated 36.9% of unnecessary biopsies without decreasing the sensitivity.	bi-rads	Isaac Leichter;Richard Lederman;Shalom Buchbinder;Yossi Srour;Philippe Bamberger;Fanny Sperber	2006		10.1007/11783237_11	computer vision;medicine;pathology;biological engineering	Vision	35.46326951916147	-78.8330806604527	88352
b5e23433a0cae630dacf3581548d1f2637bad114	detection of mammographic masses by content-based image retrieval		Computer-aided diagnosis (CAD) of mammographic masses is important yet challenging, since masses have large variation in shape and size and are often indistinguishable from surrounding tissue. As an alternative solution, content-based image retrieval (CBIR) techniques can facilitate the diagnosis by finding visually similar cases. However, they still need radiologists to identify suspicious regions in the query case. To overcome the drawbacks of both kinds of methods, we propose a CAD approach that integrates image retrieval with learning-based mass detection. Specifically, a query mammogram is first matched with a database of exemplar masses, getting a series of similarity maps. Then these maps are subtracted by discriminatively learned thresholds to eliminate noise. At last, individual similarity maps are aggregated, and local maxima in the final map are selected as masses. By utilizing a large database, our approach can effectively detect masses despite their variation. Moreover, it bypasses the identification of suspicious regions by radiologists. Experiments are conducted on 500 mammograms randomly selected from the digital database for screening mammography (DDSM) using receiver operating characteristic (ROC) analysis. The proposed approach achieves a promising ROC area index Az = 0.91, and outperforms two traditional classifier-based CAD methods.	computer-aided design;content-based image retrieval;database;discriminative model;experiment;map;mass effect trilogy;maxima and minima;naive bayes classifier;radiology;randomness;receiver operating characteristic	Menglin Jiang;Shaoting Zhang;Dimitris N. Metaxas	2014		10.1007/978-3-319-10581-9_5	maxima and minima;image retrieval;artificial intelligence;cad;content-based image retrieval;receiver operating characteristic;classifier (linguistics);screening mammography;pattern recognition;computer science	AI	34.53907869196168	-76.96678931362405	89150
a5234be352a934b87028cf66269803fad62ed8d3	retrieval of 4d dual energy ct for pulmonary embolism diagnosis	4d texture;pulmonary embolism;dual energy ct	Pulmonary embolism is a common condition with high short– term morbidity. Pulmonary embolism can be treated successfully but diagnosis remains difficult due to the large variability of symptoms, which are often non–specific including breath shortness, chest pain and cough. Dual energy CT produces 4–dimensional data by acquiring variation of attenuation with respect to spatial coordinates and also with respect to the energy level. This additional information opens the possibility of discriminating tissue with specific material content, such as bone and adjacent contrast. Despite having already been available for clinical use for a while, there are few applications where Dual energy CT is currently showing a clear clinical advantage. In this article we propose to use the additional energy–level data in a 4D dataset to quantify texture changes in lung parenchyma as a way of finding parenchyma perfusion deficits characteristic of pulmonary embolism.	energy level;heart rate variability;while	Antonio Foncubierta-Rodríguez;Alejandro Vargas;Alexandra Platon;Pierre-Alexandre Poletti;Henning Müller;Adrien Depeursinge	2012		10.1007/978-3-642-36678-9_5	radiology;medicine;pathology;surgery	Comp.	33.41765641961125	-79.93052539247456	89683
b438dd974c51d10575e74a62b33b46702ba070da	lumen and media-adventitia border detection in ivus images using texture enhanced deformable model	border detection;ensemble svm;ivus;texture enhancement	Lumen and media-adventitia (MA) borders in intravascular ultrasound (IVUS) images are critical for assessing the dimensions of vascular structures and providing plaque information in the diagnosis and navigation of vascular interventions. However, manual delineation of the lumen and MA borders is an intricate and time-consuming process. In this paper, a texture-enhanced deformable model (TEDM) is proposed to accurately detect these borders by incorporating texture information with the morphological factors of deformable model. An ensemble support vector machine classifier is used to classify IVUS pixels presented by texture features into different tissue types. The image regionalization maps of different tissue types are further used for texture enhancement modules in the TEDM. The proposed TEDM method has been tested on 1500 images from 15 clinical IVUS datasets by comparing with the manual delineations. Evaluation results demonstrate that our method can accurately detect lumen and MA surfaces with small surface distance errors of 0.17 and 0.19 mm, respectively. Accurate segmentation results provide 2D measurements of MA/lumen areas and 3D vessel visualizations for vascular interventions.		Fang Chen;Ruibin Ma;Jia Liu;Mingyu Zhu;Hongen Liao	2018	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2018.02.003	adventitia;computer vision;intravascular ultrasound;support vector machine;pixel;artificial intelligence;lumen (unit);medicine	Vision	36.329193423994504	-77.85880351247961	89755
3dd5182862f3f642c6cb2bacb2fa3ec7ff8e8c35	an application to pulmonary emphysema classification based on model of texton learning by sparse representation	emphysema;computed tomography;tissues;computer aided diagnosis;lung;associative arrays	We aim at using a new texton based texture classification method in the classification of pulmonary emphysema in computed tomography (CT) images of the lungs. Different from conventional computer-aided diagnosis (CAD) pulmonary emphysema classification methods, in this paper, firstly, the dictionary of texton is learned via applying sparse representation(SR) to image patches in the training dataset. Then the SR coefficients of the test images over the dictionary are used to construct the histograms for texture presentations. Finally, classification is performed by using a nearest neighbor classifier with a histogram dissimilarity measure as distance. The proposed approach is tested on 3840 annotated regions of interest consisting of normal tissue and mild, moderate and severe pulmonary emphysema of three subtypes. The performance of the proposed system, with an accuracy of about 88%, is comparably higher than state of the art method based on the basic rotation invariant local binary pattern histograms and the texture classification method based on texton learning by k-means, which performs almost the best among other approaches in the literature.© (2012) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	sparse approximation;sparse matrix;texton	Min Zhang;Xiangrong Zhou;Satoshi Goshima;Huayue Chen;Chisako Muramatsu;Takeshi Hara;Ryujiro Yokoyama;Masayuki Kanematsu;Hiroshi Fujita	2012		10.1117/12.912454	computer vision;computer science;machine learning;pattern recognition;computed tomography;associative array	Vision	34.00324081858454	-75.30026854899027	89763
8e6d0d56687db9bb03e1383a353189e039c3fe7e	fast detection of sclerotinia sclerotiorum on oilseed rape leaves using low-altitude remote sensing technology	sclerotinia sclerotiorum;image fusion;machine learning;multispectral technology;oilseed rape;thermal imaging technology	Sclerotinia sclerotiorum, one of the major diseases infecting oilseed rape leaves, has seriously affected crop yield and quality. In this study, an indoor unmanned aerial vehicle (UAV) low-altitude remote sensing simulation platform was built for disease detection. Thermal, multispectral and RGB images were acquired before and after being artificially inoculated with Sclerotinia sclerotiorum on oilseed rape leaves. New image registration and fusion methods based on scale-invariant feature transform (SIFT) were presented to construct a fused database using multi-model images. The changes of temperature distribution in different sections of infected areas were analyzed by processing thermal images, the maximum temperature difference (MTD) on a single leaf reached 1.7 degrees Celsius 24 h after infection. Four machine learning models were established using thermal images and fused images respectively, including support vector machine (SVM), random forest (RF), K-nearest neighbor (KNN) and naïve Bayes (NB). The results demonstrated that the classification accuracy was improved by 11.3% after image fusion, and the SVM model obtained a classification accuracy of 90.0% on the task of classifying disease severity. The overall results indicated the UAV low-altitude remote sensing simulation platform equipped with multi-sensors could be used to early detect Sclerotinia sclerotiorum on oilseed rape leaves.		Feng Cao;Fei Liu;Han Guo;Wenwen Kong;Chu Zhang;Yong He	2018		10.3390/s18124464		AI	34.23719512413266	-70.6108083716336	89824
873bd058487f808c0f66d4d8cdfc516712961fa4	wavelet-based asphalt concrete texture grading and classification	wavelet features;statistical classification;asphalt concrete grading;texture classification;fractal dimension;wavelet transforms;wavelet transform;cross validation;support vector machine;asphalt concrete;classification accuracy;automatic classification;quality control;fractal analysis;wavelets	In this Paper, we introduce a new method for evaluation, quality control, and automatic grading of texture images representing different textural classes of Asphalt Concrete (AC). Also, we present a new asphalt concrete texture grading, wavelet transform, fractal, and Support Vector Machine (SVM) based automatic classification and recognition system. Experimental results were simulated using different cross-validation techniques and achieved an average classification accuracy of 91.4.0 % in a set of 150 images belonging to five different texture grades.	cross-validation (statistics);fractal;support vector machine;wavelet transform	Ali Almuntashri;Sos S. Agaian	2011		10.1117/12.876682	statistical classification;computer vision;speech recognition;pattern recognition;wavelet transform	Vision	34.83879145910993	-73.61295106263299	89831
5e8ab2946926f52aa0d3f0cd39fe7953e52dde38	visual analytic-based technique for handwritten indic script identification - a greedy heuristic feature fusion framework			greedy algorithm;heuristic	Sk Md Obaidullah;Chayan Halder;Nibaran Das;Kaushik Roy	2015		10.1007/978-81-322-2695-6_19		Robotics	28.006127951315666	-66.55295183193131	90292
5baefd1d51e7380f2c164c8e8aa04073c8ffaea8	a non-invasive approach for estimation of hemoglobin analyzing blood flow in palm		Estimation of hemoglobin is important to diagnose anaemia which is a grave public health problem in developing and in other less developed countries. Hemoglobin, which normally is present within red blood cells, is the compound responsible for coloring blood red. Therefore redness of blood and consequently of skin, is a measure of hemoglobin concentration in blood. We utilize redness of palm to estimate hemoglobin non-invasively. We propose a machine vision based portable, user-friendly, non-invasive and cost effective approach to measure hemoglobin exploiting the redness measure of skin of palm. A camera captures the video of a palm of a human subject before and after the blood flow is restricted to the palm using a sphygmomanometer cuff in forearm close to the wrist. The video continues till the blood flow is released after sudden and rapid release of pressure in cuff. Measuring the redness of skin color after occlusion and after resumption of blood flow to palm, we propose a regression based classifier to predict the hemoglobin content of the blood. Through a human subject study, we show that our approach can estimate hemoglobin content up to an accuracy of 91%.	graph coloring;machine vision;usability	Bikash Santra;Dipti Prasad Mukherjee;Dipankar Chakrabarti	2017	2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)	10.1109/ISBI.2017.7950708	computer vision;artificial intelligence;sphygmomanometer;cuff;blood flow;forearm;surgery;internal medicine;palm;hemoglobin;cardiology;medicine	Vision	28.50342900318305	-71.88722297947895	90556
66cf4421e976216dc6f79dbbbdeecb4d5ac05c61	deep sparse feature selection for computer aided endoscopy diagnosis	computer aided diagnosis;endoscopy;deep sparse;image representation;feature extraction;group sparsity;feature selection	In this paper, we develop a computer aided diagnosis algorithm to detect and classify the abnormalities in vision-based endoscopic examination. We focus on analyzing the traditional gastroscope data and help the medical experts improve the accuracy of medical diagnosis with our analysis tool. To achieve this, we first segment the image into superpixels, then extract various color and texture features from them and combine the features into one feature vector to represent the images. This approach is more flexible and accurate than the traditional patch-based image representation. Then we design a novel feature selection model with group sparsity, Deep Sparse SVM (DSSVM) that not only can assign a suitable weight to the feature dimensions like the other traditional feature selection models, but also directly exclude useless features from the feature pool. Thus, our DSSVM model can maintain the accuracy while reducing the computation complexity. Moreover, the image quality is also pre-assessed. For the experiments, we build a new gastroscope dataset with a total of about 3800 images from 1284 volunteers, and conducted various experiments and comparisons with other algorithms to justify the effectiveness and efficiency of our algorithm. & 2014 Elsevier Ltd. All rights reserved.	computation;experiment;feature selection;feature vector;image quality;medical algorithm;sparse matrix	Yang Cong;Shuai Wang;Ji Liu;Jun Cao;Yunsheng Yang;Jiebo Luo	2015	Pattern Recognition	10.1016/j.patcog.2014.09.010	computer vision;feature extraction;computer science;machine learning;kanade–lucas–tomasi feature tracker;pattern recognition;feature selection;feature	AI	33.092105747756015	-74.6182337509714	90780
708c6a0020f2c56ab225a748c3f90eb3faddfecc	locally linear embedding (lle) for mri based alzheimer's disease classification	sensitivity and specificity;female;brain;middle aged;male;image enhancement;image interpretation computer assisted;magnetic resonance imaging;reproducibility of results;artificial intelligence;algorithms;pattern recognition automated;humans;alzheimer disease;linear models;computer simulation;aged	Modern machine learning algorithms are increasingly being used in neuroimaging studies, such as the prediction of Alzheimer's disease (AD) from structural MRI. However, finding a good representation for multivariate brain MRI features in which their essential structure is revealed and easily extractable has been difficult. We report a successful application of a machine learning framework that significantly improved the use of brain MRI for predictions. Specifically, we used the unsupervised learning algorithm of local linear embedding (LLE) to transform multivariate MRI data of regional brain volume and cortical thickness to a locally linear space with fewer dimensions, while also utilizing the global nonlinear data structure. The embedded brain features were then used to train a classifier for predicting future conversion to AD based on a baseline MRI. We tested the approach on 413 individuals from the Alzheimer's Disease Neuroimaging Initiative (ADNI) who had baseline MRI scans and complete clinical follow-ups over 3 years with the following diagnoses: cognitive normal (CN; n=137), stable mild cognitive impairment (s-MCI; n=93), MCI converters to AD (c-MCI, n=97), and AD (n=86). We found that classifications using embedded MRI features generally outperformed (p<0.05) classifications using the original features directly. Moreover, the improvement from LLE was not limited to a particular classifier but worked equally well for regularized logistic regressions, support vector machines, and linear discriminant analysis. Most strikingly, using LLE significantly improved (p=0.007) predictions of MCI subjects who converted to AD and those who remained stable (accuracy/sensitivity/specificity: =0.68/0.80/0.56). In contrast, predictions using the original features performed not better than by chance (accuracy/sensitivity/specificity: =0.56/0.65/0.46). In conclusion, LLE is a very effective tool for classification studies of AD using multivariate MRI data. The improvement in predicting conversion to AD in MCI could have important implications for health management and for powering therapeutic trials by targeting non-demented subjects who later convert to AD.	algorithm;alzheimer's disease neuroimaging initiative;arc diagram;baseline (configuration management);cognition disorders;data structure;dimensions;disease regression;embedding;linear iga bullous dermatosis;linear discriminant analysis;machine learning;malignant fibrous histiocytoma;nonlinear dimensionality reduction;nonlinear system;randomness;sensitivity and specificity;support vector machine;thickness (graph theory);unsupervised learning;windows embedded industry;disease classification	Xin Liu;Duygu Tosun;Michael Weiner;Norbert Schuff	2013	NeuroImage	10.1016/j.neuroimage.2013.06.033	psychology;computer simulation;alzheimer's disease;radiology;medicine;artificial intelligence;magnetic resonance imaging;machine learning;linear model;data mining	ML	29.38513094171384	-77.87193769427711	90870
ae2290673c54743dedd1cfdd306d11369efbc077	methods for the evaluation of quality in machine processing of biomedical images	skeleton microscopy image segmentation muscles measurement image recognition;expert fatigue machine processing quality evaluation biomedical images microscopic image processing smooth muscle intestinal wall contrast agent patients processing related operations intestinal tissue layers overlapping nuclei nuclei areas tissue microstructures image artefacts comprehensive image database;medical image processing;tissue engineering medical image processing;smooth muscle layer microscopic images image processing evaluation of errors diverticulosis;tissue engineering	The authors report on the main objectives and evaluation methods within microscopic image processing as related to the layer of smooth muscle of the intestinal wall. The presented images were acquired to facilitate effective study of diverticulosis. The general aim of image processing is to determine the number of cell nuclei highlighted by a contrast agent. By enabling comparison of the numbers of cell nuclei established in healthy individuals and in patients suffering from diverticulosis, the entire corpus of processing-related operations will contribute to further development within the recognition and assessment of structural changes in intestinal tissue layers. Image processing can be realized using traditional fast methods, for example thresholding with the subsequent summation of segments. The disadvantages of these methods consist in their inability to recognize overlapping nuclei, nuclei areas disrupted by image artefacts, or tissue microstructures; this deficiency causes a considerable error rate and necessitates manual postprocessing. However, such manual verification of results in a comprehensive image database is time-consuming and produces additional errors brought about by various aspects, for instance the verifying expert's fatigue. The metrics for the evaluation of quality in the obtained processing results consists in the values of correctly identified and incorrectly rejected.	angular defect;bit error rate;computation;image processing;text corpus;thresholding (image processing);usability;verification and validation	Jan Mikulka;Radim Burget;Kamil Ríha	2013	2013 36th International Conference on Telecommunications and Signal Processing (TSP)	10.1109/TSP.2013.6613991	computer vision;tissue engineering	Visualization	37.0029259170843	-78.8584140110462	90915
a63032e0f3166df7e1e3e46927a9b78de4d3872b	non-extensive entropy for cad systems of breast cancer images	shannon entropy;image segmentation;entropy breast cancer ultrasonic imaging image segmentation proposals protocols statistics biomedical imaging medical diagnostic imaging level set;support vector machines;cancer;maximization;receiver operating characteristic curves nonextensive entropy cad systems breast cancer images computer aided diagnosis systems ultrasound resolution medical image segmentation maximization shannon entropy q entropy breast cancer classification mammographic exams level set formulation support vector machine automatic protocol breast ultrasound images cross validation protocol;ultrasound resolution;receiver operating characteristic curves;medical image processing;support vector machines biomedical ultrasonics cancer entropy image segmentation mammography medical image processing signal classification;signal classification;cross validation protocol;automatic protocol;breast ultrasound images;level set formulation;mammographic exams;breast cancer images;entropy;support vector machine;mammography;breast cancer classification;medical image segmentation;nonextensive entropy;cad systems;biomedical ultrasonics;q entropy;computer aided diagnosis systems	Recent statistics show that breast cancer is a major cause of death among women in all of the world. Hence, early diagnostic with computer aided diagnosis (CAD) systems is a very important tool. This task is not easy due to poor ultrasound resolution and large amount of patient data size. Then, initial image segmentation is one of the most important and challenging task. Among several methods for medical image segmentation, the use of entropy for maximization the information between the foreground and background is a well known and applied technique. But, the traditional Shannon entropy fails to describe some physical systems with characteristics such as long-range and longtime interactions. Then, a new kind of entropy, called non-extensive entropy, has been proposed in the literature for generalizing the Shannon entropy. In this paper, we propose the use of non-extensive entropy, also called q-entropy, applied in a CAD system for breast cancer classification in ultrasound of mammographic exams. Our proposal combines the non-extensive entropy, a level set formulation and a support vector machine framework to achieve better performance than the current literature offers. In order to validate our proposal, we have tested our automatic protocol in a data base of 250 breast ultrasound images (100 benign and 150 malignant). With a cross-validation protocol, we demonstrate system's accuracy, sensitivity, specificity, positive predictive value and negative predictive value as: 95%, 97%, 94%, 92% and 98%, respectively, in terms of ROC (receiver operating characteristic) curves and Az areas	b-spline;computation;computer graphics;computer-aided design;cross-validation (statistics);database;discriminant;entropy (information theory);entropy maximization;experiment;feature vector;image processing;image segmentation;interaction;pixel;receiver operating characteristic;region of interest;sensitivity and specificity;shannon (unit);support vector machine;texture filtering;time complexity	Paulo S. Rodrigues;Ruey-Feng Chang;Jasjit S. Suri	2006	2006 19th Brazilian Symposium on Computer Graphics and Image Processing	10.1109/SIBGRAPI.2006.31	computer vision;computer science;machine learning;pattern recognition	Graphics	35.73011555492722	-76.0658948209608	90933
1b457b5a8ad5f827f155be7b66e0af84478bf16c	deep sequential segmentation of organs in volumetric medical scans		Segmentation in 3D scans is playing an increasingly important role in current clinical practice supporting diagnosis, tissue quantification, or treatment planning. The current 3D approaches based on Convolutional Neural Networks (CNN) usually suffer from at least three main issues caused predominantly by implementation constraints - first, they require resizing the volume to the lower-resolutional reference dimensions, second, the capacity of such approaches is very limited due to memory restrictions, and third, all slices of volumes have to be available at any given training or testing time. We address these problems by a U-Net-like [1] architecture consisting of bidirectional Convolutional Long Short-Term Memory (C-LSTM) [2] and convolutional, pooling, upsampling and concatenation layers enclosed into timedistributed wrappers. Our network can either process the full volumes in a sequential manner, or segment slabs of slices on demand. We demonstrate performance of our architecture on vertebrae and liver segmentation tasks in 3D CT scans.	bone structure of spine;ct scan;computer multitasking;concatenation;convolution;convolutional neural network;dimensions;end-to-end principle;ephrin type-b receptor 1, human;evaluation;generalization (psychology);inference;long short-term memory;memory segmentation;numerous;organ;p-value;quantitation;scanning;upsampling;visual inspection;algorithm;anatomical layer;biologic segmentation	Alexey A. Novikov;David Major;Maria Wimmer;Dimitrios Lenis;Katja Bühler	2018	IEEE transactions on medical imaging	10.1109/TMI.2018.2881678	image segmentation;mathematics;computer vision;artificial intelligence;upsampling;concatenation;convolutional neural network;medical imaging;radiation treatment planning;segmentation;pooling	Vision	30.442529494171115	-75.75967066939651	91062
a83d3349354fb289e8471935f7e1e2517952fa3e	figure-based writer verification by matching between an arbitrary part of registered sequence and an input sequence extracted from on-line handwritten figures	dynamic programming;handwriting recognition;engineering drawings;authentication;dynamic program;data mining;shape;feature extraction;error rate;writing;feature extraction authentication writing dynamic programming handwriting recognition data mining shape character recognition computer science engineering drawings;computer science;character recognition	This paper propose a method of writer verification based on on-line features extracted from a process of drawing a figure, and evaluate its performance on handdrawn figures by genuine writers and pretenders. In the proposed method, a person in registration writes only the reference figure, which is composed of as many parts as possible and the person can be verified with a arbitrary part of the reference figure. The verification is based on a spotting method called CDP (Continuous Dynamic Programming). From some requirements in authentication system, the proposed method is tested through some experiments using figures. The error rates in the experiment were different depending on conditions such as kind of on-line features, minimum number of strokes comprised in acceptable test sequence as input, figure for determination of threshold and the genuine writer. The result of the experiment shows that the proposed method is effective.	authentication;database;dynamic programming;experiment;online and offline;requirement	Hiroshi Kameya;Shunji Mori;Ryuichi Oka	2003		10.1109/ICDAR.2003.1227807	natural language processing;speech recognition;feature extraction;shape;intelligent character recognition;word error rate;computer science;machine learning;dynamic programming;authentication;handwriting recognition;writing	Vision	33.96019752589221	-66.2995824967367	91197
67536ef25c65e983c1e8ebde233c3a6ef94941a8	a complete printed bangla ocr system	lenguaje natural;eficacia sistema;detection erreur;deteccion error;feature detection;sistema experto;optical character recognition;langage naturel;character segmentation;performance systeme;tratamiento lenguaje;segmentation;system performance;regle decision;language processing;traitement document;error correction;natural language;traitement langage;reconocimento optico de caracteres;correcteur;corrector;pattern recognition;document processing;reconnaissance forme;regla decision;systeme expert;error detection;spell checker;reconocimiento patron;template matching;segmentacion;decision rule;indian language;reconnaissance optique caractere;tratamiento documento;expert system	A complete Optical Character Recognition (OCR) system for printed Bangla, the fourth most popular script in the world, is presented. This is the first OCR system among all script forms used in the Indian sub-continent. The problem is difficult because (i) there are about 300 basic, modified and compound character shapes in the script, (ii) the characters in a word are topologically connected and (iii) Bangla is an inflectional language. In our system the document image captured by Flat-bed scanner is subject to skew correction, text graphics separation, line segmentation, zone detection, word and character segmentation using some conventional and some newly developed techniques. From zonal information and shape characteristics, the basic, modified and compound characters are separated for the convenience of classification. The basic and modified characters which are about 75 in number and which occupy about 96% of the text corpus, are recognized by a structural-feature-based tree classifier. The compound characters are recognized by a tree classifier followed by template-matching approach. The feature detection is simple and robust where preprocessing like thinning and pruning are avoided. The character unigram statistics is used to make the tree classifier efficient. Several heuristics are also used to speed up the template matching approach. A dictionary-based error-correction scheme has been used where separate dictionaries are compiled for root word and suffixes that contain morpho-syntactic informations as well. For single font clear documents 95.50% word level (which is equivalent to 99.10% character level) recognition accuracy has been obtained. Extension of the work to Devnagari, the third most popular script in the world, is also discussed. ( 1998 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved Optical character recognition Document processing Language processing Spell-checker Indian language	compiler;dictionary;document processing;error detection and correction;feature detection (computer vision);feature detection (web development);graphics;heuristic (computer science);n-gram;optical character recognition;pattern recognition;preprocessor;printing;spell checker;template matching;text corpus;thinning	Bidyut Baran Chaudhuri;Umapada Pal	1998	Pattern Recognition	10.1016/S0031-3203(97)00078-2	computer vision;error detection and correction;speech recognition;computer science;artificial intelligence;expert system;algorithm;statistics	AI	34.23510440381953	-67.1054029230624	91280
c38f0482fc342c374e7d1b7dd74a5381fa0d2205	analysis of mammograms using fractal features	benign tumors;biocomputing;fractals;x ray imaging;cancer;biological organs;tumours;mammographic image analysis society;fractal feature;fractal dimension;microcalcifications;fractal feature breast cancer microcalcifications malignant benign fractal dimension;medical image;malignant;feature extraction;medical image processing;pixel;benign;benign mammograms analysis fractal features modified average image microcalcifications mammographic image analysis society digital mammogram database malignant tumors;x ray imaging biocomputing biological organs cancer fractals mammography medical image processing tumours visual databases;mammography;breast cancer;fractals breast cancer malignant tumors image analysis cancer detection benign tumors shape measurement image texture analysis image databases spatial databases;visual databases	Medical images like mammograms are very difficult to analyze because of their low contrast. Different fractal features are used for analyzing mammograms in this paper. The new fractal feature derived from the modified average image is found to be a better feature for distinguishing between normal, malignant, benign and mammograms with microcalcifications. The study is performed on the mammograms obtained from the online Mammographic Image Analysis Society (MIAS) Digital Mammogram database. The average values of the new normalized fractal feature for normal, mammogram with microcalcifications, benign and malignant tumors are obtained as 0.148, 0.437, 0.3145, and 0.5465 respectively.	fractal;image analysis	Deepa Sankar;Tessamma Thomas	2009	2009 World Congress on Nature & Biologically Inspired Computing (NaBIC)	10.1109/NABIC.2009.5393875	computer vision;fractal;feature extraction;computer science;breast cancer;machine learning;fractal dimension;pixel;cancer	HCI	36.869957782885535	-74.27914662554865	91509
fdedf028a8570c6e634e1ebf96d11222fa8a34c5	novel approaches for the microcalcification problem of non-palpable lesions	cpr;false positives;computer aided diagnosis;lacunarity;classification;non palpable lesions;fuzzy logic;correlation plane;cade 47;cadx;fractal abundance;computer aided detection;correlation pattern recognition;mammograms;pleomorphic microcalcification	Fusion of hard and soft information using correlation pattern recognition and fuzzy logic in an integrated detection/classification system based on the DDSM database of pleomorphic microcalcifications provides a detection rate of 0.47 false positives per image at 100% sensitivity using classical matched filter methods on wavelet denoised full mammograms. Advanced correlation filtering yields 0.85 and 0.58 false positives per image at 100% and 87% sensitivity. Classification results generalisable to unseen images at 71.4% specificity for 100% and 96% sensitivity are in a range likely to be clinically acceptable, based on human vision performance of 73.3% specificity at 97.6% sensitivity.		Walker H. Land;Elizabeth A. Verheggen	2009	I. J. Functional Informatics and Personalised Medicine	10.1504/IJFIPM.2009.022835	fuzzy logic;computer vision;biological classification;computer science;false positive paradox;machine learning;pattern recognition;lacunarity	PL	34.6228045525412	-76.12018364473163	91576
0269d9166d38fa351354902c0ee933011adce981	immunohistochemical quantification of expression of a tight junction protein, claudin-7, in human lung cancer samples using digital image analysis method	claudin-7;fragmentation;image analysis;immunohistochemistry;intensity;lung cancer	BACKGROUND AND OBJECTIVES Tight junction proteins are correlated with cancer development. As the pivotal proteins in epithelial cells, altered expression and distribution of different claudins have been reported in a wide variety of human malignancies. We have previously reported that claudin-7 was strongly expressed in benign bronchial epithelial cells at the cell-cell junction while expression of claudin-7 was either altered with discontinued weak expression or completely absent in lung cancers. Based on these results, we continued working on the expression pattern of claudin-7 and its relationship with lung cancer development. We herein proposed a new Digital Image Classification, Fragmentation index, Morphological analysis (DICFM) method for differentiating the normal lung tissues and lung cancer tissues based on the claudin-7 immunohistochemical staining.   METHODS Seventy-seven lung cancer samples were obtained from the Second Affiliated Hospital of Zhejiang University and claudin-7 immunohistochemical staining was performed. Based on C++ and Open Source Computer Vision Library (OpenCV, version 2.4.4), the DICFM processing module was developed. Intensity and fragmentation of claudin-7 expression, as well as the morphological parameters of nuclei were calculated. Evaluation of results was performed using Receiver Operator Characteristic (ROC) analysis.   RESULTS Agreement between these computational results and the results obtained by two pathologists was demonstrated. The intensity of claudin-7 expression was significantly decreased while the fragmentation was significantly increased in the lung cancer tissues compared to the normal lung tissues and the intensity was strongly positively associated with the differentiation of lung cancer cells. Moreover, the perimeters of the nuclei of lung cancer cells were significantly greater than that of the normal lung cells, while the parameters of area and circularity revealed no statistical significance.   CONCLUSIONS Taken together, our DICFM approach may be applied as an appropriate approach to quantify the immunohistochemical staining of claudin-7 on the cell membrane and claudin-7 may serve as a marker for identification of lung cancer.		Zhe Lu;Yi Liu;Junfeng Xu;Hongping Yin;Haiying Yuan;Jinjing Gu;Yan-hua Chen;Liyun Shi;Dan Chen;Bin Xie	2018	Computer methods and programs in biomedicine	10.1016/j.cmpb.2017.12.014	lung cancer;claudin;computer vision;morphological analysis;cancer;artificial intelligence;receiver operating characteristic;pathology;lung;immunohistochemistry;computer science;tight junction	Comp.	36.16016935785584	-77.59546325162036	91650
588e3979ae741bc7b4ca78b1fab6777c705f8bee	deep learning classification of photographic paper based on clustering by domain experts	art;image resolution;neural networks;training;observers;gray scale;machine learning	Prior work on texture analysis of historic, photographic papers has focused primarily on measures of texture similarity. However, automated grouping or clustering of photographic paper textures in a way that is meaningful to art conservators remains an open problem. In this work a deep learning approach to automated classification is presented, for clusters derived from a human sorting experiment conducted by 19 art conservators and paper experts and subsequently extended through crowd-sourcing. The proposed approach uses a deep convolutional neural network, and results are presented on the performance in automatically classifying images when compared to human experts.	artificial neural network;cluster analysis;convolutional neural network;crowdsourcing;deep learning;sorting	Andrew G. Klein;Paul Messier;Andrea L. Frost;David Palzer;Sally L. Wood	2016	2016 50th Asilomar Conference on Signals, Systems and Computers	10.1109/ACSSC.2016.7869011	computer vision;computer science;artificial intelligence;machine learning	AI	30.76336320828003	-66.61436814751234	91740
714e15a14cb5214c65a4e295c65cc89606e916c5	baseline extraction-driven parsing of handwritten mathematical expressions	probability;trees mathematics handwritten character recognition hidden markov models image classification probability;image classification;grammar layout hidden markov models vegetation handwriting recognition law;trees mathematics;hidden markov models;crohme 2011 handwritten math recognition competition handwritten mathematical expression parsing recursive baseline extraction algorithm symbol layout analysis math expression handwritten stroke lexical analysis modified ll 1 parser parse tree hidden markov model symbol classification horizontal adjacency probabilistic quadratic classifier;handwritten character recognition	We generalize recursive baseline extraction algorithms for symbol layout analysis in math expressions so that handwritten strokes may be provided as input. Specifically, baseline extraction is used for lexical analysis in a modified LL(1) parser, returning a set of candidate symbols when the leftmost or next symbol along the current baseline (from left-to-right) is requested by the parser. Candidate symbols are used to produce a forest of parse trees, and the highest ranked parse returned. Hidden Markov Models (HMMs) are used for symbol classification, and horizontal adjacency between symbols is determined using two probabilistic quadratic classifiers, one for ascenders (e.g. `A') and another for centered and descender symbols (e.g. `y' and `x'). The system placed second in the CROHME 2011 handwritten math recognition competition.	algorithm;baseline (configuration management);hidden markov model;ll parser;lexical analysis;markov chain;parse tree;parsing;quadratic function;recursion	Lei Hu;Kevin Hart;Richard Pospesel;Richard Zanibbi	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		contextual image classification;speech recognition;computer science;machine learning;pattern recognition;probability;hidden markov model;statistics	Vision	34.126476188876254	-66.2333205678673	91892
de2daf03144a0850acebf77a536991b191f72491	objective assessment of pathological speech using distribution regression		Objective assessment of pathological speech is an important part of existing systems for automatic diagnosis and treatment of various speech disorders. In this paper, we propose a new regression method for this application. Rather than treating speech samples from each speaker as individual data instances, we treat each speaker's data as a probability distribution. We propose a simple non-parametric learning method to make predictions for out-of-sample speakers based on a probability distance measure to the speakers in the training set. This is in contrast to traditional learning methods that rely on Euclidean distances between individual instances. We evaluate the method on two pathological speech data sets with promising results.	euclidean distance;test set	Ming Tu;Visar Berisha;Julie M. Liss	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7953118	probability distribution;artificial intelligence;probability density function;feature extraction;machine learning;pattern recognition;computer science;regression;pathological;training set;speech-language pathology;data set	Robotics	26.270350458270748	-79.7591748871012	91975
f923556b1d377bc83f9949d863873189c9bbc23b	deep learning features for wireless capsule endoscopy analysis		The interpretation and analysis of wireless capsule endoscopy images is a complex task which requires sophisticated computer aided decision (CAD) systems in order to help physicians with the video screening and, finally, with the diagnosis. Most of the CAD systems for capsule endoscopy share a common system design, but use very different image and video representations. As a result, each time a new clinical application of WCE appears, new CAD system has to be designed from scratch. Therefore, in this paper we introduce a system for small intestine motility characterization, based on Deep Convolutional Neural Networks, which avoids the laborious step of designing specific features for individual motility events. Experimental results show the superiority of the learned features over alternative classifiers constructed by using state of the art hand-crafted features.	deep learning	Santi Seguí;Michal Drozdzal;Guillem Pascual;Petia Radeva;Carolina Malagelada;Fernando Azpiroz;Jordi Vitrià	2016		10.1007/978-3-319-52277-7_40	computer vision;convolutional neural network;computer-aided;artificial intelligence;scratch;deep learning;systems design;wireless;computer science;capsule endoscopy	Robotics	31.989423346745106	-75.21679962043821	92059
609660dde104f29984810064eb9abb1cc4a08d96	a vision-based analysis system for gait recognition in patients with parkinson's disease	image processing;vision based;gait recognition;linear discriminate analysis;principal component analysis pca;feature extraction;principal component analysis;gait analysis;parkinson s disease;article;linear discriminant analysis lda	0957-4174/$ see front matter Crown Copyright 2 doi:10.1016/j.eswa.2008.08.076 * Corresponding author. Tel.: +886 3 571 2121x544 E-mail address: irradiance@so-net.net.tw (Y.-Y. Ch Recognition of specific Parkinsonian gait patterns is helpful in the diagnosis of Parkinson’s disease (PD). However, there are few computer-aided methods to identify the specific gait patterns of PD. We propose a vision-based diagnostic system to aid in recognition of the gait patterns of Parkinson’s disease. The proposed system utilizes an algorithm combining principal component analysis (PCA) with linear discriminant analysis (LDA). This scheme not only addresses the high data dimensionality problem during image processing but also distinguishes different gait categories simultaneously. The feasibility of the proposed system for the recognition of PD gait was tested by using gait videos of PD and normal subjects. The efficiency of feature extraction using PCA and LDA coefficients are also compared. Experimental results showed that LDA had a recognition rate for Parkinsonian gait of 95.49%, which is higher than the conventional PCA feature extraction method. The proposed system is a promising aid in identifying the gait of Parkinson’s disease patients and can discriminate the gait patterns of PD patients and normal people with a very high classification rate. Crown Copyright 2008 Published by Elsevier Ltd. All rights reserved.	algorithm;coefficient;crown group;feature extraction;gait analysis;image processing;linear discriminant analysis;principal component analysis	Chien-Wen Cho;Wen-Hung Chao;Sheng-Huang Lin;You-Yin Chen	2009	Expert Syst. Appl.	10.1016/j.eswa.2008.08.076	computer vision;speech recognition;gait analysis;image processing;feature extraction;computer science;machine learning;pattern recognition;principal component analysis	AI	34.09500141333372	-73.50138708300447	92083
5fe87c0865e38b0fd4ba42319a98d3480f88e9b9	detection of high-grade atypia nuclei in breast cancer imaging	neural networks;breast cancer	Along with mitotic count, nuclear pleomorphism or nuclear atypia is an important criterion for the grading of breast cancer in histopathology. Though some works have been done in mitosis detection (ICPR 2012,1 MICCAI 2013,2 and ICPR 2014), not much work has been dedicated to automated nuclear atypia grading, especially the most difficult task of detection of grade 3 nuclei. We propose the use of Convolutional Neural Networks for the automated detection of cell nuclei, using images from the three grades of breast cancer for training. The images were obtained from ICPR contests. Additional manual annotation was performed to classify pixels into five classes: stroma, nuclei, lymphocytes, mitosis and fat. At total of 3,000 thumbnail images of 101 × 101 pixels were used for training. By dividing this training set in an 80/20 ratio we could obtain good training results (around 90%). We tested our CNN on images of the three grades which were not in the training set. High grades nuclei were correctly classified. We then thresholded the classification map and performed basic analysis to keep only rounded objects. Our results show that mostly all atypical nuclei were correctly detected. © (2015) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.		Henri Noël;Ludovic Roux;Shijian Lu;Thomas Boudier	2015		10.1117/12.2081793	computer vision;breast cancer;multimedia;artificial neural network;physics	Vision	33.816939577195726	-76.11806745812622	92123
268ed989f6c71fd4f008b06e367d43243f215240	lung nodule classification by jointly using visual descriptors and deep features		Classifying benign and malignant lung nodules using the thoracic computed tomography (CT) screening is the primary method for early diagnosis of lung cancer. Despite of their widely recognized success in image classification, deep learning techniques may not achieve satisfying accuracy on this problem, due to the limited training samples resulted from the all-consuming nature of medical image acquisition and annotation. In this paper, we jointly use the texture and shape descriptors, which characterize the heterogeneity of nodules, and the features learned by a deep convolutional neural network, and thus proposed a combined-feature based classification (CFBC) algorithm to differentiate lung nodules. We have evaluated this algorithm against four state-of-the-art nodule classification approaches on the benchmark LIDC-IDRI dataset. Our results suggest that the proposed CFBC algorithm can distinguish malignant lung nodules from benign ones more accurately than other four methods.	algorithm;artificial neural network;benchmark (computing);ct scan;computer vision;convolutional neural network;deep learning;the australian;tomography;visual descriptor	Yutong Xie;Jianpeng Zhang;Sidong Liu;Tom Weidong Cai;Yong Xia	2016		10.1007/978-3-319-61188-4_11	computed tomography;lung cancer;convolutional neural network;visual descriptors;lung;deep learning;texture descriptor;contextual image classification;artificial intelligence;pattern recognition;anatomy;computer science	Vision	32.33505462387269	-75.49593044066621	92196
e3ef90f13978ff02e0c39706ce4d70ec75a29bb8	brain tumor segmentation with optimized random forest		In this paper we propose and tune a discriminative model based on Random Forest (RF) to accomplish brain tumor segmentation in multimodal MR images. The objective of tuning is meant to establish the optimal parameter values and the most significant constraints of the discriminative model. During the building of the RF classifier, the algorithm evaluates the importance of variables, the proximities between data instances and the generalized error. These three properties of RF are employed to optimize the segmentation framework. At the beginning the RF is tuned for variable importance evaluation, and after that it is used to optimize the segmentation framework. The framework was tested on unseen test images from BRATS. The results obtained are similar to the best ones presented in previous BRATS Challenges.	random forest	László Lefkovits;Szidónia Lefkovits;László Szilágyi	2016		10.1007/978-3-319-55524-9_9	discriminative model;feature selection;random forest;artificial intelligence;segmentation;pattern recognition;computer science	Vision	30.954825147862188	-73.36594493725676	93039
c331a17a46e93499e0f27d98c794d760d27923a6	towards automatic acne detection using a mrf model with chromophore descriptors	markov random fields mrfs;image segmentation;markov random fields;acne detection;image segmentation computational modeling abstracts indexes labeling biomedical optical imaging optical imaging;chromophore descriptors;markov random fields mrfs image segmentation acne detection chromophore descriptors	This paper proposes a new acne detection approach using a Markov random field (MRF) model and chromophore descriptors extracted by bilateral decomposition. Compared to most existing acne segmentation methods, the proposed algorithm enables to cope with large-dynamic-range intensity usually existing in conventional RGB acne images captured under uncontrolled environment. Algorithm performance has been tested on acne images of human face from a free public database. Experimental results show that acne segmentation derived from this new approach highly agrees to human visual inspection. Moreover, inflammatory response and hyperpigmentation scar can be well discriminated. It is expected that a computer-assisted diagnostic system for acne severity evaluation will be constructed as a consequence of the present work.	algorithm;bilateral filter;database;dynamic range;markov chain;markov random field;uncontrolled format string;visual inspection	Zhao Liu;Josiane Zerubia	2013	21st European Signal Processing Conference (EUSIPCO 2013)		computer vision;geography;optics;scale-space segmentation;communication	Vision	38.94814828000074	-75.38675367016388	93218
88a404bdad9d1e2c8bf1570ee6945f06a5d29880	automatic detection and tracking of animal sperm cells in microscopy images	microscopy images root mean square error rmse svm classifier casa system computer assisted sperm analysis system sperm tracking and analysis automatic detection animal sperm cells tracking;feature extraction training tracking videos histograms support vector machines dictionaries;support vector machines image classification image segmentation medical image processing;microscopy;segmentation;classification;sperm;sperm microscopy classification segmentation tracking;tracking	Sperm tracking-and-analysis is one of the interesting topics in biological research and reproductive medicine, as it helps to assess the quality of the sperm for the male infertility. Computer-Assisted Sperm Analysis (CASA) systems provide a rapid and automated assessment of the parameters of sperm motion, together with improved standardization and quality control. In this paper, we propose a method to detect and track animal sperms automatically. First, we detect the sperms in the first frame of all the sequences using a bag-of-words approach and SVM classifier. Then, the detected sperm cells are tracked in the rest of all sequences using mean-shift. The proposed algorithm is evaluated on three videos in our datasets which have sperms as ground truth. The experimental results show that our method achieves a precision of 0.94, 0.93 and 0.96, and are call of 0.96, 0.92, and 0.97 for the three videos respectively in terms of sperm detection. RMSE (Root mean square error) is calculated to evaluate our results in terms of sperms tracking. The results show that we achieve high performance with RMSE of 8.06, 9.01, and 7.09 pixels for three different videos.	algorithm;bag-of-words model;computational auditory scene analysis;database;dictionary;ground truth;histogram of oriented gradients;local binary patterns;mean shift;mean squared error;pixel;precision and recall;resultant;sensor;speeded up robust features;statistical classification	Ouadi Beya;Mohamad Mazen Hittawe;Desire Sidibé;Fabrice Mériaudeau	2015	2015 11th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)	10.1109/SITIS.2015.111	computer vision;biological classification;microscopy;machine learning;pattern recognition;tracking;segmentation	Robotics	36.76967313268758	-73.604845001647	93220
d57edfa430226a608bd06db4c0e5eeded790ebf9	segmentation of a text printed in korean and english using structure information and character recognizers	image segmentation;optical character recognition;text analysis;natural languages;classified block text image segmentation korean english structure information character recognizers character images mixed language character recognizer average width text lines touching alphanumeric characters cut points vertical histogram;image segmentation optical character recognition natural languages text analysis;character recognition image segmentation natural languages image recognition text recognition histograms moon computer vision image processing laboratories	The purpose of the research presented is to segment a text image printed in both Korean and English into character images, utilizing the structure information in Korean and English characters, and using a Korean, English and mixed language character recognizer. The image cannot be separated by only using the width and height of a character because those of an English character are not constant, contrary to those of a Korean character. Therefore we first classify the image into Korean or English using the structure information in Korean and English characters. If it is determined as a Korean character, we segment it with the average width of Korean characters in the text lines. If it is determined as an English character, we segment it using a classical method to segment touching alphanumeric characters. If it cannot be determined, we find possible cut points using a vertical histogram and use the mixed language recognizer to determine the right cut point. Since our method first classifies a block into Korean or English, it can be run faster than the traditional method that cannot identify the language. Each classified block can be segmented more accurately because more specific knowledge about Korean and English characters can be applied.	finite-state machine;printing	Young-Sup Hwang;Kyung-Ae Moon;Su-Young Chi;Dae-Geun Jang;Weon-Geun Oh	2000		10.1109/ICSMC.2000.886248	natural language processing;text mining;speech recognition;computer science;pattern recognition;image segmentation;natural language;optical character recognition	HCI	34.712763183980655	-66.50627446244113	93429
e98c764d46de9d81ef6f7836707eb7f6e11deaa1	peripheral bronchial identification on chest ct using unsupervised machine learning	lung;machine learning;cad;computed tomography	To automatically identify small- to medium-diameter bronchial segments distributed throughout the lungs. We segment the peripheral pulmonary vascular tree and construct cross-sectional images perpendicular to the lung vasculature. The bronchi running with pulmonary arteries appear as concentric rings, and potential center points that lie within the bronchi are identified by looking for circles (using the circular Hough transform) and rings (using a novel variable ring filter). The number of candidate bronchial center points are further reduced by using agglomerative hierarchical clustering applied to the points represented with 18 features pertaining to their 3D position, orientation and appearance of the surrounding cross-sectional image. Resulting clusters corresponded to bronchial segments. Parameters of the algorithm are varied and applied to two experimental data sets to find the best values for bronchial identification. The optimized algorithm was then applied to a further 21 CT studies obtained using two different CT vendors. The parameters that result in the most number of true positive bronchial center points with > 95% precision are a tolerance of 0.15 for the hierarchical clustering algorithm and a threshold of 75 HU with 10 spokes for the ring filter. Overall, the performance on all 21 test data sets from CT scans from both vendors demonstrates a mean number of 563 bronchial points detected per CT study, with a mean precision of 96%. The detected points across this group of test data sets are relatively uniformly distributed spatially with respect to spherical coordinates with the origin at the center of the test imaging data sets. We have constructed a robust algorithm for automatic detection of small- to medium-diameter bronchial segments throughout the lungs using a combination of knowledge-based approaches and unsupervised machine learning. It appears robust over two different CT vendors with similar acquisition parameters.	amendment;blood supply aspects;bronchi;bronchial tree;bronchiolitis;ct scan;cluster analysis;cross-sectional data;declaration (computer programming);desquamative interstitial pneumonia;diameter (qualifier value);drug allergy;extrinsic allergic alveolitis;helsinki declaration;hierarchical clustering;hough transform;interstitial webpage;lung diseases, interstitial;lung diseases;machine ethics;machine learning;moses;peripheral;pulmonary artery structure;ring device;small;structure of parenchyma of lung;test data;training programs;algorithm;standards characteristics;statistical cluster	Daniel Moses;Laughlin Dawes;Claude Sammut;Tatjana Zrimec	2018	International Journal of Computer Assisted Radiology and Surgery	10.1007/s11548-018-1805-8	artificial intelligence;radiology;peripheral;computer vision;computed tomography;unsupervised learning;medicine	ML	36.67148319279957	-79.13120839307358	94166
fe172f71868c5446f1e3a862b8de8ee7763acc62	content based image retrieval of diabetic macular edema images	medical image processing content based retrieval diseases eye image retrieval image texture;eye;image texture;vectors lesions retina image edge detection image retrieval diabetes educational institutions;medical image processing;diseases;exudate content based image retrieval diabetic macular edema image colour fundus image cbir system texture discontinuity lesion content image to image distance retina;content based retrieval;image retrieval	Colour fundus images play an important role in diagnosing and screening diabetic macular edema (DME). In rural areas, content-based image retrieval (CBIR) might compensate the lack of expert ophthalmologists. In this work, we present a fully automated CBIR system that retrieves fundus images according to their content (quantity and location) of exudates. First, the macula is divided into three concentric regions whose texture discontinuities are used to represent lesion content of the retina. The image-to-image distance measure gives higher weights to lesions closer to the fovea to reflect the severity of the DME. Retrieval results of the system show precision of 79.2%.	content-based image retrieval;icl direct machine environment	Aya M. Naguib;Ahmed M. Ghanem;Ahmed S. Fahmy	2013	Proceedings of the 26th IEEE International Symposium on Computer-Based Medical Systems	10.1109/CBMS.2013.6627877	image texture;computer vision;image retrieval;computer science;multimedia	Vision	36.21095655967943	-73.15188182996954	94606
c66d40a9935450c93cabe16b8831f92819a25692	visual feature learning with application to medical image classification	radiology;medical image classification;machine learning;colonoscopy;local binary patterns;feature learning;histology		computer vision;feature learning	Siyamalan Manivannan	2015			computer vision;contextual image classification;computer science;machine learning;pattern recognition	Vision	32.748065568425844	-74.65131181508646	94639
5ccd307f15e8d4ee3bc3698f90c73a8931624f8d	application of averaged learning subspace method in mri classification	biological tissues;brain;binary image;perceptrons;training;brain models;image classification;classification;higher order statistics;multispectral mri image classification;perceptrons biological tissues biomedical mri brain higher order statistics image classification learning artificial intelligence medical image processing;classification alsm mri;magnetic resonance imaging laser radar x rays biomedical imaging covariance matrix hospitals statistics blood testing computed tomography;mr imaging;perceptron neural network;alsm;perceptron neural network averaged learning subspace method alsm multispectral mri image classification brain tissue binary image medical diagnosis high order statistics;medical image processing;magnetic resonance imaging;classification algorithms;mri;subspace method;multi spectral;learning artificial intelligence;high order statistics;brain tissue;medical diagnosis;averaged learning subspace method;noise;biomedical mri;neural network	The objective of this paper is to establish an “Averaged Learning Subspace Method” (ALSM) applicable for classification of multi-spectral MR images. By using the ALSM to process the massive amounts of information in multi-spectral MR images, and classification tissues of brain. The classification result of each tissue has shown by binary image, respectively. The classification results would assist doctor to diagnose more efficiently and more accurately and thus to gain more time for necessary action. In order to further evaluate the performance of ALSM, the high order statistics is adopted assessment and compare with perceptron neural network.	artificial neural network;binary image;nonlinear system;perceptron	Chuin-Mu Wang;Jau-An Chen;Jui-Hsing Chu	2009	2009 Fifth International Conference on Information Assurance and Security	10.1109/IAS.2009.275	computer vision;computer science;machine learning;pattern recognition	Robotics	33.812599274257494	-74.44880518344648	94696
2bef902fa96cadaf19ac466583ed9dfe7a557d4c	segmentation of tumor and edema along with healthy tissues of brain using wavelets and neural networks	tumor diagnosis;brain magnetic resonance mr;brain;white matter;wavelet transforms biomedical mri brain image segmentation medical image processing neural nets tumours vector quantisation;image segmentation;brain magnetic resonance segmentation algorithms;neural networks;neural nets;self organizing feature map;image segmentation tumors feature extraction vectors training accuracy artificial neural networks;stationary wavelet transform swt;training;edema diagnosis;tumours;skull;segmentation process;wavelet transforms;accuracy;artificial neural networks;vectors;stationary wavelet transform brain mr image segmentation learning vector quantization self organizing feature map;feature extraction;medical image processing;glial tumor;tissue segmentation algorithm;self organizing map;tumors;gray matter;learning vector quantization lvq;stationary wavelet transform;brain mr;stationary wavelet transform coefficients;vector quantisation;flair mr images;learning vector quantization;brain magnetic resonance segmentation algorithms neural networks stationary wavelet transform coefficients learning vector quantization self organizing map segmentation process skull glial tumor flair mr images cerebrospinal fluid white matter gray matter tissue segmentation algorithm tumor diagnosis edema diagnosis;biomedical mri;cerebrospinal fluid	Robust brain magnetic resonance (MR) segmentation algorithms are critical to analyze tissues and diagnose tumor and edema in a quantitative way. In this study, we present a new tissue segmentation algorithm that segments brain MR images into tumor, edema, white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF). The detection of the healthy tissues is performed simultaneously with the diseased tissues because examining the change caused by the spread of tumor and edema on healthy tissues is very important for treatment planning. We used T1, T2, and FLAIR MR images of 20 subjects suffering from glial tumor. We developed an algorithm for stripping the skull before the segmentation process. The segmentation is performed using self-organizing map (SOM) that is trained with unsupervised learning algorithm and fine-tuned with learning vector quantization (LVQ). Unlike other studies, we developed an algorithm for clustering the SOM instead of using an additional network. Input feature vector is constructed with the features obtained from stationary wavelet transform (SWT) coefficients. The results showed that average dice similarity indexes are 91% for WM, 87% for GM, 96% for CSF, 61% for tumor, and 77% for edema.	algorithm;body tissue;cerebrospinal fluid;cluster analysis;coefficient;edema;flair (product);feature vector;glioma;gray matter;index;learning vector quantization;neoplasms;neural networks;neuroglia;organizing (structure);resonance;self-organization;self-organizing map;standard widget toolkit;stationary process;stationary wavelet transform;unsupervised learning;white matter;biologic segmentation;statistical cluster	Ayse Demirhan;Mustafa Toru;Inan Güler	2015	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2014.2360515	computer vision;self-organizing map;learning vector quantization;feature extraction;computer science;artificial intelligence;machine learning;accuracy and precision;stationary wavelet transform;image segmentation;artificial neural network;wavelet transform	ML	36.092687783928206	-77.30184810172906	94989
78d606dc8947e9459012baa3963857b19f144be7	cellular community detection for tissue phenotyping in histology images		A primary aim of detailed analysis of multi-gigapixel histology images is assisting pathologists for better cancer grading and prognostication. Several methods have been proposed for the analysis of histology images in the literature. However, these methods are often limited to the classification of two classes i.e., tumor and stroma. Also, most existing methods are based on fully supervised learning and require a large amount of annotations, which are very difficult to obtain. To alleviate these challenges, we propose a novel community detection algorithm for the classification of tissue in Whole-slide Images (WSIs). The proposed algorithm uses a novel graph-based approach to the problem of detecting prevalent communities in a collection of histology images in an semi-supervised manner resulting the identification of six distinct tissue phenotypes in the multi-gigapixel image data. We formulate the problem of identifying distinct tissue phenotypes as the problem of finding network communities using the geodesic density gradient in the space of potential interaction between different cellular components. We show that prevalent communities found in this way represent distinct and biologically meaningful tissue phenotypes. Experiments on two independent Colorectal Cancer (CRC) datasets demonstrate that the proposed algorithm outperforms current state-of-the-art methods.		Sajid Javed;Muhammad Moazam Fraz;David B. A. Epstein;David R. J. Snead;Nasir M. Rajpoot	2018		10.1007/978-3-030-00949-6_15	histology;supervised learning;pattern recognition;artificial intelligence;graph;computer science	ML	28.77672799659225	-74.90521802358792	95008
c1b9455f831552662c96f048fbb1c86cebd90224	heartperfect: data mining in a large database of myocardial perfusion scintigraphy	sensitivity and specificity;cardiac imaging;myocardial perfusion scintigraphy;data mining;statistical analysis;operating characteristic;roc curve;similarity measure	  We are presenting a method to obtain diagnosis and prognosis information by searching similar images into a large database  of Myocardial Perfusion Scintigraphy (MPS) cases for which diagnosis is known. We are applying similarity measures to cardiac  images pre-registered with a template. Our database is composed of 1430 patient cases with associated clinical information.  For each new case, we sort all the patients of the database from most to less similar ones and compute a severity criterion,  based on a statistical analysis of normal and diseased most similar patients. By varying a threshold on the severity criterion  and testing the classification of controlled cases, we have measured the operational characteristic of this test (ROC curves),  and shown increased performance in sensitivity and specificity for disease detection with respect to clinicians and to experts  in consensus. Through the extension of database to patients’ outcome information, we expect to extend this method to prognosis.    		Bernard Hotz;Jean-Philippe Thirion	2000		10.1007/978-3-540-40899-4_37	radiology;pathology;computer science;mathematics;nuclear medicine;receiver operating characteristic;statistics	DB	35.280696135065895	-79.19360086272363	95297
c5a734dc91c5906b303703963dc5614436f1d1a0	a novel pavement crack detection approach using pre-selection based on transfer learning		Most of the existing pavement image crack detection methods cannot effectively solve the noise problem caused by the complicated pavement textures and intensity inhomogeneity. In this paper, we propose a novel fully automatic crack detection approach by incorporating a pre-selection process. It starts by dividing images into small blocks and training a deep convolutional neural network to screen out the non-crack regions in a pavement image which usually cause lots of noise and errors when performing crack detection; then an efficient thresholding method based on linear regression is applied to the crack-block regions to find the possible crack pixels; at last, tensor voting-based curve detection is employed to fill the gaps between crack fragments and produce the continuous crack curves. We validate the approach on a dataset of 600 (2000 × 4000-pixel) pavement images. The experimental results demonstrate that, with pre-selection, the proposed detection approach achieves very good performance (recall = 0.947, and precision = 0.846).		Kaige Zhang;Heng-Da Cheng	2017		10.1007/978-3-319-71607-7_24	tensor;computer science;computer vision;pattern recognition;convolutional neural network;artificial intelligence;transfer of learning;pixel;linear regression;thresholding	NLP	32.94708703328017	-73.7829584541204	95877
826015d9ade1637b3fcbeca071e3137d3ac1ef56	a deep learning frame-work for recognizing developmental disorders	face genetics computer vision autism support vector machines atmospheric modeling neural networks;neural networks;support vector machines;autism;genetics;computer vision;face;atmospheric modeling	Developmental Disorders are chronic disabilities that have a severe impact on the day to day functioning of a large section of the human population. Recognizing developmental disorders from facial images is an important but a relatively unexplored challenge in the field of computer vision. This paper proposes a novel framework to detect developmental disorders from facial images. A spectrum of disorders constituting of Autism Spectrum Disorder, Cerebral Palsy, Fetal Alcohol Syndrome, Down syndrome, Intellectual disability and Progeria have been considered for recognition. The framework relies on Deep Convolutional Neural Networks (DCNN) for feature extraction. A new data-set comprising of images of subjects with these disabilities was built for testing the performance of the frame work. This model has been tested on different age groups, individual disabilities and has also been compared to a similar model that uses human intelligence to identify different developmental disorders. The results indicate that the model performs better than average human intelligence in terms of differentiating amongst different disabilities and is able to recognize subjects with these developmental disorders with an accuracy of 98.80%.	computer vision;convolutional neural network;deep learning;feature extraction	Pushkar Shukla;Tanu Gupta;Aradhya Saini;Priyanka Singh;Balasubramanian Raman	2017	2017 IEEE Winter Conference on Applications of Computer Vision (WACV)	10.1109/WACV.2017.84	face;computer vision;autism;computer science;artificial intelligence;machine learning;artificial neural network	Vision	27.501935796859517	-76.56141816843456	95968
87f191a057d19936c523bd483a604e6aa72b87a6	classification of lung nodules in ct scans using three-dimensional deep convolutional neural networks with a checkpoint ensemble method	convolutional neural network;deep learning;ensemble;lung cancer;lung nodule	BACKGROUND Accurately detecting and examining lung nodules early is key in diagnosing lung cancers and thus one of the best ways to prevent lung cancer deaths. Radiologists spend countless hours detecting small spherical-shaped nodules in computed tomography (CT) images. In addition, even after detecting nodule candidates, a considerable amount of effort and time is required for them to determine whether they are real nodules. The aim of this paper is to introduce a high performance nodule classification method that uses three dimensional deep convolutional neural networks (DCNNs) and an ensemble method to distinguish nodules between non-nodules.   METHODS In this paper, we use a three dimensional deep convolutional neural network (3D DCNN) with shortcut connections and a 3D DCNN with dense connections for lung nodule classification. The shortcut connections and dense connections successfully alleviate the gradient vanishing problem by allowing the gradient to pass quickly and directly. Connections help deep structured networks to obtain general as well as distinctive features of lung nodules. Moreover, we increased the dimension of DCNNs from two to three to capture 3D features. Compared with shallow 3D CNNs used in previous studies, deep 3D CNNs more effectively capture the features of spherical-shaped nodules. In addition, we use an alternative ensemble method called the checkpoint ensemble method to boost performance.   RESULTS The performance of our nodule classification method is compared with that of the state-of-the-art methods which were used in the LUng Nodule Analysis 2016 Challenge. Our method achieves higher competition performance metric (CPM) scores than the state-of-the-art methods using deep learning. In the experimental setup ESB-ALL, the 3D DCNN with shortcut connections and the 3D DCNN with dense connections using the checkpoint ensemble method achieved the highest CPM score of 0.910.   CONCLUSION The result demonstrates that our method of using a 3D DCNN with shortcut connections, a 3D DCNN with dense connections, and the checkpoint ensemble method is effective for capturing 3D features of nodules and distinguishing nodules between non-nodules.		Hwejin Jung;Bumsoo Kim;Inyeop Lee;Junhyun Lee;Jaewoo Kang	2018		10.1186/s12880-018-0286-0		Web+IR	31.874347630734498	-76.0661010856011	95989
5e5bc38a6b6f66cdd80494ce0b884af8d6f23a40	computer vision for automated inspection of fabric products: methodology for feature extraction and classification			computer vision;feature extraction	Ahmed Alam Eldin	1988				Vision	37.14326424361234	-68.43907589701041	96113
3f3856747431f5c10df168efed2c92db6be512ef	weakly-supervised lesion detection in video capsule endoscopy based on a bag-of-colour features model		Robotic video capsule endoscopy (VCE) is a rapidly evolving medical imaging technology enabling more thorough examination and treatment of the gastrointestinal tract than conventional endoscopy technologies. Despite of the technological advances in this field, the reviewing of the large VCE image sequences remains manual and challenges experts’ diagnostic capabilities. Video reviewing systems for automated lesion detection are still under investigation. Most of these systems are based on supervised machine learning algorithms, which require a training set of images, manually annotated by the experts to indicate which pixels correspond to lesions. In this paper, we investigate a weakly-supervised approach for lesion detection, which requires image-level instead of pixel-level annotations for training. Such an approach offers a considerable advantage with respect to the efficiency of the annotation process. It is based on state-of-the-art colour features, which, in this study, are extended according to the bag-of-visual-words model. The area under receiver operating characteristic achieved, reaches 81%.		Michael Vasilakakis;Dimitrios K. Iakovidis;Evaggelos Spyrou;Anastasios Koulaouzidis	2016		10.1007/978-3-319-54057-3_9	lesion;endoscopy;receiver operating characteristic;computer vision;pixel;bag-of-words model;capsule endoscopy;artificial intelligence;medical imaging;computer science;annotation	Vision	32.29129203928012	-75.089474026352	96378
2797df2da95e3be868afb6e9810b11e88687abdc	automatic visual detection of incorrect endoscope adaptions in chemical disinfection devices		This paper presents a complete analyzing system for detecting incorrect endoscope adaptions prior to the use of chemical disinfection devices to guarantee hygienic standards and to save resources. The adaptions are detected visually with the help of an image registration algorithm based on feature detection algorithms. On top of the processing pipeline, we implemented a k-nearest neighbor algorithm to predict the status of the adaption. The proposed approach shows good results in detecting the adaptions correctly.	correctness (computer science);feature detection (computer vision);feature detection (web development);forward compatibility;image registration;k-nearest neighbors algorithm;keystroke-level model;preprocessor;prototype;sensor;speeded up robust features	Timo Brune;Björn Brune;Sascha Eschborn;Klaus Brinker	2017		10.5220/0006143003050312	computer science;data mining;computer vision;endoscope;artificial intelligence	Vision	34.645355629811974	-80.07840661761402	96587
711c31d956b2d3eafd4dd6f8beda6303cdfa2391	air-tissue boundary segmentation in real-time magnetic resonance imaging video using semantic segmentation with fully convolutional networks		In this paper, we propose a new technique for the segmentation of the Air-Tissue Boundaries (ATBs) in the vocal tract from the real-time magnetic resonance imaging (rtMRI) videos of the upper airway in the midsagittal plane. The proposed technique uses the approach of semantic segmentation using the Deep learning architecture called Fully Convolutional Networks (FCN). The architecture takes an input image and produces images of the same size with air and tissue class labels at each pixel. These output images are post processed using morphological filling and image smoothing to predict realistic ATBs. The performance of the predicted contours is evaluated using Dynamic Time Warping (DTW) distance between the manually annotated ground truth contours and the predicted contours. Four fold experiments with four subjects from USC-TIMIT corpus (with ∼2900 training images in every fold) demonstrate that the proposed FCN based approach has 8.87% and 9.65% lesser average error than the baseline Maeda Grid based scheme, for the lower and upper ATBs respectively. In addition, the proposed FCN based rtMRI segmentation achieves an average pixel classification accuracy of 99.05% across all subjects.	baseline (configuration management);deep learning;dynamic time warping;experiment;ground truth;image editing;mike lesser;pixel;real-time clock;resonance;smoothing;timit;tract (literature)	C. A. Valliappan;Renuka Mannem;Prasanta Kumar Ghosh	2018		10.21437/Interspeech.2018-1939	real-time magnetic resonance imaging;pattern recognition;artificial intelligence;computer science;segmentation	Vision	30.91741827011495	-75.27157740965434	96707
52ec3cb99133bc6f9e3e87d8beb6bd28296d6e59	bleeding frame and region detection in the wireless capsule endoscopy video	histograms;support vector machines biomedical optical imaging endoscopes feature extraction image classification image colour analysis image fusion image representation medical image processing;fusion strategy bleeding frame region detection wireless capsule endoscopy video direct visual inspection digestive tract automatic computer aided technique color feature extraction method bleeding region color information wce images k means clustering method pixel represented images cluster centers words based color histograms support vector machine svm k nearest neighbor methods classification performance ycbcr color space cluster number 80 bleeding classification two stage saliency map extraction method first stage saliency map color channel mixer second stage saliency map visual contrast;support vector machines;image color analysis hemorrhaging histograms feature extraction support vector machines visualization accuracy;hemorrhaging;accuracy;visualization;image color analysis;feature extraction;wireless capsule endoscopy bleeding classification and region detection words based color histograms	Wireless capsule endoscopy (WCE) enables noninvasive and painless direct visual inspection of a patient's whole digestive tract, but at the price of long time reviewing large amount of images by clinicians. Thus, an automatic computer-aided technique to reduce the burden of physicians is highly demanded. In this paper, we propose a novel color feature extraction method to discriminate the bleeding frames from the normal ones, with further localization of the bleeding regions. Our proposal is based on a twofold system. First, we make full use of the color information of WCE images and utilize K-means clustering method on the pixel represented images to obtain the cluster centers, with which we characterize WCE images as words-based color histograms. Then, we judge the status of a WCE frame by applying the support vector machine (SVM) and K-nearest neighbor methods. Comprehensive experimental results reveal that the best classification performance is obtained with YCbCr color space, cluster number 80 and the SVM. The achieved classification performance reaches 95.75% in accuracy, 0.9771 for AUC, validating that the proposed scheme provides an exciting performance for bleeding classification. Second, we propose a two-stage saliency map extraction method to highlight bleeding regions, where the first-stage saliency map is created by means of different color channels mixer and the second-stage saliency map is obtained from the visual contrast. Followed by an appropriate fusion strategy and threshold, we localize the bleeding areas. Quantitative as well as qualitative results show that our methods could differentiate the bleeding areas from neighborhoods correctly.	area under curve;capsule endoscopy;channel (digital image);color space;eighty;feature extraction;frame (physical object);gastrointestinal system;gastrointestinal tract structure;hemorrhage;k-means clustering;k-nearest neighbors algorithm;mixer device component;patients;pixel;single linkage cluster analysis;support vector machine;tract (literature);visual inspection;statistical cluster	Yixuan Yuan;Baopu Li;Max Q.-H. Meng	2016	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2015.2399502	color histogram;support vector machine;computer vision;speech recognition;visualization;color image;feature extraction;computer science;machine learning;pattern recognition;histogram;accuracy and precision;statistics	Vision	36.16408798388919	-74.19852977667253	96722
5fec51cf2d044c764a049d8455f96869d31f1e99	neural classification of mass abnormalities with different types of features in digital mammography	neural networks;breast cancer diagnosis;digital mammography;feature extraction;classifiers	Early detection of breast abnormalities remains the primary prevention against breast cancer despite the advances in breast cancer diagnosis and treatment. Presence of mass in breast tissues is highly indicative of breast cancer. The research work presented in this paper investigates the significance of different types of features using proposed neural network based classification technique to classify mass type of breast abnormalities in digital mammograms into malignant and benign. 14 gray level based features, four BIRADS features, patient age feature and subtlety value feature have been explored using the proposed research methodology to attain maximum classification on test dataset. The proposed research technique attained a 91% testing classification rate with a 100% training classification rate on digital mammograms taken from the DDSM benchmark database.	artificial neural network;bi-rads;benchmark (computing);grayscale	Rinku Panchal;Brijesh Verma	2006	International Journal of Computational Intelligence and Applications	10.1142/S1469026806001757	feature extraction;computer science;machine learning;artificial neural network	ML	33.31309732887286	-76.50943308934782	96753
e82362d39e67bb2dcd39e0731d0c723aaea06a9c	implementing word retrieval in handwritten documents using a small dataset	word spotting;digital archives;handwriting recognition;t technology;training character recognition image segmentation testing handwriting recognition hidden markov models training data;historical manuscript;handwritten character recognition document image processing;document image processing;handwritten keyword retrieval;word querying keyword retrieval cursive handwritten document grapheme handwritten word recognition model;handwritten character recognition;digital archives handwritten keyword retrieval word spotting handwriting recognition historical manuscript	A novel approach to the problem of keyword retrieval in cursive handwritten documents is introduced in this work. Two issues are addressed: small dataset size and uneven sample distribution across the character set. The proposed strategies utilise graphemes (fragments of a handwritten word) to implement a recognition model which is subsequently used to form the feature model for the query word.	character encoding;feature model;information retrieval	Yiqing Liang;Richard M. Guest;Michael C. Fairhurst	2012	2012 International Conference on Frontiers in Handwriting Recognition	10.1109/ICFHR.2012.220	natural language processing;speech recognition;document processing;intelligent character recognition;computer science;intelligent word recognition;machine learning;pattern recognition;handwriting recognition	Vision	30.952515469822348	-66.42782860201862	96905
b2704b89675fd5bd9c768034c7fd24bcd42f8172	research on burning dynamic inspection technology of wheel tread using vision	railways;wheel tread;mechanical engineering computing;edge detection;backpropagation;inspection;computer vision;pattern recognition burning dynamic inspection technology vision train wheel tread canny algorithm stationary wavelet edge detection algorithm extracting technologies tread boundary searching technology ga bp algorithm;wheels backpropagation computer vision edge detection genetic algorithms inspection mechanical engineering computing railways;feature extraction;dynamic inspection;burning;pattern recognition;genetic algorithms;wheels image edge detection feature extraction image segmentation heuristic algorithms inspection pattern recognition;vision;wheels;vision burning dynamic inspection wheel tread	In order to realize burning inspection for the train wheel tread, a burning dynamic inspecting technology using vision were investigated. Firstly, the tread region was segmented by tread segmentation technology based on improved Canny algorithm combined stationary wavelet edge detection algorithm. Then the extracting technologies of the suspicious regions of the wheel tread burnings based on tread boundary searching technology are studied. Finally, GA-BP algorithm was applied in the pattern recognition of burnings based on the feature extraction. The experimental results show that that the burning effective detecion was 96.67%, the fulfillment rate was 65.7%.Therefore, the proposed method was effective method of burning dynamic inspection.	algorithm;backpropagation;canny edge detector;edge detection;effective method;feature extraction;pattern recognition;scroll wheel;software bug;software release life cycle;stationary process;wavelet	Yong Zhao;Hong Ye;Yong-Biao Hu;Song-shan Shi;Lin Zhou	2012	2012 9th International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2012.6233951	vision;computer vision;simulation;genetic algorithm;edge detection;inspection;feature extraction;computer science;backpropagation;machine learning;combustion	Robotics	38.92810410412865	-68.39019862693245	96979
36daf6bbca30e7fc8e1fbcf81f300c0e6ebdc7ec	threshold algorithm for pancreas segmentation in dixon water magnetic resonance images		Pancreas segmentation is crucial for a computer-aided diagnosis (CAD) system to provide cancer detection and radiation therapy of pancreatic cancer. Because of anatomically high-variability between subjects, achieving high accuracies in pancreas segmentation remains a challenging task. In this work, based on Otsu threshold method and morphological method, we first proposed a segmentation pipeline for pancreas, using Dixon water magnetic resonance image (MRI) data from five healthy volunteers. The threshold method was used to obtain the approximate outline of the pancreas, and the morphological method was used to separate the pancreas from the surrounding tissues. The segmentation results were compared with manual contours using Dice Index (DI) and we achieved DI: 0.80 ± 0.08 which was better than the level Set Methods (LSMs) DI: 0.64 ± 0.08. The proposed method was simple and easy to integrate with the Medical Imaging Interaction Toolkit (MITK) workbench, so it provided an efficient and simple segmentation method for processing large clinical datasets.	approximation algorithm;computer-aided design;dixon's factorization method;heart rate variability;medical imaging;otsu's method;resonance;workbench	Xiaoying Shan;Chaolin Du;Yufei Chen;Asoke K. Nandi;Xiaoliang Gong;Chao Ma;Panpan Yang	2017	2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)	10.1109/FSKD.2017.8393142	computer vision;machine learning;image segmentation;computer science;magnetic resonance imaging;medical imaging;segmentation;pancreas;artificial intelligence	Vision	37.68800833642394	-79.65378170206114	97105
a82dab83b765b3e733f8be183d9615fd46ccf5bb	manifold learning for biomarker discovery in mr imaging	mr imaging;longitudinal image information;mr image data;separate manifold representation;low-dimensional space captures information;single manifold;biomarker discovery;intra-subject brain variation;low-dimensional manifold;intra-subject variation;disease neuroimaging initiative;manifold learning	mr imaging;longitudinal image information;mr image data;separate manifold representation;low-dimensional space captures information;single manifold;biomarker discovery;intra-subject brain variation;low-dimensional manifold;intra-subject variation;disease neuroimaging initiative;manifold learning		Robin Wolz;Paul Aljabar;Joseph V. Hajnal;Daniel Rueckert	2010		10.1007/978-3-642-15948-0_15	computer vision;artificial intelligence;machine learning;mathematics	ML	30.06093316003965	-79.27625557089648	97114
3186d1dcd971267a3c1690ca2604f1b336ddf04e	computer-aided diagnosis algorithm for lung cancer using retrospective ct images	lung cancer;low dose;computer aided diagnosis;large data sets;optical inspection;medical diagnostics;visual inspection;computing systems	ABSTRACT This paper presents a method for detecting suspicious nodules based on successive low-dose helical CT images. The method uses both initial and follow-up images to improve nodule detection performance. The basic idea of the detection is to register nodule images measured at different time and to assess the changes in size, shape, and density of the nodule. Since there are several variations of nodule changes, such as stable, shrinking, expansion in size, disappearance, appearance, and separation, a coarse-to-fine registration technique was adopted to deal with large nodule deformation. Especially, the fine registration is performed by excluding nodule regions and using nodule surroundings to avoid effects of nodule deformations in alignment task. In a preliminary experiment, the method was applied to ten cases with successive scans. From visual inspection, the corresponding results between initial and follow-up images were acceptable in clinical use. More researches using a large data set will be required. Still, we believe that the method has the potential of detecting suspicious nodules for use in a computer-aide diagnosis system. Keywords: low-dose helical CT images, screening, lung cancer, computer-aide diagnosis system, coarse-to-fine corresponding technique, follow-up	ct scan;medical algorithm	Hironori Nakashima;Takuya Yamamoto;Mitsuru Kubo;Yoshiki Kawata;Noboru Niki;Hironobu Ohmatsu;Kenji Eguchi;Hiroyuki Nishiyama;Masahiro Kaneko;Masahiko Kusumoto;Ryutaro Kakinuma;Noriyuki Moriyama	2005		10.1117/12.595591	computer vision;radiology;pathology;engineering	Vision	38.41907585296016	-80.02179922011825	97268
5233e5686a44b306cc1f2bcc127d81d5364861af	improving needle detection in 3d ultrasound using orthogonal-plane convolutional networks		Successful automated detection of short needles during an intervention is necessary to allow the physician identify and correct any misalignment of the needle and the target at early stages, which reduces needle passes and improves health outcomes. In this paper, we present a novel approach to detect needle voxels in 3D ultrasound volume with high precision using convolutional neural networks. Each voxel is classified from locally-extracted raw data of three orthogonal planes centered on it. We propose a bootstrap re-sampling approach to enhance the training in our highly imbalanced data. The proposed method successfully detects 17G and 22G needles with a single trained network, showing a robust generalized approach. Extensive ex-vivo evaluations on 3D ultrasound datasets of chicken breast show 25% increase in F1-score over the state-of-the-art feature-based method. Furthermore, very short needles inserted for only 5 mm in the volume are detected with tip localization errors of ({u003c})0.5 mm, indicating that the tip is always visible in the detected plane.	artificial neural network;convolutional neural network;f1 score;robustness (computer science);sampling (signal processing);video-in video-out;voxel	Arash Pourtaherian;Farhad Ghazvinian Zanjani;Svitlana Zinger;Nenad Mihajlovic;Gary C. Ng;Hendrikus H. M. Korsten;Peter H. N. de With	2017		10.1007/978-3-319-66185-8_69	pattern recognition;computer vision;convolutional neural network;artificial intelligence;voxel;raw data;computer science;3d ultrasound	Vision	36.34078311979631	-80.0763706116382	97280
400f495cfa73456d213f885b2a20d6910caacbe1	joint identification of imaging and proteomics biomarkers of alzheimer's disease using network-guided sparse learning	biological patents;biomedical journals;text mining;europe pubmed central;proteomics biomarkers cross validation trial multimodal biomarker network guided sparse learning model cognitive prediction multimodal imaging alzheimers disease detection biomarker identification;citation search;sparse learning;citation networks;regression;research articles;abstracts;neuroimaging;open access;proteomics magnetic resonance imaging correlation alzheimer s disease predictive models;proteomic biomarker;life sciences;clinical guidelines;cognitive outcome;cognitive outcome sparse learning regression neuroimaging proteomic biomarker;full text;rest apis;orcids;europe pmc;biomedical research;proteomics biomedical mri cognitive systems diseases learning artificial intelligence medical image processing;bioinformatics;literature search	Identification of biomarkers for early detection of Alzheimer's disease (AD) is an important research topic. Prior work has shown that multimodal imaging and biomarker data could provide complementary information for prediction of cognitive or AD status. However, the relationship among multiple data modalities are often ignored or oversimplified in prior studies. To address this issue, we propose a network-guided sparse learning model to embrace the complementary information and inter-relationships between modalities. We apply this model to predict cognitive outcome from imaging and proteomic data, and show that the proposed model not only outperforms traditional ones, but also yields stable multimodal biomarkers across cross-validation trials.	alzheimer's disease;biological markers;cross infection;cross-validation (statistics);early diagnosis;multimodal imaging;multimodal interaction;proteomics;sparse matrix	Jingwen Yan;Heng Huang;Sungeun Kim;Jason H. Moore;Andrew J. Saykin;Li Shen	2014	2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2014.6867958	text mining;regression;computer science;bioinformatics;data science;data mining;neuroimaging	Vision	25.12531862464834	-77.8631775164256	97290
03ebb6780cf976cb17a62400e513511e20123262	neural image thresholding with sift-controlled gabor features	image features;image segmentation;feed forward neural network;feature extraction image segmentation training shape accuracy histograms level set;neural nets;neural network neural image thresholding sift controlled gabor features image analysis process segmentation scheme intelligent segmentation dynamic determination gabor filter sift technique scale invariant feature transform;level set;threshold scheme;gabor filters;gold standard;gabor filter;medical image;scale invariant feature transform;transforms gabor filters image segmentation neural nets;region of interest;transforms;image analysis;region growing;neural network	Image thresholding is a very important phase in the image analysis process. In all traditional segmentation schemes, statically calculated thresholds or initial points are used to binarize images. Because of the differences in images characteristics, these techniques may generate high segmentation accuracy for some images and low accuracy for other images. Intelligent segmentation by “dynamic” determination of thresholds based on image properties may be a more robust solution. In this paper, we use the Gabor filter to generate features from regions of interest (ROIs) detected by the the SIFT technique (Scale-Invariant Feature Transform). These features are used to train a neural network for the task of image thresholding. The average of segmentation accuracies for a set of test images is calculated by comparing every segmented image with its gold standard image marked by human experts.	artificial neural network;gabor filter;image analysis;image segmentation;region of interest;scale-invariant feature transform;thresholding (image processing)	Ahmed A. Othman;Hamid R. Tizhoosh	2011	The 2011 International Joint Conference on Neural Networks	10.1109/IJCNN.2011.6033488	image texture;computer vision;feedforward neural network;feature detection;range segmentation;binary image;image processing;gold standard;computer science;level set;machine learning;segmentation-based object categorization;pattern recognition;scale-invariant feature transform;mathematics;region growing;thresholding;image segmentation;scale-space segmentation;feature;artificial neural network;region of interest	Vision	36.02144227116207	-74.52675016412108	97546
45377d6efc32a2b858a86160c55ed6152ddf7100	application of adaptive resonance theory neural network for mr brain tumor image classification	textural features;image classification;art2;brain tumor images;brain tumor;classification accuracy;adaptive resonance theory;neural network	In the present study, the effectiveness of the adaptive resonance theory neural network (ART2) is illustrated in the context of automatic classification of abnormal brain tumor images. Abnormal images from four different classes namely metastase, meningioma, glioma and astrocytoma have been used in this work. Initially, textural features are extracted from these images. An extensive feature selection is performed to optimize the number of features. These optimized features are then used to classify the images using ART2 neural network. Experimental results show promising results for the ART2 network in terms of classification accuracy and convergence rate. A comparison is made with other conventional classifiers to show the superior nature of ART2 neural network. The classification accuracy of the ART2 classifier is significantly higher than the statistical classifiers. ART2 classifier is also computationally feasible over other neural classifiers. Thus this work suggests ART2 neural network as an optimal image classifier which finds application in clinical field. DOI: 10.4018/978-1-4666-1755-1.ch010	adaptive resonance theory;artificial neural network;feature selection;linear classifier;rate of convergence;statistical classification	D. Jude Hemanth;D. Selvathi;J. Anitha	2010	IJHISI	10.4018/jhisi.2010110304	computer vision;contextual image classification;computer science;adaptive resonance theory;machine learning;pattern recognition;artificial neural network	ML	33.47594927194636	-73.74040758489699	97779
5c65c9f519cee17206d6af13628ed4361a6c899d	measuring morphologic properties of the human retinal vessel system using a two-stage image processing approach	patient diagnosis;mathematical morphology;pilot study;quantitative reproducible methods;eye;image segmentation;image processing;tortuosity;tortuosity morphologic properties measurement human retinal vessel system two stage image processing scanning laser technique digital image analysis retinal vascular tree retinal vascular network pathophysiology systemic vascular disease retinal vascular disease arterial hypertension quantitative reproducible methods automatic measurement diagnosis therapy control two stage image analysis image segmentation neural net arteries veins arterial diameter;neural nets;digital image analysis;pathophysiology;top down;therapy control;systemic vascular disease;arteries;mathematical morphology eye blood pressure measurement blood flow measurement patient monitoring medical image processing image segmentation image classification neural nets patient diagnosis;image classification;veins;automatic measurement;retinal vascular network;two stage image processing;morphologic properties measurement;functional imaging;morphology;neural net;two stage image analysis;monitoring;retina;medical image processing;vascular disease;diseases;humans retinal vessels retina image analysis morphology image segmentation digital images diseases monitoring medical treatment;arterial diameter;retinal vascular tree;image analysis;patient monitoring;humans;human retinal vessel system;retinal vascular disease;blood pressure measurement;medical treatment;retinal vessels;diagnosis;follow up study;scanning laser technique;digital images;arterial hypertension;blood flow measurement	The scanning laser technique in combination with digital image analysis can be used to assess the morphology of the retinal vascular tree. Quantitative description of the retinal vascular network may provide further knowledge in pathophysiology of retinal and systemic vascular disease. Especially, for monitoring of vascular alteration in follow-up studies quantitative reproducible methods to assess the vascular morphology are essential. Therefore we developed an automatic scheme allowing the measurement of morphological properties for the use in diagnosis and therapy control. To extract the morphological properties of the retina a two-stage image analysis procedure is employed. First the image is segmented in objects using a model-based top-down, image segmentation scheme. Then the obtained objects are classified with a neural net, the result being the tree of the arteries and veins. The third step is a measurement process which yields the desired information of arterial diameter, tortuosity and other morphological properties. As an example we show a functional image of the diameters and present a pilot-study in patients with arterial hypertension to demonstrate the ability of the new method for computerized analysis of the retinal vascular tree to detect arteriolar vascular alterations. >	image processing	Ansgar Kaupp;A. Dölemeyer;R. Wilzeck;R. Schlösser;Stephan Wolf;Dietrich Meyer-Ebrecht	1994		10.1109/ICIP.1994.413350	computer vision;contextual image classification;tortuosity;mathematical morphology;computer science;blood pressure;functional imaging;top-down and bottom-up design;remote patient monitoring;image segmentation;digital image;artificial neural network	Robotics	37.261328063825424	-78.03903929548694	97968
cd30075afc0b2ad2af9d57fa7a37ca9a4cfeb980	non-intrusive practitioner pupil detection for unmodified microscope oculars	pupil center estimation;surgical microscope;pupil detection	Modern microsurgery is a long and complex task requiring the surgeon to handle multiple microscope controls while performing the surgery. Eye tracking provides an additional means of interaction for the surgeon that could be used to alleviate this situation, diminishing surgeon fatigue and surgery time, thus decreasing risks of infection and human error. In this paper, we introduce a novel algorithm for pupil detection tailored for eye images acquired through an unmodified microscope ocular. The proposed approach, the Hough transform, and six state-of-the-art pupil detection algorithms were evaluated on over 4000 hand-labeled images acquired from a digital operating microscope with a non-intrusive monitoring system for the surgeon eyes integrated. Our results show that the proposed method reaches detection rates up to 71% for an error of ≈3% w.r.t the input image diagonal; none of the state-of-the-art pupil detection algorithms performed satisfactorily. The algorithm and hand-labeled data set can be downloaded at:: www.ti.uni-tuebingen.de/perception.	eye tracking;fatigue;hough transform;human error;microscope, surgical;microscope device component;microscope image processing;microsurgery;operating room;pupil;tracer;weatherstar;algorithm	Wolfgang Fuhl;Thiago Santini;Carsten Reichert;Daniel Claus;Alois M Herkommer;Hamed Bahmani;Katharina Rifai;Siegfried Wahl;Enkelejda Kasneci	2016	Computers in biology and medicine	10.1016/j.compbiomed.2016.10.005	computer vision;simulation	Vision	34.943665058005735	-80.15780933377785	98271
baf6c58b6e0a738592f75d09a3b45784dc96e5c4	visual contents adaptation for color vision deficiency	conference;colour blindness visual contents adaptation color vision deficiency dichromat adaptations anomalous trichromat quantitative measurements qualitative measurements color information readability;vision defects;image colour analysis;image colour analysis colour vision vision defects;colour vision;pigments laboratories wireless communication cellular phones web pages internet table lookup costs humans photoreceptors;content adaptation;color vision	In this paper. we propose methods to adapt colors on the visual content for people with color vision deficiency. The proposed adaptation consists of two parts: adaptations for dichromat and anomalous trichromat. The adaptation for dichromats aims to give them better color information, while the adaptation for anomalous trichromats aims to give them original color. To verify the proposed methods, we used both quantitative and qualitative measurements. Experimental results showed that the proposed adaptation enhanced color information readability of the people with color vision deficiency.	angular defect;color vision	Seungji Yang;Yong Man Ro	2003		10.1109/ICIP.2003.1246996	computer vision;multimedia;color vision	Vision	29.081912731242	-69.82952472431998	98287
c7771fac94f187af65fbe75710901b9da263d3d9	the current state of art: handwriting a behavioral biometric for person identification and verification	disguised and forgery detection;software tool;writer identification;criminal justice;writer identification and verification;comparative study;text dependent;text independent	Person identification and verification based on handwriting is a hot research topic. The use of computer in this area is within recent years. It has received its interest due to a great importance in criminal justice based on handwriting analysis. This paper presents a current research in person identification and verification based on natural as well as disguised and forged handwritings. The focus is on the approaches present for off line cursive and isolated English handwriting up till date. A comparative study is presented for text dependent and text independent methods. It briefly discuss about the software tools available and its applicability. Also gives a summary of research results. It outlines the directions for further research.	biometrics;graphology	Sharada Laxman Kore;Shaila Apte	2012		10.1145/2345396.2345545	criminal justice;speech recognition;artificial intelligence;comparative research	HCI	30.646289764434968	-67.91246871435276	98433
9da905e95e39cc666f250fb5943c55b3b2adde16	skin cancer reorganization and classification with deep neural network		As one kind of skin cancer, melanoma is very dangerous. Dermoscopy based early detection and recognization strategy is critical for melanoma therapy. However, well-trained dermatologists dominant the diagnostic accuracy. In order to solve this problem, many effort focus on developing automatic image analysis systems. Here we report a novel strategy based on deep learning technique, and achieve very high skin lesion segmentation and melanoma diagnosis accuracy: 1) we build a segmentation neural network (skin_segnn), which achieved very high lesion boundary detection accuracy; 2) We build another very deep neural network based on Google inception v3 network (skin_recnn) and its well-trained weight. The novel designed transfer learning based deep neural network skin_inceptions_v3_nn helps to achieve a high prediction accuracy. Introduction Melanoma is the most dangerous type of skin cancer. It kills more than 10,000 people each year in United States1. Early detection, reorganization and treatment is critical for melanoma therapy. It can help save more than 95% people. Dermoscopy is one of the most important techniques to exam skin lesions and can capture high resolution images of the skin escaping the interruption of surface reflections. Specially well-trained clinicians use this high resolution imaging to evaluate the possibility of melanoma at the very beginning and can obtain a diagnostic accuracy as high as ~80%2. However, there is not enough experienced dermatologists all over the world. In order to solve this problem, there has been effort to create machine-driven image analysis software to classify different skin associated diseases using dermoscopy images in the academic research community. Previous computer-aided classification strategies are less successful for two major reasons: 1) the database is not as good as enough. Previous work is based on quite few amount of dermoscopy skin lesion images, so programs cannot learn and extract useful features. 2) There was also limited computing ability in previous time, so people had little ideas to treat with a huge amount of images. Artificial intelligent and deep learning technique, powered by advanced computation ability and large datasets people have collected and published as open sources, have been dominated in many areas and been proved to exceed human performance in strategic games like Go3, image recognition like ImageNet competition4, language translation and speech recognition. A very important paper published recently in nature also validates that deep constitutional neural network exhibits very high melanoma classification ability and has been shown to exceed common well trained dermatologists (72.1% vs 66.0%)5. In this paper, the author utilized a GoogleNet Inception v3 CNN architecture with well trained weight on 1.28 million ImageNet datas. The final layer is removed and fine tune to the author categorized dataset containing more than 13,000 images which was collected from a combination of open-access dermatology repositories, the ISIC Dermoscopic Archive, the Edinburgh Dermofit Librar. The significance of this paper is that it is the first time scientists proved the diagnostic ability of deep learning in skin cancer screen. This is also the major concept of ISIC Dermoscopic Archive dataset and many other open source medical imaging datasets. Those datasets help us to improve the whole research community and to develop more powerful artificial intelligent based methodologies. In the future, we believe that artificial intelligent and deep learning would obtain more powerful results and finally benefit the whole society and human health. In this ISIC skin cancer competition, I am trying to develop a novel deep learning based solution to solve melanoma classification problem. In details, I am trying to solve two major problems: 1) the skin lesion recognition problem (ISIC Challenge Part 1). Skin lesion recognition is very important, because it would be helpful for cameras and computers to automatically detect and zoom-in to the lesion regions. I have tried many strategies and finally chose the U-Net6 based neural network and have achieved a good detection and recognition accuracy. 2) the melanoma judgment (ISIC Challenge Part 3). I utilize the transfer learning strategy based on Google well trained Inceptions_v3 neural network. This novel designed network also help to achieve a very high melanoma prediction accuracy.	archive;artificial neural network;categorization;computation;computer vision;deep learning;human reliability;image analysis;image resolution;imagenet;interrupt;medical imaging;net6;open-source software;reflection (computer graphics);speech recognition	Hao Chang	2017	CoRR		artificial intelligence	AI	32.23579666336592	-76.04010871117924	98681
a597f9e5586884eaafc3aeb4fbf9164536d3e045	computer-aided diagnosis of mass-like lesion in breast mri: differential analysis of the 3-d morphology between benign and malignant tumors	ellipsoid fitting;computer aided diagnosis;3 d morphology;co occurrence matrix	This study aimed to evaluate the value of using 3-D breast MRI morphologic features to differentiate benign and malignant breast lesions. The 3-D morphological features extracted from breast MRI were used to analyze the malignant likelihood of tumor from ninety-five solid breast masses (44 benign and 51 malignant) of 82 patients. Each mass-like lesion was examined with regards to three categories of morphologic features, including texture-based gray-level co-occurrence matrix (GLCM) feature, shape, and ellipsoid fitting features. For obtaining a robust combination of features from different categories, the biserial correlation coefficient (|r(pb)|)≧0.4 was used as the feature selection criterion. Receiver operating characteristic (ROC) curve was used to evaluate performance and Student's t-test to verify the classification accuracy. The combination of the selected 3-D morphological features, including conventional compactness, radius, spiculation, surface ratio, volume covering ratio, number of inside angular regions, sum of number of inside and outside angular regions, showed an accuracy of 88.42% (84/95), sensitivity of 88.24% (45/51), and specificity of 88.64% (39/44), respectively. The AZ value was 0.8926 for these seven combined morphological features. In conclusion, 3-D MR morphological features specified by GLCM, tumor shape and ellipsoid fitting were useful for differentiating benign and malignant breast masses.	angularjs;assignment zero;bone structure of radius;categories;co-occurrence matrix;coefficient;document-term matrix;ellipsoid method;extraction;feature selection;malignant neoplasms;mammary neoplasms;mathematical morphology;noninfiltrating intraductal carcinoma;patients;receiver operating characteristic;receiver operator characteristics;sensitivity and specificity;spiculate;azimexon;t test	Yan-Hao Huang;Yeun-Chung Chang;Chiun-Sheng Huang;Tsung-Ju Wu;Jeon-Hor Chen;Ruey-Feng Chang	2013	Computer methods and programs in biomedicine	10.1016/j.cmpb.2013.08.016	computer vision;pathology;computer science;pattern recognition;mathematics;co-occurrence matrix	Vision	35.39243247811738	-77.49450534744051	98882
5e70b1beef10efafc6165018fa0ab790bd3bfc28	classification algorithm of retina images of diabetic patients based on exudates detection	eye;image processing;diabetes;image classification;patient treatment diseases eye image classification medical image processing;image color analysis;retina;medical image processing;retinopathy;classification algorithms;diseases;patient treatment;retina diabetes retinopathy classification algorithms diseases algorithm design and analysis image color analysis;clinical environments classification algorithm retina images diabetic patients exudates detection chronic hyperglycemia diabetes eyes kidneys nerves heart blood vessels vision impairment last instance blindness diabetic retinopathy detection laser therapy treatment ophthalmologists light intensity levels emphasis;algorithm design and analysis;exudates detection;image processing diabetes retinopathy exudates detection	The chronic hyperglycemia of diabetes is associated with long-term damage, dysfunction, and failure of different organs, especially the eyes, kidneys, nerves, heart, and blood vessels. The regular examination of diabetic patients can potentially reduce the risk of vision impairment and in the last instance blindness. Early diabetic retinopathy detection enables application of laser therapy treatment in order to prevent or delay loss of vision. The diagnostics and detection of diabetic retinopathy is performed by specialized ophthalmologists manually and represents expensive procedure. Automatic exudates detection and retina images classification would be helpful for reducing diabetic retinopathy screening costs and encouraging regular examinations. We proposed the automated algorithm that applies mathematical modeling which enables light intensity levels emphasis, easier exudates detection, efficient and correct classification of retina images. The proposed algorithm is robust to various appearance changes of retinal fundus images which are usually processed in clinical environments.	algorithm;mathematical model	Vesna Zeljkovic;Milena Bojic;Claude Tameze;Ventzeslav Valev	2012	2012 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCSim.2012.6266907	algorithm design;computer vision;contextual image classification;image processing;computer science	Vision	36.38422142713258	-76.53590528017895	99018
2985e474e42a2200da0807e187d251a9eeff0f62	neural network analysis applied to tumor segmentation on 3d breast ultrasound images	3d breast ultrasound images;neural network 3d ultrasound images breast tumor segmentation;2d image processing neural network analysis tumor segmentation 3d breast ultrasound images;image segmentation;neural nets;ultrasound;tumor segmentation;tumours;segmentation;three dimensional;ultrasound imaging;3d ultrasound;medical image processing;breast tumor;neural network analysis;2d image processing;3d ultrasound images;neural networks image analysis breast neoplasms image segmentation ultrasonic imaging image processing shadow mapping feature extraction image enhancement area measurement;image processing techniques;biomedical ultrasonics;tumours biomedical ultrasonics image segmentation medical image processing neural nets;neural network	Our study presents a fully automatic tumor segmentation method using three-dimensional (3D) breast ultrasound (US) images. The proposed method is an approach based on 2D image processing techniques, which considers the variations of contours between two adjacent planes in a 3D dataset. In this approach, a reference image obtained in the previous plane was used to facilitate the segmentation in the next plane. To determine the initial reference image, we extracted five features from regions in each 2D slice and applied neural network analysis to discriminate the tumor from the background. Finally, three area error metrics were calculated to measure the overall performance of the system.	artificial neural network;image processing;network theory;residual (numerical analysis)	Sheng-Fang Huang;Yen-Ching Chen;Woo Kyung Moon	2008	2008 5th IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2008.4541243	three-dimensional space;computer vision;radiology;medicine;pathology;computer science;machine learning;segmentation-based object categorization;ultrasound;image segmentation;scale-space segmentation;segmentation;artificial neural network	Vision	38.01070478153644	-77.42841444310037	99121
54763e674d481d9102ac5d73e24da6e5259f605a	using irregular pyramid for text segmentation and binarization of gray scale image	image segmentation;binary image;text extraction;image segmentation data mining information retrieval colored noise image analysis algorithm design and analysis feature extraction focusing text recognition text analysis;filtering process irregular pyramid structure text segmentation text binarization gray scale image binary image text extraction method text recognition local thresholding technique;focus of attention;feature extraction;document image processing;character recognition feature extraction document image processing image segmentation;subject areas;character recognition;text segmentation	Compared to binary images that most text extraction methods work on, gray scale images provides much more information for the extraction task. On the other hand complication also arises in determining the subject textual content from its background region (ie. thresholding) before the actual text extraction process can begin. Differing from the usual sequence of processes where document images are binarized before the actual text extraction, this paper proposes a new method by first segmenting individual subject area with the help of irregular pyramid to be followed by the binarization process. This permits the focus of attention only on the appropriate subject areas for the binarization process before text recognition. Our method overcomes the difficulty in global binarization to find a single value to fit all. It also avoids the common problem in most local thresholding technique of finding a suitable window size. As shown in our experimented result, our method performed well in both text segmentation and binarization by varying the sequence of processing.	binary image;grayscale;optical character recognition;preprocessor;test case;text segmentation;thresholding (image processing);video post-processing	Poh Kok Loo;Chew Lim Tan	2003		10.1109/ICDAR.2003.1227733	text segmentation;computer vision;speech recognition;binary image;feature extraction;computer science;pattern recognition;image segmentation;scale-space segmentation	Vision	38.16188125396464	-66.58320405718804	99223
d848882526de35a79a523b4a8b178b292fa93d9f	automatic identification of human parasite eggs based on multitexton histogram retrieving the relationships between textons	histograms;cbir;electronic mail;support vector machines;human parasite eggs;multitexton histogram descriptor;microscopy;shape;image color analysis;feature extraction;textons	In order to identify the parasitic diseases, this paper propose the automatic identification of Human Parasite Eggs to eight different species : Ascaris, Uncinarias, Trichuris, Dyphillobothrium-Pacificum, Taenia-Solium, Fasciola Hepetica and Enterobius-Vermicularis from their microscopic images based on Multitexton Histogram - MTH using new structures of textons. This proposed system includes two stages. In first stage, a feature extraction mechanism that is based on MTH descriptor retrieving the relationships between textons. In second stage, an CBIR system has been implemented in orden to detect their correct species of helminths. Finally, simulation results show overall success rates of 94,78% in the detection.	automatic identification and data capture;content-based image retrieval;feature extraction;granular computing;simulation	Roxana Flores-Quispe;Yuber Velazco-Paredes;Raquel Esperanza Patiño-Escarcina;Cesar Beltran-Castanon	2014	2014 33rd International Conference of the Chilean Computer Science Society (SCCC)	10.1109/SCCC.2014.17	biology;computer vision;data mining;communication	Robotics	34.396284639700184	-72.78704819940607	99320
8276e1edab78f4f3bbc5d0f2316bc795ac7f00c2	study on contribution of biological interpretable and computer-aided features towards the classification of childhood medulloblastoma cells	colour feature;medulloblastoma;morphology;multiclass classification;texture feature;who subtypes	Diagnosis and Prognosis of brain tumour in children is always a critical case. Medulloblastoma is that subtype of brain tumour which occurs most frequently amongst children. Post-operation, the classification of its subtype is most vital for further clinical management. In this paper a novel approach of pathological subtype classification using biological interpretable and computer-aided textural features is forwarded. The classifier for accurate features prediction is built purely on the feature set obtained by segmentation of the ground truth cells from the original histological tissue images, marked by an experienced pathologist. The work is divided into five stages: marking of ground truth, segmentation of ground truth images, feature extraction, feature reduction and finally classification. Kmeans colour segmentation is used to segment out the ground truth cells from histological images. For feature extraction we used morphological, colour and textural features of the cells followed by feature reduction using Principal Component Analysis. Finally both binary and multiclass classification is done using Support Vector Method (SVM). The classification was compared using six different classifiers and performance was evaluated employing five-fold cross-validation technique. The accuracy achieved for binary and multiclass classification before applying PCA were 95.4 and 62.1% and after applying PCA were 100 and 84.9% respectively. The run-time analysis are also shown. Results reveal that this technique of cell level classification can be successfully adopted as architectural view can be confusing. Moreover it conforms substantially to the pathologist's point of view regarding morphological and colour features, with the addition of computer assisted texture feature.	analysis of algorithms;bitwise operation;brain neoplasms;cell (microprocessor);cross-validation (statistics);entity name part qualifier - adopted;feature extraction;ground truth;item unique identification;k-means clustering;medulloblastoma;multiclass classification;point of view (computer hardware company);principal component analysis;support vector machine;biologic segmentation;high-grade childhood cerebral astrocytoma;triangulation	Daisy Das;Lipi B. Mahanta;Shabnam Ahmed;Basanta Kr. Baishya;Inamul Haque	2018	Journal of medical systems	10.1007/s10916-018-1008-4	support vector machine;data mining;feature extraction;k-means clustering;principal component analysis;ground truth;classifier (linguistics);segmentation;medicine;artificial intelligence;multiclass classification;pattern recognition	ML	34.13632403355107	-75.60821236026364	99430
52140a3160867e83baa602d48dc960a46cdbfa91	a complementary method for the detection of osteoblastic metastases on digitized radiographs	coefficient of variation;receiver operator characteristic;standard deviation;trabecular bone;roc curve;differential diagnosis;image analysis;medical treatment	This study was conducted to evaluate the diagnostic usefulness of gray level parameters in order to distinguish healthy bone from osteoblastic metastases on digitized radiographs. Skeletal radiographs of healthy bone (n = 144) and osteoblastic metastases (n = 35) were digitized using pixels 0.175 mm in size and 4,096 gray levels. We obtained an optimized healthy bone classification to compare with pathological bone: cortical, trabecular, and flat bone. The osteoblastic metastases (OM) were classified in nonflat and flat bone. These radiological images were analyzed by using a computerized method. The parameters (gray scale) calculated were: mean, standard deviation, and coefficient of variation (MGL, SDGL, and CVGL, respectively) based on gray level histogram analysis. Diagnostic utility was quantified by measurement of parameters on healthy and pathological bone, yielding quantification of area under the receiver operating characteristic (ROC) curve, AUC. All three image parameters showed high and significant values of AUC when comparing healthy trabecular bone and nonflat bone OM, showing MGL the best discriminatory ability (0.97). As for flat bones, MGL showed no ability to distinguish between healthy and flat bone OM (0.50). This could be achieved by using SDGL or CVGL, with both showing a similar diagnostic ability (0.85 and 0.83, respectively). Our results show that the use of gray level parameters quantify healthy bone and osteoblastic metastases zones on digitized radiographs. This may be helpful as a complementary method for differential diagnosis. Moreover, our method will allow us to study the evolution of osteoblastic metastases under medical treatment.	area under curve;bone marrow diseases;bone tissue;bone neoplasms;clec10a wt allele;cns metastases;cancellous bone;classification;coefficient;differential diagnosis;grayscale;histogram;multiple granularity locking;organ measurement domain;pixel;plain x-ray;quantitation;radiography;receiver operating characteristic;receiver operator characteristics;skeletal bone;standard deviation;structure of flat bone;bone metastases prevention/treatment	Angel González-Sistal;Alicia Baltasar Sánchez	2006	Journal of Digital Imaging	10.1007/s10278-006-9946-7	image analysis;radiology;medicine;pathology;computer science;receiver operating characteristic;surgery;statistics	HCI	35.68989718483766	-77.67081032140436	99436
4babb12d6785a779ffd8b1d4cd3f7f11ca60c1e6	a quantitative line-scan image analysis method for colonoscopy diagnosis using fice	image scanners;tumours;endoscopes image color analysis colonoscopy lesions gastrointestinal tract colon;image colour analysis;medical image processing;endoscopes;tumours endoscopes image colour analysis image scanners medical image processing;fice images quantitative line scan image analysis method colonoscopy diagnosis abnormal lesions fuji intelligent chromo endoscopy color histogram technique gray level co occurrence matrix glcm tumor observation minute diagnosis semimanual image horizontal line selection colonoscopy video color histogram index contrast energy homogeneity entropy glcm matrix;large intestine lesions early diagnosis tumor image analysis fuji intelligent chromo endoscopy image evaluation	This paper presents a quantitative image analysis technique for colonoscopy diagnosis to distinguish abnormal lesions, especially for using Fuji Intelligent Chromo Endoscopy (FICE). We take the color histogram technique and gray level co-occurrence matrix (GLCM) into account, and proposed an efficient line-scan method for observing early and small tumor during minute diagnosis. The line-scan method is based on semimanual image horizontal line selection of colonoscopy video, then the color histogram index, contrast, energy, homogeneity and entropy are calculated via GLCM matrix of the selection image area. Thus, the method leads the FICE images measurable and provides a view to accelerate and enhance physician to determine the lesions quickly. The results show that the proposed line-scan method significantly evaluates the diagnosis images for the real patient experiments.	asea irb;co-occurrence matrix;color histogram;document-term matrix;experiment;grayscale;image analysis;review board;software diagnosis	Min-Liang Wang;Pin-Zhi Lin;Sheng-lei Yan	2012	2012 International Symposium on Intelligent Signal Processing and Communications Systems	10.1109/ISPACS.2012.6473455	computer vision;radiology;medicine;pathology	Robotics	37.31667724082617	-76.3042637635252	99510
ef20eb76d0034c3f6a4e3dd5eed1ffda65fefc35	automated single and multi-breast tumor segmentation using improved watershed technique in 2d mri images	pre processing;segmentation;mri images;multi rio detection;breast tumor;gradient magnitude;watershed	Image segmentation is a challenging task in image processing. The purpose is to divide up pixels into different partitions in which members of each partition have similar characteristics and a unique label. Image segmentation and extracting the characteristics of a tumor are powerful tools that can be used in medical science. In the case of breast cancer medical treatment, segmentation methods can be used to extract and segment the tumor for better diagnoses and earlier detection of breast tumors. However, extracting and segmentation of the tumors or region of interest (RIO) can be challenging. This is due to the existence of noise in the images, along with the complicated structures of the image. Manual classification of the images is time-consuming, and needs to be done only by medical experts. Hence, using an automated medical image segmentation tool will be useful and necessary. In this paper, a method is proposed based on the well-known watershed technique and automated thresholding for single and multi-tumor segmentation in medical images. The procedure consists of pre-processing, removing noise, elimination of unwanted objects, generating and segmentation. Segmentation involves automatic thresholding, gradient magnitude, finding regional minimums, and recognition. Experimental results show that this method performs well in segmentation with efficient execution time and can be used for medical diagnostics of breast cancer.	gradient;image noise;image processing;image segmentation;pixel;preprocessor;region of interest;regional lockout;run time (program lifecycle phase);thresholding (image processing);watershed (image processing);whole earth 'lectronic link	Mohammad Taheri;George Hamer;Seong-Ho Son;Sung Y. Shin	2016		10.1145/2987386.2987421	computer vision;computer science;segmentation-based object categorization;pattern recognition;data mining;region growing;thresholding;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation	Vision	37.792721734750934	-75.61548641935596	99594
f9adcbbfccfc8bc665f2175ad6f6b1feed5a5802	a novel morphological segmentation method for evaluating estrogen receptors' status in breast tissue images	erbium;breast tissue;image segmentation;cancer;morphological operators breast cancer medical image analysis nuclear segmentation color deconvolution;shape;image segmentation cancer image color analysis deconvolution shape erbium breast tissue;image color analysis;deconvolution	In this paper, we propose a fully automated method able to perform accurate nuclear segmentation in immunohistochemical breast tissue images in order to provide quantitative assessment of estrogen receptor's status that will help pathologists in their diagnosis. The presented approach is based on color deconvolution and an enhanced morphological processing, which is used to identify positive stained nuclei and to separate all touching nuclei in the microscopic image for a subsequent cancer evaluation. Experiments on several breast cancer images of different patients admitted into the Tunisian Salah Azaiez Cancer Center, show the efficiency of the proposed method when compared to the manual evaluation of experts.	algorithm;deconvolution;design of the fat file system;erdős–rényi model;image segmentation;real life;watershed (image processing)	Aymen Mouelhi;Mounir Sayadi;Farhat Fnaiech	2014	2014 1st International Conference on Advanced Technologies for Signal and Image Processing (ATSIP)	10.1109/ATSIP.2014.6834601	computer vision;medicine;pathology;medical physics	Robotics	37.74581400109191	-75.82724671269878	99691
039d35a9b6e9e0d6e3a7759f1823d3afd397bba0	detection of juxta-pleural lung nodules in computed tomography images	computed tomography;lung;volume segmentation;chest;blood vessels	A method for the detection of juxta-pleural lung nodules with radius ≤ 5mm in chest computed tomography images is proposed. The lung volume is segmented using region-growing and refined with morphological operations and active contours to include juxta-pleural nodules. Nodule candidates are searched slice-wise inside the lung volume segmentation. Solid nodules are detected by selecting an appropriate threshold inside a representative sliding window. Sub-solid and non-solid nodules are enhanced with a multiscale Laplacian-of-Gaussian filtering prior to their detection. Obvious non-nodule candidates, namely small blood vessels, are discarded using fixed rules. Then, a support vector machine with radial basis function is trained with the remaining candidates to further reduce the number of false positives (FPs). The final system sensitivity is 57.4% with 4 FPs/scan.The performance is similar or better than state-of-the-art methods, especially when considering the high number and small radius of the studied juxta-pleural nodules.	blob detection;ct scan;international symposium on fundamentals of computation theory;internationalization and localization;mathematical morphology;radial (radio);radial basis function;region growing;supervised learning;support vector machine;tomography	Guilherme Aresta;António Cunha;Aurélio Campilho	2017		10.1117/12.2252022	computed tomography	Vision	37.12521099563551	-77.11059496722486	99826
dfae5c67a9462aeb2a659f35a3bcdf33ac96380b	segmentation of breast ultrasound images using neural networks		Medical image segmentation is considered a very important task for diagnostic and treatment-planning purposes. Accurate segmentation of medical images helps clinicians to clarify the type of the disease and facilitates the process of efficient treatment. In this paper, we propose two different approaches to segment breast ultrasound images using neural networks. In the first approach, we use scale invariant feature transform (SIFT) to calculate a set of descriptors for a set of points inside the image. These descriptors are used to train a supervised neural network. In the second approach, we use SIFT to detect a set of key points inside the image. Texture features are then extracted from a region around each point to train the network. This process is repeated multiple times to verify the generalization ability of the network. The average segmentation accuracy is calculated by comparing every segmented image with corresponding gold standard images marked by an expert.	artificial neural network;image segmentation;medical imaging;medical ultrasound;scale-invariant feature transform;thresholding (image processing)	Ahmed A. Othman;Hamid R. Tizhoosh	2011		10.1007/978-3-642-23957-1_30	artificial neural network;image segmentation;computer vision;artificial intelligence;scale-invariant feature transform;breast ultrasound;computer science;segmentation	Vision	34.628662516823894	-76.39534533279412	99968
666ba429d8add508cc07c4cd32c77e10ae191b8c	automated fuzzy logic based skull stripping in neonatal and infantile mr images	medical image processing bayes methods biomedical mri fuzzy logic fuzzy set theory gaussian processes;neonatal mr images;histograms;bayesian classification;fuzzy membership function;pediatrics;white matter;image segmentation;morphometric analysis;gaussian processes;bayes methods;fuzzy rules;bayesian methods;automated morphometric analysis;skull;fuzzy membership functions;fuzzy set theory;surface morphology;infantile mr images;fuzzy logic;brain modeling;mr imaging;gaussian mixture model;a priori knowledge;automated fuzzy logic;magnetic resonance;fuzzy active surface model;skull stripping;medical image processing;surface model;gray matter;infantile brain diseases;brain modeling surface morphology skull histograms bayesian methods pediatrics image segmentation;deformable model;human brain;human brain magnetic resonance images;fuzzy active surface model automated fuzzy logic skull stripping neonatal mr images infantile mr images automated morphometric analysis human brain magnetic resonance images neonatal brain diseases infantile brain diseases bayesian classification gaussian mixture model fuzzy membership functions fuzzy rules;biomedical mri;cerebrospinal fluid;neonatal brain diseases	Automated morphometric analysis using human brain magnetic resonance (MR) images is an effective approach to investigate the morphological changes of the brain. However, even though many methods for adult brain have been studied, there are few studies for infantile brain. Same as the adult brain, it is effective to measure cerebral surface and for quantitative diagnosis of neonatal and infantile brain diseases. This article proposes a skull stripping method that can be applied to the neonatal and infantile brain. The proposed method can be applied to both of T1 weighted and T2 weighted MR images. First, the proposed method estimates intensity distribution of white matter, gray matter, cerebrospinal fluid, fat, and others using a priori knowledge based Bayesian classification with Gaussian mixture model. The priori knowledge is embedded by representing them with fuzzy membership functions. Second, the proposed method optimizes the whole brain by using fuzzy active surface model, which evaluates the deforming model with fuzzy rules. The proposed method was applied to 26 neonatal and infantile subjects between −4 weeks and 4 years 1 month old. The results showed that the proposed method stripped skull well from any neonatal and infantile MR images.	bayesian network;embedded system;fuzzy logic;mixture model;morphometrics;resonance	Kosuke Yamaguchi;Yuko Fujimoto;Syoji Kobashi;Yuki Wakata;Reiichi Ishikura;Kei Kuramoto;Seturo Imawaki;Shozo Hirota;Yutaka Hata;Shinichi Yoshiya	2010	International Conference on Fuzzy Systems	10.1109/FUZZY.2010.5584839	fuzzy logic;computer vision;a priori and a posteriori;naive bayes classifier;bayesian probability;computer science;artificial intelligence;magnetic resonance imaging;machine learning;mixture model;gaussian process;histogram;fuzzy set;image segmentation;statistics	Robotics	36.454576248541045	-77.57938853172192	100033
d11965700c13c6b63affbb476ebbdd0db7845ca4	automated color calibration method for dermoscopy images	color calibration;computer aided diagnosis;melanoma;dermoscopy;computer aided diagnosis cad	Accurate color information in dermoscopy images is very important for melanoma diagnosis since inappropriate white balance or brightness in the images adversely affects the diagnostic performance. In this paper, we present an automated color calibration method for dermoscopy images of skin lesions. On a set of 319 dermoscopy images, we develop color calibration filters based on the HSV color system. We determined that the color characteristics of the peripheral part of the tumors have significant influence on the color calibration filters and confirmed that the presented filters achieved satisfactory calibration performance as evaluated by cross-validation. We also confirmed that our method successfully modifies the color distribution of a given image to make it closer to the color distribution of the training image set.		Hitoshi Iyatomi;M. Emre Celebi;Gerald Schaefer;Masaru Tanaka	2011	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2010.08.003	computer vision;pathology;computer science;computer graphics (images)	Vision	36.11045478030459	-75.46686408879907	100143
6318fd1d2ab3c3b2e8b65249bcb6e9949bec9624	segmentation and recognition strategy of handwritten connected digits based on the oriented sliding window	oriented sliding window segmentation segmentation recognition handwritten digits;handwritten digits;image segmentation;oriented sliding window;image segmentation document image processing handwritten character recognition;segmentation;segmentation recognition;ip networks image segmentation handwriting recognition databases nist skeleton;global decision module segmentation strategy recognition strategy handwritten connected digits oriented sliding window handwritten digit strings connection configuration interconnection point adjacent digit cutting path;document image processing;handwritten character recognition	In this paper, we propose a system to recognize handwritten digit strings, which constitutes a difficult task because of overlapping and/or joining of adjacent digits. To resolve this problem, we use a segmentation-recognition of handwritten connected digits based on the oriented sliding window. The proposed approach allows separating adjacent digits according the connection configuration by finding at the same time the interconnection points between adjacent digits and the cutting path. The segmentation-recognition using the global decision module allows the rejection or acceptance of the processed image. Experimental results conducted on the handwritten digit database NIST SD19 show the effective use of the sliding window for segmentation-recognition.	handwriting recognition;interconnection;rejection sampling;string (computer science)	Abdeljalil Gattal;Youcef Chibani	2012	2012 International Conference on Frontiers in Handwriting Recognition	10.1109/ICFHR.2012.265	computer vision;speech recognition;computer science;pattern recognition;image segmentation;scale-space segmentation;segmentation	Robotics	34.43214232201377	-66.69121873717054	100424
d94d967d9f3800295025f9ed63af8eceac726b9c	a color texture analysis method based on a gravitational approach for classification of the pap-smear database	lacunarity pap smear database gravitational model rgb bouligand minkowski fractal dimension;bouligand minkowski fractal dimension;lacunarity;image color analysis databases fractals pattern recognition complexity theory feature extraction biomedical imaging;pap smear database classification color texture analysis method pap smear cell image classification color channel gravitational method descriptor extraction auc color texture classification;visual databases image classification image colour analysis image texture;gravitational model rgb;pap smear database	Classification of pap-smear cell images is a relevant and challenging medical problem. In order to contribute to the analysis of these images, we propose to compute complexity based features from each color channel of them. Moreover, we propose to use the gravitational method, a novel and very discriminative approach which improves our ability to extract descriptors from the images. We compared our approach with results obtained from other color texture analysis methods by using both accuracy and AUC, which are measurements of performance. The obtained results (89.64% for accuracy and 0.9086 for AUC) demonstrate that color texture classification using the gravitational model is a feasible approach for the classification of pap-smear images.	channel (digital image);smear campaign	Jarbas Joaci de Mesquita Sá Junior;André Ricardo Backes	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7025462	color histogram;computer vision;machine learning;pattern recognition;mathematics;lacunarity	Vision	35.93100963469778	-73.95759090122094	100599
74d7f4fb7bab8bc59353a81409a07dc6e6975f37	fault diagnosis for rotating machinery based on local mean decomposition morphology filtering and least square support vector machine			mathematical morphology;support vector machine	Tongle Xu;Zhaojie Yin;Daoyong Cai;Diankun Zheng	2017	Journal of Intelligent and Fuzzy Systems	10.3233/JIFS-161676	machine learning;pattern recognition	Robotics	28.538689430433237	-67.94683846736775	100785
4cc2e5ad3527ea1a5eebb0aa543587bb58a9490c	contour extraction of left ventricular cavity from digital subtraction angiograms using a neural edge detector	nonuniform contrasting;left ventricular;image enhancement;supervised edge detection;contour extraction;neural filter	Abstract#R##N##R##N#In this paper, a supervised edge detector based on a multilayer neural network, which is called a neural edge detector (NED), is proposed for detecting edges which coincide with edges traced by a human operator (e.g., a medical doctor). The NED is trained by use of the contours traced by a cardiologist. Using the trained NED, the contours coinciding well with the contours traced by a cardiologist are extracted from the left ventricular angiograms even with nonuniform contrast medium.#R##N##R##N##R##N##R##N#The proposed contour extraction method consists of (1) detection of fine edges by the NED, (2) extraction of rough contours, and (3) contour tracing based on contour candidates synthesized from the rough contours and the edges detected by the NED. The contour of the left ventricle is automatically extracted by inputting two points manually. Experiments with clinical images show that the proposed method can stably extract the contours coinciding well with the contours traced by a cardiologist. © 2003 Wiley Periodicals, Inc. Syst Comp Jpn, 34(2): 55–69, 2003; Published online in Wiley InterScience (www.interscience.wiley.com). DOI 10.1002/scj.1190	contour line;edge detection	Kenji Suzuki;Isao Horiba;Noboru Sugie;Michio Nanki	2003	Systems and Computers in Japan	10.1002/scj.1190	computer vision;speech recognition;computer science;artificial intelligence	NLP	36.825756915334765	-77.38008652217597	101019
7472b93c3989f90fcc5d7bfdcb014794b75dd8f0	dsp implementation of a low-complexity algorithm for real-time automated vessel detection in images of the fundus of the human retina	eye;digital signal processing humans retina image segmentation feature extraction image databases cameras medical diagnosis ambulatory surgery image sequences;image segmentation;real time;low complexity;vessel network dsp implementation low complexity algorithm real time automated vessel detection human retina real time vessel segmentation rgb image sequences vessel enhancement vessel thresholding ophthalmology equipments;medical image processing;digital signal processing chips;sezele;medical image processing digital signal processing chips eye image segmentation image sequences;image sequences	In this paper we propose an algorithm for real-time vessel segmentation in sequences of RGB images of the human retina. The algorithm is made up of two main blocks providing vessel enhancement and thresholding, respectively. It is implemented on a DSP board for future embedding in ophthalmology equipments. The obtained results (binary images) show a good trade-off between processing speed and accuracy, since the main structure of the vessel network is preserved and the simplicity of the algorithm allows the DSP to process about ten images per second	algorithm;binary image;digital signal processor;real-time clock;thresholding (image processing)	Andrea Anzalone;Federico Bizzarri;Paolo Camera;Luca Petrillo;Marco Storace	2007	2007 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2007.378230	computer vision;binary image;computer hardware;image processing;computer science;digital image processing;image segmentation;scale-space segmentation;computer graphics (images)	Embedded	37.543985504038005	-72.17216958642419	101041
11935d7f7e306f05f6528d380c494d12088c1fc9	automatic stent border detection in intravascular ultrasound images	knowledge-guided;intravascular ultrasound;quantitative analysis;stents;border detection;three dimensional	This paper describes a knowledge- and model-based system for the automatic detection of the stent borders in intravascular ultrasound (IVUS) images. The detection consists of four steps starting from a global detection in the transversal images, continues with a local detection and optimization in the transversal images, and finishes with a model-guided optimization in the volumetric dataset. The method shows to be almost automatic and only fails in situations at the edges of the stent where not enough strut information is available to come up with a meaningful three-dimensional model for the endpoints. The method can be very useful during IVUS-guided stent placement, showing the cardiologist the results of the stent placement online. The location of the smallest stent diameter can be selected automatically, providing the opportunity to optimize the stent placement according to established criteria.	edge detection	Jouke Dijkstra;Gerhard Koning;Joan C. Tuinenburg;Pranobe V. Oemrawsingh;Johan H. C. Reiber	2003			three-dimensional space;radiology;medicine;quantitative analysis;surgery	Vision	38.53213199786128	-79.9530877517824	101122
86dd64630b9fb4f560aac15898643dc8f806ffc8	a novel approach for automatic region of interest extraction in industrial radiographic images	industrial radiographic image;region of interest;segmentation technique;roi	The increase in dearth of image analysis and interpretation in the field of remote sensing, communication, medical imaging, forensics and industrial inspection demands for a complete automated image processing system. Especially, automating the process of region of interest extraction is a great challenge as it depends completely on the domain information. Many of the researchers had attempted to automate the process of image interpretation and classification only. In particular, automating ROI extraction process in greyscale images containing weld defects had demonstrated great difficulty towards the accuracy. This paper attempted to address the issue of complete automation of greyscale image ROI extraction for further image analysis and classification. The attempt also outlines the necessity of segregating background and foreground images in industrial radiographs through a new intensity-based filtering method. A study is made to determine an appropriate segmentation method for different defect detection. In order to evaluate the designed methodology, industrial radiographs containing defects of welding process are considered.	radiography;region of interest	Mythili Thirugnanam;S. Margret Anouncia	2014	IJCVR	10.1504/IJCVR.2014.062949	computer vision;return on investment;computer science;region of interest	Logic	36.99491906562529	-70.47220186172986	101668
d5160da00afd2aa46b417489cfc47e47ac46928a	off-line cursive word recognition with a hybrid neural-hmm system	dynamic programming;programacion dinamica;hand writing;modelo markov;binary image;hidden markov model;analisis forma;dynamic program;segmentation;feature vector;markov model;left right;reconnaissance caractere;escritura manual;feature extraction;programmation dynamique;word recognition;pattern recognition;pattern analysis;reconnaissance forme;modele markov;reseau neuronal;reconocimiento patron;multilayer neural network;character recognition;red neuronal;segmentacion;analyse forme;reconocimiento caracter;neural network;ecriture	In a recent publication [1], we have introduced a neural predictive system for on-line word recognition. Our approach implements a Hidden Markov Model (HMM)-based cooperation of several predictive neural networks. The task of the HMM is to guide the training procedure of neural networks on successive parts of a word. Each word is modeled by the concatenation of letter-models corresponding to the letters composing it. Successive parts of a word are this way modeled by different neural networks. A dynamical segmentation allows to adjust letter-models to the great variability of handwriting encountered in the words. Our system combines Multilayer Neural Networks and Dynamic Programming with an underlying Left-Right Hidden Markov Model (HMM). In this paper, we present an extension of this model to off-line word recognition. We use on-line data in these off-line experiments, generating a binary image from trajectory data. The feature extraction module then turns each binary image into a sequence of feature vectors, called 'frames', combining low-level and high-level features in a new feature extraction paradigm. Some results for word recognition are presented.	hidden markov model	Zsolt Wimmer;Sonia Garcia-Salicetti;Bernadette Dorizzi;Patrick Gallinari	1997		10.1007/3-540-63791-5_19	computer vision;speech recognition;feature vector;binary image;feature extraction;word recognition;computer science;artificial intelligence;machine learning;dynamic programming;markov model;segmentation;artificial neural network;algorithm;hidden markov model	Vision	32.83525277307797	-67.51741583974551	101914
131a45b18625d422a4e3104e53c37850b1418c9e	automated segmentation of geographic atrophy using deep convolutional neural networks		Geographic atrophy (GA) is an end-stage manifestation of the advanced age-related macular degeneration (AMD), the leading cause of blindness and visual impairment in developed nations. Techniques to rapidly and precisely detect and quantify GA would appear to be of critical importance in advancing the understanding of its pathogenesis. In this study, we develop an automated supervised classification system using deep convolutional neural networks (CNNs) for segmenting GA in fundus autofluorescene (FAF) images. More specifically, to enhance the contrast of GA relative to the background, we apply the contrast limited adaptive histogram equalization. Blood vessels may cause GA segmentation errors due to similar intensity level to GA. A tensor-voting technique is performed to identify the blood vessels and a vessel inpainting technique is applied to suppress the GA segmentation errors due to the blood vessels. To handle the large variation of GA lesion sizes, three deep CNNs with three varying sized input image patches are applied. Fifty randomly chosen FAF images are obtained from fifty subjects with GA. The algorithm-defined GA regions are compared with manual delineation by a certified grader. A two-fold cross-validation is applied to evaluate the algorithm performance. The mean segmentation accuracy, true positive rate (i.e. sensitivity), true negative rate (i.e. specificity), positive predictive value, false discovery rate, and overlap ratio, between the algorithm- and manually-defined GA regions are 0.97 ± 0.02, 0.89 ± 0.08, 0.98 ± 0.02, 0.87 ± 0.12, 0.13 ± 0.12, and 0.79 ± 0.12 respectively, demonstrating a high level of agreement.	artificial neural network;convolutional neural network	Zhihong Hu;Ziyuan Wang;Srinivas R. Sadda	2018		10.1117/12.2287001	inpainting;convolutional neural network;false discovery rate;adaptive histogram equalization;deep learning;atrophy;fundus (eye);computer science;pattern recognition;artificial intelligence;segmentation	Robotics	33.18353190922299	-76.68666338838248	101950
b8f937c7a1771d1d0a106592df15d295e91119ce	optical character recognition: a comprehensive study of hybrid methods	traditional method;though k-pca;hybrid method;processing time;neural networks;neural network;comprehensive study;template matching;optical character recognition ocr;better accuracy;optical character recognition;intelligent system;non-intelligent system	traditional method;though k-pca;hybrid method;processing time;neural networks;neural network;comprehensive study;template matching;optical character recognition ocr;better accuracy;optical character recognition;intelligent system;non-intelligent system	optical character recognition	Abhishek A. Sharma;Madhavi H. Sane;Sanjay T. Gandhe	2011	KES Journal	10.3233/KES-2011-0225	computer vision;speech recognition;intelligent character recognition;artificial intelligence;machine learning	ECom	32.24045801560129	-66.71502889279304	102008
c64f8da387dd0ab44dd349af688c3d4fc33871a7	texture segmentation using local energy in wavelet scale space	spatial variation;texture segmentation;computer vision;texture analysis;scale space;wavelet transform;image analysis	Wavelet transforms are attracting increasing interest in computer vision because they provide a mathematical tool for multiscale image analysis. In this paper, we show that i) the subsampled wavelet multiresolution representation is translationally variant; and ii) a wavelet transform of a signal generally confounds the phase component of the analysing wavelet associated with that scale and orientation. The importance of this observation is that commonly used features in texture analysis also depend on this phase component. This not only causes unnecessary spatial variation of features at each scale but also makes it more difficult to match features across scales.	scale space;wavelet	Zhi-Yan Xie;Michael Brady	1996		10.1007/BFb0015546	image texture;spatial variability;computer vision;scale space;image analysis;computer science;pattern recognition;image segmentation;scale-space segmentation;texture compression;texture filtering;wavelet transform	Vision	38.40790490550155	-71.01419454908293	102188
db6945fc5c772c6cebfcfb5904e3ddf11b6c1f42	weakly-supervised evidence pinpointing and description	qa76 electronic computers computer science computer software;r medicine general	We propose a learning method to identify which specific regions and features of images contribute to a certain classification. In the medical imaging context, they can be the evidence regions where the abnormalities are most likely to appear, and the discriminative features of these regions supporting the pathology classification. The learning is weakly-supervised requiring only the pathological labels and no other prior knowledge. The method can also be applied to learn the salient description of an anatomy discriminative from its background, in order to localise the anatomy before a classification step. We formulate evidence pinpointing as a sparse descriptor learning problem. Because of the large computational complexity, the objective function is composed in a stochastic way and is optimised by the Regularised Dual Averaging algorithm. We demonstrate that the learnt feature descriptors contain more specific and better discriminative information than handcrafted descriptors contributing to superior performance for the tasks of anatomy localisation and pathology classification respectively. We apply our method on the problem of lumbar spinal stenosis for localising and classifying vertebrae in MRI images. Experimental results show that our method when trained with only target labels achieves better or competitive performance on both tasks compared with strongly-supervised methods requiring labels and multiple landmarks. A further improvement is achieved with training on additional weakly annotated data, which gives robust localisation with average error within 2 mm and classification accuracies close to human performance.	algorithm;computational complexity theory;feature recognition;graphics processing unit;human reliability;loss function;matlab;medical imaging;optimization problem;random-access memory;sampling (signal processing);sparse matrix;supervised learning	Qiang Zhang;Abhir Bhalerao;Charles Hutchinson	2017		10.1007/978-3-319-59050-9_17	discriminative model;local binary patterns;convolutional neural network;computational complexity theory;medical imaging;machine learning;artificial intelligence;computer science	ML	30.61073900691239	-74.87641613400774	102245
a56733f39207f53a16f20ad3037d0cb2b029cd5d	deep learning for skin lesion classification		Melanoma, a malignant form of skin cancer is very threatening to life. Diagnosis of melanoma at an earlier stage is highly needed as it has a very high cure rate. Benign and malignant forms of skin cancer can be detected by analyzing the lesions present on the surface of the skin using dermoscopic images. In this work, an automated skin lesion detection system has been developed which learns the representation of the image using Google’s pretrained CNN model known as Inception-v3 [1]. After obtaining the representation vector for our input dermoscopic images we have trained two layer feed forward neural network to classify the images as malignant or benign. The system also classifies the images based on the cause of the cancer either due to melanocytic or non-melanocytic cells using a different neural network. These classification tasks are part of the challenge organized by International Skin Imaging Collaboration (ISIC) 2017. Our system learns to classify the images based on the model built using the training images given in the challenge and the experimental results were evaluated using validation and test sets. Our system has achieved an overall accuracy of 65.8% for the validation set.	artificial neural network;deep learning	P. Mirunalini;Chandrabose Aravindan;Vignesh Gokul;S. M. Jaisakthi	2017	CoRR		pattern recognition;lesion;computer science;artificial neural network;cancer;artificial intelligence;deep learning;skin cancer;feedforward neural network;melanoma	ML	32.76887091823729	-75.44702772070481	102407
9c4aba528c270ed5d5eabfe32bdf17e6867445d8	towards the identification of parkinson's disease using only t1 mr images		Parkinson's Disease (PD) is one of the most common types of neurological diseases caused by progressive degeneration of dopaminergic neurons in the brain. Even though there is no fixed cure for this neurodegenerative disease, earlier diagnosis followed by earlier treatment can help patients have a better quality of life. Magnetic Resonance Imaging (MRI) has been one of the most popular diagnostic tool in recent years because it avoids harmful radiations. In this paper, we investigate the plausibility of using MRIs for automatically diagnosing PD. Our proposed method has three main steps : 1) Preprocessing, 2) Feature Extraction, and 3) Classification. The FreeSurfer library is used for the first and the second steps. For classification, three main types of classifiers, including Logistic Regression (LR), Random Forest (RF) and Support Vector Machine (SVM), are applied and their classification ability is compared. The Parkinsons Progression Markers Initiative (PPMI) data set is used to evaluate the proposed method. The proposed system prove to be promising in assisting the diagnosis of PD.	color gradient;feature extraction;freesurfer;lr parser;logistic regression;plausibility structure;preprocessor;progressive scan;radio frequency;random forest;resonance;support vector machine	Sara Soltaninejad;L. Irene Cheng;Anup Basu	2018		10.1007/978-3-030-04375-9_13	support vector machine;artificial intelligence;feature extraction;parkinson's disease;logistic regression;machine learning;computer science;pattern recognition;preprocessor;random forest;magnetic resonance imaging	AI	30.943530741322736	-77.31389610512076	102583
5a8061c66db8ae8d0ee3a447e0b677a7f731182f	effective shape-based retrieval and classification of mammograms	zernike moments;computer aided diagnosis;automatic segmentation;association rules;similarity retrieval;feature vector;invariant pattern recognition;dimensionality reduction;association rule;feature extraction;region of interest;data mining algorithm;zernike moment;k nearest neighbor;content based image retrieval;dimensional reduction;similarity measure	This paper presents a new approach to support Computer-aided Diagnosis (CAD) aiming at assisting the task of classification and similarity retrieval of mammographic mass lesions, based on shape content. We have tested classical algorithms for automatic segmentation of this kind of image, but usually they are not precise enough to generate accurate contours to allow lesion classification based on shape analyses. Thus, in this work, we have used Zernike moments for invariant pattern recognition within regions of interest (ROIs), without previous segmentation of images. A new data mining algorithm that generates statistical-based association rules is used to identify representative features that discriminate the disease classes of images. In order to minimize the computational effort, an algorithm based on fractal theory is applied to reduce the dimension of feature vectors. K-nearest neighbor retrieval was applied to a database containing images excerpted from previously classified digitalized mammograms presenting breast lesions. The results reveal that our approach allows fast and effective feature extraction and is robust and suitable for analyzing this kind of image.	association rule learning;computation;computer-aided design;data mining;database;feature extraction;fractal;k-nearest neighbors algorithm;pattern recognition;region of interest	Joaquim Cezar Felipe;Marcela Xavier Ribeiro;Elaine P. M. de Sousa;Agma J. M. Traina;Caetano Traina	2006		10.1145/1141277.1141333	computer vision;association rule learning;computer science;machine learning;pattern recognition	ML	34.59453217173766	-74.44494190291239	102605
66fa1662e42c26f06ce604b2ae3cad8fb36d0ec8	identifying histological elements with convolutional neural networks	histological analysis;computer aided diagnosis;cancer;oncology;computer aided diagnosis cad;gastric cancer;medical image;machine learning;biopsy;medical imaging;convolutional neural networks cnn;image analysis;neural network	Histological analysis on stained biopsy samples requires recognizing many kinds of local and structural details, with some awareness of context. Machine learning algorithms such as convolutional networks can be powerful tools for such problems, but often there may not be enough training data to exploit them to their full potential. In this paper, we show how convolutional networks can be combined with appropriate image analysis to achieve high accuracies on three very different tasks in breast and gastric cancer grading, despite the challenge of limited training data. The three problems are to count mitotic figures in the breast, to recognize epithelial layers in the stomach, and to detect signet ring cells.	algorithm;artificial neural network;convolutional neural network;image analysis;machine learning;seal (emblem)	Christopher Malon;Matthew Miller;Harold Christopher Burger;Eric Cosatto;Hans Peter Graf	2008		10.1145/1456223.1456316	medical imaging;image analysis;computer science;artificial intelligence;machine learning;artificial neural network;cancer	AI	32.59629505962379	-75.17103994694514	102650
60c7c35b373936acf3082d422a5db5df4f586a42	towards computer-aided diagnostics of screening mammography using content-based image retrieval	eigenvalues and eigenfunctions;biological tissues;cause of death;computer aided diagnostic;computer aided diagnosis;support vector machines;cancer;gaussian processes;chain code;breast density;breast lesion;image classification;lesions feature extraction support vector machines breast databases cancer principal component analysis;breast density content based image retrieval computer aided diagnosis principal component analysis support vector machine mammography breast lesion;feature extraction;medical image processing;principal component analysis;feature extraction computer aided diagnostics screening mammography content based image retrieval breast cancer early detection tissue classification lesion classification 2d principal component analysis eigenvalues support vector machine gaussian kernel;gaussian kernel;support vector machines biological tissues cancer content based retrieval eigenvalues and eigenfunctions feature extraction gaussian processes image classification image retrieval mammography medical image processing principal component analysis;ground truth;support vector machine;mammography;content based image retrieval;early detection;content based retrieval;breast cancer;image retrieval	Screening mammography has been established worldwide for early detection of breast cancer, one of the main causes of death among women in occidental countries. In this paper, we aim at moving towards computer-aided diagnostics of screening mammography. Tissue and lesion are classified using the methodology of content-based image retrieval. In addition, we aim at comprehensive evaluation and have established a large database of annotated reference images (ground truth), which has been merged and unified from different sources publicly available to research. In total, 10,509 mammographic images have been collected from the different sources. From this, 3,375 images are provided with one and 430 radiographs with more than one chain code annotations. This data supports experiments with up to 12 classes, and 233 images per class if a equal distribution is required. Using a two-dimensional principal component analysis with four eigenvalues and a support vector machine with Gaussian kernel for feature extraction and image retrieval, respectively, the precision of computer-aided diagnosis is above 80%. It therefore may be used as second opinion in screening mammography.	chain code;content-based image retrieval;experiment;feature extraction;ground truth;principal component analysis;radiography;support vector machine;virtual screening	Thomas Martin Deserno;Michael Soiron;Júlia Epischina Engrácia de Oliveira;Arnaldo de Albuquerque Araújo	2011	2011 24th SIBGRAPI Conference on Graphics, Patterns and Images	10.1109/SIBGRAPI.2011.40	computer vision;computer science;machine learning;pattern recognition	Vision	36.233440627339064	-74.76314692774673	102699
179c6d816866db343670c0f9c19dd84c0625b124	computer-assisted decision support system in pulmonary cancer detection and stage classification on ct images	convolutional neural networks (cnn);deep learning;lung cancer stages;mban (medical body area network);nodule detection;miot (medical internet of things)	Pulmonary cancer is considered as one of the major causes of death worldwide. For the detection of lung cancer, computer-assisted diagnosis (CADx) systems have been designed. Internet-of-Things (IoT) has enabled ubiquitous internet access to biomedical datasets and techniques; in result, the progress in CADx is significant. Unlike the conventional CADx, deep learning techniques have the basic advantage of an automatic exploitation feature as they have the ability to learn mid and high level image representations. We proposed a Computer-Assisted Decision Support System in Pulmonary Cancer by using the novel deep learning based model and metastasis information obtained from MBAN (Medical Body Area Network). The proposed model, DFCNet, is based on the deep fully convolutional neural network (FCNN) which is used for classification of each detected pulmonary nodule into four lung cancer stages. The performance of proposed work is evaluated on different datasets with varying scan conditions. Comparison of proposed classifier is done with the existing CNN techniques. Overall accuracy of CNN and DFCNet was 77.6% and 84.58%, respectively. Experimental results illustrate the effectiveness of proposed method for the detection and classification of lung cancer nodules. These results demonstrate the potential for the proposed technique in helping the radiologists in improving nodule detection accuracy with efficiency.		Anum Masood;Bin Sheng;Ping Li;Xuhong Hou;Xiaoer Wei;Jing Qin;David Dagan Feng	2018	Journal of biomedical informatics	10.1016/j.jbi.2018.01.005	cancer;data mining;internet access;convolutional neural network;decision support system;deep learning;metastasis;lung cancer;computer science;body area network;pattern recognition;artificial intelligence	AI	32.218162436140226	-75.75685122779267	102705
349f2149d8bb37686fe04fbd286889a28bfe4322	combining analytical and holistic strategies for handwriting recognition	databases;handwriting recognition;probability density function;training;hidden markov models;feature extraction;writing	In this paper, a study is conducted on combining analytical and holistic strategies for handwriting recognition. Even though the big majority of the recent high recognition rate systems adopts analytical strategies, physiological scientists suggest that the holistic strategy is the key for realizing near-human performance. In what we believe is a fresh perspective on handwriting recognition, combining the two strategies results in improving recognition rate. The concept and the analysis of combining the two strategies is the first contribution of this work. The proposed approach is applied to an Arabic handwriting recognition system. We use a hidden Markov model (HMM)-based analytical recognizer, and four different methods combined as a holistic recognizer. Two of the used holistic recognition methods are novel: a method based on estimating the probability of writing in each pixel, and a method that uses the Hausdorff distance. The third holistic method is a connected components-based approach, and the fourth one uses dynamic time warping (DTW) with two modifications. These four methods and their use as a holistic recognizer are the second contribution of this work. The proposed technique is tested using the IFN/ENIT database. The combination between the holistic and the analytical recognizers has led to an evident recognition rate improvement ranging from 5% to 16% over the use of the analytical recognizer alone.	connected component (graph theory);dynamic time warping;finite-state machine;handwriting recognition;hausdorff dimension;hidden markov model;holism;human reliability;markov chain;pixel	Hesham M. Eraqi;Sherif Abdelazeem;Mohsen A. A. Rashwan	2016	2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)	10.1109/ICMLA.2016.0179	probability density function;speech recognition;feature extraction;intelligent character recognition;computer science;machine learning;pattern recognition;handwriting recognition;writing	Robotics	32.02712587755875	-66.85970393201558	102729
69aeca72f9933d404afd575884ce42eff745a785	circular noises removal from scanned document images	circular noise;coons surface;punched hole;scanned document images;circular noises removal;small region;located hole;holes noise;scanned document;robust algorithm;distinctive small region;proposed algorithm;interpolation;hough transform;hough transformation	Defects inspection and correction is an important topic in the fields of scanned documents preprocessing. In this paper, a very fast and robust algorithm is proposed for locating and removing a special kind of circular noises caused by scanning documents with punched holes. Firstly, original image is reduced according to an elaborately selected ratio. Punched holes after reduction will leave some distinctive small regions. By examining such small regions, holes noises can be fast detected and located. To diminish false detections, Hough transformation is applied to the roughly located regions to further confirm the located holes. Finally, circular noise is eliminated by fitting a bi-linear blending Coons surface which interpolates along the four edges of noisy region. Experiments on a variety of scanned documents with punched holes demonstrate the feasibility and efficiency of the proposed algorithm.	algorithm;alpha compositing;coons patch;hough transform;interpolation;preprocessor;punched card;real-time clock;sensor;time complexity	Gaofeng Meng;Nanning Zheng;Yuanlin Zhang;Yonghong Song	2007	Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)	10.1109/ICDAR.2007.80	hough transform;computer vision;speech recognition;computer science;computer graphics (images)	Vision	38.91064723370587	-66.22466566460629	103095
79ab7398def32f9d4893c571aefe5248805ae0b5	multiscale blood vessel segmentation in retinal fundus images		Retinal fundus imaging is widely used for eye examinations. The acquired images provide a unique view on the eye vasculature. The analysis of the vasculature has a high importance especially for detecting cardiovascular diseases. We present a multiscale algorithm for automatic retinal blood vessel segmentation, which is considered as a requirement for the diagnosis of vascular diseases. The algorithm uses a Gaussian resolution hierarchy to decrease computational needs, and allows to use of the same methods to detect vessels of different diameters. The algorithm is tested on two public databases using a common notebook. The algorithm segmented each image in less than 20 seconds with a competitive accuracy over 93% in both cases. This proves the applicability for medical applications.	algorithm;computation;database;sensor	Attila Budai;Georg Michelson;Joachim Hornegger	2010			computer vision;eye vasculature;retinal;artificial intelligence;blood vessel;fundus (eye);segmentation;computer science	Vision	36.76712327565894	-76.96594502763185	103142
92d2b2756697e1a03e7f1e770a2f0037d1a9df4b	3d-modeling of deformed halite hopper crystals by object based image analysis	3d modeling;halite;accuracy assessment;svm;hopper crystals;obia	Object Based Image Analysis (OBIA) is an established method for analyzing multiscale and multidimensional imagery in a range of disciplines. In the present study this method was used for the 3D reconstruction of halite hopper crystals in a mudrock sample, based on Computed Tomography data. To quantitatively assess the reliability of OBIA results, they were benchmarked against a corresponding “gold standard”, a reference 3D model of the halite crystals that was derived by manual expert digitization of the CT images. For accuracy assessment, classical per-scene statistics were extended to per-object statistics. The strength of OBIA was to recognize all objects similar to halite hopper crystals and in particular to eliminate cracks. Using a support vector machine (SVM) classifier on top of OBIA, unsuitable objects like halite crystal clusters, polyhalite-coated crystals and spherical halite crystals were effectively dismissed, but simultaneously the number of well-shaped halites was reduced. & 2014 Elsevier Ltd. All rights reserved.	3d modeling;3d reconstruction;ct scan;feature vector;hopper;image analysis;object-based language;polygonal modeling;scene statistics;support vector machine;tomography;voxel	Christoph Leitner;Peter Hofmann;Robert Marschallinger	2014	Computers & Geosciences	10.1016/j.cageo.2014.08.010	crystallography;support vector machine;computer vision;computer science;machine learning;mineralogy	Vision	38.52476151300851	-71.04722613230139	103299
ddb2d9e20d2f201cb60cdd6358ac5aff92ad87a1	discrimination of breast tumors in ultrasonic images using an ensemble classifier based on the adaboost algorithm with feature selection	breast tumors;mahalanobis distance;breast neoplasms;adaboost m2;multiclass adaboost learning algorithm;learning algorithm;fibroadenomas;image coding;sequential feature selection;support vector machines;cancer;support vector machine svm;ultrasonic imaging;biological organs;tumours;image classification;log compressed k distribution;echo pattern homogeneity;algorithms artificial intelligence breast cyst breast neoplasms carcinoma databases factual female fibroadenoma humans image interpretation computer assisted reproducibility of results ultrasonography mammary;spectrum;malignant tumors;carcinomas;pattern spectrum breast tumor ultrasonic imaging log compressed k distribution parameter ensemble classifier echo pattern homogeneity compression parameters discrimination process multiclass adaboost learning algorithm sequential feature selection carcinomas fibroadenomas;log compressed k distribution parameter;shape;medical image processing;tumours biological organs biomedical ultrasonics cancer image classification log normal distribution medical image processing;breast tumor;pattern spectrum;support vector machine classification;differential diagnosis;ensemble classifier;feature selection;cross validation;ultrasonic image;support vector machine;discrimination process;parameter estimation;ultrasonic image adaboost m2 breast tumor differential diagnosis log compressed k distribution support vector machine svm;log normal distribution;compression parameters;biomedical ultrasonics;breast tumors ultrasonic imaging breast neoplasms support vector machines support vector machine classification malignant tumors image coding parameter estimation shape cancer	This paper proposes a novel algorithm to estimate a log-compressed K distribution parameter and presents an algorithm to discriminate breast tumors in ultrasonic images. We computed a total of 208 features for discrimination, including those based on a parameter of a log-compressed K-distribution, which quantifies the homogeneity of the echo pattern in the tumor, but is influenced by compression parameters in the ultrasonic device. The proposed algorithm estimates the parameter of the log-compressed K-distribution in a manner free from this influence. To quantify irregularities in tumor shape, pattern-spectrum-based features were newly developed in this paper. The discrimination process uses an ensemble classifier trained by a multiclass AdaBoost learning algorithm (AdaBoost.M2), combined with a sequential feature-selection process. A 10-fold cross-validation test validated the performance, and the results were compared with those of a Mahalanobis distance-based classifier and a multiclass support vector machine. A total of 200 carcinomas, 50 fibroadenomas, and 50 cysts were used in the experiments. This paper demonstrates that the combination of a classifier trained by AdaBoost.M2 and features based on the estimated parameter of a log-compressed K-distribution, as well as those of the pattern spectrum, are useful for the discrimination of tumors.	acceptance testing;adaboost;breast diseases;carcinoma;co-occurrence matrix;compression;cross reactions;cross-validation (statistics);cyst;document-term matrix;ensemble learning;estimated;experiment;feature selection;fibroadenoma;genetic selection;genetic algorithm;granulometry (morphology);hereditary diseases;k-distribution;learning disorders;mammary neoplasms;mucinous adenocarcinoma;population parameter;statistical classification;support vector machine;ultrasonics (sound)	Atsushi Takemura;Akinobu Shimizu;Kazuhiko Hamamoto	2010	IEEE Transactions on Medical Imaging	10.1109/TMI.2009.2022630	support vector machine;speech recognition;computer science;machine learning;pattern recognition;mathematics;feature selection	ML	35.413438471876496	-77.31467238936571	103301
f248bfe4fef21072f53d870f83cfe95caa694c21	cerebral surface extraction from neonatal mr images using cerebral surface model	neonatal mr images;pediatrics image segmentation deformable models brain modeling spatial resolution volume measurement asphyxia image edge detection radiology educational institutions;radiology;brain;hypoxic ischemic encephalopathy cerebral surface extraction neonate cerebral surface model magnetic resonance image;pediatrics;image segmentation;neurophysiology biomedical mri brain feature extraction image segmentation;deformable models;magnetic resonance image;neonate;cerebral region segmentation cerebral surface extraction neonatal mr images cerebral surface model hypoxic ischemic encephalopathy;hypoxic ischemic encephalopathy;brain modeling;mr imaging;cerebral surface model;asphyxia;image edge detection;feature extraction;surface model;volume measurement;cerebral region segmentation;neurophysiology;cerebral surface extraction;biomedical mri;spatial resolution	It is known that Hypoxic ischemic encephalopathy of the neonate decreases the cerebral volume. And, the volume decrement occurs at the different rate on each gyrus. Therefore, it is helpful for diagnosing such symptoms to segment the cerebral region from neonatal MR images and measure the volume of each gyms. Many conventional methods for segmenting brain region from adult brain MR images have been proposed. However, in case of neonatal subjects, these methods cannot extract the sulci correctly. This paper proposes a method for extracting the cerebral contour accurately using cerebral surface model, which is the novel segmentation algorithm proposed in this paper. We applied the proposed method to computer synthesized images and MR images of a neonatal subject. The experimental results showed that the proposed method extracted the cerebral contour well.	algorithm;increment and decrement operators	Takuma Oshiba;Syoji Kobashi;Kumiko Ando;Reiichi Ishikura;Katsuya Kondo;Yutaka Hata	2007	2007 IEEE International Conference on System of Systems Engineering	10.1109/SYSOSE.2007.4304259	image resolution;feature extraction;computer science;image segmentation;neurophysiology	Robotics	38.87234769798163	-79.3988300192644	103872
7928dad14f4fddede800843e6e83c52568fdad23	automated detection and segmentation of drusen in retinal fundus images	boundary extraction;retinal fundus images;segmentation;drusen;grading;age related macular degeneration	The druse, an abnormal yellow/white deposit on retina, is a dominant characteristic of agerelated macular degeneration (AMD) which is a retinal disorder associated with age. The early detection of drusen is useful for ophthalmologists to diagnose the patients that suffer from AMD. An automated method has been proposed in this work to detect and segment drusen using retinal fundus images by (i) gradient based segmentation to find true edges of drusen, (ii) connected component labeling to remove suspicious pixels from drusen region and (iii) edge linking to connect all labeled pixels into a meaningful boundary. The proposed method outperforms other existing methods in detection of drusen with an accuracy/sensitivity/specificity of 96.17/89.81/99.00 on two publicly available retinal image databases. In order to grade the severity of AMD, the detected drusen by the proposed method are further quantified into small, intermediate and large with an accuracy of 88.46, 98.55, and 88.37%, respectively. © 2015 Elsevier Ltd. All rights reserved.	connected component (graph theory);connected-component labeling;database;gradient;pixel;sensitivity and specificity	Deepti Mittal;Kajal Kumari	2015	Computers & Electrical Engineering	10.1016/j.compeleceng.2015.08.014	computer vision;grading;segmentation;computer graphics (images)	AI	36.67935490327143	-76.92646681162809	104215
2cec1f07986f97e5ece802992220234924bf03cf	hybrid features and mediods classification based robust segmentation of blood vessels	false vessels;mediods based classification;ocular diseases;lesions;shape and intensity based features	Retinal blood vessels are the source to provide oxygen and nutrition to retina and any change in the normal structure may lead to different retinal abnormalities. Automated detection of vascular structure is very important while designing a computer aided diagnostic system for retinal diseases. Most popular methods for vessel segmentation are based on matched filters and Gabor wavelets which give good response against blood vessels. One major drawback in these techniques is that they also give strong response for lesion (exudates, hemorrhages) boundaries which give rise to false vessels. These false vessels may lead to incorrect detection of vascular changes. In this paper, we propose a new hybrid feature set along with new classification technique for accurate detection of blood vessels. The main motivation is to lower the false positives especially from retinal images with severe disease level. A novel region based hybrid feature set is presented for proper discrimination between true and false vessels. A new modified m-mediods based classification is also presented which uses most discriminating features to categorize vessel regions into true and false vessels. The evaluation of proposed system is done thoroughly on publicly available databases along with a locally gathered database with images of advanced level of retinal diseases. The results demonstrate the validity of the proposed system as compared to existing state of the art techniques.	blood vessel tissue;categorization;cerebrovascular disorders;classification;congenital abnormality;database;diabetes mellitus;disorder of eye;exudate;gabor wavelet;hemorrhage;hypertensive disease;image analysis;matched filter;oxygen;retina;retinal diseases;algorithm;biologic segmentation	Amna Waheed;Muhammad Usman Akram;Shehzad Khalid;Zahra Waheed;Muazzam Ali Khan;Arslan Shaukat	2015	Journal of Medical Systems	10.1007/s10916-015-0316-1	computer vision;pathology;anatomy	Vision	35.10322058986748	-75.90145876282034	104350
b2214982e8dab1dbeaf1a1f11ad591e664421a18	improving automatic dubbing with subtitle timing optimisation using video cut detection	histograms;optimisation;katedra kybernetiky;speech synthesis;video signal processing;kybernetika;color;informacni a řidici systemy;publications improving automatic dubbing with subtitle timing optimisation using video cut detection;automaticke řizeni;speech;spring based model text to speech automatic dubbing video cut detection subtitle timing optimisation;subtitle timing optimisation;springs;speeding up factors subtitle timing optimisation video cut detection automatic dubbing system text to speech technology spring based subtitle timing optimisation speech synthesis subtitle slots stretching subtitles prevention;publikace improving automatic dubbing with subtitle timing optimisation using video cut detection;uměla inteligence;text to speech;spring based model;optimization;speech timing tv springs optimization color histograms;tv;automatic dubbing;video signal processing optimisation speech synthesis;video cut detection;timing	This paper presents improvements to an automatic dubbing system in which text-to-speech technology is used to synthesise speech from subtitles. Spring-based subtitle timing optimisation was proposed to reduce the need for speeding up synthetic speech to fit it into corresponding subtitle slots. Video cut detection algorithm was also introduced, and the cuts were then used to prevent stretching subtitles across the cuts. Results show that after the optimisation smaller speeding-up factors are applied on synthetic speech while keeping optimised subtitle start and end times close to original positions.	algorithm;mathematical optimization;shot transition detection;speech synthesis;speech technology;synthetic intelligence	Jindrich Matousek;Jakub Vit	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6288395	computer vision;speech recognition;computer science;speech;histogram;mathematics;multimedia;speech synthesis;statistics	Robotics	37.763249026390014	-67.27474447178612	104656
3423c3cee79556e6a7f859021a8e1e705005935f	segmentation of optic disk and optic cup from digital fundus images for the assessment of glaucoma	active contour;optic disk;cup;fundus image;glaucoma	Glaucoma is an eye disease that results in irreversible loss of vision. The manual examination of optic disk (OD) is a standard procedure used for detecting glaucoma. This paper presents a glaucoma expert system based on the segmentations of OD and optic cup attained from color fundus images. A novel implicit region based active contour model is proposed for OD segmentation which incorporates the image information at the point of interest from multiple image channels to have robustness against the variations found in and around the OD region. A novel optic cup segmentation method is also proposed based on the structural and gray level properties of cup. Based on the precise information about the contours of OD and cup different parameters are calculated for glaucoma assessment. The proposed system is evaluated on 59 retinal images comprising 17 normal and 42 glaucomatous images against the groundtruths given by an experienced ophthalmologist. The proposed OD segmentation method achieved an average F-score of 0.975, average boundary distance of 10.112 pixel and average correlation coefficient of 0.916. The cup segmentation method attained an average F-score of 0.89, average boundary distance of 18.927 pixel and average correlation coefficient of 0.835. The mean error and standard deviation of the error σ for all the parameters are much smaller in glaucomatous images compared to normal images. This indicates high sensitivity of the proposed method in glaucoma assessment.		Pardha Saradhi Mittapalli;Giri Babu Kande	2016	Biomed. Signal Proc. and Control	10.1016/j.bspc.2015.09.003	computer vision;computer science;active contour model;optics	Robotics	36.39428333422604	-76.03523460908175	104659
a870a3ff1f6a8ee9031f782d54a2712855b42526	automatic fire pixel detection using image processing: a comparative analysis of rule-based and machine learning-based methods		This paper1 presents a comparative analysis of state of the art image processing based fire color detection rules and methods in the context of geometrical characteristics measurement of wildland fires. Two new rules and two new detection methods using an intelligent combination of the rules are presented and their performances are compared with their counterparts. The benchmark is performed on approximately two hundred million fire pixels and seven hundred million non-fire pixels extracted from five hundred wildland images under diverse imaging conditions. The fire pixels are categorized according to fire color and existence of smoke, meanwhile, non-fire pixels are categorized according to the average intensity of the corresponding image. This characterization allows to analyze the performance of each rule by category. It is shown that the performances of the existing rules and methods from the literature are category dependent and none of them is able to perform equally well on all categories. Meanwhile, a new proposed method based on machine learning techniques and using all the rules as features outperforms existing state of the art techniques in the literature by performing almost equally well on different categories. Thus, this method, promises very interesting deT. Toulouse · L. Rossi UMR CNRS 6134 SPE, University of Corsica, 20250 Corte, France E-mail: toulouse@univ-corse.fr, lrossi@univ-corse.fr T. Celik School of Computer Science, University of the Witwatersrand, Johannesburg, South Africa and Electrical and Electronics Engineering, Meliksah University, Kayseri, Turkey E-mail: celikturgay@gmail.com M. Akhloufi Department of Electronics Engineering, Universidad Tecnica Federico Santa Maria, Valparaso, Chile E-mail: akhloufi@gel.ulaval.ca velopments for the future of metrologic tools for fire detection in unstructured environments.	benchmark (computing);categorization;color;computer science;electrical engineering;electronic engineering;image processing;logic programming;logistic regression;machine learning;mail (macos);performance;pixel;qualitative comparative analysis	Tom Toulouse;Lucile Rossi;Turgay Çelik;Moulay A. Akhloufi	2016	Signal, Image and Video Processing	10.1007/s11760-015-0789-x	simulation;artificial intelligence;machine learning;data mining	ML	34.18427979477044	-70.5591484424245	104665
bbdf337e4604d38f073cd83f9020f9cf18d1fe46	non-invasive indicators of pulmonary hypertension from pulmonary veins quantification in sickle cell disease	pulmonary hypertension;pulmonary vein;estimation theory;cause of death;geodesic active contour;heart;image segmentation;angiocardiography;arteries;haemodynamics;sickle cell disease;hypertension;biomedical imaging;veins;segmentation;quantification;medical image processing angiocardiography blood vessels catheters cellular biophysics computerised tomography diseases estimation theory haemodynamics image segmentation;fast marching;hemodynamics;retrospective study;left atrium;medical image processing;catheters;computerised tomography;diseases;right heart catheterization noninvasive indicators pulmonary hypertension pulmonary veins quantification sickle cell disease pulmonary vein analysis computerised tomography angiography images adaptive fast marching approach left atrium segmentation geodesic active contour noninvasive estimations clinical hemodynamics measurements;veins heart image segmentation hypertension hemodynamics arteries biomedical imaging;cellular biophysics;ct angiography;blood vessels;sickle cell disease pulmonary hypertension pulmonary veins segmentation quantification;pulmonary veins	Pulmonary hypertension is a common cause of death among patients with sickle cell disease. This retrospective study investigates the use of pulmonary vein analysis to diagnose pulmonary hypertension non-invasively with CT-Angiography images. Ten images from patients with pulmonary hypertension were matched with controls. An adaptive fast marching approach is applied in order to segment the left atrium and pulmonary veins, followed by a geodesic active contour to isolate the atrium. The ostia of the pulmonary veins are determined by computing the skeleton and finding the intersections with the contour of the atrium. 96.3% of the ostia are identified correctly by the technique. The diameters of the veins are then measured and their sum is computed at fixed distances from the ostium. These quantitative indicators are significantly larger in patients as compared to controls (p-values <; 0.01). Furthermore, the non-invasive estimations of the method present a high and significant correlation with the clinical hemodynamics measurements obtained from right heart catheterization.	active contour model;fast marching method;hemodynamics	Guido H. Jajamovich;Vivek Pamulapati;Shoaib Alam;Alem Mehari;Gregory J. Kato;Bradford J. Wood;Marius George Linguraru	2012	2012 9th IEEE International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2012.6235679	medical imaging;computer vision;radiology;medicine;pathology;hemodynamics;cardiology	Visualization	38.86299838340577	-79.44550229545885	104963
d949eba623fcb15a2193fd0b7bc9e9ec676774aa	automatic detection of retinal lesions for screening of diabetic retinopathy	differential evolution exudates hemorrhages log matched filter microaneurysms mutual information;lesions blood vessels biomedical imaging retina image edge detection kernel shape	Objective: Diabetic retinopathy (DR) is characterized by the progressive deterioration of retina with the appearance of different types of lesions that include microaneurysms, hemorrhages, exudates, etc. Detection of these lesions plays a significant role for early diagnosis of DR. Methods: To this aim, this paper proposes a novel and automated lesion detection scheme, which consists of the four main steps: vessel extraction and optic disc removal, preprocessing, candidate lesion detection, and postprocessing. The optic disc and the blood vessels are suppressed first to facilitate further processing. Curvelet-based edge enhancement is done to separate out the dark lesions from the poorly illuminated retinal background, while the contrast between the bright lesions and the background is enhanced through an optimally designed wideband bandpass filter. The mutual information of the maximum matched filter response and the maximum Laplacian of Gaussian response are then jointly maximized. Differential evolution algorithm is used to determine the optimal values for the parameters of the fuzzy functions that determine the thresholds of segmenting the candidate regions. Morphology-based postprocessing is finally applied to exclude the falsely detected candidate pixels. Results and Conclusions: Extensive simulations on different publicly available databases highlight an improved performance over the existing methods with an average accuracy of $97.71\%$ and robustness in detecting the various types of DR lesions irrespective of their intrinsic properties.	algorithm;blob detection;blood vessel tissue;curvelet;database;diabetic retinopathy;differential evolution;early diagnosis;edge enhancement;exudate;hemorrhage;matched filter;mathematical morphology;microaneurysm;mutual information;normal statistical distribution;optic disk;pixel;preprocessor;retina;retinal diseases;sensor;simulation	Sudeshna Sil Kar;Santi Prasad Maity	2018	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2017.2707578	edge enhancement;retina;lesion;computer vision;artificial intelligence;differential evolution;blob detection;diabetic retinopathy;optic disc;computer science;matched filter	Vision	37.03185939829167	-75.95757926110637	105002
0c417281bcb38c24005d72978e89232ee8c289fc	automated segmentation of free-lying cell nuclei in pap smears for malignancy-associated change analysis	sensitivity and specificity;dice coefficient automated segmentation free lying cell nuclei pap smear malignancy associated change analysis automated algorithm bright field microscope cervical cancer gray scale annular closing marker based watershed segmentation nuclear boundaries artifact rejection intermediate squamous epithelial cells;dice coefficient;image segmentation;cancer;cell nucleus;cervical cancers;algorithms automation female humans microscopy papanicolaou test uterine cervical neoplasms vaginal smears;automated segmentation;microscope images;gray scale;robustness image segmentation sensitivity transforms shape nuclear measurements;datoriserad bildanalys;medicinsk bildbehandling;automated screening;medical image processing;brightfield;watershed segmentation;automated algorithms;optical microscopy biomedical optical imaging cancer cellular biophysics image segmentation medical image processing obstetrics;computerized image analysis;pap smear;biomedical optical imaging;cellular biophysics;change analysis;optical microscopy;obstetrics;epithelial cells;manual segmentation;segmentation algorithms	This paper presents an automated algorithm for robustly detecting and segmenting free-lying cell nuclei in bright-field microscope images of Pap smears. This is an essential initial step in the development of an automated screening system for cervical cancer based on malignancy associated change (MAC) analysis. The proposed segmentation algorithm makes use of gray-scale annular closings to identify free-lying nuclei-like objects together with marker-based watershed segmentation to accurately delineate the nuclear boundaries. The algorithm also employs artifact rejection based on size, shape, and granularity to ensure only the nuclei of intermediate squamous epithelial cells are retained. An evaluation of the performance of the algorithm relative to expert manual segmentation of 33 fields-of-view from 11 Pap smear slides is also presented. The results show that the sensitivity and specificity of nucleus detection is 94.71% and 85.30% respectively, and that the accuracy of segmentation, measured using the Dice coefficient, of the detected nuclei is 97.30±1.3%.	algorithm;cell nucleus;cervix carcinoma;coefficient of determination;deny (action);grayscale;microscope device component;nop slide;neoplasms;papanicolaou test;password authentication protocol;rejection sampling;segmentation action;sensitivity and specificity;sensor;slide (glass microscope);smear - instruction imperative;smear campaign;sørensen–dice coefficient;telling untruths;watershed (image processing);biologic segmentation	Ramin Moshavegh;Babak Ehteshami Bejnordi;Andrew Mehnert;K. Sujathan;Patrik Malm;Ewert Bengtsson	2012	2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2012.6347208	computer vision;medicine;watershed;pathology;computer science;optical microscope;image segmentation;sørensen–dice coefficient;grayscale;anatomy;statistics;cancer	Robotics	38.722872190449664	-77.88641863785033	105143
235b735cc7d183465e1709682be4bc943e44e6e0	neuronet: fast and robust reproduction of multiple brain image segmentation pipelines		NeuroNet is a deep convolutional neural network mimicking multiple popular and state-of-the-art brain segmentation tools including FSL, SPM, and MALPEM. The network is trained on 5,000 T1-weighted brain MRI scans from the UK Biobank Imaging Study that have been automatically segmented into brain tissue and cortical and sub-cortical structures using the standard neuroimaging pipelines. Training a single model from these complementary and partially overlapping label maps yields a new powerful “all-in-one”, multi-output segmentation tool. The processing time for a single subject is reduced by an order of magnitude compared to running each individual software package. We demonstrate very good reproducibility of the original outputs while increasing robustness to variations in the input data. We believe NeuroNet could be an important tool in large-scale population imaging studies and serve as a new standard in neuroscience by reducing the risk of introducing bias when choosing a specific software package.	artificial neural network;computer multitasking;convolutional neural network;end-to-end principle;expectation propagation;fmrib software library (fsl);graphics processing unit;image scaling;image segmentation;intranet;mira;map;medical imaging;microsoft research;multi-function printer;multi-task learning;pipeline (computing);super paper mario;titan (supercomputer);uk biobank	Martin Rajchl;Nick Pawlowski;Daniel Rueckert;Paul M. Matthews;Ben Glocker	2018	CoRR		robustness (computer science);convolutional neural network;pattern recognition;artificial intelligence;image segmentation;software;neuroimaging;segmentation;computer science;population;brain segmentation	Vision	30.22791670086578	-75.00029210656756	105169
78a6436e8f95840fd0a92745bce73f813bd3aade	robust skull stripping of clinical glioblastoma multiforme data	gbm case;potential resection;brain boundary;surgical resection;healthy brain;strip brain image;gbm image;robust skull;clinical glioblastoma multiforme data;robex skull;popular skull	Skull stripping is the first step in many neuroimaging analyses and its success is critical to all subsequent processing. Methods exist to skull strip brain images without gross deformities, such as those affected by Alzheimer's and Huntington's disease. However, there are no techniques for extracting brains affected by diseases that significantly disturb normal anatomy. Glioblastoma multiforme (GBM) is such a disease, as afflicted individuals develop large tumors that often require surgical resection. In this paper, we extend the ROBEX skull stripping method to extract brains from GBM images. The proposed method uses a shape model trained on healthy brains to be relatively insensitive to lesions inside the brain. The brain boundary is then searched for potential resection cavities using adaptive thresholding and the Random Walker algorithm corrects for leakage into the ventricles. The results show significant improvement over three popular skull stripping algorithms (BET, BSE and HWA) in a dataset of 48 GBM cases.	amiga walker;anatomic structures;biological systems engineering;brain;cerebral ventricles;computational anatomy;congenital abnormality;encephalopathy, bovine spongiform;excision;extravasation;glioblastoma multiforme;gross motor development delay;mesa;neoplasms;neuroimaging;parkinson disease;random walker algorithm;search - action;silo (dataset);spectral leakage;thresholding (image processing);high-grade childhood cerebral astrocytoma	William Speier;Juan Eugenio Iglesias;Leila El-Kara;Zhuowen Tu;Corey W. Arnold	2011	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-23626-6_81	medicine;pathology;surgery	HPC	38.110918043590736	-78.9353379839063	105462
180a78e4b08a333a4509b11c47c51153393ede7a	fully automatic region of interest selection in glomerular filtration rate estimation from 99mtc-dtpa renogram	female;radioisotope renography;middle aged;adolescent;male;gadolinium dtpa;image interpretation computer assisted;adult;contrast media;algorithms;gamma cameras;pattern recognition automated;humans;glomerular filtration rate;aged;aged 80 and over	Glomerular filtration rate (GFR) is a common accepted standard estimation of renal function. Gamma camera-based methods for estimating renal uptake of 99mTc-diethylenetriaminepentaacetic acid (DTPA) without blood or urine sampling have been widely used. Of these, the method introduced by Gates has been the most common method. Currently, most of gamma cameras are equipped with a commercial program for GFR determination, a semi-quantitative analysis by manually drawing region of interest (ROI) over each kidney. Then, the GFR value can be computed from the scintigraphic determination of 99mTc-DTPA uptake within the kidney automatically. Delineating the kidney area is difficult when applying a fixed threshold value. Moreover, hand-drawn ROIs are tedious, time consuming, and dependent highly on operator skill. Thus, we developed a fully automatic renal ROI estimation system based on the temporal changes in intensity counts, intensity-pair distribution image contrast enhancement method, adaptive thresholding, and morphological operations that can locate the kidney area and obtain the GFR value from a 99mTc-DTPA renogram. To evaluate the performance of the proposed approach, 30 clinical dynamic renograms were introduced. The fully automatic approach failed in one patient with very poor renal function. Four patients had a unilateral kidney, and the others had bilateral kidneys. The automatic contours from the remaining 54 kidneys were compared with the contours of manual drawing. The 54 kidneys were included for area error and boundary error analyses. There was high correlation between two physicians’ manual contours and the contours obtained by our approach. For area error analysis, the mean true positive area overlap is 91%, the mean false negative is 13.4%, and the mean false positive is 9.3%. The boundary error is 1.6 pixels. The GFR calculated using this automatic computer-aided approach is reproducible and may be applied to help nuclear medicine physicians in clinical practice.	bilateral filter;blood urea nitrogen measurement;error analysis (mathematics);estimated;gadolinium dtpa;gamma camera;genetic selection;glomerular filtration rate;hl7publishingsubsection <operations>;hepatobiliary system;human resources;kidney calculi;kidney diseases;mathematical morphology;national supercomputer centre in sweden;organ;patients;pentetic acid;pixel;radionuclide imaging;region of interest;renal tissue;sampling (signal processing);semiconductor industry;sensitivity and specificity;short;technetium tc 99m pentetate;thresholding (image processing);web of trust	Kun-Ju Lin;Jia-Yann Huang;Yung-Sheng Chen	2011	Journal of Digital Imaging	10.1007/s10278-011-9361-6	medicine;pathology;computer science;renal function;nuclear medicine	Vision	38.04380854786733	-79.94330790782591	105474
fa06004f1f41f7adf70698324d5d9c2ac39d114d	image and signal processing	pattern recognition;computer graphic;signal processing;artificial intelligent;computer vision	In the context of computer vision applied to precision agriculture, this paper presents an imaging system based on shape and intensity features, extracted from RGB images, for the discrimination between crop plants and weeds. A segmentation method with many constraints to overcome light acquisition conditions is used and coupled with morphological filtering suitable for denoising segmented images. A SVMs classifier based on a polynomial kernel function is implemented and a k-folds cross validation process is used to evaluate the performance of the SVMs classifier usable in 2 different configurations. On a training dataset, these 2 configurations are evaluated for the performance of classification in terms of true and false positive rates, according to ROC curves and area under curves. On a test dataset, these 2 configurations are exploited, giving both a relevant classification rate.	computer vision;mathematical morphology;noise reduction;polynomial kernel;receiver operating characteristic;signal processing	Alamin Mansouri Abderrahim El Moataz Fathallah Nouboud Dr Mammass	2018		10.1007/978-3-319-94211-7	multidimensional signal processing;pyramid;analog image processing;image processing;digital signal processing;digital image processing;multiplicative noise;clipping;normalization	Vision	36.16694607130798	-69.34573507709678	105684
c3ddf3e5b337039419d29ad5ae3a7a8d1697fb7d	exploiting ruling line artifacts in writer identification	handwriting recognition;feature extraction hidden markov models text analysis histograms vectors noise measurement;performance gain ruling line artifact exploitation writer identification problem noisy handwritten documents preprinted ruling lines displacement features handwritten text lines;image denoising document image processing feature extraction handwriting recognition;feature extraction;document image processing;image denoising	In this paper, we address the writer identification problem for noisy handwritten documents written on a substrate of pre-printed ruling lines. Instead of attempting to remove rulings and to recover broken strokes, we incorporate rulings to help with the identification task through the use of new displacement features. Experiments involving 61 writers and 4,890 handwritten text lines show that our technique is effective, with a relative 10% performance gain over the baseline system which attempts to remove ruling lines and recover broken strokes.	baseline (configuration management);displacement mapping;experiment;printing	Jin Chen;Daniel P. Lopresti	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		computer vision;speech recognition;feature extraction;computer science;machine learning;pattern recognition;handwriting recognition	Robotics	36.636863696124024	-66.53392263580123	105980
85886d669ce1b990abb17d076c47698c2a852e4f	optical recognition of braille writing	image processing;optical character recognition;writing optical character recognition software character recognition books text recognition punching optical materials machine vision lighting image recognition;image processing techniques braille writing optical recognition braille characters interleaved matrices optical reading system;handicapped aids;machine vision;pattern recognition;handicapped aids character recognition pattern recognition image processing optical character recognition;image processing techniques;character recognition	This article describes the way we solved the optical recognition of Braille characters (OBR). Braille is a relief writing for the Blind and partially sighted. Its characters consist of punched dots that are placed in a fixed matrix. Double sided (recto-verso) Braille is obtained by punching dots at both sides, using interleaved matrices. As a consequence, an optical reading system will see both sides of the printed material simultaneously. Reading this relief writing with machine vision needs special conditions of illumination. The article will show that this writing can be read using standard equipment and that the recognition can be solved with image processing techniques.	image processing;machine vision;optical character recognition;printing	Jan Mennens;Luc Van Tichelen;Guido Francois;Jan J. Engelen	1993		10.1109/ICDAR.1993.395702	computer vision;speech recognition;document processing;machine vision;image processing;intelligent character recognition;computer science;intelligent word recognition;optical character recognition	Vision	35.14678772530288	-66.79370739424513	106126
9b8da434dfa6f44efc599f4ef5e5ca16cba6957e	gray level co-occurrence and random forest algorithm-based gender determination with maxillary tooth plaster images	image processing;feature extraction;random forest algorithm;gender determination	Gender is one of the intrinsic properties of identity, with performance enhancement reducing the cluster when a search is performed. Teeth have durable and resistant structure, and as such are important sources of identification in disasters (accident, fire, etc.). In this study, gender determination is accomplished by maxillary tooth plaster models of 40 people (20 males and 20 females). The images of tooth plaster models are taken with a lighting mechanism set-up. A gray level co-occurrence matrix of the image with segmentation is formed and classified via a Random Forest (RF) algorithm by extracting pertinent features of the matrix. Automatic gender determination has a 90% success rate, with an applicable system to determine gender from maxillary tooth plaster images.		Betul Akkoc;Ahmet Arslan;Hatice Kök	2016	Computers in biology and medicine	10.1016/j.compbiomed.2016.04.003	random forest;image processing;feature extraction;computer science;machine learning;dentistry	Vision	34.58429757043768	-72.78522144066685	106262
31dffa0325ca8b93147931750f297bda9cce2214	joint detection and diagnosis of prostate cancer in multi-parametric mri based on multimodal convolutional neural networks		This paper presents an automated method for jointly localizing prostate cancer (PCa) in multi-parametric MRI (mp-MRI) images and assessing the aggressiveness of detected lesions. Our method employs multimodal multi-label convolutional neural networks (CNNs), which are trained in a weakly-supervised manner by providing a set of prostate images with image-level labels without priors of lesions’ locations. By distinguishing images with different labels, discriminative visual patterns related to indolent PCa and clinically significant (CS) PCa are automatically learned from clutters of prostate tissues. Cancer response maps (CRMs) with each pixel indicating the likelihood of being part of indolent/CS are explicitly generated at the last convolutional layer. We define new back-propagate error of CNN to enforce both optimized classification results and consistent CRMs for different modalities. Our method enables the feature learning processes of different modalities to mutually influence each other and, in turn yield more representative features. Comprehensive evaluation based on 402 lesions demonstrates superior performance of our method to the state-of-the-art method [13].	artificial neural network;compute against cancer;convolutional neural network;experiment;feature learning;map;multi-label classification;multimodal interaction;pixel	Xin Yang;Zhiwei Wang;Chaoyue Liu;Hung Le Minh;Jingyu Chen;Kwang-Ting Cheng;Liang Wang	2017		10.1007/978-3-319-66179-7_49	pixel;discriminative model;computer vision;pattern recognition;artificial intelligence;convolutional neural network;computer science;prior probability;parametric statistics;prostate cancer;feature learning	Vision	31.659841213064492	-75.82606517096312	106356
63e576f870cf8fda2ae971601f504f7c4c129fc2	multi-step offline handwritten chinese characters segmentation with ga		Offline Chinese characters segmentation is one of the most diffi- cult problems in Chinese character recognition, because handwritten Chinese characters have deformations, connected strokes and overlapped characters, and they often occurre with punctuations and digital numrbers. The multi- step offline handwritten Chinese characters segmentation method based on adaptive genetic algorithm was put forward in this paper to segment con- nected or overlaps characters, punctuations and digital numbers. Genetic al- gorithm chose the optimal threshold of projection profile histogram method to segment character string roughly. Genetic algorithm parameters were adap- tively chosen according to different character string images. Then, an esti- mation strategy determines whether the character block to be merged If the character block contained character, then it would be merged with neighbor character block that had the shortest distance to it. Finally, Viterbi algo- rithm re-segmented the insufficient segmented characters. Original rule 4 was modified and a genetic algorithm rules were put forward to delete redundant paths. Experiments on HIW-MW database shows that the new algorithm has correct segmentation rate of 74.55% which is higher than other two segment methods. The new algorithm can segment Chinese characters, punctuation and digital numbers correctly, and it is an efficient segment method.	online and offline;software release life cycle	Rui-rui Zheng;Ji-yin Zhao;Bao-chun Wu	2009		10.1007/978-3-642-03664-4_1	arithmetic;speech recognition;computer science;algorithm	NLP	38.8330417580833	-67.16327813746064	106436
9b121809ecbc75db7c2b4323fb62b01056a325b8	an integrated texton and bag of words classifier for identifying anaplastic medulloblastomas	text detection biological tissues diseases image classification image texture medical image processing;image features;biological tissues;filter bank;haar wavelet;cancer;training;image classification;biomedical imaging;image texture;accuracy;rotation invariance;feature extraction;medical image processing;dictionaries;nearest neighbor;κ nn classifier integrated texton words classifier anaplastic medulloblastoma identification bag of words approach digitized histopathology histological image signatures disease texture based approaches texture appearance haar wavelet responses mr8 filter bank κ nearest neighbor content based image retrieval system;roc curve;diseases;text detection;accuracy dictionaries biomedical imaging training cancer diseases feature extraction;cross validation;classification accuracy;content based image retrieval;bag of words;spatial orientation;cerebellar neoplasms cohort studies humans medulloblastoma roc curve terminology as topic	In this paper we present a combined Bag of Words and texton based classifier for differentiating anaplastic and non-anaplastic medulloblastoma on digitized histopathology. The hypothesis behind this work is that histological image signatures may reflect different levels of aggressiveness of the disease and that texture based approaches can help discriminate between more aggressive and less aggressive phenotypes of medulloblastoma. The bag of words approach attempts to model the occurrence of differently expressed image features. In this work we choose to model the image features via textons which can quantitatively capture and model texture appearance in the images. The texton-based features, obtained via two methods, the Haar Wavelet responses and MR8 filter bank, provide spatial orientation and rotation invariant attributes. Applying these features to the bag of words framework yields textural representations that can be used in conjunction with a classifier (κ-nearest neighbor) or a content based image retrieval system. Over multiple runs of randomized cross validation, a κ-NN classifier in conjunction with Haar wavelets and the texton, bag of words approach yielded a mean classification accuracy of 80, an area under the precision recall curve of 87 and an area under the ROC curve of 83 in distinguishing between anaplastic and non-anaplastic medulloblastomas on a cohort of 36 patient studies.	anaplastic medulloblastoma;antivirus software;bag-of-words model;content-based image retrieval;cross reactions;eighty;filter bank;haar wavelet;histopathology;patients;personality disorders;phenotype;precision and recall;randomized algorithm;receiver operating characteristic;space perception;statistical classification;texton	Joseph Galaro;Alexander R. Judkins;David Ellison;Jennifer Baccon;Anant Madabhushi	2011	2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/IEMBS.2011.6090931	medical imaging;image texture;computer vision;contextual image classification;speech recognition;spatial disorientation;feature extraction;computer science;bag-of-words model;machine learning;pattern recognition;filter bank;accuracy and precision;k-nearest neighbors algorithm;feature;receiver operating characteristic;cross-validation;cancer	Vision	34.20119734316212	-75.97728353765744	106437
b8a505c8fbcc3ad6fcfffce4bc13fcab60a55ce5	accurate diagnosis of thyroid follicular lesions from nuclear morphology using supervised learning	sensitivity and specificity;optimal transport;female;middle aged;cell nucleus;thyroid diseases;male;microscopy;image interpretation;image enhancement;diagnosis differential;image interpretation computer assisted;adult;nuclear morphology;reproducibility of results;thyroid follicular lesions;pattern recognition;artificial intelligence;algorithms;image analysis;pattern recognition automated;humans;computer assisted;young adult;automated;diagnosis;differential;aged	Follicular lesions of the thyroid remain significant diagnostic challenges in surgical pathology and cytology. The diagnosis often requires considerable resources and ancillary tests including immunohistochemistry, molecular studies, and expert consultation. Visual analyses of nuclear morphological features, generally speaking, have not been helpful in distinguishing this group of lesions. Here we describe a method for distinguishing between follicular lesions of the thyroid based on nuclear morphology. The method utilizes an optimal transport-based linear embedding for segmented nuclei, together with an adaptation of existing classification methods. We show the method outputs assignments (classification results) which are near perfectly correlated with the clinical diagnosis of several lesion types' lesions utilizing a database of 94 patients in total. Experimental comparisons also show the new method can significantly outperform standard numerical feature-type methods in terms of agreement with the clinical diagnosis gold standard. In addition, the new method could potentially be used to derive insights into biologically meaningful nuclear morphology differences in these lesions. Our methods could be incorporated into a tool for pathologists to aid in distinguishing between follicular lesions of the thyroid. In addition, these results could potentially provide nuclear morphological correlates of biological behavior and reduce health care costs by decreasing histotechnician and pathologist time and obviating the need for ancillary testing.		John A. Ozolek;Akif Burak Tosun;Wei Wang;Cheng Chen;Soheil Kolouri;Saurav Basu;Hu Huang;Gustavo K. Rohde	2014	Medical image analysis	10.1016/j.media.2014.04.004	endocrinology;image analysis;medicine;pathology;young adult;computer science;microscopy;automation;differential	ML	33.370568861226644	-79.2112876450408	106453
5106ec965782110293cda68b2c0a3b6c5a946c6a	supervised classification techniques for identifying alzheimer’s disease		Alzheimer’s Disease is a serious form of dementia. With no current cure, treatments focus on slowing the progression of the disease and controlling its symptoms. Early diagnosis by studying the biomarkers found in structural MRI is the key. This paper proposes a method which combines texture features extracted from gray level co-occurrence matrix and voxel-based morphometry neuroimaging analysis to classify Alzheimer’s disease patients. Different supervised classification techniques are studied, support vector machine, k-nearest neighbor, and decision tree, to obtain best identification accuracy. The paper explores as well the discriminative power for Alzheimer’s disease of certain anatomical regions of interest. The proposed technique is applied on gray matter tissues, and managed successfully to differentiate between Alzheimer’s disease patients and normal controls with accuracy 92%.		Yasmeen Farouk;Sherine Rady	2018		10.1007/978-3-319-99010-1_17	support vector machine;discriminative model;decision tree;region of interest;biomarker (medicine);k-nearest neighbors algorithm;neuroimaging;pattern recognition;artificial intelligence;computer science;dementia	ML	30.427941141763494	-78.30603352755854	106495
c182834521937f64a63e70be8436bbda7ad6c6f9	automatic facial spirit classification for traditional chinese medicine based on mutiple facial features	face feature extraction iris recognition medical services medical diagnostic imaging educational institutions;spirit diagnosis artificial intelligence eye detection tcm objectification;iris recognition;medical services;feature extraction;face;medicine biometrics access control face recognition feature extraction image fusion image registration medical image processing;automatic facial spirit classification ig analysis high facial feature classification accuracy information gain analysis video image capture tcm quantification method experience based tcm diagnostic method observation based tcm diagnostic method tcm facial diagnostic method tcm facial diagnosis quantitative facial feature classification system automatic facial feature classification system multiple facial feature classification model multiple facial feature classification system facial feature based tcm spirit diagnosis traditional chinese medicine spirit diagnosis;medical diagnostic imaging	This paper presents a new automatically quantitative facial features classification system for TCM spirit diagnosis based on facial features. Facial diagnosis is an important diagnostic method in TCM (Traditional Chinese Medicine) and has been used for a long time. However, this traditional diagnostic method is mainly based on observation by TCM doctors and their personal experience. To develop quantification methods for TCM is very important. First, we capture facial features from video images through some algorithms, and then we use some classification models to analyze them. Finally, IG (Information Gain) is used to analyse which kind of features has good performance. Experiment results show that our system has high classification accuracy.	algorithm;computer cooling;facial recognition system;kullback–leibler divergence;toolkit for conceptual modeling	Chenyang Sun;Hongkai Zhang;Xiaoxin Qiu;Qian Peng;Zhumei Sun;Wenqiang Zhang;Fufeng Li	2014	2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2014.6999314	face;computer vision;speech recognition;feature extraction;computer science;pattern recognition;iris recognition	Robotics	35.226098490013335	-73.3938707967875	106509
d4d109873f9fa3c2993e2693c8bfdbc6c7990b8a	recognition-based character segmentation for multi-level writing style	character segmentation;optical character recognition;multi-level writing style;graph partitioning;touching and broken characters	Character segmentation is an important task in optical character recognition (OCR). The quality of any OCR system is highly dependent on character segmentation algorithm. Despite the availability of various character segmentation methods proposed to date, existing methods cannot satisfyingly segment characters belonging to some complex writing styles such as the Lanna Dhamma characters. In this paper, a new character segmentation method named graph partitioning-based character segmentation is proposed to address the problem. The proposed method can deal with multi-level writing style as well as touching and broken characters. It is considered as a generalization of existing approaches to multi-level writing style. The proposed method consists of three phases. In the first phase, a newly devised over-segmentation technique based on morphological skeleton is used to obtain redundant fragments of a word image. The fragments are then used to form a segmentation hypotheses graph. In the last phase, the hypotheses graph is partitioned into subgraphs each corresponding to a segmented character using the partitioning algorithm developed specifically for character segmentation purpose. Experimental results based on handwritten Lanna Dhamma characters datasets showed that the proposed method achieved high correct segmentation rate and outperformed existing methods for the Lanna Dhamma alphabet.	algorithm;graph partition;mojibake;morphological skeleton;named graph;null character;optical character recognition	Papangkorn Inkeaw;Jakramate Bootkrajang;Phasit Charoenkwan;Sanparith Marukatat;Shinn-Ying Ho;Jeerayut Chaijaruwanich	2018	International Journal on Document Analysis and Recognition (IJDAR)	10.1007/s10032-018-0302-5	optical character recognition;named graph;artificial intelligence;machine learning;pattern recognition;writing style;graph partition;alphabet;morphological skeleton;segmentation;computer science;graph	AI	36.279680403742404	-66.24879834493068	106742
14e75e9200fd44b68522ddb2b085f35e6d9603a0	histopathological image classification using discriminative feature-oriented dictionary learning	biological patents;training optimization histopathological image analysis feature extraction biomedical imaging;tcga database histopathological image classification discriminative feature oriented dictionary learning histopathological image analysis feature extraction histology feature diversity automatic feature discovery framework learning class specific dictionary disease grading sparsity constraint image database intraductal breast lesion images mammalian kidney images mammalian lung images mammalian spleen images animal diagnostics lab pennsylvania state university brain tumor images the cancer genome atlas;biomedical journals;histopathological image classification sparse coding dictionary learning feature extraction cancer grading;cancer;text mining;europe pubmed central;training;citation search;biomedical imaging;cancer grading histopathological image classification sparse coding dictionary learning feature extraction;citation networks;research articles;yttrium;tumours brain cancer feature extraction image classification kidney lung medical image processing;abstracts;feature extraction;open access;dictionaries;life sciences;clinical guidelines;dictionary learning;histopathological image classification discriminative feature oriented dictionary learning histopathological image analysis feature extraction histology feature diversity automatic feature discovery framework learning class specific dictionary disease grading sparsity constraint image database intraductal breast lesion images mammalian kidney images mammalian lung images mammalian spleen images animal diagnostics lab pennsylvania state university brain tumor images the cancer genome atlas tcga database;optimization;histopathological image classification;full text;brain cancer feature extraction image classification kidney lung medical image processing tumours;sparse coding;rest apis;orcids;europe pmc;cancer grading;biomedical research;bioinformatics;literature search	In histopathological image analysis, feature extraction for classification is a challenging task due to the diversity of histology features suitable for each problem as well as presence of rich geometrical structures. In this paper, we propose an automatic feature discovery framework via learning class-specific dictionaries and present a low-complexity method for classification and disease grading in histopathology. Essentially, our Discriminative Feature-oriented Dictionary Learning (DFDL) method learns class-specific dictionaries such that under a sparsity constraint, the learned dictionaries allow representing a new image sample parsimoniously via the dictionary corresponding to the class identity of the sample. At the same time, the dictionary is designed to be poorly capable of representing samples from other classes. Experiments on three challenging real-world image databases: 1) histopathological images of intraductal breast lesions, 2) mammalian kidney, lung and spleen images provided by the Animal Diagnostics Lab (ADL) at Pennsylvania State University, and 3) brain tumor images from The Cancer Genome Atlas (TCGA) database, reveal the merits of our proposal over state-of-the-art alternatives. Moreover, we demonstrate that DFDL exhibits a more graceful decay in classification accuracy against the number of training images which is highly desirable in practice where generous training is often not available.	brain neoplasms;class;data format description language;database;dictionary [publication type];exhibits as topic;experiment;feature extraction;histopathologic grade;histopathology;image analysis;machine learning;occam's razor;problem-based learning;renal tissue;sparse matrix;spleen tissue;structure of parenchyma of lung;the cancer genome atlas;world file	Tiep Huu Vu;Hojjat Seyed Mousavi;Vishal Monga;Ganesh Rao;Arvind U. K. Rao	2016	IEEE Transactions on Medical Imaging	10.1109/TMI.2015.2493530	text mining;speech recognition;radiology;pathology;feature extraction;computer science;yttrium;pattern recognition;neural coding;cancer	Vision	28.11511720273514	-77.39002759462448	106998
13aa11f60bf53aee440facaee410163650dbedf3	perceptually adapted method for optic disc detection on retinal fundus images	eye;probability biomedical optical imaging biomimetics edge detection eye image classification image colour analysis medical image processing;probability;image color analysis retina classification algorithms biomedical optical imaging optical imaging diabetes;edge detection;image classification;livewire technique perceptually adapted method optic disc detection retinal fundus image image color information cie lab color space cie94 color distance pixel color derivative pixel classifier pixel probability value optic disc border basic point detection;image colour analysis;medical image processing;biomedical optical imaging;biomimetics	This paper presents a novel technique for the detection of the optic disc (OD) in retinal fundus images. The method exploits the color information of the image with a perception adapted approach. CIE L*a*b* color space along with CIE94 color distance are used to obtain 12 color derivatives for each pixel under study. Based on this information, a classifier assigns a probability value to each pixel in the image, meaning its suitability for being part of the OD border. Looking for the pixels with highest probability values, the method detects the basic points for the OD border that are subsequently connected with the livewire technique. The reliability of the tool has been tested with three different classifiers on 198 images from four public available databases obtaining an average success percentage of 85.48% and a mean distance to the closest point of 2 pixels.	color space;computability in europe;database;livewire segmentation technique;pixel;statistical classification;virtual retinal display	Irene Fondón;Mark J. J. P. van Grinsven;Clara I. Sánchez;Aurora Sáez	2013	Proceedings of the 26th IEEE International Symposium on Computer-Based Medical Systems	10.1109/CBMS.2013.6627802	color co-site sampling;biomimetics;color histogram;rgb color model;computer vision;contextual image classification;feature detection;edge detection;image resolution;color depth;color image;image gradient;binary image;computer science;probability;color balance;statistics;computer graphics (images)	Vision	36.83299812091755	-73.31018374852232	107151
a7f5a8fb71f6c939a876dcd2446ea4daeb00408e	an expert system for detection of breast cancer based on association rules and neural network	association rules;feature space;system performance;automatic detection;association rule;cross validation;breast cancer;neural network;expert system	This paper presents an automatic diagnosis system for detecting breast cancer based on association rules (AR) and neural network (NN). In this study, AR is used for reducing the dimension of breast cancer database and NN is used for intelligent classification. The proposed AR + NN system performance is compared with NN model. The dimension of input feature space is reduced from nine to four by using AR. In test stage, 3-fold cross validation method was applied to the Wisconsin breast cancer database to evaluate the proposed system performances. The correct classification rate of proposed system is 95.6%. This research demonstrated that the AR can be used for reducing the dimension of feature space and proposed AR + NN model can be used to obtain fast automatic diagnostic systems for other diseases. 2008 Elsevier Ltd. All rights reserved.	artificial neural network;association rule learning;cross-validation (statistics);expert system;feature extraction;feature vector;mathematical model;pattern recognition;performance;randomness extractor;sensor;statistical classification	Murat Karabatak;M. Cevdet Ince	2009	Expert Syst. Appl.	10.1016/j.eswa.2008.02.064	association rule learning;computer science;machine learning;pattern recognition;data mining;expert system;artificial neural network	Robotics	34.07417139441754	-73.44179541848183	107652
578572bb505ba0e5441ffcf0ed49c36e1c9627b8	a novel invariant mapping applied to hand-written arabic character recognition	pattern recognition;character recognition	This paper describes an application of a novel mapping, one that is intended for use in on-line handwritten character recognition. This mapping produces the same output pattern regardless of the orientation, position, and size of the input pattern. The mapping has the advantage of being simple. This makes it computationally efficient and fast, which in turn makes it appropriate for on-line implementations. To demonstrate the usefulness of this mapping, a recognition system utilising it has been developed for hand-written Arabic characters. The performance of this system is shown to be comparable to that of existing on-line Arabic character recognition systems.	algorithmic efficiency;handwriting recognition;online and offline;optical character recognition	Nawwaf N. Kharma;Rabab Kreidieh Ward	2001	Pattern Recognition	10.1016/S0031-3203(00)00140-0	arithmetic;speech recognition;feature;intelligent character recognition;computer science;intelligent word recognition	AI	32.26552270858012	-67.3697753990821	107787
71dd90cb3a5b5371223a83eeb706e3e6d6cb0270	the ms kinect image and depth sensors use for gait features detection	video signal processing data acquisition diseases feature extraction gait analysis graphical user interfaces image sensors image sequences medical disorders medical image processing video cameras;image and depth sensors;gait recognition;motion;classification;ms kinect;parkinson s disease motion image and depth sensors three dimensional modelling gait recognition ms kinect classification biomedical signal processing;parkinson s disease image sensor depth sensor ms kinect gait feature detection movement disorder gait stability motion sensors video sequences complex camera systems data acquisition graphical user interface gait disorders motion stability;biomedical signal processing;parkinson s disease;sensors accuracy image sensors legged locomotion parkinson s disease joints cameras;three dimensional modelling	Movement disorders, problems with motion and gait stability related to aging form a very intensively studied research area. The paper presents a contribution to these topics through the use of data acquired by motion sensors and namely image and depth sensors of the MS Kinect. While video sequences obtained by complex camera systems can be used for the precise gait features evaluation, it is possible to use much cheaper devices for diagnostic purposes accurate enough in many cases. The experimental part of the study presents video sequences and depth sensors data acquisition for 18 individuals with the Parkinson's disease and 18 healthy age-matched controls using the proposed graphical user interface in the clinical environment. Results presented include the estimation of gait features to distinguish gait disorders and to classify individuals in the early stage of possible serious diseases. The accuracy achieved was higher then 90 % for given sets of individuals.	data acquisition;gait analysis;graphical user interface;kinect;sensor	Ales Procházka;Martin Schätz;Ondrej Tupa;Mohammadreza Yadollahi;Oldrich Vysata;M. Walls	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7025460	computer vision;simulation;biological classification;computer science;motion	Robotics	26.676938083947274	-72.26529316155448	107974
36d56f096eb8058cd256d4b233cd9f6deb197a6f	high resolution segmentation of neuronal tissues from low depth-resolution em imagery	connectomics;segmentation of neuronal tissues;task driven dictionary learning;sparse over complete representation	The challenge of recovering the topology of massive neuronal circuits can potentially be met by high throughput Electron Microscopy (EM) imagery. Segmenting a 3-dimensional stack of EM images into the individual neurons is difficult, due to the low depth-resolution in existing high-throughput EM technology, such as serial section Transmission EM (ssTEM). In this paper we propose methods for detecting the high resolution locations of membranes from low depth-resolution images. We approach this problem using both a method that learns a discriminative, over-complete dictionary and a kernel SVM. We test this approach on tomographic sections produced in simulations from high resolution Focused Ion Beam (FIB) images and on low depth-resolution images acquired with ssTEM and evaluate our results by comparing it to manual labeling of this data.	dictionary;electron tomography;focused ion beam;high-throughput computing;image resolution;radial basis function kernel;sensor;simulation;super-resolution imaging;throughput;tomographic reconstruction	Daniel Glasner;Tao Hu;Juan Nunez-Iglesias;Louis K. Scheffer;Shan Xu;Harald F. Hess;Richard Fetter;Dmitri B. Chklovskii;Ronen Basri	2011		10.1007/978-3-642-23094-3_19	computer vision;computer science;machine learning;pattern recognition	ML	30.7449605552163	-74.56579317834792	108068
38c895f708d8d4321b1335ae590494fea4d5db7d	automated chromosome classification using wavelet-based band pattern descriptors	signal image processing in medicine;biological cells wavelet packets pattern recognition humans digital images cells biology instruments cities and towns cancer computerized instrumentation;pattern recognition automated chromosome classification wavelet based band pattern descriptors;image classification;wavelet packet;wavelet transforms;chromosome classification;medical image processing;cellular biophysics wavelet transforms image classification medical image processing;pattern recognition;cellular biophysics;band pattern descriptor	Automated chromosome classification has been an important pattern recognition problem for decades. Numerous attempts were made in the past to characterize chromosome band patterns as part of the feature description vector. In this paper we describe a recent study to employ wavelet packets as basis function sets to compute chromosome band pattern features. A total of 28 wavelet packet basis function sets were evaluated in this study. The experimental results are presented and compared with those currently best-performing method on two benchmark chromosome datasets.	wavelet	Qiang Zheng;Kenneth R. Castleman	2000		10.1109/CBMS.2000.856898	computer vision;contextual image classification;computer science;machine learning;pattern recognition;wavelet transform	Vision	36.60994821292002	-74.43875081501852	108181
901d96f6aeb32cf22d807d2e64d256c7b81f6788	automated detection of microaneurysms using robust blob descriptors	databases;radon transform;computer aided diagnosis;image contrast enhancement;medical diagnostics;machine learning;retina	Microaneurysms (MAs) are among the first signs of diabetic retinopathy (DR) that can be seen as round dark-red structures in digital color fundus photographs of retina. In recent years, automated computer-aided detection and diagnosis (CAD) of MAs has attracted many researchers due to its low-cost and versatile nature. In this paper, the MA detection problem is modeled as finding interest points from a given image and several interest point descriptors are introduced and integrated with machine learning techniques to detect MAs. The proposed approach starts by applying a novel fundus image contrast enhancement technique using Singular Value Decomposition (SVD) of fundus images. Then, Hessian-based candidate selection algorithm is applied to extract image regions which are more likely to be MAs. For each candidate region, robust low-level blob descriptors such as Speeded Up Robust Features (SURF) and Intensity Normalized Radon Transform are extracted to characterize candidate MA regions. The combined features are then classified using SVM which has been trained using ten manually annotated training images. The performance of the overall system is evaluated on Retinopathy Online Challenge (ROC) competition database. Preliminary results show the competitiveness of the proposed candidate selection techniques against state-of-the art methods as well as the promising future for the proposed descriptors to be used in the localization of MAs from fundus images.	computer-aided design;data descriptor;hessian;high- and low-level;machine learning;selection algorithm;singular value decomposition;speeded up robust features	Kedir M. Adal;Sharib Ali;Desire Sidibé;Thomas P. Karnowski;Edward Chaum;Fabrice Mériaudeau	2013		10.1117/12.2007913	computer vision;radon transform;speech recognition;computer graphics (images)	ML	32.97074179464438	-74.46724469177407	108488
435022765ef2db8212c7ad79fca1f46e63a9b72d	new selective nodule enhancement filter and its application for significant improvement of nodule detection on computed tomography	lung cancer;computer aided diagnostic;computed tomography;magnetism;intracranial aneurysm;blood vessel;three dimensional;lung;angiography;magnetic resonance angiography;computing systems;diagnostics;false positive;early detection;blood vessels	Computer-aided diagnostic (CAD) schemes have been developed to assist radiologists in the early detection of lung cancer in radiographs and computed tomography (CT) images. In order to improve the sensitivity for nodule detection, many researchers have employed a filter as a preprocessing step for enhancement of nodules. However, these filters enhance not only nodules, but also other anatomic structures such as ribs, blood vessels, and airway walls. Therefore, nodules are often detected together with a large number of false positives caused by these normal anatomic structures. In this study, we developed a selective enhancement filter for nodule which can simultaneously enhance nodules and suppress other normal anatomic structures such as blood vessels and airway walls. Therefore, as preprocessing steps, this filter would be useful for improving the sensitivity of nodule detection and for reducing the number of false positives. We applied the enhancement filter to two-dimensional (2-D) and three-dimensional (3-D) CT images and also to 3-D magnetic resonance angiography (MRA) images to show its effectiveness in the enhancement of lung nodules and intracranial aneurysms.© (2004) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Qiang Li;Kunio Doi	2004		10.1117/12.535802	radiology;medicine;pathology;medical physics	Vision	37.631372209866214	-78.18250143870955	108552
bd45cb3a20a364f82482281b1e75a735172f11e9	multi-scale fully convolutional densenets for automated skin lesion segmentation in dermoscopy images		This paper addresses the problem of automated skin lesion segmentation in dermoscopy images. We propose a novel Multi-Scale Fully Convolutional DenseNets (MSFCDN) for skin lesion segmentation. The MSFCDN adopts fully convolutional architecture, which after training, can perform semantic segmentation of an image with arbitrary size. We conduct extensive experiments on ISBI 2017 “Skin Lesion Analysis Towards Melanoma Detection” Challenge dataset. Our method achieves an average Dice coefficient of 86.9% and an average accuracy of 95.3% for skin lesion segmentation.	convolutional neural network	Guodong Zeng;Guoyan Zheng	2018		10.1007/978-3-319-93000-8_58	lesion;artificial intelligence;sørensen–dice coefficient;computer vision;computer science;architecture;pattern recognition;deep learning;segmentation	Vision	31.683798948320256	-75.37437403591204	108840
4ea885fc24ff76b75fcf63fb89514bc5d1706f64	neural networks for the texture classification of temporally consistent segmented regions of flir sequences	image segmentation;hermite function;texture classification;neural networks image segmentation matrix decomposition image analysis image texture analysis image sequence analysis gaussian noise laboratories educational institutions permission;neural network classifier;feature vector;pattern classification;image segmentation texture classification temporally consistent segmented regions flir sequences edge co occurrence matrices discrete 2d orthogonal hermite functions feature vector neural network;neural network	Texture can be interpreted as a measure of the edginess about a pixel and can be described by edge co-occurrence matrices. When the matrix is decomposed using discrete 2D orthogonal Hermite functions, the coefficients are a low order feature vector which is characteristic of the texture. They can be used as features in a neural network classifier for labelling regions of FLIR images segmented using co-occurrence based techniques. Emphasis is placed on ensuring temporal consistency of the segmentation.	neural networks	John F. Haddon;James F. Boyce	1994		10.1109/ICPR.1994.576885	image texture;computer vision;feature vector;computer science;machine learning;pattern recognition;mathematics;image segmentation;artificial neural network	Vision	34.92695103745856	-68.59847845288921	108861
1023b6bbd46f38e963d30f45c321ecaeaf46cf5f	analysis and classification of remote sensing, by using wavelet transform and neural network	remote sensing image;levenberg marquardt;lms algorithm;features extraction;neural nets;earth;standard deviation;training;symmlet5;and lm algorithm remote sensing wavelet transform symmlet5 cioflet1;wavelet transforms;wavelet transforms feature extraction neural nets remote sensing;artificial neural networks;wavelet transform;feature extraction;remote sensing;transforms;remote sensing wavelet analysis wavelet transforms neural networks image texture analysis image analysis frequency information analysis earth feature extraction;and lm algorithm;features extraction remote sensing wavelet transform neural network ciofletl symmlet5;ciofletl;neural network;cioflet1	In this paper, we analysis textures of remote sensing images by taking two reference remote sensing images. We employ the wavelet transform and neural network for analysis and classification respectively. We use (symmlet5) and (cioflet1) mother functions for analyzing the two images, that contains water, forest and earth. The images are gray level and (128 times 128) size. The processing is carried out to divide each image into (16) blocks with size (32 times 32). Each block will be entered to the wavelet mother function, after trying several mother functions, we found that the (Coif1, Sym5) are the best choice. The results are passed to the features extraction (mean, standard deviation, and variance) and the output is then fed as input to the neural network(NN). Finally the result from NN with (Levenberg Marquardt (LM) algorithm) gives the type of texture (forest , earth, and water).	artificial neural network;grayscale;levenberg–marquardt algorithm;texture mapping;wavelet transform	Shaker K. Ali;Zou Beijie	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.464	computer vision;computer science;machine learning;pattern recognition;artificial neural network;wavelet transform	Vision	35.1742920625292	-69.2893383521385	109260
1f58e68698c3de1959cf7b2060ba4842bc3a2b4d	mitosis detection in breast cancer using superpixels and ensemble classifiers		Determining the severity and potential aggressiveness of breast cancer is an important step in the determination of the treatment options for a patient. Mitosis activity is one of the main components in breast cancer severity grading. Currently, mitosis counting is a laborious, prone to processing errors, done manually by a pathologist.	ensemble kalman filter	César Antonio Ortiz Toro;Consuelo Gonzalo-Martín;Angel Garcia-Pedrero;Alejandro Rodríguez González;Ernestina Menasalvas Ruiz	2017		10.1007/978-3-319-60816-7_17	breast cancer;cancer research;mitosis;bioinformatics;medicine	Vision	35.24890939607111	-78.51233024464638	109379
122d9c2a3f2d128ce604f3a499528af8b2864fb2	sparse multi-response tensor regression for alzheimer's disease study with multivariate clinical assessments	biological patents;biomedical journals;tensor regression alzheimer s disease magnetic resonance imaging multiple responses region selection;tensile stress;text mining;europe pubmed central;citation search;citation networks;region selection;tensor regression;brain modeling;research articles;abstracts;neuroimaging;magnetic resonance imaging;open access;tensors biomedical mri brain diseases medical disorders neurophysiology regression analysis sparse matrices;life sciences;alzheimer s disease;clinical guidelines;predictive models;full text;tensile stress magnetic resonance imaging brain modeling neuroimaging alzheimer s disease predictive models;multiple responses;rest apis;orcids;europe pmc;sparse multiresponse tensor regression amnestic mild cognitive impairment ad mci disease diagnosis disease pathology brain subregions alzheimer disease neuroimaging initiative dataset adni dataset irreversible neurodegenerative disorder multivariate clinical assessments;biomedical research;bioinformatics;literature search	Alzheimer's disease (AD) is a progressive and irreversible neurodegenerative disorder that has recently seen serious increase in the number of affected subjects. In the last decade, neuroimaging has been shown to be a useful tool to understand AD and its prodromal stage, amnestic mild cognitive impairment (MCI). The majority of AD/MCI studies have focused on disease diagnosis, by formulating the problem as classification with a binary outcome of AD/MCI or healthy controls. There have recently emerged studies that associate image scans with continuous clinical scores that are expected to contain richer information than a binary outcome. However, very few studies aim at modeling multiple clinical scores simultaneously, even though it is commonly conceived that multivariate outcomes provide correlated and complementary information about the disease pathology. In this article, we propose a sparse multi-response tensor regression method to model multiple outcomes jointly as well as to model multiple voxels of an image jointly. The proposed method is particularly useful to both infer clinical scores and thus disease diagnosis, and to identify brain subregions that are highly relevant to the disease outcomes. We conducted experiments on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, and showed that the proposed method enhances the performance and clearly outperforms the competing solutions.	alzheimer's disease neuroimaging initiative;cognition disorders;experiment;mild cognitive disorder;neurodegenerative disorders;numerous;prodromal stage;silo (dataset);solutions;sparse matrix;voxel	Zhou Li;Heung-Il Suk;Dinggang Shen;Lexin Li	2016	IEEE Transactions on Medical Imaging	10.1109/TMI.2016.2538289	text mining;radiology;medicine;pathology;computer science;magnetic resonance imaging;predictive modelling;stress;neuroimaging	ML	24.87573758244	-77.80635923521716	109427
ca5d456548390a0bd93409508084900df2a22e48	ovarian tumor characterization and classification: a class of gynescan™ systems	ovarian tumor;computer aided diagnosis;ultrasonic imaging;software application ovarian tumor characterization gynescan systems computer aided diagnostic technique cad 3d acquired ultrasound images data mining algorithms benign ovarian tumor classification malignant ovarian tumor classification image texture extraction higher order spectra based features decision tree classifier ten fold stratified cross validation sensitivity pixel intensity;biological organs;tumours;image classification;texture features;data mining;classification;gynaecology;image texture;sensitivity;higher order spectra;feature extraction;medical image processing;cancer feature extraction ultrasonic imaging accuracy tumors entropy design automation;characterization;algorithms female humans image enhancement image interpretation computer assisted ovarian neoplasms pattern recognition automated reproducibility of results sensitivity and specificity ultrasonography;ultrasonic imaging biological organs biomedical ultrasonics data mining decision trees feature extraction gynaecology image classification image texture medical image processing sensitivity tumours;decision trees;computer aided diagnosis ovarian tumor texture features higher order spectra characterization classification;biomedical ultrasonics	In this work, we have developed an adjunct Computer Aided Diagnostic (CAD) technique that uses 3D acquired ultrasound images of the ovary and data mining algorithms to accurately characterize and classify benign and malignant ovarian tumors. In this technique, we extracted image-texture based and Higher Order Spectra (HOS) based features from the images. The significant features were then selected and used to train and test the Decision Tree (DT) classifier. The proposed technique was validated using 1000 benign and 1000 malignant images, obtained from 10 patients with benign and 10 with malignant disease, respectively. On evaluating the classifier with 10-fold stratified cross validation, we observed that the DT classifier presented a high accuracy of 95.1%, sensitivity of 92.5% and specificity of 97.7%. Thus, the four significant features could adequately quantify the subtle changes and nonlinearities in the pixel intensities. The preliminary results presented in this paper indicate that the proposed technique can be reliably used as an adjunct tool for ovarian tumor classification since the system is accurate, completely automated, cost-effective, and can be easily written as a software application for use in any computer.	biomarkers, tumor;both ovaries;computer-aided design;cross reactions;cross-validation (statistics);data mining;decision tree;extraction;image texture;malignant neoplasm of ovary;neoplasms;one thousand;patients;pixel;rca spectra 70;sensitivity and specificity;algorithm;malignant disease;ovarian carcinosarcoma;ovarian neoplasm	U. Rajendra Acharya;S VinithaSree;Luca Saba;Filippo Molinari;Stefano Guerriero;Jasjit S. Suri	2012	2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2012.6346953	image texture;computer vision;contextual image classification;pathology;sensitivity;feature extraction;biological classification;computer science;machine learning;decision tree;biological engineering	EDA	34.73717961273898	-77.54077916217102	109657
79f5438fbcd0c5fb42ec960356a4890d9bcacdbb	identifying cancer regions in vital-stained magnification endoscopy images using adapted color histograms	histograms;medical image processing endoscopes image colour analysis image texture;image processing;cancer;color space;color features;color histogram;natural images;precancer group cancer regions identification vital stained magnification endoscopy images adapted color histograms computer assisted decision systems color spaces natural textures local binary patterns texture descriptor normal group cancer group;local binary pattern;body image;image texture;accuracy;image color analysis;image colour analysis;medical image processing;pixel;imaging;endoscopes;pattern recognition;local binary patterns;cancer endoscopes histograms biomedical imaging medical diagnostic imaging color pattern recognition diseases videos space technology;color features medical image processing pattern recognition local binary patterns	In-body imaging technologies such as vital-stained magnification endoscopy pose novel image processing challenges to computer-assisted decision systems given their unique visual characteristics such as reduced color spaces and natural textures. In this paper we will show the potential of using adapted color features combined with local binary patterns, a texture descriptor that has exhibited good adaptation to natural images, for classifying gastric regions into three groups: normal, pre-cancer and cancer lesions. Results exhibit 91% accuracy, confirming that specific research for in-body imaging could be the key for future computer assisted decision systems for medicine.	color space;image processing;imaging technology;local binary patterns;texture filtering	André Sousa;Mário Dinis-Ribeiro;Miguel Areia;Miguel Tavares Coimbra	2009	2009 16th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2009.5414082	computer vision;local binary patterns;image processing;computer science;computer graphics (images)	Robotics	36.573468824253446	-73.2768063215705	109834
7be6406b1604a8d1d9ba505e0b7a6f208c9bcfac	classifying protein crystallization trial images using subordinate color channel	fluorescent image analysis;protein crystallization;image segmentation;classification;robustness	This paper presents a new method of segmenting and classifying protein crystallization trial images that were collected using trace fluorescent labeling. Trace fluorescent labeling typically involves fluorescence dye that can re-emit the illumination light at other wavelengths around the principal wavelength. The captured image has a primary color channel with respect to illumination light and fluorescence dye. Crystals will have higher intensity than non-crystal areas. But there might be bright regions that may not be crystals, thereby making inaccurate and not robust trial images classification. In this paper, we utilize the subordinate color channel besides the primary color in the image of trace fluorescently labeled protein solution. This new method extracts proper features and successfully builds a high accuracy classifier with a low rate of misclassification of crystals as non-crystals. We also present a framework that could optimize both image segmentation and classification. In our experiments, we achieved around 94% accuracy with 0.6% misclassification of crystals as non-crystal.	algorithm;channel (digital image);color;crystal structure;experiment;illumination (image);image segmentation;mathematical optimization;random forest;robustness (computer science);sensor;statistical classification;thresholding (image processing)	Truong X. Tran;Ramazan Savas Aygün;Marc L. Pusey	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217890	primary color;machine learning;computer science;feature extraction;fluorescence;computer vision;image segmentation;fluorescent labelling;artificial intelligence;protein crystallization;channel (digital image);communication channel	Robotics	38.61552632209803	-72.95023526009308	110078
ecc7ed0bef7e8b16f27e803bd4343856f6924408	detection and segmentation of sputum cell for early lung cancer detection	image segmentation;cancer;bayes methods;image classification;lung;patient treatment bayes methods cancer cellular biophysics image classification image segmentation lung medical image processing;medical image processing;cancer image color analysis image segmentation histograms lungs bayesian methods accuracy;patient treatment;mean shift segmentation sputum cell segmentation sputum cell detection early lung cancer detection patient treatment computer aided design system sputum stained smears sputum image bayesian classification;cellular biophysics;early lung cancer detection medical image cell detection bayesian classification mean shift	Lung cancer has been the largest cause of cancer deaths worldwide with an overall 5-year survival rate of only 15%. Its early detection significantly increases the chances of an effective treatment. For this purpose, a computer-aided design system using images of sputum stained smears is a practical, low-cost, and totally non invasive solution. In this paper, we present a framework for the detection and segmentation of sputum cells in sputum images using respectively, a Bayesian classification and mean shift segmentation. Our methods are validated and compared with other competitive approaches via a series of experiments conducted with a data set of 88 images.	computer-aided design;experiment;mean shift;naive bayes classifier	Naoufel Werghi;Christian Donner;Fatma Taher;Hussain Al-Ahmad	2012	2012 19th IEEE International Conference on Image Processing	10.1109/ICIP.2012.6467484	computer vision;contextual image classification;computer science;image segmentation;cancer	Robotics	35.844899002541204	-76.25659978635476	110123
803a8dcd98c9a5a2c799122c162a88c0983c2e83	classification of dce-mri data for breast cancer diagnosis combining contrast agent dynamics and texture features		Classification of breast tumors via dynamic contrast-enhanced magnetic resonance imaging is an important task for tumor diagnosis. In this paper, we present an approach for automatic tumor segmentation, feature generation and classification. We apply fuzzy c-means on co-occurrence texture features to generate discriminative features for classification. High-frequency information is removed via discrete wavelet transform and computation is simplified via principal component analysis before extraction. We evaluate our approach using different classification algorithms. Our experimental results show the performances of different classifiers with respect to sensitivity and specificity.	algorithm;computation;contrast ratio;discrete wavelet transform;performance;principal component analysis;resonance;sensitivity and specificity	Kai Nie;Sylvia Glaßer;Uli Niemann;Gabriel Mistelbauer;Bernhard Preim	2017		10.1007/978-3-662-54345-0_73	computer vision;pathology;pattern recognition	AI	34.58431060612874	-75.03142631143712	110136
03aca587f27fda3cbdad708aa69c07fc71b691d7	lung pattern classification for interstitial lung diseases using a deep convolutional neural network	ct volume scans lung pattern classification interstitial lung diseases deep convolutional neural network automated tissue characterization computer aided diagnosis system deep learning techniques computer vision problems medical image analysis ild pattern classification feature maps ground glass opacity micronodules consolidation reticulation honeycombing;design automation;computed tomography;neural networks;lungs computed tomography diseases feature extraction convolution design automation neural networks;neural nets biological tissues computerised tomography convolution diseases feature extraction image classification learning artificial intelligence lung medical image processing;convolution;610 medicine health;lungs;biology;feature extraction;diseases;texture classification convolutional neural networks interstitial lung diseases;570 life sciences	Automated tissue characterization is one of the most crucial components of a computer aided diagnosis (CAD) system for interstitial lung diseases (ILDs). Although much research has been conducted in this field, the problem remains challenging. Deep learning techniques have recently achieved impressive results in a variety of computer vision problems, raising expectations that they might be applied in other domains, such as medical image analysis. In this paper, we propose and evaluate a convolutional neural network (CNN), designed for the classification of ILD patterns. The proposed network consists of 5 convolutional layers with 2 × 2 kernels and LeakyReLU activations, followed by average pooling with size equal to the size of the final feature maps and three dense layers. The last dense layer has 7 outputs, equivalent to the classes considered: healthy, ground glass opacity (GGO), micronodules, consolidation, reticulation, honeycombing and a combination of GGO/reticulation. To train and evaluate the CNN, we used a dataset of 14696 image patches, derived by 120 CT scans from different scanners and hospitals. To the best of our knowledge, this is the first deep CNN designed for the specific problem. A comparative analysis proved the effectiveness of the proposed CNN against previous methods in a challenging dataset. The classification performance ( ~ 85.5%) demonstrated the potential of CNNs in analyzing lung patterns. Future work includes, extending the CNN to three-dimensional data provided by CT volume scans and integrating the proposed method into a CAD system that aims to provide differential diagnosis for ILDs as a supportive tool for radiologists.	artificial neural network;biological neural networks;ct scan;class;computer vision;computer-aided design;convolutional neural network;cross entropy;deep learning;differential diagnosis;futures studies;glass;high- and low-level;honeycomb food;image analysis;internet listing display;interstitial webpage;lung consolidation;lung diseases;map;mathematical optimization;medical image computing;medical imaging;network architecture;qualitative comparative analysis;semiconductor consolidation;silo (dataset);structure of parenchyma of lung;universal conductance fluctuations;weight;anatomical layer	Marios Anthimopoulos;Stergios Christodoulidis;Lukas Ebner;Andreas Christe;Stavroula G. Mougiakakou	2016	IEEE Transactions on Medical Imaging	10.1109/TMI.2016.2535865	computer vision;pathology;electronic design automation;feature extraction;computer science;machine learning;convolution;computed tomography;artificial neural network	Vision	31.96785686258094	-75.39548260285255	110170
8cb8a4e4419a081dac3636c0129dc8f3101e0745	voxel-based morphometry and minimum redundancy maximum relevance method for classification of parkinson's disease and controls from t1-weighted mri	computer aided diagnosis;voxel based morphometry;magnetic resonance imaging;parkinson s disease;minimum redundancy maximum relevance	Parkinson's disease (PD) is a neurodegenerative disorder, which needs to be accurately diagnosed in early stage. Voxel-based morphometry (VBM) has been extensively utilized to determine focal changes between PD patients and controls. However, it is not much utilized in differential diagnosis of an individual subject. Thus, in this study, VBM findings in conjunction with minimum redundancy maximum relevance (mRMR) method are utilized to obtain a set of relevant and non-redundant features for computer-aided diagnosis (CAD) of PD using T1-weighted MRI. In the proposed method, firstly, statistical features are extracted from the clusters obtained from statistical maps, generated using VBM, of gray matter (GM), white matter (WM) and cerebrospinal fluid (CSF) independently and their different combinations. Then mRMR, a multivariate feature selection method, is utilized to find a minimal set of relevant and non-redundant features. Finally, support vector machine is utilized to learn a decision model using the selected features. Experiments are performed on newly acquired T1-weighted MRI of 30 PD patients and 30 age & gender matched controls. The performance is evaluated using leave-one out cross-validation scheme in terms of sensitivity, specificity and classification accuracy. The maximum accuracy of 88.33% is achieved for GM+WM and GM+WM+CSF. In addition, the proposed method outperforms the existing methods. It is also observed that the selected clusters belong to regions namely middle and superior frontal gyrus for GM, inferior, middle frontal gyrus and insula for WM and lateral ventricle for CSF. Further, correlation of UPDRS/H&Y staging scale with GM/WM/CSF volume is observed to be not significant. Appreciable classification performance of the proposed method highlights the potential of the proposed method in CAD support system for the clinicians in PD diagnosis.	computer-aided design;cross-validation (statistics);data validation;disk staging;fltk;focal (programming language);feature selection;lateral thinking;map;morphometrics;relevance;sensitivity and specificity;support vector machine;voxel	Bharti;Akanksha Juneja;Mohit Saxena;Sunita Gudwani;S. Senthil Kumaran;R. K. Agrawal;Madhuri Behari	2016		10.1145/3009977.3009998	psychology;neuroscience;pathology;artificial intelligence	ML	30.774904693067555	-78.75690806039923	110214
931966558b86b5dfcc7522d92fda123f53e4b2af	learning radiologist’s step-by-step skill for cervical spinal injury examination: line drawing, prevertebral soft tissue thickness measurement, and swelling detection		Radiologists examine lateral view radiographs of the cervical spine to determine the presence of cervical spinal injury. In this paper, we demonstrate that an artificial intelligence neural network can learn the steps employed by a radiologist when examining these radiographs for possible injury. We deconstructed the decision-making strategy into three steps: line drawing, prevertebral soft tissue thickness (PSTT) measurement, and swelling detection. After training neural networks to be guided by the radiologist’s intermediate labels, the networks successfully performed comparable line drawings to those of the radiologists, and subsequent PSTT measurement and swelling detection were successful. Quantitative comparison of PSTT measurements between our proposed method and radiologists showed a high correlation (r = 0.8663, p < 0.05, and intraclass correlation coefficient = 0.9283 at the C2 level; r = 0.7720, p < 0.05, and intraclass correlation coefficient = 0.8667 at the C6 level). Using the radiologist’s diagnosis as the reference point, the sensitivity, specificity, and accuracy of swelling detection by our proposed method were 100%, 98.37%, and 98.48, respectively. We conclude that our neural networks successfully learned the sequence of skills used by radiologists when interpreting radiographs for injury of the cervical spine.	artificial intelligence;artificial neural network;coefficient;lateral thinking;line drawing algorithm;radiography;radiology;sensitivity and specificity;thickness (graph theory)	Young Han Lee;Sewon Kim;Jin-suck Suh;Dosik Hwang	2018	IEEE Access	10.1109/ACCESS.2018.2871502	intraclass correlation;possible injury;radiography;soft tissue;artificial neural network;computer science;swelling;radiology	AI	36.06595890758778	-79.44266679040206	110256
b1d2df1f3f911b8dbf0991fb79df19ae76c8e8fa	multiscale segmentation of exudates in retinal images using contextual cues and ensemble classification	exudate segmentation;ensemble classification;medical image analysis;machine learning;feature extraction;diabetic retinopathy;biological sciences	Diabetic Retinopathy (DR) is the one among other main reasons of blindness in the adult population. Early discovery of DR through screening programs and successive treatment is critical in order to avoid visual blindness. The early signs of DR as manifested in retinal images include micro-aneurysms, hemorrhages and exudates. In this paper, we have presented an ensemble classifier of bootstrapped decision trees for multiscale localization and segmentation of exudates in retinal fundus images. The candidate exudates are extracted at fine grain and coarse grain levels using morphological reconstruction and Gabor filter respectively. The contextual cues are applied to the candidate exudates, which greatly reduces false positives in exudate segmentation. Several region based features are computed from candidate regions to train the ensemble classifier for classification of pixel as exudate and non-exudate region. The method has been evaluated on four publically available databases; DIARETDB1, e-Ophtha EX, HEI-MED and Messidor. The method has achieved the segmentation accuracy as (0.8772, 0.8925, 0.9577, and 0.9836) and area under ROC as (0.9310, 0.9403, 0.9842, and 0.9961) for each of the dataset respectively. The algorithm appears to be an efficient tool for automated detection of exudates in large population based DR screening programs, due to the attained accuracy, robustness, simplicity and speed.		Muhammad Moazam Fraz;Waqas Jahangir;Saqib Zahid;Mian M. Hamayun;Sarah Barman	2017	Biomed. Signal Proc. and Control	10.1016/j.bspc.2017.02.012	computer vision;feature extraction;computer science;machine learning;pattern recognition	Vision	34.3351992605685	-76.20089655564898	110296
bd4fc66141410047b463756bb4776e261002980d	a neural network approach to character recognition	neural networks;walsh function;optical character recognition;pattern recognition;character recognition;neural network	An application of neural networks in optical character recognition (OCR) is presented. The concept of learning in neural networks is utilized to a large extent in developing an OCR system to recognize characters of various fonts and sizes, and hand written characters. Parallel computational capability helps reduce recognition time which is crucial in a commercial context. The sensitivity of the network is such that small variations in the input do not affect the output and this results in an improvement in the recognition rate of characters with slight variations in structure, linearity, and orientation.	artificial neural network;optical character recognition	A. Rajavelu;Mohamad T. Musavi;Mukul Vassant Shirvaikar	1989	Neural Networks	10.1016/0893-6080(89)90023-3	speech recognition;feature;intelligent character recognition;computer science;artificial intelligence;intelligent word recognition;machine learning;time delay neural network;optical character recognition;walsh function;neocognitron;artificial neural network	AI	33.300239037649355	-67.12668829483557	110406
7a6e68baae4186986ae014ff920e9e40f2e5436a	handwritten text line segmentation by shredding text into its lines	experimental tests;handwritten documents text line segmentation historical documents;handwritten document image;topology;image recognition;text line area;handwriting recognition;image segmentation;text line segmentation;local minima tracer;image segmentation strips text analysis image analysis pipelines informatics handwriting recognition image recognition text recognition educational technology;text analysis;topology document image processing handwritten character recognition image segmentation text analysis;left to right;trajectory;text line area handwritten text line segmentation image segmentation handwritten document image local minima tracer topological assumption;pipelines;pixel;document image processing;image analysis;informatics;historical documents;strips;handwritten documents;educational technology;text recognition;local minima;topological assumption;handwritten character recognition;handwritten text line segmentation	In this paper, we propose a novel technique to segment handwritten document images into text lines by shredding their surface with local minima tracers. Our approach is based on the topological assumption that for each text line, there exists a path from one side of the image to the other that traverses only one text line. We first blur the image and then use tracers to follow the white-most and black-most paths from left to right as well as from right to left in order to shred the image into text line areas. We experimentally tested the proposed methodology and got promising results comparable to state of the art text line segmentation techniques.	experiment;gaussian blur;maxima and minima;right-to-left;shredding (disassembling genomic data)	Anguelos Nicolaou;Basilios Gatos	2009	2009 10th International Conference on Document Analysis and Recognition	10.1109/ICDAR.2009.243	computer vision;strips;educational technology;image analysis;speech recognition;computer science;trajectory;maxima and minima;pattern recognition;pipeline transport;handwriting recognition;image segmentation;informatics;pixel	Vision	36.946262892816655	-66.32577610659206	110659
4c4c98e3f853338fa82035ce778c742d8fe8f331	image processing and reconstruction of cultured neuron skeletons	skeleton branch;image segmentation;image processing;280203;nova;book chapter;eskitis institute for drug discovery;faculty of science environment engineering and technology;grey and distance difference;neuron skeleton;080106;research repository;university of newcastle;journal article;neuron cell image;filtering window;skeleton reconstruction;pre2009 image processing;institutional repository;research online	One approach to investigating neural death is through systematic studies of the changing morphology of cultured brain neurons in response to cellular challenges. Image segmentation and neuron skeleton reconstruction methods developed to date to analyze such changes have been limited by the low contrast of cells. In this paper we present new algorithms that successfully circumvent these problems. The binary method is based on logical analysis of grey and distance difference of images. The spurious regions are detected and removed through use of a hierarchical window filter. The skeletons of binary cell images are extracted. The extension direction and connection points of broken cell skeletons are automatically determined, and broken neural skeletons are reconstructed. The spurious strokes are deleted based on cell prior knowledge. The reconstructed skeletons are processed furthermore by filling holes, smoothing and extracting new skeletons. The final constructed neuron skeletons are analyzed and calculated to find the length and morphology of skeleton branches automatically. The efficacy of the developed algorithms is demonstrated here through a test of cultured brain neurons from newborn mice.		Donggang Yu;Tuan D. Pham;Hong Yan;Jesse S. Jin;Suhuai Luo;Denis I. Crane	2008	Int. J. Hybrid Intell. Syst.	10.1007/978-3-642-33015-5_3	image processing;computer science;artificial intelligence;image segmentation;nova;computer graphics (images)	DB	38.142523020813094	-72.42022318707106	110883
5f9c3b25eaca97af3c86460d365a3dd485ecbf96	presentation attack detection for cadaver iris		This paper presents a deep-learning-based method for iris presentation attack detection (PAD) when iris images are obtained from deceased people. Post-mortem iris recognition, despite being a potentially useful method that could aid forensic identification, can also pose challenges when used inappropriately, i.e. utilizing a dead organ of a person in an unauthorized way. Our approach is based on the VGG-16 architecture fine-tuned with a database of 574 post-mortem, near-infrared iris images from the WarsawBioBase-PostMortem-Iris-v1 database, complemented by a dataset of 256 images of live irises, collected within the scope of this study. Experiments described in this paper show that our approach is able to correctly classify iris images as either representing a live or a dead eye in almost 99% of the trials, averaged over 20 subject-disjoint, train/test splits. We also show that the post-mortem iris detection accuracy increases as time since death elapses, and that we are able to construct a classification system with APCER=0%@BPCER≈1% (Attack Presentation and Bona Fide Presentation Classification Error Rates, respectively) when only post-mortem samples collected at least 16 hours post-mortem are considered. Since acquisitions of anteand post-mortem samples differ significantly, we applied countermeasures to minimize bias in our classification methodology caused by image properties that are not related to the PAD. This included using the same iris sensor in collection of anteand post-mortem samples, and analysis of class activation maps to ensure that discriminant iris regions utilized by our classifier are related to properties of the eye, and not to those of the acquisition protocol. This paper offers the first known to us PAD method in a postmortem setting, together with an explanation of the decisions made by the convolutional neural network. Along with the paper we offer source codes, weights of the trained network, and a dataset of live iris images to facilitate reproducibility and further research.	artificial neural network;authorization;cadaver;code;convolutional neural network;deep learning;discriminant;emoticon;experiment;gradient;iris recognition;liveness;map	Mateusz Trokielewicz;Adam Czajka;Piotr Maciejewicz	2018	CoRR		convolutional neural network;forensic identification;cadaver;artificial intelligence;acquisition protocol;computer science;pattern recognition;iris recognition;source code;classifier (linguistics)	ML	32.63083199230002	-76.93526812731348	111036
35371edd05655256cc1a0563664841812aa85a83	improving medical image retrieval through multi-descriptor similarity functions and association rules	fractals;cbir;medical image retrieval;measurement;multi descriptor similarity functions;sfpm;statistical analysis content based retrieval data mining image retrieval medical computing;association rules;data mining;magnetic resonance image;association rule mining;medical computing;feature vector;feature extraction measurement fractals association rules magnetic resonance imaging image retrieval;statistical analysis;association rule;feature extraction;magnetic resonance imaging;fractal theory;statistical fractal scaled product metric;content based image retrieval;similarity function;content based retrieval;fractal theory medical image retrieval content based image retrieval multi descriptor similarity functions association rules cbir statistical fractal scaled product metric sfpm;image retrieval;image similarity	Content-based image retrieval (CBIR) systems still face the problem of low precision of system results. To improve the precision of such systems, many image visual extractors have been developed and employed to represent the images. However, the usage of a large number of extractors and consequently, a large number of features, leads to the “dimensionality curse”, where the retrieval performance and the query accuracy diminish. In this paper, we propose a new method, called Statistical Fractal-scaled Product Metric (SFPM), to maximize the accuracy of CBIR systems and speedup similarity queries. The SFPM method combines association rule mining and the Fractal-scaled Product Metric (FPM) [4], to determine a reduced set of features and appropriate scale factors in multi-descriptor image similarity assessment. The FPM is an unsupervised method to determine a scale factor among features in multi-descriptor image similarity assessment based on the Fractal Theory. Experiments have shown that SFPM reduced the feature vector size in up to 65% and improved in up to 27% the query precision when comparing with the use of the FPM technique. The results show that the proposed method SFPM is effective in determining a reduced set of features and a near-optimal set of scale factors for the descriptors involved, and it is well-suited to improve the quality of content-based query in CBIR systems.	approximation algorithm;association rule learning;content-based image retrieval;curse of dimensionality;experiment;feature selection;feature vector;fractal;randomness extractor;similarity measure;speedup;unsupervised learning;visual descriptor	Renato Bueno;Marcela Xavier Ribeiro;Agma J. M. Traina;Caetano Traina	2010	2010 IEEE 23rd International Symposium on Computer-Based Medical Systems (CBMS)	10.1109/CBMS.2010.6042661	association rule learning;computer science;magnetic resonance imaging;machine learning;pattern recognition;data mining;information retrieval	DB	32.54772929467953	-71.35877311791506	111038
b0e385875a03fd5098dd2859db60615de10d298b	image processing algorithm to detect defects in optical fibers		This work proposes a system to detect visual defects in an optical fiber. Fibers of different types and with different simulated deformations were used, looking for an approximation of a real case of defect in an optical fiber. Some continuous fiber patterns were detected in images captured with a microscopic camera. The identification of these patterns was searched using different image processing techniques, such as edge detection, line detection and feature descriptors. In order to classify images of the fibers in good and defective ones, a fuzzy classifier was used. Experimental results of the algorithm are shown and is demonstrated that the proposed method helps to detect defects and classify optical fibers.	algorithm;image processing;optical fiber	Marcelo Mafalda;Daniel Welfer;Marco Antônio De Souza Leite Cuadros;Daniel Fernando Tello Gamarra	2018		10.1007/978-3-319-95312-0_21	optical fiber;fuzzy logic;image processing;fiber;algorithm;classifier (linguistics);visual defects;computer science;edge detection	ML	37.322593621168274	-68.57122158103114	111193
3835396e66faeba3b5eade797c04a3f67106957c	mri shoulder complex segmentation and classification		This paper deals with a segmentation (classification) problem which arises in the diagnostic and treatment of shoulder disorders. Classical techniques can be applied successfully to solve the binary problem but they do not provide a suitable method for the multiphase problem we consider. To this end we compare two different methods which have been applied successfully to other medical images modalities and structures. Our preliminary results suggest that a successful segmentation and classification has to be based on an hybrid method combining statistical and geometric information.	chan's algorithm;iterative method;medical imaging	Gabriela Pérez;Juan Francisco Garamendi;Raquel Montes Diez;Emanuele Schiavi	2008			guard (information security);computer vision;artificial intelligence;computer science;elbow;mri shoulder;wrist;segmentation	Vision	37.327262316514265	-79.30728105271845	111231
df4744a0fc9e7a83137b779a6b14d2beabab4b0b	knowledge leverage from contours to bounding boxes: a concise approach to annotation	concise annotation approach;object contour;knowledge leverage;true object contour;image segmentation problem;good tight segment;concise approach;multiple image segmentation;tight segment;distinctive tight segment;manual annotation;augmented knowledge	In the class based image segmentation problem, one of the major concerns is to provide large training data for learning complex graphical models. To alleviate the labeling effort, a concise annotation approach working on bounding boxes is introduced. The main idea is to leverage the knowledge learned from a few object contours for the inference of unknown contours in bounding boxes. To this end, we incorporate the bounding box prior into the concept of multiple image segmentations to generate a set of distinctive tight segments, with the condition that at least one tight segment approaching to the true object contour. A good tight segment is then selected via semi-supervised regression, which bears the augmented knowledge transferred from object contours to bounding boxes. The experimental results on the challenging Pascal VOC dataset corroborate that our new annotation method can potentially replace the manual annotations.	collision detection;experiment;graphical model;graphical user interface;image segmentation;minimum bounding box;national supercomputer centre in sweden;performance evaluation;prospective search;rendering (computer graphics);semi-supervised learning;semiconductor industry	Jie-Zhi Cheng;Feng-Ju Chang;Kuang-Jui Hsu;Yen-Yu Lin	2012		10.1007/978-3-642-37331-2_55	computer vision;bounding interval hierarchy;computer science;artificial intelligence;machine learning;data mining;bounding volume hierarchy	ML	29.812073640261737	-73.45633437990706	111395
c90c822631438ddfcc55ba229dd5d1d265f875ea	texture analysis for ulcer detection in capsule endoscopy images	support vector machines;multilayer perceptron;local binary pattern;texture features;image texture;texture analysis;curvelet transform;capsule endoscopy;small bowel;capsule endoscopy image;support vector machine;data validation;neural network	Capsule endoscopy (CE) has gradually seen its wide application in hospitals in the last few years because it can view the entire small bowel without invasiveness. However, CE produces too many images each time, thus causing a huge burden to physicians, so it is meaningful to help clinicians if we can employ computerized methods to diagnose. This paper presents a new texture extraction scheme for ulcer region discrimination in CE images. A new idea of curvelet based local binary pattern is proposed as textural features to distinguish ulcer regions from normal regions, which makes full use of curvelet transformation and local binary pattern. The proposed new textural features can capture multi-directional features and show robustness to illumination changes. Extensive classification experiments using multilayer perceptron neural network and support vector machines on our image data validate that it is promising to employ the proposed texture features to recognize ulcer regions in CE images.		Baopu Li;Max Q.-H. Meng	2009	Image Vision Comput.	10.1016/j.imavis.2008.12.003	support vector machine;computer vision;computer science;machine learning;pattern recognition;artificial neural network	Vision	34.21438267027235	-75.090465866176	111485
f07187a0ad74924d6acf80e314e52843330d055d	highly accurate recognition of printed korean characters through an improved two-stage classification method	coreano;caracter impreso;printed character;classification;system performance;korean;reconnaissance caractere;coreen;pattern recognition;reconnaissance forme;reseau neuronal;reconocimiento patron;caractere imprime;character recognition;clasificacion;red neuronal;reconocimiento caracter;neural network	Abstract   This paper presents a recognition system which obtains a recognition rate higher than 99% for the printed Korean characters of multifont and multisize. We recognize a given input by first identifying the character type of the input and then recognizing its constituent graphemes. In order to improve the performance we incorporated three new ideas in our system: the expansion of the subimage areas used by the grapheme classifiers, an algorithm to accurately segment the horizontal vowel’s subimage areas, and a validation process to evaluate the result of the type classifier. Through experiments we confirmed that our system performs well in a multi-font and multi-size environment and that those three ideas actually contributed to improve the performance significantly.	printing	Jin Soo Lee;Oh Jun Kwon;Sung Yang Bang	1999	Pattern Recognition	10.1016/S0031-3203(97)00126-X	speech recognition;computer science;artificial intelligence;machine learning;pattern recognition;computer performance;artificial neural network;korean	Vision	33.63195229861981	-67.26681161076701	111714
2c45825debb9614b8398cecee89a31457c34f170	detection and classification of microaneurysms using dtcwt and log gabor features in retinal images		Diabetic Retinopathy (DR) is one of the major causes of blindness in diabetic patients. Early detection is required to reduce the visual impairment causing damage to eye. Microaneurysms are the first clinical sign of diabetic retinopathy. Robust detection of microaneurysms in retinal fundus images is critical in developing automated system. In this paper we present a new technique for detection and localization of microaneurysms using Dual tree complex wavelet transform and log Gabor features. Retinal blood vessels are eliminated using minor and major axis properties and correlation is performed on images with the Gabor features to detect the microaneurysms. Feature vectors are extracted from candidate regions based on texture properties. Support vector machine classifier classifies the detected regions to determine the findings as microaneurysms or not. Accuracy of the algorithm is evaluated using the sensitivity and specificity parameters.	log gabor filter	Sujay Angadi;M. Ravishankar	2014		10.1007/978-3-319-12012-6_65	computer vision	Vision	36.06661868415989	-75.78428836310154	111733
c510eb971f001b934af820dd3bb068558715153d	automated detection of cells from immunohistochemically-stained tissues: application to ki-67 nuclei staining	tissues;blob detection;detection and tracking algorithms;computing systems;pathology	An automated cell nuclei detection algorithm is described to be used for the quantification of immunohistochemicallystained tissues. Detection and segmentation of positively stained cells and their separation from the background and negatively-stained cells is crucial for fast, accurate, consistent and objective analysis of pathology images. One of the major challenges is the identification, hence accurate counting of individual cells, when these cells form clusters. To identify individual cell nuclei within clusters, we propose a new cell nuclei detection method based on the well-known watershed segmentation, which can lead to under- or over-segmentation for this problem. Our algorithm handles oversegmentation by combining H-minima transformed watershed algorithm with a novel region merging technique. To handle under-segmentation problem, we develop a Laplacian-of-Gaussian (LoG) filtering based blob detection algorithm, which estimates the range of the scales from the image adaptively. An SVM classifier was trained in order to separate non-touching single cells and touching cell clusters with five features representing connected region properties such as eccentricity, area, perimeter, convex area and perimeter-to-area ratio. Classified touching cell clusters are segmented with the H-minima based watershed algorithm. The resulting over-segmented regions are improved with the merging algorithm. The remaining under-segmented cell clusters are convolved with LoG filters to detect the cells within them. Cell-by-cell nucleus detection performance is evaluated by comparing computer detections with cell locations manually marked by eight pathology residents. The sensitivity is 89% when the cells are marked as positive at least by one resident and it increases to 99% when the evaluated cells are marked by all eight residents. In comparison, the average reader sensitivity varies between 70% ± 18% and 95% ± 11%.© (2012) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.		Hatice Çinar Akakin;Hui Kong;Camille Elkins;Jessica Hemminger;Barrie Miller;Jin Ming;Elizabeth Plocharczyk;Rachel Roth;Mitchell Weinberg;Rebecca Ziegler;Gerard Lozanski;Metin Nafi Gürcan	2012		10.1117/12.911314	computer vision;blob detection;computer science;bioinformatics;machine learning	NLP	37.545615350636595	-75.94927204676132	111770
8e562bbe7cf24f7725484273183438b9b5e5ce37	diagnosis of broiler livers by classifying image patches		The manual health inspection are becoming the bottleneck at poultry processing plants. We present a computer vision method for automatic diagnosis of broiler livers. The non-rigid livers, of varying shape and sizes, are classified in patches by a convolutional neural network, outputting maps with probabilities of the three most common diseases. A Random Forest classifier combines the maps to a single diagnosis. The method classifies 77.6% livers correctly in a problem that is far from trivial.		Anders Jørgensen;Jens Fagertun;Thomas B. Moeslund	2017		10.1007/978-3-319-59126-1_31	convolutional neural network;entire liver;artificial intelligence;computer vision;computer science;random forest;pattern recognition;bottleneck;hyperspectral imaging	Vision	32.563359637487096	-75.82998701263806	111919
ddb6c32957e485d6e87018dc9827ec9a4c834976	automated detection of presence of mucus foci in airway diseases: preliminary results	high resolution;chronic obstructive pulmonary disease;ct scoring for cystic fibrosis;lung;airway diseases;optical inspection;mucoid impactions;visual inspection;assessment methods;positive predictive value;true positive;wall thickening;computing systems;false positive;diseases and disorders;scoring system	Chronic Obstructive Pulmonary Disease (COPD) is often characterized by partial or complete obstruction of airflow in the lungs. This can be due to airway wall thickening and retained secretions, resulting in foci of mucoid impactions. Although radiologists have proposed scoring systems to assess extent and severity of airway diseases from CT images, these scores are seldom used clinically due to impracticality. The high level of subjectivity from visual inspection and the sheer number of airways in the lungs mean that automation is critical in order to realize accurate scoring. In this work we assess the feasibility of including an automated mucus detection method in a clinical scoring system. Twenty high-resolution datasets of patients with mild to severe bronchiectasis were randomly selected, and used to test the ability of the computer to detect the presence or absence of mucus in each lobe (100 lobes in all). Two experienced radiologists independently scored the presence or absence of mucus in each lobe based on the visual assessment method recommended by Sheehan et al [1]. These results were compared with an automated method developed for mucus plug detection [2]. Results showed agreement between the two readers on 44% of the lobes for presence of mucus, 39% of lobes for absence of mucus, and discordant opinions on 17 lobes. For 61 lobes where 1 or both readers detected mucus, the computer sensitivity was 75.4%, the specificity was 69.2%, and the positive predictive value (PPV) was 79.3%. Six computer false positives were a-posteriori reviewed by the experts and reassessed as true positives, yielding results of 77.6% sensitivity, 81.8% for specificity, and 89.6% PPV.	acoustic lobing;ct pulmonary angiogram;ct scan;high-level programming language;image resolution;radiology;randomness;robertson–seymour theorem;sensitivity and specificity;visual inspection	Benjamin L. Odry;Atilla P. Kiraly;Carol L. Novak;David P. Naidich;Jane P. Ko;Myrna C. B. Godoy	2009		10.1117/12.811923	image resolution;type i and type ii errors;visual inspection	ML	34.26039052535516	-78.68985255224062	111972
cd6972676b3d7fee18b1680a28303a206bee15d4	unsupervised identification of clinically relevant clusters in routine imaging data		A key question in learning from clinical routine imaging data is whether we can identify coherent patterns that re-occur across a population, and at the same time are linked to clinically relevant patient parameters. Here, we present a feature learning and clustering approach that groups 3D imaging data based on visual features at corresponding anatomical regions extracted from clinical routine imaging data without any supervision. On a set of 7812 routine lung computed tomography volumes, we show that the clustering results in a grouping linked to terms in radiology reports which were not used for clustering. We evaluate different visual features in light of their ability to identify groups of images with consistent reported findings.	3d reconstruction;78xx;ct scan;cluster analysis;coherence (physics);feature learning;population;radiology;relevance;tomography;unsupervised learning	Johannes Hofmanninger;Markus Krenn;Markus Holzer;Thomas Schlegl;Helmut Prosch;Georg Langs	2016		10.1007/978-3-319-46720-7_23	computer science;latent dirichlet allocation;pattern recognition;computed tomography;artificial intelligence;cluster analysis;radiology report;population;feature learning	ML	30.071835109851246	-79.40494808230858	112272
53cc2e5c06fffca8b79add3d6d91a23fe19d61c0	discovering brain regions relevant to obsessive-compulsive disorder identification through bagging and transduction	transduction;machine learning;mri;voxel selection;obsessive compulsive disorder	In the present study we applied a multivariate feature selection method based on the analysis of the sign consistency of voxel weights across bagged linear Support Vector Machines (SVMs) with the aim of detecting brain regions relevant for the discrimination of subjects with obsessive-compulsive disorder (OCD, n=86) from healthy controls (n=86). Each participant underwent a structural magnetic resonance imaging (sMRI) examination that was pre-processed in Statistical Parametric Mapping (SPM8) using the standard pipeline of voxel-based morphometry (VBM) studies. Subsequently, we applied our multivariate feature selection algorithm, which also included an L2 norm regularization to account for the clustering nature of MRI data, and a transduction-based refinement to further control overfitting. Our approach proved to be superior to two state-of-the-art feature selection methods (i.e., mass-univariate t-Test selection and recursive feature elimination), since, following the application of transductive refinement, we obtained a lower test error rate of the final classifier. Importantly, the regions identified by our method have been previously reported to be altered in OCD patients in studies using traditional brain morphometry methods. By contrast, the discrimination patterns obtained with the t-Test and the recursive feature elimination approaches extended across fewer brain regions and included fewer voxels per cluster. These findings suggest that the feature selection method presented here provides a more comprehensive characterization of the disorder, thus yielding not only a superior identification of OCD patients on the basis of their brain anatomy, but also a discrimination map that incorporates most of the alterations previously described to be associated with the disorder.	anatomic structures;bootstrap aggregating;cluster analysis;compulsive personality disorder;excretory function;feature selection;magnetic resonance imaging;morphometric analysis;morphometrics;obsessive-compulsive disorder;overfitting;patients;recursion;refinement (computing);selection algorithm;sensor;support vector machine;transduction (machine learning);voxel;weight;statistical cluster	Emilio Parrado-Hernández;Vanessa Gómez-Verdejo;Manel Martínez-Ramón;John Shawe-Taylor;Pino Alonso;Jesús Pujol;José M. Menchón;Narcís Cardoner;Carles Soriano-Mas	2014	Medical image analysis	10.1016/j.media.2014.01.006	transduction;radiology;computer science;artificial intelligence;magnetic resonance imaging;machine learning;pattern recognition	ML	30.180132634895937	-78.50017066804116	112478
0f507955078fc2b808fbecd78f2f9fc6246b4d4c	automatic detection and segmentation of vascular structures in dermoscopy images using a novel vesselness measure based on pixel redness and tubularness	image segmentation;skin;independent component analysis;medical diagnostics;diseases and disorders;blood vessels	ABSTRACT Vascular structures are one of the most important features in the diagnosis and assessment of skin disorders. The presence and clinical appearance of vascular structures in skin lesions is a discriminating factor among different skin diseases. In this paper, we address the problem of segmentation of vascular patterns in dermoscopy images. Our proposed method is composed of three parts. First, based on biological properties of human skin, we decompose the skin to melanin and hemoglobin component using independent component analysis of skin color images. The relative quantities and pure color densities of each component were then estimated. Subsequently, we obtain three reference vectors of the mean RGB values for normal skin, pigmented skin and blood vessels from the hemoglobin component by averaging over 100000 pixels of each group outlined by an expert. Based on the Euclidean distance thresholding, we generate a mask image that extracts the red regions of the skin. Finally, Frangi measure was applied to the extracted red areas to segment the tubular structures. Finally, 2WVX¶VWKUHVKROGLQJ was applied to segment the vascular structures and get a binary vessel mask image. The algorithm was implemented on a set of 50 dermoscopy images. In order to evaluate the performance of our method, we have artificially extended some of the existing vessels in our dermoscopy data set and evaluated the performance of the algorithm to segment the newly added vessel pixels. A sensitivity of 95% and specificity of 87% were achieved.	pixel	Pegah Kharazmi;Harvey Lui;William V. Stoecker;Tim K. Lee	2015		10.1117/12.2082720	independent component analysis;computer vision;skin;image segmentation	Vision	36.184291912577734	-76.24723965009407	112564
a8bdb39b1a8d855f135733bb4814413479c2c8ad	a complementary method for automated detection of microaneurysms in fluorescein angiography fundus images to assess diabetic retinopathy	radon transform;computer aided diagnosis;fluorescein angiography;fundus images;microaneurysms;diabetic retinopathy	Early detection of microaneurysms (MAs), the first sign of Diabetic Retinopathy (DR), is an essential first step in automated detection of DR to prevent vision loss and blindness. This study presents a novel and different algorithm for automatic detection of MAs in fluorescein angiography (FA) fundus images, based on Radon transform (RT) and multi-overlapping windows. This project addresses a novel method, in detection of retinal land marks and lesions to diagnose the DR. At the first step, optic nerve head (ONH) was detected and masked. In preprocessing stage, top-hat transformation and averaging filter were applied to remove the background. In main processing section, firstly, we divided the whole preprocessed image into sub-images and then segmented and masked the vascular tree by applying RT in each sub-image. After detecting and masking retinal vessels and ONH, MAs were detected and numbered by using RT and appropriated thresholding. The results of the proposed method were evaluated on three different retinal images databases, the Mashhad Database with 120 FA fundus images, Second Local Database from Tehran with 50 FA retinal images and a part of Retinopathy Online Challenge (ROC) database with 22 images. Automated DR detection demonstrated a sensitivity and specificity of 94% and 75% for Mashhad database and 100% and 70% for the Second Local Database	algorithm;color gradient;computed tomography angiography;database;image quality;image registration;microsoft windows;optic nerve (gchq);preprocessor;sensitivity and specificity;sensor;thresholding (image processing)	Meysam Tavakoli;Reza Pourreza-Shahri;Hamid Reza Pourreza;Alireza Mehdizadeh;Touka Banaee;Mohammad Hosein Bahreini Toosi	2013	Pattern Recognition	10.1016/j.patcog.2013.03.011	computer vision;radon transform;mathematics	Vision	36.5672150846252	-75.61241473587317	112578
c2ce27f60d5c834d3d1cf8b096b8da3c71065a36	maximized inter-class weighted mean for fast and accurate mitosis cells detection in breast cancer histopathology images	breast cancer grading;histopathology image;maximized inter-class weighted mean;mitosis detection	Based on the Nottingham criteria, the number of mitosis cells in histopathological slides is an important factor in diagnosis and grading of breast cancer. For manual grading of mitosis cells, histopathology slides of the tissue are examined by pathologists at 40× magnification for each patient. This task is very difficult and time-consuming even for experts. In this paper, a fully automated method is presented for accurate detection of mitosis cells in histopathology slide images. First a method based on maximum-likelihood is employed for segmentation and extraction of mitosis cell. Then a novel Maximized Inter-class Weighted Mean (MIWM) method is proposed that aims at reducing the number of extracted non-mitosis candidates that results in reducing the false positive mitosis detection rate. Finally, segmented candidates are classified into mitosis and non-mitosis classes by using a support vector machine (SVM) classifier. Experimental results demonstrate a significant improvement in accuracy of mitosis cells detection in different grades of breast cancer histopathological images.	breast carcinoma;class;classification;extraction;google forms;histopathologic grade;histopathology;image segmentation;malignant neoplasm of breast;mammary neoplasms;mitosis;patients;slide (glass microscope);support vector machine;biologic segmentation	Ramin Nateghi;Habibollah Danyali;Mohammad Sadegh Helfroush	2017	Journal of Medical Systems	10.1007/s10916-017-0773-9	breast cancer;mitosis;computer vision;histopathology;artificial intelligence;medicine;weighted arithmetic mean	ML	35.52084640006992	-76.19946139505417	112720
2a588ab10705ab5a1c6516029a179bc3b12d9dd5	mr enterography image fusion in small bowel analysis		In the last years, the use of magnetic resonance enterography to evaluate inflammatory bowel diseases has become a mainstay, thanks to its non-ionizing nature, and to the advent of faster sequences that are less sensitive to motion artifacts. In this work we present a novel multimodal image merging framework able to combine the detailed structural information, and the small bowel motility provided by the SSFSE and the FIESTA sequence, respectively. Once the breathing motion has been eliminated via non-rigid B-spline based registration, we create a personalized peristaltic activity map from the FIESTA sequence using optical flow analysis. Defining a new multimodal similarity measure, the two nearest sets of FIESTA frames are projected over the SSFSE slices, leading to a new image that provides specific structural and functional information of the patient simultaneously. The practical utility of these new images has been successfully evaluated in a preliminary study with 13 cases, showing its potential for planning small bowel interventions, and patients’ diagnosis and follow up.	b-spline;data-flow analysis;image fusion;multimodal interaction;optical flow;personalization;resonance;similarity measure	Juan J. Cerrolaza;Nabile M. Safdar;Raymond W. Sze;Marius George Linguraru	2013		10.1007/978-3-319-05666-1_7	simulation;pathology;engineering;biological engineering	Vision	38.93762301429872	-79.98992863035525	112742
c9a391f8cd3f498149581430fb11861e2e3f3285	preprocesamiento de imágenes dermatoscopicas para extracción de características		Perform an image preprocessing for its conditioning and feature extraction needs a work scheme where the elements, that affects the region of interest and processing, are removed of the image. There is a dermoscopic image processing and shape analysis approach, with getting data that characterizes the image and use this information for clinic diagnosis. 200 dermoscopic images were used in similar analysis between the images with processing and without processing; a 0.96±0.02 similar measure was obtained showing that an image significant damage is not present for next processing stages. A segmentation error of 30.12±19.19% was obtained because a comparative between subjective and objective segmentations where the medic classifies regions of skin that no belongs to the lesion but are contained in that.	feature extraction;image processing;preprocessor;region of interest;shape analysis (digital geometry)	Miguel A. Castillo Martínez;Francisco J. Gallegos Funes;Alberto Rosales-Silva;Rosa I. Ramos-Arredondo	2016	Research in Computing Science			Graphics	36.00177127125512	-75.51634185395626	113129
6d2cbb109f626cf3daf1fbeab48ab0a3f2f2590f	a novel method for automatic hard exudates detection in color retinal images	eye;image segmentation;support vector machines;image color analysis retina abstracts;histogram segmentation;image classification;support vector machines diseases eye feature extraction image classification image colour analysis image reconstruction image segmentation medical image processing;svm diabetic retinopathy hard exudates histogram segmentation morphological reconstruction;morphological reconstruction;public diaretdb1 database automatic hard exudates detection color retinal images diabetic retinopathy dr blindness early clinical signs automatic he detection histogram segmentation morphological reconstruction supervised support vector machine svm candidate regions classification;image color analysis;image colour analysis;abstracts;hard exudates;retina;feature extraction;image reconstruction;medical image processing;diabetic retinopathy;diseases;svm	Diabetic Retinopathy (DR) is one of the major causes of blindness, and Hard Exudates (HEs) which are common and early clinical signs of DR. This paper presented a novel method to automatically detect HEs in color retinal images. We first extract HEs candidate regions by combining histogram segmentation with morphological reconstruction. Next, we define 44 significant features for each candidate region. A supervised support vector machine (SVM) is finally trained based on these features to classify the candidate regions for HEs. We evaluate the proposed method on the public DIARETDB1 database and achieve an sensitivity of 94.7% and an positive predictive value of 90.0%. Experimental results show that our method can produce reliable detection of HEs.	image segmentation;support vector machine	Xiang Chen;Wei Bu;Xiangqian Wu;Baisheng Dai;Yan Teng	2012	2012 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2012.6359522	support vector machine;computer vision;speech recognition;computer science;machine learning;pattern recognition	Robotics	36.32583935782406	-75.35899794757931	113223
d1b170150599fc5b011b8bc503a9063635f4bbae	blood vessels segmentation in non-mydriatic images using wavelets and statistical classi.ers	image segmentation;noise filtering blood vessels segmentation optic fundus nonmydriatic image statistical classifier pixel classification pattern recognition technique feature vector continuous wavelet transform morlet transform;pixel classification;image classification;blood vessel;wavelet transforms;feature vector;image colour analysis;medical image processing;blood vessels biomedical imaging image segmentation optical filters image analysis pixel continuous wavelet transforms filtering optical noise pattern analysis;pattern recognition;health workers;image denoising;image thinning;blood vessels;pattern recognition medical image processing image classification image thinning image segmentation image colour analysis image denoising blood vessels wavelet transforms	This work describes a new framework for automatic analysis of optic fundus non-mydriatic images, focusing on the segmentation of the blood vessels by using pixel classification based on pattern recognition techniques. Each pixel is represented by a feature vector composed of color information and measurements at different scales taken from the continuous wavelet (Morlet) transform as well as from mean and order filtering applied to the green channel. The major benefit resulting from the wavelet application to the optic fundus images is its multiscale analysing capability in tuning to specific frequencies, thus allowing noise filtering and blood vessel enhancement in a single step. Supervised classifiers are then applied to label each pixel as either a vessel or a non-vessel . Two different strategies to select the traning set have been devised: (1) the blood vessels of a sample image are completely drawn by hand, leading to a labeled image (i.e. vessels × non-vessel pixels) which is used to train the classifier, to be applied to other images; (2) the vessels located in a given small portion of the target image are drawn by hand and the remaining fundus image is segmented by a classifier trained using the hand-drawn portion to define the training set. The latter strategy is particularly suitable for the implementation of a semi-automated software to be used by health workers in order to avoid the need of setting imaging parameters such as thresholds. Both strategies have been extensively assessed and several successful experimental results using real-case images have been obtained.	channel (digital image);continuous wavelet;feature vector;pattern recognition;pixel;semiconductor industry;supervised learning;test set	Jorge J. G. Leandro;João V. B. Soares;Roberto Marcondes Cesar Junior;Herbert F. Jelinek	2003		10.1109/SIBGRA.2003.1241018	computer vision;speech recognition;computer science;pattern recognition	Vision	37.788974561402455	-74.88219293093839	113259
3d5f86e96ae47803984b2428b882b8d2095e2474	automated detection of changes in sequential color ocular fundus images	fond oeil;analisis sensibilidad;automatic system;individual specificity;diagnostico;hombre;specificite individuelle;metodo secuencial;sequential method;variations;sistema automatico;side effect;fondo ojo;sensitivity analysis;human;fundus of the eye;tecnica;systeme automatique;methode sequentielle;analyse sensibilite;variacion;variation;imagen color;diagnosis;especificidad individual;early detection;technique;image couleur;diseases and disorders;color image;homme;diagnostic	A recent trend is the automatic screening of color ocular fundus images. The examination of such images is used in the early detection of several adult diseases such as hypertension and diabetes. Since this type of examination is easier than CT, costs less, and has no harmful side effects, it will become a routine medical examination. Normal ocular fundus images are found in more than 90% of all people. To deal with the increasing number of such images, this paper proposes a new approach to process them automatically and accurately. Our approach, based on individual comparison, identifies changes in sequential images: a previously diagnosed normal reference image is compared to a non-diagnosed image. This paper presents a new approach for measuring changes in sequential color ocular fundus images and presents test results that prove its detection efficiency. Two processes that are required are registration and the detection of color differences in the two images. First, the images are registered based on the individual's ocular fundus structure. Second, the images are divided into blocks and for each pair of blocks, the chromaticity and luminosity are extracted. This block-wise division offsets the effect of environmental variations which extend over much larger areas than the blocks. If one block diverges sufficiently from its reference, it signifies a change in the block. The initial screening results, 350 image pairs, showed that 86% of the pairs (50 abnormal and 300 normal image pairs) had no significant difference and were successfully detected as normal with no false negatives. This approach suits the processing of image pairs where there is a need to detect small changes accurately regardless of environmental changes. Prior to clinical use, the proposed approach must be more extensively evaluated using a wide sample.	frame rate control	Satoshi Sakuma;Tadashi Nakanishi;Yasuko Takahashi;Yuichi Fujino;Tetsuro Tsubouchi;Norimasa Nakanishi	1998		10.1117/12.310868	computer vision;geography;optics;cartography	Vision	38.133041850041856	-76.21380040228965	113416
ff62fa665b4ae75c7faf7cb33198c8c43f396b06	bleeding detection in wireless capsule endoscopy based on color features from histogram probability	object detection content based retrieval endoscopes feature extraction image classification image colour analysis image retrieval medical image processing;image classification;classification accuracy bleeding detection wireless capsule endoscopy color features histogram probability capsule endoscopy images color feature extraction image regions standard deviation mean calculation skew rgb planes rgb color space content based retrieval system pathology images capsule endoscopic images;image colour analysis;feature extraction;medical image processing;endoscopes;image color analysis hemorrhaging accuracy endoscopes feature extraction histograms support vector machine classification;content based retrieval;wireless capsule endoscopy bleeding detection histogram probability neural networks;object detection;image retrieval	This paper presents a novel technique for detecting bleeding regions in capsule endoscopy images. The proposed algorithm extracts color features from image-regions by calculating mean, standard deviation, skew and energy from the first order histogram of the RGB planes separately. Through the use of RGB color space, three times more number of features can be obtained than while using a grayscale image. Such color features have been used in content based retrieval system in pathology images. However, in spite of simplicity and ease of calculation, these features have not yet been studied in the classification of bleeding and non-bleeding regions in capsule endoscopic images. This paper studies the feasibility of using these features by assessing all possible feature subsets through the use of classification accuracy. The proposed algorithm could obtain classification accuracy up to 89%.	algorithm;color space;grayscale;sensor	Sonu Sainju;Francis Minhthang Bui;Khan A. Wahid	2013	2013 26th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2013.6567779	color histogram;computer vision;contextual image classification;feature detection;color image;feature extraction;image retrieval;computer science;machine learning;pattern recognition;histogram equalization;feature;information retrieval	Vision	36.35974240635711	-73.87270657025182	113546
f4df04df283e0583501be0136eca92ee497ccf56	less is more: simultaneous view classification and landmark detection for abdominal ultrasound images		An abdominal ultrasound examination, which is the most common ultrasound examination, requires substantial manual efforts to acquire standard abdominal organ views, annotate the views in texts, and record clinically relevant organ measurements. Hence, automatic view classification and landmark detection of the organs can be instrumental to streamline the examination workflow. However, this is a challenging problem given not only the inherent difficulties from the ultrasound modality, e.g., low contrast and large variations, but also the heterogeneity across tasks, i.e., one classification task for all views, and then one landmark detection task for each relevant view. While convolutional neural networks (CNN) have demonstrated more promising outcomes on ultrasound image analytics than traditional machine learning approaches, it becomes impractical to deploy multiple networks (one for each task) due to the limited computational and memory resources on most existing ultrasound scanners. To overcome such limits, we propose a multi-task learning framework to handle all the tasks by a single network. This network is integrated to perform view classification and landmark detection simultaneously; it is also equipped with global convolutional kernels, coordinate constraints, and a conditional adversarial module to leverage the performances. In an experimental study based on 187,219 ultrasound images, with the proposed simplified approach we achieve (1) view classification accuracy better than the agreement between two clinical experts and (2) landmark-based measurement errors on par with inter-user variability. The multi-task approach also benefits from sharing the feature extraction during the training process across all tasks and, as a result, outperforms the approaches that address each task individually.	adobe streamline;artificial neural network;computer multitasking;convolutional neural network;experiment;feature extraction;heart rate variability;machine learning;medical ultrasound;modality (human–computer interaction);multi-task learning;performance	Zhoubing Xu;Yuankai Huo;Jin Hyeong Park;Bennett A. Landman;Andy Milkowski;Sasa Grbic;Shaohua Kevin Zhou	2018		10.1007/978-3-030-00934-2_79	machine learning;artificial intelligence;convolutional neural network;computer vision;computer science;feature extraction;landmark;ultrasound;workflow;organ measurements;analytics	ML	29.62954463935532	-76.04224908145657	113717
64c4655d72eef1ab37d8dac5bd051a2f25f20e2e	a novel deep learning framework on brain functional networks for early mci diagnosis		Although alternations of brain functional networks (BFNs) derived from resting-state functional magnetic resonance imaging (rs-fMRI) have been considered as promising biomarkers for early Alzheimer’s disease (AD) diagnosis, it is still challenging to perform individualized diagnosis, especially at the very early stage of preclinical stage of AD, i.e., early mild cognitive impairment (eMCI). Recently, convolutional neural networks (CNNs) show powerful ability in computer vision and image analysis applications, but there is still a gap for directly applying CNNs to rs-fMRI-based disease diagnosis. In this paper, we propose a novel multiple-BFN-based 3D CNN framework that can automatically and deeply learn complex, high-level, hierarchical diagnostic features from various independent component analysis-derived BFNs. More importantly, the embedded features of different BFNs could comprehensively support each other towards a more accurate eMCI diagnosis in a unified model. The performance of the proposed method is validated by a large-sample, multisite, rigorously controlled publicly accessible dataset. The proposed framework can also be conveniently and straightforwardly applied to individualized diagnosis of various neurological and psychiatric diseases.	deep learning	Tae-Eui Kam;Han Zhang;Dinggang Shen	2018		10.1007/978-3-030-00931-1_34	pattern recognition;convolutional neural network;computer science;deep learning;functional magnetic resonance imaging;artificial intelligence;cognition	ML	29.8059705576233	-76.66704913640139	113721
13567a4460294d70d9cd444c5e44050ddb7186c2	lung nodule detection using eye-tracking	decision support system eye tracking feature selection image processing image region analysis;eye;probability;image processing;indexing terms;lung;support system;decision support system;machine learning;medical image processing;decision support systems;computerised tomography;lungs computed tomography cancer data mining biomedical imaging medical diagnostic imaging decision support systems image analysis keyboards telecommunications;visual features;feature selection;eye tracking;image region analysis eye tracking decision support system ct lung nodule detection machine learning salient region weighted probability function;image region analysis;object detection;probability computerised tomography decision support systems eye lung medical image processing object detection	This paper describes a decision support system for determining salient features for CT lung nodule detection using an eye-tracking based machine learning technique. The method first analyses the scan paths of expert radiologists during normal examination. The underlying features are then used to highlight salient regions that may be of diagnostic relevance by merging visual features learned from different experts with a weighted probability function. The framework has been evaluated using data from CT lung nodule examination and the results demonstrate the potential clinical value of the proposed technique, which can also be generalized to other diagnostic applications.	decision support system;eye tracking;machine learning;radiology;relevance	Michela Antonelli;Guang-Zhong Yang	2007	2007 IEEE International Conference on Image Processing	10.1109/ICIP.2007.4379191	computer vision;simulation;index term;decision support system;eye tracking;computer science;machine learning;pattern recognition;probability	Robotics	35.926372963160496	-76.94759499566828	113901
040227edec43ec5d84a88c5b8e27994d10ab2136	retinal vessel segmentation via multiscaled deep-guidance		Retinal vessel segmentation is a fundamental and crucial step to develop a computer-aided diagnosis (CAD) system for retinal images. Retinal vessels appear as multiscaled tubular structures that are variant in size, length, and intensity. Due to these vascular properties, it is difficult for prior works to extract tiny vessels, especially when ophthalmic diseases exist. In this paper, we propose a multiscaled deeply-guided neural network, which can fully exploit the underlying multiscaled property of retinal vessels to address this problem. Our network is based on an encoder-decoder architecture which performs deep supervision to guide the training of features in layers of different scales, meanwhile it fuses feature maps in consecutive scaled layer via skip-connections. Besides, a residual-based boundary refinement module is adopted to refine vessel boundaries. We evaluate our method on two public databases for retinal vessel segmentation. Experimental results show that our method can achieve better performance than the other five methods, including three state-of-the-art deep-learning based methods.		Rui Xu;Guiliang Jiang;Xinchen Ye;Yen-Wei Chen	2018		10.1007/978-3-030-00767-6_15	residual;computer vision;computer science;artificial intelligence;architecture;artificial neural network;exploit;retinal;pattern recognition;segmentation	Vision	31.39736191210323	-75.17704702212127	114090
fa3bab181ce0ba445d89ea1aeca4ca1f22346ca2	analyzing training information from random forests for improved image segmentation	graph cut algorithms training information analysis medical image segmentation random forest rf classifiers learning discriminative features graph cut segmentation mrf framework curvature information texture information intensity information;graph theory;medical image processing graph theory image texture learning artificial intelligence;image texture;medical image processing;image segmentation training context radio frequency feature extraction accuracy vegetation;context random forests training information feature selection graph cut segmentation probability maps supervoxels;learning artificial intelligence	Labeled training data are used for challenging medical image segmentation problems to learn different characteristics of the relevant domain. In this paper, we examine random forest (RF) classifiers, their learned knowledge during training and ways to exploit it for improved image segmentation. Apart from learning discriminative features, RFs also quantify their importance in classification. Feature importance is used to design a feature selection strategy critical for high segmentation and classification accuracy, and also to design a smoothness cost in a second-order MRF framework for graph cut segmentation. The cost function combines the contribution of different image features like intensity, texture, and curvature information. Experimental results on medical images show that this strategy leads to better segmentation accuracy than conventional graph cut algorithms that use only intensity information in the smoothness cost.	adult fanconi syndrome;algorithm;cut (graph theory);feature selection;forests;generalization (psychology);graph - visual representation;graph cuts in computer vision;hoc (programming language);image segmentation;loss function;markov random field;medical image;radio frequency;random forest;segmentation action;texture mapping;tracer;biologic segmentation	D. Mahapatra	2014	IEEE Transactions on Image Processing	10.1109/TIP.2014.2305073	image texture;computer vision;computer science;graph theory;machine learning;segmentation-based object categorization;pattern recognition;mathematics;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation;connected-component labeling	Vision	37.776640450366585	-73.8008583793204	114322
aba32163e972e0f5b50ea0fe6ce26b2e93179dc2	tumor detection in automated breast ultrasound using 3-d cnn and prioritized candidate aggregation		Automated whole breast ultrasound (ABUS) has been widely used as a screening modality for examination of breast abnormalities. Reviewing hundreds of slices produced by ABUS, however, is time consuming. Therefore, in this paper, a fast and effective computer-aided detection system based on 3-D convolutional neural networks (CNNs) and prioritized candidate aggregation is proposed to accelerate this reviewing. First, an efficient sliding window method is used to extract volumes of interest (VOIs). Then, each VOI is estimated the tumor probability with a 3-D CNN, and VOIs with higher estimated probability are selected as tumor candidates. Since the candidates may overlap each other, a novel scheme is designed to aggregate the overlapped candidates. During the aggregation, candidates are prioritized based on estimated tumor probability to alleviate over-aggregation issue. The relationship between the sizes of VOI and target tumor is optimally exploited to effectively perform each stage of our detection algorithm. On evaluation with a test set of 171 tumors, our method achieved sensitivities of 95% (162/171), 90% (154/171), 85% (145/171), and 80% (137/171) with 14.03, 6.92, 4.91, and 3.62 false positives per patient (with six passes), respectively. In summary, our method is more general and much faster than preliminary works and demonstrates promising results.		Tsung-Chen Chiang;Yao-Sian Huang;Rong-Tai Chen;Chiun-Sheng Huang;Ruey-Feng Chang	2018	IEEE Transactions on Medical Imaging	10.1109/TMI.2018.2860257	convolutional neural network;breast cancer;computer vision;sliding window protocol;artificial intelligence;mathematics;feature extraction;automated whole-breast ultrasound;false positive paradox;test set;breast ultrasound	Vision	32.112858032017584	-75.89054080942212	114373
d42f54906a8db544d7d0374c28d0f18575f927e4	a blind stereoscopic image quality evaluator with segmented stacked autoencoders considering the whole visual perception route		Most of the current blind stereoscopic image quality assessment (SIQA) algorithms cannot show reliable accuracy. One reason is that they do not have the deep architectures and the other reason is that they are designed on the relatively weak biological basis, compared with the findings on the human visual system. In this paper, we propose a Deep Edge and COlor Signal INtegrity Evaluator (DECOSINE) based on the whole visual perception route from eyes to the frontal lobe, and especially focus on the edge and color signal processing in retinal ganglion cells and lateral geniculate nucleus. Furthermore, to model the complex and deep structure of the visual cortex, segmented stacked auto-encoder (S-SAE) is used, which has not utilized for SIQA before. The utilization of the S-SAE complements the weakness of deep learning-based SIQA metrics that require a very long training time. Experiments are conducted on popular SIQA databases, and the superiority of DECOSINE in terms of prediction accuracy and monotonicity is proved. The experimental results show that our model about the whole visual perception route and utilization of S-SAE are effective for SIQA.	architecture as topic;body dysmorphic disorders;cdisc sdtm evaluator terminology;cell nucleus;cerebral cortex;complement system proteins;databases;encoder device component;eye;ganglion cell;geniculate body structure;large;movies;name;published database;retina;retinal ganglion cells;sumo activating enzyme complex;serious adverse event report;vision;visual perception;visual evoked cortical potential;visually impaired persons;algorithm;frontal lobe;lateral geniculate complex	Jiachen Yang;Kyohoon Sim;Xinbo Gao;Wen Lu;Qinggang Meng;Baihua Li	2018	IEEE Transactions on Image Processing	10.1109/TIP.2018.2878283	computer vision;image quality;stereoscopy;feature extraction;deep learning;mathematics;visual cortex;human visual system model;artificial intelligence;visual perception;retinal ganglion;pattern recognition	Visualization	26.030260698565055	-74.34733038603939	114460
dde79a336abf6be06cdaf8c4348b894b93bcae7b	the application of fuzzy reasoning and biclustering in ultrasound breast tumor classification		The breast tumor is a common disease for females. In the paper, we designed a computer-aided diagnosis (CAD) method for breast tumor which employed the biclustering algorithm and fuzzy inference. The specialist of Sun Yat-sen University helped us collect 500 breast tumor cases. The BI-RADS feature scoring standard was utilized to extract the useful information from ultrasound images. Compared with previous method, the diagnosis process of the proposed method is more easy to be understood. Meanwhile, the performance of the method in this paper is not restricted by the type of image source. The experiment shows that the performance of our method exceeded the previous method which also employed the BI-RADS information in accuracy, positive predictive value (PPV), negative predictive value (NVP), and sensitivity. According to the experiment, the average accuracy achieves 88. S7%, PPV is 86.45%, NVP is 94.24%, specificity reaches 76.55% and sensitivity is 96.85%. The result means that the method in this paper can distinguish the malignant breast tumor precisely.		Fan Zhang;Qinghua Huang;Xuelong Li	2018	2018 3rd International Conference on Advanced Robotics and Mechatronics (ICARM)	10.1109/ICARM.2018.8610696	fuzzy logic;cad;biclustering;artificial intelligence;malignant breast tumor;ultrasound;ultrasound breast;inference;computer science;pattern recognition	Robotics	34.24268692519156	-77.57129327318074	114647
5ef5a0e49393525f7c98db13a00519c5f231c6ed	medical image classification via 2d color feature based covariance descriptors		In these notes we present an image classification method which has been submitted to the ImageCLEF 2015 Medical Classification challenge. The aim is to classify images from 30 heterogeneous classes ranging from diagnose images coming from different acquisition techniques, to various biomedical publication illustrations. The presented work is intended to be a proof of concept of how our method, which uses only visual information, performs in the modelling of such image classes. Our approach uses 1 and 2 order color features obtained at a whole image level. These features are considered as samples of a multidimensional statistical distribution, and a distinctive signature of the represented image can be built in the form of a Covariance-matrix based descriptor. The Riemannian manifold structure of such descriptors can be exploited in order to formulate an image classification methodology. Despite the challenging task due to unbalanced classes and image homogeneity, the obtained results in the task place our method on the top of the most accurate ones using purely visual features. This asserts the feasibility of our methodology and proves that its performance can be on par with other methods which use also complementary textual features for complex image retrieval.	algorithmic efficiency;benchmark (computing);binary file descriptor library;color;computation;computer vision;high- and low-level;image retrieval;sparse approximation;sparse matrix;unbalanced circuit	Pol Cirujeda;Xavier Binefa	2015			riemannian manifold;homogeneity (statistics);proof of concept;ranging;image retrieval;feature (computer vision);computer vision;contextual image classification;artificial intelligence;covariance;computer science;pattern recognition	Vision	32.40469532468808	-71.59095059713556	114925
ac0f9d3908bf476cb518fc41eb7fc6b0170fb262	character stroke extraction based on b-spline curve matching by constrained alternating optimization	chinese character;constrained alternating optimization;document rec;character stroke extraction;technical advance;b-spline curve matching;key technical development;handwriting recognition	This paper proposes a character stroke extraction method for handwriting recognition based on B-spline curve matching. In our method, a character is modeled as a set of B-splines, each of which represents a character stroke. Stroke extraction is accomplished through matching candidate strokes in the skeleton of the input character image with B-splines in the character model. We discussed the character structure modeling, the principal curve based image skeletonization, and the constrained alternating optimization algorithm for affine-invariant B-spline curve matching. With the use of the proposed stroke extraction method, different types of characters can be reliably processed in a common way. The experimental results on data of handwritten numerals, handwritten English letters, and handwritten Chinese characters show the effectiveness of the proposed method.	algorithm;b-spline;handwriting recognition;mathematical optimization;spline (mathematics)	Xin Liu;Y. Jia	2007	Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)	10.1109/ICDAR.2007.78	speech recognition;computer science;machine learning;pattern recognition;handwriting recognition	Robotics	33.13937578502921	-66.39602333919999	115148
5e10a999925907c8018a10a338a3734e111c6c70	deep mri brain extraction: a 3d convolutional neural network for skull stripping	brain extraction;brain mask;convolutional networks;deep learning;mri;skull stripping	Brain extraction from magnetic resonance imaging (MRI) is crucial for many neuroimaging workflows. Current methods demonstrate good results on non-enhanced T1-weighted images, but struggle when confronted with other modalities and pathologically altered tissue. In this paper we present a 3D convolutional deep learning architecture to address these shortcomings. In contrast to existing methods, we are not limited to non-enhanced T1w images. When trained appropriately, our approach handles an arbitrary number of modalities including contrast-enhanced scans. Its applicability to MRI data, comprising four channels: non-enhanced and contrast-enhanced T1w, T2w and FLAIR contrasts, is demonstrated on a challenging clinical data set containing brain tumors (N=53), where our approach significantly outperforms six commonly used tools with a mean Dice score of 95.19. Further, the proposed method at least matches state-of-the-art performance as demonstrated on three publicly available data sets: IBSR, LPBA40 and OASIS, totaling N=135 volumes. For the IBSR (96.32) and LPBA40 (96.96) data set the convolutional neuronal network (CNN) obtains the highest average Dice scores, albeit not being significantly different from the second best performing method. For the OASIS data the second best Dice (95.02) results are achieved, with no statistical difference in comparison to the best performing tool. For all data sets the highest average specificity measures are evaluated, whereas the sensitivity displays about average results. Adjusting the cut-off threshold for generating the binary masks from the CNN's probability output can be used to increase the sensitivity of the method. Of course, this comes at the cost of a decreased specificity and has to be decided application specific. Using an optimized GPU implementation predictions can be achieved in less than one minute. The proposed method may prove useful for large-scale studies and clinical trials.	addresses (publication format);artificial neural network;biological neural networks;brain neoplasms;convolutional neural network;deep learning;fluid attenuated inversion recovery;graphics processing unit;magnetic resonance imaging;masks;neuroimaging;norm (social);patients;sensitivity and specificity	Jens Kleesiek;Gregor Urban;Alexander Hubert;Daniel Schwarz;Klaus H. Maier-Hein;Martin Bendszus;Armin Biller	2016	NeuroImage	10.1016/j.neuroimage.2016.01.024	simulation;computer science;artificial intelligence;data mining;statistics	ML	31.19547176155223	-76.18497027975712	115557
c2513a741abca4cd52246ba356c77bdee3ddc2b0	high intraocular pressure detection from frontal eye images: a machine learning based approach		This paper presents a novel framework to detect the status of intraocular pressure (normal/high) using solely frontal eye image analysis. The framework is based on machine learning approaches to extract six features from frontal eye images. These features include Pupil/Iris ratio, red area percentage, mean redness level of the sclera, and three novel features from the sclera contour (angle, area and distance). Four hundred frontal eye images were used as the image database. The images were taken and annotated by ophthalmologists at Princess Basma Hospital. The proposed framework is fully automated and once the six features were extracted, two classifiers (decision tree and support vector machine) were applied to obtain the status of the eye in terms of eye pressure. The overall accuracy of the proposed framework is 95.5% using the decision tree classifier.	decision tree;erythema;extraction;image analysis;image processing;industrial and organizational psychology;interoperability;machine learning;patients;risk assessment;sclera;support vector machine;support vector machine	Mohammad Aloudat;Miad Faezipour;Ahmed El-Sayed	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8513645	sclera;support vector machine;computer vision;intraocular pressure;decision tree;high intraocular pressure;pupil;feature extraction;decision tree learning;artificial intelligence;machine learning;computer science	Robotics	35.421938188140686	-75.61354316077565	115841
c54e822698327defa8c82c2893830010c0d1d7cf	an assistive annotation system for retinal images	manuals;design automation;medical image processing biomedical optical imaging eye;lesions retina biomedical imaging design automation diabetes manuals image analysis;diabetes;biomedical imaging;assistive annotation system image level annotations dark lesion annotation visual assessment lesion level annotation diaretdb1 dataset bright lesion annotation manual annotation process computer assisted diagnostic algorithm retinal images;lesions;retina;image analysis;gmp groundtruth annotation color fundus images assistive annotation	Annotated data is critical for the development of many computer assisted diagnostic (CAD) algorithms. The process of manual annotation is very strenuous, time-consuming and an expensive component in CAD development. In this paper, we propose the idea of an interactive Assistive Annotation System (AAS) aimed at helping annotators by automatically marking possible regions of interest for further refinement by an annotator. We propose an unsupervised, biologically inspired method for bright lesion annotation. The performance of the proposed system has been evaluated against regionlevel ground truth in DiaretDB1 dataset and was found to have a sensitivity of 60% at 7 false positives per image. Preliminary testing was also done on public datasets which do not provide any lesion level annotations. A visual assessment of the obtained results affirm a good agreement with lesions visible in images. The system with a simple modification is shown to have the potential to handle dark lesion annotation, which is a significantly more challenging problem. Thus, the proposed system is a good starting point for exploring the AAS idea for retinal images. Such systems can help extend the use of many existing datasets by enriching the image-level annotations with localised information.	algorithm;assistive technology;computer-aided design;ground truth;internationalization and localization;item unique identification;refinement (computing);region of interest;unsupervised learning	Ujjwal;Arunava Chakravarty;Jayanthi Sivaswamy	2015	2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2015.7164163	computer vision;image analysis;radiology;image retrieval;computer science;bioinformatics;automatic image annotation;information retrieval	Vision	32.65088273229732	-75.21541537317434	116133
db65d1231ac1248cbc4d659643b255cc1d7c6dce	multi-class lesion diagnosis with pixel-wise classification network		Lesion diagnosis of skin lesions is a very challenging task due to high inter-class similarities and intra-class variations in terms of color, size, site and appearance among different skin lesions. With the emergence of computer vision especially deep learning algorithms, lesion diagnosis is made possible using these algorithms trained on dermoscopic images. Usually, deep classification networks are used for the lesion diagnosis to determine different types of skin lesions. In this work, we used pixel-wise classification network to provide lesion diagnosis rather than classification network. We propose to use DeeplabV3+ for multiclass lesion diagnosis in dermoscopic images of Task 3 of ISIC Challenge 2018. We used the various post-processing methods with DeeplabV3+ to determine the lesion diagnosis in this challenge and submitted the test results.	algorithm;color;computer vision;deep learning;emergence;machine learning;pixel;video post-processing	Manu Goyal;Jiahua Ng;Moi Hoon Yap	2018	CoRR		lesion;computer science;deep learning;pixel;artificial intelligence;pattern recognition	AI	32.45028680024649	-75.21083641531834	116255
5d78c88b0208b45780e4d4726ff5e55b0aa5c5ca	handwritten character recognition adaptable to the writer		I n this paper, we describe the handwritten character recognition adaptable to the writer. I t is efficient when the specific writer uses the same OCR for many characters. At the early stage, input characters are recognized using genera 1 dictionary, and then the correctly recognized character modify the dictionary to be adaptable to the variation of the characters of the specific writer. Using the adaptable dictionary modif ied by 10 characters/category, the classification rate is improved from 96.8% ( general dictionary ) to 99.5%.	counter-ied equipment;dictionary;genera;handwriting recognition;optical character recognition	Shinji Tsuruoka;Hiroyuki Morita;Fumitaka Kimura;Yasuji Miyake	1988			artificial intelligence;mathematics;pattern recognition;intelligent word recognition;intelligent character recognition;information technology;speech recognition	Crypto	32.601671678602415	-66.22859647526325	116445
411377832a48c02ecdf242b48d27537dd7faec19	color segmentation for historical documents using markov random fields	image segmentation;image color analysis image segmentation markov processes simulated annealing cooling vectors covariance matrices;simulated annealing;light red color markov random fields pixel wise document text extraction scanned historical documents grayscale images binarization approach text segmentation color segmentation approach noisy page background historical arabic manuscripts;vectors;covariance matrices;image color analysis;text detection document image processing history image colour analysis image resolution image segmentation markov processes;binarization color segmentation text segmentation markov random fields historical documents;markov processes;cooling	Binarization is often used for pixel-wise document text extraction as preprocessing step for scanned historical documents. These documents are scanned in color and high resolution today. The reduction of color to grayscale images and the subsequent binarization implies a loss of information and often results in unsatisfying processing results. In this paper, a color segmentation instead of a binarization approach is used to segment text from background in historical manuscripts. A color segmentation approach based on Markov random fields with a reduced set of required parameters is presented to segment text written in different colors from noisy page background. First tests with historical Arabic manuscripts show promising results. In case of words written in light red color, our approach shows better results than a state-of-the-art binarization approach.	binary image;color;distortion;experiment;grayscale;historical document;image resolution;image segmentation;markov chain;markov random field;pixel;preprocessor;text segmentation	Werner Pantke;Arne Haak;Volker Märgner	2014	2014 6th International Conference of Soft Computing and Pattern Recognition (SoCPaR)	10.1109/SOCPAR.2014.7007997	color histogram;computer vision;speech recognition;color image;simulated annealing;computer science;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;markov process;scale-space segmentation;statistics	Vision	37.21993697315328	-66.21676950094576	116535
d960abcfedb6fc2d31cc93040d4e59c27f126879	weaidu - a decision support system for myocardial perfusion images using artificial neural networks	myocardial infarction;support system;artificial neural networks;myocardial perfusion imaging;biofysik;myocardial infarct;image processing techniques;clinical decision support system;myocardial perfusion images;computer assisted;myocardial;myocardial ischemia;infarction;diagnosis;artificial neural network	This paper presents a computer-based decision support system for automated interpretation of diagnostic heart images (called WeAidU), which is made available via the Internet. The system is based on image processing techniques, artificial neural networks (ANNs) and large well-validated medical databases. We present results using artificial neural networks, and compare with two other classification methods, on a retrospective data set containing 1320 images from the clinical routine. The performance of the artificial neural networks detecting infarction and ischemia in different parts of the heart, measured as areas under the receiver operating characteristic curves, is in the range 0.83-0.96. These results indicate a high potential for the tool as a clinical decision support system.	artificial neural network;cns disorder;clinical decision support system;database;decision support systems, clinical;image processing;infarction;internet;receiver operating characteristic;sensor	Mattias Ohlsson	2004	Artificial intelligence in medicine	10.1016/S0933-3657(03)00050-2	myocardial infarction;computer science;machine learning;artificial neural network	ML	33.867465432752155	-77.9618517410515	116962
0585e53dae00f82fb9165cc669adb63b476199e3	simple methods for segmentation and measurement of diabetic retinopathy lesions in retinal fundus images	automatic segmentation;background image extraction;dr;medical image analysis;retinal images;automatic diagnosis of dr;optic disc	Diabetic retinopathy (DR) is one of the most important complications of diabetes mellitus, which causes serious damages in the retina, consequently visual loss and sometimes blindness if necessary medical treatment is not applied on time. One of the difficulties in this illness is that the patient with diabetes mellitus requires a continuous screening for early detection. So far, numerous methods have been proposed by researchers to automate the detection process of DR in retinal fundus images. In this paper, we developed an alternative simple approach to detect DR. This method was built on the inverse segmentation method, which we suggested before to detect Age Related Macular Degeneration (ARMDs). Background image approach along with inverse segmentation is employed to measure and follow up the degenerations in retinal fundus images. Direct segmentation techniques generate unsatisfactory results in some cases. This is because of the fact that the texture of unhealthy areas such as DR is not homogenous. The inverse method is proposed to exploit the homogeneity of healthy areas rather than dealing with varying structure of unhealthy areas for segmenting bright lesions (hard exudates and cotton wool spots). On the other hand, the background image, dividing the retinal image into high and low intensity areas, is exploited in segmentation of hard exudates and cotton wool spots, and microaneurysms (MAs) and hemorrhages (HEMs), separately. Therefore, a complete segmentation system is developed for segmenting DR, including hard exudates, cotton wool spots, MAs, and HEMs. This application is able to measure total changes across the whole retinal image. Hence, retinal images that belong to the same patients are examined in order to monitor the trend of the illness. To make a comparison with other methods, a Naïve Bayes method is applied for segmentation of DR. The performance of the system, tested on different data sets including various qualities of retinal fundus images, is over 95% in detection of the optic disc (OD), and 90% in segmentation of the DR.	abnormal degeneration;diabetes mellitus;diabetic retinopathy;exanthema;exudate;hemorrhage;illness (finding);macular degeneration;microaneurysm;naive bayes classifier;optic disk;patients;retina;retinal diseases;virtual retinal display;wool;biologic segmentation;hearing impairment	Cemal Köse;Ugur Sevik;Cevat Ikibas;Hidayet Erdöl	2012	Computer methods and programs in biomedicine	10.1016/j.cmpb.2011.06.007	computer vision;medicine;pathology	Vision	35.682620543088895	-76.31066882471731	116963
ad4be1ec378560a700d695f958dfcc5033c34e38	classification method of tactile feeling using stacked autoencoder based on haptic primary colors	vibrations;neural networks;skin;force;image color analysis;feature extraction;haptic interfaces	We have developed a classification method of tactile feeling using a stacked autoencoder-based neural network on haptic primary colors. The haptic primary colors principle is a concept of decomposing the human sensation of tactile feeling into force, vibration, and temperature. Images were obtained from variation in the frequency of the time series of the tactile feeling obtained when tracing a surface of an object, features were extracted by employing a stacked autoencoder using a neural network with two hidden layers, and supervised learning was conducted. We confirmed that the tactile feeling for three different surface materials can be classified with an accuracy of 82.0 [%].	artificial neural network;autoencoder;color;haptic technology;supervised learning;time series	Fumihiro Kato;Charith Lasantha Fernando;Yasuyuki Inoue;Susumu Tachi	2017	2017 IEEE Virtual Reality (VR)	10.1109/VR.2017.7892341	computer vision;feature extraction;computer science;vibration;multimedia;skin;force;artificial neural network	Robotics	26.025820543015765	-67.1061638630235	117163
e19cd643f63205e2e967b16f104f70674acc49e1	automatic drug image identification system based on multiple image features	image features;cbir;weight similarity;gabor filter;hamming distance;keyword search;neural network	Drugs can be divided into many types, such as different compositions, content and shapes, but users do not always possess or comprehend professional drug facts. Many drug recognition systems offer keyword search but they are difficult for users to understand the medications' names. One possible way would be for users to describe the features of drugs according to their appearance, such as color, shape, etc. In this paper, we propose an automatic drug image identification system (ADIIS) based on multiple image features. ADIIS is able to improve drug identification errors as well as provide drug information. In our primary experiments, by using an image, the system was able to retrieve the top ten similar drugs for the user to identify the specific drug. In addition, out of the ten identified drugs retrieved by ADIIS, the first of the ten drug identifications was 95% of the correct match.		Rung Ching Chen;Cho-Tsan Pao;Ying-Hao Chen;Jeng-Chih Jian	2010		10.1007/978-3-642-16732-4_27	computer vision;hamming distance;computer science;machine learning;data mining;feature;information retrieval;artificial neural network	Vision	32.16433359346624	-70.48423482658237	117443
7767bef5f2e63263d7a0fa2564226ee82278524b	independent component analysis assisted unsupervised multispectral classification	unsupervised classifiers;cost function;statistical independence;choroid plexus;independent component analysis;signal processing;multispectral images;random variable;unsupervised classification;multispectral classification;independent component	ABSTRACT The goal of unsupervised multispectral classification is to precisely identify objects in a scene by incorporating the complementary information available in spatially registered multispectral images. If the channels are less noisy and are as complementary as possible, the performance of the unsupervised classifier will improve. The discriminatory power of the classifier also increases if the individual channels have good contrast. Hence there is a need to preprocess the channels so that they have high contrast and are as complementary as possible. Independent Component Analysis (ICA) is a signal processing technique that expresses a set of random variables as linear combinations of statistically inde-pendent components. Performing ICA on the multispectral images yields images that have high contrast and are maximally complementary. Unsupervised classification on these images captures more information than on the original images. This paper presents some results based on this simple preprocessing step. In preliminary studies, using MR images of the brain, we were able to classify detailed neuro anatomical structures such as the putamen and choroid plexus, from the independent component channels. These structures could not be delineated from the original images using the same classifier. Keywords : multispectral classification, unsupervised classifiers, statistical independence, independent component analysis.	independent component analysis;multispectral image;unsupervised learning	Srinivasan Rajagopalan;Richard A. Robb	2003		10.1117/12.479606	computer vision;geography;machine learning;pattern recognition;multispectral pattern recognition	NLP	35.20380072884549	-72.22073030192202	117591
b1851988a58f26446821b8b8e10563aa9cac0cc5	a novel use of color computer vision methods for the quantification of neurons in 3-d brain tissue samples	brain;bayesian classifier;image segmentation;histologist color computer vision methods neurons quantification 3d brain tissue samples neurobiological studies color images neuronal nucleus bayesian classifier 3 d tissue sample object oriented database management system;3d brain tissue samples;neural nets;computer vision neurons brain machine vision color microscopy bayesian methods labeling image segmentation image reconstruction;color;bayesian methods;microscopy;medical image processing computer vision neural nets neurophysiology object oriented databases;computer vision;object oriented database management system;color images;machine vision;image reconstruction;medical image processing;brain structure;neurobiological studies;neuronal nucleus;neurons quantification;object oriented databases;neurons;histologist;neurophysiology;brain tissue;color computer vision methods;3 d tissue sample;labeling;color image	Neuron count in various brain structures is an important factor in many neurobiological studies. We describe a machine vision system which uses color images for the automated classification and counting of neurons in tissue samples. Samples are sliced into registered sections whose thickness is on the order of the diameter of a neuronal nucleus. Sections are stained so that the spectral transmission functions of the neuronal nuclei differ from the surrounding tissue. Each section is imaged using a light microscope. A Bayesian classifier is used for pixel labeling and a geometric analysis routine is employed to segment neuron regions in each section. The 3-D tissue sample is reconstructed using registered neuron regions from each section. An object-oriented database management system provides an efficient framework for cataloging neuron classes. Experimental results are presented and compared with results obtained by a histologist.	computer vision	David Slater;Glenn Healey;Phillip C.-Y. Sheu;Carl Cotman;Joseph H. Su;Andrea J. Wasserman;William Rodman Shankle	1998		10.1109/ICSMC.1998.727544	iterative reconstruction;computer vision;labeling theory;naive bayes classifier;color image;machine vision;bayesian probability;computer science;microscopy;artificial intelligence;image segmentation;neurophysiology;artificial neural network;computer graphics (images)	Vision	38.105426641895185	-74.08313845598047	117595
40b4d6d143bb929e92e332effa36ad099379ef55	development of system for crossarm reuse judgment on the basis of classification of rust images using support vector machine	image coding;data compression;support vector machines;support vector machines support vector machine classification machine learning digital cameras books microcomputers pattern classification image processing data mining feature extraction;personal computer;rust image classification;support vector machines data compression image classification image coding learning artificial intelligence power engineering computing power system management;digital camera;image classification;crossarm reuse judgment system;learning systems;power engineering computing;machine learning;image compression;power system management;pattern classification;image compression crossarm reuse judgment system rust image classification support vector machine machine learning;image processing techniques;support vector machine;learning artificial intelligence	We attempt to develop a crossarm reuse judgment system based on rust images that uses machine learning techniques. The system consists of a digital camera and a standard note book personal computer (PC). We estimate the degree of accuracy of the judgment of various pattern classification methods without special image processing techniques such as the extraction of features. The results show that a support vector machine is the most suitable instrument for this judgment system. We obtain the high degree of accuracy by compressing the image data in order to decrease the number of features	digital camera;image processing;machine learning;personal computer;rust;support vector machine	Michiko Yamana;Hiroshi Murata;Takashi Onoda;Tohru Ohashi;Seiji Kato	2005	17th IEEE International Conference on Tools with Artificial Intelligence (ICTAI'05)	10.1109/ICTAI.2005.58	support vector machine;computer vision;computer science;machine learning;pattern recognition	Robotics	34.93671132769493	-71.69951721421215	117636
54d318179a2b8c39267013c7635f615bc5176bbe	fuzzy watershed segmentation algorithm: an enhanced algorithm for 2d gel electrophoresis image segmentation	image segmentation;protein spots;fuzzy logic;protein spot detection;watershed segmentation;gel electrophoresis images;over segmentation;fuzzy relations;wavelet denoising;bioinformatics	Detection and quantification of protein spots is an important issue in the analysis of two-dimensional electrophoresis images. However, there is a main challenge in the segmentation of 2DGE images which is to separate overlapping protein spots correctly and to find the weak protein spots. In this paper, we describe a new robust technique to segment and model the different spots present in the gels. The watershed segmentation algorithm is modified to handle the problem of over-segmentation by initially partitioning the image to mosaic regions using the composition of fuzzy relations. The experimental results showed the effectiveness of the proposed algorithm to overcome the over segmentation problem associated with the available algorithm. We also use a wavelet denoising function to enhance the quality of the segmented image. The results of using a denoising function before the proposed fuzzy watershed segmentation algorithm is promising as they are better than those without denoising.		Shaheera Rashwan;Amany Sarhan;Mohamed Talaat Faheem;Bayumy B. A. Youssef	2015	International journal of data mining and bioinformatics	10.1504/IJDMB.2015.069659	fuzzy logic;computer vision;watershed;computer science;bioinformatics;machine learning;segmentation-based object categorization;mathematics;image segmentation;scale-space segmentation	Vision	39.03947570593176	-73.55385126639987	117952
c0d136ba2f5a5a074b3f23761e42997b46b6994e	learning to boost filamentary structure segmentation	neuronal segmentation filamentary structure segmentation boosting filamentary fragment detection filamentary fragment restoration iterative two step learning based approach base segmenter initial partial segmentation scanning horizon epsilon balls data driven latent classification tree model training process local figure background separation scenarios image space supervised unsupervised segmenter retinal blood vessel segmentation;trees mathematics blood vessels eye image classification image restoration image segmentation learning artificial intelligence medical image processing object detection;image segmentation shape retina vegetation image restoration biomedical imaging context	The challenging problem of filamentary structure segmentation has a broad range of applications in biological and medical fields. A critical yet challenging issue remains on how to detect and restore the small filamentary fragments from backgrounds: The small fragments are of diverse shapes and appearances, meanwhile the backgrounds could be cluttered and ambiguous. Focusing on this issue, this paper proposes an iterative two-step learning-based approach to boost the performance based on a base segmenter arbitrarily chosen from a number of existing segmenters: We start with an initial partial segmentation where the filamentary structure obtained is of high confidence based on this existing segmenter. We also define a scanning horizon as epsilon balls centred around the partial segmentation result. Step one of our approach centers on a data-driven latent classification tree model to detect the filamentary fragments. This model is learned via a training process, where a large number of distinct local figure/background separation scenarios are established and geometrically organized into a tree structure. Step two spatially restores the isolated fragments back to the current partial segmentation, which is accomplished by means of completion fields and matting. Both steps are then alternated with the growth of partial segmentation result, until the input image space is entirely explored. Our approach is rather generic and can be easily augmented to a wide range of existing supervised/unsupervised segmenters to produce an improved result. This has been empirically verified on specific filamentary structure segmentation tasks: retinal blood vessel segmentation as well as neuronal segmentations, where noticeable improvement has been shown over the original state-of-the-arts.	decision tree learning;horizon effect;iterative method;linear canonical transformation;machine epsilon;microsoft outlook for mac;resonance;supervised learning;tree structure;unsupervised learning	Lin Gu;Li Cheng	2015	2015 IEEE International Conference on Computer Vision (ICCV)	10.1109/ICCV.2015.80	computer vision;machine learning;segmentation-based object categorization;pattern recognition;mathematics;image segmentation;scale-space segmentation	Vision	30.463562497523284	-72.47746101282026	118051
778ffdb0565a3c11974a2b8ed32a89b68195af2d	incorporation of clinical data into a computerized method for the assessment of mammographic breast lesions	databases;aide diagnostic;clinical data;glandula mamaria patologia;female;factor riesgo;radiodiagnostic;informatica biomedical;biomedical data processing;image processing;cancer;tumor maligno;risk factor;mastografia;mammary gland;informatique biomedicale;procesamiento imagen;hombre;statistical significance;intelligence artificielle;classification;facteur risque;traitement image;breast;glandula mamaria;radiodiagnostico;artificial neural networks;risk factors;round robin;hembra;mammographie;receiver operating characteristic curves;human;mammary gland diseases;computing systems;artificial intelligence;tumeur maligne;glande mammaire;inteligencia artificial;radiodiagnosis;femelle;mammography;reseau neuronal;metodo roc;methode roc;breast cancer;clasificacion;red neuronal;diagnostic aid;glande mammaire pathologie;malignant tumor;artificial neural network;homme;neural network;ayuda diagnostica	We previously developed a computerized method to classify mammographic masses as benign or malignant. In this method, mammographic features that are similar to the ones used by radiologists are automatically extracted to characterize a mass lesion. These features are then merged by an artificial neural network (ANN), which yields an estimated likelihood of malignancy for each mass. The performance of the method was evaluated on an independent database consisting of 110 cases (60 benign and 50 malignant cases). The method achieved an Az of 0.91 from round-robin analysis in the task of differentiating between benign and malignant masses using the computer-extracted features only. As the most important clinical risk factor for breast cancer, age achieved a performance level (Az equals 0.79) similar to that (Az equals 0.77 and 0.80) of the computer-extracted spiculation features, which are the most important indicators for malignancy of a mass, in differentiating between the malignant and benign cases. In this study, age is included as an additional input feature to the ANN. The performance of the scheme (Az equals 0.93) is improved when age is included. However, the improvement is not found to be statistically significant. Our results indicated that age may be a strong feature in predicting malignancy of a mass. For this database, however, the inclusion of age may not have a strong impact on the determination of the likelihood for a mammographic mass lesion when the major mammographic characteristics (e.g., spiculation) of a mass are accurately extracted and analyzed along with other features using an artificial neural network.© (2000) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Zhimin Huo;Maryellen Lissak Giger	2000		10.1117/12.387626	pathology;engineering;artificial intelligence;surgery	DB	34.387411290378004	-78.03742257793914	118103
30a319d6e1472c81a1987133afb01f524df459dc	pedestrian detection based on adaptive selection of visible light or far-infrared light camera image by fuzzy inference system and convolutional neural network-based verification	adaptive selection;convolutional neural network;fuzzy inference system;pedestrian detection;visible light and fir cameras	A number of studies have been conducted to enhance the pedestrian detection accuracy of intelligent surveillance systems. However, detecting pedestrians under outdoor conditions is a challenging problem due to the varying lighting, shadows, and occlusions. In recent times, a growing number of studies have been performed on visible light camera-based pedestrian detection systems using a convolutional neural network (CNN) in order to make the pedestrian detection process more resilient to such conditions. However, visible light cameras still cannot detect pedestrians during nighttime, and are easily affected by shadows and lighting. There are many studies on CNN-based pedestrian detection through the use of far-infrared (FIR) light cameras (i.e., thermal cameras) to address such difficulties. However, when the solar radiation increases and the background temperature reaches the same level as the body temperature, it remains difficult for the FIR light camera to detect pedestrians due to the insignificant difference between the pedestrian and non-pedestrian features within the images. Researchers have been trying to solve this issue by inputting both the visible light and the FIR camera images into the CNN as the input. This, however, takes a longer time to process, and makes the system structure more complex as the CNN needs to process both camera images. This research adaptively selects a more appropriate candidate between two pedestrian images from visible light and FIR cameras based on a fuzzy inference system (FIS), and the selected candidate is verified with a CNN. Three types of databases were tested, taking into account various environmental factors using visible light and FIR cameras. The results showed that the proposed method performs better than the previously reported methods.	artificial neural network;biological neural networks;blurred vision;body temperature;cns disorder;convolutional neural network;database;face detection;finite impulse response;genetic selection;immunoglobulin kappa-chains;immunoglobulin lambda-chains;inference engine;light, visible;lightheadedness;normal statistical distribution;obstruction;pedestrian detection;photophobia;radiation;radix angelicae sinensis/radix astragali herbal supplement;serial ata;spectroscopy, near-infrared;vezf1 protein, human;verification of theories;algorithm;sensor (device)	Jin Kyu Kang;Hyung Gil Hong;Kang Ryoung Park	2017		10.3390/s17071598	convolutional neural network;fuzzy logic;engineering;visible spectrum;computer vision;inference;radiation;artificial intelligence;pedestrian detection;far infrared	Vision	34.1990233691719	-70.1257373437714	118199
2fcd1e1b94d87ddd92405f8cf4dac26b2c153eca	a pilot study on image analysis techniques for extracting early uterine cervix cancer cell features	medical image analysis;cervical cancer;cytopathological cell images;pap smear	The second most common and preventable form of cancer among women worldwide is cervical cancer in which the signs for this disease can be detected in the early Pap smear screening of cervical cells. To improve the efficiency of expert diagnosis, we will need to automate the feature extraction of cervical cancer cells by the means of image processing techniques. This article employs image processing techniques to get the special features of normal, precancerous and cancerous cell images. We extract spectral features for cervical cancer cell detection. This article uses the noise decrease filters, OTSU threshold to make it ready for processing through 2-D Fourier and logarithmic transforms. By drawing the linear plot, we will be able to extract the feature of normal, precancerous and cancerous cells according to the texture and morphology automatically. These linear plots will be unique which can separate the cells in three groups of normal, precancerous and cancerous cells. This separation is done with 100% accuracy due to the unique linear plots. The experiment shows that extracted unique features for each cell will provide evidences for diagnoses even in cytopathology images in which the nucleus and cytoplasm segmentation algorithms suffer from complex overlaying cells.	artificial neural network;cell nucleus;cervix uteri;cervix carcinoma;classification;conflict (psychology);diagnostic service section id - cytopathology;feature extraction;frequency analysis;graph - visual representation;high-grade squamous intraepithelial lesions;image analysis;image processing;low grade squamous intraepithelial neoplasia;mathematical morphology;neck;neoplasms;neural network simulation;smear - instruction imperative;smear campaign;algorithm;interest	Babak Sokouti;Siamak Haghipour;Ali Dastranj Tabrizi	2010	Journal of Medical Systems	10.1007/s10916-010-9649-y	computer vision;medicine;pathology;gynecology	ML	36.14768465955921	-76.23844618873575	118204
94f942e5dfff35a2836e70c4baa257c90ebc0cbc	robust separation of visceral and subcutaneous adipose tissues in micro-ct of mice	separation bone computerised tomography gaussian processes image classification image matching medical image processing muscle physiological models;gaussian processes;mice robustness image segmentation skeleton biomedical imaging accuracy magnetic resonance imaging;image matching;image classification;separation;computed tomography visceral adipose tissue separation framework subcutaneous adipose tissue separation framework obesity diabetes soft tissue bone gaussian model mixture spatial recognition abdominal muscular wall vat region of interest skeleton matching procedure image classification accuracy microct mouse volume dataset;medical image processing;bone;computerised tomography;physiological models;muscle	One of the common practices in obesity and diabetes studies is to measure the volumes and weights of various adipose tissues, among which, visceral adipose tissue (VAT) and subcutaneous adipose tissue (SAT) play critical yet different physiological roles in mouse aging. In this paper, a robust two-stage VAT/SAT separation framework for micro-CT mouse data is proposed. The first stage is to distinguish adipose from other tissue types, including background, soft tissue and bone, through a robust mixture of Gaussian model. Spatial recognition relevant to anatomical locations is carried out in the second step to determine whether the adipose is visceral or subcutaneous. We tackle this problem through a novel approach that relies on evolving the abdominal muscular wall to keep VAT/SAT separated. The VAT region of interest (ROI) is also automatically set up through an atlas based skeleton matching procedure. The results of our method are compared with VAT/SAT delineations by human experts, and a high classification accuracy is demonstrated on eight micro-CT mouse volume sets.	adipose tissue;atlases;body tissue;bone tissue;diabetes mellitus;fat measurement;histocompatibility testing;matching;muscle;normal statistical distribution;platelet glycoprotein 4, human;preparation;region of interest;stage level 1;subcutaneous fat;terminate (software);visceral fat;weight;algorithm;biologic segmentation;registration - actclass;soft tissue	Bibo Shi;Shuisheng Xie;Darlene E. Berryman;Edward O. List;Jundong Liu	2013	2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2013.6610000	contextual image classification;muscle;medicine;pathology;computer science;gaussian process;mathematics;biological engineering;anatomy;statistics	Vision	39.066831441585	-78.30138509213427	118301
4e39af8663c7df094e249fb57eee92eb6b99f992	automated segmentation of intra-retinal cysts from optical coherence tomography scans using marker controlled watershed transform	image segmentation;retina;transforms;diseases;clustering algorithms;pathology	Optical Coherence Tomography (OCT) has emerged as a major diagnostic modality for retinal imaging. Although OCT generates gross volumetric data, manual analysis of the images for locating or quantifying retinal cysts is a time consuming process. Recently semi- and fully-automatic methods for locating and segmenting retinal cysts have been proposed in the literature. Our paper proposes a fully automatic method for intra-retinal cyst segmentation using marker controlled watershed transform on B-scan images obtained on OCT scanning. Markers are obtained using k-means clustering and used as sources for topographical based watershed transform for final segmentation. Proposed method was evaluated both quantitatively and qualitatively on Optima Cyst Challenge dataset against ground truth obtained from two graders. Experimental results show that the proposed method outperformed other recently proposed methods. Our algorithm achieved a recall rate of 82% while preserving precision rate of 77%, and gave a higher correlation rate of 96% with ground truth obtained from two graders.	algorithm;cluster analysis;cyst;ground truth;k-means clustering;modality (human–computer interaction);retina;retinal implant;sensitivity and specificity;silo (dataset);tomography, optical coherence;topography;watershed (image processing);x-ray computed tomography;biologic segmentation;statistical cluster	G. N. Girish;Abhishek R. Kothari;Jeny Rajan	2016	2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2016.7590943	computer vision;pathology;computer science;machine learning;image segmentation;cluster analysis	Vision	38.74666917745811	-79.19742985901273	118375
c379676e58f2ecfd0c9b8d1002a63cbdc9a4cc21	feature selection in melanoma recognition	image recognition;image segmentation;cancer;computer graphics;skin;bioluminescence;radiometry skin cancer medical image processing image segmentation biomedical imaging image classification bioluminescence optical microscopy;image classification;microscopy;biomedical imaging;skin cancer;malignant tumors;radiometry;melanoma recognition;ear;shape;lesions;malignant tumors lesions image analysis skin cancer image recognition microscopy image segmentation computer graphics ear;medical image processing;medical criteria;image analysis;feature selection;digital epiluminescence microscopic images;medical criteria melanoma recognition feature selection cancer digital epiluminescence microscopic images shape radiometric properties;optical microscopy;radiometric properties	Melanoma, one of the most aggressive types of cancer, can be healed, if recognized in early stages. In order to automate the early recognition of skin cancer, a system that analyses digital epiluminescence microscopic images is used. After segmentation, 33 features representing shape and radiometric properties are calculated. In this paper the quality of the features is evaluated by applying several feature selection methods. The results show that with each selection method the feature set can be reduced to dimension four with nearly no loss of information. Results with classification rates of up to 75% are achieved and realtions between selected features and medical criteria are observed.	feature selection;metric	Reinhard Röhrer;Harald Ganster;Axel Pinz;Michael Binder	1998		10.1109/ICPR.1998.712040	computer vision;contextual image classification;image analysis;radiometry;bioluminescence;shape;computer science;microscopy;optical microscope;skin;image segmentation;computer graphics;feature selection;cancer	Web+IR	36.612831805231835	-74.34178334499099	118414
2ac04880623235b1a62477aba03d569c9d327cee	leaf recognition for plant classification based on wavelet entropy and back propagation neural network		In this paper, we proposed a method for plant classification, which aims to recognize the type of leaves from a set of image instances captured from same viewpoints. Firstly, for feature extraction, this paper adopted the 2-level wavelet transform and obtained in total 7 features. Secondly, the leaves were automatically recognized and classified by Back-Propagation neural network (BPNN). Meanwhile, we employed K-fold cross-validation to test the correctness of the algorithm. The accuracy of our method achieves 90.0%. Further, by comparing with other methods, our method arrives at the highest accuracy.	algorithm;artificial neural network;backpropagation;correctness (computer science);cross-validation (statistics);feature extraction;software propagation;wavelet transform	Meng-Meng Yang;Preetha Phillips;Shuihua Wang;Yudong Zhang	2017		10.1007/978-3-319-65298-6_34	wavelet;engineering;plant taxonomy;wavelet transform;feature extraction;artificial neural network;correctness;backpropagation;machine learning;artificial intelligence;pattern recognition	AI	32.80618090010356	-70.55749280731484	118867
6f9b2e42141e74ec71ec4547415dad25dfcab1e2	computer aided detection and measurement of coronary artery disease from computed tomography angiography images	allied health professions and studies;computer science and informatics	Coronary artery disease is one of the most pernicious diseases around the world and early identification of vascular disease can help to reduce morbidity and mortality. Assessment of the degree of vascular obstruction, or stenosis, is critical for classifying the risks of the future vascular events. Automatic detection and quantification of stenosis are important in assessing coronary artery disease from medical imagery, especially for disease progression. Important factors affecting the reproducability and robustness of accuarate quantification arise from the partial volume effect and other noise sources. The main goal of this study is to present a fully automatic approach for detection and quantification of the stenosis in the coronary arteries. The proposed approach begins by building a 3D reconstruction of the coronary arterial system and then making accurate measurement of the vessel diameter from a robust estimate of the vessel cross-section. The proposed algorithm models the partial volume effect using a Markovian fuzzy clustering method in the process of accurate quantification of the degree of stenosis. To evaluate the accuracy and reproducibility of the measurement, the method was applied to a vascular phantom that was scanned using different protocols. The algorithm was applied to 20 CTA patient datasets containing a total of 85 stenoses, which were all successfully detected, with an average false positive rate of 0.7 per scan.	ct scan;computed tomography angiography	Mahdi Mazinani	2012			radiology;medicine;pathology;biological engineering	Vision	37.253808799884695	-78.9209123679964	119016
e77e7a7c79518231b6b78e491eb5ce0d5c8040af	investigating the impact of cnn depth on neonatal seizure detection performance		This study presents a novel, deep, fully convolutional architecture which is optimized for the task of EEG-based neonatal seizure detection. Architectures of different depths were designed and tested; varying network depth impacts convolutional receptive fields and the corresponding learned feature complexity. Two deep convolutional networks are compared with a shallow SVMbased neonatal seizure detector, which relies on the extraction of hand-crafted features. On a large clinical dataset, of over 800 hours of multichannel unedited EEG, containing 1389 seizure events, the deep 11-layer architecture significantly outperforms the shallower architectures, improving the AUC90 from 82.6% to 86.8%. Combining the end-to-end deep architecture with the feature-based shallow SVM further improves the AUC90 to 87.6%. The fusion of classifiers of different depths gives greatly improved performance and reduced variability, making the combined classifier more clinically reliable.	architecture as topic;convolutional neural network;detectors;electroencephalography;end-to-end principle;spatial variability;neonatal seizures	Alison O'Shea;Gordon Lightbody;Geraldine B. Boylan;Andriy Temko	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8513617	artificial intelligence;machine learning;support vector machine;feature extraction;architecture;neonatal seizure;computer science;electroencephalography;receptive field	Vision	30.44093801836307	-75.92504597446163	119035
4cf4bdbf65d1db8fe22ac040591dba9622fce5b3	correcting the document layout: a machine learning approach	hierarchical structure;learning artificial intelligence document image processing feature extraction;machine learning;feature extraction;document image processing;machine learning performance analysis text analysis image sequence analysis xml image segmentation image analysis assembly systems tree data structures histograms;learning artificial intelligence;multipage documents document layout correction machine learning document layout analysis hierarchical structure extraction page layout global analysis local analysis;global analysis	In this paper, a machine learning approach to support the user during the correction of the layout analysis is proposed. Layout analysis is the process of extracting a hierarchical structure describing the layout of a page. In our approach, the layout analysis is performed in two steps: firstly, the global analysis determines possible areas containing paragraphs, sections, columns, figures and tables, and secondly, the local analysis groups together blocks that possibly fall within the same area. The result of the local analysis process strongly depends on the quality of the results of the first step. We investigate the possibility of supporting the user during the correction of the results of the global analysis. This is done by allowing the user to correct the results of the global analysis and then by learning rules for layout correction from the sequence of user actions. Experimental results on a set of multi-page documents are reported and commented. 1. Background and motivation Strategies for the extraction of layout analysis have been traditionally classified as top-down or bottom-up [10]. In top-down methods, the document image is repeatedly decomposed into smaller and smaller components, while in bottom-up methods, basic layout components are extracted from bitmaps and then grouped together into larger blocks on the basis of their characteristics. In WISDOM++, a document image analysis system that can transform paper documents into XML format [1], the applied page decomposition method is hybrid, since it combines a top-down approach to segment the document image, and a bottom-up layout analysis method to assemble basic blocks into frames. Some attempts to learn the layout structure from a set of training examples have also been reported in the literature [2,3,4,7,11]. They are based on ad-hoc learning algorithms, which learn particular data structures, such as geometric trees and tree grammars. Results are promising, although it has been proven that good layout structures could also be obtained by exploiting generic knowledge on typographic conventions [5]. This is the case of WISDOM++, which analyzes the layout in two steps: 1. A global analysis, in order to determine possible areas containing paragraphs, sections, columns, figures and tables. This step is based on an iterative process, in which the vertical and horizontal histograms of text blocks are alternately analyzed, in order to detect columns and sections/paragraphs, respectively. 2. A local analysis to group together blocks that possibly fall within the same area. Generic knowledge on west-style typesetting conventions is exploited to group blocks together, such as “the first line of a paragraph can be indented” and “in a justified text, the last line of a paragraph can be shorter than the previous one”. Experimental results proved the effectiveness of this knowledge-based approach on images of the first page of papers published in conference proceedings and journals [1]. However, performance degenerates when the system is tested on intermediate pages of multi-page articles, where the structure is much more variable, due to the presence of formulae, images, and drawings that can stretch over more than one column, or are quite close. The majority of errors made by the layout analysis module were in the global analysis step, while the local analysis step performed satisfactorily when the result of the global analysis was correct. In this paper, we investigate the possibility of supporting the user during the correction of the results of the global analysis. This is done by allowing the user to correct the results of the global analysis and then by learning rules for layout correction from his/her sequence of actions. This approach is different from those that learn the layout structure from scratch, since we try to correct the result of a global analysis returned by a bottom-up algorithm. Furthermore, we intend to capture knowledge on correcting actions performed by the user of the document image processing system. Other document processing systems allow users to correct the result of the layout analysis; nevertheless WISDOM++ is the only one that tries to learn correcting actions from user interaction with the system. Proceedings of the Seventh International Conference on Document Analysis and Recognition (ICDAR 2003) 0-7695-1960-1/03 $17.00 © 2003 IEEE In the following section, we describe the layout correction operations. The automated generation of training examples is explained in Section 3. Section 4 introduces the learning strategy, while Section 5 presents some experimental results. 2. Correcting the layout Global analysis aims at determining the general layout structure of a page and operates on a tree-based representation of nested columns and sections. The levels of columns and sections are alternated (Figure 1), which means that a column contains sections, while a section contains columns. At the end of the global analysis, the user can only see the sections and columns that have been considered atomic, that is, not subject to further decomposition (Figure 2). The user can correct this result by means of three different operations: • Horizontal splitting: a column/section is cut horizontally. • Vertical splitting: a column/section is cut vertically. • Grouping: two sections/columns are merged together. The cut point in the two splitting operations is automatically determined by computing either the horizontal or the vertical histogram on the basic blocks returned by the segmentation algorithm. The horizontal (vertical) cut point corresponds to the largest gap between two consecutive bins in the horizontal (vertical) histogram. Therefore, splitting operations can be described by means of a unary function, split(X), where X represents the column/section to be split and the range is the set {horizontal, vertical, no_split}. The grouping operation, which can be described by means of a binary predicate group(A,B), is applicable to two sections (columns) A and B and returns a new section (column) C, whose boundary is determined as follows. Let (leftX, topX) and (bottomX, rightX) be the coordinates of the top-left and bottom-right vertices of a column/section X, respectively. Then: leftC= min(leftA, leftB), rightC=max(rightA,rightB), topC=min(topA,topB), bottomC=max(bottomA,bottomB). Grouping is possible only if the following two conditions are satisfied: 1. C does not overlap another section (column) in the document. 2. A and B are nested in the same column (section). After each splitting/grouping operation, WISDOM++ recomputes the result of the local analysis process, so that the user can immediately perceive the final effect of the requested correction and can decide whether to confirm the correction or not. 3. Representing corrections From the user interaction, WISDOM++ implicitly generates some training observations describing when and how the user intended to correct the result of the global analysis. These training observations are used to learn correction rules of the result of the global analysis, as explained in the next section. The simplest representation describes, for each training observation, the page layout at the i-th correction step and the correcting operation performed by the user on that layout. Therefore, if the user performs n-1 correcting operations, n observations are generated. The last one corresponds to the page layout accepted by the user. In the learning phase, this representation may lead the system to generate rules which strictly take into account the exact user correction sequence. However, several alternative correction sequences, which lead to the same result, may be also possible. If they are not considered, the learning strategy will suffer from data overfitting problems. This issue was already discussed in a preliminary work [9]. A more sophisticated representation, which takes into account alternative correction sequences, is based on the Column level	algorithm;archive;basic block;bitmap;bottom-up parsing;bottom-up proteomics;column (database);data structure;document layout analysis;document processing;experiment;hoc (programming language);image analysis;image processing;inductive reasoning;international conference on document analysis and recognition;iteration;knowledge-based systems;machine learning;overfitting;tj-2;top-down and bottom-up design;unary operation;vertical bar;xml;xslt/muenchian grouping	Donato Malerba;Floriana Esposito;Oronzo Altamura;Michelangelo Ceci;Margherita Berardi	2003		10.1109/ICDAR.2003.1227635	feature extraction;computer science;machine learning;document layout analysis;pattern recognition;data mining;global analysis	Vision	35.15941647736534	-68.01413810453298	119086
858faddb520a3d54194d92a433b855917664ce15	fully connected cascade artificial neural network architecture for attention deficit hyperactivity disorder classification from functional magnetic resonance imaging data	fcc;training;computer architecture;accuracy;artificial neural networks;support vector machines svms artificial neural networks anns attention deficit hyperactivity disorder adhd classification functional magnetic resonance imaging fmri;magnetic resonance imaging;fcc training artificial neural networks accuracy neurons magnetic resonance imaging computer architecture;neurons	Automated recognition and classification of brain diseases are of tremendous value to society. Attention deficit hyperactivity disorder (ADHD) is a diverse spectrum disorder whose diagnosis is based on behavior and hence will benefit from classification utilizing objective neuroimaging measures. Toward this end, an international competition was conducted for classifying ADHD using functional magnetic resonance imaging data acquired from multiple sites worldwide. Here, we consider the data from this competition as an example to illustrate the utility of fully connected cascade (FCC) artificial neural network (ANN) architecture for performing classification. We employed various directional and nondirectional brain connectivity-based methods to extract discriminative features which gave better classification accuracy compared to raw data. Our accuracy for distinguishing ADHD from healthy subjects was close to 90% and between the ADHD subtypes was close to 95%. Further, we show that, if properly used, FCC ANN performs very well compared to other classifiers such as support vector machines in terms of accuracy, irrespective of the feature used. Finally, the most discriminative connectivity features provided insights about the pathophysiology of ADHD and showed reduced and altered connectivity involving the left orbitofrontal cortex and various cerebellar regions in ADHD.	artificial neural network;attention deficit hyperactivity disorder;bipolar disorder;brain diseases;cascade device component;classification;hyperactive behavior;network architecture;neuroimaging;resonance;statistical classification;subtype (attribute);support vector machine	Gopikrishna Deshpande;Peng Wang;D. Rangaprakash;Bogdan M. Wilamowski	2015	IEEE Transactions on Cybernetics	10.1109/TCYB.2014.2379621	computer science;artificial intelligence;magnetic resonance imaging;machine learning;accuracy and precision;artificial neural network;statistics	ML	27.290911855778464	-77.07437862075126	119099
36ac77d96d4b823d872b097a6751f8fac925a085	automatic segmentation of cerebral ischemic lesions from diffusion tensor mr images	brain;tissues;automatic segmentation;anisotropy;ischemic stroke;satisfiability;anisotropic diffusion;magnetic resonance image;mr imaging;radio frequency;partial volume;magnetic resonance imaging;fractional anisotropy;synthetic data;diffusion tensor imaging;brain tissue;diffusion;spatial information;partial volume effect;diffusion tensor	There has been increasing interest in quantitatively analyzing diffusion anisotropy of ischemic lesions from diffusion tensor magnetic resonance imaging (DT-MRI). In this study, we develop and evaluate a novel method to automatically segment cerebral ischemic lesions from DT-MRI images. The method is a combination of image preprocessing, measures of diffusion anisotropy, multi-scale statistical classification (MSSC), and partial volume reclassification (PVRC). First, non-linear anisotropic diffusion filtering are applied to DT-MRI images to reduce image noise. Then, measures of diffusion anisotropy, such as fractional anisotropy and trace of the diffusion tensor, are calculated to acquire the diffusion properties of different brain tissues. Finally, ischemic lesions are accurately segmented using robust MSSC-PVRC, taking into account spatial information, intensity gradient, radio frequency (RF) inhomogeity and measures of diffusion anisotropy of DT-MRI images. After MSSC, PVRC is applied to overcome partial volume effect (PVE). Analyses of synthetic data and DT-MRI scans of 20 patients with ischemic stroke were carried out. It shows that the method got a satisfied segmentation of ischemic lesions, successfully overcoming the problem of intensity overlapping and reducing PVE, and that the method is robust to varying starting parameters. The results of the automated method are compared with lesion delineations by human experts, showing the rapid identification of ischemic lesion with accuracy and reproducibility. The proposed automatic technique is promising not only to detect the site and size of ischemic lesions in stroke patients but also to quantitatively analyze diffusion anisotropy of lesions for further clinical diagnoses and therapy.© (2004) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Wu Li;Jie Tian;Jianping Dai	2004		10.1117/12.536007	radiology;mathematics;nuclear magnetic resonance;medical physics	Vision	38.72475437266787	-78.79490309640371	119160
7c3c23f6f676921c286f2e3d27eec2ace579f538	syntactic and semantic labeling of hierarchically organized document image components of indian scripts	gray scale image processing hierarchically organized document image component syntactic labeling semantic labeling indian script document image analysis system image segmentation content characterization white space;pediatrics;document image analysis;document model;image segmentation;page segmentation;text analysis;labeling image segmentation skeleton white spaces particle separators graphics iterative algorithms pattern recognition computer science text analysis;skeleton;domain knowledge;pixel;document image processing;particle separators;image segmentation document image processing;semantic labeling;semantic labeling page segmentation;labeling	In this paper we describe our document image analysis system which performs segmentation, content characterization as well as semantic labeling of components.  Segmentation is done using white spaces and gives the segmented components arranged in a hierarchy.  Semantic labeling is done using domain knowledge which is specified where possible in the form of a document model applicable to a class of documents.  The novelty of the system lies in the suite of methods it employs which are capable of handling documents in Indian scripts.  We have obtained promising results for semantic segmentation of over 30 categories of documents in Indian scripts.	grayscale;image analysis;optical character recognition;semantic role labeling;white spaces (radio)	Gaurav Harit;Ritu Garg;Santanu Chaudhury	2009	2009 Seventh International Conference on Advances in Pattern Recognition	10.1109/ICAPR.2009.88	computer vision;speech recognition;computer science;pattern recognition	Vision	35.935647418446976	-66.22675030994742	119586
80ce1fd2f9437e6bb21646e58e9ad61af16922a1	abdominal organ identification based on atlas registration and its application in fuzzy connectedness segmentation	normalized mutual information;affine transformation;abdominal organ;fuzzy connectedness;similarity measure;atlas registration	A framework based on atlas registration is proposed for automatic identification and segmentation of abdominal organs. The VIP-Man atlas is adopted to guide the whole process. The atlas was registered onto the subject through global registration and organ registration. In global registration, an affine transformation was found to eliminate the global differences between the atlas and the subject, using normalized mutual information as the similarity measure. In organ registration, organs of interest were registered respectively to achieve better alignments. An original similarity measure was proposed in organ registration. The registered atlas can be viewed as an initial segmentation of the subject, and make organs of interest identified. As an application of the registered atlas, novel methods were designed to estimate necessary parameters for fuzzy connectedness (FC) segmentation. Manual intervention was avoided, and thus to increase the automation degree of the method. This atlas-based method was tested on abdominal CT images of Chinese patients. Experimental results indicated the validity of the method for both male and female subjects of different ages.		Yongxin Zhou;Jing Bai	2006		10.1007/11812715_46	computer vision;data mining;mathematics;engineering drawing	Vision	38.661639529714584	-78.44456462010162	119652
e4a75044cc9f0e9f82d5f477cf748e7e92f568f4	recurrent capsule network for relations extraction: a practical application to the severity classification of coronary artery disease		Coronary artery disease (CAD) is one of the leading causes of cardiovascular disease deaths. CAD condition progresses rapidly, if not diagnosed and treated at an early stage may eventually lead to an irreversible state of the heart muscle death. Invasive coronary arteriography is the gold standard technique for CAD diagnosis. Coronary arteriography texts describe which part has stenosis and how much stenosis is in details. It is crucial to conduct the severity classification of CAD. In this paper, we propose a recurrent capsule network (RCN) to extract semantic relations between clinical named entities in Chinese coronary arteriography texts, through which we can automatically find out the maximal stenosis for each lumen to inference how severe CAD is according to the improved method of Gensini. Experimental results on the corpus collected from Shanghai Shuguang Hospital show that our proposed RCN model achieves a F1-score of 0.9641 in relation extraction, which outperforms the baseline methods.		Qi Wang;Jiahui Qiu;Yangming Zhou;Tong Ruan;Daqi Gao;Ju Gao	2018	CoRR		machine learning;artificial intelligence;stenosis;computer science;coronary artery disease;relationship extraction;internal medicine;cardiology	NLP	31.9593966952173	-76.72168450819966	119703
89423229f7e206e8ba5677614ee2dd1fa2e6418c	computer-aided septal defect diagnosis and detection	surgical planning;septal defects;heart;computer aided diagnosis;clinical diagnosis;medical diagnostics;cardiac mri;blood;image registration;registration;clinical practice;computing systems;cardiovascular magnetic resonance imaging;information fusion;blood flow;tracking;defect detection	To facilitate the clinical diagnosis, surgical planning and after operation follow-up, a computer aided septal defect diagnosis and detection framework is proposed. The framework is consisted of four steps: image registration, flow balance measurement, heart wall tracking and septal defects detection. First, a global smooth constrained localized registration method is employed to register the image; Then, flow balance measurement is employed to determine the unbalance of in and out blood flow, which usually indicate the septal defects in the heart; After that, the wall of the heart is tracked using the same framework used in the registration to improve the efficiency and accuracy; Defects along septal are detected using a Bayesian based information fusion to analyze the profile lines from registered image, difference image and original grey image for the whole sequence (3D+T). The proposed method is tested using gated cardiac MRI, which is a well-established clinical diagnosis method for septal defect detection. Experimental results show that the proposed framework is able to successfully detect the septal defects and provide the visual assistance to the radiologist for further diagnosis. The proposed detection can be widely used in both clinical practice, surgical planning and after operation follow-up. To the best of our knowledge, the work is first such an effort.	computation;image registration;planning;radiology;robustness (computer science);software bug;time complexity	Shuwei Li;Ian G. Ross;Sukhdeep Gill;Terry M. Peters;Prakash Mahesh;Richard Rankin	2007		10.1117/12.710078	radiology;medicine;pathology;biological engineering	Vision	39.141078044493874	-79.72984686117819	119976
1be08ae74ca6e82b57ea0e1253a83debb5bf45c6	content-based retrieval of mammograms using visual features related to breast density patterns	contend based image retrieval;kohonen self organizing map;breast neoplasms;female;granulometric measures;performance evaluation;radon transform;database management systems;breast density;texture features;image processing computer assisted;breast;diagnosis computer assisted;visual features;artificial intelligence;algorithms;pattern recognition automated;humans;radiographic image interpretation computer assisted;mammography;neural networks computer;content based image retrieval;radon transform domain;information storage and retrieval;content based retrieval;neural network;image retrieval	This paper describes part of content-based image retrieval (CBIR) system that has been developed for mammograms. Details are presented of methods implemented to derive measures of similarity based upon structural characteristics and distributions of density of the fibroglandular tissue, as well as the anatomical size and shape of the breast region as seen on the mammogram. Well-known features related to shape, size, and texture (statistics of the gray-level histogram, Haralick’s texture features, and moment-based features) were applied, as well as less-explored features based in the Radon domain and granulometric measures. The Kohonen self-organizing map (SOM) neural network was used to perform the retrieval operation. Performance evaluation was done using precision and recall curves obtained from comparison between the query and retrieved images. The proposed methodology was tested with 1,080 mammograms, including craniocaudal and mediolateral-oblique views. Precision rates obtained are in the range from 79% to 83% considering the total image set. Considering the first 50% of the retrieved mages, the precision rates are in the range from 78% to 83%; the rates are in the range from 79% to 86% considering the first 25% of the retrieved images. Results obtained indicate the potential of the implemented methodology to serve as a part of a CBIR system for mammography.	artificial neural network;bilateral filter;biological neural networks;breast fibroglandular tissue;content-based image retrieval;distortion;euclidean distance;histogram;mammography;microcalcification;oblique projection;organizing (structure);performance evaluation;physiologic calcification;precision and recall;question (inquiry);radiology;radon;relevance feedback;robert haralick;self-organization;self-organizing map;seventy nine;stage level 1	Sérgio Koodi Kinoshita;Paulo Mazzoncini de Azevedo Marques;Roberto Rodrigues Pereira;Jose Antônio Heisinger Rodrigues;Rangaraj M. Rangayyan	2007	Journal of Digital Imaging	10.1007/s10278-007-9004-0	computer vision;radon transform;image retrieval;computer science;multimedia;information retrieval	Vision	34.68120622734187	-76.60477819514895	120125
39075b2045b88e81b9ba1f787048a024b0959f29	classifying treated vs. untreated mdd adolescents from anatomical connectivity using nonlinear svm		Identification of the treatment-related responders for adolescent Major Depressive Disorder (MDD) is urgently needed to develop effective treatments. In this paper, machine learning based classifiers are used to reveal anatomical features as responders for distinguishing MDD patients who have received treatment from those who never received any treatment. The features are drawn from two sets of measurements: 1) anatomical connectivity defined by diffusion tensor imaging measurements between a pair of brain regions, and 2) topological measurements from anatomical networks. Feature selection was performed based on p-value and minimum redundancy maximum relevance (mRMR) method to achieve improved classification accuracy. The classification performance is evaluated with a leave-one-out cross-validation method using 37 treated and 15 untreated subjects. The proposed methodology achieves 73% accuracy, 100% specificity, and 100% precision for 52 subjects. The most distinguishing features are the strength of the right hippocampus of the mean diffusivity (MD) network at 18% density and of the track-count (TR) network, the participation coefficient of the left middle temporal gyrus of the radial diffusivity (RD) network at 20% density, the axial diffusivity (AD) connectivity between right middle temporal gyrus and right supramarginal gyrus, the betweenness centrality of the right hippocampus of the TR network at 11% density, the apparent diffusion coefficient (ADC) connectivity between the left pars opercularis and the left rostral anterior cingulate cortex, the clustering coefficient of the middle anterior corpus callosum of the TR network at 11% density, and the AD connectivity between the left pars opercularis and the left rostral anterior cingulate cortex.	betweenness centrality;body of uterus;ct scan;cingulate cortex;classification;clustering coefficient;connected_to relation;corpus callosum;cross infection;cross-validation (statistics);diffusion tensor imaging;feature selection;machine learning;major depressive disorder;molecular dynamics;p-value;patients;radial (radio);radial basis function;relevance;ruby document format;sensitivity and specificity;structure of middle temporal gyrus;transistor;statistical cluster	Shu-Hsien Chu;Christophe Lenglet;Mindy W. Schreiner;Bonnie Klimes-Dougan;Kathryn Cullen;Keshab K. Parhi	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8513168	computer vision;anterior cingulate cortex;hippocampus;artificial intelligence;feature selection;effective diffusion coefficient;major depressive disorder;corpus callosum;diffusion mri;computer science;pattern recognition;betweenness centrality	Vision	30.113232422338474	-78.38995030372473	120144
fab26b65c74ad06c11f72e0e37f000592d3267e3	facial image medical analysis system using quantitative chromatic feature	medical face image analysis;face diagnosis;traditional chinese medicine;dominant color;chromatic feature;journal	In order to investigate whether the appearance of a human face can be utilized for diagnostic purposes, which have been practiced for thousands of years in Traditional Chinese Medicine (TCM), this paper aims to present a computerized facial image analysis system by using quantitative chromatic features for disease diagnosis applications. A face image acquisition device is dedicatedly designed to acquire image samples from volunteers who have three types of health conditions: normal health, icterohepatitis, and severe hepatitis. Then, after color calibration on the acquired images to remove noises caused by lighting fluctuations, quantitative dominant color features are extracted by fuzzy clustering method. In order to further improve the diagnosis accuracy, a feature selection procedure is involved to identify the most discriminative feature subset for the diagnostic classification. Lastly, based on these selected quantitative feature, each face image could be diagnosed into different health groups. Experiments are conducted based on a database which includes over 300 sample images, and the result shows that the overall diagnosis accuracy between healthy samples and other two diseases is higher than 88%. Hence the feasibility of disease diagnosis by inspecting the chromatic feature of human face could be verified.		Xingzheng Wang;Bob Zhang;Zhenhua Guo;David Zhang	2013	Expert Syst. Appl.	10.1016/j.eswa.2012.12.079	traditional chinese medicine;computer vision;speech recognition;feature	Vision	35.16282967995416	-74.13079573273791	120221
f6b0a07d59fcd728aa779aaa8d9683b7fa4bdbd6	a novel system for the analysis of civil aerial meteorological drawing map		Along with fast development of computer science, traditional recognition for the documents and literatures have replaced by the technique of computer auto-digitalization. Computer auto-digitalization is a popular technique which not only has the merit of low labor cost, but also has comprehensive functional extensions (multi-status, for the detection, recognition, classification and storage). However, the problem is centered in the reliability and adaptation. Bad compatibility and error-prone are universal features. So in this paper, taking a complex material, the civil aerial meteorological map, as experimental goal, we developed a novel system for the analysis of drawing map, and also introduced the detailed algorithms of it. The superiority of algorithms and efficiency of system in generating meaningful interpretation are clear from experimental results.		Xiaoguang Tian;Dayong Zhu;Xiaorong Hou	2016	KES Journal	10.3233/KES-160328	machine learning;computer science;artificial intelligence	AI	30.82596518422555	-68.11725982152306	120443
5b733e4f1d92316ccad4286023d933cf82d0b6d8	automatic thresholding of infected blood images using granulometry and regional extrema	image recognition;image recognition automatic thresholding infected blood images granulometry morphological method malaria parasites giemsa;mathematical morphology;morphological method;mathematics;image colour analysis medical image processing blood mathematical morphology image recognition;diseases cells biology pixel surface morphology mathematics biomedical imaging microscopy red blood cells data mining shape;infected blood images;microscopy;biomedical imaging;data mining;malaria parasites;surface morphology;giemsa;granulometry;shape;image colour analysis;medical image processing;blood;pixel;automatic thresholding;diseases;red blood cells;cells biology	This work introduces a morphological method for detecting malaria parasites in images of Giemsa stained blood slides. Generally, blood images are made up of three different kinds of cells: red, white and blood platelets. These are distinguished by their dimensions and their colour. In malarial blood the red corpuscles of vertebrates are infected by malaria parasites. The aim of our system is to detect the parasites by means of an automatic thresholding based on a morphological approach, using granulometries to evaluate the size of the red cells and the nuclei of parasites, and the regional maxima to mark the nuclei of parasites.	granulometry (morphology);optical granulometry;thresholding (image processing)	Cecilia Di Ruberto;Andrew G. Dempster;Shahid Khan;Bill Jarra	2000		10.1109/ICPR.2000.903579	computer vision;mathematical morphology;giemsa stain;shape;computer science;microscopy;geometry;granulometry;pixel	Vision	37.93218715423373	-75.55104648827205	120760
6cb842662cf17c64582e0a80efe12156760eaf94	semi-automatic detection of calcified plaque in coronary ct angiograms with 320-msct	eigenvalues and eigenfunctions;computed tomography;arteries;angiography;europe	Coronary CT angiography (Coronary Computed Tomography Angiography) by MSCT (Multi-Slice Computed Tomography) offers not only a diagnostic capability matching that of CAG (Coronary Angiography) that is the gold standard of the cardiovascular diagnosis, but also a much less invasive examination. However, if calcified plaque adheres to a vessel wall, high brightness shading due to calcium in the calcified plaque, called the blooming artefacts, causes to make it difficult to diagnose the region around the plaque. In this study, we propose a method to semi-automatically detect and remove calcified plaques, which hinder diagnosing a stenosed coronary artery, from a CCTA image. In addition, an analyzing method to accurately and objectively measure angiostenosis rate is provided.	chassis air guide;computed tomography angiography;semiconductor industry;shading	Yuki Yoshida;Kaori Fujisaku;Kei Sasaki;Tetsuya Yuasa;Koki Shibuya	2016	2016 24th European Signal Processing Conference (EUSIPCO)	10.1109/EUSIPCO.2016.7760539	radiology;medicine;cardiology;medical physics	Vision	38.85058430676881	-79.42761079999227	120789
743b12efc03aa0d7b8f78b332f3491382bc07899	exudate segmentation using fully convolutional neural networks and inception modules		Diabetic retinopathy is an eye disease associated with diabetes mellitus and also it is the leading cause ofrnpreventable blindness in working-age population. Early detection and treatment of DR is essential to preventrnvision loss. Exudates are one of the earliest signs of diabetic retinopathy. This paper proposes an automaticrnmethod for the detection and segmentation of exudates in fundus photographies. A novel fully convolutionalrnneural network architecture with Inception modules is proposed. Compared to other methods it does not requirernthe removal of other anatomical structures. Furthermore, a transfer learning approach is applied between smallrndatasets of different modalities from the same domain. To the best of authors’ knowledge, it is the first timernthat such approach has been used in the exudate segmentation domain. The proposed method was evaluatedrnusing publicly available E-Ophtha datasets. It achieved better results than the state-of-the-art methods in termsrnof sensitivity and specificity metrics. The proposed algorithm accomplished better results using a diseased/notrndiseased evaluation scenario which indicates its applicability for screening purposes. Simplicity, performance,rnefficiency and robustness of the proposed method demonstrate its suitability for diabetic retinopathy screeningrnapplications.	algorithm;artificial neural network;convolutional neural network;network architecture;robustness (computer science);sensitivity and specificity	Piotr Chudzik;Somshubra Majumdar;Francesco Calivà;Bashir Al-Diri;Andrew Hunter	2018		10.1117/12.2293549	convolutional neural network;robustness (computer science);modalities;transfer of learning;diabetic retinopathy;population;segmentation;pattern recognition;fundus (eye);computer science;artificial intelligence	Vision	31.94029403092766	-75.64754882326429	120947
e4bbd237f6434fe2dea0f6b7221972d0b5ef04c2	multiple adaptive neuro-fuzzy inference system with automatic features extraction algorithm for cervical cancer recognition	software;female;cell nucleus;cytoplasm;computer systems;image processing computer assisted;fuzzy logic;uterine cervical neoplasms;reproducibility of results;artificial intelligence;algorithms;humans;neural networks computer;automatic data processing	To date, cancer of uterine cervix is still a leading cause of cancer-related deaths in women worldwide. The current methods (i.e., Pap smear and liquid-based cytology (LBC)) to screen for cervical cancer are time-consuming and dependent on the skill of the cytopathologist and thus are rather subjective. Therefore, this paper presents an intelligent computer vision system to assist pathologists in overcoming these problems and, consequently, produce more accurate results. The developed system consists of two stages. In the first stage, the automatic features extraction (AFE) algorithm is performed. In the second stage, a neuro-fuzzy model called multiple adaptive neuro-fuzzy inference system (MANFIS) is proposed for recognition process. The MANFIS contains a set of ANFIS models which are arranged in parallel combination to produce a model with multi-input-multioutput structure. The system is capable of classifying cervical cell image into three groups, namely, normal, low-grade squamous intraepithelial lesion (LSIL) and high-grade squamous intraepithelial lesion (HSIL). The experimental results prove the capability of the AFE algorithm to be as effective as the manual extraction by human experts, while the proposed MANFIS produces a good classification performance with 94.2% accuracy.	adaptive neuro fuzzy inference system;analog front-end;cervix uteri;cervix carcinoma;cessation of life;classification;computer vision;high-grade squamous intraepithelial lesions;inference engine;low grade squamous intraepithelial neoplasia;neck;neoplasms;neuro-fuzzy;numerous;pap smear;smear - instruction imperative;smear campaign;stage level 1;stage level 2;uterus;vulvar high grade squamous intraepithelial lesion;algorithm;liquid-based cytology (procedure)	Mohammad Subhi Al-Batah;Nor Ashidi Mat Isa;Mohammad Fadel Jamil Klaib;Mohammed Azmi Al-Betar	2014		10.1155/2014/181245	fuzzy logic;computer vision;pathology;cytoplasm;computer science;artificial intelligence;machine learning	Vision	34.044247476438166	-76.50805844469815	121092
625936957d625e89cf2692cf58c4dd76c8542353	comparison of a genetic algorithm & hopfield neural network in segmening lung regions in chest ct images	genetic algorithm		ct scan;genetic algorithm;hopfield network	Rachid Sammouda;Jamal Abu Hassan;Mohamed Sammouda;Hatem abou ElAbbas;Abdulridha Al-Zuhairy	2005			genetic algorithm;computer science;artificial neural network;artificial intelligence;machine learning	AI	33.25615918892105	-73.14205295979146	121273
2651cfa50dcd940056102784206f32a952997d12	automated colour identification in melanocytic lesions	skin biomedical optical imaging cancer image colour analysis medical image processing quadtrees;image color analysis lesions malignant tumors skin cancer image segmentation australia;cielab1 colour space automated colour identification melanocytic lesions skin lesion dermatologists visual perception melanoma quadtree decomposition dermoscopy nih dataset ph2 dataset	Colour information plays an important role in classifying skin lesion. However, colour identification by dermatologists can be very subjective, leading to cases of misdiagnosis. Therefore, a computer-assisted system for quantitative colour identification is highly desirable for dermatologists to use. Although numerous colour detection systems have been developed, few studies have focused on imitating the human visual perception of colours in melanoma application. In this paper we propose a new methodology based on QuadTree decomposition technique for automatic colour identification in dermoscopy images. Our approach mimics the human perception of lesion colours. The proposed method is trained on a set of 47 images from NIH dataset and applied to a test set of 190 skin lesions obtained from PH2 dataset. The results of our proposed method are compared with a recently reported colour identification method using the same dataset. The effectiveness of our method in detecting colours in dermoscopy images is vindicated by obtaining approximately 93% accuracy when the CIELab1 colour space is used.	central nervous system melanocytic neoplasm;classification;color space;dermatologic disorders;dermoscopy;quadtree;sensor;silo (dataset);test set;melanoma	S. Sabbaghi;Mohammad Aldeen;Rahil Garnavi;George Andrew Varigos;C. Doliantis;J. Nicolopoulos	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7319028	dermatology;computer vision;medicine;pathology	Vision	36.378033999564025	-73.79050807048604	121337
0c116ee9141024c9c06cc0791d20dd2bb8ccc7e0	a hybrid system for locating and recognizing low level graphic items	connectionist models;morphological operation;hybrid model;hybrid system;connected component	This paper addresses the problem of locating and recognizing graphic items in document images. The proposed approach allows us to recognize such items also in the presence of high noise, scaling, and rotation. This is accomplished by a hybrid model which performs graphic item location by morphological operations and connected component analysis, and item recognition by a proper connectionist model. Some very promising experimental results are reported to support the proposed algorithms.	hybrid system	Francesca Cesarini;Marco Gori;Simone Marinai;Giovanni Soda	1995		10.1007/3-540-61226-2_12	connected component;computer science;artificial intelligence;machine learning;pattern recognition;hybrid system	NLP	34.13222003750866	-66.93282282548476	121398
8d802d6a944f8182b51ce070727fd7d7ec352004	automatic left ventricular outflow tract classification for accurate cardiac mr planning		Cardiac MR planning is important to ensure high quality image data and to enable accurate quantification of cardiac function. One result of inaccurate planning is an ‘off-axis’ orientation of the 4-chamber view, often recognized by the presence of the left ventricular outflow tract (LVOT). This can lead to difficulties in assessment of atrial volumes and septal wall motion, either manually by experts or by automated image analysis algorithms. For large datasets such as the UK biobank, manual labelling is tedious and automated analysis pipelines including automatic image quality assessment need to be developed. In this paper, we propose a method to automatically detect the presence of the LVOT in cardiac MRI, which can aid identifying poorly planned 4-chamber images. Our method is based on Convolutional Neural Networks (CNNs) and is able to detect LVOT in 4-chamber images in less than 1ms. We test our algorithm on a subset of the UK biobank dataset (246 cardiac MR images) and achieve an average accuracy of 83%. We compare our approach to a range of state of the art classification methods.	algorithm;convolutional neural network;display resolution;image analysis;image quality;pipeline (computing);tract (literature);uk biobank	Ilkay Öksüz;Bram Ruijsink;Esther Puyol-Antón;Matthew Sinclair;Daniel Rueckert;Julia A. Schnabel;Andrew P. King	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363616	convolutional neural network;computer vision;pattern recognition;image quality;artificial intelligence;cardiac function curve;computer science;ventricular outflow tract	Vision	37.960221262498266	-79.99780678394968	121616
3f99feb5458a358580cbce20efdcffc2f3ca9038	vitisflower®: development and testing of a novel android-smartphone application for assessing the number of grapevine flowers per inflorescence using artificial vision techniques	biological patents;yield prediction;biomedical journals;text mining;opencv library;europe pubmed central;articulo;citation search;precision viticulture;opencv4android;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;image analysis;precision agriculture;full text;grapevine flower counting;vitis vinifera l;android application;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Grapevine flowering and fruit set greatly determine crop yield. This paper presents a new smartphone application for automatically counting, non-invasively and directly in the vineyard, the flower number in grapevine inflorescence photos by implementing artificial vision techniques. The application, called vitisFlower(®), firstly guides the user to appropriately take an inflorescence photo using the smartphone's camera. Then, by means of image analysis, the flowers in the image are detected and counted. vitisFlower(®) has been developed for Android devices and uses the OpenCV libraries to maximize computational efficiency. The application was tested on 140 inflorescence images of 11 grapevine varieties taken with two different devices. On average, more than 84% of flowers in the captures were found, with a precision exceeding 94%. Additionally, the application's efficiency on four different devices covering a wide range of the market's spectrum was also studied. The results of this benchmarking study showed significant differences among devices, although indicating that the application is efficiently usable even with low-range devices. vitisFlower is one of the first applications for viticulture that is currently freely available on Google Play.	android;computer vision;flowers;greater than;heart rate variability;image analysis;inflorescence;libraries;microsoft outlook for mac;mobile app;norm (social);opencv;play store;smartphone;flower allergenic extracts	Arturo Aquino;Borja Millán;Daniel Gaston;María-Paz Diago;Javier Tardáguila	2015		10.3390/s150921204	text mining;image analysis;simulation;computer science;engineering;data mining;precision agriculture;precision viticulture	HCI	37.4626902614339	-69.99704979020642	122977
9cc3edcd6619c5c8f3cc210af0d62a062677e5a8	deep multiscale convolutional feature learning for weakly supervised localization of chest pathologies in x-ray images		Localization of chest pathologies in chest X-ray images is a challenging task because of their varying sizes and appearances. We propose a novel weakly supervised method to localize chest pathologies using class aware deep multiscale feature learning. Our method leverages intermediate feature maps from CNN layers at different stages of a deep network during the training of a classification model using image level annotations of pathologies. During the training phase, a set of layer relevance weights are learned for each pathology class and the CNN is optimized to perform pathology classification by convex combination of feature maps from both shallow and deep layers using the learned weights. During the test phase, to localize the predicted pathology, the multiscale attention map is obtained by convex combination of class activation maps from each stage using the layer relevance weights learned during the training phase. We have validated our method using 112000 X-ray images and compared with the state-of-the-art localization methods. We experimentally demonstrate that the proposed weakly supervised method can improve the localization performance of small pathologies such as nodule and mass while giving comparable performance for bigger pathologies e.g., Cardiomegaly.	experiment;feature learning;map;relevance;supervised learning	Suman Sedai;Dwarikanath Mahapatra;Zongyuan Ge;Rajib Chakravorty;Rahil Garnavi	2018		10.1007/978-3-030-00919-9_31	artificial intelligence;pattern recognition;computer science;feature learning;convex combination	Vision	30.91126592521723	-75.48598804440233	123290
fa515480f2d4f2c7d188fe34cb7ca3c7149b0553	construction of neural networks to select harmonious color combinations	harmonious color;learning;color;performance;recognition accuracy;armonica;harmonic;training rule;aprendizaje;apprentissage;harmonique;color combinations;pattern recognition;couleur;reconnaissance forme;rendimiento;reseau neuronal;reconocimiento patron;red neuronal;neural network	Abstract#R##N##R##N#Humans have a sense of color which, when a color is presented, can determine another color that is harmonious to the presented color (called harmonious color combination). This paper considers the two-color combination problem, which is to decide whether or not the two given colors are harmonious. The three-layered neural network with the error backpropagation learning is used to realize on a computer the color combination aesthetics of an individual trained in color harmonization.#R##N##R##N##R##N##R##N#The performance of the realized system is examined. The result obtained by the constructed system is the correct recognition rate of 97 percent for the learned data and approximately 70 percent for the unlearned data. The correct recognition rate for the unlearned data agrees almost with the rate of coincidence when the same subject selected the harmonious color twice. It is observed also that the color selection histogram pattern of the neural network is very similar to that of the subject. It is possible to identify the original subject from the tendency of the color selection tendency of the neural network. Thus, it is verified that the model is constructed reflecting well the color selection aesthetics of the subject.	artificial neural network	Kunihiko Hirano;Juichi Miyamichi	1992	Systems and Computers in Japan	10.1002/scj.4690231004	computer vision;performance;computer science;artificial intelligence;machine learning;harmonic;pattern recognition;artificial neural network;algorithm	Robotics	33.46343293489242	-67.58292252404392	123447
46bbe27e25f5ad07b40b83aa44457a4dff295212	effect of image standardization on flair mri for brain extraction		Fluid attenuation inversion recovery (FLAIR) magnetic resonance images (MRI) are being used by physicians to identify and analyze white matter lesions in the brain to determine whether patients are at risk of stroke. Pipelines used to analyze these images require a preprocessing step of brain extraction in order to be robust and to be applied to multicenter, large-scale studies. This paper proposes a novel brain extraction tool solely for the FLAIR modality, as well as a robust standardization pipeline that eliminates variability between datasets by reducing image noise, intensity inhomogeneity, patient movement, and the nonstandardness of tissue intensities, which are inherent in MRI. Feature extraction is performed on the standardized dataset, and a brain segmentation is produced by a random forest classifier. The effects of the standardization steps are evaluated using objective metrics, and the resultant segmentations produced by the unstandardized and standardized images are compared. By implementing a robust standardization pipeline, images acquired from different scanners at different centers can be processed automatically and accurately, allowing for the fast processing of large-scale, multicenter data.		Brittany Reiche;Alan R. Moody;April Khademi	2015	Signal, Image and Video Processing	10.1007/s11760-015-0831-z	computer vision;computer science;data mining	Vision	38.28777893014267	-80.18847151077087	123550
86fd5ae8d49687b8d0ae13bfe4d93ee30873cc24	a system of microcalcifications detection and evaluation of the radiologist: comparative study of the three main races in malaysia	working time;radiologist;cancer;receiver operator curve;microcalcifications;client server;visual inspection;digital image;mammogram;breast cancer;wavelets;qa75 5 76 95 electronic computers computer science	This paper uses wavelets in the detection comparison of breast cancer among the three main races in Malaysia: Chinese, Malays, and Indians followed by a system that evaluates the radiologist's findings over a period of time to gauge the radiologist's skills in confirming breast cancer cases. The db4 wavelet has been utilized to detect microcalcifications in mammogram-digitized images obtained from Malaysian women sample. The wavelet filter's detection evaluation was done by visual inspection by an expert radiologist to confirm the detection results of those pixels that corresponded to microcalcifications. Detection was counted if the wavelet-detected pixels corresponded to the radiologist's identified microcalcification pixels. After the radiologist's detection confirmation a new client-server radiologist recording and evaluation system is designed to evaluate the findings of the radiologist over some period of cancer detection working time. It is a system that records the findings of the Malaysian radiologist for the presence of breast cancer in Malaysian patients and provides a way of registering the progress of detecting breast cancer of the radiologist by tracking certain metric values such as the sensitivity, specificity, and receiver operator curve (ROC). The initial findings suggest that no single race mammograms are easier for wavelets' detections of microcalcifications and for the radiologist confirmation even though for this study the Chinese race samples detection average were a few percentages less than the other two races, namely the Malay and Indian races.		Majdi Al-Qdah;Abdul Rahman Ramli;Rozi Mahmud	2005	Computers in biology and medicine	10.1016/j.compbiomed.2004.06.010	wavelet;computer vision;simulation;radiology;medicine;pathology;computer science;breast cancer;receiver operating characteristic;digital image;client–server model;statistics;cancer;visual inspection	Security	34.48516700749588	-78.99533899410736	123636
d8cf6d4056c4c01d1303ab0aaa841d670a41df56	accurate automatic segmentation of retina layers with emphasis on first layer		Quantification of intra-retinal boundaries in optical coherence tomography (OCT) is a crucial task for studying and diagnosing neurological and ocular diseases. Since manual segmentation of layers is usually a time consuming task and relay on user, a lot of attempts done to do it automatically and without interference of user. Although for extracting all layers usually same procedure is applied but finding the first layer is usually more difficult due to vanishing it in some region specially close to Fobia. To have a general software, beside using common methods like applying shortest path algorithm on global gradient of image, some extra steps are used here to confine search area for Dijstra algorithm especially for the second layer. Results demonstrates high accuracy in segmenting all present layers, especially the first one that is important for diagnosing issue.		Mahdi Salarian	2015	CoRR		computer vision;simulation;computer science	NLP	32.334432654005376	-76.03219314479348	123814
2246002d866dae1152936ea5ac570fda92639639	symtosis: a liver ultrasound tissue characterization and risk stratification in optimized deep learning paradigm		Background and Objective Fatty Liver Disease (FLD) - a disease caused by deposition of fat in liver cells, is predecessor to terminal diseases such as liver cancer. The machine learning (ML) techniques applied for FLD detection and risk stratification using ultrasound (US) have limitations in computing tissue characterization features, thereby limiting the accuracy.  Methods Under the class of Symtosis for FLD detection and risk stratification, this study presents a Deep Learning (DL)-based paradigm that computes nearly seven million weights per image when passed through a 22 layered neural network during the cross-validation (training and testing) paradigm. The DL architecture consists of cascaded layers of operations such as: convolution, pooling, rectified linear unit, dropout and a special block called inception model that provides speed and efficiency. All data analysis is performed in optimized tissue region, obtained by removing background information. We benchmark the DL system against the conventional ML protocols: support vector machine (SVM) and extreme learning machine (ELM).  Results The liver US data consists of 63 patients (27 normal/36 abnormal). Using the K10 cross-validation protocol (90% training and 10% testing), the detection and risk stratification accuracies are: 82%, 92% and 100% for SVM, ELM and DL systems, respectively. The corresponding area under the curve is: 0.79, 0.92 and 1.0, respectively. We further validate our DL system using two class biometric facial data that yields an accuracy of 99%.  Conclusion DL system shows a superior performance for liver detection and risk stratification compared to conventional machine learning systems: SVM and ELM.	area under curve;artificial neural network;benchmark (computing);biological neural networks;biometrics;chemical vapor deposition;convolution;cross infection;cross reactions;cross-validation (statistics);deep learning;dropout (neural networks);elm;hl7publishingsubsection <operations>;hepatocyte;liver diseases;machine learning;ninety nine;paget's disease, mammary;patients;platelet glycoprotein 4, human;programming paradigm;protocols documentation;rectifier (neural networks);stratification;support vector machine;anatomical layer	Mainak Biswas;Venkatanareshbabu Kuppili;Damodar Reddy Edla;Harman S. Suri;Luca Saba;Rui Tato Marinho;J. Miguel Sanches;Jasjit S. Suri	2018	Computer methods and programs in biomedicine	10.1016/j.cmpb.2017.12.016	computer vision;support vector machine;computer science;artificial intelligence;extreme learning machine;artificial neural network;deep learning;biometrics;fatty liver;rectifier (neural networks);convolution;pattern recognition	ML	32.32157351332017	-75.42975350717997	123939
5bdb0d7329da678a1324573a13cc7c3c5728578e	segmented handwritten text recognition with recurrent neural network classifiers	hidden markov models computational modeling handwriting recognition artificial neural networks	Recognition of handwritten text is a useful technique that can be applied in different applications, such as signature recognition, bank check recognition, etc. However, the off-line handwritten text recognition in an unconstrained situation is still a very challenging task due to the high complexity of text strokes and image background. This paper presents a novel segmented handwritten text recognition technique that ensembles recurrent neural network (RNN) classifiers. Two RNN models are first trained that take advantage of the widely used geometrical feature and the Histogram of Oriented Gradient (HOG) feature, respectively. Given a handwritten word image, the optimal recognition result is then obtained by integrating the two trained RNN models together with a lexicon. Experiments on public datasets show the superior performance of our proposed technique.	artificial neural network;experiment;gradient;lexicon;online and offline;optical character recognition;random neural network;recurrent neural network;signature recognition	Bolan Su;Xi Zhang;Shijian Lu;Chew Lim Tan	2015	2015 13th International Conference on Document Analysis and Recognition (ICDAR)	10.1109/ICDAR.2015.7333789	speech recognition;intelligent character recognition;computer science;intelligent word recognition;machine learning;pattern recognition;neocognitron	Vision	32.61891381429888	-66.21447856348499	124323
fe99b1dd784a9470f3c1b20fbfa7498ce25283b3	topo-geometric filtration scheme for geometric active contours and level sets: application to cerebrovascular segmentation		One of the main problems of the existing methods for the segmentation of cerebral vasculature is the appearance in the segmentation result of wrong topological artefacts such as the kissing vessels. In this paper, a new approach for the detection and correction of such errors is presented. The proposed technique combines robust topological information given by Persistent Homology with complementary geometrical information of the vascular tree. The method was evaluated on 20 images depicting cerebral arteries. Detection and correction success rates were 81.80% and 68.77%, respectively.	benign childhood cerebral neoplasm;blood vessel;blood supply aspects;homology (biology);morphologic artifacts;persistent homology;segmentation action;structure of cerebral artery;topo;filtration	Helena Molina-Abril;Alejandro F. Frangi	2014	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-319-10404-1_94	computer vision;topology;mathematics;geometry	Robotics	38.515938251407384	-77.44555531491815	124415
22b542c8506655b89fd09bb50b49bacb2956edbf	3d topology optimization using convolutional neural networks		Topology optimization is computationally demanding that requires the assembly and solution to a finite element problem for each material distribution hypothesis. As a complementary alternative to the traditional physics-based topology optimization, we explore a data-driven approach that can quickly generate accurate solutions. To this end, we propose a deep learning approach based on a 3D encoder-decoder Convolutional Neural Network architecture for accelerating 3D topology optimization and to determine the optimal computational strategy for its deployment. Analysis of iteration-wise progress of the Solid Isotropic Material with Penalization process is used as a guideline to study how the earlier steps of the conventional topology optimization can be used as input for our approach to predict the final optimized output structure directly from this input. We conduct a comparative study between multiple strategies for training the neural network and assess the effect of using various input combinations for the CNN to finalize the strategy with the highest accuracy in predictions for practical deployment. For the best performing network, we achieved about 40% reduction in overall computation time while also attaining structural accuracies in the order of 96%. Keywords— Deep learning, data-driven 3D topology optimization, Convolutional Neural Networks	artificial neural network;computation;convolutional neural network;deep learning;encoder;finalize (optical discs);finite element method;iteration;mathematical optimization;network architecture;neural network software;software deployment;time complexity;topology optimization	Saurabh Banga;Harsh Gehani;Sanket Bhilare;Sagar C Patel;Levent Kara	2018	CoRR		convolutional neural network;machine learning;software deployment;architecture;computation;deep learning;finite element method;artificial neural network;mathematics;artificial intelligence;topology optimization	ML	29.447364851830383	-74.42277494406035	124485
3a3d5989138a9ba91b16d776e5367f91215cbb65	automated visual inspection of rolled metal surfaces	image processing;copper alloy;automated visual inspection;product line;surface defects;image acquisition;machine vision	A prototype for an automated visual on-line metal strip inspection system is described. The system is capable of both detecting and classifying surface defects in copper alloy strips, and it has been installed for evaluation in a production line in a rolling mill. The image acquisition part of the system is based on a CCD line scan camera and condensing bright field illuminators. The inspection algorithms are based on morphological preprocessing and combined statistical and structural defect recognition. The image processing hardware consists of commercial modules. An analysis of this implementation is presented. A similar inspection principle has also been successfully applied to steel strip inspection.	algorithm;alloy (specification language);charge-coupled device;image processing;line level;online and offline;preprocessor;prototype;strips;sensor;software bug;visual inspection	Timo Piironen;Olli Silvén;Matti Pietikäinen;Toni Laitinen;Esko Strömmer	1990	Machine Vision and Applications	10.1007/BF01211850	computer vision;machine vision;image processing;automated x-ray inspection;computer science;automated optical inspection	Robotics	36.94250361797277	-68.38078892178613	124585
7f780b19812bf72420e2fd685899c9ff4cb07bac	sensitivity characterization by impression and color words	painting;painting classification;art;distance measure;color;color words;similarity relation;self organising feature maps image classification image colour analysis;image classification;data mining;two layered neural network;recommendation system;brightness;impression words;recommender system;self organising feature maps;image color analysis;image colour analysis;recommendation system sensitivity characterization painting classification impression words color words self organizing map two layered neural network;sensitivity characterization;self organizing map;painting humans art neural networks artificial intelligence information science heart earth image databases multimedia databases;self organized map;neural network	Paintings have some sensibility information to human hearts. But, the sensibility information will be different to person to person. We like some paintings, while other persons like another ones. For appreciation of paintings, grouping of paintings with similar sensitivity will be helpful. In this paper, we developed a distance measure relation among paintings for similarity grouping. Four similarity relations (types) are developed by the distance measure for classification of paintings. Impression words and color words play an important role for the sensibility expression of paintings. To verify the combination of these words, a self-organizing map(SOM) by two layered neural network, was applied for the grouping of paintings. It was shown that the combination of the impression words and color ones make a well similar grouping of paintings. Grouping similar paintings in impression words and color ones will be useful for a recommendation system.	artificial neural network;color;organizing (structure);recommender system;self-organization;semantic similarity;similarity measure;top-down and bottom-up design;xslt/muenchian grouping	Naohiro Ishii;Yusaku Tokuda;Ippei Torii;Tomomi Kanda	2009	2009 21st IEEE International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2009.50	computer vision;painting;computer science;artificial intelligence;machine learning;multimedia;brightness;recommender system	Robotics	32.06533802895565	-70.18720385164121	124823
94809366866c4f818fa85be11b801af25130bc1c	automatic classification of thyroid histopathology images using multi-classifier system		A computer aided diagnosis system supports doctors by providing quantitative diagnostic clues from medical data. In this paper, we propose a computer aided diagnosis (CAD) system to automatically discriminate hematoxylin and eosin (H&E)-stained thyroid histopathology images either as normal thyroid (NT) images or as papillary thyroid carcinoma (PTC) images. The CAD system incorporates a multi-classifier system to maximize the diagnostic accuracy of classification. Thyroid histopathology images are provided as input to the CAD system. The input images are enhanced and the nuclei present in the images are segmented automatically. Shape and texture features are extracted from the segmented images. Classification of the features is studied using classifiers such as support vector machine (SVM), naive Bayes (NB), K-nearest neighbor (K-nn) and closest matching rule (CMR) either as stand alone classifiers or as combinations to form multi-classifier systems. The multi-classifier system which provides the best accuracy is found out experimentally. The CAD system thus formed can be used as a second opinion to assist pathologists.	computer-aided design;experiment;k-nearest neighbors algorithm;learning classifier system;naive bayes classifier;pupillary distance;support vector machine	J. Angel Arul Jothi;V. Mary Anita Rajam	2017	Multimedia Tools and Applications	10.1007/s11042-017-4363-0	artificial intelligence;computer science;support vector machine;naive bayes classifier;computer vision;computer-aided diagnosis;pattern recognition;classifier (linguistics);histopathology;thyroid	ML	34.622624557811584	-75.8650004112891	124958
fd9b86fb36a0b48e4eca0d73f8c3c683fdaf6231	super-high-purity seed sorter using low-latency image-recognition based on deep learning		Most commercial optical sorting systems are designed to achieve high throughput, so they use a naive low-latency image processing for object identification. These naive low-latency algorithms have difficulty in accurately identifying objects with various shapes, textures, sizes, and colors, so the purity of sorted objects is degraded. Current deep learning technology enables robust image detection and classification, but its inference latency requires several milliseconds; thus, deep learning cannot be directly applied to such real-time high throughput applications. We therefore developed a super-high purity seed sorting system that uses a low-latency image-recognition based on a deep neural network and removes the seeds of noxious weeds from mixed seed product at high throughput with accuracy. The proposed system partitions the detection task into localization and classification, and applies batch inference only once strategy; it achieved 500-fps throughput image-recognition including detection and tracking. Based on the classified and tracked results, air ejectors expel the unwanted seeds. This proposed system eliminates almost the whole weeds with small loss of desired seeds, and is superior to current commercial optical sorting systems.	algorithm;artificial neural network;bitonic sorter;classification;color;computer vision;deep learning;image processing;inference;internationalization and localization;neural network simulation;physical object;plant weeds;plant seeds;purity (quantum mechanics);real-time clock;seed;sorting;throughput	Young Jin Heo;Se Jin Kim;Dayeon Kim;Keondo Lee;Wan Kyun Chung	2018	IEEE Robotics and Automation Letters	10.1109/LRA.2018.2849513	throughput;image processing;latency (engineering);artificial neural network;latency (engineering);deep learning;optical sorting;engineering;computer vision;sorting;artificial intelligence	Robotics	30.55982287661459	-71.18374161573857	125230
32ad4c92a606a956e21754398212ce70bdb8ccde	segmentation and localisation of whole slide images using unsupervised learning	unsupervised learning;image localisation;image segmentation;digital pathology;high resolution images;tissue type whole slide images unsupervised learning digital pathology high resolution images scanning time memory space image segmentation image localisation;tissue type;memory space;scanning time;whole slide images;unsupervised learning biological tissues image resolution image segmentation medical image processing	Digital pathology has been clinically approved for over a decade to replace traditional methods of diagnosis. Many challenges appear when digitising the whole slide scan into high resolution images including memory and time management. Whole slide images require huge memory space if the tissue is not pre-localised for the scanner. The authors propose a set of clinically motivated features representing colour, intensity, texture and location to segment and localise the tissue from the whole slide image. This step saves both the scanning time and the required memory space. On average, it reduces scanning time up to 40% depending on the tissue type. The authors propose, using unsupervised learning, to segment and localise tissue by clustering. Unlike supervised methods, this method does not require the ground truth which is time consuming for domain experts. The authors proposed method achieves an average of 96% localisation accuracy on a large dataset. Moreover, the authors outperform the previously proposed supervised learning results on the same data.	cluster analysis;dspace;ground truth;image resolution;language localisation;supervised learning;unsupervised learning	Hazem Hiary;Raja' S. Alomari;Vipin Chaudhary	2013	IET Image Processing	10.1049/iet-ipr.2013.0008	unsupervised learning;computer vision;computer science;machine learning;pattern recognition;image segmentation	Vision	36.20274678192281	-75.21502462673232	125293
1a41b159ce1d7600e59bdf2bc062be93f25d89da	deep learning models for plant disease detection and diagnosis		Abstract In this paper, convolutional neural network models were developed to perform plant disease detection and diagnosis using simple leaves images of healthy and diseased plants, through deep learning methodologies. Training of the models was performed with the use of an open database of 87,848 images, containing 25 different plants in a set of 58 distinct classes of [plant, disease] combinations, including healthy plants. Several model architectures were trained, with the best performance reaching a 99.53% success rate in identifying the corresponding [plant, disease] combination (or healthy plant). The significantly high success rate makes the model a very useful advisory or early warning tool, and an approach that could be further expanded to support an integrated plant disease identification system to operate in real cultivation conditions.	deep learning	Konstantinos P. Ferentinos	2018	Computers and Electronics in Agriculture	10.1016/j.compag.2018.01.009	convolutional neural network;computer vision;artificial intelligence;machine learning;deep learning;engineering;warning system	AI	32.50060687953252	-75.76289757381171	125596
6357af7526691d9e4c3883d1fb3aaca4641f678f	combining hmm-based two-pass classifiers for off-line word recognition	hmm model;cursive handwritten word recognition;degradation;image segmentation handwritten character recognition hidden markov models;nist;handwriting recognition;image segmentation;hidden markov model;error analysis;relative error;hidden markov models;stochastic processes;hidden markov models handwriting recognition voting character recognition computer science nist error analysis stochastic processes degradation man machine systems;voting;viterbi algorithm;weighted voting;word recognition;two pass modeling;nist sample hand print data hidden markov models hmm model cursive handwritten word recognition image segmentation two pass modeling viterbi algorithm weighted voting;computer science;nist sample hand print data;character recognition;man machine systems;handwritten character recognition	For off-line recognition of cursive handwritten word, the intersection between segmentation and recognition is complicated and makes the recognition problem still a challenging task. Hidden Markov models (HMMs) have the ability to perform segmentation and recognition in a single step. In this paper we present an HMM based unsymmetric two-pass modeling approach for recognizing cursive handwritten word. The two-pass recognition approach exploits the segmentation ability of the Viterbi algorithm and creates three different HMM sets and carries out two passes of recognition. A weighted voting approach is used to combine results of the two recognition passes. A high recognition rate was achieved for recognizing cursive handwritten words with a lexicon of 1120 words. An experiment on NIST sample hand print data of ten different writers was also carried out. The experimental results demonstrate that the two-pass approach can achieve better recognition performance and reduce the relative error rate significantly.	hidden markov model	Wenwei Wang;Anja Brakensiek;Gerhard Rigoll	2002		10.1109/ICPR.2002.1047817	speaker recognition;approximation error;speech recognition;degradation;nist;voting;word recognition;intelligent character recognition;viterbi algorithm;computer science;intelligent word recognition;machine learning;pattern recognition;image segmentation;weighted voting;hidden markov model;signature recognition	Vision	32.56593567882694	-66.33955376793878	125605
b5483bef190d7feab5c4c1dc9075ccd84aeecb7c	asbestos detection method with frequency analysis for microscope images	building material;building construction;frequency analysis	In this paper, we propose an asbestos detection method focusing on frequency distribution of microscopic images. In building construction, asbestos has been used for molding plates and heat insulation materials. However, increased injury caused by asbestos has become a problem in Japan. Removal of asbestos from building materials and rendering it harmless are common means of alleviating asbestos hazards. Nevertheless, those processes necessitate a judgment of whether asbestos is included in building materials. According to the JIS standards, it is necessary to count 3000 particles in microscopic images. We consider the asbestos shape, and define a new feature obtained through frequency analysis. The proposed method intensifies the low-brightness asbestos using its feature, so it can detect not only high-brightness particles and asbestos but also low-brightness asbestos. We underscore the effectiveness of the method by comparing its results with results counted by an expert.	frequency analysis	Hikaru Kumagai;Soichiro Morishita;Kuniaki Kawabata;Hajime Asama;Taketoshi Mishima	2009		10.1007/978-3-642-10520-3_40	computer science;frequency analysis	Vision	38.39413335912285	-68.3592979361701	125863
57b04a5c8156b7daa6a8a2a5ee9cd1553b4315a9	lymph node detection in 3-d chest ct using a spatial prior probability	detectors;mediastinal lymph nodes;radiology;lymph nodes computed tomography detectors cancer filters humans shape anatomical structure pattern recognition radiology;anatomical structure;atlas matching;heart;computed tomography;cancer;image matching;lymph node detection;training;filters;statistical distributions;shape;statistical distributions computerised tomography image matching learning artificial intelligence medical image processing;esophagus;spatial distribution;discrimination learning;medical image processing;computerised tomography;detection rate;pattern recognition;true positive;3d chest ct;spatial prior probability;discriminative learning;humans;cross validation;cross validation lymph node detection 3d chest ct computerised tomography spatial prior probability discriminative learning spatial distribution atlas matching;learning artificial intelligence;false positive;anatomical variation;lymph nodes;lymph node	Lymph nodes have high clinical relevance but detection is challenging as they are hard to see due to low contrast and irregular shape. In this paper, a method for fully automatic mediastinal lymph node detection in 3-D computed tomography (CT) images of the chest area is proposed. Discriminative learning is used to detect lymph nodes based on their appearance. Because lymph nodes can easily be confused with other structures, it is vital to incorporate as much anatomical knowledge as possible to achieve good detection rates. Here, a learned prior of the spatial distribution is proposed to model this knowledge. As atlas matching is generally inaccurate in the chest area because of anatomical variations, this prior is not learned in the space of a single atlas, but in the space of multiple ones that are attached to anatomical structures. During test, the priors are weighted and merged according to spatial distances. Cross-validation on 54 CT datasets showed that the prior based detector yields a true positive rate of 52.3% for seven false positives per volume image, which is about two times better than without a spatial prior.	ct scan;relevance;sensitivity and specificity;tomography	Johannes Feulner;Shaohua Kevin Zhou;Martin Huber;Joachim Hornegger;Dorin Comaniciu;Alexander Cavallaro	2010	2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2010.5540034	probability distribution;detector;type i and type ii errors;shape;computer science;mathematics;computed tomography;heart;cross-validation;statistics;discrimination learning;cancer	Vision	35.23501000539912	-77.40415570776071	126057
3607df7c37a06c6566140bf977c83901dfd8a4c3	computer-aided diagnostic scheme for distinction between benign and malignant nodules in thoracic low-dose ct by use of massive training artificial neural network	patient diagnosis;lung cancer;low dose;low dose ct;computer aided diagnostic;computed tomography;computer aided diagnosis;cancer;neural nets;receiver operator characteristic;nonlinear filter;dosimetry;massive training artificial neural network;lung;lung nodules computer aided diagnostic scheme benign nodules malignant modules thoracic ct low dose ct massive training neural network artificial neural network low dose computed tomography helical computed tomography lung cancer screening nonlinear filter two dimensional gaussian distribution likelihood pf malignancy receiver operating characteristic analysis round robin test;medical computing;lung nodule;computer aided diagnosis cad;round robin;computer networks cancer artificial neural networks lungs computed tomography education nonlinear filters gaussian distribution databases performance analysis;lung nodule artificial neural network computer aided diagnosis cad likelihood of malignancy low dose ct;roc analysis;gaussian distribution patient diagnosis computerised tomography dosimetry artificial intelligence neural nets medical computing lung cancer;computerised tomography;algorithms artificial intelligence coin lesion pulmonary humans lung neoplasms neural networks computer pattern recognition automated radiation dosage radiographic image enhancement radiographic image interpretation computer assisted radiography thoracic reproducibility of results retrospective studies sensitivity and specificity tomography spiral computed;roc curve;artificial intelligence;likelihood of malignancy;gaussian distribution;artificial neural network	"""Low-dose helical computed tomography (LDCT) is being applied as a modality for lung cancer screening. It may be difficult, however, for radiologists to distinguish malignant from benign nodules in LDCT. Our purpose in this study was to develop a computer-aided diagnostic (CAD) scheme for distinction between benign and malignant nodules in LDCT scans by use of a massive training artificial neural network (MTANN). The MTANN is a trainable, highly nonlinear filter based on an artificial neural network. To distinguish malignant nodules from six different types of benign nodules, we developed multiple MTANNs (multi-MTANN) consisting of six expert MTANNs that are arranged in parallel. Each of the MTANNs was trained by use of input CT images and teaching images containing the estimate of the distribution for the """"likelihood of being a malignant nodule"""", i.e., the teaching image for a malignant nodule contains a two-dimensional Gaussian distribution and that for a benign nodule contains zero. Each MTANN was trained independently with ten typical malignant nodules and ten benign nodules from each of the six types. The outputs of the six MTANNs were combined by use of an integration ANN such that the six types of benign nodules could be distinguished from malignant nodules. After training of the integration ANN, our scheme provided a value related to the """"likelihood of malignancy"""" of a nodule, i.e., a higher value indicates a malignant nodule, and a lower value indicates a benign nodule. Our database consisted of 76 primary lung cancers in 73 patients and 413 benign nodules in 342 patients, which were obtained from a lung cancer screening program on 7847 screenees with LDCT for three years in Nagano, Japan. The performance of our scheme for distinction between benign and malignant nodules was evaluated by use of receiver operating characteristic (ROC) analysis. Our scheme achieved an Az (area under the ROC curve) value of 0.882 in a round-robin test. Our scheme correctly identified 100% (76/76) of malignant nodules as malignant, whereas 48% (200/413) of benign nodules were identified correctly as benign. Therefore, our scheme may be useful in assisting radiologists in the diagnosis of lung nodules in LDCT."""	arabic numeral 0;artificial neural network;biopsy;ct scan;carcinoma of lung;chest;computer-aided design;diagnostic techniques, ophthalmological;malignant childhood central nervous system neoplasm;malignant neoplasm of lung;modality (human–computer interaction);neoplasms;nodule;nonlinear system;numerous;patients;receiver operating characteristic;receiver operator characteristics;round-robin scheduling;spiral computed tomography;tsh-producing pituitary gland carcinoma;tomography, spiral computed;urinary sphincter, artificial	Kenji Suzuki;Feng Li;Shusuke Sone;Kunio Doi	2005	IEEE Transactions on Medical Imaging	10.1109/TMI.2005.852048	radiology;medicine;pathology;computer science;machine learning;receiver operating characteristic;artificial neural network;medical physics	ML	33.88410747804705	-78.23389314009624	126338
005bdff289eedc5c2c336d202b2bb596e82c51ee	a new scheme to evaluate the accuracy of knowledge representation in automated breast cancer diagnosis	breast ultrasound image database knowledge representation accuracy evaluation automated breast cancer diagnosis computer aided diagnosis system cad systems advanced computation ability artificial intelligence system benign lesions malignant lesions breast imaging reporting and data system birads features classifiers digital features feature measurement procedure;visual databases biomedical ultrasonics cancer feature extraction image classification knowledge representation medical image processing;automated breast cancer diagnosis knowledge representation evaluation and measurement;lesions accuracy breast cancer ultrasonic imaging learning systems	In the field of breast cancer diagnosis, computer-aided diagnosis (CAD) systems can provide doctors important second opinions, relying on the advanced computation ability and artificial intelligence of computing systems. The collaboration between doctors and CAD systems can help reducing the false diagnosis rate. Knowledge representation is an important chain for any artificial intelligence system, including automated breast cancer diagnosis. The breast cancer experts' knowledge of distinguishing benign and malignant lesions is well described by Breast Imaging Reporting and Data System (BIRADS). Many digital formulas have been proposed to quantify BIRADS features. However, there is no direct evaluation scheme for these digital features. A common way that people evaluate digital features is using them as the input for classifiers, such as machine learning methods, and then evaluating the performance of classifiers, which indirectly serves as the evaluation of digital features. The performance of a classifier is affected by the digital features, but also affected by other factors. It is inaccurate to use only the performance of classifiers as the metric to evaluate digital features. The vision of this work is to separate the evaluation of digital features from the evaluation of classifiers, with the purpose of providing an accurate feature measurement procedure and improving the quality of knowledge representation. An independent feature evaluation scheme without using any automatic classifier is proposed. Such a scheme can directly evaluate how precisely experts' knowledge is represented in computerized systems. Several commonly used digital features and newly proposed digital features in this work are evaluated using this scheme on a breast ultrasound image database. Pathological results and radiologist's opinions serve as the ground truth for evaluation purpose.	artificial intelligence system;bi-rads;computation;computer-aided design;data system;ground truth;knowledge representation and reasoning;lazy evaluation;machine learning;radiology;statistical classification	Juan Shan;Lin Li	2014	2014 International Conference on Collaboration Technologies and Systems (CTS)	10.1109/CTS.2014.6867636	computer vision;computer science;machine learning	AI	34.059589350886924	-77.50374932946772	126367
05c1dbf35e90dfd9b90a6b5ed5bb8e669d2b0f33	gaussian mixture models and semantic gating improve reconstructions from human brain activity	unsupervised learning;biological patents;bayesian network;biomedical journals;fmri;text mining;europe pubmed central;reconstruction;citation search;semantic categories;data fusion;citation networks;probabilistic inference;article letter to editor;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Better acquisition protocols and analysis techniques are making it possible to use fMRI to obtain highly detailed visualizations of brain processes. In particular we focus on the reconstruction of natural images from BOLD responses in visual cortex. We expand our linear Gaussian framework for percept decoding with Gaussian mixture models to better represent the prior distribution of natural images. Reconstruction of such images then boils down to probabilistic inference in a hybrid Bayesian network. In our set-up, different mixture components correspond to different character categories. Our framework can automatically infer higher-order semantic categories from lower-level brain areas. Furthermore, the framework can gate semantic information from higher-order brain areas to enforce the correct category during reconstruction. When categorical information is not available, we show that automatically learned clusters in the data give a similar improvement in reconstruction. The hybrid Bayesian network leads to highly accurate reconstructions in both supervised and unsupervised settings.	bayesian network;categories;cerebral cortex;electroencephalography;inference;mixture model;normal statistical distribution;protocols documentation;reconstructive surgical procedures;fmri;furuncle	Sanne Schoenmakers;Umut Güçlü;Marcel van Gerven;Tom Heskes	2014		10.3389/fncom.2014.00173	unsupervised learning;text mining;computer science;bioinformatics;data science;machine learning;bayesian network;data mining;sensor fusion	ML	24.94035039192564	-73.65703686661384	126392
1e03317c67a577211d5ec63f9cc067b64ec6afb6	test of label-free nasopharyngeal carinoma tissue at different stages by raman spectroscopy	sensitivity and specificity;support vector machines biological tissues biomedical optical imaging cancer medical computing principal component analysis raman spectra;support vector machines;covariance matrices;principal component analysis;classification algorithms;npc stage diagnosis label free nasopharyngeal carinoma tissue raman spectroscopy npc raman spectra classification multivariate statistical analysis high quality raman spectra npc tissue sample diagnostic algorithms principle component analysis support vector machine classification performance;support vector machines classification algorithms algorithm design and analysis covariance matrices principal component analysis sensitivity and specificity;nasopharyngeal carcinoma tissue raman spectroscopy different stages principle components analysis support vector machine;algorithm design and analysis	Raman spectroscopy (RS) of Nasopharyngeal carcinoma (NPC) tissue contained various biomedicine features. These features indicated molecular-level information of tissue at different carcinoma development-level. This study suggested an automatic and quick method for the NPC Raman spectra classification at different stages by multivariate statistical analysis. In the RS measurement, high quality Raman spectra was acquired from each NPC tissue sample in two groups: one group consisted of 30 NPC patients at the early stages (I-II), another group was 46 NPC patients at the advanced stages (III-IV). Moreover, tentative diagnostic algorithms based on principle components analysis (PCA) and support vector machine (SVM) were employed to classify the multivariate data of Raman spectra effectively. The classification performance (sensitivities and specificities were 70% (21/30) and 91% (42/46)) was achieved by the PCA-SVM in conjunction with leave-one-out cross validation method. In this beneficial study, the RS technique in conjunction with PCA-SVM provided a great clinical potential for rapid NPC stage diagnosis.	algorithm;cross-validation (statistics);display resolution;np-completeness;nonlinear system;principal component analysis;raman scattering;sensitivity and specificity;support vector machine	Mingyu Liu;Sufang Qiu;Jinyong Lin;Weilin Wu;Guannan Chen;Rong Chen	2015	2015 8th International Conference on Biomedical Engineering and Informatics (BMEI)	10.1109/BMEI.2015.7401505	statistical classification;support vector machine;algorithm design;speech recognition;computer science;bioinformatics;machine learning;principal component analysis	Visualization	27.540184509609183	-73.97437308488988	126762
f4ac0acec59e18c0ec70cd16e51b17a8db280bb2	assessing the quality level of corn tortillas with inductive characterization and digital image analysis		Characterization and classification of corn tortillas turns out to be an extremely delicate and difficult process when dealing with regulations for import/export and production process certification. In this paper we present a method for non-invasive feature extraction, based on digital imaging and a series of procedures to characterize different qualities of corn tortillas for their later classification. The novelty in this whole method lies in the extremely reduced set of features required for the characterization with only geometrical and color features. Nonetheless, this set of features can assess diverse quality elements like the homogeneity of the baking process and others alike. Experimental results on a sample batch of 600 tortillas show the presented method to be around 95% effective.	digital image;image analysis	Marco A. Moreno-Armendáriz;Salvador Godoy-Calderón;Hiram Calvo;Oscar M. Rojas-Padilla	2013		10.1007/978-3-642-38989-4_5	computer vision	EDA	35.952570707149484	-70.21653731169845	126918
969002ebd9f05221307a33b7e29333fbd0e64ba8	retinal vessel inpainting using recursive least square dictionary learning algorithm	least squares approximations;image segmentation;biomedical imaging;drive public database retinal blood vessel inpainting recursive least square dictionary learning algorithm retinal image frequent eye disease blood vessel structure retinal lesion segmentation textural feature extraction pathology detection online dictionary learning grayscale image rgb image;rls dla retinal image blood vessel inpainting sparse representation dictionary learning;retina;dictionaries;dictionaries retina blood vessels biomedical imaging least squares approximations image segmentation;medical image processing blood vessels diseases eye learning artificial intelligence;blood vessels	Retinal blood vessels are considered as being interference on the retinal images for the task of detecting significant features of the most frequent eye diseases. If these blood vessel structures could be suppressed, it might lead to a more accurate segmentation of retinal lesions as well as a better extraction of textural features to be used for pathology detection. This work proposes, as a novelty, the use of sparse representations and dictionary learning techniques for retinal vessel inpainting. The dictionary learning algorithms used in this paper were the Recursive Least Square Dictionary Learning (RLS-DL), and Online Dictionary Learning (ODL). We tested the performance of the algorithm for grayscale and RGB images from the DRIVE public database, employing different neighbourhoods and sparseness factors. An average recovery error smaller than 0.022 was achieved. The results suggest that the use of sparse representations and dictionaries learned by RLS-DLA performs very well for inpainting of retinal blood vessels.	algorithm;database;dictionary;drive letter assignment;grayscale;inpainting;interference (communication);machine learning;neural coding;recursion;recursive least squares filter;sensor;sparse matrix	Adrián Colomer;Valery Naranjo;Kjersti Engan;Karl Skretting	2015	2015 International Conference on Image Processing Theory, Tools and Applications (IPTA)	10.1109/IPTA.2015.7367181	medical imaging;computer vision;speech recognition;computer science;pattern recognition;image segmentation	Vision	36.0136434253709	-74.44463445834936	127013
9d22997867d7073acc5072280b0fb255ea2cefec	learning hmm structure for on-line handwriting modelization	structure learning;pattern clustering;handwriting recognition;allograph clustering;hidden markov models;allograph identification hmm structure learning online handwriting modelization hidden markov model training sequences;allograph clustering hmm structure learning;handwriting recognition hidden markov models learning artificial intelligence pattern clustering;learning artificial intelligence;hmm structure learning;hidden markov models clustering algorithms handwriting recognition writing training data inference algorithms iterative algorithms signal processing shape topology	We present a hidden Markov model-based approach to model on-line handwriting sequences. This problem is addressed in term of learning both hidden Markov models (HMM) structure and parameters from data. We iteratively simplify an initial HMM that consists in a mixture of as many left-right HMM as training sequences. There are two main applications of our approach: allograph identification and classification. We provide experimental results on these two different tasks.	algorithm;cluster analysis;handwriting recognition;hidden markov model;markov chain;mathematical model;mixture model;online and offline;sequence clustering	Henri Binsztok;Thierry Artières	2004	Ninth International Workshop on Frontiers in Handwriting Recognition	10.1109/IWFHR.2004.60	speech recognition;computer science;machine learning;pattern recognition;handwriting recognition	Vision	32.116521741843826	-66.66038455347692	127090
830e6e3393377aaffc5371c4b0a94ba9ddf390dc	trajectory planning for keyhole neurosurgery using fuzzy logic for risk evaluation	image segmentation;trajectory surgery biomedical imaging planning image segmentation blood vessels fuzzy logic;fuzzy logic trajectory planning image guided surgery artificial intelligence in surgery;biomedical imaging;fuzzy logic;surgery brain decision making fuzzy logic medical image processing neurophysiology planning artificial intelligence;trajectory;surgery;planning;risk structure trajectory planning keyhole neurosurgery fuzzy logic risk evaluation planning safe trajectory biopsy deep brain computer system decision making preoperative neurosurgery membership function decision function;blood vessels	Planning safe trajectories in keyhole neurosurgery requires a high level of accuracy in order to access to small structures either by biopsies, stimulating deep brain and others. We propose a computer system that carries out decision making based on rules using fuzzy logic to plan safe trajectories for preoperative neurosurgery. The processes to generate input values of membership functions, and implementation of the system for decision function will be explained. The results of risk weights for each candidate trajectory are evaluated and the safest calculated trajectories taking into account the risk structures that there are in the brain from the insertion points to the target point are visualized.	caret;computer;defuzzification;fuzzy control system;fuzzy logic;high-level programming language;mathematical optimization;preprocessor;thickness (graph theory);voxel	Alejandro De Leon-Cuevas;Saúl Tovar-Arriaga;Arturo Gonzalez-Gutierrez;Marco Antonio Aceves-Fernández	2015	2015 12th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE)	10.1109/ICEEE.2015.7357927	fuzzy logic;planning;medical imaging;computer vision;computer science;artificial intelligence;trajectory;biological engineering;image segmentation	Robotics	36.81052665812099	-79.5789369277945	127483
8e802197cf2baf1e2be53bad731a2e19e1b124a2	locating destination address block on handwritten korean envelopes	splitting method;postal services image segmentation feature extraction oils optical character recognition software character recognition automation writing merging image analysis;postal services;feature analysis;postal automation destination address block location handwritten korean envelopes knowledge based system iterative procedure statistical feature extraction;knowledge base	In this paper, we propose a knowledge-based approach for locating destination address block (DAB) on handwritten Korean envelopes by merging and splitting method. DAB of the input envelope image is extracted by an iterative procedure based on the knowledge acquired from the statistical feature analysis of the various handwritten Korean envelopes. Experimental results reveal that the proposed approach is very effective for address block location on handwritten Korean envelopes.		Seong-Whan Lee;Ki-Cheol Kim	1994		10.1109/ICPR.1994.577058	pattern recognition;knowledge base;speech recognition;computer science;pattern recognition;data mining	EDA	33.55490734964738	-66.26779116797645	127511
46d538f25cf411f88d2b540bd74dfc34f1ef7b17	a general type-ii similarity based model for breast cancer grading with ftir spectral data	patient diagnosis biomedical optical imaging cancer fourier transform spectroscopy fuzzy logic infrared spectroscopy;similarity measures breast cancer ftir type ii fuzzy logic;zslices based type ii fuzzy logic approach type ii similarity based model breast cancer grading ftir spectral data breast cancer prognosis fourier transform infrared spectroscopy breast cancer spectral data breast cancer grade classification;iron conferences fuzzy systems	Breast cancer is one of the most frequently occurring cancers among women throughout the world. In breast cancer prognosis, grading plays an important role. In this paper, we apply a novel method based on type-II fuzzy logic to Fourier Transform Infra-red Spectroscopy based breast cancer spectral data for the classification of breast cancer grade. A FTIR spectral data set consisting of 14 cases of breast cancer has been used. A zSlices based type-II fuzzy logic approach has been used to create prototype models for the classification of unseen breast cancer cases. The prototype models are used with a similarity measure to classify unseen cases of cancer. We have shown that the T-II similarity based model is a promising methodology for classification.	fuzzy logic;prototype;similarity measure	Shabbar Naqvi;Simon Miller;Jonathan M. Garibaldi	2014	2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2014.6891831	computer vision;mathematics	Robotics	34.60992999777214	-72.88180603586291	128030
3a510b8d2893530f0f6af01782ad40be5ad9a5f7	segmentation of intracranial vessels and aneurysms in phase contrast magnetic resonance angiography using multirange filters and local variances	dh hemts aneurysm image segmentation equations mathematical model shape level set;algorithms cerebral angiography contrast media humans image enhancement image interpretation computer assisted imaging three dimensional intracranial aneurysm magnetic resonance angiography pattern recognition automated reproducibility of results sensitivity and specificity;level sets;intracranial;sensitivity and specificity;computer aided analysis;image segmentation;imaging three dimensional;phantoms;computer aided diagnosis;vessels active contour models aneurysms intracranial level sets magnetic resonance angiography mra segmentation;flow velocities;noninvasive diagnosis;lethal vascular disease;topology based detection;level set;pc mra images;pc mra images intracranial vessels segmentation aneurysms phase contrast magnetic resonance angiography multirange filters local variances intensity varying segmentation intracranial aneurysms computer aided diagnosis lethal vascular disease noninvasive diagnosis pc mra based segmentation method flow velocities turbulent flows low contrast aneurysmal regions phantom image volume multirange filters topology based detection;intracranial aneurysm;segmentation;intracranial aneurysms;phantoms computer aided analysis diseases image segmentation medical image processing;dh hemts;local variances;pc mra based segmentation method;image enhancement;cerebral angiography;shape;image interpretation computer assisted;medical image processing;low contrast aneurysmal regions;multirange filters;active contour models;reproducibility of results;aneurysms;magnetic resonance angiography;mathematical model;contrast media;diseases;turbulent flows;algorithms;pattern recognition automated;humans;intracranial vessels segmentation;phantom image volume;intensity varying segmentation;aneurysm;phase contrast magnetic resonance angiography;magnetic resonance angiography mra;vessels	Segmentation of intensity varying and low-contrast structures is an extremely challenging and rewarding task. In computer-aided diagnosis of intracranial aneurysms, segmenting the high-intensity major vessels along with the attached low-contrast aneurysms is essential to the recognition of this lethal vascular disease. It is particularly helpful in performing early and noninvasive diagnosis of intracranial aneurysms using phase contrast magnetic resonance angiographic (PC-MRA) images. The major challenges of developing a PC-MRA-based segmentation method are the significantly varying voxel intensity inside vessels with different flow velocities and the signal loss in the aneurysmal regions where turbulent flows occur. This paper proposes a novel intensity-based algorithm to segment intracranial vessels and the attached aneurysms. The proposed method can handle intensity varying vasculatures and also the low-contrast aneurysmal regions affected by turbulent flows. It is grounded on the use of multirange filters and local variances to extract intensity-based image features for identifying contrast varying vasculatures. The extremely low-intensity region affected by turbulent flows is detected according to the topology of the structure detected by multirange filters and local variances. The proposed method is evaluated using a phantom image volume with an aneurysm and four clinical cases. It achieves 0.80 dice score in the phantom case. In addition, different components of the proposed method-the multirange filters, local variances, and topology-based detection-are evaluated in the comparison between the proposed method and its lower complexity variants. Owing to the analogy between these variants and existing vascular segmentation methods, this comparison also exemplifies the advantage of the proposed method over the existing approaches. It analyzes the weaknesses of these existing approaches and justifies the use of every component involved in the proposed method. It is shown that the proposed method is capable of segmenting blood vessels and the attached aneurysms on PC-MRA images.	anatomy, regional;blood vessel;computer assisted diagnosis;diagnosis, noninvasive;flow;imaging phantom;intracranial aneurysm;microscopy, phase-contrast;phantoms, imaging;resonance;rewards;turbulence;vascular diseases;vasculature;voxel;weakness;algorithm;angiogram;biologic segmentation	Max W. K. Law;Albert C. S. Chung	2013	IEEE Transactions on Image Processing	10.1109/TIP.2012.2216274	computer vision;computer science;level set;mathematics	Vision	38.80256351522704	-78.14469617168575	128034
59e3556febd99fd374d6558dd4958447354e82b6	a hybrid model of maximum margin clustering method and support vector regression for noninvasive electrocardiographic imaging	myocardium;diagnostic imaging;support vector machines;l1 norm regularization;reconstruction;electrophysiology;image processing computer assisted;activation;electrocardiography;cluster analysis;inverse problem;heart conduction system;models statistical;algorithms;regression analysis;humans;computer simulation;models cardiovascular	Noninvasive electrocardiographic imaging, such as the reconstruction of myocardial transmembrane potentials (TMPs) distribution, can provide more detailed and complicated electrophysiological information than the body surface potentials (BSPs). However, the noninvasive reconstruction of the TMPs from BSPs is a typical inverse problem. In this study, this inverse ECG problem is treated as a regression problem with multi-inputs (BSPs) and multioutputs (TMPs), which will be solved by the Maximum Margin Clustering- (MMC-) Support Vector Regression (SVR) method. First, the MMC approach is adopted to cluster the training samples (a series of time instant BSPs), and the individual SVR model for each cluster is then constructed. For each testing sample, we find its matched cluster and then use the corresponding SVR model to reconstruct the TMPs. Using testing samples, it is found that the reconstructed TMPs results with the MMC-SVR method are more accurate than those of the single SVR method. In addition to the improved accuracy in solving the inverse ECG problem, the MMC-SVR method divides the training samples into clusters of small sample sizes, which can enhance the computation efficiency of training the SVR model.	body dysmorphic disorders;body surface;computation;entity name part qualifier - adopted;membrane potentials;memory management controller;mitomycin;numerous;sample size;support vector machine;total peripheral resistance	Mingfeng Jiang;Feng Liu;Yaming Wang;Guofa Shou;Wenqing Huang;Huaxiong Zhang	2012		10.1155/2012/436281	computer simulation;support vector machine;mathematical optimization;electrophysiology;computer science;inverse problem;machine learning;electrical conduction system of the heart;mathematics;cluster analysis;regression analysis;statistics	ML	24.622850658682697	-76.99885016598193	128087
0118dacdf6b540fbdbc1e129c1555e3db5dfaab2	unsupervised color decomposition of histologically stained tissue samples	spectral decomposition;ground truth	Accurate spectral decomposition is essential for the analysis and diagnosis of histologically stained tissue sections. In this paper we present the first automated system for performing this decomposition. We compare the performance of our system with ground truth data and report favorable results.	ground truth	Andrew Rabinovich;Sameer Agarwal;Casey Laris;Jeffrey H. Price;Serge J. Belongie	2003			computer vision;ground truth;computer science;mathematics;matrix decomposition	ML	37.96802571654372	-74.8618639502689	128241
43f66683a8a4952daa131b9065e77dcd43007281	automated detection of lung tumors in pet/ct images using active contour filter	computed tomography;computer aided diagnosis;image contrast enhancement;positron emission tomography;lung;chest;blood vessels	"""In a previous study, we developed a hybrid tumor detection method that used both computed tomography (CT) and positron emission tomography (PET) images. However, similar to existing computer-aided detection (CAD) schemes, it was difficult to detect low-contrast lesions that touch to the normal organs such as the chest wall or blood vessels in the lung. In the current study, we proposed a novel lung tumor detection method that uses active contour filters to detect the nodules deemed """"difficult"""" in previous CAD schemes. The proposed scheme detects lung tumors using both CT and PET images. As for the detection in CT images, the massive region was first enhanced using an active contour filter (ACF), which is a type of contrast enhancement filter that has a deformable kernel shape. The kernel shape involves closed curves that are connected by several nodes that move iteratively in order to enclose the massive region. The final output of ACF is the difference between the maximum pixel value on the deformable kernel, and pixel value on the center of the filter kernel. Subsequently, the PET images were binarized to detect the regions of increased uptake. The results were integrated, followed by the false positive reduction using 21 characteristic features and three support vector machines. In the experiment, we evaluated the proposed method using 100 PET/CT images. More than half of nodules missed using previous methods were accurately detected. The results indicate that our method may be useful for the detection of lung tumors using PET/CT images."""	acf;active contour model;ct scan;computer-aided design;kernel (operating system);pixel;polyethylene terephthalate;support vector machine;tomography	Atsushi Teramoto;Hayato Adachi;Masakazu Tsujimoto;Hiroshi Fujita;Katsuaki Takahashi;Osamu Yamamuro;Tsuneo Tamaki;Masami Nishio;Toshiki Kobayashi	2015		10.1117/12.2081680	computed tomography;medical physics	Vision	37.03941863272853	-77.51073869404793	128474
5c6e2f099a4573b467b2c05e49e95adb6b19aba5	a prostate cad system based on multiparametric analysis of dce t1-w, and dw automatically registered images	bayesian classifier;tissues;computer aided diagnosis;cancer;diffusion weighted imaging;malignancy probability;automatic multimodal registration;biopsy;magnetic resonance imaging;prostate cancer detection;diagnostics;ultrasonography;diseases and disorders;prostate;multiparametric mri	Prostate specific antigen (PSA)-based screening reduces the rate of death from prostate cancer (PCa) by 31%, but this benefit is associated with a high risk of overdiagnosis and overtreatment. As prostate transrectal ultrasound-guided biopsy, the standard procedure for prostate histological sampling, has a sensitivity of 77% with a considerable false-negative rate, more accurate methods need to be found to detect or rule out significant disease. Prostate magnetic resonance imaging has the potential to improve the specificity of PSA-based screening scenarios as a non-invasive detection tool, in particular exploiting the combination of anatomical and functional information in a multiparametric framework. The purpose of this study was to describe a computer aided diagnosis (CAD) method that automatically produces a malignancy likelihood map by combining information from dynamic contrast enhanced MR images and diffusion weighted images. The CAD system consists of multiple sequential stages, from a preliminary registration of images of different sequences, in order to correct for susceptibility deformation and/or movement artifacts, to a Bayesian classifier, which fused all the extracted features into a probability map. The promising results (AUROC=0.87) should be validated on a larger dataset, but they suggest that the discrimination on a voxel basis between benign and malignant tissues is feasible with good performances. This method can be of benefit to improve the diagnostic accuracy of the radiologist, reduce reader variability and speed up the reading time, automatically highlighting probably cancer suspicious regions. © (2013) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	computer-aided design;dce/rpc;dreamwidth	Valentina Giannini;Anna Vignati;Simone Mazzetti;Massimo De Luca;Christian Bracco;Michele Stasi;Filippo Russo;Enrico Armando;Daniele Regge	2013		10.1117/12.2006336	diffusion mri;naive bayes classifier;magnetic resonance imaging;cancer	Vision	35.395901764349944	-78.91154021505311	128572
50c789fd27673ddba03af7119e08d1b53243b952	efficient and direct estimation of a neural subunit model for sensory coding	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Many visual and auditory neurons have response properties that are well explained by pooling the rectified responses of a set of spatially shifted linear filters. These filters cannot be estimated using spike-triggered averaging (STA). Subspace methods such as spike-triggered covariance (STC) can recover multiple filters, but require substantial amounts of data, and recover an orthogonal basis for the subspace in which the filters reside rather than the filters themselves. Here, we assume a linear-nonlinear-linear-nonlinear (LN-LN) cascade model in which the first linear stage is a set of shifted ('convolutional') copies of a common filter, and the first nonlinear stage consists of rectifying scalar nonlinearities that are identical for all filter outputs. We refer to these initial LN elements as the 'subunits' of the receptive field. The second linear stage then computes a weighted sum of the responses of the rectified subunits. We present a method for directly fitting this model to spike data, and apply it to both simulated and real neuronal data from primate V1. The subunit model significantly outperforms STA and STC in terms of cross-validated accuracy and efficiency.	apply;cascade device component;copy (object);ibm notes;linear stage;nonlinear system;primates;rectifier;reside;stc1 gene;spike-triggered covariance;stage is;weight function	Brett Vintch;Andrew D. Zaharia;J. Anthony Movshon;Eero P. Simoncelli	2012	Advances in neural information processing systems		text mining;medical research;computer science;bioinformatics;data science;machine learning;data mining;mathematics;statistics	ML	24.697085229023966	-74.6906398961055	128818
7350d3d08ebe9be54041b14ac71f44670ca9c802	automated detection of clustered microcalcifications on digitized mammograms		We have been developing an automated detection scheme for clustered microcalcifications on digital mammograms and reported the methods in several papers [1]–[4]. These schemes show a good performance in detection, but there is a problem that many false-positive candidates (ten and more) appear in some specific images. Therefore, an improvement of the elimination step of false positives is required. To achieve this, we have developed new methods of discrimination of the candidates and elimination of the false positives.		Daisuke Fukuoka;Satoshi Kasap;Hiroshi Fujita;Takeshi Hara;Motohiro Kato;Tokiko Endo;Hitoshi Yoshimura	1998		10.1007/978-94-011-5318-8_31	false positive paradox;artificial intelligence;computer science;pattern recognition	NLP	35.93699408533223	-75.16519003971678	128953
c12f447680f627769de3325dd31e0bcf797c726b	automatic working area classification in peripheral blood smears using spatial distribution features across scales	kernel;support vector machines;training;sensitivity;petroleum;statistical analysis;blood petroleum lenses morphology image analysis diseases inspection support vector machines support vector machine classification cities and towns;spatial distribution;feature extraction;medical image processing;blood;cell distribution automatic working area classification peripheral blood smears spatial distribution features quality control smears evaluation smear maker devices image analysis statistical pattern recognition individual cells extraction;statistical pattern recognition;pattern classification;image analysis;automatic classification;quality control;peripheral blood;cellular biophysics;statistical analysis blood cellular biophysics medical image processing pattern classification	Automatic classification of working areas in peripheral blood smears can provide objective and reproducible quality control for the evaluation of smears and smear maker devices. However, it has drawn little research attention. In this paper we study this topic using image analysis and statistical pattern recognition methods. We employ generic features without requiring the extraction of individual cells. Two new spatial distribution features across scales are defined and utilized to classify working areas. We demonstrate that the only feature and method proposed in a similar work by others is insufficient to characterize the goodness of working areas, particularly the cell distribution. However, by utilizing it together with the features developed in this paper, we can achieve much better results. Our method has been tested on about 150 labeled images acquired from three malaria-infected Giemsa-stained blood smears using an oil immersion 100x objective lens.	cell (microprocessor);image analysis;immersion (virtual reality);pattern recognition;peripheral;smear campaign	Wei Xiong;Sim Heng Ong;Joo-Hwee Lim;Nn Tung;Jiang Liu;Daniel Racoceanu;Kevin S. W. Tan;Alvin G. L. Chong;Kelvin Weng Chiong Foong	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761743	support vector machine;computer vision;quality control;kernel;image analysis;sensitivity;feature extraction;computer science;machine learning;data mining;petroleum	Robotics	35.85799789878588	-73.1114564195555	129096
2446bcedddc0a123f13c78db8997e1dfa5f481bc	automated detection of dark and bright lesions in retinal images for early detection of diabetic retinopathy	optic disk;bright lesions;diabetic retinopathy;preprocessing;dark lesions;blood vessels	There is an ever-increasing interest in the development of automatic medical diagnosis systems due to the advancement in computing technology and also to improve the service by medical community. The knowledge about health and disease is required for reliable and accurate medical diagnosis. Diabetic Retinopathy (DR) is one of the most common causes of blindness and it can be prevented if detected and treated early. DR has different signs and the most distinctive are microaneurysm and haemorrhage which are dark lesions and hard exudates and cotton wool spots which are bright lesions. Location and structure of blood vessels and optic disk play important role in accurate detection and classification of dark and bright lesions for early detection of DR. In this article, we propose a computer aided system for the early detection of DR. The article presents algorithms for retinal image preprocessing, blood vessel enhancement and segmentation and optic disk localization and detection which eventually lead to detection of different DR lesions using proposed hybrid fuzzy classifier. The developed methods are tested on four different publicly available databases. The presented methods are compared with recently published methods and the results show that presented methods outperform all others.	blood vessel;database;diabetic retinopathy;early diagnosis;edge detection;exanthema;exudate;eye;gabor wavelet;hemorrhage;hough transform;microaneurysm;optic disk;preprocessor;retina;retinal diseases;scientific publication;thresholding (image processing);algorithm	Muhammad Usman Akram;Shoab Ahmad Khan	2011	Journal of Medical Systems	10.1007/s10916-011-9802-2	computer vision;medicine;pathology;computer science;preprocessor	Vision	35.603487307448546	-75.60062189172464	129191
2885e3427a673a8d9bb058d055925af260b2441d	cancer cells detection and pathology quantification utilizing image analysis techniques	support vector machines biomedical optical imaging cancer cellular biophysics image classification image enhancement image segmentation medical image processing optical microscopy;image segmentation;support vector machines;cancer;image classification;image enhancement;optical microscopy cancer cells detection pathology quantification image analysis techniques apoptotic cells microscopy images support vector machines classifier image segmentation image enhancement majority voting watershed technique breast cancer images;medical image processing;cancer biomedical imaging tumors drugs image edge detection filtering support vector machines;biomedical optical imaging;algorithms animals breast neoplasms image enhancement image interpretation computer assisted mice microscopy pattern recognition automated reproducibility of results sensitivity and specificity support vector machines;cellular biophysics;optical microscopy	This paper presents an advanced image analysis tool for the accurate and fast characterization and quantification of cancer and apoptotic cells in microscopy images utilizing adaptive thresholding and a Support Vector Machines classifier. The segmentation results are also enhanced through a Majority Voting and a Watershed technique. The proposed tool was evaluated by experts on breast cancer images and the reported results were accurate and reproducible.	image analysis;mammary neoplasms;quantitation;support vector machine;thresholding (image processing);watershed (image processing)	Theodosios Goudas;Ilias Maglogiannis	2012	2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2012.6346946	support vector machine;computer vision;contextual image classification;pathology;computer science;machine learning;optical microscope;image segmentation;cancer	SE	38.2876703550103	-75.19489045623521	129303
4834de75807f007b47e95d829ae159376168421c	identification of insect damaged wheat kernels using transmittance images	agricultural products;image classification;image resolution;radial basis function networks;false positive rate;histogram;insect damaged wheat kernel;learning algorithm;linear model;radial basis function network;transmittance image identification;wheat image	We used transmittance images and different learning algorithms to classify insect damaged and un-damaged wheat kernels. Using the histogram of the pixels of the wheat images as the feature, and the linear model as the learning algorithm, we achieved a false positive rate (1-specificity) of 0.2 at the true positive rate (sensitivity) of 0.8 and an area under the ROC curve (AUC) of 0.86. Combining the linear model and a radial basis function network in a committee resulted in a FP rate of 0.1 at the TP rate of 0.8 and an AUC of 0.92.	algorithm;linear model;machine learning;pixel;radial (radio);radial basis function network;receiver operating characteristic;sensitivity and specificity	Zehra Cataltepe;A. Enis Çetin;Tom C. Pearson	2004	2004 International Conference on Image Processing, 2004. ICIP '04.	10.1109/ICIP.2004.1421723	computer vision;contextual image classification;image resolution;feature extraction;false positive rate;computer science;machine learning;linear model;pattern recognition;mathematics;radial basis function network;receiver operating characteristic	Robotics	30.758393532676152	-70.04031788666889	129436
f4adf5e82904090bd7ce4f8354ab3053dd974393	characterising shape patterns using features derived from best-fitting ellipsoids		A method is developed to characterise highly irregular shape patterns, especially those appearing in biomedical settings. A collection of best-fitting ellipsoids is found using principal component analysis, and features are defined based on these ellipsoids in four different ways. The method is defined in a general setting, but is illustrated using two-dimensional images of dimorphic yeast exhibiting pseudohyphal growth, three-dimensional images of cancellous bone and three-dimensional images of marbling in beef. Classifiers successfully distinguish between the yeast colonies with a mean classification accuracy of 0.843 ( SD = 0 . 021 ), and between cancellous bone from rats in different experimental groups with a mean classification accuracy of 0.745 ( SD = 0 . 024 ). A strong correlation ( R 2 = 0 . 797 ) is found between marbling ratio and a shape feature. Key aspects of the method are that local shape patterns, including orientation, are learned automatically from the data, and the method applies to objects that are irregular in shape to the point where landmark points cannot be identified between samples. © 2018 Elsevier Ltd. All rights reserved.	landmark point;principal component analysis;shape context;software design pattern;two-hybrid screening	Amelia Gontar;Hayden Tronnolone;Benjamin J. Binder;Murk J. Bottema	2018	Pattern Recognition	10.1016/j.patcog.2018.06.009	pseudohyphal growth;cancellous bone;principal component analysis;landmark;ellipsoid;artificial intelligence;correlation;mathematics;pattern recognition	ML	34.079454706237826	-71.81388544910473	129496
0d807c6d02016278fc363a97322b7ed551f8765f	automated analysis and detection of cracks in underground scanned pipes	feature extraction crack analysis crack detection underground scanned pipes closed circuit television cctv underground pipe structural integrity video images image classification image recognition pipe defects preventive maintenance;image recognition;crack analysis;investments;preventive maintenance;north america;automatic assessment;video signal processing;system analysis and design;image classification;underground pipe structural integrity;maintenance engineering;pipe defects;inspection;cctv;underground scanned pipes;image edge detection inspection radar detection tv pipelines investments cameras image analysis computer vision system analysis and design;computer vision;civil engineering computing;closed circuit television;image edge detection;crack detection;feature extraction;video images;pipelines;image analysis;radar detection;tv;structural integrity;feature extraction crack detection civil engineering computing closed circuit television image classification video signal processing maintenance engineering;cameras	Closed Circuit Television ( C C W ) surveys are used widely in North America to assess the structural integrity of underground pipes. The video images are examined visually and classified into grades according to degrees of damage. The human eye is extremely effective at recognition and classification, but it is not suitable for assessing pipe defects in thousand of miles of pipeline images due to fatigue, subjectivity, and cost. This paper presents ongoing research into the automatic assessment of the structural condition of underground pipes for the purpose of preventive maintenance by municipalities.	closed-circuit television;structural integrity and failure;underground	Paul W. Fieguth;Sunil K. Sinha	1999		10.1109/ICIP.1999.819622	maintenance engineering;preventive maintenance;computer vision;contextual image classification;image analysis;inspection;feature extraction;computer science;pipeline transport;structured systems analysis and design method	AI	38.378605496901486	-68.27992851915745	129695
ab09262c210411d94fb1fe1a7dacfc59fc1fa00a	arrowhead detection in biomedical images		Medical images in biomedical documents tend to be complex by nature and often contain several regions that are annotated using arrows. Arrowhead detection is a critical precursor to regionof-interest (ROI) labeling and image content analysis. To detect arrowheads, images are first binarized using fuzzy binarization technique to segment a set of candidates based on connected component principle. To select arrow candidates, we use convexity defect-based filtering, which is followed by template matching via dynamic programming. The similarity score via dynamic time warping (DTW) confirms the presence of arrows in the image. Our test on biomedical images from imageCLEF 2010 collection shows the interest of the technique.	connected component (graph theory);dynamic programming;dynamic time warping;region of interest;software bug;template matching	K. C. Santosh;Naved Alam;Partha Pratim Roy;Laurent Wendling;Sameer K. Antani;George R. Thoma	2016			computer vision;artificial intelligence;computer science;arrowhead	Vision	38.54820201579799	-73.90446473478877	129765
88d7b0d54949a2195c5dba3f2624a6e9595a2dc5	auto-annotation of tomato images based on ripeness and firmness classification for multimodal retrieval	classification based annotation;firmness estimation;auto annotation;multimodal retrieval;tomato ripeness classification	An interesting application of machine vision is quality estimation of tomatoes. Here, there is extensive availability of images that needs to be retrieved in an effective and efficient manner. In this paper, a classification based auto annotation (CBA) of tomato images for providing semantic tags is proposed. These tags are derived from their content-based learning. Semantic tags are deduced from the classification of tomatoes on two most important quality parameters i.e. ripeness and firmness. For firmness estimation, an approach is proposed that exploits three texture feature extraction algorithms: two are based on statistical techniques viz. first order statistics (FOS), and, gray level co-occurrence matrix (GLCM), and one is based on transform-based technique viz. wavelet-transform. Multiple linear regression (MLR) analysis has been used to establish the relationship between the instrumental firmness and texture values obtained from texture analysis. Prediction models for three texture feature sets are built, compared, and tested for over fitting using double cross-validation method. Based on the firmness of tomatoes, which is estimated through digital color imaging technique, they are classified into three classes soft, medium, and hard. To select a classifier for CBA, experiments with five learning methods, Naïve Bayes, multilayer perceptron (MLP), support vector machine (SVM), decision table, and random tree have been carried out. Their class-prediction accuracy has been compared using supplied test set. Ripeness classification of tomato images is done based on color using a previously proposed fuzzy rule based classification (FRBC) approach and are classified into three classes unripe, ab2ripe, and ripe. Grounded on classification, multi-labeling methodology is adopted for automatic annotation of tomato images. From the experimental results it is established that RandomTree classifier performs well for the classification of tomato firmness. In addition, presented work takes the advantage of progression in machine vision to address the issue of semantic gap in multimodal retrieval.	algorithm;co-occurrence matrix;color gradient;cross-validation (statistics);decision table;document-term matrix;experiment;feature extraction;fuzzy rule;grayscale;learning to rank;machine vision;memory-level parallelism;multilayer perceptron;multimodal interaction;naive bayes classifier;overfitting;random tree;rule 90;support vector machine;test set;viz: the computer game;wavelet transform	Priti Sehgal;Nidhi Goel	2016	2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2016.7732189	computer vision;computer science;machine learning;data mining	Vision	27.298458185750757	-68.51048328788794	129772
d811d38dd2eecd21a8733453a746bae63df86ec3	aplicação de redes neurais art e análise de textura para a classificação do estado de alteração de agregados minerais		A new approach to identify weathered and non-weathered aggregates that will be employed in construction works is presented. This identification is important to prevent premature failures and defects in works that can be attributed to the use of weathered aggregates. Image processing techniques are employed to acquire the color histograms, followed by calculating the entropy of the histograms which provides the main features for classification. Finally, a model of incremental acquisition of knowledge and classification that uses ART (Adaptive Resonance Theory) neural networks is built to automate the process of classification. This model is built through two steps. In the first step, the aggregates are classified as weathered and non-weathered, and in a second step, the group of weathered aggregates are classified on its weathering level. The proposed model presents better classification results when compared with the ones obtained through other classification algorithms. 1Departamento de Informática, UEPG, PR, Brasil. ljsenger@uepg.br 2Departamento de Engenharia Civil, UEPG, PR, Brasil. ltgouveia@gmail.com Identificação do estado de alteração de agregados minerais		Luciano José Senger;Lilian Tais de Gouveia	2010	RITA		computer science;computer vision;artificial intelligence;performance art	Vision	35.451415185406375	-73.85873699979923	129782
5d097e956bbd42ed409f66481dc6d413246c7b15	coarse-to-fine stacked fully convolutional nets for lymph node segmentation in ultrasound images	image segmentation;ultrasonic imaging;training;biological system modeling;biomedical imaging;machine learning;lymph nodes	Ultrasound as a well-established imaging modality is widely used in imaging lymph nodes for clinical diagnosis and disease analysis. Quantitative analysis of lymph node features, morphology, and relations can provide valuable information for diagnosis and immune system studies. For such analysis, it is necessary to first accurately segment the lymph node areas in ultrasound images. In this paper, we develop a new deep learning method, called Coarse-to-Fine Stacked Fully Convolutional Nets (CFS-FCN), for automatically segmenting lymph nodes in ultrasound images. Our method consists of multiple stages of FCN modules. We train the CFS-FCN model to learn the segmentation knowledge from a coarse-to-fine, simple-to-complex manner. A data set of 80 ultrasound images containing both normal and diseased lymph nodes is used in our experiments, which show that our method considerably outperforms the state-of-the-art deep learning methods for lymph node segmentation.	climate forecast system;deep learning;experiment;mathematical morphology;refinement (computing)	Yizhe Zhang;Michael T. C. Ying;Lin Yang;Anil T. Ahuja;Danny Ziyi Chen	2016	2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2016.7822557	medical imaging;computer science;machine learning;image segmentation;anatomy	Robotics	31.593208676009425	-75.58881162519202	129871
7487cec0c1996c510799b1cd396c6a8b46d974b0	a structural parametrization of the brain using hidden markov models-based paths in alzheimer's disease	sbm;hmm;texture features;info eu repo semantics article;spherical brain mapping;hidden markov models;alzheimer;feature extraction;mri;svm;paths	The usage of biomedical imaging in the diagnosis of dementia is increasingly widespread. A number of works explore the possibilities of computational techniques and algorithms in what is called computed aided diagnosis. Our work presents an automatic parametrization of the brain structure by means of a path generation algorithm based on hidden Markov models (HMMs). The path is traced using information of intensity and spatial orientation in each node, adapting to the structure of the brain. Each path is itself a useful way to characterize the distribution of the tissue inside the magnetic resonance imaging (MRI) image by, for example, extracting the intensity levels at each node or generating statistical information of the tissue distribution. Additionally, a further processing consisting of a modification of the grey level co-occurrence matrix (GLCM) can be used to characterize the textural changes that occur throughout the path, yielding more meaningful values that could be associated to Alzheimer's disease (AD), as well as providing a significant feature reduction. This methodology achieves moderate performance, up to 80.3% of accuracy using a single path in differential diagnosis involving Alzheimer-affected subjects versus controls belonging to the Alzheimer's disease neuroimaging initiative (ADNI).	algorithm;alzheimer's disease neuroimaging initiative;anatomic node;brain;co-occurrence matrix;dementia;document-term matrix;drug or chemical tissue distribution;grayscale;hidden markov model;magnetic resonance imaging;markov chain;medical imaging;space perception	Francisco Jesús Martínez-Murcia;Juan Manuel Górriz;Javier Ramírez;Andrés Ortiz	2016	International journal of neural systems	10.1142/S0129065716500246	support vector machine;computer vision;feature extraction;computer science;artificial intelligence;machine learning;hidden markov model	ML	29.833302462962635	-79.07350048824863	129938
2b3498afd53fbbdf4d7a88be1c5f02db61232381	recognition of blurred plate numbers using a novel algorithm based on hopfield neural network	hopfield neural networks pattern recognition samarium error correction neural networks computer networks medical services computer languages;image recognition;automobiles;hopfield neural nets;hopfield neural network;criminal investigation organization;image recognition blurred plate number recognition hopfield neural network criminal investigation organization;blurred plate number recognition;hopfield networks;image recognition automobiles hopfield neural nets;neural network;road vehicles	In this paper, we propose a novel algorithm based on the Hopfield neural network (HNN) and apply it to the recognition of blurred plate numbers. For a blurred plate number with m characters, the proposed algorithm takes competitions in pairs for each given pattern of m groups by using the HNN. The won numbers of given patterns of m groups can be obtained. Utilizing these won numbers, the competition score of every plate number can be calculated. According to these competition scores, we can sort the plate numbers and select the former sorted plate numbers as candidates. This result is very helpful for the criminal investigation organization to reduce the investigation range and is available to investigate these candidates one by one	algorithm;artificial neural network;hopfield network	Hung-Pin Chen;Ming-Hwa Chan;Yn-Her Juang	2004	2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)	10.1109/ICSMC.2004.1401281	computer vision;computer science;artificial intelligence;machine learning;time delay neural network;hopfield network;artificial neural network	Robotics	32.718250504968324	-67.9175019299789	130011
ea5ea74e1fe78fa32196b5ef74e19ed83e34c1c4	characterization of myocardial velocities by multiple kernel learning: application to heart failure with preserved ejection fraction		The present study aims at improving the characterization of myocardial velocities in the context of heart failure with preserved ejec- tion fraction (HFPEF) by combining multiple descriptors. It builds upon a recent extension of manifold learning known as multiple kernel learn- ing (MKL), which allows the combination of data of different natures towards the learning. Such learning is kept unsupervised, thus benefiting from all the inherent explanatory power of the data without being con- ditioned by a given class. The methodology was applied to 2D sequences from a stress echocardiography protocol from 33 subjects (21 healthy controls and 12 HFPEF subjects). Our method provides a novel way to tackle the understanding of the HFPEF syndrome, in contrast with the diagnostic issues surrounding it in the current clinical practice. Notably, our results confirm that the characterization of the myocardial functional response to stress in this syndrome is improved by the joint analysis of multiple relevant features.	kernel (operating system);multiple kernel learning	Sergio Sanchez-Martinez;Nicolas Duchateau;Bart Bijnens;Tamás Erdei;Alan Fraser;Gemma Piella	2015		10.1007/978-3-319-20309-6_8	simulation;artificial intelligence;mathematics;algorithm	ML	29.63297333204151	-78.97656805206786	130026
af30794d4f2e56bf00134038401c0c7ed81a243f	in-air handwritten chinese character recognition using multi-stage classifier based on adaptive discriminative locality alignment	character recognition training writing optimization handwriting recognition computers human computer interaction;dla in air handwritten chinese character recognition adaptive discriminative locality alignment static similar character set similar handwritten chinese character recognition;会议论文;parameter optimization handwritten chinese character recognition multi stage classifier adaptive discriminative locality alignment in air handwriting human computer interaction iahccr dla technique adla;pattern classification handwritten character recognition human computer interaction natural language processing optimisation	The in-air handwriting is a natural and useful way for human-computer interaction. Yet, to our knowledge, few work has been done for the in-air handwritten Chinese character recognition (IAHCCR). In this paper, we present a multi-stage recognizer to address the problem of IAHCCR. The proposed methods can also deal with the classical handwritten Chinese character recognition (HCCR). We find that the discriminative locality alignment (DLA) technique in HCCR heavily depends on the choice of parameters in practice. To overcome the disadvantage, we present an adaptive discriminative locality alignment (ADLA), which does not involve the parameter optimization process. At the same time, a new static similar characters collection technique is proposed. We evaluate the proposed methods on the IAHCC-UCAS2014 dataset, an in-air handwritten Chinese character dataset constructed by us, as well as the SCUT-COUCH2009 database, a HCCR dataset. The experimental results demonstrate the effectiveness of the proposed methods on two different kinds of dataset.	drive letter assignment;finite-state machine;human–computer interaction;locality of reference;mathematical optimization;optical character recognition	Xiwen Qu;Weiqiang Wang;Ke Lu;Ning Xu	2015	2015 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2015.7351717	natural language processing;speech recognition;intelligent character recognition;computer science;intelligent word recognition;pattern recognition	Vision	31.799504340086802	-66.39138322105632	130073
4b799a480836f4b5f1c2b47dd592d06ed4127c09	a method for linking computed image features to histological semantics in neuropathology	image features;discrete wavelet transform;87 57 nk;world health organization;histopathology;clinical diagnosis;feature space;medical image analysis;wavelet transform;unsupervised machine learning;semantic gap;self organizing map;image analysis;self organized map;feature selection;feature analysis	In medical image analysis the image content is often represented by features computed from the pixel matrix in order to support the development of improved clinical diagnosis systems. These features need to be interpreted and understood at a clinical level of understanding Many features are of abstract nature, as for instance features derived from a wavelet transform. The interpretation and analysis of such features are difficult. This lack of coincidence between computed features and their meaning for a user in a given situation is commonly referred to as the semantic gap. In this work, we propose a method for feature analysis and interpretation based on the simultaneous visualization of feature and image domain. Histopathological images of meningiomas WHO (World Health Organization) grade I are represented by features derived from color transforms and the Discrete Wavelet Transform. The wavelet-based feature space is then visualized and explored using unsupervised machine learning methods. We show how to analyze and select features according to their relevance for the description of clinically relevant characteristics.	class;cluster analysis;computation;curse of dimensionality;diagnosis, clinical;discrete wavelet transform;feature selection;feature vector;image analysis;imagery;machine learning;medical image computing;meningioma;neuropathology;pixel;preprocessor;relevance;separation kernel;subgroup;statistical cluster	Birgit Lessmann;Tim W. Nattkemper;Volkmar H. Hans;Andreas Degenhard	2007	Journal of biomedical informatics	10.1016/j.jbi.2007.06.007	pattern recognition;computer vision;image analysis;feature vector;self-organizing map;computer science;machine learning;pattern recognition;histopathology;discrete wavelet transform;feature selection;feature;semantic gap;wavelet transform	Vision	33.96210602437899	-74.32617135570524	131082
1c6902ed53a7861b9211ecb7b57b95be5e08633e	cytological image analysis with firefly nuclei detection and hybrid one-class classification decomposition	one class classification;classifier ensemble;ensemble pruning;firefly algorithm;image analysis;multi class decomposition	Recently a great increase of interest in digital pathology and cytology can be observed. Computer-aided diagnosis solutions, developed to assist physicians in the early detection of diseases, can improve accuracy and robustness of the diagnosis. In this paper we present a work in progress on a computeraided breast cancer diagnosis. We propose an efficient medical decision support framework that allows distinguishing between benign, malignant and fibroadenoma cases. The nuclei detection procedure is based on the firefly algorithm. The procedure generates nuclei markers that are used in markercontrolled watershed segmentation. Image recognition is done by a novel classifier. Instead of using a multi-class approach we decided to implement one-class decomposition strategy, where each of the classes is represented by an ensemble of one-class classifiers. We propose to use a multi-objective memetic algorithm to select the pool of one-class predictors that display at the same time high diversity and consistency. Experiments conducted on a set of 675 real case medical images obtained from patients of the Regional Hospital in Zielona Góra showed that our framework returns highly satisfactory results, outperforming other state-of-the-art methods. & 2013 Elsevier Ltd. All rights reserved.	computer vision;decision boundary;decision support system;firefly (cache coherence protocol);firefly algorithm;image analysis;memetic algorithm;one-class classification;pattern recognition;semi-supervised learning;semiconductor industry;statistical classification;watershed (image processing);whole earth 'lectronic link	Bartosz Krawczyk;Pawel Filipczuk	2014	Eng. Appl. of AI	10.1016/j.engappai.2013.09.017	mathematical optimization;image analysis;computer science;artificial intelligence;firefly algorithm;machine learning;pattern recognition;one-class classification	AI	33.93976977998756	-75.23511308723947	131139
4e62f683e778a5cb680be0cddd579059fcce24db	detection of prostate abnormality within the peripheral zone using local peak information	computer aided detection of prostate cancer;peak detection;prostate abnormality detection;prostate mri	In this paper, a fully automatic method is proposed for the detection of prostate cancer within the peripheral zone. The method starts by filtering noise in the original image followed by feature extraction and smoothing which is based on the Discrete Cosine Transform. Next, we identify the peripheral zone area using a quadratic equation and divide it into left and right regions. Subsequently, peak detection is performed on both regions. Finally, we calculate the percentage similarity and Ochiai coefficients to decide whether abnormality occurs. The initial evaluation of the proposed method is based on 90 prostate MRI images from 25 patients and 82.2% (sensitivity/specificity: 0.81/0.84) of the slices were classified correctly with 8.9% false negative and false	blob detection;coefficient;discrete cosine transform;feature extraction;haplogroup cz (mtdna);jaccard index;kepler engelbrecht;peripheral;project zomboid;quadratic equation;sensitivity and specificity;sensor;smoothing;supervised learning;unsupervised learning;vos or openvos	Andrik Rampun;Paul Malcolm;Reyer Zwiggelaar	2014		10.5220/0004762905100519	computer science;pattern recognition;filter (signal processing);artificial intelligence;prostate;feature extraction;discrete cosine transform;smoothing;quadratic equation;abnormality;prostate cancer	Vision	36.439164322134516	-76.99067168360101	131281
9732f55c55512309e24a88ae4f0728cc763b626f	deepcut: object segmentation from bounding box annotations using convolutional neural networks	engineering;flow segmentation;weak annotations;engineering biomedical;image segmentation;08 information and computing sciences;technology;nuclear medicine medical imaging;deepcut bounding box weak annotations image segmentation machine learning convolutional neural networks;journal article;09 engineering;grabcut;science technology;computer science interdisciplinary applications;machine learning;cs cv;radiology nuclear medicine medical imaging;graph cut segmentation;life sciences biomedicine;mri;imaging science photographic technology;optimization;computer science;convolutional neural networks;deepcut;engineering electrical electronic;bounding box;image segmentation training object segmentation biological neural networks optimization computational modeling imaging	"""In this paper, we propose <italic>DeepCut</italic>, a method to obtain pixelwise object segmentations given an image dataset labelled weak annotations, in our case bounding boxes. It extends the approach of the well-known <italic>GrabCut</italic> <xref ref-type=""""bibr"""" rid=""""ref1"""">[1]</xref> method to include machine learning by training a neural network classifier from bounding box annotations. We formulate the problem as an energy minimisation problem over a densely-connected conditional random field and iteratively update the training targets to obtain pixelwise object segmentations. Additionally, we propose variants of the <italic>DeepCut</italic> method and compare those to a naïve approach to CNN training under weak supervision. We test its applicability to solve brain and lung segmentation problems on a challenging fetal magnetic resonance dataset and obtain encouraging results in terms of accuracy."""	anatomic structures;artificial neural network;biological neural networks;conditional random field;convolutional neural network;cross-reference;endoscopic retrograde cholangiography;epidemiologic research design;graphics processing unit;human connectome project;iterative method;machine learning;medical imaging;minimum bounding box;naivety;neural network simulation;neural tube defects;resonance;silo (dataset);structure of parenchyma of lung;synergy;tesla (microarchitecture);tesla - unit;whole earth 'lectronic link;biologic segmentation	Martin Rajchl;Matthew C. H. Lee;Ozan Oktay;Konstantinos Kamnitsas;Jonathan Passerat-Palmbach;Wenjia Bai;Mellisa Damodaram;Mary A. Rutherford;Joseph V. Hajnal;Bernhard Kainz;Daniel Rueckert	2017	IEEE Transactions on Medical Imaging	10.1109/TMI.2016.2621185	computer vision;computer science;artificial intelligence;grabcut;magnetic resonance imaging;machine learning;data mining;mathematics;image segmentation;convolutional neural network;technology	Vision	30.64727799047954	-74.61694161020343	131418
0a0541389a6b239d0e8247cc03e7979d23398df1	synergetic neuro-fuzzy feature selection and classification of brain tumors		Brain tumors constitute one of the deadliest forms of cancers, with a high mortality rate. Of these, Glioblastoma multiforme (GBM) remains the most common and lethal primary brain tumor in adults. Tumor biopsy being challenging for brain tumor patients, noninvasive techniques like imaging play an important role in the process of brain cancer detection, diagnosis and prognosis; particularly using Magnetic Resonance Imaging (MRI). Therefore, development of advanced extraction and selection strategies of quantitative MRI features become necessary for noninvasively predicting and grading the tumors. In this paper we extract 56 three-dimensional quantitative MRI features, related to tumor image intensities, shape and texture, from 254 brain tumor patients. An adaptive neuro-fuzzy classifier based on linguistic hedges (ANFC-LH) is developed to simultaneously select significant features and predict the tumor grade. ANFC-LH achieves a significantly higher testing accuracy (85.83%) as compared to existing standard classifiers.	cylinder-head-sector;feature selection;glr parser;lh (complexity);lr parser;medical imaging;mesa;neuro-fuzzy;resonance;synergetics (haken);synergy	Subhashis Banerjee;Sushmita Mitra;B. Uma Shankar	2017	2017 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2017.8015514	cancer;artificial intelligence;machine learning;neuro-fuzzy;glioblastoma;computer science;feature selection;magnetic resonance imaging;biopsy;brain tumor;pattern recognition	Robotics	31.055859263842343	-77.31856675253204	131571
1c82df34bff38242d09b9868948c1eb957062539	a novel image mining technique for classification of mammograms using hybrid feature selection		The image mining technique deals with the extraction of implicit knowledge and image with data relationship or other patterns not explicitly stored in the images. It is an extension of data mining to image domain. The main objective of this paper is to apply image mining in the domain such as breast mammograms to classify and detect the cancerous tissue. Mammogram image can be classified into normal, benign, and malignant class. Total of 26 features including histogram intensity features and gray-level co-occurrence matrix features are extracted from mammogram images. A hybrid approach of feature selection is proposed, which approximately reduces 75% of the features, and new decision tree is used for classification. The most interesting one is that branch and bound algorithm that is used for feature selection provides the best optimal features and no where it is applied or used for gray-level co-occurrence matrix feature selection from mammogram. Experiments have been taken for a data set of 300 images taken from MIAS of different types with the aim of improving the accuracy by generating minimum number of rules to cover more patterns. The accuracy obtained by this method is approximately 97.7%, which is highly encouraging.	algorithm;apache ant (another neat tool);branch and bound;co-occurrence matrix;computation;computer-aided design;data mining;decision tree;document-term matrix;feature extraction;feature selection;image analysis;image resolution;k-nearest neighbors algorithm;measurement problem;medical image computing;medical imaging;preprocessor;radiology;requirement;rough set;test set;usability	Aswini Kumar Mohanty;Manas Ranjan Senapati;Saroj Kumar Lenka	2012	Neural Computing and Applications	10.1007/s00521-012-0881-x	computer vision;feature detection;pattern recognition;data mining;mathematics;feature	ML	34.91123861946308	-74.7372307364563	131652
02027601f76a55ed75f340cde045fc5547b7cc9b	teeth segmentation of dental periapical radiographs based on local singularity analysis	teeth segmentation;singularity analysis;adaptive power law transformation;periapical radiographs	Teeth segmentation for periapical raidographs is one of the most critical tasks for effective periapical lesion or periodontitis detection, as both types of anomalies usually occur around tooth boundaries and dental radiographs are often subject to noise, low contrast, and uneven illumination. In this paper, we propose an effective scheme to segment each tooth in periapical radiographs. The method consists of four stages: image enhancement using adaptive power law transformation, local singularity analysis using Hölder exponent, tooth recognition using Otsu's thresholding and connected component analysis, and tooth delineation using snake boundary tracking and morphological operations. Experimental results of 28 periapical radiographs containing 106 teeth in total and 75 useful for dental examination demonstrate that 105 teeth are successfully isolated and segmented, and the overall mean segmentation accuracy of all 75 useful teeth in terms of (TP, FP) is (0.8959, 0.0093) with standard deviation (0.0737, 0.0096), respectively.	connected component (graph theory);connected-component labeling;hl7publishingsubsection <operations>;image editing;mathematical morphology;odontogenic tissue;otsu's method;periapical diseases;radiography;suppurative periapical periodontitis;thresholding (image processing);biologic segmentation	P. L. Lin;P. Y. Huang;P. W. Huang;H. C. Hsu;C. C. Chen	2014	Computer methods and programs in biomedicine	10.1016/j.cmpb.2013.10.015	pathology;dentistry	Vision	38.05826578012151	-77.26841522596175	132156
267341349dc647d79ca82fa25963c2f29a7c61c4	image segmentation to evaluate islets of langherans	image segmentation	This contribution deals with an unsupervised system to process digital photomicrographs in order to locate and analyze islets of Langherans in human pancreases. The experiment has been conducted on real data and, though we are still going to complete the evaluation of the whole method, we expect to define a set of proper features (e.g. area, perimeter, fractal dimension, shape complexity, texture and entropy) useful for a fast and reliable counting of healthy cells. In particular, this research aims to measure the advisability of a possible implantation in patients affected by type 1 diabetes mellitus.	fractal dimension;image segmentation;ion implantation;perimeter;unsupervised learning	C. Grimaudo;Domenico Tegolo;Cesare Valenti;F. Bertuzzi	2008			computer science;machine learning;image segmentation;scale-space segmentation	AI	37.167474266229654	-75.99444466172409	132735
7b457ada931604a1cd940927fea91651b39c3d45	automatic lung segmentation using control feedback system: morphology and texture paradigm	health informatics;interstitial lung disease;health information management;information systems;medicine miscellaneous;lung segmentation;high resolution computed tomography thorax hrct	Interstitial Lung Disease (ILD) encompasses a wide array of diseases that share some common radiologic characteristics. When diagnosing such diseases, radiologists can be affected by heavy workload and fatigue thus decreasing diagnostic accuracy. Automatic segmentation is the first step in implementing a Computer Aided Diagnosis (CAD) that will help radiologists to improve diagnostic accuracy thereby reducing manual interpretation. Automatic segmentation proposed uses an initial thresholding and morphology based segmentation coupled with feedback that detects large deviations with a corrective segmentation. This feedback is analogous to a control system which allows detection of abnormal or severe lung disease and provides a feedback to an online segmentation improving the overall performance of the system. This feedback system encompasses a texture paradigm. In this study we studied 48 males and 48 female patients consisting of 15 normal and 81 abnormal patients. A senior radiologist chose the five levels needed for ILD diagnosis. The results of segmentation were displayed by showing the comparison of the automated and ground truth boundaries (courtesy of ImgTracer™ 1.0, AtheroPoint™ LLC, Roseville, CA, USA). The left lung’s performance of segmentation was 96.52 % for Jaccard Index and 98.21 % for Dice Similarity, 0.61 mm for Polyline Distance Metric (PDM), −1.15 % for Relative Area Error and 4.09 % Area Overlap Error. The right lung’s performance of segmentation was 97.24 % for Jaccard Index, 98.58 % for Dice Similarity, 0.61 mm for PDM, −0.03 % for Relative Area Error and 3.53 % for Area Overlap Error. The segmentation overall has an overall similarity of 98.4 %. The segmentation proposed is an accurate and fully automated system.	choose (action);computer-aided design;control system;embedded system;embedding;fatigue;feedback;galaxy morphological classification;ground truth;heart rate variability;internet listing display;interstitial webpage;jaccard index;lung diseases, interstitial;lung diseases;mathematical morphology;overlap–add method;patients;programming paradigm;radiology;right lung;segmentation action;structure of parenchyma of lung;sørensen–dice coefficient;thresholding (image processing);biologic segmentation;large latent transforming growth factor-beta complex	Norliza Mohd. Noor;Joel Chia Ming Than;Omar Mohd. Rijal;Rosminah M. Kassim;Ashari Yunus;Amir A. Zeki;Michele Anzidei;Luca Saba;Jasjit S. Suri	2015	Journal of Medical Systems	10.1007/s10916-015-0214-6	health informatics;computer vision;simulation;medicine;pathology;nursing;information system	Vision	36.40157794137803	-78.98670950379788	133083
6f0445871bf946881833fff543cbcf0394fd5041	coronary calcium detection using 3d attention identical dual deep network based on weakly supervised learning		Coronary artery calcium (CAC) is biomarker of advanced subclinical coronary artery disease and predicts myocardial infarction and death prior to age 60 years. The slice-wise manual delineation has been regarded as the gold standard of coronary calcium detection. However, manual efforts are time and resource consuming and even impracticable to be applied on large-scale cohorts. In this paper, we propose the attention identical dual network (AID-Net) to perform CAC detection using scan-rescan longitudinal non-contrast CT scans with weakly supervised attention by only using per scan level labels. To leverage the performance, 3D attention mechanisms were integrated into the AID-Net to provide complementary information for classification tasks. Moreover, the 3D Gradient-weighted Class Activation Mapping (Grad-CAM) was also proposed at the testing stage to interpret the behaviors of the deep neural network. 5075 non-contrast chest CT scans were used as training, validation and testing datasets. Baseline performance was assessed on the same cohort. From the results, the proposed AID-Net achieved the superior performance on classification accuracy (0.9272) and AUC (0.9627).	artificial neural network;baseline (configuration management);ct scan;common access card;deep learning;gradient;supervised learning;the grid analysis and display system (grads)	Yuankai Huo;James G. Terry;Jiachen Wang;Vishwesh Nath;Camilo Bermudez;Shunxing Bao;Prasanna Parvathaneni;J. Jeffery Carr;Bennett A. Landman	2018	CoRR			ML	30.975806706210836	-76.08693856511958	133094
9611e90c7c5b50cd29ede04d76c1565f7c1678ad	detecting the pigment network in dermoscopy images: a directional approach	skin;tumours;clinical diagnosis;malignant tumors;clinical diagnosis routine pigment network dermoscopy image melanomas directional niters topological properties;algorithms colorimetry dermoscopy humans image enhancement image interpretation computer assisted pattern recognition automated reproducibility of results sensitivity and specificity skin skin neoplasms skin pigmentation;topological properties;lesions;image color analysis;image colour analysis;medical image processing;pigments;pigments lesions image color analysis skin hair algorithm design and analysis malignant tumors;algorithm design;tumours image colour analysis medical image processing skin;algorithm design and analysis;hair	Several algorithms have been recently proposed for the analysis of dermoscopy images and the detection of melanomas. However, the pigment network is not considered in most of these works, although this cue plays a major role in clinical diagnosis routines. This paper proposes an algorithm for the detection of the pigment network. The algorithm is based on a bank of directional filters (difference of Gaussians) and explores color, directionality and topological properties of the network.	algorithm;dermoscopy;difference of gaussians;pigment;sensor;melanoma	Catarina Barata;Jorge S. Marques;Jorge Rozeira	2011	2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/IEMBS.2011.6091268	algorithm design;computer vision;medicine;pathology;computer science	Vision	38.608676764765654	-74.88104499495365	133651
0474b5174933981734cba1a653d7eb7092542d9b	quality classification of microscopic imagery with weakly supervised learning		In this post-genomic era, microscopic imaging is playing a crucial role in biomedical research and important information is to be discovered by quantitatively mining the resulting massive imagery databases. To this end, an important prerequisite is robust, high quality imagery databases. This is because defect images will jeopardize downstream tasks such as feature extraction and statistical analysis, yielding misleading results or even false conclusions. This paper presents a weakly supervised learning framework to tackle this problem. Our framework resembles a cascade of classifiers with feature and similarity measure designed for both global and local defects. We evaluated the framework on a database of images and obtained a 96.9% F-score for the important normal class. Click-and-play open source software is provided.	database;display resolution;downstream (software development);feature extraction;image quality;medical imaging;microsoft outlook for mac;open-source software;scalability;similarity measure;software bug;supervised learning	Xinghua Lou;Luca Fiaschi;Ullrich Köthe;Fred A. Hamprecht	2012		10.1007/978-3-642-35428-1_22	computer vision;machine learning;pattern recognition	Vision	32.18182670697842	-73.60939610013031	133706
d38e1470f95b35c9116b1bb1e32b899ea8f15ae3	deep voting: a robust approach toward nucleus localization in microscopy images		Robust and accurate nuclei localization in microscopy image can provide crucial clues for accurate computer-aid diagnosis. In this paper, we propose a convolutional neural network (CNN) based hough voting method to localize nucleus centroids with heavy cluttering and morphologic variations in microscopy images. Our method, which we name as deep voting, mainly consists of two steps. (1) Given an input image, our method assigns each local patch several pairs of voting offset vectors which indicate the positions it votes to, and the corresponding voting confidence (used to weight each votes), our model can be viewed as an implicit hough-voting codebook. (2) We collect the weighted votes from all the testing patches and compute the final voting density map in a way similar to Parzen-window estimation. The final nucleus positions are identified by searching the local maxima of the density map. Our method only requires a few annotation efforts (just one click near the nucleus center). Experiment results on Neuroendocrine Tumor (NET) microscopy images proves the proposed method to be state-of-the-art.	1-click;artificial neural network;biological neural networks;biomarkers, tumor;cell nucleus;codebook;convolutional neural network;hough transform;kernel density estimation;maxima and minima;neoplasms;neuroendocrine tumors;window function;dorsal raphe nucleus	Yuanpu Xie;Xiangfei Kong;Fuyong Xing;Fujun Liu;Hai Su;Lin Yang	2015	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-319-24574-4_45	computer vision	Vision	36.3518543495322	-76.99267507215288	133830
5d07db23cbc6c4c469436e2972efce305889c5c7	deriving statistical significance maps for svm based image classification and group comparisons	software;brain;diagnostic imaging;support vector machines;brain mapping;models statistical;artificial intelligence;algorithms;pattern recognition automated;humans;alzheimer disease;computer simulation	Population based pattern analysis and classification for quantifying structural and functional differences between diverse groups has been shown to be a powerful tool for the study of a number of diseases, and is quite commonly used especially in neuroimaging. The alternative to these pattern analysis methods, namely mass univariate methods such as voxel based analysis and all related methods, cannot detect multivariate patterns associated with group differences, and are not particularly suitable for developing individual-based diagnostic and prognostic biomarkers. A commonly used pattern analysis tool is the support vector machine (SVM). Unlike univariate statistical frameworks for morphometry, analytical tools for statistical inference are unavailable for the SVM. In this paper, we show that null distributions ordinarily obtained by permutation tests using SVMs can be analytically approximated from the data. The analytical computation takes a small fraction of the time it takes to do an actual permutation test, thereby rendering it possible to quickly create statistical significance maps derived from SVMs. Such maps are critical for understanding imaging patterns of group differences and interpreting which anatomical regions are important in determining the classifier's decision.	approximation algorithm;biological markers;computation (action);data interpretation, statistical;inference;mind map;morphometric analysis;morphometrics;neuroimaging;null value;p-value;pattern recognition;population;resampling (statistics);statistical classification;support vector machine;voxel	Bilwaj Gaonkar;Christos Davatzikos	2012	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-33415-3_89	computer simulation;support vector machine;radiology;computer science;machine learning;pattern recognition;data mining;brain mapping;statistics	ML	25.03286564378199	-79.30433413503387	134059
0bd85708716d197c695ab47bc6a67cd009767d33	leveraging random forests for interactive exploration of large histological images.		The large size of histological images combined with their very challenging appearance are two main difficulties which considerably complicate their analysis. In this paper, we introduce an interactive strategy leveraging the output of a supervised random forest classifier to guide a user through such large visual data. Starting from a forest-based pixelwise estimate, subregions of the images at hand are automatically ranked and sequentially displayed according to their expected interest. After each region suggestion, the user selects among several options a rough estimate of the true amount of foreground pixels in this region. From these one-click inputs, the region scoring function is updated in real time using an online gradient descent procedure, which corrects on-the-fly the shortcomings of the initial model and adapts future suggestions accordingly. Experimental validation is conducted for extramedullary hematopoesis localization and demonstrates the practical feasibility of the procedure as well as the benefit of the online adaptation strategy.	1-click;acclimatization;gradient descent;mitosis;musculoskeletal diseases;pixel;random forest;region of interest;score;scoring functions for docking;simulation;spatial variability;synthetic intelligence	Loïc Peter;Diana Mateus;Pierre Chatelain;Noemi Schworm;Stefan Stangl;Gabriele Multhoff;Nassir Navab	2014	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-319-10404-1_1	computer vision;simulation;machine learning;data mining;multimedia	Vision	29.93359933515464	-72.62989676331225	134152
439e6846ce4d62506a5b0ce427d1407594b2d0e4	thinning and stroke segmentation for handwritten chinese character recognition	handwritten chinese character recognition	Firstly, a thinning technique by means of stroke tracking is proposed. The method is considered to preserve the straightness of strokes and the length, which is useful for the stroke segmentation procedure on the recognition of handwritten Chinese characters.#R##N##R##N#Secondly, a method for stroke segmentation, i.c. a way of breaking down a character to a set of consecutive partial strokes, is proposed, which works well owing to the favourable properties of the proposed thinning technique. The method consists of five procedures: extraction of feature pixels, calculation of stroke directions, piecewise linear representation of strokes, unification of intersections and extraction of the consecutive partial strokes.	optical character recognition;thinning	Hideo Ogawa;Keiji Taniguchi	1982	Pattern Recognition	10.1016/0031-3203(82)90032-2	arithmetic;speech recognition;computer science;artificial intelligence	Vision	35.28148457990021	-66.77207627422385	134166
efc5fa23fe93dc676bfa016c5f92230736e95ec5	learning global and cluster-specific classifiers for robust brain extraction in mr data		We present a learning-based framework for automatic brain extraction in MR images. It accepts single or multi-contrast brain MR data, builds global binary random forests classifiers at multiple resolution levels, hierarchically performs voxelwise classifications for a test subject, and refines the brain surface using a narrow-band level set technique on the classification map. We further develop a data-driven schema to improve the model performance, which clusters patches of co-registered training images and learns cluster-specific classifiers. We validate our framework via experiments on single and multi-contrast datasets acquired using scanners with different magnetic field strengths. Compared to the state-of-the-art methods, it yields the best performance with statistically significant improvement of the cluster-specific method (with a Dice coefficient of 97.6 ± 0.4 % and an average surface distance of 0.8 ± 0.1 mm) over the global method.		Yuan Liu;Hasan Ertan Çetingül;Benjamin Odry;Mariappan S. Nadar	2016		10.1007/978-3-319-47157-0_16	machine learning;pattern recognition;data mining	ML	30.395650216919154	-75.8012516485077	134551
eb5dc4fe4dcb9e2a73cf7e3cbf9f476d98b6eb01	automatic brain tissue segmentation based on graph filter	brain tissue segmentation;graph filter;magnetic resonance imaging;supervoxel generation	BACKGROUND Accurate segmentation of brain tissues from magnetic resonance imaging (MRI) is of significant importance in clinical applications and neuroscience research. Accurate segmentation is challenging due to the tissue heterogeneity, which is caused by noise, bias filed and partial volume effects.   METHODS To overcome this limitation, this paper presents a novel algorithm for brain tissue segmentation based on supervoxel and graph filter. Firstly, an effective supervoxel method is employed to generate effective supervoxels for the 3D MRI image. Secondly, the supervoxels are classified into different types of tissues based on filtering of graph signals.   RESULTS The performance is evaluated on the BrainWeb 18 dataset and the Internet Brain Segmentation Repository (IBSR) 18 dataset. The proposed method achieves mean dice similarity coefficient (DSC) of 0.94, 0.92 and 0.90 for the segmentation of white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF) for BrainWeb 18 dataset, and mean DSC of 0.85, 0.87 and 0.57 for the segmentation of WM, GM and CSF for IBSR18 dataset.   CONCLUSIONS The proposed approach can well discriminate different types of brain tissues from the brain MRI image, which has high potential to be applied for clinical applications.	body tissue;brain neoplasms;cerebrospinal fluid;classification;coefficient;graph - visual representation;gray matter;magnetic resonance imaging;neuroscience discipline;segmentation action;silo (dataset);white matter;algorithm;biologic segmentation;brain segmentation	Youyong Kong;Xiaopeng Chen;Jiasong Wu;Pinzheng Zhang;Yang Chen;Huazhong Shu	2018		10.1186/s12880-018-0252-x	grey matter;white matter;filter (signal processing);radiology;partial volume;segmentation;artificial intelligence;pattern recognition;medicine;magnetic resonance imaging;brain segmentation;graph	Vision	37.81341044021118	-78.59960504001344	134586
1c98f7a90ac165bb8be69732c1b141a0774c7ebc	a new supervised method for blood vessel segmentation in retinal images by using gray-level and moment invariants-based features	databases;imagenes tratamiento de las;7d vector;digital retinal image;algorithms databases factual diabetic retinopathy fluorescein angiography humans image enhancement image interpretation computer assisted information storage and retrieval pattern recognition automated reproducibility of results retinal vessels sensitivity and specificity;eye;vessels segmentation;image segmentation;neural nets;moment invariants;telemedicine;pixel classification;drive database;biomedical imaging;early diabetic retinopathy detection;diagnostico por imagenes;blood vessels biomedical imaging image segmentation retina neural networks image databases computer networks spatial databases testing application software;blood vessel;supervised method;retinopatia diabetica;retina;feature extraction;medical image processing;blood vessel segmentation;pixel;diabetic retinopathy;stare database;gray level;vessels segmentation diabetic retinopathy moment invariants retinal imaging telemedicine;retinal imaging;early diabetic retinopathy detection supervised method blood vessel segmentation gray level moment invariants based feature digital retinal image neural network pixel classification 7d vector drive database stare database;blood vessels;moment invariants based feature;neural nets blood vessels eye image segmentation medical image processing;neural network;moment invariant	This paper presents a new supervised method for blood vessel detection in digital retinal images. This method uses a neural network (NN) scheme for pixel classification and computes a 7-D vector composed of gray-level and moment invariants-based features for pixel representation. The method was evaluated on the publicly available DRIVE and STARE databases, widely used for this purpose, since they contain retinal images where the vascular structure has been precisely marked by experts. Method performance on both sets of test images is better than other existing solutions in literature. The method proves especially accurate for vessel detection in STARE images. Its application to this database (even when the NN was trained on the DRIVE database) outperforms all analyzed segmentation approaches. Its effectiveness and robustness with different image conditions, together with its simplicity and fast implementation, make this blood vessel segmentation proposal suitable for retinal image computer analyses such as automated screening for early diabetic retinopathy detection.	artificial neural network;biological neural networks;blood glucose self-monitoring;blood vessel tissue;cerebrovascular disorders;database;diabetic retinopathy;neoplasms, vascular tissue;pixel;retina;retinal diseases;solutions;biologic segmentation	Diego Marin;Arturo Aquino;Manuel Emilio Gegúndez-Arias;José Manuel Bravo	2011	IEEE Transactions on Medical Imaging	10.1109/TMI.2010.2064333	computer vision;feature extraction;computer science;machine learning;data mining;image segmentation;artificial neural network;pixel;computer graphics (images)	Vision	36.67175714717713	-75.03347212639214	134653
d050b0456ebb919170d3b2f3950f58c602beac8c	application of the boundary contour/feature contour system to magnetic resonance brain scan imagery	psychophysical evidence boundary contour system feature contour system human vision models magnetic resonance brain scan imagery neurophysiological evidence pattern recognition;magnetic resonance brain scan imagery;brain;human vision;neural nets;psychophysical evidence;biomedical nmr;feature contour system;neural nets biomedical nmr brain computerised pattern recognition computerised picture processing medical diagnostic computing;computerised pattern recognition;boundary contour system;magnetic resonance;pattern recognition;computerised picture processing;neurophysiological evidence;medical diagnostic computing;human vision models	Boundary contour system (BCS) and feature contour system (FCS) human vision models are applied to magnetic resonance brain scan imagery to highlight significant features for the purpose of pattern recognition. A discussion is presented of psychophysical and neurophysiological evidence in support of the model. The implementation is described. The resulting images are compared to the original to demonstrate the effectiveness of the model	resonance	Steve Lehar;Andrew J. Worth;David N. Kennedy	1990		10.1109/IJCNN.1990.137604	computer vision;speech recognition;computer science;magnetic resonance imaging;machine learning;artificial neural network	Vision	38.0149047683257	-73.98377134332564	135103
33ec2a7d4dc2ab887dbe1b8b10af077582c85628	illumination compensation for document images using local-global block analysis	local global block analysis;ocr;illumination compensation	This paper presents the illumination compensation technique for document images using local-global block analysis. Imbalance illumination will affect the performance of classification and segmentation process because the darker regions conceal the information of the image. This method will split the image into non-overlapped blocks, and utilize the information within the local and global area of the image. The output images were binarized with simple global thresholding technique and the result shows that the output image is comparable in quality with the existed method. A comparative result will be presented with other document binarization methods.	global illumination	Mohd. Hafrizal Azmi;M. Iqbal Saripan;Raja Syamsul Azmir;Raja Abdullah	2009		10.1007/978-3-642-05036-7_60	computer vision;geography;pattern recognition;computer graphics (images)	Vision	38.464149242773495	-66.19026764030912	135149
fb0ae36d5bd354b31b1f2553dae13cc136cc7280	atlas registration and ensemble deep convolutional neural network-based prostate segmentation using magnetic resonance imaging		Using a registration-based coarse segmentation to the pre-processed prostate MRI images to get the potential boundary region.Constructing a prostate pixel classifier in fine segmentation using pre-trained VGG-19 network model.Introducing ensemble learning to the fine segmentation to further improve the segmentation results.Evaluating the proposed method on the PROMIS12 challenge dataset and PROSTATEx17 challenge dataset. Automatic segmentation of prostate in magnetic resonance (MR) images has been more and more applied to the diagnosis of prostate disease and various clinical applications. However, due to the inhomogeneous and varying anatomical appearance around prostate boundary, the segmentation of prostate MR images faces great challenges. Since deep learning shows superior performance in computer vision, we propose a coarse-to-fine segmentation strategy by using deep neural networks to tackle the segmentation problem of the endorectal coil prostate images and non-endorectal coil prostate images separately. First, we present a registration-based coarse segmentation to the pre-processed prostate MR images to get the potential boundary region. Second, we train deep neural networks as pixel-based classifier to predict whether the pixel in the potential boundary region is prostate pixel or not. To improve the discriminability of the algorithm, we further introduce ensemble learning for fine segmentation. Finally, a boundary refinement is used to eliminate the outlier and smooth the boundary. The proposed method has been extensively evaluated on the PROMIS12 challenge dataset and PROSTATEx17 challenge dataset. Experimental results show superior segmentation performance (0.9100.036 in dice ratio, 1.5830.441 in average boundary distance and 4.5791.791 in Hausdorff distance), which demonstrates the effectiveness of the proposed algorithm.	artificial neural network;atlas autocode;convolutional neural network;resonance	Haozhe Jia;Yong Xia;Yang Song;Tom Weidong Cai;Michael J. Fulham;David Dagan Feng	2018	Neurocomputing	10.1016/j.neucom.2017.09.084	convolutional neural network;machine learning;hausdorff distance;deep learning;artificial neural network;scale-space segmentation;image segmentation;ensemble learning;artificial intelligence;computer vision;segmentation-based object categorization;pattern recognition;computer science	Vision	31.46361140447347	-75.45360341263834	135250
48e902a3825fe4b88b41e8c43a14beaafa97f52c	dynamic character grouping based on four consistency constraints in topographic maps	topographic maps;character expandability;text direction;color information;character size;character grouping;character spacing;consistency constraint	In optical character recognition, text strings should be extracted from images first. But only the complete text strings can accurately express the meanings of the words, so the extracted individual characters should be grouped into text strings before recognition. There are lots of text strings in topographic maps, and these texts consist of the characters with multi-colored, multi-sized and multi-oriented, and the existing methods cannot effectively group them. In this paper, a dynamic character grouping method is proposed to group the characters into text strings based on four consistency constraints, which are the color, size, spacing and direction respectively. As we know that the characters in the same word have similar colors, sizes and distances between them, and they are also on some curve lines with a certain bending, but the characters in different words are not. Based on these features of the characters, the background pixels around the characters are expanded to link the characters into text strings. In this method, due to the introduction of the color consistency constraint, the characters with different colors can be grouped well. And this method can deal with curved character strings more accurately by the improved direction consistency constraint. The final experimental results show that this method can group the characters more efficiently, especially for the case in which the beginning or the end characters of words are close to the characters of the other words.	map;topography	Pengfei Xu;Qiguang Miao;Ruyi Liu;Xiaojiang Chen;Xunli Fan	2016	Neurocomputing	10.1016/j.neucom.2016.01.118	arithmetic;topographic map;pattern recognition;mathematics	NLP	36.0498184335162	-66.90925475031305	135355
a0ca1e4bb9ffa300fcd7764dc658c7e88da05f1f	unsupervised tissue segmentation in screening mammograms for automated breast density assessment	unsupervised clustering;tissues;neural networks;automatic assessment;k means;statistical significance;breast;region segmentation;feature vector;statistical analysis;indexation;computing systems;self organized map;mammography;neural network;knowledge base	This paper describes a computer-assisted algorithm to automatically assess mammographic breast density. The algorithm was applied to 160 cranio-caudal DDSM mammograms (80 Lumisys and 80 Howtek images). The breast region was first segmented from its background using our self-organizing map (SOM) with knowledge-based refinement algorithm (presented previously). A different SOM neural network was subsequently developed to operate within the determined breast region. Multiscale feature vectors from the breast region were used to train the new SOM. The weight vectors of the SOM were then clustered by the K-means method, resulting in a breast region segmented into K different clusters. The prevalence of SOM clusters containing dense tissues was calculated to develop a summary density index. Statistical analysis was applied to optimize the implementation parameters of the summary index. The average summary index was higher in dense breasts than in non-dense breasts. The trend was consistent for both digitizers, though the results were statistically significant for only the Lumisys set. Unsupervised clustering and segmentation of mammograms is a promising approach for automated breast density assessment.© (2004) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	unsupervised learning	H. Erin Rickard;Georgia D. Tourassi;Adel Said Elmaghraby	2004		10.1117/12.535762	computer vision;engineering;machine learning;data mining	NLP	35.939038589070236	-73.97730003360007	135439
5103fbaa74e920fa9be8bef82b80b19fa22cd03d	automatic identification of glaucoma using deep learning methods	glaucoma;neural network (computer);retina	This paper proposes an automatic classification method to detect glaucoma in fundus images. The method is based on training a neural network using public image databases. The network used in this paper is the GoogLeNet, adapted for this proposal. The methodology was divided into two stages, namely: (1) detection of the region of interest (ROI); (2) image classification. We first used a sliding-window approach combined with the GoogLeNet network. This network was trained using manually extracted ROIs and other fundus image structures. Afterwards, another GoogLeNet model was trained using the previous resulting images. Then those images were used to train another GoogLeNet model to automatically detect glaucoma. To prevent overfitting, data augmentation techniques were used on smaller databases. The results demonstrated that the network had a good accuracy, even with poor quality images found in some databases or generated by the data augmentation algorithm.	algorithm;artificial neural network;automatic identification and data capture;biological neural networks;computer vision;convolutional neural network;databases;deep learning;extraction;glaucoma;overfitting;published database;region of interest;small	Allan Cerentini;Daniel Welfer;Marcos Cordeiro d'Ornellas;Carlos Jesus Pereira Haygert;Gustavo Nogara Dotto	2017	Studies in health technology and informatics	10.3233/978-1-61499-830-3-318	deep learning;glaucoma;computer science;artificial intelligence;pattern recognition	ML	33.57537814812321	-75.12254124782969	135442
cbebc527c22fcfafdf7699750fb7add683d15f78	a new normalization technique for cursive handwritten words	slope removal;cursive word normalization;off-line cursive script recognition;slant removal;vision;parameter space;word recognition	This paper presents new techniques for slant and slope removal in cursive handwritten words. Both methods require neither heuristics nor parameter tuning. This avoids the heavy experimental eort required to ®nd the optimal con-®guration of a parameter set. A comparison between the new deslanting technique and the method proposed by Bo-zinovic and Srihari was made by measuring the performance of both methods within a word recognition system tested on dierent databases. The proposed technique is shown to improve the recognition rate by 10.8% relative to traditional normalization methods. Moreover, a long exploration of the parameter space is avoided.	call of duty: black ops;database normalization;heuristic (computer science)	Alessandro Vinciarelli;Juergen Luettin	2001	Pattern Recognition Letters		vision;speech recognition;word recognition;computer science;machine learning;pattern recognition;parameter space;statistics	Vision	33.60258596541103	-67.76523112964732	135700
7626dcf5ef876753b010c84b1c0c81636e9b395c	crack detection in x-ray images using fuzzy index measure	crack;x ray images;image processing;x ray imaging;fuzzy entropy;image acquisition;crack detection;indexation;medical application;fuzzy index measure	Crack of the bone is a very serious medical condition. In medical applications, sensitivity in detecting medical problems and accuracy of detection are often in conflict. Computer detection of cracks can assist the doctors by flagging suspicious cases for closer examinations and thus improve the timeliness and accuracy. This paper presents the detailed image processing procedure including the grid formation, local thresholding, threshold value interpolation, segmentation using fuzzy index measure, background removal, and morphological filtering for the determination of infestation sites of a crack in X-ray image. The image processing procedure was tested with X-ray images of several types of crack bones. Additional tests and analyses were also performed using the developed algorithm on the X-ray images obtained with different image acquisition parameter. Compared to existing methods, this approach enhances the accuracy and reliability of proposed work.		C. Harriet Linda;G. Wiselin Jiji	2011	Appl. Soft Comput.	10.1016/j.asoc.2011.01.029	computer vision;simulation;image processing;computer science;mathematics	Robotics	37.535438326207434	-75.90381799011936	135911
c555ef77838346fb531fddd881ab5ee6ed53c0b8	early diagnosis of mild cognitive impairment using random forest feature selection		Alzheimer‘s disease (AD) is a neurodegenerative disease which is progressive and can be described by amyloid deposition, and neuronal atrophy. In this study, a support vector machine (SVM) approach with radial basis function (RBF) has been proposed in order to detect the Alzheimer's disease in its early stage using multiple modalities, including positron emission tomography (PET), magnetic resonance imaging (MRI), and standard neuropsychological test scores. A total number of 896 participants from the Alzheimer's Disease Neuroimaging Initiative (ADNI) were considered in this study. The proposed approach is able to classify cognitively normal control (CN) group from early mild cognitive impairment (EMCI) with an accuracy of 81.1%. In addition, the accuracy of 91.9% for CN vs. late mild cognitive impairment and accuracy of 96.2% for CN vs. AD classifications have been achieved through the proposed model.		Parisa Forouzannezhad;Alireza Abbaspour;Mercedes Cabrerizo;Malek Adiouadi	2018	2018 IEEE Biomedical Circuits and Systems Conference (BioCAS)	10.1109/BIOCAS.2018.8584773	feature selection;neuroimaging;computer vision;neuropsychological test;cognition;random forest;artificial intelligence;computer science;pattern recognition	Vision	30.269327294096456	-78.1974654393802	136202
5ba4433a8104e76ee71e6d5aabfdb9511b0b5541	neural network classification of blood vessels and tubules based on haralick features evaluated in histological images of kidney biopsy		In this paper, we present a Computer Aided Diagnosis that implements a supervised approach to discriminate vessels versus tubules that are two different types of structural elements in images of biopsy tissue. In particular, in this work we formerly describe an innovative preliminary step to segment region of interest, then the procedure to extract from them significant features and finally present and discuss the Back Propagation Neural Network binary classifier performance that shows Precision 91 % and Recall 91 %.	artificial neural network;robert haralick	Vitoantonio Bevilacqua;Nicola Pietroleonardo;Vito Triggiani;Loreto Gesualdo;Annamaria Di Palma;Michele Rossini;Giuseppe Dalfino;Nico Mastrofilippo	2015		10.1007/978-3-319-22053-6_81	pattern recognition;artificial neural network;artificial intelligence;computer science;binary classification;region of interest;computer-aided diagnosis;image segmentation;backpropagation;biopsy	ML	34.60183582348381	-75.51117881262176	136374
35ef277cb07b43bcd76033f9099d56523116486b	a geometric approach to fully automatic chromosome segmentation		A fundamental task in human chromosome analysis is chromosome segmentation. Segmentation plays an important role in chromosome karyotyping. The first step in segmentation is to remove intrusive objects such as stain debris and other noises. The next step is detection of touching and overlapping chromosomes, and the final step is separation of such chromosomes. Common methods for separation between touching chromosomes are interactive and require human intervention for correct separation between touching and overlapping chromosomes. In this paper, a geometric-based method is used for automatic detection of touching and overlapping chromosomes and separating them. The proposed scheme performs segmentation in two phases. In the first phase, chromosome clusters are detected using three geometric criteria, and in the second phase, chromosome clusters are separated using a cut-line. Most of earlier methods did not work properly in case of chromosome clusters that contained more than two chromosomes. Our method, on the other hand, is quite efficient in separation of such chromosome clusters. At each step, one separation will be performed and this algorithm is repeated until all individual chromosomes are separated. Another important point about the proposed method is that it uses the geometric features of chromosomes which are independent of the type of images and it can easily be applied to any type of images such as binary images and does not require multispectral images as well. We have applied our method to a database containing 62 touching and partially overlapping chromosomes and a success rate of 91.9% is achieved.	algorithm;binary image;database;multispectral image	Shervin Minaee;Mehran Fotouhi;Babak Hossein Khalaj	2014	2014 IEEE Signal Processing in Medicine and Biology Symposium (SPMB)		computer vision;bioinformatics	Vision	38.55643645076226	-72.3478346029367	136439
a20e93a10e1dc6455d477d4be304e9976af8a775	a probabilistic stroke-based viterbi algorithm for handwritten chinese characters recognition	multistage directed graph;handwritten chinese character recognition;probabilistic model;reconnaissance caractere chinois;handwritten chinese character;reconnaissance caractere;viterbi algorithm;feature extraction;modele probabiliste;pattern recognition;reconnaissance forme;extraction caracteristique;reconocimiento patron;algorithme viterbi;character recognition;on line stroke sequence;reconocimiento caracter;stroke extraction;chinese character recognition;modelo probabilista	This paper proposes a probabilistic approach to recognize handwritten Chinese characters. According to the stroke writing sequence, strokes and interleaved stroke relations are built manually as a 1-D string, called an on-line model, to describe a Chinese character. In an input character, strokes are first extracted by a tree searching method. The recognition problem is then formulated as an optimization matching problem in a multistage directed graph, where the number of stages is the length of the modelled stroke sequence. Nodes in a stage represent extracted strokes that have the same stroke type as defined in the on-line model and the link between two neighboring nodes corresponds to the relationship between the two extracted strokes. The probability that the extracted stroke belongs to the predefined stroke type is calculated from the stroke line segments, and the transition probability between two extracted strokes is the degree of satisfaction of the relationship defined in the on-line model. The Viterbi algorithm, which can handle stroke insertion, deletion, splitting, and merging, is applied to recover the sequence of strokes consisting of the unknown character. The similarity is defined to be the product of stroke probabilities and stroke transition probabilities in the stroke sequence. The unknown character is matched with all modelled characters and is recognized as the one with the highest similarity. Experiments with 540 characters uniformly selected from the database CCL/HCCR1 (250 variations/class) are conducted, and the recognition rate is about 92.8%, which proves the feasibility of the proposed recognition system.	viterbi algorithm	Chen-Chiung Hsieh;Hsi-Jian Lee	1993	IJPRAI	10.1142/S0218001493000170	statistical model;speech recognition;feature extraction;viterbi algorithm;computer science;artificial intelligence;machine learning;pattern recognition	AI	35.21562895939764	-67.45647806534248	136466
64980c908e93946bfc0d9484c9f763866adae900	breast cancer diagnosis in digitized mammograms using curvelet moments	breast cancer diagnosis;feature reduction;curvelet transform;mammography;curvelet moments	BACKGROUND Feature extraction is a key issue in designing a computer aided diagnosis system. Recent researches on breast cancer diagnosis have reported the effectiveness of multiscale transforms (wavelets and curvelets) for mammogram analysis and have shown the superiority of curvelet transform. However, the curse of dimensionality problem arises when using the curvelet coefficients and therefore a reduction method is required to extract a reduced set of discriminative features.   METHODS This paper deals with this problem and proposes a feature extraction method based on curvelet transform and moment theory for mammogram description. First, we performed discrete curvelet transform and we computed the four first-order moments from curvelet coefficients distribution. Hence, two feature sets can be obtained: moments from each band and moments from each level. In this work, both sets are studied. Then, the t-test ranking technique was applied to select the best features from each set. Finally, a k-nearest neighbor classifier was used to distinguish between normal and abnormal breast tissues and to classify tumors as malignant or benign. Experiments were performed on 252 mammograms from the Mammographic Image Analysis Society (mini-MIAS) database using the leave-one-out cross validation as well as on 11553 mammograms from the Digital Database for Screening Mammography (DDSM) database using 2×5-fold cross validation.   RESULTS Experimental results prove the effectiveness and the superiority of curvelet moments for mammogram analysis. Indeed, results on the mini-MIAS database show that curvelet moments yield an accuracy of 91.27% (resp. 81.35 %) with 10 (resp. 8) features for abnormality (resp. malignancy) detection. In addition, empirical comparisons of the proposed method against state-of-the-art curvelet-based methods on the DDSM database show that the suggested method does not only lead to a more reduced feature set, but it also statistically outperforms all the compared methods in terms of accuracy.   CONCLUSIONS In summary, curvelet moments are an efficient and effective way to extract a reduced set of discriminative features for breast cancer diagnosis.		Sami Dhahbi;Walid Barhoumi;Ezzeddine Zagrouba	2015	Computers in biology and medicine	10.1016/j.compbiomed.2015.06.012	computer vision;speech recognition;pattern recognition;mathematics	AI	34.02385616538985	-74.74238429306835	136576
1ddbb170c1473e93fc871ae0b477f81f59f74344	segmentation of on-line freely written japanese text using svm for improving text recognition	tecnologia electronica telecomunicaciones;on line recognition;caracter manuscrito;japonais;manuscript character;maquina vector soporte;character segmentation;database;base dato;concatenacion;segmentation;concatenation;multi dimensional;machine vecteur support;reconnaissance caractere;signal classification;base de donnees;pattern recognition;classification signal;writing constraint;svm;reconnaissance forme;support vector machine;stochastic model;reseau neuronal;tecnologias;reconocimiento patron;grupo a;discriminacion;caractere manuscrit;modelo estocastico;character recognition;japones;red neuronal;modele stochastique;segmentacion;reconocimiento caracter;discrimination;neural network;japanese	This paper describes a method of producing segmentation point candidates for on-line handwritten Japanese text by a support vector machine (SVM) to improve text recognition. This method extracts multi-dimensional features from on-line strokes of handwritten text and applies the SVM to the extracted features to produces segmentation point candidates. We incorporate the method into the segmentation by recognition scheme based on a stochastic model which evaluates the likelihood composed of character pattern structure, character segmentation, character recognition and context to finally determine segmentation points and recognize handwritten Japanese text. This paper also shows the details of generating segmentation point candidates in order to achieve high discrimination rate by finding the combination of the segmentation threshold and the concatenation threshold. We compare the method for segmentation by the SVM with that by a neural network using the database HANDSKondate_t_bf-2001-11 and show the result that the method by the SVM bring about a better segmentation rate and character recognition rate.	artificial neural network;concatenation;online and offline;optical character recognition;support vector machine	Bilan Zhu;Masaki Nakagawa	2008	IEICE Transactions	10.1093/ietisy/e91-d.1.105	support vector machine;computer vision;speech recognition;computer science;artificial intelligence;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation;artificial neural network	AI	33.54026694342722	-67.24325342820013	136777
168cd5282f822fb143a4f749c24fc8d622ceeee8	off line recognition of handwritten postal words using neural networks	dynamic programming;programacion dinamica;image processing;connectionism;conexionismo;procesamiento imagen;intelligence artificielle;segmentation;documento manuscrito;traitement image;digits;cursive;connexionnisme;reconnaissance caractere;programmation dynamique;artificial intelligence;inteligencia artificial;reseau neuronal;document manuscrit;character recognition;red neuronal;segmentacion;reconocimiento caracter;manuscript document;neural network	We describe a method, “Shortest Path Segmentation” (SPS), which combines dynamic programming and a neural net recognizer for segmenting and recognizing character strings. We describe the application of this method to two problems: recognition of handwritten ZIP Codes, and recognition of handwritten words. For the ZIP Codes, we also used the method to automatically segment the images during training: the dynamic programming stage both performs the segmentation and provides inputs and desired outputs to the neural network. Results are reported for a test set of 2642 unsegmented handwritten 212 dpi binary ZIP Code (5- and 9-digit) images. For handwritten word recognition, we combined SPS with a “Space Displacement Neural Network” approach, in which a single-character-recognition network is extended over the entire word image, and in which SPS techniques are then used to rank order a given lexicon. We report results on a test set of 3000 300 ppi gray scale word images, extracted from images of live mail pieces, for lexicons of size 10, 100, and 1000. Representing the problem as a graph as proposed in this paper has advantages beyond the efficient finding of the final optimal segmentation, or the automatic segmentation of images during training. We can also easily extend the technique to generate K “runner up” answers (for example, by finding the K shortest paths). This paper will also describe applications of some of these ideas.	neural networks;postal	Christopher J. C. Burges;Jan Ben;John S. Denker;Yann LeCun;Craig R. Nohl	1993	IJPRAI	10.1142/S0218001493000340	computer vision;connectionism;speech recognition;image processing;computer science;artificial intelligence;intelligent word recognition;machine learning;dynamic programming;pattern recognition;segmentation;artificial neural network	ML	33.369205620425504	-67.45059097047469	136782
9c75effaf7fb2960bb0d59e3ff8193972ac45f28	mental stress detection based on soft computing techniques	mental stress recognition;eye;video signal processing edge detection eye feature extraction fuzzy reasoning genetic algorithms hough transforms image classification medical image processing neurophysiology psychology support vector machines;fuzzy reasoning;support vector machines;video signal processing;edge detection;soft computing;image classification;fuzzy support vector machine mental stress recognition fuzzy image processing genetic algorithm;psychology;fuzzy support vector machine;stress feature extraction image edge detection electrocardiography support vector machines physiology;learning system;stroop color word test mental stress detection soft computing technique mental stress recognition eye video sequences video capturing fuzzy image processing signal processing feature extraction classification process pupil diameter pupil dilation acceleration pda genetic algorithm fuzzy filter noise reduction edge detection fuzzy reasoning hough transform fuzzy svm fsvm;affective state;fuzzy image processing;feature extraction;medical image processing;signal processing;noise reduction;hough transforms;genetic algorithm;genetic algorithms;mental stress;hough transform;neurophysiology;pupil diameter;electrocardiogram	"""In this study, a novel approach is proposed for mental stress recognition through automatic analysis of eye video sequences. The proposed system consists of five stages: video capturing, fuzzy image processing, signal processing, feature extraction and, classification. The pupil parameters including Pupil Diameter (PD) and Pupil Dilation Acceleration (PDA) are measured using soft computing techniques wherein the eye region is detected using the genetic algorithm (GA), and a fuzzy filter is designed for noise reduction. Edge detection is performed based on fuzzy reasoning and linking is done using Hough transform. Then, signal processing technique is applied to the pupil parameters to extract their most relevant features. Extracted features are imported into the learning system to classify the affective states between """"stress"""" and """"relaxed"""". The Fuzzy SVM (FSVM) is applied to this classification process. In order to induce the stress in subjects, a Stroop color-word test is designed. Also, the results obtained from the pupil parameters are compared with two other physiological signals including Electrocardiogram (ECG) and Photoplethysmogram (PPG). The experimental results indicate the pupil parameters have great potential for stress recognition compared to the other two physiological signals and, proposed stress recognition system is promising."""	affective computing;dilation (morphology);edge detection;feature extraction;fuzzy concept;genetic algorithm;hough transform;image processing;noise reduction;personal digital assistant;signal processing;soft computing;software release life cycle	Fania Mokhayeri;Mohammad R. Akbarzadeh-Totonchi	2011	2011 IEEE International Conference on Bioinformatics and Biomedicine	10.1109/BIBM.2011.80	computer vision;genetic algorithm;computer science;machine learning;signal processing;pattern recognition;soft computing;neurophysiology	Robotics	35.115909585403536	-73.30574624264614	137397
2b0738a0ebb186480f3d11138043c24821716ee1	identification of the optic nerve head with genetic algorithms	optic nerve head;optic nerve head segmentation;constraint handling;genetic algorithm;glaucoma;ellipse fitting	OBJECTIVE This work proposes creating an automatic system to locate and segment the optic nerve head (ONH) in eye fundus photographic images using genetic algorithms.   METHODS AND MATERIAL Domain knowledge is used to create a set of heuristics that guide the various steps involved in the process. Initially, using an eye fundus colour image as input, a set of hypothesis points was obtained that exhibited geometric properties and intensity levels similar to the ONH contour pixels. Next, a genetic algorithm was used to find an ellipse containing the maximum number of hypothesis points in an offset of its perimeter, considering some constraints. The ellipse thus obtained is the approximation to the ONH. The segmentation method is tested in a sample of 110 eye fundus images, belonging to 55 patients with glaucoma (23.1%) and eye hypertension (76.9%) and random selected from an eye fundus image base belonging to the Ophthalmology Service at Miguel Servet Hospital, Saragossa (Spain).   RESULTS AND CONCLUSIONS The results obtained are competitive with those in the literature. The method's generalization capability is reinforced when it is applied to a different image base from the one used in our study and a discrepancy curve is obtained very similar to the one obtained in our image base. In addition, the robustness of the method proposed can be seen in the high percentage of images obtained with a discrepancy delta<5 (96% and 99% in our and a different image base, respectively). The results also confirm the hypothesis that the ONH contour can be properly approached with a non-deformable ellipse. Another important aspect of the method is that it directly provides the parameters characterising the shape of the papilla: lengths of its major and minor axes, its centre of location and its orientation with regard to the horizontal position.	active contour model;algorithmic efficiency;approximation algorithm;color image;compiler;computation;discrepancy function;execution;fitness function;generalization (psychology);genetic algorithm;glaucoma;heuristic (computer science);hypertensive disease;inter-rater reliability;interpreted language;matlab;maxima and minima;ninety nine;ophthalmology specialty;optic disk;optic nerve (gchq);optics;papilla of tongue;parallel computing;patients;perimeter;pixel;sensor;software release life cycle;solutions;spatial variability;structure of fundus of eye;biologic segmentation	Enrique J. Carmona;Mariano Rincón;Julián García-Feijoó;José M. Martínez-de-la-Casa	2008	Artificial intelligence in medicine	10.1016/j.artmed.2008.04.005	computer vision;genetic algorithm;computer science;artificial intelligence;machine learning	AI	39.171320294484715	-76.49863824903494	137464
b5290134111e28b278942b61743fa60ddc06b203	fast optic disc segmentation using fft-based template-matching and region-growing techniques		AbstractThe analysis of retinal features, such as blood vessels, optic disc and fovea, plays an important role in the detection of several diseases. This paper presents a method for automated optic disc segmentation from colour fundus images. The proposed method comprises three major stages, namely optic disc localisation, preprocessing and segmentation. Localisation is performed using the fast Fourier transform-based template matching to obtain a seed point located on the optic disc which is then used as an input to the region growing technique for the purpose of segmentation. Three sets of fundus images, namely DRIVE, MESSIDOR and a LOCAL database are used to measure the accuracy of the proposed method. From the experimental results, it is found that the proposed localisation method achieves success rates of 100, 98.91 and 97.56% for these databases, respectively, which are comparable to other known methods. The proposed segmentation method is compared with several known segmentation methods using DRIVE...	fast fourier transform;region growing	N. D. Salih;Marwan D. Saleh;Chikkannan Eswaran;Junaidi Abdullah	2018	CMBBE: Imaging & Visualization	10.1080/21681163.2016.1182071	fast fourier transform;optic disc;scale-space segmentation;template matching;computer vision;region growing;computer science;fundus (eye);artificial intelligence;mathematical morphology;segmentation	Visualization	36.91338892234613	-75.66850080459336	138128
b536dc3d0fa191c28c4a5445efe76ebfb244bc18	computer-aided detection of pulmonary nodules using genetic programming	databases;lung region;genetic program;adaptive thresholding;image segmentation;computed tomography;pulmonary nodule;cancer;cad development;feature extraction lungs three dimensional displays computed tomography cancer databases labeling;lungs;rule based;image classification;genetic programming;lung;medical image processing computerised tomography feature extraction genetic algorithms image classification image segmentation image sequences lung;voxel labelling;ct image sequence;three dimensional displays;feature extraction;medical image processing;lung imaging database consortium;image sequence;pulmonary nodules;computerised tomography;detection rate;computer aided detection;genetic algorithms;hrct;national cancer institute;rule based classifier;lung image database consortium;false positive;cad development hrct pulmonary nodule lung nodule detection;lung imaging database consortium computer aided detection pulmonary nodules genetic programming nodule detection false positive reduction lung region ct image sequence adaptive thresholding feature extraction voxel labelling rule based classifier fitness function;nodule detection;labeling;false positive reduction;fitness function;image sequences	This paper describes a novel nodule detection method that enhances false positive reduction. Lung region is extracted from CT image sequence using adaptive thresholding and 18-connectedness voxel labelling. In the extracted lung region, nodule candidates are detected using adaptive multiple thresholding and rule based classifier. After that, we extract the 3D and 2D features from nodule candidates. The nodule candidates are then classified using genetic programming (GP) based classifier. In this work, a new fitness function is proposed to generate optimal adaptive classifier. We tested the proposed algorithm by using Lung Imaging Database Consortium (LIDC) database of National Cancer Institute (NCI). The classifier was trained and evaluated using two independent dataset and whole dataset. The proposed method reduced the false positives in nodule candidates and achieved 92% detection rate with 6.5 false positives per scan.	algorithm;consortium;fitness function;genetic programming;nc (complexity);thresholding (image processing);voxel	Wook-Jin Choi;Tae-Sun Choi	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5652369	rule-based system;genetic programming;computer vision;labeling theory;contextual image classification;genetic algorithm;type i and type ii errors;feature extraction;computer science;machine learning;thresholding;image segmentation;computed tomography;fitness function;cancer	Robotics	36.5915693826338	-75.19132833545416	138251
646eb6e19d2d0c858d71d3d810f4642cfaa130c2	human body shape prediction and analysis using predictive clustering tree	trees mathematics pattern clustering shape recognition;pattern clustering;shape solid modeling training three dimensional displays principal component analysis buildings partitioning algorithms;predictive modeling;training;shape recognition;trees mathematics;demographic attributes predictive modeling digital human modeling predictive clustering tree;three dimensional;human body shape prediction;shape;body shape descriptors;three dimensional displays;principal component analysis;human body;solid modeling;pct;digital human modeling;prediction model;demographic attributes;body shape descriptors human body shape prediction predictive clustering tree digital human modeling pct demographic attributes;buildings;predictive clustering tree;partitioning algorithms	Predictive modeling aims at constructing models that predict a target property of an object based on its descriptions. In digital human modeling, it can be applied to predicting human body shape from images, measurements, or descriptive features. While images and measurements can be converted to numerical values, it is difficult to assign numerical values to descriptive features and therefore regression based methods cannot be applied. In this work, we propose to use Predictive Clustering Trees (PCT) to predict human body shapes from demographic information. We build PCTs using a dataset of demographic attributes and body shape descriptors. We demonstrate empirically that the PCT-based method has similar predicting power as the numerical approaches using body measurements. The PCTs also reveal interesting structures of the training dataset and provide interpretations of the body shape variations from the perspective of the demographic attributes.	cluster analysis;numerical analysis;object-based language;predictive modelling;protein structure prediction	Pengcheng Xi;Hongyu Guo;Chang Shu	2011	2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission	10.1109/3DIMPVT.2011.32	computer vision;computer science;machine learning;pattern recognition	Vision	36.85369704501934	-69.79494701428374	138286
68353b0cfa6cd44b5ff97ce957084b72bc84934c	an exploration of 2d and 3d deep learning techniques for cardiac mr image segmentation		Accurate segmentation of the heart is an important step towards evaluating cardiac function. In this paper, we present a fully automated framework for segmentation of the left (LV) and right (RV) ventricular cavities and the myocardium (Myo) on short-axis cardiac MR images. We investigate various 2D and 3D convolutional neural network architectures for this task. Experiments were performed on the ACDC 2017 challenge training dataset comprising cardiac MR images of 100 patients, where manual reference segmentations were made available for end-diastolic (ED) and end-systolic (ES) frames. We find that processing the images in a slice-by-slice fashion using 2D networks is beneficial due to a relatively large slice thickness. However, the exact network architecture only plays a minor role. We report mean Dice coefficients of 0.950 (LV), 0.893 (RV), and 0.899 (Myo), respectively with an average evaluation time of 1.1 seconds per volume on a modern GPU.	apache axis;artificial neural network;coefficient;convolutional neural network;deep learning;graphics processing unit;image segmentation;logical volume management;myo armband;network architecture;thickness (graph theory)	Christian F. Baumgartner;Lisa M. Koch;Marc Pollefeys;Ender Konukoglu	2017		10.1007/978-3-319-75541-0_12	convolutional neural network;pattern recognition;network architecture;machine learning;dice;computer science;deep learning;cardiac function curve;artificial intelligence;computer vision;image segmentation	Vision	31.002897736906892	-75.4217297045382	138333
fd80a812a98ddab213b9baadafd15fa3644ed227	a two-view ultrasound cad system for spina bifida detection using zernike features	brain;spine;zernike moments;image segmentation;computer aided diagnosis;ultrasound;segmentation;decision maker;ultrasound imaging;medical diagnostics;feature extraction;zernike moment;computer aided detection;svm;ultrasonography;birth defect;computer aided detection diagnosis;spina bifida	In this work, we address a very specific CAD (Computer Aided Detection/Diagnosis) problem and try to detect one of the relatively common birth defects - spina bifida, in the prenatal period. To do this, fetal ultrasound images are used as the input imaging modality, which is the most convenient so far. Our approach is to decide using two particular types of views of the fetal neural tube. Transcerebellar head (i.e. brain) and transverse (axial) spine images are processed to extract features which are then used to classify healthy (normal), suspicious (probably defective) and non-decidable cases. Decisions raised by two independent classifiers may be individually treated, or if desired and data related to both modalities are available, those decisions can be combined to keep matters more secure. Even more security can be attained by using more than two modalities and base the final decision on all those potential classifiers. Our current system relies on feature extraction from images for cases (for particular patients). The first step is image preprocessing and segmentation to get rid of useless image pixels and represent the input in a more compact domain, which is hopefully more representative for good classification performance. Next, a particular type of feature extraction, which uses Zernike moments computed on either B/W or gray-scale image segments, is performed. The aim here is to obtain values for indicative markers that signal the presence of spina bifida. Markers differ depending on the image modality being used. Either shape or texture information captured by moments may propose useful features. Finally, SVM is used to train classifiers to be used as decision makers. Our experimental results show that a promising CAD system can be actualized for the specific purpose. On the other hand, the performance of such a system would highly depend on the qualities of image preprocessing, segmentation, feature extraction and comprehensiveness of image data.© (2011) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	computer-aided design	Umut Konur;Fikret S. Gürgen;Füsun Varol	2011		10.1117/12.878458	support vector machine;computer vision;decision-making;spine;feature extraction;artificial intelligence;ultrasonography;ultrasound;image segmentation;segmentation	Robotics	33.78157053386349	-76.5517768869767	138401
bb60196acdd4b0870cd0dd7f5a7c712aa042b1d1	a benchmark for endoluminal scene segmentation of colonoscopy images		Colorectal cancer (CRC) is the third cause of cancer death worldwide. Currently, the standard approach to reduce CRC-related mortality is to perform regular screening in search for polyps and colonoscopy is the screening tool of choice. The main limitations of this screening procedure are polyp miss rate and the inability to perform visual assessment of polyp malignancy. These drawbacks can be reduced by designing decision support systems (DSS) aiming to help clinicians in the different stages of the procedure by providing endoluminal scene segmentation. Thus, in this paper, we introduce an extended benchmark of colonoscopy image segmentation, with the hope of establishing a new strong benchmark for colonoscopy image analysis research. The proposed dataset consists of 4 relevant classes to inspect the endoluminal scene, targeting different clinical needs. Together with the dataset and taking advantage of advances in semantic segmentation literature, we provide new baselines by training standard fully convolutional networks (FCNs). We perform a comparative study to show that FCNs significantly outperform, without any further postprocessing, prior results in endoluminal scene segmentation, especially with respect to polyp segmentation and localization.	benchmark (computing);cervix adenomatous polyp;class;colorectal carcinoma;compute against cancer;cyclic redundancy check;decision support systems, clinical;decision support system;image analysis;image segmentation;internationalization and localization;neoplasms;screening procedure;silo (dataset);biologic segmentation;cellular targeting;decision support systems;polyps	David Vázquez;Jorge Bernal;F. Javier Sánchez;Gloria Fernández-Esparrach;Antonio M. López;Adriana Romero;Michal Drozdzal;Aaron C. Courville	2017		10.1155/2017/4037190	computer vision	Vision	32.26971598999162	-75.43544179155207	138533
055545f63bf1e3c28ea909d952a17a11cf5cee42	learning-based mitotic cell detection in histopathological images	source code learning based mitotic cell detection histopathological images breast cancer grading histological tissue samples visual inspection standard clinical practice cancer development prognosis cancer development diagnosis tumor prognosis histologically stained breast cancer tissue sections hierarchical learning workflow automated mitosis detection pixel wise classifier candidate cell segmentation nonmitotic cells object shape texture features open source biomedical image analysis software cellcognition ilastik user friendly interface learning algorithms pathologist work high resolution histopathological images precision recall curve annotated dataset;image segmentation;cancer;biological organs;tumours;image classification;shape recognition;tumours biological organs cancer cellular biophysics image classification image segmentation learning artificial intelligence medical image processing object detection shape recognition;medical image processing;learning artificial intelligence;image segmentation breast cancer training accuracy shape pattern recognition standards;cellular biophysics;object detection	Breast cancer grading of histological tissue samples by visual inspection is the standard clinical practice for the diagnosis and prognosis of cancer development. An important parameter for tumor prognosis is the number of mitotic cells present in histologically stained breast cancer tissue sections. We propose a hierarchical learning workflow for automated mitosis detection in breast cancer. From an initial training set a pixel-wise classifier is learned to segment candidate cells, which are then classified into mitotic and non-mitotic cells using object shape and texture features. Our workflow banks on two open source biomedical image analysis software: “ilastik” and “CellCognition” which provide a user user friendly interface to powerful learning algorithms, with the potential of making the pathologist work an easier task. We evaluate our approach on a dataset of 35 high-resolution histopathological images from 5 different specimen (provided by International Conference for Pattern Recognition 2012 contest on Mitosis Detection in Breast Cancer Histological Images). Based on the candidate segmentation our approach achieves an area-under Precision-Recall-curve of 70% on an annotated dataset, with good localization accuracy, little parameter tuning and small user effort. Source code is provided.	algorithm;biological specimen;cellcognition;graphical user interface;image analysis;image resolution;machine learning;open-source software;pattern recognition;pixel;supervised learning;test set;usability;visual inspection;ilastik	Christoph Sommer;Luca Fiaschi;Fred A. Hamprecht;Daniel Gerlich	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		computer vision;contextual image classification;computer science;bioinformatics;image segmentation;cancer	Vision	36.08713603745968	-75.17548112687275	138645
5064e5e8d1d8f68957e6cd219b6b0902139a1392	semi-automatic region-of-interest segmentation based computer-aided diagnosis of mass lesions from dynamic contrast-enhanced magnetic resonance imaging based breast cancer screening	sensitivity and specificity;breast neoplasms;female;retrospective studies;breast;image enhancement;diagnosis differential;image interpretation computer assisted;magnetic resonance imaging;reproducibility of results;contrast media;roc curve;pattern recognition automated;humans	Cancer screening with magnetic resonance imaging (MRI) is currently recommended for very high risk women. The high variability in the diagnostic accuracy of radiologists analyzing screening MRI examinations of the breast is due, at least in part, to the large amounts of data acquired. This has motivated substantial research towards the development of computer-aided diagnosis (CAD) systems for breast MRI which can assist in the diagnostic process by acting as a second reader of the examinations. This retrospective study was performed on 184 benign and 49 malignant lesions detected in a prospective MRI screening study of high risk women at Sunnybrook Health Sciences Centre. A method for performing semi-automatic lesion segmentation based on a supervised learning formulation was compared with the enhancement threshold based segmentation method in the context of a computer-aided diagnostic system. The results demonstrate that the proposed method can assist in providing increased separation between malignant and radiologically suspicious benign lesions. Separation between malignant and benign lesions based on margin measures improved from a receiver operating characteristic (ROC) curve area of 0.63 to 0.73 when the proposed segmentation method was compared with the enhancement threshold, representing a statistically significant improvement. Separation between malignant and benign lesions based on dynamic measures improved from a ROC curve area of 0.75 to 0.79 when the proposed segmentation method was compared to the enhancement threshold, also representing a statistically significant improvement. The proposed method has potential as a component of a computer-aided diagnostic system.	computer assisted diagnosis;computer-aided design;heart rate variability;magnetic resonance imaging;malignant childhood central nervous system neoplasm;neoplasms;prospective search;radiology;receiver operating characteristic;receiver operator characteristics;semiconductor industry;silo (dataset);stage 0 breast carcinoma;supervised learning;therapy, computer-assisted;biologic segmentation	Jacob E. D. Levman;Ellen Warner;Petrina Causer;Anne L. Martel	2014	Journal of Digital Imaging	10.1007/s10278-014-9723-y	radiology;medicine;pathology;magnetic resonance imaging;retrospective cohort study;receiver operating characteristic	EDA	34.84629440588008	-78.27772995323558	138751
1ba2523b6b64a7d0f39aeaad4696364cee14c622	skinnet: a deep learning framework for skin lesion segmentation		There has been a steady increase in the incidence of skin cancer worldwide, with a high rate of mortality. Early detection and segmentation of skin lesions is crucial for timely diagnosis and treatment, necessary to improve the survival rate of patients. However, skin lesion segmentation is a challenging task due to the low contrast of lesions and their high similarity in terms of appearance, to healthy tissue. This underlines the need for an accurate and automatic approach for skin lesion segmentation. To tackle this issue, we propose a convolutional neural network (CNN) called SkinNet. The proposed CNN is a modified version of U-Net. We compared the performance of our approach with other state-of-the-art techniques, using the ISBI 2017 challenge dataset. Our approach outperformed the others in terms of the Dice coefficient, Jaccard index and sensitivity, evaluated on the held-out challenge test data set, across 5-fold cross validation experiments. SkinNet achieved an average value of 85.10, 76.67 and 93%, for the DC, JI and SE, respectively.	artificial neural network;convolutional neural network;deep learning;experiment;incidence matrix;jaccard index;sørensen–dice coefficient;test data	Sulaiman Vesal;Nishant Ravikumar;Andreas K. Maier	2018	CoRR		lesion;jaccard index;cross-validation;machine learning;convolutional neural network;sørensen–dice coefficient;deep learning;pattern recognition;artificial intelligence;test data;computer science;segmentation	AI	32.28340051373195	-75.93881962206437	139294
78849debe2ffe006b21574e429fec3d839ae6686	a decision support system based on the semantic analysis of melanoma images using multi-elitist pso and svm	decision support system;medical expert;automatic classification process;proposed classification method;semantic analysis;image feature extraction;classification accuracy;melanoma image;multi-elitist pso;melanoma malignum image;melanoma malignum;medical diagnosis;image segmentation	decision support system;medical expert;automatic classification process;proposed classification method;semantic analysis;image feature extraction;classification accuracy;melanoma image;multi-elitist pso;melanoma malignum image;melanoma malignum;medical diagnosis;image segmentation		Weronika Piatkowska;Jerzy Martyna;Leszek Nowak;Karol Przystalski	2011		10.1007/978-3-642-23199-5_27	computer science;machine learning;pattern recognition;data mining	Robotics	34.79930707667607	-74.22366966667757	139401
e5c65d84dea4ba506173a939c7626ebb2397e8d9	sorting the phenotypic heterogeneity of autism spectrum disorders: a hierarchical clustering model	hierarchical clustering;mental disorders;hierarchical clustering data mining autism spectrum disorder machine learning;spectrum analysis;bepress selected works;autism spectrum disorder;autism spectrum disorders;mixed data types;data mining;learning systems;genetic data;hierarchical structures;autism genetics indexes clustering algorithms algorithm design and analysis correlation pediatrics;cluster analysis;pattern clustering bioinformatics medical disorders;machine learning;genetic studies;diseases;artificial intelligence;hier archical clustering;artificial intelligence bioinformatics cluster analysis data mining diseases learning systems autism spectrum disorders genetic data genetic studies hier archical clustering hierarchical structures mental disorders mixed data types spectrum analysis;cluster analysis phenotypic heterogeneity sorting autism spectrum disorders hierarchical clustering model etiology diagnosis treatment prognosis phenotype variability dsm 5 model phenotypic markers genotypic markers;bioinformatics	Autism spectrum disorder (ASD) is characterized by notable phenotypic heterogeneity, which is often viewed as an obstacle to the study of its etiology, diagnosis, treatment, and prognosis. Heterogeneity in ASD is multidimensional and complex including variability in phenotype as well as clinical, physiologic, and pathologic parameters. We apply a hierarchical clustering model suited to dealing with datasets of mixed data types to stratify children with ASD into more homogeneous subgroups in line with the Diagnostic and Statistical Manual of Mental Disorders (DSM)-5 model. The results of this cluster analysis will provide a better understanding the complex issue of ASD phenotypic heterogeneity and identify subgroups useful for further ASD genetic studies. Our goal is to provide insight into viable phenotypic and genotypic markers that would guide further cluster analysis of ASD genetic data. We suggest that analyzing the clusters in a hierarchical structure is a well-suited and meaningful model to unravel the complex heterogeneity of this disorder.	cluster analysis;hierarchical clustering;hierarchical database model;numerical analysis;programming paradigm;sorting;spatial variability;tree structure	Tayo Obafemi-Ajayi;Dao Lam;T. Nicole Takahashi;Stephen M Kanne;Donald C. Wunsch	2015	2015 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)	10.1109/CIBCB.2015.7300337	spectrum analyzer;computer science;bioinformatics;machine learning;hierarchical clustering;cluster analysis	Visualization	25.096116179859305	-79.12936380935325	139453
99d98d54678af2b427eab3479525c6609e59c9bf	self-learning to detect and segment cysts in lung ct images without manual annotation		Image segmentation is a fundamental problem in medical image analysis. In recent years, deep neural networks achieve impressive performances on many medical image segmentation tasks by supervised learning on large manually annotated data. However, expert annotations on big medical datasets are tedious, expensive or sometimes unavailable. Weakly supervised learning could reduce the effort for annotation but still required certain amounts of expertise. Recently, deep learning shows a potential to produce more accurate predictions than the original erroneous labels. Inspired by this, we introduce a very weakly supervised learning method, for cystic lesion detection and segmentation in lung CT images, without any manual annotation. Our method works in a self-learning manner, where segmentation generated in previous steps (first by unsupervised segmentation then by neural networks) is used as ground truth for the next level of network learning. Experiments on a cystic lung lesion dataset show that the deep learning could perform better than the initial unsupervised annotation, and progressively improve itself after self-learning.	artificial neural network;ct scan;deep learning;ground truth;image analysis;image segmentation;medical image computing;performance;supervised learning;unsupervised learning	Ling Zhang;Vissagan Gopalakrishnan;Le Lu;Ronald M. Summers;Joel Moss;Jianhua Yao	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363763	convolutional neural network;supervised learning;machine learning;artificial neural network;artificial intelligence;deep learning;pattern recognition;computer science;image segmentation;ground truth;segmentation;annotation	Vision	31.48930069285123	-74.64380545939788	139499
ae01dc69334057e124ce654f3ef25fa9a351933e	lumbar spine discs labeling using axial view mri based on the pixels coordinate and gray level features		Disc herniation is a major reason for lower back pain (LBP), a health issue that affects a very high proportion of the UK population and is costing the UK government over £1.3 million per day in health care cost. Currently, the process to diagnose the cause of LBP involves examining a large number of Magnetic Resonance Images (MRI) but this process is both expensive in terms time and effort. Automatic labeling of lumbar disc pixels in the MRI to detect the herniation area will reduce the time to diagnose and detect the cause of LBP by the physicians. In this paper, we present a method for automatic labeling of the lumbar spine disc pixels in axial view MRI using pixels locations and gray level as features. Clinical MRIs are used for the training and testing of the method. The pixel classification accuracy and the quality of the reconstructed disc images are used as the main performance indicators for our method. Our experiments show that high level of classification accuracy of 91.1% and 98.9% can be achieved using Weighted KNN and Fine Gaussian SVM classifiers respectively.	dendritic spine;grayscale;k-nearest neighbors algorithm;local binary patterns;neutral spine;pixel;radiology;resonance;support vector machine	Ala S. Al Kafri;Sud Sudirman;Abir Jaafar Hussain;Paul Fergus;Dhiya Al-Jumeily;Hiba Al Smadi;Mohammed Khalaf;Mohammed Al-Jumaily;Wasfi Al-Rashdan;Mohammad Bashtawi;Jamila Mustafina	2017		10.1007/978-3-319-63315-2_10	support vector machine;pattern recognition;artificial intelligence;pixel;computer science;lumbar;magnetic resonance imaging;back pain;population;gray (unit)	Vision	33.130394129241246	-76.15600792225457	140161
adc441580cfaf6a005efd397e0bf18ca57146951	random sampling based svm for relevance feedback image retrieval	statistical natural language processing;user-customized presentation;image retrieval;automated production;media integration;visual information;content-based image retrieval system;virtualized classroom;challenging research issue;electronic learning;user interfaces;software systems;user interface;indexation;computer science;production	Relevance feedback (RF) schemes based on support vector machine (SVM) have been widely used in content-based image retrieval. However, the performance of SVM based RF is often poor when the number of labeled positive feedback samples is small. This is mainly due to three reasons: (1) SVM classifier is unstable on small size training set; (2) SVM's optimal hyper-plane may be biased when the positive feedback samples are much less than the negative feedback samples; (3) overfitting due to that the feature dimension is much higher than the size of the training set. In this paper, we try to use random sampling techniques to overcome these problems. To address the first two problems, we propose an asymmetric bagging based SVM. For the third problem, we combine the random subspace method (RSM) and SVM for RF. Finally, by integrating bagging and RSM we solve all the three problems and further improve the RF performance.	content-based image retrieval;control theory;monte carlo method;negative feedback;overfitting;positive feedback;radio frequency;random subspace method;regular expression;relevance feedback;response surface methodology;sampling (signal processing);support vector machine;test set	Dacheng Tao;Xiaoou Tang	2004	Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.	10.1109/CVPR.2004.199	support vector machine;sampling;image retrieval;computer science;machine learning;pattern recognition;ranking svm;information retrieval;statistics	Vision	29.944942620819756	-66.70439833842714	140283
0b9b1b0bafba858ce1112763d21696c43e01345a	application of structural and textural features from x-ray images to predict the type of bone fracture treatment		Analysis of medical images plays a very important role in clinical decisionmaking. For a long time it has required extensive involvement of a human expert. However, recent progress in data mining techniques, especially in machine learning, allows for creating decision models and support systems that help to automatize this task and provide clinicians with patient-specific therapeutic and diagnostic suggestions. In this paper, we describe a study aimed at building a decision model (a classifier) that would predict the type of treatment (surgical vs. non-surgical) for patients with bone fractures based on their X-ray images. We consider two types of features extracted from images (structural and textural) and used them to construct multiple classifiers that are later evaluated in a computational experiment. Structural features are computed by applying the Hough transform, while textural information is obtained from gray-level occurrence matrix (GLCM). In research reported by other authors structural and textural features were typically considered separately. Our findings show that while structural features have better predictive capabilities, they can benefit from combining them with textural ones. Interestingly, there are no statistical differences in overall classification accuracy attained by the classifiers considered in the study (it ranges from 91.0% to 96.1%), however, the most promising one is the random forest.	computation;data mining;document-term matrix;hough transform;machine learning;medical imaging;random forest	Anam Haq;Szymon Wilk	2018			bone fracture;data mining;computer science;computer vision;artificial intelligence	ML	32.992075711460025	-76.700301592108	140867
26ce3517232003335a0c16e13e5abe99e7894b23	automatic generation of suitable dwt sub-band - an application to brain mri classification		This paper addresses the Brain MRI (Magnetic Resonance Imaging) classification problem from a new point of view. Indeed, most of the works reported in the literature follow the subsequent methodology: 1) Discrete Wavelet Transform (DWT) application, 2) sub-band selection, 3) feature extraction, and 4) learning. Consequently, those methods are limited by the information contained on the selected DWT outputs (sub-bands). This paper addresses the possibility of creating new suitable DWT sub-bands (by combining the classical DWT sub-bands) using Genetic Programming (GP) and a Random Forest (RF) classifier. These could be employed to efficiently address different classification scenarios (normal versus pathological, one versus all, and even multiclassification) as well as other automatic tasks.	discrete wavelet transform;feature extraction;genetic programming;radio frequency;random forest;resonance	Mohamed Mokhtar Bendib;Hayet Farida Merouani;Fatma Diaba	2015		10.5220/0005333001660170	artificial intelligence;pattern recognition;computer vision;computer science	Vision	34.20976727718281	-74.88527062599381	140984
cd0083f4e7392e4049ee6f0c8b1bfafb748eabce	hair removal methods: a comparative study for dermoscopy images	skin lesion;human vision;fast marching method;pde;skin cancer;melanoma;fast marching;dermoscopy;hair segmentation;non linear partial differential equations;linear interpolation;comparative study;performance analysis;ground truth;image inpainting	Removal and restoration of hair and hair-like regions within skin lesion images is needed so features within lesions can be more effectively analyzed for benign lesions, cancerous lesions, and for cancer discrimination. This paper refers to “melanoma texture” as a rationale for supporting the need for the proposed hair detection and repair techniques, which incompletely represents why hair removal is an important operation for skin lesion analysis. A comparative study of the state-of-the-art hair-repaired methods with a novel algorithm is also proposed by morphological and fast marching schemes. The hair-repaired techniques are evaluated in terms of computational, performance and tumor-disturb patterns ( TDP ) aspects. The comparisons have been done among (i) linear interpolation, inpainting by (ii) non-linear partial differential equation ( PDE ) and (iii) exemplar-based repairing techniques. The performance analysis of hair detection quality, was based on the evaluation of the hair detection error ( HDE ), quantified by statistical metrics and manually used to determine the hair lines from a dermatologist as the ground truth. The results are presented on a set of 100 dermoscopic images. For the two characteristics measured in the experiments the best method is the fast marching hair removal algorithm ( HDE : 2.98%,  TDP : 4.21%). This proposed algorithm repaired the texture of the melanoma, which becomes consistent with human vision. The comparisons results obtained, indicate that hair-repairing algorithm based on the fast marching method achieve an accurate result.		Qaisar Abbas;M. Emre Celebi;Irene Fondón	2011	Biomed. Signal Proc. and Control	10.1016/j.bspc.2011.01.003	computer vision;pathology;computer science;fast marching method;mathematics	Robotics	38.725524385335724	-76.02189722910084	141183
41d7e974d0d90e8e32558d03c0b86ff863ae623a	acoustic range image segmentation by effective mean shift	pattern clustering;range data;image segmentation;acoustic data analysis;underwater sound;mean shift;acoustic signal processing;segmentation;indexing terms;clustering methods acoustic signal processing image segmentation;range image segmentation;underwater sound acoustic imaging image segmentation pattern clustering;parameter tuning;range image;clustering method;image segmentation bandwidth kernel signal processing underwater acoustics image converters acoustic beams humans image recognition acceleration;acoustic imaging;clustering methods;acceleration techniques;acoustic signal processing acoustic range image segmentation effective mean shift image perception underwater environment mean shift clustering paradigm reverse projection paradigm acceleration technique	Image perception in underwater environment is a difficult task for a human operator, and data segmentation becomes a crucial step toward an higher level interpretation and recognition of the observing scenarios. This paper contributes to the related state of the art, by fitting the mean shift clustering paradigm to the segmentation of acoustical range images, providing a segmentation approach in which whatever parameter tuning is absent. Moreover, the method exploits actively the connectivity information provided by the range map, by using reverse projection as acceleration technique. Therefore, the method is able to produce, starting from raw range data, meaningful segmented clouds of points in a fully automatic and efficient fashion.	acoustic fingerprint;cluster analysis;image segmentation;mean shift;programming paradigm;range imaging;range segmentation	Umberto Castellani;Marco Cristani;Vittorio Murino	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312769	computer vision;range segmentation;speech recognition;index term;mean-shift;computer science;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation;optoacoustic imaging;segmentation	Robotics	27.60450742839174	-67.82566340280393	141258
f550c3a1322b8709b257c83f5016160a655dfcb9	automatic detection of hard exudates and optic disc in digital fundus images		Automatic detection of characteristic patterns of diabetic retinopathy such as hard exudates may help to an early diagnosis. Methods for automatic detection of hard exudates and optic disc are presented. Exudates detection involves a preprocessing stage, threshold selection and region growing. For optic disc detection a Bayes classifier is applied followed by mathematical morphology techniques in order to improve the final result. The methods here presented were evaluated using the IMAGERET database, which contains fundus images evaluated by qualified experts. In average, the area of exudates automatically detected overlaped with 60.75% and 63.91% areas defined by each of the two experts. For optic disc detection, sensitivity and specificity were 72.12% and 95.56% respectively.	mathematical morphology;preprocessor;region growing;sensitivity and specificity	Elizabeth Chavez-Hernandez;M. Elena Martínez-Pérez	2012			ophthalmology;hard exudates;optic disc;fundus (eye);computer science	Vision	36.79422917559961	-75.7602719712832	141469
cd7faf422cf44304666b840e0dab0754e9ec0c6a	recognition of lung nodules from x-ray ct images using 3d markov random field models	x ray images;image recognition;mathematical morphology;computed tomography;volume of interest;x ray imaging;lungs;filters;markov random fields;biomedical imaging;lung computerised tomography x ray imaging medical image processing image recognition markov processes;blood vessel;lung;markov random field;model evaluation;morphology;x ray ct;medical image processing;3d markov random field;computerised tomography;image recognition lungs x ray imaging computed tomography markov random fields blood vessels biomedical imaging pathology morphology filters;medical image processing lung nodules image recognition x ray images ct images computerised tomography 3d markov random field volume of interest;markov processes;lung nodules;ct images;pathology;blood vessels;object model	In this paper, we propose a new recognition method of lung nodules from X-ray CT images using 3D Markov random field(MRF) models. Pathological shadow candidates are detected by a mathematical morphology filter, and volume of interest(VOI) areas which include the shadow candidates are extracted. The probabilities of the hypotheses that the VOI areas come from nodules(which are candidates of cancers) and blood vessels are calculated using nodule and blood vessel models evaluating the relations between these object models by 3D MRF models. If the probabilities for the nodule models are higher, the shadow candidates are determined to be abnormal. By applying this new recognition method to actual 38 CT images, good results has been acquired.	ct scan;markov chain;markov random field;mathematical morphology	Hotaka Takizawa;Shinji Yamamoto;Toru Matsumoto;Yukio Tateno;Takeshi Iinuma;Mitsuomi Matsumoto	2002		10.1109/ICPR.2002.1044622	computer vision;mathematical morphology;object model;morphology;computer science;mathematics;markov process	Vision	38.29675527266694	-75.50988151250871	141683
d9879835f88be19e9e64e8155c2c5aa37b492018	interpretation of mammogram and chest radiograph reports using deep neural networks - preliminary results.		Radiology reports are an important means of communication between radiologists and other physicians. These reports express a radiologistu0027s interpretation of a medical imaging examination and are critical in establishing a diagnosis and formulating a treatment plan. In this paper, we propose a Bi-directional convolutional neural network (Bi-CNN) model for the interpretation and classification of mammograms based on breast density and chest radiographic radiology reports based on the basis of chest pathology. The proposed approach helps to organize databases of radiology reports, retrieve them expeditiously, and evaluate the radiology report that could be used in an auditing system to decrease incorrect diagnoses. Our study revealed that the proposed Bi-CNN outperforms the random forest and the support vector machine methods.		Hojjat Salehinejad;Joseph Barfett;Shahrokh Valaee;Errol Colak;Aren Mnatzakanian;Tim Dowdell	2017	CoRR		medical physics;medical diagnosis;support vector machine;convolutional neural network;random forest;radiography;artificial neural network;chest radiograph;computer science;medical imaging	NLP	32.485252336858906	-76.52903596930588	141692
5c1c0ab21d095b18590095e0b2c930e171ddb3e6	automatic detection of epiretinal membrane in oct images by means of local luminosity patterns		This work presents a novel approach for automatic detection of the epiretinal membrane in Optical Coherence Tomography (OCT) images. A tool able to detect this pathology is very valued since it can prevent further ocular damage by doing an early detection. This approach is based in the location of the inner limiting membrane (ILM) layers of the retina. Then, the detected locations are classified using a local-feature based vector in order to determine presence of the membrane. Different tests are run and compared to establish the appropriateness of the approach as well as its practical validity.		Sergio Baamonde;Joaquim de Moura;Jorge Novo;Marcos Ortega	2017		10.1007/978-3-319-59153-7_20	computer vision;artificial intelligence;computer science;retina;pattern recognition;epiretinal membrane;inner limiting membrane;membrane;medical imaging;luminosity;optical coherence tomography	Vision	36.72174115142184	-76.23506854031668	141947
e0ed576a03e3fa970c2e97d1ca8ad6fd3d0aff2e	a knowledge-based videotheodolite measurement system for object representation/monitoring	object representation;knowledge based system;image processing;interest points;interest operator;measurement system;videometric system;3d measurement;knowledge base	High-precision online 3D-measurement systems can perform their measurements with and without targeting. Systems which are able to measure without artificial targets use the texture on the surface of the object to find ‘interesting points’. However, well-trained ‘measurement experts’ are required to operate such a measurement system. In order to make such systems easy to use even for non-experts, we extend it by a knowledge-based component which supports the operator. We report on the architecture and functionality of the respective knowledge-based system, its development stage and the promising results obtained in experimentation. 2007 Elsevier Ltd. and Civil-Comp Ltd. All rights reserved.	algorithm;artificial neural network;case-based reasoning;edge detection;embedded system;experiment;feature extraction;high- and low-level;image analysis;image editing;image processing;knowledge base;knowledge-based systems;preprocessor;semiconductor industry;software release life cycle;system of measurement;unsharp masking	Alexander Reiterer;Uwe Egly;Thomas Eiter;Heribert Kahmen	2008	Advances in Engineering Software	10.1016/j.advengsoft.2007.05.003	computer vision;knowledge base;simulation;image processing;computer science;artificial intelligence;system of measurement;data mining	AI	36.78694642468758	-68.95428940342275	141997
4cf2455178674ace9bdd12342a793afbf07f61c2	cervical cancer classification using gabor filters	texture;biological tissues;classification cervical gabor cancer filters;image segmentation;cancer;bepress selected works;filters;image classification;medical image processing biological tissues biomedical optical imaging cancer feature extraction gabor filters gynaecology image classification image segmentation image texture;gabor filters image segmentation cervical cancer biomedical imaging image color analysis filter banks;biomedical imaging;gabor filter cervical cancer histology image biopsy texture;gabor filters;classification;gynaecology;image texture;gabor filter;biopsy;cervical cancer diagnosis cervical cancer classification computer assisted classification digitized histology images cervical biopsy texture analysis nuclei structure cervical cancer histology two tier classification strategy malignant tissue benign tissue texture classification gabor filter bank image segmentation background cell abnormal cell basal cell stroma cell global classification algorithm feature vectors epithelium layer;image color analysis;cervical cancer;feature extraction;medical image processing;gabor;cervical;filter banks;biomedical optical imaging;histology image	This paper presents a novel algorithm for computer-assisted classification of cervical cancers using digitized histology images of biopsies. Texture analysis of the nuclei structure is very important for classification of cervical cancer histology. In this paper we present a two-tier classification strategy using Gabor filter banks for local classification and abnormality spread for global taxonomy. The test data used in this work are digitized histology images of cervical biopsies acquired from the pathology laboratories in the Saiful An war Hospital in Indonesia. The images from over 500 subjects are categorized by the pathologists into five grades, benign, pre-cancer (CIN1, CIN2, CIN3) and malignant. In the algorithm developed in this work, a texture classification method using Gabor filter banks is implemented to segment the image into five possible regions: of background, normal, abnormal, basal and stroma cells. The global classification algorithm uses the segmented image for the final prognosis of the degree of malignancies from benign to malignant. The process of texture segmentation using the Gabor filter bank involves the application of filters for several spatial frequencies and orientations. The Gabor filter bank is applied to cervical histology images with six frequencies and four orientations. Feature vectors are formed, comprising the response of each pixel and its neighboring pixels to each filter. The feature vectors are then used to classify each pixel and its immediate neighbor pixels into five categories. Based on the spread of abnormalities on the epithelium layer, the cervical histology image is then classified. The classification results are then used to further classify the image into: 1) normal, 2) pre-cancer and 3) malignant. The pre-cancer is divided into: a) CIN 1, b) CIN 2 and c) CIN 3. The final system will take as input a biopsy image of the cervix containing the epithelium layer and provide the classification using our new approach, to assist the pathologist in cervical cancer diagnosis.	algorithm;basal (phylogenetics);categorization;cluster analysis;emoticon;feature vector;filter bank;gabor filter;multitier architecture;pixel;saiful islam (professor);sensitivity and specificity;test data	Rahmadwati;Golshah Naghdy;Montserrat Ros;Catherine A. Todd;Eviana Norahmawati	2011	2011 IEEE First International Conference on Healthcare Informatics, Imaging and Systems Biology	10.1109/HISB.2011.15	computer vision;medicine;pathology;pattern recognition	Vision	36.79720213402136	-75.4461759891125	142088
5af396a1d8dd33b562b79611782ea732e5200bea	application of artificial neural networks for quantitative analysis of image data in chest radiographs for detection of interstitial lung disease	interstitial lung disease;radiography thoracic;computer aided diagnosis;receiver operator characteristic;rule based;chest radiograph;image processing computer assisted;interstitial infiltrate;statistical properties;roc analysis;region of interest;roc curve;quantitative analysis;humans;lung diseases interstitial;neural networks computer;artificial neural network	The authors have developed an automated computeraided diagnostic (CAD) scheme by using artificial neural networks (ANNs) on quantitative analysis of image data. Three separate ANNs were applied for detection of interstitial disease on digitized chest images. The first ANN was trained with horizontal profiles in regions of interest (ROIs) selected from normal and abnormal chest radiographs for distinguishing between normal and abnormal patterns. For training and testing of the second ANN, the vertical output patterns obtained from the 1st ANN were used for each ROI. The output value of the second ANN was used to distinguish between normal and abnormal ROIs with interstitial infiltrates. If the ratio of the number of abnormal ROIs to the total number of all ROIs in a chest image was greater than a specified threshold level, the image was classified as abnormal. In addition, the third ANN was applied to distinguish between normal and abnormal chest images. The combination of the rule-based method and the third ANN also was applied to the classification between normal and abnormal chest images. The performance of the ANNs was evaluated by means of receiver operating characteristic (ROC) analysis. The average Az value (area under the ROC curve) for distinguishing between normal and abnormal cases was 0.976±0.012 for 100 chest radiographs that were not used in training of ANNs. The results indicate that the ANN trained with image data can learn some statistical properties associated with interstitial infiltrates in chest radiographs.	artificial neural network;chest tightness;classification;computer-aided design;diagnostic techniques, neurological;infiltration;interstitial disease;interstitial webpage;logic programming;lung diseases, interstitial;lung diseases;parameter (computer programming);pneumonia, interstitial;radiography;receiver operating characteristic;receiver operator characteristics;region of interest;total number	Takayuki Ishida;Shigehiko Katsuragawa;Kazuto Ashizawa;Heber MacMahon;Kunio Doi	1998	Journal of Digital Imaging	10.1007/BF03178081	radiology;medicine;pathology;computer science;artificial intelligence;receiver operating characteristic;artificial neural network	ML	34.87226690780368	-77.60778487923046	142174
77c4971b14f3ae294945010d5d718c3ca46f5a1d	chronic wound tissue characterization under telemedicine framework	telemedicine chronic wound bayesian classifier k means fuzzy c means;bayesian classifier;telemedicine;k means;wounds bayes methods biological tissues biomedical optical imaging data acquisition image classification image colour analysis medical image processing telemedicine tissue engineering;fuzzy c means;chronic wound;chronic wound tissue characterization bayesian classifier based wound characterization regular time intervals color variation wound screening telewound technology network wounds data acquisition comprehensive cw diagnostic approach remote rural areas healing process chronic wound diagnosis telemedicine framework;wounds image segmentation image color analysis bayes methods telemedicine clinical diagnosis	Chronic wound (CW) diagnosis is more demanding to monitor the healing process of the wound. However, the availability of specialist medical help in remote/rural areas in developing countries, like India, is a challenge. Further, visiting specially hospitals in city is both expensive and time consuming. This paper discusses the comprehensive CW diagnostic approach using three important modules, namely, wounds data acquisition (WDA), tele-wound technology network (TWTN), and wound screening and diagnostic (WSD) respectively. We have proposed a CW characterization and diagnosis under telemedicine framework to classify the tissue depending on percentage of wound and based on color variation at regular time intervals. The Bayesian classifier based wound characterization (BWC) method is proposed to identify the percentage of tissue with high accuracy. It has been observed that the BWC method provides overall accuracy of 87.11%.	algorithm;bayesian network;chronic electrode implant;data acquisition;decibel;fuzzy cognitive map;k-means clustering;naive bayes classifier;smartphone;television;web services for devices	Chinmay Chakraborty;Bharat Gupta;Soumya K. Ghosh	2015	2015 17th International Conference on E-health Networking, Application & Services (HealthCom)	10.1109/HealthCom.2015.7454566	medicine;pathology;biological engineering;surgery	Robotics	34.52308886287047	-78.93027426436697	142216
2fa602cc54bbc6fe6d77d8c1aca4e6cc5ca6740f	automatic detection of microaneurysms in retinal fundus images	microaneurysms mas;eye fundus images;classifier;profile features;local features;diabetic retinopathy dr	Diabetic retinopathy (DR) is one of the leading causes of new cases of blindness. Early and accurate detection of microaneurysms (MAs) is important for diagnosis and grading of diabetic retinopathy. In this paper, a new method for the automatic detection of MAs in eye fundus images is proposed. The proposed method consists of four main steps: preprocessing, candidate extraction, feature extraction and classification. A total of 27 characteristic features which contain local features and profile features are extracted for KNN classifier to distinguish true MAs from spurious candidates. The proposed method has been evaluated on two public database: ROC and e-optha. The experimental result demonstrates the efficiency and effectiveness of the proposed method, and it has the potential to be used to diagnose DR clinically.	database;diabetic retinopathy;feature extraction;histopathologic grade;k-nearest neighbors algorithm;microaneurysm;naive bayes classifier;preprocessor;retina;retinal diseases;statistical classification;structure of fundus of eye	Bo Wu;Weifang Zhu;Fei Shi;Shuxia Zhu;Xinjian Chen	2017	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2016.08.001	computer vision;medicine;classifier;optics;diabetes mellitus	Vision	35.39490219014046	-75.68756992875647	142257
50480b557d3ff358ccdb26a83d80fcb6dadd3693	automatic segmentation of mammographic masses using fuzzy shadow and maximum-likelihood analysis	image segmentation;maximum likelihood;probability density function;automatic segmentation;fuzzy logic mammography medical image processing image segmentation tumours maximum likelihood estimation;tumours;maximum likelihood estimation;fuzzy logic;medical image processing;region of interest;computer analysis;mammography;cancer image databases radiology breast neoplasms testing image segmentation intersymbol interference lesions benign tumors pixel;region growing;likelihood function;extended margin mammographic masses fuzzy shadow automatic segmentation pixel aggregation medical diagnostic imaging algorithm tumor body region growing techniques accurate tumor segmentation breast lesions analysis segmented region gaussian envelope	This study attempted to accurately segment tumors in mammograms. Although this task is considered to be a preprocessing step in a computer analysis program, it plays an important role for further analysis of breast lesions. The region of interest (ROI) was segmented using the pixel aggregation and region growing techniques combined with maximum likelihood analysis. A fast segmentation algorithm has been developed to facilitate the segmentation process. The algorithm repetitively sweeps the ROI horizontally and vertically to aggregate the pixels that have intensities higher than a threshold. The ROI is then fuzzified by the Gaussian envelope. With each segmented region for a given threshold step in the original ROI, the likelihood function is computed and is comprised of probability density functions inside and outside of the fuzzified ROI. We have implemented this method to test on 90 mammograms. We found the segmented region with the maximum likelihood corresponds to the body of tumor. However, the segmented region with the maximum change of likelihood corresponds to the tumor and it extended margin.	aggregate data;algorithm;fast fourier transform;pixel;preprocessor;region growing;region of interest	Lisa Kinnard;Shih-Chung Ben Lo;Paul C. Wang;Matthew T. Freedman;Mohamed F. Chouikha	2002		10.1109/ISBI.2002.1029238	computer vision;computer science;machine learning;pattern recognition;mathematics;maximum likelihood;statistics	ML	38.0344025608644	-75.25729769066074	142274
ccc9dabd7a660f2a4a1ca9bd386e82ad61128437	image quality transfer and applications in diffusion mri		"""This paper introduces a new computational imaging technique called image quality transfer (IQT). IQT uses machine learning to transfer the rich information available from one-off experimental medical imaging devices to the abundant but lower-quality data from routine acquisitions. The procedure uses matched pairs to learn mappings from low-quality to corresponding high-quality images. Once learned, these mappings then augment unseen low quality images, for example by enhancing image resolution or information content. Here, we demonstrate IQT using a simple patch-regression implementation and the uniquely rich diffusion MRI data set from the human connectome project (HCP). Results highlight potential benefits of IQT in both brain connectivity mapping and microstructure imaging. In brain connectivity mapping, IQT reveals, from standard data sets, thin connection pathways that tractography normally requires specialised data to reconstruct. In microstructure imaging, IQT shows potential in estimating, from standard """"single-shell"""" data (one non-zero b-value), maps of microstructural parameters that normally require specialised multi-shell data. Further experiments show strong generalisability, highlighting IQT's benefits even when the training set does not directly represent the application domain. The concept extends naturally to many other imaging modalities and reconstruction problems."""	application domain;arabic numeral 0;body dysmorphic disorders;estimated;experiment;human connectome project;image quality;image resolution;imaging techniques;machine learning;map;medical imaging;numerous;self-information;test set;benefit	Daniel C. Alexander;Darko Zikic;Aurobrata Ghosh;Ryutaro Tanno;Viktor Wottschel;Jiaying Zhang;Enrico Kaden;Tim B. Dyrby;Stamatios N. Sotiropoulos;Hui Zhang;Antonio Criminisi	2017	NeuroImage	10.1016/j.neuroimage.2017.02.089	computer vision;computer science;machine learning;data mining	Vision	29.57097802459106	-75.68277446933531	142629
cf0f958cd2fe5c33fbd251309223c003da668acb	using hybrid neural networks for identifying the brain abnormalities from mri structural images	deep machine learning;mri;extreme machine learning;pca	In this study, we present the investigations being pursued in our research laboratory on magnetic resonance images (MRI) of various states of brain by extracting the most significant features, and to classify them into normal and abnormal brain images. We propose a novel method based on deep and extreme machine learning on wavelet transform to initially decompose the images, and then use various features selection and search algorithms to extract the most significant features of brain from the MRI images. By using a comparative study with different classifiers to detect the abnormality of brain images from publicly available neuro-imaging dataset, we found that a principled approach involving wavelet based feature extraction, followed by selection of most significant features using PCA technique, and the classification using deep and extreme machine learning based classifiers results in a significant improvement in accuracy and faster training and testing time as compared to previously reported studies.	artificial neural network	Lavneet Singh;Girija Chetty;Dharmendra Sharma	2012		10.1007/978-3-642-34500-5_55	computer science;magnetic resonance imaging;machine learning;pattern recognition;data mining;principal component analysis	ML	30.76540766278262	-77.46389900128482	142700
d946043092710147fbde1dace828e1bb47f4d3d9	automatic classification for solitary pulmonary nodule in ct image by fractal analysis based on fractional brownian motion model	solitary pulmonary nodule;ct image;classification;fractal dimension;fractional brownian motion	Perfusion computed tomography (CT) method has been used to differentiate malignant pulmonary nodules from benign nodules based on the assessment for the change of the CT attenuation value within the pulmonary nodules. Instead of using the change of the CT attenuation value, a set of fractal features based on fractional Brownian motion model is proposed in this paper to automatically distinguish malignant nodules from benign nodules. In a set of 107 CT images from 107 different patients with each image containing a solitary pulmonary nodule, our experimental results obtained from a support vector machine classifier show that the accuracy, sensitivity, specificity, positive predictive value, negative predictive value, and the area under the ROC curve are 83.11%, 90.92%, 71.70%, 80.05%, 87.52%, and 0.8437, respectively, by using the proposed fractal-based feature set. Such a result outperforms the conventional method of using the change of the CT attenuation value as the feature for classification. When combining this conventional method with our proposed fractal-based method, the accuracy, sensitivity, specificity, positive predictive value, negative predictive value, and the area under the ROC curve can be promoted to 88.82%, 93.92%, 82.90%, 87.30%, 90.20%, and 0.9019, respectively. In other words, a high performance of pulmonary nodule classification can be achieved with a single post-contrast CT scan. & 2013 Elsevier Ltd. All rights reserved.	brownian motion;ct scan;fractal analysis;norm (social);receiver operating characteristic;sensitivity and specificity;substitution-permutation network;support vector machine;test engineer;tomography	Phen-Lan Lin;Po-Whei Huang;Cheng-Hsiung Lee;Ming-Ting Wu	2013	Pattern Recognition	10.1016/j.patcog.2013.06.017	computer vision;biological classification;mathematics;fractional brownian motion;fractal dimension;statistics	AI	34.7854611847275	-75.8146894866129	143325
24413f2611ad6a2cb662127ad7bb73bc21f6c6e6	a region segmentation method for colonoscopy images using a model of polyp appearance	region segmentation;polyp detection;colonoscopy;region merging	This work aims at the segmentation of colonoscopy images into a minimum number of informative regions. Our method performs in a way such, if a polyp is present in the image, it will be exclusively and totally contained in a single region. This result can be used in later stages to classify regions as polyp-containing candidates. The output of the algorithm also defines which regions can be considered as noninformative. The algorithm starts with a high number of initial regions and merges them taking into account the model of polyp appearance obtained from available data. The results show that our segmentations of polyp regions are more accurate than state-of-the-art methods.		Jorge Bernal;F. Javier Sánchez;Fernando Vilariño	2011		10.1007/978-3-642-21257-4_17	computer vision	Vision	38.71006452618294	-71.24622479853775	143338
26b6b834f57f2b2986721520b16a5edcca88740c	tensor-based multi-view feature selection with applications to brain diseases	biological patents;biomedical journals;multi view learning;tensile stress;support vector machines;text mining;europe pubmed central;neurological disorder tensor based multi view feature selection brain diseases big data feature subsets multiview learning medical science medical examinations clinical measures imaging measures immunologic measures serologic measures cognitive measures brain diagnosis disease diagnosis tensor based multiview feature selection dual tmfs support vector machine recursive feature elimination;support vector machines big data brain diseases feature selection learning artificial intelligence medical administrative data processing medical computing neurophysiology patient diagnosis;citation search;tensile stress support vector machines vectors diseases medical diagnostic imaging correlation;会议论文;citation networks;tensor;vectors;research articles;abstracts;open access;life sciences;clinical guidelines;diseases;feature selection;correlation;full text;brain diseases;feature selection tensor brain diseases multi view learning;rest apis;orcids;europe pmc;biomedical research;medical diagnostic imaging;bioinformatics;literature search	In the era of big data, we can easily access information from multiple views which may be obtained from different sources or feature subsets. Generally, different views provide complementary information for learning tasks. Thus, multi-view learning can facilitate the learning process and is prevalent in a wide range of application domains. For example, in medical science, measurements from a series of medical examinations are documented for each subject, including clinical, imaging, immunologic, serologic and cognitive measures which are obtained from multiple sources. Specifically, for brain diagnosis, we can have different quantitative analysis which can be seen as different feature subsets of a subject. It is desirable to combine all these features in an effective way for disease diagnosis. However, some measurements from less relevant medical examinations can introduce irrelevant information which can even be exaggerated after view combinations. Feature selection should therefore be incorporated in the process of multi-view learning. In this paper, we explore tensor product to bring different views together in a joint space, and present a dual method of tensor-based multi-view feature selection DUAL-TMFS based on the idea of support vector machine recursive feature elimination. Experiments conducted on datasets derived from neurological disorder demonstrate the features selected by our proposed method yield better classification performance and are relevant to disease diagnosis.	application domain;big data;biological markers;brain diseases;cognition;dual;excretory function;fear, uncertainty and doubt;feature selection;genetic selection;ibm notes;joint space;medical examination;medicine;numerous;recursion;relevance;support vector machine;united states national institutes of health;vii;funding grant;nervous system disorder	Bokai Cao;Lifang He;Xiangnan Kong;Philip S. Yu;Zhifeng Hao;Ann B. Ragin	2014	2014 IEEE International Conference on Data Mining	10.1109/ICDM.2014.26	support vector machine;text mining;tensor;computer science;data science;machine learning;data mining;stress;feature selection;correlation;feature	Vision	26.001539966301845	-77.62745340779003	143423
2854592165adf1b48cf19656dd60c67b62b8f75c	word detecting in document image based on two-stage model		This paper proposes a word detecting method for document image using character models and word models to evaluate the features of single-character and between-character. First, the text line is segmented into several fragments. Second, the candidate character, which is generated by merging some consecutive fragments, will be identified to be the right one if it conforms to the query word character models. Third, the path search strategy is used to search the candidate words constructed with candidate characters. The word model is used to identify the matching cost. Our experimental results on a dataset of document images demonstrate the effectiveness of the proposed method.		Xiujuan Li;Zhimin Huang;Ying Wen;Yue Lu	2012		10.1007/978-3-642-34595-1_25	pattern recognition	Vision	36.21091106959794	-66.21130226378611	143710
0edf88ea866bcafc40c27714f3587a56e4d15967	recurrent nasal papilloma detection using a fuzzy algorithm learning vector quantization neural network	patient diagnosis;fuzzy neural nets;clinical diagnosis recurrent nasal papilloma detection fuzzy algorithm learning vector quantization neural network gadolinium enhanced dynamic magnetic resonance image mri;recurrent nasal papilloma detection;clinical diagnosis;vector quantisation biomedical mri fuzzy neural nets learning artificial intelligence patient diagnosis;magnetic resonance image;mr imaging;gadolinium enhanced dynamic magnetic resonance image;mri;fuzzy neural networks vector quantization neural networks recurrent neural networks neoplasms magnetic resonance magnetic resonance imaging magnetic materials mathematical model lesions;learning artificial intelligence;vector quantisation;region growing;fuzzy algorithm learning vector quantization neural network;learning vector quantization;biomedical mri;neural network	The objective of this paper is to develop a complete solution for recurrent nasal papilloma (RNP) detection. Recently, the gadolinium-enhanced dynamic magnetic resonance image (MRI) has been developed and widely used in clinical diagnosis of recurrent nasal papilloma. Owing to the response of RNP regions in gadolinium-enhanced magnetic resonance images is different from the response of normal tissues, the difference between the dynamic-MR images before and after administering contrast material can be used to extract the coarse RNP regions automatically. Then, a fuzzy algorithm for learning vector quantization (FALVQ) neural network is used to pick the suspicious RNP regions. Finally, a feature-based region growing method is applied to recover the complete RNP regions. The experimental results show that the proposed method can detect RNP regions automatically, correctly and fast.	algorithm;artificial neural network;learning vector quantization;recurrent neural network;region growing;resonance	Chuan-Yu Chang;Da-Feng Zhuang	2006	2006 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2006.384443	computer vision;learning vector quantization;computer science;artificial intelligence;magnetic resonance imaging;machine learning;mathematics;region growing	Robotics	37.3982402421941	-75.46396015376965	144104
d38eeb88a928c1a1c6e1fdd18d504669b112ed8b	local binary patterns applied to breast cancer classification in mammographies		Among all cancer types, breast cancer is the one with the second highest incidence rate for women. Mammography is the most used method for breast cancer detection, as it reveals abnormalities such as masses, calcifications, asymmetries and architectural distortions. In this paper, we propose a classification method for breast cancer that has been tested for six different cancer types: CALC, CIRC, SPIC, MISC, ARCH, ASYM. The proposed approach is composed of a SVM classifier trained with LBP features. The MIAS image database was used in the experiments and ROC curves were generated. To the best of our knowledge, our approach is the first to handle those six different cancer types using the same technique. One important result of the proposed approach is that it was tested over six different breast cancer types proving to be generic enough to obtain high classification results in all cases.	distortion;experiment;incidence matrix;libreoffice calc;local binary patterns;receiver operating characteristic;support vector machine	Eanes Torres Pereira;Sidney Pimentel Eleutério;João Marques de Carvalho	2014	RITA		cancer;local binary patterns;artificial intelligence;computer vision;spic;breast cancer;computer science;breast cancer classification;receiver operating characteristic;support vector machine;mammography;pattern recognition	Comp.	34.018245581117235	-75.28136250127041	144343
0c49f0fa9f670db295644e44aa52e20702ebf7eb	survival analysis of pre-operative gbm patients by using quantitative image features	survival analysis glioblastoma imaging;glioblastoma;tumors imaging cancer image segmentation hazards satellites educational institutions;medical image processing;prognostic value survival analysis preoperative gbm patients quantitative image features progression free survival multiple imaging features glioblastoma;imaging;survival analysis	This paper concerns a preliminary study of the relationship between survival time of both overall and progression free survival, and multiple imaging features of patients with glioblastoma. Simulation results showed that specific imaging features were found to have significant prognostic value to predict survival time in glioblastoma patients.	color gradient;mesa;simulation	Pattana Wangaryattawanich;Jixin Wang;Ginu A. Thomas;Ahmad Chaddad;Pascal O. Zinn;Rivka R. Colen	2014	2014 International Conference on Control, Decision and Information Technologies (CoDIT)	10.1109/CoDIT.2014.6996968	pathology;geography;nuclear medicine;medical physics	Robotics	36.180473941629096	-80.09721800160689	144500
b05e61a953c1e35c9ae55b52474eec6ac37637a7	prostate boundary detection in ultrasound images using biologically-inspired spiking neural network	fuzzy c mean;image processing;median filter;ultrasound;prostate segmentation;ultrasound imaging;spiking neural network;bio inspiring;machine learning;ultrasound images;boundary detection;visual cortex;pulse coupled neural network;neural network;pulse coupled neural networks	Pulse-coupled neural networks (PCNNs) are a biologically inspired type of neural networks. It is a simplified model of the cat’s visual cortex with local connections to other neurons. PCNN has the ability to extract edges, segments and texture information from images. Only a few changes to the PCNN parameters are necessary for effective operation on different types of data. This is an advantage over published image processing algorithms that generally require information about the target before they are effective. The main aim of this paper is to provide an accurate boundary detection algorithm of the prostate ultrasound images to assist radiologists in making their decisions. To increase the contrast of the ultrasound	algorithm;artificial neural network;image processing;medical ultrasound;pulse-coupled networks;radiology;spiking neural network	Aboul Ella Hassanien;Hameed Al-Qaheri;El-Sayed A. El-Dahshan	2011	Appl. Soft Comput.	10.1016/j.asoc.2010.07.001	median filter;computer vision;image processing;computer science;artificial intelligence;machine learning;ultrasound;artificial neural network;spiking neural network	ML	34.38222519418527	-76.44421903460024	144512
955d12439a8cd300a614be45cb6ed6bb1bf13212	digital bowel cleansing free detection method of colonic polyp from fecal tagging ct images	computerized axial tomography;tomodensitometria;ct colonography;deteccion;standard deviation;colon;polyp;image;methode;detection;polipo;tomodensitometrie;polype;matrices;imagen;marcacion;marquage;virtual colonoscopy;tecnica;abdomen;diagnostics;false positive;metodo;method;technique;tagging;diagnostic method	ABSTRACT This paper presents a digital bowel cleansing (DBC) free detection method of colonic polyp from fecal taggingCT images. Virtual colonoscopy (VC) or CT colonography is a new colon diagnostic method to examine theinside of the colon. However, since the colon has many haustra and its shape is long and convoluted, there isa risk of overlooking of lesions existing in blinded areas caused by haustra. Automated polyp detection fromcolonic CT images will reduce the risk of overlooking. Although many methods for polyp detection have beenproposed, these methods needed DBC to detect polyps surrounded by tagged fecal material (TFM). However,DBC may changes shapes of polyps or haustra while removing TFM and it adversely aect polyp detection. Wepropose a colonic polyp detection method that enables us to detect polyps surrounded by either the air or theTFM simultaneously without any DBC processes. CT values inside polyps surrounded by the air and polypssurrounded by the TFM regions tend to gradually increase (blob structure) and decrease (inverse-blob structure)from outward to inward, respectively. We thus employ blob and inverse-blob structure enhancement lters basedon the eigenvalues of the Hessian matrix to detect polyps using intensity characteristic of polyps. False positiveelimination is performed using three feature values: the volume, maximum value of the lter outputs, and thestandard deviation of CT values inside polyp candidate regions. We applied the proposed method to 104 casesof abdominal CT images. Sensitivity for polyps 6 mm was 91.2% with 7.8 FPs/case.Keywords: Colonic polyp, virtual colonoscopy, abdominal CT image, Hessian matrix	ct scan	Masahiro Oda;Takayuki Kitasaka;Kensaku Mori;Yasuhito Suenaga;Tetsuji Takayama;Hirotsugu Takabatake;Masaki Mori;Hiroshi Natori;Shigeru Nawano	2008		10.1117/12.771580	method;type i and type ii errors;image;standard deviation;matrix	Vision	37.815070350626165	-77.79060576783533	144517
27719721c4136cb49f38b165b7c46c53c329d448	context-based interpolation of coarse deep learning prediction maps for the segmentation of fine structures in immunofluorescence images		The automatic analysis of digital pathology images is becoming of increasing interest for the development of novel therapeutic drugs and of the associated companion diagnostic tests in oncology. A precise quantification of the tumor microenvironment and therefore an accurate segmentation of the tumor extent are critical in this context. In this paper, we present a new approach based on visual context random forest to generate precise segmentation maps from deep learning coarse segmentation maps. Applied to the detection of cytokeratin positive (CK) epithelium regions in immunofluorescence (IF) images, we show that this method enables an accurate and fast detection of detailled structures in terms of qualitative and quantitative evaluation against three baseline approaches. For the method to be resilient to the high variability of staining intensity, a novel normalization algorithm for IF images is moreover introduced.	algorithm;baseline (configuration management);deep learning;habitat;image resolution;linear interpolation;map;nonlinear system;random forest;spatial variability;ternary numeral system	Nicolas Brieu;Christos G. Gavriel;David J. Harrison;Peter David Caie;Günter Schmidt	2018		10.1117/12.2292794	interpolation;immunofluorescence;companion diagnostic;normalization (statistics);deep learning;random forest;artificial intelligence;digital pathology;computer science;segmentation;pattern recognition	Vision	31.20136212978843	-76.81967594875844	144666
7caaaee7c06174c13530fc8058dd7939f216bdb9	shape and texture based classification of fish species	texture features;image registration	In this paper we conduct a case study of fish species classification based on shape and texture. We consider three fish species: cod, haddock, and whiting. We derive shape and texture features from an appearance model of a set of training data. The fish in the training images were manual outlined, and a few features including the eye and backbone contour were also annotated. From these annotations an optimal MDL curve correspondence and a subsequent image registration were derived. We have analyzed a series of shape and texture and combined shape and texture modes of variation for their ability to discriminate between the fish types, as well as conducted a preliminary classification. In a linear discrimant analysis based on the two best combined modes of variation we obtain a resubstitution rate of 76 %.		Rasmus Larsen;Hildur Ólafsdóttir;Bjarne K. Ersbøll	2009		10.1007/978-3-642-02230-2_76	image texture;computer vision;computer science;image registration;pattern recognition	Vision	35.6759848946442	-69.63523746310484	144725
b416fcac95b711681e2243657af79ea7058b9b44	a genetic learning system for on-line character recognition	handwriting recognition;writer dependent learning genetic learning system online character recognition learning system string matching image classification genetic algorithm;prototypes;image classification;data mining;genetics;learning systems;learning system;engines;learning systems character recognition prototypes genetic algorithms information analysis writing humans engines data mining handwriting recognition;writing;genetic algorithm;genetic algorithms;humans;writer dependent learning;genetic learning system;string matching;online character recognition;information analysis;character recognition	In this paper we present the result of an investigation on a new method to perform online character recognition. The method is based on a genetic algorithm used as the engine of a learning system to produce prototypes of the characters, and on a string matcher to perform the classification. The learning mechanism, provided by a genetic algorithm, allows the system to have both a writer independent core and an adaptation scheme to finely tune the recognizer to the writer's style. Preliminary experiments have shown that the method is very promising, since it produces prototypes general enough to cope with the large variability encountered when handling specimen produced by different writers. Moreover, it provides a natural and effective writer-dependent learning of new symbols.	online and offline;optical character recognition	Bruno Bontempi;Angelo Marcelli	1994		10.1109/ICPR.1994.576880	speech recognition;genetic algorithm;computer science;machine learning;pattern recognition;handwriting recognition	AI	31.775976965952438	-66.23179488866488	144929
5b2d11dee01c63068af56df6cab938214fc093c5	automatic measurement of cup to disc ratio for diagnosis of glaucoma on retinal fundus images	glaucoma detection automatic measurement cup disc ratio glaucoma diagnosis retinal fundus image disease glaucoma symptoms blindness ophthalmology;retinal fundus image glaucoma optic disc detection optic cup detection cup to disc ratio;vision defects diseases eye medical image processing;eye;vision defects;medical image processing;diseases;optical imaging retina biomedical optical imaging optical filters adaptive optics integrated optics optical signal processing	Glaucoma is the second leading cause of blindness in the world. It is estimated that 66.8 million people in the world have glaucoma, with 6.7 million bilaterally blind from this disease. One of the glaucoma symptoms is that the cup enlarges until it occupies most of the disc area. This results in blindness. The cup-to-disc ratio is a measurement used in ophthalmology to detect glaucoma and assess its progression. This paper presents an approach to automatic calculation of cup to disc ratio using accurate detection of disc and cup, and quantitative determination of their areas in retinal fundus images to diagnose glaucoma. This method is computationally efficient. Experimental results indicate sufficient validity of the quantitative analysis to diagnose glaucoma.	algorithm;algorithmic efficiency;color gradient;virtual retinal display	Azin Poshtyar;Jamshid Shanbehzadeh;Hamid Ahmadieh	2013	2013 6th International Conference on Biomedical Engineering and Informatics	10.1109/BMEI.2013.6746900	ophthalmology;optometry;optics	Robotics	38.29791614044474	-76.4765418381419	145095
7f73e1d1e5e6d53ddbe343de19a4d90eb4804281	cardiac cycle phase estimation in 2-d echocardiographic images using an artificial neural network	image segmentation;neural nets;image classification;volume measurement echocardiography feature extraction image classification image segmentation medical image processing neural nets random noise;image features artificial intelligence cardiac cycle computer aided diagnosis;random noise;feature extraction;medical image processing;algorithms databases factual echocardiography humans image interpretation computer assisted image processing computer assisted myocardial contraction myocardial infarction neural networks computer;echocardiography;volume measurement;valves noise image edge detection noise reduction artificial neural networks image segmentation heart;cadi software cardiac cycle phase estimation 2d echocardiographic images cardiac volume estimation atrial systole event atrial diastole event mitral valve geometrical position image features image processing methods artificial neural networks ann classifier anatomical information extraction denoising scenario gaussian noise rayleigh noise distribution hybrid algorithm segmentation process computer aided diagnosis software	This paper proposes a new hybrid approach to estimate the cardiac cycle phases in 2-D echocardiographic images as a first step in cardiac volume estimation. We focused on analyzing the atrial systole and diastole events by using the geometrical position of the mitral valve and a set of three image features. The proposed algorithm is based on a tandem of image processing methods and artificial neural networks as a classifier to robustly extract anatomical information. An original set of image features is proposed and derived to recognize the cardiac phases. The aforementioned approach is performed in two denoising scenarios. In the first scenario, the images are corrupted with Gaussian noise, and in the second one with Rayleigh noise distribution. Our hybrid algorithm does not involve any manual tracing of the boundaries for segmentation process. The algorithm is implemented as computer-aided diagnosis (CADi) software. A dataset of 150 images that include both normal and infarct cardiac pathologies was used. We reported an accuracy of 90 % and a 2 ± 0.3 s in terms of execution time of CADi application in a cardiac cycle estimation task. The main contribution of this paper is to propose this hybrid method and a set of image features that can be helpful for automatic detection applications without any user intervention. The results of the employed methods are qualitatively and quantitatively compared in terms of efficiency for both scenarios.	algorithmic efficiency;artificial neural network;binary image;cell hybridization;computer assisted diagnosis;diastole;feature (computer vision);heart atrium;heart diseases;hybrid algorithm;image processing;infarction;logical volume management;mitral valve;multiplicative noise;noise reduction;normal statistical distribution;pathology;patients;quantum phase estimation algorithm;rayleigh–ritz method;real-time clock;region of interest;run time (program lifecycle phase);silo (dataset);statistical classification;utility functions on indivisible goods;atrial systole;benefit;biologic segmentation	Dorin Bibicu;Lumini&#x0163;a Moraru	2013	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2012.2231864	computer vision;contextual image classification;feature detection;feature extraction;computer science;artificial intelligence;machine learning;image segmentation;artificial neural network	Vision	37.665004821619064	-77.04142203260812	145323
1e7d1fca22e681dac8939db02750437f29b73e00	neural network positioning and classification of handwritten characters	extraction information;posicionamiento;neural networks;information extraction;segmentation;classification;positioning;reconnaissance caractere;feature extraction;united kingdom;success rate;pattern recognition;reconnaissance forme;reseau neuronal;reconocimiento patron;gabor wavelets;character recognition;clasificacion;red neuronal;segmentacion;sliding window;reconocimiento caracter;neural network;positionnement;extraction informacion;subspace projection	This paper describes two algorithms at the core of the new Kodak Imagelink™ OCR numeric and alphanumeric handprint modules. Both variants of the system were designed to work with fields of characters, typically scanned from forms. The first neural network is trained to find individual characters in the field. Its outputs are associated with an array of pixels in the middle of a sliding window, and they signal the presence of characters centered at corresponding positions. A window containing each detected character (and, possibly, pieces of adjacent characters) is passed on to the second network, which performs the classification. The outputs of both networks are interpreted by an application specific postprocessing module that generates the final label string. Both networks were trained on Gabor projections of the original pixel images, which resulted in higher recognition rates and greater noise immunity. The system has been implemented in specialized parallel hardware, and has been installed and used in production mode at the Driver and Vehicle Licensing Agency (DVLA) in the United Kingdom. The success rate of the purely numeric handprint module (as measured on randomly selected batches of over 200 real forms containing 3500 characters) exceeds 98.5% (character level without rejects), which translates into 93% field rate. After approximately 7% of the characters are rejected, the system achieves a 99.5% character level success rate acceptable for this application. The similarly measured overall success rate of the alphanumeric handprint module exceeds 96% (character level without rejects), which translates into 85% field rate. If approximately 20% of the fields are rejected, the system achieves 99.8% character and 99.5% field success rate.	artificial neural network	Alexander Shustorovich;Christopher W. Thrasher	1996	Neural Networks	10.1016/0893-6080(95)00143-3	sliding window protocol;speech recognition;feature extraction;biological classification;computer science;artificial intelligence;machine learning;segmentation;artificial neural network;statistics	ML	34.01873287871707	-67.31315410995059	145437
87b8122f31301ba05bcb56eda0ac747f816ec003	discrimination of malignant lymphomas and leukemia using radon transform based-higher order spectra	image processing;radon transform;morphological watershed segmentation;euclidean distance;leukemia;feature vector;malignant lymphoma;higher order spectra;principal component analysis pca;background subtraction;minimum distance euclidean classifier;higher order spectra hos;lymphoma	ABSTRACT A new algorithm that can be used to automatically recognize and classify malignant lymphomas and leukemia is proposed in this paper. The algorithm utilizes the morphological watersheds to obtain boundaries of cells from cell images and isolate them from the surrounding background. The areas of cells are extracted from cell images after background subtraction. The Radon transform and higher-order spectra (HOS) analysis are utilized as an image processing tool to generate class feature vectors of different type cells and to extract testing cells feature vectors. The testing cells feature vectors are then compared with the known class feature vectors for a possible match by computing the Euclidean distances. The cell in question is classified as belonging to one of the existing cell classes in the least Euclidean distance sense. Keywords: malignant lymphoma, morphological watershed segmentation, radon transform, higher-order spectra (HOS), principal component analysis (PCA), minimum-distance Euclidean classifier		Yi Luo;Mehmet Celenk;Prashanth Bejai	2006		10.1117/12.654288	arithmetic;computer vision;speech recognition;mathematics	Vision	37.45332204855578	-72.30539567717351	145447
f2bdcfe4a9dd27fe54a1e0062770687b617b6ec1	an ensemble rule learning approach for automated morphological classification of erythrocytes	anaemia;ensemble learning;erythrocytes classification;rule mining;segmentation	The analysis of pathophysiological change to erythrocytes is important for early diagnosis of anaemia. The manual assessment of pathology slides is time-consuming and complicated regarding various types of cell identification. This paper proposes an ensemble rule-based decision-making approach for morphological classification of erythrocytes. Firstly, the digital microscopic blood smear images are pre-processed for removal of spurious regions followed by colour normalisation and thresholding. The erythrocytes are segmented from background image using the watershed algorithm. The shape features are then extracted from the segmented image to detect shape abnormality present in microscopic blood smear images. The decision about the abnormality is taken using proposed multiple rule-based expert systems. The deciding factor is majority ensemble voting for abnormally shaped erythrocytes. Here, shape-based features are considered for nine different types of abnormal erythrocytes including normal erythrocytes. Further, the adaptive boosting algorithm is used to generate multiple decision tree models where each model tree generates an individual rule set. The supervised classification method is followed to generate rules using a C4.5 decision tree. The proposed ensemble approach is precise in detecting eight types of abnormal erythrocytes with an overall accuracy of 97.81% and weighted sensitivity of 97.33%, weighted specificity of 99.7%, and weighted precision of 98%. This approach shows the robustness of proposed strategy for erythrocytes classification into abnormal and normal class. The article also clarifies its latent quality to be incorporated in point of care technology solution targeting a rapid clinical assistance.	abnormal red blood cell;anemia;blood smear;c4.5 algorithm;decision making;decision tree;early diagnosis;expert systems;expert system;extraction;galaxy morphological classification;logic programming;machine learning;polycythemia;rule (guideline);sensitivity and specificity;sensor;shape context;slide (glass microscope);smear - instruction imperative;smear campaign;supervised learning;thresholding (image processing);watershed (image processing);cellular targeting	Maitreya Maity;Tushar Mungle;Dhiraj Manohar Dhane;Asok Kumar Maiti;Chandan Chakraborty	2017	Journal of Medical Systems	10.1007/s10916-017-0691-x	machine learning;pattern recognition;data mining;mathematics	AI	36.01781995297307	-76.13928821795965	145622
f17ab57b4e975cf6de53bfcf7548fff0772dfad4	a system for recognizing numeric strings from topographical maps	image recognition;numeric string recognition;topography earth;automatic recognition stage;image recognition educational institutions computer science roads character recognition computer displays image resolution;uncertain numeric string extraction;topographic map;numerals;image recognition cartography document image processing topography earth;map image;document image processing;cartography;interactive recognition stage;numerals numeric string recognition topographical maps automatic recognition stage interactive recognition stage uncertain numeric string extraction map image;topographical maps;article	This paper proposes a system for recognizing numeric strings from topographical maps, which is composed of the automatic recognition stage and the interactive recognition stage. In this method, uncertain numeric strings extracted through the automatic recognition stage based on topographical map feature only, are confirmed and corrected by the interactive recognition stage. Therefore we can obtain high precise recognition results. The method was applied to numeric string recognition from map image which include 102 strings made up of 249 numerals. As a result, 95.1% of 102 numeric strings were correctly recognized.	map;topography	Masanori Anegawa;Osamu Shiku;Akira Nakamura;T. Ohyamat;Hideo Kuroda	1995		10.1109/ICDAR.1995.602056	computer vision;topographic map;feature;computer science;artificial intelligence;machine learning	Vision	33.664212615351815	-68.43591996218852	145724
8dd29ca7f30dacd4cc601751e965abc891f6347c	breast tumor classification in ultrasound images using texture analysis and super-resolution methods	ultrasound;texture analysis;super resolution;breast cancer	Ultrasound images can be used to detect tumors that do not appear in the mammograms of dense breasts. Several computer-aided diagnosis (CAD) systems based on this type of images have been proposed to detect tumors and discriminate between benign and malignant ones. To characterize those lesions, many of the aforementioned systems rely on texture analysis methods. However, speckle noise and artifacts that appear in ultrasound images may degrade their performance. To tackle this problem, and contrary to the state-of-the-art methods that utilize a single image of the breast, this paper proposes the use of a super-resolution approach that exploits the complementary information provided by multiple images of the same target. The proposed CAD system consists of four stages: super-resolution computation, extraction of the region of interest, feature extraction and classification. We have evaluated the performance of five texture methods with the proposed CAD system: gray level co-occurrence matrix features, local binary patterns, phase congruency-based local binary pattern, histogram of oriented gradients and pattern lacunarity spectrum. We show that our super-resolutionbased approach improves the performance of the evaluated texture methods and thus outperforms the state of the art in benign/malignant tumor classification.	artifact (error);autostereogram;binary pattern (image generation);co-occurrence matrix;computation;computer-aided design;document-term matrix;feature extraction;gradient;grayscale;histogram of oriented gradients;lr parser;local binary patterns;medical imaging;phase congruency;preprocessor;region of interest;shape analysis (digital geometry);super-resolution imaging;xfig	Mohamed Abdel-Nasser;Jaime Melendez;Antonio Moreno;Osama Ahmed Omer;Domenec Puig	2017	Eng. Appl. of AI	10.1016/j.engappai.2016.12.019	computer vision;breast cancer;ultrasound;superresolution	AI	33.566195455721974	-75.05515966892817	145817
b47e3e8ba05e5b77af767e76053fae5787e5a422	development of a camera-based portable automatic inspection system for printed labels using neural networks	image segmentation;image processing;automatic optical inspection;chip;machine vision;mechanical system;pattern recognition;real time system;mechanical systems;neural network;real time systems	For the automatic inspection for printed labels, which are covered with rubber-like coatings and curl, we have developed a camera-based portable inspection system. In this paper, we explained the developed system, and especially discuss the inspection method of the spread and chip of the printed labels using neural networks. The experimental results confirm the validity of the proposed method for the spread and chip of alphanumerics.	neural networks	Yuhki Shiraishi;Fumiaki Takeda	2009		10.1007/978-3-642-02481-8_28	embedded system;computer vision;machine vision;image processing;automated x-ray inspection;computer science;artificial intelligence;mechanical system;artificial neural network;automated optical inspection	HCI	36.917686689098836	-68.35640024995732	145912
73a767c9e4459d3d56456c26057a6967e4e3c43a	indexing images by trees of visual content	image recognition;image databases;indexing images;information retrieval;image database;shallow trees;tree data structures;binary trees;search trees;unsupervised algorithm;digital communication;indexing;clustering;indexation;spatial databases;image retrieval unsupervised algorithm image database binary tree indexing images clustering shallow trees search trees;image recognition visual databases indexing tree data structures tree searching;humans;tree searching;content based retrieval;indexing image databases spatial databases binary trees humans visual databases information retrieval image retrieval content based retrieval digital communication;visual databases;binary tree;image retrieval	"""Haim Schweitzer (haim@utdallas.edu) The University of Texas at Dallas P.O Box 830688, Richardson, Texas 75083 Abstract An unsupervised algorithm for arranging an image database as a binary tree is described. Tree nodes are associated with image subsets, maintaining the property that the similarity among the images associated with the children of a node is higher than the similarity among the images associated with the parent node. Experiments with datasets of hundreds and thousands of images show that shallow trees can produce clustering into \meaningful"""" classes. Visual-content search trees can be used to automate image retrieval by content, or help a human to interactively search for images."""	algorithm;binary tree;cluster analysis;image retrieval;interactive media;richardson number;tree (data structure)	Haim Schweitzer	1998		10.1109/ICCV.1998.710776	binary tree;image retrieval;computer science;pattern recognition;data mining;ternary search tree;information retrieval	Vision	30.021256810756825	-66.71888430890725	146461
66c9559756ea5238add7018b78d52e9f61b853c2	detection of retinopathy of prematurity using multiple instance learning	image segmentation;biomedical imaging;medical image processing biomedical optical imaging eye feature extraction image classification learning artificial intelligence medical disorders;migraph retinopathy of prematurity computer aided diagnosis multiple instance learning;feature extraction retina cameras biomedical imaging image segmentation;retina;feature extraction;rop retinal images multiple instance learning retinopathy of prematurity retcam digital retinal camera rop characteristics migraph mil classifier diagnostic image feature sets;cameras	This paper proposes a new method for detecting Retinopathy of Prematurity (ROP) using multiple instance learning (MIL) approach from retinal images captured by RetCam, a digital retinal camera. In this work, a set of features having significant relevance to capture ROP characteristics, are extracted and miGraph MIL method is used as the classifier to learn from the extracted features. The diagnostic image is split into a grid of patches, and instances are constructed from each grid element by extracting a set of features from it. All the feature sets or group of instances belonging to the same image are grouped into a bag. Labels are assigned for instances and for the bags as a whole. Finally, the bags along with their labels are fed into a MIL classifier for classification. A good performance of miGraph on the ROP retinal images is observed and the initial experimental results are promising. In our literature survey, we observed that current research on detection of ROP using MIL has not been reported till now. Our results indicate that MIL offers an easy, yet effective, paradigm for ROP screening.	mil-std-1750a;multiple instance learning;patch (computing);programming paradigm;relevance;sensor	Priya Rani;Elagiri Ramalingam Rajkumar;Kumar T. Rajamani;Melih Kandemir;Digvijay Singh	2015	2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2015.7275949	medical imaging;computer vision;feature extraction;computer science;machine learning;pattern recognition;image segmentation	Robotics	35.25979908870783	-74.88245422847092	146490
5cd57501fb04435727344fb70b50aca8d4aed237	coupling convolutional neural networks and hough voting for robust segmentation of ultrasound volumes		This paper analyses the applicability and performance of Convolutional Neural Networks (CNN) to localise and segment anatomical structures in medical volumes under clinically realistic constraints: small amount of available training data, the need of a short processing time and limited computational resources. Our segmentation approach employs CNNs for simultaneous classification and feature extraction. A Hough voting strategy has been developed in order to automatically localise and segment the anatomy of interest. Our results show (i) improved robustness, due to the inclusion of prior shape knowledge, (ii) highly accurate segmentation even when only small datasets are available during training, (iii) speed and computational requirements that match those that are usually present in clinical settings.	convolutional neural network;hough transform	Christine Kroll;Fausto Milletari;Nassir Navab;Seyed-Ahmad Ahmadi	2016		10.1007/978-3-319-45886-1_36	computer vision;speech recognition;computer science;machine learning	Vision	31.078730592793814	-75.08817428156398	146622
e333d099362c898efad58b23d2da66801ae816ca	a multi-classifier combination strategy for the recognition of handwritten cursive words	handwritten cursive words;classifier combination;art;mail;handwriting recognition;image segmentation;neural networks;neural nets;lexicon sizes;character classifier;optical character recognition;reading;testing;data mining;handwriting recognition encoding image segmentation testing writing data mining feature extraction neural networks postal services art;recognition scheme;word segmentation;holistic recognition technique;image segmentation optical character recognition handwriting recognition neural nets;postal services;feature extraction;word recognition;writing;statistical linear classifier;multiclassifier combination strategy;recognition rates;encoding;lexicon sizes multiclassifier combination strategy word segmentation recognition scheme reading handwritten cursive words word recognition holistic recognition technique character classifier statistical linear classifier neural network mail recognition rates;neural network	The paper describes a recognition scheme for reading handwritten cursive words using three word recognition techniques. It particularly focuses on the implementation used to combine the three techniques based on a comparative sru& of different strategies. The first holistic recognition technique derives a global encoding of the word. The other techniques both rely on the segmentatiorr of the word into letters, bur diger in the character ClassiJier they use. The former runs a statistical linear classifier, and the latter runs a neural network with a different representation of the input data. The testing, comparison, and combination studies have been perfornied on word images from mail provided by the USPS. The top choice recognition rates achieved so far correspond to 88 %, 76 %, 6.5 % with respect to lexicon sizes of 10, 100, and IO00 words.	artificial neural network;holism;lexicon;linear classifier;search/retrieve via url	Brigitte Plessis;Anne Sicsu;Laurent Heutte;Eric Menu;Eric Lecolinet;Olivier Debon;Jean-Vincent Moreau	1993		10.1109/ICDAR.1993.395655	natural language processing;text segmentation;speech recognition;feature extraction;word recognition;computer science;intelligent word recognition;machine learning;pattern recognition;software testing;image segmentation;optical character recognition;writing;artificial neural network;reading;encoding	Vision	32.280558873120846	-66.15706184847306	146755
956a9fd3b5186e48e5486c35022c0b70ab4c88a1	asymmetric loss functions and deep densely-connected networks for highly-imbalanced medical image segmentation: application to multiple sclerosis lesion detection		Fully convolutional deep neural networks have been asserted to be fast and precise frameworks with great potential in image segmentation. One of the major challenges in training such networks raises when the data are unbalanced, which is common in many medical imaging applications, such as lesion segmentation, where lesion class voxels are often much lower in numbers than non-lesion voxels. A trained network with unbalanced data may make predictions with high precision and low recall, being severely biased toward the non-lesion class which is particularly undesired in most medical applications where false negatives are actually more important than false positives. Various methods have been proposed to address this problem, including two-step training, sample re-weighting, balanced sampling, and more recently, similarity loss functions and focal loss. In this paper, we fully trained convolutional deep neural networks using an asymmetric similarity loss function to mitigate the issue of data imbalance and achieve much better tradeoff between precision and recall. To this end, we developed a 3D fully convolutional densely connected network (FC-DenseNet) with large overlapping image patches as input and an asymmetric similarity loss layer based on Tversky index (using  $F_\beta $  scores). We used large overlapping image patches as inputs for intrinsic and extrinsic data augmentation, a patch selection algorithm, and a patch prediction fusion strategy using B-spline weighted soft voting to account for the uncertainty of prediction in patch borders. We applied this method to multiple sclerosis (MS) lesion segmentation based on two different datasets of MSSEG 2016 and ISBI longitudinal MS lesion segmentation challenge, where we achieved average Dice similarity coefficients of 69.9% and 65.74%, respectively, achieving top performance in both the challenges. We compared the performance of our network trained with  $F_\beta $  loss, focal loss, and generalized Dice loss functions. Through September 2018, our network trained with focal loss ranked first according to the ISBI challenge overall score and resulted in the lowest reported lesion false positive rate among all submitted methods. Our network trained with the asymmetric similarity loss led to the lowest surface distance and the best lesion true positive rate that is arguably the most important performance metric in a clinical decision support system for lesion detection. The asymmetric similarity loss function based on  $F_\beta $  scores allows training networks that make a better balance between precision and recall in highly unbalanced image segmentation. We achieved superior performance in MS lesion segmentation using a patch-wise 3D FC-DenseNet with a patch prediction fusion strategy, trained with asymmetric similarity loss functions.		Seyed Raein Hashemi;Seyed Sadegh Mohseni Salehi;Deniz Erdogmus;Sanjay P. Prabhu;Simon Keith Warfield;Ali Gholipour	2019	IEEE Access	10.1109/ACCESS.2018.2886371	selection algorithm;lesion;tversky index;false positive rate;voxel;artificial neural network;distributed computing;image segmentation;computer science;precision and recall;artificial intelligence;pattern recognition	ML	31.069975132623643	-75.77617404634357	146836
58cbfbea57574ac4b4d3ded6c219528d022c342c	integrated feature analysis for prostate tissue characterization using trus images	roi segmentation;classification;doctoral thesis;ultrasound images;feature analysis;electrical computer engineering;prostate cancer	ii I hereby declare that I am the sole author of this thesis. This is a true copy of the thesis, including any required final revisions, as accepted by my examiners. I understand that my thesis may be made electronically available to the public. Abstract The Prostate is a male gland that is located around the urethra. Prostate Cancer is the second most diagnosed malignancy in men over the age of fifty. Typically, prostate cancer is diagnosed from clinical data, medical images, and biopsy. Computer Aided Diagnosis (CAD) was introduced to help in the diagnosis in order to assist in the biopsy operations. Usually, CAD is carried out utilizing either the clinical data, using data mining techniques, or using features extracted from either TransRectal UltraSound (TRUS) images or the Radio Frequency (RF) signals. The challenge is that TRUS images' quality is usually poor compared to either Magnetic Resonance Imaging (MRI) or the Computed Tomography (CT). On the other hand, ultrasound imaging is more convenient because of its simple instrumentation and mobility capability compared to either CT or MRI. Moreover, TRUS is far less expensive and does not need certain settings compared to either MRI or CT. Accordingly; the main motivation of this research is to enhance the outcome of TRUS images by extracting as much information as possible from it. The main objective of this research is to implement a powerful noninvasive CAD tool that integrates all the possible information gathered from the TRUS images in order to mimic the expert radiologist opinion and even go beyond his visual system capabilities, a process that will in turn assist the biopsy operation. In this sense, looking deep in the TRUS images by getting some mathematical measures that characterize the image and are not visible by the radiologist is required to achieve the task of cancer recognition. This thesis presents several comprehensive algorithms for integrated feature analysis systems for the purpose of prostate tissue classification. The proposed algorithm is composed of several stages, which are: First, the regions that are highly suspicious are selected using the proposed Gabor filter based ROI identification algorithm. Second, the selected regions are further examined by constructing different novel as well as typical feature sets. The novel constructed feature sets are composed of statistical feature sets, spectral feature sets and model based feature sets. Next, the constructed features were further analyzed by selecting the best feature subset …	algorithm;ct scan;computer-aided design;data mining;feature model;gabor filter;medical ultrasound;radio frequency;radiology;region of interest;resonance;stand up to cancer;tomography	Samar Mohamed	2006			computer vision;medicine;pathology;biological engineering	Vision	34.39090341501697	-76.99772700019582	147269
5c0ec1133e435f5d046d987ed1f6f34e67f106bf	accurate segmentation of dermoscopic images by image thresholding based on type-2 fuzzy logic	skin lesion;image segmentation;image processing;cancer;malignant melanoma diagnosis;uncertainty;skin;microscopy;pigmentation;skin cancer;malignant tumors;fuzzy logic;dermoscopic image segmentation;skin cancer dermoscopic image segmentation image thresholding type 2 fuzzy logic technique pigmented skin lesion image malignant melanoma diagnosis automatic threshold determination;automatic threshold determination;lesions;medical image processing;image segmentation fuzzy logic lesions pigmentation malignant tumors image processing skin cancer medical treatment microscopy uncertainty;image thresholding;type 2 fuzzy logic;skin cancer fuzzy logic image segmentation medical image processing;medical treatment;malignant melanoma;type 2 fuzzy logic fuzzy logic image processing image thresholding;pigmented skin lesion image;type 2 fuzzy logic technique	A novel thresholding-based segmentation approach for accurate segmentation of pigmented skin lesion images regarding malignant melanoma diagnosis has been proposed. The presented approach utilizes type-2 fuzzy logic techniques for automatic threshold determination. The method is applied on various clinically obtained lesion images, and the results are compared with those obtained with two other popular methods from the literature. It is observed that the presented method exhibits superior performance over competing methods and is very successful at handling the uncertainty encountered in determining the border between the lesion and the skin.	abcd schema;fuzzy logic;thresholding (image processing)	M. Emin Yüksel;Murat Borlu	2009	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2009.2018300	fuzzy logic;computer vision;uncertainty;image processing;computer science;pigment;microscopy;pattern recognition;mathematics;skin;thresholding;image segmentation;scale-space segmentation;cancer	Vision	38.60795356073265	-75.5142736845676	147383
74eee002f5c30bcec3088f4f9fb274ec040d14f0	recognizing deviations from normalcy for brain tumor segmentation	bayesian classification;image segmentation;markov random field;brain tumor;electrical engineering and computer science;information flow;thesis;structural properties	A framework is proposed for the segmentation of brain tumors from MRI. Instead of training on pathology, the proposed method trains exclusively on healthy tissue. The algorithm attempts to recognize deviations from normalcy in order to compute a fitness map over the image associated with the presence of pathology. The resulting fitness map may then be used by conventional image segmentation techniques for honing in on boundary delineation. Such an approach is applicable to structures that are too irregular, in both shape and texture, to permit construction of comprehensive training sets. We develop the method of diagonalized nearest neighbor pattern recognition, and we use it to demonstrate that recognizing deviations from normalcy requires a rich understanding of context. Therefore, we propose a framework for a Contextual Dependency Network (CDN) that incorporates context at multiple levels: voxel intensities, neighborhood coherence, intra-structure properties, inter-structure relationships, and user input. Information flows bi-directionally between the layers via multi-level Markov random fields or iterated Bayesian classification. A simple instantiation of the framework has been implemented to perform preliminary experiments on synthetic and MRI data. Thesis Supervisor: W. Eric L. Grimson Title: Bernard Gordon Professor of Medical Engineering Readers: Tomis Lozano-Perez William Freeman Ron Kikinis	algorithm;bayesian network;content delivery network;experiment;image segmentation;iteration;markov chain;markov random field;pattern recognition;synthetic intelligence;universal instantiation;voxel;eric	David T. Gering	2002		10.1007/3-540-45786-0_48	computer vision;naive bayes classifier;information flow;computer science;artificial intelligence;machine learning;segmentation-based object categorization;image segmentation;scale-space segmentation;statistics	Vision	31.603397992516445	-73.57196245536466	147539
66a942d0e4ff1de72809e98a9fb01756000e3afa	retinacad, a system for the assessment of retinal vascular changes	cardiovascular pathologies retinacad retinal vascular change assessment automatic measurement central retinal arteriolar equivalent central retinal venular equivalent arteriolar to venular ratio values geometrical features retinal vasculature landmarks blood vessels optic disc artery vein classification vessel width measurement crae values crve values avr values right eyes left eyes camera fields of view avr estimation retinal images high blood pressure cad tool early diabetes detection diabetes follow up hypertension;retina correlation image segmentation optical imaging diabetes arteries bifurcation;size measurement biomedical optical imaging blood vessels cad cameras cardiovascular system diseases eye image classification medical image processing	This paper introduces RetinaCAD, a system, for the fast, reliable and automatic measurement of the Central Retinal Arteriolar Equivalent (CRAE), the Central Retinal Venular Equivalent (CRVE), and the Arteriolar-to-Venular Ratio (AVR) values, as well as several geometrical features of the retinal vasculature. RetinaCAD identifies important landmarks in the retina, such as the blood vessels and optic disc, and performs artery/vein classification and vessel width measurement. The estimation of the CRAE, CRVE and AVR values on 480 images from 120 subjects has shown a significant correlation between right and left eyes and also between images of same eye acquired with different camera fields of view. AVR estimation in retinal images of 54 subjects showed the lowest values in people with diabetes or high blood pressure thus demonstrating the potential of the system as a CAD tool for early detection and follow-up of diabetes, hypertension or cardiovascular pathologies.	atmel avr;blood vessel tissue;blood supply aspects;cardiovascular diseases;computer-aided design;diabetes mellitus;early diagnosis;eye;hypertensive disease;lupus erythematosus, systemic;optic disk;retina;usability;veins;width	Behdad Dashtbozorg;Ana Maria Mendonça;Susana Penas;Aurélio J. C. Campilho	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6945076	computer vision;medicine;anatomy;diabetes mellitus	Visualization	37.154324804942505	-78.39467073566676	147632
c303c94825a6be7003b9abccecc434f6975abcbe	recognition of damaged letters based on mathematical fuzzy logic analysis	pattern recognition;optical character recognition;captcha	This paper reports a real application whose task was to recognize characters printed on metal ingots. The problem is that surface of ingots is very uneven - ingots are hot or cold, cut by rough instrument, the printing machine can be worn down, etc. In this paper, we present two original recognition methods: the first one is based on application of mathematical fuzzy logic and the second one is based on representation of an image by a fuzzy-valued function. Results of these methods are compared with a simple neural network classifier and few other common methods.	fuzzy logic	Vilém Novák;Hashim Habiballa	2012		10.1007/978-3-642-33018-6_51	fuzzy classification;computer science;artificial intelligence;machine learning;captcha;optical character recognition;algorithm	Logic	36.54424329460246	-68.41133771045533	147791
1af9078a5c2fac2caecb899302a2193139aff415	a web-based application for dermoscopic measurements and learning	diagnostic method 7 point checklist dermoscopic measurement learning image processing techniques automatic analysis skin lesion early melanoma detection computer aided systems diagnostic accuracy expert dermatologists original web based application automatic detection dermoscopic structures pigmented lesions digital images digital cameras smartphones dermoscopy morphological parameters chromatic parameters measurement uncertainty clinical decision;image segmentation;skin;smart phones biomedical optical imaging cameras cancer computer aided instruction measurement uncertainty medical image processing skin;malignant tumors;lesions feature extraction malignant tumors skin image color analysis algorithm design and analysis image segmentation;lesions;image color analysis;feature extraction;uncertainty management biomedical image processing distributed measurement systems e learning;algorithm design and analysis	Image processing techniques have been long proposed for automatic analysis of skin lesions in the field of early detection of melanoma. Nevertheless, Computer Aided Systems are not yet able to outperform the diagnostic accuracy of expert dermatologists. They could instead reveal very useful in providing with a second opinion and improving the detection results from physicians with short clinical experience. The paper introduces an original web-based application for the automatic detection of dermoscopic structures within pigmented lesions and the support to novel dermatologists. It is able to receive and store digital images captured by digital cameras and smartphones equipped with dermoscopy, measure morphological and chromatic parameters, and take into account the measurement uncertainty to finally provide a clinical decision according to the diagnostic method 7-Point Checklist.	digital camera;digital image;distributed computing;edge detection;high- and low-level;image processing;microwave;mobile device;sensor;smartphone;system of measurement;web application	Giuseppe Di Leo;Consolatina Liguori;Alfredo Paolillo;Paolo Sommella	2015	2015 IEEE International Symposium on Medical Measurements and Applications (MeMeA) Proceedings	10.1109/MeMeA.2015.7145213	computer vision;pathology;computer science;multimedia	Visualization	35.40857806020854	-73.61079073481798	147793
06004d926090de80297c054063919e901ee2158c	a segmentation algorithm for handwritten chinese character strings	dynamic programming;algorithm design and analysis image segmentation image processing dynamic programming heuristic algorithms design methodology pattern recognition character recognition speech recognition;probability;image segmentation;over split component merging;image processing;chinese bank check amount recognition handwritten chinese character string segmentation algorithm split and merge strategy ligature location over split component merging structural properties accuracy character recognition maximum a posteriori probability index results optimization dynamic programming algorithm modified level building algorithm;ligature location;dynamic programming algorithm;modified level building algorithm;chinese bank check amount recognition;bank data processing;split and merge strategy;maximum likelihood estimation;handwritten chinese character string segmentation algorithm;cheque processing;accuracy;heuristic algorithms;indexation;results optimization;maximum a posteriori probability index;merging;pattern recognition;speech recognition;probability handwritten character recognition image segmentation dynamic programming merging maximum likelihood estimation cheque processing bank data processing;character recognition;algorithm design and analysis;handwritten character recognition;structural properties;design methodology	A new algorithm for segmenting handwritten Chinese character strings is presented. This approach is based on a split and merge strategy by locating possible ligatures between Chinese characters and merge the over-split components. The strategy is proposed by considering the structural properties of Chinese characters strings. To guarantee accuracy of the above segmentation algorithm, a recognizer is involved to aid the segmentation process. A maximum a posteriori probability index is derived for joint optimization of segmentation and recognition results, and a dynamic programming algorithm—modified level building algorithm is used to optimize this index. The whole algorithm is applied to Chinese bank check amount recognition, and some promising experimental results are obtained.	algorithm;computation;connected component (graph theory);dynamic programming;experiment;finite-state machine;mathematical optimization;structural analysis	Jiang Gao;Xiaoqing Ding;Youshou Wu	1999		10.1109/ICDAR.1999.791867	speech recognition;image processing;computer science;machine learning;dynamic programming;pattern recognition;scale-space segmentation;statistics	Vision	35.09707030522394	-67.27479814351504	147803
93534dea4bd6d02c833692e7ee52ecdfa9258899	diagnosis of heart disease using artificial immune recognition system and fuzzy weighted pre-processing	heart disease;artificial immune system;airs;benchmark problem;fuzzy weighted pre processing;hybrid method;machine learning;artificial immune recognition system;confusion matrix;classification accuracy;breast cancer;k fold cross validation;medical diagnosis	This paper presents a novel method for diagnosis of heart disease. The proposed method is based on a hybrid method that uses fuzzy weighted pre-processing and artificial immune recognition system (AIRS). Artificial immune recognition system has showed an effective performance on several problems such as machine learning benchmark problems and medical classification problems like breast cancer, diabetes, liver disorders classification. The robustness of the proposed method is examined using classification accuracy, k-fold cross-validation method and confusion matrix. The obtained classification accuracy is 96.30% and it is very promising compared to the previously reported classification techniques. 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	benchmark (computing);confusion matrix;cross-validation (statistics);experiment;machine learning;medical decision making;pattern recognition;preprocessor	Kemal Polat;Salih Günes;Sülayman Tosun	2006	Pattern Recognition	10.1016/j.patcog.2006.05.028	confusion matrix;computer science;artificial intelligence;breast cancer;machine learning;medical diagnosis;data mining;artificial immune system	AI	33.802812571120306	-73.72116359555358	148074
d0f36e51c5dcaf0ed846a33d64e969be1fbba2e2	18f-fdg pet imaging analysis for computer aided alzheimer's diagnosis	alzheimer s disease ad;high dimensionality;computer aided diagnosis;supervised learning;dimension reduction;support vector machine svm;adni;pet imaging;independent component analysis;feature space;independent component analysis ica;principal component analysis pca;feature extraction;principal component analysis;fdg pet;pattern classification;image analysis;support vector machine;mild cognitive impairment;early detection	Finding sensitive and appropriate technologies for non-invasive observation and early detection of Alzheimer’s disease (AD) is of fundamental importance to develop early treatments. In this work we develop a fully automatic computer aided diagnosis (CAD) system for high-dimensional pattern classification of baseline F-FDG PET scans from Alzheimer’s disease neuroimaging initiative (ADNI) participants. Image projection as feature space dimension reduction technique is combined with an eigenimage based decomposition for feature extraction, and support vector machine (SVM) is used to manage the classification task. A two folded objective is achieved by reaching relevant classification performance complemented with an image analysis support for final decision making. A 88.24% accuracy in identifying mild AD, with 88.64% specificity, and 87.70% sensitivity is obtained. This method also allows the identification of characteristic AD patterns in mild cognitive impairment (MCI) subjects. 2010 Elsevier Inc. All rights reserved.	baseline (configuration management);computer-aided design;dimensionality reduction;feature extraction;feature vector;functional discourse grammar;image analysis;polyethylene terephthalate;principal component analysis;sensitivity and specificity;support vector machine	Ignacio Álvarez;Juan Manuel Górriz;Javier Ramírez;Diego Salas-Gonzalez;M. M. López;Fermín Segovia;Rosa Chaves;Manuel Gómez-Río;Carlos García Puntonet	2011	Inf. Sci.	10.1016/j.ins.2010.10.027	independent component analysis;support vector machine;computer vision;image analysis;feature vector;feature extraction;computer science;machine learning;pattern recognition;supervised learning;dimensionality reduction;principal component analysis	ML	31.00856644020115	-78.29039511299916	148239
5a23b223c91d7b628dfff13484bd10163f619571	real-time and long-time quantification of behavior of laboratory mice scratching	motion analysis;vision system;frame to frame difference;frames per second;long time mice behavior quantification;image motion analysis;new drugs development;quick movement detection;real time;laboratory mice scratching behavior;real time mice behavior quantification;atopic dermatitis;automatic optical inspection;biomechanics;automated behavior quantification;medical image processing;high speed vision system;real time systems automatic optical inspection biological techniques biomechanics computerised instrumentation image motion analysis medical control systems medical image processing;laboratories mice animals drugs skin real time systems motion analysis diseases cameras magnetic analysis;new drugs development automated behavior quantification high speed vision frame to frame difference;computerised instrumentation;biological techniques;high speed;quantification algorithm;real time motion analysis system;quantification algorithm real time mice behavior quantification long time mice behavior quantification laboratory mice scratching behavior real time motion analysis system automated behavior quantification quick movement detection high speed vision system;high speed vision;drug development;medical control systems;real time systems	A novel real-time motion analysis system was developed for detecting the scratching behavior of laboratory mice in long-time experiments, which enables automated behavior quantification for new drug development in diseases such as atopic dermatitis and so on. This system can detect quick movements of laboratory mice, such as scratching, by introducing a specially designed high-speed vision system that can calculate the frame-to-frame difference at a frame rate of 240 fps (frames per second). Quantification algorithm was also implemented for distinguishing scratching behavior from other behaviors. In fact, we evaluated the effectiveness of our system by demonstrating the experimental results of scratching behavior detection during long-time observation of several ICR mice.	algorithm;experiment;intelligent character recognition;maxima and minima;pixel;real-time clock;real-time computing;real-time transcription;sensor	Idaku Ishii;Yuman Nie;Kenichi Yamamoto;Kensuke Orito;Hiroshi Matsuda	2007	2007 IEEE International Conference on Automation Science and Engineering	10.1109/COASE.2007.4341720	computer vision;simulation;engineering;computer graphics (images)	Robotics	26.73311586053507	-72.18574592679843	148279
f0d00ca0ec50a3c1b7f8f2dc90e1421c3f355a2c	color categorization properties and color sensation on monitor for color-vision deficient subjects and normal trichromat subjects	electronic mail;color vision deficient;multidimensional scaling method color categorization properties color sensation color vision deficient subjects normal trichromat subjects color naming characteristics cvd observers;color;luminance;observers;color categorization;observers computer vision image colour analysis;color sensation;monitoring;yttrium;image color analysis color observers monitoring yttrium electronic mail;color sensation color vision deficient color categorization luminance;image color analysis	This study aimed to compare color-naming characteristics of color-vision deficient (CVD) observers with those of normal trichromat (NT) observers and investigate color sensation. This experiment used 68 color stimuli at three different luminance levels. In the color-naming task, five CVD and five NT subjects selected one color category among 11 basic color terms, and an unknown category. In the evaluation task for color sensation, they evaluated color impression using six adjectives. We used the multidimensional scaling method to construct color categorization space, and applied the factor analysis to compare color sensation of the CVD subjects with those of the NT subjects. As the results, we found that the green and blue categories of the CVD subjects were expanded more than those of NT the subjects at all luminance levels. Moreover, with the activity evaluation for the pink or purple categories, there was difference between the NT and CVD subjects, although the color categorization behaviors of the CVD subjects were similar to those of the NT subjects.	categorization;color vision;evaluation function;factor analysis;image scaling;multidimensional scaling	Keiko Sato;Hironori Takimoto;Yasue Mitsukura	2015	2015 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/SMC.2015.424	computer vision;yttrium;luminance;computer graphics (images)	Robotics	29.083407634641198	-69.83076293944242	148342
77f6c68dce6468b6bd7e50e4957e0d603327703b	skin lesion feature vectors classification in models of a riemannian manifold	feature vectors;62h35;support vector machines;68p10;classification;68u10;riemannian manifold;intervals of confidence	This study is a continuation of a work published by Mete, Ou, and Sirakov (2012), where a model of a 4D manifold of feature vectors was developed. The present paper introduces an improved metric in the 4D manifold first and then extends both the size of the sample space and the dimension (to 6D) of the manifold model in which the sample space lies. As a result, we not only overcame the issue of one single vector representing multiple skin lesions, which occurred in the work of Mete, Ou, and Sirakov (2012), but also improved the accuracy of classification. Furthermore, a statistical evaluation of our support vector machine (SVM) classification method was performed. The intervals of confidence were calculated for the mean of classification of a large sample set in the 6D model. Comparison results of classification with our SVM in 4D and 6D models using 10-fold cross-validation are given at the end of the paper. It is found that the 6D model improves the classification results of the previous study suggesting that two newly introduced features contributed to the increase of the classification accuracy.	continuation;cross-validation (statistics);manifold regularization;support vector machine	Nikolay Metodiev Sirakov;Ye-Lin Ou;Mutlu Mete	2014	Annals of Mathematics and Artificial Intelligence	10.1007/s10472-014-9424-8	support vector machine;statistical manifold;feature vector;biological classification;computer science;machine learning;pattern recognition;mathematics;statistics;manifold alignment	ML	33.95772179598095	-71.85473359412622	148388
8632d6f7671a6b2753237c80f8844cebdf8b5cfb	capturing contextual dependencies in medical imagery using hierarchical multi-scale models	computer assisted diagnosis;medical imagery;image coding;probability;neural networks;neural nets image classification data compression mammography probability modelling medical image processing;data compression;generic model;neural nets;computer assisted detection;contextual dependencies capturing hierarchical multiscale models hierarchical pyramid neural network hidden variables set mammographic mass images information integration computer assisted detection computer assisted diagnosis medical diagnostic imaging microcalcification hierarchical image probability model breast cancer medical imagery discriminative model;hip;microcalcification;image classification;biomedical imaging;mammographic mass images;multi scale modeling;information integration;biomedical imaging context modeling hip image analysis medical diagnostic imaging neural networks biomedical engineering image coding robustness object detection;biomedical engineering;neural net work;medical image processing;hidden variables set;robustness;hierarchical multiscale models;image analysis;mammography;hierarchical pyramid neural network;context modeling;hierarchical image probability model;breast cancer;discriminative model;object detection;medical diagnostic imaging;contextual dependencies capturing	In this paper we summarize our results for two classes of hierarchical multi-scale models that exploit contextual information for detection of structure in mammographic imagery. The first model, the hierarchical pyramid neural network (HPNN), is a discriminative model which is capable of integrating information either coarse-to-fine or fine-tocoarse for microcalcification and mass detection. The second model, the hierarchical image probability (HIP) model, captures short-range and contextual dependencies through a combination of coarse-to-fine factoring and a set of hidden variables. The HIP model, being a generative model, has broad utility, and we present results for classification, synthesis and compression of mammographic mass images. The two models demonstrate the utility of the hierarchical multi-scale framework for computer assisted detection and diagnosis.	artificial neural network;discriminative model;generative model;hidden variable theory;integer factorization;medical imaging	Paul Sajda;Clay Spence;Lucas C. Parra	2002		10.1109/ISBI.2002.1029219	data compression;computer vision;contextual image classification;computer science;information integration;breast cancer;machine learning;pattern recognition;probability;context model;artificial neural network;discriminative model;robustness	Vision	31.89962103492605	-73.74426124841054	148652
6510c5bea04a36e6e016bf4906e230a177542d57	neural network for the recognition of handwritten tunisian city names	neural nets;handwriting recognition;neural network	The complexity of the Arabic characters morphology makes research in recognition of the handwritten Arabic writing remain an interesting topic. In this setting, a system for recognition of handwritten Arabic words based on a Transparent Neural Network, called TNN-DF is developed within the LSTS laboratory. It uses structural features to describe words and makes recourse to Fourier descriptors (DF) when encounters an ambiguity. To enhance recognition results of TNN-DF, we suggest a neural approach to learn letters, part ofarabic words and words. Experiments conducted on 750 samples, of 50 city names, extracted from the standard IFN/ENIT' database of handwritten Tunisian city names show an improvement of recognition accuracy. The results are promising, and suggestions for improvements leading to recognition of larger voca bulary are proposed.	artificial neural network;direction finding;fourier analysis;galaxy morphological classification;speech-generating device	Imen Ben Cheikh;Afef Kacem	2007	Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)	10.1109/ICDAR.2007.174	natural language processing;speech recognition;intelligent character recognition;computer science;intelligent word recognition;machine learning;artificial neural network	Robotics	33.20526696144134	-66.68166466591805	148878
5e6754dae83267e5c5aa27851b5958c1a0d13814	learning to group text lines and regions in freeform handwritten notes	tabletpc;ink parsing;text segmentation;adaboost decision-tree classifier;learning (artificial intelligence);image segmentation;group text regions;freeform handwritten notes;key technical development;technical advance;ink;image classification;group text lines;handwritten character recognition;freeform digital ink notes;document rec;machine learning;chinese character;text analysis;document image analysis;decision trees;document image processing;group theory;program compilers;decision tree classifier;learning artificial intelligence	This paper proposes a machine learning approach to grouping problems in ink parsing. Starting from an initial segmentation, hypotheses are generated by perturbing local configurations and processed in a high-confidence-first fashion, where the confidence of each hypothesis is produced by a data-driven AdaBoost decision-tree classifier with a set of intuitive features. This framework has successfully applied to grouping text lines and regions in complex freeform digital ink notes from real TabletPC users. It holds great potential in solving many other grouping problems in the ink parsing and document image analysis domains.	adaboost;decision tree;image analysis;machine learning;parsing;tablet computer	Ming Ye;Paul A. Viola;Sashi Raghupathy;Herry Sutanto;Chengyang Li	2007	Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)	10.1109/ICDAR.2007.159	text segmentation;computer vision;contextual image classification;speech recognition;decision tree learning;computer science;machine learning;decision tree;pattern recognition;image segmentation;group theory	Vision	31.811339118428076	-66.56496323537948	148928
a907e3d019862aea0af4e36f7ea1bb99794de4f5	using early acquisitions of amyloid-pet as a surrogate of fdg-pet: a machine learning based approach		Recent studies have suggested that early acquisitions of 18F-FBB-PET data (eFBB) provides similar information to 18 F-FDG-PET images. As far as we know, presently this attractive idea has been only tested by experiments focused on the routine clinical practice. In this work, we compare the usefulness of FDG and eFBB images to separate Alzheimer’s disease (AD) and non-AD patients using Computer Aided Diagnosis (CAD) systems based on machine learning. Specifically, a Support Vector Machine classifier was used to estimate the potential of both data modalities to separate the groups. Two dimensionality reduction approaches, one based on previous knowledge (predefined regions of interest) and other based on Principal Component Analysis were also investigated. The results suggest that eFBB images could be used as a surrogate of FDG data in CAD systems for AD. However we found slight differences that might indicate that FDG images are more suitable than eFBB data to model the metabolic changes of non-AD patients. In addition, using multimodal systems we evaluated weather FDG and eFBB images contain complementary information and would be worth to use them together.	computer-aided design;dimensionality reduction;experiment;functional discourse grammar;machine learning;multimodal interaction;polyethylene terephthalate;principal component analysis;region of interest;support vector machine	Fermín Segovia;Juan Manuel Górriz;Javier Ramírez;Francisco Jesús Martínez-Murcia;Diego Castillo-Barnes;R. Sanchez-Vano;P. Sopena-Novales;Manuel Gómez-Río	2018	2018 International Workshop on Pattern Recognition in Neuroimaging (PRNI)	10.1109/PRNI.2018.8423959	support vector machine;computer-aided diagnosis;dimensionality reduction;clinical practice;principal component analysis;machine learning;artificial intelligence;computer science	ML	31.044018396056252	-78.31023538550497	148934
e9cc46491ffc3009073dac10bad80efc289e731b	intensity population based unsupervised hemorrhage segmentation from brain ct images		Abstract This article has proposed an intelligent knowledge driven method to segment hemorrhage from brain CT images using the information of pixel intensity population and distribution. A mathematical model is designed to identify the unexpected variation in pixel intensity population in a brain CT image having hemorrhage. Complete batch of multi-slice CT scan images is taken as input. Fusion of knowledge of brain anatomy with intensity distribution information of CT brain image results in a unique solution for hemorrhage segmentation. To test the robustness, segmentation of different types of hemorrhage of different patients is done using the proposed method. The results are accepted and validated by radiology experts. A fully automatic and fast Computer Aided Diagnosis (CAD) is designed, using the proposed method, to segment hemorrhage automatically, in the absence of an expert, for further inspections like checking severity, volume, size, shape and type of hemorrhage. Competence of the CAD is tested against mostly used established clustering methods to demonstrate its potential.	ct scan	Soumi Ray;Vinod Kumar;Chirag Kamal Ahuja;Niranjan Khandelwal	2018	Expert Syst. Appl.	10.1016/j.eswa.2017.12.032	data mining;computed tomography;pixel;robustness (computer science);cluster analysis;computer science;cad;computer-aided diagnosis;population;artificial intelligence;pattern recognition;segmentation	Vision	37.64152453917989	-78.51658375370612	149222
f493453d74d127309defbf5f0521221de0c1a3af	recognition of handwritten hindu numerals using structural descriptors	hindu numerals;structural descriptors;term rewriting;handwritten recognition	A method for recognizing handwritten Hindi numerals is proposed based on the structural descriptors of a numeral's shape. The method consists of three major steps. The first one is preprocessing, where a handwritten numeral is scanned, normalized and then thinned. Next, a robust algorithm is used to segment the scanned image into stroke(s), based on feature points, and to identify cavity features. The output of this algorithm is a syntactic representation (that is one or more syntactic terms). Finally, this syntacytic representation is matched against the set of prototype syntactic representations of handwritten numerals for a possible match. Early experimental results are not only encouraging but also proving the tolerance of the proposed system to recognize a high variability of Hindi numerals' shapes. The system attained a successful recognition rate of 96%.		Ashraf Elnagar;Saad Harous	2003	J. Exp. Theor. Artif. Intell.	10.1080/0952813021000047170	speech recognition;hindu–arabic numeral system;computer science;pattern recognition	Vision	34.624309518258315	-66.6688083180654	149518
9227c7f56b6330983ecea9aea8e22d280a94d399	fully automatic brain tumor segmentation by using competitive em and graph cut		Manual MRI brain tumor segmentation is a difficult and time con- suming task which makes computer support highly desirable. This paper presents a hybrid brain tumor segmentation strategy characterized by the allied use of Graph Cut segmentation method and Competitive Expectation Maximi- zation (CEM) algorithm. Experimental results were obtained by processing in- house collected data and public data from benchmark data sets. To see if the proposed method can be considered an alternative to contemporary methods, the results obtained were compared with those obtained by authors who under- took the Multi-modal Brain Tumor Segmentation challenge. The results ob- tained prove that the method is competitive with recently proposed approaches.	cut (graph theory)	Valentina Pedoia;Sergio Balbi;Elisabetta Binaghi	2015		10.1007/978-3-319-23231-7_51	computer science;artificial intelligence;machine learning;segmentation-based object categorization;data mining;scale-space segmentation	NLP	31.082351199963295	-73.15149111544225	149539
4668fe3413e7a62ba0efa6bbb4f25bcda23d6383	deep learning for the classification of lung nodules		Deep learning, as a promising new area of machine learning, has attracted a rapidly increasing attention in the field of medical imaging. Compared to the conventional machine learning methods, deep learning requires no hand-tuned feature extractor, and has shown a superior performance in many visual object recognition applications. In this study, we develop a deep convolutional neural network (CNN) and apply it to thoracic CT images for the classification of lung nodules. We present the CNN architecture and classification accuracy for the original images of lung nodules. In order to understand the features of lung nodules, we further construct new datasets, based on the combination of artificial geometric nodules and some transformations of the original images, as well as a stochastic nodule shape model. It is found that simplistic geometric nodules cannot capture the important features of lung nodules.	artificial neural network;ct scan;convolutional neural network;deep learning;machine learning;medical imaging;outline of object recognition;randomness extractor	He Yang;Hengyong Yu;Ge Wang	2016	CoRR		computer vision;machine learning	ML	31.996184682564017	-74.96697446000503	149592
eed0e357bbdba7b0905cb26de35cd002c2de0d6e	complementarity of feature point detectors		The goal of this paper is to provide a study on complementarity of feature point detectors. Many studies have been proposed on these detectors but none deals with complementarity in details. We introduce an evaluation of eleven well-known detectors based on new criteria used to characterize complementarity. The complementarity is computed with spatial distribution and contribution measures as well as repeatability and distribution gains of the association of two detectors.	complementarity (physics);complementarity theory;feature vector;repeatability;sensor	Guillaume Gales;Alain Crouzil;Sylvie Chambon	2010			artificial intelligence;computer science;spatial distribution;repeatability;computer vision;pattern recognition;complementarity (molecular biology);detector	Vision	37.454907430114176	-70.79463366216365	149704
0e2a569f51bb83f5a053aa91c012a6fed7f61d2c	automatic segmentation of skin lesion images using evolutionary strategy	skin lesion;evolutionary computation;image segmentation;transillumination epiluminescence microscopy;cancer;automatic segmentation;skin;bioluminescence;skin lesion images;tumours;indexing terms;image texture;shape feature;texture analysis;transillumination epiluminescence microscopy automatic segmentation skin lesion images evolutionary strategy malignant melanoma shape feature texture analysis cross polarization epiluminescence microscopy;medical image processing;skin lesion evolutionary strategy image segmentation biomedical application fitness function;evolutionary strategy;cross polarization epiluminescence microscopy;biomedical optical imaging;malignant melanoma;biomedical application;fitness function;tumours bioluminescence biomedical optical imaging cancer evolutionary computation image segmentation image texture medical image processing skin;image segmentation lesions cancer detection malignant tumors skin cancer microscopy pigmentation computer science shape fuzzy systems	Malignant melanoma has a good prognosis if treated early. Accurate skin lesion segmentation from the background skin is important not only because the shape feature can be directly derived from the process, but also because it can provide a scope for texture analysis. In this paper, we propose an evolutionary strategy based segmentation algorithm to identify the lesion area by an ellipse. It can detect the lesion automatically without setting parameters manually. The method is validated by experiments and comparisons with manually segmentation by an expert and algorithms developed by M. Doshi, et al. (2004).	algorithm;experiment	Ning Situ;Xiaojing Yuan;George Zouridakis;Nizar Mullani	2007	2007 IEEE International Conference on Image Processing	10.1109/ICIP.2007.4379575	image texture;computer vision;index term;bioluminescence;computer science;machine learning;skin;image segmentation;evolution strategy;scale-space segmentation;fitness function;evolutionary computation;cancer	Robotics	38.74074886268338	-75.36630228342149	149982
942beadf34b3241f4e6a8c66a746417f6e27c942	scout: simultaneous time segmentation and community detection in dynamic networks		Many evolving complex real-world systems can be modeled via dynamic networks. An important problem in dynamic network research is community detection, which finds groups of topologically related nodes. Typically, this problem is approached by assuming either that each time point has a distinct community organization or that all time points share a single community organization. The reality likely lies between these two extremes. To find the compromise, we consider community detection in the context of the problem of segment detection, which identifies contiguous time periods with consistent network structure. Consequently, we formulate a combined problem of segment community detection (SCD), which simultaneously partitions the network into contiguous time segments with consistent community organization and finds this community organization for each segment. To solve SCD, we introduce SCOUT, an optimization framework that explicitly considers both segmentation quality and partition quality. SCOUT addresses limitations of existing methods that can be adapted to solve SCD, which consider only one of segmentation quality or partition quality. In a thorough evaluation, SCOUT outperforms the existing methods in terms of both accuracy and computational complexity. We apply SCOUT to biological network data to study human aging.	addresses (publication format);biological network;computational complexity theory;mathematical optimization;world-system;biologic segmentation	Yuriy Hulovatyy;Tijana Milenkovi&#x0107;	2016		10.1038/srep37557	simulation;artificial intelligence	Web+IR	38.57140039147439	-69.99997242599397	150117
728b2b4783db4b9b2fe53835deea9bab95410ae8	supervised enhancement filters: application to fissure detection in chest ct scans	low dose;enhancement;computed tomography;receiver operator characteristic;optimal filtering;hessian matrix;algorithms artificial intelligence humans imaging three dimensional lung pattern recognition automated radiographic image enhancement radiographic image interpretation computer assisted radiography thoracic reproducibility of results sensitivity and specificity signal processing computer assisted tomography x ray computed;image classification;ct scan;receiver operating characteristic curve;fissure detection;chest ct scans;classifier;receiver operating characteristic curve supervised enhancement filters fissure detection chest ct scans medical image processing pattern recognition feature selection pulmonary fissures 3 d computed tomography;supervised classifier enhancement hessian matrix pulmonary fissures;feature extraction;medical image processing;computerised tomography;pattern recognition;filters computed tomography eigenvalues and eigenfunctions tensile stress pattern recognition biomedical imaging filtering theory biomedical image processing training data feature extraction;roc curve;feature selection;pulmonary fissures;pneumodynamics;3 d computed tomography;pneumodynamics computerised tomography feature extraction image classification medical image processing;supervised enhancement filters;supervised	In medical image processing, many filters have been developed to enhance certain structures in 3-D data. In this paper, we propose to use pattern recognition techniques to design more optimal filters. The essential difference with previous approaches is that we provide a system with examples of what it should enhance and suppress. This training data is used to construct a classifier that determines the probability that a voxel in an unseen image belongs to the target structure(s). The output of a rich set of basis filters serves as input to the classifier. In a feature selection process, this set is reduced to a compact, efficient subset. We show that the output of the system can be reused to extract new features, using the same filters, that can be processed by a new classifier. Such a multistage approach further improves performance. While the approach is generally applicable, in this work the focus is on enhancing pulmonary fissures in 3-D computed tomography (CT) chest scans. A supervised fissure enhancement filter is evaluated on two data sets, one of scans with a normal clinical dose and one of ultra-low dose scans. Results are compared with those of a recently proposed conventional fissure enhancement filter. It is demonstrated that both methods are able to enhance fissures, but the supervised approach shows better performance; the areas under the receiver operating characteristic (ROC) curve are 0.98 versus 0.90, for the normal dose data and 0.97 versus 0.87 for the ultra low dose data, respectively.	basis function;ct scan;edge enhancement;feature selection;filter (software);fissure;image processing;medical image;medical imaging;multistage amplifier;pattern recognition;receiver operator characteristics;receiver operating characteristic;scanning;statistical classification;subgroup;voxel	Eva M. van Rikxoort;Bram van Ginneken;M. A. J. Klik;Mathias Prokop	2008	IEEE Transactions on Medical Imaging	10.1109/TMI.2007.900447	computer vision;radiology;computer science;machine learning;pattern recognition;mathematics;computed tomography;receiver operating characteristic	Vision	34.71642925182762	-76.83033031795618	150336
55090c3a9dd80c233384b07c669d5c75fb6185a4	segmentation of skull base tumors from mri using a hybrid support vector machine-based method	machine-based method;negative class;trained bsvc;binary svc;final tumor lesion;hybrid support vector;higher segmentation accuracy;initial tumor region;skull base tumor;developed method;binary svms;pre-segmented initial tumor region	To achieve robust classification performance of support vector machine (SVM), it is essential to have balanced and representative samples for both positive and negative classes. A novel three-stage hybrid SVM (HSVM) is proposed and applied for the segmentation of skull base tumor. The main idea of the method is to construct an online hybrid support vector classifier (HSVC), which is a seamless and nature connection of one-class and binary SVMs, by a boosting tool. An initial tumor region was first pre-segmented by a one-class SVC (OSVC). Then the boosting tool was employed to automatically generate the negative (non-tumor) samples, according to certain criteria. Subsequently the pre-segmented initial tumor region and the non-tumor samples were used to train a binary SVC (BSVC). By the trained BSVC, the final tumor lesion was segmented out. This method was tested on 13 MR images data sets. Quantitative results suggested that the developed method achieved significantly higher segmentation accuracy than OSVC and BSVC.	support vector machine	Jiayin Zhou;Qi Tian;Vincent Chong;Wei Xiong;Weimin Huang;Zhimin Wang	2011		10.1007/978-3-642-24319-6_17	machine learning;pattern recognition;data mining	Vision	30.930516577609318	-75.61214809669418	150618
8a8c86244bed1caf3c08916d7d716a157b877b42	use of colour in form layout analysis	form processing system;finance;storage requirement;optical character recognition;performance;data mining;data mining costs image color analysis iris computational efficiency brightness information analysis finance computer science education medical services;form layout analysis;colour reduction;brightness;ocr form layout analysis image colour form processing system storage requirement computational cost hue chroma brightness colour document processing data extraction performance colour reduction;colour document processing;computer science education;medical services;data extraction;image color analysis;image colour analysis;business forms;hue;chroma;ocr;document image processing;computational cost;image colour;optical character recognition document image processing image colour analysis business forms;iris;computational efficiency;institutional repository research archive oaister;information analysis	Colour has long been viewed as one of the unnecessary features in any form processing system, due not only to the large storage requirement and computational cost its inclusion imposes but also to the complexities of hue, chroma and brightness variation. However, as technology has advanced and computing costs have reduced, the processing of documents in colour has now become practical. This paper describes a protootype form extraction system that utilises colour information to he@ facilitate data extraction from a form. Blank forms are first automatically analysed to obtain their layout, colour and statistical information. The filled data is then extracted from the filled forms using techniques based upon the colour characteristic changes that have occurred with respect to the blank form. The improved performance of the proposed method has been verlfied by comparing the processing time, data extraction precision and recall rate of the proposed system to that of an archetypal black and white form extraction system.	algorithmic efficiency;computation;data compression;precision and recall;sensitivity and specificity	Wing Seong Wong;Nasser Sherkat;Tony Allen	2001		10.1109/ICDAR.2001.953924	computer vision;hue;performance;computer science;colour look-up table;multimedia;data analysis;optical character recognition;brightness;computer graphics (images)	AI	37.7670732180487	-66.76123061351346	150730
2cdf5952b5a1bea5d24917aa2f3fc2ee33568e9a	autoencoding the retrieval relevance of medical images	histograms;annotated feature vector dimensionality medical image retrieval relevance autoencoding content based image retrieval cbir big data feature extraction feature classification digital images medical imaging memory requirements image retrieval systems image blocks feature dimensionality reduction local binary patterns lbp support vector machines svm cbir research community irma dataset x ray images;image coding;support vector machines big data content based retrieval feature extraction image classification image coding image retrieval medical image processing relevance feedback;visualization;feature extraction;feature extraction histograms image retrieval visualization medical diagnostic imaging image coding;medical diagnostic imaging;image retrieval	Content-based image retrieval (CBIR) of medical images is a crucial task that can contribute to a more reliable diagnosis if applied to big data. Recent advances in feature extraction and classification have enormously improved CBIR results for digital images. However, considering the increasing accessibility of big data in medical imaging, we are still in need of reducing both memory requirements and computational expenses of image retrieval systems. This work proposes to exclude the features of image blocks that exhibit a low encoding error when learned by a n/p/n autoencoder (p <; n). We examine the histogram of autoendcoding errors of image blocks for each image class to facilitate the decision which image regions, or roughly what percentage of an image perhaps, shall be declared relevant for the retrieval task. This leads to reduction of feature dimensionality and speeds up the retrieval process. To validate the proposed scheme, we employ local binary patterns (LBP) and support vector machines (SVM) which are both well-established approaches in CBIR research community. As well, we use IRMA dataset with 14,410 x-ray images as test data. The results show that the dimensionality of annotated feature vectors can be reduced by up to 50% resulting in speedups greater than 27% at expense of less than 1% decrease in the accuracy of retrieval when validating the precision and recall of the top 20 hits.	accessibility;analysis of algorithms;archive;autoencoder;big data;computational resource;computer vision;content-based image retrieval;digital image;feature extraction;feature model;feature vector;image analysis;irma board;local binary patterns;medical image computing;medical imaging;precision and recall;radiography;region of interest;relevance;requirement;support vector machine;test data	Zehra Camlica;Hamid R. Tizhoosh;Farzad Khalvati	2015	2015 International Conference on Image Processing Theory, Tools and Applications (IPTA)	10.1109/IPTA.2015.7367208	image texture;computer vision;feature detection;visual word;visualization;feature extraction;image retrieval;computer science;machine learning;digital image processing;pattern recognition;histogram;automatic image annotation;feature;information retrieval;statistics	Vision	32.64804756227465	-71.8524778113848	150746
5c65c2143026368d166756d7b5fa23f9555b4cce	audiovisual attention modeling and salient event detection		Although human perception appears to be automatic and unconscious, complex sensory mechanisms exist that form the preattentive component of understanding and lead to awareness. Considerable research has been carried out into these preattentive mechanisms and computational models have been developed for similar problems in the fields of computer vision and speech analysis. The focus here is to explore aural and visual information in video streams for modeling attention and detecting salient events. The separate aural and visual modules may convey explicit, complementary or mutually exclusive information around the detected audiovisual events. Based on recent studies on perceptual and computational attention modeling, we formulate measures of attention using features of saliency for the audiovisual stream. Audio saliency is captured by signal modulations and related multifrequency band features, extracted through nonlinear operators and energy tracking. Visual saliency is measured by means of a spatiotemporal attention model driven by various feature cues (intensity, color, motion). Features from both modules mapped to one-dimensional, time-varying saliency curves, from which statistics of salient segments can be extracted and important audio or visual events can be detected through adaptive, threshold-based mechanisms. Audio and video curves are integrated in a single attention curve, where events may be enhanced, suppressed or vanished. Salient events from the audiovisual curve are detected through geometrical features such as local extrema, sharp transitions and level sets. The potential of inter-module fusion and audiovisual event detection is demonstrated in applications such as video key-frame selection, video skimming and video annotation.	algorithm;audio signal processing;computation;computational model;computer vision;digital video;image processing;key frame;maxima and minima;modality (human–computer interaction);nonlinear system;sensor;sound card;static key;streaming media;voice analysis	Georgios Evangelopoulos;Konstantinos Rapantzikos;Petros Maragos;Yannis S. Avrithis;Alexandros Potamianos	2008		10.1007/978-0-387-76316-3_8	operator (computer programming);streams;salient;perception;computational model;salience (neuroscience);audio signal;computer vision;artificial intelligence;computer science;mutually exclusive events	Vision	24.629428159317783	-69.21709777632373	150952
13e462a030dcf760cdbd91fcb5eb0635f77a0dc5	a semi-automatic coronary artery segmentation framework using mechanical simulation	semi automatic segmentation;coronary stenosis;coronary vessels;mechanical simulation;reproducibility of results;algorithms;humans;radiographic image interpretation computer assisted;coronary artery;tomography x ray computed	CVD (cardiovascular disease) is one of the biggest threats to human beings nowadays. An early and quantitative diagnosis of CVD is important in extending lifespan and improving people’s life quality. Coronary artery stenosis can prevent CVD. To diagnose the degree of stenosis, the inner diameter of coronary artery needs to be measured. To achieve such measurement, the coronary artery is segmented by using a method that is based on morphology and the continuity between computed tomography image slices. A centerline extraction method based on mechanical simulation is proposed. This centerline extraction method can figure out a basic framework of the coronary artery by simulating pixel dots of the artery image into mass points. Such mass points have tensile forces, with which the outer pixel dots can be drawn to the center. Subsequently, the centerline of the coronary artery can be outlined by using the local line-fitting method. Finally, the nearest point method is adopted to measure the inner diameter. Experimental results showed that the methods proposed in this paper can precisely extract the centerline of the coronary artery and can accurately measure its inner diameter, thereby providing a basis for quantitative diagnosis of coronary artery stenosis.	arterial stenosis;ct scan;cardiovascular diseases;chemical vapor deposition;computed tomography of the heart;coronary artery disease;coronary stenosis;diameter (qualifier value);entity name part qualifier - adopted;inner mitochondrial membrane;mathematical morphology;perceived quality of life;pixel;scott continuity;semiconductor industry;simulation;x-ray computed tomography	Ken Cai;Rongqian Yang;Lihua Li;Shanxing Ou;Yuke Chen;Jianhong Dou	2015	Journal of Medical Systems	10.1007/s10916-015-0329-9	radiology;medicine;computer science;surgery;cardiology	Vision	38.181643171010236	-78.2343539871722	151093
851a2991f575dfb701ccebe1e06110e6a9c0b3a1	automatic pharynx segmentation from mri data for analysis of sleep related disorders	pharynx;segmentation;mri	In our project, we analyse throat structures using magnetic resonance imaging (MRI) to associate anatomic risk factors with sleep related disorders. Pharynx segmentation is the first step in the three-dimensional analysis of throat tissues. We present a pipeline for automatic pharynx segmentation. The automatic part of the approach consists of three steps: smoothing, thresholding, 2D and 3D connected component analysis. Whereas two first steps are rather common, the third step provides a set of general rules for the automatic extraction of the pharyngeal component. Our method requires less than one minute to extract the pharyngeal structures. The approach is evaluated quantitatively on 30 data sets using region-based and edge-based measures.		Tetyana Ivanovska;René Laqua;Muhammad Laiq Ur Rahman Shahid;Lars Linsen;Katrin Hegenscheid;Henry Völzke	2015	International Journal on Artificial Intelligence Tools	10.1142/s0218213015500189	magnetic resonance imaging;segmentation	Robotics	38.780062566796	-79.49278176102834	151095
ef4b4e57975dd5b1be42aa15d32877b02a4db11d	structural group classification technique based on regional fmri bold responses	sensitivity and specificity;functional magnetic resonance imaging;structural group classification;female;brain;adult algorithms artificial intelligence brain brain mapping computer simulation evoked potentials female humans image interpretation computer assisted imaging three dimensional magnetic resonance imaging male marijuana abuse middle aged models biological models statistical oxygen pattern recognition automated reproducibility of results sensitivity and specificity;time shifted gaussian functions;analysis of variance brain magnetic resonance imaging neuroimaging hospitals biomedical imaging independent component analysis blood flow principal component analysis extraterrestrial measurements;imaging three dimensional;bold modeling;fmri;evoked potentials;gaussian processes;middle aged;mean time intensity curve;fmri bold modeling classification technique feature extraction;oxygen;hospitals;male;image classification;biomedical imaging;models biological;canonical transformations;mean regional response;independent component analysis;feature space;gaussian processes brain blood oxygen biomedical mri medical image processing image classification;brain mapping;image interpretation computer assisted;feature extraction;medical image processing;adult;principal component analysis;functional magnetic resonance images;neuroimaging;region of interest;blood;magnetic resonance imaging;classification technique;canonical transformation;reproducibility of results;heavy marijuana smokers;analysis of variance;models statistical;artificial intelligence;algorithms;24 hour;pattern recognition automated;humans;marijuana abuse;blood flow;28 day;brain activation;extraterrestrial measurements;reduced dimension optimal discrimination space;computer simulation;regional brain activity;time intensity curve	This paper presents a new multigroup classification method based on subtle differences in regional brain activity during the completion of a functional magnetic resonance imaging (fMRI) challenge paradigm. Classification is performed based on features derived from BOLD time intensity curves in selected regions of interest (ROI). For each ROI, a mean time intensity curve [called mean regional response (MRR)] is calculated from realigned and normalized datasets. The overall subject performance is characterized with a vector of features obtained using nonlinear modeling of all subject's MRRs with a mixture of time shifted Gaussian functions. The classification is performed in the reduced-dimension optimal discrimination space, obtained through canonical transformations of original feature space. In order to demonstrate feasibility of the proposed method, classification of three groups of subjects is presented. The three groups are defined as heavy marijuana smokers after 24 hours of abstinence, heavy marijuana smokers after 28 days of abstinence, and healthy nonusing controls. The proposed method can be useful as an analytic tool for the discrimination of different groups of subjects based on temporal features of functional magnetic resonance imaging activation.	classification;electroencephalography;feature vector;magnetic resonance imaging;nonlinear system;normal statistical distribution;programming paradigm;region of interest;cell transformation;fmri	Piotr Bogorodzki;Jadwiga Rogowska;Deborah A. Yurgelun-Todd	2005	IEEE Transactions on Medical Imaging	10.1109/TMI.2004.843183	computer simulation;independent component analysis;canonical transformation;computer vision;contextual image classification;radiology;feature vector;analysis of variance;feature extraction;computer science;blood flow;artificial intelligence;magnetic resonance imaging;gaussian process;oxygen;brain mapping;neuroimaging;principal component analysis;region of interest	Visualization	31.59068984075479	-79.90684341300773	151362
a3f3f108e47541bc28c6f0b771591f1116842f63	complex network properties of eye-tracking in the face recognition process - an initial study		In the paper, we propose to investigate eye-tracking sequences obtained in the face recognition process in terms of complex networks. A proper algorithm for transformation sequences coming from eye-tracking into complex networks is described. The analysis of parameters of obtained complex networks can be helpful in better understanding and classifying human mental behaviors and activities.	algorithm;ct scan;complex network;electroencephalography;experiment;eye tracking;facial recognition system;tomography	Boleslaw Jaskula;Jaroslaw Szkola;Krzysztof Pancerz	2012			computer science;artificial intelligence;computer vision;facial recognition system;complex network;eye tracking	AI	27.407313251403213	-79.2317225977904	151552
76290a9555670a473bcb5ea968e53a91d967f0c4	detection of corpus callosum malformations in pediatric population using the discriminative direction in multiple kernel learning	computer aided diagnosis;multiple kernel learning;magnetic resonance imaging;brain imaging	In this paper we propose a Multiple Kernel Learning (MKL) classifier to detect malformations of the Corpus Callosum (CC) and apply it in a pediatric population. Furthermore, we extend the concept of discriminative direction to the linear MKL methods, implementing it in a single subject analysis framework. The CC is characterized using different measures derived from Magnetic Resonance Imaging (MRI) data and the MKL approach is used to efficiently combine them. The discriminative direction analysis highlights those features that lead the classification for each given subject. In the case of a CC with malformation this means highlighting the abnormal characteristics of the CC that guide the diagnosis. Experiments show that the method correctly identifies the malformative aspects of the CC. Moreover, it is able to identify dishomogeneus, localized or widespread abnormalities among the different features. The proposed method is therefore suitable for supporting neuroradiologists in the decision-making process, providing them not only with a suggested diagnosis, but also with a description of the pathology.	agenesis of corpus callosum;body of uterus;congenital abnormality;decision making;feature selection;inference;information theory;kernel (operating system);magnetic resonance imaging;math kernel library;mathematical optimization;multiple kernel learning;personalization;precision medicine;subject indexing;glycoprotein gl, varicella-zoster virus	Denis Peruzzo;Filippo Arrigoni;Fabio M. Triulzi;Cecilia Parazzini;Umberto Castellani	2014	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-319-10470-6_38	speech recognition;radiology;medicine;computer science;magnetic resonance imaging;machine learning;pattern recognition	Vision	29.77461907511379	-78.75089459504369	151680
7a694d246139ce0272b36bd48db8e6c5623e8670	spinenet: automated classification and evidence visualization in spinal mris	mri analysis;radiological classification;spinal mri	The objective of this work is to automatically produce radiological gradings of spinal lumbar MRIs and also localize the predicted pathologies. We show that this can be achieved via a Convolutional Neural Network (CNN) framework that takes intervertebral disc volumes as inputs and is trained only on disc-specific class labels. Our contributions are: (i) a CNN architecture that predicts multiple gradings at once, and we propose variants of the architecture including using 3D convolutions; (ii) showing that this architecture can be trained using a multi-task loss function without requiring segmentation level annotation; and (iii) a localization method that clearly shows pathological regions in the disc volumes. We compare three visualization methods for the localization. The network is applied to a large corpus of MRI T2 sagittal spinal MRIs (using a standard clinical scan protocol) acquired from multiple machines, and is used to automatically compute disk and vertebra gradings for each MRI. These are: Pfirrmann grading, disc narrowing, upper/lower endplate defects, upper/lower marrow changes, spondylolisthesis, and central canal stenosis. We report near human performances across the eight gradings, and also visualize the evidence for these gradings localized on the original scans.	body of uterus;bone structure of spine;cns disorder;computer multitasking;convolution;convolutional neural network;histopathologic grade;imagery;internationalization and localization;intervertebral disc structure;loss function;numerous;pathology;performance;sagittal plane;spondylolisthesis;text corpus	Amir Jamaludin;Timor Kadir;Andrew Zisserman	2017	Medical image analysis	10.1016/j.media.2017.07.002	artificial intelligence;computer vision;pattern recognition;convolutional neural network;architecture;mathematics;spondylolisthesis;sagittal plane;visualization;vertebra;lumbar;intervertebral disc	Vision	30.50260582835224	-75.92314928256015	151901
7051503717c1104cbd5e7429282497276d551f91	a new automatic segmentation method for lung tumor based on suv threshold on 18f-fdg pet images	tumors image segmentation positron emission tomography lungs heart biochemistry cancer;image segmentation;tumours;positron emission tomography;lung;18 f fluorodeoxyglucose positron emission tomography automatic segmentation method suv threshold 18 f fdg pet images pet lung images radiotracer concentration lung tumor detection lung tumor segmentation standardized uptake value malignant tumors benign tumors tumor volume segmentation tumor extraction healthy tissues image noise image enhancement iterative thresholding method suv distribution image;image enhancement;feature extraction;medical image processing;thresholding suv pet images image segmentation;object detection;tumours feature extraction image enhancement image segmentation lung medical image processing object detection positron emission tomography	"""Heart metabolizes more glucose and """"light up"""" more brightly on PET lung images than other healthy or normal tissues and organs because of its constant pumping of blood and accumulation of radiotracer concentration. It affects the results of lung tumor detection and segmentation using the thresholding methods, which is the most used method currently. Standardized uptake value (SUV) on 18F-FDG PET images is an important indicator to differentiate malignant from benign tumors, and has been applied in tumor volume segmentation. However, some methods based on SUV have been shown unable to distinguish regions between tumor and heart. In this paper, we present a novel segmentation method based on SUV to extract the tumor alone from the background of healthy tissues and image noise. Firstly we use SUV to enhance the images and then apply an iterative thresholding method to get a coarse result. Secondly we label the fragmented parts and fuse them with the SUV distribution image, and then calculate the SUVmean for each part. Finally we use the maximum of SUV mean to locate the tumor region. The proposed method is compared with current segmentation methods on PET images. The results show that the new method is able to detect tumors in the background of heart effectively, and can potentially be used as a tool of automatic segmenting tumor from 18F-FDG PET images."""	functional discourse grammar;image noise;iterative method;light up (puzzle);polyethylene terephthalate;pumping (computer systems);standardized uptake value;thresholding (image processing);tree accumulation	Xin Ming;Yuanming Feng;Yu Guo;Chunmei Yang	2012	2012 IEEE International Conference on Virtual Environments Human-Computer Interfaces and Measurement Systems (VECIMS) Proceedings	10.1109/VECIMS.2012.6273223	computer vision;feature extraction;computer science;machine learning;image segmentation	Robotics	38.4948143680409	-75.45620066116345	152192
2137207bcd1683afa2977b3a897d56e2f323d1b3	bayesian inference for low rank spatiotemporal neural receptive fields		The receptive field (RF) of a sensory neuron describes how the neuron integrates sensory stimuli over time and space. In typical experiments with naturalistic or flickering spatiotemporal stimuli, RFs are very high-dimensional, due to the large number of coefficients needed to specify an integration profile across time and space. Estimating these coefficients from small amounts of data poses a variety of challenging statistical and computational problems. Here we address these challenges by developing Bayesian reduced rank regression methods for RF estimation. This corresponds to modeling the RF as a sum of space-time separable (i.e., rank-1) filters. This approach substantially reduces the number of parameters needed to specify the RF, from 1K-10K down to mere 100s in the examples we consider, and confers substantial benefits in statistical power and computational efficiency. We introduce a novel prior over low-rank RFs using the restriction of a matrix normal prior to the manifold of low-rank matrices, and use “localized” row and column covariances to obtain sparse, smooth, localized estimates of the spatial and temporal RF components. We develop two methods for inference in the resulting hierarchical model: (1) a fully Bayesian method using blocked-Gibbs sampling; and (2) a fast, approximate method that employs alternating ascent of conditional marginal likelihoods. We develop these methods for Gaussian and Poisson noise models, and show that low-rank estimates substantially outperform full rank estimates using neural data from retina and V1.	approximation algorithm;bayesian approaches to brain function;coefficient;computation;computational problem;experiment;flicker (screen);gibbs sampling;hierarchical database model;linear-nonlinear-poisson cascade model;low-pass filter;low-rank approximation;marginal model;markov chain monte carlo;mathematical optimization;neuron;rf modulator;radio frequency;sampling (signal processing);shot noise;sparse matrix;spatiotemporal pattern;the matrix;time complexity;times ascent	Mijung Park;Jonathan W. Pillow	2013			econometrics;machine learning;mathematics;statistics	ML	24.701542751016202	-74.86613622519948	152344
702cad20d0ae2abce9163781c9c996e601135adb	morphological classification: application to cardiac mri of tetralogy of fallot	cardiac disease;manifold learning;structural change;morphological classification;cardiac mri;normal control;support vector machine;tetralogy of fallot;computational anatomy	This paper presents an image-based classification method, and applies it to classification of cardiac MRI scans of individuals with Tetralogy of Fallot (TOF). Clinicians frequently diagnose cardiac disease by measuring the ventricular volumes from cardiac MRI scans. Interrater variability is a common issue with these measurements. We address this issue by proposing a fully automatic approach for detecting structural changes in the heart. We first extract morphological features of each subject by registering cardiac MRI scans to a template. We then reduce the size of the features via a nonlinear manifold learning technique. These low dimensional features are then fed into nonlinear support vector machine classifier identifying if the subject of the scan is effected by the disease. We apply our approach to MRI scans of 12 normal controls and 22 TOF patients. Experimental result demonstrates that the method can correctly determine whether subject is normal control or TOF with 91% accuracy.	clinical use template;galaxy morphological classification;heart diseases;heart ventricle;inter-rater reliability;isomap;liner device;mri scans;nonlinear dimensionality reduction;nonlinear system;pet/ct scan;patients;registration;scanning;sensor;spatial variability;support vector machine;tetralogy of fallot;x-ray microtomography;disease classification;manifold	Dong Hye Ye;Harold Litt;Christos Davatzikos;Kilian M. Pohl	2011	Functional imaging and modeling of the heart : ... International Workshop, FIMH ..., proceedings. FIMH	10.1007/978-3-642-21028-0_23	real-time mri;pathology;engineering;biological engineering;surgery	Vision	36.56096222296885	-78.96201297133312	152362
e03a6b506700d339efbf75c7547aa6507ec792ae	image classification from generalized image distance features: application to detection of interstitial disease in chest radiographs	multiple representation;radiology;interstitial lung disease;chest radiograph;image classification;image distance features;lung;radiography;medical image analysis;radiology diseases feature extraction image classification image representation lung medical image processing radiography;medical image;image representation;feature extraction;medical image processing;local per pixel features;roc curve;diseases;chest radiographs;image classification computer vision diseases radiography biomedical imaging pixel pathology lungs pattern recognition image representation;interstitial lung disease detection image classification image distance features chest radiographs medical image analysis pathology image representation local per pixel features;pathology;interstitial lung disease detection	One of the most important tasks in medical image analysis is to detect the absence or presence of disease in an image, without having precise delineations of pathology available for training. A novel method is proposed to solve such a classification task, based on a generalized representation of an image derived from local per-pixel features. From this representation, differences between images can be computed, and these can be used to classify the image requiring knowledge of only global image labels for training. It is shown how to construct multiple representations of one image to get multiple classification opinions and combine them to smooth over errors of individual classifiers. The performance of the method is evaluated on the detection of interstitial lung disease on standard chest radiographs. The best result is obtained for the combining classification scheme yielding an area under the ROC curve of 0.955	cellular automaton;image analysis;interstitial webpage;medical image computing;medical imaging;pixel;radiography;receiver operating characteristic	Yulia Arzhaeva;Bram van Ginneken;David M. J. Tax	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.682	computer vision;contextual image classification;feature detection;radiography;feature extraction;computer science;machine learning;receiver operating characteristic	Vision	34.49102738120858	-76.14692265060708	152493
b99385198d8daf188da90e7625978fe1c5f2b6e4	detection of glaucomatous change based on vessel shape analysis	optic nerve head;sensitivity and specificity;k nearest neighbor classifier;stereotaxic techniques;self organizing maps;sequential float forward search;optic disk;shape analysis;photography;classification;structural change;glaucoma open angle;artificial neural networks;risk factors;image interpretation computer assisted;intraocular pressure;registration;k nearest neighbor;self organized map;humans;optic nerve diseases;glaucoma;neural networks computer;visual field;retinal vessels;ocular hypertension;data classification;retinal imaging;forward search;wavelet coefficients;artificial neural network	Glaucoma, a leading cause of blindness worldwide, is a progressive optic neuropathy with characteristic structural changes in the optic nerve head and concomitant visual field defects. Ocular hypertension (i.e. elevated intraocular pressure without glaucoma) is the most important risk factor to develop glaucoma. Even though a number of variables, including various optic disc and visual field parameters, have been used in order to identify early glaucomatous damage, there is a need for computer-based methods that can detect early glaucomatous progression so that treatment to prevent further progression can be initiated. This paper is focused on the description of a system based on image processing and classification techniques for the estimation of quantitative parameters to define vessel deformation and the classification of image data into two classes: patients with ocular hypertension who develop glaucomatous damage and patients with ocular hypertension who remain stable. The proposed system consists of the retinal image preprocessing module for vessel central axis segmentation, the automatic retinal image registration module based on a novel application of self organizing maps (SOMs) to define automatic point correspondence, the retinal vessel attributes calculation module to select the vessel shape attributes and the data classification module, using an artificial neural network classifier, to perform the necessary subject classification. Implementation of the system to optic disc data from 127 subjects obtained by a fundus camera at regular intervals provided a classification rate of 87.5%, underscoring the value of the proposed system to assist in the detection of early glaucomatous change.	apache axis;area striata structure;artificial neural network;automatic identification and data capture;blood vessel tissue;cns disorder;class;color gradient;decision support system;disorder of the optic nerve;eye;gain;glaucoma;hypertensive disease;image analysis;image processing;image registration;liver damage;ocular hypertension;ophthalmology specialty;optic disk;optic nerve (gchq);optics;organizing (structure);patients;preprocessor;pulmonary hypertension;retina;schedule (document type);self-organization;self-organizing map;shape analysis (digital geometry);statistical classification;biologic segmentation;nervous system disorder	George K. Matsopoulos;Pantelis A. Asvestas;Kostas Delibasis;Nicolaos A. Mouravliansky;Thierry G. Zeyen	2008	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2007.11.003	computer vision;self-organizing map;biological classification;computer science;photography;machine learning;structural change;shape analysis;optics;k-nearest neighbors algorithm;risk factor;artificial neural network	ML	35.717384398218236	-76.07821693851376	152680
c7e3fcac54a5cb6a3b09963221102fc19130ec6e	multi-linguistic optical font recognition using stroke templates	image matching;visual databases character sets document image processing image classification image matching natural languages optical character recognition;optical character recognition;prior information;image classification;natural languages;multilinguistic optical font recognition;typeface;bayes decision rule;document image processing;stroke template classification;representative stroke template extraction;stroke shape;input text image;font database;image databases optical character recognition software shape image recognition text recognition skeleton optical filters character recognition spatial databases flowcharts;english fonts;character sets;english fonts multilinguistic optical font recognition stroke shape representative stroke template extraction typeface stroke template classification font database input text image bayes decision rule chinese fonts;decision rule;chinese fonts;visual databases	One of the essential distinctions between different fonts is their stroke shape. A method is presented to automatically extract representative stroke templates from a text image, which contains characters of the same typeface. The collected stroke templates are classified and saved to a font database. To recognize an unknown font for an input text image, a Bayes decision rule is used to determine which font entrant in the database provides the best matching to the unknown font. The experiment demonstrates that this approach can distinguish between Chinese and English fonts without the prior information of their script. Another advantage is that it can learn a new font very quickly. Forty fonts (twenty English and twenty Chinese) are used in our experiment. An average recognition accuracy of 97 percent can be achieved in the present system	ascii art	Hung-Ming Sun	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.824	computer vision;contextual image classification;speech recognition;character encoding;computer science;unicode font;typeface;pattern recognition;decision rule;natural language;optical character recognition	Vision	34.443527314160754	-66.14883700911552	152763
4794a5b7b9523c2fd421fdcbec69f54a9c319638	automated classification of liver disorders using ultrasound images	support vector machines;ultrasound;fatty liver disease;wavelet packet transform;heterogeneous liver	This paper presents a novel approach for detection of Fatty liver disease (FLD) and Heterogeneous liver using textural analysis of liver ultrasound images. The proposed system is able to automatically assign a representative region of interest (ROI) in a liver ultrasound which is subsequently used for diagnosis. This ROI is analyzed using Wavelet Packet Transform (WPT) and a number of statistical features are obtained. A multi-class linear support vector machine (SVM) is then used for classification. The proposed system gives an overall accuracy of ~95% which clearly illustrates the efficacy of the system.	co-occurrence matrix;effective method;fatty liver;incidence matrix;liver diseases;numerous;region of interest;spleen tissue;structure of cortex of kidney;support vector machine;wavelet analysis;wavelet packet decomposition	Fayyaz ul Amir Afsar Minhas;Durre Sabih;Mutawarra Hussain	2011	Journal of Medical Systems	10.1007/s10916-011-9803-1	support vector machine;computer vision;speech recognition;radiology;medicine;pathology;computer science;machine learning;ultrasound;wavelet packet decomposition	ML	34.29754828675971	-75.163182082308	153040
543c2913cac26f4129fc0817cbc16a6dc52431a4	the identification of powdery mildew spores image based on the integration of intelligent spore image sequence capture device	smoothing methods backpropagation crops feature extraction image colour analysis image enhancement image segmentation image sequences microorganisms neural nets object detection plant diseases;the image sequence capture device;automatic recognition the image sequence capture device powdery mildew spores image;image segmentation lighting feature extraction image sequences image enhancement neural networks image matching;automatic recognition;powdery mildew spores image identification bp neural network method binary image smoothing image enhancement graying illumination compensation feature extraction image segmentation image preprocessing automatic detection agricultural crops harmful bacteria spore image series intelligent spore image sequence capture device;powdery mildew spores image	The integration of intelligent spore image sequence capture device is designed for capturing spores and then generates a series of images. Powdery mildew spore is an extremely harmful bacteria spore in agricultural crops. This paper mainly introduced a new method which could realize the automatic detection of the powdery mildew spores. The new method mainly included pre-processing, image segmentation, feature extraction and identification. Pre-processing included illumination compensation, graying, image enhancement. Image segmentation included binary, image smoothing. Finally identification used BP neural network method. Training pictures used 155 pictures and the correct rate was 95.5%. Testing took 89 pictures, and the correct rate was 63.6%. The result proved the validity and correctness of this method.	spore	Danping Wang;Botao Wang;Yue Yan	2013		10.1109/IIH-MSP.2013.53	computer vision	Robotics	38.23306963860324	-68.378241386825	153228
10fa692d6cba6e3fe566983d498c9ee67f22dbec	detection of microcalcification clusters in mammograms using a difference of optimized gaussian filters	analisis imagen;processus gauss;cancerology;desviacion tipica;analyse amas;tumor maligno;mastografia;asymmetry;standard deviation;mammary gland;microcalcification;diagnostico;hombre;imagen nivel gris;asymetrie;classification;symetrie;symmetry;glandula mamaria;cluster analysis;mammographie;microcalcificacion;filter;cancerologie;image niveau gris;human;ecart type;pattern recognition;filtre;asimetria;image analysis;analisis cluster;tumeur maligne;glande mammaire;cancerologia;reconnaissance forme;gaussian process;mammography;reconocimiento patron;simetria;proceso gauss;diagnosis;grey level image;analyse image;breast cancer;filtro;clasificacion;malignant tumor;homme;diagnostic	Since microcalcification clusters are primary indicators of malignant types of breast cancer, its detection is important to prevent and treat the disease. This paper proposes a method for detection of microcalcification clusters in mammograms using sequential Difference of Gaussian filters (DoG). In a first stage, fifteen DoG filters are applied sequentially to extract the potential regions, and later, these regions are classified using the following features: absolute contrast, standard deviation of the gray level of the microcalcification and a moment of contour sequence (asymmetry coefficient). Once the microcalcifications are detected, two approaches for clustering are compared. In the first one, several microcalcification clusters are detected in each mammogram. In the other, all microcalcifications are considered in a single cluster. We demonstrate that the diagnosis based on the detection of several microcalcification clusters in a mammogram is more efficient than considering a single cluster including all the microcalcifications in the image.	cluster analysis;coefficient;difference of gaussians;grayscale	Samuel Oporto-Díaz;Rolando R. Hernández-Cisneros;Hugo Terashima-Marín	2005		10.1007/11559573_121	computer vision;image analysis;biological classification;filter;computer science;breast cancer;gaussian process;mathematics;symmetry;cluster analysis;standard deviation;asymmetry;statistics	NLP	37.136856055066325	-74.4975318352873	153242
a7cf001555fcc24d9886a936f08e2a75c314e183	intelligent information system for interpretation of dermatoglyphic patterns of down's syndrome in infants	intelligent information system;automatic processing;dermatoglyphic prints enhancement;pattern classification;image processing;dermatoglyphic pattern;dermatoglyphic print;svm multi-class system;pattern recognition algorithm;dermatoglyphic index;one-vs-one scheme	intelligent information system;automatic processing;dermatoglyphic prints enhancement;pattern classification;image processing;dermatoglyphic pattern;dermatoglyphic print;svm multi-class system;pattern recognition algorithm;dermatoglyphic index;one-vs-one scheme	information system	Hubert Wojtowicz;Wieslaw Wajs	2012		10.1007/978-3-642-28490-8_30	computer vision;speech recognition;artificial intelligence	Logic	34.43019884255463	-72.83687469139636	153350
59893697f01bdf0f88e08dc345da0c93ab96a564	hemorrhage detection and segmentation in traumatic pelvic injuries	hemorrhage;support vector machines;arteries;pelvis;reproducibility of results;models statistical;algorithms;pattern recognition automated;humans;bone and bones;radiographic image interpretation computer assisted;tomography x ray computed	Automated hemorrhage detection and segmentation in traumatic pelvic injuries is vital for fast and accurate treatment decision making. Hemorrhage is the main cause of deaths in patients within first 24 hours after the injury. It is very time consuming for physicians to analyze all Computed Tomography (CT) images manually. As time is crucial in emergence medicine, analyzing medical images manually delays the decision-making process. Automated hemorrhage detection and segmentation can significantly help physicians to analyze these images and make fast and accurate decisions. Hemorrhage segmentation is a crucial step in the accurate diagnosis and treatment decision-making process. This paper presents a novel rule-based hemorrhage segmentation technique that utilizes pelvic anatomical information to segment hemorrhage accurately. An evaluation measure is used to quantify the accuracy of hemorrhage segmentation. The results show that the proposed method is able to segment hemorrhage very well, and the results are promising.	bone tissue;ct scan;cessation of life;decision making;emergence;gradient;grayscale;hemorrhage;large;logic programming;mathematical optimization;memory segmentation;patients;pelvic inflammatory disease;pixel;region growing;segmentation action;segmentation fault;x-ray computed tomography;biologic segmentation	Pavani Davuluri;Jie Wu;Yang Tang;Charles Cockrell;Kevin Ward;Kayvan Najarian;Rosalyn Hobson Hargraves	2012		10.1155/2012/898430	support vector machine;radiology;medicine;pathology;computer science;machine learning;algorithm;surgery	Vision	37.56051546102644	-79.18716268777422	153714
97b5452c13cf2737b683e826afd6d2ae8ffeb954	efficient detection of mesial temporal sclerosis using hippocampus and csf features in mri images		Mesial temporal sclerosis (MTS) is one of the most common pathological abnormalities associated with temporal lobe epilepsy. Prompt identification of MTS can determine surgical candidacy of a medically refractory epilepsy patient thus reducing morbidity and mortality. Traditionally, MTS is detected by visual inspection or manual quantification using structural brain MRI images based on characteristics such as the volume loss, shape variance and high intensities. However, it is a subjective process with inter-observer variance. In this paper, we propose an automated detection method for MTS based on brain MRI image analysis. It includes brain and hippocampus segmentation followed by extraction of volume, shape and CSF-ratio features from the 3D hippocampal images. Support vector machines are then used for MTS detection based on the extracted features. Experimental results show that the proposed technique provides promising performance in MTS detection.	acoustic lobing;feature extraction;image analysis;support vector machine;visual inspection	Huiquan Wang;S. Nizam Ahmed;Mrinal Mandai	2018	2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)	10.1109/BHI.2018.8333398	temporal lobe;hippocampus;image segmentation;hippocampal formation;feature extraction;epilepsy;segmentation;magnetic resonance imaging;artificial intelligence;pattern recognition;medicine	Vision	36.646367856574436	-78.52116991798088	153904
f5fb6f726632561024e9866a1714ca280ebca921	on the classification of congenital abnormalities from hand radiographs	congenital abnormalities	Abstract   Mathematical techniques for the computer classification of congenital abnormalities using metacarpophalageal lengths obtained from hand radiographs have been investigated. Discriminant analysis has been shown to be significantly better than similarity measures in distinguishing the normal condition, Down's syndrome, Turner's syndrome and achondroplasia from one another.	radiography	D. J. Landry;D. E. Raiside;J. J. Vanhoutte	1979	Pattern Recognition	10.1016/0031-3203(79)90039-6	computer science	Vision	30.81199148093819	-78.80872373966766	154058
dd44fcc91d3362bb9138fec64aca8641cd841185	weakly supervised fluid filled region localization in retinal oct scans		Retinal Optical Coherence Tomography (OCT) scans are an important diagnostic tool for ophthalmologists. These scans provide a cross-sectional view of the retina for ophthalmologists to detect abnormalities. A common type of abnormality found in these scans is a Fluid Filled Region (FFR). In this paper, we present a method to simultaneously classify and localize FFRs within retinal OCT scans using a specialized Convolutional Neural Network (CNN). The training data is weakly labeled, with only an indication of whether a scan contains FFRs or not. We compare different architectures to see which ones give us the best localization and classification metrics. We have found that architectures using Dense Blocks and Scaled Exponential Unit (SeLU) activations give us the best localizations with a Mean Average Precision (mAP) of 0.75 on true positive images and a classification accuracy of 94.8%.	convolutional neural network;cross-sectional data;information retrieval;mean squared error;precision and recall;tomography	Shahrukh Athar;Abhishek Vahadane;Ameya Joshi;Tathagato Rai Dastidar	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363849	computer vision;artificial intelligence;retina;convolutional neural network;pattern recognition;computer science;optical coherence tomography;training set;retinal	Vision	30.84232048608031	-75.86435453763455	154121
1e9617a1a27ef2f6115e07b6059997aed01a91d1	automatic quantitative assessment of the small bowel motility with cine-mri sequence analysis	automatic contour initialization;motility;small bowel;quantitative assessment;moving benchmark line	The contour of small bowel segment is informative for the quantitative assessment of its motility. Contour detection requires initial contour for Level Set Method in every MR image of Cine-MRI sequences. Manual initialization is a time-consuming and labor-intensive task, which may hamper its clinical uses. We proposed to generate initial contour automatically for a whole Cine-MRI sequence, which only needs radiologist's interaction in the first MR image. Furthermore a moving benchmark line strategy is proposed to improve the accuracy. Experimental results demonstrate that the proposed method can detect desired small bowel segment's contour correctly and outperform traditional methods in low contrast situation.	sequence analysis	Xing Wu;Shaojian Zhuo;Wu Zhang	2013		10.1007/978-3-642-41914-0_2	computer vision;simulation;quantitative research;computer science;motility	Logic	38.066140617956904	-79.9289450494977	154215
24bf42df1b6ec1a5d86bc7c29cd4dab10913ec64	bayesian network structure learning and inference methods for handwriting	structure learning;belief networks;computational complexity bayesian network structure learning inference methods handwriting directed probabilistic graphical models probabilistic queries bn structure learning problem np hard problem chi squared tests directed edges log loss united states cursive writing hand printing probability of random correspondence conditional prc;document handling;probability;forensics bayesian networks structure learning;probability belief networks computational complexity document handling inference mechanisms;inference mechanisms;computational complexity;bayes methods joints probabilistic logic forensics writing sociology statistics;forensics;bayesian networks	Probabilistic models of characteristics of handwritten words are useful in forensic document examination since they can be used to answer queries such as: determine the rarity of a given style of writing of the word, find the probability of observing those characteristics in a representative database of given size, etc. The task considered here is to use a training set of samples of a word written by a representative population of individuals (with each individual's writing of the word being described by a fixed set of discrete categorical variables), to construct directed probabilistic graphical models (Bayesian networks or BNs) and then use such models to answer probabilistic queries. However, since the BN structure learning problem is NP-hard, we propose an approximate method and analyze its performance and complexity. The proposed algorithm uses a local measure of deviance from independence (chi-squared tests between pairs of variables) and a global score (log-loss). The method builds the BN structure incrementally, by adding directed edges with high deviance and choosing the edge direction to minimize log-loss. The method is evaluated with samples of the word and obtained from a representative population of the United States with descriptive characteristic sets that are different for cursive writing and for hand-printing. For several samples obtained from the BN, the probability of random correspondence (PRC) is inferred. A measure of the discriminatory power of the characteristic set (conditional PRC) is also determined. The computational complexity of determining the probability of finding a similar one to a given sample, within a tolerance, in a database of given size, is discussed.	adobe framemaker;approximation algorithm;bayesian network;causality;chi-squared target models;computational complexity theory;directed graph;exploit (computer security);graphical model;np-hardness;population;printing;relevance;requirement;test set	Mukta Puri;Sargur N. Srihari;Yi Tang	2013	2013 12th International Conference on Document Analysis and Recognition	10.1109/ICDAR.2013.267	speech recognition;computer science;machine learning;pattern recognition;probability;bayesian network;data mining;graphical model;forensic science;computational complexity theory;statistics	AI	27.111466104559426	-67.2598601509439	154656
57d5999531ea9e705770582a77e0a33d032922e4	fuzzy algorithm for segmentation of images in extraction of objects from mri	medical image processing biological tissues biomedical mri fuzzy set theory image colour analysis image segmentation;image segmentation pathology magnetic resonance imaging image color analysis algorithm design and analysis histograms interpolation;image histogram fuzzy logics matlab image segmentation object detection;tissue structures fuzzy algorithm image segmentation mri segmentation method magnetic resonance imaging articular tissues knee images physicians articular cartilage brightness scale colour map tissue density membership function image density colour spectrum	The paper discusses a suitable segmentation method for extraction of specific objects from Magnetic Resonance Imaging (MRI). A particular attention is paid to detection and extraction of articular tissues from knee images. This is a pressing issue for physicians because MRI reveals often damage to articular cartilage which is shown by a minor change in a brightness scale. The image segmentation can provide a detailed colour map which shows distribution of the tissue densities. This algorithm is based on detection of local extremes in histogram and uses a membership function in order to allocate each image density into an output set. Each such set is given a colour from a predefined colour spectrum. This procedure can easily differentiate between the tissue structures based on the tissue densities.	algorithm;image segmentation;resonance	Jan Kubicek;Marek Penhaker	2014	2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2014.6968264	image texture;computer vision;feature detection;binary image;segmentation-based object categorization;pattern recognition;mathematics;region growing;image segmentation;scale-space segmentation	Vision	38.04425049657348	-75.57323003895311	154711
0d81009ebac470693f8684e04294571b1cfb7ed3	deciphering egyptian hieroglyphs: towards a new strategy for navigation in museums	object recognition;region identification;edge detection;egyptian hieroglyphs	This work presents a novel strategy to decipher fragments of Egyptian cartouches identifying the hieroglyphs of which they are composed. A cartouche is a drawing, usually inside an oval, that encloses a group of hieroglyphs representing the name of a monarch. Aiming to identify these drawings, the proposed method is based on several techniques frequently used in computer vision and consists of three main stages: first, a picture of the cartouche is taken as input and its contour is localized. In the second stage, each hieroglyph is individually extracted and identified. Finally, the cartouche is interpreted: the sequence of the hieroglyphs is established according to a previously generated benchmark. This sequence corresponds to the name of the king. Although this method was initially conceived to deal with both high and low relief writing in stone, it can be also applied to painted hieroglyphs. This approach is not affected by variable lighting conditions, or the intensity and the completeness of the objects. This proposal has been tested on images obtained from the Abydos King List and other Egyptian monuments and archaeological excavations. The promising results give new possibilities to recognize hieroglyphs, opening a new way to decipher longer texts and inscriptions, being particularly useful in museums and Egyptian environments. Additionally, devices used for acquiring visual information from cartouches (i.e., smartphones), can be part of a navigation system for museums where users are located in indoor environments by means of the combination of WiFi Positioning Systems (WPS) and depth cameras, as unveiled at the end of the document.	benchmark (computing);computer vision;contain (action);decipher prostate cancer test;depth map;drawings (art);egyptian language;extraction;global positioning system;hertz (hz);image analysis;kinect;mandibular right second molar tooth;navigation;personal digital assistant;personality character;physical object;pixel;rgd;router (computing);scott continuity;server (computer);server (computing);skeleton;smartphone;stage level 2;web server;wireless access point;sensor (device)	Jaime Duque Domingo;Pedro Javier Herrera;Enrique Valero;Carlos Cerrada	2017		10.3390/s17030589	edge detection;telecommunications;egyptian hieroglyphs;computer science;engineering;cognitive neuroscience of visual object recognition;nanotechnology;optics	HCI	37.94322039684837	-69.77610181414691	154723
fac241662aca4d0147ee62f4d8394a8b692ce5ae	breast tumor analysis in dynamic contrast enhanced mri using texture features and wavelet transform	breast tumors;wavelet analysis;discrete wavelet transform;image segmentation;support vector machines;receiver operator characteristic;edge detection;pixel classification;tumours;image classification;wavelet transform breast cancer dynamic contrast enhanced mri texture analysis;texture features;image texture;wavelet transforms;dynamic contrast enhanced;texture analysis;wavelet transform;sensitivity analysis;roc analysis;roc analysis breast tumor analysis dynamic contrast enhanced mri magnetic resonance imaging mr image artifacts textural feature temporal sequence pixel by pixel classification breast region segmentation active contour model pixel block textural change three scale discrete wavelet transform frequency feature extraction progressive feature selection scheme support vector machines image classification;magnetic resonance imaging;pixel;robust method;breast tumors magnetic resonance imaging wavelet analysis wavelet transforms discrete wavelet transforms system testing image texture analysis protocols breast cancer pixel;dynamic contrast enhanced mri;robustness;feature selection;support vector machine;breast cancer;active contour model;wavelet transforms biomedical mri edge detection image classification image segmentation image texture sensitivity analysis support vector machines tumours;biomedical mri	Dynamic contrast enhanced MRI (DCE-MRI) is an emerging imaging protocol in locating, identifying and characterizing breast cancer. However, due to image artifacts in MR, pixel intensity alone cannot accurately characterize the tissue properties. We propose a robust method based on the temporal sequence of textural change and wavelet transform for pixel-by-pixel classification. We first segment the breast region using an active contour model. We then compute textural change on pixel blocks. We apply a three-scale discrete wavelet transform on the texture temporal sequence to further extract frequency features. We employ a progressive feature selection scheme and a committee of support vector machines for the classification. We trained the system on ten cases and tested it on eight independent test cases. Receiver-operating characteristics (ROC) analysis shows that the texture temporal sequence (Az: 0.966 and 0.949 in training and test) is much more effective than the intensity sequence (Az: 0.871 and 0.868 in training and test). The wavelet transform further improves the classification performance (Az: 0.989 and 0.984 in training and test).	active contour model;discrete wavelet transform;feature selection;pixel;receiver operating characteristic;support vector machine;test case;visual artifact	Jianhua Yao;Jeremy Chen;Catherine Chow	2009	IEEE Journal of Selected Topics in Signal Processing	10.1109/JSTSP.2008.2011110	support vector machine;computer vision;computer science;magnetic resonance imaging;machine learning;pattern recognition;feature selection;receiver operating characteristic;wavelet transform	Vision	36.72057048001898	-74.75569609171201	154730
4146978a55d9e0d1c67d9c79da0f25662c90ac5a	skin lesions diagnosis based on fluorescence image processing: simple parameters scanning	skin lesion;secuencial;fluorescence;sequential;piel;image processing;viability;peau;fluorescence imaging;basal cell carcinoma;skin;dispositif balayage;diagnostico;procesamiento imagen;viabilite;exploracion;traitement image;scanning device;viabilidad;fluorescencia;dispositivo barrido;vecino mas cercano;sequentiel;balayage;plus proche voisin;nearest neighbour;k nearest neighbour;scanning;diagnosis;discriminacion;discrimination;diagnostic	This paper studies the viability of a skin lesion diagnosis scheme based on fluorescence images. Three kinds of skin lesions are considered: actinitic keratosis, basal cell carcinoma and psoriasis. A wide and diverse set of simple parameters have been extracted and their discrimination potential is evaluated through an automatic diagnosis scheme based on the k-nearest neighbours. We use a sequential scanning technique that automatically selects the most relevant parameters for the addressed problem.	image processing	Eduardo Ros Vidal;M. M. Rodríguez;Sonia Mota;José Luis Bernier;Ignacio Rojas;Carlos García Puntonet;Elmar Wolfgang Lang	2003		10.1007/978-3-540-44871-6_99	computer vision;discrimination;image processing;fluorescence;computer science;fluorescence-lifetime imaging microscopy;skin	Graphics	37.148032373238415	-74.80118290883358	154989
ecd5ef4042a6c71eba718738ab8d8479f7c2458d	computer-aided diagnosis of mammographic masses using geometric verification-based image retrieval	computer aided diagnosis;breast;computer programming;mammography;breast cancer;image retrieval	Computer-Aided Diagnosis of masses in mammograms is an important indicator of breast cancer. The use of retrieval systems in breast examination is increasing gradually. In this respect, the method of exploiting the vocabulary tree framework and the inverted file in the mammographic masse retrieval have been proved high accuracy and excellent scalability. However it just considered the features in each image as a visual word and had ignored the spatial configurations of features. It greatly affect the retrieval performance. To overcome this drawback, we introduce the geometric verification method to retrieval in mammographic masses. First of all, we obtain corresponding match features based on the vocabulary tree framework and the inverted file. After that, we grasps the main point of local similarity characteristic of deformations in the local regions by constructing the circle regions of corresponding pairs. Meanwhile we segment the circle to express the geometric relationship of local matches in the area and generate the spatial encoding strictly. Finally we judge whether the matched features are correct or not, based on verifying the all spatial encoding are whether satisfied the geometric consistency. Experiments show the promising results of our approach.	image retrieval	Qingliang Li;Weili Shi;Huamin Yang;Huimao Zhang;Guoxin Li;Tao Chen;Kensaku Mori;Zhengang Jiang	2017		10.1117/12.2255799	computer vision;image retrieval;breast cancer;computer programming	Vision	39.06290658238233	-69.80684394761742	155424
fd92ad18615662c8f9a7c1435615ea2b9f7eb895	computer aided detection of breast masses from digitized mammograms	diagnostic medical informatique;image segmentation;seno;mastografia;localizacion objeto;object location;segmentation;breast;detection objet;breast masses;mammographie;segmentation image;sein;computer aided detection;mammography;localisation objet;medical diagnostic computing;breast cancer;object detection	In this paper, an automated computer-aided-detection scheme is proposed to identify and locate the suspicious masses in the abnormal breasts from the full mammograms. Mammograms are examined using a four-stage detection method including pre-processing, identification of local maxima, seeded region-growing, and false positive (FP) reduction. This method has been applied to the entire Mammographic Image Analysis Society (MIAS) database of 322 digitized mammograms containing 59 biopsy-proven masses in 56 images. Results of detection show 95% true positive (TP) fraction at 1.9 FPs per image for the 56 images and 1.3 FPs per image for the entire database.		Han Zhang;Say Wei Foo	2006	IEICE Transactions	10.1093/ietisy/e89-d.6.1955	computer vision;computer science;breast cancer;image segmentation;segmentation	Vision	37.022862631671224	-75.12591531367043	155517
d95adec73461f64d0e2cd72431419fdd52baea52	medical image categorization based on gaussian mixture model	mixture model medical image categorization gaussian;ct image categorization;medical image processing computerised tomography image classification image texture;computed tomography;neural networks;information science;image shape;gaussian;bayesian methods;image classification;biomedical imaging;testing;image texture;medical image categorization;gaussian mixture model;biomedical engineering;shape;medical image;mixture model;medical image processing;image intensity;computerized tomography;computerised tomography;biomedical imaging medical diagnostic imaging neural networks shape computed tomography biomedical engineering biomedical informatics information science testing bayesian methods;classification accuracy;biomedical informatics;bayesian principle;computerized tomography medical image categorization gaussian mixture model image texture image shape image intensity characteristic vectors bayesian principle ct image categorization;medical diagnostic imaging;categorization;characteristic vectors	In this paper we present an approach for medical image categorization based on Gaussian mixture model. There are distinct differences on texture, shape and intensity characteristics among the images of different parts of body. Considering of the features of the Gaussian mixture model , first we extract the characteristic vectors of the training image set to learn the class model for each class , then categorize the test image using the Bayesian principle. The experimental results indicate that the method performs very well on CT image categorization. We achieved classification accuracy up to 97% in the experiment.	ct scan;categorization;co-occurrence matrix;database;document-term matrix;experiment;google map maker;mixture model;standard test image;texture mapping	Dong Yin;Jia Pan;Peng Chen;Rong Zhang	2008	2008 International Conference on BioMedical Engineering and Informatics	10.1109/BMEI.2008.210	image texture;computer vision;information science;computer science;machine learning;pattern recognition;mixture model;artificial neural network	Vision	35.963310049060375	-71.81212914636373	155579
c72745788fd540f4789da82240ead1f166653c33	an accurate segmentation method for white blood cell images	white blood cell;biology computing;mathematical morphology;blood smear images;disease diagnosis white blood cell images accurate segmentation method automated cell count project simple thresholding approach initial labels pixels algorithm priori information blood smear images shape detection method large regional information blood cell structure local context information unsharp boundaries;context information;white blood cell images;image segmentation;shape detection method;initial labels;local context information;biological techniques blood cellular biophysics image segmentation medical image processing diseases mathematical morphology biology computing;blood cell structure;algorithm;morphology;disease diagnosis;automated cell count project;shape;image edge detection;large regional information;unsharp boundaries;medical image processing;blood;pixel;simple thresholding approach;pixels;priori information;diseases;lighting;image segmentation white blood cells cells biology shape image edge detection laboratories pixel lighting morphology red blood cells;biological techniques;blood cells;accurate segmentation method;cellular biophysics;red blood cells;cells biology;white blood cells	Abslrocl-This paper describes a part of our research work on an Automated Cell Count project. A major requirement for this project is an efficient method to segment cell images. This work presents an accurate segmentation method for automatic count of white blood cells. First a simple thresholding approach is applied to give initial labels to pixels in the blood cell images. The algorithm i s based on priori information about blood smear images. Then the labels are adjusted with a shape detection method based on large regional context information to produce meaningful results. This approach makes use of knowledge of the blood cell structure. The experimental result shows that this method Is more powerful than traditional methods that use only local context information. It can perform accurate segmentation of white blood cells even ifthey have uosharp boundaries.	algorithm;pixel;smear campaign;thresholding (image processing)	Qingmin Liao;Yingying Deng	2002		10.1109/ISBI.2002.1029239	computer vision;pathology;morphology;computer science;pixel;computer graphics (images)	ML	38.64308675853147	-75.47195074213217	155587
03884a9581446859bb31e4d8c73fa3b70184666e	a volumetric convolutional neural network for brain tumor segmentation		Brain cancer can be very fatal, but chances of survival increase through early detection and treatment. Doctors use Magnetic Resonance Imaging (MRI) to detect and locate tumors in the brain, and very carefully analyze scans to segment brain tumors. Manual segmentation is time consuming and tiring for doctors, and it can be difficult for them to notice extremely small abnormalities. Automated segmentations performed by computers offer quicker diagnoses, the ability to notice small details, and more accurate segmentations. Advances in deep learning and computer hardware have allowed for high-performing automated segmentation approaches. However, several problems persist in practice: increased training time, class imbalance, and low performance. In this paper, I propose applying V-Net, a volumetric, fully convolutional neural network, to segment brain tumors in MRI scans from the BraTS Challenges. With this approach, I achieve a whole tumor dice score of 0.89 and train the network in a short time while addressing class imbalance with the use of a dice loss layer. Then, I propose applying an existing technique to improve automated segmentation performance in practice.	artificial neural network;computer hardware;convolutional neural network;deep learning;resonance	Ryan Sherman	2018	CoRR			Vision	32.038365928312125	-76.19312879077779	155632
33bcc76fba9b669d94648f93fbc339cb7fd2e529	a universal image forensic strategy based on steganalytic model	steganalysis;universal forensics;tampering detection	Image forensics have made great progress during the past decade. However, almost all existing forensic methods can be regarded as the specific way, since they mainly focus on detecting one type of image processing operations. When the type of operations changes, the performances of the forensic methods usually degrade significantly. In this paper, we propose a universal forensics strategy based on steganalytic model. By analyzing the similarity between steganography and image processing operation, we find that almost all image operations have to modify many image pixels without considering some inherent properties within the original image, which is similar to what in steganography. Therefore, it is reasonable to model various image processing operations as steganography and it is promising to detect them with the help of some effective universal steganalytic features. In our experiments, we evaluate several advanced steganalytic features on six kinds of typical image processing operations. The experimental results show that all evaluated steganalyzers perform well while some steganalytic methods such as the spatial rich model (SRM) [4] and LBP [19] based methods even outperform the specific forensic methods significantly. What is more, they can further identify the type of various image processing operations, which is impossible to achieve using the existing forensic methods.	experiment;image processing;local binary patterns;performance;pixel;sensor;steganography	Xiaoqing Qiu;Haodong Li;Weiqi Luo;Jiwu Huang	2014		10.1145/2600918.2600941	computer vision;steganalysis;computer science;computer security;statistics	ML	34.07883488359555	-69.19839105804797	155713
aa2f7ea7caeff72d47f821390ef92d81102bfba3	vector quantization distortion of medical ultrasound features	tissue characterization;ultrasound;first order;tree structure;fatty liver;vector quantizer;second order statistics;covariance matrix;principal component	Pruned-tree structured vectored quantization (PTSVQ) was applied to the lower five gray scale remapped bits of normal and fatty ultrasound liver images. The upper bits were compressed reversibly. This combination of techniques is termed PTSVQ with splitting. The effect of the compression on the difference in texture between normal and fatty liver images was studied at different compression rates and distortions. The changes in texture were measured by changes in the principal components of the covariance matrix of image vectors. The vectors were the same size as those used in the compression technique. There were clear differences in the components of normal and fatty liver images. These differences were largely removed by the PTSVQ with splitting technique even at average single pixel distortions several times smaller than the image noise. These results suggest that the effect of compression on second order statistics should be measured when evaluating algorithms in addition to the first order average distortion.	algorithm;citrus aurantifolia tree ab.ige:acnc:pt:ser:qn;compression;distortion;fatty liver;grayscale;image noise;medical ultrasound;pixel;quantization (signal processing);reversible computing;small;tree (descriptive set theory);vector quantization	Brian H. Krasner;Shih-Chung Ben Lo;Seong Ki Mun	1993	Journal of Digital Imaging	10.1007/BF03168489	computer vision;covariance matrix;speech recognition;radiology;medicine;computer science;pattern recognition;first-order logic;ultrasound;mathematics;tree structure;statistics;principal component analysis	Graphics	37.63215336309881	-73.69536154376256	155727
96c252f32d8af265fef51d22dee76e16519bf294	deeplung: 3d deep convolutional nets for automated pulmonary nodule detection and classification		In this work, we present a fully automated lung CT cancer diagnosis system, DeepLung. DeepLung contains two parts, nodule detection and classification. Considering the 3D nature of lung CT data, two 3D networks are designed for the nodule detection and classification respectively. Specifically, a 3D Faster R-CNN is designed for nodule detection with a U-net-like encoder-decoder structure to effectively learn nodule features. For nodule classification, gradient boosting machine (GBM) with 3D dual path network (DPN) features is proposed. The nodule classification subnetwork is validated on a public dataset from LIDC-IDRI, on which it achieves better performance than state-of-the-art approaches, and surpasses the average performance of four experienced doctors. For the DeepLung system, candidate nodules are detected first by the nodule detection subnetwork, and nodule diagnosis is conducted by the classification subnetwork. Extensive experimental results demonstrate the DeepLung is comparable to the experienced doctors both for the nodule-level and patient-level diagnosis on the LIDC-IDRI dataset.	3d television;best, worst and average case;encoder;gradient boosting;mesa;modality (human–computer interaction);subnetwork;unified framework	Wentao Zhu;Chaochun Liu;Wei Fan;Xiaohui Xie	2017	CoRR		gradient boosting;subnetwork;biology;bioinformatics	ML	31.33118527333673	-75.35325343760827	155735
a5cf24e2fd271a9cf7db2453d9e3717b1afb9ba7	detection of immunocytological markers in photomicroscopic images	cervix;cervical cancer	Early detection of cervical cancer can be achieved through visual analysis of cell anomalies. The established PAP smear achieves a sensitivity of 50–90%, most false negative results are caused by mistakes in the preparation of the specimen or reader variability in the subjective, visual investigation. Since cervical cancer is caused by human papillomavirus (HPV), the detection of HPV-infected cells opens new perspectives for screening of precancerous abnormalities. Immunocytochemical preparation marks HPV-positive cells in brush smears of the cervix with high sensitivity and specificity. The goal of this work is the automated detection of all marker-positive cells in microscopic images of a sample slide stained with an immunocytochemical marker. A color separation technique is used to estimate the concentrations of the immunocytochemical marker stain as well as of the counterstain used to color the nuclei. Segmentation methods based on Otsu’s threshold selection method and Mean Shift are adapted to the task of segmenting marker-positive cells and their nuclei. The best detection performance of single marker-positive cells was achieved with the adapted thresholding method with a sensitivity of 95.9%. The contours differed by a modified Hausdorff Distance (MHD) of 2.8 μm. Nuclei of single marker positive cells were detected with a sensitivity of 95.9% and MHD = 1.02 μm.	biological specimen;fiducial marker;hausdorff dimension;heart rate variability;mean shift;otsu's method;password authentication protocol;sensitivity and specificity;smear campaign;thresholding (image processing)	David Friedrich;Joschka zur Jacobsmühlen;Till Braunschweig;André A. Bell;Kraisorn Chaisaowong;Ruth Knüchel-Clarke;Til Aach	2012		10.1117/12.911796	physics	Vision	37.22839181309169	-76.61812714051396	155979
35af6d334ed6562cc1eb86b8feb233d41f785c79	an improved segmentation of online english handwritten text using recurrent neural networks	handwriting recognition;text analysis;decision support systems;pattern analysis;text recognition;context	Segmentation of online handwritten text recognition is better to employ the dependency on context of strokes written before and after it. This paper shows an application of Bidirectional Long Short-term Memory recurrent neural networks for segmentation of on-line handwritten English text. The networks allow incorporating long-range context from both forward and backward directions to improve the confident of segmentation over uncertainty. We show that applying the method in the semi-incremental recognition of online handwritten English text reduces up to 62% of waiting time, 50% of processing time. Moreover, recognition rate of the system also improves remarkably by 3 points from 71.7%.	artificial neural network;long short-term memory;online and offline;optical character recognition;recurrent neural network;semiconductor industry	Cuong Tuan Nguyen;Masaki Nakagawa	2015	2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)	10.1109/ACPR.2015.7486489	speech recognition;computer science;machine learning;pattern recognition	NLP	32.60787888992362	-66.76411569137068	156432
540933a2858483f2e71eea58026d011fb4bba040	a boosted bayesian multiresolution classifier for prostate cancer detection from digitized needle biopsies	decision tree classifier;second order;cancer detection;gabor filter features;belief networks;image features;boosted bayesian multiresolution classifier;digitized needle biopsies;biopsy needle;bayesian classifier;whole slide image;classifier ensemble;image resolution;ensemble method;cancer;digital pathology;cad;supervised classification;male;bayes theorem;bayesian methods;image classification;microscopy;prostate cancer diagnosis;gabor filters;quantification;multiple resolution levels;receiver operating characteristic curve;bayesian method;first order statistical features;tissue samples;algorithms bayes theorem biopsy needle humans image interpretation computer assisted male prostatic neoplasms;gabor filter;adaboost ensemble method;first order;digitized glass slides;prostatic neoplasms;image interpretation computer assisted;biopsy;feature extraction;medical image processing;computer aided algorithms;random forest;prostate cancer detection;computerized image analysis program;computer aided detection cad;gleason grading algorithm;needles belief networks biomedical optical imaging cad cancer computerised instrumentation decision trees feature extraction gabor filters image classification image resolution medical image processing;diseases;computer aided detection;algorithms;image analysis;efficiency analysis;feature selection;digitized histology images;humans;classification tree analysis;computerised instrumentation;feature selection boosted bayesian multiresolution classifier prostate cancer detection digitized needle biopsies prostate cancer diagnosis tissue samples digital pathology computer aided algorithms digitized glass slides digitized histology images computerized image analysis program gleason grading algorithm whole slide image image pyramid multiple resolution levels image features first order statistical features gabor filter features adaboost ensemble method multiple decision tree classifiers image resolutions;biomedical optical imaging;histology	Diagnosis of prostate cancer (CaP) currently involves examining tissue samples for CaP presence and extent via a microscope, a time-consuming and subjective process. With the advent of digital pathology, computer-aided algorithms can now be applied to disease detection on digitized glass slides. The size of these digitized histology images (hundreds of millions of pixels) presents a formidable challenge for any computerized image analysis program. In this paper, we present a boosted Bayesian multiresolution (BBMR) system to identify regions of CaP on digital biopsy slides. Such a system would serve as an important preceding step to a Gleason grading algorithm, where the objective would be to score the invasiveness and severity of the disease. In the first step, our algorithm decomposes the whole-slide image into an image pyramid comprising multiple resolution levels. Regions identified as cancer via a Bayesian classifier at lower resolution levels are subsequently examined in greater detail at higher resolution levels, thereby allowing for rapid and efficient analysis of large images. At each resolution level, ten image features are chosen from a pool of over 900 first-order statistical, second-order co-occurrence, and Gabor filter features using an AdaBoost ensemble method. The BBMR scheme, operating on 100 images obtained from 58 patients, yielded: 1) areas under the receiver operating characteristic curve (AUC) of 0.84, 0.83, and 0.76, respectively, at the lowest, intermediate, and highest resolution levels and 2) an eightfold savings in terms of computational time compared to running the algorithm directly at full (highest) resolution. The BBMR model outperformed (in terms of AUC): 1) individual features (no ensemble) and 2) a random forest classifier ensemble obtained by bagging multiple decision tree classifiers. The apparent drop-off in AUC at higher image resolutions is due to lack of fine detail in the expert annotation of CaP and is not an artifact of the classifier. The implicit feature selection done via the AdaBoost component of the BBMR classifier reveals that different classes and types of image features become more relevant for discriminating between CaP and benign areas at different image resolutions.	adaboost;algorithm;area under curve;bayesian analysis;bayesian network;class;computation;core needle biopsy;decision tree;ensemble kalman filter;feature selection;first-order predicate;gabor filter;gleason's theorem;histopathologic grade;image analysis;malignant neoplasm of prostate;microscope device component;naive bayes classifier;patients;pixel;prostate carcinoma;prostatic neoplasms;pyramid (image processing);random forest;receiver operating characteristic;slide (glass microscope);time complexity	Scott Doyle;Michael D. Feldman;John E. Tomaszeweski;Anant Madabhushi	2012	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2010.2053540	computer vision;image analysis;image resolution;bayesian probability;computer science;microscopy;machine learning;pattern recognition;histology;feature selection	Vision	34.355279355808726	-77.02643213984852	156796
0ecea6c5a967c8a707a5141cd0c85433809f8668	an automated, segmentation-based, rigid registration system for cervigram/spl trade/ images utilizing simple clustering and active contour techniques	region of interest;image registration;fourier method;adverse effect;segmentation;fourier transforms;process development;image analysis;image segmentation;biomedical imaging;clustering algorithms;gynaecology;active contour;clustering;computer vision	In this article, a technique for the automated registration of Cervigram/spl trade/ images will be introduced. The motivation for the development of such a technique is warranted by the fact that registration is often a first step to other, more sophisticated, algorithms useful in medical applications. Such algorithms are typically processes developed for the tracking and monitoring of patient health. The registration described in this article is segmentation-based and utilizes a combination of clustering- and active contour-based methodologies. The clustering algorithm is used to obtain an initial contour that will subsequently serve as initialization for an active contour. The active contour, in conjunction with various internal and external forces, should converge to a more precise segmentation of the region of interest which, in this application, is the cervix. Once the segmentations are completed, more traditional registration techniques, such as those of Fourier or correlation-based techniques, may be used to register the segmented images with more accuracy as the adverse effects stemming from the highly variable background features are no longer a source of error. For illustration purposes, the results from two patients are demonstrated at the end of this article.	active contour model;algorithm;cluster analysis;contour line;converge;region of interest;stemming	Philip S. King;Sunanda Mitra;Brian Nutter	2004	Proceedings. 17th IEEE Symposium on Computer-Based Medical Systems	10.1109/CBMS.2004.1311730	fourier transform;computer vision;process development execution system;adverse effect;computer science;image registration;pattern recognition;active contour model;image segmentation;computer graphics (images);region of interest	Vision	39.07225962338428	-76.87318937918904	157029
a78d02dd2a2feddbf2dd50b9418b9a54793c513a	neural network synthesis of spin echo multiecho sequences	magnetic resonance image;image synthesis;image generation;spin echo;clinical practice;artificial neural network;neural network	Spin echo multiecho sequences are not frequently used in clinical practice, because they allow the observation of one single slice, imaged at different echo times, for each acquisition. To limit examination time, multislice sequences that include only images derived from one or two echoes are usually acquired. Nevertheless, the strong T2 dependence of multiecho sequences can be used effectively to enhance the contrast between tissues with different T2 and to gather useful diagnostic information. Artificial neural networks can offer new interesting facilities to the radiologist. In fact, the learning capabilities of neural networks allow them to extract the prototypical behavior of a system from a set of examples. After learning, artificial neural networks can emulate the system behavior even in the presence of new inputs, as far as these are not too different from those included in the training set. A conveniently trained neural network can synthesize a multiecho sequence for each slice of a multislice sequence, requiring only two images for each slice to achieve reliable results. When compared with a true multiecho sequence, the images generated by the network preserve the contrast characteristics of the original ones and have a better signal-to-noise (SNR) ratio. In this paper we report the results achieved by using a neural network to reconstruct synthetic spin echo multiecho images of the brain.	artificial neural network;body tissue;cns disorder;network synthesis filters;radiology;signal-to-noise ratio;spin echo;synthetic intelligence;test set	Stefano Cagnoni;Davide Caramella;Raffaella De Dominicis;Guido Valli	1992	Journal of Digital Imaging	10.1007/BF03167832	spin echo;radiology;medicine;computer science;artificial intelligence;nuclear medicine;artificial neural network	ML	32.61661529366715	-79.5829632352826	157130
25289ab928a504a18436d81b0e8696bcf7e86385	optimal biopsy protocols for prostate cancer	lung cancer;biopsies;ultrasound;low resolution;false negative;skin cancer;digital rectal examination;optimization;early detection;public health;prostate cancer	Prostate cancer is the second leading cause of cancer-related death among American men. Biopsy for prostate cancer is a procedure known as transrectal ultrasound-guided needle biopsy. Because of the low resolution of ultrasound, the urologist cannot usually distinguish between cancerous and healthy tissue. For this reason, most biopsies follow standard protocols based on long-term experience of physicians. Recent studies indicate that these protocols have a significant rate of false negative diagnoses. In this research we use real prostate specimens removed by prostatectomy to develop a 3-D distribution map of cancer in the prostate, and use this to develop optimized biopsy procedures. The new procedures have the potential to increase the rate of early detection of prostate cancer, and thus decrease the rate of mortality.	experience;image resolution;thematic map;video-in video-out;yao graph;on-line system	Ariela Sofer;Jianchao Zeng;Seong Ki Mun	2003	Annals OR	10.1023/A:1022974221137	mathematical optimization;image resolution;public health;ultrasound	ML	35.37229493137586	-79.38165099013855	157163
160f5f9792ba489a4c6e988ec2b892bf9c5dc4d3	machining process classification using pca reduced histogram features and the support vector machine	histograms;machining;kernel;support vector machines;training;turning machining grinding lapping machining milling production engineering computing support vector machines;artificial neural networks;surface treatment;support vector machines artificial neural networks kernel histograms machining surface treatment training;shaping machining process classification pca reduced histogram features support vector machine machining processes manufacturing production image processing computer vision technologies automated identification inspection time svm classifier turning grinding horizontal milling vertical milling lapping;artificial nueral networks machined surface gray level histogram principal component analysis texture classification support vector machine	Being able to identify machining processes that produce specific machined surfaces is crucial in modern manufacturing production. Image processing and computer vision technologies have become indispensable tools for automated identification with benefits such as reduction in inspection time and avoidance of human errors due to inconsistency and fatigue. In this paper, the Support Vector Machine (SVM) classifier with various kernels is investigated for the categorization of machined surfaces into the six machining processes of Turning, Grinding, Horizontal Milling, Vertical Milling, Lapping, and Shaping. The effectiveness of the gray-level histogram as the discriminating feature is explored. Experimental results suggest that the SVM with the linear kernel provides superior performance for a dataset consisting of 72 workpiece images.	categorization;computer vision;experiment;grayscale;heart rate variability;image processing;noise shaping;support vector machine	Mohammed Waleed Ashour;Fatimah Khalid;Alfian Abdul Halin;Lili Nurliyana Abdullah	2015	2015 IEEE International Conference on Signal and Image Processing Applications (ICSIPA)	10.1109/ICSIPA.2015.7412226	support vector machine;computer vision;kernel;machining;computer science;machine learning;histogram;mathematics;artificial neural network	Robotics	35.5023285211874	-70.08061542780916	157180
1426392b67737711ccc0ba6399890f5130d6892f	a novel computerized tool to stratify risk in carotid atherosclerosis using kinematic features of the arterial wall	design automation;support vector machines biomedical ultrasonics blood vessels diseases feature extraction feature selection image classification kinematics medical image processing;arteries;kinematics;accuracy;principal component analysis;support vector machine classification;design automation kinematics arteries accuracy principal component analysis support vector machine classification;image classification carotid atherosclerosis patient safety kinematic features computer aided diagnosis motion based cad tool atherosclerotic plaque arterial wall asymptomatic patients fisher discriminant ratio feature selection support vector machines texture based cad performance image data driven diagnosis	Valid characterization of carotid atherosclerosis (CA) is a crucial public health issue, which would limit the major risks held by CA for both patient safety and state economies. This paper investigated the unexplored potential of kinematic features in assisting the diagnostic decision for CA in the framework of a computer-aided diagnosis (CAD) tool. To this end, 15 CAD schemes were designed and were fed with a wide variety of kinematic features of the atherosclerotic plaque and the arterial wall adjacent to the plaque for 56 patients from two different hospitals. The CAD schemes were benchmarked in terms of their ability to discriminate between symptomatic and asymptomatic patients and the combination of the Fisher discriminant ratio, as a feature-selection strategy, and support vector machines, in the classification module, was revealed as the optimal motion-based CAD tool. The particular CAD tool was evaluated with several cross-validation strategies and yielded higher than 88% classification accuracy; the texture-based CAD performance in the same dataset was 80%. The incorporation of kinematic features of the arterial wall in CAD seems to have a particularly favorable impact on the performance of image-data-driven diagnosis for CA, which remains to be further elucidated in future prospective studies on large datasets.	carotid atherosclerosis;computer assisted diagnosis;computer-aided design;cross reactions;cross-validation (statistics);discriminant;feature selection;patients;plaque, atherosclerotic;prospective search;senile plaques;silo (dataset);support vector machine	Aimilia Gastounioti;Stavros Makrodimitris;Spyretta Golemati;Nikolaos P. E. Kadoglou;Christos D. Liapis;Konstantina S. Nikita	2015	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2014.2329604	computer vision;kinematics;electronic design automation;computer science;accuracy and precision;statistics;principal component analysis	ML	33.435367537615946	-77.72216632663425	157619
09a6ea080a810296ff23aeaeb5998a1f2791c98b	a hierarchical method for block segmentation and classification of general document images	documento;metodologia;image processing;structure document;well structured document;procesamiento imagen;document structure analysis;segmentation;classification;traitement image;methodologie;document;analyse structure;structured document;pattern recognition;document image processing;block classification;block segmentation;pretraitement;reconnaissance forme;reconocimiento patron;methodology;documentation segmentation system;clasificacion;segmentacion;pretreatment;pretratamiento	Abstract#R##N##R##N#In a document analysis system, block segmentation and block classification are very important. The former segments a particular document image into homogeneous rectangular blocks. The latter classifies the segmented blocks into categories. These classified blocks may then be processed by suitable recognition systems. In this paper, we formalize the structure styles of general documents, and then propose both a robust hierarchical method of block segmentation and a simple method of block classification. The proposed block segmentation method takes a top-down hierarchical approach based on the spatial features and formalized concepts of document structure. This method is essentially independent of the document style, and can perform a type of structural analysis of the document image. The classification approach is based on a new scheme of statistical textual features, and classifies the segmented blocks into four categories: text blocks, title letter blocks, line drawing (or graphics) blocks, and halftone phonograph blocks. The proposed approaches were implemented using the C programming language in an X-Window environment under the UNIX operating system. The performance of each approach was experimentally evaluated, for both effectiveness and computational efficiency, using actual test images.		Young Seak Park;Tsuyoshi Ebina;Akira Ito	1993	Systems and Computers in Japan	10.1002/scj.4690240909	computer vision;speech recognition;image processing;biological classification;computer science;pattern recognition;methodology;data mining;segmentation	NLP	35.95758987396544	-67.32904533930969	157635
6afddc28559250f8c23965856b4b217104ef6eca	mri-based semi-automatic pelvimetry measurement for pelvic organ prolapse diagnosis	patient diagnosis;multiscale analysis pelvimetry measurements mri wavelets first derivatives;multiscale analysis;orthopaedics;pelvimetry measurements;image edge detection magnetic resonance imaging approximation methods surgery joints wavelet analysis image segmentation;medical image processing;patient diagnosis biomedical measurement biomedical mri medical image processing orthopaedics;mri;first derivatives;biomedical measurement;wavelets;radiologic evaluation mri based semiautomatic pelvimetry measurement pelvic organ prolapse diagnosis magnetic resonance imaging pelvimetry measurements mr images multiscale wavelet analysis pelvic bone structure dynamic mr studies;biomedical mri	Magnetic resonance imaging (MRI) pelvimetry measurements are useful in the diagnosis of pelvic organ prolapse given the inaccuracy of clinical examination. However, MRI measurements are currently performed manually and can be inconsistent, time-consuming and inaccurate. In this paper, we present a scheme for semi-automatic measurements on MR images based on multi scale wavelet analysis. The experiments on the MR images show that the presented scheme can detect the points of reference on the pelvic bone structure to determine the lines needed for the assessment of pelvic organ prolapse. This may lead towards more accurate and faster pelvic organ prolapse diagnosis on dynamic MR studies, and possible screening procedures for predicting predisposition to pelvic organ prolapse by radiologic evaluation of pelvimetry measurements.	disk staging;experiment;graph (discrete mathematics);map;pedal keyboard;predispositioning theory;radiology;resonance;semiconductor industry;wavelet	Sinan Onal;Susana K. Lai-Yuen;Stuart Hart;Paul Bao;Alfredo Weitzenfeld	2012	2012 11th International Conference on Information Science, Signal Processing and their Applications (ISSPA)	10.1109/ISSPA.2012.6310663	wavelet;magnetic resonance imaging;statistics	Robotics	39.0260802790002	-80.05700843621976	158026
31383892dbd6fbfdc73da7bf3cda42a50700f6cb	knowledge-based adaptive thresholding segmentation of digital subtraction angiography images	adaptive thresholding;adaptive threshold;prior knowledge;the busyness;three dimensional reconstruction;vessel segmentation;digital subtraction angiography;knowledge base	Vessel segmentation is the base of three dimensional reconstruction on digital subtraction angiography (DSA) images. In this paper we propose two simple but efficient methods of vessel segmentation for DSA images. The original DSA image is divided into several appropriate subimages according to a prior knowledge of the diameter of vessels. We introduce the vessels existence measure to determine whether each subimage contains vessels and then choose an optimal threshold, respectively, for every subimage previously determined to contain vessels. Finally, an overall binarization of the original image is achieved by combining the thresholded subimages. Experiments are implemented on cerebral and hepatic DSA images. The results demonstrate that our proposed methods yield better binary results than global thresholding methods and some other local thresholding methods do. 2006 Elsevier B.V. All rights reserved.	binary image;thresholding (image processing)	Nong Sang;Heng Li;Weixue Peng;Tianxu Zhang	2007	Image Vision Comput.	10.1016/j.imavis.2006.07.026	computer vision;knowledge base;computer science;mathematics;thresholding	Vision	37.68091479941786	-75.84337622651675	158049
6c3bebd34b5754ff892c4887684f8fe61c6464e5	multispectral texture analysis of histopathological abnormalities in colorectal tissues	indexes;decision support systems	This paper proposes to use texture features extracted from multispectral microscopic images to detect histopathological abnormalities related to colorectal cancer (CRC): stroma (ST), benign hyperplasia (BH), intraepithelial neoplasia (IN) and carcinoma (Ca). Texture features, based on gray-level co-occurrence matrices (GLCM) and discrete wavelets (DW), are obtained from colon biopsy images, captured using 16 different bands of the visible spectrum. A random forest classifier is used to evaluate the usefulness of these texture features, for each spectral band, on the task of discriminating between the four types of abnormal tissue. Preliminary results on the data of 39 CRC patients show that such features, in particular those based on GLCM and Symlet wavelets, can accurately predict the type of CRC tissue (94% accuracy, 88% sensibility and 100% specificity for Symlet features in the 16th spectral band). These results also reveal important differences in the textural information captured in each band, which could be used to develop more efficient procedures for the diagnosis of CRC.	co-occurrence matrix;colon classification;cyclic redundancy check;dreamwidth;multispectral image;random forest;sensitivity and specificity;strömberg wavelet;symlet;x86	Ahmad Chaddad;Christian Desrosiers;Lama Hassan;Matthew Toews	2016	2016 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2016.7532835	database index;computer vision;speech recognition;computer science	Robotics	34.429582735726264	-74.7463720798102	158070
a86caf824eddc1430d2de98c83ed9deae4b852c2	survey of computer-aided diagnosis of thyroid nodules in medical ultrasound images		In medical science, diagnostic imaging is an invaluable tool because of restricted observation of the specialist and uncertainties in medical knowledge. A thyroid ultrasound is a non-invasive imaging study used to understand the anatomy of thyroid gland which is not possible with other techniques. Various classifiers are used to characterize thyroid nodules into benign/malignant based on the extracted features to make correct diagnosis. Current classification approaches are reviewed with classification accuracy for thyroid ultrasound image applications. The aim of this paper is to review existing approaches for the diagnosis of Nodules in thyroid ultrasound images.		Deepika Koundal;Savita Gupta;Sukhwinder Singh	2012		10.1007/978-3-642-31552-7_47	radiology	AI	34.11711100761406	-78.53011133473976	158216
546ccaaff6ad6ddd725ddd6fc5d72c7c866db176	a robust real-timed recognizer of printed chinese characters	systeme temps reel;methode branch and bound;decision tree;image processing;real time;sistema informatico;aproximacion;procesamiento imagen;computer system;chino;arbol decision;classification;traitement image;approximation;branch and bound method;reconnaissance caractere;metodo branch and bound;pattern recognition;real time system;systeme informatique;sistema tiempo real;reconnaissance forme;reconocimiento patron;chinois;chinese;character recognition;arbre decision;clasificacion;reconocimiento caracter	-A Bayes recognizer supporting 3770 printed (non-simplified) Chinese characters with sizes no smaller than 2.5 mm 2 in various fonts has been built with an overall recognition rate of 96~o on characters found in general printed materials. These characters, according to their usage frequencies, are divided into two sets and two decision trees, one for each set, which are used to reduce the recognition time by factors of 21 and 3, respectively. These two sets together include over 99.9~o of the characters one can find in any piece of text. Storage requirement for the entire recognition system amounts to 4.2 MB at any one time while the system throughput is 20 characters per second running on an IBM RS 6000/320 workstation. Such a performance compares favorably against any printed Chinese character recognizer known today and the key to success lies in the partitioning of the characters according to their usage frequencies and a branch and bound tree search algorithm with likelihood metric. Pattern recognition Large pattern set recognition Printed Chinese character recognition	branch and bound;decision tree;finite-state machine;optical character recognition;pattern recognition;printer (computing);printing;search algorithm;throughput;tree traversal;workstation	Pak-Kwong Wong;Chorkin Chan	1992	Pattern Recognition	10.1016/0031-3203(92)90022-B	image processing;computer science;artificial intelligence;approximation;decision tree;pattern recognition;chinese;algorithm	AI	33.93599904850154	-67.93555943357299	158280
c26e2a39a0cdd6c8177b8beb068b66f9e99449b9	automatic classification of micro-organisms by shape and color, in water quality control: a preliminary study	water quality;automatic classification	Automatic segmentation and classification of stained micro-organism images in micrographs are investigated. To discriminate such ellipse-like shapes, a moment based method shows higher reliability than the perimeter based method. A ‘multi-threshold-expansion algorithm’ is successfully applied to segmentation of areas which have darkly stained cores and lightly stained surroundings.		Johji Tajima	1981	Pattern Recognition	10.1016/0031-3203(81)90065-0	computer vision;computer science;pattern recognition	Vision	37.17863310746389	-68.26266428341516	158312
cc814a0be7ba591587446083199de4a46cdc634f	automatic detection of microaneurysms in color fundus images	criteria based operators;computer assisted diagnosis;mathematical morphology;diameter opening;threshold scheme;attribute opening;density estimation;image enhancement;automatic detection;lesion detection;diabetic retinopathy;kernel density estimate;eye disease;shade correction;microaneurysm detection;false positive	This paper addresses the automatic detection of microaneurysms in color fundus images, which plays a key role in computer assisted diagnosis of diabetic retinopathy, a serious and frequent eye disease. The algorithm can be divided into four steps. The first step consists in image enhancement, shade correction and image normalization of the green channel. The second step aims at detecting candidates, i.e. all patterns possibly corresponding to MA, which is achieved by diameter closing and an automatic threshold scheme. Then, features are extracted, which are used in the last step to automatically classify candidates into real MA and other objects; the classification relies on kernel density estimation with variable bandwidth. A database of 21 annotated images has been used to train the algorithm. The algorithm was compared to manually obtained gradings of 94 images; sensitivity was 88.5% at an average number of 2.13 false positives per image.	addresses (publication format);channel (digital image);closing (morphology);computer assisted diagnosis;diabetic retinopathy;diameter (qualifier value);disorder of eye;extraction;exudate;hemorrhage;histopathologic grade;image editing;kernel density estimation;large;microaneurysm;physical object;population;retinal diseases;sdha wt allele;secret sharing;sensor;algorithm	Thomas Walter;Pascale Massin;Ali Erginay;Richard C. Ordonez;Clotilde Jeulin;Jean-Claude Klein	2007	Medical image analysis	10.1016/j.media.2007.05.001	kernel density estimation;computer vision;mathematical morphology;density estimation;type i and type ii errors;computer science;mathematics;statistics;computer graphics (images)	Vision	36.78221156643664	-75.83415326980627	158402
699737f491200bd13d439201f26f1a83a3894ad2	hard exudates detection method based on background-estimation		Hard exudates (HEs) are one kind of the most important symptoms of Diabetic Retinopathy (DR). A new method based on background-estimation for hard exudates detection is presented. Firstly, through background-estimation, foreground map containing all bright objects is acquired. We use the edge information based on Kirsch operator to obtain HE candidates, and then we remove the optic disc. Finally, the shape features, histogram statistic features and phase features of the HE candidates are extracted. We use the SVM classifier to acquire the accurate extraction of HEs. The proposed method has been demonstrated on the public databases of DIARETDB1 and HEI-MED. The experiment results show that the method’s sensitivity is 97.3 % and the specificity is 90 % at the image level, and the mean sensitivity is 84.6 % and the mean predictive value is 94.4 % at the lesion level.		Zhitao Xiao;Feng Li;Lei Geng;Fang Zhang;Jun Wu;Xinpeng Zhang;Long Su;Chunyan Shan;Zhenjie Yang;Yuling Sun;Yu Xiao;Weiqiang Du	2015		10.1007/978-3-319-21963-9_33	support vector machine;pattern recognition;kirsch operator;hard exudates;computer vision;optic disc;statistic;artificial intelligence;computer science;classifier (linguistics);histogram	Logic	35.79147743702277	-75.1394214827608	158882
5339208ac2e6b63115cbbdb016dea2f5713dc565	evaluation of supervised vs. non supervised databases for hand geometry identification	operant conditioning;image database;image acquisition;infrared	In this paper, we describe two different hand image databases. One has been acquired in laboratory condition with a document scanner, and the other one in operational conditions using a webcam and an infrared filter. The experimental part describes some identification experiments and extracts relevant conclusions about image acquisition and biometric classification	biometrics;database;emoticon;epoch (reference date);experiment;hand geometry;image scanner;mad;open platform communications;supervised learning;webcam	Marcos Faúndez-Zanuy;Joan Fabregas;Miguel Angel Ferrer-Ballester;Carlos Manuel Travieso-González;Jesús B. Alonso	2006	Proceedings 40th Annual 2006 International Carnahan Conference on Security Technology	10.1007/978-3-540-73007-1_136	computer vision;speech recognition;infrared;computer science;operant conditioning;pattern recognition	Robotics	36.38217600478332	-68.27360312439559	158888
75aedffb70b4b8573b217e3b152be58774cf20bd	a joint multi-scale convolutional network for fully automatic segmentation of the left ventricle		Left ventricle (LV) segmentation is crucial for quantitative analysis of the cardiac contractile function. In this paper, we propose a joint multi-scale convolutional neural network to fully automatically segment the LV. Our method adopts two kinds of multi-scale features of cardiac magnetic resonance (CMR) images, including multi-scale features directly extracted from CMR images with different scales and multi-scale features constructed by intermediate layers of standard CNN architecture. We take advantage of these two strategies and fuse their prediction results to produce more accurate segmentation results. Qualitative results demonstrate the effectiveness and robustness of our method, and quantitative evaluation indicates our method achieves LV segmentation with higher accuracy than state-of-the-art approaches.	artificial neural network;convolutional neural network;logical volume management;resonance	Qianqian Tong;Zhiyong Yuan;Xiangyun Liao;Mianlun Zheng;Weixu Zhu;Guian Zhang;Munan Ning	2017	2017 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2017.8296855	computer vision;artificial intelligence;convolutional neural network;pattern recognition;robustness (computer science);architecture;feature extraction;ventricle;computer science;segmentation;image segmentation	Vision	31.302735484600937	-75.53195292560572	159051
ed3bec6b70e40360aee113523c3a1ee780058647	texture feature extraction methods for microcalcification classification in mammograms	databases;transformation ondelette;glandula mamaria patologia;female;informatica biomedical;biomedical data processing;differential diagnostic;performance evaluation;image processing;analisis textura;cancer;tumor maligno;estudio comparativo;extraction forme;mammary gland;microcalcification;informatique biomedicale;procesamiento imagen;hombre;texture features;algoritmo genetico;classification;traitement image;glandula mamaria;etude comparative;texture analysis;wavelet transform;hembra;microcalcificacion;extraccion forma;receiver operating characteristic curves;feature extraction;human;comparative study;algorithme genetique;true positive;roc curve;mammary gland diseases;diagnostico diferencial;genetic algorithm;k nearest neighbor;genetic algorithms;tumeur maligne;glande mammaire;transformacion ondita;femelle;mammography;metodo roc;false positive;methode roc;analyse texture;pattern extraction;wavelets;clasificacion;extraction method;wavelet transformation;diagnostic differentiel;glande mammaire pathologie;malignant tumor;homme	We present development, application, and performance evaluation of three different texture feature extraction methods for classification of benign and malignant microcalcifications in mammograms. The steps of the work accomplished are as follows. (1) A total of 103 regions containing microcalcifications were selected from a mammographic database. (2) For each region, texture features were extracted using three approaches: co-occurrence based method of Haralick; wavelet transformations; and multi-wavelet transformations. (3) For each set of texture features, most discriminating features and their optimal weights were found using a real-valued genetic algorithm (GA) and a training set. For each set of features and weights, a KNN classifier and a malignancy criterion were used to generate the corresponding ROC curve. The malignancy of a given sample was defined as the number of malignant neighbors among its K nearest neighbors. The GA found a population with the largest area under the ROC curve. (4) The best results obtained using each set of features were compared. The best set of features generated areas under the ROC curve ranging from 0.82 to 0.91. The multi-wavelet method outperformed the other two methods, and the wavelet features were superior to the Haralick features. Among the multi-wavelet methods, redundant initialization generated superior results compared to non-redundant initialization. For the best method, a true positive fraction larger than 0.85 and a false positive fraction smaller than 0.1 were obtained.© (2000) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	feature extraction	Hamid Soltanian-Zadeh;Siamak Pourabdollah-Nezhad;Farshid Rafiee Rad	2000		10.1117/12.387602	speech recognition;artificial intelligence;pattern recognition;mathematics	NLP	36.697235181931966	-74.47828964093713	159224
79c94c5d1632167bb6751f4d2a98e400a58662bf	automatic segmentation and measurement of vasculature in retinal fundus images using probabilistic formulation	software;sensitivity and specificity;probability;normal distribution;bayes theorem;fundus oculi;image processing computer assisted;diagnosis computer assisted;retina;reproducibility of results;algorithms;humans;databases factual;retinal vessels;automation	The automatic analysis of retinal blood vessels plays an important role in the computer-aided diagnosis. In this paper, we introduce a probabilistic tracking-based method for automatic vessel segmentation in retinal images. We take into account vessel edge detection on the whole retinal image and handle different vessel structures. During the tracking process, a Bayesian method with maximum a posteriori (MAP) as criterion is used to detect vessel edge points. Experimental evaluations of the tracking algorithm are performed on real retinal images from three publicly available databases: STARE (Hoover et al., 2000), DRIVE (Staal et al., 2004), and REVIEW (Al-Diri et al., 2008 and 2009). We got high accuracy in vessel segmentation, width measurements, and vessel structure identification. The sensitivity and specificity on STARE are 0.7248 and 0.9666, respectively. On DRIVE, the sensitivity is 0.6522 and the specificity is up to 0.9710.	aspartate transaminase;blood vessel tissue;blood supply aspects;computer assisted diagnosis;database;edge detection;evaluation;experiment;gray platelet syndrome;grayscale;phenylephrine hydrochloride 10 mg oral tablet;sensitivity and specificity;structure of blood vessel of retina;algorithm;biologic segmentation;interest;width	Yi Yin;Mouloud Adel;Salah Bourennane	2013		10.1155/2013/260410	normal distribution;computer vision;computer science;automation;probability;mathematics;optics;bayes' theorem;statistics	Vision	37.605227943893766	-78.40801083269065	159253
eb3cb4d0b578d3c8643aa275e3d757565f96d92f	finding regions of interest in document images by planar hmm	document image processing optical character recognition handwritten character recognition cheque processing hidden markov models;hidden markov model;optical character recognition;cheque processing;hidden markov models;cheque images region finding document images planar hmm planar hidden markov models phmm stochastic approach legal amount check images;region of interest;document image processing;hidden markov models image segmentation stochastic processes text analysis image analysis automatic speech recognition lattices training data testing law;handwritten character recognition	We present a new stochastic approach based on Planar Hidden Markov Models (PHMM) for finding regions of Interest (ROI) in document images. The main advantage of the proposed approach is that no explicit rules characterizing the ROIs have to be defined. Instead, the PHMM learns to find the ROIs based on training data which show examples of document images together with the ROIs. The method has been tested on the task of finding the legal amount in real check images.	hidden markov model;markov chain;region of interest	J. Golenzer;Christian Viard-Gaudin;Pierre Michel Lallican	2002		10.1109/ICPR.2002.1047935	computer vision;speech recognition;computer science;machine learning;pattern recognition;optical character recognition;hidden markov model;region of interest	ML	33.90242911063141	-66.3748663671568	159269
6ff6ee1669045988855ef62238cd11a34d9ff538	perceptron error surface analysis: a case study in breast cancer diagnosis	tratamiento automatico;performance measure;aide diagnostic;glandula mamaria patologia;female;valor predictivo;radiodiagnostic;informatica biomedical;image numerique;biomedical data processing;computer aided diagnosis;tumor maligno;genie biomedical;mastografia;receiver operator characteristic;predictive value;mammary gland;erreur quadratique moyenne;informatique biomedicale;diagnostico;model performance;hombre;breast cancer diagnosis;error surface;glandula mamaria;radiodiagnostico;automatic processing;hembra;biomedical engineering;mammographie;receiver operating characteristic curves;mean square error;weighted space;imagen numerica;human;computer aid;roc curve;mammary gland diseases;asistencia ordenador;ingenieria biomedica;tumeur maligne;glande mammaire;digital image;valeur predictive;radiodiagnosis;femelle;error medio cuadratico;mammography;perceptron;reseau neuronal;metodo roc;traitement automatique;methode roc;diagnosis;high sensitivity;breast cancer;assistance ordinateur;red neuronal;diagnostic aid;glande mammaire pathologie;malignant tumor;homme;neural network;surface analysis;ayuda diagnostica;diagnostic	Perceptrons are typically trained to minimize mean square error (MSE). In computer-aided diagnosis (CAD), model performance is usually evaluated according to other more clinically relevant measures. The purpose of this study was to investigate the relationship between MSE and the area (A(z)) under the receiver operating characteristic (ROC) curve and the high-sensitivity partial ROC area ((0.90)A'(z)). A perceptron was used to predict lesion malignancy based on two mammographic findings and patient age. For each performance measure, the error surface in weight space was visualized. Comparison of the surfaces indicated that minimizing MSE tended to maximize A(z), but not (0.90)A'(z).		Mia K. Markey;Joseph Y. Lo;Rene Vargas-Voracek;Georgia D. Tourassi;Carey E. Floyd	2002	Computers in biology and medicine	10.1016/S0010-4825(01)00035-X	telecommunications;computer science;artificial intelligence;machine learning;receiver operating characteristic;artificial neural network;surgery	HCI	34.23280258377499	-78.48596705482568	159361
4742c5b991e4663ef4d3a68f75369acbee6c5b56	off-line verification of japanese signatures after elimination of background patterns	verification;background noise;signature analysis;arc pattern method;eliminacion;analyse signature;binary image;japonais;signature verification;traveler s cheque;image bruitee;imagen sonora;background elimination;japanese signature;noisy image;japanese signature verification;handwriting test;image binaire;imagen binaria;ruido fondo;traveler cheque;elimination;verificacion;bruit fond;japones;off line method;analisis firma;japanese	A system of off-line signature verification composed of a preprocessing stage and a verification stage is proposed in this paper. It is assumed that each signature is written on a surface with a background pattern and a sample of the background pattern is available. The preprocessing stage to eliminate the background pattern from a signature image consists of 5 steps: the position adjustment between a signature image and a background image, the filtering of the background pattern by local maximization, the clipping of random noises from the background pattern, the background elimination by transformation of the multilevel signature image to a binary signature image through subtraction and thresholding, and the smoothing for defects recovery and isolated noise elimination. The effect of the preprocessing operation is illustrated in figures. The verification stage following the preprocessing stage is based on the Arc Pattern Method proposed in Ref. 7. An experiment is performed to examine the performance of the proposed system. Twenty Japanese autographs, for which 20 authentic signatures, 10 genuine counter signatures and 10 forged counter signatures are provided, are used in the experiment. The experiment achieved an error rate of as low as approximately 14%.	signature	Isao Yoshimura;Mitsu Yoshimura	1994	IJPRAI	10.1142/S0218001494000371	japanese;verification;speech recognition;binary image;computer science;mathematics;background noise;algorithm;elimination	Logic	38.7226220543692	-66.26428932543585	159461
3fea73fb2c95731bd22a09370c24369b97499e92	detection of dead stained microscopic cells based on color intensity and contrast		Apoptosis is an imperative constituent of various processes including proper progression and functioning of the immune system, embryonic development as well as chemical-induced cell death. Improper apoptosis is a reason in numerous human/animal’s conditions involving ischemic damage, neurodegenerative diseases, autoimmune disorders and various types of cancer. An outstanding feature of neurodegenerative diseases is the loss of specific neuronal populations. Thus, the detection of the dead cells is a necessity. This paper proposes a novel algorithm to achieve the dead cells detection based on color intensity and contrast changes and aims for fully automatic apoptosis detection based on image analysis method. A stained cultures images using Caspase stain of albino rats hippocampus specimens using light microscope (total 21 images) were used to evaluate the system performance. The results proved that the proposed system is efficient as it achieved high accuracy (98.89 ± 0.76 %) and specificity (99.36 ± 0.63 %) and good mean sensitivity level of (72.34 ± 19.85 %).		Taras Kotyk;Nilanjan Dey;Amira S. Ashour;Cornelia Victoria Anghel Drugarin;Tarek Gaber;Aboul Ella Hassanien;Václav Snásel	2015		10.1007/978-3-319-26690-9_6	cell biology;cancer;apoptosis;immune system;caspase;programmed cell death;biology	EDA	36.82421686849153	-76.6318626412487	159656
98afb17fd980dbc29dbd7726c6b54a420e6ef3df	assessment of mass detection using tissue background information as input to a computer-assisted diagnosis scheme	analisis imagen;faux positif;glandula mamaria patologia;computer assisted diagnosis;female;analisis sensibilidad;radiodiagnostic;informatica biomedical;biomedical data processing;tissues;mastografia;mammary gland;informatique biomedicale;diagnostico;hombre;task difficulty;falso positivo;dificultad tarea;glandula mamaria;radiodiagnostico;performance improvement;difficulte tâche;hembra;medical diagnostics;mammographie;sensitivity analysis;tumor;medical image processing;human;computer aid;mammary gland diseases;analyse sensibilite;tumeur;computing systems;asistencia ordenador;image analysis;glande mammaire;index of difficulty;radiodiagnosis;femelle;mammography;false positive;diagnosis;analyse image;assistance ordinateur;glande mammaire pathologie;homme;diagnostic	The purpose of this study is to explore the potential application of region conspicuity as an index of difficulty for mass detection using computer-assisted diagnosis (CAD) schemes on mammograms and to assess the performance improvement of our own CAD scheme by incorporation of conspicuity as well as other features related to tissue background. Two independent image databases that contained 978 images were used to train and test the CAD scheme. Using a growth algorithm of three adaptive topographic layers, 592 positive mass regions and another 3,790 suspicious but actually negative regions were initially selected from these two image databases. For each region, a set of 21 image features was computed, including five features from surrounding tissue background. Using these image features as input data, an artificial neural network was employed to classify regions as positive or negative for masses. Both the area under the ROC curve and the false-positive detection rate at 80% sensitivity were used as indices of CAD performance. The experimental results demonstrated that region conspicuity could be used as an effective index of identification difficulty of suspicious mass regions. The performance of our own CAD scheme improves monotonously and substantially as the regions with lower conspicuity are removed from the training and testing databases. The experimental results also revealed that region conspicuity and other relevant image features extracted from surrounding tissue background carried independent, hence potentially useful, information in the identification of suspicious mass regions. In this experiment, a five percent increase in the area under the ROC curve, or a 15 percent reduction in the false-positive detection rate at a given sensitivity of 80 percent, was obtained after incorporating five tissue background-related features as input to the scheme.		Bin Zheng;Yuan-Hsiang Chang;Walter F. Good;David Gur	1998		10.1117/12.310888	simulation;pathology;engineering;biological engineering	Vision	34.57510249960205	-77.68313893338465	159692
6f9a76dccf28b01210935a2cecac97e4fcb6f6e5	joint segmentation and characterization of the dermis in 50 mhz ultrasound 2d and 3d images of the skin	characterization;dermatology;high-frequency ultrasound;level-set;nakagami distribution;nonlinear filter;recursive filter;segmentation;skin aging;ultrasound	Abstract We propose a novel joint segmentation and characterization algorithm for the assessment of skin aging using 50 MHz high-frequency ultrasound images. The proposed segmentation method allows a fine determination of the envelope signalu0027s statistics in the dermis as a function of depth. The sequence of statistical estimates obtained is then combined into a single aging score. The segmentation is based on tailored recursive non-linear filters. The epidermis and the dermis are jointly segmented with a non-parametric active contour combining a texture criterion, an epidermis indicator map and the geometric constraint of horizontal continuity. The algorithm is designed to apply to 2D and 3D images as well. We evaluated skin photo-aging on ultrasound images with an experimental study on a cohort of 76 women separated into 2 groups of different ages. Two aging scores are computed from the images: local dermal contrast and skin roughness. We show that these scores are much better at identifying the two groups (p-value ≈ 10 − 6 ) than the previously used MGVR indicator (p-value 0.046). Moreover, we find that a combined score more reliably evaluates skin photo-aging, with 84% success, than a scoring of the ultrasound images by 4 experts.	active contour model;algorithm;algorithmic trading;ambiguous name resolution;approximation;artificial neural network;behavior;deep learning;dermatologic disorders;dermis;epidermis;estimated;experiment;grayscale;inspiration function;large;megahertz;memory segmentation;neural network simulation;nonlinear system;p-value;preclinical imaging;recursion;relevance;scene statistics;score;scott continuity;segmentation action;seizures;silo (dataset);skin (computing);skin aging;variational principle;biologic segmentation	Bruno Sciolla;Jimmy Le Digabel;Gwendal Josse;Thibaut Dambry;Benoit Guibert;Philippe Delachartre	2018	Computers in biology and medicine	10.1016/j.compbiomed.2018.10.029	computer vision;skin aging;computer science;artificial intelligence;active contour model;ultrasound;skin roughness;pattern recognition;segmentation;dermis	Vision	32.15808944088802	-78.3473079510754	159733
8900fcdd50631d9b27dc640dc733983bc349b4a1	pruning the nodule candidate set in postero anterior chest radiographs		In this paper we describe and compare two different methods to reduce the cardinality of the set of candidates nodules, characterized by an high sensitivity ratio, and extracted from PA chest radiographs by a fully automatized method. The methods are a rule based system and a feed-forward neural network trained by back-propagation. Both the systems allow to recognize almost the 021 % of false positives without losing any true positives.	artificial neural network;backpropagation;feedforward neural network;radiography;rule-based system;software propagation	Paola Campadelli;Elena Casiraghi	2004		10.1007/1-4020-3432-6_5	pattern recognition;rule-based system;computer science;postero-anterior;pruning;artificial intelligence;cardinality;radiography;artificial neural network;support vector machine;false positive paradox	ML	31.809714185223534	-76.55115842752247	159764
3b49425163072a1e38af80f457ae192030265fec	genetic algorithms as a useful tool for trabecular and cortical bone segmentation	image segmentation;cortical bone;trabecular bone;genetic algorithms;ct scans	The aim of this study was to find a semi-automatic method of bone segmentation on the basis of computed tomography (CT) scan series in order to recreate corresponding 3D objects. So, it was crucial for the segmentation to be smooth between adjacent scans. The concept of graphics pipeline computing was used, i.e. simple graphics filters such as threshold or gradient were processed in a manner that the output of one filter became the input of the second one resulting in so called pipeline. The input of the entire stream was the CT scan and the output corresponded to the binary mask showing where a given tissue is located in the input image. In this approach the main task consists in finding the suitable sequence, types and parameters of graphics filters building the pipeline. Because of the high number of desired parameters (in our case 96), it was decided to use a slightly modified genetic algorithm. To determine fitness value, the mask obtained from the parameters found through genetic algorithms (GA) was compared with those manually prepared. The numerical value corresponding to such a comparison has been defined by Dice's coefficient. Preparation of reference masks for a few scans among the several hundreds of them was the only action done manually by a human expert. Using this method, very good results both for trabecular and cortical bones were obtained. It has to be emphasized that as no real border exists between these two bone types, the manually prepared reference masks were quite conventional and therefore charged with errors. As GA is a non-deterministic method, the present work also contains a statistical analysis of the relations existing between various GA parameters and fitness function. Finally the best sets of the GA parameters are proposed.		K. Janc;Jacek Tarasiuk;A. S. Bonnet;P. Lipinski	2013	Computer methods and programs in biomedicine	10.1016/j.cmpb.2013.03.012	computer vision;genetic algorithm;computer science;machine learning;image segmentation	Graphics	39.017423852886004	-76.05214534100686	159820
9b7e92921adad8eb62439976a757e3fb298f676c	burn depth analysis using multidimensional scaling applied to psychophysical experiment data	svm classifier comparison burn depth analysis psychophysical experiment data multidimensional scaling analysis burn depth diagnosis mathematical features physical characteristics analysis burn classification mds axes k nearest neighbor classifier principal component analysis support vector machine pca classifier comparison;burns color humans image interpretation computer assisted image processing computer assisted principal component analysis psychophysics skin support vector machines;image classification;image color analysis surgery cameras wounds skin correlation;multidimensional scaling mds burn color computer aided diagnosis cad tool k nearest neighbor k nn classifier;medical image processing;injuries;biomedical optical imaging;medical image processing biomedical optical imaging image classification injuries	In this paper a psychophysical experiment and a multidimensional scaling (MDS) analysis are undergone to determine the physical characteristics that physicians employ to diagnose a burn depth. Subsequently, these characteristics are translated into mathematical features, correlated with these physical characteristics analysis. Finally, a study to verify the ability of these mathematical features to classify burns is performed. In this study, a space with axes correlated with the MDS axes has been developed. 74 images have been represented in this space and a k-nearest neighbor classifier has been used to classify these 74 images. A success rate of 66.2% was obtained when classifying burns into three burn depths and a success rate of 83.8% was obtained when burns were classified as those which needed grafts and those which did not. Additional studies have been performed comparing our system with a principal component analysis and a support vector machine classifier. Results validate the ability of the mathematical features extracted from the psychophysical experiment to classify burns into their depths. In addition, the method has been compared with another state-of-the-art method and the same database.	burn injury;classification;extraction;image scaling;k-nearest neighbors algorithm;mathematics;nearest neighbour algorithm;principal component analysis;single linkage cluster analysis;support vector machine;test scaling;transplanted tissue;multidimensional scaling	Begoña Acha;Carmen Serrano;Irene Fondón;Tomás Gómez-Cía	2013	IEEE Transactions on Medical Imaging	10.1109/TMI.2013.2254719	computer vision;contextual image classification;speech recognition;computer science;machine learning;pattern recognition	Visualization	36.020545401917616	-72.52439812573999	159870
722d68a8f0ac715c2c6fe938ab2f0a0f05dda04f	automatic detection of neovascularization on optic disk region with feature extraction and support vector machine	image segmentation;support vector machines;optical filters;training;optical imaging;retina;feature extraction	Neovascularization (NV) is a definitive indicator for the onset of Proliferative Diabetic Retinopathy (PDR). The new vessels are fragile and prone to bleed, leading to high risk of sudden vision loss. Automatic detection of NV is an important task in automatic Diabetic Retinopathy (DR) screening as a consequence of the unmet requirement between the growing number of DR patients and limited number of ophthalmologists. This paper focuses on the computer aided detection of neovascularization in the optic disk region. We propose a novel image processing approach that involves vessel segmentation using multi-level Gabor filtering, feature extraction from vessel related features and texture features, and image classification based on machine learning. 21 features were extracted from each NVD image. The extracted features were trained and tested on 66 retinal images, which contains 16 NVD and 50 normal images, and achieved an sensitivity of 15/16 and specificity of 47/50.	blood vessel tissue;computer vision;design review (u.s. government);diabetic nephropathy;eye;feature extraction;gabor filter;hemorrhage;image processing;machine learning;national vulnerability database;numerous;nv network;onset (audio);optic disk;pathologic neovascularization;patients;proliferative diabetic retinopathy;retina;retinal diseases;sensitivity and specificity;support vector machine;test set;unspecified visual loss;algorithm;sudden loss of vision	Shuang Yu;Di Xiao;Yogesan Kanagasingam	2016	2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2016.7590951	support vector machine;computer vision;speech recognition;feature extraction;computer science;engineering;machine learning;optical imaging;optical filter;image segmentation;optics	Vision	35.348817445230466	-75.7790684674381	159911
528c867ae0dc6d045465496571ed089ffea3f988	classification of alzheimer's disease patients with hippocampal shape, wrapper based feature selection and support vector machine	databases;atrophy;ad;software;radiology;optics;support vector machines;shape analysis;physical sciences;nuclear medicine medical imaging;science technology;medical diagnostics;magnetic resonance imaging;life sciences biomedicine;mri;alzheimer s disease;feature selection;mild cognitive impairment;diseases and disorders	ABSTRACT It is well known that hippocampal atrophy is a marker of the onset of Alzheimers disease (AD) and as a result hippocampal volumetry has been used in a number of studies to provide early diagnosis of AD and predict conversion of mild cognitive impairment patients to AD. However, rates of atrophy are not uniform across the hippocampus making shape analysis a potentially more accurate biomarker. This study studies the hippocampi from 226 healthy controls, 148 AD patients and 330 MCI patients obtained from T1 weighted structural MRI images from the ADNI database. The hippocampi are anatomically segmented using the MAPS multi-atlas segmentation method, and the resulting binary images are then processed with SPHARM software to decom pose their shapes as a weighted sum of spherical harmonic basis functions. The resulting parameterizations are then used as feature vectors in Support Vector Machine (SVM) classification. A wrapper based feature selection method was used as this considers the utility of features in discriminating classes in combination, fully exploiting the multivariate nature of the data and optimizing the selected set of features for the type of classifier th at is used. The leave-one-ou t cross validated accuracy obt ained on training data is 88.6% for classifying AD vs controls and 74% for classifying MCI-converters vs MCI-stable with very compact feature sets, showing that this is a highly promising method. There is currently a considerable fall in accuracy on unseen data indicating that the feature selection is sensitive to the data used, however feature ensemble methods may overcome this. Keywords: Alzheimer's disease, mild cognitive impairment, support vector machines, shape analysis, feature selection	feature selection;support vector machine	Jonathan Young;Gerard R. Ridgway;Kelvin K. Leung;Sébastien Ourselin	2012		10.1117/12.911100	support vector machine;computer science;magnetic resonance imaging;machine learning;pattern recognition;data mining;shape analysis;physical science	ML	31.81345965992097	-78.14336802075421	159946
34126af8f455399cb5a5e4d7e7b257e2aa47f11f	handwritten devanagari script segmentation: a non-linear fuzzy approach		The paper concentrates on improvement of segmentation accuracy by addressing some of the key challenges of handwritten Devanagari word image segmentation technique. In the present work, we have developed a new feature based approach for identification of Matra pixels from a word image, design of a non-linear fuzzy membership functions for headline estimation and finally design of a non-linear fuzzy functions for identifying segmentation points on the Matra. The segmentation accuracy achieved by the current technique is 94.8%. This shows an improvement of performance by 1.8% over the previous technique [1] on a 300-word dataset, used for the current experiment.	fuzzy logic;image segmentation;nonlinear system;pixel	Ram Sarkar;Bibhash Sen;Nibaran Das;Subhadip Basu	2001	CoRR		computer vision;speech recognition;computer science;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation	Robotics	32.90663969343138	-66.1970273230126	160460
08c812a9f456371c1c001dc5b8d6406ced591d5e	online arabic handwriting recognition: a survey	handwriting recognition;written arabic language;online recognition;cursive script	Researches on handwriting recognition have known a great attention since it has been considered as a technological revolution in man-machines interfaces especially that handwriting has continued to persist as the most used mean of communication and recording information in day-to-day life. The challenging nature of handwriting recognition and segmentation has attracted the attention of researchers from academic and industry circles. The huge part of these researches deals with Latin and Chinese. Interest in Arabic script comes years later, and so the state of the art is less advanced. This survey describes the nature of this Arabic handwritten language and the basic concepts behind the recognition process. An overview of the state of the art of online Arabic handwriting recognition is presented. It is based on an extensive review of the literature in order to describe background in the field, discussion of the methods, and future research directions. It is the first survey to focus on online Arabic handwriting recognition and provide recognition rates and descriptions of database used for the discussed approaches.	handwriting recognition	Najiba Tagougui;Monji Kherallah;Adel M. Alimi	2012	International Journal on Document Analysis and Recognition (IJDAR)	10.1007/s10032-012-0186-8	natural language processing;speech recognition;intelligent character recognition;computer science;machine learning;linguistics;handwriting recognition	Vision	30.693750342179964	-67.8572166202282	160579
a61f7f6c35039d66e56bda83c268472c8e7ae81f	lung field segmentation in chest radiographs: a historical review, current status, and expectations from deep learning		Lung field defines a region-of-interest in which specific radiologic signs such as septal lines, pulmonary opacities, cavities, consolidations, and lung nodules are searched by a chest radiographic computer-aided diagnostic system. Thus, its precise segmentation is extremely important. To precisely segment it, numerous methods have been developed during the last four decades. However, no exclusive survey consolidating the advancements in these methods has been presented till date, thus indicating a void and the need. This study fills the void by presenting a comprehensive survey of these methods with a focus on their underlying principle, the dataset used, reported performance, and relative merits and demerits. It refrains from doing a hard comparative evaluation by bringing all of them on a common platform, since the datasets used in their development and testing are of varied quality, complexity, and are not publicly available. It also provides a glimpse of deep learning, the present state of deep-learning-based lung field segmentation methods, expectations from it, and the challenges ahead of it.	deep learning;radiography	Ajay Mittal;Rahul Hooda;Sanjeev Sofat	2017	IET Image Processing	10.1049/iet-ipr.2016.0526	medical physics;region of interest;deep learning;mathematics;radiography;pattern recognition;artificial intelligence;segmentation;lung field	HCI	33.2902541297158	-76.62339271837905	160709
48c4c3e35fcfe1b2e14cda4b0cef6cf026610395	bayesian analysis of cell nucleus segmentation by a viterbi search based active contour	electrical capacitance tomography;biology computing;active contour;image segmentation;cancer;application software;bayes methods;bayesian methods;viterbi search based active contour;active contours;cancer cellular biophysics medical image processing image segmentation bayes methods viterbi detection biological techniques biology computing;bayesian methods viterbi algorithm active contours image segmentation signal processing information processing computer science application software electrical capacitance tomography cervical cancer;viterbi detection;cervical cancer screening;cell nucleus segmentation;second stage bayesian analysis cell nucleus segmentation viterbi search based active contour cervical cancer screening image segmentation high level knowledge;viterbi algorithm;cervical cancer;medical image processing;signal processing;second stage;information processing;high level knowledge;computer science;biological techniques;bayesian analysis;cellular biophysics;iris research	An image segmentation scheme is shown to be exceptionally successful through the application of high-level knowledge of the required image objects (cell nuclei). By tuning the algorithm’s single parameter, it is shown that the performance can be maximised for the dataset, but leads to individual failures that may require alternative choices. A second stage is introduced to process each of the resulting segmentations obtained by varying the parameter over the working range. This stage gives a Bayesian interpretation of the results which indicates the probable accuracy of each of the segmentations that can then be used to make a decision upon whether to a ccept or reject the segmentation.	active contour model;high- and low-level;image segmentation;viterbi algorithm	Pascal Bamford;Brian C. Lovell	1998		10.1109/ICPR.1998.711098	computer vision;information processing;bayesian probability;computer science;machine learning;signal processing;pattern recognition;scale-space segmentation	Vision	38.5144756814127	-75.00011990209582	160906
f069df4f4d2809aa3bdc8376bef68b5b326c9937	3d multifractal analysis: application for epilipsy detection in spect imaging	spect imaging;biology computing;fractals;brain spect imaging;brain;epilipsy detection;geometry;hospitals;texture analysis methods;fractal geometry;brain spect;biomedical imaging;gabor filters;detection;multifractal analysis;image texture;fractal dimension;textures 3d multifractal analysis epilipsy detection brain spect imaging single photon emission computed tomography texture analysis methods fractal dimension;texture analysis;medical image;single photon emission computed tomography;detection 3d mutlifractal analysis spect imaging epilepsy;image analysis;nuclear medicine;image texture analysis;3d multifractal analysis;single photon emission computed tomography biology computing brain fractals image texture;3d mutlifractal analysis;pathology;textures;fractals image analysis image texture analysis biomedical imaging geometry epilepsy pathology nuclear medicine hospitals gabor filters;epilepsy	In medical imaging, many texture analysis methods were studied with different degrees of effectiveness. These last years, works showed the usefulness of the fractal geometry to characterize textures. The fractal dimension provides a global aspect of the texture, while the multifractal analysis provides a local and global aspect of the texture. In this study, we were interested in the detection of epileptic fit sources on brain SPECT images. The detection problem is formulated as a 3D multifractal analysis scheme. The first results obtained on a base of 5 patients show that this method can be effective for this application.	fractal dimension;medical imaging;multifractal system	Renaud Lopes;Nasr Makni;Romain Viard;Marc Steinling;Salah Maouche;Nacim Betrouni	2008	2008 5th IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2008.4541217	computer vision;image analysis;fractal;fractal analysis;computer science;mathematics;nuclear medicine;medical physics	Vision	37.49907804783587	-74.59511623555598	160915
8308ec6d4da376471db448f71a7ad4a3b8aac90c	a comparison of classification approaches for threat detection in ct based baggage screening	national security;image segmentation;3d shape retrieval methods computed tomography based baggage security screening system ct based baggage security screening system transportation security classification approaches automated threat object detection cluttered 3d ct imagery 3d medical image segmentation techniques 3d shape classification methods;image classification;shape recognition;medical image processing;transportation;computerised tomography;transportation computerised tomography image classification image retrieval image segmentation medical image processing national security object detection security shape recognition;shape indexes computed tomography histograms vectors decision trees security;security;object detection;3d object recognition aviation security 3d medical image segmentation 3d zernike descriptors histogram of shape index automated classification;image retrieval	Computed Tomography (CT) based baggage security screening systems are of increasing use in transportation security. The ability to automatically identify potential threat item is a key aspect of current research in this area. Here we present a comparison of varying classification approaches for the automated detection of threat objects in cluttered 3D CT imagery from such security screening systems. By combining 3D medical image segmentation techniques with 3D shape classification and retrieval methods we compare five varying final classification stage approaches and present significant performance achievements in the automated detection of specified exemplar items.	airport security;image segmentation;threat (computer);tomography	Najla Megherbi Bouallagu;Ji Wan Han;Toby P. Breckon;Gregory T. Flitton	2012	2012 19th IEEE International Conference on Image Processing	10.1109/ICIP.2012.6467558	computer vision;transport;contextual image classification;image retrieval;computer science;national security;pattern recognition;data mining;image segmentation	Vision	36.115079419393325	-72.23063501590956	160923
95dbc324eab79f5226b9342ed164601612614a5a	performance of a dermoscopy-based computer vision system for the diagnosis of pigmented skin lesions compared with visual evaluation by experienced dermatologists	computer aided diagnosis;supervised classification;pigmented skin lesions;melanoma;dermoscopy;skin cancer detection	BACKGROUND It is often difficult to differentiate early melanomas from benign melanocytic nevi even by expert dermatologists, and the task is even more challenging for primary care physicians untrained in dermatology and dermoscopy. A computer system can provide an objective and quantitative evaluation of skin lesions, reducing subjectivity in the diagnosis.   OBJECTIVE Our objective is to make a low-cost computer aided diagnostic tool applicable in primary care based on a consumer grade camera with attached dermatoscope, and compare its performance to that of experienced dermatologists.   METHODS AND MATERIALS We propose several new image-derived features computed from automatically segmented dermoscopic pictures. These are related to the asymmetry, color, border, geometry, and texture of skin lesions. The diagnostic accuracy of the system is compared with that of three dermatologists.   RESULTS With a data set of 206 skin lesions, 169 benign and 37 melanomas, the classifier was able to provide competitive sensitivity (86%) and specificity (52%) scores compared with the sensitivity (85%) and specificity (48%) of the most accurate dermatologist using only dermoscopic images.   CONCLUSION We show that simple statistical classifiers can be trained to provide a recommendation on whether a pigmented skin lesion requires biopsy to exclude skin cancer with a performance that is comparable to and exceeds that of experienced dermatologists.		Maciel Zortea;Thomas Roger Schopf;Kevin Thon;Marc Geilhufe;Kristian Hindberg;Herbert M. Kirchesch;Kajsa Møllersen;Jörn Schulz;Stein Olav Skrøvseth;Fred Godtliebsen	2014	Artificial intelligence in medicine	10.1016/j.artmed.2013.11.006	computer vision	Vision	34.90350803275161	-76.18580272554732	161233
a968532870ee1fd716e9e5a65a006688291bd1d7	domain specific convolutional neural nets for detection of architectural distortion in mammograms		Detection of Architectural distortion (AD) is important for ruling out possible pre-malignant lesions in breast, but due to its subtlety, it is often missed on the screening mammograms. In this work we suggest a novel AD detection method based on region proposal convolution neural nets (R-CNN). When the data is scarce, as typically the case in medical domain, R-CNN yields poor results. In this study, we suggest a new R-CNN method addressing this shortcoming by using a pretrained network on a candidate region guided by clinical observations. We test our method on the publicly available DDSM data set, with comparison to the latest faster R-CNN and previous works. Our detection accuracy allows binary image classification (normal vs. containing AD) with over 80% sensitivity and specificity, and yields 0.46 false-positives per image at 83% true-positive rate, for localization accuracy. These measures significantly improve the best results in the literature.	artificial neural network;binary image;computer vision;convolution;distortion;sensitivity and specificity	Rami Ben-Ari;Ayelet Akselrod-Ballin;Leonid Karlinsky;Sharbell Y. Hashoul	2017	2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)	10.1109/ISBI.2017.7950581	pattern recognition;artificial neural network;computer vision;artificial intelligence;computer science;binary image;mammography;convolution;architectural distortion	Arch	32.534492344756586	-75.62894035689156	161258
41e8c3d5c87db9e5fabb8d8e22550bdab1274459	online handwriting character recognition method using directional and direction-change features	hand writing;directional and direction change pattern matching method;on line;en linea;extraction forme;offline;reconnaissance caractere;extraccion forma;escritura manual;forme directionnelle;pattern recognition;en ligne;extraction of features;reconnaissance forme;reconocimiento patron;caractere japonaise;character recognition;pattern extraction;online;reconocimiento caracter;ecriture	We propose a new online recognition method to recognize handwritten cursive-style Japanese characters correctly. Our method simultaneously uses both directional features, otherwise known as offline features, and direction-change features which we designed as online features. The direction-change features express where in the mesh and in which direction the character's coordinates change. These features express both written strokes in the pen-down state and unwritten imaginary strokes in the pen-up state. The recognition rate was improved by our method over the traditional method using only directional features.		Masayoshi Okamoto;Kazuhiko Yamamoto	1999	IJPRAI	10.1142/S0218001499000586	computer vision;speech recognition;computer science;pattern recognition	Vision	35.5448142467259	-67.16454487774593	161659
e2a06099dea4d4ffd9ffd5b00e5053d9fce91b7e	developing image informatics methods for histopathological computer-aided decision support systems				Sonal Kothari	2013			data science;computer-aided;imaging informatics;visual analytics;decision support system;computer vision;informatics;image segmentation;computer science;contextual image classification;artificial intelligence	EDA	32.95090087399419	-74.13378030039662	162081
4f38f2de3b49981aa24ac761ae426097282294cc	the classification gradient	classification gradient;3d imaging;image classification;pixel lungs tumors humans higher order statistics histograms speech processing signal processing educational institutions computed tomography;bootstraping;weak statistical borders detection classification gradient bootstraping sliding window real image boundary classification accuracy;weak statistical borders detection;real image boundary;classification accuracy;sliding window	"""We propose a method that uses bootstraping to classify the pixels in the two halves of a sliding window, assuming that if there is a real image boundary separating the two halves, the pixels in the two halves will be classified in two separate classes. The accuracy of the classification is used as a local """"gradient"""". High values of this gradient allow us to detect weak statistical borders in 2D and 3D images"""	3d computer graphics;bootstrapping (statistics);concatenation;emoticon;gradient;grayscale;pixel;sensor	Vassili A. Kovalev;Maria Petrou	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.1116	sliding window protocol;stereoscopy;computer vision;contextual image classification;computer science;machine learning;pattern recognition;mathematics;bootstrapping	Vision	37.68898261028276	-74.12234313477538	162112
4599d0e875e6a9d8f621d5d44cae76ecc58144df	early detection of alzheimer's disease using deep learning		Using a combination of methods from image processing, signal processing and deep learning, we aim to develop a model to predict whether or not a patient will develop symptomatic Alzheimer’s disease using Diffusion MRI (dMRI) imaging data. We first propose a 3D multichannel convolutional neural network (CNN) architecture to distinguish patients with Alzheimer’s from normal controls, then propose an extension of our architecture to incorporate multiple scans from a patient’s history to improve classification accuracy and predict future prognosis. Finally, we discuss methods for performing data augmentation to add diversity and robustness to our unique and comparatively small dataset.	deep learning	Laura McCrackin	2018		10.1007/978-3-319-89656-4_40	image processing;robustness (computer science);convolutional neural network;machine learning;diffusion mri;signal processing;architecture;pattern recognition;deep learning;computer-aided diagnosis;artificial intelligence;computer science	ML	31.969656010131512	-75.74910667027757	162126
13301a0fc2171cfd0c508e6097dfde4a41f2844b	dynamic text line segmentation for real-time recognition of chinese handwritten sentences	online chinese handwritten sentence real time dynamic text line segmentation statistical classifier geometric relationship delayed stroke robust real time recognition;dynamic text line segmentation;handwriting recognition;image segmentation;real time recognition;support vector machines;image classification;text analysis;real time systems character recognition handwriting recognition feature extraction text recognition writing support vector machines;text analysis handwriting recognition image classification image segmentation natural language processing statistical analysis;statistical analysis;feature extraction;writing;text recognition;stroke line relationaship real time recognition dynamic text line segmentation;character recognition;natural language processing;real time systems;stroke line relationaship	Real-time recognition of handwritten sentences enables fast text input but the dynamic nature of writing makes reliable text line segmentation difficult. This paper proposes a method for real-time dynamic text line segmentation of online Chinese handwriting. The core of the method is a statistical classifier for modeling the geometric relationship between an ongoing stroke and the previous text lines, to assign the stroke into a previous line or form a new line. The method can deal with delayed strokes and therefore enables robust real-time recognition. We evaluated the segmentation performance on a dataset of online Chinese handwriting by simulating the real-time writing and recognition process. The experimental results demonstrate the effectiveness and robustness of the proposed method.	algorithm;experiment;real-time clock;real-time transcription;robustness (computer science);simulation;statistical classification	Da-Han Wang;Cheng-Lin Liu	2011	2011 International Conference on Document Analysis and Recognition	10.1109/ICDAR.2011.189	natural language processing;support vector machine;contextual image classification;speech recognition;feature extraction;computer science;machine learning;pattern recognition;handwriting recognition;image segmentation;scale-space segmentation;writing	Robotics	32.66832213818488	-66.6013271009246	162639
3a03781aea9baa46c1d48ca9b840f1958cb6f10b	make your bone great again : a study on osteoporosis classification		Osteoporosis can be identified by looking at 2D x-ray images of the bone. The high degree of similarity between images of a healthy bone and a diseased one makes classification a challenge. A good bone texture characterization technique is essential for identifying osteoporosis cases. Standard texture feature extraction techniques like Local Binary Pattern (LBP), Gray Level Cooccurrence Matrix (GLCM), Law’s etc. have been used for this purpose. In this paper, we draw a comparison between deep features extracted from convolution neural network against these traditional features. Our results show that deep features have more discriminative power as classifiers trained on them always outperform the ones trained on traditional features.	artificial neural network;convolution;feature extraction;local binary patterns;radiography	Rahul Paul;Saeed Alahamri;Sulav Malla;Ghulam Jilani Quadri	2016	CoRR		osteoporosis;dentistry;computer science	ML	33.80391806935874	-75.04164302209391	162815
52ac1d962a8470edb4e3901bdc840b06c72dfce0	multiple kernel learning based modality classification for medical images	kernel;explicit feature maps multiple kernel learning image modality classification medical image retrieval multidisciplinary approach image features meta data textual information referential information imageclef 2011 medical modality classification data set multiple kernel based classification linear support vector machine;support vector machines;kernel feature extraction visualization accuracy vectors biomedical imaging support vector machines;image classification;biomedical imaging;accuracy;visualization;vectors;feature extraction;medical image processing;meta data;learning artificial intelligence;support vector machines feature extraction image classification image retrieval learning artificial intelligence medical image processing meta data;image retrieval	Modality is a key facet in medical image retrieval, as a user is likely interested in only one of e.g. radiology images, flowcharts, and pathology photos. While assessing image modality is trivial for humans, reliable automatic methods are required to deal with large un-annotated image bases, such as figures taken from the millions of scientific publications. We present a multi-disciplinary approach to tackle the classification problem by combining image features, meta-data, textual and referential information. We test our system's accuracy on the ImageCLEF 2011 medical modality classification data set. We show that using multiple kernel based classification, where the kernels are carefully selected for the different features, significantly increases the classification accuracy. Moreover, we demonstrate that by using linear support vector machine with explicit feature maps [35] of the selected kernels one can achieve comparable results to the (non-linear) kernel based one. Our best method achieves 88.47% accuracy and outperforms the state of the art.	bag-of-words model in computer vision;color histogram;flowchart;heuristic;human killing machine;image retrieval;kernel (operating system);linear classifier;map;medical imaging;modality (human–computer interaction);multiple kernel learning;nonlinear system;radiology;scalability;scientific literature;support vector machine	Viktor Gál;Etienne E. Kerre;Mike Nachtegael	2012	2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops	10.1109/CVPRW.2012.6239251	support vector machine;computer vision;kernel method;contextual image classification;feature detection;kernel;visualization;feature extraction;image retrieval;computer science;machine learning;linear classifier;pattern recognition;graph kernel;accuracy and precision;tree kernel;metadata;automatic image annotation;feature	Vision	32.49754378372634	-71.77955936133488	162864
1d2c9b4a15c3de5647848f025cd390f74544996c	pap smear image classification using convolutional neural network	pap smear image;deep learning;softmax regression;lssvm	This article presents the result of a comprehensive study on deep learning based Computer Aided Diagnostic techniques for classification of cervical dysplasia using Pap smear images. All the experiments are performed on a real indigenous image database containing 1611 images, generated at two diagnostic centres. Focus is given on constructing an effective feature vector which can perform multiple level of representation of the features hidden in a Pap smear image. For this purpose Deep Convolutional Neural Network is used, followed by feature selection using an unsupervised technique with Maximal Information Compression Index as similarity measure. Finally performance of two classifiers namely Least Square Support Vector Machine (LSSVM) and Softmax Regression are monitored and classifier selection is performed based on five measures along with five fold cross validation technique. Output classes reflects the established Bethesda system of classification for identifying pre-cancerous and cancerous lesion of cervix. The proposed system is also compared with two existing conventional systems and also tested on a publicly available database. Experimental results and comparison shows that proposed system performs efficiently in Pap smear classification.	artificial neural network;computer vision;convolutional neural network;database;deep learning;experiment;feature selection;feature vector;maximal set;mental representation;multinomial logistic regression;similarity measure;smear campaign;softmax function;support vector machine	Kangkana Bora;Manish Chowdhury;Lipi B. Mahanta;Malay Kumar Kundu;Anup Kumar Das	2016		10.1145/3009977.3010068	computer vision;computer science;machine learning;pattern recognition	ML	31.79347482074972	-74.57804964081747	162867
f0a5e0e5c62c01cc5066b1c7d7176e8cecccc108	computer aided detection of clustered microcalcifications in digitized mammograms using gabor functions	image resolution;supervised learning;cancer;neural nets;breast cancer cancer detection mammography humans physics computing shape spatial resolution frequency data mining artificial neural networks;image classification;cancer mammography medical image processing learning artificial intelligence feature extraction image classification neural nets image resolution;feature extraction;medical image processing;elementary functions;gabor elementary functions computer aided detection clustered microcalcifications digitized mammograms multiresolution approach artificial neural network classification feature extraction supervised learning sensibility specificity;computer aided detection;mammography;learning artificial intelligence;spatial frequency;artificial neural network	This paper presents a multiresolution approach to the computer aided detection of clustered microcalcifications in digitized mammograms based on Gabor elementary functions. A bank of Gabor functions with varying spatial extent and tuned to different spatial frequencies is used for the extraction of microcalcifications characteristics. Classification is performed by an artificial neural network with supervised learning. First results show that most microcalcifications, isolated or clustered, are detected by our algorithm with a 95% value both for sensibility and specificity as measured on a test data set.	gabor atom	Ezio Catanzariti;Monica Ciminello;Roberto Prevete	2003		10.1109/ICIAP.2003.1234061	computer vision;contextual image classification;image resolution;feature extraction;computer science;elementary function;machine learning;pattern recognition;spatial frequency;artificial neural network;cancer	NLP	34.99552793259682	-76.86842092301981	162912
9659ec4621f76b86667c37ceee57964d83292e72	automatic hemorrhage detection in color fundus images based on gradual removal of vascular branches	image segmentation;hemorrhaging;lesions;image color analysis;feature extraction;retinal vessels	Hemorrhages in color fundus images usually vary in size and shape, and some are even connected with the retinal vasculature such that they are often omitted by previous detection methods. In this paper, we propose a new method to deal with these problems. During the hemorrhage candidate extraction stage, dark regions and retinal vasculature are segmented out respectively. Their individual advantages are fused together into a binary image with good vascular continuity. Then the gradual removal of vascular branches is applied to generate hemorrhage candidates. In the classification stage, a SVM classifier using 49 features is trained to classify the candidates into hemorrhages and non-hemorrhages. The experiments on DIARETDB1 and DIARETDB0 show that our method achieves good performance on sensitivity and specificity, especially at lesion level.	binary image;business continuity;experiment;scott continuity;sensitivity and specificity	Lei Zhou;Penglin Li;Qi Yu;Yu Qiao;Jie Yang	2016	2016 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2016.7532387	computer vision;feature extraction;computer science;machine learning;image segmentation	Robotics	36.36588392981724	-75.20140186224461	162980
12bb78a78973da5262cb011eca8fdd3dbe6bed72	similarity measurement method for the classification of architecturally differentiated images	medical imagery;informatica biomedical;biomedical data processing;computed tomography;systeme mesure;histologie;histologia;matematica;performance;extraction forme;informatique biomedicale;computadores;anatomia;classification;similitude;humanos;modelos biologicos;extraccion forma;masculino;similarity;imagerie medicale;processamento de imagem assistida por computador;measuring system;imageneria medical;similitud;rendimiento;histology;analise de fourier;anatomie;neoplasias da prostata;similarity measure;pattern extraction;anatomy;clasificacion;sistema medida;prostate cancer	A similarity measurement method for the classification of architecturally differentiated image sections is described. The strength of the method is demonstrated by performing the complex task of assigning severity grading (Gleason grading) to histological slides of prostate cancer. As shown, all that is required to employ the method is a small set of preclassified images. The images can be real world images acquired by means of a camera, computer tomography, etc., or schematic drawings representing samples of different classes. The schematic option allows a quick test of the method for a particular classification problem.		Yoav Smith;Gershom Zajicek;Michael Werman;Galina Pizov;Yoav Sherman	1999	Computers and biomedical research, an international journal	10.1006/cbmr.1998.1500	similarity;medicine;pathology;performance;biological classification;artificial intelligence;similitude;histology;algorithm	Vision	37.56255177821238	-73.60543830082408	163523
4d29cd06d001dbcd454d6c7d3290beb52c43d5de	cervical nuclei classification: feature engineering versus deep belief network		A database of 9405 cervical cells is introduced, which was collected from Pap-smear images: 1791 cells are pathologic cases (two types), the rest are healthy cases (three types). Their cell nuclei are classified using two methods: once with a traditional feature engineering approach using in particular iso-contours; and once with a Deep Belief Network made of Restricted Boltzmann Machines. The Deep Belief Network returns higher accuracy, but not in all classification tasks. The retrieval results show that nuclei information alone can be probably sufficient for a computer-assistive diagnosis of Pap-smear images.	deep belief network;feature engineering	Christoph Rasche;Ciprian Tiganesteanu;Mihai Neghina;Alina Sultana	2017		10.1007/978-3-319-60964-5_76	feature extraction;cervical cells;deep learning;deep belief network;boltzmann machine;artificial intelligence;feature engineering;computer science;pattern recognition	AI	30.54034560558746	-76.15709276372397	163555
fbfb861e4d8a090b8be133d7b580e33a57e04f58	fast lung nodule detection in chest ct images using cylindrical nodule-enhancement filter	nodule;image processing;computed tomography ct;fast detection;lung;computer aided detection cad	Existing computer-aided detection schemes for lung nodule detection require a large number of calculations and tens of minutes per case; there is a large gap between image acquisition time and nodule detection time. In this study, we propose a fast detection scheme of lung nodule in chest CT images using cylindrical nodule-enhancement filter with the aim of improving the workflow for diagnosis in CT examinations. Proposed detection scheme involves segmentation of the lung region, preprocessing, nodule enhancement, further segmentation, and false-positive (FP) reduction. As a nodule enhancement, our method employs a cylindrical shape filter to reduce the number of calculations. False positives (FPs) in nodule candidates are reduced using support vector machine and seven types of characteristic parameters. The detection performance and speed were evaluated experimentally using Lung Image Database Consortium publicly available image database. A 5-fold cross-validation result demonstrates that our method correctly detects 80 % of nodules with 4.2 FPs per case, and detection speed of proposed method is also 4–36 times faster than existing methods. Detection performance and speed indicate that our method may be useful for fast detection of lung nodules in CT images.	blood vessel;ct scan;chamaecyparis lawsoniana;computer-aided design;consortium;cross reactions;cross-validation (statistics);eighty;experiment;image resolution;neoplasms;nodule;patients;polyethylene terephthalate;preprocessor;structure of parenchyma of lung;support vector machine;transcutaneous electric nerve stimulation;biologic segmentation	Atsushi Teramoto;Hiroshi Fujita	2012	International Journal of Computer Assisted Radiology and Surgery	10.1007/s11548-012-0767-5	computer vision;radiology;medicine;pathology;image processing;computer science;medical physics	Vision	36.6976566837838	-77.38249399115809	163699
f6d28c8674f546895ce79cabf16f7f8dabac99db	left ventricle segmentation in cardiac mr images using fully convolutional network		Medical image analysis, especially segmenting a specific organ, has an important role in developing clinical decision support systems. In cardiac magnetic resonance (MR) imaging, segmenting the left and right ventricles helps physicians diagnose different heart abnormalities. There are challenges for this task, including the intensity and shape similarity between the left ventricle and other organs, inaccurate boundaries, and presence of noise in most of the images. In this paper, we propose an automated method for segmenting the left ventricle in cardiac MR images. We first automatically extract the region of interest and then employ it as an input of a fully convolutional network. We train the network accurately despite the small number of left ventricle pixels in comparison with the whole image. Thresholding on the output map of the fully convolutional network and selection of regions based on their roundness are performed in our proposed post-processing phase. The Dice score of our method reaches 87.24% by applying this algorithm on the York dataset of heart images.	clinical decision support system;computer model railroad interface;congenital abnormality;congenital heart defects;decision support systems, clinical;frame (physical object);heart ventricle;hypoplastic left heart syndrome;image analysis;left ventricular structure;medical image computing;organ;pixel;population parameter;region of interest;resonance;right ventricular structure;segmentation action;sensitivity and specificity;silo (dataset);thresholding (image processing);video post-processing;algorithm;biologic segmentation	Mina Nasr-Esfahani;Majid Mohrekesh;Mojtaba Akbari;S. Mohamad R. Soroushmehr;Ebrahim Nasr-Esfahani;Nader Karimi;S Abdolvahab Samavi;Kayvan Najarian	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8512536	pattern recognition;computer vision;artificial intelligence;region of interest;feature extraction;computer science;heart abnormality;image segmentation;thresholding;medical imaging;active appearance model;segmentation	Vision	38.1312674283691	-79.09532644129914	163905
557bfd55c791558e76fd7e979c488c69c2f033cc	a vectorized chinese font personalizing system	vectorized font;strokes;font personalizing system;contours;radicals	The modification of a standard character according to the features of an individual's handwriting endows the character with handwritten traits, a process called font personalization. In this paper, a novel approach is proposed to transform a full set of standard Chinese vectorized font, according to a writer's handwritten characteristics, into a personalized font possessing the writer's discernible features. Once installed in a computer, the personalized font set obtained can efficiently replace existing standard fonts to exhibit unique handwritten features.		John Y. Chiang;Chung-Hsun Hsieh;Shuenn-Ren Cheng	2008	Int. J. Comput. Proc. Oriental Lang.	10.1142/S1793840608001895	speech recognition;radical;computer science;unicode font;multimedia;computer graphics (images)	Logic	31.408760164664997	-67.68241525961012	163965
78bdb92bf5bbcc66ad06334db507b4f87183d8bf	an improved 2d colonic polyp segmentation framework based on gradient vector flow deformable model	fuzzy c means algorithm;gradient vector flow;inner product;geometric feature;bias correction;indexation;colorectal cancer;computed tomography colonography;deformable model	Computed Tomography Colonography has been proved to be a valid technique for detecting and screening colorectal cancers. In this paper, we present a framework for colonic polyp detection and segmentation. Firstly, we propose to use four different geometric features for colonic polyp detection, which include shape index, curvedness, sphericity ratio and the absolute value of inner product of maximum principal curvature and gradient vector flow. Then, we use the bias-corrected fuzzy c-mean algorithm and gradient vector flow based deformable model for colonic polyp segmentation. Finally, we measure the overlap between the manual segmentation and the algorithm segmentation to test the accuracy of our frame work. The quantitative experiment results have shown that the average overlap is 85.17% ± 3.67%.	algorithm;ct scan;cluster analysis;gradient;planning;sensor;tomography;virtual colonoscopy	Dongqing Chen;M. Sabry Hassouna;Aly A. Farag;Robert Falk	2006		10.1007/11812715_47	computer vision;mathematical optimization;pathology;mathematics;scale-space segmentation	Vision	38.780384859506036	-77.26039403046354	164250
59d4fa2cebfcac7c7ce2df20ee8c1664d66e94c8	optical inspection and morphological analysis of diospyros kaki plant leaves for the detection of circular leaf spot disease	ss oct;optical coherence tomography;circular leaf spot cls disease;persimmon leaf;diospyros kaki	The feasibility of using the bio-photonic imaging technique to assess symptoms of circular leaf spot (CLS) disease in Diospyros kaki (persimmon) leaf samples was investigated. Leaf samples were selected from persimmon plantations and were categorized into three groups: healthy leaf samples, infected leaf samples, and healthy-looking leaf samples from infected trees. Visually non-identifiable reduction of the palisade parenchyma cell layer thickness is the main initial symptom, which occurs at the initial stage of the disease. Therefore, we established a non-destructive bio-photonic inspection method using a 1310 nm swept source optical coherence tomography (SS-OCT) system. These results confirm that this method is able to identify morphological differences between healthy leaves from infected trees and leaves from healthy and infected trees. In addition, this method has the potential to generate significant cost savings and good control of CLS disease in persimmon fields.	british informatics olympiad;categorization;common language infrastructure;diospyros kaki;imaging techniques;mongolian spot;palisade parenchyma cells;plant leaves;thickness (graph theory);tomography, emission-computed;tomography, optical coherence;trees (plant);tomography	Ruchire Eranga Wijesinghe;Seung-Yeol Lee;Pil Un Kim;Heeyoung Jung;Mansik Jeon;Jeehyun Kim	2016		10.3390/s16081282	optics	Robotics	38.86984769588392	-78.19024460355637	164485
d0fb5e39093255929a7197b813becd108b8d68fd	review of pattern matching approaches	pattern matching	This paper presents a review of pattern matching techniques. The application areas for pattern matching are extensive, ranging from CAD systems to chemical analysis and from manufacturing to image processing. Published techniques and methods are classified and assessed within the context of three key issues: pattern classes, similarity types and matching methods. It has been shown that the techniques and approaches are as diverse and varied as the applications.	computer-aided design;image processing;pattern language;pattern matching	Djauhar Manfaat;Alex H. B. Duffy;Byung S. Lee	1996	Knowledge Eng. Review	10.1017/S0269888900007815	computer science;pattern matching	DB	37.09863394859399	-68.37526074272773	164651
57422334d4a6063720cad054f08ad1b6cebb33d9	combining single view features and asymmetry for detection of mass lesions		Radiologists in breast cancer screening are trained to use comparisons of left and right mammograms to identify suspicious asymmetric densities. Asymmetry is not a very specific sign, as the majority of asymmetric densities are due to normal variation of the parenchymal pattern. However, when an asymmetric density has some of the characteristics that are typical for a malignant mass or appears in a region that should normally be empty, it may be suspicious. Previously, we have developed a method for detecting stellate and circumscribed masses in mammograms from single views [5], [11], based on a statistical analysis of line and gradient orientation patterns. In this study we investigated the use of a local measure of asymmetry as an additional feature, with the aim of improving overall detection performance on a large consecutive sample of screening cases.		Nico Karssemeijer;Guido M. te Brake	1998		10.1007/978-94-011-5318-8_16	computer vision;pattern recognition	Vision	35.1830233014173	-76.58023994510431	164754
906592d7a72db0099f5fa0888a83a727039f203c	a comparison of accurate automatic hippocampal segmentation methods	cohen s d;dice s κ;dice s;alzheimer s disease;area under receiver operating characteristic curve;hippocampal segmentation	The hippocampus is one of the first brain structures affected by Alzheimer's disease (AD). While many automatic methods for hippocampal segmentation exist, few studies have compared them on the same data. In this study, we compare four fully automated hippocampal segmentation methods in terms of their conformity with manual segmentation and their ability to be used as an AD biomarker in clinical settings. We also apply error correction to the four automatic segmentation methods, and complete a comprehensive validation to investigate differences between the methods. The effect size and classification performance is measured for AD versus normal control (NC) groups and for stable mild cognitive impairment (sMCI) versus progressive mild cognitive impairment (pMCI) groups. Our study shows that the nonlinear patch-based segmentation method with error correction is the most accurate automatic segmentation method and yields the most conformity with manual segmentation (κ=0.894). The largest effect size between AD versus NC and sMCI versus pMCI is produced by FreeSurfer with error correction. We further show that, using only hippocampal volume, age, and sex as features, the area under the receiver operating characteristic curve reaches up to 0.8813 for AD versus NC and 0.6451 for sMCI versus pMCI. However, the automatic segmentation methods are not significantly different in their performance.	alzheimer's disease neuroimaging initiative;biological markers;cognition disorders;cognitive science;conformity;experiment;forecast of outcome;freesurfer;memory segmentation;nonlinear system;receiver operating characteristic;biologic segmentation;error correction	Azar Zandifar;Vladimir Fonov;Pierrick Coupé;Jens C. Pruessner;D. Louis Collins	2017	NeuroImage	10.1016/j.neuroimage.2017.04.018	cognitive psychology;hippocampal formation;receiver operating characteristic;machine learning;artificial intelligence;computer science;pattern recognition;segmentation	NLP	31.318797215214786	-78.644944372045	164898
a84865a64168aa627aa19364bfcc32fcf40f3e77	representation and classification of complex-shaped printed regions using white tiles	bounding box representation;document analysis;image segmentation;tiles image segmentation shape pressing text analysis image analysis white spaces pixel systems engineering and theory classification algorithms;white tiles;complex shaped printed regions representation;page segmentation;image classification;complex shaped printed regions classification;printed regions;complex shaped regions;image representation;page classification;page classification complex shaped printed regions representation complex shaped printed regions classification white tiles document analysis methods printed regions complex shapes bounding box representation page segmentation complex shaped regions;document image processing;image segmentation image classification image representation document image processing;document analysis methods;complex shapes	There is an increasingly pressing need to develop document analysis methods that are able to cope with images of documents containing printed regions of complex shapes. Contrary to the bounding-box representation used in most past page segmentation and classification approaches which assume rectangular regions, there is a need for a more flexible description which also retains most of the functionality of the representation by rectangles. In the first part of this paper, the practical considerations of describing and handling the complexshaped regions are examined and an appropriate representation scheme is proposed. For page classification, a new approach based on the description of white space inside regions is presented. In contrast to previous page classification approaches, skewed and complex-shaped regions are handled efficiently and the features are derived with no need for time-consuming accesses of the pixel-based image data.	minimum bounding box;pixel;printing;statistical classification	Apostolos Antonacopoulos;Tim Ritchings	1995		10.1109/ICDAR.1995.602119	computer vision;contextual image classification;computer science;machine learning;pattern recognition;image segmentation	ML	37.28244067567538	-66.63961499789332	164996
c5501ffe63bf27a26bb456ce46b5f7c0089f30d6	detection and classification of citrus diseases in agriculture based on optimized weighted segmentation and feature selection		In agriculture, plant diseases are primarily responsible for the reduction in production which causes economic losses. In plants, citrus is used as a major source of nutrients like vitamin C throughout the world. However, ‘Citrus’ diseases badly effect the production and quality of citrus fruits. From last decade, the computer vision and image processing techniques have been widely used for detection and classification of diseases in plants. In this article, we propose a hybrid method for detection and classification of diseases in citrus plants. The proposed method consists of two primary phases; (a) detection of lesion spot on the citrus fruits and leaves; (b) classification of citrus diseases. The citrus lesion spots are extracted by an optimized weighted segmentation method, which is performed on an enhanced input image. Then, color, texture, and geometric features are fused in a codebook. Furthermore, the best features are selected by implementing a hybrid feature selection method, which consists of PCA score, entropy, and skewness-based covariance vector. The selected features are fed to MultiClass Support Vector Machine (M-SVM) for final citrus disease classification. The proposed technique is tested on Citrus Disease Image Gallery Dataset, Combined dataset (Plant Village and Citrus Images Database of Infested with Scale), and our own collected images database. We used these datasets for detection and classification of citrus diseases namely anthracnose, black spot, canker, scab, greening, and melanose. The proposed technique outperforms the existing methods and achieves 97% classification accuracy on citrus disease image gallery dataset, 89% on combined dataset and 90.4% on our local dataset.	codebook;computer vision;emoticon;feature selection;image processing;support vector machine	Muhammad Majid Sharif;Muhammad Attique Khan;Zahid Iqbal;Muhammad Faisal Azam;M. Ikram Ullah Lali;Muhammad Younus Javed	2018	Computers and Electronics in Agriculture	10.1016/j.compag.2018.04.023	support vector machine;spots;computer vision;artificial intelligence;image processing;feature selection;engineering;codebook;disease classification;segmentation;pattern recognition	Vision	34.63348525347404	-71.03533070571496	165115
e30a4dd903c6c26276eec5507116baf0c5507577	a fast and accurate automatic lung segmentation and volumetry method for mr data used in epidemiological studies	pulmonary imaging;segmentation;mri;volumetry	"""In modern epidemiological population-based studies a huge amount of magnetic resonance imaging (MRI) data is analysed. This requires reliable automatic methods for organ extraction. In the current paper, we propose a fast and accurate automatic method for lung segmentation and volumetry. Our approach follows a """"coarse-to-fine"""" segmentation strategy. First, we extract the lungs and trachea excluding the main pulmonary vessels. This step is executed very fast and allows for measuring the volume of both structures. Thereafter, we start a refinement procedure that consists of three main stages: trachea extraction, lung separation, and filling the cavities on the final lung masks. After the trachea extraction step the volumes of both lungs without the main vessels can be measured. The final segmentation step results in the volumes of the left and right lungs including the vessels. The method has been tested by processing MR datasets from ten healthy participants. We compare our results with manually produced masks and obtain high agreement between the expert reading and our method: the True Positive Volume Fraction is more than 95%. The proposed automatic approach is fast and accurate enough to be applied in clinical routine for processing of thousands of participants."""		Tetyana Ivanovska;Katrin Hegenscheid;René Laqua;Jens-Peter Kühn;Sven Gläser;Ralf Ewert;Norbert Hosten;Ralf Puls;Henry Völzke	2012	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2011.10.001	radiology;medicine;pathology;magnetic resonance imaging;segmentation	Visualization	38.4322796658522	-80.12009677392507	165924
f8ae25941c980a00fe644057dc2ab2b1a1b150f5	stroke level user-adaptation for stroke order free online handwriting recognition	handwriting recognition character recognition libraries prototypes table lookup accuracy writing;dtw distance online handwriting recognition stroke order free recognmition;android based bangla handwriting recognizer lightweight user adaptive online handwriting recognition scheme stroke level user adaptation prior identification representative sample database weighted dtw distance nearest neighbour classifier look up table lut learning vector quantization method lvq method;table lookup handwriting recognition pattern classification	In this article, a novel lightweight user-adaptive online handwriting recognition scheme has been presented. The present recognition approach is stroke order free. It is based on prior identification of the set of various strokes of different shapes used in writing the characters of the underlying alphabet utilizing a representative sample database. In this approach a very small number of prototypes of each stroke shape is used along with certain weighted DTW distance based nearest neighbour classifier to recognize the strokes in the input character. Individual characters are identified using a look-up table (LUT) each row of which corresponds to one character composed of a distinct set of stroke shapes. This LUT is formed using the representative sample set of the underlying character set. If a stroke does not find a close match in the training set or if the set of strokes for an input character does not find a corresponding entry in the LUT, user adaptation takes place using a modified Learning Vector Quantization (LVQ) method. The proposed scheme has been implemented in an Android-based Bangla handwriting recognizer [1] for handheld devices and its recognition performance is encouraging.	android;character encoding;finite-state machine;handwriting recognition;learning vector quantization;lookup table;mobile device;test set	Diptavo Dutta;Aruni Roy Chowdhury;Ujjwal Bhattacharya;Swapan K. Parui	2014	2014 14th International Conference on Frontiers in Handwriting Recognition	10.1109/ICFHR.2014.50	speech recognition;intelligent character recognition;computer science;machine learning;pattern recognition	Vision	31.817238239580853	-67.42547381248376	166000
6bbd6150b5ca602f20b89e3d2427aba61365f4f5	recognizing on-line handwritten alphanumeric characters through flexible structural matching	hand writing;analisis estructural;on line;on line handwriting recognition;en linea;estructura;structural primitive;extraccion;primitive structurelle;reconnaissance caractere;structural approch;escritura manual;syntactic pattern recognition;pattern recognition;flexible structure;en ligne;estructura flexible;analyse structurale;structure flexible;structural analysis;character recognition;structure;approche structurelle;extraction;handwritten character recognition;reconocimiento caracter;ecriture	Speed, accuracy, and #exibility are crucial to the practical use of on-line handwriting recognition. Besides, extensibility is also an important concern as we move from one domain to another which requires the character set to be extended. In this paper, we will propose a simple yet robust structural approach for recognizing on-line handwriting. Our approach is designed to achieve reasonable speed, fairly high accuracy and su$cient tolerance to variations. At the same time, it maintains a high degree of reusability and hence facilitates extensibility. Experimental results show that the recognition rates are 98.60% for digits, 98.49% for uppercase letters, 97.44% for lowercase letters, and 97.40% for the combined set. When the rejected cases are excluded from the calculation, the rates can be increased to 99.93%, 99.53%, 98.55% and 98.07%, respectively. On the average, the recognition speed is about 7.5 characters per second running in Prolog on a Sun SPARC 10 Unix workstation and the memory requirement is reasonably low. With this simple yet robust structural approach, we already have an e!ective and e$cient on-line character recognition module. This module will be used as part of a larger system, a pen-based mathematical equation editor, which is being developed by the authors using a syntactical pattern recognition approach. ( 1999 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	character encoding;extensibility;fault tolerance;handwriting recognition;online and offline;optical character recognition;pattern recognition;printer (computing);prolog;sparc;unix;video post-processing;workstation	Kam-Fai Chan;Dit-Yan Yeung	1999	Pattern Recognition	10.1016/S0031-3203(98)00155-1	computer vision;structure;extraction;speech recognition;computer science;artificial intelligence;structural analysis;algorithm	Vision	34.29351031574515	-67.49067111268528	166192
149d7a525723fc83c61cd63a11ee77538106cba3	automatic classification of tongueprints in healthy and unhealthy individuals	traditional chinese medicine;feature recognition;image database;small samples;statistical analysis;automatic classification;diagnostic method	Tongueprints are fissile texture on tongue and one of observational contents of tongue diagnosis, which is an important diagnostic method in Traditional Chinese Medicine (TCM). With deep researches on tongueprints, three basic problems emerge: (1) TCM has always held that healthy individuals do not exhibit tongueprints, but in the recent years some medical researchers have found some healthy individuals in their small sample ( 2000 cases)? (2) If about a third of a large amount of healthy individuals have tongueprints, mainstream diagnosis by inspecting tongueprints should lead to an over-diagnosis problem and some healthy individuals are diagnosed mistakenly as unhealthy individuals because it holds tongueprints themselves declare publicly diseases. Thus it is necessary to diagnose definitely a tongueprint image belong to an unhealthy individual based on tongueprint features. This is a basic problem and is of theoretical and practical importance for diagnosis by inspecting tongueprints. And which features of tongueprints can be used to diagnose definitely a tongueprint image belong to an unhealthy individual? (3) Actually, the second problem is recognition and classification of tongueprints in healthy and unhealthy individuals. To further promote the modernization process of the traditional tongue diagnosis,how are the researches done on automatic classification of tongueprints in healthy and unhealthy individuals? After further making sure there appear tongueprints in healthy individuals and finding which features of tongueprints can be used to diagnose definitely a tongueprint image belong to an unhealthy individual by statistic analysis on a large database of tongue images (more than 3000 cases), this paper do the researches about automatic classification of tongueprints in healthy and unhealthy individuals based on the large database. Firstly tongeprint regions are extracted by multi-direction synthetic tongueprint extraction. Then a SVM classifier is used to recognize a tongueprint image belong to a healthy or unhealthy individual based on tongueprint features. Recognition accurate rate of tongueprints in healthy and unhealthy individuals respectively are 75.81% and 74.61% based on the large database.		ZhaoHui Yang;Naimin Li	2008		10.1007/978-3-540-77413-6_18	alternative medicine;medicine;pathology;communication	Crypto	34.680371756230905	-73.90445002258406	166214
ff7b5c781f10ab4dc47e6c8cb786bcb32d8a4a2d	automatic bladder segmentation from ct images using deep cnn and 3d fully connected crf-rnn	segmentation;bladder;cnn;crf-rnn	Automatic approach for bladder segmentation from computed tomography (CT) images is highly desirable in clinical practice. It is a challenging task since the bladder usually suffers large variations of appearance and low soft-tissue contrast in CT images. In this study, we present a deep learning-based approach which involves a convolutional neural network (CNN) and a 3D fully connected conditional random fields recurrent neural network (CRF-RNN) to perform accurate bladder segmentation. We also propose a novel preprocessing method, called dual-channel preprocessing, to further advance the segmentation performance of our approach. The presented approach works as following: first, we apply our proposed preprocessing method on the input CT image and obtain a dual-channel image which consists of the CT image and an enhanced bladder density map. Second, we exploit a CNN to predict a coarse voxel-wise bladder score map on this dual-channel image. Finally, a 3D fully connected CRF-RNN refines the coarse bladder score map and produce final fine-localized segmentation result. We compare our approach to the state-of-the-art V-net on a clinical dataset. Results show that our approach achieves superior segmentation accuracy, outperforming the V-net by a significant margin. The Dice Similarity Coefficient of our approach (92.24%) is 8.12% higher than that of the V-net. Moreover, the bladder probability maps performed by our approach present sharper boundaries and more accurate localizations compared with that of the V-net. Our approach achieves higher segmentation accuracy than the state-of-the-art method on clinical data. Both the dual-channel processing and the 3D fully connected CRF-RNN contribute to this improvement. The united deep network composed of the CNN and 3D CRF-RNN also outperforms a system where the CRF model acts as a post-processing method disconnected from the CNN.	artificial neural network;biological neural networks;bladder tissue;ct scan;coefficient;conditional random field;convergence (action);convolutional neural network;deep learning;dual;ephrin type-b receptor 1, human;experiment;informed consent;manuscripts;map;mental suffering;multi-channel memory architecture;natural science disciplines;preprocessor;random neural network;recurrent neural network;segmentation action;silo (dataset);urinary bladder;video post-processing;voxel;x-ray computed tomography;biologic segmentation;standards characteristics	Xuanang Xu;Fugen Zhou;Bo Liu	2018	International Journal of Computer Assisted Radiology and Surgery	10.1007/s11548-018-1733-7	convolutional neural network;computer vision;deep learning;clinical practice;conditional random field;automatic bladder;recurrent neural network;preprocessor;segmentation;medicine;artificial intelligence	Vision	31.0487295252115	-75.39176769740823	166304
67cdd7b7d8413ce7b177a6b7e6199a575aa0b315	on plant detection of intact tomato fruits using image analysis and machine learning methods	fruit detection;tomato;photography;machine learning;image interpretation computer assisted;artificial intelligence;algorithms;fruit;agriculture;image analysis;food analysis;lycopersicon esculentum;young fruit	Fully automated yield estimation of intact fruits prior to harvesting provides various benefits to farmers. Until now, several studies have been conducted to estimate fruit yield using image-processing technologies. However, most of these techniques require thresholds for features such as color, shape and size. In addition, their performance strongly depends on the thresholds used, although optimal thresholds tend to vary with images. Furthermore, most of these techniques have attempted to detect only mature and immature fruits, although the number of young fruits is more important for the prediction of long-term fluctuations in yield. In this study, we aimed to develop a method to accurately detect individual intact tomato fruits including mature, immature and young fruits on a plant using a conventional RGB digital camera in conjunction with machine learning approaches. The developed method did not require an adjustment of threshold values for fruit detection from each image because image segmentation was conducted based on classification models generated in accordance with the color, shape, texture and size of the images. The results of fruit detection in the test images showed that the developed method achieved a recall of 0.80, while the precision was 0.88. The recall values of mature, immature and young fruits were 1.00, 0.80 and 0.78, respectively.	attempt;class;cluster analysis;color;digital camera;fruit;image analysis;image processing;image segmentation;machine learning;pixel;plant leaves;segmentation action;benefit;biologic segmentation;statistical cluster	Kyosuke Yamamoto;Wei Guo;Yosuke Yoshioka;Seishi Ninomiya	2014		10.3390/s140712191	computer vision;agriculture;image analysis;computer science;engineering;photography	HCI	34.95923773219295	-70.55172606945025	166326
88bedb11fbf443bac3ac20276933692b3e0d84d0	basic study of automated diagnosis of viral plant diseases using convolutional neural networks		Detecting plant diseases is usually difficult without an experts’ knowledge. Therefore, fast and accurate automated diagnostic methods are highly desired in agricultural fields. Several studies on automated plant disease diagnosis have been conducted using machine learning methods. However, with these methods, it can be difficult to detect regions of interest, (ROIs) and to design and implement efficient parameters. In this study, we present a novel plant disease detection system based on convolutional neural networks (CNN). Using only training images, CNN can automatically acquire the requisite features for classification, and achieve high classification performance. We used a total of 800 cucumber leaf images to train CNN using our innovative techniques. Under the 4-fold cross-validation strategy, the proposed CNN-based system (which also extends the training dataset by generating additional images) achieves an average accuracy of 94.9 % in classifying cucumbers into two typical disease classes and a non-diseased class.	convolutional neural network;neural networks	Yusuke Kawasaki;Hiroyuki Uga;Satoshi Kagiwada;Hitoshi Iyatomi	2015		10.1007/978-3-319-27863-6_59	computer science;bioinformatics;artificial intelligence;machine learning	NLP	32.46376534574828	-75.77190860789949	166343
80d2a700f017464c92f6a65a312e788042a48780	automatic detection and quantification of tree-in-bud (tib) opacities from ct scans	silicon;sensitivity and specificity;radiology;design automation;radiography thoracic;computed tomography;tree in bud tib;lungs;statistical method;algorithms artificial intelligence humans lung diseases pattern recognition automated radiographic image interpretation computer assisted radiography thoracic reproducibility of results sensitivity and specificity tomography x ray computed;willmore energy;ct scan;computer assisted detection cad;receiver operating characteristic curve;lung;image texture;shape;statistical analysis;automatic detection;feature extraction shape lungs computed tomography design automation diseases silicon;statistical analysis computerised tomography diseases feature extraction image texture lung medical image processing radiology sensitivity analysis;lung diseases;sensitivity analysis;feature extraction;medical image processing;reproducibility of results;observer cad agreements automatic detection automatic quantification tree in bud opacities ct scans computer assisted detection system cad system abnormal nodular branching opacities chest computed tomography candidate imaging patterns local scale information mobius invariant feature extraction method local shape properties texture properties tib patterns ball scale filtering small size patterns receiver operator characteristics curves visual grading scheme patient data well trained radiologists lung zones high detection rates;computerised tomography;detection rate;diseases;infectious diseases;artificial intelligence;algorithms;willmore energy computer assisted detection cad infectious diseases lung tree in bud tib;pattern recognition automated;humans;radiographic image interpretation computer assisted;infectious disease;extraction method;invariant feature;tomography x ray computed	This study presents a novel computer-assisted detection (CAD) system for automatically detecting and precisely quantifying abnormal nodular branching opacities in chest computed tomography (CT), termed tree-in-bud (TIB) opacities by radiology literature. The developed CAD system in this study is based on 1) fast localization of candidate imaging patterns using local scale information of the images, and 2) Möbius invariant feature extraction method based on learned local shape and texture properties of TIB patterns. For fast localization of candidate imaging patterns, we use ball-scale filtering and, based on the observation of the pattern of interest, a suitable scale selection is used to retain only small size patterns. Once candidate abnormality patterns are identified, we extract proposed shape features from regions where at least one candidate pattern occupies. The comparative evaluation of the proposed method with commonly used CAD methods is presented with a dataset of 60 chest CTs (laboratory confirmed 39 viral bronchiolitis human parainfluenza CTs and 21 normal chest CTs). The quantitative results are presented as the area under the receiver operator characteristics curves and a computer score (volume affected by TIB) provided as an output of the CAD system. In addition, a visual grading scheme is applied to the patient data by three well-trained radiologists. Interobserver and observer-computer agreements are obtained by the relevant statistical methods over different lung zones. Experimental results demonstrate that the proposed CAD system can achieve high detection rates with an overall accuracy of 90.96%. Moreover, correlations of observer-observer (R2=0.8848, p <; 0.01) and observer-CAD agreements (R2=0.824, p <; 0.01) validate the feasibility of the use of the proposed CAD system in detecting and quantifying TIB patterns.	bronchiolitis;bronchiolitis, viral;bud - chv concept;ct scan;computer-aided design;feature extraction;histopathologic grade;limited availability;quantitation;radiology;receiver operator characteristics;scanning;sensor;silo (dataset);structure of parenchyma of lung;tebibyte	Ulas Bagci;Jianhua Yao;Albert Wu;Jesus Caban;Tara N. Palmore;Anthony F. Suffredini;Omer Aras;Daniel J. Mollura	2012	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2012.2190984	willmore energy;image texture;computer vision;simulation;radiology;medicine;pathology;feature extraction;shape;computer science;engineering;mathematics;computed tomography;silicon;sensitivity analysis;receiver operating characteristic	Vision	37.616716760624975	-77.81517762170634	166344
583b591101a1a4ce9092ad2f71cee5fe9ffc84bf	estimated of coordinates of user's looked point on laptop screen by ann	internal webcam;image capture;laptop user images;neural nets;laptop computers;training;ann;coordinate region estimation;eye region;artificial neural networks;test set processing;mouse control eye gaze eye tracking;portable computers;mouse control;feature extraction;webcams;image regions;artificial neural network training;training set creation;user looked point coordinate estimation;image pixels;eye tracking;learning artificial intelligence;webcams artificial neural networks conferences feature extraction portable computers training;laptop screen;eye gaze;conferences;image pieces	In this study, is aimed to estimated of the region which observed on the screen by the artificial neural network (ANN) trained with using images of laptop user. Study were formed of two phases. In the first stage, an ANN has been developed for determining eye region in the captured image with webcam. In the second stage, the data obtained from the eye region are used for training of another ANN which will be estimated to region of coordinate. For the creation of the training set, the laptop screen is divided to 57×32 pieces region of coordinate (24×24 pixels in size). 100 pieces of these regions identified as random. And user when looking at each of this regions were taken 20 different images via internal webcam. For the creation of test set randomly selected 20 regions. And each of this regions were taken 20 different images. In the training set was used 2000 pieces image. Similarly, test set was created using 400 images. The result of the test set processing with ANN, the region of coordinates in close proximity to the actual region of coordinates were obtained. Of the regions estimated via the ANN, was seen to cluster around of actual region and does not interfere the values obtained for the different zones.	artificial neural network;laptop;pixel;randomness;test set;webcam	Bulent Turan;Halil Ibrahim Eskikurt;Mehmet Serhat Can	2014	2014 22nd Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2014.6830177	computer vision;simulation;eye tracking;computer science;artificial intelligence;machine learning;artificial neural network	ML	31.135620960843994	-68.97409051285871	166390
074093678719d7f8d57e8f5f24126d4fac76c8b4	a computer aided detection system for cerebral microbleeds in brain mri	cad system;computer aided analysis;brain;medical image processing biomedical mri brain computer aided analysis diseases;image processing;computer aided diagnosis;image processing computer aided detection system cerebral microbleeds brain mri brain image lesions hemorrhages ischemic stroke intracerebral bleeding cad system visual analysis skull stripping initial candidate selection false positive reduction local image descriptor features;brain mri;brain image lesions;training;initial candidate selection;magnetic resonance imaging biomedical imaging training sensitivity feature extraction blood vessels;ischemic stroke;biomedical imaging;classification;blood vessel;magnetic resonance image;sensitivity;hemorrhages;computer aided diagnosis brain mri cerebral microbleeds classification;skull stripping;feature extraction;medical image processing;intracerebral bleeding;magnetic resonance imaging;visual analysis;brain imaging;diseases;computer aided detection;local image descriptor features;false positive;cerebral microbleeds;blood vessels;false positive reduction;biomedical mri;computer aided detection system	Advances in MR technology have improved the potential for visualization of small lesions in brain images. This has resulted in the opportunity to detect cerebral microbleeds (CMBs), small hemorrhages in the brain that are known to be associated with risk of ischemic stroke and intracerebral bleeding. In this paper, we propose a computer aided detection (CAD) system for the detection of CMBs to speed up visual analysis. Our method consists of three steps: (i) skull-stripping (ii) initial candidate selection and (iii) reduction of false-positives (FPs) using a two layer classification. Geometrical, intensity-based and local image descriptor features were used in the classification steps. The training and test set consist of 156 subjects (448 CMBs) and 81 subjects (183 CMBs), respectively. The sensitivity for CMB detection was 91% with, on average, 4.1 false-positives per subject.	computer-aided design;test set;visual descriptor	Babak Ghafaryasl;Fedde van der Lijn;Marielle Poels;Henri A. Vrooman;M. Arfan Ikram;Wiro J. Niessen;Aad van der Lugt;Meike W. Vernooij;Marleen de Bruijne	2012	2012 9th IEEE International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2012.6235503	computer vision;radiology;medicine;pathology;type i and type ii errors;sensitivity;feature extraction;biological classification;computer science;magnetic resonance imaging	Arch	35.62960305152204	-77.46958927781989	166464
279269e4e05fce0c326e6b43b9cff2529c642679	image retrieval based on lbp pyramidal multiresolution using reversible watermarking		In the medical field, images are increasingly used to facilitate diagnosis of diseases. These images are stored in multimedia databases accompanied by doctor’s prescriptions and other information related to patients. Search for medical images has become for clinical applications an essential tool to bring effective aid in diagnosis. Content Based Image Retrieval (CBIR) is one of the possible solutions to effectively manage these databases. Our contribution is to define a relevant descriptor to retrieve images based on multiresolution analysis of texture using Local Binary Pattern LBP. This descriptor once calculated and information’s relating to the patient; will be placed in the image using the technique of reversible watermarking. Thereby, the image, descriptor of its contents, the BFILE locator and patientrelated information become a single entity, so even the administrator cannot have access to the patient private data. Keywords— Reversible Watermarking, LBP, Pyramidal analysis, CBIR.	airplane mode;content-based image retrieval;database;digital watermarking;embedded system;information privacy;local binary patterns;multiresolution analysis;online and offline;online locator service;personally identifiable information	H. Ouahi;Karim Afdel;Mustapha Machkour	2015	CoRR		computer vision;local binary patterns;computer science;data mining;multimedia	Vision	32.923490763942524	-71.1672906045565	166474
0314826fd8b94343e1c5a131179ab0a844f99eb7	microcalcification classification assisted by content-based image retrieval for breast cancer diagnosis	microcalcification classification;support vector machines;perforation;adaptive support vector machine;image classification;support vector machines content based retrieval image classification image retrieval learning artificial intelligence mammography medical image processing;breast cancer diagnosis;indexing terms;machine learning;medical image processing;adaptive support vector machine microcalcification classification content based image retrieval content based mammogram retrieval breast cancer diagnosis machine learning similarity measure local proximity information classification accuracy mammogram database;roc curve;image retrieval content based retrieval breast cancer support vector machines support vector machine classification information retrieval biomedical engineering machine learning image databases biomedical computing;image retrieval microcalcification classification adaptive support vector machine;support vector machine;mammography;learning artificial intelligence;classification accuracy;content based image retrieval;content based retrieval;image retrieval	"""In this paper we propose a microcalcification classification scheme, assisted by content-based mammogram retrieval, for breast cancer diagnosis. We recently developed a machine learning approach for mammogram retrieval where the similarity measure between two lesion mammograms is modeled after expert observers. In this work we investigate how to use retrieved similar cases as references to improve the performance of a numerical classifier. Our rationale is that by adap-tively incorporating local proximity information into a classifier, it can help improve its classification accuracy, thereby leading to an improved """"second opinion"""" to radiologists. Our experimental results on a mammogram database demonstrate that the proposed retrieval-driven approach with an adaptive support vector machine (SVM) could improve the classification performance from 0.78 to 0.82 in terms of the area under the ROC curve."""	content-based image retrieval	Yongyi Yang;Liyang Wei;Robert M. Nishikawa	2007		10.1109/ICIP.2007.4379750	support vector machine;computer vision;image retrieval;computer science;machine learning;pattern recognition	Vision	32.97973282694427	-71.8842390459619	166779
0f4a10d6d8292dfd468b5ad7c8f9a2ba15201713	improving mass detection performance by use of 3d difference filter in a whole breast ultrasonography screening system	evaluation performance;performance evaluation;mass screening;computer aided diagnosis;ultrasound;deteccion;masse;estudio comparativo;evaluacion prestacion;rule based;performance;mammary gland;echography;detection;breast;glandula mamaria;etude comparative;scanners;filter;breast cancer screening;comparative study;depistage;descubrimiento;filtre;computer aided detection;glande mammaire;medical screening;ultrasonography;rendimiento;false positive;masa;quadratic discriminant analysis;reduction method;breast cancer;filtro;ecografia;echographie;mass	Ultrasonography is one of the most important methods for breast cancer screening in Japan. Several mechanical whole breast ultrasound (US) scanners have been developed for mass screening. We have reported a computeraided detection (CAD) scheme for the detection of masses in whole breast US images. In this study, the method of detecting mass candidates and the method of reducing false positives (FPs) were improved in order to enhance the performance of this scheme. A 3D difference (3DD) filter was newly developed to extract low-intensity regions. The 3DD filter is defined as the difference of pixel values between the current pixel value and the mean pixel value of 17 neighboring pixels. Low-intensity regions were efficiently extracted by use of 3DD filter values, and FPs were reduced using a FP reduction method employing the rule-based technique and quadratic discriminant analysis with the filter values. The performance of our previous and improved CAD schemes indicated a sensitivity of 80.0% with 16.8 FPs and 9.5 FPs per breast, respectively. The FPs of the improved scheme were reduced by 44% as compared to the previous scheme. The 3DD filter was useful for the detection of masses in whole breast US images.		Yuji Ikedo;Daisuke Fukuoka;Takeshi Hara;Hiroshi Fujita;Etsuo Takada;Tokiko Endo;Takako Morita	2008		10.1117/12.769301	rule-based system;type i and type ii errors;performance;quadratic classifier;filter;ultrasonography;breast cancer;comparative research;ultrasound;mass	Vision	36.823834746226325	-74.70970661168538	166921
d8cd3fc8339a77b06ddb081d262a43f65acfa87d	deep learning vs. conventional machine learning: pilot study of wmh segmentation in brain mri with absence or mild vascular pathology		In the wake of the use of deep learning algorithms in medical image analysis, we compared performance of deep learning algorithms, namely the deep Boltzmann machine (DBM), convolutional encoder network (CEN) and patch-wise convolutional neural network (patch-CNN), with two conventional machine learning schemes: Support vector machine (SVM) and random forest (RF), for white matter hyperintensities (WMH) segmentation on brain MRI with mild or no vascular pathology. We also compared all these approaches with a method in the Lesion Segmentation Tool public toolbox named lesion growth algorithm (LGA). We used a dataset comprised of 60 MRI data from 20 subjects in the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database, each scanned once every year during three consecutive years. Spatial agreement score, receiver operating characteristic and precision-recall performance curves, volume disagreement score, agreement with intra-/inter-observer reliability measurements and visual evaluation were used to find the best configuration of each learning algorithm for WMH segmentation. By using optimum threshold values for the probabilistic output from each algorithm to produce binary masks of WMH, we found that SVM and RF produced good results for medium to very large WMH burden but deep learning algorithms performed generally better than conventional ones in most evaluations.		Muhammad Febrian Rachmadi;Maria del C. Valdés Hernández;Maria Leonora Fatimah Agan;Taku Komura	2017	J. Imaging	10.3390/jimaging3040066	convolutional neural network;deep learning;support vector machine;mathematics;boltzmann machine;receiver operating characteristic;machine learning;pathology;random forest;hyperintensity;artificial intelligence	ML	31.207489496517905	-75.87590024421358	167243
2f35e451cf51168257cd9808f6ce6eab4b0bdcf2	a system for an automatic reading of student information sheets	databases;handwriting recognition;writing language identification;authoring languages;image classification;data mining;accuracy;feature extraction;handwritten recognition form segmentation feature extraction writing language identification;image classification authoring languages decision trees document image processing handwritten character recognition;document image processing;writing;feature extraction handwriting recognition writing decision trees databases data mining accuracy;form segmentation;decision trees;handwritten character recognition;handwritten recognition;image classification automatic reading student information sheets handwritten answer field script language differentiation decision tree sheet recognition arabic scripts french scripts printed sheets	In this paper we present a student information sheet reading system. Relevant algorithm is proposed to locate and label handwritten answer field. As information sheets can be filled in Arabic and/or in French, automating the script language differentiation is a pre-recognition required in the proposed system. We have developed a robust and fast field classification and script language identification method, based on a decision tree, to make these processing practical for sheet recognition. To this end, the system uses several novel features (loops, descenders, diacritics) and analyses the lower profile of script. The classification rates are 92.5% for numeric fields, 94.34% for Arabic scripts and 94.66% for French scripts. Experimental results, carried on 80 sheets, show our system provides an effective way to convert printed sheets into computerized format or collect information for database from printed sheets.	algorithm;decision tree;language identification;printing;scripting language	Afef Kacem;Asma Saïdani;Abdel Belaïd	2011	2011 International Conference on Document Analysis and Recognition	10.1109/ICDAR.2011.255	natural language processing;contextual image classification;speech recognition;feature extraction;computer science;machine learning;decision tree;pattern recognition;accuracy and precision;handwriting recognition;writing	Robotics	33.337889592966384	-66.23901756535065	167296
418c5ba0fb0bf1bb64242786c8540f73d59546dd	a sorting system for hierarchical grading of diabetic fundus images: a preliminary study	patient diagnosis;protocols;vision diseases image classification learning artificial intelligence medical computing medical image processing patient diagnosis sorting;hybrid intelligent systems;visual loss;sorting;sorting diabetes retinopathy protocols blindness medical treatment standards development personnel throughput hybrid intelligent systems;diabetes;image classification;classification;hybrid intelligent system;knowledge representation classification diabetic retinopathy hybrid intelligent system;medical computing;standards development;blindness;multilevel knowledge representation;ophthalmologist;diabetic fundus images;sorting system;personnel;medical image processing;retinopathy;diabetic retinopathy;diseases;developing country;diabetic retinopathy fundus oculi humans user computer interface;learning artificial intelligence;knowledge representation;medical treatment;hierarchical grading;vision;multilevel knowledge representation sorting system hierarchical grading diabetic fundus images diabetic retinopathy blindness visual loss united states ophthalmologist hybrid intelligent system;early treatment diabetic retinopathy study;throughput	Diabetic retinopathy is a leading cause of blindness in developed countries. Diabetic patients can prevent severe visual loss by attending regular eye examinations and receiving timely treatments. In the United States, standard protocols have been developed and refined for years to provide better screening and evaluation procedures of the fundus images. Due to the emerging number of diabetic retinopathy cases, accurate and efficient evaluations of the fundus images have become a serious burden for the ophthalmologists or care providers. While diabetic retinopathy remains too complicated to call for an automatic diagnosis system, an efficient tool to facilitate the grading process with a limited number of personnel is in great demand. The current study is to develop a sorting system with a user-friendly interface, based upon the standardized early treatment diabetic retinopathy study (ETDRS) protocol, to assist the professional graders. The raw fundus images will be screened and assigned to different graders according to their skill levels and experiences. The developed hierarchical sorting process will greatly support the graders and enhance their efficiency and throughput. The proposed hybrid intelligent system with multilevel knowledge representation is used to construct this sorting system. A preliminary case study is conducted using only the features of the spot lesion group coupled with the ETDRS standard to demonstrate its feasibility and performance. The results obtained from the case study show a promising future.	classification;diabetes mellitus;diabetic neuropathies;diabetic retinopathy;embedded system;embedding;evaluation;experience;explanation module;histopathologic grade;hybrid intelligent system;knowledge representation and reasoning;linguistics;patients;personnameuse - assigned;projection screen;protocols documentation;retinal diseases;simulation;sorting;throughput;usability;hearing impairment	Gary G. Yen;Wen-Fung Leong	2008	IEEE Transactions on Information Technology in Biomedicine	10.1109/TITB.2007.910453	knowledge representation and reasoning;vision;communications protocol;computer vision;contextual image classification;ophthalmology;throughput;medicine;developing country;biological classification;computer science;sorting;artificial intelligence;optometry;hybrid intelligent system	Visualization	33.52841333574073	-77.94675948138277	167603
0393269b63766b9d0dc5c97f9baf736fd4accf47	an approach for reducing the error rate in automated lung segmentation	segmentation fusion;computed tomography;classification;lung segmentation	Robust lung segmentation is challenging, especially when tens of thousands of lung CT scans need to be processed, as required by large multi-center studies. The goal of this work was to develop and assess a method for the fusion of segmentation results from two different methods to generate lung segmentations that have a lower failure rate than individual input segmentations. As basis for the fusion approach, lung segmentations generated with a region growing and model-based approach were utilized. The fusion result was generated by comparing input segmentations and selectively combining them using a trained classification system. The method was evaluated on a diverse set of 204 CT scans of normal and diseased lungs. The fusion approach resulted in a Dice coefficient of 0.9855±0.0106 and showed a statistically significant improvement compared to both input segmentation methods. In addition, the failure rate at different segmentation accuracy levels was assessed. For example, when requiring that lung segmentations must have a Dice coefficient of better than 0.97, the fusion approach had a failure rate of 6.13%. In contrast, the failure rate for region growing and model-based methods was 18.14% and 15.69%, respectively. Therefore, the proposed method improves the quality of the lung segmentations, which is important for subsequent quantitative analysis of lungs. Also, to enable a comparison with other methods, results on the LOLA11 challenge test set are reported.		Gurman Gill;Reinhard Beichel	2016	Computers in biology and medicine	10.1016/j.compbiomed.2016.06.022	computer vision;radiology;pathology;biological classification;computed tomography	Robotics	37.21061034720102	-79.34955502866416	167696
c4cd8d80f1ea58059b5b122a9f4f84135fb67960	automated discrimination of pathological regions in tissue images: unsupervised clustering vs. supervised svm classification	lung cancer;unsupervised clustering;support vector machine;k means clustering;quantitative evaluation	Recognizing and isolating cancerous cells from non pathological tissue areas (e.g. connective stroma) is crucial for fast and objective immunohistochemical analysis of tissue images. This operation allows the further application of fully-automated techniques for quantitative evaluation of protein activity, since it avoids the necessity of a preventive manual selection of the representative pathological areas in the image, as well as of taking pictures only in the pure-cancerous portions of the tissue. In this paper we present a fully-automated method based on unsupervised clustering that performs tissue segmentations highly comparable with those provided by a skilled operator, achieving on average an accuracy of 90%. Experimental results on a heterogeneous dataset of immunohistochemical lung cancer tissue images demonstrate that our proposed unsupervised approach overcomes the accuracy of a theoretically superior supervised method such as Support Vector Machine (SVM) by 8%.	artificial neural network;cluster analysis;image segmentation;logical connective;support vector machine;unsupervised learning	Santa Di Cataldo;Elisa Ficarra;Enrico Macii	2008		10.1007/978-3-540-92219-3_26	support vector machine;computer science;machine learning;pattern recognition;data mining;k-means clustering	ML	34.40928026489002	-76.17722341800841	167777
6ed42b626c80c3199a8c4603c8c5aed98f0c5d07	application of cost-sensitive fuzzy classifiers to image understanding problems	image classification fuzzy set theory;image understanding problems;fuzzy set;image segmentation;image processing;cost function;image understanding;training;image classification;cost sensitive fuzzy classifiers;fuzzy set theory;fuzzy sets;fuzzy rule base;image processing cost sensitive fuzzy classifiers image understanding problems fuzzy rule based classifier cost function fuzzy sets;feature extraction;satellites;pattern classification;fuzzy if then rules;fuzzy sets pattern classification cancer image processing fuzzy systems medical diagnosis classification algorithms cost function hypercubes feature extraction;fuzzy rule based classifier;breast cancer;fuzzy classifier	Image understanding applications often involve a pattern classification stage. In this paper we show how a fuzzy rule-based classifier, extended to incorporate a cost function, can be successfully used in various imaging applications. The antecedent part of fuzzy if-then rules are specified by partitioning each attributes into fuzzy sets while the consequent class and the degree of certainty are determined from compatibility training patterns. Extension to include a cost term is shown to be straightforward and experimental results on several image processing tasks demonstrate the efficacy of our method.	algorithm;computer vision;fuzzy classification;fuzzy concept;fuzzy rule;fuzzy set;image processing;image segmentation;logic programming;loss function	Gerald Schaefer;Takashima Nakashima	2009	2009 IEEE International Conference on Fuzzy Systems	10.1109/FUZZY.2009.5276886	membership function;defuzzification;image processing;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;data mining;mathematics;fuzzy set;fuzzy set operations	Robotics	37.06430278938026	-71.96534058517355	167785
f99724268a80b768dc6b9461fb10911f20c380a8	quantification of blood vessel calibre in retinal images of multi-ethnic school children using a model based approach	ophthalmology;retinal blood vessels;medical imaging;width measurement;computer science and informatics;model fitting;retinal image analysis;retinal image database	Changes and variation in retinal vessel width are related to vascular risk factors and prospectively related to cardiovascular disease in later life. Hence, assessment of vessel width may be a useful physio-marker and potential predictor of cardiovascular status. However, measurement of vessel calibre from retinal images is a challenging process to automate. This paper proposes an automated system to measure vessel calibre in retinal images, which is demonstrated in images of multi-ethnic school children. The diameter measurement is based on the detection of the centreline pixels from a vessel probability map image, determining the vessel orientation at these pixels, extracting the vessel segments and later using a two-dimensional model, which is optimized to fit various types of intensity profiles of vessel segments. The width is then estimated from parameters of the optimized model. The method is also quantitatively analyzed using monochromatic representations of different colour spaces. The algorithm is evaluated on a recently introduced public database CHASE_DB1, which is a subset of retinal images of multi-ethnic children from the Child Heart and Health Study in England (CHASE) dataset. Moreover, the precise estimation of retinal vascular widths is critical for epidemiologists to identify the risk factors. This work also introduces an interactive software tool for epidemiologists, with which retinal vessel calibre can be precisely marked.		Muhammad Moazam Fraz;Paolo Remagnino;Andreas Hoppe;Alicja R. Rudnicka;Christopher G. Owen;Peter Whincup;Sarah Barman	2013	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2013.01.004	medical imaging;computer vision;radiology;medicine	Vision	37.0422851565604	-78.81609119871307	167868
6b74b928992d3d19aa97492175784385dc4093f5	diagnosis of breast tumors with ultrasonic texture analysis using support vector machines	base donnee;multilayer;coeficiente correlacion;ultrason;analisis textura;computer aided diagnosis;loi probabilite;tumor maligno;ley probabilidad;ultrasound;sistema informatico;diagnostico;database;base dato;matrice covariance;image classification;clasificador;computer system;couche multimoleculaire;matriz covariancia;texture features;multilayer perception;textural analysis;ultrasound imaging;texture analysis;perception multicouche;classifier;red multinivel;ultrasonido;probability distribution;classification image;computer aid;capa multimolecular;classificateur;differential diagnosis;asistencia ordenador;svm;systeme informatique;tumeur maligne;analyse vectorielle;multilayer network;support vector machine;reseau multicouche;reseau neuronal;correlation coefficient;diagnosis;analyse texture;coefficient correlation;breast cancer;assistance ordinateur;red neuronal;vector analysis;malignant tumor;covariance matrix;neural network;diagnostic	This study presents a computer-aided diagnosis (CAD) system with textural features for classifying benign and malignant breast tumors on medical ultrasound systems. A series of pathologically proven breast tumors were evaluated using the support vector machine (SVM) in the differential diagnosis of breast tumors. The proposed CAD system utilized facile textural features, i.e., block difference of inverse probabilities, block variation of local correlation coefficients and auto-covariance matrix, to identify breast tumor. An SVM classifier using the textual features classified the tumor as benign or malignant. The proposed system identifies breast tumors with a comparatively high accuracy. This can help inexperienced physicians avoid misdiagnosis. The main advantage of the proposed system is that the training and diagnosis procedure of SVM are faster and more stable than that of multilayer perception neural networks. With the expansion of the database, new cases can easily be gathered and used as references. This study dramatically reduces the training and diagnosis time. The SVM is a reliable choice for the proposed CAD system because it is fast and excellent in ultrasound image classification.	artificial neural network;coefficient;computer vision;computer-aided design;experience;medical ultrasound;support vector machine	Yu-Len Huang;Kao-Lun Wang;Dar-Ren Chen	2005	Neural Computing & Applications	10.1007/s00521-005-0019-5	support vector machine;speech recognition;computer science;artificial intelligence;machine learning;artificial neural network	ML	34.37547494360694	-72.94112757421598	167911
c6f0b1003aa70b1defdca83f28a27559d1104514	methods and criteria for detecting significant regions in medical image analysis	image features;medical image analysis;medical image;image analysis	This paper studies the problem of detecting significant regions in medical image analysis. The solution of this non well-defined problem requires in general several criteria to attempt to measure the relevance of an input image features. Criteria properties are important in medical imaging in order to permit their application in a variety of situations. We adopt in this paper the morphological framework, which facilitates the study of the problem and, in addition, provides useful pre-processing and image analysis techniques.		José Crespo;Holger Billhardt;Juan Rodríguez-Pedrosa;José A. Sanandrés	2001		10.1007/3-540-45497-7_3	computer vision;feature detection;image analysis;computer science;pattern recognition;data mining;feature	Vision	34.04010543976278	-74.35631271007104	168034
0e3b94621a788281ee67ccad3e91bac92734e321	shrec’08 entry: training set expansion via autotags	text tagging;h 3 1 information storage and retrieval content analysis and indexing classification labeling autotagging;query processing;shape descriptor;shape solid modeling airplanes aircraft labeling information retrieval content based retrieval information analysis indexing nearest neighbor searches;large dataset;3d model classifier;h 3 1 information storage and retrieval content analysis and indexing;text tag;query model;autotagging;text analysis;robotics;indexing terms;classification;content analysis;3d model;shape descriptor shrec training set expansion autotag 3d model classifier partially classified model text tag tag assignment query model tag similarity;indexing;partially classified model;shrec;indexation;artificial intelligence;tag similarity;text analysis classification indexing query processing;autotag;information storage and retrieval;training set expansion;labeling;tag assignment	Training a 3D model classifier on a small dataset is very challenging. However, large datasets of partially classified models are now commonly available online. We use an external training set of models with associated text tags to automatically assign tags to both training and query models. The similarity between these tags, used in conjunction with a standard shape descriptor, yields a multiclassifier that outperforms the standalone shape descriptor.	test set	Corey Goldfeder;Haoyun Feng;Peter K. Allen	2008	2008 IEEE International Conference on Shape Modeling and Applications	10.1109/SMI.2008.4547983	computer science;pattern recognition;data mining;information retrieval	Vision	30.296883189418587	-66.57387837550034	168038
e910f99b3e291c8e0ae209790ee7d7ee908a4e23	disease classification and prediction via semi-supervised dimensionality reduction	unlabeled data;constrained matrix decomposition;basis learning;matrix factorization;semisupervised algorithm;disease prediction;image classification;biomedical imaging;semi supervised learning;semisupervised dimensionality reduction;objective function;accuracy;laplace equations;medical image;mild cognitive impairment disease prediction semisupervised dimensionality reduction semisupervised algorithm image based disease classification medical imaging constrained matrix decomposition semisupervised learning;matrix decomposition;medical image processing;medical imaging;image based disease classification;alzheimer s disease;laplace equations accuracy matrix decomposition optimization alzheimer s disease biomedical imaging;diseases;normal control;optimization;mild cognitive impairment mci;mild cognitive impairment;learning artificial intelligence;dimensional reduction;medical image processing diseases image classification learning artificial intelligence;semisupervised learning;high risk;mild cognitive impairment mci semi supervised learning basis learning matrix factorization optimization alzheimer s disease	We present a new semi-supervised algorithmfor dimensionality reduction which exploits information of unlabeled data in order to improve the accuracy of image-based disease classification based on medical images. We perform dimensionality reduction by adopting the formalismof constrainedmatrix decomposition of [1] to semi-supervised learning. In addition, we add a new regularization term to the objective function to better captur the affinity between labeled and unlabeled data. We apply our method to a data set consisting of medical scans of subjects classified as Normal Control (CN) and Alzheimer (AD). The unlabeled data are scans of subjects diagnosedwith Mild Cognitive Impairment (MCI), which are at high risk to develop AD in the future. We measure the accuracy of our algorithm in classifying scans as AD and NC. In addition, we use the classifier to predict which subjects with MCI will converge to AD and compare those results to the diagnosis given at later follow ups. The experiments highlight that unlabeled data greatly improves the accuracy of our classifier.	algorithm;cognition disorders;converge;dimensionality reduction;experiment;loss function;malignant fibrous histiocytoma;mild cognitive disorder;nc (complexity);optimization problem;processor affinity;scanning;semi-supervised learning;semiconductor industry;statistical classification;supervised learning;tracer;disease classification	Nematollah Batmanghelich;Dong Hye Ye;Kilian M. Pohl;Ben Taskar;Christos Davatzikos	2011	2011 IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2011.5872590	medical imaging;radiology;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;matrix decomposition	Vision	27.267051579234664	-77.78509440789834	168075
9f13742a81acd9743ab70276d4aadeb0d6d2c7e1	recognition of instrumental activities of daily living in egocentric video for activity monitoring of patients with dementia		In this chapter we study the problem of recognizing Instrumental Activities of Daily Living (IADL) in egocentric camera view. The target application of this research is the indexing of videos of patients with Alzehimer disease, thus providing medical staff with fast access and easy navigation through the video contents and helping them while assessing patients’ abilities to perform IADL. Driven by the consideration that an activity in egocentric videos can be defined as a sequence of interacted objects inside different rooms, we present a novel representation based on the output of object and room detectors over temporal segments. In addition, our object detection approach is extended by automatic detection of visually salient regions since distinguishing active objects from context has been proven to dramatically improve performances in egocentric ADL recognition. We have assessed our proposal on a publicly available egocentric dataset and show extensive experimental results that demonstrate our approach outperforms current state of the art for unconstrained scenarios in which training and testing environments may be notably different.		Iván González-Díaz;Vincent Buso;Jenny Benois-Pineau;Guillaume Bourmaud;Gaelle Usseglio;Rémi Mégret;Yann Gaëstel;Jean-François Dartigues	2015		10.1007/978-3-319-17963-6_9	psychology;developmental psychology;communication;social psychology	HCI	26.613684747639066	-75.62942535120635	168164
33468415b90a8cd31c48ada464ee7c46072e437e	analysis of the glomerular basement membrane in images of renal biopsies using the split-and-merge method: a pilot study	female;pilot study;biopsy needle;diagnostic imaging;glomerular basement membrane;comparative analysis;image processing;middle aged;standard deviation;hematuria;male;microscopy electron transmission;segmentation;diabetes mellitus;split and merge algorithm;image processing computer assisted;signal processing computer assisted;renal biopsy;statistical analysis;diabetic nephropathies;adult;algorithmic skeletons;morphological image processing;diabetic nephropathy;algorithms;humans;skeletonization;sampling studies;pilot projects;transmission electron microscope;alport syndrome;aged 80 and over;automation	Abnormal thinning, thickening, or variation in the thickness of the glomerular basement membrane (GBM) are caused by familial hematuria, diabetes mellitus, and Alport syndrome, respectively. We propose a semi-automated procedure for the segmentation and analysis of the thickness of the GBM in images of renal biopsy samples obtained by using a transmission electron microscope (TEM). The procedure includes the split-and-merge algorithm, morphological image processing, skeletonization, and statistical analysis of the width of the GBM. The procedure was tested with 34 TEM images of six patients. The mean and standard deviation of the GBM width for a patient with normal GBM were estimated to be 368 ± 177 nm, those for a patient with thin GBM associated with familial hematuria were 216 ± 95 nm, and those for a patient with thick GBM due to diabetic nephropathy were 1,094 ± 361 nm. Comparative analysis of the results of image processing with manual measurements by an experienced renal pathologist indicated low error in the range of 12 ± 9 nm.	apc gene;alport syndrome;diabetes mellitus;diabetic nephropathy;glomerular basement membrane;hematuria;image processing;kidney diseases;kidney biopsy;mathematical morphology;merge algorithm;mesa;microscope device component;patients;ramer–douglas–peucker algorithm;scanning electron microscopy;semiconductor industry;standard deviation;thickness (graph theory);thinning;transmission electron microscopes;transmission electron microscopy;biologic segmentation;width	Ilya Kamenetsky;Rangaraj M. Rangayyan;Hallgrimur Benediktsson	2009	Journal of Digital Imaging	10.1007/s10278-009-9233-5	medical imaging;qualitative comparative analysis;skeletonization;transmission electron microscopy;medicine;pathology;image processing;computer science;automation;standard deviation;segmentation;anatomy;diabetes mellitus;statistics	Vision	38.12920328305552	-79.5512212865283	168293
c75b48fb0c6f39e201d4e8e40628ca1b775722c6	inductive learning of skin lesion images for early diagnosis of melanoma	wavelet analysis;skin lesion;cancer;skin;tumours;image classification;pigmentation;malignant tumors;probes;epidemiology;malignant human cancer;wavelet transforms;learning systems;pattern discovery;early diagnosis;wavelet transform;learning by example;filtering algorithms;attributional calculus;machine learning;lesions;feature extraction;medical image processing;calculus;transforms;inductive learning;natural induction methods;tumors;feature selection;tumors lesions skin wavelet transforms filtering algorithms machine learning transforms;wavelet transforms calculus cancer feature extraction image classification learning by example medical image processing skin tumours;melanoma early diagnosis;pigmented skin lesion image;feature selection melanoma early diagnosis inductive learning pigmented skin lesion image natural induction methods attributional calculus pattern discovery image classification malignant human cancer epidemiology wavelet transform	We take advantage of natural induction methods to build classifiers of the pigmented skin lesion images. This methodology can be treated as a non-invasive approach to early diagnosis of melanoma. We use the AQ21 application, which is based on the attributional calculus, to discover patterns in the skin images. Our classifier has good efficiency and may potentially be an important diagnostic aid.	algorithm;attributional calculus;inductive reasoning;machine learning;pixel;wavelet	Grzegorz Surowka	2008	2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)	10.1109/IJCNN.2008.4634165	computer vision;epidemiology;computer science;machine learning;pattern recognition;mathematics;feature selection;wavelet transform	Vision	34.90701081557085	-73.60695093555113	168378
84591851ae048fea93ef5c51ad6fa8b7ebe66545	alzheimer's disease diagnosis based on anatomically stratified texture analysis of the hippocampus in structural mri		In this paper, we propose a novel method to integrate texture and shape analysis in an anatomically-informed way to model the hippocampus from structural MRI. Specifically, Poisson map is used to stratify the segmented hippocampus into layers, and a bag-of-words (BoW) model on the image intensity is generated to analyze the texture information embedded over the layers. Another level of BoW model is used to further encode the texture over subjects and across layers. A Bayesian non-parametric (BNP) method is proposed to infer and adjust for the variability of different layers. We validate our model on hippocampus-based Alzheimer's disease (AD) and mild cognitive impairment (MCI) diagnosis. A thorough comparison of related features is performed. Results demonstrate that our method achieves state-of-the-art performance while using information from the hippocampus only.	bag-of-words model in computer vision;encode;embedded system;shape analysis (digital geometry);spatial variability	Xinyang Feng;Jie Yang;Andrew F. Laine;Elsa D. Angelini	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363868	shape analysis (digital geometry);artificial intelligence;pattern recognition;hippocampus;computer science;poisson distribution	Vision	31.528174305189623	-77.31894615328093	168435
94b967a1fce7d8a4b4d77fbce5245fd54bfb61eb	validation of a regression technique for segmentation of white matter hyperintensities in alzheimer’s disease		"""Segmentation and volumetric quantification of white matter hyperintensities (WMHs) is essential in assessment and monitoring of the vascular burden in aging and Alzheimer’s disease (AD), especially when considering their effect on cognition. Manually segmenting WMHs in large cohorts is technically unfeasible due to time and accuracy concerns. Automated tools that can detect WMHs robustly and with high accuracy are needed. Here, we present and validate a fully automatic technique for segmentation and volumetric quantification of WMHs in aging and AD. The proposed technique combines intensity and location features frommultiplemagnetic resonance imaging contrasts and manually labeled training data with a linear classifier to perform fast and robust segmentations. It provides both a continuous subject specific WMH map reflecting different levels of tissue damage and binary segmentations. Themethodwas used to detectWMHs in 80 elderly/AD brains (ADC data set) as well as 40 healthy subjects at risk of AD (PREVENT-AD data set). Robustness across different scanners was validated using ten subjects from ADNI2/GO study. Voxel-wise and volumetric agreements were evaluated using Dice similarity index (SI) and intra-class correlation (ICC), yielding <inline-formula> <tex-math notation=""""LaTeX"""">${\mathrm{ ICC}}=0.96$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=""""LaTeX"""">${\mathrm{ SI}}= 0.62\pm 0.16$ </tex-math></inline-formula> for ADC data set and <inline-formula> <tex-math notation=""""LaTeX"""">${\mathrm{ ICC}}=0.78$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=""""LaTeX"""">${\mathrm{ SI}}=0.51\pm 0.15$ </tex-math></inline-formula> for PREVENT-AD data set. The proposed method was robust in the independent sample yielding <inline-formula> <tex-math notation=""""LaTeX"""">${\mathrm{ SI}}=0.64\pm 0.17$ </tex-math></inline-formula> with <inline-formula> <tex-math notation=""""LaTeX"""">${\mathrm{ ICC}}=0.93$ </tex-math></inline-formula> for ADNI2/GO subjects. The proposed method provides fast, accurate, and robust segmentations on previously unseen data from different models of scanners, making it ideal to study WMHs in large scale multi-site studies."""	alzheimer's disease assessment scale-cognitive cdisc version questionnaire;alzheimer's disease neuroimaging initiative;brain;cognition;eighty;hyperintensity of cerebral white matter on mri;linear classifier;numerous;quantitation;resonance;soft tissue injuries;tracer;voxel;biologic segmentation	Mahsa Dadar;Tharick A. Pascoal;Sarinporn Manitsirikul;Karen Misquitta;Vladimir S Fonov;Maria Carmela Tartaglia;John C. S. Breitner;Pedro Rosa-Neto;Owen T. Carmichael;Charles DeCarli;D. Louis Collins	2017	IEEE Transactions on Medical Imaging	10.1109/TMI.2017.2693978	mathematics;computer vision;contrast (statistics);image segmentation;artificial intelligence;training set;linear classifier;hyperintensity;pattern recognition	Visualization	33.45015273006184	-79.38661422270751	168454
f2a04484c90bb7249ad6b72e55f8919e6737419f	three-dimensional local energy-based shape histogram (3d-lesh): a novel feature extraction technique		In this paper, we present a novel feature extraction technique, termed Three-Dimensional Local EnergyBased Shape Histogram (3D-LESH), and exploit it to detect breast cancer in volumetric medical images. The technique is incorporated as part of an intelligent expert system that can aid medical practitioners making diagnostic decisions. Analysis of volumetric images, slice by slice, is cumbersome and inefficient. Hence, 3D-LESH is designed to compute a histogram-based feature set from a local energy map, calculated using a phase congruency (PC) measure of volumetric Magnetic Resonance Imaging (MRI) scans in 3D space. 3D-LESH features are invariant to contrast intensity variations within different slices of the MRI scan and are thus suitable for medical image analysis. The contribution of this article is manifold. First, we formulate a novel 3D-LESH feature extraction technique for 3D medical images to analyse volumetric images. Further, the proposed 3D-LESH algorithmis, for the first time, applied to medical MRI images. The final contribution is the design of an intelligent clinical decision support system (CDSS) as a multi-stage approach, combining novel 3D-LESH feature extraction with machine learning classifiers, to detect cancer from breast MRI scans. The proposed system applies contrast-limited adaptive histogram equalisation (CLAHE) to the MRI images before extracting 3D-LESH features. Furthermore, a selected subset of these features is fed into a machine-learning classifier, namely, a support vector machine (SVM), an extreme learning machine (ELM) or an echo state network (ESN) classifier, to detect abnormalities and distinguish between different stages of abnormality. We demonstrate the performance of the proposed technique by its application to benchmark breast cancer MRI images. The results indicate high-performance accuracy of the proposed system (98% ±0.0050, with an area under a receiver operating charactertistic curve value of 0.9900 ± 0.0050) with multiple classifiers. When compared with the state-of-the-art wavelet-based feature extraction technique, statistical analysis provides conclusive evidence of the significance of our proposed 3D-LESH algorithm. © 2017 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license. ( http://creativecommons.org/licenses/by/4.0/ )	adaptive histogram equalization;algorithm;benchmark (computing);clinical decision support system;echo state network;expert system;feature extraction;image analysis;machine learning;medical image computing;medical imaging;phase congruency;resonance;support vector machine;wavelet	Summrina Kanwal Wajid;Amir Hussain;Kaizhu Huang	2018	Expert Syst. Appl.	10.1016/j.eswa.2017.11.057	support vector machine;wavelet;machine learning;phase congruency;adaptive histogram equalization;breast mri;extreme learning machine;feature extraction;histogram;computer science;artificial intelligence;pattern recognition	ML	33.89416080723073	-74.9627348873433	168485
b3a08d292765e1977fa88cfb4e4e54932457d324	automatic detection of calcified coronary plaques in computed tomography data sets	computed tomography;coronary heart disease;automatic detection	The detection of calcified plaques is an essential step in the assessment of coronary heart diseases. However, manual plaque segmentation is subjected to intra- and inter-observer variability. We present a novel framework for the automatic detection of calcified coronary plaques in Computed Tomography images. In contrast to the state-of-the-art, both the native and the angio data sets are included to gain additional information about each plaque for its detection and subsequent assessment. The framework was successfully tested on 127 patients where 85.5% of the calcified and 96% of the obstructive plaques have been detected.	ct scan;coronary heart disease;dental plaque;heart diseases;inter-rater reliability;patients;pioneer plaque;senile plaques;spatial variability;x-ray computed tomography	Stefan C. Saur;Hatem Alkadhi;Lotus Desbiolles;Gábor Székely;Philippe C. Cattin	2008	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-540-85988-8_21	radiology;medicine;pathology;computed tomography;cardiology	Vision	38.546557754032754	-80.10625809850544	169204
523f6f604d379adc54073fa7262abcf71a14ba90	2d adaptive filtering and region growing algorithm for the detection of microaneurysms in retinal angiograms	eye;prediction error;high pass filter;automatic detection;diabetic retinopathy;algorithms;region growing;adaptive filter;diseases and disorders	ABSTRACT The diabetic retinopathy is a common disease among diabetic patients that can cause blindness. The number of microaneurysms in an eye fundus indicates the evolution stage of the illness. In this paper, an algorithm to automatically detect microaneurysms in retinal angiograms is proposed. The method has three main steps: preprocessing step, seed detection and a subsequent region-growing algorithm. The preprocessing step consists of a Gaussian high pass filtering followed by a top-hat filtering. The aim of this preprocessing step is to eliminate the vascular tree while enhancing microaneurysms. In the second step, a 2-D adaptive filtering is performed and those pixels where the prediction error is high are considered seeds. After the region growing, only regions that fit certain validation criteria are considered microaneurysms. These criteria are intensity, contrast and shape criteria. Intensity and contrast ones are typical criteria used in region-growing algorithms. To create the shape criterion, we have used the fact that microaneurysms can be modelled as 2D Gaussian functions. During the application of this criterion we pass each grown region through a bank of nine correlators, a 2D Gaussian function and eight linear segments oriented in eight different directions. Then we compare the outputs of this bank and we impose that a region can be a microaneurysm when the maximum peak of correlation is obtained when passing through the Gaussian correlator. In this study we have tested the algorithm with 11 images containing 711 microaneurysms in all and we have obtained a sensitivity of 90,72% for a predictive positive value of 82,35% .	adaptive filter;algorithm;region growing	Carmen Serrano;Begoña Acha;Sergio Revuelto	2004		10.1117/12.535118	computer vision;simulation;computer science;optics	Vision	37.9001934500997	-75.45159929890882	169225
5fbb079962e8ebea26edda432ce287d3a8edd70f	liver tumor detection and classification using content-based image retrieval	databases;liver;tissues;computer aided diagnosis;multiphase ct scans;index structure;hyper cube structure indexing;texture features;ct scan;focal liver mass detection and classification;medical diagnostics;automatic detection;liver cancer;computing systems;differential diagnosis;multiple phase encoded texture feature;content based image retrieval;liver tumor	Computer aided liver tumor detection and diagnosis can assist radiologists to interpret abnormal features in liver CT scans. In this paper, a general frame work is proposed to automatically detect liver focal mass lesions, conduct differential diagnosis of liver focal mass lesions based on multiphase CT scans, and provide visually similar case samples for comparisons. The proposed method first detects liver abnormalities by eliminating the normal tissue/organ from the liver region, and in the second step it ranks these abnormalities with respect to spherical symmetry, compactness and size using a tumoroid measure to facilitate fast location of liver focal mass lesions. To differentiate liver focal mass lesions, content-based image retrieval technique is used to query a CT model database with known diagnosis. Multiple-phase encoded texture features are proposed to represent the focal mass lesions. A hypercube indexing structure based method is adopted as the retrieval strategy and the similarity score is calculated to rank the retrieval results. Good performances are obtained from eight clinical CT scans. With the proposed method, the clinician is expected to improve the accuracy of differential diagnosis.© (2011) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.		Y. Chi;Jun Liu;Sudhakar K. Venkatesh;J. Zhou;Q. Tian;Wieslaw Lucjan Nowinski	2011		10.1117/12.877919	computer vision;medical diagnosis;computed tomography	Vision	35.662960000962045	-77.8235957668491	169227
136d178dbf2afd85b213d36febc459e222df9818	automatic identification of macular edema in optical coherence tomography images		This paper proposes a novel system for the simultaneous identification and characterization of the three types of Macular Edema (ME) in Optical Coherence Tomography (OCT). These MEs are clinically defined, by the reference classification of the field, as: Serous Retinal Detachment (SRD), Diffuse Retinal Thickening (DRT) and Cystoid Macular Edema (CME). Our system uses multilevel image thresholding approaches to identify the SRD and CME cases and a learning approach for the DRT identification. The system provided promising results with F-Measures of 83.35% and 81.95% for the DRT and CME detections, respectively. It was also efficient in detecting all the SRD cases included in the testing image dataset. The system was able to identify individually the different types of ME on the OCT images but it was also capable to detect simultaneously the existence of the three ME cases when they appeared merged in the lower retinal layers.	automatic identification and data capture;diffuse reflection;sensor;thresholding (image processing);tomography;virtual retinal display	Gabriela Samagaio;Aída Estévez;Joaquim de Moura;Jorge Novo;Marcos Ortega;María Isabel Fernández	2018		10.5220/0006544105330540	computer vision;macular edema;artificial intelligence;computer science;optical coherence tomography	Vision	37.7946893125081	-75.09939512337061	169441
675a6cfe0cefd78432347778667f221d5ee422b4	classification of malignant and benign liver tumors using a radiomics approach		Correct diagnosis of the liver tumor phenotype is crucial for treatment planning, especially the distinction between malignant and benign lesions. Clinical practice includes manual scoring of the tumors on Magnetic Resonance (MR) images by a radiologist. As this is challenging and subjective, it is often followed by a biopsy. In this study, we propose a radiomics approach as an objective and non-invasive alternative for distinguishing between malignant and benign phenotypes. T2-weighted (T2w) MR sequences of 119 patients from multiple centers were collected. We developed an efficient semi-automatic segmentation method, which was used by a radiologist to delineate the tumors. Within these regions, features quantifying tumor shape, intensity, texture, heterogeneity and orientation were extracted. Patient characteristics and semantic features were added for a total of 424 features. Classification was performed using Support Vector Machines (SVMs). The performance was evaluated using internal random-split cross-validation. On the training set within each iteration, feature selection and hyperparameter optimization were performed. To this end, another cross validation was performed by splitting the training sets in training and validation parts. The optimal settings were evaluated on the independent test sets. Manual scoring by a radiologist was also performed. The radiomics approach resulted in 95% confidence intervals of the AUC of [0.75, 0.92], specificity [0.76, 0.96] and sensitivity [0.52, 0.82]. These approach the performance of the radiologist, which were an AUC of 0.93, specificity 0.70 and sensitivity 0.93. Hence, radiomics has the potential to predict the liver tumor benignity in an objective and non-invasive manner.	radiomics	Martijn P. A. Starmans;Razvan L. Miclea;Sebastian R. van der Voort;Wiro J. Niessen;Maarten G. Thomeer;Stefan Klein	2018		10.1117/12.2293609	cross-validation;support vector machine;hyperparameter optimization;feature selection;biopsy;computer-aided diagnosis;pattern recognition;artificial intelligence;radiomics;computer science;liver tumor	Logic	32.58843473867799	-78.34045158982724	169490
bc7fdd91d351203f2820240b43b9aa4a66d0a8e3	automatic tuberculosis screening using chest radiographs	image segmentation;x ray imaging computer aided detection and diagnosis lung pattern recognition and classification segmentation tuberculosis tb;image classification;lung;image texture;sensitivity analysis;lungs shape hospitals x rays computational modeling medical diagnostic imaging diseases;feature extraction;medical image processing;diseases;sensitivity analysis diagnostic radiography diseases feature extraction image classification image segmentation image texture lung medical image processing;automatic tuberculosis screening radiologists roc curve computer aided diagnostic system tuberculosis control program binary classifier abnormal classification normal classification shape features texture graph cut segmentation method lung region conventional posteroanterior chest radiographs disease standard diagnostics mortality rates tuberculosis diagnosis multidrug resistant bacterial strains immunocompromised hiv aids patients opportunistic infections health threat;diagnostic radiography	Tuberculosis is a major health threat in many regions of the world. Opportunistic infections in immunocompromised HIV/AIDS patients and multi-drug-resistant bacterial strains have exacerbated the problem, while diagnosing tuberculosis still remains a challenge. When left undiagnosed and thus untreated, mortality rates of patients with tuberculosis are high. Standard diagnostics still rely on methods developed in the last century. They are slow and often unreliable. In an effort to reduce the burden of the disease, this paper presents our automated approach for detecting tuberculosis in conventional posteroanterior chest radiographs. We first extract the lung region using a graph cut segmentation method. For this lung region, we compute a set of texture and shape features, which enable the X-rays to be classified as normal or abnormal using a binary classifier. We measure the performance of our system on two datasets: a set collected by the tuberculosis control program of our local county's health department in the United States, and a set collected by Shenzhen Hospital, China. The proposed computer-aided diagnostic system for TB screening, which is ready for field deployment, achieves a performance that approaches the performance of human experts. We achieve an area under the ROC curve (AUC) of 87% (78.3% accuracy) for the first set, and an AUC of 90% (84% accuracy) for the second set. For the first set, we compare our system performance with the performance of radiologists. When trying not to miss any positive cases, radiologists achieve an accuracy of about 82% on this set, and their false positive rate is about half of our system's rate.	appendix;architecture as topic;area under curve;atlases;benchmark (computing);best, worst and average case;binary classification;computer-aided design;deploy;diagnostic radiologic examination;experiment;graph - visual representation;graph cuts in computer vision;hiv infections;human reliability;hypothalamic area, lateral;image retrieval;incidence matrix;large;mathematical optimization;montgomery modular multiplication;opportunistic infections;outline of object recognition;patients;personalization;radiation;radiography;radiology;receiver operating characteristic;repository;sensor;state or local health department;structure of parenchyma of lung;tablet dosage form;terabyte;test set;threat (computer);tuberculosis;web page;weight;biologic segmentation	Stefan Jaeger;Alexandros Karargyris;Sema Candemir;Les R. Folio;Jenifer Siegelman;Fiona M. Callaghan;Zhiyun Xue;Kannappan Palaniappan;Rahul K. Singh;Sameer K. Antani;George R. Thoma;Yi-Xiang Wang;Pu-Xuan Lu;Clement J. McDonald	2014	IEEE Transactions on Medical Imaging	10.1109/TMI.2013.2284099	image texture;computer vision;contextual image classification;radiology;medicine;pathology;feature extraction;computer science;image segmentation;sensitivity analysis;surgery	ML	34.830430941169716	-77.37135803568852	169526
2dc37a2b18ac04a335a7acac29fd99ddaa124abd	residual deep convolutional neural network predicts mgmt methylation status	deep learning;mgmt methylation;mri	Predicting methylation of the O6-methylguanine methyltransferase (MGMT) gene status utilizing MRI imaging is of high importance since it is a predictor of response and prognosis in brain tumors. In this study, we compare three different residual deep neural network (ResNet) architectures to evaluate their ability in predicting MGMT methylation status without the need for a distinct tumor segmentation step. We found that the ResNet50 (50 layers) architecture was the best performing model, achieving an accuracy of 94.90% (+/− 3.92%) for the test set (classification of a slice as no tumor, methylated MGMT, or non-methylated). ResNet34 (34 layers) achieved 80.72% (+/− 13.61%) while ResNet18 (18 layers) accuracy was 76.75% (+/− 20.67%). ResNet50 performance was statistically significantly better than both ResNet18 and ResNet34 architectures (p < 0.001). We report a method that alleviates the need of extensive preprocessing and acts as a proof of concept that deep neural architectures can be used to predict molecular biomarkers from routine medical images.	architecture as topic;artificial neural network;biological markers;biological neural networks;brain neoplasms;convolutional neural network;deep learning;kerrison predictor;nc (complexity);o(6)-methylguanine-dna methyltransferase;o-(6)-methylguanine;preprocessor;test set;anatomical layer	Panagiotis Korfiatis;Timothy L. Kline;Daniel H. Lachance;Ian F. Parney;Jan C. Buckner;Bradley J. Erickson	2017	Journal of Digital Imaging	10.1007/s10278-017-0009-z	residual;oncology;convolutional neural network;radiology;tumor suppressor proteins;artificial neural network;residual neural network;deep learning;computer science;artificial intelligence;methylation;methyltransferase;bioinformatics;internal medicine	ML	30.040714739415222	-76.6651746001431	169664
650c975f42b91ce636605c41faa55d1c13df7811	weighted radial basis function kernel-based support vector machines for multispectral magnetic resonance brain image classification.				Clayton Chi-Chang Chen;Shih-Yu Chen;Hsian-Min Chen;Bor-Hung Lin;Yen Chieh Ouyang;Jyh Wen Chai;Ching-Wen Yang;San-Kan Lee;Chein-I Chang	2014		10.3233/978-1-61499-484-8-1970	machine learning;pattern recognition	Vision	33.344952584055285	-73.06638121574647	169889
a3d70ee9266dc0368d944bf3256b951ac26b66cc	pit pattern classification of zoom-endoscopical colon images using dct and fft	image classification bayes methods discrete cosine transforms endoscopes feature extraction fourier transforms genetic algorithms;bayes normal classifier;fourier transform;cancer;zoom endoscopy;bayes methods;colon;image classification;biomedical imaging;colon images;lesions;bayes normal classifier pit pattern classification zoom endoscopy colon images colonoscopy discrete cosine transformation fourier transformation feature selection genetic algorithm pattern recognition;fourier transformation;discrete cosine transforms;feature extraction;pattern classification colon discrete cosine transforms lesions cancer biomedical imaging medical diagnostic imaging endoscopes colonic polyps colonoscopy;fourier transforms;endoscopes;statistical pattern recognition;pattern classification;pattern recognition;colonoscopy;pit pattern classification;genetic algorithm;genetic algorithms;feature selection;discrete cosine transformation;frequency domain;colonic polyps;medical diagnostic imaging	This work presents a classification approach for images taken from magnifying colonoscopy. Classification is done according to the pit pattern scheme. Images are not classified directly in the proposed classifier. Instead, they are transformed to a frequency domain using discrete cosine or Fourier transformation. Feature selection is optimized using a genetic algorithm, the actual classification is done using standard methods from statistical pattern recognition (a Bayes normal classifier).	colon classification;discrete cosine transform;fast fourier transform;feature selection;genetic algorithm;pattern recognition;statistical classification	Michael Häfner;Leonhard Brunauer;Hannes Payer;Robert Resch;Friedrich Wrba;Alfred Gangl;Andreas Vécsei;Andreas Uhl	2007	Twentieth IEEE International Symposium on Computer-Based Medical Systems (CBMS'07)	10.1109/CBMS.2007.85	medical imaging;fourier transform;computer vision;speech recognition;computer science;machine learning;pattern recognition;feature selection	Vision	35.06464523170791	-73.93317143192459	170064
ca313da00e00a8fe69d1a2a5bdcb012fc124839c	disease quantification on pet/ct images without explicit object delineation	cancer;disease quantification;image segmentation;object recognition;pet/ct;quantitative radiology;total lesion glycolysis (tlg)	"""PURPOSE The derivation of quantitative information from images in a clinically practical way continues to face a major hurdle because of image segmentation challenges. This paper presents a novel approach, called automatic anatomy recognition-disease quantification (AAR-DQ), for disease quantification (DQ) on positron emission tomography/computed tomography (PET/CT) images. This approach explores how to decouple DQ methods from explicit dependence on object (e.g., organ) delineation through the use of only object recognition results from our recently developed automatic anatomy recognition (AAR) method to quantify disease burden.   METHOD The AAR-DQ process starts off with the AAR approach for modeling anatomy and automatically recognizing objects on low-dose CT images of PET/CT acquisitions. It incorporates novel aspects of model building that relate to finding an optimal disease map for each organ. The parameters of the disease map are estimated from a set of training image data sets including normal subjects and patients with metastatic cancer. The result of recognition for an object on a patient image is the location of a fuzzy model for the object which is optimally adjusted for the image. The model is used as a fuzzy mask on the PET image for estimating a fuzzy disease map for the specific patient and subsequently for quantifying disease based on this map. This process handles blur arising in PET images from partial volume effect entirely through accurate fuzzy mapping to account for heterogeneity and gradation of disease content at the voxel level without explicitly performing correction for the partial volume effect. Disease quantification is performed from the fuzzy disease map in terms of total lesion glycolysis (TLG) and standardized uptake value (SUV) statistics. We also demonstrate that the method of disease quantification is applicable even when the """"object"""" of interest is recognized manually with a simple and quick action such as interactively specifying a 3D box ROI. Depending on the degree of automaticity for object and lesion recognition on PET/CT, DQ can be performed at the object level either semi-automatically (DQ-MO) or automatically (DQ-AO), or at the lesion level either semi-automatically (DQ-ML) or automatically.   RESULTS We utilized 67 data sets in total: 16 normal data sets used for model building, and 20 phantom data sets plus 31 patient data sets (with various types of metastatic cancer) used for testing the three methods DQ-AO, DQ-MO, and DQ-ML. The parameters of the disease map were estimated using the leave-one-out strategy. The organs of focus were left and right lungs and liver, and the disease quantities measured were TLG, SUVMean, and SUVMax. On phantom data sets, overall error for the three parameters were approximately 6%, 3%, and 0%, respectively, with TLG error varying from 2% for large """"lesions"""" (37 mm diameter) to 37% for small """"lesions"""" (10 mm diameter). On patient data sets, for non-conspicuous lesions, those overall errors were approximately 19%, 14% and 0%; for conspicuous lesions, these overall errors were approximately 9%, 7%, 0%, respectively, with errors in estimation being generally smaller for liver than for lungs, although without statistical significance.   CONCLUSIONS Accurate disease quantification on PET/CT images without performing explicit delineation of lesions is feasible following object recognition. Method DQ-MO generally yields more accurate results than DQ-AO although the difference is statistically not significant. Compared to current methods from the literature, almost all of which focus only on lesion-level DQ and not organ-level DQ, our results were comparable for large lesions and were superior for smaller lesions, with less demand on training data and computational resources. DQ-AO and even DQ-MO seem to have the potential for quantifying disease burden body-wide routinely via the AAR-DQ approach."""		Yubing Tong;Jayaram K. Udupa;Dewey Odhner;Caiyun Wu;Stephen J. Schuster;Drew A. Torigian	2019	Medical image analysis	10.1016/j.media.2018.11.002		ML	36.42313154836315	-80.15894546845118	170372
24271d403328a3b1652813657da533381c2e2e92	diagnosing cervical cell images using pre-trained convolutional neural network as feature extractor	neural networks;support vector machines;cancer;microscopy;biomedical imaging;breast;feature extraction	Cervical cancer is a disease that affects 266,000 deaths worldwide and is the fourth highest incidence of cancer in women. This cancer can be diagnosed through a Pap smear, where a cytopathologist observes a microscopic image of the cervix cells to determine whether the patient is normal or abnormal. The sensitivity and specificity of the Pap smear is known to be respectively 53.4% and 69.2%. Since the test is related to the patient's life, it is important to improve the accuracy of the test. A variety of systems have been proposed to help judge experts to improve the accuracy of tests in the medical field, but the development of these systems has been limited to areas where digitized test data are clearly present. In this paper, we design and propose a model that automatically classifies normal/abnormal states of cervical cells from microscopic images using convolutional neural network and several machine learning classifiers. As a result, the support vector machine showed the best performance with a 78% F1 score.	artificial neural network;convolutional neural network;f1 score;incidence matrix;machine learning;randomness extractor;sensitivity and specificity;smear campaign;support vector machine;test data	Jonghwan Hyeon;Ho-Jin Choi;Byung Doo Lee;Kap No Lee	2017	2017 IEEE International Conference on Big Data and Smart Computing (BigComp)	10.1109/BIGCOMP.2017.7881741	computer vision;pathology;engineering;machine learning	Robotics	33.3949005319011	-76.32295429712936	170375
418cfe0fa5f7ffffe8b5051b310ff3961070c609	skin hair removal for 2d psoriasis images	skin diseases feature extraction image restoration image texture interpolation medical image processing object detection shape recognition;hair skin gray scale feature extraction lesions australia shape;skin;gray scale;lesion intensity skin hair removal 2d psoriasis image psoriasis skin image computer aided analysis psoriasis diagnosis hair detection hair removal algorithm markers removal algorithm shape feature extraction binary input image object removal image lesion psoriasis lesion contrast enhancement method morphological operation image interpolation hair pixels hair free neighbouring pixels value image inpainting royal melbourne hospital victoria australia hair removal software dullrazor lesion texture feature;shape;lesions;feature extraction;australia;hair	Presence of hair in psoriasis skin images may adversely affect the extraction of the features required for computer aided analysis, thus compromise the detection and diagnostic results. Therefore, for the diagnosis of psoriasis to be accurate, it is vitally important to remove hair, if it exists, from images in the preprocessing stage. This paper presents, for the first time, a hair detection and removal algorithm for 2D psoriasis images. The hair removal process starts with a markers removal algorithm, where the shape features are extracted from the binary input image. The outcome of this step is removal of all objects that obscure the image lesions such that the output image contains psoriasis lesions and normal skin only. Next, the dark hair in the skin is identified using contrast enhancement method and morphological operations. Finally, image interpolation is performed to replace the hair pixels with hair free neighbouring pixels values through image inpainting. The proposed algorithm is tested on 64 psoriasis images acquired from the Royal Melbourne Hospital, Victoria, Australia. Experimental results demonstrate that the algorithm is highly accurate and effective. In addition, the widely used hair removal software DullRazor® is used on the same 64 images for comparison. The results show that our proposed algorithm performs quite well and is more adapt to psoriasis images. The method is more effective because it overcomes the problem of removing skin hair without affecting the intensity or texture features of the lesions.	algorithm;inpainting;interpolation;mathematical morphology;pixel;preprocessor;victoria (3d figure)	Yasmeen George;Mohammad Aldeen;Rahil Garnavi	2015	2015 International Conference on Digital Image Computing: Techniques and Applications (DICTA)	10.1109/DICTA.2015.7371308	computer vision;feature extraction;shape;computer science;geometry;skin;grayscale	Vision	37.00168596897796	-75.79857423684264	170419
3f03a2e8efce9347a46dd9917b365e2c45f13248	mammographic mass detection by adaptive thresholding and region growing	adaptive thresholding;computer aided diagnosis;neural network classification;mammographic mass;region growing;article	We present an efficient method to detect mass lesions on digitized mammograms, which consists of breast region extraction, region partitioning, automatic seed selection, segmentation by region growing, feature extraction, and neural network classification. The method partitions the breast region into a fat region, a fatty and glandular region, and a dense region, so that different threshold values can be applied to each partitioned region during processes of the seed selection and segmentation. The mammographic masses are classified by using four features representing shape, density, and margin of the segmented regions. The method detects subtle mass lesions with various contrast ranges and can facilitate a procedure of mass detection in computer-aided diagnosis systems. © 2001 John Wiley & Sons, Inc. Int J Imaging Syst Technol, 11, 340–346, 2000	advanced transportation controller;algorithm;artificial neural network;business process network;design of the fat file system;feature extraction;john d. wiley;region growing;test set;thresholding (image processing);window function	Yong Jin Lee;Jeong Mi Park;Hyun Wook Park	2000	Int. J. Imaging Systems and Technology	10.1002/ima.1018	computer vision;computer science;machine learning;pattern recognition;region growing;thresholding	ML	36.42491607080927	-75.0733083952236	170426
35b78a9c17e494b7781d93547cb1b83b814ef960	a feature selection scheme for accurate identification of alzheimer's disease	alzheimer s disease ad;support vector machine svm;feature selection fs;mild cognitive impairment mci		feature selection	Hao Shen;Wen Zhang;Peng Chen;Jun Zhang;Aiqin Fang;Bing Wang	2016		10.1007/978-3-319-31744-1_7	machine learning;pattern recognition	Crypto	30.007974805194934	-78.29099066106956	170706
129a8fab5ae220757106d2b49fda2404e624cc0f	application of a distance-based method for analysing spatial patterns to the analysis of radionuclide tomograms	spatial pattern	The application of a statistical pattern recognition technique to the analysis of radionuclide tomograms of the liver was investigated. A diagnostic test of aggregation was applied to the spatial distribution of pixels within each colour band of the image and the behaviour of a resulting statistic used as a classdier lot distinguishing live types of liver disease. The results of a preliminary training procedure are presented and show good separation of the classes. Image processing Cluster analysis Radionuclide imaging Computed tomography Liver disease	ct scan;cluster analysis;image processing;pattern recognition;pixel;tomography	R. W. Rowe;W. I. Keyes	1981	Pattern Recognition	10.1016/0031-3203(81)90041-8	computer vision;econometrics;common spatial pattern;computer science;mathematics;statistics	Vision	37.14785913683737	-74.86057392843041	171076
ae408e5f85233935801e75409d1aa048d1a32cd3	semantic shape models for leaf species identification	fusion;naive bayesian classifier;semantic segment based representation;leaf contour;botany	We present two complementary botanical-inspired leaf shape representation models for the classification of simple leaf species leaves with one compact blade. The first representation is based on some linear measurements that characterise variations of the overall shape, while the second consists of semantic part-based segment models. These representations have two main advantages: First, they only require the extraction of two points: the base and apex, which are the key characterisation points of simple leaves. The second advantage is the complementary of the proposed model representations, which provides robustness against large leaf species variations as well as high inter-species and low intra-class similarity that occurs for some species. For the decision procedure, we use a two-stage Bayesian framework: the first concerns each shape model separately and the second is a combination of classification scores posterior probabilities obtained from each shape model. Experiments carried out on real world leaf images, the simple leaves of the Pl@ntLeaves scan images 46 species, show an increase in performance compared to previous related work.		Olfa Mzoughi;Itheri Yahiaoui;Nozha Boujemaa;Ezzeddine Zagrouba	2015		10.1007/978-3-319-25903-1_57	computer vision;fusion;machine learning;pattern recognition;mathematics	AI	35.637389281881305	-69.42402758777179	171094
2ba73c9fa30375c5b138198b1e80f406ecb260cd	applying of pre-processing techniques in bruise images	bruises aging;white point correction;bruises images analysis;image analysis	"""The paper justifies the necessity to apply some beforehand corrections of the bruise images in order to analyse and compare the differences. The colour palette """"Macbeth Colour Checker"""" is used in some of the corrections. The comparison of the results is made by using colour differences in L*a*b* colour space for each of the palette colours. The results show that the colour differences between the colours in the white-point corrected image and ideal colours are smaller than these between the original no-processed image and ideal colours. The results also show that this type of processing is not specific enough for the correction of the bruise colours. Here is used the healthy skin reference in order to receive helpful images for following analysis of the bruise changes in its evolution."""	color space;palette (computing);preprocessor	Tatyana Dimitrova;Lidiya Georgieva	2007		10.1145/1330598.1330721	computer vision;image analysis;computer science	Vision	36.81995434256612	-75.11756613379002	171399
066e91079925d4193950af5247209ecad8ebf0f2	mdct-based 3-d texture classification of emphysema and early smoking related lung pathologies	sensitivity and specificity;pulmonary function test;female;early smoking related lung pathologies;emphysema;lungs pathology neural networks computed tomography two dimensional displays humans diseases testing bayesian methods sensitivity and specificity;bayesian classifier;algorithms artifacts artificial intelligence female humans imaging three dimensional information storage and retrieval male middle aged pattern recognition automated pulmonary emphysema radiation dosage radiographic image enhancement radiographic image interpretation computer assisted reproducibility of results sensitivity and specificity severity of illness index smoking stochastic processes tomography x ray computed transducers;mdct based 3 d texture classification;computed tomography;imaging three dimensional;neural networks;volume of interest;adaptive multiple feature method;middle aged;texture classification;bayes methods;lungs;male;bayesian methods;transducers;tissue classification emphysema multidetector row computed tomography quantitative ct texture analysis;multidetector row ct;image classification;two dimensional displays;testing;radiation dosage;radiographic image enhancement;multidetector row computed tomography;texture features;chronic obstructive pulmonary disease;smoking;three dimensional;lung parenchyma mdct based 3 d texture classification multidetector row ct emphysema early smoking related lung pathologies adaptive multiple feature method chronic obstructive pulmonary disease pulmonary function test bayesian classifier;lung;artifacts;image texture;texture analysis;quantitative ct;stochastic processes;tissue classification;bayes methods lung diseases computerised tomography medical image processing image texture image classification;medical image processing;severity of illness index;reproducibility of results;pulmonary emphysema;computerised tomography;diseases;artificial intelligence;algorithms;pattern recognition automated;humans	Our goal is to enhance the ability to differentiate normal lung from subtle pathologies via multidetector row CT (MDCT) by extending a two-dimensional (2-D) texturebased tissue classification [adaptive multiple feature method (AMFM)] to use three-dimensional (3-D) texture features. We performed MDCT on 34 humans and classified volumes of interest (VOIs) in the MDCT images into five categories: EC, emphysema in severe chronic obstructive pulmonary disease (COPD); MC, mild emphysema in mild COPD; NC, normal appearing lung in mild COPD; NN, normal appearing lung in normal nonsmokers; and NS, normal appearing lung in normal smokers. COPD severity was based upon pulmonary function tests (PFTs). Airways and vessels were excluded from VOIs; 24 3-D texture features were calculated; and a Bayesian classifier was used for discrimination. A leave-one-out method was employed for validation. Sensitivity of the four-class classification in the form of 3-D/2-D was: EC: 85%/71%, MC: 90%/82%; NC: 88%/50%; NN: 100%/60%. Sensitivity and specificity for NN using a two-class classification of NN and NS in the form of 3-D/2-D were: 99%/72% and 100%/75%, respectively. We conclude that 3-D AMFM analysis of lung parenchyma improves discrimination compared to 2-D AMFM of the same VOIs. Furthermore, our results suggest that the 3-D AMFM may provide a means of discriminating subtle differences between smokers and nonsmokers both with normal PFTs.	blood vessel tissue;ct pulmonary angiogram;ct scan;categories;chronic obstructive airway disease;classification;exclusion;fractal;lung diseases, obstructive;lung diseases;modified discrete cosine transform;multiple personality disorder;naive bayes classifier;pathological accumulation of air in tissues;population;pulmonary emphysema;pulmonary function tests;sensitivity and specificity;status epilepticus;structure of parenchyma of lung;x-ray computed tomography	Ye Xu;Milan Sonka;Geoffrey McLennan;Junfeng Guo;Eric A. Hoffman	2006	IEEE Transactions on Medical Imaging	10.1109/TMI.2006.870889	image texture;stochastic process;three-dimensional space;parenchyma;computer vision;contextual image classification;naive bayes classifier;pulmonary function testing;radiology;medicine;transducer;pathology;bayesian probability;computer science;machine learning;mathematics;severity of illness;software testing;computed tomography;artificial neural network	Vision	34.810819143449535	-77.781195127067	171799
46e5667399e3c70f2fa135b5970466453d129987	automatic detection and segmentation of axillary lymph nodes	computed tomography;cancer treatment;automatic detection;detection rate;false positive;marginal space learning;lymph node	Lymph node detection and measurement is a difficult and important part of cancer treatment. In this paper we present a robust and effective learning-based method for the automatic detection of solid lymph nodes from Computed Tomography data. The contributions of the paper are the following. First, it presents a learning based approach to lymph node detection based on Marginal Space Learning. Second, it presents an efficient MRF-based segmentation method for solid lymph nodes. Third, it presents two new sets of features, one set self-aligning to the local gradients and another set based on the segmentation result. An extensive evaluation on 101 volumes containing 362 lymph nodes shows that this method obtains a 82.3% detection rate at 1 false positive per volume, with an average running time of 5-20 seconds per volume.	101 mouse;anatomic node;axilla;axillary lymph node group;blood vessel tissue;ct scan;detectors;gradient;intestines;lymph node tissue;lymphadenopathy;marginal model;markov random field;mediastinal lymph node group;neoplasms;node - plant part;segmentation action;time complexity;tomography, emission-computed;biologic segmentation;cancer therapy;lymph nodes;tomography	Adrian Barbu;Michael Sühling;Xun Xu;David Liu;Shaohua Kevin Zhou;Dorin Comaniciu	2010	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-15705-9_4	radiology;medicine;pathology;type i and type ii errors;mathematics;computed tomography;surgery	Vision	38.95425687525636	-78.3109582107179	171839
65aae20a52971abe37f106a3377b70d1e69f549e	automated detection of microaneurysms using scale-adapted blob analysis and semi-supervised learning	fundus image;semi supervised learning;microaneurysms;scale space;diabetic retinopathy;blobs;basic biological sciences	Despite several attempts, automated detection of microaneurysm (MA) from digital fundus images still remains to be an open issue. This is due to the subtle nature of MAs against the surrounding tissues. In this paper, the microaneurysm detection problem is modeled as finding interest regions or blobs from an image and an automatic local-scale selection technique is presented. Several scale-adapted region descriptors are introduced to characterize these blob regions. A semi-supervised based learning approach, which requires few manually annotated learning examples, is also proposed to train a classifier which can detect true MAs. The developed system is built using only few manually labeled and a large number of unlabeled retinal color fundus images. The performance of the overall system is evaluated on Retinopathy Online Challenge (ROC) competition database. A competition performance measure (CPM) of 0.364 shows the competitiveness of the proposed system against state-of-the art techniques as well as the applicability of the proposed features to analyze fundus images.	binary large object;body tissue;closing (morphology);computation;computer-aided design;contrast resolution;data descriptor;database;detectors;diabetic retinopathy;image analysis;image resolution;microaneurysm;receiver operating characteristic;retina;retinal diseases;semi-supervised learning;semiconductor industry;sensor;shading;silo (dataset);supervised learning;time complexity;tracer	Kedir M. Adal;Desire Sidibé;Sharib Ali;Edward Chaum;Thomas P. Karnowski;Fabrice Mériaudeau	2014	Computer methods and programs in biomedicine	10.1016/j.cmpb.2013.12.009	semi-supervised learning;computer vision;scale space;computer science;binary large object;computer graphics (images)	Vision	32.80874018866764	-74.96806528342063	172061
08786f22c56f65b937bb3378e49e342c2ff28be6	development of software for obtaining image attributes for evaluation of the wound healing process		The biological process of wound healing is one of the most complex occurrences during our lives turning a serious public health problem. The rate of healing chronic wounds in humans is relatively uniform, regardless of etiologies, and is estimated to be 0.63–0.65 mm/week for diabetics and non- diabetics [1], respectively, being visually unnoticeable throughout the daily care of a wound. A ruler designed for this purpose using a decal for setting the wound limits, however an area with a lot of irregularity requires a tool that carries out this measurement autonomously through image recognition, making the process feasible for the medical teams responsible for the treatment. The digitized images undergo morphological processes sing on the polygonal line that delimits the wound region. With the region delimited by the polygonal, the area and the perimeter are determined. A comparison with analytical methods demonstrates that this tool has the potential to become gold standard for estimating to estimate the area and the perimeter of wounds in the healing process.	biological processes;care-of address;computer vision;delimiter;estimated;impaired wound healing;perimeter;teams	Adriana G. da Costa;A. A. Mehl;Bolegenova S.;Adriana M. W. Stadnik;Rubens Alexandre De Faria	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8512439	image processing;computer vision;medical imaging;artificial intelligence;software;wound healing;computer science	Visualization	37.85512611589019	-76.84382275039249	172282
9cd00e7349807cefacae4810c84347aa023c289b	classification of cirrhotic liver in gadolinium-enhanced mr images	sensitivity and specificity;liver;gadolinium;computer aided diagnosis;magnetic resonance imaging mri;k means;cirrhosis of the liver;magnetic resonance image;conference paper;distortion;computer aided diagnosis cad;mr imaging;matrices;clustering method;region of interest;k means clustering;diseases and disorders;co occurrence matrix	Cirrhosis of the liver is characterized by the presence of widespread nodules and fibrosis in the liver. The fibrosis and nodules formation causes distortion of the normal liver architecture, resulting in characteristic texture patterns. Texture patterns are commonly analyzed with the use of co-occurrence matrix based features measured on regionsof-interest (ROIs). A classifier is subsequently used for the classification of cirrhotic or non-cirrhotic livers. Problem arises if the classifier employed falls into the category of supervised classifier which is a popular choice. This is because the 'true disease states' of the ROIs are required for the training of the classifier but is, generally, not available. A common approach is to adopt the 'true disease state' of the liver as the 'true disease state' of all ROIs in that liver. This paper investigates the use of a nonsupervised classifier, the k-means clustering method in classifying livers as cirrhotic or non-cirrhotic using unlabelled ROI data. A preliminary result with a sensitivity and specificity of 72% and 60%, respectively, demonstrates the feasibility of using the k-means non-supervised clustering method in generating a characteristic cluster structure that could facilitate the classification of cirrhotic and non-cirrhotic livers.	cluster analysis;co-occurrence matrix;distortion;document-term matrix;k-means clustering;machine learning;naive bayes classifier;region of interest;sensitivity and specificity	Gobert N. Lee;Yoshikazu Uchiyama;Xuejun Zhang;Masayuki Kanematsu;Xiangrong Zhou;Takeshi Hara;Hiroki Kato;Hiroshi Kondo;Hiroshi Fujita;Hiroaki Hoshi	2007		10.1117/12.710288	radiology;medicine;pathology;biological engineering	ML	34.25642425636857	-76.09378865461093	172472
1f31353539c422e60e9fcd3d93a5bed62c29be20	volumetric extraction of pulmonary blood vessels from computerized tomography scans		In this study we created 3D model of pulmonary blood vessels in order to help surgeons while they are performing bronoschopy which is for cancer detection on early stages and preventing unintended interception to blood vessels during process. From Computerized Tomography scans, masks are created by using morphological operations which are used to segment lungs and blood vessels. Segmented blood vessels then shown in 3D space by relation of their pixel intensities.	ct scan;mathematical morphology;pixel;tomography	Kaya Mustafa Aribac;Gokhan Bora Esmer;Alper Sismanu;Tunc Lacin;Neslihan Sarigul;Beyza Ayvacikli	2018	2018 26th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2018.8404593	artificial intelligence;computer vision;computer science;image segmentation;pixel;computed tomography;medical imaging;tomography	Visualization	38.528833767138096	-78.95305335910237	172520
3f83b443043e3e1bf0ca87685e7d2495b9a80cd7	mapping visual features to semantic profiles for retrieval in medical imaging	visualization semantics training radiology lungs imaging feature extraction;localized image volume areas medical imaging retrieval content based image retrieval diagnosis image similarity measures appearance variability diseases semantic clinical information image elements clinical routine visual features extraction remapping medical imaging data weak labels radiology reports local image content semantic profiles clinical findings;radiology content based retrieval diseases feature extraction image retrieval medical image processing patient diagnosis	Content based image retrieval is highly relevant in medical imaging, since it makes vast amounts of imaging data accessible for comparison during diagnosis. Finding image similarity measures that reflect diagnostically relevant relationships is challenging, since the overall appearance variability is high compared to often subtle signatures of diseases. To learn models that capture the relationship between semantic clinical information and image elements at scale, we have to rely on data generated during clinical routine (images and radiology reports), since expert annotation is prohibitively costly. Here we show that re-mapping visual features extracted from medical imaging data based on weak labels that can be found in corresponding radiology reports creates descriptions of local image content capturing clinically relevant information. We show that these semantic profiles enable higher recall and precision during retrieval compared to visual features, and that we can even map semantic terms describing clinical findings from radiology reports to localized image volume areas.	antivirus software;content-based image retrieval;medical imaging;precision and recall;radiology;spatial variability	Johannes Hofmanninger;Georg Langs	2015	2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2015.7298643	computer vision;visual word;image retrieval;computer science;multimedia;automatic image annotation;information retrieval	Vision	33.68874434551085	-79.3928678361946	172772
f75c090e25731f18c7d5e8ce119bf39b5d63bf2e	automatic image analysis and classification for urinary bacteria infection screening		In this paper, we present an automatic system for the screening of urinary tract infections. It is estimated that about 150 million infections of this kind occur world wide yearly, giving rise to roughly five billion health–care expenditures. Currently, Petri plates seeded with infected samples are analyzed by human experts, an error prone and lengthy process. Nevertheless, based on image processing techniques and machine learning tools, the recognition of the bacterium type and the colony count can be automatically carried out. The proposed system captures a digital image of the plate and, after a preprocessing stage to isolate the colonies from the culture ground, accurately identifies the infection type and severity. Moreover, it contributes to the standardization of the analysis process, also avoiding the continuous transition between sterile and external environments, which is typical in the classical laboratory procedure.	image analysis	Paolo Andreini;Simone Bonechi;Monica Bianchini;Alessandro Mecocci;Vincenzo Di Massa	2015		10.1007/978-3-319-23231-7_57	artificial intelligence;computer science;image processing;pattern recognition;digital image;support vector machine;infection screening;standardization;colony count;preprocessor;laboratory procedure	Vision	33.780963568360626	-76.60371486964279	173088
79ab1444a1c6ab0bfbab8d7da0119e22d92b1c91	digital bowel cleansing for computer-aided detection of polyps in fecal-tagging ct colonography	mouth;tissues;ct colonography;computer aided diagnosis;opacity;colon;x ray and ct;matrices;virtual colonoscopy;computer aided detection;soft tissue;contrast agent;false positive;level set method;x rays;abdominal	Digital bowel cleansing (DBC) is an emerging method for segmentation of fecal materials, which are tagged by an X-ray-opaque oral contrast agent in CT colonography (CTC) images, effectively removing them for digital cleansing of the colon. Existing DBC approaches tend to use simple thresholding-based methods for the removal of tagged fecal materials; however, because of the pseudo-enhancement of polyps caused by the surrounding tagged fecal materials, such methods tend erroneously to remove a part of or the entire polyps submerged in these materials. In this study, we developed a novel DBC method that preserves the soft-tissue structures submerged in or partially covered by tagged fecal materials. In our approach, submerged soft-tissue structures are characterized by their local shape signatures that are calculated based on the eigenvalues of a Hessian matrix. A structure-enhancement function is formulated for enhancing of the soft-tissue structures, and the values of the function are integrated into the speed function of a level set method to delineate the submerged soft-tissue structures while removing the tagged fecal materials. In an analysis of 10 submerged polyps, our new DBC method was shown to delineate polyps better than was possible with our previously reported cleansing method based on thresholding. Application of our computer-aided detection (CAD) scheme showed that the use of the new DBS method substantially reduced the number of false-positive detections compared with those of our previous, thresholding-based method.© (2006) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	ct scan;virtual colonoscopy	Wenli Cai;Janne Näppi;Micheal E. Zalis;Gordon J. Harris;Hiroyuki Yoshida	2006		10.1117/12.654168	radiology;pathology;engineering;biological engineering	EDA	37.879634434097426	-78.08656475378926	173140
2eacf452cafa5d41011086e7b0eade768ed84a2e	scalable multi-task gaussian process tensor regression for normative modeling of structured variation in neuroimaging data		Most brain disorders are very heterogeneous in terms of their underlying biology and developing analysis methods to model such heterogeneity is a major challenge. A promising approach is to use probabilistic regression methods to estimate normative models of brain measures then use these to map variation across individuals. To fully capture individual differences and detect disorders in individual subjects it is crucial to statistically model patterns of correlation across different brain regions and individuals. However, this is very challenging for neuroimaging data because of high dimensionality and highly structured correlations across multiple axes. Here, we propose tensor Gaussian predictive process (TGPP) as a general and flexible Bayesian mixed-effects modeling framework. In TGPP, we develop multi-task Gaussian process tensor regression (MT-GPTR) to simultaneously model the structured random effects and structured noise. We use Kronecker algebra and a low-rank approximation to efficiently scale MT-GPTR to the whole brain. On a publicly available clinical fMRI dataset and in a novelty detection scenario, we show that our computationally affordable multivariate normative modeling approach substantially improves the detection rate over a baseline mass-univariate normative model and an offthe-shelf supervised alternative. Preprint in arXiv.		Seyed Mostafa Kia;Christian F. Beckmann;Andre F. Marquand	2018	CoRR		tensor;anomaly detection;kronecker delta;artificial intelligence;mathematics;machine learning;scalability;normative;probabilistic logic;neuroimaging;gaussian process	ML	24.82720104771868	-77.18704404948429	173310
9ba1284ff46e07a42cb51ccaa00510c4aa5b3ddd	automatic diagnosis of the footprint pathologies based on neural networks	principal component analysis;training algorithm;neural network	Currently foot pathologies, like cave and flat foot, are detected by an human expert who interprets a footprint image. The lack of trained personal to carry out massive first screening detection campaigns precludes the routinary diagnostic of these pathologies. This work presents a novel automatic system, based on Neural Networks (NN), for foot pathologies detection. In order to improve the efficiency of the neural network training algorithm, we propose the use of principal components analysis to reduce the number of inputs to the NN. The results obtained with this system demonstrate the feasibility of building automatic diagnosis systems based on the foot image. These systems are very valuable in remote areas and can be also used for massive first screening health campaigns.		Marco Mora;Mary Carmen Jarur Muñoz;Daniel G. Sbarbaro-Hofer	2007		10.1007/978-3-540-71629-7_13	simulation;computer science;artificial intelligence;machine learning;artificial neural network;principal component analysis	NLP	33.368529926977324	-77.86421528286111	173377
767363e3b084d7f4fd45d30107ac69f37402d6ca	automated segmentation of mammary gland regions in non-contrast torso ct images based on probabilistic atlas	standard deviation;mammary gland;pectoralis major;segmentation;gold standard;ct scan;breast;torso ct images;gold;medical diagnostics;human body;probabilistic atlas	The identification of mammary gland regions is a necessary processing step during the anatomical structure recognition of human body and can be expected to provide the useful information for breast tumor diagnosis. This paper proposes a fully-automated scheme for segmenting the mammary gland regions in non-contrast torso CT images. This scheme calculates the probability for each voxel belonging to the mammary gland or other regions (for example pectoralis major muscles) in CT images and decides the mammary gland regions automatically. The probability is estimated from the location of the mammary gland and pectoralis major muscles in CT images. The location (named as a probabilistic atlas) is investigated from the pre-segmentation results in a number of different CT scans and the CT number distribution is approximated using a Gaussian function. We applied this scheme to 66 patient cases (female, age: 40-80) and evaluated the accuracy by using the coincidence rate between the segmented result and gold standard that is generated manually by a radiologist for each CT case. The mean value of the coincidence rate was 0.82 with the standard deviation of 0.09 for 66 CT cases.	approximation algorithm;ct scan;computer-aided design;radiology;voxel	Xiangrong Zhou;M. Kan;Takeshi Hara;Hiroshi Fujita;Keiko Sugisaki;Ryujiro Yokoyama;Gobert N. Lee;Hiroaki Hoshi	2007		10.1117/12.709345	medicine;pathology;nuclear medicine;anatomy	Vision	37.990428466502024	-79.2135548522494	173698
3a41cfb89b41210ec290411f834abf4ae6f8f672	character recognition using attributed grammar	position angle;branch point;attribute grammar;grammars;attribute information attributed grammar character recognition algorithm korean characters syntactic algorithm;grammars character recognition;character recognition pattern recognition production testing speech recognition computer science computer vision natural languages shape skeleton;character recognition;production rule	We describe a character recognition algorithm for Korean characters by employing attribute dependent regular programmed grammar (ADRPG). Each Korean character has more strokes than a English character, and the recognition of Korean characters is heavily dependent o n the attributes of strokes. We implemented a syntactic algorithm based on the ADPRG, and the ADRPG can easily incorporates attribute information in character pattern, such as position, angle, length, and branch points t o recognize characters with many strokes. The algorithm based on the ADPRG is implemented on a PC-AT compatible, and 377 production rules and 78 attribute test functions are derived from a printed document containing 4206 Korean characters. The productions and the attribute test functions obtained from the 4206 characters are applied to another document containing 3092 Korean characters having some defects. More than 95.1% of 3092 Korean characters are correctly recognized by the algorithm based on the ADPRG with average speed of 1.15 characters/second.	algorithm;distribution (mathematics);optical character recognition;printing	Kyoon Ha Lee;Kie B. Eom;Rangasami L. Kashyap	1988		10.1109/CVPR.1988.196269	natural language processing;branch point;speech recognition;intelligent character recognition;computer science;pattern recognition;mathematics;attribute grammar;position angle	Graphics	34.38637287733423	-66.83916891750519	173721
3ede39c791e003c01ea543d6cd8728f5665011af	extraction of newspaper headlines from microfilm for automatic indexing	headline extraction;run length smoothing;histogram transformation;noise reduction;image quality;automatic indexing	This paper proposes a document image analysis system that extracts newspaper headlines from microfilm images with a view to providing automatic indexing for news articles in microfilm. A major challenge in achieving this is the poor image quality of microfilm as most images are usually inadequately illuminated and considerably dirty. To overcome the problem we propose a new effective method for separating characters from noisy background since conventional threshold selection techniques are inadequate to deal with this kind of image. A run length smoothing algorithm is then applied to the headline extraction. Experimental results confirm the validity of the approach.	algorithm;effective method;image analysis;image quality;microform;run-length encoding;smoothing	Chew Lim Tan;Qing Hong Liu	2003	Document Analysis and Recognition	10.1007/s10032-003-0111-2	image quality;computer vision;speech recognition;computer science;noise reduction;data mining;information retrieval	Vision	38.381436089767334	-66.31281285873	173778
d1be4277a9e6b5f2bf31f3c8ff1d5cada21cf50b	mitosis detection in breast cancer histological images with mathematical morphology	mathematical morphology;biological tissues;object detection biological tissues cancer mathematical morphology medical image processing;cancer;circular covariance histogram mathematical morphology watershed transform texture description;morphology breast cancer histograms electronic mail biomedical imaging image analysis color;medical image processing;international mitosis detection contest breast cancer histological images mathematical morphology malignant tumors mitotic count patient tissue samples;object detection	One of the most important outcome predictors of malignant tumors is the mitotic count, i.e. the division speed of cells. This value is computed from the patient's tissue samples by medical experts, that count each mitosis case one by one under a microscope, and as such it is a time consuming process. In order to accelerate it, we present in this paper a system capable of mitosis detection from histological breast cancer images. To this end we have developed a fully automatic solution based on mathematical morphology. The proposed approach has achieved the 10th best performance among 14 teams at the international mitosis detection contest organized by ICPR'12.	mathematical morphology	Erchan Aptoula;Nicolas Courty;Sébastien Lefèvre	2013	2013 21st Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2013.6531502	computer vision;mathematical morphology;bioinformatics;cancer	Robotics	36.51553989308325	-75.26778910546277	173834
813254613e96e5343c1f1ba95e7c79df73409e74	automated image analysis of the pathological lung in ct	high resolution;high density;computer aided diagnosis;lung disease;segmentation;classification;lung;hybrid approach;texture analysis;high resolution ct;diffuse parenchymal lung disease;region of interest;registration;pattern recognition;computer aided detection;image analysis;computer analysis	The general objective of the thesis is automation of the analysis of the pathological#R##N#lung from CT images. Specifically, we aim for automated detection and classification of#R##N#abnormalities in the lung parenchyma. #R##N##R##N##R##N#We first provide a review of computer analysis techniques applied to CT of the lungs as published in the past five years. The rest of the thesis focuses on the steps needed for computer aided detection and diagnosis of disease in High Resolution CT (HRCT) images of the lung parenchyma: segmentation of the pathological lung, detection of abnormalities and classification of abnormalities.  #R##N##R##N##R##N#For the normal lung, segmentation can be performed making use of the excellent contrast between air and surrounding tissues. However, this approach fails when the lung is affected by high density pathology. Dense pathologies are present in approximately a fifth of clinical scans, and for computer analysis such as detection and quantification of abnormal areas it is vital that these pathologies are not missed in the initial segmentation. We propose a hybrid approach that incorporates atlas-based registration and voxel classification and as such responds to both shape and textural cues from both inside and outside the lung. It is shown that the proposed method can accurately segment scans with up to a quarter of the lung volume affected by high density pathology and therefore presents a considerable improvement over conventional techniques.  #R##N##R##N##R##N#After the lung fields have been identified, the task is to recognize possibly abnormal regions within them. We present an automated method for making the distinction between normal and abnormal lung tissue that makes use of the pattern recognition technique of statistical feature-based learning. Its performance in classifying a set of regions of interest (ROIs) is compared to that of two experts. It is concluded that the computer system is almost as adept at retrieving diagnostic information from the isolated ROIs as are the expert radiologists. However, performance of the radiologists when reviewing the entire scan is not rivaled by the automated system, indicating that further improvement should be sought in incorporation of the context of the ROIs. #R##N##R##N##R##N#In the final chapter it is investigated whether the more complex differentiation between several types of abnormal tissue can be made automatically. This analysis is performed on the entire lung field, rather than a selected set of ROIs. To this end, we propose an automatic unsupervised method of subdividing the lung fields into regions that are homogeneous in texture. It is shown that the proposed subdivision more closely resembles freehand drawing than the popular square grid, and additionally improves the computer classification performance. In classification of the entire lung fields, the automated system mostly confuses the same classes as do the experts. On a more global scale, the computer is used to answer the question whether or not a certain type of abnormality is present in a slice. In this task it achieves accuracies comparable to that of the experts.	image analysis	Ingrid Sluimer	2005			image analysis;image resolution;biological classification;segmentation;region of interest	Vision	33.513555206060985	-76.65136372260653	173852
dc9d689410e496105b00a5aedf9b764957b970f4	a heuristic algorithm for optical character recognition of arabic script	main feature segment;hidden variable theory;contour following;modelo markov;contour;learning;chain code;hidden markov model;optical character recognition;heuristic method;extraction forme;teoria variable escondida;hmm;segmentation;algorithme;aprendizaje;algorithm;apprentissage;markov model;arabic;extraccion forma;feature extraction;theorie variable cachee;reconocimento optico de caracteres;contorno;arabe;modele markov;feature analysis;key feature;character recognition;pattern extraction;segmentacion;heuristic algorithm;reconnaissance optique caractere;algoritmo	In this paper, a heuristic method is developed for segmentation, feature extraction and recognition of the Arabic script. The study is part of a large project for transcription of the documents in Ottoman Archives. A geometrical and topological feature analysis method is developed for segmentation and feature extraction stages. Chain code transformation is applied to main strokes of the characters, which are classified by the hidden Markov model (HMM) in the recognition stage. Experimental results indicate that the performance of the proposed method is quite satisfactory, provided that the thinning process does not yield spurious branches.	algorithm;chain code;data structure;feature extraction;heuristic (computer science);hidden markov model;markov chain;optical character recognition;preprocessor;signal processing;thinning;transcription (software);trie	A. Alper Atici;Fatos T. Yarman-Vural	1997	Signal Processing	10.1016/S0165-1684(97)00117-5	feature extraction;computer science;artificial intelligence;machine learning;arabic;chain code;markov model;optical character recognition;segmentation;hidden variable theory;algorithm;hidden markov model	NLP	34.17485156183021	-67.52588901627945	174032
1830eeec8b920d48f3f718ec1f0b8608b2579c2f	automated object tracing for biomedical image segmentation using a deep convolutional neural network		Convolutional neural networks (CNNs) have been used for fast and accurate segmentation of medical images. In this paper, we present a novel methodology that uses CNNs for segmentation by mimicking the human task of tracing object boundaries. The architecture takes as input a patch of an image with an overlay of previously traced pixels and the output predicts the coordinates of the next m pixels to be traced. We also consider a CNN architecture that leverages the output from another semantic segmentation CNN, e.g., U-net, as an auxiliary image channel. To initialize the trace path in an image, we use either locations identified as object boundaries with high confidence from a semantic segmentation CNN or a short manually traced path. By iterating the CNN output, our method continues the trace until it intersects with the beginning of the path. We show that our network is more accurate than the state-of-the-art semantic segmentation CNN on microscopy images from the ISBI cell tracking challenge. Moreover, our methodology provides a natural platform for performing human-in-the-loop segmentation that is more accurate than CNNs alone and orders of magnitude faster than manual segmentation.	convolutional neural network;image segmentation	Erica M. Rutter;John H. Lagergren;Kevin B. Flores	2018		10.1007/978-3-030-00937-3_78	computer vision;computer science;artificial intelligence;convolutional neural network;architecture;pattern recognition;overlay;image segmentation;pixel;communication channel;tracing;segmentation	Vision	30.48868489049556	-73.68326171098518	174407
38ff0da9a7c5ee503824c4b9838419d4039e8ae7	multi-feature analysis and classification of human chromosome images using centromere segmentation algorithms	medical image processing cellular biophysics image classification feature extraction gradient methods image segmentation cancer genetics optical microscopy fuzzy set theory;classification algorithm;multi feature analysis;image segmentation;heteromorphic chromosomes;centromere segmentation algorithms;iterative algorithms;cancer;gradient method;parental homologues multi feature analysis classification human chromosome images centromere segmentation algorithms homologous human chromosomes cancer genetics multiple features microscopy images multicolour images metaphase chromosome pna probes iterative fuzzy algorithm gradient method telomere length intensity features heteromorphic chromosomes;image database;image classification;microscopy;telomere length;humans biological cells iterative algorithms image segmentation cancer genetics classification algorithms feature extraction microscopy presence network agents;pna probes;classification;fuzzy set theory;genetics;cancer genetics;homologous human chromosomes;biological cells;intensity features;metaphase chromosome;multiple features;feature extraction;medical image processing;presence network agents;classification algorithms;gradient methods;microscopy images;humans;multicolour images;feature analysis;parental homologues;iterative fuzzy algorithm;cellular biophysics;optical microscopy;human chromosome images	Classification of homologous human chromosomes is essential to advanced studies of cancer genetics. This paper describes novel segmentation and classification algorithms to extract multiple features, from microscopy images of chromosomes, for classification purposes. Multicolour images of metaphase chromosomes prepared applying PNA probes are used for this purpose. Centromeres are segmented using an iterative fuzzy algorithm as well as a gradient method. Moreover, telomere length measurements are performed on chromosome images and normalized for the image database. Multiple intensity features are calculated as a result of the developed algorithms. Heteromorphic chromosomes (such as 16 and 22) are then successfully classified into their parental homologues, based on the calculated multiple features, and used to verify the developed methods.	algorithm;gradient method;homepna;homology (biology);iterative method	Parvin Mousavi;Rabab Kreidieh Ward;Peter M. Lansdorp;Sidney S. Fels	2000		10.1109/ICIP.2000.900917	pattern recognition;computer vision;contextual image classification;feature extraction;biological classification;computer science;bioinformatics;microscopy;gradient method;machine learning;optical microscope;fuzzy set;image segmentation;cancer	Vision	38.245496402329344	-74.66593510104714	174434
51f5b6b5c420a2f7211e5b939f0041957c362d88	an hmm implementation for on-line handwriting recognition based on pen-coordinate feature and pen-direction feature	10 stroke chinese characters on line handwriting recognition pen coordinate feature pen direction feature hidden markov models inter state transition intra state transition;on line handwriting recognition;feature extraction handwritten character recognition hidden markov models;hidden markov models;feature extraction;hidden markov models handwriting recognition character recognition proposals topology information science shape solid modeling deformable models tellurium;handwritten character recognition;state transition	An on-line handwritten character recognition technique based on a new HMM is proposed. In the proposed HMM, not only pen-direction feature but also pen-coordinate feature are separately utilized for describing the shape variation of on-line characters accurately. Specifically speaking, the proposed HMM outputs a pen-coordinate feature at each inter-state transition and outputs a pen-direction feature at each intra-state transition, i.e., self-transition. Thus, each state of the proposed HMM can specify the starting position and the direction of a line segment by its incoming inter-state transition and intra-state transition, respectively. The results of recognition experiments on 10-stroke Chinese characters show that the proposed HMM outperforms the conventional HMM which does not use the pen-coordinate feature because of its non-stationarity.	experiment;handwriting recognition;hidden markov model;online and offline;optical character recognition;state transition table;stationary process	Daiki Okumur;Seiichi Uchida;Hiroaki Sakoe	2005	Eighth International Conference on Document Analysis and Recognition (ICDAR'05)	10.1109/ICDAR.2005.50	speech recognition;feature;feature extraction;intelligent character recognition;computer science;machine learning;pattern recognition;feature;hidden markov model	Robotics	32.680096472124	-66.95072438941511	174812
00b75be22d45700d1263e1d25d142fce6da7bd13	craniofacial reconstruction based on multi-linear subspace analysis	engineering;it software telecommunications;aerospace;industry sectorsautomotive;craniofacial reconstruction;journal;期刊论文;electronics;multi linear subspace analysis;partial least squares regression	Craniofacial reconstruction aims to estimate an individual’s facial appearance from its skull. It can be applied in many multimedia services such as forensic medicine, archaeology, face animation etc. In this paper, a statistical learning based method is proposed for 3D craniofacial reconstruction. In order to well represent the craniofacial shape variation and better utilize the relevance between different local regions, two tensor models are constructed for the skull and the face skin respectively, and multi-linear subspace analysis is used to extract the craniofacial subspace features. A partial least squares regression (PLSR) based mapping from skull subspace to skin subspace is established with the attributes such as age and BMI being considered. For an unknown skull, the 3D face skin is reconstructed using the learned mapping with the help of the skin tensor model. Compared with some other statistical learning based method in literature, the proposed method more directly and properly reflects the shape relationship between the skull and the face. In addition, the proposed method has little manual intervention. Experimental results show that the proposed method is valid.	brain–computer interface;machine learning;partial least squares regression;relevance;tomographic reconstruction	Fuqing Duan;Sen Yang;Donghua Huang;Yongli Hu;Zhongke Wu;Mingquan Zhou	2012	Multimedia Tools and Applications	10.1007/s11042-012-1351-2	electronics;speech recognition;machine learning;partial least squares regression;aerospace	Vision	36.28264910613493	-72.22346262080492	174815
d31bc8e53ae895bc8c730a03b10c977fffa9b5c4	local binary pattern for word spotting in handwritten historical document		Digital libraries store images which can be highly degraded and to index this kind of images we resort to word spotting as our information retrieval system. Information retrieval for handwritten document images is more challenging due to the difficulties in complex layout analysis, large variations of writing styles, and degradation or low quality of historical manuscripts. This paper presents a simple innovative learning-free method for word spotting from large scale historical documents combining Local Binary Pattern (LBP) and spatial sampling. This method offers three advantages: firstly, it operates in completely learning free paradigm which is very different from unsupervised learning methods, secondly, the computational time is significantly low because of the LBP features which are very fast to compute, and thirdly, the method can be used in scenarios where annotations are not available. Finally we compare the results of our proposed retrieval method with the other methods in the literature.	belief propagation;benchmark (computing);circuit complexity;computation;computer performance;computer vision;digital library;elegant degradation;feature extraction;handwriting recognition;historical document;information retrieval;k-nearest neighbors algorithm;library (computing);local binary patterns;programming paradigm;quadtree;requirement;sampling (signal processing);spatial variability;time complexity;unsupervised learning	Sounak Dey;Anguelos Nicolaou;Josep Lladós;Umapada Pal	2016		10.1007/978-3-319-49055-7_51	computer vision;speech recognition;computer science;machine learning;pattern recognition;data mining	Web+IR	30.590485661570618	-66.49518508304295	174980
00be78806b90b995f956032a9863d7389510f96c	a novel adcs-based cnn classification system for precise diagnosis of prostate cancer		This paper addresses the issue of early diagnosis of prostate cancer from diffusion-weighted magnetic resonance imaging (DWI) using a convolutional neural network (CNN) based computer-aided diagnosis (CAD) system. The proposed CNN-based CAD system first segments the prostate using a geometric deformable model. The evolution of this model is guided by a stochastic speed function that exploits first-and second-order appearance models besides shape prior. The fusion of these guiding criteria is accomplished using a nonnegative matrix factorization (NMF) model. Then, the apparent diffusion coefficients (ADCs) within the segmented prostate are calculated at each b-value. They are used as imaging markers for the blood diffusion of the scanned prostate. For the purpose of classification/diagnosis, a three dimensional CNN has been trained to extract the most discriminatory features of these ADC maps for distinguishing malignant from benign prostate tumors. The performance of the proposed CNN-based CAD system is evaluated using DWI datasets acquired from 45 patients (20 benign and 25 malignant) at seven different b-values. The acquisition of these DWI datasets is performed using two different scanners with different magnetic field strengths (1.5 Tesla and 3 Tesla). The conducted experiments on in-vivo data confirm that the use of ADCs makes the proposed system nonsensitive to the magnetic field strength.		Islam Reda;Mohammed Ghazal;Ahmed Shalaby;Mohammed Elmogy;Ahmed Abou El-Fetouh;Babajide Odunitan Ayinde;Mohamed Abou El-Ghar;Adel Said Elmaghraby;Robert Keynton;Ayman El-Baz	2018	2018 24th International Conference on Pattern Recognition (ICPR)	10.1109/ICPR.2018.8546029	computer vision;convolutional neural network;flight dynamics (spacecraft);artificial intelligence;feature extraction;cad;pattern recognition;solid modeling;prostate cancer;magnetic resonance imaging;computer science;non-negative matrix factorization	Robotics	34.429301022435	-77.18426597979943	174995
2e41fe070fbfb9faec3c998d87ead95365c0b611	computer-aided diagnostic tool for early detection of prostate cancer	design automation;training;feature extraction;magnetic resonance imaging;solid modeling;prostate cancer	In this paper, we propose a novel non-invasive framework for the early diagnosis of prostate cancer from diffusion-weighted magnetic resonance imaging (DW-MRI). The proposed approach consists of three main steps. In the first step, the prostate is localized and segmented based on a new level-set model. In the second step, the apparent diffusion coefficient (ADC) of the segmented prostate volume is mathematically calculated for different b-values. To preserve continuity, the calculated ADC values are normalized and refined using a Generalized Gauss-Markov Random Field (GGMRF) image model. The cumulative distribution function (CDF) of refined ADC for the prostate tissues at different b-values are then constructed. These CDFs are considered as global features describing water diffusion which can be used to distinguish between benign and malignant tumors. Finally, a deep learning auto-encoder network, trained by a stacked non-negativity constraint algorithm (SNCAE), is used to classify the prostate tumor as benign or malignant based on the CDFs extracted from the previous step. Preliminary experiments on 53 clinical DW-MRI data sets resulted in 100% correct classification, indicating the high accuracy of the proposed framework and holding promise of the proposed CAD system as a reliable non-invasive diagnostic tool.	autoencoder;coefficient;computer-aided design;constraint algorithm;deep learning;dreamwidth;encoder;experiment;markov chain;markov random field;negativity (quantum mechanics);resonance;scott continuity	Islam Reda;Ahmed Shalaby;Fahmi Khalifa;Mohammed M. Elmogy;Ahmed Aboulfotouh;Mohamed Abou El-Ghar;Ehsan Hosseini-Asl;Naoufel Werghi;Robert Keynton;Ayman El-Baz	2016	2016 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2016.7532843	feature extraction;computer science;magnetic resonance imaging;solid modeling	Robotics	31.32434041676982	-76.01839477780753	175219
2b917cd79d3eb1bb95e1cd11509575e5965639a8	decision tree based medical image clustering algorithm in computer-aided diagnoses		With the rapid development of intelligent diagnostic medical imaging, artificial intelligent methods have become a research hotspot in this field with the rapid development of medical imaging intelligent diagnosis. The new research progress of artificial intelligence in medical image processing in recent five years is discussed. This paper discussed the function of medical image mining in computer-aided diagnoses. The idea of using luminance grade as the features of CT image and the method of extracting and storing the luminance grade are proposed. The results of classification based on decision tree and clustering based on density to some brain and breast CT images and the analysis to them are introduced. Moreover, the conclusion and future work are given.	algorithm;cluster analysis;decision tree	Wei Zhou;Hongqiang Wang;Chunmei Yang;Yang Bai;Dongliang Wang;Yongfeng Zhan	2015	J. Comput. Meth. in Science and Engineering	10.3233/JCM-150585	computer vision;computer science;artificial intelligence;data mining	DB	33.56688917564192	-75.56181952262513	175237
e559a653115157433806d8e974d6efbfbd0d63e9	text line identification in tagore's manuscript	histograms;frequency modulation;handwriting recognition;optical filters;text analysis document image processing handwritten character recognition image segmentation optical character recognition;text analysis;handwriting recognition histograms image analysis text analysis optical filters frequency modulation character recognition;image analysis;connected component analysis text line identification method printed document text line segmentation uniform line straightness handwritten documents nonuniform line variable interline gaps rabindranath tagore manuscript preprocessing stage document image cleaning doodle separation textual region window examination black run length smearing horizontal histogram;manuscript processing document image analysis doodle handwritten document text line identification;character recognition	In this paper, a text line identification method is proposed. The text lines of printed document are easy to segment due to uniform straightness of the lines and sufficient gap between the lines. But in handwritten documents, the line is nonuniform and interline gaps are variable. We take Rabindranath Tagore's manuscript as it is one of the most difficult manuscripts that contain doodles. Our method consists of a preprocessing stage to clean the document image. Then we separate doodles from the manuscript to get the textual region. After that we identify the text lines on the manuscript. For text line identification, we use window examination, black run-length smearing, horizontal histogram and connected component analysis.	connected component (graph theory);connected-component labeling;f1 score;handwriting recognition;identifier;interlaced video;preprocessor;printing;run-length encoding;semiconductor industry;test case	Chandranath Adak;Bidyut Baran Chaudhuri	2014	Proceedings of the 2014 IEEE Students' Technology Symposium	10.1109/TechSym.2014.6808048	frequency modulation;computer vision;image analysis;speech recognition;computer science;pattern recognition;optical filter;histogram;handwriting recognition	Vision	37.14941572271498	-66.35240059770994	175438
a73ab02343dfbe8d31ffca952d8e2d0ed0cf6599	automatic counting of leukocytes in giemsa-stained images of peripheral blood smear	histograms;red cells;electronic mail;image segmentation;giemsa stained image;leukocyte counting;peripheral blood image;component;microscopy;deformable models;segmentation;data mining;human body infection;white cell;histogram;leukocyte count;feature extraction;medical image processing;human body;blood;pixel;image thresholding;diseases;neutrophils;analysis;humans;thresholding;nucleus blood cellular biophysics diseases image segmentation medical image processing;dilation;peripheral blood smear;image histogram;nucleus;peripheral blood;digital images;cellular biophysics;dilation component histogram analysis thresholding leukocyte counting segmentation;white blood cells cells biology image segmentation humans histograms deformable models laboratories digital images electronic mail feature extraction;cells biology;white blood cells;image thresholding giemsa stained image peripheral blood smear peripheral blood image leukocyte count human body infection image segmentation nucleus white cell neutrophils image histogram red cells	There are many different classes of leukocyte in peripheral blood image. Leukocyte count is used to determine the presence of an infection in the human body. To be able to observe and recognize the different kinds of leukocyte, you must stain them. For this purpose, normally Giemsa stain is used. There are two difficult issues in image segmentation which common segmentation algorithms can not overcome them. Nucleus which is laid inside white cell is the darkest part of image which can be used to count cells. Since Giemsa staining is done by humans, intensity of images is slightly different from each others. Neutrophils are kinds of leukocytes which have segmented and distinctive nucleus. These reasons cause a considerable error in counting. In this paper, we have proposed to use histogram of images and intensity of red cells which are major objects in images to select appropriate point for thresholding. And then the distances among centers of the extracted nuclei have been calculated, according to the specified size of leukocytes, we merge the nuclei which those distances are less than the diameter of one leukocyte. Experimental results show that our approach is very efficient.	algorithm;image segmentation;peripheral;smear campaign;thresholding (image processing)	Mohammad Hamghalam;Ahmad Ayatollahi	2009	2009 International Conference on Digital Image Processing	10.1109/ICDIP.2009.9	biology;computer vision;pathology;computer graphics (images)	Robotics	37.80628479248956	-76.29759615909728	175824
5a7483c675a7722dcd3bc571392d59f54c706f5e	ct image segmentation in traumatic brain injury	ground truth ct image segmentation traumatic brain injury tbi diagnosis computer aided imaging analysis automated system real time clinical diagnosis quality assurance hematoma region image denoising image enhancement gaussian mixture model;quality assurance brain computerised tomography gaussian processes image denoising image enhancement image segmentation injuries medical disorders medical image processing mixture models neurophysiology;image segmentation computed tomography brain injuries hemorrhaging noise reduction biomedical imaging level set	Traumatic brain injury (TBI) is a major cause of disability and death. Speed and accuracy are vital in diagnosing TBI for which computer-aided imaging analysis may speedup and improve the efficiency of diagnosis and help reduce mortality, long-term complications, and the associated costs. However, developing such a system is challenging due to some factors such as the inherent noise associated with obtaining the images, artifacts and quality of the images. An automated system that can preliminary identify, localize and quantify the imaging features of TBI would be beneficial in guiding real-time clinical diagnosis as well as for quality assurance. In this paper we propose an automated system to segment the hematoma region from CT images. The proposed method first performs denoising and image enhancement and then by developing a Gaussian mixture model, segmentation is carried out. We show the performance of the system by comparing the results with ground truth generated by specialists.	brain injuries;ct scan;contain (action);gm(m);google map maker;ground truth;hematoma;image noise;image segmentation;mixture model;morphologic artifacts;noise reduction;normal statistical distribution;part dosing unit;patients;preprocessor;real-time transcription;region of interest;simulation;speedup;traumatic brain injury;video post-processing;biologic segmentation	S. Mohamad R. Soroushmehr;A. Bafna;S. Schlosser;Kevin Ward;Harm Derksen;Kayvan Najarian	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7319016	computer vision;radiology;medicine;medical physics	Robotics	38.61640699542729	-79.7191224258806	175825
6baa593eb24fa8591d285a53bf8b9ffda26cb402	development of enhanced weed detection system with adaptive thresholding and support vector machine	image segmentation;automatic thresholding;automatic greenness identification;weed identification;support vector machine;precision agriculture	This paper proposes a sophisticated classification process to segment the leaves of carrots from weeds. In the early stages of the plants' development, the color of both the plants and the weeds are similar, making it difficult to differentiate between the two. The process becomes even harder if the weeds and plants overlap. The proposed system addresses this problem by creating a sophisticated mean for weed identification. The major components of this system are composed of three processes: image segmentation, feature extraction and decision-making. In the image segmentation process, the input images are processed into lower units where the relevant features are extracted. In the decision-making process, the system makes use of the Support Vector Machine to analyze and segregate the weeds from the plants. Afterward, the findings are used to dictate which plants receive herbicides and which do not. The main priority for the image segmentation process is on the overlapping images where weeds need to be isolated from plants so that they can be used for cultivation purpose.  The evaluation of the approach is done using an open dataset of images consisting of carrot plants. The system is able to achieve 88.99% accuracy for weed classification using this dataset. This methodology will help to reduce the use of herbicides while improving the performance and costs of precision agriculture.	color;feature extraction;image segmentation;support vector machine;thresholding (image processing)	Dheeman Saha;Austin Hanson;Sung Y. Shin	2016		10.1145/2987386.2987433	computer vision;engineering;data mining;horticulture	Vision	35.131181978278306	-71.22579870028528	175844
d66c396a3047465afc585e783c7086233ba6f360	effective quantification of gene expression levels in microarray images using a spot-adaptive compound clustering-enhancement-segmentation scheme	dna;noise estimation;clahe;coefficient of variation;srg;microarray image analysis;gene expression;image enhancement;microarray griding;image analysis;dna microarray;fuzzy c means clustering	A spot-adaptive compound clustering-enhancement-segmentation (CES) scheme was developed for the quantification of gene expression levels in microarray images. The CES-scheme employed 1/griding, for locating spotregions, 2/Fuzzy C-means clustering, for segmenting spots from background, 3/ background noise estimation and spot’s center localization, 4/emphasizing of spot’s outline by the CLAHE image enhancement technique, 5/segmentation by the SRG algorithm, using information from step 3, and 6/microarray spot intensity extraction. Extracted intensities by the CES-Scheme were compared against those obtained by the MAGIC TOOL’s SRG. Kullback-Liebler metric’s values for the CES-Scheme were on average double than MAGIC TOOL’s, with differences ranging from 1.45bits to 2.77bits in 7 cDNA images. Coefficient-ofVariation results showed significantly higher reproducibility (p<0.001) for the CES-Scheme in quantifying gene expression levels. Processing times for 1024x1024 16-bit microarray images containing 6400 spots were 300 and 487 seconds for the CES-Scheme and MAGIC TOOL respectively.	16-bit;adaptive histogram equalization;algorithm;cluster analysis;coefficient;image editing;kullback–leibler divergence;microarray;strongly regular graph	Antonis Daskalakis;Dionisis A. Cavouras;Panagiotis Bougioukos;Spiros A. Kostopoulos;Pantelis Georgiadis;Ioannis Kalatzis;George C. Kagadis;George Nikiforidis	2007		10.1007/978-3-540-74484-9_48	image analysis;gene expression;dna microarray;computer science;bioinformatics;data mining;adaptive histogram equalization;coefficient of variation;dna	Visualization	38.16264663754701	-72.89460588568772	175955
6a9268913070f2ea72c884b050901066e1b769f7	on the segmentation of multiple touched cursive characters: a heuristic approach	search algorithm;character segmentation;qa75 electronic computers computer science;q science	Heuristics are based on the experiences and solves problems approximately that cannot be solved exactly. In handwritten documents recognition, the most difficult phase is touched character segmentation as incorrectly segmented characters cannot be recognized correctly. Accordingly, this paper presents a heuristic approach for multiple touched cursive characters. Initially, a possible segmentation zone is detected using peak to valley function. Next, greedy best search algorithm is implemented in the possible segmentation zone for touched characters segmentation. Experimental results on a test set extracted from the IAM benchmark database exhibit high segmentation accuracy up to 91.63%. Moreover, proposed approach is very fast and can handle multiple cursive touching characters.	benchmark (computing);greedy algorithm;heuristic;identity management;search algorithm;test set	Tanzila Saba;Ghazali Sulong;Shafry Rahim;Amjad Rehman	2010		10.1007/978-3-642-15766-0_91	computer vision;computer science;artificial intelligence;machine learning;segmentation-based object categorization;scale-space segmentation;search algorithm	Vision	35.75203186784367	-66.5881451776782	176471
3e93f99eed9290ec4a4b3272f9bb275fe0e23360	blood cell classification using the hough transform and convolutional neural networks		The detection of red blood cells in blood samples can be crucial for the disease detection in its early stages. The use of image processing techniques can accelerate and improve the effectiveness and efficiency of this detection. In this work, the use of the Circle Hough transform for cell detection and artificial neural networks for their identification as a red blood cell is proposed. Specifically, the application of neural networks (MLP) as a standard classification technique with (MLP) is compared with new proposals related to deep learning such as convolutional neural networks (CNNs). The different experiments carried out reveal the high classification ratio and show promising results after the application of the CNNs.	convolutional neural network;hough transform;neural networks	Miguel A. Molina-Cabello;Ezequiel López-Rubio;Rafael Marcos Luque Baena;María Jesús Rodríguez-Espinosa;Karl Thurnhofer-Hemsi	2018		10.1007/978-3-319-77712-2_62	convolutional neural network;image processing;deep learning;artificial neural network;blood cell;artificial intelligence;computer science;hough transform;pattern recognition	Vision	32.79114900799811	-75.14887668568983	176490
3397f3c5fb873aacdfa5ba1fa9c3e1250a9b8762	an overview of approaches for content-based medical image retrieval		Medical imaging performs a vital role in the medical field as it provides important information on the internal body parts for the clinical analysis and medical intervention which enables physicians to diagnose and treat a variety of diseases. Nowadays the medical diagnosis is increasing at a very high rate, which results in the formation of a huge medical image database, and retrieving similar medical images from such a huge database is a very difficult task. A literature review of various methods for biomedical image indexing and retrieval is presented here. Over 140 contributions are included from the literature in this survey. And it is mainly concentrated on the methodology based on the visual representation of the medical images as content-based medical image retrieval (CBMIR) approaches retrieve similar medical images more efficiently as compared to text-based biomedical image retrieval approaches. It also delineates how various ideas were adopted from different computer science methodologies for developing CBMIR systems.	artificial neural network;barcode;computer science;global optimization;grayscale;image noise;image retrieval;information retrieval;machine learning;medical imaging;region of interest;spatial variability;text-based (computing)	Pranjit Das;Arambam Neelima	2017	International Journal of Multimedia Information Retrieval	10.1007/s13735-017-0135-x	automatic image annotation;medical diagnosis;clinical pathology;data mining;search engine indexing;information retrieval;image retrieval;medical imaging;computer science	Vision	32.902887522064205	-73.40248634363618	176578
140dbee2cc7a2b3ab93c731f5aa01e5105c35153	towards automatic assessment of compulsive hoarding from images	clutter;support vector machines;estimation;image edge detection;static var compensators;clothing;public healthcare	Hoarding is a complex and impairing psychiatric disorder and a public health problem. Traditionally it is assessed through observation and interview, but recently a new method has been proposed where living quarters of an individual are visually compared with a set of template images ranked according to the “Clutter Image Rating” (CIR) scale from 1 to 9. However, such an assessment is time-consuming, subjective, and weak in repeatability. We propose an automatic method for classifying hoarding images according to the CIR scale. Since clutter in living quarters (e.g., piles of boxes, newspapers, clothing) corresponds to “busy” areas with lots of edges in captured images, we use the histogram-of-gradients (HOG) descriptor to characterize images and estimate the CIR value using two methods: regression and classification. In 4-fold cross-validation on 620 images that we harvested from the internet, both methods result in mean-absolute CIR error of about 1.2. Given the simplicity of our method, this is an encouraging result as it approximates ratings by trained professionals who admit assigning CIR values within ± 1 CIR point.	clutter;committed information rate;cross-validation (statistics);gradient;repeatability	Alexander Tooke;Janusz Konrad;Jordana Muroff	2016	2016 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2016.7532573	support vector machine;computer vision;estimation;simulation;computer science;clothing;mathematics;clutter;computer security;statistics	Robotics	29.921474540326546	-70.6507681913844	176580
1ea792028907fa6e2816e63a3f5e295ea4c46134	projection-based text line segmentation with a variable threshold		Document image segmentation into text lines is one of the stages in unconstrained handwritten document recognition. This paper presents a new algorithm for text line separation in handwriting. The developed algorithm is based on a method using the projection profile. It employs thresholding, but the threshold value is variable. This permits determination of low or overlapping peaks of the graph. The proposed technique is shown to improve the recognition rate relative to traditional methods. The algorithm is robust in text line detection with respect to different text line lengths.		Roman Ptak;Bartosz Zygadlo;Olgierd Unold	2017	Applied Mathematics and Computer Science	10.1515/amcs-2017-0014	pattern recognition;scale-space segmentation	AI	36.36840531149208	-66.29796835653003	176695
295890e72d9d80edae3e3b6f98378f9d38c77522	one-line recognition system for free-format handwritten japanese characters	graph search;parallelisme;image processing;caracter manuscrito;hierarchized structure;japonais;manuscript character;character segmentation;procesamiento imagen;structure hierarchisee;segmentation;grafico;traitement image;parallelism;reconnaissance caractere;paralelismo;graph;graphe;pattern recognition;reconnaissance forme;reconocimiento patron;caractere manuscrit;character recognition;japones;estructura jerarquizada;segmentacion;reconocimiento caracter;parallel processors;japanese	This paper describes an on-line recognition system for free-format handwritten Japanese character strings which may contain characters with separated constituents or overlapping characters. The recognition method for the system, called candidate lattice method, conducts segmentation and recognition of individual character candidates, and applies linguistic information to determine the most probable character string in order to achieve high recognition rates. Special hardware designed to realize a real-time recognition system is also introduced. The method used on the special hardware attained a segmentation rate of 98.8% and an overall recognition rate of 98.7% for 105 samples.		Hiroshi Murase	1991	IJPRAI	10.1142/S0218001491000144	computer vision;japanese;speech recognition;document processing;feature;image processing;intelligent character recognition;computer science;artificial intelligence;intelligent word recognition;pattern recognition;graph;segmentation	Vision	34.10753909469164	-67.68709562148638	177012
f658bd5af5310a7592ebe654fb3cf492835f0f26	automatic conjunctival provocation test using hough transform of extended canny edge maps		Computer-aided diagnosis is developed for assessment of allergic rhinitis/rhinoconjunctivitis measuring the relative redness of sclera under application of allergen solution. The patient’s eye images are taken from commercial digital camera. The iris is robustly localized using a gradient-based Hough circle transform. From the center of the pupil, the region of interest within the sclera is extracted using geometric anatomybased a-priori information. The red color pixels are extracted thresholding in the hue, saturation and value color space. Then, redness is measured by taking mean of saturation projected into zero hue. Evaluation is performed with 92 images taken from 13 subjects, 8 responders and 5 non-responders, which were classified according to an experienced otorhinolaryngologist. Provocation is performed with 100, 1,000 and 10,000 AU/ml allergic solution and normalized to control images without provocation. The evaluation yields redness of 1.14, 1.30, 1.60 and 1.04, 1.12, 1.11 for responders and non-responders, respectively. This indicates that our method is suitable as reliable endpoint in controlled clinical trials.	canny edge detector;hough transform	Suman Raj Bista;Serkan Dogan;Anatoli Astvatsatourov;Ralph Mösges;Thomas Martin Deserno	2013		10.1007/978-3-642-36480-8_51	canny edge detector;sclera;provocation test;region of interest;computer vision;artificial intelligence;hue;thresholding;color space;geography;hough transform	Vision	37.14118718133498	-76.41468669762857	177410
5839c0f0c57ba032391d078325de86f72e41f4b1	an automated system for detecting and measuring nailfold capillaries	sensitivity and specificity;raynaud disease;image enhancement;image interpretation computer assisted;reproducibility of results;capillaries;algorithms;pattern recognition automated;humans;subtraction technique;microscopic angioscopy;nails	Nailfold capillaroscopy is an established qualitative technique in the assessment of patients displaying Raynaud's phenomenon. We describe a fully automated system for extracting quantitative biomarkers from capillaroscopy images, using a layered machine learning approach. On an unseen set of 455 images, the system detects and locates individual capillaries as well as human experts, and makes measurements of vessel morphology that reveal statistically significant differences between patients with (relatively benign) primary Raynaud's phenomenon, and those with potentially life-threatening systemic sclerosis.	addison disease;biological markers;blood vessel tissue;blood capillaries;machine learning;mathematical morphology;microscopic angioscopy;nailfold capillaroscopy;patients;raynaud disease;raynaud phenomenon;sensor;systemic scleroderma;anatomical layer	Michael Berks;Philip A. Tresadern;Graham Dinsdale;Andrea Murray;Tonia L Moore;Ariane L. Herrick;Christopher J. Taylor	2014	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-319-10404-1_82	computer vision;pathology;computer science;algorithm	EDA	36.2032627165757	-78.23361683454247	177457
526d9d47e39c84d4a33f9011a54228d04f882ed6	classification of melanoma lesions using sparse coded features and random forests	image segmentation;image processing;cancer;skin cancer;melanoma;classification;random forests;dermoscopy;medical diagnostics;machine learning;associative arrays;sparse coding;cad systems;radiometric corrections;chemical species	Malignant melanoma is the most dangerous type of skin cancer, yet it is the most treatable kind of cancer, conditioned by its early diagnosis which is a challenging task for clinicians and dermatologists. In this regard, CAD systems based on machine learning and image processing techniques are developed to differentiate melanoma lesions from benign and dysplastic nevi using dermoscopic images. Generally, these frameworks are composed of sequential processes: pre-processing, segmentation, and classification. This architecture faces mainly two challenges: (i) each process is complex with the need to tune a set of parameters, and is specific to a given dataset; (ii) the performance of each process depends on the previous one, and the errors are accumulated throughout the framework. In this paper, we propose a framework for melanoma classification based on sparse coding which does not rely on any pre-processing or lesion segmentation. Our framework uses Random Forests classifier and sparse representation of three features: SIFT, Hue and Opponent angle histograms, and RGB intensities. The experiments are carried out on the public PH dataset using a 10-fold cross-validation. The results show that SIFT sparse-coded feature achieves the highest performance with sensitivity and specificity of 100% and 90.3% respectively, with a dictionary size of 800 atoms and a sparsity level of 2. Furthermore, the descriptor based on RGB intensities achieves similar results with sensitivity and specificity of 100% and 71.3%, respectively for a smaller dictionary size of 100 atoms. In conclusion, dictionary learning techniques encode strong structures of dermoscopic images and provide discriminant descriptors.	algorithm;color space;computer-aided design;cross-validation (statistics);dictionary;discriminant;encode;experiment;high- and low-level;image processing;machine learning;neural coding;opponent process;preprocessor;radio frequency;random forest;scale-invariant feature transform;sensitivity and specificity;sparse approximation;sparse matrix	Mojdeh Rastgoo;Guillaume Lemaître;Olivier Morel;Joan Massich;Rafael García;Fabrice Mériaudeau;Franck Marzani;Desire Sidibé	2016		10.1117/12.2216973	random forest;computer vision;image processing;biological classification;computer science;machine learning;pattern recognition;chemical species;image segmentation;neural coding;cancer;associative array	Vision	33.613605444256486	-75.32476157951092	177836
0ca5749b323de4837e7dc261ef6db96dab742920	relevance vector machine for automatic detection of clustered microcalcifications	free response receiver operating characteristic;breast cancer detection;estimation theory;computer aided diagnosis;supervised learning;support vector machines;bayes methods;medical image processing biological organs mammography support vector machines learning artificial intelligence bayes methods estimation theory image classification sensitivity analysis computational complexity;biological organs;real time processing;image classification;relevance vector machine breast cancer detection computer aided diagnosis mammography microcalcifications;microcalcifications;machine learning;automatic detection;computational complexity;sensitivity analysis;medical image processing;algorithms artificial intelligence breast diseases breast neoplasms calcinosis cluster analysis female humans imaging three dimensional information storage and retrieval pattern recognition automated precancerous conditions radiographic image enhancement radiographic image interpretation computer assisted reproducibility of results retrospective studies sensitivity and specificity;relevance vector machine;detection algorithm;computer aided detection;bayesian estimator;support vector machines support vector machine classification computer networks breast cancer bayesian methods estimation theory detection algorithms object detection databases computational complexity;support vector machine;mammography;learning artificial intelligence;breast cancer;7 26 s relevance vector machine automatic clustered microcalcification detection digital mammograms breast cancer computer aided detection machine learning relevance vector machine classifier bayesian estimation theory supervised learning two stage classification network support vector machine classifier free response receiver operating characteristic curves computational complexity 250 s	Clustered microcalcifications (MC) in mammograms can be an important early sign of breast cancer in women. Their accurate detection is important in computer-aided detection (CADe). In this paper, we propose the use of a recently developed machine-learning technique - relevance vector machine (RVM) - for detection of MCs in digital mammograms. RVM is based on Bayesian estimation theory, of which a distinctive feature is that it can yield a sparse decision function that is defined by only a very small number of so-called relevance vectors. By exploiting this sparse property of the RVM, we develop computerized detection algorithms that are not only accurate but also computationally efficient for MC detection in mammograms. We formulate MC detection as a supervised-learning problem, and apply RVM as a classifier to determine at each location in the mammogram if an MC object is present or not. To increase the computation speed further, we develop a two-stage classification network, in which a computationally much simpler linear RVM classifier is applied first to quickly eliminate the overwhelming majority, non-MC pixels in a mammogram from any further consideration. The proposed method is evaluated using a database of 141 clinical mammograms (all containing MCs), and compared with a well-tested support vector machine (SVM) classifier. The detection performance is evaluated using free-response receiver operating characteristic (FROC) curves. It is demonstrated in our experiments that the RVM classifier could greatly reduce the computational complexity of the SVM while maintaining its best detection accuracy. In particular, the two-stage RVM approach could reduce the detection time from 250 s for SVM to 7.26 s for a mammogram (nearly 35-fold reduction). Thus, the proposed RVM classifier is more advantageous for real-time processing of MC clusters in mammograms.	algorithm;algorithmic efficiency;computation;computational complexity theory;estimation theory;experiment;machine learning;mammary neoplasms;mammography;mast-cell sarcoma;microcalcification;naive bayes classifier;pixel;real-time clock;receiver operating characteristic;relevance vector machine;sparse matrix;statistical classification;supervised learning;support vector machine;organelle membrane contact site	Liyang Wei;Yongyi Yang;Robert M. Nishikawa;Miles N. Wernick;A. Edwards	2005	IEEE Transactions on Medical Imaging	10.1109/TMI.2005.855435	support vector machine;computer vision;computer science;machine learning;pattern recognition;supervised learning	ML	36.570304871525074	-76.10287280648137	178131
d9b39d43740c378a56d2279d97c512b40d4e5b88	ontology-based automatic reclassication of tissues and organs in histological images		Heterogeneous data source produces different types of data that cannot be treated in the same way. In this paper, two sources of data are considered: image and human knowledge. The former is represented using visual descriptors and the latter is represented using an ontology. The integration of these data sources is used in the automatic classification of tissues and organs of the human cardiovascular system together. Firstly, visual descriptors – texture descriptors – are used in the automatic classification using a cascade Support Vector Machine. Secondly, obtained classification results are refined using a histological ontology of the human cardiovascular system to confirm or reclassified. The final classification results are more precise than the obtained using only image data, in all cases.	support vector machine;visual descriptor	Claudia Mazo;María P. Trujillo;Enrique Alegre;Liliana Salazar	2018			ontology;biological system;biology	ML	33.70390629361047	-72.67528888537947	178255
7d47d4e3e0ee387ea5604e1d56916233e18348aa	development of a reference image collection library for histopathology image processing, analysis and decision support systems research	brain cancer;breast cancer;cancer;computer-aided diagnosis;histology image collection;laryngeal cancer;microscopy	Histopathology image processing, analysis and computer-aided diagnosis have been shown as effective assisting tools towards reliable and intra-/inter-observer invariant decisions in traditional pathology. Especially for cancer patients, decisions need to be as accurate as possible in order to increase the probability of optimal treatment planning. In this study, we propose a new image collection library (HICL–Histology Image Collection Library) comprising 3831 histological images of three different diseases, for fostering research in histopathology image processing, analysis and computer-aided diagnosis. Raw data comprised 93, 116 and 55 cases of brain, breast and laryngeal cancer respectively collected from the archives of the University Hospital of Patras, Greece. The 3831 images were generated from the most representative regions of the pathology, specified by an experienced histopathologist. The HICL Image Collection is free for access under an academic license at http://medisp.bme.teiath.gr/hicl/ . Potential exploitations of the proposed library may span over a board spectrum, such as in image processing to improve visualization, in segmentation for nuclei detection, in decision support systems for second opinion consultations, in statistical analysis for investigation of potential correlations between clinical annotations and imaging findings and, generally, in fostering research on histopathology image processing and analysis. To the best of our knowledge, the HICL constitutes the first attempt towards creation of a reference image collection library in the field of traditional histopathology, publicly and freely available to the scientific community.	carcinoma of larynx;computer assisted diagnosis;consultation;decision support system;histopathology;image processing;imagery;laryngeal prosthesis;neoplasms;patients;raw image format;span distance;archive	Spiros A. Kostopoulos;Panagiota Ravazoula;Pantelis A. Asvestas;Ioannis Kalatzis;George Xenogiannopoulos;Dionisis A. Cavouras;Dimitris Glotsos	2017	Journal of Digital Imaging	10.1007/s10278-017-9947-8	medicine;pathology;computer science;data mining	Visualization	34.22312400194394	-78.12430087781681	178330
0cf8b05ed95cb043c86e4d10862446b5e597c47d	machine printed text and handwriting identification in noisy document images	sensitivity and specificity;image segmentation text recognition text analysis handwriting recognition markov random fields image analysis context modeling solid modeling noise robustness image enhancement;handwriting recognition;document analysis;image segmentation;image processing;machine printed text;computer graphics;text processing;reading;markov random fields;page segmentation;text analysis;classification;noise robustness;markov random field;text identification;signal processing computer assisted;image enhancement;numerical analysis computer assisted;image interpretation computer assisted;stochastic processes;feature extraction;identification;solid modeling;handwriting identification;reproducibility of results;noisy document image enhancement;document image processing;postprocessing;writing;models statistical;artificial intelligence;algorithms;image analysis;pattern recognition automated;technical report;markov processes;subtraction technique;noisy document images;user computer interface;text recognition;page segmentation text identification handwriting identification noisy document images machine printed text recognition techniques fisher classifiers markov random field;context modeling;fisher classifiers;information storage and retrieval;automatic data processing;geometric structure;documentation;algorithms artificial intelligence automatic data processing computer graphics documentation image enhancement image interpretation computer assisted information storage and retrieval models statistical numerical analysis computer assisted pattern recognition automated reading reproducibility of results sensitivity and specificity signal processing computer assisted stochastic processes subtraction technique user computer interface writing;noise;handwriting;markov processes handwriting recognition image segmentation document image processing text analysis image enhancement feature extraction;recognition techniques	In this paper, we address the problem of the identification of text in noisy document images. We are especially focused on segmenting and identifying between handwriting and machine printed text because: 1) Handwriting in a document often indicates corrections, additions, or other supplemental information that should be treated differently from the main content and 2) the segmentation and recognition techniques requested for machine printed and handwritten text are significantly different. A novel aspect of our approach is that we treat noise as a separate class and model noise based on selected features. Trained Fisher classifiers are used to identify machine printed text and handwriting from noise and we further exploit context to refine the classification. A Markov Random Field-based (MRF) approach is used to model the geometrical structure of the printed text, handwriting, and noise to rectify misclassifications. Experimental results show that our approach is robust and can significantly improve page segmentation in noisy document collections.	collections (publication);linear classifier;markov chain;markov random field;noise (electronics);printing;request - action;biologic segmentation	Yefeng Zheng;Huiping Li;David S. Doermann	2003	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2004.1262324	identification;computer vision;image analysis;speech recognition;image processing;feature extraction;documentation;computer science;noise;technical report;machine learning;noisy text analytics;pattern recognition;handwriting recognition;image segmentation;solid modeling;computer graphics;writing;reading	Vision	37.133482649243476	-66.61284578152662	178463
b64c95e18669ba253b6c28228a40f77b46a61216	rearrangement of recognized strokes in online handwritten gurmukhi words recognition	mathematics;words recognition;handwriting recognition;stroke recognition rearrangement;stroke identification online handwritten gurmukhi dictionary word recognition stroke recognition rearrangement;natural language processing handwritten character recognition;online handwritten gurmukhi dictionary word recognition;text analysis;foot;online handwriting recognition;natural languages;computer applications;handwriting recognition character recognition speech recognition data preprocessing mathematics text analysis computer applications dictionaries foot natural languages;stroke identification;hidden markov models;words recognition online handwriting recognition post processing;dictionaries;word recognition;speech recognition;data preprocessing;character recognition;natural language processing;handwritten character recognition;post processing	This paper presents a system to recognize online handwritten Gurmukhi words. We have proposed a new step as rearrangement of recognized strokes in online handwriting recognition procedure. The rearrangement of recognized strokes includes: strokes identification as dependent and major dependent strokes; the rearrangement of strokes with respect to their positions; the combination of strokes to recognize character. We have achieved an overall recognition rate as 81.02% in online handwritten cursive handwriting for a set of 2576 Gurmukhi dictionary words.	dictionary;handwriting recognition	Anuj Sharma;Rajesh Kumar;Rakesh Sharma	2009	2009 10th International Conference on Document Analysis and Recognition	10.1109/ICDAR.2009.36	natural language processing;speech recognition;word recognition;computer science;pattern recognition;data pre-processing;handwriting recognition;natural language;computer applications;video post-processing;foot	Robotics	32.99483478555484	-66.31495908641384	179094
abccd520533b1e04c6eb96326e57851208909a0e	neurologist standard classification of facial nerve paralysis with deep neural networks		Facial nerve paralysis (FNP) is the most common form of facial nerve damage, which leads to significant physical pain and abnormal function in patients. Traditional FNP detection methods are based on visual diagnosis, which relies solely on the physician’s assessment. The use of objective measurements can reduce the frequency of errors which are caused by subjective methods. Hence, a fast, accurate, and objective computer method for FNP classification is proposed that uses a single Convolutional neural network (CNN), trained end-to-end directly from images, with only pixels and disease labels as inputs. We trained the CNN using a dataset of 1049 clinical images and divided the dataset into 7 categories based on classification standards with the help of neurologists. We tested its performance against the neurologists’ ground truth, and our results matched the neurologists’ level with 97.5% accuracy.		Anping Song;Zuoyu Wu;Xuehai Ding;Qian Hu;X H Di	2018	Future Internet	10.3390/fi10110111	facial nerve;paralysis;convolutional neural network;computer network;computer science;artificial neural network;ground truth;contextual image classification;pattern recognition;artificial intelligence	ML	32.32185965349646	-76.57079481261665	179247
db480b3f22244151cfeaa4beedc406a5137d1a4e	mammosys: a content-based image retrieval system using breast density patterns	two dimensional principal component analysis;medical images;computer aided diagnosis;genie biomedical;average precision;medical image databases;breast density;two dimensional principal;biomedical engineering;medical image;system design;principal component analysis;artigo publicado em periodico;component analysis;image retrieval in medical applications;ingenieria biomedica;ground truth;support vector machine;content based image retrieval;dimensional reduction	In this paper, we present a content-based image retrieval system designed to retrieve mammographies from large medical image database. The system is developed based on breast density, according to the four categories defined by the American College of Radiology, and is integrated to the database of the Image Retrieval in Medical Applications (IRMA) project, that provides images with classification ground truth. Two-dimensional principal component analysis is used in breast density texture characterization, in order to effectively represent texture and allow for dimensionality reduction. A support vector machine is used to perform the retrieval process. Average precision rates are in the range from 83% to 97% considering a data set of 5024 images. The results indicate the potential of the system as the first stage of a computer-aided diagnosis framework.	categories;computer assisted diagnosis;content-based image retrieval;dimensionality reduction;ground truth;immunoradiometric assays;information retrieval;irma board;mammography;medical imaging;principal component analysis;radiology;stage level 1;support vector machine	Júlia Epischina Engrácia de Oliveira;Alexei Manso Corrêa Machado;Guillermo Cámara Chávez;Ana Paula Brandão Lopes;Thomas Martin Deserno;Arnaldo de Albuquerque Araújo	2010	Computer methods and programs in biomedicine	10.1016/j.cmpb.2010.01.005	image texture;support vector machine;computer vision;visual word;ground truth;computer science;machine learning;data mining;automatic image annotation;information retrieval;systems design;principal component analysis	Vision	34.719478568720774	-74.61501140466561	179316
4cc9cfc677187dd9b55b0b8db558de41e782cb0e	voxel selection framework in multi-voxel pattern analysis of fmri data for prediction of neural response to visual stimuli	least squares approximations;brain;pattern recognition classification feature selection functional magnetic resonance imaging fmri information theory multi voxel pattern analysis mvpa partial least square pls;image classification;classification;image representation;medical image processing;multi voxel pattern analysis mvpa;cognition;functional magnetic resonance imaging fmri;partial least square pls;pattern recognition;feature selection;regression analysis;brain activity voxel selection framework multivoxel pattern analysis visual stimuli functional magnetic resonance imaging data cognitive states neural activity generalizable classification model mutual information partial least square regression feature selection approach publicly available fmri dataset object level representation benchmark mvpa performance pls functional anatomic relationship;neurophysiology;feature extraction accuracy brain support vector machines educational institutions indexes pattern analysis;regression analysis biomedical mri brain cognition feature selection image classification image representation least squares approximations medical image processing neurophysiology;information theory;biomedical mri	Multi-voxel pattern analysis (MVPA) of functional magnetic resonance imaging (fMRI) data is an emerging approach for probing the neural correlates of cognition. MVPA allows cognitive states to be modeled as distributed patterns of neural activity and classified according to stimulus conditions. In practice, building a robust, generalizable classification model can be challenging because the number of voxels (features) far exceeds the number of stimulus instances/data observations. To avoid model overfitting, there is a need to select informative voxels before building a classification model. In this paper, we propose a robust feature (voxel) selection framework using mutual information (MI) and partial least square regression (PLS) to establish an informativeness index for prioritizing selection of voxels based on the degree of their association to the experimental conditions. We evaluated the robustness of our proposed framework by assessing performance of standard classification algorithms, when combined with our feature selection approach, in a publicly-available fMRI dataset of object-level representation widely used to benchmark MVPA performance (Haxby, 2001). The computational results suggest that our feature selection framework based on MI and PLS drastically improves the classification accuracy relative to those previously reported in the literature. Our results also suggest that highly informative voxels may provide meaningful insight into the functional-anatomic relationship of brain activity and stimulus conditions.	algorithm;benchmark (computing);classification;cluster analysis;cognition;consciousness;electroencephalography;elegant degradation;epilepsies, partial;feature selection;genetic selection;index;lr parser;least-squares analysis;machine learning;magnetic resonance imaging;mutual information;numerous;one thousand;overfitting;papillon-lefevre disease;pattern recognition;region of interest;silo (dataset);the globe and mail;voxel;fmri;statistical cluster	Chun-An Chou;Kittipat Kampa;Sonya H. Mehta;Rosalia F. Tungaraza;W. Art Chaovalitwongse;Thomas J. Grabowski	2014	IEEE Transactions on Medical Imaging	10.1109/TMI.2014.2298856	contextual image classification;cognition;information theory;biological classification;computer science;machine learning;pattern recognition;data mining;feature selection;neurophysiology;regression analysis;statistics	ML	24.905222361432223	-77.94204634909968	179525
c1f2ddcbb08f1fef2addcc038b0adf04c7873627	learning textural concepts through multilevel symbolic transformations	learning systems computerised pattern recognition computerised picture processing knowledge based systems;computerised pattern recognition;presentation;image recognition artificial intelligence data mining image generation humans character recognition labeling testing acoustic noise computer vision;learning systems;computerised picture processing;convolution operator;rule assertions textural image concept learning rule learning computerised pattern recognition knowledge based system textral system symbolic transformations convolutional operators;knowledge based systems;symbolic representation	The TEXTRAL system, used for determining structural visual properties of textures through symbolic transformations, is presented. The method consists of two phases: one that extracts information from raw textural images by applying convolutional operators and learns an initial set of rules; and a second that iteratively extracts symbolic information from the transformed representation of initial image and learns another set of rules. The transformed symbolic representation is obtained by applying previously learned rules to a new image location and generating symbolic images based on rule assertions. >		Jerzy W. Bala;Ryszard S. Michalski	1991		10.1109/TAI.1991.167081	computer vision;computer science;artificial intelligence;knowledge-based systems;machine learning;symbolic data analysis;convolution	EDA	34.703955799073654	-68.51053980927395	180017
3f8957463e7cbd70001560e3ded6d3ed76519ffc	word grouping in document images based on voronoi tessellation	document structure;image numerique;text;diagramme voronoi;analisis datos;estructura documental;structure document;tiling;texte;high precision;data analysis;proximite;proximidad;precision elevee;proximity;imagen numerica;pavage;precision elevada;voronoi tessellation;analyse donnee;digital image;connected component;diagrama voronoi;texto;voronoi diagram	Voronoi tessellation of image elements provides an intuitive and appealing definition of proximity, which has been suggested as an effective tool for the description of relations among the neighboring objects in a digital image. In this paper, a Voronoi tessellation based method is presented for word grouping in document images. The Voronoi neighborhoods are generated from the Voronoi tessellation, with the information about the relations and distances of neighboring connected components, based on which word grouping is carried out. The proposed method has been evaluated on a variety of document images. The experimental results show that it has achieved promising results with a high accuracy, and is robust to various font types, styles, sizes, skew angles, as well as different text orientations.	algorithm;centroidal voronoi tessellation;connected component (graph theory);digital image;voronoi diagram	Yue Lu;Zhe Wang;Chew Lim Tan	2004		10.1007/978-3-540-28640-0_14	voronoi diagram;centroidal voronoi tessellation;theoretical computer science;mathematics;computer graphics (images)	Vision	36.03219585018495	-67.0980485646183	180034
d0bace94f54c4b15b2119ec674582f1a13fd637f	deep learning assessment of tumor proliferation in breast cancer histological images	deep learning	Current analysis of tumor proliferation, the most salient breast cancer prognostic biomarker, is limited to subjective mitosis counting by pathologists in localized regions of tissue images. This study presents the first data-driven integrative approach to characterize the severity of tumor growth and spread on a categorical and molecular level, utilizing multiple biologically salient deep learning classifiers to develop a comprehensive prognostic model. Our approach achieves pathologist-level performance on three-class categorical tumor severity prediction. It additionally pioneers prediction of molecular expression data from a tissue image, obtaining a Spearman's rank correlation coefficient of 0.60 with ex vivo mean calculated RNA expression. Furthermore, our framework is applied to identify over two hundred unprecedented biomarkers critical to the accurate assessment of tumor proliferation, validating our proposed integrative pipeline as the first to holistically and objectively analyze histopathological images.	coefficient;deep learning;holism;video-in video-out	Manan A. Shah;Christopher Rubadue;David Suster;Dayong Wang	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217719	pattern recognition;bioinformatics;artificial intelligence;breast cancer;feature extraction;deep learning;categorical variable;computer science;medical imaging;biomarker (medicine);rank correlation	Visualization	30.99631742738102	-77.07011961005793	180148
084b47539506c70b05de859918d86d2a48e61eb4	automatic computational labeling of glomerular textural boundaries	image segmentation;tissues;proteins;biopsy;blood;capillaries;structural analysis;pathology;kidney;optical microscopes	The glomerulus, a specialized bundle of capillaries, is the blood filtering unit of the kidney. Each human kidney contains about 1 million glomeruli. Structural damages in the glomerular micro-compartments give rise to several renal conditions; most severe of which is proteinuria, where excessive blood proteins flow freely to the urine. The sole way to confirm glomerular structural damage in renal pathology is by examining histopathological or immunofluorescence stained needle biopsies under a light microscope. However, this method is extremely tedious and time consuming, and requires manual scoring on the number and volume of structures. Computational quantification of equivalent features promises to greatly ease this manual burden. The largest obstacle to computational quantification of renal tissue is the ability to recognize complex glomerular textural boundaries automatically. Here we present a computational pipeline to accurately identify glomerular boundaries with high precision and accuracy. The computational pipeline employs an integrated approach composed of Gabor filtering, Gaussian blurring, statistical F-testing, and distance transform, and performs significantly better than standard Gabor based textural segmentation method. Our integrated approach provides mean accuracy/precision of 0.89/0.97 on 200 n = Hematoxylin and Eosin (H&E) glomerulus images, and mean 0.88/0.94 accuracy/precision on 200 n = Periodic Acid Schiff (PAS) glomerulus images. Respective accuracy/precision of the Gabor filter bank based method is 0.83/0.84 for H&E and 0.78/0.8 for PAS. Our method will simplify computational partitioning of glomerular micro-compartments hidden within dense textural boundaries. Automatic quantification of glomeruli will streamline structural analysis in clinic, and can help realize real time diagnoses and interventions.	adobe streamline;almost periodic function;computation;distance transform;filter bank;gabor filter;structural analysis	Brandon Ginley;John E. Tomaszewski;Pinaki Sarder	2017		10.1117/12.2254517	structural analysis;image segmentation	ML	37.937263030312124	-79.24973348800695	180270
26f89745408ca7290e2b0b74700d821282b4cf10	computer-assisted delineation of cerebral infarct from diffusion-weighted mri using gaussian mixture model	dwi;fuzzy contrast enhancement;gaussian mixture model;segmentation;stroke lesion	Diffusion-weighted imaging (DWI) is a widely used medical imaging modality for diagnosis and monitoring of cerebral stroke. The identification of exact location of stroke lesion helps in perceiving its characteristics, an essential part of diagnosis and treatment planning. This task is challenging due to the typical shape of the stroke lesion. This paper proposes an efficient method for computer-aided delineation of stroke lesions from DWI images. Proposed methodology comprises of three steps. At the initial step, image contrast has been improved by applying fuzzy intensifier leading to the better visual quality of the stroke lesion. In the following step, a two-class (stroke lesion area vs. non-stroke lesion area) segmentation technique based on Gaussian mixture model has been designed for the localization of stroke lesion. To eliminate the artifacts which would appear during segmentation process, a binary morphological post-processing through area operator has been defined for exact delineation of the lesion area. The performance of the proposed methodology has been compared with the manually delineated images (ground truth) obtained from different experts, individually. Quantitative evaluation with respect to various performance measures (such as dice coefficient, Jaccard score, and correlation coefficient) shows the efficient performance of the proposed technique.	amendment;ct scan;cerebral infarction;cerebrovascular accident;coherence (physics);declaration (computer programming);diffusion weighted imaging;eko;entity class - imaging modality;experiment;fuzzy logic;google map maker;ground truth;helsinki declaration;image quality;jaccard index;magnetic resonance imaging;medical imaging;mixture model;morphologic artifacts;noise reduction;normal statistical distribution;perception;science;sørensen–dice coefficient;video post-processing;biologic segmentation;standards characteristics	Manas K. Nag;Subhranil Koley;Debarghya China;Anup K. Sadhu;Ravikanth Balaji;Siddharth Ghosh;Chandan Chakraborty	2017	International Journal of Computer Assisted Radiology and Surgery	10.1007/s11548-017-1520-x	radiology;medicine;pathology;surgery	Vision	38.393672314919584	-79.5608526121879	180359
1f37c5542db39b6a5e7c0c2e2b0a77e4ba00a51e	automatic road crack segmentation using entropy and image dynamic thresholding	histograms;image segmentation;image databases;image database;dynamic threshold;roads;crack detection;classification system;entropy;high speed;surface cracks	Human observation is commonly used to collect pavement surface distress data, during periodic road surveys. This method is labour-intensive, subjective and potentially hazardous for both inspectors and road users. This paper presents a novel framework for automatic crack detection and classification using survey images acquired at high driving speeds. The resulting images are pre-processed using morphological filters for reducing pixel intensity variance. Then, a dynamic thresholding is applied to identify dark pixels in images, as these correspond to potential crack pixels. Thresholded images are divided into non-overlapping blocks for entropy computation. A second dynamic thresholding is applied to the resulting entropy blocks matrix, used as the basis for identification of image blocks containing crack pixels. The classification system then labels images as containing horizontal, vertical, miscellaneous or no cracks. Two image databases are used for test purposes, to infer about the method's robustness, one of which acquired using professional high speed equipment.	computation;database;distress (novel);international symposium on fundamentals of computation theory;pixel;sensor;thresholding (image processing);web typography	Henrique Oliveira;Paulo Lobato Correia	2009	2009 17th European Signal Processing Conference		computer vision;geography;pattern recognition;data mining;thresholding	Vision	38.16794420711188	-67.80169428260463	180410
8214f5d8dc87554ad13a72850fd202018a56220c	employing multi-agents to identify touching of adjacent digits in handwritten hindi numerals	image recognition;image segmentation;multi agent system;image segmentation handwritten hindi numerals adjacent digit touching character recognition multi agent system scanned image handwriting thickness thinned image;multi agent systems;success factor;character sets;character recognition;image recognition handwritten character recognition character sets multi agent systems image segmentation;handwritten character recognition;character recognition handwriting recognition writing image segmentation computer science multiagent systems image recognition postal services computer vision mood	The paper addresses an important and vital problem within the general area of character recognition, namely the identification and recognition of touching in handwritten Hindi numerals. The basic idea is that while writing down numbers, it is possible to have adjacent digits touching each other. To handle this, we are developing a multi-agent system. So far, we have two agents, which are presented. The first agent works directly on the scanned image of the original handwritten number. It locates possible touching based on the thickness of handwriting. The other works on the thinned image. It segments the image into four categories of segments and tries to locate possible touching based on the rules that govern the connection of segments to form digits. After each of the two agents applies its own rules and investigates possible touching, and to increase touching recognition rate, the two agents negotiate and try to agree on the actual touching. The experiments carried out so far are promising and successful. The obtained results are very encouraging with a success factor of 92.70%.		Reda Alhajj;Faruk Polat;Ashraf Elnagar	2000		10.1109/ICSMC.2000.884408	computer vision;speech recognition;document processing;character encoding;intelligent character recognition;computer science;artificial intelligence;intelligent word recognition;multi-agent system;image segmentation	ML	34.71857743735845	-66.71774196020591	180636
d201c605ff337f4d9d0a8ba5c52cc28e19c423b3	detection and classification of explosive substances in multi-spectral image sequences using linear subspace matching	multi spectral imaging explosives detection raman spectroscopy;demonstrator system explosive substance detection explosive substance classification multispectral image sequences linear subspace matching dangerous substance detection security applications imaging raman spectroscopy multispectral imaging technique stand off screening real stand off measurements;image matching;imaging shape explosives raman scattering noise accuracy feature extraction;explosive detection;image classification;raman spectroscopy;image registration;spectral analysis;security;spectral analysis explosive detection image classification image matching image registration image sequences raman spectroscopy security;image sequences	Fast detection and analysis of dangerous substances from longer distances is highly desired in many security applications. Imaging Raman spectroscopy is a novel multi-spectral imaging technique designed for stand-off screening and detection of explosive substances. In this paper we present a method for detection and classification of explosive substances in multi-spectral image sequences from imaging Raman spectroscopy using linear subspace matching. Our approach uses limited spectral information and is computationally efficient, which enables fast screening of interesting areas. The performance of the method is evaluated on real stand-off measurements from a demonstrator system. We show that the method can detect and classify substances with high accuracy.	algorithmic efficiency;multispectral image;raman scattering	Maria Axelsson;Ola Friman;Ida Johansson;Markus Nordberg;Henric Östmark	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6638307	computer vision;contextual image classification;raman spectroscopy;computer science;image registration;information security	Vision	38.215175028837145	-70.16777068983438	180955
07cc48e8aae17bc77a2c4799e72b9f83570814de	detection of courtesy amount block on bank checks	image recognition;deterministic automata;handwriting recognition;image segmentation;handprinted courtesy amount;image processing;neural nets cheque processing bank data processing image segmentation document image processing character recognition handwriting recognition deterministic automata finite automata;neural nets;deterministic finite automaton;optical character recognition;neural network based recognition;text analysis;bank data processing;cheque processing;technology management;segmenting;optical character recognition software;courtesy amount block;recognition;finite automata;pattern recognition;document image processing;optical character recognition software image recognition image segmentation image processing pattern recognition text analysis text recognition technology management educational institutions computer science;currency sign;computer science;text recognition;handprinted courtesy amount courtesy amount block bank checks recognition currency sign deterministic finite automaton neural network based recognition segmenting;connected component;working paper;character recognition;bank checks;neural network	This paper presents a multi-staged technique for locating the courtesy £iinount block on bank checks. In the case of a check processing system, mfiny of the proposed methods are not acceptable, due to the the presence of mainy fonts and text sizes, eis well as the short length of many text strings. This paper will describe pzirticular methods chosen to implement a Courtesy Amount Block Locator (CABL). First, the connected components in the image are identified. Next, strings are constructed on the basis of proximity and horizontal alignment of characters. Finally a set of rules and heuristics are applied to these strings to choose the correct one. The chosen string is only reported if it passes a verification test, which includes an attempt to recognize the currency sign.	connected component (graph theory);heuristic (computer science);online locator service	Arun Agarwal;Len Granowetter;Karim Hussein;Amar Gupta;Patrick Shen-Pei Wang	1995		10.1109/ICDAR.1995.602011	computer vision;speech recognition;connected component;computer science;deterministic finite automaton;machine learning;pattern recognition;image segmentation;optical character recognition;artificial neural network;market segmentation	PL	34.30692986639835	-66.55772749076044	181297
1b3b28ebddfb25c3db7ce90a92414a69c8a36cb9	breast tissue classification using local binary pattern variants: a comparative study		Mammographic tissue density is considered to be one of the major risk factors for developing breast cancer. In this paper we use quantitative measurements of Local Binary Patterns and its variants for breast tissue classification. We compare the classification results of LBP, ELBP, Uniform ELBP and M-ELBP for classifying mammograms as fatty, glandular and dense. A Bayesian-Network classifier is used with stratified ten-fold cross-validation. The experimental results indicate that ELBP patterns at different orientations extract more relevant elliptical breast tissue information from the mammograms indicating the importance of directional filters for breast tissue classification.		Minu George;Reyer Zwiggelaar	2018		10.1007/978-3-319-95921-4_15	breast cancer;local binary patterns;mathematics;pattern recognition;artificial intelligence	ML	34.29077603025742	-75.47935600119763	181473
b6ad542e85c8f1f4e8f6c03d1d68ecb1780d8811	learning from a handful volumes: mri resolution enhancement with volumetric super-resolution forests		Magnetic resonance imaging (MRI) enables 3-D imaging of anatomical structures. However, the acquisition of MR volumes with high spatial resolution leads to long scan times. To this end, we propose volumetric super-resolution forests (VSRF) to enhance MRI resolution retrospectively. Our method learns a locally linear mapping between low-resolution and high-resolution volumetric image patches by employing random forest regression. We customize features suitable for volumetric MRI to train the random forest and propose a median tree ensemble for robust regression. VSRF out-performs state-of-the-art example-based super-resolution in terms of image quality and efficiency for model training and inference on different MRI datasets. It is also superior to unsupervised methods with just a handful or even a single volume to assemble training data.		Aline Sindel;Katharina Breininger;Johannes Käßer;Andreas Hess;Andreas K. Maier;Thomas Köhler	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451320	robust regression;computer vision;artificial intelligence;pattern recognition;image quality;computer science;random forest;superresolution;magnetic resonance imaging;image resolution;training set	Vision	29.954970880102533	-75.52094587105124	181703
6a79b1262e59be3256338ce342cc2feced400f69	medical image classification based on artificial intelligence approaches: a practical study on normal and abnormal confocal corneal images	image classification;texture features;confocal microscopy;cornea;adaptive neuro fuzzy inference system;artificial neural network	A new intelligent system to tackle the main challenges of confocal corneal imaging is developed.This system underpins the expertise of ophthalmologists.It provides clinically useful factors, saves a useful amount of clinician time in the process.It is able to model the stromal keratocyte cells for better evaluation and fast analysis.Early approval by corneal clinicians. Corneal images can be acquired using confocal microscopes which provide detailed views of the different layers inside a human cornea. Some corneal problems and diseases can occur in one or more of the main corneal layers: the epithelium, stroma and endothelium. Consequently, for automatically extracting clinical information associated with corneal diseases, identifying abnormality or evaluating the normal cornea, it is important to be able to automatically recognise these layers reliably. Artificial intelligence (AI) approaches can provide improved accuracy over the conventional processing techniques and save a useful amount of time over the manual analysis time required by clinical experts. Artificial neural networks (ANNs), adaptive neuro fuzzy inference systems (ANFIS) and a committee machine (CM) have been investigated and tested to improve the recognition accuracy of the main corneal layers and identify abnormality in these layers. The performance of the CM, formed from ANN and ANFIS, achieves an accuracy of 100% for some classes in the processed data sets. Three normal corneal data sets and seven abnormal corneal images associated with diseases in the main corneal layers have been investigated with the proposed system. Statistical analysis for these data sets is performed to track any change in the processed images. This system is able to pre-process (quality enhancement, noise removal), classify corneal images, identify abnormalities in the analysed data sets and visualise corneal stroma images as well as each individual keratocyte cell in a 3D volume for further clinical analysis.	artificial intelligence;computer vision	Mhd Saeed Sharif;Rami Qahwaji;Stanley S. Ipson;Arun Brahma	2015	Appl. Soft Comput.	10.1016/j.asoc.2015.07.019	computer vision;contextual image classification;adaptive neuro fuzzy inference system;computer science;artificial intelligence;confocal laser scanning microscopy;machine learning;artificial neural network	AI	33.63221439897092	-76.46995987159622	181710
6501c9b2b3c9714247a026c87ed826ec6d554d4f	hierarchical probabilistic gabor and mrf segmentation of brain tumours in mri volumes		In this paper, we present a fully automated hierarchical probabilistic framework for segmenting brain tumours from multispectral human brain magnetic resonance images (MRIs) using multiwindow Gabor filters and an adapted Markov Random Field (MRF) framework. In the first stage, a customised Gabor decomposition is developed, based on the combined-space characteristics of the two classes (tumour and non-tumour) in multispectral brain MRIs in order to optimally separate tumour (including edema) from healthy brain tissues. A Bayesian framework then provides a coarse probabilistic texture-based segmentation of tumours (including edema) whose boundaries are then refined at the voxel level through a modified MRF framework that carefully separates the edema from the main tumour. This customised MRF is not only built on the voxel intensities and class labels as in traditional MRFs, but also models the intensity differences between neighbouring voxels in the likelihood model, along with employing a prior based on local tissue class transition probabilities. The second inference stage is shown to resolve local inhomogeneities and impose a smoothing constraint, while also maintaining the appropriate boundaries as supported by the local intensity difference observations. The method was trained and tested on the publicly available MICCAI 2012 Brain Tumour Segmentation Challenge (BRATS) Database [1] on both synthetic and clinical volumes (low grade and high grade tumours). Our method performs well compared to state-of-the-art techniques, outperforming the results of the top methods in cases of clinical high grade and low grade tumour core segmentation by 40% and 45% respectively.		Nagesh K. Subbanna;Doina Precup;D. Louis Collins;Tal Arbel	2013	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-40811-3_94	artificial intelligence;computer vision;markov random field;voxel;computer science;pattern recognition;mixture model;probabilistic logic;smoothing;segmentation	Vision	31.804199016531705	-77.54497359139181	181837
bac96aba9300d0d4328c14623d4b418b852298b5	invasive cancer detection utilizing compressed convolutional neural network and transfer learning		Identification of invasive cancer in Whole Slide Images (WSIs) is crucial for tumor staging as well as treatment planning. However, the precise manual delineation of tumor regions is challenging, tedious and time-consuming. Thus, automatic invasive cancer detection in WSIs is of significant importance. Recently, Convolutional Neural Network (CNN) based approaches advanced invasive cancer detection. However, computation burdens of these approaches become barriers in clinical applications. In this work, we propose to detect invasive cancer employing a lightweight network in a fully convolution fashion without model ensembles. In order to improve the small network’s detection accuracy, we utilized the “soft labels” of a large capacity network to supervise its training process. Additionally, we adopt a teacher guided loss to help the small network better learn from the intermediate layers of the high capacity network. With this suite of approaches, our network is extremely efficient as well as accurate. The proposed method is validated on two large scale WSI datasets. Our approach is performed in an average time of 0.6 and 3.6 min per WSI with a single GPU on our gastric cancer dataset and CAMELYON16, respectively, about 5 times faster than Google Inception V3. We achieved an average FROC of (81.1%) and (85.6%) respectively, which are on par with Google Inception V3. The proposed method requires less high performance computing resources than state-of-the-art methods, which makes the invasive cancer diagnosis more applicable in the clinical usage.	convolutional neural network	Bin Kong;Shanhui Sun;Xin Wang;Qi Song;Shaoting Zhang	2018		10.1007/978-3-030-00934-2_18	convolutional neural network;computer science;transfer of learning;pattern recognition;tumor staging;computation;machine learning;cancer;convolution;suite;supercomputer;artificial intelligence	NLP	29.467627543224168	-74.45380576677464	182031
2a1fe2c94fbacb97f24913cf5cfb9740e58f4bf8	mining faces from biomedical literature using deep learning		Gaining access to large, labelled sets of relevant images is crucial for the development and testing of biomedical imaging algorithms. Using images found in biomedical research articles would contribute some way towards a solution to this problem. However, this approach critically depends on being able to identify the most relevant images from very large sets of potentially useful figures. In this paper a deep convolutional neural network (CNN) classifier is trained using only synthetic data, to rapidly and accurately label raw images taken from biomedical articles. We apply this method in the context of detecting faces in biomedical images; and show that the classifier is able to retrieve figures containing faces with an average precision of 94.8%, from a dataset of over 31,000 images taken from articles held in the PubMed database. The utility of the classifier is then demonstrated through a case study, by aiding the mining of photographs of patients with rare genetic disorders from targeted articles. This approach is readily adaptable to facilitate the retrieval of other categories of biomedical images.	algorithm;artificial neural network;convolutional neural network;deep learning;information retrieval;medical imaging;precision and recall;pubmed;radiography;sensor;synthetic data;synthetic intelligence;web search engine	Mitchell Dawson;Andrew Zisserman;Christoffer Nellåker	2017		10.1145/3107411.3107476	machine learning;convolutional neural network;bioinformatics;deep learning;contextual image classification;classifier (linguistics);synthetic data;medical imaging;computer science;artificial intelligence;pattern recognition	Vision	32.312032308081264	-73.87904328951495	182584
dabbe2b9310c03999668ee6dbffb9d710fb3a621	accurate pulmonary nodule detection in computed tomography images using deep convolutional neural networks		Early detection of pulmonary cancer is the most promising way to enhance a patient’s chance for survival. Accurate pulmonary nodule detection in computed tomography (CT) images is a crucial step in diagnosing pulmonary cancer. In this paper, inspired by the successful use of deep convolutional neural networks (DCNNs) in natural image recognition, we propose a novel pulmonary nodule detection approach based on DCNNs. We first introduce a deconvolutional structure to Faster Region-based Convolutional Neural Network (Faster R-CNN) for candidate detection on axial slices. Then, a three-dimensional DCNN is presented for the subsequent false positive reduction. Experimental results of the LUng Nodule Analysis 2016 (LUNA16) Challenge demonstrate the superior detection performance of the proposed approach on nodule detection (average FROC-score of 0.893, ranking the 1st place over all submitted results), which outperforms the best result on the leaderboard of the LUNA16 Challenge (average FROC-score of 0.864).	artificial neural network;ct scan;computer vision;computer-aided design;convolution;convolutional neural network;tomography	Jia Ding;Aoxue Li;Zhiqiang Hu;Liwei Wang	2017		10.1007/978-3-319-66179-7_64	pattern recognition;computed tomography;computer science;convolutional neural network;artificial intelligence;computer vision	AI	32.62110642031982	-75.56354212119699	182703
6aa3a8b80aa9e45a3843379ba4b2e95e31025af7	classification of melanoma using tree structured wavelet transforms	skin lesion;semantic representation;genie biomedical;melanoma;wavelet transform;biomedical engineering;tree structured wavelet transform;tree structure;model development;ingenieria biomedica;dysplastic nevus;nevoscope;spatial frequency	This paper presents a wavelet transform based tree structure model developed and evaluated for the classification of skin lesion images into melanoma and dysplastic nevus. The tree structure model utilizes a semantic representation of the spatial-frequency information contained in the skin lesion images including textural information. Results show that the presented method is effective in discriminating melanoma from dysplastic nevus. The results are also compared with those obtained using another method of developing tree structures utilizing the maximum channel energy criteria with a fixed energy ratio threshold.	contain (action);data collection;dysplastic nevus;early diagnosis;patients;tree structure;wavelet transform;abnormal cellular structure or growth;melanoma	Sachin V. Patwardhan;Atam P. Dhawan;Patricia A. Relue	2003	Computer methods and programs in biomedicine	10.1016/S0169-2607(02)00147-5	computer vision;speech recognition;pathology;mathematics;spatial frequency;tree structure;wavelet transform	Robotics	35.746970752792095	-75.62033337394067	182867
2ee9f595b96349233cd4cdf62841573f20063504	development of an interface for detection of slices with ground-glass opacity nodule by using the nearest neighbor algorithm		Calculating features of the GGO nodule can help to detect the benign or malignant of lung tumors, but it took a lot of time for radiologists to acquire all slices including the GGO nodules in CT volume data. This paper proposed the nearest neighbor algorithm without any parameters and developed an interface to assist the radiologist to detect all the GGO slices in the CT volume data. An interface to assist the radiologist to find slices including a GGO nodule was designed as follows. First, the region of interest (ROI) was obtained as preprocesses of the interface preprocesses from the original CT. Secondly, a slice including the GGO nodule was designated by a radiologist. The designated slice was called the labeled datum. Finally, all slices including the GGO nodules were detected based on the nearest neighbor algorithm and the labeled datum. Thus, the radiologist can quickly find all slices including GGO nodules in CT volume data without drawing the GGO nodules of all slices manually. The proposal is compared with detection of all slices containing GGO nodules manually. The experimental result showed that the proposal was quicker to find all slices including GGO nodules than the manual method.	geodetic datum;k-nearest neighbors algorithm;radiology;region of interest	Dandan Yuan;Weiwei Du;Jianming Wang;Xiaojie Duan;Yanhe Ma;Hong Zhang	2017	2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)	10.1109/CISP-BMEI.2017.8302300	artificial intelligence;ground-glass opacity;computer vision;region of interest;pattern recognition;feature extraction;computed tomography;computer science;k-nearest neighbors algorithm	Visualization	35.900497622880536	-77.71200877165671	182960
bdc784b77b6490e65097c1eeca2026ba4dceae7f	apple color grading based on organization feature parameters	vision system;ccd camera;appareillage essai;vision ordenador;decision tree;methode essai;image processing;learning;systeme vision;chine;maquina vector soporte;procesamiento imagen;arbol decision;algoritmo genetico;traitement image;computer vision;aprendizaje;tree algorithm;machine vecteur support;apprentissage;asie;quality evaluation;machine vision;aparato ensayo;signal classification;algorithme genetique;controle qualite;testing equipment;classification signal;algorithme en arbre;camara ccd;camera ccd;genetic algorithm;apple;vision ordinateur;vision artificielle;algoritmo del arbol;organization feature parameter;support vector machine;test method;reseau neuronal;china;quality control;artificial vision;arbre decision;red neuronal;sistema vision;control calidad;asia;neural network;vision artificial;metodo ensayo	This paper presents a system for apple color grading into four classes according to standards stipulated in China. To automatically grade apple fruit color, a laboratory machine vision system was developed, which consisted of a color CCD camera equipped with an image grab device, a bi-cone roller device controlled by a stepping motor, and a lighting source. Four images, one for every rotation of 90^o, were taken from each apple. Seventeen color feature parameters (FP) were extracted from each apple in the image processing. Three hundred and eighteen ''Fuji'' apples were examined by the system, and were divided into two sets, with 200 in ''Training set'' and 118 in ''Test set''. A method called organization feature parameter (OFP), based on formulae expression trees by using genetic algorithms (GA), was used in this paper. When the initial FP could not sensitively distinguish among different classes of apples, the FP were organized into one new OFP by using genetic algorithm. By applying the step decision tree algorithm in combination with the OFP method, high grade judgment ratios were achieved in the classification of two of four apple color grades, i.e., 'Extra', and 'Reject'. However, the grade judgment ratio for 'class I' and 'class II' was relatively low. Compared with BP-ANN and SVM, the OFPs method was more accurate than BP-ANN, but a little lower than SVM for identification results.		Xiaobo Zou;Jiewen Zhao;Yanxiao Li	2007	Pattern Recognition Letters	10.1016/j.patrec.2007.06.001	support vector machine;computer vision;quality control;genetic algorithm;machine vision;computer science;artificial intelligence;machine learning;decision tree;chine;test method;china	Vision	33.661162545076046	-67.7569250443541	183017
e5371b1a6c9a92a6053fe6a835554f3590a991c9	neural network based ocr for keg identification	neural networks;ocr;keg tracking	A keg asset management system that can reduce the annual rate of keg attrition by 5% to 20% can deliver significant savings to breweries with large fleets of kegs. A typically large brewery can have at least tens of thousands of kegs, a sizable investment given an initial cost of around USD100 per keg. A key element in a keg tracking system is on-line keg identification. This research explores the feasibility of an intelligent machine vision approach to identifying the unique serial number embossed on the dome of each keg at manufacture. The demonstration system developed auto-locates candidate serial numbers and applies optical character recognition (OCR) techniques. The neural network based OCR achieved the best performance over template matching achieving an overall recognition rate of 92% and no missed digits. If non-permanent serial number occlusions can be removed by caustic washing prior to the image capture stage in a production line implementation, the recognition rate approaches 97%.	artificial intelligence;artificial neural network;attrition (website);machine vision;online and offline;optical character recognition;template matching;tracking system	A. Keir;Michael J. Lees;Duncan A. Campbell	2006			speech recognition;engineering;artificial intelligence;engineering drawing	AI	29.03787090421563	-68.63523344004199	183053
365a5ff4e3ab7b7af198fc0e0e1d456b3677e41c	a novel online variance based instance selection (vbis) method for efficient atypicality detection in chest radiographs	tissues;computer aided diagnosis;instance selection;chest x rays;anomaly detection;atypicality detection;machine learning;nearest neighbor;radiology training;chest	Chest radiographs are complex, heterogeneous medical images that depict many different types of tissues, and many different types of abnormalities. A radiologist develops a sense of what visual textures are typical for each anatomic region within chest radiographs by viewing a large set of “normal” radiographs over a period of years. As a result, an expert radiologist is able to readily detect atypical features. In our previous research, we modeled this type of learning by (1) collecting a large set of “normal” chest radiographs, (2) extracting local textural and contour features from anatomical regions within these radiographs, in the form of high-dimensional feature vectors, (3) using a distance-based transductive machine learning method to learn what it typical for each anatomical region, and (4) computing atypicality scores for the anatomical regions in test radiographs. That research demonstrated that the transductive One-NearestNeighbor (1NN) method was effective for identifying atypical regions in chest radiographs. However, the large set of training instances (and the need to compute a distance to each of these instances in a high dimensional space) made the transductive method computationally expensive. This paper discusses a novel online Variance Based Instance Selection (VBIS) method for use with the Nearest Neighbor classifier, that (1) substantially reduced the computational cost of the transductive 1NN method, while maintaining a high level of effectiveness in identifying regions of chest radiographs with atypical content, and (2) allowed the incremental incorporation of training data from new informative chest radiographs as they are encountered in day-to-day clinical work.	algorithmic efficiency;analysis of algorithms;computation;high-level programming language;information;machine learning;nearest neighbour algorithm;radiography;radiology	Mohammad Alzubaidi;Vineeth N. Balasubramanian;Ameet Patel;Sethuraman Panchanathan;John A. Black	2012		10.1117/12.911154	computer vision;anomaly detection;machine learning;pattern recognition;k-nearest neighbors algorithm	ML	32.367350515654365	-77.21462025895079	183167
b8feae8a7060dd1e664f487e0c284f651ef056dd	brain tumor segmentation using genetic algorithm and artificial neural network fuzzy inference system (anfis)		Medical image segmentation plays an important role in treatment planning, identifying tumors, tumor volume, patient follow up and computer guided surgery. There are various techniques for medical image segmentation. This paper presents a image segmentation technique for locating brain tumor(AstrocytomaA type of brain tumor).Proposed work has been divided in two phases-In the first phase MRI image database(Astrocytoma grade I to IV) is collected and then preprocessing is done to improve quality of image. Second-phase includes three steps-Feature extraction, Feature selection and Image segmentation. For feature extraction proposed work uses GLCM (Grey Level co-occurrence matrix).To improve accuracy only a subset of feature is selected using hybrid Genetic algorithm(Genetic Algorithm+fuzzy rough set) and based on these features fuzzy rules and membership functions are defined for segmenting brain tumor from MRI images of .ANFIS is a adaptive network which combines benefits of both fuzzy and neural network .Finally, a comparative analysis is performed between ANFIS, neural network, Fuzzy ,FCM,K-NN, DWT+SOM,DWT+PCA+KN, Texture combined +ANN, Texture Combined+ SVM in terms of sensitivity ,specificity ,accuracy.	adaptive neuro fuzzy inference system;artificial neural network;genetic algorithm;inference engine	Minakshi Sharma;Sourabh Mukharjee	2012		10.1007/978-3-642-31552-7_35	computer vision;computer science;machine learning;pattern recognition;image segmentation;scale-space segmentation	AI	34.80057029929085	-74.93107609049585	183453
1e49b083f15a035e68a12e39f00cab71777dde33	automatic assessment of cardiac artery disease by using dcad module	stress;software;myocardium;spect image processing image skeleton cardiac artery disease;image skeleton;pattern clustering;quantitative myocardial spect perfusion;image segmentation;image processing;arteries cardiac disease cardiovascular diseases myocardium clustering methods skeleton fuzzy logic muscles stress coronary arteriosclerosis;automatic assessment;defect diagnosis automatic cardiac artery disease assessment dcad module cardiac artery disease patients myocardial perfusion scan noninvasive method quantitative myocardial spect perfusion left ventricle segmentation fuzzy clustering myocardial skeleton fuzzy logic myocardial muscle perfusion perturbation coronary artery disease diagnosis artery obstruction diagnosis coronary angiography coronary artery occlusion diagnosis nuclear medicine;angiocardiography;arteries;coronary angiography;left ventricle segmentation;cardiac artery disease patients;spect;artery obstruction diagnosis;fuzzy set theory;left ventricle;skeleton;defect diagnosis;fuzzy logic;fuzzy clustering;coronary artery disease;coronary artery occlusion diagnosis;noninvasive method;coronary artery disease diagnosis;medical image processing;perfusion perturbation;pixel;dcad module;single photon emission computed tomography;myocardial perfusion scan;cardiac artery disease;diseases;myocardial perfusion;short axis;cross section;nuclear medicine;myocardial skeleton;radioisotope imaging;coronary artery;myocardial muscle;single photon emission computed tomography angiocardiography blood vessels diseases fuzzy logic fuzzy set theory image segmentation medical image processing muscle pattern clustering radioisotope imaging;blood vessels;automatic cardiac artery disease assessment;muscle	In patients with cardiac artery disease myocardial perfusion scan, which is a non-invasive method, is utilized. This study is conducted to achieve an advantageous software applicable to quantitative myocardial SPECT perfusion. Each cross-section of the left ventricle is segmented by applying fuzzy clustering method. After obtaining the myocardial skeleton of the left ventricle from its short axis cross sections, we make use of fuzzy logic to decide whether the pixel belongs to myocardial muscle and any perfusion perturbation or not. Abnormal critical conditions in rest and stress studies and coronary artery disease diagnosis were investigated in a set of about 200 images. Measurement and allocation of different myocardial sectors to specific coronary arteries were accomplished by utilizing collected information about respectively 75 patient men and 62 patient women, and the validity of artery obstruction diagnosis has been proved in 40 patients having been under the coronary angiography. We named the achieved software DCAD(b) which has demonstrated a considerably good performance in coronary artery occlusion diagnosis and would be a promising method aiding nuclear medicine specialists in diagnosing these defections.	apache axis;cluster analysis;fuzzy clustering;fuzzy logic;pixel;robertson–seymour theorem	Vahid Khalilzad-Sharghi;Alireza Talebpour;Alireza Kamali-Asl;Nastaran Hendijani	2008	2008 10th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing	10.1109/SYNASC.2008.57	fuzzy logic;muscle;fuzzy clustering;image processing;computer science;machine learning;cross section;fuzzy set;image segmentation;stress;skeleton;pixel	AI	38.29828295021276	-78.26012289392179	183522
f41f99f13bcbc0939eb5a8c405f3e731947cc60c	noise resistance analysis of wavelet-based channel energy feature for breast lesion classification on ultrasound images	performance evaluation;breast lesion classification;clinical application;the noise resistance analysis system;ultrasound imaging;imagej;wavelet based channel energy;detection algorithm;genetic algorithm;probabilistic neural network	Wavelet-based channel energy with low cost and high efficacy is a valuable feature for the differential diagnoses between benign and malignant breast lesions. The new feature is a contour approach that generally suffers from lacking a reliable contour detection algorithm with convincing results due to extreme noise. For investigating a procedure suitable for clinical application, noise resistance capability of the new feature is evaluated in this study. The evaluation system consists of two snake-based contour detection algorithms associated with two pre-processes. These combinations can produce four test datasets of contour sonogram. Classification performance evaluation is based on a probabilistic neural network and a genetic algorithm used for distribution parameter determination.	wavelet	Yueh-Ching Liao;Shu-Mei Guo;King-Chu Hung;Po-Chin Wang;Tsung-Lung Yang	2010		10.1007/978-3-642-15696-0_51	computer vision;probabilistic neural network;genetic algorithm;computer science;machine learning;pattern recognition	Vision	34.919348187777125	-75.47497543483435	183525
706120acc55f99709474b7830268d44ddcc147d3	automating image segmentation verification and validation by learning test oracles	3d segmentation;image segmentation;image processing;ct scan;left ventricle;real world application;machine learning;verification and validation;similarity measure;test oracle	An image segmentation algorithm delineates (an) object(s) of interest in an image. Its output is referred to as a segmentation. Developing these algorithms is a manual, iterative process involving repetitive verification and validation tasks. This process is time-consuming and depends on the availability of experts, who may be a scarce resource (e.g., medical experts). We propose a framework referred to as Image Segmentation Automated Oracle (ISAO) that uses machine learning to construct an oracle, which can then be used to automatically verify the correctness of image segmentations, thus saving substantial resources and making the image segmentation verification and validation task significantly more efficient. The framework also gives informative feedback to the developer as the segmentation algorithm evolves and provides a systematic means of testing different parametric configurations of the algorithm. During the initial learning phase, segmentations from the first few (optimally two) versions of the segmentation algorithm are manually verified by experts. The similarity of successive segmentations of the same images is also measured in various ways. This information is then fed to a machine learning algorithm to construct a classifier that distinguishes between consistent and inconsistent segmentation pairs (as determined by an expert) based on the values of the similarity measures associated with each segmentation pair. Once the accuracy of the classifier is deemed satisfactory to support a consistency determination, the classifier is then used to determine whether the segmentations that are produced by subsequent versions of the algorithm under test, are (in)consistent with already verified segmentations from previous versions. This information is then used to automatically draw conclusions about the correctness of the segmentations. We have successfully applied this approach to 3D segmentations of the cardiac left ventricle obtained from CT scans and have obtained promising results (accuracies of 95%). Even though more experiments are needed to quantify the effectiveness of the approach in real-world applications, ISAO shows promise in increasing the quality and testing efficiency of image segmentation	algorithm;benchmark (computing);c4.5 algorithm;ct scan;converge;correctness (computer science);decision tree;experiment;formal verification;image processing;image segmentation;information;inpainting;interpreter (computing);iteration;iterative and incremental development;iterative method;machine learning;medical imaging;oracle (software testing);receiver operating characteristic;verification and validation	Kambiz Frounchi;Lionel C. Briand;Leo Grady;Yvan Labiche;Rajesh Subramanyan	2011	Information & Software Technology	10.1016/j.infsof.2011.06.009	oracle;computer vision;verification and validation;image processing;computer science;segmentation-based object categorization;pattern recognition;data mining;database;image segmentation;scale-space segmentation	Vision	37.54411090877279	-80.13540958528205	183769
7c882a4c8a8f48ce207293c82ac798ae9bebeb94	multiple tbsvm-rfe for the detection of architectural distortion in mammographic images		Breast cancer is a leading health threaten for women in the world. Among the several abnormalities observable on mammograms, architecture distortion is one of the most difficult to detect due to its subtlety. Computer-Aided Diagnosis (CAD) technology has been widely used for the detection and diagnosis of breast cancer. In this paper, a new automatic architectural distortion detection method for breast cancer in mammographic images is proposed. Firstly, Gabor filters and phase portrait analysis are used to locate the suspicious regions based on the image characteristic of architectural distortion. Twin bounded Support Vector Machine (TBSVM) is employed to reduce the large amounts of false positives. TBSVM is a kind of binary classifier, which has advantages in both computation efficiency and generalization when dealing with binary classification. For each suspicious region, several features are extracted. However, not every extracted feature contributes to the classification accuracy. We proposed a novel feature selection method for TBSVM and utilized it for the architectural distortion detection in mammograms, named Multiple Twin Bound Support Vector Machines Recursive Feature Elimination (MTBSVM-RFE). The results showed that our proposed method detect the region of architecture distortion with high accuracy.	binary classification;computation;computer-aided design;distortion;feature selection;gabor filter;observable;recursion (computer science);support vector machine	Xiaoming Liu;Leilei Zhai;Ting Zhu;Jun O Liu;Kai Zhang;Wei Hu	2017	Multimedia Tools and Applications	10.1007/s11042-017-5150-7	computer science;artificial intelligence;support vector machine;computer vision;feature selection;cad;recursion;distortion;pattern recognition;binary classification;architectural distortion;false positive paradox	AI	33.67329851238291	-74.77541024621654	183813
b2804c276b1b636851837224a01c3fae918b87d5	a region segmentation method on 2-d vessel optical coherence tomography images	optical tomography cancer fuzzy set theory image resolution image segmentation medical image processing;fuzzy c mean;fractals;image segmentation;cancer;oct;vessel;texture segmentation;optical coherence tomography;vessel optical coherence tomography oct texture segmentation fuzzy c mean;image edge detection;image color analysis;proceedings paper;clustering algorithms;cancer diagnosis region segmentation method 2d vessel optical coherence tomography images threshold process layer analysis region analysis speckle effect canny edge otsu methods mean value enhanced fuzzy c mean algorithm low resolution vessel oct high resolution oral cancer oct images overcomplete wavelet frame based fractal signature method;fractals image edge detection image segmentation image color analysis cancer noise clustering algorithms;noise	This paper describes a novel region segmentation method designed to avoid complications of the threshold process used in traditional segmentation methods in 2-D optical coherence tomography (OCT) images. Analysis of the layers and regions in OCT images is used to diagnose the presence of cancer and identify the stage of the cancer if present. However, scattering during OCT images generates a speckle effect and creates diffusion problems which are also captured; these problems cause traditional image processing methods such as the Canny edge and Otsu methods to fail in finding the proper layer and region edges. The proposed method uses the mean value and an enhanced-fuzzy-c-mean algorithm to cluster pixels in 2-D OCT images and find the edge between different clustered regions. Low-resolution vessel OCT and high-resolution oral cancer OCT images are tested in the experiment, and the experimental results show that the proposed method performs with more robust and accurate segmentation results than does the overcomplete-wavelet-frame-based fractal signature method.	algorithm;ct scan;canny edge detector;fractal;image processing;image resolution;otsu's method;pixel;tomography;wavelet	Li-Chang Liu;Jiann-Der Lee;Yu-Wei Hsu;Carol T. Liu;Ellen Tseng;Meng-Tsan Tsai	2013	2013 10th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2013.6816218	computer vision;fractal;computer science;noise;machine learning;mathematics;image segmentation;cluster analysis;cancer;computer graphics (images)	Robotics	38.99644931985289	-75.302343569902	184385
17df66bbd1474c82759af68ff009c5c00f00cae7	modeling cognitive trends in preclinical alzheimer's disease (ad) via distributions over permutations		This paper presents an algorithm to identify subsets of subjects who share similarities in the context of imaging and clinical measurements within a cohort of cognitively healthy individuals at risk for Alzheimer’s disease (AD). In particular, we wish to evaluate how patterns in the subjects’ cognitive scores or PIB-PET image measurements are associated with a clinical assessment of risk of developing AD, image based measures, and future cognitive decline. The challenge here is that all the participants are asymptomatic, our predictors are noisy and heterogeneous, and the disease specific signal, when present, is weak. As a result, off-the-shelf methods do not work well. We develop a model that uses a probability distribution over the set of permutations to represent the data; this yields a distance measure robust to these issues. We then show that our algorithm produces consistent and meaningful groupings of subjects based on their cognitive scores and that it provides a novel and interesting representation of measurements from PIB-PET images.		Gregory Plumb;Lindsay Clark;Sterling C. Johnson;Vikas Singh	2017		10.1007/978-3-319-66179-7_78	permutation;artificial intelligence;pattern recognition;computer science;asymptomatic;probability distribution;cohort;disease;cognition	Crypto	24.972873080564195	-79.39586421335616	184595
afcc37a981ae60d79e51a0286550ed005699d40d	a new application of texture unit coding to mass classification for mammograms	visual databases image texture image coding image classification mammography medical image processing;image coding;texture classification;mammographic image analysis society texture unit coding mass classification mammograms texture spectrum approach texture classification information divergence discrimination criterion texture spectra minimammographic database;image classification;spectrum;mammographic image analysis society;image texture;texture analysis;medical image processing;mammography;pixel breast cancer application software image coding image texture analysis spatial databases helium image generation histograms shape;visual databases	Texture is one of important features of masses in mammograms. A recent texture unit-based texture spectrum approach, referred to as texture unit coding (TUC) has shown promise in texture classification. This paper presents a new application of the TUC to mass classification in mammograms. The TUC generates a texture spectrum for a texture image that can be used to describe the characteristics of masses. It also develops an information divergence (ID)-based discrimination criterion to measure the discrepancy between two texture spectra, a concept yet to explore in texture analysis. The TUC along with ID are further applied to mass classification in mammograms where the minimammographic database provided by the Mammographic Image Analysis Society (MIAS) is used for experiments.	discrepancy function;experiment;image analysis;image processing;performance evaluation;shape analysis (digital geometry);texture mapping unit	Yuan Chen;Chein-I Chang	2004	2004 International Conference on Image Processing, 2004. ICIP '04.	10.1109/ICIP.2004.1421828	image texture;spectrum;computer vision;contextual image classification;speech recognition;computer science;pattern recognition;texture compression	Vision	36.8638472524364	-73.227012794962	185075
0211e35a21bf9c8fe6b1faef4791d5b6ee6abea9	estimation of the cardiac ejection fraction from image statistics	manuals;cavity resonators;image distributions;image segmentation;neural nets;cardiology;automatic segmentation;principal component analysis biomedical mri cardiology image segmentation learning artificial intelligence medical image processing neural nets;cavity resonators image segmentation manuals artificial neural networks magnetic resonance imaging principal component analysis;bhattacharyya similarity coefficient;ann;image statistics;dimension reduced features cardiac ejection fraction estimation image statistics cardiovascular disease prognosis machine learning techniques mri images user provided single image segmentation bhattacharyya similarity coefficient image distributions left ventricle cavity areas principal component analysis pca feature dimensionality reduction artificial neural network ann;magnetic resonance image;left ventricle;artificial neural networks;machine learning techniques;mri images;machine learning;cardiovascular disease;medical image processing;principal component analysis;magnetic resonance imaging;user provided single image segmentation;cardiac ejection fraction estimation;ejection fraction;dimension reduced features;learning artificial intelligence;user interaction;pca;cardiovascular disease prognosis;left ventricle cavity areas;artificial neural network;biomedical mri;feature dimensionality reduction	The Cardiac Ejection Fraction (EF) is an essential criterion in cardiovascular disease prognosis. In clinical routine, EF is often computed from manually or automatically segmenting the Left Ventricle (LV) in End-dyastole and Endsystole frames, which is prohibitively time consuming and needs user interactions. In this paper, we propose a method to minimize user effort and estimate the EF directly from image statistics via machine-learning techniques, without the need for comprehensive segmentations of all the MRI images in a subject dataset. From a user-provided segmentation of a single image, we build a statistic based on the Bhattacharyya coefficient of similarity between image distributions for each of the images in a subject dataset (200 images). We demonstrate that these statistical features are non-linearly related to the LV cavity areas and therefore can be used to estimate the EF. We used Principal Component Analysis (PCA) to reduce the dimensionality of the features and areas. Then, an Artificial Neural Network (ANN) was used to predict the LV cavity areas from the dimension-reduced features. The EF is finally estimated from the obtained areas.	artificial neural network;autostereogram;cloud fraction;coefficient;entity framework;interaction;jaccard index;logical volume management;machine learning;principal component analysis;scene statistics	Mariam Afshin;Ismail Ben Ayed;Ali Islam;Aashish Goela;Ian G. Ross;Terry M. Peters;Shuo Li	2012	2012 9th IEEE International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2012.6235675	computer vision;computer science;machine learning;pattern recognition;artificial neural network;principal component analysis	Vision	34.136348146120774	-78.67191081686968	185089
464ddf99a5a69f51235eebaef403ce302d4565bc	rapid automated classification of anesthetic depth levels using gpu based parallelization of neural networks	neural networks;parallel programming;eeg;parallel processing;anesthetic depth level;anesthesia	The effect of anesthesia on the patient is referred to as depth of anesthesia. Rapid classification of appropriate depth level of anesthesia is a matter of great importance in surgical operations. Similarly, accelerating classification algorithms is important for the rapid solution of problems in the field of biomedical signal processing. However numerous, time-consuming mathematical operations are required when training and testing stages of the classification algorithms, especially in neural networks. In this study, to accelerate the process, parallel programming and computing platform (Nvidia CUDA) facilitates dramatic increases in computing performance by harnessing the power of the graphics processing unit (GPU) was utilized. The system was employed to detect anesthetic depth level on related electroencephalogram (EEG) data set. This dataset is rather complex and large. Moreover, the achieving more anesthetic levels with rapid response is critical in anesthesia. The proposed parallelization method yielded high accurate classification results in a faster time.	artificial neural network;automatic parallelization;cuda;computation (action);computer graphics;electroencephalography phase synchronization;graphics processing unit;hl7publishingsubsection <operations>;mathematics;neural network simulation;neural tube defects;parallel computing;patients;signal processing;silo (dataset);algorithm	Musa Peker;Baha Sen;Hüseyin Gürüler	2015	Journal of Medical Systems	10.1007/s10916-015-0197-3	parallel processing;simulation;electroencephalography;computer science;theoretical computer science;machine learning;artificial neural network	ML	28.766271748461918	-76.67104970639079	185355
4a9c0f45c593ec28ca7b711762a9cdc49db248f8	slant estimation and core-region detection for handwritten latin words	handwritten document image pre processing;word slant estimation;core region detection	In this paper, we present a new technique that estimates the slant in handwritten words while a new word core-region detection method is introduced as part of the proposed technique. The proposed core-region detection algorithm can be also used independently to detect the upper and lower baselines of a word. Our method takes advantage of the orientation of the nonhorizontal strokes of Latin characters as well as their location regarding to the word’s core-region. As a first step, the word core-region is detected with the use of novel reinforced horizontal black run profiles which permits to detect the coreregion scan lines more accurately. Then, the near-horizontal parts of the document word are extracted and the orientation and the height of non-horizontal remaining fragments as well as their location in relation to the word’s core-region are calculated. Word slant is estimated taking into consideration the orientation and the height of each fragment while an additional weight is applied if a fragment is partially outside the core-region of the word which indicates that this fragment corresponds to a part of the character stroke that has a significant contribution to the overall word slant and should by definition be vertical to the orientation of the word. Extensive experimental results prove the efficiency of the proposed slant estimation method compared to current state-of-the-art algorithms. 2012 Elsevier B.V. All rights reserved.	algorithm;newton's method;protologism;scan line;the times;thinking outside the box	A. Papandreou;Basilios Gatos	2014	Pattern Recognition Letters	10.1016/j.patrec.2012.08.005	arithmetic;speech recognition;computer science	AI	36.41498850849505	-66.77649974641045	185844
df86562844503ce1b80aa95f791211bfc5ee5932	context-sensitive deep learning for detection of clustered micro calcifications in mammograms		A challenging issue in computerized detection of clustered microcalcifications (MCs) is the frequent occurrence of false positives (FPs) caused by local image patterns that resemble MCs. We develop a context-sensitive deep neural network (DNN) for MC detection, aimed to take into account both the local image features of an MC and its surrounding tissue background. The proposed approach was evaluated on the accuracy both in detecting individual MCs and in detecting MC clusters on a set of 292 mammograms using free-response receiver operating characteristic (FROC) analysis. The results demonstrate that the proposed approach could achieve a significantly higher accuracy in detected individual MCs; incorporating image context information in MC detection can be beneficial for reducing FPs.	artificial neural network;context-sensitive grammar;deep learning;receiver operating characteristic;sensor	Juan Wang;Yongyi Yang	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8462553	feature (computer vision);feature extraction;receiver operating characteristic;deep learning;artificial neural network;pattern recognition;artificial intelligence;mammography;false positive paradox;computer science	Robotics	32.59380857355081	-75.66115743299285	185904
50113b6a3c65a1e13df7d0c6a56b94b53e66deca	mining histopathological images via hashing-based scalable image retrieval	histopathological image mining breast microscopic tissue image classification image feature vector supervised hashing method kernelized hashing method decision support disease detection content based image retrieval systems computer aided diagnosis systems machine learning techniques computational image processing hashing based scalable image retrieval method;image retrieval feature extraction accuracy cancer support vector machines kernel binary codes;tumours cancer content based retrieval data mining feature extraction image classification image retrieval learning artificial intelligence medical image processing;hashing histopathological image analysis breast lesion cbir scalable image retrieval	Automatic analysis of histopathological images has been widely investigated using computational image processing and machine learning techniques. Computer-aided diagnosis (CAD) systems and content-based image retrieval (CBIR) systems have been successfully developed for diagnosis, disease detection, and decision support in this area. In this paper, we focus on a scalable image retrieval method with high-dimensional features for the analysis of histopathology images. Specifically, we present a kernelized and supervised hashing method. With a small amount of supervised information, our method can compress a 10,000-dimensional image feature vector into only tens of binary bits with informative signatures preserved, and these binary codes are then indexed into a hash table that enables real-time retrieval. We validate the hashing-based image retrieval framework on several thousands of images of breast microscopic tissues for both image classification (i.e., benign vs. actionable categorization) and retrieval. Our framework achieves high search accuracy and promising computational efficiency, comparing favorably with other commonly used methods.	binary code;categorization;computation;computer vision;computer-aided design;content-based image retrieval;cryptographic hash function;decision support system;feature (computer vision);feature vector;hash table;image processing;information;kernel method;machine learning;real-time clock;scalability;semi-supervised learning;type signature	Xiaofan Zhang;Wei Liu;Shaoting Zhang	2014	2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2014.6868069	computer vision;visual word;image retrieval;computer science;pattern recognition;automatic image annotation;information retrieval	Vision	32.57377256007128	-72.58315275736754	185919
cf59cdb8cc2e028c544e45017c39971910f01725	understanding of hand motion in sentence level using hmm	lenguaje por signos;transformation affine;coreano;sign language recognition;image segmentation;image processing;methode echelle multiple;sign language;modele markov variable cachee;procesamiento imagen;metodo escala multiple;probabilistic approach;test;traitement image;korean;ensayo;algorithme;langage gestuel;algorithm;essai;hidden markov models;viterbi code;coreen;viterbi algorithm;enfoque probabilista;approche probabiliste;affine transformation;image sequence;segmentation image;success rate;codigo viterbi;context dependent;secuencia imagen;multiscale method;code viterbi;transformacion afin;sequence image;algoritmo	This paper proposes a new method that can recognize a sequence of hand motion expressing a sentence in sign language. Recognition procedure is divided into two steps: separation of the sequence of hand motions into the sub-sequences each of which expresses one word and combination of the words in order to construct a sentence having a meaning. In the first step, sequences of hand motion images are segmented by testing the continuity of the hand motions and by the multiscale image segmentation scheme. The trajectory of the hand motions are estimated by the affine transformation. Each sign in the sentence is represented by the extended chereme analysis model and each chereme is represented by the status vector for determining the transition in the HMM. In the second step, each sentence is also represented by the HMM. The Viterbi algorithm and context-dependent HMM are used to find the best state sequence in the HMM. The proposed algorithm has been tested with ten sequences of images, each of which expresses a sentence in Korean sign language. The experimental results have shown that the proposed algorithm can separate the sentence level image sequence into the word level sub-sequences with the success rate of 75% on average and recognize the sentence with the success rate of 80%. Keyword: Hand motion, Multi-scale image segmentation, Affine transform, Chereme analysis model, HMM, Viterbi algorithm	context-sensitive language;hidden markov model;image segmentation;login;scale-space segmentation;scott continuity;viterbi algorithm;vocabulary	Boohyung Lee;Youngjoon Han;Hwanik Chung;Hernsoo Hahn	2004		10.1117/12.526425	speech recognition;mathematics;communication;algorithm	Vision	35.17956371805334	-67.54805846247685	186063
8e6dee7d90164c9d7eddd8bc15130c646de87a1c	automatic polyp region segmentation for colonoscopy images using watershed algorithm and ellipse segmentation	watershed image segmentation ellipse segmentation;lung cancer;sensitivity and specificity;cancer;real time;colonoscopy video;region segmentation;polyp segmentation;analytical method;ellipse segmentation;colonoscopy;colorectal cancer;computing systems;video;early detection;cameras;watershed image segmentation	In the US, colorectal cancer is the second leading cause of all cancer deaths behind lung cancer. Colorectal polyps are the precursor lesions of colorectal cancer. Therefore, early detection of polyps and at the same time removal of these precancerous lesions is one of the most important goals of colonoscopy. To objectively document detection and removal of colorectal polyps for quality purposes, and to facilitate real-time detection of polyps in the future, we have initiated a computer-based research program that analyzes video files created during colonoscopy. For computer-based detection of polyps, texture based techniques have been proposed. A major limitation of the existing texture-based analytical methods is that they depend on a fixed-size analytical window. Such a fixed-sized window may work for still images, but is not efficient for analysis of colonoscopy video files, where a single polyp can have different relative sizes and color features, depending on the viewing position and distance of the camera. In addition, the existing methods do not consider shape features. To overcome these problems, we here propose a novel polyp region segmentation method primarily based on the elliptical shape that nearly all small polyps and many larger polyps possess. Experimental results indicate that our proposed polyp detection method achieves a sensitivity and specificity of 93% and 98%, respectively. Keywords: Colonoscopy video, Polyp segmentation, Watershed image segmentation. Ellipse segmentation	algorithm;watershed (image processing)	Sae Hwang;Jung Hwan Oh;Wallapak Tavanapong;Johnny S. Wong;Piet C. de Groen	2007		10.1117/12.709835	computer vision;radiology;medicine;pathology	Vision	37.49203190840487	-76.83804108644841	186254
fc458a7f6b27d7c8a51ce8040b2ab867d0310f14	curve evolution for medical image segmentation	electrical engineering and computer science;thesis	The model of geodesic curves in three dimensions is a powerful tool for image segmentation and also has potential for general classification tasks. We extend recent proofs on curve evolution and level set methods to a complete algorithm for the segmentation of tubular structures in volumetric images, and we apply this algorithm primarily to the segmentation of blood vessels in magnetic resonance angiography (MRA) images. This application has clear clinical benefits as automatic and semi-automatic segmentation techniques can save radiologists large amounts of time required for manual segmentation and can facilitate further data analysis. It was chosen both for these benefits and because the vessels provide a wonderful example of complicated 3D curves. These reasons reflect the two primary contributions of this research: it addresses a challenging application that has large potential benefit to the medical community, while also providing a natural extension of previous geometric active contour models research. In this dissertation, we discuss this extension and the MRA segmentation system, CURVES, that we have developed. We have run CURVES on over 30 medical datasets and have compared our cerebral segmentations to segmentations obtained manually by a neurosurgeon for approximately 10 of these datasets. In most cases, we are able to obtain a more detailed representation of the thin vessels, which are most difficult to obtain. We also discuss a novel procedure for extracting the centerlines of tubular structures and proof-of-concept experiments applying surface evolution ideas to general feature-based classification problems. This work is a collaboration with Brigham and Women's Hospital. Thesis Supervisor: Olivier D. Faugeras Title: Adjunct Professor of Computer Science and Engineering Thesis Supervisor: W. Eric L. Grimson Title: Bernard M. Gordon Professor of Medical Engineering		Liana M. Lorigo	2000			computer vision;computer science;artificial intelligence;segmentation-based object categorization;data mining;image segmentation;scale-space segmentation	Vision	37.00972822197069	-80.08066789703679	186439
8d112bb692e338120c44b838a3a83a0f78c14a9b	fuzzy emotional semantic analysis and automated annotation of scene images	emotions;semantics;image processing computer assisted;image interpretation computer assisted;artificial intelligence;algorithms;humans;neural networks computer;information storage and retrieval;automation	With the advances in electronic and imaging techniques, the production of digital images has rapidly increased, and the extraction and automated annotation of emotional semantics implied by images have become issues that must be urgently addressed. To better simulate human subjectivity and ambiguity for understanding scene images, the current study proposes an emotional semantic annotation method for scene images based on fuzzy set theory. A fuzzy membership degree was calculated to describe the emotional degree of a scene image and was implemented using the Adaboost algorithm and a back-propagation (BP) neural network. The automated annotation method was trained and tested using scene images from the SUN Database. The annotation results were then compared with those based on artificial annotation. Our method showed an annotation accuracy rate of 91.2% for basic emotional values and 82.4% after extended emotional values were added, which correspond to increases of 5.5% and 8.9%, respectively, compared with the results from using a single BP neural network algorithm. Furthermore, the retrieval accuracy rate based on our method reached approximately 89%. This study attempts to lay a solid foundation for the automated emotional semantic annotation of more types of images and therefore is of practical significance.	adaboost;algorithm;annotation;artificial intelligence;artificial neural network;back pain;backpropagation;biological neural networks;computation;computer;computers;digital image;eighty nine;exhibits as topic;fuzzy set;imaging techniques;large;network model;set theory;simulation;software propagation;test set;time complexity;interest	Jian-Fang Cao;Li-Chao Chen	2015		10.1155/2015/971039	computer vision;emotion;image retrieval;computer science;artificial intelligence;automation;machine learning;data mining;semantics;automatic image annotation	NLP	32.93278746236226	-69.17602824897638	186953
a0c334ae53d5233a5aec729b6d64903f29f04aa0	medical image categorization and retrieval for pacs using the gmm-kl framework	picture archiving and communication systems pacs;information theoretic image matching;sensitivity and specificity;x ray images;unsupervised clustering;image content;pacs;image segmentation;x ray imaging;content based image retrieval system;content based image retrieval cbir;radiology information systems;database management systems;information retrieval;image matching;medical content retrieval;visual information analysis;statistical medical image modeling;image classification;text based search;biomedical imaging;kullback leibler measure;gaussian mixture modeling;feature space;picture archiving and communication system;radiological images;gmm kl framework;x ray image analysis medical image categorization content based image retrieval system pacs gmm kl framework image representation medical image archives image content imaging modality text based search visual information analysis picture archiving and communication systems gaussian mixture modeling information theoretic image matching kullback leibler measure x ray images multidimensional feature space image intensity image texture spatial information unsupervised clustering feature extraction radiological images illumination invariant representation image classification global representation schemes local representation schemes statistical medical image modeling;image texture;medical image categorization;x ray image analysis content based image retrieval cbir image matching medical content retrieval medical image categorization picture archiving and communication systems pacs statistical medical image modeling;x ray image analysis;medical image archives;gaussian mixture model;statistical analysis;medical image;image representation;feature extraction;medical image processing;image intensity;reproducibility of results	This paper presents an image representation and matching framework for image categorization in medical image archives. Categorization enables one to determine automatically, based on the image content, the examined body region and imaging modality. It is a basic step in content-based image retrieval (CBIR) systems, the goal of which is to augment text-based search with visual information analysis. CBIR systems are currently being integrated with picture archiving and communication systems for increasing the overall search capabilities and tools available to radiologists. The proposed methodology is comprised of a continuous and probabilistic image representation scheme using Gaussian mixture modeling (GMM) along with information-theoretic image matching via the Kullback-Leibler (KL) measure. The GMM-KL framework is used for matching and categorizing X-ray images by body regions. A multidimensional feature space is used to represent the image input, including intensity, texture, and spatial information. Unsupervised clustering via the GMM is used to extract coherent regions in feature space that are then used in the matching process. A dominant characteristic of the radiological images is their poor contrast and large intensity variations. This presents a challenge to matching among the images, and is handled via an illumination-invariant representation. The GMM-KL framework is evaluated for image categorization and image retrieval on a dataset of 1500 radiological images. A classification rate of 97.5% was achieved. The classification results compare favorably with reported global and local representation schemes. Precision versus recall curves indicate a strong retrieval result as compared with other state-of-the-art retrieval techniques. Finally, category models are learned and results are presented for comparing images to learned category models	archive;body regions;categorization;cluster analysis;coherence (physics);content-based image retrieval;entity class - imaging modality;feature vector;google map maker;image registration;information theory;kullback–leibler divergence;matching;medical image;modality (human–computer interaction);normal statistical distribution;picture archiving and communication system;racepinephrine;radiology;silo (dataset);text-based (computing);statistical cluster	Hayit Greenspan;Adi Pinhas	2007	IEEE Transactions on Information Technology in Biomedicine	10.1109/TITB.2006.874191	medical imaging;image texture;computer vision;feature detection;visual word;template matching;radiology;image retrieval;computer science;machine learning;pattern recognition;picture archiving and communication system;automatic image annotation;information retrieval;statistics	Vision	36.007869187952416	-71.90027428017497	186987
73168aae5e45f3eceb86e4e2d575c125b15c4fee	uolo - automatic object detection and segmentation in biomedical images		We propose UOLO, a novel framework for the simultaneous detection and segmentation of structures of interest in medical images. UOLO consists of an object segmentation module which intermediate abstract representations are processed and used as input for object detection. The resulting system is optimized simultaneously for detecting a class of objects and segmenting an optionally different class of structures. UOLO is trained on a set of bounding boxes enclosing the objects to detect, as well as pixel-wise segmentation information, when available. A new loss function is devised, taking into account whether a reference segmentation is accessible for each training image, in order to suitably backpropagate the error. We validate UOLO on the task of simultaneous optic disc (OD) detection, fovea detection, and OD segmentation from retinal images, achieving state-of-the-art performance on public datasets.	backpropagation;ground truth;image analysis;international symposium on fundamentals of computation theory;internationalization and localization;loss function;medical image computing;medical imaging;object detection;pixel;sensor	Teresa Araújo;Guilherme Aresta;Adrian Galdran;Pedro Costa;Ana Maria Mendonça;Aurélio Campilho	2018		10.1007/978-3-030-00889-5_19	convolutional neural network;market segmentation;pattern recognition;optic disc;object detection;artificial intelligence;computer science;segmentation	Vision	31.276745100414274	-74.48113346971931	187566
092aa5753a069a7c85686f83d1d1fb6afb66491e	exploitation of 3d stereotactic surface projection for predictive modelling of alzheimer's disease	correlation based feature selection;ad;ssp;predictive modelling;naive bayes;nb;positron emission tomography;alzheimer s disease;dementia;svm;stereotactic surface projection;support vector machine	Alzheimer's Disease (AD) is one major cause of dementia. Previous studies have indicated that the use of features derived from Positron Emission Tomography (PET) scans lead to more accurate and earlier diagnosis of AD, compared to the traditional approaches that use a combination of clinical assessments. In this study, we compare Naive Bayes (NB) with variations of Support Vector Machines (SVMs) for the automatic diagnosis of AD. 3D Stereotactic Surface Projection (3D-SSP) is utilised to extract features from PET scans. At the most detailed level, the dimensionality of the feature space is very high. Hence we evaluate the benefits of a correlation-based feature selection method to find a small number of highly relevant features; we also provide an analysis of selected features, which is generally supportive of the literature. However, we have also encountered patterns that may be new and relevant to prediction of the progression of AD.		Murat Seçkin Ayhan;Ryan G. Benton;Vijay V. Raghavan;Suresh K. Choubey	2013	International journal of data mining and bioinformatics	10.1504/IJDMB.2013.053194	support vector machine;computer vision;computer science;machine learning;pattern recognition	Web+IR	30.809006258392124	-78.45356812262462	187659
26702c76bf2a024302f34865a7325198593c1874				artificial neural network;benchmark (computing);complex network;convolutional neural network;design rationale;estimated;gait disorders, neurologic;gait analysis;lateral thinking;neural network simulation;neural tube defects;part dosing unit;population parameter;score;silo (dataset);spastic paraplegia, hereditary;wearable computer;sensor (device);width	Julius Hannink;Thomas Kautz;Cristian F. Pasluosta;Jochen Klucken;Bjoern M. Eskofier	2016	IEEE journal of biomedical and health informatics			Vision	29.463396030517202	-77.20786548142084	187902
816e7e08923a768b0fd409785a33e251406dc6aa	segmentation and analysis of the glomerular basement membrane in renal biopsy samples using active contours: a pilot study	female;pilot study;glomerular basement membrane;active contour;image processing;middle aged;edge detection;standard deviation;hematuria;male;microscopy electron transmission;active contours;segmentation;renal disease;renal biopsy;transmission electron microscopy;statistical analysis;diabetic nephropathies;adult;image processing methods;diabetic nephropathy;humans;skeletonization;kidney;pilot projects;active contour model;aged;aged 80 and over;automation	Some renal diseases cause changes in the structure of the glomerular basement membranes (GBM). Measurement of the thickness of the GBM can be performed on transmission electron microscopy (TEM) images of renal biopsy samples. Increased thickness of the GBM is observed in patients with diabetic nephropathy. Abnormally thin GBMs are associated with hematuria. We propose image processing methods for the detection and measurement of the GBM. The methods include edge detection, morphological image processing, active contour modeling, skeletonization, and statistical analysis of the width of the GBM. In the present pilot study, the methods were tested with 34 TEM images of six patients. The estimated mean and standard deviation of the GBM width for a patient with normal GBM were 348 ± 135 nm; those for a patient with thin GBMs due to hematuria were 227 ± 94 nm; and those for a patient with diabetic nephropathy were 1,152 ± 411 nm. Comparison with manual measurements by an experienced renal pathologist indicated low error in the range of 36 ± 11 nm.	active contour model;diabetic nephropathy;edge detection;glomerular basement membrane;hematuria;image processing;kidney diseases;kidney biopsy;mathematical morphology;mesa;patients;scanning electron microscopy;standard deviation;thickness (graph theory);thin layer chromatography;transmission electron microscopy;width	Rangaraj M. Rangayyan;Ilya Kamenetsky;Hallgrimur Benediktsson	2009	Journal of Digital Imaging	10.1007/s10278-009-9188-6	medicine;pathology;image processing;computer science;active contour model;anatomy;diabetes mellitus	Vision	38.02429985004632	-79.57323203000443	188057
a1697b461c3173d840514ed25bed1f24e79fb8ff	dynamic 3-d mr visualization and detection of upper airway obstruction during sleep using region-growing segmentation	manuals;image segmentation;sleep apnea;three dimensional displays;magnetic resonance imaging;manuals sleep apnea three dimensional displays image segmentation magnetic resonance imaging;sleep biomedical mri geriatrics image segmentation medical disorders medical image processing neurophysiology paediatrics;medical diagnostic imaging biomedical image processing magnetic resonance imaging;airway collapse dynamic 3d mr visualization upper airway obstruction detection region growing segmentation upper airway dynamics dynamic 3d magnetic resonance imaging scans pharyngeal airway 3d region growth region of interest pharyngeal airway patent airway cpu time manual segmentation dice coefficients semiautomated segmentation approach obstructive events obstructive sleep apnea children 3d dynamic mri spatiotemporal resolution airway obstruction young adults	Goal: We demonstrate a novel and robust approach for visualization of upper airway dynamics and detection of obstructive events from dynamic 3-D magnetic resonance imaging (MRI) scans of the pharyngeal airway. Methods: This approach uses 3-D region growing, where the operator selects a region of interest that includes the pharyngeal airway, places two seeds in the patent airway, and determines a threshold for the first frame. Results: This approach required 5 s/frame of CPU time compared to 10 min/frame of operator time for manual segmentation. It compared well with manual segmentation, resulting in Dice Coefficients of 0.84 to 0.94, whereas the Dice Coefficients for two manual segmentations by the same observer were 0.89 to 0.97. It was also able to automatically detect 83% of collapse events. Conclusion: Use of this simple semiautomated segmentation approach improves the workflow of novel dynamic MRI studies of the pharyngeal airway and enables visualization and detection of obstructive events. Significance: Obstructive sleep apnea (OSA) is a significant public health issue affecting 4-9% of adults and 2% of children. Recently, 3-D dynamic MRI of the upper airway has been demonstrated during natural sleep, with sufficient spatiotemporal resolution to noninvasively study patterns of airway obstruction in young adults with OSA. This study makes it practical to analyze these long scans and visualize important factors in an MRI sleep study, such as the time, site, and extent of airway collapse.	airway obstruction;cpu (central processing unit of computer system);central processing unit;chronic obstructive airway disease;coefficient;imagery;magnetic resonance imaging;maxima and minima;pharyngeal structure;polysomnography;reactive airway disease;region growing;region of interest;scanning;sleep (system call);sleep apnea syndromes;sleep apnea, obstructive;sleep mode;zenker diverticulum;biologic segmentation	Ahsan Javed;Yoon-Chul Kim;Michael C. K. Khoo;Sally L. Davidson Ward;Krishna S. Nayak	2016	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2015.2462750	radiology;medicine;pathology;computer science;magnetic resonance imaging;image segmentation;surgery	Visualization	38.75978638796735	-79.47253945896024	188376
0614947e42f95859cf566b21fb843086bcdfca20	automatic can separation	ccd camera;imprinted text automatic can separation can lids ccd camera;ccd image sensors;charge coupled devices image analysis charge coupled image sensors cameras pixel robustness standardization machine vision aluminum character recognition	A system for analysing can lids is presented Im ages of the can lids are captured by a CCD camera The images are then analysed to determined whether the cans are with or without imprinted text on the lid The system is also capable of detecting whether the can is viewed from the top or the bottom The performance of the system is promising yet there are possibilities	charge-coupled device;linux intrusion detection system;sensor	Kjersti Aas;Line Eikvil;Otto Milvang	1996		10.1109/ICPR.1996.547309	computer vision;charge-coupled device;computer graphics (images)	Visualization	36.59901202821063	-68.20405469509221	188448
02c3089ff0feea1eefab20ad8d4b69c25e3f396a	skin lesion classification using class activation map		We proposed a two stage framework with only one network to analyze skin lesion images, we firstly trained a convolutional network to classify these images, and cropped the import regions which the network has the maximum activation value. In the second stage, we retrained this CNN with the image regions extracted from stage one and output the final probabilities. The two stage framework achieved a mean AUC of 0.857 in ISIC-2017 skin lesion validation set and is 0.04 higher than that of the original inputs, 0.821.		Xi Jia;Linlin Shen	2017	CoRR		lesion;artificial intelligence;pattern recognition;computer science	ML	31.295888479807864	-75.66741168732766	188946
c4d6c1489833466e9c28c0678ae42a98ae8a786f	deep learning and its application to medical image segmentation		One of the most common tasks in medical imaging is semantic segmentation. Achieving this segmentation automatically has been an active area of research, but the task has been proven very challenging due to the large variation of anatomy across different patients. However, recent advances in deep learning have made it possible to significantly improve the performance of image recognition and semantic segmentation methods in the field of computer vision. Due to the data driven approaches of hierarchical feature learning in deep learning frameworks, these advances can be translated to medical images without much difficulty. Several variations of deep convolutional neural networks have been successfully applied to medical images. Especially fully convolutional architectures have been proven efficient for segmentation of 3D medical images. In this article, we describe how to build a 3D fully convolutional network (FCN) that can process 3D images in order to produce automatic semantic segmentations. The model is trained and evaluated on a clinical computed tomography (CT) dataset and shows stateof-the-art performance in multi-organ segmentation.	artificial neural network;ct scan;computer vision;convolutional neural network;deep learning;feature learning;graphics processing unit;image segmentation;medical imaging;performance;tomography	Holger Roth;Chen Shen;Hirohisa Oda;Masahiro Oda;Yuichiro Hayashi;Kazunari Misawa;Kensaku Mori	2018	CoRR	10.11409/mit.36.63	convolutional neural network;image segmentation;computed tomography;deep learning;medical imaging;data-driven;segmentation;computer science;feature learning;artificial intelligence;pattern recognition	Vision	31.099992640466464	-75.0305814549007	189069
d525bc496167a8d7df5dadd978fb5225e7e58f97	ratio-hypothesis-based fuzzy fusion with application to classification of cellular morphologies		Fusion of knowledge from multiple sources for pattern recognition has been an active area of research in many scientific disciplines. This paper presents a fuzzy version of a probabilistic fusion scheme, known as permanence-of-ratio-based combination, with application to analysis of cellular imaging for high-content screening. Classification of cellular phenotypes has been carried out to illustrate the usefulness of the permanence-of-ratio-based fuzzy fusion.	pattern recognition;signal processing	Tuan D. Pham;Xiaobo Zhou	2010			pattern recognition;artificial intelligence;computer science;fuzzy logic;fusion	Vision	37.739892666232926	-70.98870762603211	189131
6c1eba11dc40bad5ba2d646edab87b94df6ef59d	increasing the credibility of mr spectroscopy-based automatic brain tumor classification systems	tumors reliability accuracy vectors magnetic resonance spectroscopy visualization;tumours biochemistry biomedical nmr brain cancer magnetic resonance spectroscopy medical signal processing pattern recognition signal classification;pattern recognition mr spectroscopy svs brain tumor;metabolite concentrations mr spectroscopy based automatic brain tumor classification systems pattern recognition magnetic resonance spectroscopy aggressive tumors low grade glioma meningioma classification accuracy visualization method	In the last decade many approaches have been introduced that allow for automatic classification of brain tumors by means of pattern recognition and magnetic resonance spectroscopy. Despite promising classification accuracies, none of these methods has found its way into clinical practice, which is also related to the missing transparency for the basis of their decision making. In this work, we develop two methods to increase the interpretability of such classification systems. First we propose a new reliability measure that determines a lower bound for the probability that a particular classification is correct. Additionally, we present a method that visualizes important regions for the classifier directly in the spectral domain. As a basis for this, seven classification methods were evaluated for their performance in discriminating aggressive tumors, low-grade glioma and meningioma, based on a common database. Our results show that the novel reliability measure is in good agreement with the actual classification accuracy. Further we point out that our visualization method clearly indicates which spectral regions are important for a classifier and how metabolite concentrations correspond to specific tumor types. Combining both methods can help to better understand a classifier's decision and therefore make the outcome more transparent and trustworthy.	pattern recognition;resonance;statistical classification;trust (emotion)	Martin Berger;Klaus Sembritzki;Joachim Hornegger;Christina Bauer	2014	2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2014.6867879	pathology;nuclear magnetic resonance	Visualization	34.37513508063161	-76.39684743970071	189402
704c633d41236a5f6c14badbadd2139fb0759d0d	computer aided system for leukocytes classification and segmentation in blood smear images	image segmentation;support vector machines;biomedical imaging;image color analysis;feature extraction;blood;clustering algorithms	Detection and counting of white blood cells (WBC) in blood samples provides valuable information to medical specialists, helping them to evaluate a wide range of important hematic pathologies such as AIDS and blood cancer (Leukaemia). However, this task is prone to errors and time consuming. An automatic detection and classification of WBC images can enhance the accuracy and speed up the detection of WBCs. In this paper, we propose an efficient framework for localization of WBCs within microscopic blood smear images using a multi-class ensemble classification mechanism. In the proposed framework, the nuclei are first segmented, followed by extraction of features such as texture, statistical, and wavelet features. Finally, the detected WBCs are classified into five classes including basophil, eosinophil, neutrophil, lymphocyte, and monocyte. Experimental results on a natural (non-synthetic) benchmark database validate the effectiveness and efficiency of the proposed system in contrast to state-of-the-art schemes.	benchmark (computing);dhrystone;smear campaign;texture mapping;wavelet	Muhammad Sajjad;Siraj Khan;Muhammad Shoaib;Hazrat Ali;Zahoor Jan;Khan Muhammad;Irfan Mehmood	2016	2016 International Conference on Frontiers of Information Technology (FIT)	10.1109/FIT.2016.026	computer vision;medicine;pathology;data mining	Vision	35.870972677816454	-75.2378488816529	189581
2f4886b344d0f28704a4026d6a07642cb25cdd00	non-invasive health status detection system using gabor filters based on facial block texture features	non invasive;gabor filter;health status detection;support vector machine;texture feature	Blood tests allow doctors to check for certain diseases and conditions. However, using a syringe to extract the blood can be deemed invasive, slightly painful, and its analysis time consuming. In this paper, we propose a new non-invasive system to detect the health status (Healthy or Diseased) of an individual based on facial block texture features extracted using the Gabor filter. Our system first uses a non-invasive capture device to collect facial images. Next, four facial blocks are located on these images to represent them. Afterwards, each facial block is convolved with a Gabor filter bank to calculate its texture value. Classification is finally performed using K-Nearest Neighbor and Support Vector Machines via a Library for Support Vector Machines (with four kernel functions). The system was tested on a dataset consisting of 100 Healthy and 100 Diseased (with 13 forms of illnesses) samples. Experimental results show that the proposed system can detect the health status with an accuracy of 93 %, a sensitivity of 94 %, a specificity of 92 %, using a combination of the Gabor filters and facial blocks.	a library for support vector machines;convolution;extraction;face;filter bank;gabor filter;illness (finding);k-nearest neighbors algorithm;sensitivity and specificity;support vector machine	Ting Shu;Bob Zhang	2015	Journal of Medical Systems	10.1007/s10916-015-0227-1	support vector machine;computer vision;computer science;machine learning;pattern recognition	HCI	33.92767041335874	-73.68881348688622	189823
50e111c582cecc3ad548672497f9e3e449d52e64	image-processing technique for suppressing ribs in chest radiographs by means of massive training artificial neural network (mtann)	sensitivity and specificity;solitary pulmonary nodule;computer aided diagnostic;dual energy subtraction technique;radiography thoracic;image processing;image resolution;imaging three dimensional;dual energy subtraction;pulmonary nodule;algorithms artificial intelligence cluster analysis coin lesion pulmonary humans imaging three dimensional information storage and retrieval neural networks computer pattern recognition automated radiographic image enhancement radiographic image interpretation computer assisted radiography thoracic reproducibility of results retrospective studies ribs sensitivity and specificity subtraction technique;computer aided diagnosis;image databases;neural nets;coin lesion pulmonary;retrospective studies;medical tests;lungs;multiresolution massive training artificial neural network;chest radiograph;nonlinear filter;radiographic image enhancement;massive training artificial neural network;indexing terms;ribs artificial neural networks spatial resolution image resolution diagnostic radiography lungs education bones medical tests image databases;lung nodule;computer aided diagnosis cad;artificial neural networks;bones;cluster analysis;medical image processing;rib suppression artificial neural network chest radiography computer aided diagnosis cad dual energy subtraction lung nodule;pulmonary nodules;reproducibility of results;pulmonary nodules image processing ribs clavicles chest radiographs multiresolution massive training artificial neural network lung nodules computer aided diagnosis dual energy subtraction technique multiresolution decomposition composition techniques;ribs;chest radiographs;image processing techniques;artificial intelligence;algorithms;pattern recognition automated;multiresolution decomposition composition techniques;humans;soft tissue;subtraction technique;radiographic image interpretation computer assisted;lung nodules;learning artificial intelligence;chest radiography;neural networks computer	"""When lung nodules overlap with ribs or clavicles in chest radiographs, it can be difficult for radiologists as well as computer-aided diagnostic (CAD) schemes to detect these nodules. In this paper, we developed an image-processing technique for suppressing the contrast of ribs and clavicles in chest radiographs by means of a multiresolution massive training artificial neural network (MTANN). An MTANN is a highly nonlinear filter that can be trained by use of input chest radiographs and the corresponding """"teaching"""" images. We employed """"bone"""" images obtained by use of a dual-energy subtraction technique as the teaching images. For effective suppression of ribs having various spatial frequencies, we developed a multiresolution MTANN consisting of multiresolution decomposition/composition techniques and three MTANNs for three different-resolution images. After training with input chest radiographs and the corresponding dual-energy bone images, the multiresolution MTANN was able to provide """"bone-image-like"""" images which were similar to the teaching bone images. By subtracting the bone-image-like images from the corresponding chest radiographs, we were able to produce """"soft-tissue-image-like"""" images where ribs and clavicles were substantially suppressed. We used a validation test database consisting of 118 chest radiographs with pulmonary nodules and an independent test database consisting of 136 digitized screen-film chest radiographs with 136 solitary pulmonary nodules collected from 14 medical institutions in this study. When our technique was applied to nontraining chest radiographs, ribs and clavicles in the chest radiographs were suppressed substantially, while the visibility of nodules and lung vessels was maintained. Thus, our image-processing technique for rib suppression by means of a multiresolution MTANN would be potentially useful for radiologists as well as for CAD schemes in detection of lung nodules on chest radiographs."""	acceptance testing;artificial neural network;blood vessel;body tissue;bone tissue;bone structure of clavicle;bone structure of rib;chest tightness;computer-aided design;diagnostic techniques, ophthalmological;dual;image processing;multiresolution analysis;nonlinear system;processing (action);radiography;radiology;rib fractures;solitary pulmonary nodule;structure of parenchyma of lung;subtraction technique;urinary sphincter, artificial;zero suppression	Kenji Suzuki;Hiroyuki Abe;Heber MacMahon;Kunio Doi	2006	IEEE Transactions on Medical Imaging	10.1109/TMI.2006.871549	computer vision;radiology;image resolution;medicine;pathology;computer science;machine learning;artificial neural network	Visualization	34.99213916416717	-77.08618072210595	190031
323d2e60c8495315d85ee652761d6bf0d165de48	a new deep-learning approach for early detection of shape variations in autism using structural mri		This paper introduces a novel shape-based computer-aided diagnosis (CAD) system using magnetic resonance (MR) brain images for autism diagnosis at different life stages. To improve the classification robustness, the system fuses the shape features extracted from the cerebral cortex (Cx) and cerebral white matter (CWM). Fusion is conducted based on the findings suggesting that Cx changes in autism are related to CWM abnormalities. The CAD system starts with segmenting Cx and CWM using a 3D joint model that combines intensity, shape, and spatial information. Then, Spherical Harmonic (SPHARM) is applied to the re-constructed meshes of Cx to derive 4 metrics for each mesh point; normal curvature, mean curvature, gaussian curvature, and Cx surface reconstruction error. To analyze the CWM shape, distance maps of its gyri are computed and three more shape features are extracted for these gyri. Finally, all the extracted shape features are fed to a multi-level deep network for feature fusion and diagnosis. The CAD system has been evaluated using subjects from the ABIDE database (8–12.8 years), achieving an accuracy of 93%, and from NDAR/Pitt database (16–51 years), achieving an accuracy of 97%. Also in order to show the capability of the system for early diagnosis, it has been tested on NDAR/IBIS database for infants, resulting in an accuracy of 85%. These initial results on the 3 databases hold the promise of efficient autism diagnosis.	computer-aided design;database;deep learning;ibis (server);map;resonance	Marwa Ismail;Gregory Barnes;Matthew Nitzken;Andrew E. Switala;Ahmed Shalaby;Ehsan Hosseini-Asl;Manuel Casanova;Robert Keynton;Ashraf Khalil;Ayman El-Baz	2017	2017 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2017.8296443	artificial intelligence;computer vision;mean curvature;curvature;deep learning;spatial analysis;feature extraction;pattern recognition;computer science;gaussian curvature;cwm;solid modeling	Robotics	30.885645434652346	-77.91466244161751	190294
6bb74d7cba59cc7183920dc70f101fb2b27432af	real-time scratching behavior quantification system for laboratory mice using high-speed vision	motion analysis;vision system;frame to frame difference;new drugs development;real time;atopic dermatitis;real time vision;automatic behavior quantification;high speed;animal model;drug development	Scratching is a specific behavior induced by itching; it is also a common symptom of many types of dermatitis. For the itching evaluation in animal models, automatic quantification system is needed for objective and accurate observation. In this study, a dedicated real-time motion analysis system is developed for detecting the scratching behavior of laboratory mice in long-time experiments, which enables automated behavior quantification for the development of new drugs for diseases such as atopic dermatitis. This system can detect laboratory mice scratching in a non-invasive method by introducing a specially designed high-speed vision system that can calculate the frame-to-frame difference at a frame rate of 240 fps. A quantification algorithm is also implemented for distinguishing the scratching behavior from other behaviors. In fact, we evaluate the effectiveness of our system by demonstrating the experimental results of scratching behavior detection during the long-time observation of several ICR mice. The results also show the objectiveness and accuracy.	algorithm;experiment;intelligent character recognition;real-time clock;sensor	Yuman Nie;Idaku Ishii;Kenichi Yamamoto;Kensuke Orito;Hiroshi Matsuda	2009	Journal of Real-Time Image Processing	10.1007/s11554-009-0111-7	simulation;computer science;drug development;computer graphics (images)	Robotics	26.739243753522494	-72.17834293867027	190311
fd9785e0051f63447f5215e639b68d189ce0fb88	lstgee: longitudinal analysis of neuroimaging data	clinical data;score statistic;brain;longitudinal study;longitudinal analysis;image processing;substance use disorder;anisotropy;statistical methods;statistical method;statistical power;neuroimaging;brain structure;covariate;score test;longitudinal;generalized estimating equation;cross section;diagnostics;time dependent covariate;fractional anisotropy;resampling method;neural development;longitudinal data;modeling;diseases and disorders	Longitudinal imaging studies are essential to understanding the neural development of neuropsychiatric disorders, substance use disorders, and normal brain. Using appropriate image processing and statistical tools to analyze the imaging, behavioral, and clinical data is critical for optimally exploring and interpreting the findings from those imaging studies. However, the existing imaging processing and statistical methods for analyzing imaging longitudinal measures are primarily developed for cross-sectional neuroimaging studies. The simple use of these cross-sectional tools to longitudinal imaging studies will significantly decrease the statistical power of longitudinal studies in detecting subtle changes of imaging measures and the causal role of time-dependent covariate in disease process. The main objective of this paper is to develop longitudinal statistics toolbox, called LSTGEE, for the analysis of neuroimaging data from longitudinal studies. We develop generalized estimating equations for jointly modeling imaging measures with behavioral and clinical variables from longitudinal studies. We develop a test procedure based on a score test statistic and a resampling method to test linear hypotheses of unknown parameters, such as associations between brain structure and function and covariates of interest, such as IQ, age, gene, diagnostic groups, and severity of disease. We demonstrate the application of our statistical methods to the detection of the changes of the fractional anisotropy across time in a longitudinal neonate study. Particularly, our results demonstrate that the use of longitudinal statistics can dramatically increase the statistical power in detecting the changes of neuroimaging measures. The proposed approach can be applied to longitudinal data with multiple outcomes and accommodate incomplete and unbalanced data, i.e., subjects with different number of measurements.	causal filter;cross-sectional data;fractional anisotropy;image processing;medical imaging;resampling (statistics);scene statistics;sensor;unbalanced circuit	Yimei Li;Hongtu Zhu;Yasheng Chen;Hongyu An;John H. Gilmore;Weili Lin;Dinggang Shen	2009		10.1117/12.812432	neural development;systems modeling;covariate;score test;image processing;data science;statistical power;cross section;score;anisotropy;fractional anisotropy;neuroimaging;generalized estimating equation	ML	24.797848999410682	-76.41362472950888	190358
d188a5adf6fb1ef8eb2a6182ec083ecf033d414e	encephalic nmr image analysis by textural interpretation	information content;texture analysis;feature extraction;pattern recognition;image analysis;digital image;object identification	The novel technologies used in different application domains allow to obtain digital images with a high complex informative content. These meaningful information are expressed by textural skin that covers the objects represented inside the images. The textural information can be exploited to interpret the semantic meaning of the images themselves. This paper provides a mathematical characterization, based on texture analysis, of the basic objects contained in the layout of the NMR encephalic images (cerebral tissue, rest of skull, eventual abnormal mass, and background). By this characterization a prototype has been developed, which has allowed the achievement of three different targets: segmentation of the image layout in basic objects, identification of the eventual abnormal masses, characterization of the morphologic structures of the cerebral tissue.	3d reconstruction;adobe air;application domain;digital image;image analysis;information;medical image computing;medical imaging;prototype;skin (computing)	Danilo Avola;Luigi Cinque	2008		10.1145/1363686.1363997	computer vision;image analysis;self-information;feature extraction;computer science;multimedia;digital image	Vision	38.82676379049779	-71.8199549728477	190454
052820bc846805c24fba1ed76d8dfe33d61f4f54	a statistical method for an automatic detection of form types	document structure;statistical approach;mahalanobis distance;estructura de documento;metodo estadistico;traitement image document;document analysis;image segmentation;structure document;analisis forma;statistical method;analyse documentaire;automatic detection;methode statistique;segmentation image;document image processing;analisis documental;block matching;pattern analysis;classification automatique;automatic classification;clasificacion automatica;analyse forme	In this paper, we present a method to classify forms by a statistical approach; the physical structure may vary from one writer to another. An automatic form segmentation is performed to extract the physical structure which is described by the main rectangular block set. During the form learning phase, a block matching is made inside each class; the number of occurrences of each block is counted, and statistical block attributes are computed. During the phase of identification, we solve the block instability by introducing a block penalty coefficient, which modifies the classical expression of Mahalanobis distance. A block penalty coefficient depends on the block occurrence probability. Experimental results, using the different form types, are given.		Saddok Kebairi;Bruno Taconet;Abderrazak Zahour;Said Ramdane	1998		10.1007/3-540-48172-9_8	speech recognition;computer science;mahalanobis distance;document structure description;machine learning;pattern recognition;mathematics;image segmentation;algorithm	Logic	35.9297845553617	-67.28786577729538	190586
52f1d91f21d68ce4186a9a4cd9f562b383544535	facial expressions and flat affect in schizophrenia, automatic analysis from depth camera data	support vector machines;prototypes;prediction algorithms;clustering algorithms;facial features;correlation;cameras	One of the prominent clinical manifestations of schizophrenia is flat or altered facial activity, and flattening of emotional expressiveness (Flat Affect). In this study we used a structured-light depth camera and dedicated software to automatically measure the facial activity of schizophrenia patients and healthy individuals during a short structured interview. Based on K-means clustering analysis, facial activity was characterized in terms of Typicality, Richness and Distribution of 7 facial-clusters. Thus we found patients' facial activity to be poorer, more typical, and characterized mainly by neutral (flat) expressions. The facial features defined in our study achieved up to 85% correct diagnosis classification rate in a SVM based two-step algorithm, and were in significant correlation with Flat Affect severity. Our results demonstrate how the use of assistive technology and data-driven computational tools allow for a comprehensive description of patients' facial behavior in clinical settings, and may contribute to the reliability and accuracy of psychiatric diagnosis.	algorithm;assistive technology;cluster analysis;embedded system;expressive power (computer science);k-means clustering;structured light	Talia Tron;Abraham Peled;Alexander Grinsphoon;Daphna Weinshall	2016	2016 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)	10.1109/BHI.2016.7455874	psychology;computer vision;machine learning;communication	HCI	26.623623674237344	-75.68876873684542	190636
bd8738fc6fd1d442b4a0079cc4e80bb28f4b1b36	computer-aided diagnostics in digital pathology: automated evaluation of early-phase pancreatic cancer in mice		   Digital pathology diagnostics are often based on subjective qualitative measures. A murine model of early-phase pancreatic ductal adenocarcinoma provides a controlled environment with a priori knowledge of the genetic mutation and stage of the disease. Use of this model enables the application of supervised learning methods to digital pathology. A computerized diagnostics system for histological detection of pancreatic adenocarcinoma was developed and tested. Pathological H&E-stained specimens with early pancreatic lesions were identified and evaluated with a system that models cancer detection using a top-down object learning paradigm, mimicking the way a pathologist learns. First, the dominant primitives were identified and segmented in the images, i.e., the ducts, nuclei and tumor stroma. A boost-based machine learning technique was used for duct segmentation, classification and outlier pruning. Second, a set of morphological features traditionally used for cancer diagnosis which provides quantitative image features was employed to quantify subtle findings such as duct deformation and nuclei malformations. Finally, a visually interpretable predictive model was trained to distinguish between normal tissue and premalignant cancer lesions, given ground truth samples. A predictive success rate of 92 % was achieved using tenfold cross-validation and 93 % on an independent test set. Comparison was made with state-of-the-art classification algorithms that are not interpretable as visible features yielded the contribution of individual primitive features to the prediction outcome. Quantitative image analysis and classification were successful in preclinical histology diagnosis for early-stage pancreatic adenocarcinoma. The usage of annotated contours coupled with interpretable supervised learning methods and outlier pruning can be adapted to other medical imaging tasks. The usage of interpretable supervised learning techniques may improve the success of CAD in histopathological diagnosis.	biomarkers, tumor;body tissue;choose (action);computer assisted diagnosis;computer-aided design;congenital abnormality;cross-sectional studies;cross-validation (statistics);decision trees;decision tree;duct (organ) structure;ductal breast carcinoma;generic drugs;ground truth;image analysis;machine learning;malignant neoplasm of pancreas;medical imaging;neoplasms;overfitting;pancreatic ductal adenocarcinoma;pancreatic adenocarcinoma;precancerous conditions;predictive modelling;programming paradigm;silo (dataset);specimen;stroma;supervised learning;test set;top-down and bottom-up design;algorithm;biologic segmentation;quantitative	Leeor Langer;Yoav Binenbaum;Leonid Gugel;Moran Amit;Ziv Gil;Shai Dekel	2014	International Journal of Computer Assisted Radiology and Surgery	10.1007/s11548-014-1122-9	medicine;pathology;bioinformatics	ML	32.737865214215084	-78.38698667559055	190717
f4d839247c3c1eb37fd18833b8c214cfe0543854	connection method of separated luminal regions of intestine from ct volumes	endoscopy;digestive system;intestine;medical diagnostics;endoscopes;cad systems;diseases and disorders	This paper proposes a connection method of separated luminal regions of the intestine for Crohn's disease diagnosis. Crohn's disease is an inflammatory disease of the digestive tract. Capsule or conventional endoscopic diagnosis is performed for Crohn's disease diagnosis. However, parts of the intestines may not be observed in the endoscopic diagnosis if intestinal stenosis occurs. Endoscopes cannot pass through the stenosed parts. CT image-based diagnosis is developed as an alternative choice of the Crohn's disease. CT image-based diagnosis enables physicians to observe the entire intestines even if stenosed parts exist. CAD systems for Crohn's disease using CT volumes are recently developed. Such CAD systems need to reconstruct separated luminal regions of the intestines to analyze intestines. We propose a connection method of separated luminal regions of the intestines segmented from CT volumes. The luminal regions of the intestines are segmented from a CT volume. The centerlines of the luminal regions are calculated by using a thinning process. We enumerate all the possible sequences of the centerline segments. In this work, we newly introduce a condition using distance between connected ends points of the centerline segments. This condition eliminates unnatural connections of the centerline segments. Also, this condition reduces processing time. After generating a sequence list of the centerline segments, the correct sequence is obtained by using an evaluation function. We connect the luminal regions based on the correct sequence. Our experiments using four CT volumes showed that our method connected 6.5 out of 8.0 centerline segments per case. Processing times of the proposed method were reduced from the previous method. © (2015) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	ct scan	Masahiro Oda;Takayuki Kitasaka;Kazuhiro Furukawa;Osamu Watanabe;Takafumi Ando;Yoshiki Hirooka;Hidemi Goto;Kensaku Mori	2015		10.1117/12.2081977	digestion	Vision	37.95205167976631	-78.88172727945292	190736
68b34b40bdb9de764e943872497a9dea2deb2e46	detection of cracks and corrosion for automated vessels visual inspection	visual inspection	Despite the efforts on reducing maritime accidents, they still occur and, from time to time, have catastrophic consequences both in personal, environmental and financial terms. Structural failure is the major cause of ships wreckages and, as such, Vessel Classification Societies impose extensive inspection schemes for assessing the structural integrity of vessels. The external and internal parts of the hull can be affected by different kinds of defects typical of steel surfaces and structures, such as cracks and corrosion. Nowadays, to detect these defects, visual hull inspections are carried out at a great cost. The goal of the EU-funded FP7 MINOAS project is to develop a fleet of robots for automating as much as possible the aforementioned inspection and maintenance operations. Within this general context, the work presented constitutes a first attempt towards the remote visual inspection and documentation of hull surfaces. In this regard, the two main defective situations, cracks and corrosion, are expected to be autonomously or semi-autonomously detected by means of computer vision techniques. In this work, several algorithms are presented for visual detection of the above mentioned two kinds of defects. On the one hand, a crack detector is described, which is based on a percolation process that exploits the morphological properties of cracks in steel surfaces: dark, narrow and elongated sets of connected pixels. On the other hand, two different approaches for corrosion detection are introduced and compared. While the first one takes profit from the distribution of color in corroded areas, the second one has been built around a weak classifier cascade scheme, separating the spatial and colour analysis in two different steps. As an final contribution, the crack detector is combined with the corrosion detector in order to guide the crack location and improve its performance. The obtained detectors have shown promising rates of detection as well as close to real-time performance.	adaboost;algorithm;bilateral filter;charge-coupled device;computation;computer vision;convex hull;convolution;documentation;fp (complexity);gaussian blur;gradient boosting;image processing;jones calculus;map;noise reduction;percolation;pixel;process-centered design;real-time clock;robot;semiconductor industry;sensor;software bug;structural integrity and failure;supervised learning;time complexity;unintended consequences;visual hull;visual inspection;weak value	Francisco Bonnín-Pascual;Alberto Ortiz	2010		10.3233/978-1-60750-643-0-111	computer vision;engineering;forensic engineering;engineering drawing;automated optical inspection	Vision	36.623432903559085	-70.32318578650556	190750
ebbc3f41b233a5a348fd4999c1f4f3091ccd1838	computer aided breast calcification auto-detection in cone beam breast ct	feed forward;tissues;cad;standard deviation;breast;three dimensional;cone beam;artificial neural networks;calcification auto detection;cone beam breast ct;computing systems;superposition;false positive;back propagation;foreground background;artificial neural network	In Cone Beam Breast CT (CBBCT), breast calcifications have higher intensities than the surrounding tissues. Without the superposition of breast structures, the three-dimensional distribution of the calcifications can be revealed. In this research, based on the fact that calcifications have higher contrast, a local thresholding and a histogram thresholding were used to select candidate calcification areas. Six features were extracted from each candidate calcification: average foreground CT number value, foreground CT number standard deviation, average background CT number value, background CT number standard deviation, foreground-background contrast, and average edge gradient. To reduce the false positive candidate calcifications, a feed-forward back propagation artificial neural network was designed. The artificial neural network was trained with the radiologists confirmed calcifications and used as classifier in the calcification auto-detection task. In the preliminary experiments, 90% of the calcifications in the testing data sets were detected correctly with an average of 10 false positives per data set.© (2010) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Xiaohua Zhang;Ruola Ning;Jiangkun Liu	2010		10.1117/12.844362	superposition principle;three-dimensional space;computer vision;type i and type ii errors;backpropagation;foreground-background;cad;standard deviation;feed forward;artificial neural network	EDA	35.6266606245975	-76.70605128661035	190786
cdf5ff9ab243ca7e21e3de72a29e4295d1cc71a7	statistical disease mapping for heterogeneous neuroimaging studies		Most cancers and neuro-related diseases (e.g., autism and stroke) display significant phenotypic and genetic heterogeneity. Characterizing such heterogeneity could transform our understanding of the etiology of these conditions and inspire new approaches to urgently needed preventions, diagnoses, and treatments. However, existing statistical methods face major challenges in delineating such heterogeneity at both group and individual levels. The aim of this paper is to propose a novel statistical disease mapping (SDM) framework to address some of these challenges. We develop an efficient estimation method to estimate unknown parameters in SDM and individual and group disease maps. Both simulation studies and real data analysis on the ADNI PET dataset indicate that our SDM can not only effectively detect diseased regions in each patient, but also provide a group disease map analysis of Alzheimer (AD) subgroups.	genetic algorithm;map analysis;polyethylene terephthalate;simulation	Rongjie Liu;Chao Huang;Tengfei Li;Liuqing Yang;Hongtu Zhu	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363837	medical diagnosis;autism;genetic heterogeneity;artificial intelligence;pattern recognition;computer science;hidden markov model;neuroimaging;disease	Visualization	29.418697288015306	-79.0951428126458	190852
69cb6cc38e5f343f1721e7a71defdf010cb17f91	classification of breast cancer histopathological images using kaze features		Breast cancer (BC) is a public health problem of first importance, being the second most common cancer worldwide. BC represents 30.4% of all new cancer cases in the European female population. The diagnosis and differential diagnosis of BC is based on the clinical presentations, physical examinations combined with imaging studies, and confirmed by histopathologic findings. Pathologists’ examination is a time-consuming analysis, susceptible to an interpretation bias mainly caused by the experience of the pathologist and the decrease of attention due to fatigue. Currently, computer-aided detection and diagnosis techniques applied to digital images are assisting the specialists.		Daniel Sánchez Morillo;Jesús González;Marcial García-Rojo;Julio Ortega	2018		10.1007/978-3-319-78759-6_26	computer vision;engineering;breast cancer;cancer;artificial intelligence;radiology;public health;differential diagnosis;population;medical imaging;histopathology;contextual image classification	Vision	33.88351473031529	-77.30819974458578	191236
6e5d7632f15a7071e2af88d2d86d4b2171f30e71	improving face recognition with a quality-based probabilistic framework	databases;image features;bayesian network;image recognition;face verification face recognition quality based probabilistic framework facial image quality metrics biometric matching bayesian network image features image recognition probabilistic inference;probability;biometrics access control;image matching;bayes methods;training;biometrics;additive noise;prediction algorithms;face verification;probabilistic inference;probes;computer vision;visualization;quality based probabilistic framework;biometric matching;quality assessment;face recognition;shape;image quality metric;image quality;face recognition biometrics probes image quality image recognition additive noise prediction algorithms quality assessment visualization computer vision;facial image quality metrics;decision process;face;probability bayes methods biometrics access control face recognition image matching	This paper addresses the problem of developing facial image quality metrics that are predictive of the performance of existing biometric matching algorithms and incorporating the quality estimates into the recognition decision process to improve overall performance. The first task we consider is the separation of probe/gallery qualities since the match score depends on both. Given a set of training images of the same individual, we find the match scores between all possible probe/gallery image pairs. Then, we define symmetric normalized match score for any pair, model it as the average of the qualities of probe/gallery corrupted by additive noise, and estimate the quality values such that the noise is minimized. To utilize quality in the decision process, we employ a Bayesian network to model the relationships among qualities, predefined quality related image features and recognition. The recognition decision is made by probabilistic inference via this model. We illustrate with various face verification experiments that incorporating quality into the decision process can improve the performance significantly.	additive white gaussian noise;algorithm;bayesian network;biometrics;experiment;facial recognition system;image quality;modal logic;overfitting;test set;transformation matrix;utility functions on indivisible goods	N. Ozay;Yan Tong;Frederick W. Wheeler;Xiaoming Liu	2009	2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops	10.1109/CVPRW.2009.5204299	image quality;facial recognition system;face;computer vision;visualization;prediction;shape;computer science;machine learning;pattern recognition;probability;bayesian network;feature;biometrics	Vision	27.176803608524278	-66.20730616420055	191348
04bf4d409df9d4725f01bca9c4c4882630a0c3a0	color energy as a seed descriptor for image segmentation with region growing algorithms on skin wound images	region growing algorithm seed medical computing image segmentation skin lesion recognition;image segmentation;image color analysis image segmentation wounds skin lesions green products;green products;skin;wounds;lesions;image color analysis;skin image colour analysis image segmentation injuries medical image processing;region size color channel energy seed descriptor image segmentation region growing segmentation algorithm skin wound image seed finding method rgb system	This paper presents a seed finding method for region growing segmentation approach using color channel energy in image regions. Instead of using the RGB system separated for each pixel, the proposal uses the energy on each color channel to improve the range of the possible values, then creates a more specific seed to detail different regions. Region size used to calculate energy was adjusted to verify the proposed method. Images used were real wound photos, taken from patients undergoing treatment at the university hospital. Results showed that energy on regions presents enough information to segment, leading to a high percentage of matching with experts marks.	algorithm;channel (digital image);computer performance;computer science;image segmentation;medical imaging;pixel;region growing;seed;vii	Jose Luis Seixas;Sylvio Barbon Junior;Claudia Martins Siqueira;Ivan Frederico Lupiano Dias;Andre Giovanni Castaldin;Alan Salvany Felinto	2014	2014 IEEE 16th International Conference on e-Health Networking, Applications and Services (Healthcom)	10.1109/HealthCom.2014.7001874	color histogram;image texture;computer vision;range segmentation;color image;binary image;geography;region growing;image segmentation;optics;scale-space segmentation;computer graphics (images)	Robotics	37.63052314857564	-76.22115714893684	191521
5a2be67c071250e22260789e195ae1bab3dac254	convolutional neural network for reconstruction of 7t-like images from 3t mri using appearance and anatomical features		The advanced 7 Tesla (7T) Magnetic Resonance Imaging (MRI) scanners provide images with higher resolution anatomy than 3T MRI scanners, thus facilitating early diagnosis of brain diseases. However, 7T MRI scanners are less accessible, compared to the 3T MRI scanners. This motivates us to reconstruct 7T-like images from 3T MRI. We propose a deep architecture for Convolutional Neural Network (CNN), which uses the appearance (intensity) and anatomical (labels of brain tissues) features as input to non-linearly map 3T MRI to 7T MRI. In the training step, we train the CNN by feeding it with both appearance and anatomical features of the 3T patch. This outputs the intensity of center voxel in the corresponding 7T patch. In the testing step, we apply the trained CNN to map each input 3T patch to the 7T-like image patch. Our performance is evaluated on 15 subjects, each with both 3T and 7T MR images. Both visual and numerical results show that our method outperforms the comparison methods.	convolutional neural network	Khosro Bahrami;Feng Shi;Islem Rekik;Dinggang Shen	2016		10.1007/978-3-319-46976-8_5	computer vision;voxel;pattern recognition;convolutional neural network;artificial intelligence;computer science;anatomical feature;sparse approximation;magnetic resonance imaging	Vision	31.156313116557584	-75.8132933906983	191550
615c038647e6247aa31715d6b332d429b67d8a94	self-paced learning for multi-modal fusion for alzheimer's disease diagnosis		Alzheimeru0027s disease (AD) is a sort of nervous system disease, and it may cause amnesia and executive dysfunction etc. AD seriously reduces the quality of peopleu0027s life, so it is very important to improve the diagnosis accuracy of AD in its prodromal stage, mild cognitive impairment (MCI). In recent years, multi-modal methods had been proven to be effective in prediction of AD and MCI by utilizing the complementary information across different modalities in AD data. In this paper, we propose self-paced sample weighting based low-rank representation (SPLRR) to explore the latent correlation across different modalities. By imposing rank minimization on different modalities regression coefficients, we can capture the intrinsic structure among modalities. Meanwhile, we introduce self-paced learning to allot the corresponding weight to samples based on the contribution of each sample to the label in the current modality. Experiments on the Alzheimeru0027s disease Neuroimaging Initiative (ADNI) database show that the SPLRR model obtains the better classification performance than the state-of-the-art methods.	alzheimer's disease neuroimaging initiative;amnesia: the dark descent;coefficient;decision boundary;modal logic;modality (human–computer interaction)	Ning Yuan;Donghai Guan;Qi Zhu;Weiwei Yuan	2017	2017 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)	10.1109/SPAC.2017.8304253	modalities;task analysis;amnesia;machine learning;neuroimaging;cognition;computer science;weighting;executive dysfunction;artificial intelligence;dementia	Vision	25.981348588284725	-77.8191391070768	191696
de35dfc99886a14e019489c8c3d365e271c74fc0	predicting conversion of mild cognitive impairments to alzheimer's disease and exploring impact of neuroimaging		Nowadays, a lot of scientific efforts are concentrated on the diagnosis of Alzheimers Disease (AD) applying deep learning methods to neuroimaging data. Even for 2017, there were published more than a hundred papers dedicated to AD diagnosis, whereas only a few works considered a problem of mild cognitive impairments (MCI) conversion to AD. However, the conversion prediction is an important problem as approximately 15% of patients with MCI converges to AD every year. In the current work, we are focusing on the conversion prediction using brain Magnetic Resonance Imaging and clinical data, such as demographics, cognitive assessments, genetic, and biochemical markers. First of all, we applied state-of-the-art deep learning algorithms on the neuroimaging data and compared these results with two machine learning algorithms that we fit using the clinical data. As a result, the models trained on the clinical data outperform the deep learning algorithms applied to the MR images. To explore the impact of neuroimaging further, we trained a deep feed-forward embedding using similarity learning with Histogram loss on all available MRIs and obtained 64-dimensional vector representation of neuroimaging data. The use of learned representation from the deep embedding allowed to increase the quality of prediction based on the neuroimaging. Finally, the current results on this dataset show that the neuroimaging does affect conversion prediction, however, cannot noticeably increase the quality of the prediction. The best results of predicting MCI-to-AD conversion are provided by XGBoost algorithm trained on the clinical and embedding data. The resulting accuracy is ACC = 0.76±0.01 and the area under the ROC curve – ROC AUC = 0.86 ± 0.01.	algorithm;computer vision;deep learning;experiment;machine learning;numerical weather prediction;receiver operating characteristic;resonance;similarity learning;xgboost	Yaroslav Shmulev;Mikhail Belyaev	2018		10.1007/978-3-030-00689-1_9		ML	29.807734356510537	-76.90807257485258	191725
06a4c2af857635cda94965749fd5a4c9d3b8dfc7	computer-aided cirrhosis diagnosis via automatic liver capsule extraction and combined geometry-texture features		This paper presents a computer-aided system for automatic diagnosis of cirrhosis based on ultrasound images. We first propose a dynamic programming algorithm to automatically extract the liver capsule, and then the continuity and smoothness of capsule serve as an important guideline for image classification. Via the decomposition of the ultrasound image in spatial and gray scales, the density and entropy of suspected nodular areas are used to describe texture features of liver parenchyma. Finally, a trained SVM classifier is applied to classify the samples into normal, mild, moderate and severe clinical stages of the disease. Experiment results show that the proposed method achieves better performance than existing approaches. Moreover, it can be used as an efficient method for early cirrhosis diagnosis in consideration of its high accuracy in distinguishing between normal and abnormal cases.	algorithm;computer vision;dynamic programming;scott continuity	Xiang Liu;Zhiqin Zhan;Ming Yan;Jingwen Zhao;Jia Lin Song;Yan Qiu Chen	2017	2017 IEEE International Conference on Multimedia and Expo (ICME)	10.1109/ICME.2017.8019551	artificial intelligence;computer science;computer vision;pattern recognition;support vector machine;cirrhosis;computer-aided;ultrasound;feature extraction;classifier (linguistics);contextual image classification;fibrous capsule of glisson	Robotics	34.891461601939824	-75.92041694596466	191847
8cd39c4c0d44f69cb2bffc53e82642f9121ff207	ensemble classification system applied for retinal vessel segmentation on child images containing various vessel profiles	boot strapped decision tree;ensemble classifier;computer science and informatics;retinal blood vessel segmentation;public database	This paper describes a new supervised method for segmentation of blood vessels in retinal images of multi ethnic school children. This method uses an ensemble classification system of boot strapped decision trees. A filter bank of the dual Gaussian and the Gabor filters, along with the line strength measure of blood vessels is used to generate the feature vector. The feature vector encodes information to handle the normal vessels as well as the vessels with strong light reflexes along their centerline, which is more apparent on arteriolars than venules, and in children compared to adult patients. For this purpose we also present a new public retinal image database of multi ethnic school children along with vessel segmentation ground truths. The image set is named as CHASE_DB1 and is a subset of retinal images from the Child Heart and Health Study in England (CHASE) dataset. The performance of the ensemble system for vessel segmentation is evaluated on CHASE_DB1 in detail, and the incurred accuracy, speed, robustness and simplicity make the algorithm a suitable tool for automated retinal image analysis in large population based studies.		Muhammad Moazam Fraz;Paolo Remagnino;Andreas Hoppe;Bunyarit Uyyanonvara;Alicja R. Rudnicka;Christopher G. Owen;Sarah Barman	2012		10.1007/978-3-642-31298-4_45	computer vision;artificial intelligence;data mining	Vision	34.498913315363275	-75.57484232649641	191936
3d366eca8c4640cc95c117e6dd473ffc76cfb66c	computer vision -- accv 2014		Vessel segmentation is a key step for various medical applications, such as diagnosis assistance, quantification of vascular pathology, and treatment planning. This paper describes an automatic vessel segmentation framework which can achieve highly accurate segmentation even in regions of low contrast and signal-to-noise-ratios (SNRs) and at vessel boundaries with disturbance induced by adjacent non-vessel pixels. There are two key contributions of our framework. The first is a progressive contrast enhancement method which adaptively improves contrast of challenging pixels that were otherwise indistinguishable, and suppresses noises by weighting pixels according to their likelihood to be vessel pixels. The second contribution is a method called canny refinement which is based on a canny edge detection algorithm to effectively re-move false positives around boundaries of vessels. Experimental results on a public retinal dataset and our clinical cerebral data demonstrate that our approach outperforms state-of-the-art methods including the vesselness based method [1] and the optimally oriented flux (OOF) based method [2].	algorithm;canny edge detector;computer vision;edge detection;pixel;refinement (computing);signal-to-noise ratio	Daniel Cremers;Ian D. Reid;Hideo Saito;Ming-Hsuan Yang	2014		10.1007/978-3-319-16811-1		Vision	39.10931591077019	-79.09797783763725	191952
983cb991e851d8f89d0053555a2b3c66d0910f16	identification of ulcers in wireless capsule endoscopy videos	texture;rgb color space;crohn s disease;log gabor filters;image segmentation;image classification wireless capsule endoscopy videos noninvasive procedure gastrointestinal tract diseases bleeding crohn s disease peptic ulcers colon cancer small intestine hsv color space log gabor filters segmentation scheme color information extraction rgb color space texture information artificial neural network;support vector machines;neural nets;video signal processing;fuzzy region segmentation;color space;small intestine;biological organs;image classification;hsv color space;peptic ulcers;gabor filters;data mining;noninvasive procedure;wireless capsule endoscopy imaging;colon cancer;region segmentation;wireless communication;gabor filter;wireless capsule endoscopy;image color analysis;gastrointestinal tract;feature extraction;medical image processing;pixel;endoscopes;diseases;endoscopes videos diseases data mining gastrointestinal tract cancer detection hemorrhaging colon intestines gabor filters;video signal processing biological organs diseases endoscopes feature extraction gabor filters image classification image segmentation medical image processing neural nets;texture information;hsv color space wireless capsule endoscopy imaging fuzzy region segmentation fuzzy least squares support vector machines log gabor filters ulcers texture;peptic ulcer;wireless capsule endoscopy videos;bleeding;fuzzy least squares support vector machines;ulcers;artificial neural network;least squares support vector machine;color information extraction;segmentation scheme	Wireless Capsule Endoscopy (WCE) is a non invasive procedure which is used to view the lower gastrointestinal tract. Physicians can detect diseases such as bleeding, Crohn's disease, peptic ulcers, and colon cancer. In this paper a methodology is presented to identify peptic ulcers in the small intestine automatically. It first performs color transformation into the HSV color space; it utilizes log Gabor filters to find meaningful regions. A segmentation scheme is used to extract color information of these meaningful regions in the original RGB color space. Additionally, texture information is extracted and together with color values are fed into an artificial neural network for classification. Illustrative results from the methodology are also given in this paper.	artificial neural network;colon classification;color space;log gabor filter;tract (literature)	Alexandros Karargyris;Nikolaos G. Bourbakis	2009	2009 IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2009.5193107	support vector machine;least squares support vector machine;computer vision;gastroenterology;contextual image classification;hsl and hsv;medicine;pathology;feature extraction;computer science;rgb color space;machine learning;image segmentation;texture;color space;artificial neural network;pixel;wireless	Robotics	35.50237830792203	-75.24634742966043	192412
ace04bd21f15eb48e7d3519c9e579e4805607c8a	a deep learning method for prediction of benign epilepsy with centrotemporal spikes		Benign epilepsy with centrotemporal spikes (BECT) is the most common epilepsy in the children. The research of BECT mainly focuses on the comparative analysis of the BECT patients and the healthy controls. Different from the existing methods, we proposed a 3D convolution neural network (3DCNN) that directly predicts the disease of BECT from raw magnetic resonance imaging (MRI). The experiment shows our 3DCNN model get an (89.80%) accuracy in the five-fold cross-validation evaluation which is over a large margin than the benchmark method.	deep learning	Ming Yan;Ling Liu;Sihan Chen;Yi Pan	2018		10.1007/978-3-319-94968-0_24	machine learning;deep learning;computer science;artificial intelligence;convolutional neural network;magnetic resonance imaging;epilepsy	NLP	29.895819435212008	-77.05964154523524	192953
aac41345fabfff1ee8f1c4c2bc93865b8d837fe1	automated calibration for computerized analysis of prostate lesions using pharmacokinetic magnetic resonance images	diagnostic accuracy;automatic segmentation;peripheral zone;system performance;magnetic resonance image;dynamic contrast enhanced;mr imaging;arterial input function;support vector machine;prostate cancer	The feasibility of an automated calibration method for estimating the arterial input function when calculating pharmacokinetic parameters from Dynamic Contrast Enhanced MRI is shown. In a previous study, it was demonstrated that the computer aided diagnoses (CADx) system performs optimal when per patient calibration was used, but required manual annotation of reference tissue. In this study we propose a fully automated segmentation method that tackles this limitation and tested the method with our CADx system when discriminating prostate cancer from benign areas in the peripheral zone. A method was developed to automatically segment normal peripheral zone tissue (PZ). Context based segmentation using the Otsu histogram based threshold selection method and by Hessian based blob detection, was developed to automatically select PZ as reference tissue for the per patient calibration. In 38 consecutive patients carcinoma, benign and normal tissue were annotated on MR images by a radiologist and a researcher using whole mount step-section histopathology as standard of reference. A feature set comprising pharmacokinetic parameters was computed for each ROI and used to train a support vector machine (SVM) as classifier. In total 42 malignant, 29 benign and 37 normal regions were annotated. The diagnostic accuracy obtained for differentiating malignant from benign lesions using a conventional general patient plasma profile showed an accuracy of 0.65 (0.54-0.76). Using the automated segmentation per patient calibration method the diagnostic value improved to 0.80 (0.71-0.88), whereas the manual segmentation per patient calibration showed a diagnostic performance of 0.80 (0.70-0.90). These results show that an automated per-patient calibration is feasible, a significant better discriminating performance compared to the conventional fixed calibration was obtained and the diagnostic accuracy is similar to using manual per-patient calibration.		Pieter C. Vos;Thomas Hambrock;Jelle O. Barentsz;Henkjan J. Huisman	2009	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-642-04271-3_101	support vector machine;computer vision;radiology;pathology;computer science;magnetic resonance imaging;machine learning;computer performance	Vision	35.7481984821999	-78.4001931319165	193043
99849b9aedbf3e7b4f87f2c8bb8886133aba72f1	clinical decision support system for early detection and diagnosis of dementia	qa75 electronic computers computer science;ta engineering general civil engineering general	Dementia is a syndrome caused by a chronic or progressive disease of the brain, which affects memory, orientation, thinking, calculation, learning ability and language. Until recently, early diagnosis of dementia was not a high priority, since the related diseases were considered untreatable and irreversible. However, more effective treatments are becoming available, which can slow the progress of dementia if they are used in the early stages of the disease. Therefore, early diagnosis is becoming more important. The Clock Drawing Test (CDT) and Mini Mental State Examination (MMSE) are well-known cognitive assessment tests. A known obstacle to the wider usage of the CDT assessments is the scoring and interpretation of the results.#R##N#This thesis introduces a novel diagnostic Clinical Decision Support System (CDSS) based on CDT which can help in the diagnosis of three stages of dementia. It also introduces the advanced methods developed for the interpretation and analysis of CDTs. The data used in this research consist of 604 clock drawings produced by dementia patients and healthy individuals. A comprehensive catalogue of 47 visual features within CDT drawings is proposed to enhance the sensitivity of the CDT in diagnosing the early stages of dementia. These features are selected following a comprehensive analysis of the available data and the most common CDT scoring systems reported in the medical literature. These features are used to build a new digitised dataset necessary for training and validating the proposed CDSS.#R##N#In this thesis, a novel feature selection method is proposed for the study of CDT feature significance and to define the most important features in diagnosing dementia.#R##N#iii#R##N#A new framework is also introduced to analyse the temporal changes in the CDT features corresponding to the progress of dementia over time, and to define the first onset symptoms.#R##N#The proposed CDSS is designed to differentiate between four cognitive function statuses: (i) normal; (ii) mild cognitive impairment or mild dementia; (iii) moderate or severe dementia; and (vi) functional. This represents a new application of the CDT, as it was previously used only to detect the positive dementia cases.#R##N#Diagnosing mild cognitive impairment or early stage dementia using CDT as a standalone tool is a very challenging task. To address this, a novel cascade classifier is proposed, which benefits from combining CDT and MMSE to enhance the overall performance of the system.#R##N#The proposed CDSS diagnoses the CDT drawings and places them into one of three cognitive statuses (normal or functional, mild cognitive impairment or mild dementia, and moderate or severe dementia) with an accuracy of 78.34 %. Moreover, the proposed CDSS can distinguish between the normal and the abnormal cases with accuracy of 89.54 %.#R##N#The achieved results are good and outperform most of CDT scoring systems in discriminating between normal and abnormal cases as reported in existing literature. Moreover, the system shows a good performance in diagnosing the CDT drawings into one of the three cognitive statuses, even comparing well with the performance of dementia specialists.#R##N#The research has been granted ethical approval from the South East Wales Research Ethics Committee to employ anonymised copies of clock drawings and copies of Mini Mental State Examination made by patients during their examination by the memory team in Llandough hospital, Cardiff	algorithm;backward induction;binary number;cascading classifiers;case preservation;circular layout;clinical decision support system;cognition;color gradient;discriminative model;displacement mapping;distortion;eclipse;emoticon;feature (computer vision);feature extraction;feature selection;futures studies;handwriting recognition;image processing;information theory;item unique identification;java metadata interface;line–line intersection;multidimensional digital pre-distortion;multistage amplifier;problem solving;progressive scan;relevance;scientific literature;scoring functions for docking;sensor;seven-segment display;stylus (computing);tablet computer;unity;velocity (software development);voice activity detection;web application	Mohamed Bennasar	2014			psychology;psychiatry;developmental psychology;social psychology	ML	30.475576287606483	-78.39356754412015	193247
dd5e2803b604db427fd724a9d8a2dca5d6903a7f	substructure shape analysis for kanji character recognition	look up table;shape analysis;neural net;character recognition	A method towards analytical recognition of Chinese characters is described. Basic character components (substructures) of any size are recognized anywhere on a Kanji string, even if they touch other components. The algorithm performs skeleton extraction, skeleton grouping, indexing of structural features on a previously generated look-up table, structural verification of hypothesis using model graphs, and geometrical verification by an array of neural nets, each one specialized on the geometry of each model. The system retrieves 98 % of substructures with 91% precision rate.	shape analysis (digital geometry)	Jairo Rocha;Hiromichi Fujisawa	1996		10.1007/3-540-61577-6_37	speech recognition;pattern recognition	Vision	34.59351368604942	-66.73781966376538	193267
92230faf59c3ab76eece131f57194bb0a9001a21	manifold population modeling as a neuro-imaging biomarker: application to adni and adni-go	classification;kernel density estimation;laplacian eigenmaps;mild cognitive impairment (mci);sparse regression;alzheimer's disease (ad);manifold learning	We propose a framework for feature extraction from learned low-dimensional subspaces that represent inter-subject variability. The manifold subspace is built from data-driven regions of interest (ROI). The regions are learned via sparse regression using the mini-mental state examination (MMSE) score as an independent variable which correlates better with the actual disease stage than a discrete class label. The sparse regression is used to perform variable selection along with a re-sampling scheme to reduce sampling bias. We then use the learned manifold coordinates to perform visualization and classification of the subjects. Results of the proposed approach are shown using the ADNI and ADNI-GO datasets. Three types of classification techniques, including a new MRI Disease-State-Score (MRI-DSS) classifier, are tested in conjunction with two learning strategies. In the first case Alzheimer's Disease (AD) and progressive mild cognitive impairment (pMCI) subjects were grouped together, while cognitive normal (CN) and stable mild cognitive impaired (sMCI) subjects were also grouped together. In the second approach, the classifiers are learned using the original class labels (with no grouping). We show results that are comparable to other state-of-the-art methods. A classification rate of 71%, of arguably the most clinically relevant subjects, sMCI and pMCI, is shown. Additionally, we present classification accuracies between CN and early MCI (eMCI) subjects, from the ADNI-GO dataset, of 65%. To our knowledge this is the first time classification accuracies for eMCI patients have been reported.	alzheimer's disease;biological markers;classification;cognition disorders;cognitive science;feature extraction;feature selection;imagery;mental disorders;mental state;patients;population model;region of interest;sampling (signal processing);sampling - surgical action;silo (dataset);sparse matrix;spatial variability;manifold	Ricardo Guerrero;Robin Wolz;A. W. Rao;Daniel Rueckert	2014	NeuroImage	10.1016/j.neuroimage.2014.03.036	mild cognitive impairment (mci);kernel density estimation;feature extraction;regression;feature selection;artificial intelligence;nonlinear dimensionality reduction;machine learning;classifier (linguistics);pattern recognition;population;computer science	ML	24.97814007394887	-78.12102832000353	193350
1f8564d458f2e36f5d1ad756c4a92485e45cf7ff	retinal vessel segmentation via deep learning network and fully-connected conditional random fields	image segmentation retinal vessels computer architecture machine learning neural networks pathology;conditional random fields;retinal vessel segmentation stare dataset drive dataset binary vessel segmentation fully connected conditional random fields fundus image pathological region vessel probability map convolutional neural networks boundary detection deep learning network;convolutional neural networks vessel segmentation conditional random fields;vessel segmentation;convolutional neural networks;neural nets blood vessels eye image segmentation medical image processing	Vessel segmentation is a key step for various medical applications. This paper introduces the deep learning architecture to improve the performance of retinal vessel segmentation. Deep learning architecture has been demonstrated having the powerful ability in automatically learning the rich hierarchical representations. In this paper, we formulate the vessel segmentation to a boundary detection problem, and utilize the fully convolutional neural networks (CNNs) to generate a vessel probability map. Our vessel probability map distinguishes the vessels and background in the inadequate contrast region, and has robustness to the pathological regions in the fundus image. Moreover, a fully-connected Conditional Random Fields (CRFs) is also employed to combine the discriminative vessel probability map and long-range interactions between pixels. Finally, a binary vessel segmentation result is obtained by our method. We show that our proposed method achieve a state-of-the-art vessel segmentation performance on the DRIVE and STARE datasets.	artificial neural network;conditional random field;convolutional neural network;deep learning;feature learning;interaction;pixel	Huazhu Fu;Yanwu Xu;Damon Wing Kee Wong;Jiang Liu	2016	2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2016.7493362	computer vision;computer science;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;convolutional neural network;scale-space segmentation;conditional random field	Vision	31.950541084044243	-75.00509615094725	193422
2708333b3edd02761a3d215caab834fd0e65791d	active relearning for robust supervised classification of pulmonary emphysema	radiology;emphysema;supervised classification;lung;feedback;medical diagnostics;active relearning;diagnostics;svm;hrct;chest	Radiologists are adept at recognizing the appearance of lung parenchymal abnormalities in CT scans. However, the inconsistent differential diagnosis, due to subjective aggregation, mandates supervised classification. Towards optimizing Emphysema classification, we introduce a physician-in-the-loop feedback approach in order to minimize uncertainty in the selected training samples. Using multi-view inductive learning with the training samples, an ensemble of Support Vector Machine (SVM) models, each based on a specific pair-wise dissimilarity metric, was constructed in less than six seconds. In the active relearning phase, the ensemble-expert label conflicts were resolved by an expert. This just-in-time feedback with unoptimized SVMs yielded 15% increase in classification accuracy and 25% reduction in the number of support vectors. The generality of relearning was assessed in the optimized parameter space of six different classifiers across seven dissimilarity metrics. The resultant average accuracy improved to 21%. The co-operative feedback method proposed here could enhance both diagnostic and staging throughput efficiency in chest radiology practice.© (2012) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	machine learning;supervised learning	Sushravya Raghunath;Srinivasan Rajagopalan;Ronald A. Karwoski;Brian J. Bartholmai;Richard A. Robb	2012		10.1117/12.911648	support vector machine;simulation;speech recognition;machine learning;feedback	ML	30.875799123075925	-78.86132802271189	193553
c8f41f77bf4c73502e3b28a9bb7f87ad23f7873a	a classification performance measure considering the degree of classification difficulty	performance evaluation;auc;roc curves;classification difficulty;classification models	In the field of classification, classification difficulty of instances is one of vital factors that influence the performance of classifiers, however it has been totally neglected. In this paper, a new performance measure for classification algorithms based on Receiver Operator Characteristic (ROC) curves is proposed with the ability of incorporating the information of difficulty. First, a new ROC curve with the information two-dimensional graph, on which weighted true positive rate is plotted on Y-axis and weighted false positive rate is plotted on X-axis. The weights of true positive rates are proportional to classification difficulty index, while those of false positive rates are inversely proportional to classification difficulty index. Then, the Area Under diROC Curves, or simply diAUC, is defined to represent the performance of classifiers quantitatively. We test the diROC curves and diAUC on real-word datasets, the experimental results suggest that they are insensitive to changes in class distribution, and superior to traditional ROC curves and AUC in terms of discrimination. & 2016 Elsevier B.V. All rights reserved.	algorithm;apache axis;coefficient;data mining;image fusion;image quality;receiver operating characteristic;sensitivity and specificity;statistical classification;two-dimensional graph;verse protocol	Xiaoli Zhang;Xiongfei Li;Yuncong Feng	2016	Neurocomputing	10.1016/j.neucom.2016.02.001	computer science;machine learning;pattern recognition;mathematics;receiver operating characteristic;statistics	ML	34.06750265100323	-72.18630069934501	193893
2c3dd7fddd1bdcdce9642a6bec78b12aa8ee2dd2	mask editor : an image annotation tool for image segmentation tasks		Deep convolutional neural network (DCNN) is the state-of-the-art method for image segmentation, which is one of key challenging computer vision tasks. However, DCNN requires a lot of training images with corresponding image masks to get a good segmentation result. Image annotation software which is easy to use and allows fast image mask generation is in great demand. To the best of our knowledge, all existing image annotation software support only drawing bounding polygons, bounding boxes, or bounding ellipses to mark target objects. These existing software are inefficient when targeting objects that have irregular shapes (e.g., defects in fabric images or tire images). In this paper we design an easy-to-use image annotation software called Mask Editor for image mask generation. Mask Editor allows drawing any bounding curve to mark objects and improves efficiency to mark objects with irregular shapes. Mask Editor also supports drawing bounding polygons, drawing bounding boxes, drawing bounding ellipses, painting, erasing, super-pixel-marking, image cropping, multi-class masks, mask loading, and mask modifying. Keywords—Image segmentation; defect detection; multi-class mask, deep learning; neural network	artificial neural network;automatic image annotation;image segmentation;item unique identification;mask (computing);mask data preparation;pixel;software bug	Chuanhai Zhang;Kurt Loken;Zhiyu Chen;Zhiyong Xiao;Gary Kunkel	2018	CoRR		automatic image annotation;pattern recognition;convolutional neural network;image segmentation;polygon;cropping;software;artificial intelligence;computer science	Vision	37.404907918090856	-66.79287210007858	193953
d25b6ce18e4c62e5cdbb7f8a6b0e34acb7d37557	mammography assessment using multi-scale deep classifiers		Applying deep learning methods to mammography assessment has remained a challenging topic. Dense noise with sparse expressions, mega-pixel raw data resolution, lack of diverse examples have all been factors aecting performance. e lack of pixel-level ground truths have especially limited segmentation methods in pushing beyond approximately bounding regions. We propose a classication approach grounded in high performance tissue assessment as an alternative to all-in-one localization and assessment models that is also capable of pinpointing the causal pixels. First, the objective of the mammography assessment task is formalized in the context of local tissue classiers. en, the accuracy of a convolutional neural net is evaluated on classifying patches of tissue with suspicious ndings at varying scales, where highest obtained AUC is above 0.9. e local evaluations of one such expert tissue classier is used to augment the results of a heatmap regression model and additionally recover the exact causal regions at high resolution as a saliency image suitable for clinical seings.	artificial neural network;baseline (configuration management);casp;causal filter;deep learning;heat map;image resolution;multi-function printer;pixel;sparse matrix	Ulzee An;Khader Shameer;Lakshminarayanan Subramanian	2018	CoRR		pixel;raw data;deep learning;computer science;regression analysis;pattern recognition;artificial neural network;machine learning;artificial intelligence;salience (neuroscience);mammography;expression (mathematics)	ML	30.625374472343342	-76.4799812782824	194112
28b7a1a18638b0b1fc70ad0f3d6955c369f18e0a	automatic selection of binarization method for robust ocr	binarization techniques;automatic generation of training data;evaluation automatic algorithm selection binarization techniques machine learning automatic generation of training data;optical character recognition;optical character recognition document image processing learning artificial intelligence;optical character recognition software training image segmentation algorithm design and analysis accuracy machine learning algorithms prediction algorithms;automatic algorithm selection;machine learning;icdar 2003 robust reading data set binarization method automatic selection robust ocr document image analysis dia machine learning approach;document image processing;evaluation;learning artificial intelligence	Many algorithms are now available for doing the same task (e.g. binarization, page segmentation, character recognition, etc.) in document image analysis (DIA) and choosing a particular algorithm(s) for a particular task is often a non-trivial problem. This paper proposes a model for automatically selecting the correct algorithm(s) for a given problem. Binarization has been taken a reference to illustrate the proposed approach. Several previously unexplored issues are addressed in this work. For example, only one method may not be good for the binarization of an entire document whereas a particular method may produce desired result for a particular region. Therefore, for a given document image, our model selects a set of one or more binarization techniques suitable for different regions of the document. This selection is completely automatic and guided by the machine learning approaches. Formulation of a completely automatic way for generating the annotated data for training the learning algorithms is also a novel contribution of this work. Evaluation of the approach is done using ICDAR 2003 Robust Reading data set and results highlight the potential of the proposed approach for automatic selection of correct DIA algorithm(s) from a set of several alternatives.	algorithm;binary image;image analysis;international conference on document analysis and recognition;machine learning;optical character recognition	Tanushyam Chattopadhyay;V. Ramu Reddy;Utpal Garain	2013	2013 12th International Conference on Document Analysis and Recognition	10.1109/ICDAR.2013.237	computer vision;speech recognition;computer science;evaluation;machine learning;pattern recognition;optical character recognition	Vision	31.198759964867183	-66.75508147583369	194198
8d75173f78ae4dbcdb65fe0eead822dcb71526c0	automatic polyp frame screening using patch based combined feature and dictionary learning	colonoscopy;computer-aided detection;dictionary learning;polyp classification;shape and color feature;sparse coding	Polyps in the colon can potentially become malignant cancer tissues where early detection and removal lead to high survival rate. Certain types of polyps can be difficult to detect even for highly trained physicians. Inspired by aforementioned problem our study aims to improve the human detection performance by developing an automatic polyp screening framework as a decision support tool. We use a small image patch based combined feature method. Features include shape and color information and are extracted using histogram of oriented gradient and hue histogram methods. Dictionary learning based training is used to learn features and final feature vector is formed using sparse coding. For classification, we use patch image classification based on linear support vector machine and whole image thresholding. The proposed framework is evaluated using three public polyp databases. Our experimental results show that the proposed scheme successfully classified polyps and normal images with over 95% of classification accuracy, sensitivity, specificity and precision. In addition, we compare performance of the proposed scheme with conventional feature based methods and the convolutional neural network (CNN) based deep learning approach which is the state of the art technique in many image classification applications.	artificial neural network;biological neural networks;body tissue;colon classification;computer vision;convolutional neural network;database;decision support systems, clinical;decision support system;deep learning;dictionary;early diagnosis;extraction;feature vector;gradient;histogram;machine learning;neural coding;sensitivity and specificity;sparse matrix;support vector machine;thresholding (image processing);polyps	Younghak Shin;Ilangko Balasingham	2018	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2018.08.001	computer vision;support vector machine;convolutional neural network;feature vector;deep learning;thresholding;histogram;contextual image classification;neural coding;medicine;artificial intelligence	Vision	33.47468971339246	-75.22999787332668	194396
c8ae5f4eda2d1ac4e0051bcf198d3682b53dd78b	hippocampus segmentation and spharm coefficient selection are decisive for mci detection		Spherical Harmonics (SPHARM), when computed from hippocampus segmentation, have been shown to be useful features for discriminatingMCI affected patients from healthy controls. In this paper we assess the impact (i) of using different hippocampus segmentation techniques, among them three out-of-the-box automated segmentation tools and three human raters with different qualification, and (ii) of applying different strategies which SPHARM coefficients to submit to SVM-based two-class classification. We find that both choices are crucial for successful classification.	coefficient	Andreas Uhl;Michael Liedlgruber;Kevin Butz;Yvonne Höller;Georgi Kuchukhidze;Alexandra Taylor;A. Thomschewski;Ottavio Tomasi;Eugen Trinka	2018		10.1007/978-3-662-56537-7_65	spherical harmonics;support vector machine;hippocampus;segmentation;pattern recognition;artificial intelligence;mathematics	Vision	31.888022253050558	-78.25136633108681	194548
3c328b247c6534fe56e2157e9db0d6e1d3383040	automatic screening of bladder cells for cancer diagnosis	medical image processing cancer image classification;cancer bladder microscopy tiles fluorescence dna image analysis computer science classification algorithms testing;support vector machines;cancer;supervised classification;image classification;microscopy;supervised classification automatic screening bladder cells cancer diagnosis morphological screening slide scanning cells detection morphological analysis;biological cells microscopy;biological cells;bladder;medical image processing;cancer diagnosis;morphological analysis;ground truth;humans;tiles;fluorescent in situ hybridization;cells biology	This paper presents an automatic system for morphological screening of the bladder cells. This system is intended to increase efficiency of the subsequent fluorescence in situ hybridization examination by limiting the number of suspicious cells. The system works in two major phases. The first phase is slide scanning. The second stage includes cells detection and morphological analysis. Both stages refine their results using supervised classification algorithm. The developed method was tested on nine microscopical slides, containing more than 12000 manually labeled cells. The results provided by the system were compared to the ground truth labeled by a human expert.	algorithm;ground truth;machine learning;slide rule;supervised learning	Grigory Begelman;Ehud Rivlin	2009	2009 16th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2009.5414076	support vector machine;computer vision;contextual image classification;ground truth;morphological analysis;computer science;bioinformatics;microscopy;machine learning;cancer	Robotics	36.298725282407624	-75.38188687876273	194612
619d215c2e80eedcc5a65c00fdcf5852f9cdedf8	feature selection and classification of imbalanced datasets: application to pet images of children with autistic spectrum disorders	classification algorithm;social interaction;generic algorithm;dimension reduction;multivariate classification;autism spectrum disorder;autism;treatment response;general methods;distribution pattern;brain imaging;feature selection;high dimension;functional brain imaging;superior temporal sulcus	Learning with discriminative methods is generally based on minimizing the misclassification of training samples, which may be unsuitable for imbalanced datasets where the recognition might be biased in favor of the most numerous class. This problem can be addressed with a generative approach, which typically requires more parameters to be determined leading to reduced performances in high dimension. In such situations, dimension reduction becomes a crucial issue. We propose a feature selection/classification algorithm based on generative methods in order to predict the clinical status of a highly imbalanced dataset made of PET scans of forty-five low-functioning children with autism spectrum disorders (ASD) and thirteen non-ASD low functioning children. ASDs are typically characterized by impaired social interaction, narrow interests, and repetitive behaviors, with a high variability in expression and severity. The numerous findings revealed by brain imaging studies suggest that ASD is associated with a complex and distributed pattern of abnormalities that makes the identification of a shared and common neuroimaging profile a difficult task. In this context, our goal is to identify the rest functional brain imaging abnormalities pattern associated with ASD and to validate its efficiency in individual classification. The proposed feature selection algorithm detected a characteristic pattern in the ASD group that included a hypoperfusion in the right Superior Temporal Sulcus (STS) and a hyperperfusion in the contralateral postcentral area. Our algorithm allowed for a significantly accurate (88%), sensitive (91%) and specific (77%) prediction of clinical category. For this imbalanced dataset, with only 13 control scans, the proposed generative algorithm outperformed other state-of-the-art discriminant methods. The high predictive power of the characteristic pattern, which has been automatically identified on whole brains without any priors, confirms previous findings concerning the role of STS in ASD. This work offers exciting possibilities for early autism detection and/or the evaluation of treatment response in individual patients.	anterior descending branch of left coronary artery;apply;autism spectrum disorders;autistic disorder;behavior;brain;computation;congenital abnormality;cross reactions;cross-validation (statistics);dimensionality reduction;discriminant;emoticon;epilepsy, temporal lobe;feature extraction;feature selection;hardware random number generator;heart rate variability;lasso;local-density approximation;lucas–lehmer–riesel test;medical imaging;mental disorders;model selection;multimodal interaction;neuroimaging;occam's razor;p-value;patients;penalty method;performance;polyethylene terephthalate;positron-emission tomography;selection algorithm;silo (dataset);sixty nine;social communication disorder;statistical classification;structure of superior temporal sulcus;hypoperfusion;interest	Edouard Duchesnay;Arnaud Cachia;Nathalie Boddaert;Nadia Chabane;Jean-Francois Mangin;Jean-Luc Martinot;Francis Brunelle;Monica Zilbovicius	2011	NeuroImage	10.1016/j.neuroimage.2011.05.011	psychology;autism;artificial intelligence;machine learning;pattern recognition;feature selection	ML	25.00349206148657	-78.26487645789177	194825
7141d40abee644a249d0ba3b9feff97c2686da5e	robustness evaluation of a computer-aided detection system for pulmonary embolism (pe) in ctpa using independent test set from multiple institutions	pulmonary arteries;image segmentation;performance evaluation;computer aided diagnosis;photoemission spectroscopy;receivers;angiography;computer aided detection;feature selection;vessel segmentation;false positive reduction	We have developed a computer-aided detection (CAD) system for assisting radiologists in detection of pulmonary embolism (PE) in computed tomographic pulmonary angiographic (CTPA) images. The CAD system includes stages of pulmonary vessel segmentation, prescreening of PE candidates and false positive (FP) reduction to identify suspicious PEs. The system was trained with 59 CTPA PE cases collected retrospectively from our patient files (UM set) with IRB approval. Five feature groups containing 139 features that characterized the intensity texture, gradient, intensity homogeneity, shape, and topology of PE candidates were initially extracted. Stepwise feature selection guided by simplex optimization was used to select effective features for FP reduction. A linear discriminant analysis (LDA) classifier was formulated to differentiate true PEs from FPs. The purpose of this study is to evaluate the performance of our CAD system using an independent test set of CTPA cases. The test set consists of 50 PE cases from the PIOPED II data set collected by multiple institutions with access permission. A total of 537 PEs were manually marked by experienced thoracic radiologists as reference standard for the test set. The detection performance was evaluated by freeresponse receiver operating characteristic (FROC) analysis. The FP classifier obtained a test Az value of 0.847 and the FROC analysis indicated that the CAD system achieved an overall sensitivity of 80% at 8.6 FPs/case for the PIOPED test set. © (2015) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	ct pulmonary angiogram;test set	Chuan Zhou;Heang-Ping Chan;Aamer Chughtai;Jean W. Kuriakose;Ella A. Kazerooni;Lubomir M. Hadjiiski;Jun Wei;Smita Patel	2015		10.1117/12.2082015	photoemission spectroscopy;simulation;image segmentation;feature selection	EDA	35.56377885806602	-77.46975199694712	194896
64d0f38ea578a023f64bdeded1440d39c9872594	detection of gastric cancer risk from x-ray images via patch-based convolutional neural network		This paper presents a novel detection method of gastric cancer risk from X-ray images using the patch-based Convolutional Neural Network (CNN). Our method enables the training of the patch-based CNN which can accurately detect gastric cancer risk even though there is only the image-level ground truth. Furthermore, the proposed method can extract a feature vector that can represent the whole of symptoms associated with the presence or absence of the risk. Specifically, the proposed method selects the patches related to their true risk via the CNN, and it is the most innovative contribution of our method. Moreover, we extract the feature vector by applying the Bag-of-Feature representation to the output values from the CNN's intermediate layer obtained from the selected patches. Finally, the detection of gastric cancer risk is performed by inputting the extracted feature vector into Support Vector Machine. Experimental results confirm that the proposed method outperforms a previously reported method that combines the detection results obtained from X-ray images taken from multiple angles even though the proposed method only uses an X-ray image taken from a single angle, and we can achieve a higher performance than that of doctors.	artificial neural network;convolutional neural network;feature vector;ground truth;patch (computing);radiography;support vector machine	Kenta Ishihara;Takahiro Ogawa;Miki Haseyama	2017	2017 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2017.8296643	computer vision;support vector machine;convolutional neural network;feature vector;artificial intelligence;feature extraction;pattern recognition;computer science;ground truth	Vision	33.06731285962758	-75.47464655532474	194916
72c6d8a06fe5dd903a103b5fb731b2f75d6ca3a2	computer-aided detection and characterization of hyperparathyroidism in digital hand radiographs	radiology;subperiosteal resorption;computer aided diagnosis;hospitals;mean square;power spectrum;digitized hand radiographs;computer aided diagnosis system;secondary hyperparathyroidism;radiologists computer algorithm subperiosteal resorption digitized hand radiographs hyperparathyroidism bony resorption radial phalangeal margins model guided boundary tracking scheme mean square variation power spectrum computer aided diagnosis system;bones;radial phalangeal margins;biomedical engineering;medical image processing;hyperparathyroidism;fingers;diseases;radiologists;computer aided detection;computer algorithm;model guided boundary tracking scheme;power system modeling;optical materials;bony resorption;mean square variation;diagnostic radiography;diseases fingers radiology bones biomedical engineering hospitals diagnostic radiography power system modeling computer aided diagnosis optical materials;medical image processing diagnostic radiography	Subperiosteal bony resorption involving the hands is both a sensitive and specific manifestation of secondary hyperparathyroidism. Our computer method can quantify the severity of bony resorption by analyzing the roughness of the radial phalangeal margins as projected on !he hand radiographs. This margin is detected by a model-guided boundary-tracking scheme, and its roughness quantified by the mean-square Variation and the first moment of the power spectrum. The computer-aided diagnosis system is both accurate and not subject to either intraor inter-observer variations.	radial (radio);radial basis function;radiography;spectral density	Chair-Li Chang;Heang-Ping Chan;Loren Niklason;Jeffery Crabbe;John Mathews;Mark Cobby;Ronald S. Adler	1992		10.1109/CBMS.1992.245001	radiology;pathology;spectral density;statistics	EDA	36.571655728301266	-78.1355675176163	194935
18427bd66abfdc334c6b86524f350e4919098333	intelligent feature selection for regions of interest identification in retinal images	optical imaging adaptive optics feature extraction image color analysis hemorrhaging algorithm design and analysis optical scattering;hemorrhaging;optical imaging;intelligent feature selection sliding box techniques fixed box techniques confusion matrices voting scheme feature classification feature detection fractal features textural features statistical features retinal images;optical scattering;image color analysis;feature extraction;retinal recognition feature selection image classification matrix algebra;algorithm design and analysis;adaptive optics	In this paper we developed an intelligent method for the selection of statistical, textural and fractal features that characterize different regions of interest in eye-fundus images. Because the regions like optic disc, macula, exudates and hemorrhages are difficult to detect, an intelligent scheme for feature detection and classification is necessary. The method is based on a voting scheme that takes into account the values on the main diagonal of different confusion matrices. These matrices are generated based on clusters from sorted data-sets of feature values. Both the sliding box and fixed box techniques where used to divide the image into patches, in order to highlight the regions of interest and to obtain the unique signature of features for each of them. Two algorithms are proposed, one for the intelligent selection of features and the second for the testing of the accuracy of selected features. The results obtained on 100 test images proved the efficiency of the proposed method compared to other algorithms.	algorithm;antivirus software;cluster analysis;confusion matrix;feature detection (computer vision);feature detection (web development);feature selection;fractal;region of interest	Loretta Ichim;Traian Caramihale;Dan Popescu	2016	2016 IEEE 11th International Symposium on Applied Computational Intelligence and Informatics (SACI)	10.1109/SACI.2016.7507392	algorithm design;computer vision;feature detection;feature extraction;computer science;machine learning;pattern recognition;optical imaging;mathematics;light scattering;adaptive optics;feature	Vision	36.081966792277704	-72.42520719255798	194938
440077531e82e242f0c788319365f8b67fb81497	tongue image identification system on congestion of fungiform papillae (cfp)	bayesian network;traditional chinese medicine;texture features;gabor filter;gabor filter banks;region of interest;tongue texture;experience base;congestion of fungiform papillae cfp;diagnostic method	Tongue diagnosis is a unique and important diagnostic method in Traditional Chinese Medicine (TCM). It is used to observe abnormal changes in the tongue for identifying diseases. However, due to its qualitative, subjective and experience-based nature, traditional tongue diagnosis has very limited applications in clinical medicine. To date, no work has sought to automatically recognize a distinctive diagnostic and textural feature of the tongue, Congestion of Fungiform Papillae (CFP) on the middle of tongue surface. In this paper, we present a novel computerized tongue inspection system for identifying the presence or absence of CFP images. We first define and partition a region of interest (ROI) for texture acquisition. After preprocessing for reflective points, we apply the Gabor filter banks and Bayesian Network to identify the texture blocks. Finally, a fusion strategy is employed to model the relationship between the image classes and the presence of CFP. The results are promising.	computers, freedom and privacy conference;network congestion	Bo Huang;Naimin Li	2010		10.1007/978-3-642-13923-9_8	computer vision;speech recognition;engineering;communication	Vision	35.827597210884846	-76.72702963133908	195019
b43f39cece102414655c5d7f53d233d87fec0e81	superpixel-based classification of occlusal caries photography		Segmentation using superpixels of simple photographic image for classification of occlusal caries according to the lesion severity, makes significant changes to the way experts annotate the image, but also in the way of learning and evaluating of an automatic classifier. Working on an extension of the lower part of the 6-class ICDAS (International Caries Detection and Assessment System) scale, we are building a classifier exhibiting very low Random Forests OOB (Out-Of-Bag) Error estimation, without performing any image enhancement or morphological operation techniques. We also demonstrate the robustness of the classifier's performance over the size of superpixels by introducing a shrinking factor in the model's learning phase. Finally we highlight the complications to evaluate the models performance through the cross-validation procedure, arising from the class inequalities as distributed across the limited image dataset.		Konstantinos Moutselos;Elias D. Berdouses;Constantine J. Oulis;Ilias Maglogiannis	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451373	occlusal caries;robustness (computer science);computer vision;image segmentation;pattern recognition;artificial intelligence;classifier (linguistics);random forest;computer science;segmentation;photography	Vision	36.98511238939807	-73.66989381432036	195059
56a61a07f0974116f086713cc1c15cb624293cfb	analysis of dermatoses using segmentation and color hue in reference to skin lesions		In dermatology there are several well known algorithms of melanocytic lesions recognition but there are not automated algorithms of skin lesion identification and classification. The main aim of this paper is to examine skin changes based on the skin analysis in the chosen model color spaces. With the help of that analysis, the authors show how to extract information from the skin images that will be useful for a future dermatology expert system. In the paper, the authors introduce a novel clinical feature extraction and segmentation method based on modified dermatologists’ approach to diagnose skin lesions. We have also prepared a database (DermDB) of dermoscopic images with the reference data prepared and validated by expert dermatologists.		Lukasz Was;Piotr Milczarski;Zofia Stawska;Marcin Wyczechowski;Marek Kot;Slawomir Wiak;Anna Wozniacka;Lukasz Pietrzak	2017		10.1007/978-3-319-59063-9_61	computer science;artificial intelligence;pattern recognition;hue;feature extraction;principal component analysis;expert system;reference data (financial markets);color space;segmentation;lesion identification	Vision	35.32022008498518	-74.64137018669847	195095
9314e5dea57d05336c7e676026a658f745b2cd2b	fully automatic finger extensor tendon segmentation in ultrasound images of the metacarpophalangeal joint		In this work a fully automatic system to identify the extensor tendon on ultrasound images of the metacarpophalangeal joint is proposed. These images are used to diagnose rheumatic diseases which are one of the main causes of impairment and pain in developed countries. The early diagnosis of these conditions is crucial to a proper treatment and follow-up and so, a system such as the one proposed here, could be useful to automatically extract relevant information from the resulting images. This work is an extension of a previous published work which uses manual annotations of the skin line, metacarpus and phalange to guide the extensor tendon segmentation. By introducing automatic segmentations of all structures, we expect to create a fully automatic system, which is more interesting to the possible end-users. Results show that, despite an expected loss in the performance, it is still possible to correctly identify the extensor tendon with a Confidence of 88% considering a maximum allowed Modified Hausdorff Distance of 0.5mm.	follow-up report;hausdorff dimension;metacarpophalangeal joint structure;pain;phalanx of hand;rheumatism;scientific publication;structure of extensor tendon;temporomandibular joint disorders;tendon structure;tendon-driven robot;biologic segmentation	Nelson Martins;Malik Saad Sultan;Diana Veiga;Manuel Ferreira;Miguel Coimbra	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8512969	computer vision;hausdorff distance;tendon;metacarpophalangeal joint;image segmentation;ultrasound;artificial intelligence;metacarpus;computer science;segmentation	Vision	36.945018674558206	-79.29519522426698	195102
f369a49f184b5fc4727bbf2f28cd5e80a80a63b5	modified backpropagation algorithm for polycystic ovary syndrome detection based on ultrasound images		Polycystic Ovary Syndrome (PCOS) is an endocrine abnormality that occurred in the female reproductive cycle. In general, the approaches to detect PCO follicles are (1) stereology and (2) feature extraction and classification. In Stereology, two-dimensional images are viewed as projections of three-dimensional objects. In this paper, we use the second approach, namely Gabor Wavelet as a feature extractor and a modified backpropagation as a classifier. The modification of backpropagation algorithm which is proposed, namely Levenberg Marquardt optimization and Conjugate Gradient Fletcher Reeves to improve the convergence rate. Levenberg Marquardt optimization produce the higher accuracy than Conjugate Gradient Fletcher Reeves, but it has a drawback of running time. The best accuracy of Levenberg Marquardt is 93.925% which is gained from 33 neurons and 16 vector feature and Conjugate Gradient Fletcher Reeves is 87.85% from 13 neurons and 16 vector feature.	backpropagation;carpal tunnel syndrome;conjugate gradient method;convex conjugate;experiment;feature extraction;fletcher's checksum;gabor wavelet;levenberg–marquardt algorithm;mathematical optimization;neuron;randomness extractor;rate of convergence;time complexity	Untari N. Wisesty;Jondri Nasri;Adiwijaya	2016		10.1007/978-3-319-51281-5_15	rate of convergence;machine learning;gabor wavelet;artificial neural network;feature extraction;artificial intelligence;conjugate gradient method;computer science;backpropagation;stereology;levenberg–marquardt algorithm	ML	32.862095749072765	-73.16218577378041	195149
9da3ade53bf91556fe46828b216aab20a4e72294	snc neuron detection method based on deep learning for efficacy evaluation of anti-pd drugs		The development of anti-PD drugs research, as well as the efficacy evaluation, have fundamental significance in treating PD (Parkinsonu0027s Disease). At present, the number of neurons in SNc (substantia nigra compacta) of the PD model animal has been proved one of the most important indexes to evaluate the efficacy of anti-PD drugs. Due to variable fluorescence, background noises, easily confused regions, weak boundaries of neurons, variations in neurons size and shape, digital pathological image analysis still remains a challenging task. This paper constructed a PD animal modelsu0027 brain slices database. Additionally, a Faster-RCNN-based SNc localization method and CNN-LSTM-based neuron automatic detection method are utilized to analyze the digital pathological image. The results can provide reliable data support for the evaluation of anti-PD drugsu0027 efficacy, which can also demonstrate that the intelligent analysis method based on deep learning has reached effective results in the dataset, with the accuracy rate achieves 95%.	algorithm;deep learning;image analysis;long short-term memory;neuron	Shuxin Zhao;Kaijie Wu;Chaochen Gu;Xiaoping P. Pu;Xin-Ping Guan	2018	2018 Annual American Control Conference (ACC)	10.23919/ACC.2018.8431470	neuroscience;control engineering;object detection;substantia nigra compacta;computer science;feature extraction;deep learning;neuron;artificial intelligence	Vision	32.79879468851092	-76.78885844822219	195359
c3dc17c268487be4d4e14165026312f3d79a5809	neural-based iterative approach for iris detection in iris recognition systems	iterative refinement;image segmentation;neural networks;iterative algorithms;operant conditioning;iris detection approach iterative approach trained neural network iris recognition biometric system;trained neural network;helium;image converters;computational intelligence;training;iris recognition;iterative methods iris recognition neural networks iterative algorithms image segmentation helium feature extraction computational intelligence security image converters;data mining;iterative methods;accuracy;artificial neural networks;estimation;feature extraction;region of interest;pixel;learning artificial intelligence;iris recognition biometric system;iris;security;iterative approach;iris detection approach;neural network;learning artificial intelligence iris recognition	The detection of the iris boundaries is considered in the literature as one of the most critical steps in the identification task of the iris recognition systems. In this paper we present an iterative approach to the detection of the iris center and boundaries by using neural networks. The proposed algorithm starts by an initial random point in the input image, then it processes a set of local image properties in a circular region of interest searching for the peculiar transition patterns of the iris boundaries. A trained neural network processes the parameters associated to the extracted boundaries and it estimates the offsets in the vertical and horizontal axis with respect to the estimated center. The coordinates of the starting point are then updated with the processed offsets. The steps are then iterated for a fixed number of epochs, producing an iterative refinements of the coordinates of the pupils center and its boundaries. Experiments showed that the method is feasible and it can be exploited even in non-ideal operative condition of iris recognition biometric systems.	algorithm;artificial neural network;biometrics;displacement mapping;epoch (reference date);experiment;iris recognition;iteration;iterative method;optic axis of a crystal;region of interest	Ruggero Donida Labati;Vincenzo Piuri;Fabio Scotti	2009	2009 IEEE Symposium on Computational Intelligence for Security and Defense Applications	10.1109/CISDA.2009.5356533	computer vision;estimation;feature extraction;computer science;artificial intelligence;machine learning;operant conditioning;pattern recognition;iris recognition;accuracy and precision;iterative method;image segmentation;helium;artificial neural network;pixel;region of interest	Vision	39.15373934570697	-68.42145670317683	195694
af3f24f40cf2a18864142cab418359050d1ee3aa	study on identification system of maize seedsvarieties based on machine vision	maize;image processing;geometric feature;machine vision;feature extraction	This paper systematically studies maize seeds varieties identification technology and algorithms using advanced machine vision technology. A multi-object contour extraction algorithm adapting to maize seeds varieties identification was proposed. Geometric features and color features parameters of maize seeds were defined and analyzed, and a multi-object geometric features and color features extraction algorithm is realized. Maize seeds image processing strategies and varieties identification algorithms, which is based on the machine vision, is optimized. The precision and speed of maize seeds varieties identification is improved. Through maize seeds varieties identification test on four species including Nongda 108, Ludan 981 and Zhengdan 958, identification accuracy is more than 95%.	algorithm;feature extraction;image processing;machine vision;seeds (cellular automaton)	Xianxi Liu;Yuliang Wang;Qingtang Su;Zhaona Wang	2008		10.1007/978-1-4419-0213-9_72	computer vision;feature extraction;machine learning;pattern recognition;feature	Robotics	37.27696549485755	-67.86234069376704	195696
c8a706aa439548bdc1488a307b4a4bf88a6d6c47	supervised discriminative eeg brain source imaging with graph regularization		As Electroencephalography (EEG) is a non-invasive brain imaging technique that records the electric field on the scalp instead of direct measuring activities of brain voxels on the cortex, many approaches were proposed to estimate the activated sources due to its significance in neuroscience research and clinical applications. However, since most part of the brain activity is composed of the spontaneous neural activities or non-task related activations, true task relevant activation sources can be very challenging to be discovered given strong background signals. For decades, the EEG source imaging problem was solved in an unsupervised way without taking into consideration the label information that representing different brain states (e.g. happiness, sadness, and surprise). A novel model for solving EEG inverse problem called Graph Regularized Discriminative Source Imaging (GRDSI) was proposed, which aims to explicitly extract the discriminative sources by implicitly coding the label information into the graph regularization term. The proposed model is capable of estimating the discriminative brain sources under different brain states and encouraging intra-class consistency. Simulation results show the effectiveness of our proposed framework in retrieving the discriminative sources.	discriminative model;electroencephalography;sadness;search algorithm;simulation;spontaneous order;unsupervised learning;voxel	Feng Liu;Rahilsadat Hosseini;Jay Rosenberger;Shouyi Wang;Jianzhong Su	2017		10.1007/978-3-319-66182-7_57	artificial intelligence;voxel;computer science;brain activity and meditation;pattern recognition;coding (social sciences);discriminative model;electroencephalography;sparse approximation;inverse problem;speech recognition;neuroimaging	ML	24.93338456149476	-73.65666327794003	195859
e41a1c8165e84d576b34e06b7941f0dfde479cf7	seednet: automatic seed generation with deep reinforcement learning for robust interactive segmentation		In this paper, we propose an automatic seed generation technique with deep reinforcement learning to solve the interactive segmentation problem. One of the main issues of the interactive segmentation problem is robust and consistent object extraction with less human effort. Most of the existing algorithms highly depend on the distribution of inputs, which differs from one user to another and hence need sequential user interactions to achieve adequate performance. In our system, when a user first specifies a point on the desired object and a point in the background, a sequence of artificial user input is automatically generated for precisely segmenting the desired object. The proposed system allows the user to reduce the number of input significantly. This problem is difficult to cast as a supervised learning problem because it is not possible to define globally optimal user input at some stage of the interactive segmentation task. Hence, we formulate automatic seed generation problem as Markov Decision Process (MDP) and then optimize it by reinforcement learning with Deep Q-Network (DQN). We train our network on the MSRA10K dataset and show that the network achieves notable performance improvement from inaccurate initial segmentation on both seen and unseen datasets.		Gwangmo Song;Heesoo Myeong;Kyoung Mu Lee	2018	2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2018.00189	market segmentation;task analysis;supervised learning;artificial intelligence;performance improvement;reinforcement learning;pattern recognition;image segmentation;computer science;markov decision process;segmentation	Vision	29.57547582360656	-71.94140054683092	195898
4ce562811b2161efd034e74ff9348b8122043deb	an assessment method of tongue image quality based on random forest in traditional chinese medicine		In the study and practice of the tongue characterization, experienced doctors found that a large number of the tongue images collected by tongue image instrument don’t meet the clinical requirement, which will directly affects the final result of tongue image analysis. In this paper, the automatic quality evaluation of tongue image is designed for the first time through the following steps. First, the original tongue images are processed. Second, statistics of local normalized luminance based on natural scene statistics (NSS) model, color, geometric and texture features of tongue images are extracted respectively. Finally, the Random Forest classifier is used to classify. Experimental results show that the method we proposed can get a better evaluation of tongue image quality. This approach can provide reliably reference data for assisted tongue image analysis.	image quality;random forest	Xinfeng Zhang;Yazhen Wang;Guangqin Hu;Jing Zhang	2015		10.1007/978-3-319-22053-6_77	speech recognition	AI	36.41959151970499	-73.94280318111593	196216
074cfffa59603673401763091ce04f60ccb5e48b	a novel method for binarization of badly illuminated document images	binarization;histograms;mathematical morphology;degradation;measurement;morphological operations binarization thresholding document images;document images;text analysis;morphological operation;image compensation document image binarization technique morphological closing operation;morphological operations;estimation;pixel;pixel measurement lighting histograms degradation estimation text analysis;document image processing;document image binarization technique;thresholding;lighting;mathematical morphology document image processing;morphological closing operation;image compensation	This paper presents a novel document image binarization technique that separates text from background in badly illuminated document images. This technique is based on background estimation by using morphological closing operation. Binarization methods can be categorized into two categories: the global methods which do not work well in badly illuminated images, and the local methods which are usually parametric. In this paper a new local method is proposed. The most important feature of this local method is that, contrary to other common local methods, it is not dependent on any parameter. In other words it is an automatic method. Morphological closing operation is used to compensate for uneven background illumination. Closing operation is applied to remove small dark details while living the overall gray and larger dark features relatively undisturbed. Experiment results show that the proposed method offers better result for document images with bad degradation and lighting variance in comparison to former common methods.	binary image;categorization;closing (morphology);elegant degradation;mathematical morphology;morphological parsing;runge–kutta methods;scope (computer science)	Seyed Amin Tabatabaei;Mehdy Bohlool	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5650950	computer vision;estimation;text mining;mathematical morphology;degradation;computer science;pattern recognition;lighting;histogram;mathematics;thresholding;pixel;measurement;statistics;computer graphics (images)	Vision	38.50734621763299	-66.25537964479147	196870
697fa1c1aa81ea1e0dbdfea5c8d7769ab6cbb6df	does the prediction of breast cancer improve using a combination of mammographic density measures compared to individual measures alone?	cancer;breast;breast cancer			Joseph Ryan Wong Sik Hee;Elaine F. Harkness;Soujanya Gadde;Yit Yoong Lim;Anthony J. Maxwell;D Gareth R Evans;Anthony Howell;Susan M. Astley	2017		10.1117/12.2254291	breast cancer;cancer	HCI	34.18816633909064	-75.96151975436041	196903
5a58ca97c28ac90c9fc1e3ae2030ca9278e17ba2	deep learning for image-based cancer detection and diagnosis - a survey			deep learning	Zilong Hu;Jinshan Tang;Ziming Wang;Kai Zhang;Ling Zhang;Qingling Sun	2018	Pattern Recognition	10.1016/j.patcog.2018.05.014		Vision	31.87348112223131	-74.47196780145369	197095
2474bbd56fe9bb7c038d4f7ca50a67005a32b655	fusing texture, shape and deep model-learned information at decision level for automated classification of lung nodules on chest ct		Abstract The separation of malignant from benign lung nodules on chest computed tomography (CT) is important for the early detection of lung cancer, since early detection and management offer the best chance for cure. Although deep learning methods have recently produced a marked improvement in image classification there are still challenges as these methods contain myriad parameters and require large-scale training sets that are not usually available for most routine medical imaging studies. In this paper, we propose an algorithm for lung nodule classification that fuses the texture, shape and deep model-learned information (Fuse-TSD) at the decision level. This algorithm employs a gray level co-occurrence matrix (GLCM)-based texture descriptor, a Fourier shape descriptor to characterize the heterogeneity of nodules and a deep convolutional neural network (DCNN) to automatically learn the feature representation of nodules on a slice-by-slice basis. It trains an AdaBoosted back propagation neural network (BPNN) using each feature type and fuses the decisions made by three classifiers to differentiate nodules. We evaluated this algorithm against three approaches on the LIDC-IDRI dataset. When the nodules with a composite malignancy rate 3 were discarded, regarded as benign or regarded as malignant, our Fuse-TSD algorithm achieved an AUC of 96.65%, 94.45% and 81.24%, respectively, which was substantially higher than the AUC obtained by other approaches.		Yutong Xie;Jianpeng Zhang;Yong Xia;Michael J. Fulham;Yanning Zhang	2018	Information Fusion	10.1016/j.inffus.2017.10.005	convolutional neural network;computed tomography;artificial neural network;pattern recognition;mathematics;deep learning;medical imaging;computer vision;backpropagation;texture descriptor;artificial intelligence;contextual image classification	Vision	32.84536629515769	-75.68204842664349	197131
23adf9f5352fada1cc6a8fbb2dd1ebca71d668ef	fast lyric area extraction from images of printed korean music scores		In recent years, optical music recognition (OMR) has been extensively developed, particularly for use with mobile devices that require fast processing to recognize and play live the notes in images captured from sheet music. However, most techniques that have been developed thus far have focused on playing back instrumental music and have ignored the importance of lyric extraction, which is time consuming and affects the accuracy of the OMR tools. The text of the lyrics adds complexity to the page layout, particularly when lyrics touch or overlap musical symbols, in which case it is very difficult to separate them from each other. In addition, the distortion that appears in captured musical images makes the lyric lines curved or skewed, making the lyric extraction problem more complicated. This paper proposes a new approach in which lyrics are detected and extracted quickly and effectively. First, in order to resolve the distortion problem, the image is undistorted by a method using information of stave lines and bar lines. Then, through the use of a frequency count method and heuristic rules based on projection, the lyric areas are extracted, the cases where symbols touch the lyrics are resolved, and most of the information from the musical notation is kept even when the lyrics and music notes are overlapping. Our algorithm demonstrated a short processing time and remarkable accuracy on two test datasets of images of printed Korean musical scores: the first set included three hundred scanned musical images; the second set had two hundred musical images that were captured by a digital camera. key words: lyric detection, lyric extraction, lyric area, optical music recognition	algorithm;digital camera;distortion;heuristic;mobile device;optical mark recognition;printing	Cong Minh Dinh;Hyung Jeong Yang;Gueesang Lee;Soo-Hyung Kim	2016	IEICE Transactions		speech recognition	ML	36.81334404915983	-67.01624853643247	197351
83f014a2588ebb8ef6bf1a6f909bfcfbd0f3e518	neural networks applied to recognition of ccd camera images where a 3-digit number is stamped on the surface of chip resistors	neural network;chip;ccd camera	We describe Back-Propagation neural networks (BP model) ['I implemented into a visual verification system of numbers stamped on the surface of chip resistors. A 3-digit number is stamped whitely on the rectangular black area, that is on the su@ace of each chip resistor, bordered by a white frame. The number and a fragment of the frame are imaged from a CCD camera. Firstly, the number is circumscribed by a rectangular frame for segmentation in each CCD camera image (this is a segmentation module). Secondly, while a narrow slit window is scanning across the partial image inside the segmented rectangular area, each digit is classified one after another concurrently with separation from its neighbors (this is a recognition module). Both modules are developed by training BP models, Position Network and Recognition Network. Experimental results show that the proposed method could correctly recognize the number even if digits were stamped poorly and imaged with extraneous substances.	artificial neural network;charge-coupled device;software propagation	Katsuji Imai;Kazutoshi Gouhara;Yoshiki Uchikawa	1992			resistor;chip;artificial intelligence;computer vision;artificial neural network;numerical digit;computer science	Vision	32.7113273764287	-69.49921551214454	197480
2476bb2c9891e175431f7d8688284bc2c73e186b	automatic categorization of mammographic masses using bi-rads as a guidance	automatic;categorisation;guidage;mastografia;clinical application;automatico;guiado;image annotation;breast imaging;categorizacion;mammographie;subset selection;automatique;guidance;mammography;categorization	In this study, we present a clinically guided technical method for content-based categorization of mammographic masses. Our work is motivated by the continuing effort in content-based image annotation and retrieval to extract and model the semantic content of images. Specifically, we classified the shape and margin of mammographic mass into different categories, which are designated by radiologists according to descriptors from Breast Imaging Reporting and Data System Atlas (BI-RADS). Experiments were conducted within subsets selected from datasets consisting of 346 masses. In the experiments that categorize lesion shape, we obtained a precision of 70% with three classes and 87.4% with two classes. In the experiments that categorize margin, we obtained precisions of 69.4% and 74.7% for the use of four and three classes, respectively. In this study, we intend to demonstrate that this classification based method is applicable in extracting the semantic characteristics of mass appearances, and thus has the potential to be used for automatic categorization and retrieval tasks in clinical applications.	bi-rads;categorization	Yimo Tao;Shih-Chung Ben Lo;Matthew T. Freedman;Erini Makariou;Jianhua Xuan	2008		10.1117/12.772808	computer vision;computer science;data mining;automatic transmission;automatic image annotation;information retrieval;categorization	NLP	32.36596792471941	-71.86623901495723	197571
cc4a9c100393bfe20f914862fbd78d2251860df4	automated assessment of hemodynamics in the conjunctival microvasculature network	image segmentation hemodynamics blood filtering velocity measurement fluid flow measurement;biological patents;filtering;biomedical journals;image segmentation;image processing;text mining;image processing automated image analysis conjunctival microvasculature hemodynamics;europe pubmed central;citation search;citation networks;fluid flow measurement;velocity measurement blood blood flow measurement blood vessels diameter measurement image segmentation medical image processing shear flow;conjunctival microvasculature;conjunctival microvascular hemodynamic network wall shear rate venules arterioles blood flow detection variance filtering automatic microvessel segmentation frangi filtering conjunctival microcirculation image acquisition blood velocity measurements diameter measurements automated image analysis method microvessels;hemodynamics;research articles;abstracts;blood;open access;life sciences;clinical guidelines;automated image analysis;full text;velocity measurement;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	The conjunctival microcirculation is accessible for direct visualization and quantitative assessment of microvascular hemodynamic properties. Currently available methods to assess hemodynamics in the conjunctival microvasculature use manual or semi-automated algorithms, which can be inefficient for application to a large number of microvessels within the microvascular network. We present an automated image analysis method for measurements of diameter and blood velocity in microvessels. The method was applied to conjunctival microcirculation images acquired in 15 healthy human subjects. Frangi filtering, thresholding, and morphological closing were applied to automatically segment microvessels, while variance filtering was used to detect blood flow. Diameter and blood velocity were measured in arterioles and venules within the conjunctival microvascular network, and blood flow and wall shear rate were calculated. Repeatability and validity of hemodynamic measurements were established. The automated image analysis method allows reliable, rapid and quantitative assessment of hemodynamics in the conjunctival microvascular network and can be potentially applied to microcirculation images of other tissues.	body tissue;closing (morphology);congenital abnormality;conjunctival diseases;diameter (qualifier value);hemodynamics;image analysis;imagery;mathematical morphology;microcirculation;microvessels;repeatability;sample variance;semiconductor industry;structure of arteriole;structure of venule;thresholding (image processing);velocity (software development);algorithm	Maziyar M. Khansari;Justin Wanek;Anthony E. Felder;Nicole Camardo;Mahnaz Shahidi	2016	IEEE Transactions on Medical Imaging	10.1109/TMI.2015.2486619	filter;computer vision;text mining;pathology;image processing;computer science;hemodynamics;image segmentation	Visualization	39.02470226071331	-79.03597760440819	197594
3239e14dbb5b8f0dad95de330d8aa03a110071e9	features for cells and nuclei classification	feature extraction microscopy redundancy support vector machines bioinformatics image edge detection accuracy;support vector machines;edge detection;image classification;microscopy;texture features;image texture;wavelet transforms;accuracy;redundancy;image edge detection;fluorescence microscopy;feature extraction;medical image processing;zernike moment;fluorescent microscopy images cell classification features cell nuclei classification features automated cellular image analysis morphological features topological features texture features feature selection methods zernike moment daubechies wavelets gabor wavelets;feature selection;support vector machine;biomedical optical imaging;algorithms animals cell biology cell cycle cell nucleus computational biology cytological techniques hela cells humans image processing computer assisted microscopy fluorescence models statistical reproducibility of results software;gabor wavelets;cellular biophysics;optical microscopy;wavelet transforms biomedical optical imaging cellular biophysics feature extraction fluorescence spectroscopy image classification image texture medical image processing optical microscopy;fluorescence spectroscopy;bioinformatics	The performance of automated analysis of cellular images is heavily influenced by the features that characterize cells or cell nuclei. In this paper, an exhaustive set of features including morphological, topological, and texture features are explored to determine the optimal features for classification of cells and cell nuclei. The optimal subset of features are obtained using popular feature selection methods. The results of feature selection indicate that Zernike moment, Daubechies wavelets, and Gabor wavelets give the most important features for the classification of cells or cell nuclei in fluorescent microscopy images.	cell nucleus;daubechies wavelet;feature selection;gabor wavelet;subgroup	Song Liu;Piyushkumar A. Mundra;Jagath C. Rajapakse	2011	2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/IEMBS.2011.6091628	support vector machine;computer vision;computer science;microscopy;machine learning;pattern recognition;mathematics;feature selection	Visualization	36.35329399939894	-74.19823442438984	197641
e3165b3911810217d92daa1d89a0f90061f2cc12	a fully-automated zebra animal identification approach based on sift features	animal identification;zebra animal identification;biometrics;sift	Zoonoses (Zoonotic diseases) transferred from animals to human leads to death of many people every year. Controlling and tracking infected animals may save millions of human’s life. One way to help achieve this is to develop an automatic animal identification/recognition systems. In this paper, a fully automated zebra animal identification approach is proposed. In this approach, the Scale Invariant Feature Transform (SIFT) feature extraction method is used to compute the features of 2D zebra images. A matching between training and testing images is calculated based on Support Vector Machine (SVM), Decision Tree (DT), and Fuzzy k-Nearest Neighbour (Fk-NN) classifiers. The experimental results show that the proposed approach is superior than other existed ones in terms of identification accuracy and the automation as our approach is fully automated while the other zebra identification systems are semi-automated or manual. The proposed approach achieved high recognition rate and the SVM classifier in this application is better than the other two classifiers.		Alaa Tharwat;Tarek Gaber;Aboul Ella Hassanien;Gerald Schaefer;Jeng-Shyang Pan	2016		10.1007/978-3-319-48490-7_34	automation;support vector machine;machine learning;fuzzy logic;artificial intelligence;decision tree;feature extraction;animal identification;scale-invariant feature transform;biometrics;computer science	NLP	34.12693149763309	-72.92293900733607	197819
3bba83122d797a23cb8d6dd719bc29f42fd3e214	deep learning based syndrome diagnosis of chronic gastritis	software;chronic disease;symptom assessment;brain;medicine chinese traditional;gastritis;decision support systems clinical;reproducibility of results;artificial intelligence;algorithms;humans;computer simulation	In Traditional Chinese Medicine (TCM), most of the algorithms used to solve problems of syndrome diagnosis are superficial structure algorithms and not considering the cognitive perspective from the brain. However, in clinical practice, there is complex and nonlinear relationship between symptoms (signs) and syndrome. So we employed deep leaning and multilabel learning to construct the syndrome diagnostic model for chronic gastritis (CG) in TCM. The results showed that deep learning could improve the accuracy of syndrome recognition. Moreover, the studies will provide a reference for constructing syndrome diagnostic models and guide clinical practice.	acupuncture and oriental medicine;chronic gastritis;deep learning;hamming distance;hearing loss, high-frequency;high-level programming language;index;information retrieval;nonlinear system;sensorineural hearing loss (disorder);the superficial;toolkit for conceptual modeling;traditional chinese medicine;algorithm;diagnostic criteria;interest	Guo-Ping Liu;Jianjun Yan;Yiqin Wang;Wu Zheng;Tao Zhong;Xiong Lu;Peng Qian	2014		10.1155/2014/938350	computer simulation;alternative medicine;medicine;pathology;computer science;algorithm	AI	29.84205603250144	-78.18213823807973	197831
1ecd2272a6e0f51c66a877a3455355286f73bcda	gabor filter and eigen-flame image-based burning state recognition for sintering process of rotary kiln	image recognition;object recognition;sintering channel bank filters feature extraction flames gabor filters image classification image texture kilns object recognition process control;compact filter bank gabor filter selection eigen flame image based burning state recognition rotary kiln sintering process control flame zones material zones global feature extraction texture analysis eigen flame image decomposition pattern classifier;kilns;image segmentation;filter bank;flames;image classification;gabor filters;materials;image texture;gabor filter;texture analysis;sintering;channel bank filters;feature extraction;image quality;coal;process control;temperature measurement;image decomposition;kilns image recognition feature extraction temperature measurement materials image segmentation coal;large classes	Accurate recognition of burning state is critical in sintering process control of rotary kiln. Recently, flame image-based burning state recognition has received much attention. However, most of the existing methods demand accurate image segmentation, which is quite challenging due to poor image quality caused by smoke and dust inside the kiln. In this study, we develop a more reliable method for burning state recognition without image segmentation issue. From the experience of operators, more discriminable flame and material zones will facilitate the subsequent feature extraction and burning state recognition. Motivated by this knowledge, we propose to include texture analysis based on Gabor filter as a pre-processing to improve the recognition result further and then extract global features based on eigen-flame images decomposition, and finally recognize the burning state using pattern classifier. The advantages of our method are threefold. Firstly, our Gabor filter selection approach can generate a compact filter bank to distinguish ROIs much more and offers help to facilitate the sequel. Secondly, the eigen-flame image method provides global features of an image with large class separability and hence can lead to more accurate classification performance. Thirdly, the new method is more robust and reliable than image segmentation-based methods and temperature-based method. Experimental studies show the effectiveness of our method.	control system;eigen (c++ library);feature extraction;filter bank;gabor filter;image quality;image segmentation;linear separability;preprocessor;robustness (computer science);rotary woofer	Weitao Li;Kezhi Mao;Tianyou Chai;Hong Zhang;Hong Wang	2011	IEEE Conference on Decision and Control and European Control Conference	10.1109/CDC.2011.6160229	image quality;image texture;computer vision;contextual image classification;flame;speech recognition;coal;feature extraction;temperature measurement;computer science;engineering;cognitive neuroscience of visual object recognition;process control;pattern recognition;filter bank;image segmentation;kiln	Robotics	38.02501107346504	-68.41313054940092	197869
b8f8b7713c4961f7989ec5bfcd98afed83d65cac	segmentation of digitized mammograms using self-organizing maps in a breast cancer computer aided diagnosis system	cancer detection;radiology;digitized mammograms;image segmentation;neural networks;computer aided diagnosis;cancer;multilayer perceptrons;multilayer perceptron;self organizing feature maps breast cancer neurons cancer detection mammography radiology neural networks breast biopsy clustering algorithms feature extraction;backpropagation;breast biopsy;computer aided diagnosis system;self organising feature maps;kohonen self organizing maps;self organizing feature maps;feature extraction;backpropagation algorithm;image segmentation cancer medical diagnostic computing mammography self organising feature maps multilayer perceptrons backpropagation;clustering algorithms;self organized map;neurons;mammography;medical diagnostic computing;breast cancer;backpropagation kohonen self organizing maps digitized mammograms feature extraction breast cancer computer aided diagnosis system multilayer perceptron image segmentation	The objective of this work is to develop a digitized mammograms’ feature extraction approach using Kohonen’s Self-Organizing Maps (SOM). Once developed, the SOM network will be used as the first processing stage in a breast cancer computer aided diagnosis (CAD) system. Its role will be to offer segmented data as input to a second stage dedicated to the diagnosis task, which will be implemented via a multi layer perceptron (MLP) trained by the backpropagation algorithm.	algorithm;backpropagation;computer-aided design;feature extraction;memory-level parallelism;organizing (structure);perceptron;self-organizing map	Túlio Cesar Soares dos Santos André;Antônio Carlos Roque da Silva Filho	2002		10.1109/SBRN.2002.1181458	computer vision;computer science;artificial intelligence;backpropagation;machine learning;artificial neural network	AI	34.683347631131674	-74.44326420054539	197949
79c232a4971a6a0fb86972285aee209494c06423	bayesian multiresolution variable selection for ultra-high dimensional neuroimaging data	ultra high dimensional imaging data;block gibbs sampler;input variables computational modeling imaging biological system modeling bayes methods spatial resolution;ising priors;bayesian spatial probit model;multiresolution variable selection;block gibbs sampler multiresolution variable selection bayesian spatial probit model ising priors ultra high dimensional imaging data	Ultra-high dimensional variable selection has become increasingly important in analysis of neuroimaging data. For example, in the Autism Brain Imaging Data Exchange ABIDE study, neuroscientists are interested in identifying important biomarkers for early detection of the autism spectrum disorder ASD using high resolution brain images that include hundreds of thousands voxels. However, most existing methods are not feasible for solving this problem due to their extensive computational costs. In this work, we propose a novel multiresolution variable selection procedure under a Bayesian probit regression framework. It recursively uses posterior samples for coarser-scale variable selection to guide the posterior inference on finer-scale variable selection, leading to very efficient Markov chain Monte Carlo MCMC algorithms. The proposed algorithms are computationally feasible for ultra-high dimensional data. Also, our model incorporates two levels of structural information into variable selection using Ising priors: the spatial dependence between voxels and the functional connectivity between anatomical brain regions. Applied to the resting state functional magnetic resonance imaging R-fMRI data in the ABIDE study, our methods identify voxel-level imaging biomarkers highly predictive of the ASD, which are biologically meaningful and interpretable. Extensive simulations also show that our methods achieve better performance in variable selection compared to existing methods.	atrial septal defects;autism spectrum disorders;autistic disorder;biological markers;early diagnosis;feature selection;financial cost;genetic selection;image resolution;inference;ising model;magnetic resonance imaging;markov chain monte carlo;monte carlo method;mood disorders;neuroimaging;probit model;recursion;rest;resting state fmri;simulation;spatial autocorrelation;voxel;algorithm	Yize Zhao;Jian Kang;Qi Long	2018	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2015.2440244	machine learning;voxel;resting state fmri;computer science;probit model;prior probability;feature selection;inference;markov chain monte carlo;spatial dependence;pattern recognition;artificial intelligence	ML	24.62384591101082	-77.40461176682379	198168
7bd2174878685922c8114429b2d3c724349b7ca1	penalized likelihood phenotyping: unifying voxelwise analyses and multi-voxel pattern analyses in neuroimaging	female;models neurological;brain;penalized likelihood;middle aged;adolescent;male;image processing computer assisted;classification;negotiating;regression;brain mapping;voxel based morphometry;adult;neuroimaging;magnetic resonance imaging;child;child development disorders pervasive;roc curve;risk assessment;artificial intelligence;humans;young adult;multi voxel pattern analysis;phenotype;linear models;nerve fibers myelinated;image phenotyping;generalization risk;diffusion magnetic resonance imaging	Neuroimage phenotyping for psychiatric and neurological disorders is performed using voxelwise analyses also known as voxel based analyses or morphometry (VBM). A typical voxelwise analysis treats measurements at each voxel (e.g. fractional anisotropy, gray matter probability) as outcome measures to study the effects of possible explanatory variables (e.g. age, group) in a linear regression setting. Furthermore, each voxel is treated independently until the stage of correction for multiple comparisons. Recently, multi-voxel pattern analyses (MVPA), such as classification, have arisen as an alternative to VBM. The main advantage of MVPA over VBM is that the former employ multivariate methods which can account for interactions among voxels in identifying significant patterns. They also provide ways for computer-aided diagnosis and prognosis at individual subject level. However, compared to VBM, the results of MVPA are often more difficult to interpret and prone to arbitrary conclusions. In this paper, first we use penalized likelihood modeling to provide a unified framework for understanding both VBM and MVPA. We then utilize statistical learning theory to provide practical methods for interpreting the results of MVPA beyond commonly used performance metrics, such as leave-one-out-cross validation accuracy and area under the receiver operating characteristic (ROC) curve. Additionally, we demonstrate that there are challenges in MVPA when trying to obtain image phenotyping information in the form of statistical parametric maps (SPMs), which are commonly obtained from VBM, and provide a bootstrap strategy as a potential solution for generating SPMs using MVPA. This technique also allows us to maximize the use of available training data. We illustrate the empirical performance of the proposed framework using two different neuroimaging studies that pose different levels of challenge for classification using MVPA.	apolipoprotein e phenotyping:prid:pt:bld:nom;computer assisted diagnosis;forecast of outcome;fractional anisotropy;gray matter;interaction;machine learning;map;mental disorders;morphometric analysis;morphometrics;neuroimaging;nevus sebaceous;numerous;receiver operating characteristic;receiver operator characteristics;statistical learning theory;unified framework;voxel;explanation;nervous system disorder;triangulation	Nagesh Adluru;Bret M. Hanlon;Antoine Lutz;Janet E. Lainhart;Andrew L. Alexander;Richard J. Davidson	2012	Neuroinformatics	10.1007/s12021-012-9175-9	psychology;risk assessment;econometrics;neuroscience;developmental psychology;regression;radiology;young adult;biological classification;magnetic resonance imaging;phenotype;linear model;brain mapping;negotiation;receiver operating characteristic;statistics;neuroimaging;voxel-based morphometry	ML	24.84937340200229	-79.38899382645243	198195
8b137891e4d077bd1f84f9af8e64d023c872db92	estimating maximal measurable performance for automated decision systems from the characteristics of the reference standard. application to diabetic retinopathy screening	standards diabetes retinopathy mathematical model diseases vectors pathology;vision defects biomedical measurement diseases eye probability sensitivity analysis;receiver operating characteristic estimating maximal measurable performance reference standard characteristics diabetic retinopathy screening automated binary decision systems roc curve single human reader multiple human readers eye fundus examinations iowa detection program	We investigate the maximal performance that can be measured for automated binary decision systems in terms of area under the ROC curve (AUC), against a reference standard provided by human readers. The goal is to determine the required characteristics of the reference standard to assess and compare automated decision systems with a given degree of confidence, or, to determine what degree of confidence can be obtained given the characteristics of the reference standard. We modeled the expected value of the AUC that can be measured for a perfect decision system, given a reference standard provided either by a single human reader or by multiple human readers (consensus, majority vote). The proposed model was applied to diabetic retinopathy screening in a dataset of 874 eye fundus examinations graded by three readers. The expected value of the AUC for a perfect decision system was estimated at 0.956 against a single human reader, and 0.990 against a `majority wins' vote of three human readers. The Iowa detection program has reached the maximal performance measurable by a single human reader (0.929, CI: [0.897-0.962]) and is close to the maximal performance measurable by a `majority wins' vote (0.955, CI: [0.939-0.972]).	area under curve;consensus (computer science);decision support system;diabetic retinopathy;estimated;maximal set;receiver operating characteristic;reference standards;retinal diseases;silo (dataset);structure of fundus of eye;technical standard	Gwénolé Quellec;Michael D. Abràmoff	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6943552	computer vision;computer science;optometry;diabetes mellitus	Vision	34.774367050298274	-79.59080843105404	198639
3d9b91564020515f3deea79cf42fc8dbac3cd154	automatic localization of the optic disc center in retinal images based on angle detection in curvature scale space	css angles detection;retinal image;optic disc	Digital images of the retina is widely used for screening of patients suffering from sight threatening diseases such as Diabetic retinopathy and Glaucoma. The localization of the Optic Disc (OD) center is the first and necessary step identification and segmentation of anatomical structures and in pathological retinal images. From the center of the optic disc spreads the major blood vessels of the retina. Therefore, by considering the high number of vessels and the high number of the angles resulted from the vessels crossing, the authors propose a new method based on the number of angles in the vicinity of optic disc for localization of the center of optic disc. The first step is pre-processing of retinal image for separate the fundus from its background and increase the contrast between contours. In the second step, the authors use the Curvature Scale Space (CSS) for angle detection. In the next step, they move a window about the size of optic disc to count the number of corners. In the final step, they use the center of windows which has the most number of corners for localizing the optic disc center. The proposed method is evaluated on DRIVE, CHASE_DB1 and STARE databases and the success rate is 100, 100 and 96.3%, respectively. Automatic Localization of the Optic Disc Center in Retinal Images based on Angle Detection in Curvature Scale Space		Abderrahmane Elbalaoui;Mohamed Fakir;Mehdi Boutaounte;Abdelkarim Merbouha	2015	JECO	10.4018/JECO.2015040101	computer vision	Vision	37.29311833536401	-76.9053759589237	199225
868237a479bdcb18ef5756b4354636cdd2a82e6e	automated retina identification based on multiscale elastic registration	retinal fundus images;biometrics;elastic image registration;retina identification;vessel network	In this work we propose a novel method for identifying individuals based on retinal fundus image matching. The method is based on the image registration of retina blood vessels, since it is known that the retina vasculature of an individual is a signature, i.e., a distinctive pattern of the individual. The proposed image registration consists of a multiscale affine registration followed by a multiscale elastic registration. The major advantage of this particular two-step image registration procedure is that it is able to account for both rigid and non-rigid deformations either inherent to the retina tissues or as a result of the imaging process itself. Afterwards a decision identification measure, relying on a suitable normalized function, is defined to decide whether or not the pair of images belongs to the same individual. The method is tested on a data set of 21721 real pairs generated from a total of 946 retinal fundus images of 339 different individuals, consisting of patients followed in the context of different retinal diseases and also healthy patients. The evaluation of its performance reveals that it achieves a very low false rejection rate (FRR) at zero FAR (the false acceptance rate), equal to 0.084, as well as a low equal error rate (EER), equal to 0.053. Moreover, the tests performed by using only the multiscale affine registration, and discarding the multiscale elastic registration, clearly show the advantage of the proposed approach. The outcome of this study also indicates that the proposed method is reliable and competitive with other existing retinal identification methods, and forecasts its future appropriateness and applicability in real-life applications.	amazon elastic compute cloud (ec2);arabic numeral 0;biometrics;biometry and biostatistics (occupation or discipline);blood supply aspects;body tissue;clock rate;computation;deny (action);elastic matching;enhanced entity–relationship model;image registration;muscle rigidity;norm (social);patients;projections and predictions;real life;rejection sampling;retinal diseases;retinal scan;silo (dataset);structure of blood vessel of retina;virtual retinal display;registration - actclass	Isabel N. Figueiredo;Susana D. Moura;Júlio S. Neves;Luís Pinto;Sunil Kumar;Carlos Manta Oliveira;João Diogo Ramos	2016	Computers in biology and medicine	10.1016/j.compbiomed.2016.09.019	computer vision;biometrics	Vision	36.48485244554113	-79.57334754115442	199359
02c99c27773b568fadff6fd8af7efd4a29c54741	highlighted deep learning based identification of pharmaceutical blister packages		Precise identification of blister packages carries utmost importance at dispensing stations, where numerous prescriptions are to be efficiently dispensed by pharmacists. However, the usual presence of several hundreds of similarly looking, but completely different types of blister packages, in a crowded dispensing station makes it prone to human error, posing serious safety and health concerns for a patients life. In this work, we propose a highlighted deep learning (HDL) based approach for accurate identification of blister packages. HDL allows smart manipulation on raw data in order to better segment the identified targets and to expose inherent descriptive features, thus facilitating an accurate deep learning based classification process. Specifically, HDL uses automatic detection and then segments and processes the raw blister pack images irrespective of position, lighting variations, etc., making them suitable for CNN to classify the correct blister pack types. A ResNet CNN classifier has been trained using the processed images, and the resultant CNN model is finally deployed for classification. We have conducted an extensive experiment at the adult lozenge dispensing station of MacKay Memorial Hospital. The database that will be released along with this paper, consists of 272 types of blister packages, with 65 images belonging to each type for training and additional 7 images for validation. On real testing scenario, the proposed approach yielded almost 100% accuracy, consistently over the entire testing set. The proposed solution can also be extended to any dispensing station for automatic detection and classification of blister packages, thereby offering an highly effective and efficient delivery system.	deep learning;hardware description language;human error;lozenge;norm (social);resultant;test data	Willie A Bidot;Arul-Murugan Ambikapathi;Yun Han;Sheng-Luen Chung;Hsien-Wei Ting;Chih-Fang Chen	2018	2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA)	10.1109/ETFA.2018.8502488		SE	32.777396228478004	-76.92681437070075	199475
8a64b575546ac0a8949bdf28e9c3c2f3a8517bae	high dynamic range microscopy for cytopathological cancer diagnosis	nuclear segmentation high dynamic range microscopy cytopathological cancer diagnosis cell based cancer diagnosis bright field light microscopy microscope mounted camera computer assisted microscopy image analysis hdr microscopy based algorithms cytopathological oncology silver stained nucleolar organizer regions stained cell detection immunocytochemical preparations color separation;cause of death;image segmentation;colored noise;cancer;color;optical microscopy biomedical optical imaging cancer cellular biophysics image sensors medical image processing;microscopy;microscopy biomedical image processing cancer color imaging;light microscopy;image sensors;image color analysis;medical image processing;cancer diagnosis;imaging;dynamic range;biomedical image processing;robustness;biomedical optical imaging;high dynamic range;dynamic range microscopy cancer detection cameras colored noise image analysis noise reduction oncology silver image segmentation;cellular biophysics;optical microscopy;color image	Cancer is one of the most common causes of death. Cytopathological, i.e., cell-based, diagnosis of cancer can be applied in screening scenarios and allows an early and highly sensitive detection of cancer, thus increasing the chance for cure. The detection of cancer on cells addressed in this paper is based on bright field light microscopy. The cells are imaged with a camera mounted on a microscope, allowing to measure cell properties. However, these cameras exhibit only a limited dynamic range, which often makes the quantification of properties difficult or even impossible. Consequently, to allow a computer-assisted analysis of microscopy images, the imaging has to be improved. To this end, we show how the dynamic range can be increased by acquiring a set of differently exposed cell images. These high dynamic range (HDR) images allow to measure cellular features that are otherwise difficult to capture, if at all. We show that HDR microscopy not only increases the dynamic range, but furthermore reduces noise and improves the acquisition of colors. We develop HDR microscopy-based algorithms, which are essential for cytopathological oncology and early cancer detection and only possible with HDR microscopy imaging. We show the detection of certain subcellular features, so-called AgNORs, in silver (Ag) stained specimens. Furthermore, we give examples of two further applications, namely: 1) the detection of stained cells in immunocytochemical preparations and 2) color separation for nuclear segmentation of specimens stained with low contrast.	algorithm;color;experiment;high dynamic range;high-dynamic-range imaging;image noise;image processing	André A. Bell;Johannes Brauers;Jens N. Kaftan;Dietrich Meyer-Ebrecht;Alfred Böcking;Til Aach	2009	IEEE Journal of Selected Topics in Signal Processing	10.1109/JSTSP.2008.2011101	computer vision;dynamic range;colors of noise;color image;computer science;microscopy;cause of death;image segmentation;robustness;cancer	Vision	38.73012639866174	-75.19592191821279	199512
8809298bc374a3deb0bb25ea8ab820452f9ed16d	slideseg: a python module for the creation of annotated image repositories from whole slide images.		Machine learning methods are being widely used in medicine to aid cancer diagnosis and detection. In the area of digital pathology, prediction heat maps produced by convolutional neural networks (CNN) have already exceeded the performance of a trained pathologist with no time constraints. To train deep learning networks, large datasets of accurately labeled ground truth data are required; however, whole slide images are often on the scale of 10p gigapixels when digitized at 40X magnification, contain multiple magnification levels, and have unstandardized formats. Due to these characteristics, traditional techniques for the production of training and validation data cannot be used, resulting in the limited availability of annotated datasets. This research presents a Python module and method to rapidly produce accurately annotated image patches from whole slide images. This module is built on OpenCV, an open source computer vision library, OpenSlide, an open source library for reading virtual slide images, and NumPy, a library for scientific computing with Python. These Python scripts successfully produce u0027ground truthu0027 image patches and will help transfer advances in research laboratories into clinical application by addressing many of the challenges associated with the development of annotated datasets for machine learning in histopathology.		Brendan Crabb;Niels Olson	2018		10.1117/12.2300262	convolutional neural network;numpy;deep learning;digital pathology;scripting language;python (programming language);computer vision;ground truth;computer science;artificial intelligence;virtual slide	Vision	29.31087474206751	-74.17273821090433	199670
31cf1c5198a37a8bee0e9a497744a110dcdb72f1	region segmentation in histopathological breast cancer images using deep convolutional neural network	image segmentation breast cancer training kernel neural networks scalability;kernel;neural nets cancer image classification image recognition image segmentation medical image processing;image segmentation;neural networks;training;texton based pixel wise methods region segmentation histopathological breast cancer images deep convolutional neural network computer aided diagnosis breast cancers automatic image analysis regional variations computational costs pixel wise segmentation fast scanning deep convolutional neural network fcnn image recognition image classification lbp feature based methods local binary pattern;scalability;breast cancer	Computer aided diagnosis of breast cancers often relies on automatic image analysis of histopathology images. The automatic region segmentation in breast cancer is challenging due to: i) large regional variations, and ii) high computational costs of pixel-wise segmentation. Deep convolutional neural network (CNN) is proven to be an effective method for image recognition and classification. However, it is often computationally expensive. In this paper, we propose to apply a fast scanning deep convolutional neural network (fCNN) to pixel-wise region segmentation. The fCNN removes the redundant computations in the original CNN without sacrificing its performance. In our experiment it takes only 2.3 seconds to segment an image with size 1000 × 1000. The comparison experiments show that the proposed system outperforms both the LBP feature-based and texton-based pixel-wise methods.	analysis of algorithms;artificial neural network;belief propagation;computation;computer performance;computer vision;convolutional neural network;deep learning;effective method;experiment;image analysis;pixel;scalability;texton	Hai Su;Fujun Liu;Yuanpu Xie;Fuyong Xing;Sreenivasan Meyyappan;Lin Yang	2015	2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2015.7163815	computer vision;kernel;scalability;computer science;breast cancer;machine learning;segmentation-based object categorization;pattern recognition;region growing;image segmentation;scale-space segmentation;artificial neural network	Vision	31.968923897108787	-74.95809139826358	199747
3bdd5200877acc951a86cef0e38aad112f84165e	optimal feature selection for automated classification of fdg-pet in patients with suspected dementia	brain;frontotemporal dementia;pet imaging;neurodegenerative disorder;neurodegenerative disease;automated classification;fdg pet;pattern recognition;brain imaging;dementia;normal control;feature selection;classification accuracy;human brain;diseases and disorders	FDG-PET is increasingly used for the evaluation of dementia patients, as major neurodegenerative disorders, such as Alzheimer's disease (AD), Lewy body dementia (LBD), and Frontotemporal dementia (FTD), have been shown to induce specific patterns of regional hypo-metabolism. However, the interpretation of FDG-PET images of patients with suspected dementia is not straightforward, since patients are imaged at different stages of progression of neurodegenerative disease, and the indications of reduced metabolism due to neurodegenerative disease appear slowly over time. Furthermore, different diseases can cause rather similar patterns of hypo-metabolism. Therefore, classification of FDG-PET images of patients with suspected dementia may lead to misdiagnosis. This work aims to find an optimal subset of features for automated classification, in order to improve classification accuracy of FDG-PET images in patients with suspected dementia. A novel feature selection method is proposed, and performance is compared to existing methods. The proposed approach adopts a combination of balanced class distributions and feature selection methods. This is demonstrated to provide high classification accuracy for classification of FDG-PET brain images of normal controls and dementia patients, comparable with alternative approaches, and provides a compact set of features selected.© (2009) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	feature selection;functional discourse grammar;polyethylene terephthalate	Ahmed Serag;Fabian Wenzel;Frank Thiele;Ralph Buchert;Stewart Young	2009		10.1117/12.811562	feature selection	ML	30.984609010962107	-78.4185463448931	199940
